<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 17 Apr 2025 16:36:37 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>有了它，AI 都能直接管理 Gitee 代码仓啦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;不久前，Gitee 开源了官方的 MCP Server——&lt;a href=&quot;https://gitee.com/oschina/mcp-gitee&quot; rel=&quot;nofollow&quot;&gt;Gitee MCP Server&lt;/a&gt;。有了它，我们就能用 AI 助手直接管理 Gitee 代码仓了！&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;读取文件内容、查看 PR 变更、理解 Issue 描述，甚至直接操作代码管理任务，比如创建 PR、合并分支、发布版本等等，全都不是问题。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;简单来说，Gitee MCP Server 让 AI 不再是「代码的旁观者」，真正成为了参与软件开发过程的智能助手。&lt;/p&gt; 
 &lt;p&gt;如果你是&lt;strong&gt;个人开发者&lt;/strong&gt;， Gitee MCP Server 可以让 AI 助手直接参与 PR 审查，减少低级错误，提高代码质量；如果你是&lt;strong&gt;开源项目维护者&lt;/strong&gt;，可以接入 Gitee MCP Server，让 AI 助手帮助处理大量 Issue，并提供自动化代码审查，提升社区协作效率。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;既然它是一个 MCP Server，那么所有支持 MCP Client 的应用都能用，&lt;/strong&gt;比如 Cursor、claude desktop、windsurf、cherry studio 或是自行实现的带有 mcp client 的 Agent，等等。（之前「马建仓」就&lt;a href=&quot;https://www.oschina.net/news/340077&quot; rel=&quot;nofollow&quot;&gt;秀了把操作&lt;/a&gt;：没写一行代码，只用 Cursor 和 Gitee MCP 做了个贪吃蛇游戏。 ）&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a4168709eaed70c553754b7015120c1931.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;那么，这么好用的东西怎么用呢？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;4 月 21 日晚，&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;Gitee 研发工程师黄家建&lt;/span&gt;&lt;/strong&gt;将做客【开源中国】直播栏目《技术领航》，手把手教学如何上手 Gitee MCP Server：从安装与配置开始，实战演练如何用 AI 开发工具结合 Gitee MCP Server 实现 AI + 研发流程的融合。&lt;/p&gt; 
 &lt;p&gt;当然啦，作为 Gitee MCP Server 核心开发者，黄家建还会结合自己的实践经验，讲一讲 MCP 协议是什么，与 function call 到底有什么区别。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;赶紧打开微信，扫码预约直播吧~&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;1840&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-858977b0e133cc1bd2a46be9d6dc787b8dc.png&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。&lt;br&gt; 目前，Gitee 已经有超过 1350 万名开发者，累计托管超过 3600 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 36 万家企业。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;网址：&lt;a href=&quot;https://gitee.com/&quot; rel=&quot;nofollow&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技术领航》是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18184933</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18184933</guid>
            <pubDate>Sun, 13 Apr 2025 13:44:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>北京市人工智能产业投资基金追加投资智谱（Z.ai）2 亿元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1829640482444053837%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;《北京日报》报道称&lt;/a&gt;，&lt;strong&gt;北京市人工智能产业投资基金追加投资北京智谱华章科技股份有限公司（以下简称智谱）2 亿人民币。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京市人工智能产业投资基金表示，智谱是基金成立以来投资的第一家 AI 大模型企业，也是目前成长最快的企业。智谱在包括文本、推理、语音、图像、视频、代码等在内的全面模型能力上有深厚积累。此外，商业化布局完善，拥有超过百万规模的开发者社区和企业用户。&lt;/p&gt; 
&lt;p&gt;北京市人工智能产业投资基金表示：希望通过这次投资，进一步推动智谱在开源模型和算法创新方面的能力建设。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4 月 15 日，智谱开源 32B/9B 系列 GLM 模型，包括了基座、推理和沉思模型，所有模型采用宽松的 MIT 许可协议，免费商用、分发，引发业内关注。与此同时，智谱启用全新域名 Z.ai，目前该平台整合了 32B 基座、推理、沉思三类 GLM 模型，后续将作为智谱最新模型的交互体验入口。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;472&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/192641_FbK5_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智谱此前在开源方面已经做了很多贡献，2023 年率先开源国内第一个 Chat 大模型 ChatGLM-6B，短时间内就吸引超过千万次下载。智谱持续为开源社区和大模型生态发展注入源源不断的活力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京市人工智能产业投资基金自 2023 年 12 月成立以来，围绕北京市在人工智能领域的总体布局，开展直接股权投资。重点方向包括人工智能芯片、训练数据及相关软件等底层技术领域，大模型算法创新、具身智能、可信 AI 等关键领域，以及大模型等人工智能技术产品开发和垂直行业创新应用等相关领域。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344631&quot; target=&quot;news&quot;&gt;智谱启动上市辅导&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344598&quot; target=&quot;news&quot;&gt;智谱开源 32B/9B 系列 GLM 模型，极速版最高达到 200 tokens/秒&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345155</guid>
            <pubDate>Sun, 13 Apr 2025 11:29:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Figma 要求 AI 初创公司停止使用「Dev Mode」一词</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;近日，设计协作平台 Figma 向瑞典人工智能编程初创公司 Loveable 发出了一份停止使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FBillHeyman%2Fstatus%2F1912182928471412932&quot; target=&quot;_blank&quot;&gt;警告&lt;/a&gt;，原因是 &lt;strong&gt;Loveable 将其新产品的某项功能命名为「Dev Mode」，而 Figma 声称该术语已被其注册为商标&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a60eef82084c2c7bde0249e75284af4f5bc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftsdr.uspto.gov%2F%23caseNumber%3D98045640%26caseSearchType%3DUS_APPLICATION%26caseType%3DDEFAULT%26searchType%3DstatusSearch&quot; target=&quot;_blank&quot;&gt;据美国专利商标局的记录显示&lt;/a&gt;，Figma 在 2024 年 11 月成功注册了「Dev Mode」商标。该公司于 2023 年推出了自己的「Dev Mode」功能，旨在帮助设计师和开发者更好地协作。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1838&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/183511_QrFp_2720166.png&quot; width=&quot;2684&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.figma.com%2Fdev-mode%2F&quot; target=&quot;_blank&quot;&gt;https://www.figma.com/dev-mode/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Figma 在致 Loveable 的信中表示：「我们很荣幸您认同‘Dev Mode’是连接设计与开发的软件工具的理想名称。」&lt;/p&gt; 
&lt;p&gt;然而，Figma 强调，该术语已与其软件广泛关联，并且公司需要「保护我们的知识产权」，因此要求 Loveable 停止在其产品中使用「Dev Mode」一词。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345147/figma-the-term-dev-mode</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345147/figma-the-term-dev-mode</guid>
            <pubDate>Sun, 13 Apr 2025 10:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Qt AI Assistant v0.9 发布，AI 驱动的开发助手</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;过去两年中，Qt 一直在努力拥抱生成式 AI，以增强 Qt Creator 中 Qt/QML/C++应用程序的编码能力。去年推出的 Qt AI Assistant 是一款 AI 驱动的开发助手，可在 Qt Creator 中运行，支持多种大型语言模型（LLM）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-45670371548f2d5dce858a5fa6c1497cc5e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1240&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/182356_Duh4_2720166.png&quot; width=&quot;2308&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Qt AI Assistant v0.9 已于近日发布，旨在为构建 Qt/C++软件提供最新的 AI 驱动编码帮助。现在，通过 CodeLlama-7B-QML 和 DeepSeekCoder v2 Lite 语言模型支持，Qt AI Assistant 提供了本地 LLM 支持。&lt;/p&gt; 
&lt;p&gt;Qt 还发布了 CodeLlama-7B-QML 和 CodeLlama-13B-QML 作为他们在 HuggingFace 和 Ollama 上微调的模型，这些模型基于额外的 QML 代码片段进行训练。&lt;/p&gt; 
&lt;p&gt;Qt AI Assistant v0.9 还增加了流式文本支持，以便更好地逐段处理大型语言模型的响应。同时，还引入了利用 AI 构建 Google Test 测试的初步支持。此外，Qt AI Assistant 现在还能够为 QML 和 C++ 代码生成内联代码注释。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qt.io%2Fblog%2Fqt-ai-assistant-v0.9-released-deploy-llms-locally-and-enjoy-the-upgraded-user-experience&quot; target=&quot;_blank&quot;&gt;Qt 博客&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345140/qt-ai-assistant-v0-9-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345140/qt-ai-assistant-v0-9-released</guid>
            <pubDate>Sun, 13 Apr 2025 10:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Scala 语言未来如何进化？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;blockquote&gt; 
 &lt;p&gt;Scala 语言创建者 Martin Odersky 以及关键库作者与维护者李浩毅描述了他们对 Scala 语言未来的规划，并希望 Scala 能在现代编程领域保有一席之地。&lt;/p&gt; 
 &lt;p&gt;原文：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2025%2F03%2F24%2Fevolving-scala.html&quot; target=&quot;_blank&quot;&gt;Evolving Scala&lt;/a&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Scala 应该前进得多快？需要改进什么？语言本身是否应该改变？本文讨论了&lt;strong&gt;Scala 必须不断进化&lt;/strong&gt;的原因，为什么这种进化是必要的，以及我们预计这种进化将采取哪些方向。&lt;/p&gt; 
&lt;p&gt;我们希望这能涵盖许多关于 Scala 语言方向的常见问题，并帮助社区了解语言在未来几个月和几年中将走向何方。&lt;/p&gt; 
&lt;h2&gt;摘要&lt;/h2&gt; 
&lt;p&gt;尽管 Scala 不再像 2010 年代中期那样处于炒作的风口浪尖，根据大多数调查，该语言保持在主流语言列表之外。从技术角度来看，核心语言和生态系统在过去十年中得到了极大的改善。在许多方面，Scala 今天的基石比十年前要好得多。&lt;/p&gt; 
&lt;p&gt;Scala 一直引领着编程领域的潮流。为了换取比主流语言略逊一筹的打磨和稳定性，人们选择 Scala，以便今天就能享受到下个十年的语言特性。Scala 的价值始终在于这些语言特性所赋予的独特组合——&lt;strong&gt;&lt;em&gt;安全性和便利性&lt;/em&gt;&lt;/strong&gt;，以及它将&lt;strong&gt;&lt;em&gt;面向对象和函数式编程&lt;/em&gt;&lt;/strong&gt;思想融合在一起，从而优雅地适应这些特性。&lt;/p&gt; 
&lt;p&gt;但其他语言也在不断进步，因此 Scala 必须继续创新，在它的优势和劣势上不断改进，特别关注新用户的入门体验。当然，有一些持续存在的问题，尤其是在 IDE 支持以及生态系统的易学性方面，随着语言的发展，工具、兼容性和迁移成本等问题也始终会存在。但如果 Scala 想要在未来几年保持其吸引力和相关性，它别无选择，只能继续前进。&lt;/p&gt; 
&lt;h2&gt;Scala 当前所处的位置&lt;/h2&gt; 
&lt;p&gt;尽管炒作已经消退，但从普及度来看，Scala 仍然处於其一贯的位置：并不完全属于主流，但比那些更小众的语言有着更广泛的采用率。例如，RedMonk 语言排名在 2014 年将 Scala 排在第 14 位（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2014%2F06%2F13%2Flanguage-rankings-6-14%2F&quot; target=&quot;_blank&quot;&gt;2014 年的排名&lt;/a&gt;），10 年后的 2024 年仍然在第 14 位（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2024%2F09%2F12%2Flanguage-rankings-6-24%2F&quot; target=&quot;_blank&quot;&gt;2024 年的排名&lt;/a&gt;）。&lt;/p&gt; 
&lt;p&gt;在这段时间里，编程领域发生了显著变化：Swift 取代了 Objective C，Go、Kotlin、Dart 和 Rust 的出现，CoffeeScript 和 Perl 的衰落。然而，Scala 的位置始终保持不变。尽管社区中的个人来来去去，但整体而言，Scala 似乎保持着强大的稳定性，拥有一个坚实的爱好者基础。&lt;/p&gt; 
&lt;p&gt;技术上，Scala 现在比 10 年前拥有更坚实的基础。生态系统已经成熟，各种反应式或纯函数式编程风格已经找到了他们的受众。像&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Ftoolkit%2Fintroduction.html&quot; target=&quot;_blank&quot;&gt;Scala Toolkit&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcom-lihaoyi&quot; target=&quot;_blank&quot;&gt;com.lihaoyi&lt;/a&gt;平台这样的替代风格现在也可供选择。新的构建工具如&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscala-cli.virtuslab.org%2F&quot; target=&quot;_blank&quot;&gt;Scala-CLI&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmill-build.org%2F&quot; target=&quot;_blank&quot;&gt;Mill&lt;/a&gt;已经出现，而开发者工具如&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fscalafmt&quot; target=&quot;_blank&quot;&gt;Scalafmt&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalacenter%2Fscalafix&quot; target=&quot;_blank&quot;&gt;Scalafix&lt;/a&gt;已经得到广泛应用。IDE 仍然是一个痛点，但我们预计到 2025 年它们会有所改进。重用符号运算符的潮流已经逐渐式微。&lt;/p&gt; 
&lt;p&gt;Scala 一直处于语言前沿，证明了像 lambda 表达式、记录和模式匹配等语言特性在 10-15 年后被 Java、Python 和其他主流语言采纳的可行性。目前尚不清楚主流语言在 10-15 年后将会采纳 Scala 的哪些当前特性。&lt;/p&gt; 
&lt;h2&gt;Scala 将走向何方？&lt;/h2&gt; 
&lt;p&gt;在本节中，我们将讨论核心 Scala 开发者将集中精力的一些领域。&lt;/p&gt; 
&lt;h3&gt;安全性与便利性：两者取其一&lt;/h3&gt; 
&lt;p&gt;Scala 一直是一种混合型语言。面向对象和函数式风格的融合经常被提及。但它的另一种融合是 &lt;em&gt;安全性&lt;/em&gt; 和 &lt;em&gt;便利性&lt;/em&gt;。传统上，「脚本」语言如 Python 不安全但方便，而「应用」语言如 Java 安全但不便。Scala 是第一个证明你可以在同一语言中做到这两点的语言。更现代的语言如 Swift 或 Kotlin 也在这条道路上取得了进步，当 Scala 最初开始时，这种想法是闻所未闻的。&lt;/p&gt; 
&lt;p&gt;然而，过去二十年里，编程领域并没有停滞不前。曾经属于 Scala 的许多独特之处现在已成为普遍现象。所有现代语言都提供了泛型、类型推断、lambda 表达式、记录、模式匹配等特性。为了继续吸引用户，Scala 必须在这两个方向上继续创新：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提升安全性而不牺牲便利性&lt;/strong&gt;：例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fexperimental%2Fcc.html&quot; target=&quot;_blank&quot;&gt;捕获检查&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fexperimental%2Fexplicit-nulls.html&quot; target=&quot;_blank&quot;&gt;显式空值&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fother-new-features%2Fsafe-initialization.html&quot; target=&quot;_blank&quot;&gt;安全初始化&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Fbook%2Fca-multiversal-equality.html&quot; target=&quot;_blank&quot;&gt;多态等价&lt;/a&gt; 等特性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;在不妥协安全性的前提下提高便利性&lt;/strong&gt;：如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fenums%2Fenums.html&quot; target=&quot;_blank&quot;&gt;枚举&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fother-new-features%2Findentation.html&quot; target=&quot;_blank&quot;&gt;可选括号&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdotty.epfl.ch%2Fdocs%2Freference%2Fother-new-features%2Fnamed-tuples.html&quot; target=&quot;_blank&quot;&gt;命名元组&lt;/a&gt; 等特性。关于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcontributors.scala-lang.org%2Ft%2Fpre-sip-a-syntax-for-aggregate-literals%2F6697&quot; target=&quot;_blank&quot;&gt;聚合数据字面量&lt;/a&gt; 的讨论激起了广泛的兴趣，尽管目前还太早看到它将带来什么结果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Scala 生态系统广泛且多样化，但我们认为这些双重目标是共同的主线。无论您是在 JVM 上使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fakka.io%2F&quot; target=&quot;_blank&quot;&gt;Akka&lt;/a&gt; 实现后端服务，通过 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fscala.js%2F&quot; target=&quot;_blank&quot;&gt;Scala.js&lt;/a&gt; 在浏览器中构建 Web UI，还是通过 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chisel-lang.org%2F&quot; target=&quot;_blank&quot;&gt;Chisel&lt;/a&gt; 定制硅芯片，Scala 的安全性和便利性是人们选择这种语言的原因。&lt;/p&gt; 
&lt;p&gt;其他语言也在追求这些目标，但我们相信 Scala 做得比大多数语言都要好：它的类型系统、模式匹配、集合库、多重继承系统等都是业界领先的，即使其他语言也有自己的特色。因此，Scala 能够比其他语言更好地执行和组合特性，并以一种统一、简洁和原则性的方式将这些特性结合起来，而不是临时性地拼接它们。&lt;/p&gt; 
&lt;p&gt;展望未来，Scala 必须继续追求安全性和便利性的双重目标。明天的流行框架可能与今天的不同，而今天的又与几年前的不同。但几十年来，开发者们一直希望获得安全性和便利性，我们预计在未来几年这种需求将继续存在。&lt;/p&gt; 
&lt;h3&gt;打磨「粗糙边缘」&lt;/h3&gt; 
&lt;p&gt;Scala 已不再是新兴语言。二十年前，许多事物看似是好的想法，但并非所有决定都取得了预期的效果。尽管长期使用 Scala 的开发者可能已经习惯了这些特性，但 Scala 语言本身需要不断打磨这些粗糙的边缘：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;一些特性，如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Foverviews%2Fcore%2Factors.html&quot; target=&quot;_blank&quot;&gt;scala-actors&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala-parser-combinators&quot; target=&quot;_blank&quot;&gt;scala-parser-combinators&lt;/a&gt; 或 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala-xml&quot; target=&quot;_blank&quot;&gt;scala-xml&lt;/a&gt; 已经被移除。它们现在作为独立的库存在，你可以根据需要选择使用或不使用，但已不再是语言的核心部分或标准库的一部分。其他类似的清理工作包括 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2018%2F06%2F13%2Fscala-213-collections.html&quot; target=&quot;_blank&quot;&gt;Scala 2.13 集合重写&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;正在处理的更多问题包括：&lt;code&gt;@unroll&lt;/code&gt; 以避免与默认参数和 &lt;code&gt;case class&lt;/code&gt; 的二进制兼容性问题，这是实验性的（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F78&quot; target=&quot;_blank&quot;&gt;SIP-61&lt;/a&gt;），以及 &lt;code&gt;for&lt;/code&gt;-comprehension 的改进处于预览阶段（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F79&quot; target=&quot;_blank&quot;&gt;SIP-62&lt;/a&gt;），这些改进应该有助于解决使用这些 Scala 语言特性时长期存在的问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一些其他长期存在的问题尚未得到解决，但正在讨论中：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F105&quot; target=&quot;_blank&quot;&gt;灵活的变长参数&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcontributors.scala-lang.org%2Ft%2Funpacking-classes-into-method-argument-lists%2F6329&quot; target=&quot;_blank&quot;&gt;解包&lt;/a&gt;、涉及 &lt;code&gt;for&lt;/code&gt;-comprehension 语法的一些其他问题，等等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;过去 20 年间，编程领域发生了巨大变化，Swift、Kotlin、Java、C# 和 Python 等语言都迅速发展。有时是发现新的方法，有时是针对常见用例收敛到相似解决方案。仅仅因为 Scala 在 2005 年做出了一个设计决策，并且我们接受了这个决策 20 年，并不意味着这个决策在 2025 年仍然是最佳的。有时，我们可以也应该做得更好。&lt;/p&gt; 
&lt;p&gt;Scala 的核心一直是其面向对象（OO）和函数式编程（FP）特征的融合，以及安全性和便利性的融合，但其他一切都是可以讨论的。例如，Scala 经历了三次集合库的迭代，才到达了今天的地位，尽管经历了变革，但语言也因此变得更加出色。我们今天能够解决哪些长期存在的问题，而我们在 5-10 年后会为此感到庆幸？我们可以从其他语言中采纳哪些特性和约定，而不是以我们独特的方式重新发明轮子？&lt;/p&gt; 
&lt;h3&gt;让新手更容易上手&lt;/h3&gt; 
&lt;p&gt;我们相信 Scala 可以变得更加容易让新入门者掌握。所有高级 Scala 用户在某个时刻也都是新手。你今天所听到的所有大型 Scala 项目最初都是由一群新手开始的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;大学生尝试使用这门语言来完成他们的研究项目&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Python/Ruby 开发者尝试使用这门语言来提高他们生产系统的稳定性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;想要更多灵活性、力量和快速开发的 Java 老手&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们支持高级用户和高级框架，但根据定义，高级用户能够自我照顾：解决他们自己的问题，编写他们自己的文档，并提出他们自己的语言变更。Scala 的高级用户一直都在提交他们自己的补丁和改进——来自 Akka 世界的&lt;code&gt;scala.concurrent.Future&lt;/code&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Fcats%2Fissues%2F2948&quot; target=&quot;_blank&quot;&gt;部分统一&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2F2021%2F02%2F26%2Ftuples-bring-generic-programming-to-scala-3.html&quot; target=&quot;_blank&quot;&gt;泛型元组&lt;/a&gt;，以及来自纯函数式编程世界的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Fkind-projector&quot; target=&quot;_blank&quot;&gt;kind-projector&lt;/a&gt;——我们希望他们将继续这样做。相比之下，新来者必须依赖 Scala 的核心维护者来确保他们有一个良好的体验。&lt;/p&gt; 
&lt;p&gt;实际上，这意味着：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;优先支持简单易用的库，如&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Ftoolkit%2Fintroduction.html&quot; target=&quot;_blank&quot;&gt;Scala Toolkit&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcom-lihaoyi&quot; target=&quot;_blank&quot;&gt;com.lihaoyi&lt;/a&gt;平台，提供代码和文档支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将 Scala 语法与其他语言中不必要的差异进行对齐。已经实现了通过&lt;code&gt;import foo.*&lt;/code&gt;进行的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fchanged-features%2Fimports.html&quot; target=&quot;_blank&quot;&gt;通配符导入&lt;/a&gt;和通过&lt;code&gt;foo*&lt;/code&gt;进行的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fchanged-features%2Fvararg-splices.html&quot; target=&quot;_blank&quot;&gt;可变参数拼接&lt;/a&gt;，后者取代了旧的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F46418559%2Fextractor-not-compiling-in-scala%2F46420376&quot; target=&quot;_blank&quot;&gt;蜗牛操作符&lt;/a&gt; &lt;code&gt;foo@_*&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下一个重要的 Scala 项目很可能会由那些为了解决之前没有人想过要解决的问题而开始学习这门语言的新手发起。他们会很聪明，但不会是那些推动 Scala 语言极限的专家，他们也不会使用最复杂的高级语言特性或设计模式。他们会知道 Java、Python 或 JavaScript，因为那是他们在学校里学的。这就是我们需要确保那些人能够轻松地进入 Scala 语言的原因。&lt;/p&gt; 
&lt;h2&gt;考虑的替代方案&lt;/h2&gt; 
&lt;p&gt;关于 Scala 应该走向何方，总是有不同的意见。我们将讨论两个在语言发展方向上反复出现的主张。&lt;/p&gt; 
&lt;h3&gt;为什么不全面拥抱框架？&lt;/h3&gt; 
&lt;p&gt;社区中常见的请求之一是让 Scala 社区全面拥抱某些框架或工具链。例如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;将 Scala 全面作为纯函数式编程语言&lt;/li&gt; 
 &lt;li&gt;将 IO monads 作为构建应用程序的方式&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;这些想法值得讨论；毕竟，使用 Scala 进行纯函数式编程和 IO 单子的子社区一直健康且充满活力。然而，当更深入地分析这种做法时，存在一些问题：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Scala 的设计初衷就是灵活且富有表现力。正如历史所证明的那样，这促进了创新：十年前，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fakka%2Fakka&quot; target=&quot;_blank&quot;&gt;Akka&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalaz%2Fscalaz&quot; target=&quot;_blank&quot;&gt;Scalaz&lt;/a&gt; 是流行的框架。Scalaz 让位于更新的函数式库，如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzio%2Fzio&quot; target=&quot;_blank&quot;&gt;ZIO&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Fcats-effect&quot; target=&quot;_blank&quot;&gt;Cats-Effect&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmonix%2Fmonix&quot; target=&quot;_blank&quot;&gt;Monix&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Ffs2&quot; target=&quot;_blank&quot;&gt;FS2&lt;/a&gt;。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetkyo%2Fkyo&quot; target=&quot;_blank&quot;&gt;Kyo&lt;/a&gt; 看起来有潜力，但仍然处于早期阶段。Scala 语言必须足够通用，以支持这种自然演变，而不能将自己绑定到那些随时间兴衰的具体框架上。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;核心 Scala 开发者并非框架专家。当 Akka 流行时，他们并非 actor 模型方面的专家，如今也不是 IO monads 方面的专家。因此，我们需要那些子社区中的高级用户为自己发声，并推动语言在社区所需方面的改进。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;因此，Scala 必须保持通用性，通过构建任何框架或库都能从中受益的特性。我们鼓励框架爱好者提出对 Scala 语言的改进建议：虽然并非每个具体想法都会被接受，但反馈会推动语言变化，从而惠及所有框架。&lt;/p&gt; 
&lt;h3&gt;为什么不能冻结所有特性开发？&lt;/h3&gt; 
&lt;p&gt;另一个常见的请求是「停止实现特性」。这经常在语言讨论中出现，来自对工具支持、就业市场或其他事物不满意的人。这些情绪是可以理解的。但现实中，冻结特性开发将注定导致 Scala 语言的衰落。&lt;/p&gt; 
&lt;p&gt;Scala 一直以来都比 Java 等语言功能更丰富，但打磨和稳定性却相对不足。Scala 的核心价值主张是，作为交换，你将获得来自未来的语言特性，而其他语言可能要过 10-15 年才能获得：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Apache Spark 于 2014 年选择 Scala 作为在 JVM 上具有 lambda 表达式和模式匹配功能的语言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Akka 选择 Scala，因为它是一种简洁、高效的编程语言，支持使用 Futures 或 Actors 进行轻量级并发。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scalaz 和 Cats 选择 Scala，因为它是一种简洁的语言，拥有丰富的类型系统。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其他语言开始采用这些特性，给 Scala 带来了创新的压力。到 2025 年，基本上在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2024%2F09%2F12%2Flanguage-rankings-6-24%2F&quot; target=&quot;_blank&quot;&gt;RedMonk top 20&lt;/a&gt; 的所有语言中，都包含了 lambda 表达式、模式匹配、轻量级并发和类型系统！那么，为什么任何项目会选择 Scala 呢？&lt;/p&gt; 
&lt;p&gt;Scala 仅凭稳定性和完善性是无法与主流语言竞争的，因此如果我们今天停止功能开发，Scala 最终会变成一个功能更差、完善性和稳定性更差的编程语言，并且没有存在的理由。因此，Scala 需要持续不断的改进来维持其发展，为人们和项目提供选择这门语言的理由。我们可能会犯错——没有一条保证成功的道路——但功能冻结是一条保证停滞和失败的道路。&lt;/p&gt; 
&lt;h2&gt;Scala 生态系统中的开放性问题&lt;/h2&gt; 
&lt;p&gt;Scala 生态系统并非没有问题。以下我们将简要介绍我们认为 Scala 当前面临的最大挑战，以及我们将如何应对这些问题。&lt;/p&gt; 
&lt;h3&gt;工具：集成开发环境 (IDEs)&lt;/h3&gt; 
&lt;p&gt;「工具」是上次 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscalasurvey2023.virtuslab.com%2F&quot; target=&quot;_blank&quot;&gt;VirtusLab Scala 调查&lt;/a&gt; 中指出的最大改进领域。这主要指的是集成开发环境（IntelliJ 和 VSCode）以及构建工具（如 sbt），这些是每位编写 Scala 的人都必须与之交互的工具。&lt;/p&gt; 
&lt;p&gt;在 Scala 社区中，使用的两个主要 IDE 是 IntelliJ 和 VSCode。上述调查表明，大约 80% 的受访者使用 IntelliJ，大约 50% 使用 VSCode，还有一些人同时使用两者。&lt;/p&gt; 
&lt;h4&gt;IntelliJ&lt;/h4&gt; 
&lt;p&gt;IntelliJ 对 Scala 3 的支持仍然需要赶上它对 Scala 2 一直以来的支持质量。尽管如此，进展是稳步的，最近的改进显示出加速的步伐。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Scala 3 最近引入了「预览」功能的概念：这些功能已经从实验性稳定下来，但尚未在 IDE 和其他生态系统中获得支持。这是为了帮助 IntelliJ 和其他 IDE 有足够的时间跟进，以免在语言演变时落后。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fscala%2F2024%2F05%2F13%2Fjetbrains-joins-the-scala-center-advisory-board%2F&quot; target=&quot;_blank&quot;&gt;JetBrains 现已成为 Scala 中心咨询委员会的成员&lt;/a&gt;。这已经改善了 JetBrains 和 Scala 编译器团队之间的沟通和协调，并有助于避免过去出现的问题，即 IntelliJ 需要时间才能跟上 Scala 的变化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最近的语言变更已经相对迅速地融入到 IntelliJ 中：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2Fsips%2Ftypeclasses-syntax.html&quot; target=&quot;_blank&quot;&gt;SIP-64 改进的给定语法&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2Fnamed-tuples.html&quot; target=&quot;_blank&quot;&gt;SIP-58 命名元组&lt;/a&gt; 已经在 IntelliJ 2024.3 中可用，而 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2Fbetter-fors.html&quot; target=&quot;_blank&quot;&gt;SIP-62 For 推导改进&lt;/a&gt; 将在 2025.1 中提供。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;我们承认还有很多工作要做。IntelliJ 团队正在努力提供对 Scala 3 的最佳支持，您可以期待在未来几个月看到更多改进。&lt;/p&gt; 
&lt;h4&gt;Metals - Scala 语言服务器&lt;/h4&gt; 
&lt;p&gt;金属（Metals）通常与 VSCode 一起使用，但也支持其他编辑器。金属（Metals）与 IntelliJ 相比面临不同的挑战：它始终使用实际的 Scala 编译器来进行代码智能，因此始终与实际语言保持同步。但它曾遇到过稳定性问题（例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals%2Fissues%2F6478&quot; target=&quot;_blank&quot;&gt;#6478&lt;/a&gt;），其中一些问题源于其多进程架构的复杂性，另一些则源于其与 Scala 3 的新集成（例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals%2Fissues%2F6628&quot; target=&quot;_blank&quot;&gt;#6628&lt;/a&gt;）。金属（Metals）的维护者目前正在专注于修复最突出的问题，但如果您在自己的代码库中发现了任何问题，请打开 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals%2Fissues&quot; target=&quot;_blank&quot;&gt;https://github.com/scalameta/metals/issues&lt;/a&gt; 上的问题，VirtusLab 团队将乐意查看（必要时甚至签署保密协议）。&lt;/p&gt; 
&lt;p&gt;Scala 3 编译器的开发者已经广泛使用 IntelliJ 和 Metals，我们也清楚开发者在使用这两个 IDE 时所面临的问题。我们将继续在发现问题时进行报告，并与 IntelliJ 和 Metals 的维护者合作，以改善编译器与 IDE 之间的集成。但我们也需要社区人士积极参与问题报告，以便 IDE 维护者能够进行调查和修复。&lt;/p&gt; 
&lt;h3&gt;构建工具&lt;/h3&gt; 
&lt;p&gt;构建工具 sbt 的复杂性在过去十年或更长时间一直是 Scala 社区的一个长期问题。然而，我们认为隧道尽头已经出现了曙光：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscala-cli.virtuslab.org%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Scala-CLI&lt;/strong&gt;&lt;/a&gt; 已变得流行。现在它是默认的 Scala 启动器（自 Scala &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala3%2Freleases%2Ftag%2F3.5.0&quot; target=&quot;_blank&quot;&gt;3.5.0&lt;/a&gt; 以来）。最新的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscalasurvey2023.virtuslab.com%2F&quot; target=&quot;_blank&quot;&gt;VirtusLab Scala 调查&lt;/a&gt; 显示，35% 的人喜欢使用它，另外 35% 的人想要学习它。虽然不适合大型多模块项目，但 Scala-CLI 几乎为几乎所有单模块项目提供了所需的一切。它也是探索性编码小型项目和实验的出色工具。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;替代方案如&lt;/strong&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmill-build.org%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Mill&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;存在&lt;/strong&gt;。调查发现，10% 的 Scala 开发者喜欢使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmill-build.org%2F&quot; target=&quot;_blank&quot;&gt;Mill&lt;/a&gt;，但近 50% 的人希望学习它，而像&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feed3si9n.com%2Fsbt-remote-cache%2F&quot; target=&quot;_blank&quot;&gt;Scala-CLI&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcoursier%2Fcoursier&quot; target=&quot;_blank&quot;&gt;Coursier&lt;/a&gt;这样的基础项目也是使用 Mill 构建的。我们认为，Mill 为大型项目提供了 sbt 的一个很好的替代方案。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foyvindberg%2Fbleep&quot; target=&quot;_blank&quot;&gt;Bleep&lt;/a&gt;虽然仍处于早期阶段，但在构建工具领域提供了一个不同的视角，同时也展现出了巨大的潜力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;sbt 本身也随着时间的推移有了很大的改进&lt;/strong&gt;。在过去的几年里，我们看到了诸如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsbt%2Fsbt%2Fpull%2F3434&quot; target=&quot;_blank&quot;&gt;Unified Slash Syntax&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsbt%2Fsbt-projectmatrix&quot; target=&quot;_blank&quot;&gt;sbt Project-Matrix&lt;/a&gt; 等改进，而即将到来的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-sbt.org%2F2.x%2Fdocs%2Fen%2Fchanges%2Fsbt-2.0-change-summary.html&quot; target=&quot;_blank&quot;&gt;sbt 2.0&lt;/a&gt; 发布将带来 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feed3si9n.com%2Fsudori-part6%2F&quot; target=&quot;_blank&quot;&gt;构建查询&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feed3si9n.com%2Fsbt-remote-cache%2F&quot; target=&quot;_blank&quot;&gt;远程缓存&lt;/a&gt; 等其他改进。虽然仍然不是完美无缺，但到 2025 年使用 sbt 的体验已经远远优于十年前。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FdavidB%2Fscala-maven-plugin&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Maven&lt;/strong&gt;&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2Fcurrent%2Fuserguide%2Fscala_plugin.html&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Gradle&lt;/strong&gt;&lt;/a&gt; 也可以使用。这些构建工具在 Java 圈子里已经流行了很长时间，并且广为人知。虽然它们在开源社区中并不像 sbt 那样受欢迎，但我们看到它们被广泛应用于许多商业 Scala 代码库中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;总体而言，我们预计这个问题在将来会自行解决：一方面是通过 sbt 本身随时间不断改进，另一方面是通过项目选择提供优秀替代方案的其他工具。&lt;/p&gt; 
&lt;h3&gt;生态系统易学性&lt;/h3&gt; 
&lt;p&gt;我们在 Scala 语言中看到的第三大问题是生态系统的易学性。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Scala 生态系统始终为高级用户提供了框架：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fakka.io%2F&quot; target=&quot;_blank&quot;&gt;Akka&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftypelevel.org%2Fcats-effect%2F&quot; target=&quot;_blank&quot;&gt;Cats-Effect&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzio.dev%2F&quot; target=&quot;_blank&quot;&gt;ZIO&lt;/a&gt; 以及其他。但它缺乏一个适合初级用户（例如：你的学生学期项目、你的新毕业生创业项目的代码库、由非工程师维护的 devops 或数据分析脚本）的平台。这些领域是 Scala 框架不适合的地方，但 Scala 语言却可以适用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Scala 生态系统中的文档传统上也一直是个问题。这加剧了上述问题：学习一个强大的框架或库已经足够困难，但糟糕的文档使得学习变得更加困难。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;传统上，尽管有人可能喜欢 Scala 语言，但当他们尝试做一些简单的事情，比如「发起一个 HTTP 请求」或「启动一个服务器」时，他们会遇到一个障碍，突然需要学习关于 Actor、IO 单子或其他高级主题的知识，而相关文档或学习资料却不够充分。&lt;/p&gt; 
&lt;p&gt;但在这里，我们也看到了乐观的理由：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Ftoolkit%2Fintroduction.html&quot; target=&quot;_blank&quot;&gt;Scala Toolkit&lt;/a&gt; 和高度重叠的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcom-lihaoyi&quot; target=&quot;_blank&quot;&gt;com-lihaoyi&lt;/a&gt; 平台，它们包括许多相同的库。这些提供了几乎完整且易于使用的「新手友好」平台。它可能没有更复杂框架的所有功能和装饰，但绝对足够用于许多生产部署，并且如果需要，可以轻松过渡到更复杂的框架。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最近 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2025%2F02%2F25%2Frock-the-jvm-partnership.html&quot; target=&quot;_blank&quot;&gt;Scala Center 与 Rock the JVM 的合作&lt;/a&gt; 有望帮助改善 Scala 的教学方面。来自 Rock the JVM 的 Daniel Ciocîrlan 一直是一位杰出的教育者和高质量教育材料的创作者。我们希望这次合作能够扩大 Rock the JVM 的影响力，并帮助 Scala 新手发现并受益于他优秀的视频和课程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;这是一个我们一直在缓慢取得进步的领域，我们希望这种「新手友好」的 Scala 风格随着时间的推移而发展：不是以牺牲更高级框架为代价，而是在它们并行发展的同时，随着新手的数量增加，更多的人在需要时选择更复杂的框架。&lt;/p&gt; 
&lt;h2&gt;如何帮助&lt;/h2&gt; 
&lt;p&gt;Scala 是一个社区努力的结果；没有像其他语言那样的庞大企业赞助 Scala 的开发。因此，我们需要社区的帮忙来推动语言的发展。这种帮助可以以各种方式实现。&lt;/p&gt; 
&lt;h3&gt;财政&lt;/h3&gt; 
&lt;p&gt;如果您想从财政上支持 Scala，有两个主要群体您可以支持：&lt;/p&gt; 
&lt;h4&gt;Scala 中心&lt;/h4&gt; 
&lt;p&gt;Scala 中心支持以下两个方面：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;核心 Scala 语言和编译器的开发：探索、原型设计、实施、维护和调试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 Scala 社区。这包括 Scala Days 会议、Scala 大使计划以及工具峰会。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;您可以通过以下两种方式向 Scala 中心捐款：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;个人捐款或让您的公司向 Scala 中心捐款 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscala.epfl.ch%2Fdonate.html&quot; target=&quot;_blank&quot;&gt;https://scala.epfl.ch/donate.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;您可以鼓励您的公司加入 Scala 中心咨询委员会，以持续资助它。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您想支持核心 Scala 语言和社区工作，请向 Scala 中心捐款。他们的大部分工作可能并不光彩夺目，但它们在确保 Scala 生态系统持续健康发展中发挥着关键作用。&lt;/p&gt; 
&lt;h4&gt;VirtusLab&lt;/h4&gt; 
&lt;p&gt;VirtusLab 负责许多 Scala 工具的核心开发：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Metals 和 VSCode Metals 插件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scala-CLI&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scala 3 LTS，Scala 的发布流程和一般项目管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scalameta 组织内的工具&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您在使用 Metals 或 Scala-CLI 时遇到问题，并且想资助修复或改进，您应该联系 VirtusLab，邮箱地址为&amp;nbsp;scala@virtuslab.com.&lt;/p&gt; 
&lt;h3&gt;代码&lt;/h3&gt; 
&lt;p&gt;Scala 生态系统的大部分内容都是开源的。这意味着您可以直接深入代码，修复或改进您自己需要的部分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;您可以自己修复 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala3&quot; target=&quot;_blank&quot;&gt;Scala3&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJetBrains%2Fintellij-scala&quot; target=&quot;_blank&quot;&gt;IntelliJ&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals&quot; target=&quot;_blank&quot;&gt;Metals&lt;/a&gt; 中的错误。尽管代码库很大，但有人能够深入其中并修复他们自己用例所需的错误并不罕见。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每 three 周都会进行一次 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fcontribute%2F%23so-you-want-to-improve-the-scala-3-compiler&quot; target=&quot;_blank&quot;&gt;Compiler Spree&lt;/a&gt; 和 Tooling Spree。这些是远程编码会议，您可以与 Scala 语言和工具的核心贡献者合作解决小规模的问题，并获取技能和知识，以应对更具挑战性的问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;向工具和基础设施贡献修复和改进并不容易，但这也不是不可能的。Scala 工具链的大部分都是开源的，并且在过去多次由个人和公司进行了一次的快速贡献，他们只是需要修复某些问题。向这些项目提交拉取请求与任何专业软件工程师每天已经做的工作没有区别，并且可以帮助你定期改善使用 Scala 的体验。&lt;/p&gt; 
&lt;h3&gt;语言设计&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2F&quot; target=&quot;_blank&quot;&gt;Scala 改进流程&lt;/a&gt; 并不仅限于核心 Scala 贡献者。任何人都可以提出一个，例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F40&quot; target=&quot;_blank&quot;&gt;SIP-42 二进制整数字面量&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F78&quot; target=&quot;_blank&quot;&gt;SIP-61 为二进制兼容性@unroll 默认参数&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F97&quot; target=&quot;_blank&quot;&gt;SIP-67 改进严格相等性&lt;/a&gt;。如果核心 Scala 团队没有优先考虑你想要的，你总是可以介入并提出自己对语言改进的建议。毕竟，没有人比你更了解自己的需求！&lt;/p&gt; 
&lt;p&gt;SIPs 进入语言并不容易。无法保证一个 SIP 会被接受。即使 SIP 成功通过，通常也需要数月甚至一年时间来完成整个审查、实施和实验过程，最终才能进入 Scala 的发布。相反，最初被拒绝的想法可能在经过数月或数年的额外实验和改进后找到进入的方式。但我们需要更多的贡献者提出更改，而不仅仅是限于 Martin Odersky 和 EPFL 的团队。&lt;/p&gt; 
&lt;p&gt;如果您有想法要提出，但需要帮助实施，并且有资金支付，请联系 [email&amp;nbsp;protected]，我们可以帮助找到合适的专家进行合作。&lt;/p&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;语言发展是一个间接的过程。核心 Scala 团队无法独自构建下一个重大的 Scala 成功故事，这也不会一蹴而就。我们能做的就是从各个方面提升 Scala 的体验：语言、工具和社区，并希望某处某个人会为一个新的项目选择 Scala，使其成为「下一个大热门」。&lt;/p&gt; 
&lt;p&gt;我们认为 Scala 语言的核心吸引力在于其安全性与便利性的结合。强大的类型系统和编译器可以防止错误，提供出色的运行时性能，而简洁的语法和类型推断则使其感觉像任何脚本语言一样灵活和富有表现力。毫无疑问，其他语言也在追求相同的目标，我们认为 Scala 凭借其独特的混合函数式-面向对象的设计，可以在多个方面做得更好，从而吸引并留住用户。&lt;/p&gt; 
&lt;p&gt;但 Scala 语言及其生态系统的细节将随着时间的推移而演变，我们不应过度依赖我们已经习惯的偶然复杂性。正如 Scala 在 2.13 版本中极大地简化了&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2018%2F06%2F13%2Fscala-213-collections.html&quot; target=&quot;_blank&quot;&gt;集合&lt;/a&gt;，并且用更简单的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2F2021%2F02%2F26%2Ftuples-bring-generic-programming-to-scala-3.html&quot; target=&quot;_blank&quot;&gt;泛型元组&lt;/a&gt;和其他&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fnew-types%2Findex.html&quot; target=&quot;_blank&quot;&gt;类型系统特性&lt;/a&gt;取代了类型级别的体操一样，我们期望继续发现可以改进 Scala 的领域。始终会有关于向后兼容性、迁移和易学性的担忧，但无论如何，Scala 需要不断地、批判性地审视自己，并借鉴过去二十年其他语言所学到的东西来提升开发者体验。&lt;/p&gt; 
&lt;p&gt;Scala 一直是一个社区项目，我们需要社区的帮助来推动它向前发展：无论是通过资金支持、提交拉取请求，还是在语言设计方面。我们希望社区中的每个人都能以自己的方式做出贡献，并推动语言的发展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345137/evolving-scala</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345137/evolving-scala</guid>
            <pubDate>Sun, 13 Apr 2025 10:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>首个云超算国标正式发布：阿里云、华为云等联合起草</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;近日，国家市场监督管理总局、国家标准化管理委员会正式发布首个云超算国家标准 GB/T 45400-2025，将于今年 10 月实施。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e500d685c371b785670bd445adca14e3947.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;该标准由阿里云、华为云、腾讯云、中国电子技术标准化研究院等机构牵头起草，为云超算在更多高性能计算领域的大规模应用奠定基础，推动我国算力基础设施建设迈向标准化、智能化新阶段。&lt;/p&gt; 
&lt;p&gt;云超算是一种新型的高性能计算（HPC），它基于云基础设施对外提供弹性可扩展的高性能计算服务。&lt;/p&gt; 
&lt;p&gt;目前，传统高性能计算在大模型训练、自动驾驶、生命科学、工业制造、半导体芯片等领域展开应用，并逐渐向更多行业渗透。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;但传统 HPC 往往架构复杂、扩展性不佳，并存在性能瓶颈、价格高昂等门槛，很多企业虽然想用，却可能「不懂用」，或「用不好」、「用不起」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开箱即用的云超算成为高性能计算的新选择，多家单位在此背景下联合起草首个云超算国家标准，对云超算基础架构、资源协同调度、全栈安全可信体系等关键技术指标作出权威性界定，内容囊括云超算服务的设计研发、部署运维和效能评估全流程。&lt;/p&gt; 
&lt;p&gt;新标准的出炉，相当于给各行各业提供了一份包含云超算服务产品的设计、实现、应用和选型的科学指南。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345132</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345132</guid>
            <pubDate>Sun, 13 Apr 2025 09:44:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 Solon AI MCP Server 入门：Helloworld （国产解决方案）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;目前网上能看到的 MCP Server 基本上都是基于 Python 或者 nodejs ，虽然也有 Java 版本的 MCP SDK，但是鲜有基于 Java 开发的。 作为 Java 开发中的国产顶级框架 Solon 已经基于 MCP SDK 在进行 Solon AI MCP 框架开发了，本文将使用 Solon AI MCP 做一个简单的 MCP Server 入门。&lt;/p&gt; 
&lt;h3&gt;引入依赖&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;Solon AI MCP 是 Solon AI 最新增加的特性。支持 Mcp Server 和 Mcp Client，且支持 Java 8 到 Java 24。最新的版本号为 3.2.0（随 Solon 的版号）。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-ai-mcp&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;3.2.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;开始写工具&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-ai-mcp 支持多端点的架构，可以手动构建端点，或者注解构建端点（&lt;code&gt;@McpServerEndpoint&lt;/code&gt;）。再使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@ToolMapping&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;注解编写工具，就像开发 MVC 一样简单和熟悉。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;@ToolMapping 注解标记这个方法是一个工具映射，通过 description 属性告诉大模型这个工具是做什么的，其实就是提示词，大模型会根据自己的理解调用这个工具，所以这个描述很重要。&lt;/li&gt; 
 &lt;li&gt;@ToolParam：从名字可以看出来，就是工具调用时需要传什么参数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@McpServerEndpoint(sseEndpoint = &quot;/sse&quot;)&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;HelloService&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@ToolMapping(description = &quot;你好世界&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; String &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#4078f2&quot;&gt;@ToolParam(description = &quot;名字&quot;)&lt;/span&gt; String name)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; SQLException {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;hello &quot;&lt;/span&gt; + name;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;这样就可以了。启动时就会自动注册。并且打印基本的信息：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e47839b4670ac8858c97f2c82a4af150.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;用客户端做个单测（调用这个工具）&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Slf4j&lt;/span&gt;
&lt;span style=&quot;color:#4078f2&quot;&gt;@SolonTest(App.class)&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;HelloTest&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;extends&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;HttpTester&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Test&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;void&lt;/span&gt; &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span style=&quot;color:#986801&quot;&gt;McpClientToolProvider&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;clientToolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientToolProvider.builder()
                .apiUrl(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://localhost:8080/sse&quot;&lt;/span&gt;)
                .build();

        &lt;span style=&quot;color:#986801&quot;&gt;String&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; clientToolProvider.callToolAsText(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;hello&quot;&lt;/span&gt;, Maps.of(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;name&quot;&lt;/span&gt;, &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;solon&quot;&lt;/span&gt;));
        log.warn(rst);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;运行单测后：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//80088a925343da37cad3f8f7a721f471.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345131</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345131</guid>
            <pubDate>Sun, 13 Apr 2025 09:43:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>黄仁勋：英伟达坚定不移服务中国市场，AI 将在每个行业引发颠覆性变革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4 月 17 日，中国贸促会会长任鸿斌在北京与英伟达公司首席执行官黄仁勋举行会谈。这是黄仁勋时隔 3 个月再次到访北京。黄仁勋在会谈中表示，&lt;strong&gt;中国是英伟达非常重要的市场，希望继续与中国合作。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;372&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1bf052320ee3587eb2eedcd683357c58a5d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据央视财经，针对美国政府决定对英伟达对华出口的 H20 芯片，黄仁勋表示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;美国政府加强芯片出口管制已对英伟达业务产生重大影响，当前全球正掀起一场激烈的人工智能竞赛，作为当代最具变革性的核心技术，AI 对各行业发展的推动前景广阔，世界各国都在加速推进技术应用，研发创新与能力提升，这必将对包括中国在内的全球市场格局产生深远影响。作为深耕中国市场三十载的企业，我们与中国市场共同成长、相互成就。中国不仅是全球最具规模的消费市场之一，其蓬勃发展的产业生态与领先的软件实力，更成为我们持续创新的重要动力，在中国市场的成功经验推动我们不断加大研发投入，而与中国企业的深度合作，也使我们成长为更具竞争力的国际化企业。因此，&lt;strong&gt;我们将继续不遗余力优化符合监管要求的产品体系，坚定不移地服务中国市场。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;黄仁勋还表示，AI 已经在诸多领域产生了重大影响，例如在软件编程方面，如今几乎所有的英伟达员工都会借助 AI 进行辅助开发。人工智能正在深刻改变众多行业的发展格局，但这仅仅是个开端，无论是医疗健康、金融服务、气候科技还是制造业，每个行业都将迎来人工智能引发的颠覆性变革。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345130</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345130</guid>
            <pubDate>Sun, 13 Apr 2025 09:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Vanna —— 基于 RAG 的自然语言生成 SQL 工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;Vanna 是一个 MIT 许可的开源 Python RAG（检索增强生成）框架，用于 SQL 生成和相关功能。&lt;/span&gt;&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;工作原理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img height=&quot;357&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/151133_1FdG_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Vanna 的工作分为两个简单的步骤 - 在你的数据上训练 RAG「模型」，然后提出问题，这些问题将返回可设置为在你的数据库上自动运行的 SQL 查询。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;在你的数据上训练 RAG「模型」&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提出问题&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;500&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/151158_TZIY_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;p&gt;&lt;strong&gt;Supported LLMs&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/openai&quot;&gt;OpenAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/anthropic&quot;&gt;Anthropic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/blob/main/src/vanna/google/gemini_chat.py&quot;&gt;Gemini&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/blob/main/src/vanna/hf/hf.py&quot;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/bedrock&quot;&gt;AWS Bedrock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/ollama&quot;&gt;Ollama&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianwen&quot;&gt;Qianwen&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianfan&quot;&gt;Qianfan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/ZhipuAI&quot;&gt;Zhipu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;p&gt;&lt;strong&gt;Supported VectorStores&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/azuresearch&quot;&gt;AzureSearch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/opensearch&quot;&gt;Opensearch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/pgvector&quot;&gt;PgVector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/pinecone&quot;&gt;PineCone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/chromadb&quot;&gt;ChromaDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/faiss&quot;&gt;FAISS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/marqo&quot;&gt;Marqo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/milvus&quot;&gt;Milvus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/qdrant&quot;&gt;Qdrant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/weaviate&quot;&gt;Weaviate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/oracle&quot;&gt;Oracle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;p&gt;&lt;strong&gt;Supported Databases&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.postgresql.org/&quot;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.mysql.com/&quot;&gt;MySQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://prestodb.io/&quot;&gt;PrestoDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://hive.apache.org/&quot;&gt;Apache Hive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://clickhouse.com/&quot;&gt;ClickHouse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.snowflake.com/en/&quot;&gt;Snowflake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.oracle.com/&quot;&gt;Oracle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.microsoft.com/en-us/sql-server/sql-server-downloads&quot;&gt;Microsoft SQL Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://cloud.google.com/bigquery&quot;&gt;BigQuery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.sqlite.org/&quot;&gt;SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://duckdb.org/&quot;&gt;DuckDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/vanna</link>
            <guid isPermaLink="false">https://www.oschina.net/p/vanna</guid>
            <pubDate>Sun, 13 Apr 2025 09:32:00 GMT</pubDate>
        </item>
        <item>
            <title>CVE 基金会成立</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;有 25 年历史的 CVE 项目在漏洞管理中起到了举足轻重的作用，它负责分配和管理漏洞的唯一 CVE ID 编号，确保在提及特定漏洞和补丁时针对的是同一个漏洞。&lt;/p&gt; 
&lt;p&gt;非营利组织 MITRE 与美国国土安全部签订了运营 CVE 项目的合同，MITRE 周二确认，合同没有续签。这意味着从 4 月 16 日（星期三）起&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/345038&quot;&gt;美国政府将停止资助 CVE&lt;/a&gt;&lt;/u&gt;。安全行业人士担心在其他人接手前漏洞管理上将会出现巨大混乱。&lt;/p&gt; 
&lt;p&gt;CVE Naming Authority 机构 VulnCheck 表示预留了 1000 个 1000 个 CVE 用于 2025 年的漏洞。MITRE 每月发布 300-600 个 CVE，预留的编号只够用 2-3 个月。&lt;/p&gt; 
&lt;p&gt;为了应对危机，长期担任 CVE 董事会成员的联盟宣布成立&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thecvefoundation.org%2F&quot; target=&quot;_blank&quot;&gt;CVE 基金会&lt;/a&gt;，这是一个致力于确保漏洞识别系统持续运行的非营利组织。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;700&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/165002_yPMw_2720166.png&quot; width=&quot;1670&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新成立的基金会官员肯特·兰德菲尔德表示：「CVE 作为全球网络安全生态系统的基石，其重要性不容忽视。全球网络安全专业人员的日常工作——从安全工具和公告到威胁情报和响应——都依赖于 CVE 标识符和数据。如果没有 CVE，防御者在应对全球网络威胁时将处于极其不利的地位。」&lt;/p&gt; 
&lt;p&gt;CVE 计划提供了一个标准化的系统，用于识别和分类所有软件和硬件（包括 Apple 的 macOS、iOS、iPadOS 和其他产品）中的安全漏洞。当安全研究人员发现漏洞时，他们会被分配唯一的 CVE 标识符，以便 Apple 等公司协调补丁和更新。&lt;/p&gt; 
&lt;p&gt;MITRE 公司与美国国土安全部签订了合同，负责管理该项目。该公司确认，政府资金已于 4 月 16 日到期。&lt;/p&gt; 
&lt;p&gt;据路透社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fus-funding-running-out-critical-cyber-vulnerability-database-manager-says-2025-04-15%2F&quot; target=&quot;_blank&quot;&gt;报道&lt;/a&gt;，该项目的到期可能与联邦政府正在进行的大规模裁员有关，此次裁员的部分原因是政府效率部（DOGE）。&lt;/p&gt; 
&lt;p&gt;受此次裁员影响的美国网络安全和基础设施安全局（CISA）表示，由于突然出现的资金缺口可能会扰乱全球漏洞管理，该局正在「紧急努力减轻影响」。&lt;/p&gt; 
&lt;p&gt;安全专家警告称，如果没有 CVE，网络安全工作将面临「彻底混乱」，因为用于沟通漏洞的通用语言实际上将消失。一位研究人员将其比作「突然删除所有词典」。&lt;/p&gt; 
&lt;p&gt;新成立的 CVE 基金会旨在将该项目转型为不依赖单一政府资助的专门的非营利模式。基金会的组织者透露，他们过去一年一直在为这一可能性做准备。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thecvefoundation.org%2F&quot; target=&quot;_blank&quot;&gt;该基金会在公告&lt;/a&gt;中表示：「对于国际网络安全界来说，此举代表着一个建立反映当今威胁形势全球性的治理机制的机会。」&lt;/p&gt; 
&lt;p&gt;资金削减还影响了相关的通用弱点枚举 (CWE) 计划，该计划帮助苹果等公司在潜在安全问题成为漏洞之前发现它们。&lt;/p&gt; 
&lt;p&gt;CVE 基金会预计将在未来几天公布更多有关其架构和资金计划的细节。苹果和其他大型科技公司可能会在支持其成为网络安全基础设施关键组成部分方面发挥重要作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345117/the-cve-foundation</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345117/the-cve-foundation</guid>
            <pubDate>Sun, 13 Apr 2025 08:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>特朗普政府考虑在美国禁用 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nytimes.com%2F2025%2F04%2F16%2Ftechnology%2Fnvidia-deepseek-china-ai-trump.html&quot; target=&quot;_blank&quot;&gt;《纽约时报》&lt;/a&gt;周三报道称，特朗普政府正在考虑对中国人工智能实验室 DeepSeek 实施新的限制，限制其购买英伟达的人工智能芯片，并可能禁止美国人访问其人工智能服务。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-203442edacfcf58c37d7ea5f763fad361b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些限制是特朗普政府在人工智能领域与中国竞争的举措之一。在 DeepSeek 震惊硅谷和华尔街数月后，美国官员似乎正在权衡多种方案，以限制中国获取美国技术和消费者。&lt;/p&gt; 
&lt;p&gt;周二，白宫采取行动限制更多英伟达人工智能芯片以及 AMD 的计算卡产品向中国销售，加强拜登政府制定的规定。&lt;/p&gt; 
&lt;p&gt;近几个月来，DeepSeek 在美国人工智能开发者中的人气飙升，这家初创公司具有竞争力的定价迫使硅谷以更低的成本提供前沿人工智能模型。&lt;/p&gt; 
&lt;p&gt;此前，OpenAI 指控这家中国实验室对其模型进行了篡改，违反了 OpenAI 的使用条款。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读：&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338735/openai-calls-deepseek-state-controlled&quot; target=&quot;news&quot;&gt;OpenAI 呼吁美国政府禁止 DeepSeek&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344925&quot; target=&quot;news&quot;&gt;英伟达对华特供版 AI 芯片（H20 GPU）遭遇出口管制&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345109/deepseek-china-ai-trump</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345109/deepseek-china-ai-trump</guid>
            <pubDate>Sun, 13 Apr 2025 08:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动发布视频生成基础大模型 Seaweed-7B</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;字节跳动近日公布了一个仅 70 亿参数的视频生成基础大模型「Seaweed-7B」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4514fa3f8394e07ea2ee816465b6d9d857e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseaweed.video%2F&quot; target=&quot;_blank&quot;&gt;https://seaweed.video/&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;令人惊喜的是，该模型以 66.5 万个 H100 GPU 小时训练成本，在文本/图像到视频生成任务中全面超越 140 亿参数的 Wan 2.1，具体来看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seaweed-7B Elo 评分为 1047，胜率 58%，而 Wan 2.1 仅有 53%，OpenAI 的 Sora 更是仅有 36%&lt;/li&gt; 
 &lt;li&gt;可实时生成分辨率为 1280×720、帧率为 24fps 的视频，比同类模型快 62 倍&lt;/li&gt; 
 &lt;li&gt;40GB 显存即可支持 1280×720 分辨率生成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;据官方介绍，Seaweed-7B 结合了变分自编码器（VAE）和潜在扩散变换器（DiT）。其中，VAE 负责高效的训练和推理，而 DiT 则通过扩散模型生成图像和视频，显著提高了生成的质量与效率。&lt;/p&gt; 
&lt;p&gt;另外，团队为了提升 Seaweed-7B 的训练效率，采用了多阶段训练策略和 GPU 资源的优化调配。预训练阶段通过低分辨率图像开始，逐步引入高分辨率视频训练，提升了模型的泛化能力。此外，在后训练阶段，通过监督微调和基于人类反馈的强化学习（RLHF）进一步提高了生成视频的美学质量和运动一致性。&lt;/p&gt; 
&lt;p&gt;目前，Seaweed-7B 相关报告已公开：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseaweed.video%2Fseaweed.pdf&quot; target=&quot;_blank&quot;&gt;https://seaweed.video/seaweed.pdf&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345103/bytedance-seaweed-video</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345103/bytedance-seaweed-video</guid>
            <pubDate>Sun, 13 Apr 2025 08:20:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马斯克：特斯拉将实现纯 AI 自动驾驶，仅需摄像头和 AI 芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;马斯克近日在社交媒体发文称，特斯拉即将实现一种通用的、纯 AI 的全自动驾驶（FSD）解决方案。&lt;/p&gt; 
&lt;p&gt;据其介绍，这一技术将完全依赖于摄像头和特斯拉自主研发的 AI 芯片，并由特斯拉开发的 AI 软件驱动。实际上，这一声明与特斯拉长期以来坚持的仅靠视觉实现自动驾驶的愿景相一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/160721_YZPO_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，特斯拉官方 X 账号近日发布视频，称特斯拉德克萨斯工厂现在使用 FSD 无监督技术将汽车从生产线末端运送到发货物流区，同时宣布无监督 FSD 系统已积累超 50000 英里（约 80467.22 公里）驾驶里程，全程无需人工干预。&lt;/p&gt; 
&lt;p&gt;在特斯拉工厂内部，新款 Model Y 和 Cybertruck 实现了从生产线到交付停车场的自动行驶。自动驾驶车辆运用最新 AI4 硬件（4.0 版），可应对交通标志、工厂建设、行人和机械化交通等复杂道路环境，且车辆间能相互通信以避免碰撞。&lt;/p&gt; 
&lt;p&gt;据悉，特斯拉无监督 FSD 公路测试计划即将开启，预计 6 月于奥斯汀率先开展。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/340233&quot; target=&quot;news&quot;&gt;马斯克：2024 年特斯拉 AI 投资约 100 亿美元、FSD 安全水平将超过人类&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345100</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345100</guid>
            <pubDate>Sun, 13 Apr 2025 08:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Linux 6.16 主线内核将合并 Asahi UAPI，进一步优化支持苹果 M1 / M2 图形驱动</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Fdri-devel%2Fe147ff95-697b-4067-9e2e-7cbd424e162a%40linux.intel.com%2F&quot; target=&quot;_blank&quot;&gt;根据 Linux 内核邮件列表的消息&lt;/a&gt;&lt;/u&gt;，Asahi 驱动用户空间 API（UAPI）的头文件已通过 DRM-Misc-Next，被提交至 DRM-Next 队列，并计划在 Linux 6.16 的合并窗口（预计为 6 月）正式纳入主线内核。&lt;/p&gt; 
&lt;p&gt;这一 UAPI 主要用于支持苹果 M1 和 M2 系列芯片的 GPU，目标是实现 Linux 系统对这些硬件图形功能的驱动。&lt;/p&gt; 
&lt;p&gt;UAPI 的设计参考了其他现代 Vulkan 驱动程序（例如 Xe 和 Panthor），采用了显式虚拟内存管理与同步机制，从而确保运行效率。开发者 Alyssa Rosenzweig 表示，此举的目的是让 Mesa 驱动能够直接基于主线内核构建，减少对外部头文件的依赖，从而提升系统的兼容性。&lt;/p&gt; 
&lt;p&gt;尽管 UAPI 的头文件已经提交，但完整的 Asahi 内核图形驱动目前尚未完成开发。主要原因在于该驱动使用 Rust 语言编写，而 Rust 在内核中的抽象支持仍需大量的上游工作。&lt;/p&gt; 
&lt;p&gt;此外，作为一款生产级图形驱动，Asahi 依赖许多尚未合并的 Rust 抽象层，因此短期内难以实现全面的上游整合。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1dade207fb4a37d21fe204449acb7a922be.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，Mesa 开源堆栈已验证了 UAPI，并支持包括 OpenGL 4.6、OpenGL ES 3.2、OpenCL 3.0 以及 Vulkan 1.4 在内的多种标准。然而，由于用户空间与主线内核之间的对接尚未完全实现，实际应用仍然受到一定限制。&lt;/p&gt; 
&lt;p&gt;Rosenzweig 进一步强调，提交 UAPI 头文件的主要目的是为了接受社区的审查，以确保其稳定性，并在未来以向后兼容的方式进行演进，从而为后续驱动程序的全面落地奠定基础。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345097/linux-6-16-ashai-uapi-header</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345097/linux-6-16-ashai-uapi-header</guid>
            <pubDate>Sun, 13 Apr 2025 08:02:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>豆包公布 Seedream 3.0 文生图模型技术报告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;字节跳动旗下「豆包大模型团队」&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmLRMHXq51HDBN_Vaylm_mw&quot; target=&quot;_blank&quot;&gt;发文表示&lt;/a&gt;&lt;/u&gt;，全新图像生成基础模型「Seedream 3.0」技术报告正式发布。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Seedream 3.0 是一个原生高分辨率、支持中英双语的图像生成基础模型，亮点如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原生 2K 直出，适配多比例场景：无需后处理可直接输出 2K 分辨率图像，从手机端到巨幅海报场景的视觉需求均可满足；&lt;/li&gt; 
 &lt;li&gt;3 秒出图，大幅提升创作效率：面向海报设计、视觉创意等需求，可实现 3 秒左右快速生成高品质图像，实现「所想即所得」的实时创意交互；&lt;/li&gt; 
 &lt;li&gt;小字更准，文本排版效果增强：优化小字体高保真生成、多行文本语义排版等业界难题，让 AI 具备商业级图文设计能力；&lt;/li&gt; 
 &lt;li&gt;美感 &amp;amp; 结构提升，生成富有感染力：指令遵循进一步增强，人体和物体结构崩坏改善，且进一步弱化了出图的 AI 感，实现从「看得清」到「有感染力」的审美提升。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/155350_bNhq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，在权威竞技场 Artificial Analysis 上，Seedream 3.0 与 GPT-4o、Imagen 3、Midjourney v6.1、FLUX 1.1 Pro、Ideogram 3.0 等文生图模型同台竞技，在近期打榜中，一度排名第一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/154909_oM7T_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Seedream 3.0 已在本月正式上线，目前已在豆包、即梦等平台全量开放。&lt;/p&gt; 
&lt;p&gt;另外，Seedream 3.0 的相关技术报告以及详细内容也已经上架：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Arxiv：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2504.11346&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2504.11346&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;技术呈现页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fteam.doubao.com%2Ftech%2Fseedream3_0&quot; target=&quot;_blank&quot;&gt;https://team.doubao.com/tech/seedream3_0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345096/seedream-3-0-technical-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345096/seedream-3-0-technical-report</guid>
            <pubDate>Sun, 13 Apr 2025 07:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯开启史上最大就业计划，今年六成面向技术人才</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腾讯&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC1XKIdH8q2DGiYNW-_7wnw&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;启动史上最大就业计划，三年内将新增 28000 个实习岗位并加大转化录用，其中仅 2025 年，就将迎来 10000 名校招实习生，有六成面向技术人才开放。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;317&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2aeffe1036b528f19b384ec56ffd839c94a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腾讯方面表示，今年开放的校招实习岗位涵盖技术、产品、设计、市场、职能等五大类 70 余种岗位，包括大模型、研发、算法、市场、策划、运营、销售、美术等多个岗位职能。同时，在大模型加速落地的背景下，腾讯加大了人工智能、大数据、云计算、游戏引擎、数字内容等技术类岗位的招聘力度，技术类岗位「扩招」力度空前，占比超 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;截至今年 3 月初，腾讯集团目前正式员工人数超 55000 人，其中科技类人才超过 40000 人，占比高达 73%，这其中，直接从事技术研发工作的员工超 27000 人，占整体员工人数的近半比例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腾讯公司高级副总裁、首席人才官奚丹表示：「校招是腾讯最重要的人才来源之一。一直以来，腾讯都高度重视对于校招生的关注和投入，招聘数量在互联网企业中处于领先。在科技创新驱动发展的时代命题下，腾讯也强化对科技人才的前瞻性储备，与青年人才共同成长，推进互联网、大数据、人工智能技术创新。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345095</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345095</guid>
            <pubDate>Sun, 13 Apr 2025 07:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Claude 更新：高级 Research 功能、深度集成 Google Workspace、语音模式即将上线</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Claude 母公司 Anthropic 宣布对其 AI 助手 Claude 进行重要升级，旨在进一步增强其作为高效协作工具的实用性。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;810&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/153302_4zCu_2720166.png&quot; width=&quot;896&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本次更新引入了两项新功能，&lt;strong&gt;Research 和 Google Workspace 深度集成&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Claude 本次新增的 Research 功能，与此前 OpenAI 在 ChatGPT 中所推出的 Deep Research 类似，能够主动进行多轮搜索，逐步深入问题并进行多角度探索，最后系统性地为用户提供更高质量的回答内容。值得一提的是，本次 Claude 的 Research 拥有代理式（Agentic）搜索框架，支持自主规划并执行多步骤搜索任务。&lt;/p&gt; 
&lt;p&gt;其核心特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代理式（Agentic）搜索框架：Claude 不再局限於单一查询，而是能够以代理方式运作，自主规划并执行多步骤、相互关联的搜索任务。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;跨源信息整合： 该功能支持同时检索并分析来自用户授权的内部数据源（如企业知识库）以及广泛的互联网公开信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;系统性问题探索：对于复杂或开放性的用户查询，Claude 能够从多个维度进行系统性探索，深度挖掘信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可验证的综合答案：最终输出为结构化、内容全面的回答，并附带清晰的引用来源，确保信息的可追溯性和可靠性，为用户的决策提供坚实依据。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另外，为了增强 Claude 各方面能力，Anthropic 为其深度集成了 Google Workspace 应用套件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;无缝连接核心应用：&lt;/strong&gt;&amp;nbsp;除原有的文档处理外，Claude 现可直接、安全地连接用户的 Gmail、Google 日历和 Google 文档。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自动化上下文获取：&lt;/strong&gt; 无需用户手动上传文件或反复提供背景信息，Claude 可直接访问并理解邮件内容、日历安排及文档细节，自动获取相关工作上下文。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;情境感知驱动的协助：&lt;/strong&gt;&amp;nbsp;基于对用户工作环境的深入理解，Claude 能够提供关联性更强、更精准的辅助，例如根据邮件和日历信息自动生成会议摘要、识别待办事项或查找项目相关资料。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;信息透明与可信：&lt;/strong&gt;&amp;nbsp;所有通过集成访问的信息，Claude 在利用时都会提供内嵌引用，确保操作的透明度和信息来源的可验证性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/153646_3cnX_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Research&lt;/strong&gt;&amp;nbsp;功能目前处于早期 Beta 测试阶段，面向美国、日本、巴西地区的 Max、Team 和 Enterprise 付费计划用户开放，用户可在设置中启用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Google Workspace 集成&lt;/strong&gt;同样处于 Beta 阶段，所有付费计划用户均可在个人设置中启用。需要注意的是，Team 和 Enterprise 计划的管理员需先在组织层面授权该集成。&lt;/p&gt; 
&lt;p&gt;另外，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-15%2Fanthropic-is-readying-a-voice-assistant-feature-to-rival-openai&quot; target=&quot;_blank&quot;&gt;根据彭博社的报道&lt;/a&gt;&lt;/u&gt;，Claude 的语音模式即将在本月上线。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345094/anthropic-claude-research</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345094/anthropic-claude-research</guid>
            <pubDate>Sun, 13 Apr 2025 07:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Spark on K8s 在 vivo 大数据平台的混部实战</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网大数据团队- Qin Yehai&lt;/p&gt; 
 &lt;p&gt;在离线混部可以提高整体的资源利用率，不过离线 Spark 任务部署到混部容器集群需要做一定的改造，本文将从在离线混部中的离线任务的角度，讲述离线任务是如何进行容器化、平台上的离线任务如何平滑地提交到混部集群、离线任务在混部集群中如何调度的完整实现以及过程中的问题解决。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、在离线业务差异&lt;/h1&gt; 
&lt;p&gt;互联网数据业务服务一般可以分为在线服务和离线任务两大类，在线服务是指那些长时间运行、随时响应对实时性要求高、负载压力随着接收流量起伏的服务，如电商、游戏等服务，离线任务是指运行周期短、可执行时间提交对实时性要求低、有一定容错性、负载压力基本可控的服务，如离线计算任务、模型训练等。一般在线服务在白天时段繁忙，离线任务在凌晨繁忙，两者的业务高峰期存在错峰现象，如果按传统方式在线和离线都是分别独立机器部署，业务高峰时期需要更多机器来支持，业务低峰期又存在部分机器空闲，整体资源利用率都不高。因此行业提出来在离线混部的解决方案，在线和离线业务通过混部系统部署在同一批机器，实现共享资源并错峰互补，提高整体的资源利用率。目前业内利用混部技术可以将数据中心的 CPU 利用率提升至 40% 左右，vivo 在 2023 年混部平台投入生产也已经将部分混部集群的 CPU 利用率提升至 30% 左右，整体收益也是可观的。&lt;/p&gt; 
&lt;p&gt;混部系统需要有强大的隔离能力，绝大部分都是基于容器，所以混部的前提是在线和离线业务都容器化，对于容器管理工具如 K8s 来说是更适应于运行时间长、启停次数少、容器数量少的在线服务，在线服务也能比较容易地上容器，而对于运行时间短、启停频繁、容器数量大的离线任务，对 K8s 来说不是天然地适应，但容器化已是大势所趋，K8s 也推出了性能更好的调度器、用于离线任务的控制器，Spark 在 2.3 版本后也支持容器化，诸多技术的发展也推动离线任务实现容器化以及在离线混部的落地。&lt;/p&gt; 
&lt;p&gt;本文将从在离线混部中的离线任务的角度，讲述离线任务是如何进行容器化、平台上的离线任务如何平滑地提交到混部集群、离线任务在混部集群中如何调度的完整实现以及过程中的问题解决。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、离线任务容器化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Spark Operator 方案&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 方案对比&lt;/h3&gt; 
&lt;p&gt;vivo 离线任务大部分任务是以 Spark 作为执行引擎，Spark 任务运行在 K8s 上，目前业界有两种架构的方案：Spark on K8s 及 Yarn on K8s。两者部分优缺点对比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//944f211eda9a472ce3e9c7cc7342579a.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark on K8s 是 Spark 容器化，由 K8s 直接创建 Driver 和 Executor 的 Pod 来运行 Spark 作业，Yarn on K8s 是 Yarn 的容器化，由 K8s 创建 RM 和 NM 的 Pod，Spark 的 Driver 和 Executor 运行在 NM Pod 的 container 中，正是由于两种架构方案的区别，它们各自也会存在优缺点。&lt;/p&gt; 
&lt;p&gt;Yarn on K8s 方案可以支持原生的 Hive、Spark、Flink 等引擎，它仅需要创建一定数量的 NodeManager Pod 来满足作业需求，Pod 运行相对稳定因此对 K8s 的压力比较小，本身 Yarn 支持调度性能和调度策略也是专门为离线任务设计的，调度性能比 K8s 的强很多。由于 NodeManager ESS 服务是对磁盘有容量和读写性能要求的，混部机器的磁盘一般难以满足，所以也需要能支持不同引擎的 Remote Shuffle Service。在资源利用上，NodeManager 需要满足多个作业的资源，最小单位是 Container，Pod 的资源粒度比较大，自身也会占用一些资源，如果资源粒度得不到有效地弹性伸缩，也会造成资源的浪费，因此需要引入额外的组件来协调,根据 Kubernetes 集群节点的剩余资源，动态调整 NodeManager 的 CPU 和内存，然而这也需要一定的改造成本。在资源紧张的情况下，NodeManager Pod 如果被驱逐也就意味着整个 NodeManager 被销毁，将会影响多个任务。&lt;/p&gt; 
&lt;p&gt;Spark on K8s 方案目前在 Spark 3.1 以上版本才正式可用，它需要频繁的创建、查询、销毁大量的 Executor Pod，对 K8s 的 ApiServer 和 ETCD 等组件都会造成比较大的压力，K8s 的调度器也不是专门为离线的大批量任务设计的，调度性能也比较弱。另一方面，Spark on K8s 虽然只能支持 Spark3.X 的 RSS，不过目前有较多的开源产品可选择。在资源利用上，最小单位是 Driver 和 Executor 的 Pod，资源粒度小，可以填充到更多的碎片资源，调度时直接与 K8s 对接，资源的弹性调度更多由 K8s 来承担，不需要额外的组件，改造成本比较低。在资源紧张的情况下，Executor、Driver 的 Pod 将依次逐个被驱逐，任务的稳定性会更高。&lt;/p&gt; 
&lt;p&gt;而对于 Spark on K8s 方案，还细分 2 种实现方案：Spark Submit on K8s 和 Spark Operator on K8s。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//65d397e91ee4e5dc2fd2dc1392df5e8c.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SparkOnK8s 架构图&lt;/p&gt; 
&lt;p&gt;(图片来源：Spark 官网)&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9690ad754f277e44ce4a6a09f6f7058a.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark Operator 架构图&lt;/p&gt; 
&lt;p&gt;(图片来源：Spark Operator 开源项目)&lt;/p&gt; 
&lt;p&gt;以 spark-submit 方式提交到 K8s 集群是 Spark 在 2.3 版本后提供的原生功能，客户端通过 spark-submit 设置 K8s 的相关参数，内部再调用 K8sApi 在 K8s 集群中创建 Driver Pod，Driver 再调用 K8sApi 创建需要的 Executor Pod，共同组成 Spark Application，作业结束后 Executor Pod 会被 Driver Pod 销毁，而 Driver Pod 则继续存在直到被清理。使用 spark-submit 方式的最大好处是由 spark-submit 来与 K8s 的进行交换，提交作业的方式几乎保持一致。但是因为使用的便利性所需要的封装也会带来一些缺点，spark-submit 是通过 K8sApi 创建 Pod，使用非声明式的提交接口，如果需要修改 K8s 配置就需要重新开发新接口，二次开发复杂繁琐，虽然 Spark 提供了大量的 K8s 配置参数，但也远比不了 K8s YAML 的声明式的提交方式更加灵活，而且 Spark Application 和 K8s Workload 的生命周期还不能较好地对应起来，生命周期不能灵活控制，任务监控也比较难接入 Prometheus 集群监控。虽然 Spark 社区也不断地在推出新特性来和 K8s 集成地更加灵活，不过对于些复杂场景需要定制开发，spark-submit 的封装性也会成为阻碍。&lt;/p&gt; 
&lt;p&gt;spark-submit 还是离线任务提交的思维，而 Spark Operator 方式就更倾向于 K8s 作业的思维，作为 K8s 的自定义控制器，在集成了原生的 Spark on K8s 的基础上利用 K8s 原生能力提供了更全面管控功能。Spark Operator 使用声明式的 YAML 提交 Spark 作业，并提供额外组件来管理 Spark 作业的生命周期，SparkApplication 控制器，负责 SparkApplicationObject 的创建、更新和删除，同时处理各种事件和作业状态，Submission Runner, 负责调用 spark-submit 提交 Spark 作业，Driver 和 Executor 的运行流程是一致的，Spark Pod Monitor，负责监控和同步 Spark 作业相关 Pod 的状态。Spark Operator 最大的好处是为在 K8s 中的 Spark 作业提供了更好的控制、管理和监控的功能，可以更加紧密地与 K8s 结合并能灵活使用 K8s 各种特性来满足复杂场景，例如混部场景，而相对地它也不再像 spark-submit 那样方便地提交任务，所以如何使用 Spark Operator 优雅提交任务将是在离线混部中一项重要的工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 最终选项&lt;/h3&gt; 
&lt;p&gt;在大的架构选型上，我们选择了 Spark on K8s，一方面因为 Spark3.X 是 vivo 当前及未来 2~3 年的主流离线引擎，另一方面 vivo 有比较完善的 K8s 生态体系，内部对 K8s 研发也比较深入，环境和能力都能很好地支持，在应用的小方向上，我们选择了 Spark Operator，因为它在混部这种复杂场景下使用更加灵活、扩展性更强、改造成本更低，我们最终决定使用 Spark Operator 方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 Spark 优化&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 Spark 镜像&lt;/h3&gt; 
&lt;p&gt;Spark 任务容器化的第一步就是构建具有 Spark 相关环境的镜像，Spark 任务类型主要分为 sql 任务和 jar 任务，在实践的过程中我们发现 Spark 的镜像构建需要&lt;strong&gt;注意几个问题&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark 环境的完整性&lt;/strong&gt;：镜像中除了打入自研的 Spark 包以外，还需要打入相应的依赖如 Hadoop、ZSTD、RSS 等包，对于 SparkJar 任务还有直接调用 Hadoop 客户端的，因此 Hadoop 客户端也需要打入镜像中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JDK 版本问题&lt;/strong&gt;：K8s 使用的 Spark 是基于 3.2.0 版本，镜像打包工具默认使用 JDK11，而自研的 Spark 用的 JDK1.8，由于在 Yarn 和 K8s 上使用的 JDK 版本不同，导致在双跑验证数据一致性时发现了 hash 函数、时间戳不一致的问题，因此 Spark 镜像中的 JDK 版本需要和 Yarn 保持一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;环境变量问题&lt;/strong&gt;：镜像生成容器后需要预置如 Spark、Hadoop 的环境变量，如果镜像中相关目录的位置不能完全和 Yarn 的提交节点保持一致，则需要检查各启动脚本，如 spark-env.sh 中的环境变量的路径是否存在，发生冲突时可以修改为绝对路径。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Spark 镜像构建完成后，区分 SparkSql 任务和 SparkJar 任务实质就是启动命令的不同，事实上 SparkSql 任务也就是 SparkJar 任务的一种，只是启动的主类是固定的，两者的启动参数如下：&lt;/p&gt; 
&lt;p&gt;SparkSql 任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver -f {sql 文件}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SparkJar 任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class {jar 任务主类} {jar 任务 jar 包} {参数}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;早期不仅构建了 Spark 镜像，还构建了 Spark 日志镜像，容器组成结构会复杂一些。如图例如 Driver 容器，我们将 Spark、Hadoop 等配置文件构建了 configMap，启动 initContainer 来拉取从 configMap 拉取配置文件，然后启动 Driver 容器执行 Spark 任务，同时也使用 sidecar 创建日志上报的容器，在 Spark 任务运行完成后上报 Driver 和 Executor 日志到 Spark HistoryServer。这样的方案看似充分应用了 K8s 技术，但是在实践的过程中这些技术却被一一弃用，转而逐步地把各种功能集中到了一个 Driver 容器上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c1f0bf5a2f03578b42831a80908e1aad.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体演进如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 initContainer&lt;/strong&gt;，拉取 Spark 等配置文件步骤写在启动命令中，Spark 作业执行前执行下载配置，原因在多个 namespace 下不方便统一管理，而且 configmap 内容较大，会导致 Pod 启动时配置加载的延迟增加，影响了 Pod 创建速度，同时 K8s 的内存和 CPU 资源占用增加，对 kube-apiserver、ETCD 负载有一些影响。去掉 initContainer 还有个重要的好处就是减小 ETCD 的存储压力，事实上我们在移除 initContainer 拉取配置的功能后的一段时间内还保留着 initContainer，在任务逐渐上量后发现 ETCD 的存储比较满，分析后发现 Spark 作业中的一个 Pod 生命周期大约 8 次更新，其中 initContainer 更新会占用 2 次，移除了之后理论上是可以减少 1/4 的 ETCD 存储，实际应用中完全去除了 initContainer 也确实能减小了 ETCD 的存储压力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 sidecar 创建日志上报的容器&lt;/strong&gt;，Driver 和 Executor 日志上报步骤写在启动命令中，Spark 作业执行完后再执行脚本上报，原因是 sidecar 在同一个 Pod 中与主容器共享相同的生命周期，不使用 sidecar 方式就能更快创建 Pod，Spark 任务执行完成后能更快释放资源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对于 Spark 作业会频繁创建、更新和销毁大量的 Pod，所以去除非必要的容器，提高 Pod 生命周期流转速度，就能降低 kube-apiserver、ETCD 工作负载，也能提高 Spark 的作业效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 Spark 改造&lt;/h3&gt; 
&lt;p&gt;Spark 任务运行在 K8s 上，对于一些使用的兼容问题也进行了&lt;strong&gt;相关改造&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HistoryServer 改造&lt;/strong&gt;，因为 Spark Operator 没有存储已结束作业的日志，因此参考了 on Yarn 的方式，在 Spark 作业结束后，通过日志上传脚本把 Driver 和 Executor 的日志上传 HDFS，与 Yarn 日志聚合类似，同时也在 Spark HistoryServer 做了二次开发工作，增加了 on K8s 方式的日志查看接口，用户查看已完成的 Executor 日志时，不再请求 JobHistory Server，而是请求 Spark HistoryServer 接口。但日志上传方式需要 Executor 执行完才能查看到日志，为了能实时查看到执行中的日志，可以在 Executor 内部实现一个 HTTP 服务，根据 Pod 以及端口信息拼接出日志请求 URL，Executor 启动一个 Servlet 自动获取本地日志并返回。日志查看体验上做到了基本与 Yarn 一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主机 ip 通信&lt;/strong&gt;，Spark Driver 和 Executor 之间的通信通常是通过主机名进行的，不过随着 Spark 任务增多，CoreDNS 因为频繁的域名解释请求导致压力增大，甚至会影响到在线服务，因此我们将 Hadoop 的配置文件改为 ip 格式、设置 Driver 和 Executor 使用 ip 地址，同时去除了对应的 K8s Service，通过访问 ip 而不是域名的方式来规避这个问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件参数兼容&lt;/strong&gt;，Spark Driver 在 K8s 上是运行在某一个 Pod 中的，所以文件需要是全局可视的，如 HDFS 文件，否则就会报文件未找到的错误，但 Spark 作业运行在大数据作业平台时有的任务使用的上传的本地文件，因此对于提交到 K8s 的任务，第一步是要把上传到大数据作业平台的文件再次上传到 HDFS，第二步是改造 add jar 和--file 等命令逻辑，Spark 任务在未能读取本地文件后将再尝试读取二次上传到 HDFS 的文件，实现任务无需修改成全局可视的文件路径也能读取到文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;non-daemon 线程终止&lt;/strong&gt;，在 K8s 上运行的 Spark 任务是指定 Client 模式，Client 模式下 Driver 遇到异常时停掉 SparkContxet，等所有 non-daemon 线程结束后，Driver 才会退出，但如果存在一直运行的 non-daemon 线程，那么 Driver 一直不退出，任务就一直处于执行中。因此需要改造成 Cluster 模式的异常退出机制，即异常时以非 0 退出码退出，不再等待其他的 non-daemon 线程结束，Driver 直接终止，以确保 Driver Pod 的正常结束。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Spark Operator 优化&lt;/h2&gt; 
&lt;p&gt;随着在 K8s 上运行的 Spark 任务不断增加，K8s 集群的负载也逐渐显现。因此，需要对 Spark Operator 进行一系列优化，以减轻 K8s 集群的压力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;离线使用独立的 kube-apiserver&lt;/strong&gt;，混部集群中离线容器占了很大一部分，而且离线任务由于生命周期短，容器创建销毁更加频繁，这对 kube-apiserver 造成了很大的压力，然而在线业务需要更高的稳定性，为了减少离线对在线业务的影响，我们拆分了 kube-apiserver，离线任务通过指定 master 参数来使用独立的 kube-apiserver。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 K8s 的 HostNetwork 网络模式&lt;/strong&gt;，在 K8s 上启动 Driver 与 Executor 虽然使用的是独立 ip+固定端口，但频繁的 ip 申请和释放也对 kube-apiserver 造成了一定的压力，因此我们改为使用 HostNetwork 网络模式，同时不指定端口避免端口冲突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化 Spark Operator 控制器的队列&lt;/strong&gt;，在任务量比较大的情况下，Spark Operator 对 Pod 创建消耗效率会遇到瓶颈，排查后发现是 Spark Operator 的事件处理队列的并发数和限速桶的默认配置地太小，因此我们调低 Spark maxPendingPods 参数，调高 schedulerBacklogTimeout、 sustainedSchedulerBacklogTimeout 参数，减少 Pending Pod 个数，使 Pod 的处理效率符合集群的承载水平。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化 Spark Driver List Pod 接口&lt;/strong&gt;，使用 kube-apiserver 缓存，避免对 ETCD 产生影响，同时修改 Spark Driver 清理 Executor 逻辑，直接 Delete，减少 List Pod 对 kube-apiserver 压力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存储 emptydir + log lv 存储优化&lt;/strong&gt;，开发 CSI 插件，Spark 任务的离线日志单独存储，避免对在线业务 pod 的影响和磁盘负载高等问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark Secret 标记 immutable&lt;/strong&gt;，减少 kubelet watch secret 请求，降低 kube-apiserver 的负载。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、离线任务提交&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 平台任务提交平滑切换&lt;/h2&gt; 
&lt;p&gt;离线任务容器化方案确定后就要落地到生产，目前有 SparkSql 和 SparkJar 两种离线任务实现了容器化，这里以 SparkSql 任务为例描述 Spark 提交到混部 K8s 集群的流程并达到与传统客户端提交任务几乎无差异的平滑切换。目前 vivo 的离线任务都是通过大数据平台进行提交和调度的，平台会把主要的提交流程进行封装形成简单操作的功能，例如在平台上提交 SparkSql 任务流程一般是编写 sql、提交任务、查看 Driver 日志或在跳转到 SparkUI、执行完成后获取结果以及更新任务状态。&lt;/p&gt; 
&lt;p&gt;在平台内部，SparkSql 任务使用传统的 spark-submit&lt;strong&gt;提交流程&lt;/strong&gt;是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户编写好的 sql 上传到提交节点生成一个 sql 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交节点使用 Spark 客户端执行该 sql 文件启动 SparkSql 任务；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务启动后，通过不断地 tail 操作查询日志转存到 HBase 方便在平台页面上查询到 Driver 日志；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务结束后，再查询输出结果转存到 HBase 方便在平台页面上查询到执行结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根据提交 sql 任务命令的返回码来更新任务状态。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;传统 Spark 客户端提交任务大部分只会涉及到提交节点的客户端与平台服务器之间的交互，而 SparkSql 任务提交到混部 K8s 集群，从上节的 Spark 容器化方案的原理可知最终目的是要将 Spark 任务的任务参数按一定的格式封装好传入 Spark Operator 控制器来创建相关的容器，平台需要通过会调用容器团队提供的封装好 K8sApi 的统一接入层来创建 Spark 容器。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//15dcd589c32637e1dde5ed6757b4eed7.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在平台内部，SparkSql 任务提交到混部 K8s 集群的&lt;strong&gt;完整流程&lt;/strong&gt;为：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户编写好的 sql 上传到 HDFS 生成一个远程可访问的 HDFS 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SparkSql 任务参数封装好传入容器接入层的 createSpark 接口来调用 Spark Operator 控制器容器，再由 Spark Operator 控制器创建 Driver Pod，最后由 Driver Pod 根据 Spark 任务需要创建多个 Executor Pod，这些 Driver、Executor 的 Pod 相当于 Driver 和 Executor 的角色，共同配合执行 Spark 作业；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务启动后，通过容器接入层的 getDriverLog 接口周期性地查询 Driver 日志，实质上是查询 Driver 容器的日志，查询到的 Driver 日志会转存到 HBase 方便在平台页面上查询；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务结束后，一方面通过 Spark 启动脚本中的日志上传命令，把 Driver 和 Executor 的日志上传 HDFS，可以在改造后的 Spark HistoryServer 直接查看，另一方面执行结果也会先输出到 HDFS，再从 HDFS 转存到 HBase 方便在平台页面上查询到执行结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通过轮询接入层的 getSpark 接口根据返回的状态码来更新任务状态，在任务结束后，此时 Driver Pod 不会主动退出，首先将任务状态更新为成功，在日志和结果都存储完成后，再调用 deleteSpark 接口主动地杀死 Driver Pod 释放资源，完成整个 Spark 任务流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;可以看出 SparkSql 任务提交到混部 K8s 的执行主体是容器，因此需要增加容器接入层来管理 Spark 相关的容器，同时容器的使用更倾向于存算分离的效果，因此需要使用 HDFS 作为远程文件中转。&lt;/p&gt; 
&lt;p&gt;大数据平台上传统使用 spark-submit 和 onK8s 使用 spark-operator 的 SparkSql 任务执行流程对比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//024fa2e15ecb64123b58156eb1fd2188.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 混部任务的资源参数调整&lt;/h2&gt; 
&lt;p&gt;Spark 任务的 Driver 和 Executor，在 Yarn 上执行实质是运行在 NodeManager 节点上的，而在 K8s 上执行实质是运行在对应的 Pod 中的，由于 Spark on K8s 的提交方式和运行环境都不同于 on Yarn，任务的资源参数不能直接套用，需要做一些参数调整才能提交到 K8s 上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、资源参数提取和转换&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SparkSql 任务在 Yarn 上可以灵活地调整 sql 中的配置来满足不同特性的任务，sql 中的资源配置会覆盖客户端启动时的全局配置，因为 Executor 是运行在 NodeManager 节点上的，资源会相对充裕能满足 Executor 的资源需求，与此不同的是 Spark on K8s 的 Executor 是运行在 Executor Pod 中的，使用的资源会受到 Pod 资源规格大小的限制，而 spark-operator 的提交方式是要先获取 Executor 全局资源规格并生成相应资源规格大小的 Executor Pod，所以在提交 Spark 任务到 K8s 前就要准确地获取任务真正生效的资源参数。在大数据平台中资源参数会存在多中类型的参数中，参数的优先级为：任务配置参数 &amp;lt; 任务模板参数 &amp;lt; sql 中设置参数 &amp;lt; HBO 优化参数 &amp;lt; 平台统一参数，按此优先级顺序依次提取最终的资源参数并传入容器接入层创建 Spark 作业。另外容器接入层对于 Spark 的 arguments 和 sparkConf 参数都是要求以字符数组的方式传入，需要做好对原任务参数中的单引号、双引号、反斜杠和回车等符号以及分段落的处理和转换。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、overheadMemory 的计算&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Yarn 上 Executor 是运行在 NodeManager 节点上的，节点的资源一般都大于并能满足 container 申请的资源，所以在 Yarn 上只需要关心 container 本身申请的资源即可，而在 K8s 上 Executor 运行在对应的 Pod 中，可以把 Pod 理解为只一台独立的节点，除了要满足 container 申请的资源量，还需要一些 Pod 容运行时网络、存储等基础设施的自身开销资源，如果把 Spark 任务中 Driver 和 Executor 申请的资源直接设置为 K8s 中 Driver Pod 和 Executor Pod 的资源规格，有可能出现 OOM 情况，另外还要考虑非 JVM 内存，Spark 默认会把申请的 Executor 内存乘以一个系数或者至少预留 384 MiB 内存作为额外的非 JVM 内存缓冲区，用于堆外内存分配、非 JVM 任务以及各类系统进程的使用，可以通过设置 overheadMemory 进行覆盖。因此 K8s 的 Pod 除了要满足申请的 Memory 和运行时需要的 overheadMemory 的资源，还会再添加 100M 资源用于 Pod 运行的自身开销。&lt;/p&gt; 
&lt;p&gt;pod 的资源规格 = memory + pod overheadMemory&lt;/p&gt; 
&lt;p&gt;对于 overheadMemory 也需要先获取到并加到 Pod 的资源规格，如果任务有配置就直接使用配置的 overheadMemory，如果没有配置值则按一定计算公式来计算得到。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = overheadMemory + 100M&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;无配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = (max(384M，0.1*memory)) 向上取整到 512MB 的整数倍 + 100M&lt;/p&gt; 
&lt;p&gt;不过在实际应用中发现对于个别任务，即使 K8s 上配置的 overheadMemory 比在 Yarn 的配置多 100M，完全一样的任务在 K8s 上则有较多的 Executor OOM 情况，而在 Yarn 上却完全没有，目前排查到的现象是有 JVM 堆外的内存无法回收，如果任务需要较多的对外内存，堆外内存一直增长最终导致 OOM，但哪些内存无法回收的还未排查到。目前对于这些 OOM 过多且实际影响到运行效率的任务，在原 overheadMemory 基础上再增加 512M 后就没有 OOM 情况了，同时也有采用了大数据平台的 HBO 能力自动调整内存参数来事后规避这个问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、CPU 超分配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spark 任务申请的 CPU 使用一般不会使用完，事实上 Executor Pod 的 CPU 利用率也并不是很高，比如 Executor 申请 1 个核，通常只能利用 0.6 个核，存在 CPU 浪费的现象。Executor Pod 的资源规格是创建的时候分配的，利用容器的能力，可以采取 CPU 超分的方式提高 CPU 的利用率，例如 Executor 申请 1 核，实际用 0.6 核，如果 Pod 分配 1 核，那利用率就只有 60%，但如果 Pod 只分配 0.8 核，那利用率就有 75% 了，所以超分的策略就是申请了 1 核只给 0.8 核，但还是要按 1 核的申请量来运行任务。目前平台使用的是静态的固定比例超分设置为 0.8，实施超分配置策略后 Pod 的实际 CPU 利用率打到 80% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//29fe0829e28d1e2084e2dbba0910de3a.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 混部任务的筛选提交&lt;/h2&gt; 
&lt;p&gt;经过上面的任务提交方式的改造和任务资源参数的调整，原 SparkSql 和 SparkJar 任务就可以平滑切换提交到混部 K8s 上执行了，但在大规模切换之前平台还做了比较长期的双跑验证工作，在执行成功率、数据一致性和执行时效等方案都进行了双跑比较，双跑通过的任务才能切换到 K8s 上执行。除了双跑通过，前期还设置了其他的筛选条件如下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//698830de13538cf7b2a6cf67d0b6fa45.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前期按这些条件筛选出可以提交到 K8s 的任务，然后分批的进行 K8s 任务的参数标记，并把标记的这批任务添加监控进行跟踪。经过双跑验证、任务筛选、批量标记、监控跟踪和问题解决这一整套 SparkSql 任务上量 K8s 的流程，K8s 上的任务运行逐步稳定，K8s 的兼容问题也基本解决，因此目前取消了双跑通过的这一条件，主要保留了任务重要性、运行时长和重试次数这几个筛选指标。随着 SparkSql 任务上量和稳定，提交到 K8s 的任务类型也增加了 SparkJar 任务，SparkJar 任务无法进行双跑验证，所以在各种 K8s 兼容问题解决后再推进会更加稳妥。&lt;/p&gt; 
&lt;p&gt;目前大数据平台会定期筛选和标记一批 SparkSql 和 SparkJar 任务允许提交到混部 K8s，用户也可以自行开启，在任务配置页面只显示已开启混部，则该任务就有机会被提交到混部 K8s 上执行。当然，用户也可以手动关闭这一开关，并且手动操作的优先级最高，手动关闭后平台的自动开启功能将不再生效。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、弹性调度系统&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 弹性调度功能矩阵&lt;/h2&gt; 
&lt;p&gt;Spark 任务开启了混部也不是必定能提交到混部，最终能不能在混部集群上执行，还要根据当时混部集群的资源和运行情况等来确定，为了更好地协调离线任务和混部集群的供需关系，大数据平台构建了离线任务混部弹性调度系统。弹性调度系统的设计目是混部集群有资源了就调度离线任务，但在生产环境中不管是混部集群还是离线任务都会各自的问题需要解决和优化的需求，弹性调度系统也逐步演变成了全面管理离线任务提交到混部以实现混部资源最大化利用的功能矩阵。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.1 资源水位线调度&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//878bdd653f0ec47e7c32fe0b09e8f975.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;弹性调度的流程，任务按调度时间以任务流的形式过来，如果任务标记了允许提交到混部，那就会先去查询 K8s 的各个集群，如果某一个集群资源充足就直接提交到 K8s，如果当时没有足够资源就等待资源再判断，这里分为有三类任务，第一类是一直等 K8s 资源，永不超时，只会提交到 K8s；第二类是长时间等待，超时时间在 1 到 5 分钟，可以等久一点；第三类是短时等待，超时时间为 30-60 秒，稍微等一下，如果 K8s 没有资源就回到 Yarn 上执行，目前平台标记的任务大部分任务都是第三类短时等待。&lt;/p&gt; 
&lt;p&gt;混部集群提供给离线任务的资源是呈潮汐波动的，使用百分比的水位线方式才能更好地贴合资源的波动情况。混部集群提供的资源是指 CPU 和内存，但离线任务一般不能百分之百地获取到这部分资源，需要设置一个折算比例也就是水位线来计算出离线任务能使用的真正资源是多少，水位线的设置需要考虑&lt;strong&gt;几个因素&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、混部集群的碎片化率&lt;/strong&gt;，混部集群中的机器规格和正在运行的业务占用量都是不确定的，但一般大规格的机器多的集群碎片化率较低，所以小规格的机器多的集群的水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、资源动态分配容纳率&lt;/strong&gt;，对于开启了动态分配的 Spark 任务，无法提前知道任务所需的资源，需要留有一部分资源用于动态分配的消耗，如果同样的水位线资源规模大的混部集群容纳率会高，所以资源规模小的集群的水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、资源配比的均衡性&lt;/strong&gt;，不同的集群或者同一集群的不同时间段的 CPU 和内存配比可能会存在很大的差异，例如 Spark 任务的 CPU 和内存的平均比例是 1 核 6G，即 1:6，如果有 CPU 和内存比为 1:2 的，内存会被用完而 CPU 有剩余，此时为了内存留有部分余量，水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部资源可用量 = 混部资源提供量 * 资源水位线&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;资源水位线有 CPU 水位线和内存水位线，设计时以 CPU 或内存中的最低水位线为准，哪个资源先分配完就停止提交任务，不过在实际生产中大部分混部集群都是受内存限制较多，个别时段 CPU 比内存多但通过其他的限制手段即使 CPU 满载对任务影响不大，因此目前只开启了内存资源水位线。以上提到的 3 点可以当成集群的固有消耗需要保留有一定的余量，为了直观地控制混部资源使用率和引入优先策略，计算方式调整为：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部资源可用量 = 混部资源提供量 * (1-余量水位线) * 优先水位线&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;余量水位线根据各个集群来调整，一般为 0.05，优先水位线的范围可以在 0-1 之间。优先水位线的作用是对于一些符合优先条件的任务可以优先提交，但是任务调度是一有任务就要调度的流式调度，不能够先集中再挑选优先任务而是先到先得，所以要为优先任务预留一部分资源，例如优先水位线为 0.8，混部资源使用到 0.8 以下的时候任何任务都可以调度上来，但使用量超过了 0.8，那只有优先任务能调上来，也就是为优先任务预留了 0.2 的资源，当然即使资源使用量达到了 1，由于余量水位线的存在，实际的使用量为 0.95，混部集群仍有资源维持周转。优先水位线是最常用的调整参数，它实质就是控制混部任务提交量，不仅能调整混部资源的使用量，还在灰度测试、压力测试和问题排查等事项起到了灵活调节的作用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.2 其他调度能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1.多集群管理&lt;/strong&gt;：混部集群通常会有多个，vivo 目前就有多个生产环境的混部集群，各混部集群由于建设周期、机器规格和业务接入的不同，混部资源的规模和变化趋势都会呈现比较大的差异，因此每个集群的调度策略配置都需要做到能独立调整来适应各自的资源特点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.分时段控制&lt;/strong&gt;：每个混部集群上的在线业务一般是潮汐波动的，给到离线任务的资源也是潮汐波动的，因此每个集群需要做到在每天不同时段可以调整不同的调度策略，尤其在波峰波谷差异较大的时间段各自调整配置的差异会更大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.分散 namespace&lt;/strong&gt;：Spark 任务的 Driver Pod 和 Executor Pod 都会放在一个 namespace 中管理，如果所有任务都由一个 namespace 管理，那需要管理的 pod 数量会达到数十万的级别，会对 K8s 集群的性能和稳定性产生影响。因此需要将 Spark 任务平均分配到多个 namespace，采用的方案是轮询填充，任务优先分配到多个 namespace 中任务最少 namespace。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.失败回退 Yarn&lt;/strong&gt;：离线任务混部推进的过程中还有会有 Spark 兼容问题、混部集群异常和平台变更等问题导致的离线任务在混部 K8s 上运行失败，为了减少失败对任务的影响，任务在 K8s 上首次执行失败后就会自动回到 Yarn 重新执行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.资源准入粒度&lt;/strong&gt;：各混部集群的机器规格和碎片率是不一样的，如 executorMemory=2G 这样较小粒度的 Spark 任务即使碎片率较高的混部集群可以填充，而对于 executorMemory=16G 这样较大粒度的 Spark 任务，机器规格大的集群才更容易获取到资源，因此不同混部集群可以设置不同的准入粒度，小规格和碎片率高的集群准入粒度可以设置小一些。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6.任务偏好配置&lt;/strong&gt;：对于一些灰度任务和特殊要求的任务，例如只有在 0 到 8 点才允许提交到混部、只提交到某几个指定的混部集群等调度要求，需要支持任务偏好配置，在任务参数中调整混部控制参数实现相应的调度需求。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 弹性调度策略优化&lt;/h2&gt; 
&lt;p&gt;弹性调度的核心是通过资源水位线的调节，有混部资源就调度离线任务，但实际生产中还要考虑混部集群的运行情况，是否能稳定地接收和消化离线任务，同时在存在多个差异较大的集群时提交到哪个集群最优。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1 任务调度稳定优化&lt;/h3&gt; 
&lt;p&gt;大数据平台的离线任务提交高峰在凌晨时段而且调度时间集中在整点半点，还有 5 分和 10 分这样的整分，例如 03:00 调度的任务达 1000 个，但在 03:01 调度的任务只有 10 个，过于集中地提交任务会导致混部集群 Pending Pod 数量急剧上升，这是因为无论是查询集群资源还是 Pending 数的接口，更新数据都需要一定的周期时间，而且离线任务提交上去到获取资源也受 K8s 的调度时间的影响，所以获取集群运行情况总会滞后于任务提交。例如 03:00 查询集群是有资源的并且是健康的，由于任务开启了动态分配所以不能确定需要多少资源，此时集中提交了 1000 个任务，这 1000 个任务首先会创建 1000 个 Driver Pod，集群资源还是能满足的并且优先创建，假如每个 Driver 需要创建 100 个 Executor，如果集群没有这么多资源，那就会产生大量的 Penging Pod，严重影响集群的性能和稳定以及任务的执行效率，因此需要对弹性调度的稳定性进行优化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短时提交限制&lt;/strong&gt;：避免集中提交任务的直接方案就是根据各混部集群的资源规模设置短时提交的任务数量限制，例如 1 分钟内只能提交 100 个任务，集群短时间内 Pending Pod 数量会增加但仍在可以承受范围内，集群和任务都会稳定运行。短时提交限制相当于拦截并舍弃了部分某个时间点集中提交的任务，这里相当于舍弃了 900 个任务，那么提交的总任务量就减少了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;延迟打散提交&lt;/strong&gt;：为解决短时提交限制导致舍弃部分任务的问题，增加了短时延迟打散提交，例如 03:00 提交的 1000 个任务，随机打散到 03:00 到 03:03 的 3 分钟内，即使有短时提交限制，这 3 分钟内也可以提交 300 个任务。理论上将集中提交的任务延迟更久，能提交到混部的任务会更多，但是增加延迟时长就等于增加任务的执行时长，会影响到业务数据产出的及时性，因此延迟打散提交策略只能是短时的，进一步的优化是执行时长更久的任务延迟更久一点，但根本解决方案还是用户能将调度时间尽量打散。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集群反馈限制&lt;/strong&gt;：短时提交限制和延迟打散提交都属于静态限制，需要人为地根据各个混部集群的情况去判断和设置限制值，因此需要做到动态限制，就需要获取集群的运行情况并根据运行情况进行限制。事实上 K8s 的调度性能相比于 Yarn 还是有差距的，从提交的 Spark 任务到获取到资源运行 Pod 有一定的滞后时间差，这段时间查询内还是有剩余资源，但如果还继续提交新任务就会产生更多 Pending Pod，因此需要做集群运行情况的反馈控制，例如查询 Pending Pod 数、等待的 SparkApp 数，当数量达到一定数量就不再提交新任务。&lt;/p&gt; 
&lt;p&gt;集群反馈限制虽然是动态的能根据混部集群情况进行反馈调节，但是查询集群状态是滞后的，这种滞后的控制就容易被集中提交给打垮，所以要加上短时提交限制来上一道保险，为缓解短时提交限制造成的任务损失，就引入了延迟打散提交，而在延时打散的过程中集群能逐步消化任务，查询集群状态逐步接近真实情况，这时又可以交给集群反馈限制来动态调节，逐步从突增恢复到稳定，三个调度稳定优化策略相辅相成。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 集群分配均匀优化&lt;/h3&gt; 
&lt;p&gt;离线任务会调度到多个混部集群，每个集群的资源总量和可用资源量，以及集群运行状况都不相同，为保证离线任务的运行稳定和执行效率，需要在多个混部集群中选择一个最合适的集群。各个集群会按一定的规则进行排序，离线任务会按这个排序依次轮询各个集群，只要集群剩余资源满足且没有被短时提交限制、集群反馈限制等拒绝，离线任务就提交到该集群。集群排序的&lt;strong&gt;演化顺序&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;①初始方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排队队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;剩余资源量多的优先&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b0cade1eb777379e3744a4104790af8.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源最多的集群，保证离线任务运行稳定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于小集群剩余资源量很小一直分配不到任务容易「饿死」（事实上有的小集群全部资源量都达不到一个大集群的 20%）&lt;/p&gt; 
&lt;p&gt;② 优化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将资源使用量超过一定比例的集群放到排序队列，剩余的集群放到随机队列&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c8b8441d6a201f0d2e84113fcc307c2f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源较多的集群，即保证任务的运行稳定，随机的方式也能均匀「喂饱」每个集群&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随机分配在大任务量时相当于是平均分配，每个集群都会调度差不多的任务量，当前情况会存在整点集中提交大量任务，小集群接收和大集群同样任务量会抗不住，影响任务执行稳定和效率，小集群容易「撑死」&lt;/p&gt; 
&lt;p&gt;③再优化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加权随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;按剩余资源进行加权随机，剩余资源多的集群有更多概率分配到任务&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39918d1411bca61982582118837a610.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源较多的集群，「大集群多吃，小集群少吃」，每个集群都能填充同时保证任务的运行稳定&lt;/p&gt; 
&lt;p&gt;④ 最终方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优先队列（排序）+加权随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考虑优先队列，无视其他排序规则，优先队列里的集群将最优先，在优先队列中的集群再按资源排序&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//db44e6961fb051bfbb59cb66ff17797f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;继承上一方案的优点，同时对于特定项目或机房的离线任务，能优先调度到某些特定的集群&lt;/p&gt; 
&lt;p&gt;目前只以内存作为资源水位线的衡量标准，这里的资源量指的是内存量。最开始方案是按集群的剩余资源排序，内存资源剩余多的集群优先，缺点是小集群一直分配不到任务容易「饿死」，然后使用随机的方式也能均匀「喂饱」每个集群，但小集群接收同样任务量时容易「撑死」，于是随机队列按剩余资源进行加权随机，剩余资源多的集群有更多概率分配到任务，这样离线任务优先提交到资源较多的集群，「大集群多吃，小集群少吃」，每个集群都能填充同时保证任务的运行稳定，在此基础上增加优先队列，无视其他排序规则，优先队列里的集群将最优先，在优先队列中的集群再按资源排序，能优先调度到某些特定的集群，形成最终集群选择排序方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_21&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、混部的效果与未来规划&lt;/h1&gt; 
&lt;p&gt;经过以上的对 Spark 组件、K8s 混部系统、大数据平台以及弹性调度系统的改造和优化，目前混部集群及提交混部的离线任务运行持续稳定，每天任务调度到混部的次数达 10+万次，在凌晨的高峰期通过混部能为离线任务额外增加数百 TB 内存的计算资源，部分混部集群的 CPU 利用率提升至 30% 左右，整体收益也是可观的。&lt;/p&gt; 
&lt;p&gt;虽然目前 vivo 的在离线混部达到了一定的规模，但未来要继续提高混部的规模和收益，还有规划一些改进工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;1、提高离线任务混部规模。&lt;/h2&gt; 
&lt;p&gt;离线任务混部的节点是在线业务提供的，节点规模取决于在线业务峰值，峰值越高那么在业务低峰期能提供给离线混部资源就越多，因此提高混部规模的重要因素是提交更多的离线任务。然而目前采用的 Spark Operator 方案能提交的离线任务只有标准的 SparkSql 和 SparkJar 任务，而对于非标准的任务如脚本任务，脚本中除了调用 spark-submit 提交 Spark 作业还有额外的处理逻辑，这类任务还不能直接以 Spark Operator 的方式提交。事实上 Spark 作业更多是来自脚本任务的非标准任务，如果要继续增加离线任务的量，就必须把非标准任务也提交到混部，因此后续是选择改造 spark-submit 客户端支持 Spark Operator，或是选择使用 Yarn on K8s，还需要综合评估。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2、提高离线任务混部收益。&lt;/h2&gt; 
&lt;p&gt;目前混部节点 CPU 的平均利用率达到 30%，但仍有提升空间。从离线任务的角度来看，一方面是要增加错峰互补的时间段，例如离线任务的高峰期是 02:00 到 08:00，在线业务的高峰期是 06:00 到 23:00，在 06:00 后在线业务逐步上量开始回收资源，所以离线任务能显著提高混部集群 CPU 利用率的黄金时间是有 02:00 到 06:00 这 4 个小时，因此如果能把离线任务高峰期提前到 00:00 到 06:00，混部提效的黄金时间就能达到 6 小时。所以需要推动离线任务高峰期的前移，对于有依赖链路的任务，尽量减少调度时间的间隔，上游任务完成后能尽快调起下游任务，而对于没有依赖的任务，可以尽量提前调度时间，不过这两种调整都需要推动业务方来调整，平台也可以给予一定的计算成本优惠作为激励。另一方面是要提高混部资源的填充率，Spark 任务需要创建大量的 Executor Pod，目前混部集群的调度器为了保证调度效率就没有开启预选、优先策略，事实上 Spark 的资源粒度比较小更适合填充资源碎片，所以在不影响 K8s 调度效率的情况下优化资源调配策略，把合适的资源粒度的 Pod 分配到合适的混部节点，也是提高混部收益的方向。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18181972</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18181972</guid>
            <pubDate>Sun, 13 Apr 2025 06:41:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>开源多模态大模型「书生·万象 3.0」发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海人工智能实验室（上海 AI 实验室）升级并开源了通用多模态大模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frb_gVjQTuwdx0hse6KuAkA&quot; target=&quot;_blank&quot;&gt;书生·万象 3.0&lt;/a&gt;（InternVL3）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，通过采用创新的多模态预训练和后训练方法，InternVL3 多模态基础能力全面提升，在专家级基准测试、多模态性能全面测试中，10 亿~780 亿参数的全量级版本在开源模型中性能均位列第一，同时大幅提升了图形用户界面（GUI）智能体、建筑场景图纸理解、空间感知推理以及通识学科推理等方面的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;292&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1e01575a2bc4dfc8530b94281d9005d52e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在专家级多学科领域知识推理基准测试 MMMU 中再次突破开源模型极限，取得 72.2 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于司南 OpenCompass 开源评测框架，研究团队对 InternVL3 进行了全面系统的评估，包括多学科推理、文档理解、多图像 / 视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力以及以语言为中心的基准测试。评测结果显示，InternVL3 在开源多模态大模型中性能表现最优，创造了开源多模态大模型的性能新标杆，性能接近闭源模型 Gemini-2.5-Pro；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;创新提出原生多模态预训练方法，将语言和多模态学习整合于同一个预训练阶段，提升及拓展多模态能力的同时，进一步提升纯语言能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;提出混合偏好优化算法以及多模态测试阶段增强，通过负监督修正模型响应分布，大幅提升模型推理能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;公测版本：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.intern-ai.org.cn%2F%C2%A0&quot; target=&quot;_blank&quot;&gt;https://chat.intern-ai.org.cn/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345071</guid>
            <pubDate>Sun, 13 Apr 2025 06:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>豆包 1.5·深度思考模型发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今日火山引擎 AI 创新巡展杭州站现场，火山引擎总裁谭待发布了最新的豆包 1.5·深度思考模型，升级豆包·文生图模型 3.0、豆包·视觉理解模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时，面向 Agent 服务，发布 OS Agent 解决方案、GUI Agent 大模型——豆包 1.5·UI-TARS 模型；面向大规模推理，发布 AI 云原生·ServingKit 推理套件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据透露，截至 2025 年 3 月底，豆包大模型日均 tokens 调用量已超过 12.7 万亿，是 2024 年 12 月的 3 倍，是一年前刚刚发布时的 106 倍。IDC 报告显示，2024 年中国公有云大模型调用量激增，火山引擎以 46.4% 的市场份额位居中国市场第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;豆包 1.5·深度思考模型在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出。同时，模型采用 MoE 架构，总参数 200B，激活参数为 20B，低于业界同类模型参数规模的 50%，具备显著的推理成本优势。基于高效算法，豆包 1.5·深度思考模型在提供行业极高并发承载能力的同时，实现 20 毫秒极低延迟。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;363&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be145536aac0c4457023c8127490097c66a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，豆包 1.5·深度思考模型还具备视觉理解能力，可以像人类一样，不光基于文字思考，更能基于所见画面思考，思考更立体，让模型同时拥有「大脑」和「眼睛」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;升级的豆包·文生图模型 3.0 则能够实现更好的文字排版表现、实拍级的图像生成效果，以及 2K 的高清图片生成方式。可以广泛应用于影视、海报、绘画、玩偶设计等营销、电商、设计场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本的豆包·视觉理解模型具备更强的视觉定位能力，支持多目标、小目标、通用目标的框定位和点定位，并支持定位计数、描述定位内容、3D 定位。可应用于线下门店的巡检场景、GUI agent、机器人训练、自动驾驶训练等。新版本在视频理解能力上也有大幅提升，比如记忆、总结理解、速度感知、长视频理解等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRYJ2OiZM_M-Jh27x3OFEdg&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345068</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345068</guid>
            <pubDate>Sun, 13 Apr 2025 05:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>