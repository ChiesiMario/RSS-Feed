<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 11 Jun 2025 12:42:01 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>macOS Tahoe 是最后一个支持英特尔处理器的 macOS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;macOS Tahoe 支持四款使用英特尔处理器的 macOS，它们的发售年份是 2019 年和 2020 年。苹果对 Tahoe 的安全更新支持将持续到 2028 年秋天。&lt;/p&gt; 
 &lt;p&gt;从 macOS 27 开始，苹果新操作系统都将需要 Apple Silicon Mac。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 WWDC 举办的分会场上，苹果明确表示搭载英特尔处理器的 Mac 将不会获得明年推出的 macOS 27 更新，但仍可能会有添加安全修复的更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f223bac2bf7e49f84aa10b4c34782dd6b33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，苹果已经停止支持其产品线中某些非 Apple Silicon 型号。例如，macOS Tahoe 不适用于任何 Intel MacBook Air 或 Mac mini。&lt;/p&gt; 
&lt;p&gt;但 Tahoe 仍然支持部分英特尔 Mac，包括 2019 款 16 英寸 MacBook Pro、2020 款英特尔 13 英寸 MacBook Pro、2020 款 iMac 和 2019 款 Mac Pro。&lt;/p&gt; 
&lt;p&gt;根据苹果的警告，macOS 27 将不再支持所有这些老旧设备，因此 macOS 26 将是最后一个兼容版本。&lt;/p&gt; 
&lt;p&gt;这意味着苹果对英特尔 Mac 的支持正在逐步取消，公司希望将所有精力和创新都放在 Apple 自主芯片的机器上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354872</guid>
      <pubDate>Sun, 11 May 2025 10:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Seelen UI —— 完全可定制的 Windows 桌面环境</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Seelen UI 是一款旨在增强 Windows 桌面体验的工具，专注于自定义和提高工作效率。它可以无缝集成到你的系统中，提供一系列功能，让你可以个性化桌面并优化工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="333" src="https://static.oschina.net/uploads/space/2025/0610/153055_JVfK_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;发挥创意&lt;/strong&gt;：Seelen UI 可让你根据自己的风格和需求定制桌面。可以调整菜单、小部件、图标和其他元素，打造个性化且美观的桌面环境。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;提升工作效率&lt;/strong&gt;：Seelen UI 可帮助你高效地组织桌面。借助平铺窗口管理器，窗口可自动排列，支持多任务处理，让工作更加流畅。&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;尽享音乐&lt;/strong&gt;：Seelen UI 集成媒体模块，兼容大多数音乐播放器，让你轻松享受音乐。可以随时暂停、继续播放和跳过曲目，无需打开其他窗口。&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;更快&lt;/strong&gt;：借助受 Rofi 启发的应用启动器，Seelen UI 提供了一种简单直观的方式来快速访问你的应用程序并执行命令。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;用户友好配置&lt;/strong&gt;：Seelen UI 提供直观的界面，方便用户自定义。只需点击几下，即可调整主题、任务栏布局、图标等设置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seelen UI 需要安装 WebView 运行时。在 Windows 11 系统中，WebView 运行时已预装在系统内。但在 Windows 10 系统中，WebView 运行时已包含在&lt;code&gt;setup.exe&lt;/code&gt;安装程序中。此外，Microsoft Edge 浏览器也需要安装才能正常运行。部分用户可能已修改系统并移除 Edge，因此请确保 Edge 和 WebView 运行时均已安装在你的系统中。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/seelen-ui</link>
      <guid isPermaLink="false">https://www.oschina.net/p/seelen-ui</guid>
      <pubDate>Sun, 11 May 2025 10:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Genspark 发布 AI 浏览器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能体 Genspark 发布了 AI 浏览器产品，官方称其具有&lt;strong&gt;极速、广告拦截、全能智能体、自动驾驶模式&lt;/strong&gt;的特性，并提供了 MCP 商店。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170325_JqCj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170647_1Eqh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="540" src="https://static.oschina.net/uploads/space/2025/0611/165940_ftHT_2720166.gif" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.genspark.ai%2Fbrowser" target="_blank"&gt;https://www.genspark.ai/browser&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Genspark 由百度前高管景鲲创立，今年 4 月宣布&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能体"Genspark Super Agent"，号称是一款 "快速、准确、可控" 的通用 AI 代理。这一消息迅速在技术社区引发热议，众多专业人士将其与 Manus 相提并论，认为这标志着通用 AI 代理技术的新一轮角逐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/344443" target="news"&gt;AI 智能体 Genspark 上线 9 天，收入近千万美元&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent" target="news"&gt;百度前高管的 AI 创企发布通用智能体：Genspark Super Agent&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354844/genspark-ai-browser</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354844/genspark-ai-browser</guid>
      <pubDate>Sun, 11 May 2025 09:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​Ilya Sutskever：AI 将接管人类的一切</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在最近的演讲中，OpenAI 前首席科学家 Ilya Sutskever 回归母校多伦多大学，分享了他对人工智能（AI）发展的深刻见解。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 与多伦多大学的渊源颇深，20 年前他在这里获得了学士学位，而此次则是他从该校获得的第四个学位。他在演讲中回顾了自己在多伦多大学的学习经历，尤其感慨与 AI 领域先驱 Geoffrey Hinton 的学习机会，使他成为一名科学家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-5833dd185f58bdfa34442db6dd544edf1b7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 强调，接受现实并专注于改善现状是个人成长的重要心态。他提到，许多人容易陷入对过去的后悔，然而这种心态并不利于前进。他鼓励大家思考下一步的行动，尽管这一转变不易，但一旦做到，就会使事情变得更简单。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;接下来，Sutskever 转向了 AI 的主题。他指出，我们正处于一个特殊的时代，AI 的迅速发展正在改变我们的学习方式和工作模式。AI 正在以不可预测的方式影响着各行各业，一些工作会更早感受到变化，而另一些则可能稍晚。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他预测，AI 未来将有能力完成所有人类能完成的任务。他认为人类大脑本质上是一种生物计算机，因此 AI 也理应具备完成所有人类任务的潜力。尽管当前的 AI 已能完成许多令人惊叹的任务，但仍存在不足之处，然而随着技术的进步，这些不足将得到改善。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 还提出了深刻的问题：当 AI 能够完成所有工作时，人类将如何应对这一变革？他强调，随着 AI 技术的发展，如何合理利用 AI 将成为人类面临的重要挑战，包括在工作、经济和 AI 研究等领域的应用。他认为，AI 的发展将极大加速人类的进步，但同时也会带来巨大的挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 指出，AI 的发展速度可能会超出我们的预期，未来几年内，AI 的能力将不断提升，其对生活的影响将更加显著。尽管目前难以完全预见 AI 带来的变化，但可以确定的是，AI 的进步将对每个人的生活产生深远的影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/344437/ilya-sutskevers-ssi-valued-at-32b" target="_blank"&gt;OpenAI 前首席科学家 Ilya Sutskever 的公司估值达 320 亿美元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354842</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354842</guid>
      <pubDate>Sun, 11 May 2025 09:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman 最新文章《温和的奇点》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Sam Altman 今天在他的博客更新了一篇长文：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthe-gentle-singularity" target="_blank"&gt;《The Gentle Singularity》&lt;/a&gt;&lt;/em&gt;，文中指出人类或许正迎来一个新的奇点，而这个奇点并非突如其来，而是温和地悄然降临。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1006" src="https://static.oschina.net/uploads/space/2025/0611/161536_O8JD_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是译文。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我们已越过临界点，起飞开始了。人类距离创造出数字超级智能已近在咫尺，而至少到目前为止，现实远比想象中来得平实自然。&lt;/p&gt; 
&lt;p&gt;街道上尚无机器人行走，我们大多数人也不整日与 AI 交谈。人们依然会因病离世，太空旅行依旧不易，宇宙中仍有诸多未解之谜。&lt;/p&gt; 
&lt;p&gt;然而，我们近期确实构建了在许多方面超越人类智慧的系统，它们能显著提升使用者的工作效率。最困难的部分已然过去：造就 GPT-4、o3 等系统的科学洞见来之不易，却将引领我们走得更远。&lt;/p&gt; 
&lt;p&gt;人工智能将以多种方式惠及世界，但由 AI 驱动的科学加速进步和生产效率提升所带来的生活质量改善，将是巨大的；未来可以远比现在美好。科学进步是整体进步的最大驱动力；想到我们本可拥有的更多可能，实在令人振奋。&lt;/p&gt; 
&lt;p&gt;从某种重要意义上说，ChatGPT 已经比历史上任何个体人类都更强大。数亿人每天依赖它处理日益重要的任务；一项微小的新能力便能产生巨大的积极影响；而一个微小的错位，乘以数亿用户，则可能造成深远的负面影响。&lt;/p&gt; 
&lt;p&gt;2025 年，能执行真正认知工作的智能体已然登场；编写计算机代码的方式将彻底改变。2026 年，我们可能迎来能够发现新见解的系统。2027 年，能在现实世界执行任务的机器人或将问世。&lt;/p&gt; 
&lt;p&gt;将会有更多人能够创作软件和艺术作品。但世界对这两者的需求远超当前供给，只要专家们善用新工具，他们很可能仍远胜于新手。总体而言，到 2030 年，单个人的生产力相比 2020 年所能达到的飞跃，将是惊人的巨变，许多人会找到从中获益的途径。&lt;/p&gt; 
&lt;p&gt;在最重要的方面，2030 年代或许不会天翻地覆。人们仍将爱自己的家人，表达创造力，玩游戏，在湖中畅游。&lt;/p&gt; 
&lt;p&gt;但在同样至关重要的其他方面，2030 年代很可能将与此前任何时代都截然不同。我们尚不知智能水平能超越人类多远，但我们即将揭开谜底。&lt;/p&gt; 
&lt;p&gt;在 2030 年代，智能与能源——即思想的涌现以及将思想变为现实的能力——将变得极度充裕。长久以来，这两者一直是人类进步的根本限制；在充裕的智能与能源（以及良好的治理）之下，理论上我们能够拥有其他一切。&lt;/p&gt; 
&lt;p&gt;我们已然生活在令人惊叹的数字智能时代，经历了初期的震惊后，大多数人已习以为常。我们飞快地从惊叹 AI 能生成优美的段落，转而期待它能创作优美的小说；从惊叹它能做出救命的医学诊断，转而期待它能研发治愈良方；从惊叹它能编写小程序，转而期待它能创立全新的公司。奇点的演变便是如此：奇迹成为日常，继而成为标配。&lt;/p&gt; 
&lt;p&gt;已有科学家坦言，借助 AI，他们的效率提升了数倍。先进 AI 令人着迷的原因众多，但或许最重大的意义在于，我们能利用它来加速 AI 自身的研究。我们或许能发现新的计算基材、更优的算法，甚至更多未知的突破。若能将十年的研究压缩至一年或一个月内完成，进步的速率显然将大不相同。&lt;/p&gt; 
&lt;p&gt;从今往后，我们已构建的工具将帮助我们探寻更深远的科学洞见，并助力我们打造更优的 AI 系统。这当然不等同于 AI 系统完全自主更新自身代码，但这已然是&lt;strong&gt;递归式自我改进&lt;/strong&gt;的雏形。&lt;/p&gt; 
&lt;p&gt;其他自我强化的循环也在发挥作用。巨大的经济价值创造已启动一个飞轮，推动着为运行日益强大的 AI 系统所需的复合式基础设施建设。能够制造其他机器人的机器人（某种意义上，也包括能建设其他数据中心的数据中心）已不再遥远。&lt;/p&gt; 
&lt;p&gt;若首批百万台人形机器人仍需传统方式制造，但之后它们便能运作整个供应链——采矿与冶炼、驾驶卡车、管理工厂等等——以制造更多机器人，而这些机器人又能建设更多芯片工厂、数据中心等，那么进步的速度显然将不可同日而语。&lt;/p&gt; 
&lt;p&gt;随着数据中心生产走向自动化，智能的成本终将趋近于电力的成本。（人们常好奇一次 ChatGPT 查询的耗能：平均每次查询耗电约 0.34 瓦时，相当于烤箱工作一秒多，或高效节能灯泡亮几分钟。耗水约 0.000085 加仑，约合十五分之一茶匙。）&lt;/p&gt; 
&lt;p&gt;技术进步的速率将持续加快，而人类总能适应几乎任何变化的特性仍将延续。挑战必然存在，如某些职业类别整体消失；但另一方面，世界财富将以前所未有的速度激增，使我们能认真考虑以往绝无可能的全新政策构想。我们或许不会立刻采纳全新的社会契约，但几十年后回望，渐进的变革终将累积成巨变。&lt;/p&gt; 
&lt;p&gt;历史经验表明，我们会找到新的工作与新的追求，并快速接纳新工具（工业革命后的职业变迁便是一个近例）。期望值会提升，但能力提升的速度同样迅猛，我们终将获得更好的事物。我们将为彼此创造越来越奇妙的东西。人类相比 AI 拥有一个长远而关键的优势：我们天生关注他人及其所思所为，而对机器则不甚在意。&lt;/p&gt; 
&lt;p&gt;千年前的农夫若审视我们许多人的工作，或许会认为那是「虚假的工作」，觉得我们不过是因食物充足、坐拥难以想象的奢华而游戏人生。我期待我们回望千年后的工作时，也会觉得它们「虚假」，但我毫不怀疑，从事它们的人必将感到无比重要与满足。&lt;/p&gt; 
&lt;p&gt;新奇迹诞生的速率将超乎想象。如今甚至难以预料到 2035 年我们将有何发现：或许今年解决高能物理难题，明年便开启太空殖民；今年取得重大材料科学突破，明年就实现真正的高带宽脑机接口。许多人会选择以相似的方式生活，但至少一部分人可能会选择「接入」（虚拟世界）。&lt;/p&gt; 
&lt;p&gt;展望未来，这听起来令人难以置信。但置身其中时，感受或许会是震撼但可控的。从相对论视角看，奇点是一点一滴发生的，融合是缓慢进行的。我们正攀登指数级技术进步的漫长弧线；向前看总是陡峭垂直，向后看则显得平坦，但它始终是一条平滑的曲线。（回想 2020 年，若有人预言 2025 年将接近通用人工智能，听起来会比我们现在对 2030 年的预测更为疯狂。）&lt;/p&gt; 
&lt;p&gt;伴随巨大机遇的，是严峻的挑战。我们亟需从技术和社会层面解决安全问题，而鉴于其经济影响，确保超级智能的广泛可及性也至关重要。最可取的前进路径或许是：&lt;/p&gt; 
&lt;p&gt;解决对齐问题：即我们能强有力地确保 AI 系统学习并践行人类集体真正的长期愿望（社交媒体信息流是 AI 未对齐的实例：其算法深谙如何让你持续滚动浏览，精准把握你的短期偏好，但这却是通过利用人脑的某种特性，凌驾于你的长期偏好之上）。&lt;/p&gt; 
&lt;p&gt;然后着力使超级智能变得廉价、普及，且不被任何个人、公司或国家过度垄断。&lt;/p&gt; 
&lt;p&gt;社会具有韧性、创造力且适应迅速。若能凝聚集体的意志与智慧，尽管会犯错，某些事情会出纰漏，但我们能快速学习调整，从而运用这项技术最大化收益、最小化风险。在由社会共同决定的宽泛边界内，给予用户充分自由至关重要。世界越早开始探讨这些边界何在以及如何定义集体对齐，结果越好。&lt;/p&gt; 
&lt;p&gt;我们（整个行业，而不仅是 OpenAI）正在为世界构建一个大脑。它将高度个性化、人人皆可轻松使用；限制我们的将是好点子的匮乏。长久以来，科技创业圈常嘲笑「点子大王」——那些只有想法却需要团队来实现的人。现在看来，他们即将迎来属于自己的高光时刻。&lt;/p&gt; 
&lt;p&gt;OpenAI 如今承载诸多角色，但首先且最重要的，我们是一家超级智能研究公司。前路漫长，但大部分路径已然照亮，未知的黑暗区域正迅速退去。能从事这份事业，我们深感庆幸。&lt;/p&gt; 
&lt;p&gt;廉价到无需计量的智能已触手可及。此言或许疯狂，但若在 2020 年告诉你们我们将达到今日之境，恐怕比如今我们对 2030 年的预测听起来更为疯狂。&lt;/p&gt; 
&lt;p&gt;愿我们借助超级智能，平稳、指数级、波澜不惊地向上攀升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrbEEJfEoCdV4aeV_LN46mg" target="_blank"&gt;https://mp.weixin.qq.com/s/rbEEJfEoCdV4aeV_LN46mg&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354832/the-gentle-singularity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354832/the-gentle-singularity</guid>
      <pubDate>Sun, 11 May 2025 08:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 据悉与谷歌达成新的云服务协议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据报道，OpenAI 与谷歌近期签署了一项新的云服务合作协议以获取更多计算资源。该协议将深化双方在技术领域的合作，涉及高性能计算资源及数据存储服务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/160306_SD6R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新协议旨在支持 OpenAI 的模型训练需求，并优化其产品性能。具体条款尚未公开，但预计将对人工智能行业发展产生重要影响。&lt;/p&gt; 
&lt;p&gt;两家公司尚未就该交易公开宣布任何消息，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fretail-consumer%2Fopenai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10%2F" target="_blank"&gt;但一位消息人士向路透社透露&lt;/a&gt;，谈判已持续数月，最终于 5 月达成协议。&lt;/p&gt; 
&lt;p&gt;自 2019 年以来，OpenAI 就与微软达成了协议，赋予其为这家初创公司构建新计算基础设施的独家权利。因此这笔交易将使 OpenAI 将其计算资源扩展到微软之外。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354829</guid>
      <pubDate>Sun, 11 May 2025 08:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源网盘应用 Alist 原开发者称项目已交由公司运营</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免费开源、支持多存储的自建网盘程序 (文件列表程序)，可以轻松在 VPS 服务器、NAS、普通电脑 Win、Mac、Linux 上部署。它除了能作为一款自建网盘 (将文件保存在设备硬盘上) 外，最大的特色就是支持「挂载各大主流网盘」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在该项目 GitHub 仓库提交 issue，反馈官网出现 404 问题，并提出」项目是否被卖了」的疑问。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原开发者 Xhofe 今日在订阅频道发布公告，&lt;strong&gt;称项目已交由公司运营&lt;/strong&gt;，之后会帮助审查开源版本仓库的代码，确保 release 分支由 CI 自动构建。此外&amp;nbsp;main 分支已开启分支保护，后续所有提交均需经过 PR 审核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Sun, 11 May 2025 07:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式发布了豆包大模型 1.6、豆包·视频生成模型 Seedance 1.0 pro、豆包·语音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新发布的豆包大模型 1.6 系列由三个模型组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的综合模型，是国内首个支持 256K 上下文的思考模型，支持深度思考、多模态理解、图形界面操作等多项能力。支持选择开启或关闭深度思考、自适应思考三种方式，其中自适应思考模式可根据提示词难度自动决定是否开启思考，提升效果的同时大幅减少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的强化版本；在代码、数学、逻辑推理等基础能力上进一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的极速版本，支持深度思考、多模态理解、256K 上下文；延迟极低，TOPT 仅需 10ms；视觉理解能力比肩友商旗舰模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在价格方面，&lt;strong&gt;豆包大模型 1.6 采用统一定价模式，首创按「输入长度」区间定价&lt;/strong&gt;，在企业使用最多的输入区间 0-32K 范围内，豆包大模型 1.6 的价格为输入 0.8 元/百万 tokens、输出 8 元/百万 tokens，综合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相当于每生成一条 5 秒的 1080P 视频只需 3.67 元，行业最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·实时语音模型已全量上线火山方舟，对企业客户开放使用。该模型支持自然语言高级指令控制，具备唱歌表演、声线模仿、方言演绎等多种能力，语气、用语、思考方式等拟人感大幅提升，能随时打断与主动搭话。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sun, 11 May 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供为期两周的免费 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 与 AI 代码工具开发商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，为 Cline 用户提供为期两周的 Grok 3 模型免费访问权限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需注册 Cline 账户，即可在 Cline 的提供商中选择并免费使用 x-ai/grok-3 模型进行编码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是开源 AI 编程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 双模式，具有终端执行能力和 Model Context Protocol (MCP) 特性。它能够分析用户的项目文件结构、源代码等，帮助用户创建和编辑文件、执行终端命令、使用浏览器进行测试等，还可以通过 MCP 协议扩展其功能，添加自定义工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sun, 11 May 2025 06:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再获数千万美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣布再次完成数千万美元的 Pre-A+轮融资，同时正式发布了全球首个 AI 驱动的一站式 3D 工作台 Tripo Studio，并即将推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;据称此次融资将重点投入 Tripo 系列大模型研发及 Tripo Studio 产品及生态平台建设，加速构建「AI+3D」全产业链条，打造「基础模型 + 生态插件 + 原生工作台」的端到端产品体系，从而构建覆盖专业级（PGC 生产者）、达人级（PUGC 创作者）到大众级（UGC 用户）的创作者画像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，VAST 成立于 2023 年 3 月，是一家专注于通用 3D 大模型研发的 AI 公司，致力于通过打造大众级 3D 内容创作工具建立 3D UGC 内容平台，使基于 3D 的空间成为用户体验升级、内容表达创新和新质生产力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持续迭代 Tripo 大模型，先后推出 Tripo1.0 至 Tripo2.5 等数十亿参数规模的 3D 大模型系列，同时发布 TripoSR、TripoSG、TripoSF 等广受全球开源社区认可的 3D 基础模型，并配套开发了系列 3D 软件生态插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新开源：通用自动骨骼绑定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 开源基础 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sun, 11 May 2025 03:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度百舸万卡集群的训练稳定性系统设计和实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 训练稳定性的演进历程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 竞赛中 AlexNet 的横空出世，开启了现代 AI 发展的新纪元。彼时我们不会想到，十年后支撑 AI 训练的 GPU 集群会从研究室里的几台服务器，发展成需要专门供电系统的万卡级计算矩阵。在这个算力爆发式增长的过程中，训练系统的稳定性管理正经历着从「简单运维」到「精密工程」的深刻变革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 标早期的小模型时代：手动运维的黄金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 训练，更像是手工作坊式的精雕细琢。大多数训练任务只需十几块 GPU，利用 PyTorch 或 TensorFlow 的数据并行功能就能轻松应对。记得那时算法工程师们有个共识：如果训练遇到问题，重启往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;当时我们构建的监控系统就像汽车仪表盘，只能显示最基本的任务状态。当训练意外中断时，工程师们会像侦探一样翻查日志 —— 如果发现是 GPU 报错，就联系运维同事。运维人员则带着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到机房巡检，像老中医把脉般通过温度、功耗等指标判断硬件状态。这种工作模式虽简单，但应对数十卡规模的集群还算游刃有余。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型风暴：从量变到质变的冲击&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登场如同打开潘多拉魔盒，将 AI 训练带入新的纪元。当我们开始部署千卡/万卡集群时，才发现原有的运维体系就像用小渔网捕鲸鱼 —— 完全无法匹配新需求。&lt;/p&gt; 
&lt;p&gt;让我们通过百度百舸经历过的一个真实案例来深入理解这个问题：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸帮助一家 AIGC 创业公司迅速将其训练规模从百卡扩展到千卡级别。然而在训练数天后的某个周末凌晨，训练进程意外发生了 hang 死。由于当时缺乏有效的故障感知和容错机制，直到第二天算法工程师发现任务超时退出时，已经耽误了数小时宝贵的训练时间。更糟糕的是，任务日志中除了简单的 timeout 报错外毫无线索，平台监控也显示所有训练节点状态正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢复训练的算法工程师没有立即上报问题，而是选择直接重新提交任务。但不幸的是，新任务运行数小时后再次出现相同的超时退出。这时他们才不得不寻求技术支持，但值班工程师面对这种任务 hang 死的问题也缺乏诊断经验，只能通过二分法慢慢定位。最终发现是某个节点的静默故障（SDC）导致了训练进程假死。等问题得到解决时，距离首次故障已经过去将近 30 小时，这意味着损失了价值巨大的千卡算力资源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集群训练稳定性全景图&lt;/h1&gt; 
&lt;p&gt;站在现在的时间点回望，AI 训练稳定性已从辅助功能演变为核心基础设施。就像现代建筑中的抗震结构，它虽不直接参与空间构成，却是万丈高楼得以屹立的关键。当行业向着数万卡集群迈进时，这套隐形护甲的质量，将直接决定 AI 进化的速度与边界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸对训练过程的生命周期进行了更细致的拆分，提出了「无效训练时间」这一关键指标，并致力于将其最小化。具体来说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任务无效训练时间 = 故障中断次数 × 任务故障恢复时长 + 任务常态写 Ckpt 总时长&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任务故障恢复时长 = 故障感知召回耗时（自动/人工定位）+ 任务调度耗时 + 任务初始化耗时 + 任务重算时长。&lt;/p&gt; 
&lt;p&gt;通过这个公式可以看出，要降低无效训练时间，需要「围绕基础设施稳定性」、「任务容错」两个维度来系统展开，重点解决三个方面的问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基础设施的交付质量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任务故障容错的召回率、准确率和时效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化 checkpoint 机制，减少保存时间和恢复时的重算时间。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过容错架构的整体变革，百度百舸形成了从 「任务负载 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基础架构」全链路的自动异常感知、诊断、恢复能力，可覆盖 90%+ 的训练异常场景，时效性最快可以实现秒级异常感知、分钟级定位，以及平均 3 分钟的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基础设施交付质量保障&lt;/h1&gt; 
&lt;p&gt;基础设施的交付质量保障是稳定性的基础。&lt;/p&gt; 
&lt;p&gt;CPU 时代，机器的交付前可能仅会跑一些常规的 CPU 计算、网络的压力测试，并不会从业务视角去评估基础架构，机器交付后硬件异常的故障频率相对较少。有硬件故障时，通常走工单系统人工换机用户相对是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 时代，AI Infra 的交付则需要考虑 CPU、GPU、RDMA 网络、存储，甚至机房的功率、温度等各方面因素，遗漏任何一个环节都会成为后续稳定性的隐患。在交付给客户后，机器也可能会由于长时间的高负载运行频繁出现硬件故障，而 GPU 机器的高昂成本，使客户对节点故障感知、换机的时效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸对 GPU 机器交付前及交付后的稳定性质量进行了系统性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸会对机器进行 200 多项指标检测，然后进行 48 小时烤机，以及 NCCL-Test 的机内、机间的大环、同号卡通信性能基准测试，端到端的大模型训练、推理性能基准测试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付后，需要能够实时的感知节点故障及定期巡检，并具备分级处理的自愈能力，例如 Error 级别的故障实现自动排水、重启，Fault 级别故障实现自动换机。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任务容错的准召率保障&lt;/h1&gt; 
&lt;p&gt;任务层面稳定性最核心的就是做好容错，能够让业务在无论遇到何种故障时都能快速恢复。&lt;/p&gt; 
&lt;p&gt;那么，首要的工作就是我们能够准确的识别出异常，然后对故障进行诊断定位，最后能够自动化的从异常中恢复。&lt;/p&gt; 
&lt;p&gt;因此，任务容错需要能够从端侧（即每个训练 worker）探测到进程与环境的各类异常，同时有个中心服务（Master）从任务全局的视角去诊断、定位异常，最终做出相应的决策来使任务能够快速从异常中恢复。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任务容错最重要的就是提升故障的召回率与准确率，即如何能够尽可能的准确识别、定位所有故障。我们将故障分类两类：显式故障和隐式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;显式的故障通常比较容易召回，我们将实践积累的各种进程异常状态及各类报错 pattern 形成专家知识库，再结合硬件感知服务（HAS Agent）的硬件全链路 10 秒级监控能力，可以实现显式故障的召回率达到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隐式的异常则往往很难轻易的识别，例如训练进程 hang、慢节点就是典型的隐式故障，需要丰富的经验积累才能准确的识别出异常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我们就以最典型的隐式故障场景 —— 训练进程 hang 死为例，来看下如何能够做好 hang 自动感知、诊断。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 训练****hang 的自动感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;训练任务发⽣ hang 之后，绝⼤多数情况都会以 timeout 的⽅式报错并退出进程，最常⻅的就是在通信过程中如果发⽣ hang，NCCL 的 watchdog 会中断通信，并有报如下 timeout 报错，然后再由 pytorch 的 torchrun 进程感知并中断训练过程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默认为 10 分钟 NCCL 通信超时，而 Megatron-LM 为 30 分钟。在万卡规模训练场景中，意味着一万张卡要至少浪费 30 分钟才能被发现。这个时效性是不可接受的。而且当 30 分钟超时后程序会立马退出，很难有机会进行下一步定位，需要一些时效性更高的感知机制，并且在程序退出前获取一些有效信息供后续诊断分析。&lt;/p&gt; 
&lt;p&gt;很多公司、实验室在面对 hang 的问题时，会在采用框架层插桩的方式来 trace 训练进程，这种方式通常是比较直接且准确的，但是有比较强的侵入性，而且可能还会有一些性能开销。对于云厂商来说，需要寻找对用户更透明、更无损的方式来感知、定位 hang 异常。&lt;/p&gt; 
&lt;p&gt;如何感知训练 hang，以百度百舸的产品设计思路为例，我们可以从以下几个方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练进程 hang 的最直观表现是什么？&lt;/p&gt; &lt;p&gt;人工判断一个任务是否 hang 了，最直接的方式就是看是否所有 worker 的任务日志一段时间内都不输出日志了，所以 hang 自动感知的第一种方法就是采集所有 worker 的日志，并判断所有 worker 日志中最后一行日志是否为 x 分钟前的（x 小于 Pytorch 的通信超时时间，例如 8 分钟），如果是则基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时进程有什么样的表现？&lt;/p&gt; &lt;p&gt;任务 hang 时，可能进程的调用栈都不在发生变化，进程的调用栈可以通过 py-spy/pystack 等工具进行探测，所以我们可以用此类工具对所有训练任务进行一个定时采样，当采集 n 个样本所有进程栈都没有变化时，可以判定一次 hang，这种方式通常可以将 hang 感知缩小至 3～5 分钟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时监控指标有哪些变化？&lt;/p&gt; &lt;p&gt;训练进程中的 CUDA 算子计算、集合通信操作通常都是在毫秒，甚至微秒、纳秒内完成的，当任务在正常迭代过程中发生了 hang，我们常遇到的情况是所有 rank 的 RDMA 流量会降到 0，而 GPU 的利用率为 100%、SM 利用率则在很低的水位。如果持续几分钟都是这种状态时，意味着训练进程已经计算完成，在等着集合通信完成，这种情况下基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信库中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常单次集合通信操作都是在 ms 级的，如果一次操作在 30 秒钟都没有完成，那就可以判定为通信 hang 死了。百度自研的 BCCL 集合通信库层可以对每一次集合通信操作都进行打点，来实现通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述几种方法，我们可以分别实现一种探针，来抓取相应的特征到中心端 master 组件进行下一步诊断和容错决策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信库 BCCL 是百度智能云推出的一款面向大模型训练场景优化的集合通信库。&lt;/p&gt; 
 &lt;p&gt;BCCL 基于开源的 NCCL 进行了功能扩展和能力增强，针对大模型训练场景在可观测性、故障诊断、稳定性等方面进行优化，进一步提升集合通信库的可运维能力。相比 NCCL，BCCL 的关键特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可观测性：新增集合通信带宽实时统计能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障诊断：新增集合通信 hang 时的故障诊断能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;稳定性：增强网络稳定性和故障容错能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能优化：提升大模型训练主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;训练 hang 的自动诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我们需要进一步的诊断、定位，来确定是否真的发生了 hang，以及 hang 的具体位置。具体的来讲，master 收集到各类 agent 的数据后，会做一些综合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的发生了 hang？&lt;/p&gt; &lt;p&gt;感知阶段各种探针只能探测到 hang 的一种特征，并没有办法 100% 的确定是否真的 hang 住了，事实上不侵入用户进程是很难做到 100% 确定 hang 的。因此，为了提高 hang 的判定准确率，我们需要将各种特种综合起来判断，探针上报到 master 后，由一个 hang 诊断模块，按照一个时间窗口（例如 5 分钟），进行综合判断。如果在时间窗口内日志、监控、进程调用栈、通信库中有 2 条以上都处于不处于活跃状态时，我们判断任务真正发生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具体发生的位置？&lt;/p&gt; &lt;p&gt;确定任务 hang 了之后，我们需要找到 hang 所在的节点来对它进行隔离。因此诊断模块需要在探针上报的数据中进一步找寻特征，来确定 hang 发生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 诊断：在感知阶段，BCCL 可以在通信库层面对所有 rank 的通信进行打点。如果有节点一直未完成通信则是发生了 hang。但是此节点可能并非真正发生 hang 的源头，有可能是在等待其他节点完成通信。诊断模块可以根据 BCCL 打印的通信组信息，进行交叉判断，如果某个节点在多个通信组中都未完成通信，那这个节点就是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指标诊断：上文中我们提到，通信阶段发生 hang 之后，所有 rank 的 RDMA 流量都会降到 0，而同时绝大部分 rank 的 GPU 利用率持续为 100%，只有某一两个 rank 的 GPU 利用率为 0，那这个 rank 很有可能是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调用栈诊断：进程调用栈也可以作为一个 hang 源头诊断的重要参考。当发生 hang 之后，绝大部分的 rank 都要么处于 barrier 等待状态，要么处于通信等待阶段。只有个别的 rank 卡在其他函数上，那么通过对比分析，可以将调用栈与其他 rank 不同的节点初步判定为 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;综合诊断：上面 3 种特征为我们提供了 hang 的诊断依据，将 3 者关联起来分析后，我们基本上可以比较准确的确定一个具体的 hang 的源头，再结合硬件故障感知的相关信息可以进一步明确根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基于 eBPF 的隐式故障感知与诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在复杂的大规模分布式训练场景中，传统用户态监控往往难以捕获系统内核层面的异常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基于 eBPF（Extended Berkeley Packet Filter）技术的隐式故障感知体系，能够在不侵入用户代码的前提下，对训练进程的系统调用、网络通信、CPU 调度等内核态行为以及训练框架关键函数运行时间建立立体观测能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探针部署原理通过在内核关键路径注入轻量级探针，实现低开销的系统级行为捕获。针对训练场景特点，主要聚焦 4 类事件跟踪：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练关键函数跟踪：微秒级跟踪训练过程中，前向计算、反向计算、集合通信操作等关键函数执行耗时，记录函数间调用关系。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调度阻塞跟踪：挂钩 sched_switch 事件，检测进程在 TASK_UNINTERRUPTIBLE 状态持续时间，当单次持续超过阈值（如 5 秒）时捕获调用栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 运行时 API 监控：通过 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等关键库注入探针，记录 CUDA API 调用耗时分布。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 级通信监控：在 ibv_post_send/ibv_poll_cq 等核心通信接口设置观测点，统计通信时延分布。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合上面 4 类事件，完成以下 2 类数据分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单体异常探测基线与实时数据对比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;群体一致性检测。采用卡间对比算法，当某一 rank 的以下指标偏离集群中位数超过阈值时判定异常，包括系统调用频率、进程就绪队列等待时长、NVLink/RDMA 带宽利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上所述方法，百度百舸针对以下 2 类典型的隐式故障进行诊断：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练 hang 根因定位。通过关联 eBPF 捕获的多维度数据进行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当检测到某 rank 的 GPU &amp;nbsp;Kernel 执行出现分钟级空跑（SM 利用率 &amp;gt; 70% 但无有效计算输出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时伴随该节点 RDMA QP 状态停滞（ibv_poll_cq 无新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内核调度器显示进程处于 D 状态超过阈值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖动溯源。基于 eBPF 火焰图、时序图等进行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取发生性能下降时段的 CPU on-cpu/off-cpu 堆栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对比正常时段数据，识别出异常的锁竞争（futex 调用占比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结合 NUMA 内存访问统计，定位跨 NUMA 内存访问导致的 TLB 颠簸问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此类技术已在百度百舸的万卡规模训练集群中验证，相比单纯依赖应用层监控的方案，将隐式故障的平均检测时间从分钟级缩短至秒级，诊断准确率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通过与既有硬件故障感知服务、BCCL 通信库监测体系联动，百度百舸形成了覆盖从硬件到系统内核再到应用层的立体化诊断能力。&lt;/p&gt; 
&lt;h1&gt;05 任务故障恢复的时效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢复的时效性也是容错能力的一个重要指标，反映的是任务从故障发生到再次重新进入训练迭代的时间，恢复效率越高则算力浪费越少。影响到任务恢复效率有 2 个重要因素，一是任务平均中断时间，二是训练重算时间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多级重启策略减少故障中断时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任务发生异常后，上文中我们提到需要经过故障自动感知、诊断和自愈等 3 个环节，那么减少中断时间的核心思想，就是尽可能的缩短这 3 个环节的时间，通过多维度的感知、诊断手段可以将故障发现、定位的时效性降低至分钟级甚至秒级。自愈则需要能够根据不同的诊断结果进行分级恢复和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单点显式故障：重调度异常节点（replace），对节点进行集群级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;单点隐式故障：重调度异常节点，对节点进行任务级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非单点故障：原地重启尝试恢复（restart），无法恢复时重新调度所有节点（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过多级重启策略，尽可能避免单点故障引发全部节点的重新调度。在万卡级别的训练场景中，百度百舸将大部分训练异常场景恢复时间从过去的 30min 缩短至现在的 30s 内，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;触发式 checkpoint 减少训练重算时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多级任务重启策略外，另一个提高任务故障恢复效率的重要手段就是减少训练重算时间。在探讨具体技术方案之前，我们先来看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;传统的 checkpoint 保存通常采用固定间隔策略，比如每隔 N 个 step 或每隔 T 小时保存一次，这种方式实现简单但缺乏灵活性，可能会产生大量冗余存储，同时在故障发生时可能会损失较多训练进度。&lt;/p&gt; 
&lt;p&gt;而触发式 checkpoint 则是一种更智能的方案，它根据特定条件或异常事件（如故障、显存不足、显式指令等）动态触发模型状态保存。其核心目标是通过灵活的控制保存时机，减少不必要的存储开销和训练中断时间，从而降低因频繁或冗余保存导致的重算时间浪费。&lt;/p&gt; 
&lt;p&gt;随着大模型训练规模的扩大，还有一种更激进的「零重复 checkpoint」技术，即在每个训练 step 都保存一次 checkpoint。这种方案的优势在于可以将重算时间降到最低，确保故障发生时能够从最近的 step 恢复，几乎不会损失训练进度。但其显著的缺点是存储开销巨大，即使采用增量式存储，仍然需要相当大的存储空间和 I/O 带宽。此外，频繁的 checkpoint 操作也可能影响训练性能。&lt;/p&gt; 
&lt;p&gt;相比之下，触发式 checkpoint 走的是一条平衡之路。我们来看下它实现的几个核心要点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容错：训练进程集成容错的故障感知与定位机制，在进程退出前自动触发保存。这种主动感知机制能够在故障发生的第一时间保存训练状态，最大限度减少进度损失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速转储：异步 checkpoint 保存机制会将 checkpoint 暂存到共享内存中，再由外部程序转储至磁盘。当某个节点异常时，容错组件会拉起新节点，并在新节点训练进程启动前，利用 RDMA 技术实现 checkpoint 快速从故障节点转储至新节点，这大大减少了从远程存储拉取 checkpoint 的时间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗余备份：触发式 checkpoint 也并非完美无缺，例如在节点发生内核 crash 等严重故障时，可能无法触发自动保存。因此，需要通过定期的冗余备份机制进行兜底，确保 checkpoint 不会完全丢失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实践表明，当触发式 checkpoint 与异步、增量式的 checkpoint 机制结合使用时，可以在保证数据安全性的同时，显著提高 checkpoint 保存效率，减少训练重算时间。&lt;/p&gt; 
&lt;p&gt;相比零重复 checkpoint 的重型方案，触发式 checkpoint 提供了一个更实用的折中方案，在合理的存储开销下实现较好的容错效果。当然，具体选择哪种方案，还需要根据实际的训练规模、硬件条件和可用资源来权衡。&lt;/p&gt; 
&lt;p&gt;随着分布式训练规模的持续增长，相信未来会出现更多创新的 checkpoint 方案，比如基于预测的主动保存策略、多级存储架构的智能调度等，这些都将为提高大规模训练的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 业务发展对稳定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 训练的稳定性管理已经演变为智能时代的精密工程。从最初靠人工重启解决问题的摸索阶段，到如今能自动感知异常、快速恢复的智能系统，每一次进步都映照着算力规模的跨越式发展。&lt;/p&gt; 
&lt;p&gt;让人不禁思考，在未来十万卡集群的算力洪流中，或许会出现更精妙的动态平衡方案：既能像鹰隼般敏锐捕捉故障征兆，又能如雁群迁移般智能调度资源，在秒级恢复与 PB 级存储成本之间找到新的平衡支点。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持厂内千卡和万卡集群有效训练时长已经可达 99.5%，为客户大模型的预训练保驾护航，比如国内第一个数学大模型——九章算术，国内第一个类 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增强语义嵌入的模型算法综述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持续推进「人工智能＋」行动，百度智能云+DeepSeek 为何成为国有企业首选？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 云服务器的软件系统设计和实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基于 Flink 的配置化实时反作弊系统&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能云 xDeepSeek，最具性价比的 DeepSeek 一体机合集来了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sun, 11 May 2025 03:02:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Hugging Face 发布开放权重模型贡献榜：Qwen 与 DeepSeek 跻身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;发布&lt;/a&gt;开放权重模型贡献榜，中国团队 Qwen 和 DeepSeek 成功入围前 15 名。该榜单表彰为开源社区提供高质量模型权重的团队，其模型广泛应用于学术与产业创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴云智能集团支持的 Qwen 团队，以 Qwen3 系列模型在指令跟随、代码生成等任务中的优异表现受到社区青睐。Qwen2.5-72B 系列位列开源大语言模型前列，其轻量化模型 QwQ-32B 通过强化学习优化，在数学推理和代码生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 则以低成本、高性能的 R1 系列模型闻名。R1-0528 在 LiveCodeBench 排行榜中超越多个国际竞品，仅次于 OpenAI 顶尖模型。其轻量化版本 DeepSeek-R1-0528-Qwen3-8B 通过知识蒸馏技术，单 GPU 即可运行，在 AIME2025 数学测试中击败 Google 的 Gemini2.5Flash，展现了在特定领域的竞争优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中国 AI 团队在开源生态中的崛起。Hugging Face 负责人表示，两团队的贡献为全球开发者提供了高效资源。NVIDIA 首席执行官黄仁勋也赞扬其性能与成本平衡正在重塑 AI 格局。未来，Qwen 计划探索多模态技术，DeepSeek 则将推出 R2 模型，持续推动 AI 创新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sun, 11 May 2025 02:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥 Solon Flow 设计器入门</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索视频：&lt;/p&gt; 
&lt;p&gt;&lt;iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114657104759990&amp;amp;bvid=BV1opT6z5EiJ&amp;amp;cid=30416702034&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354770</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354770</guid>
      <pubDate>Sun, 11 May 2025 02:51:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Android 16 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌发布了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为今年的第一次大版本升级，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按键式导航（三大金刚）的预测性返回手势&lt;/li&gt; 
 &lt;li&gt;强制通知分组&lt;/li&gt; 
 &lt;li&gt;以进度为中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 设备的桌面模式（开发者选项）&lt;/li&gt; 
 &lt;li&gt;低功耗蓝牙听力辅助设备支持&lt;/li&gt; 
 &lt;li&gt;自定义键盘快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截图优化&lt;/li&gt; 
 &lt;li&gt;以旧换新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性详细介绍查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sun, 11 May 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 推迟开源模型的发布时间</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席执行官山姆·奥特曼宣布，原计划于今年初夏发布的公开权重的开源模型预计&lt;strong&gt;将推迟至夏末发布&lt;/strong&gt;，而不是 6 月与公众见面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究团队做了一些出乎意料且非常令人惊奇的事情，这非常值得等待，但需要更长的时间。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣布将发布自 GPT-2 以来的首个「开源」语言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最强」开源模型，计划今年初夏发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sun, 11 May 2025 02:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首个推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣布推出&lt;/a&gt;其首个推理模型系列 Magistral，采用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高数学和物理等主题的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有两种版本：Magistral Small 和 Magistral Medium。Magistral Small 拥有 240 亿个参数，在 Apache 2.0 协议下开源。Magistral Medium 是一款功能更强大的模型，目前已在 Mistral 的 Le Chat 聊天机器人平台、该公司的 API 以及第三方合作伙伴云平台上提供预览。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中写道：「Magistral 适用于各种企业用例，从结构化计算和程序逻辑到决策树和基于规则的系统。这些模型针对多步骤逻辑进行了微调，提高了可解释性，并以用户的语言提供了可追溯的思维过程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立于 2023 年，该公司得到了 General Catalyst 等风险投资机构的支持，迄今已筹集超过 11 亿欧元（约合 12.4 亿美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;尽管 Mistral 资源雄厚，但在某些领域，例如推理模型开发，Mistral 仍落后于其他领先的人工智能实验室。从 Mistral 自身的基准测试来看，Magistral 似乎也并非一款特别有竞争力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 测试中，Magistral Medium 的表现不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的编程基准 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或许正因如此，Mistral 在其博客文章中大力宣扬 Magistral 的其他优势。声称 Magistral 在 Le Chat 中提供答案的速度是竞争对手的「10 倍」，并且支持多种语言，包括意大利语、阿拉伯语、俄语和简体中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的发布是在 Mistral 推出「vibe coding」客户端 Mistral Code 之后。在此之前的几周，Mistral&amp;nbsp;推出了几款专注于编码的模型，并推出了 Le Chat Enterprise，一项面向企业的聊天机器人服务，提供 AI 代理构建器等工具，并将 Mistral 的模型与 Gmail 和 SharePoint 等第三方服务集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>【运维实操指南】2 分钟定制雷池 WAF 认证页：从「标准表单」到「视觉升级」全攻略</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;在，通用设置 &amp;gt; 防护配置，模块下，找到 [自定义 HTML] 模块&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="341" src="https://oscimg.oschina.net/oscnet//30cd12a12b9b01facd09506982aa5867.jpg" width="716" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;就像写一个普通的 html 页面一样，你可以同时写入 style、script 等标签, 所以用 css 就能修改中心区域的样式啦。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;把文末的示例代码复制到&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="449" src="https://oscimg.oschina.net/oscnet//4116eaeb2f8f24a9d1bf87150294cc81.jpg" width="725" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;效果图:&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="346" src="https://oscimg.oschina.net/oscnet//679bc9d16ccf472845db825ecfd23844.jpg" width="746" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log('Im a console.log, which is written in a script tag');
&amp;lt;/script&amp;gt;
&amp;lt;style type="text/css"&amp;gt;
  body {
    background: #395180;
    margin: 0;
  }
  body #slg-box {
    background-color: grey;
    width: 400px;
    height: 100%;
    top: 0;
    left: 0;
    transform: translate(0, 0);
    padding: 100px 20px;
  }
  body #slg-usergroup-username,
  body #slg-usergroup-password {
    background-color: grey;
    color: #fff;
  }
  body #slg-box-title {
    color: #e15ccf;
  }
  body #slg-usergroup-btn {
    color: grey !important;
  }
  body #slg-with-more-title div:nth-child(2) {
    background-color: transparent;
    width: 100%;
    height: 30px;
    line-height: 30px;
    text-align: center;
    border: 1px solid;
  }
  body #slg-with-more-title div:nth-child(1) {
    display: none;
  }
  body #slg-tabs &amp;gt; div {
    fill: green;
  }
  body #slg-usergroup-container input {
    border-style: dashed;
  }
&amp;lt;/style&amp;gt;

&amp;lt;div
  style="
    background-color: grey;
    width: 200px;
    height: 100px;
    text-align: right;
    top: 50%;
    position: relative;
    left: calc(50% + 200px);
    position: relative;
    transform: translate(-50%,-50%);
    border-radius: 10px;
    font-size: 30px;
    line-height: 100px;
    text-align: center;
  "
&amp;gt;
  hello world
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354756</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354756</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 发布 o3-pro：更强大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;发布&lt;/a&gt;了 o3-pro 推理模型，基于 o3 所打造，拥有更强的数学、科学、编程等领域的表现。&lt;/p&gt; 
&lt;p&gt;据介绍，o3-Pro 可，自动调用多种工具，包括可以搜索网页、分析文件、推理视觉输入、使用 Python、通过记忆功能个性化回复等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由于调用的工具较多，所以，思考的时间比 o1 Pro、o3 更长。&lt;/strong&gt;o3-pro 与 o3 系列一样拥有 200K 的上下文窗口和 100K 的输出，但价格却比它们暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表现上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在专家评估中，评审人员普遍认为 o3 Pro 在多方面都比 o3 模型更进一步，尤其适合用在科学、教育、编程、商业和写作这些需要深度输出的任务中。&lt;/li&gt; 
 &lt;li&gt;在学术评估的基准测试中，o3-pro 的整体表现持续优于 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 还通过四次尝试获取正确答案的方式进行实验发现，o3-pro 能保持较好的性能表现。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用户提供，取代 o1-pro；企业版和教育版用户将在下周获得使用权限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;价格方面，o3-pro 输入为 20 美元/百万 token，输出 80 美元/百万 token；而 OpenAI CEO Sam Altman 昨晚宣布，o3 降价 80%——因此 o3 价格来到了输出 2 美元/百万 token、输入 8 美元/百万 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sun, 11 May 2025 02:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>KubeCon+CloudNativeCon China 2025 在香港盛大开幕，共绘云原生未来</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p&gt;2025 年 6 月 10 日，中国香港 —— 今日，由云原生计算基金会（CNCF）和 Linux 基金会联合主办的全球云原生计算领域顶尖盛会 KubeCon + CloudNativeCon China 2025 于香港隆重启幕。来自全球的开发者、技术专家、企业决策者及行业领袖共聚一堂，探索云原生技术未来蓝图，共推云计算生态繁荣发展。&lt;/p&gt; 
 &lt;p&gt;盛会首日，汇集了来自 Linux 基金会、CNCF、华为、Akamai、阿里云、Arm、AWS、Intel、LFOSSA、DaoCloud、F5、Fortinet、ICON、KubeWharf、ManageEngine、SUSE、KubeDB、科大讯飞等头部企业与组织的技术专家、企业代表及开源领袖。为期两天的议程将呈现约 100 场主题演讲、闪电演讲及项目展示，聚焦云原生与 AI 融合、安全合规、多云架构、数据处理与存储等多项前沿技术，为现场观众带来深度技术实践与战略洞察。&lt;/p&gt; 
 &lt;p&gt;聚焦核心议程，首日的开幕致辞与主题演讲环节亮点频现，重量级嘉宾相继登台。&lt;/p&gt; 
 &lt;p&gt;Linux 基金会执行董事 Jim Zemlin 为大会致开场词。Jim Zemlin 鼓励科技公司使用开源软件来帮助创新。他指出，长期以来，有很多公司反对开源，试图保持专有的地位，最终要么以低估值被收购，要么只能退出一些业务领域。为什么开源在所有的技术创新中的作用如此巨大？Jim Zemlin 表示，答案是因为它在经济上非常有价值，「我们与哈佛商学院进行了一项研究，如果必须购买所有用来创建技术、产品和服务的开源软件，那需要花费的成本高达 9 万亿美元，这就是开源如此强大的原因。」&lt;/p&gt; 
 &lt;p&gt;&lt;img height="507" src="https://oscimg.oschina.net/oscnet/up-3148dadc1499f9a5e77b67236866f6c5967.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;CNCF 首席技术官 Chris Aniszczyk 为大会做社区开幕致词。Chris Aniszczyk 高度认可中国在云原生技术领域的创新与贡献。中国在科技创新，尤其云原生领域展现重大贡献，是 CNCF 最早且最强大的生态系统之一，开源贡献位居全球第二，孕育出如 Volcano、Dragonfly、KubeEdge、OpenYurt 等多个具有全球影响力的项目，彰显了在边缘计算、容器调度、分布式处理等多方面的卓越能力。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="513" src="https://oscimg.oschina.net/oscnet/up-a458d49baccea2f5a94b050de918d9924e6.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;Odyssey Cloud 联合创始人 Amit Dsouza 和 Nirmata 社区负责人 Cortney Nickerson 发表《Crossplane Is the Answer! but What Is the Question?》主题演讲。二人介绍了 IaC 工具 Crossplane 在平台工程方面的赋能作用，比如通过扩展 Kubernetes API，以声明式的方式管理基础设施和应用程序等。此外，Crossplane + ArgoCD + Kyverno 堆栈还可以实现 GitOps 驱动的自动化，确保部署符合组织合规性和安全策略。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-b39291f8c25f9ae68378b06ecbccac514ff.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;华为首席开源联络官，CNCF 董事会成员任旭东发表《迈向人工智能集群云》主题演讲。任旭东指出，人工智能硬件基础设施正朝着大型处理器集群的方向发展，需要我们在构建和管理云的方式上进行重大变革，而借助 Linux、Volcano 和 Karmada 等项目，我们可以实现向人工智能集群云的演进。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="513" src="https://oscimg.oschina.net/oscnet/up-2981a2c77bb968828df1b6e8df65eed5037.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;Second State 创始人 Michael Yuan 发表了《针对 GenAI 工作负载优化的 Linux 堆栈》主题演讲。Michael Yuan 介绍了 Flatcar 的基础知识及其对 Wasm 运行时的支持，讨论了 WasmEdge 对可移植 AI 模型和推理应用程序的支持，并演示了一个可在 Flatcar 中跨 GPU 和 CPU 运行的 GenAI 应用程序。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="506" src="https://oscimg.oschina.net/oscnet/up-b3c6a0bdb509152e9f34e215bf552e6a93b.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;华为云软件工程师 Xuzheng Chang 和科大讯飞平台架构师 Dong Jiang 发表《利用 Volcano 进行扩展模型训练：科大讯飞的 Kubernetes 突破》主题演讲。据介绍，科大讯飞在大规模模型训练中，通过利用 Volcano，将 GPU 利用率提升了 40% 以上，并将故障恢复时间缩短了 70%。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="515" src="https://oscimg.oschina.net/oscnet/up-2098f237a664232ed1ddce8a1bd6d078672.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;香港环球航空学会科技主管、主任助理 Aaron Xu 和 DaoCloud 首席执行官兼创始人 Roby Chen 发表《香港人工智能的未来：从本地创新到全球影响力》主题演讲。据介绍，HKGAI V1 的发布标志着香港人工智能发展翻开了新的篇章。HKGAI 团队充分发挥本土互联和全球布局的优势，拥抱开源社区，共同应对从优化高性能计算集群到探索前沿人工智能模型等诸多挑战。未来，香港将进一步整合内地和国际资源，深化技术创新和应用拓展，为全球人工智能标准和应用贡献「香港方案」。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="500" src="https://oscimg.oschina.net/oscnet/up-0b36a5534d137948137e29dbcaa96ffceb9.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;此外，大会现场还特别设立了项目展厅，展示全球多个顶级开源项目，呈现开源技术生态的最新进展和创新成果。&lt;/p&gt; 
 &lt;p&gt;首日盛况已燃，精彩远未落幕！在接下来的议程中，与会者将有机会深入技术细节，参与更多深度对话。大会还将带来近百场分技术演讲及特色活动，聚焦微服务治理、可观测性、安全、平台工程等热点议题，更多来自全球顶级企业与创新团队的洞见与实践将精彩呈现。敬请期待，共同见证云原生与 AI 融合新纪元的无限可能！&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;感谢赞助商&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;KubeCon + CloudNativeCon China 2025 的成功举办，得益于赞助商们的大力支持。在此感谢以下赞助商：&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;关于&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;云原生计算基金会&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;云原生计算能协助组织利用开源软件栈，在公共云、私有云和混合云等各种云环境中构建和运行可扩展的应用程序。云原生计算基金会 (CNCF) 托管包括 Kubernetes、Prometheus 和 Envoy 在内的全球技术基础设施的关键组件。&lt;/p&gt; 
 &lt;p&gt;CNCF 汇集了行业顶尖的开发者、终端用户和供应商，并举办世界上最大的开源开发者会议。作为非营利性 Linux 基金会的部分，CNCF 得到了超过 800 个成员的支持，其中包括全球最大的云计算和软件公司，以及 200 多个创新型初创企业。有关更多信息，请搜索 CNCF 官网。&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;关于&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;Linux 基金会&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;Linux 基金会是全球领先的开源软件、硬件、标准和数据协作平台。Linux 基金会的项目对全球基础设施至关重要，涵盖 Linux、Kubernetes、Node.js、ONAP、PyTorch、RISC-V、SPDX、OpenChain 等。Linux 基金会致力于采纳最佳实践，满足贡献者、用户以及解决方案提供者的需求，打造可持续的开放合作模式。有关更多信息，请搜索 Linux 基金会官网。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354700</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354700</guid>
      <pubDate>Sat, 10 May 2025 14:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>iOS 26 新增实时翻译：基于端侧并向第三方开放接口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2e75214ed6a7bf091530afec2180ff3869d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开发者朋友们大家好：&lt;/p&gt; 
&lt;p&gt;这里是 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; ，每天和大家一起看新闻、聊八卦。&lt;/p&gt; 
&lt;p&gt;我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 &lt;strong&gt;技术&lt;/strong&gt; 」、「有亮点的 &lt;strong&gt;产品&lt;/strong&gt; 」、「有思考的 &lt;strong&gt;文章&lt;/strong&gt; 」、「有态度的 &lt;strong&gt;观点&lt;/strong&gt; 」、「有看点的 &lt;strong&gt;活动&lt;/strong&gt; 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。&lt;/p&gt; 
&lt;p&gt;本期编辑：@赵怡岭，@鲍勃&lt;/p&gt; 
&lt;h2&gt;01 有话题的技术&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Direct3D-S2：影视级 3D 生成模型，仅需 8 块 GPU 即可训练，效果超越许多闭源商用模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DreamTech 与南大、复旦和牛津联合推出的 Direct3D-S2 开源 3D 生成模型，在 HuggingFace 热榜中表现卓越，仅需 8 块 GPU 即可训练，效果超越许多闭源商用模型，达到了影视级精细度。其核心创新 —— 空间稀疏注意力机制（SSA）显著提升了生成效率和细节表现，解决了传统 3D 建模面临的计算压力和复杂度问题。&lt;/p&gt; 
&lt;p&gt;在 Direct3D-S2 中，DreamTech 团队提出了一项核心创新——空间稀疏注意力机制（Spatial Sparse Attention， SSA）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfaba50ee60f71dfe7e6d2905c689c38efe.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一机制专为解决当前 Diffusion Transformer（DiT）在处理高分辨率 3D 生成时效率低、精细度差的问题而设计，堪称 3D 生成领域的效率引擎。&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2505.17412" target="_blank"&gt;https://arxiv.org/pdf/2505.17412&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FDreamTechAI%2FDirect3D-S2" target="_blank"&gt;https://github.com/DreamTechAI/Direct3D-S2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.neural4d.com%2Fresearch%2Fdirect3d-s2%2F" target="_blank"&gt;https://www.neural4d.com/research/direct3d-s2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fwushuang98%2FDirect3D-S2-v1.0-demo" target="_blank"&gt;https://huggingface.co/spaces/wushuang98/Direct3D-S2-v1.0-demo&lt;/a&gt; （@新智元、@果比 AI）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、Neuralink 和 Grok 合作，脑机芯片为渐冻症患者赋予「发声」能力&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;近日，马斯克在 X 上转发的一则案例显示：Neuralink 和 Grok 正合作使渐冻症患者重新「发声」。&lt;/p&gt; 
&lt;p&gt;通过脑机接口技术，一名渐冻症患者成功实现了用意念输出文字，并借助 AI 完成语句补全和声音克隆，最终以接近本人的声音「说话」。这一突破性进展源于 Neuralink 的脑机芯片植入技术，以及 Grok 强大的自然语言处理能力。&lt;/p&gt; 
&lt;p&gt;具体来说，患者只需通过思考即可移动光标生成文本，Grok 助手则像「读心术」一样自动更正并补全文本，最后通过 AI 克隆出患者原本的声音，让交流更加自然。&lt;/p&gt; 
&lt;p&gt;马斯克转发的帖子原出处 Mario Nawfal 此前介绍，患者 Bradford Smith 因为渐冻症丧失了行动和说话能力，而 Neuralink 使其能够通过思考来生成文本，Grok 则可以实现「读心术」式的自动更正，再通过另一个 AI「克隆」的其真实声音，从而使他「说话」时能够拥有听起来就像本人的声音。&lt;/p&gt; 
&lt;p&gt;今年 5 月，Neuralink 的脑机接口设备 Link 获得了美国 FDA 的「突破性设备」认证，专门用于帮助严重语言障碍患者恢复沟通能力。&lt;/p&gt; 
&lt;p&gt;新闻链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ithome.com%2F0%2F859%2F328.htm" target="_blank"&gt;https://www.ithome.com/0/859/328.htm&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;X 链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FMarioNawfal%2Fstatus%2F1928406038803558837" target="_blank"&gt;https://x.com/MarioNawfal/status/1928406038803558837&lt;/a&gt; （@IT 之家、@新智讯）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、开源框架 Rowboat：快速构建智能助手，支持 MCP、Agent SDK&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由 Y Combinator 支持的开源多智能体开发框架 Rowboat 亮相，支持 MCP 服务和 OpenAI Agent SDK。框架由 Agent、Playground 和 Co pilot 三大模块构成，方便用户快速构建、测试和部署智能助手。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Agent，主要负责处理对话的特定部分，并能依据指令使用工具执行任务。其亮点在于可通过自然语言指令进行配置，能以图的形式在智能体之间进行编排，还可访问工具和 RAG。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Playground，这是一个交互式环境，方便用户在构建助手时以对话方式进行测试。它具备实时测试和调试功能，可在界面内检查工具调用的参数和结果，能与单个智能体或整个助手进行对话。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Copilot，由 AI 驱动的辅助工具，可代用户创建和更新智能体与工具。能感知包括演练场在内的所有组件的上下文，可根据对话和反馈优化智能体，能理解用户以自然语言提出的请求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;用户可创建多智能体，如信用卡助手，实现任务协同。Rowboat 还提供 HTTP API 和 Python SDK，适应多样开发场景。目前，Rowboat 在 Github 已经超过 2000 颗星。&lt;/p&gt; 
&lt;p&gt;开源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frowboatlabs%2Frowboat%3Ftab%3Dreadme-ov-file%25EF%25BC%2588%40AIGC" target="_blank"&gt;https://github.com/rowboatlabs/rowboat?tab=readme-ov-file（@AIGC&lt;/a&gt; 开放社区、@OneThingAI Lab）&lt;/p&gt; 
&lt;h2&gt;02 有亮点的产品&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Apple Intelligence 实时翻译功能：基于端侧、横框多个应用、向第三方开发者开放&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Apple 最新发布的 iOS 26 中，Apple Intelligence 支持实时翻译功能，这个功能横跨电话、信息与 Facetime 三个通讯软件，当你收到外语信息时，系统会自动将其翻译成你的语言；相关功能已集成到信息、电话等 App 中，能够实现即时翻译文本和音频，从而帮助用户跨越语言障碍。&lt;/p&gt; 
&lt;p&gt;同样的，你发出的内容也会被实时翻译成对方的语言，让跨语言交流变得前所未有的顺畅。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a1581d62c50fe6604340d5a10ba25be1442.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;实时翻译功能完全基于端侧，你的对话内容不会由此流通到任何未经允许的地方。&lt;/p&gt; 
&lt;p&gt;由 Apple Intelligence 驱动的实时翻译功能将通过 API 接口，向所有第三方开发者开放，开发者可以将实时翻译功能集成到任何通讯软件中。&lt;/p&gt; 
&lt;p&gt;过去一年，苹果在海外推出了如 Genmoji、图乐园等 AI 功能，帮助用户更自由、有趣地表达内容，而外界最为关心的 AI Siri 将什么时候落地，在今年 WWDC 依旧并没有给出具体的日期。&lt;/p&gt; 
&lt;p&gt;语言适配方面倒是有所进展，Apple 智能将在今年年底前支持这些语言：丹麦语、荷兰语、挪威语、葡萄牙语、瑞典语、土耳其语、繁体中文和越南语。&lt;/p&gt; 
&lt;p&gt;苹果宣布推出 Foundation Models Framework。这是一项全新的 API，允许第三方开发者调用 Apple Intelligence 核心的大型语言模型（LLM），并将其集成到自家应用中。&lt;/p&gt; 
&lt;p&gt;开发者无需构建自己的 AI 模型，也不必依赖云端服务，就能在自己的 App 中调用一个功能强大、响应快速、且重视隐私保护的智能助手。更重要的是，不怕断网，离线也能运行。 （@APPSO、@IT 之家）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、Talking Tours：Google 发布的 AI 导游，支持实时对话互动&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-32abd937a92b609d665aa4542e702d431b0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;打开 Talking Tours 页面，你会看到一张互动地图，涵盖全球多个文化地标和自然景观，分为多个主题：文化机构（博物馆、图书馆、剧院）、地标建筑、古迹和自然景观（森林、洞穴、沙漠、园林、海洋）。&lt;/p&gt; 
&lt;p&gt;点击地图上的座标，即可进入对应地点的沉浸式街景视图。AI 导游会通过语音讲解该地点的背景信息，比如某所博物馆的建筑风格、历史典故，甚至细节到展厅里壁纸的设计灵感。&lt;/p&gt; 
&lt;p&gt;切换画面后，点击「take a snapshot」按钮，AI 会基于新画面重新生成一段讲解，换个角度看，同一地点也可能讲出不同的故事。还可以点击右下角的「🙋」图标，对 AI 导游发起提问。&lt;/p&gt; 
&lt;p&gt;体验链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartsandculture.google.com%2Fexperiment%2F8AGlfzgsYmBeIA" target="_blank"&gt;https://artsandculture.google.com/experiment/8AGlfzgsYmBeIA&lt;/a&gt; （@Founder Park）&lt;/p&gt; 
&lt;h2&gt;03 有态度的观点&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、任正非：AI 也许是人类社会最后一次技术革命&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;《人民日报》6 月 10 日头版刊文消息，近日，在深圳华为总部，围绕大众关心的一些热点话题，人民日报记者一行与华为 CEO 任正非面对面交流。 交流中，任正非透露，在「面对外部封锁打压，遇到很多困难」时，自己坚信「不去想困难，干就完了，一步一步往前走」。&lt;/p&gt; 
&lt;p&gt;面对「人工智能（AI）的未来前景怎么看」时，任正非表示，「人工智能也许是人类社会最后一次技术革命」。其解释称：&lt;/p&gt; 
&lt;p&gt;人工智能发展要经历数十年、数百年。不要担心，中国也有很多优势。任正非还强调，人工智能在技术上的要害，是要有充足的电力、发达的信息网络。发展人工智能要有电力保障，中国的发电、电网传输都是非常好的，通信网络是世界最发达的，东数西算的理想是可能实现的。&lt;/p&gt; 
&lt;p&gt;另外，任正非还提到了其他优势：芯片问题其实没必要担心，用叠加和集群等方法，计算结果上与最先进水平是相当的。软件方面，将来是千百种开源软件满足整个社会需要。(@ APPSO)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、OpenAI 前首席科学家：AI 会完成我们能做的一切&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;日前，OpenAI 前首席科学家 Ilya Sutskever 返回母校多伦多大学，在接受荣誉博士学位时发表了个人演讲。&lt;/p&gt; 
&lt;p&gt;Ilya 开篇就分享了个人心态：接受现实，尽量不去后悔过去，努力改善现状。接着，他表示，大家都处在一个真正不同寻常的时代——因为 AI 的出现。&lt;/p&gt; 
&lt;p&gt;Ilya 坦言，如今的 AI 已经在很大程度上改变了「学生」的含义，并且远不止于此。Ilya 表示，AI 能做的事情已经远超想象，而我们眼下的挑战是「AI 会如何影响我们的工作和职业」，同时也有更深层次的挑战——未来 AI 的发展将是前所未有、极其剧烈的。&lt;/p&gt; 
&lt;p&gt;他还强调：「任何我能学到的东西，任何你们中的任何一个人能够学到的东西，AI 都能学会。那么，为什么我这么确信呢？我们怎么知道 AI 将来能做这些事情呢？原因是，我们每个人的大脑都是一个生物计算机。我们有大脑，就是因为它是一个生物计算机。那么，既然人类的生物计算机能做这些事情，为什么数字计算机、也就是数字大脑不能做同样的事呢？这就是为什么我认为 AI 最终能做到所有我们能做到的事情的原因。」&lt;/p&gt; 
&lt;p&gt;对于「当 AI 能做我们所有的工作时，会发生什么？」这一问题，Ilya 认为十分需要重视。他提醒：「你可能不关心 AI，但 AI 会主动来关心你」。&lt;/p&gt; 
&lt;p&gt;因此，Ilya 建议大家，在 AI 时代下，只要你开始使用 AI，去了解当下最先进的 AI 能做些什么，你就会逐渐建立起一种直觉。「我认为，通过使用 AI 并观察当今最先进的 AI 能做什么，你会形成一种直觉。随着 AI 在一年、两年、三年内不断改进，这种直觉会变得更强烈」。慢慢的，我们能对 AI 的发展有一定的概念，自然也不会再对 AI 产生恐惧，并能够掌控 AI，激发新技术给我们带来的力量。&lt;/p&gt; 
&lt;p&gt;最后，Ilya 强调：&lt;/p&gt; 
&lt;p&gt;AI 带来的挑战是人类历史上最大的挑战。但如果我们应对得当，所获得的回报也将是人类历史上最大的回报。&lt;/p&gt; 
&lt;p&gt;演讲全程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FzuZ2zaotrJs%3Ffeature%3Dshared" target="_blank"&gt;https://youtu.be/zuZ2zaotrJs?feature=shared&lt;/a&gt; （@APPSO、@机器之心）&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fa92df803a9e43d2a75ae183d839112a4a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多 Voice Agent 学习笔记：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGe3xHvHjsvm3cNEMxiLIEQ" target="_blank"&gt;实时多模态如何重塑未来交互？我们邀请 Gemini 解锁了 39 个实时互动新可能丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSqXLZvq_zwWDcOVKbAb7HQ" target="_blank"&gt;级联 vs 端到端、全双工、轮次检测、方言语种、商业模式…语音 AI 开发者都在关心什么？丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7QPgzp8kDR_9iHUa4oFeiA" target="_blank"&gt;a16z 最新报告：AI 数字人应用层即将爆发，或将孕育数十亿美金市场丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUM1qs2IT1S6kJ4sZf_k3uA" target="_blank"&gt;a16z 合伙人：语音交互将成为 AI 应用公司最强大的突破口之一，巨头们在 B2C 市场已落后太多丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWI0gE4x-TZG0gdgSV_bVSA" target="_blank"&gt;ElevenLabs 33 亿美元估值的秘密：技术驱动+用户导向的「小熊软糖」团队丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVsgDF8F1hxy3-e5-ntGbw" target="_blank"&gt;端侧 AI 时代，每台家居设备都可以是一个 AI Agent 丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4K5wdUEDxrs1afHZSAIuqg" target="_blank"&gt;世界最炙手可热的语音 AI 公司，举办了一场全球黑客松，冠军作品你可能已经看过&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJCYzc1Ig-HFFAN3sTQDYbw" target="_blank"&gt;多模态 AI 怎么玩？这里有 18 个脑洞&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrN9poD_X6SDxRLMsudg_xg" target="_blank"&gt;AI 重塑宗教体验，语音 Agent 能否成为突破点？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeFS1mnAbUpAJdiLSSGWpSA" target="_blank"&gt;对话 TalktoApps 创始人：Voice AI 提高了我五倍的生产力，语音输入是人机交互的未来&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;写在最后：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们欢迎更多的小伙伴参与 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。&lt;/p&gt; 
&lt;p&gt;对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8e54bdf0d246189e94f7cf3b2e418da213.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;素材来源官方媒体/网络新闻&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354682</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354682</guid>
      <pubDate>Sat, 10 May 2025 11:42:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
  </channel>
</rss>
