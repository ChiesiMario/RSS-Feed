<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 03 Mar 2025 16:40:33 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>IBM 完成 64 亿美元收购 HashiCorp 交易</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;IBM 公司近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsroom.ibm.com%2F2025-02-27-ibm-completes-acquisition-of-hashicorp%2C-creates-comprehensive%2C-end-to-end-hybrid-cloud-platform&quot; target=&quot;_blank&quot;&gt;完成&lt;/a&gt;&lt;/u&gt;了对基础设施自动化供应商 HashiCorp 公司 64 亿美元的收购。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e58fe5ac5bcf71a8ae80e6570c9c668996d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;两家公司最初预计将在 2024 年底前完成交易。延迟可能与反垄断监管机构对该交易的审查有关。去年，美国联邦贸易委员会 (FTC) 和英国竞争和市场管理局 (CMA) 都对这项收购进行了审查。&lt;/p&gt; 
&lt;p&gt;CMA 在周二批准了 IBM 收购 HashiCorp。据 TechCrunch 报道，FTC 在 CMA 之前已经悄然批准了这项交易。&lt;/p&gt; 
&lt;p&gt;HashiCorp 提供免费的 IT 基础设施管理软件工具。企业使用这些工具来配置云实例、保护网络连接并执行相关任务。该软件套件被数十万家组织使用，其中超过 5,000 家付费使用具有更多功能的商业版本。&lt;/p&gt; 
&lt;p&gt;在一篇博客文章中，HashiCorp 首席技术官 Armon Dadgar 表示，公司看到了将其工具与 IBM 产品组合更紧密集成的机会。&lt;/p&gt; 
&lt;p&gt;这项工作将特别强调 Terraform 和 Ansible。这两个分别由 HashiCorp 和 IBM 开发的自动化工具可以减少配置 IT 基础设施所需的工作量。Terraform 特别适合配置云资源和其他硬件资源，而 Ansible 可用于设置在这些资源之上运行的软件。&lt;/p&gt; 
&lt;p&gt;&quot;将用于资源配置的 Terraform 与用于配置管理的 Ansible 集成，将实现端到端的基础设施自动化即代码方案，&quot;Dadgar 写道。&lt;/p&gt; 
&lt;p&gt;产品集成工作的另一个重点是 HashiCorp 的 Vault 工具。它提供了一个加密环境来存储机密信息，如在公司网络安全工作中发挥重要作用的密码等数据。该软件可以定期轮换或替换机密信息，以降低网络攻击的风险。&lt;/p&gt; 
&lt;p&gt;HashiCorp 看到了将 Vault 与 Ansible 以及 IBM 的另外两款产品：OpenShift 和 Guardium 进行集成的机会。前者是用于支持容器应用程序的 Kubernetes 发行版，后者是帮助公司保护其业务数据的工具。&lt;/p&gt; 
&lt;p&gt;HashiCorp 还计划将 Terraform 与 Cloudability 集成。后者是 IBM 通过早期收购获得的工具，可帮助公司追踪其云支出。Terraform 持有的关于云环境的技术数据可以帮助用户更轻松地识别节省成本的机会。&lt;/p&gt; 
&lt;p&gt;IBM 和 HashiCorp 已经开始产品集成过程。周三，HashiCorp 认证其 HCP Terraform Operator for Kubernetes 可在 OpenShift 上运行。HCP Terraform Operator 允许开发人员通过 Kubernetes 的应用程序编程接口管理 Terraform。&lt;/p&gt; 
&lt;p&gt;&quot;通过联手，我们获得了他们的全球规模和增加的研发资源，&quot;Dadgar 在今天的博客文章中写道。&quot;这使我们能够接触更多客户，并继续投资解决基础设施和安全挑战。&quot;&lt;/p&gt; 
&lt;p&gt;当 IBM 去年 4 月首次宣布收购 HashiCorp 的计划时，表示该收购将在交易完成后一年内对其调整后的息税折旧及摊销前利润产生积极影响。该公司预计从第二年开始，这笔交易将提升其自由现金流。HashiCorp 上季度实现调整后营业收入 1,100 万美元，收入为 1.734 亿美元。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/327615/ibms-acquire-hashicorp-takeover-faces-uk-antitrust-scrutiny&quot; target=&quot;news&quot;&gt;IBM 收购 HashiCorp 交易面临英国反垄断审查&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/314704/mitchellh-zig-donation-300k&quot; target=&quot;news&quot;&gt;HashiCorp 创始人向 Zig 软件基金会捐赠 30 万美元&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289379/ibm-acquire-hashicorp-6-4-billion&quot; target=&quot;news&quot;&gt;IBM 以 64 亿美元收购 HashiCorp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289203/ibm-nearing-buyout-deal-hashicorp&quot; target=&quot;news&quot;&gt;IBM 正在洽谈收购云基础设施公司 HashiCorp&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336678/ibm-completes-acquisition-of-hashicorp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336678/ibm-completes-acquisition-of-hashicorp</guid>
            <pubDate>Thu, 27 Feb 2025 10:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌联合创始人督促员工一周工作 60 小时</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌联合创始人 Sergey Brin 在一份内部备忘录中&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2Fcommand-line-newsletter%2F622045%2Fgoogle-ai-nanny-products&quot; target=&quot;_blank&quot;&gt;督促&lt;/a&gt;从事 Gemini AI 产品相关工作的员工至少每个工作日都去办公室工作，&lt;strong&gt;并建议每周工作 60 小时，称这是生产力的最佳时间点&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Brin 警告，AI 的竞争在加速，而 AGI 的终赛即将到来。AGI 指 AI 将达到或超越人类智能。Brin 在备忘录中说，谷歌拥有赢得这场竞赛的所有要素，但必须加大努力。这份备忘录没有改变谷歌要求员工每周至少去办公室工作三天的政策。Brin 还在备忘录中批评没有付出更多努力的员工，称他们挫伤了所有人的士气。&lt;/p&gt; 
&lt;p&gt;Brin 要求 AI 团队优先采用「简单的解决方案」，并提高工作效率（&lt;strong&gt;「不能为了运行一小段 Python 代码等待 20 分钟」&lt;/strong&gt;）。&lt;/p&gt; 
&lt;p&gt;但最引人关注的是他对谷歌 AI 产品的批评：目前产品过度依赖过滤和限制措施。Brin 认为，谷歌应该「信任用户」，而不是继续推出「保姆式」产品。&lt;/p&gt; 
&lt;p&gt;Brin 内部备忘录大意如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Gemini 计划和 GDM 已经走过了两年。这段时间里，我们取得了显著进展，也完成了许多值得骄傲的工作。然而，竞争日益激烈，AGI 竞赛已进入关键阶段。我相信我们具备胜出的所有条件，但必须加快步伐。&lt;/p&gt; 
 &lt;p&gt;代码决定一切 ——AGI 的突破点在于&lt;strong&gt;AI 的自我优化&lt;/strong&gt;，尽管初期可能仍需大量人工干预，因此代码性能至关重要。此外，这必须建立在我们的 1p 代码基础上。我们要借助自身 AI，成为全球最高效的开发者和 AI 科学家。&lt;/p&gt; 
 &lt;p&gt;高效工作 —— 根据我的经验，&lt;strong&gt;每周 60 小时的工作量最有助于保持效率&lt;/strong&gt;。有人工作时间更长，但可能会&lt;strong&gt;精疲力竭、影响创造力&lt;/strong&gt;；也有人低于 60 小时，甚至有些人仅满足最低要求。这不仅&lt;strong&gt;效率低下，&lt;strong&gt;还会&lt;/strong&gt;影响团队士气&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;线下协作 —— 面对面沟通远比远程会议等方式高效，因此必须与团队成员在同一地点办公。我们应尽量减少跨国、跨城市、跨大楼的汇报关系，建议每个工作日都到办公室。&lt;/p&gt; 
 &lt;p&gt;组织优化 —— 团队需要明确职责分工，保持高效协作，并由统一的管理和技术领导进行协调。&lt;/p&gt; 
 &lt;p&gt;简化方案 —— 尽可能选择简单高效的解决方案。例如，如果提示词（prompting）能满足需求，就直接使用，而不是额外训练单独的模型。避免不必要的复杂技术（如 LoRA）。理想状态是采用一个通用模型，只需调整提示即可满足不同用途。&lt;/p&gt; 
 &lt;p&gt;追求卓越 —— 无论是评估指标、数据来源、仪表盘，还是内部 UI 消息，都要确保运行稳定、质量过硬。&lt;/p&gt; 
 &lt;p&gt;追求速度 —— 产品、模型和内部工具都要尽可能提高运行速度。&lt;strong&gt;不能为了运行一小段 Python 代码等待 20 分钟&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;快速迭代 —— 我们需要快速验证大量想法，最好的方法是小规模试验，逐步扩展并观察是否能带来更大优势。过度依赖大规模开发，容易陷入微调、过拟合评估指标等问题。我们要追求真正可扩展的成果。&lt;/p&gt; 
 &lt;p&gt;避免过度限制 —— 不能继续开发「保姆式」产品。当前产品已经充斥了过多的限制和筛选，我们需要打造&lt;strong&gt;真正有能力的产品&lt;/strong&gt;，并相信用户的判断。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336673/google-ai-nanny-products</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336673/google-ai-nanny-products</guid>
            <pubDate>Thu, 27 Feb 2025 10:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>软件供应链安全的研究方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h3&gt;&lt;strong&gt;01 摘要&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;可复用的软件库、框架和组件（如开源生态系统和第三方供应商提供的）加速了数字创新。但近年来，攻击者利用这些软件制品发起软件供应链攻击的数量呈指数增长，比如&amp;nbsp;**SolarWinds、log4j 和 xz utils&amp;nbsp;**等知名攻击事件。&lt;/p&gt; 
&lt;p&gt;软件供应链攻击主要有三个途径：利用开源和第三方依赖组件漏洞注入恶意内容；在构建和部署过程中渗透构建基础架构；通过社会工程学等手段针对软件开发人员。若软件行业减少对开源和第三方组件的使用来降低风险，会减缓数字创新，损害软件供应链的信任。本文从研究者与从业者交流了解到的实际挑战，以及大量研究成果出发，概述了当前保障软件供应链安全的研究工作，并提出未来研究方向以应对软件供应链攻击。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;02 研究背景&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;软件供应链的重要性与安全隐患&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;现代社会高度依赖数字创新，可复用软件制品加速了这一进程，但软件供应链却成为攻击目标。软件开发行业未料到其会被蓄意攻击，近年攻击事件频发，如 SolarWinds 等，造成了巨大影响。美国和欧洲也出台相关法规，强调提升开源制品&lt;strong&gt;透明度和完整性&lt;/strong&gt;的紧迫性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;软件供应链的攻击向量&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;存在三个主要攻击途径：一是&lt;strong&gt;利用开源和第三方代码&lt;/strong&gt;依赖中的漏洞或恶意注入，攻击者可借此执行任意代码、窃取数据；二是&lt;strong&gt;渗透构建基础架构&lt;/strong&gt;，在软件构建和部署过程中注入恶意代码；三是通过&lt;strong&gt;社会工程学手段&lt;/strong&gt;针对软件开发人员，利用人的因素发起攻击。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;安全问题的影响&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;软件供应链信任度降低，若企业减少对开源和第三方制品的使用，会阻碍数字创新。本文旨在阐述研究方法，概述针对三大攻击向量的研究挑战和成果，提出未来研究方向以增强软件供应链安全，后续内容依次介绍研究方法、各攻击向量的挑战与研究、其他方向的研究成果，总结对软件供应链安全研究方向的看法。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;03 行业和政府对挑战的投入&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;S3C2 通过举办年度安全软件供应链峰会、社区日活动，以及安排研究人员和学生到工业与政府机构演讲交流，收集软件供应链安全的实践问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;挑战反馈&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;行业和政府从业者反馈，软件供应链安全是亟待解决的实际问题。在依赖选择上，缺乏有效指标辅助决策，政府从业者还关注国外开发的软件依赖风险。依赖更新时，漏洞数量多且工具无法提供足够信息，更新可能带来兼容性问题。恶意提交检测困难，缺乏可靠方法。在构建基础架构方面，企业寻求安全构建和部署指导，认为可重复性构建不实用。此外，软件供应链安全框架的广泛实施面临挑战，需行业共同努力，且自动化漏洞修复和构建安全文化至关重要。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;04 攻击向量：代码依赖&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;开发者在代码依赖方面面临的实际挑战&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;依赖项选择困难&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开发者在挑选开源和第三方代码依赖项时，难以在安全性和功能性之间找到平衡。他们缺乏全面且实用的指标，来帮助判断依赖项是否存在安全漏洞或潜在风险，也难以确定依赖项是否符合项目的功能需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;依赖更新困难&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;保持依赖项更新对修复安全漏洞至关重要，开发者更新时会遇到麻烦。他们担心新版本依赖会引入与现有代码的兼容性问题，进而破坏软件的正常功能。而且，在更新过程中，开发者难以预估可能出现的新安全漏洞，这使得依赖更新的决策变得异常复杂。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;恶意提交难以及时发现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源生态系统中，代码依赖项的维护者提交恶意代码的情况时有发生，开发者却很难快速察觉。因为他们缺乏有效的监测机制和工具，无法及时识别这些恶意提交，从而使软件面临安全风险。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;针对代码依赖安全的现有研究成果&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;依赖选择工具与指标&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为辅助开发者进行依赖项选择，研究人员开发了如 OpenSSF Scorecard 等工具，通过评估开源项目的安全性指标，为开发者提供参考。但目前依赖选择指标体系仍不完善，无法全面覆盖所有与安全和功能相关的因素，难以满足开发者多样化的需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;依赖更新策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;研究提出了基于风险的依赖更新策略，旨在综合考虑依赖项的安全风险、更新的影响范围等因素，制定更合理的更新计划。然而，这些策略在实际应用中缺乏足够的自动化支持，需要开发者手动进行大量的分析和决策，增加了操作成本和复杂性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;恶意提交检测方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在检测开源依赖项中的恶意提交方面，研究采用机器学习技术，对代码的历史提交记录、开发者行为模式等数据进行分析建模。但该方法面临训练数据库信息不完整的问题，难以涵盖所有类型的恶意行为模式，导致检测的准确性和全面性受到限制。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;代码依赖安全研究面临的挑战&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;依赖选择指标与数据问题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当前依赖选择指标不够全面和精准，无法充分反映依赖项的真实安全状况。同时，用于评估依赖项的数据库存在信息缺失、更新不及时等问题，难以提供完整可靠的参考依据。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;理论与实践脱节&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;虽然在依赖管理的理论研究上取得了一定进展，但在将这些理论转化为实际可用的工具和方法时，存在较大差距。开发出的工具往往难以集成到现有的软件开发流程中，导致开发者在实际应用中面临诸多困难。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨平台研究不足&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着软件开发环境的日益复杂，跨平台的代码依赖越来越常见。然而，目前针对跨平台依赖安全的研究相对较少，缺乏有效的方法和工具来保障不同平台间依赖项的安全性和兼容性 。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;05 攻击向量：构建基础架构&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;从业者对构建基础架构安全的认知&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全担忧倾向&lt;/strong&gt;：相较于软件部署过程，从业者更担忧构建过程中的安全问题，认为构建环境存在更多潜在风险，容易被攻击者利用来篡改软件。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可重复性构建的看法&lt;/strong&gt;：尽管可重复性构建有助于确保软件在不同环境下的一致性，但从业者对其实际效用存在疑虑。他们觉得在实际操作中，实现可重复性构建面临诸多困难，并且其对保障软件安全的直接价值不明确。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;构建基础架构安全的现有研究成果&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;透明度研究进展&lt;/strong&gt;：研究致力于提高构建过程的透明度，通过记录和审计构建过程中的每一个步骤和操作，使得开发者和安全人员能够追溯和验证软件的构建历史，及时发现潜在的篡改行为。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完整性保障措施&lt;/strong&gt;：为确保构建输出的完整性，研究引入了如软件物料清单（SBOM）、代码签名等技术和方法，以验证软件在构建和分发过程中未被篡改。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;信任模型探索&lt;/strong&gt;：构建了信任模型来评估构建基础架构中各个组件和参与者的可信度，帮助识别潜在的不可信来源，从而降低安全风险。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD 漏洞检测&lt;/strong&gt;：针对持续集成 / 持续交付（CI/CD）流程中的漏洞，开发了相应的检测工具和技术，能够及时发现并修复流程中可能存在的安全隐患。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;构建基础架构安全研究面临的未来挑战&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;透明度实现难题&lt;/strong&gt;：虽然提高构建透明度是目标，但在实际应用中，如何在不增加过多成本和复杂性的前提下，实现全面、实时的构建过程透明化，仍是亟待解决的问题。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;代码签名推广困境&lt;/strong&gt;：尽管代码签名技术有助于保障软件完整性，但目前在行业内的广泛应用和接受度仍不理想，需要解决技术标准统一、证书管理等一系列问题，以推动其普及。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可重复性构建普及问题&lt;/strong&gt;：要使可重复性构建在实际项目中得到广泛应用，需要克服技术、流程和人员等多方面的障碍，建立更加完善的支持体系和最佳实践指南。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD 漏洞评估挑战&lt;/strong&gt;：随着 CI/CD 技术的不断发展和应用场景的日益复杂，如何持续有效地评估和应对其中的安全漏洞，需要进一步研究和探索新的方法和工具 。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;06&amp;nbsp;&lt;strong&gt;攻击向量：人为因素&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;实际挑战&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;软件供应链安全依赖行业集体行动与人员参与，相关框架需广泛采用和信息共享才有效。企业虽有安全措施，但面临文化适应问题，如 SolarWinds 事件后需调整安全文化。「guardrails, not gates」 方式平衡开发速度与安全，但仍有风险。此外，自动化漏洞修复可减轻开发者负担，构建安全文化需全员参与。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;研究成果&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;支持开发者&lt;/strong&gt;：实施软件供应链安全复杂，开发者需应对第三方组件信任、代码漏洞等问题。研究发现多数公司有外部代码管理政策，但开发者需更多资源审计和保障组件安全。同时，研究建议开发者主动预见工具的负面影响。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开源生态系统&lt;/strong&gt;：开源软件在软件供应链占比大，但面临开发分散、资源有限等问题。研究表明开源项目安全措施差异大，小项目资源不足，且存在秘密管理难题，如 API 密钥易泄露。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;学术界&lt;/strong&gt;：软件供应链安全研究人员面临伦理困境，如披露漏洞可能帮助或伤害用户，研究数据涉及隐私保护和使用许可问题。相关工作影响了计算机安全领域的伦理准则，促使研究人员讨论决策的伦理维度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;未来挑战&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;软件供应链安全方法的广泛采用至关重要，需确保其用户友好以推动行业接受。未来，高级网络钓鱼攻击将构成更大威胁，需通过改进培训、限制环境或利用 LLMs 防御等措施应对。此外，随着技术防御加强，内部威胁可能持续存在，需要更先进的行为监测和自适应安全协议。&lt;/p&gt; 
&lt;h3&gt;07&amp;nbsp;&lt;strong&gt;软件供应链安全的其他研究方向&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;软件物料清单（SBOM）&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;概述与作用：SBOM 用于识别和跟踪软件系统中的第三方组件，能提高透明度、助力企业掌握软件风险，美国政府要求关键软件提供 SBOM。&lt;/li&gt; 
 &lt;li&gt;面临的挑战：从业者虽认可其安全价值，但在实施中面临诸多问题。生成方面，工具生成的 SBOM 质量参差不齐，缺乏通用性，标准不统一且存在隐私问题。应用环节，当前流程混乱易错，SBOM 质量低且数据缺失，动态组件缺失和安全流程集成不足限制其应用。共享时，企业担心隐私泄露，且格式转换操作复杂。VEX 虽能提升 SBOM 安全性，但手动创建限制其价值，自动化生产 VEX 需解决信息识别等问题。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;从业者挑战：自我认证和出处&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;美国行政命令要求政府承包商 CEO 对软件符合开发实践、开源软件完整性和出处进行自我认证。工业参与者担心要求不明确，部分企业因负担问题将产品开源以豁免认证，但多数人认为相关认证对安全更具基础性作用。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;LLM 与软件供应链&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM 在软件供应链中的应用与风险：LLMs 在软件开发各阶段广泛应用，成为软件供应链一部分，但带来信任问题，如幻觉现象和不安全编码影响。在代码生成方面，能提高效率但可能生成不安全代码，且其供应链存在组件漏洞风险。&lt;/li&gt; 
 &lt;li&gt;LLM 在漏洞检测中的表现与问题：LLMs 在漏洞检测上比部分传统方法更有效，但存在误报、幻觉等问题。研究通过改进方法和框架提升其检测能力，但仍需克服性能和可靠性挑战。&lt;/li&gt; 
 &lt;li&gt;LLM 作为攻击向量的威胁：LLMs 可被用作攻击向量，如通过提示注入和第三方 API 集成引入新漏洞，研究展示了其被攻击的方式及潜在风险。&lt;/li&gt; 
 &lt;li&gt;LLM 性能与可扩展性研究方向：未来研究需全面提升 LLM 性能，降低成本，解决处理大文件时的局限性，提高效率和可扩展性，减少模型崩溃和幻觉现象。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;从业者挑战：供应链标准、指南和框架&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;众多软件安全标准、指南和框架涌现，如 SSDF、SLSA 等，旨在降低供应链风险。但从业者在众多标准中难以抉择，Proactive Software Supply Chain Risk Management（PSSCRM）试图整合多个框架来提供统一指导。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;软件供应链安全度量&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;美国将软件安全度量列为研究重点，但软件系统的特性使有效度量困难重重。提供支持需进行指标策划、数据发布和定期审查，以帮助开发者在复杂情况下做出决策，研究正朝着更实用的方向努力，如提供单个依赖及其生态系统的实时数据和指标。&lt;/p&gt; 
&lt;h3&gt;08&amp;nbsp;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;研究总结&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;软件供应链安全至关重要，近年来受 SolarWinds、log4j 等事件影响备受关注。行业和学术界针对代码依赖、构建基础架构、人员这三个主要攻击向量展开了大量研究。例如，行业中采用 SCA 工具、SBOMs 和 OpenSSF Scorecard 应对代码依赖问题，利用 SLSA、in - toto 和 TUF 保障构建过程安全；学术界则开发了新分析工具，对现有工具和生态系统进行实证研究，并与从业者沟通以了解实际挑战。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;现存挑战&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;尽管取得了一定进展，但软件供应链安全仍面临诸多难题。在代码依赖方面，管理漏洞困难，开发者难以选择安全可靠的依赖项；构建基础架构方面，遗留环境难以改变，缺乏有效的分析工具，构建过程的可重复性难以实现；人员因素方面，需持续关注人为因素带来的风险；同时，LLMs 在软件供应链中的应用也带来了新的安全风险。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;未来展望&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;未来需要持续深入研究软件供应链安全，具体包括改进依赖管理，加强构建环境安全，关注人员因素对软件供应链安全的影响，以及应对 LLMs 带来的新风险等。还计划开发 「软件供应链安全仪表板」 并发布年度报告，以满足从业者的数据需求并进行定期审查，从而更好地推动软件供应链安全的发展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336669</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336669</guid>
            <pubDate>Thu, 27 Feb 2025 10:20:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>百川智能在深圳以 3000 万元成立科技公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查资料显示，深圳百方智能科技有限公司于近日成立，法定代表人为谢剑；注册资本 3000 万人民币，超过了 98% 的广东省同行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;企业经营范围含计算机系统服务、人工智能应用软件开发、人工智能双创服务平台、人工智能理论与算法软件开发、人工智能基础软件开发、人工智能通用应用系统等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;股东信息显示，该公司由北京百川智能科技有限公司全资持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;239&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9257b9ebf40f2dbbbf72331a47f47e644aa.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336663</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336663</guid>
            <pubDate>Thu, 27 Feb 2025 09:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>verl —— HybridFlow 论文的开源实现</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;verl 是一个灵活、高效且可用于生产的 RL 训练库，适用于大型语言模型 (LLM)。&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;verl 是&lt;strong&gt;&amp;nbsp;&lt;a href=&quot;https://arxiv.org/abs/2409.19256v2&quot;&gt;HybridFlow：一种灵活高效的 RLHF 框架&lt;/a&gt;&amp;nbsp;&lt;/strong&gt;论文的开源实现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;verl 灵活且易于使用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;轻松扩展各种 RL 算法&lt;/strong&gt;：混合编程模型结合了单控制器和多控制器范式的优势，能够灵活地表示和高效执行复杂的训练后数据流。允许用户用几行代码构建 RL 数据流。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;现有 LLM 基础架构与模块化 API 无缝集成&lt;/strong&gt;：解耦计算和数据依赖关系，实现与现有 LLM 框架（如 PyTorch FSDP、Megatron-LM 和 vLLM）无缝集成。此外，用户可以轻松扩展到其他 LLM 训练和推理框架。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;灵活的设备映射&lt;/strong&gt;：支持将模型放置到不同的 GPU 组上，以实现高效的资源利用率和跨不同集群规模的可扩展性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;轻松与流行的 HuggingFace 模型集成&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;verl 速度很快：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;最先进的吞吐量&lt;/strong&gt;：通过无缝集成现有的 SOTA LLM 训练和推理框架，verl 实现了高生成和训练吞吐量。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用 3D-HybridEngine 进行高效的演员模型重新分片&lt;/strong&gt;：消除内存冗余并显著减少训练和生成阶段之间转换期间的通信开销&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FSDP&lt;/strong&gt;和&lt;strong&gt;Megatron-LM&lt;/strong&gt;用于训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vLLM&lt;/strong&gt;和&lt;strong&gt;TGI&lt;/strong&gt;用于推出生成，&lt;strong&gt;SGLang&lt;/strong&gt;支持即将推出。&lt;/li&gt;
&lt;li&gt;huggingface 模型支持&lt;/li&gt;
&lt;li&gt;监督微调&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/ppo_trainer&quot;&gt;使用 PPO&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/grpo_trainer&quot;&gt;GRPO&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/remax_trainer&quot;&gt;ReMax&lt;/a&gt;、&lt;a href=&quot;https://verl.readthedocs.io/en/latest/examples/config.html#algorithm&quot;&gt;Reinforce++&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/rloo_trainer/run_qwen2-7b.sh&quot;&gt;RLOO&lt;/a&gt;等&amp;nbsp;从人类反馈中进行强化学习
&lt;ul&gt;
&lt;li&gt;支持基于模型的奖励和基于函数的奖励（可验证的奖励）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;flash-attention、&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh&quot;&gt;序列打包&lt;/a&gt;、通过 DeepSpeed Ulysses、&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/sft/gsm8k/run_qwen_05_peft.sh&quot;&gt;LoRA&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh&quot;&gt;Liger-kernel 提供&lt;/a&gt;&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh&quot;&gt;长上下文支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;可扩展至 70B 模型和数百个 GPU&lt;/li&gt;
&lt;li&gt;使用 wandb、swanlab 和 mlflow 进行实验跟踪&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/verl</link>
            <guid isPermaLink="false">https://www.oschina.net/p/verl</guid>
            <pubDate>Thu, 27 Feb 2025 08:42:00 GMT</pubDate>
        </item>
        <item>
            <title>RWKV 社区 2 月动态：10 篇新学术论文！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎大家收看《RWKV 社区最新动态》，本期内容收录了 RWKV 社区 2025 年 2 月的最新动态。&lt;/p&gt; 
&lt;p&gt;只需 3 分钟，快速了解 RWKV 社区 2 月都有哪些新鲜事！&lt;/p&gt; 
&lt;h2&gt;2 月动态省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 学术研究动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新论文：Activation Sparsity in Recurrent LLMs（RWKV 能效神经形态计算）&lt;/li&gt; 
   &lt;li&gt;新论文：SNAP（RWKV 混合神经网络架构）&lt;/li&gt; 
   &lt;li&gt;新论文：ARWKV（从 DeepSeek 快速迁移到 RWKV 架构）&lt;/li&gt; 
   &lt;li&gt;新论文：OmniRWKVSR（RWKV 图像超分辨率）&lt;/li&gt; 
   &lt;li&gt;新论文：ET_MGNN（RWKV 脑部疾病诊断）&lt;/li&gt; 
   &lt;li&gt;新论文：RWKV-UI（RWKV 高分辨率用户界面理解）&lt;/li&gt; 
   &lt;li&gt;新论文：RWKV-Among-Us（RWKV 多智能体强化学习）&lt;/li&gt; 
   &lt;li&gt;新论文：LALIC（RWKV 图像压缩）&lt;/li&gt; 
   &lt;li&gt;新论文：RWKV 工业缺陷检测&lt;/li&gt; 
   &lt;li&gt;新论文：Rwkv-vg（RWKV 视觉定位）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新闻动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新模型： RKWV-7-2.9B&lt;/li&gt; 
   &lt;li&gt;新模型： 新模型：Qwerky-72B&lt;/li&gt; 
   &lt;li&gt;推理模型 G1 系列训练中&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区活动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 开发者大会 2025&lt;/li&gt; 
   &lt;li&gt;RWKV 2025 生态内容征集大赛 | 1 月投稿作品及评审结果&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 学术研究动态&lt;/h2&gt; 
&lt;p&gt;RWKV 学术研究包括&lt;strong&gt;基于 RWKV 架构的新论文&lt;/strong&gt;或&lt;strong&gt;RWKV 社区参加的学术研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Activation Sparsity in Recurrent LLMs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Explore Activation Sparsity in Recurrent LLMs for Energy-Efficient Neuromorphic Computing&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.16337&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.16337&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了一种低成本、无需训练的算法，用于稀疏循环大语言模型（R-LLMs）的激活，以实现高效能的神经形态计算。论文以 RWKV 为例展示了该方法的有效性。通过在 RWKV 中添加阈值函数，平均激活稀疏度得以提升。硬件模拟显示出显著的节能和延迟改善，并且该方法还可以扩展到其他模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-236dccf9bebcc12e643b9a73457982c5569.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;SNAP&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Learnable Sparsification of Die-to-Die Communication via Spike-Based Encoding&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08645&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08645&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-15&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了 SNAP，一种结合了脉冲神经网络（SNNs）和人工神经网络（ANNs）的混合神经网络架构。为了评估 SNAP，论文将 RWKV 作为代表性的语言模型架构进行集成。&lt;/p&gt; 
&lt;p&gt;实验表明，SNAP 优于传统的 SNN 和非脉冲模型，实现了高达 5.3 倍的能源效率提升和 15.2 倍的推理延迟降低，凸显了其在大规模人工智能系统中的潜力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5300cb672c916fedd3bf729a745b2df0d5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;ARWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.15570&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.15570&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face 仓库链接: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FRWKV-Red-Team%2FARWKV_7B_R1_16K&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/RWKV-Red-Team/ARWKV_7B_R1_16K&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了 ARWKV：一种基于 RWKV 架构的语言模型，ARWKV 引入 RWKV 的时间混合模块来替代传统 Transformer 中的自注意力机制。该方法旨在提升 RNN 的表达能力和状态跟踪能力，从而超越 Transformer 模型。ARWKV 通过从 Qwen2.5 等 Transformer 模型蒸馏知识到 RNN 中，实现了在有限资源（如单块 A100 GPU 上训练 7B 模型）下的高效训练。&lt;/p&gt; 
&lt;p&gt;ARWKV 的方法包含三个阶段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一阶段：用 RWKV-7 时间混合模块替代自注意力机制，保持了模型的表达能力，同时将架构从 Transformer 转向 RNN。&lt;/li&gt; 
 &lt;li&gt;第二阶段：进行知识蒸馏，将较大的 Transformer 模型（如 Qwen2.5）中的知识转移到基于 RNN 的 ARWKV 模型中。&lt;/li&gt; 
 &lt;li&gt;第三阶段：使用监督微调（SFT）和直接偏好优化（DPO）进一步优化模型，并对用户偏好进行对齐。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该方法融合了 Transformer 和 RNN 架构的优势，展示了 RWKV 在混合架构中的潜力。评估结果显示，ARWKV 在多个基准任务中表现良好。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca53111a4ad9e78a1c31bbfe9fee6e870dc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;OmniRWKVSR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Exploring Linear Attention Alternative for Single Image Super-Resolution&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.00404&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.00404&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 OmniRWKVSR 模型用於单图像超分辨率，结合 RWKV 架构与新型特征提取技术（VRSM 和 VRCM），以解决计算复杂性和重建质量问题。通过利用 RWKV 的线性计算效率及 RNN-Transformer 混合优势，该模型避免了二次注意力计算成本，同时增强多尺度特征捕捉。&lt;/p&gt; 
&lt;p&gt;实验结果表明其性能优于 MambaIR 和 SwinIR，在 4 倍超分辨率任务中 PSNR 提升 0.26%、SSIM 提升 0.16%，且训练速度加快 15%。研究突显了 RWKV 在平衡效率与图像恢复质量（尤其在遥感应用）中的有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eb1030d144498811dc7089ee27fcd0f4ad1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;ET_MGNN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Multi-Modal Dynamic Brain Graph Representation Learning for Brain Disorder Diagnosis Via Temporal Sequence Model&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5114041&quot; target=&quot;_blank&quot;&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5114041&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了用于脑部疾病诊断的 ET_MGNN 模型。该模型整合了多模态脑网络信息，并使用 RWKV 进行动态序列建模。通过融合结构和功能连接性，该模型能够捕捉复杂的脑网络特征。&lt;/p&gt; 
&lt;p&gt;在 ABIDE II 和 ADNI 等数据集上的实验表明，ET_MGNN 优于其他方法，且 RWKV 在性能提升中发挥了关键作用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aff6c004a3bc9826d8d334c84beef900c80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-UI&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：RWKV-UI: UI Understanding with Enhanced Perception and Reasoning&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03971&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.03971&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 RWKV-UI，一种基于 RWKV 架构的视觉语言模型，专为高分辨率用户界面（UI）理解设计。针对现有视觉语言模型在高分辨率 UI 图像处理中的信息丢失和推理能力不足，该模型集成三种视觉编码器（SIGLIP、DINO、SAM），采用分块编码策略处理 4096×4096 图像并保留细节。结合 RWKV 高效的 RNN 结构，模型引入布局检测和思维链（CoT）视觉提示，增强空间推理和多步交互预测能力。&lt;/p&gt; 
&lt;p&gt;实验表明其在 UI 理解任务中表现卓越，在动作定位和元素识别等任务上优于更大规模模型，凸显了 RWKV 在多模态场景中的适应性和高效性。 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c4074f12f1fe4b80835bf9f29a82accd791.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-Among-Us&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.06060&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.06060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出利用多智能体强化学习训练语言模型，使其在无需人类示范的社交推理游戏中实现自然语言沟通。通过结合 「听」（从讨论中推理内鬼身份）和 「说」（奖励能改变他人观点的信息），该方法采用 RWKV 模型 —— 一种基于线性注意力的循环架构，以高效处理长游戏序列并降低计算负担。&lt;/p&gt; 
&lt;p&gt;实验表明，基于 RWKV 的智能体胜率是标准强化学习方法的两倍，并展现出基于证据指控等类人策略。RWKV 的选择解决了扩展性和长上下文处理的挑战，对实时多智能体交互至关重要。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a703109ab6ab803b7e25a59685ccfa7801.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;LALIC 图像压缩方法&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Linear Attention Modeling for Learned Image Compressionc&lt;/li&gt; 
 &lt;li&gt;论文链接：https://arxiv.org/abs/2502.05741&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 LALIC 框架，一种基于 RWKV 的学习型图像压缩方法。通过双向 RWKV（BiWKV）注意力模块和 Omni-Shift 模块，LALIC 以线性复杂度捕捉二维潜在特征的全局依赖与局部上下文。结合 RWKV 空间 - 通道上下文模型（RWKV-SCCTX），该方法进一步利用空间和通道冗余优化熵建模。&lt;/p&gt; 
&lt;p&gt;实验表明，LALIC 在 Kodak、Tecnick 和 CLIC 数据集上的 BD-rate 性能超越 VTM-9.1 达 17.32%，且计算复杂度低于传统 Transformer 方法。该工作验证了 RWKV 在高分辨率图像压缩中兼顾效率与性能的优势。 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b9a74473fe332427353c4384942b0fdb52d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 工业缺陷检测&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Substation equipment non-rigid defect detection via receptance weighted key value-based causality-aware networks&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs11760-025-03852-y&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/article/10.1007/s11760-025-03852-y&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了一种基于 RWKV 架构的因果感知设备缺陷检测框架，以解决变电站设备中的非刚性缺陷检测和长尾分布问题。RWKV 架构具有全局感受野，可增强缺陷特征提取能力。它与框架中的其他模块相结合。&lt;/p&gt; 
&lt;p&gt;实验表明，该框架优于基线方法，验证了其有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5ce4856d0d0280b88440b26b881aa700d17.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Rwkv-vg&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Rwkv-vg: visual grounding with RWKV-driven encoder-decoder framework&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs00530-025-01720-w&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/article/10.1007/s00530-025-01720-w&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-02-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 RWKV-VG，一种完全基于 RWKV 架构的视觉定位框架。不同于传统的 CNN 或 Transformer 方法，RWKV-VG 利用 RWKV 结合 RNN 的顺序建模与 Transformer 注意力的混合设计，高效建模模态内和跨模态交互。该框架包含 RWKV 驱动的视觉 / 语言编码器、跨模态解码器及可学习的 [REG] 令牌用于边界框回归。&lt;/p&gt; 
&lt;p&gt;在 ReferItGame 和 RefCOCO 等基准测试中，其性能超越 TransVG 等 Transformer 方法，精度更高且收敛更快。消融实验验证了 RWKV 模块和 [REG] 令牌位置的关键作用。该工作证实了 RWKV 在视觉 - 语言任务中的竞争力，兼具高效计算与高精度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c6124a9db6e9eccb7d8157ca977f713f8ee.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型动态&lt;/h2&gt; 
&lt;h3&gt;新模型：RKWV-7-2.9B&lt;/h3&gt; 
&lt;p&gt;2025 年 2 月 11 日，RWKV 基金会正式发布 RWKV-7-World-2.9B-V3 模型（以下简称 RWKV-7-2.9B）。&lt;/p&gt; 
&lt;p&gt;RWKV-7-2.9B 模型基于 RWKV World V3 数据集训练，英文和多语言能力均&lt;strong&gt;显著超越&lt;/strong&gt;所有同尺寸模型，包括 Llama 3.2 3B、Qwen2.5 3B 等知名优秀开源模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d16b73a1fdbd217b46c921f5c7643eb0845.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可在 Hugging Face Demo 在线体验 RWKV-7-2.9B 模型：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;新模型：Qwerky-72B&lt;/h3&gt; 
&lt;p&gt;从 Qwen 2.5 迁移到 RWKV-7 的 Qwerky-72B 现已由海外 RWKV 社区开源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Ffeatherless-ai%2FQwerky-72B-Preview&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/featherless-ai/Qwerky-72B-Preview&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Qwerky-72B 基于海外 RWKV 社区提出的新颖模型迁移方法，可将使用 softmax attention （如 Qwen 和 LLaMA）的大模型用极低的成本（例如在单台 H800 训练几天）快速微调为 RWKV 模型，而无需从头开始预训练。&lt;/p&gt; 
&lt;h3&gt;推理模型 G1 系列训练中&lt;/h3&gt; 
&lt;p&gt;我们正在基于 World v3.5 数据集继续训练 RWKV-7 &quot;Goose&quot; 系列模型（0.1B/0.4B/1.6B/2.9B），并命名为 &lt;strong&gt;RWKV7-G1&lt;/strong&gt; （&quot;GooseOne&quot;）系列推理模型。据测试，最小的 G1 0.1B 就已能实现推理过程。&lt;/p&gt; 
&lt;p&gt;G1 系列模型的发布计划：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;发布计划&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 0.1B&lt;/td&gt; 
   &lt;td&gt;3 月 8 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 0.4B&lt;/td&gt; 
   &lt;td&gt;3 月下旬&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 1.6B&lt;/td&gt; 
   &lt;td&gt;4 月&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 2.9B&lt;/td&gt; 
   &lt;td&gt;5 月&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;RWKV 社区活动&lt;/h2&gt; 
&lt;p&gt;此版块包含&lt;strong&gt;RWKV 官方动态&lt;/strong&gt;，以及&lt;strong&gt;RWKV 社区举办或参加的各类活动&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;RWKV 开发者大会 2025 圆满举办&lt;/h3&gt; 
&lt;p&gt;2025 年 2 月 22 日，RWKV 在上海漕河泾举办了主题为《RWKV-7 与未来趋势》的开发者大会。&lt;/p&gt; 
&lt;p&gt;来自全国各地的开发者、行业专家和技术创新者齐聚一堂——从知名高校实验室到前沿创业团队，现场涌动的创新能量印证了 RWKV-7 的优秀性能和深远意义。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0009b032f793e66e731fcfb92175fcbbf19.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有关 RWKV 2025 开发者大会的更多信息，可以查看此文章：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fr7eUhh7BJEDLFq_Iy4XWgA&quot; target=&quot;_blank&quot;&gt;RWKV 开发者大会 2025：全球数万开发者探讨 RWKV-7 超越 Transformer&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 2025 生态内容征集大赛 | 1 月投稿作品及评审结果&lt;/h3&gt; 
&lt;p&gt;2025 年 1 月，活动共收到 RWKV 生态作品投稿 11 份，包括 3 篇论文、7 款应用和 1 篇教程 / 动画。&lt;/p&gt; 
&lt;p&gt;评审后，共选出&lt;strong&gt;金奖 1 项、银奖 4 项、铁奖 2 项&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;更多信息可参考：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqqGF05Sot1seCCRg1N9Bhg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生态内容征集大赛 | 1 月投稿作品及评审结果&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336650</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336650</guid>
            <pubDate>Thu, 27 Feb 2025 08:26:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>北京人工智能公共算力平台扩容，智算规模突破 10000P</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「北京发布」公众号发文称，北京人工智能公共算力平台近日再次实现扩容，智算规模突破 10000P，成为北京最大、国内领先的超大规模高性能单体智算集群，将有力支撑各类创新主体万亿参数级通用基础大模型一体化训练和推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;430&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-73fb2db20ce7d8ffa92917b1d678f17f7fe.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336647</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336647</guid>
            <pubDate>Thu, 27 Feb 2025 08:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 公布利润率——引发两家国产 AI Infra 公司创始人隔空互呛</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 1 日，在「开源五连发」后，DeepSeek 又来了一个「One More Thing」为开源周收官——首次&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27181462601&quot; target=&quot;_blank&quot;&gt;披露&lt;/a&gt;&lt;/u&gt;了其模型推理系统 DeepSeek-V3 / R1 的技术细节及成本利润率。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/143406_aFcS_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根据 DeepSeek 公开的信息计算，&lt;strong&gt;它理论上一天的总收入为 562027 美元，成本利润率高达 545%&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此次 DeepSeek 盈利数据公布后瞬间成为行业焦点，引发广泛讨论，尤其是引发了两家国产 AI Infra 公司创始人——尤洋与袁进辉的争论。&lt;/p&gt; 
&lt;p&gt;事件的两个主角，一方是尤洋及其创办的潞晨科技，另一方是袁进辉及其创立的硅基流动。&lt;/p&gt; 
&lt;p&gt;先是 DeepSeek 的这篇技术分享在知乎发布后，不少用户开始@尤洋，让他点评。这是因为此前在 DeepSeek 被各家服务商争相部署的热潮里，他是最积极的反对声音之一。&lt;/p&gt; 
&lt;p&gt;此前尤洋曾在社交平台上计算过部署 DeepSeek 的成本和收益，并得出结论，&lt;strong&gt;部署 DeepSeek 并提供服务的 AI Infra 公司，都是在亏钱，并且是「月亏四亿」&lt;/strong&gt;。他提到：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;短期内，中国的 MaaS（模型即服务）模式可能是最差的商业模式，大厂相互卷低价和免费，满血版 DeepSeek R1 每百万 token（输出）只收 16 元。&lt;/p&gt; 
 &lt;p&gt;如果每日输出 1000 亿 token，基于 DeepSeek 的服务每月的机器成本是 4.5 亿元，亏损 4 亿元；用 AMD 芯片月收入 4500 万元，月机器成本 2.7 亿元，这意味着亏损也超过 2 亿元。&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/143832_4Tqd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此次 DeepSeek 的开源周并非要回应某个具体质疑，但其公布的利润率之高，显然与这个计算完全相反。人们首先想到了尤洋。尤洋也在四个小时后发文&lt;em&gt;「&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27271377737&quot; target=&quot;_blank&quot;&gt;《关于 DeepSeek MaaS 成本》&lt;/a&gt;」&lt;/u&gt;&lt;/em&gt;回应，&lt;strong&gt;称 DeepSeek 官方这一计算方法不能用于 MaaS 盈亏评估&lt;/strong&gt;。在论述中，他延续了「基于大模型的 Mass 服务不赚钱」的立场。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/144501_AKpd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;袁进辉也在 DeepSeek 文章发布一小时后就火速评论道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「又颠覆了很多人的认知」，他认为「很多供应商做不到这个水平」，&quot;MaaS 能否成功，关键在于技术实力和用户基础&quot;。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0303/145540_di7S_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;紧接着两家国产 AI Infra 公司创始人隔空互呛的「对战」开始了：&lt;/p&gt; 
&lt;p&gt;首先是尤洋直接发了一篇直接批评硅基流动这家公司的文章：&lt;em&gt;「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27282739710&quot; target=&quot;_blank&quot;&gt;《坑人的硅基流动》&lt;/a&gt;」&lt;/em&gt;（现已删除）。&lt;/p&gt; 
&lt;p&gt;尤洋称本来不想发这些东西，但是硅基流动的袁进辉老师频繁在朋友圈里阴阳他，&lt;strong&gt;&lt;em&gt;&quot;这家公司疑似组织水军在网上长期黑我。今天 DeepSeek 有一篇文章指向我，他也在那里煽风点火。&quot;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尤洋称硅基流动三周前网站访问量大增，原因是：&lt;/p&gt; 
&lt;p&gt;1、牺牲员工的春节假期，绑上国产芯片，宣传效果很好。&lt;br&gt; 2、拉人头病毒传播，邀请码直接送代金券，拉人头在小红书上快速形成病毒式扩散。&lt;/p&gt; 
&lt;p&gt;尤洋认为，2 月 12 日 superclue 发布评测把硅基流动的 API 性能排到倒数第一，这很公平；从 pr 稿来看，硅基流动有 15 亿的代金券需要兑现，但是这家公司只有 1-2 亿的现金，风险很大。&lt;/p&gt; 
&lt;p&gt;尤洋不太相信硅基流动工程师的水平高于英伟达和 SGLang/vLLM 的顶尖工程师。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2068484324f86fbc8c0e03d41da3e8a7342.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;袁进辉第一时间进行了回应，一方面强调了硅基流动一系列动作背后的思路，另一方面直接抖出「潞晨代码抄袭」的旧案。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-131e5dd073d8aa98e0146931f27b1bd3397.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0bccb574a6ddbdd7dd8607372263b2a63f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ab6ab01c5062ee007aa8128525e4b012ba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPTrxfca5HnQa30C4_k2Thw&quot; target=&quot;_blank&quot;&gt;ColossalAI 重大 Bug 揭秘：DeepSeek-R1 模型微调陷阱&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjcQPmYifLXzgW-UBuwA0jQ&quot; target=&quot;_blank&quot;&gt;维护创新：对潞晨云算力云平台的公开信&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;尤洋立马在朋友圈转发袁进辉的朋友圈截图并回应：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「代码都是潞晨 CTO 负责的，抄袭代码事件后，璐晨 CTO 离职，加入了袁进辉老师的公司。你说可笑不可笑？」&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/152446_8T1l_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d47d3dbc1f62cf976348dc613f52bc28dde.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;差不多同一时间，尤洋的潞晨科技&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4WZ4nlFBei-1bdp7xJuBzw%3Ffrom%3Dgroupmessage%26scene%3D1%26subscene%3D10000%26sessionid%3D1740817599%26clicktime%3D1740827769%26enterid%3D1740827769%26ascene%3D1%26fasttmpl_type%3D0%26fasttmpl_fullversion%3D7622559-en_US-zip%26fasttmpl_flag%3D0%26realreporttime%3D1740827769421&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;将在一周后停供 DeepSeek API。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/143932_QGxE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在这期间，潞晨科技前 CTO 也针对抄袭代码事件&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13752772042%2Fanswer%2F113786841913&quot; target=&quot;_blank&quot;&gt;揭露了一些往事&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1334&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0303/153806_xSWP_2720166.png&quot; width=&quot;1344&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;针对前 CTO 发文，尤洋&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fpin%2F1879419844941816823&quot; target=&quot;_blank&quot;&gt;回复&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;928&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0303/153953_GcN1_2720166.png&quot; width=&quot;1428&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;次日（3 月 2 日）早上，尤洋向 DeepSeek 道歉：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-36027c94f1fd05eea0fc7e48fd0f697869f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;今日（3 月 3 日），尤洋再度&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fpin%2F1879818683184034076&quot; target=&quot;_blank&quot;&gt;回应&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原本只是讨论 MAAS 盈利模式的测算，我就在跟 DeepSeek Infrastructure 团队的技术探讨中显得很张扬，不是很有礼貌。现在微博小红书知乎上到处都是对我个人或我的创业公司的人身攻击和无端指责，我没有精力一条一条地解释。&lt;/p&gt; 
 &lt;p&gt;我跟 DeepSeek 的辩论我又没有说错，我的计算和分析都没有问题，只是语气不太好以及和技术无关的言论措辞不准确，一晚上几十个人让我道歉。&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a5a9c4469855baf3f01edf40e9e9acc63be.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;相关链接&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27181462601&quot; target=&quot;_blank&quot;&gt;DeepSeek-V3 / R1 推理系统概览&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13752772042%2Fanswer%2F113786841913&quot; target=&quot;_blank&quot;&gt;如何看待尤洋对 DeepSeek 成本文章的回应以及开团硅基流动&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13759294910&quot; target=&quot;_blank&quot;&gt;如何评价北京潞晨科技尤洋称「deepseek 应该感谢美国恩情」？&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13751256341&quot; target=&quot;_blank&quot;&gt;DeepSeek 和尤洋对模型服务成本的测算方式差别在哪里？对 AI 产业有什么参考意义？&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336640</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336640</guid>
            <pubDate>Thu, 27 Feb 2025 07:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>周鸿祎：人工智能将重塑所有行业，AI 安全需要「以模制模」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;em&gt;&lt;span style=&quot;color:#000000&quot;&gt;证券时报记者，王小伟&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作为全国政协委员，360 集团创始人周鸿祎今年第八年参加全国两会。他关注的方向是人工智能和安全两大主题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周鸿祎认为，人工智能将重塑所有行业，企业应该从找场景、打造专业知识库、打造智能体、接入办公流程等四个方面拥抱人工智能。他呼吁，国家对大模型发展实行柔性监管，更加包容审慎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于人工智能发展同步伴生的安全问题，周鸿祎认为，传统网络安全已经无法应对新挑战，应由既懂安全又懂 AI 的企业牵头，以模制模，通过打造安全大模型来解决大模型的应用安全问题。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;企业拥抱 AI「四步走」&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在周鸿祎看来，人工智能将重塑所有行业，每个行业都能找到降本增效的地方；对个人来说，则可以拥有自己的专业助手。「过去我们软件、APP 经常是接收指令，完成一个功能。未来人工智能的模式，会像跟一个顾问一样交流，倾诉问题，表达想法，通过多轮讨论，帮个人找到答案或启发。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;产业层面的改变会更大。他以医疗医药产业举例分析说，医院运营等传统行业，人工智能可以通过加速数字化改造和智能化升级，来提升效率，比如使病人候诊的时间缩短很多倍。生物制造等新兴产业，用人工智能可以成为研究工具和范式。基因抗癌等领域则属于 AI for Science（科学智能），用大模型这种算法模式套到生物学里，变成生物学研究的工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「AI 的应用范围非常多，成为个人助理只用到它 5% 的功能；更重要的是和产业结合。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周鸿祎建议，企业应该从四个方面拥抱人工智能。第一，找场景，需要大模型来解决效率低、成本高、体验差的问题。第二，需要打造专业知识库，在企业的数据库里、老板的脑子里、大家的开会记录里，都有很多隐藏的知识。第三，要打造智能体，比照数字员工。第四，通过企业的工作流软件把智能体接到企业的 OA 办公流程里，企业应用才能做起来。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年春节期间，DeepSeek 在全球异军突起，成为了 AI 发展史上的重要里程碑。在周鸿祎看来，DeepSeek 最大的成果不仅是让中国大模型在技术上赶上了美国大模型，同时在中国用户、企业和政府中做了一次人工智能的普及教育。由于 DeepSeek 免费、开源等特性，政府企业纷纷开始采用 DeepSeek 在内部降本增效，加速了中国爆发 AI 产业革命的步伐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「DeepSeek 对中国 AI 产业带来最大的影响，是让产业玩家各自归位，否则大家一窝蜂地‘百模大战’，等于都在造轮子。倘若都希望做通用大模型，都做 AGI，谁的卡也不够，谁的数据也不足。」周鸿祎说，如今，连腾讯、百度都宣布引入 DeepSeek。DeepSeek 做得好，就由它来做基座模型；其他厂商就不用重复造轮子，不用重复耗费算力；云服务商也不用自己开发算力，可以直接用 DeepSeek 做服务，而且价格可以做得很便宜，因为没有研发成本。他判断，未来很多小应用都会做起来。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周鸿祎呼吁，就像「避风港原则」曾带给互联网巨大的产业发展机会，国家对大模型发展实行柔性监管，更加包容审慎，这样中国人工智能才能借助 DeepSeek 的机会实现更长远的发展。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;「以模制模」应对安全挑战&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年两会提案中，周鸿祎还关注到「硬币的另一面」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「DeepSeek 作为基座模型，存在着幻觉、提示注入攻击等问题。同时，大模型要在企业内部真正发挥作用，还需要连上企业的专业知识库、打造智能体，调用企业各种 IT 系统，这进一步加剧了安全风险。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;当大模型渗透率提升时，应用安全问题也迫在眉睫。周鸿祎认为，网上现在对 DeepSeek 等大模型安全问题，还是当成一个传统 IT 设备看待。这个思路是过时的，传统网络安全的解题方法解决不了人工智能的安全问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，他建议，应由既懂安全又懂 AI 的企业牵头，以模制模，通过打造安全大模型来解决大模型的应用安全问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在周鸿祎看来，人工智能的安全问题包括多个层面。比如，基座模型的安全问题，是如何在 AI 领域防止幻觉。「DeepSeek 用互联网的知识库来做校正、企业里应用连上专有知识库校正等，一部分幻觉可以通过知识库来解决。同时，大模型很容易被 PUA，这是比较严重的问题，是基座模型的问题。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;再比如，大模型应用需要建立知识库，尤其在企业应用，单靠提示词是解决不了的。而一旦把企业很重要的资料放到知识库里喂给大模型了，大模型又会如实地把知识库里能看到的资料告诉任何人，这就会存在数据安全问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智能体的安全、知识数据的安全、客户端的安全、基座模型的安全，构成人工智能安全的新领域。周鸿祎认为，解决的关键问题是「以模制模」——专门做安全大模型，用聪明的大模型智力能力去管理知识库的使用，去管理智能体的调用，去管理基座模型的「胡说八道」和对人的「PUA 攻击」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「幻觉是一把双刃剑，是大模型具备真智能的体现，是走向 AGI 的基础，它让大模型体现出更多的创造性和想象力，能够在科研领域发挥重要作用。」周鸿祎强调，大模型幻觉很难消除，但已经通过多个大模型交叉验证、搜索矫正以及企业知识库比对等方式进行了纠正。在大模型产业高速发展的过程中，不发展是最大的不安全，所以不能因为大模型的幻觉问题就因噎废食。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;让技术转化为新质生产力&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「应该正确认识 AI 安全问题，不能夸大也不能忽视。」周鸿祎强调，不发展是最大的不安全，必须要抓住 AI 这次工业革命的机会，提升生产力，包括让科技普惠在每个人身上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于网信安全产业竞争格局，周鸿祎表示，一直以来，我国安全行业内卷严重，很多厂商只是一味的卖硬件软件，客户也无法得到想要的安全服务，致使行业面临普遍性经营困境，造成客户和厂商双输的局面。同时，各种高级别攻击日益严重，企业不只需要一个「安全盒子」，更需要高级网络安全专家协助进行数据分析研判、数据追踪及事件处置。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了解决这个困境，周鸿祎认为，通过 SaaS 的方式来为更多企业提供安全服务，企业不仅可以直接体验安全服务的效果，投入成本也降到了五分之一甚至十分之一。因此，周鸿祎在今年两会上也会呼吁国家从政策上支持采购安全服务，特别是鼓励采购 SaaS 化安全服务，实现安全的普惠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「筑牢网络安全根基，是为大模型发展铺路；而解决 AI 应用安全与幻觉问题，则是让技术真正转化为新质生产力。」周鸿祎表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在记者采访中，周鸿祎还谈到了对 360AI 产品的未来规划。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他介绍，自己一直都有危机感，搜索本来就是一个巨头林立的赛道，公司要想办法把纳米 AI 搜索做得比 DeepSeek 好。「公司产品引入了 DeepSeek 以及国内其他 16 家一共 50 种模型，通过这些模型的协作，有的擅长改写，有的擅长总结，有的擅长推理和分解任务。DeepSeek 春节期间 7 天新增用户级别以亿计算，我们 15 天涨了 2000 万手机用户。现在 PC 端 360 的产品流量很大，我们会耐心地把 PC 上再转出来至少上千万用户。有了很好的基础之后，剩下的问题就是要仔细打磨用户的体验和把各种深度的工具做好。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336639</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336639</guid>
            <pubDate>Thu, 27 Feb 2025 07:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>NVIDIA 在 2024 年出货十亿个 RISC-V 核心的背后</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在最近的 RISC-V 北美峰会上，NVIDIA 多媒体架构副总裁 Frans Sijstermans 深入阐述了 NVIDIA 选择 RISC-V 作为其嵌入式微控制器架构的原因，以及它如何成为其产品成功的重要组成部分。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;背景：NVIDIA 从零到十亿个 RISC-V 核心的历程&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 与 RISC-V 的历史可以追溯到 2016 年。当时，NVIDIA 开始将其内部的 Falcon 微处理器（用于 GPU 产品的逻辑控制）转向新的架构。在评估了多种架构后，NVIDIA 选择了 RISC-V ISA，并自此开始将 RISC-V 微控制器添加到其产品中，逐步替换旧版 Falcon。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在其 10 年的生命周期中，NVIDIA 估计出货量约为 30 亿个 Falcon 处理器，预计这一转型最终将导致数十亿个 RISC-V 处理器的出货。通常，每个 NVIDIA 芯片包含 10 到 40 个 RISC-V 核心，具体数量取决于配置。2024 年，基于出货的总芯片数量，NVIDIA 的 RISC-V 处理器出货量超过了十亿个。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;自 RISC-V 社区首次会议以来，NVIDIA 一直是该社区的积极成员，并且几乎一直在董事会层面拥有代表权。NVIDIA 参与了许多技术工作组，不仅贡献和分享自己的工作，还从其他社区成员的贡献中受益，同时还参与了 RISE 软件组织。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;尽管如此，NVIDIA 并不常与 RISC-V 联系在一起，这可能是因为其许多工作都是内部进行的，尽管重要，但大多与面向客户的产品无关。RISC-V 在 NVIDIA 产品组合中主要涉及三个关键领域：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能级控制器，包括视频编解码器、显示器、摄像头、内存控制器（培训）、芯片间接口和上下文切换。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;芯片/系统级控制，包括资源管理、电源管理和安全性。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;数据处理，包括网络中的数据包路由以及 DLA（非 GPU）中的激活和其他深度学习网络层。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 的 RISC-V 核心&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 从仅支持 32 位的 Falcon 核心过渡到 RISC-V 的初衷是为了满足 64 位能力的需求。他们的第一个 RISC-V 开发是一个相对普通的双发射乱序 RISC-V 核心，配备标准扩展，并可作为多处理器版本部署。随后，他们还为面积受限的应用添加了 32 位版本，并增加了一个 1024 位向量单元的向量处理器。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;270&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3191fcdb0cf75d8a4eb715d8d266d2d5b3.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 还开发了几个自定义扩展，有些是特定于 NVIDIA 的，另一些则对一般用户有益。例如，2kB 页面大小扩展是 NVIDIA 独有的，能够提高传统软件性能 50%。同样，64 位地址扩展在大规模系统中非常有用，如数据中心，其内存是分布式且相距甚远。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，他们的指针掩码扩展在安全和保护应用方面具有广泛的潜力。因此，NVIDIA 将该扩展提交给 RISC-V 标准，并获得批准，现在已被许多社区成员使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 还拥有额外的扩展，可实现通用功能、安全性和性能，虽然这些扩展在技术上并不特别先进，但对于整个系统来说至关重要。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;RISC-V 支持的子系统&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 的 SoC 使用自己的 RISC-V 子系统，名为 Peregrine。除了 RISC-V 核心外，它还包括其他外设，如 DMA 和安全 IP。Peregrine 对 NVIDIA 至关重要，因为它允许他们选择和重用 30 多个系统控制和管理应用，而无需每次都进行独立开发。RISC-V 架构使 NVIDIA 具备灵活性和模块化，能够根据需求配置子系统。例如，他们可以选择 32 位或 64 位核心，并添加特定工作负载所需的扩展，从而最大化开发重用和投资回报。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;261&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e6d5efcf21fdd145bf9f47617faa322fab6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;类似地，在软件方面，所有 30 多个应用使用单一堆栈，这使得诸如引导、操作系统、分离内核和应用程序库等项目的重用变得显著。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;261&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f29d3484f956627b0681c3d8db7e98230d6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 同样致力于使其产品尽可能安全，内部设有一支进攻性安全团队，作为「黑客」积极寻找设计中的弱点、漏洞和错误。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Peregrine 子系统的核心组件是分离内核，可以被视为一个非常基础的虚拟机监控器。它将系统划分为不同的独立部分，便於单独验证。用户可以在不同的分区上运行不同的软件。例如，符合 ASIL-D 认证的安全合规应用可以在一个分区上运行，而另一个非认证应用可以在另一个分区独立运行。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;275&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-18a85a32c31897f9d702222b068398b3f6f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;应用实例&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 拥有 30 多个使用 RISC-V 核心的系统控制和管理应用，并且可以根据具体用例灵活部署。以下详细介绍了其中两个应用程序。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;首先，GPU 系统处理器（GSP）为 NVIDIA 的软件开发方式带来了根本性变化。GSP 是位于 GPU 顶部的处理器，负责创建 GPU 可执行的抽象。主处理器和内核驱动不再使用 GPU 内部的各个控制寄存器，而是直接与 GSP 通信，GSP 将这些高级命令转换为低级控制寄存器的操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;275&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6d231c3a77b7674b3301eaaef98ab82b820.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;GSP Peregrine 配备 64 位 RISC-V 处理器，提供单线程和多线程版本。最重要的是，GSP 可以完全访问 GPU 中的所有内容，包括内存和显示控制器，这些在软件中需要非常仔细地管理。从软件的角度看，用户可以部署具有内核驱动和多个访客虚拟机的主处理器。访客虚拟机在 GSP 上具有相应的 vGPU 运行时分区，而分离内核确保它们之间相互隔离，不会干扰。资源管理器会根据需要切换不同的访客，并确保资源分配公平。这一功能支持了诸如保密计算等特定用例，在这种情况下，GPU 被分配给访客，且不会受到虚拟机监控器的影响。在这种情况下，RISC-V 架构因其特定的隔离能力和 NVIDIA 自身的扩展特性而对安全性至关重要。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;第二个支持 NVIDIA RISC-V 的应用程序是深度学习加速器，作为一些专用 AI SoC 的一部分。它本质上是一个图处理编程的推理引擎。例如，ONNX 程序表示深度学习网络中处理的层图。它使用标准的 RISC-V 编译器，将内核代码编译为可执行文件。在此基础上，还有一个 RVV 编译器，将其转换为可加载格式。也可以将不同内核组合成单一内核，以实现最优执行。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;DLA 并不会在 RISC-V 处理器上运行所有东西，主卷积核心和矩阵乘法器是独立的实体。在下图的硬件结构中，有两个 RISC-V 处理器，一个是控制核心，简单的 32 位单元，另一个是 NVRVV，这是一种 1024 位向量单元。还包括一个卷积核心，总共六个硬件引擎。例如，Rubik 是一个智能 DMA 数据转换器，负责数据传输，而 RISC-V RVV 向量处理器用于大多数非矩阵乘法的层。简而言之，它是一个在 DLA 上运行的完整 ONNX 实现。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;259&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e14ba4b4de454267340f43ce5d702dc2803.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;总结：为何 RISC-V 适合 NVIDIA&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;总结来说，NVIDIA 选择 RISC-V ISA 以及它取得成功的原因有 5 个：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;定制化&lt;/strong&gt;：定制能力至关重要，使 NVIDIA 能够最大化使用硅片。RISC-V 的许可模型允许他们使用基本 ISA 作为构建块，添加适合特定应用需求的扩展和配置文件。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;硬件/软件协同设计&lt;/strong&gt;：确保硬件针对软件负载进行了优化，从而提升效率和性能。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;配置选项&lt;/strong&gt;：标准的「现成」处理器往往对应用要求过高。通过 RISC-V，NVIDIA 可以通过配置实现仅需的特定扩展来节省成本和开发努力。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;自定义扩展&lt;/strong&gt;：允许 NVIDIA 添加特定功能、安全性和性能等要求。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;统一的硬件和软件架构&lt;/strong&gt;：允许 NVIDIA 在其 30 多个应用程序中重复使用资产，而无需为每个应用程序创建或调整新架构。减少开发工作量、简化部署并降低成本。&lt;/span&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;详情可查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Friscv.org%2Fblog%2F2025%2F02%2Fhow-nvidia-shipped-one-billion-risc-v-cores-in-2024%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336623/nvidia-shipped-one-billion-risc-v-cores-2024</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336623/nvidia-shipped-one-billion-risc-v-cores-2024</guid>
            <pubDate>Thu, 27 Feb 2025 06:23:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国首款 AI IDE：Trae 国内版发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;字节跳动技术团队微信公众号发文宣布，中国首个 AI 原生集成开发环境（AI IDE）Trae 国内版正式上线，配置 Doubao-1.5-pro，并支持切换满血版 DeepSeek R1、V3 模型。&lt;/p&gt; 
&lt;p&gt;Trae 国内版不仅针对中国开发场景和习惯进行了一些优化，后续还即将支持模型自定义，用户可以根据自己的喜好，接入合适的大模型 APP。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;346&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-377de0bceee6c5821234bc072a1e762f09b.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「作为更贴合中国开发者开发习惯与开发场景的 AI IDE，Trae 以动态协作为核心，打造了一种人机协同，人与 AI 互相增强的全新开发体验，助力开发者高效应对复杂技术挑战，释放创新潜能。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根据介绍。Trae 定位为「&lt;strong&gt;智能协作 AI IDE&lt;/strong&gt;」，以「人机协同、互相增强」为核心理念，对代码补全，代码理解，Bug 修复，基于自然语言生成代码等开发过程全场景都有非常好的适应性，不仅是一个开发工具，更是一位全天候开发「拍档」。Trae 希望成为更可靠的、值得开发者信赖的「AI 工程师」&lt;strong style=&quot;color:#3e3e3e&quot;&gt;（T&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;he&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;&amp;nbsp;R&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;eal&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;&amp;nbsp;A&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;I&amp;nbsp;&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;E&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;ngineer&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;）。&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全新 Builder 模式能充分利用 AI 的能力，无论是初学者还是资深的开发者，都能够轻松通过自然语言描述迅速的，端到端的生成应用：只需要用简单的语言描述需求，Trae 就可以迅速搭建起项目框架，还能持续进行调优修改，产出可用代码。这种智能化的&quot;思想到代码&quot;直通车能力，全程助力开发者将需求端到端完美落地，极大缩短了项目筹备周期，为高效开发奠定坚实基础。&lt;/li&gt; 
 &lt;li&gt;在代码理解维度，Trae 的能力边界实现了质的突破，凭借对开发项目上下文的极致理解，深入剖析代码仓库，实时获取 IDE 中的各种环境上下文，精准洞察开发者的需求，从而为开发过程提供最为契合、准确的解决方法。&lt;/li&gt; 
 &lt;li&gt;针对需求沟通效率问题，Trae 的实时代码续写技术可基于开发项目整体上下文进行智能补全，提升编码效率，而在交互体验方面，开发者可以便捷地将 AI 生成的代码一键应用到多个模块，还能根据实际需求随时灵活调整指令，并实时预览 AI 生成代码的前端效果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;详情可访问官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ftrae.com.cn&quot; target=&quot;_blank&quot;&gt;trae.com.cn&lt;/a&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336617</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336617</guid>
            <pubDate>Thu, 27 Feb 2025 05:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>联想将推出 AI PC 产品矩阵、打造企业级 AI 基础设施</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今天，联想发文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3uzAYrlxpvr_me74s2Cj5g&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;，将在 3 月 3 日-6 日举办的 MWC2025 上，正式发布一系列突破性的混合式人工智能技术。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/113731_tAhf_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI PC 产品矩阵&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;全新推出 ThinkPad T14s 2 合 1 笔记本、配备独立 NPU 的 ThinkBook 16p Gen 6，以及 Yoga Pro 9i Aura。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/114026_WZsV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;em&gt;▲ 配备独立 NPU 的 ThinkBook 16p Gen 6&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;前瞻性概念产品&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;包括 ThinkBook Flip AI PC，采用创新外折叠屏设计；全新联想 Magic Bay 配件；YOGA 太阳能笔记本电脑概念机，搭载太阳能供电技术，探索可持续计算未来。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/114140_frh2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/114240_nsMZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;联想 AI Now：端侧 AI 智能体，可提供更自然、高效的个性化交互体验。&lt;/li&gt; 
 &lt;li&gt;超级互联 Smart Connect 2.0：一款统一数字生态的软件解决方案，实现联想 AI Now 与 moto ai 跨设备协同，为用户带来无缝衔接的智能体验。·&lt;/li&gt; 
 &lt;li&gt;ThinkEdge SE100：高性价比的边缘推理服务器，让企业级 AI 计算触手可及，助力智能转型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3uzAYrlxpvr_me74s2Cj5g&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/3uzAYrlxpvr_me74s2Cj5g&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336601</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336601</guid>
            <pubDate>Thu, 27 Feb 2025 03:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「智御」个人信息保护大模型正式接入 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在工业和信息化部信息通信管理局的指导下，中国信息通信研究院（简称「中国信通院」）研发的「智御」个人信息保护大模型近日已正式接入 DeepSeek，实现了个人信息保护领域专业语义精准捕获、多维信息关联分析及持续进化的合规态势感知综合能力跃升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;280&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6c4a59474e0245277820404e2542af27d22.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，「智御」发布以来，面向移动互联网应用开发者、分发平台、终端厂商、检测机构等行业上下游企业，提供多模态、多样化的合规咨询、风险检测、代码修复、决策支持等服务，已输出合规优化建议 7200 余条，有效助力企业提升个人信息保护意识和能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次「智御」完成与 DeepSeek 的融合升级后，借助其卓越理解和推理能力，显著提升了语义意图识别和多源异构数据处理能力，能够更精准地解析行业用户需求，支持处理更复杂的场景任务，提供更加智能、高效、便捷的服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;下一步，中国信通院将持续深化技术攻关、创新实践，加速拓展「智御」在行业领域的落地应用，输出可复制、可推广的个人信息保护智能解决方案，进一步为个人信息保护工作赋能赋智。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336600</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336600</guid>
            <pubDate>Thu, 27 Feb 2025 03:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>清华大学将扩招本科生，重点培养「AI+」人才</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYvq6vbM5TmaHeLpSPMPEyA&quot; target=&quot;_blank&quot;&gt;据新华网 3 月 2 日消息&lt;/a&gt;&lt;/u&gt;，清华大学决定有序适度扩大本科招生规模&lt;strong&gt;，2025 年拟增加约 150 名本科生招生名额&lt;/strong&gt;，同时将成立新的本科通识书院，&lt;strong&gt;着力培养人工智能与多学科交叉的复合型人才&lt;/strong&gt;，提升创新人才自主培养能力，以服务国家战略需求与社会发展需要。&lt;/p&gt; 
&lt;p&gt;报道指出，该校新增本科生将进入新成立的书院学习。而新成立的本科通识书院将汇聚清华优势学科资源，突出人工智能技术在教育教学、科研创新中的驱动作用，立足人工智能与多学科交叉融合，着力探索人工智能赋能教育教学范式，以培养具有深厚人工智能素养、掌握人工智能技术、具备突出创新能力的复合型人才。&lt;/p&gt; 
&lt;p&gt;此外，清华大学教务处相关负责人介绍，目前学校已在人工智能人才培养和人工智能赋能教育方面取得阶段性成果。&lt;/p&gt; 
&lt;p&gt;具体来说，首批已有 117 门试点课程、147 个教学班开展人工智能赋能教学实践，开发出智能助教、备课辅助、智能批改等多种功能场景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336597</guid>
            <pubDate>Thu, 27 Feb 2025 03:06:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>商汤董事长：建议探索「科创算力贷」破解痛点</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;央行等金融管理部门联合全国工商联日前召开金融支持民营企业高质量发展工作座谈会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;当前，民营企业诉求主要包括，希望给予企业无本续贷贷款展期等信贷支持，希望获得与企业生产周期匹配的中长期资金支持，希望能针对企业特点开发新型金融产品，以及在债券融资中能够获得与同评级国企同样的票面利率待遇等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;商汤科技董事长兼首席执行官徐立表示，AI 技术和产业发展对资金的需求巨大，研发成本高昂、周期长、风险大，许多企业在融资和贷款方面面临困难。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;徐立建议，针对 AI 行业给予更加精准的支持政策和措施。首先，探索「科创算力贷」，破解 AI 基础设施融资痛点；其次，进一步放开股权融资、股债融合等股权融资渠道；另外，创新贷款工具，支持民营企业多元化融资。例如，利用算力资产为基础，发行「科创算力债券」，吸引长期资金支持，专项用于算力基建。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336596</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336596</guid>
            <pubDate>Thu, 27 Feb 2025 03:01:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>苹果或将回归路由器市场：支持 Wi-Fi 7、自研芯片是亮点</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.macrumors.com%2F2025%2F03%2F01%2Fapple-airport-could-return-in-unexpected-way%2F&quot; target=&quot;_blank&quot;&gt;据 MacRumors 报道&lt;/a&gt;&lt;/u&gt;，苹果为了加大智能家居产品的用户群体，或将回归路由器市场。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eadbf2f9a578cd9b0628866d49ad1dc143a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，苹果于 1999 年推出了 AirPort 系列首款产品，而后 AirPort 系列逐渐成为苹果的路由器产品线，历经 20 年的发展后，苹果于 2018 年宣布停止 AirPort 系列的更新与生产。AirPort 系列包括了 AirPort Express、AirPort Extreme 和 AirPort Time Capsule 时间胶囊等几款主要设备。&lt;/p&gt; 
&lt;p&gt;在去年 12 月，彭博社记者 Mark Gurman 曾报道，苹果正在开发自研的 Wi-Fi 蓝牙集成芯片，该芯片将会在今年晚些时候推出的新款 Apple TV 和 HomePod mini 中亮相。其中 Gurman 提到，该款芯片十分复杂，理论上可以成为无线网络的发送器。&lt;/p&gt; 
&lt;p&gt;MacRumors 指出，苹果目前正在计划加大对智能家居产品的推广。报道推测，上述的 Apple TV 和 HomePod mini 未来搭载了苹果的自研 Wi-Fi 蓝牙芯片后，将有机会成为类似 AirPort 系列的路由器产品，而这也将成为苹果在智能家居市场扩大市场占比及影响力的一种新方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336592/apple-airport-could-return-in-unexpected-way</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336592/apple-airport-could-return-in-unexpected-way</guid>
            <pubDate>Thu, 27 Feb 2025 02:49:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>荣耀：未来 5 年将投入 100 亿美元与伙伴共建 AI 终端生态</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2025 年世界移动通信大会 (MWC) 上，荣耀详细介绍了其转型的全新战略——&quot;荣耀阿尔法计划&quot;(HONOR ALPHA)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据介绍，&quot;阿尔法计划&quot;分为三个阶段：第一步是智慧手机，第二步是智慧生态系统，第三步是智慧世界。该计划旨在将内容、服务、芯片、系统全部以人和 AI 设备为中心进行连接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;荣耀 CEO 新任李健宣布，未来 5 年荣耀将投入 100 亿美元，与全球合作伙手共建 AI 设备生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ae450daeb302cd65d509d255d49ccc475e2.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;荣耀发言人向媒体透露，这笔资金将用于将 AI 融入硬件以及开发下一代 AI 代理，投资的另一部分将用于创建&quot;各种 AI 设备的平台&quot;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&quot;这不仅限于我们自己的设备，还包括来自不同合作伙伴的 AI 设备，使不同类型的 AI 设备能够相互交流，消费者可以有更多选择和无缝体验，&quot;荣耀发言人表示。此外，一小部分投资将用于&quot;为 AGI 时代做准备&quot;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336590</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336590</guid>
            <pubDate>Thu, 27 Feb 2025 02:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯元宝电脑版上线，支持 Windows 和 macOS 系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&amp;nbsp;3 月 1 日，腾讯 AI 助手「腾讯元宝」&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9V5XtAWdr_eEatKaUok3VQ&quot; target=&quot;_blank&quot;&gt;正式发布电脑版&lt;/a&gt;&lt;/u&gt;，支持 Windows 和 MacOS 系统。&lt;/p&gt; 
&lt;p&gt;此次发布的腾讯元宝电脑版面向工作和学习场景打造，旨在帮助用户减轻负担、提升效率。除具备与移动端和网页版一致的核心功能外，电脑版后续还将推出更多便捷功能，如划词搜索与翻译、截图提问等，进一步提升用户体验。&lt;/p&gt; 
&lt;p&gt;电脑浏览器打开 yuanbao.tencent.com 即可下载元宝电脑版。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/103204_EBpg_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方介绍，腾讯元宝电脑版用户可以体验到与手机端、网页端相同的智能对话能力。不仅能通过 DeepSeek-R1 满血版和推理模型混元 T1 进行深度思考，也可以通过 DeepSeek-V3 和腾讯混元 Turbo S 快速获得答案，满足不同场景下的需求。结合公众号等腾讯内容源与权威互联网信息，确保提供的答案时效性更强、可信度更高。&lt;/p&gt; 
&lt;p&gt;此前，腾讯元宝还让 DeepSeek 具备了读图能力，而该功能也完整上线电脑版，用户随手截图或发送任意图片，元宝都能结合图片内容给出自己的分析和理解。&lt;/p&gt; 
&lt;p&gt;另外电脑版也支持解析文件，大幅提升文件、论文等阅读效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336588/tencent-yuanbao-pc</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336588/tencent-yuanbao-pc</guid>
            <pubDate>Thu, 27 Feb 2025 02:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Ai.com 将以 1 亿美元出售</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fai-com-is-for-sale-asking-price-100-million&quot; target=&quot;_blank&quot;&gt;据 The Information 报道&lt;/a&gt;&lt;/u&gt;，资深域名经纪人拉里·菲舍尔正在帮雇主寻求出售备受瞩目的域名 ai.com，报价高达 1 亿美元（折合人民币 7 亿元）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cb8c4d9cfce15e676fdc256e077d3035846.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，62 岁的菲舍尔已有近 30 年域名交易经验，曾促成多笔高价域名交易，包括将 Messenger.com 卖给 Facebook、Skincare.com 卖给欧莱雅、Teams.com 卖给微软以及将 Chat.com 卖给 HubSpot 联合创始人达梅什·沙阿（后者随即将其转售给 OpenAI）。&lt;/p&gt; 
&lt;p&gt;目前 ai.com 域名的所有者保持匿名，仅透露当初购买该域名是因为与自己的缩写相符，而非看好 AI 的发展。菲舍尔认为 OpenAI、微软、Google 和 Meta 等科技巨头或加密货币富豪都可能是潜在买家。值得注意的是，目前已知最高域名交易记录为 MicroStrategy 公司 2019 年以 3000 万美元出售的 Voice.com。&lt;/p&gt; 
&lt;p&gt;此前，ai.com 多次蹭 AI 公司的热度，&lt;strong&gt;曾跳转过 DeepSeek、ChatGPT、xAI，以及 Google Gemini 官网&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;根据域名查询网站 whois 显示，ai.com 域名有效期至 2031 年 5 月 5 日，注册联系人显示来自马来西亚首都吉隆坡。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336586/ai-com-is-for-sale-asking-price-100-million</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336586/ai-com-is-for-sale-asking-price-100-million</guid>
            <pubDate>Thu, 27 Feb 2025 02:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>穿皮夹克是抄袭英伟达黄仁勋？雷军回应</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2 月 27 日进行的小米发布会上，雷军身着皮夹克引起热议。3 月 2 日，雷军在直播中回应此事表示，「皮夹克可能比较容易配得上 Ultra 这种极致驾驶的风格」，「我也没想到这个皮夹克这么多人喜欢，还上了热搜」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-39311cf4b24afe864107f10886ca0fcdcd0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;雷军回答：「为什么选皮夹克呢，我是觉得皮夹克可能比较容易配得上 Ultra 这种极致驾驶的风格。所以我们就想到了皮夹克，然后同事们就挑选了三四件，我（从中）挑了一件。我也没想到这个皮夹克这么多人喜欢，还上了热搜。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「其实我在选的时候，我就担心，我要穿皮夹克肯定很多人说你抄那个 Nvidia 的老板黄仁勋，好像我在认识黄仁勋之前，每个人家里是不是都有两三件皮衣。难道我一穿皮夹克就是抄黄仁勋？我一穿西服就是抄马斯克？这太滑稽了。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336585</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336585</guid>
            <pubDate>Thu, 27 Feb 2025 02:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>