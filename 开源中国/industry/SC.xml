<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 25 Mar 2025 07:37:10 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>阿里云开启近年来规模最大的 AI 人才校园招聘</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9UyL73Bk6FBWpWcnfFfq-A&quot; target=&quot;_blank&quot;&gt;根据《科创板日报》的独家报道&lt;/a&gt;&lt;/u&gt;，阿里云近日在全球顶尖高校招募 AI 技术储备人才，为近年来规模最大的 AI 人才校园招聘。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;840&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/152257_OouC_2720166.png&quot; width=&quot;844&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据了解，此次校招面向清华大学、北京大学、浙江大学、麻省理工大学、斯坦福大学等全球顶尖高校，招募大语言模型、多模态理解与生成、模型应用、AI Infra 等领域技术人才。&lt;/p&gt; 
&lt;p&gt;同时，&lt;strong&gt;项目设置 A Star 项目和 Al Clouder 项目，面向具备高水平论文、开源项目影响力等特质的顶尖人才，为这类毕业生提供更优薪酬和专业扶&lt;/strong&gt;持。&lt;/p&gt; 
&lt;p&gt;此举系之前 T 项目后，阿里巴巴推出的又一项 AI 人才战略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339514&quot; target=&quot;news&quot;&gt;阿里全面 AI 化，公司内部相信「基于 AI 的杀手级应用可能很快就出现」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339418&quot; target=&quot;news&quot;&gt;阿里云启动「T 项目」，加速 AI 研发&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338747&quot; target=&quot;news&quot;&gt;阿里巴巴董事长蔡崇信：AI 市场规模至少 10 万亿美元&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340879</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340879</guid>
            <pubDate>Tue, 25 Mar 2025 07:24:06 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开放，开源，全球化，国产算力展现三大演进趋势</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我国计算产业正在自主创新中快速发展，呈现出开放、开源、全球化三大趋势。专家认为，面对人工智能在各行各业加快应用带来的海量算力需求，我国计算产业亟须抓住机遇，构建算力新体系，打造世界级新产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;数字基础设施量质齐升&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;工业和信息化部 3 月 17 日公布的数据显示，2024 年我国数字基础设施量质齐升。截至 2024 年末，全国在用算力中心标准机架数超过 880 万，算力总规模较上年末增长 16.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作为数字经济时代的核心生产力，算力对经济的巨大拉动作用已经显现。中国信息通信研究院发布的《中国算力发展指数白皮书（2023 年）》显示，算力每投入 1 元钱，就将带动 3 至 4 元的 GDP 增长。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在数字经济大省浙江，去年数字经济核心产业增加值突破 1 万亿元。据介绍，在推进数字浙江建设进程中，于 2020 年投入运营的浙江省鲲鹏生态创新中心为浙江数字经济的发展提供了技术支撑和创新动力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作为国产算力的中坚力量，在硬件层面，鲲鹏 CPU 展现出强大竞争力，部件、整机实现全量自主创新，构建起坚实的自主创新产业链；在基础软件领域，以开源欧拉、开源高斯为代表的开源项目蓬勃发展，不断丰富和繁荣软件生态，为浙江数字产业发展提供了源源不断的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作报告提出，「激发数字经济创新活力」，并作出了「优化全国算力资源布局」等具体部署。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 等机构认为，2025 年中国智能算力规模将达到 1037.3EFLOPS，并在 2028 年达到 2781.9EFLOPS。当前，我国算力总规模已位居全球第二，但仍存在算力资源供给紧张和不能有效利用的矛盾情况。算力规模的高速增长和供需错配等挑战将为国产算力的未来发展提供新空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;三大产业演进趋势渐明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;专家认为，目前计算产业变革呈现出三大趋势：一是算力架构的开放特性加速了端、边、云全场景的快速协同发展；二是算力生态共建正在替代单边创新；三是计算产业的全球化趋势愈发清晰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在业界看来，当前算力领域的技术路线正向多元化、多维度演进。受限于封闭架构的短板，传统的 X86 架构难以形成生态，而 ARM 架构的开放模式，将成为未来通用算力的主流选择。数据显示，当前全球算力大约 80% 属于 ARM 架构，其中 99% 的手机采用的都是 ARM 芯片，国内的鲲鹏和飞腾以及国外都有基于 ARM 架构的产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，DeepSeek 的开源实践，推动了人工智能技术的普及和应用。在算力领域，开源同样带来了生态的繁荣。例如，鲲鹏联合超过 6000 家合作伙伴构建的「技术乐高」模式，就证明了开源协作的强大生命力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;开源、开放的生态也让计算产业打开了全球化的新格局。通过携手合作，产业各方开始充分发挥自身优势，通过资源共享与互补，联合打造更具竞争力的解决方案，共同开拓国际市场，为全球客户提供创新产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以鲲鹏生态为例，近年来，通过开源、开放，鲲鹏打造了从芯片、整机到操作系统、数据库的自主创新生态。数据显示，截至目前，鲲鹏生态已发展超过 335 万鲲鹏开发者，面向硬件、软件和应用全面创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;迎接人工智能时代新机遇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;业内人士指出，随着人工智能应用场景的爆发式增长，算力需求呈现快速攀升态势。正如当年互联网推动 PC 快速普及和升级一样，如今人工智能的大范围落地应用也将激活对算力的庞大需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作报告提出，持续推进「人工智能＋」行动，将数字技术与制造优势、市场优势更好结合起来，支持大模型广泛应用。多家机构认为，「人工智能+」行动将重塑所有产业，DeepSeek 的火爆更为大模型应用落地提供了催化剂，不仅将加速各行各业的智能化转型，更将驱动中国计算产业升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 最新数据显示，2025 年，中国人工智能市场总规模将达到 511.3 亿美元，同比增长 34.8%，预计到 2028 年市场规模将达到 1010 亿美元，年复合增长率达到 25.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;面对人工智能时代的新机遇，专家认为，我国计算产业应抓住这一历史性机遇，打造世界级新产品，构筑坚实的算力底座。一是要构建自主创新的算力新体系。IDC 发布的 2024 年中国服务器市场报告显示，自主算力鲲鹏系服务器市场份额占比已达 20% 以上，覆盖了金融、运营商、政府、互联网等核心场景。二是要打造开放开源的自主软件生态。据 IDC 报告，在中国服务器操作系统领域，2024 年开源欧拉系份额达到 50%，累计装机量突破 1000 万套；据沙利文数据，2024 年 openGauss 在关系型数据库中占比 28.5%，超过 MySQL 和 PG，成为三个主流开源数据库技术路线之首。三是要构筑根植中国、面向全球的通用计算产业。工业和信息化部数据显示，2024 年开源欧拉用户数量超过 380 万，为全球 150 余个国家和地区提供服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;专家预测，未来几年，人工智能技术普及将推动算力需求出现爆发式增长。我国计算产业将通过在根技术上的自主创新突破，实现性能提升和成本优化，助力人工智能技术的规模化商用和千行百业的智能化转型，并逐渐走向全球市场，打造面向人工智能时代的通用算力底座。（经济参考报，记者，吴蔚）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340875</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340875</guid>
            <pubDate>Tue, 25 Mar 2025 07:15:06 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>国家数据局：以高质量数据促进人工智能发展</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国家数据局局长刘烈宏 24 日在中国发展高层论坛 2025 年年会上表示，国家数据局将充分调动社会各方力量，积极推动高质量数据集建设，持续增加数据供给，推动「人工智能+」行动赋能千行百业，打造包容开放的创新环境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;302&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bfc45482de2edcfe691d1f74d79bbdf71b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;刘烈宏说，高质量数据与人工智能的结合，将会进一步发挥数据和人工智能的倍增效应。如何更好以高质量数据促进人工智能发展？刘烈宏提出重点做好四方面工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进基础制度供给——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;刘烈宏说，将统筹开展数据领域规划编制工作，加快形成数据领域的规划体系，制定印发数据产权制度和培育全国一体化数据市场的文件，加快推进数据基础制度建设，组织开展数字中国、数字经济、数据要素综合试验区的建设，因地制宜开展先行先试，为数据要素价值释放积累实践经验，健全完善数据治理、数据安全等制度，更好保障人工智能安全发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进高质量数据供给——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「‘人工智能+’行动到哪里，高质量数据集的建设和推广就要到哪里。」刘烈宏说，将强化公共数据资源登记管理，规范公共数据资源授权运营实施，建立授权运营价格形成机制，积极引导做好高质量数据集建设工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进数据基础设施建设——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;生成式人工智能的快速发展，对算力和数据流通利用提出更高更迫切的需求。刘烈宏表示，将系统推进全国一体化算力网建设，创新算力电力协同机制，推动算力设施一体化、集约化、绿色化发展。同时，加快国家数据基础设施建设，推动区域、行业数据基础设施互联互通。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进数据领域国际合作深化——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国家数据局将推进数据领域高水平开放，为中外数字企业发展创造良好环境。「欢迎世界各国企业参与到中国数据要素市场化、价值化进程中，共享数据发展红利和发展机遇。同时我们也将积极参与并持续推动人工智能安全治理，加强国际合作和对话，为全球治理体系完善提供新的动力。」刘烈宏说。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340860</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340860</guid>
            <pubDate>Tue, 25 Mar 2025 06:47:06 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>高并发场景下的库存管理，理论与实战能否兼得？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本篇文章，是一篇实战后续篇，是基于之前我发了一篇关于如何构建高并发系统文章的延伸： &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F35216%3FshareId%3D8087%26isHideShareButton%3D1&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高并发系统的艺术：如何在流量洪峰中游刃有余&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而这篇文章，从实践出发，解决一个真实场景下的高并发问题：秒杀场景下的系统库存扣减问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着互联网业务的不断发展，选择在网上购物的人群不断增加，这种情况下，会衍生出一些促销活动，类似抢购场景或者热销热卖场景，在高峰时段的下单数量会非常大，也意味着对数据库中畅销商品的库存操作十分频繁，需要频繁查库存和更新库存。这属于高读写场景，比起单独的并发读和并发写来说，业务场景更复杂一些。那么这种高并发为了保证库存数据一致性，一般会在数据库更新时进行加锁操作，以保证系统不会发生超卖情况。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们应该如何应对呢？大家可以根据我之前那篇文章中的思维导图，跟随我的思路，一起来看如何解决当前场景下的高并发问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;小试牛刀&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面对库存扣减的场景，我们第一个考虑到是数据一致性问题，因为超卖会对我们的履约和客户信誉造成影响。所以一般情况下，在数据库更新时进行加锁操作，以保证系统不会发生超卖情况。所以更多方案是提高数据库性能方法，比如增加硬件性能，优化乐观锁，提升锁效率，优化 SQL 性能等。对于一些大型系统，也衍生出一些基于分片的库存方案，通过分库分表增加并发吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然那这样不够，因为 MySQL 数据库的读写的并发上线能力是有限的，我们还是需要再进一步优化我们的方案。这里就要参考之前我写的那篇文章中的思维导论了，这里常见解决方案就是，引入缓存机制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如下图所示，我们把读请求进行缓存，每次库存校验时，我们引入 redis 缓存，读请求通过缓存，增加接口性能，然后库存扣减时，在进行缓存同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c08115baf35c2454a8997ca9afa97a80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但这种方式存在很大问题： 所有请求都会在这里等待锁，获取锁有去扣减库存。在并发量不高的情况下可以使用，但是一旦并发量大了就会有大量请求阻塞在这里，导致请求超时，进而整个系统雪崩；而且会频繁的去访问数据库，大量占用数据库资源，所以在并发高的情况下这种方式不适用。同时这个方案还会存在 mysq 和 redis 的数据同步不一致的情况，导致高并发情况下，出现超卖。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;所以这种方案虽然简单，但是无法满足高并发场景，我们必须得 pass。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;循序渐进&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;为此，我们可以进行一次优化，通过架构维度进行调整。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在这个方案中，我们将库存操作封装成一个单独模块，这个方案的优化点在于，所有库存的查询和扣减都围绕 redis 进行。当发生库存扣减操作时，会直接更新 redis，同时采用异步流程，更新 MySQL 数据库。这样以来，我们的性能会比直接访问 MySQL 数据库高效不少，并发能力会有不少提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;流程如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//f6f8964c0024b3ee676272e4655ccfa7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但这个方案依然有缺陷，它的点在于 redis 的单点性能问题。该方案的最大并发性能取决于 redis 的单点处理能力。而如果想要进一步提升并发能力，该方案不具备水平扩展能力。那么，这个方案，依然不是我们最优的选择。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大显身手&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那么接下来，我们需要考虑的是如何可以实现我们业务系统并发能力的水平扩展能力。当然这里也不是凭空来想，我们可以思考一下，业内成熟的一些中间件是如何实现高并发的，这里我们可以两个我们常见的框架：kafka 和 elasticsearch。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;上述我们常见的两个中间件框架，都以可以水平能力扩展著称。那么仔细思考一下他们的技术架构不难发现，他们的核心其实都是采用了一种所谓的分片实现的。那么问题来了，我们的库存扣减，能不能实现分片呢？或者换一个思路思考这个问题：我们的库存逻辑是否可以转化为分布式库存进行存储和扩展呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有了以上的思路，我们就可以开始构建我们的架构方案了。接下来，我先把架构图贴出来：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//6542ddad18a4604d2a38c7b51195fe8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在这个架构方案中，是以 Redis 缓存为实现基础，结合 Mysql 数据存储，通过一套控制机制，保证库存的分布式管理。在该方案中，有一些特定的业务模块单元需要说明。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1. partition&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;熟悉 kafka 的人对 partition 一定不陌生。在本架构方案之中，该业务架构中的 partition 的概念是一组基于 redis 来实现的库存分片，分别存储一部分库存大小。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一个 partition 中，会存有一定量的预占库存量，当有请求服务进行库存扣减时，只需要选择其中一个 partition 即可，这样以来，就可以减轻单节点的压力，同时可以基于 redis 集群的可扩展性，实现 partition 的水平扩展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分布式系统常见的一个问题就是数据倾斜问题，因为严重的数据倾斜，会让我们分布式方案瞬间瓦解，导致单点承担高并发。那么该方案下的数据倾斜问题如何解决呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;最终，我想到的解决方案类似养宠物狗时买的那种定时投喂仪器，每天通过定时定量投喂，来保证宠物狗不会被饿到或者吃撑。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果最初把所有库存全部平均到每个 partition 中，当有多个大库存扣减打到一个 partition 上时，会造成该 partition 上出现库存被消耗光，而失去后续提供库存扣减能力。为了解决这个问题，我在 partition 中采取的是动态库存注入和子域隔离的方案。具体方案如下图：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//8c57d7654d67f6af4f23f47905ef2ce6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每个 partition 会有两个子域，调度器中会记录每个 partition 当前激活的子域，每次库存扣减，会扣减激活的子域中的库存值。而当激活的子域库存值低于设定阈值是，会切换子域，冷却当前子域，激活另一个子域。被冷却的子域会触发任务触发器，实现预占库存的数据同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;子域中会存储一定额度的库存值，不会存储很大的量，这样就可以保证动态的预占库存实现，从而解决库存倾斜的问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然为了更好的管理 partition，我们需要单独开发一个 partition 调度器模块，来负责管理管理众多 partition 资源，那么这个调度器的具体功能包括：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;1.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;调度器中有一个注册表，会记录 Partition 的 key 值，外部服务获取 partition key 是需要通过调度器获取，调度器会记录每个 partition 的库存余量和 partition 和子域信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;2.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当 partition 无法再获取预占库存，且库存耗尽时，调度器会从注册表中摘除该 partition 信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;3.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 调度器可以采用随机或者轮训的方式获取 partition，同时每次也会校验 partition 剩余库存是否满足业务扣减数量，如果剩余库存小于业务扣减数量，将会跳过该 partition 节点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2. 异步更新库存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二个核心模块就是更新库存管理了，这块你可以理解为异步流程机制，通过异步化操作，来减轻系统的高并发对数据库的冲击。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更新库存会有一个明细表，记录每个 partition 库存扣减信息，明细表会有一个同步状态，有两种情况可以出发库存同步 MQ 消息：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一． 当每个 partition 中的明细数据条数超过设定阈值，会自动触发一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二． 每间隔额定设定时间 (默认设置 1 秒)， 会触发一次当前时间段内每个 partition 产生的库存扣减明细信息，然后发送一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;两中触发方案相互独立，互不影响，通过同步状态和明细 ID 实现幂等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3. 预占库存管理和库存管理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接下来就是关于库存的底层数据结构设计了。这里会引入一个在电商行业很共识的概念：预占库存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在库存领域层中，库存分为预占库存和库存两个模块，这里面的库存关系实例如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假设当前商品的库存值为 10000 件，当前 partition 触发一次预占库存任务，领取 400 件， 然后假设此时收到 MQ 库存消费更新消息，更新 30 件。随后 partition 又触发一次预占库存任务，零陵区了 100 件。库存变化如下图所示：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c83f3fadc83623765f0e90cf251f75ad.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其中，实际库存= 预设库存池 + 预占库存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每次预占库存任务触发，会从预设库存池中扣减，如果预占库存池清空，则 partition 就无法在获取预占库存，调度器会将它从注册表中摘除。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而每次 MQ 更新库存消息，会更新实际库存量，同时对预占库存和扣减库存值进行修改，这个操作具有事务性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_8&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;通过这次的案例分析，我们其实是通过方法论结合实际业务场景的方式出发，设计了我们的系统架构。剥离业务场景，其实本质就是通过缓存和异步流程来实现系统的高并发，同时让系统具备拥有水平扩展的能力。但这个方法论在与实际业务结合时，还是会有很多很多需要思考和细化的点，比如分布式思想的使用，比如预占库存的逻辑设计等等。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4090830/blog/17989921</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/17989921</guid>
            <pubDate>Sun, 23 Mar 2025 06:36:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>树莓派开源镜像定制工具 rpi-image-gen</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;树莓派基金会近日推出开源工具 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fraspberrypi%2Frpi-image-gen&quot; target=&quot;_blank&quot;&gt;rpi-image-gen&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;rpi-image-gen 是一个根文件系统和镜像创建工具，旨在提供高度的自定义、灵活性和控制。rpi-image-gen 使用&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbdrung%2Fbdebstrap&quot; target=&quot;_blank&quot;&gt;bdebstrap&lt;/a&gt;&amp;nbsp;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.mister-muffin.de%2Fjosch%2Fmmdebstrap&quot; target=&quot;_blank&quot;&gt; mmdebstrap &lt;/a&gt;进行根文件系统的构建，并使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpengutronix%2Fgenimage&quot; target=&quot;_blank&quot;&gt;genimage&lt;/a&gt; 进行镜像创建。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是一个以 Bash 为中心的脚本引擎，能够使用元数据集合和定义的执行流程生成具有不同磁盘分区布局、文件系统和配置文件的软件镜像。它提供了为 Raspberry Pi 设备创建高度自定义软件镜像的方法。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是易于阅读、可审计且易于使用的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;技术亮点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;模块化定制&lt;/strong&gt;：通过 YAML 配置文件定义软件包列表，移除冗余服务降低资源占用&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全增强&lt;/strong&gt;：自动扫描镜像内软件组件的已知漏洞（CVE），生成 SBOM 清单满足合规需求&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;场景化模板&lt;/strong&gt;：提供 Web Kiosk 等预设配置，5 分钟快速生成专用设备系统&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1852&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/143335_AvvG_2720166.png&quot; width=&quot;2464&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9fd9d61d93288d85f72c7f103eb0e6445bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;该工具支持用户根据需求裁剪操作系统组件、管理软件供应链安全（SBOM 与 CVE），并内置轻量化「slim」镜像模板，为树莓派设备创建定制化的 Raspberry Pi OS 镜像，适用于工厂批量烧录、边缘计算设备集群管理等场景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</guid>
            <pubDate>Sun, 23 Mar 2025 06:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>华为语言模型推理专利公布，可提高对预设内容的理解能力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查资料显示，华为技术有限公司、清华大学申请的「一种语言模型推理方法以及推理装置」专利于 3 月 25 日公布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-71363ec3371e1b4ce56ef932ddc41db7554.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要信息显示，该方法包括：根据第四问题生成第五问题，所述第五问题用于提问所述第四问题、以及提示语言模型回答所述第四问题的回复中不要包括预设内容；所述语言模型根据所述第五问题输出第三回复，所述第三回复不包括所述预设内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中，所述语言模型的参数根据第一回复的评价数据更新，所述语言模型根据第一问题输出所述第一回复，所述评价数据用于指示所述第一回复是否包括所述预设内容。该方法可以提高语言模型对预设内容的理解能力，从而更准确地抑制模型输出预设内容。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340851</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340851</guid>
            <pubDate>Sun, 23 Mar 2025 06:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>人类细胞谱系大科学研究设施启动建设，打造数字细胞 AI 大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人类细胞谱系大科学研究设施 25 日在广州启动建设，将绘制人类生命过程中的细胞动态演化图谱，构建数字细胞 AI 大模型，催生生物医药研究新范式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;这一设施是国家「十四五」重大科技基础设施，由中国科学院广州生物医药与健康研究院牵头，位于广州国际生物岛，规划建设周期 4.5 年，总建筑面积超 5 万平方米。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人员介绍，细胞是生命的基本单元。从受精卵开始，到发育成组织器官，再到衰老全过程中出现的所有细胞类型进行汇总和演变关系的绘制，就构成了「细胞谱系」。解析细胞谱系被誉为揭示生命发育与演变奥秘、操纵生命活动的「钥匙」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;533&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf7c06015d01a819ca8b5ea7cfba8024211.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该设施将以样品保活存储、空间多组学、先进成像等创新技术和装置研发为核心，集成人工智能等前沿技术，绘制涵盖发育、疾病、衰老三大维度的动态细胞图谱。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「这就像为生命编写一部详尽的‘细胞家谱’，让科学家乃至公众能够清晰追踪每个细胞的‘前世今生’。」广州健康院副院长、细胞谱系设施总指挥兼总工程师孙飞表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人员介绍，当前全球创新药研发耗时长、耗资大，但临床成功率低，部分原因在于药物研发主要在动物模型中进行，不能准确模拟人类生理系统反应。未来，细胞谱系设施有望用患者细胞信息打造一个「数字患者」，预演不同治疗手段在体内的治疗效果，实现「量体裁衣」式的精准治疗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;广州健康院研究员、细胞谱系设施副总指挥兼总工艺师陈捷凯表示，这一设施的建设将在生命科学仪器、试剂、软件和数据等方面产出一批创新性科技成果和产品，并进一步强化 AI 与数据资源整合，与龙头企业开展深度合作，加速科研成果向临床应用转化。（新华社，记者马晓澄、钟焯）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340845</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340845</guid>
            <pubDate>Sun, 23 Mar 2025 06:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>小鹏汽车公布双足机器人新专利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 APP 知识产权信息显示，广州小鹏汽车科技有限公司申请的「双足机器人的控制方法及电子设备」专利于 3 月 25 日公布。解决了相关技术中无法实现双足机器人单脚点地姿态的技术问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;310&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6ad6f0bc0677b09916d95d0fcf8a8f559d.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要显示，本发明公开了一种双足机器人的控制方法及电子设备。其中，该方法包括：响应于接收到双足机器人的控制指令，采集双足机器人的当前姿态，其中，控制指令中携带有双足机器人的姿态数据，姿态数据用于确定双足机器人的期望单脚点地姿态，期望单脚点地姿态用于表示期望在双足机器人对应支撑脚的足底区域接触地面的情况下，双足机器人对应摆动脚的足尖区域接触地面；基于当前姿态和期望单脚点地姿态，确定摆动脚的摆动脚移动轨迹和双足机器人对应机身的机身移动轨迹；基于摆动脚移动轨迹和机身移动轨迹控制双足机器人运行。本发明解决了相关技术中无法实现双足机器人单脚点地姿态的技术问题。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340843</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340843</guid>
            <pubDate>Sun, 23 Mar 2025 06:01:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>工作流自动化平台 Zapier 上线 MCP 服务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;工作流自动化平台 Zapier 近日上线了 Zapier MCP 服务，允许用户通过 Zapier 将他们的 Cursor AI 代理连接到各种应用程序，而无需复杂的 API 集成。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/114131_qF9e_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzapier.com%2Fmcp&quot;&gt;https://zapier.com/mcp&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Zapier MCP 服务赋予了 AI 助手强大的实用能力，包括自动化工作流程、管理数据、发送电子邮件、创建日历事件、更新数据库以及与其他应用进行实时交互等。无论是企业用户希望优化日常运营，还是个人用户想要简化繁琐任务，这一服务都提供了前所未有的便利。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/113921_nkJu_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;例如，AI 助手可以通过简单的配置，自动将会议安排记录到日历中，或根据需求从数据库中提取并整理数据，甚至与团队协作工具实时同步信息。&lt;/p&gt; 
&lt;p&gt;更值得一提的是，Zapier MCP 在权限控制方面表现出色。用户可以精确地定义 AI 助手能够执行的操作范围，细化到具体的应用程序、功能乃至特定字段。这种设计有效防止了 AI 滥用权限的风险。例如，用户可以设置 AI 助手仅限于向某个特定的 Slack 频道发送消息，或限制其只能访问指定的 GitHub 仓库。这种细粒度的控制不仅提升了安全性，也让 MCP 服务更具灵活性和实用性。&lt;/p&gt; 
&lt;p&gt;使用 Zapier MCP 的过程也极为简便。用户只需从 Zapier 平台复制一个专属的 URL，并将其集成到 AI 助手中，即可快速启用这些功能。无需复杂的编程或 API 对接，这一 「即插即用」 的特性大大降低了技术门槛，使得非专业人士也能轻松上手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340820/zapier-mcp-beta</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340820/zapier-mcp-beta</guid>
            <pubDate>Sun, 23 Mar 2025 03:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>韩国 AI 芯片创企 FuriosaAI 拒绝 Meta 8 亿美元收购要约</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;韩国当地媒体&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mk.co.kr%2Fnews%2Fit%2F11271852&quot; target=&quot;_blank&quot;&gt;报道称&lt;/a&gt;，专门生产 AI 应用芯片的韩国初创公司 Furiosa AI 与 Meta 的并购（M&amp;amp;A）谈判最终破裂。 Furiosa AI 没有出售经营权，而是选择走自己的发展道路，并表现出了在全球 AI 半导体市场上成为 Nvidia 替代品的强烈意愿。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;熟悉 Furiosa AI 的业内人士表示，「Meta 自去年 10 月开始，就一直在关注美国和以色列的几家 AI 半导体公司，最终选定 Furiosa AI 作为有力的收购目标，并于年初进入谈判阶段。据我了解，谈判破裂的原因并非在于价格问题，而在于双方无法缩小收购后的业务方向和组织架构方面的分歧。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;343&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-10135a5f0e88e69040878ac3f175b618862.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 提出的收购价格为 8 亿美元（约 1.2 万亿韩元），比市场评估的 Furiosa AI 的企业价值（约 8000 亿韩元）高出约 4000 亿韩元。对此，该相关人士表示「Furiosa AI 内部对收购价格进行了一些审查，但据报道，创始人白俊浩代表理事并不接受 Meta 并购后设想的经营方案」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，报道称 Furiosa AI 已从韩国企业银行获得 300 亿韩元的投资意向书（LOI），并正在与投资者洽谈筹集约 700 亿韩元，的资金，计划在本月完成融资。这些资金将用于为其 Renegade 芯片的量产做准备以及支付运营费用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;FuriosaAI 成立于 2017 年。目前该公司共开发了两款 AI 芯片，分别名为 Warboy 和 Renegade (RNGD)，以与 Nvidia 和 AMD 等公司竞争。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340819/furiosaai-turns-down-800m-acquisition-offer-meta</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340819/furiosaai-turns-down-800m-acquisition-offer-meta</guid>
            <pubDate>Sun, 23 Mar 2025 03:31:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>国家安全部通报：程序员带原单位涉密成果跳槽违反保密协议且触犯法律</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;国家安全部&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1bbY9zn_w5PAFKtP7qHL8Q&quot; target=&quot;_blank&quot;&gt;今日发布通报&lt;/a&gt;&lt;/u&gt;，提醒部分跳槽人员不能带着原单位的成果「投奔」新单位的行为，因为这不但违反了保密协议和竞业禁止协议，更是触犯了法律。&lt;/p&gt; 
&lt;p&gt;国家安全部原文如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;近年来，国家安全机关工作发现，个别涉密单位人员在离职后，明知违反保密规定，依然将在原单位工作期间的涉密成果作为「投名状」带到了新岗位，造成失泄密隐患。&lt;/p&gt; 
 &lt;h3&gt;心存侥幸不知过&lt;/h3&gt; 
 &lt;p&gt;徐某大学毕业后，一直在我某重点科研院所涉密岗位从事软件开发工作，长期接受保密教育。因与妻子两地分居，徐某决定离职和妻子一同到某市工作。经面试，徐某被该市某高新技术企业录用。&lt;/p&gt; 
 &lt;p&gt;从原单位离职前，徐某了解到新公司经营产品和自己在老东家接触的研究成果高度相似。于是，徐某打起了歪主意。适逢与外单位开展项目合作需要交接一批涉密电子文件，他趁机从原单位的软件配置管理库下载了一批涉密文件至工作电脑，以交接资料的名义经过审批后将相关涉密文件刻录成光盘，导入个人互联网笔记本电脑中。&lt;/p&gt; 
 &lt;p&gt;进入新单位后，徐某仍从事软件开发相关工作，自己带过来的「资源」似乎也确实发挥了一些作用。每念至此，徐某都不禁沾沾自喜，自认为神不知鬼不觉……&lt;/p&gt; 
 &lt;h3&gt;一错再错难回头&lt;/h3&gt; 
 &lt;p&gt;不久，新单位取得保密资质证书，可以参与部分涉密项目，徐某也被定级为一般涉密人员。因为有前期「成功」的操作经验，徐某在明知保密规章制度的情况下，还是屡次将新单位的涉密文件临时导入自己电脑，自认为用后删除就可以不留痕迹。直到被国家安全机关调查，徐某这才幡然醒悟，悔不当初。&lt;/p&gt; 
 &lt;p&gt;经查，徐某将原单位 25 份秘密级文件导入私人互联网笔记本电脑；将新单位 2 份涉密文件导入私人互联网笔记本电脑。鉴于接受询问期间，徐某态度积极，主动配合调查，且暂未发现其非法持有的涉密文件有被进一步泄露、传播的情况，未造成较大现实危害，国家安全机关会同有关单位依法对徐某作出行政处罚。&lt;/p&gt; 
 &lt;p&gt;对于涉事的两家单位，国家安全机关会同有关单位开展安全防范提醒，指导涉事单位以此为鉴，强化措施补足漏洞，排查安全防范风险隐患，进一步加强涉密人员离职期管理，落实安全防范措施。相关单位按照国家安全机关要求，落实整改措施，取得较好的效果。&lt;/p&gt; 
 &lt;h3&gt;国家安全机关提醒&lt;/h3&gt; 
 &lt;p&gt;部分跳槽人员心存侥幸，带着原单位的成果「投奔」新单位，不但违反了保密协议和竞业禁止协议，更是触犯了法律。《中华人民共和国反间谍法》第十四条规定，任何个人和组织都不得非法获取、持有属于国家秘密的文件、资料和其他物品。&lt;/p&gt; 
 &lt;p&gt;涉密人员一定要绷紧心中保密这根弦，严格遵守安全保密法律法规和单位保密制度，履行安全保密责任和义务，遵守脱密期管理规定，不得带离涉密业务件资料和物品（包含电子文档），以免贪小失大，铸成大错；相关单位须承担起反间谍安全防范责任，加强对本单位人员监督管理，加强对涉密事项、场所、载体和人员的日常安全管理，定期或不定期开展问题排查，及时发现问题隐患。&lt;/p&gt; 
 &lt;p&gt;如身边发现有类似情况，可通过 12339 国家安全机关举报受理电话、网络举报平台（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.12339.gov.cn&quot; target=&quot;_blank&quot;&gt;www.12339.gov.cn&lt;/a&gt;）、国家安全部微信公众号举报受理渠道反映，或者直接向当地国家安全机关进行举报。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1bbY9zn_w5PAFKtP7qHL8Q&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/1bbY9zn_w5PAFKtP7qHL8Q&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340818</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340818</guid>
            <pubDate>Sun, 23 Mar 2025 03:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>蔡崇信：「AI 基建」建设潮存在泡沫，美科技巨头投资很「盲目」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里巴巴集团董事会主席蔡崇信日前在香港举行的汇丰全球投资峰会上表示，开始看到人工智能（AI）数据中心建设出现泡沫苗头，他认为数据中心的建设速度可能会超过对人工智能服务的初期需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大型科技公司、投资基金和其他实体从美国到亚洲纷纷仓促建设服务器基地，这一现象开始显得有些盲目。美国的许多数据中心投资公告都是「重复」或相互重叠的，这可能导致资源浪费和过度竞争。例如，多家公司通过 SPAC（特殊目的收购公司）集资建设数据中心，但尚未签订实际用户协议，缺乏明确市场需求支撑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蔡崇信将泡沫风险归因于三类企业行为：专注模型研发的 OpenAI 类企业、专注基建的硬件供应商，以及阿里等综合型科技公司。他认为前两类企业的部分投资存在协同不足的问题，而阿里选择同时发展技术和基建，既能对外输出服务，又可支持自身研发。此外，中国公司 DeepSeek 以 560 万美元低成本开发出对标美国产品的大型语言模型（使用受限版 Nvidia 芯片），这引发对美企投资效率的质疑，可能加速泡沫破裂。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蔡崇信特别指出了美国的支出情况。仅在今年，亚马逊、Alphabet 和 Meta 就分别承诺在人工智能基础设施上投入 1000 亿美元、750 亿美元和 650 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蔡崇信对与会者说：「我仍然对美国在人工智能投资方面所提到的那些数字感到震惊。人们真的在谈论 5000 亿美元、数千亿美元这样的数字。我认为这并非完全必要。在某种程度上，我觉得人们的投资超前于他们目前所看到的需求，不过他们预计未来会有大得多的需求。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，行业内部对泡沫判断存在分歧。微软、Meta 等公司强调 AI 需求远超供给，计划继续扩大资本支出。Meta 称其新一代 Llama 4 模型需要比当前高 10 倍的计算资源。但蔡崇信指出，当前 AI 性能评估体系滞后于技术发展，部分基建可能因技术迭代而过早淘汰，特别是三级市场的训练数据中心面临适应性挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除行业分析外，蔡崇信还透露了阿里战略调整：员工数量触底后将重启招聘，通过股息回报股东。这显示阿里在警惕外部泡沫的同时，正强化内部竞争力。综合来看，AI 数据中心泡沫本质是技术爆发期资本过度追捧与市场需求不确定性的矛盾体现，其演化将取决于技术商业化进程与资源供给效率的平衡。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340816</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340816</guid>
            <pubDate>Sun, 23 Mar 2025 03:16:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek-V3 技术解析」：DeepSeekMoE</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 为什么说 DeepSeekMoE 的&quot;共享专家隔离&quot;设计，既能保留通用知识又能减少冗余？传统 MoE 的专家真的&quot;专精&quot;吗？传统 MoE 专家易&quot;崩溃&quot;，DeepSeekMoE 如何通过&quot;更细粒度的专家分割&quot;让每个专家专注更小领域，解决负载不均衡问题？&lt;/p&gt; 
 &lt;p&gt;作者巧妙地用餐厅厨师的比喻，将抽象的技术概念形象化 ------ 是聘用一位熟悉多种菜系的厨师，还是聘用多位各有专长的厨师更明智？随后，文章深入剖析了 DeepSeekMoE 的两大创新：更细粒度的专家分割通过增加专家数量并降低单个专家的参数规模，促进了专家的专业化；共享专家隔离则通过预留部分专家处理通用知识，减少了专家间的知识冗余。实验结果表明，在相同计算成本下，DeepSeekMoE 不仅性能更优，其专家的不可替代性也更强，知识冗余度更低。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shirley Li&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这是 DeepSeek-V3 系列的第二篇文章，本文将解析 DeepSeek[1,2,3] 模型的另一个关键架构创新：DeepSeekMoE[4]。&lt;/p&gt; 
&lt;p&gt;「DeepSeek-V3 技术解析」专栏其他文章：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/IDP/blog/17943880&quot;&gt;「DeepSeek-V3 技术解析」：多头潜在注意力机制（MLA）&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;具体而言，本文将解释混合专家系统（Mixture-of-Experts，MoE）的工作原理、为什么该技术在 LLMs 领域备受青睐及其面临的挑战。我们还将探讨 expert specialization（译者注：在 MoE 架构中，每个专家能够获取不重叠且聚焦的知识。） 与 knowledge sharing（译者注：指通过门控网络与专家模型的协同机制，使不同专家在独立处理特定任务的同时，仍能共享底层知识或通用特征，从而提升模型的整体性能和效率。） 之间的权衡，以及 DeepSeekMoE 如何实现更优的平衡。&lt;/p&gt; 
&lt;p&gt;最精彩的部分：&lt;strong&gt;为了让这些概念更直观，本文将通过餐厅这个场景来类比解析整个系统，借助厨房中厨师的角色来阐释 MoE 的各个要素。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本文目录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;技术背景&lt;/strong&gt;：介绍 MoE 的工作原理、优势与面临的挑战，探讨 expert specialization 与 knowledge sharing 之间的权衡&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeekMoE 架构&lt;/strong&gt;：解析更细粒度的专家分割（Fine-Grained Expert Segmentation）和共享专家隔离（Shared Expert Isolation）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;评估&lt;/strong&gt;：通过多个有趣实验讨论 DeepSeekMoE 的性能表现&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;01 技术背景&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 MoE（混合专家系统）在 LLM 中的应用&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 LLM（大语言模型）中，MoE 通常是指用 MoE 层替换 Transformer 模型中的 FFN（前馈神经网络）层，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ced184ccd8ce5f93b72ade1bc0267c3f444.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 1. MoE 层示意图，图片来自 GShard 论文[5]&lt;/p&gt; 
&lt;p&gt;具体来说，左侧展示的是由 N 个 Transformer 层组成的堆叠结构，每层包含一个 MHA（多头注意力）子层和一个 FFN 子层。而右侧展示的是由 N/2 个 Transformer 层组成的堆叠结构，其中下层 Transformer 的 FFN 子层被替换为 MoE 层。换言之，每隔一个 Transformer 层，其 FFN 子层就会被 MoE 层替代。实际应用中，可以按指定间隔将 FFN 替换为 MoE 层。&lt;/p&gt; 
&lt;p&gt;若进一步观察 MoE 层，会发现它包含一个门控（Gating）操作和一组具有相同架构的 FFN（与标准 FFN 子层一致）。这些 FFN 层在 MoE 中被称为&quot;专家&quot;，门控操作通过训练学习选择激活哪些专家来处理特定输入。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f6b88814ad22037e4841e1b3ee3b5961422.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 2. 包含门控操作和多个 FFN 专家的 MoE 层，图片来自文献[5]&lt;/p&gt; 
&lt;p&gt;MoE 的通用架构可形式化描述如下（公式编号沿用自文献[4]）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8a79193e3764eee82931b1ad7d0546ad52e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;u^l_t 和 h^l_t 分别表示第 l 层中第 t 个 token 的输入和输出的隐藏状态（hidden state）。&lt;/li&gt; 
 &lt;li&gt;FFN_i 是 N 个专家中的第 i 个专家。&lt;/li&gt; 
 &lt;li&gt;g_{i, t} 是第 t 个 token 对第 i 个专家的门控值，该值通过对 Softmax 的输出应用 TopK 操作获得。&lt;/li&gt; 
 &lt;li&gt;e^l_i 在公式 (5) 中常被称为第 i 个专家的&quot;质心（centroid）&quot;，可通过聚合历史上路由到该专家的所有输入 token 计算得到：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4e0de690fdfdeb20a97ac832e163f25785a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;该公式由原文作者创建&lt;/p&gt; 
&lt;p&gt;公式逐步解析（从公式 (5) 到公式 (3) 反向说明）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;公式 (5)：通过计算 u^l_t 与 e^l_i 的内积，衡量当前输入 token 与历史上路由到第 i 个专家的所有输入 token 的均值的相似度。若专家 i 处理过大量与当前 token 相似的输入，则其处理当前 token 的能力更强。随后对结果应用 Softmax，将其转换为概率分布。由于共有 N 个专家，每个 token 会得到 N 个 s_{i, t} 值。&lt;/li&gt; 
 &lt;li&gt;公式 (4)：对 s_{i, t} 值应用 TopK 操作，生成稀疏的 g_{i, t} 值。&lt;/li&gt; 
 &lt;li&gt;公式 (3)：利用稀疏的 g_{i, t} 值选择 K 个专家来计算输出的隐藏状态。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;换言之，对于第 t 个 token，仅会激活 N 个专家中的 K 个（通常 K 远小于 N），导致门控值 g_{i，t} 呈现稀疏性。通过这种设计，模型的可训练参数总量会因增加的 FFN 而上升，但前向传播时仅激活其中一小部分参数。&lt;/p&gt; 
&lt;p&gt;这正是采用 MoE 的 LLM 在描述模型规模时常用 &quot;总参数量 XX，其中每个 token 激活 YY&quot; 的原因 ------ 例如 DeepSeek-V3 ：&lt;/p&gt; 
&lt;p&gt;&quot;模型总参数量 2360 亿，每个 token 激活 210 亿参数......&quot;&lt;/p&gt; 
&lt;p&gt;那么，如果增加更多参数，MoE 有何优势？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 MoE 的优势与面临的挑战&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MoE 最妙的地方在于它体现了许多具有相似原理的现实场景，因此我们可以通过这些案例更直观地理解它。&lt;/p&gt; 
&lt;p&gt;现在假设我们要为一家同时提供中餐和意大利菜的餐厅雇佣厨师，有两种选择：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选项 1：雇佣一位同时精通中餐和意大利菜的厨师，这样他/她可以独自处理所有菜品。这类似于标准 Transformer 模型，由单个 FFN 子层处理所有输入 token。&lt;/li&gt; 
 &lt;li&gt;选项 2：雇佣多位各有所长的厨师（比如中餐专家和意大利菜专家），再加一位主厨根据订单内容指派擅长该菜系的厨师处理。这类似于 MoE 方法，每个厨师充当专家，主厨则作为门控机制（Gating）来选择专家。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过以上类比可以明显看出，选项 2 不仅更容易招聘人才，还能保证两种菜系都保持高水准。相比之下，要找到同时精通多种菜系的单一厨师难度极大（甚至不可能），我们可能不得不降低菜品质量要求。&lt;/p&gt; 
&lt;p&gt;回到 LLM 场景，构建 MoE 的动机部分源于&quot;扩展假说&quot;（scaling hypothesis），即在大规模数据上扩展 LLM 时更可能涌现出新的能力，这也是为什么我们看到现在 LLM 的规模越来越大的原因 ------ 比如 GPT 模型已从 117M 参数扩展到 175B 参数。&lt;/p&gt; 
&lt;p&gt;然而并非所有人都有机会训练如此大规模的 LLM，而 MoE 提供了一种折中方案：&lt;strong&gt;通过仅激活每个输入 token 对应的少量参数，我们可以在扩大模型规模（增加模型容量）的同时，保持训练和推理成本可控。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如文献[4]所示，你可以训练一个 2B 参数的模型仅激活 0.3B 参数，或训练 16B 参数模型仅激活 2.8B 参数，甚至还可以训练 145B 参数的模型仅激活 22.2B 参数。在每种情况下，每次仅使用总参数量的约 1/7，大大提升了训练和推理效率。&lt;/p&gt; 
&lt;p&gt;然而，每种设计都有其局限性，并会带来新的挑战。&lt;strong&gt;就 MoE 而言，其性能高度依赖门控机制的有效性 ------ 因为无法保证门控始终将每个输入 token 路由到最优专家，且可能出现少数专家处理大部分输入 token，而其他专家因缺乏训练机会无法充分发挥作用的现象。&lt;/strong&gt; 这通常被称为&quot;专家崩溃&quot;（expert collapse）问题。&lt;/p&gt; 
&lt;p&gt;这还会导致其他问题，例如负载不均衡（多数 token 被路由到少数专家）和不稳定性（当 token 被路由到未经充分训练的专家时效果欠佳）。&lt;/p&gt; 
&lt;p&gt;这就是为什么我们在 MoE 架构领域中经常能够看到大量关于负载均衡的讨论。&lt;/p&gt; 
&lt;p&gt;DeepSeekMoE 也提出了若干负载均衡策略，但本文将聚焦其核心创新点，关于无辅助损失负载均衡（auxiliary-loss-free load balancing）[8]的深入解析将在后续文章中展开。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 Knowledge Specialization vs. Knowledge Sharing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在上述餐厅案例中，我们做雇佣决策时其实也在权衡 expert specialization（译者注：在 MoE 架构中，每个专家能够获取不重叠且聚焦的知识。） 与 knowledge sharing（译者注：指通过门控网络与专家模型的协同机制，使不同专家在独立处理特定任务的同时，仍能共享底层知识或通用特征，从而提升模型的整体性能和效率。）：选项 1 追求通才但可能牺牲技能深度，选项 2 追求专精。这种权衡广泛存在于现实场景的各类组织中（如企业、团队等）。&lt;/p&gt; 
&lt;p&gt;在 MoE 中这种权衡同样存在，但呈现形式更为隐晦。理论上，每个专家都应具备特定领域的专长，因为每个专家仅处理部分输入 token；同时所有专家仍会共享部分通用知识，因为它们共享大量参数。与现实场景不同，我们很难界定每个专家的专精程度及他们掌握的通用知识范围的边界。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;权衡 expert specialization 与 knowledge sharing 是 MoE 架构设计的关键考量因素，因为过度专精与过度冗余均非理想状态。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前一种情况下，过度专精的专家会导致训练和推理的不稳定，任何次优的路由都可能显著影响性能。同时这往往会造成模型容量利用率不足，因为高度专精的专家只能处理极少数 token。&lt;/p&gt; 
&lt;p&gt;在后一种情况下，若专家间掌握的知识过于相似，MoE 引入的额外参数将无法带来成比例的容量提升，这显然是对有限计算资源的浪费。&lt;/p&gt; 
&lt;p&gt;下一节我们将看到 DeepSeekMoE 如何实现两者的更优平衡。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeekMoE 架构&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeekMoE 通过两项关键技术创新来平衡 MoE 中的 knowledge specialization 和 knowledge sharing，即更细粒度的专家分割（fine-grained expert segmentation）和共享专家隔离（shared expert isolation）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fa5bc97296f68f5b7ba2bfb1f829780de51.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 3. DeepSeekMoE 示意图。图片来自文献[4]。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 更细粒度的专家分割&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeekMoE 提出更细粒度的专家分割以促进专家的专业化，提出该技术的想法非常简单：&lt;strong&gt;对于每个输入 token，如果有更多专家被激活，那么处理该 token 所需的知识就更有可能被分解并由不同专家获取。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前文的餐厅案例中，就类似于将每位厨师的技能进行专业化拆分，如下图所示。最初，我们让一位厨师负责所有中餐，另一位负责所有意大利菜。应用更细粒度的专家分割（fine-grained expert segmentation）后，每种菜系所需的技能被拆分给多个专家掌握，于是我们得到一组专精中餐的厨师和另一组专精意大利菜的厨师，每位厨师只需掌握该菜系的特定技能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f91fdf07e11b67ac56a9fb4a7c900094672.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 4. 用餐厅案例说明 (a) 应用前和 (b) 应用更细粒度的专家分割后的对比。由原文作者供图。&lt;/p&gt; 
&lt;p&gt;图 3 也说明了这一点：子图 (a) 中每个输入 token 被路由到 N 个专家中的 2 个，而子图 (b) 中每个 token 被路由到 2N 个专家中的 4 个。在更一般的情况下，我们可以将专家数量从 N 增加到 mN，同时将每个专家 FFN 的中间隐藏层维度降至 1/m，并为每个输入 token 激活 m 倍的专家数量。通过这种方式，(a) 和 (b) 的总体计算成本将大致保持相同。&lt;/p&gt; 
&lt;p&gt;尽管作者未对该策略的有效性提供理论证明，但他们确实设计了实验来验证这一思路，我们将在&quot;评估&quot;部分详述。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 共享专家隔离&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeekMoE 提出的另一项技术是隔离部分共享专家以减少冗余，提出该技术的核心想法在于：&lt;strong&gt;若预留部分共享专家来学习不同任务的通用知识，可给其他专家更多的自由来剥离此类通用知识，从而减少非共享专家间的冗余。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前文提到的餐厅案例中，这就类似于将所有厨师进一步划分为两组（如下图所示）：上方第一组厨师掌握刀工、火候、调味等通用烹饪技能，下方第二组厨师专注于自己的特色菜品。&lt;/p&gt; 
&lt;p&gt;例如，包饺子的师傅只需专注包捏与蒸煮饺子，无需考虑摆盘技巧；意面师傅只需钻研意面的制作，无需学习刀工。由此减少厨师间的知识冗余。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3eea41c211b4e69c8b2c60abde72860bef2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 5. 基于图 4 的餐厅案例，进一步添加共享专家隔离的示意图。由原文作者供图。&lt;/p&gt; 
&lt;p&gt;图 3 (c) 也展示了该策略的实现方式：选定一个专家作为共享专家（绿色高亮标记），所有输入 token 均不经路由层（Router）直接激活该专家，同时将激活的专项专家数量从 4 个减至 3 个，使总激活专家数量与图 3 (b) 保持相同。&lt;/p&gt; 
&lt;p&gt;综上，DeepSeekMoE 架构可形式化表示为下图右侧公式（左侧为传统 MoE 架构作为对比）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-80ce0a46d0641ef3f9e7ccb193aca0af1b4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 6. (左) 传统 MoE vs. (右) DeepSeekMoE。作者根据文献 [4] 中的公式绘制该图。&lt;/p&gt; 
&lt;p&gt;其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;式 (11) 与传统 MoE 的式 (5) 相同&lt;/li&gt; 
 &lt;li&gt;式 (10) 与式 (4) 类似，但此处通过 TopK 从 (mN-K_s) 个专家中选择 (mK-K_s) 个，K_s 表示共享专家数量&lt;/li&gt; 
 &lt;li&gt;式 (9) 将式 (3) 的第一项拆分为两个子项，分别对应共享专家与路由专家&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;原文同样未对该策略提供理论证明，但后续评估结果表明：&lt;strong&gt;引入共享专家既能提升性能，又能有效降低知识冗余。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 Evaluation&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;正如前文所述，尽管两项策略的直觉依据看似合理，但作者并未提供理论证明，因此我们仍需验证：这些策略是否真能缓解 expert specialization（译者注：在 MoE 架构中，每个专家能够获取不重叠且聚焦的知识。） 与 knowledge sharing（译者注：指通过门控网络与专家模型的协同机制，使不同专家在独立处理特定任务的同时，仍能共享底层知识或通用特征，从而提升模型的整体性能和效率。）的冲突？其有效性程度如何？&lt;/p&gt; 
&lt;p&gt;我们主要关注三个核心问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeekMoE 能否取得更好效果？&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更细粒度的专家分割能否促进 expert specialization？其作用程度如何？&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;共享专家隔离能否减少冗余？其作用程度如何？&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为解答这些问题，作者设计了系列实验，在此有必要详述。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 DeepSeekMoE 能否取得更好效果？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先验证该方法能否提升整体性能。作者训练了总参数/激活参数规模相当的多个模型，并在不同任务上评估它们的性能。主要结果如下表所示（最优指标用粗体标注）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-409e0f09e7147196f8e5f475b7bbad25372.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 7. 整体性能对比。作者根据文献 [4] 表 1 整理。&lt;/p&gt; 
&lt;p&gt;几点启示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;蓝色高亮列对比标准 Transformer（Dense）与两种 MoE 架构（Hash Layer [6]和 Switch Transformer [7]）：在激活参数量相近时，MoE 架构性能显著更优。&lt;/li&gt; 
 &lt;li&gt;绿色高亮列进一步比较了 DeepSeekMoE 与另一种 MoE 方法 GShard [5]：在激活参数量相近时，DeepSeekMoE 性能明显更优。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;但性能提升并不直接等同于更好地平衡了 expert specialization 与 knowledge sharing 的冲突，因此仍需其他实验验证。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 DeepSeekMoE 是否促进了专家的专业化？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;直接衡量专家的专业化程度较为困难，作者转而设计了一项反向实验：禁用部分高优先级路由专家并观察性能变化。&lt;/p&gt; 
&lt;p&gt;从直觉上讲，专家专业化程度越高时其不可替代性越强，因此禁用高优先级路由专家应该会导致更明显的性能下降。&lt;/p&gt; 
&lt;p&gt;更具体一点，作者在 DeepSeekMoE 和 GShard x 1.5（作为 baseline）中逐步禁用高优先级路由专家。两种方法在未禁用专家时的 Pile loss 相当（对应下图中禁用比例为 0 时的最左侧数据点）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-af7e24704358701ad717f6b843a4b90c45d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 8. 禁用高优先级路由专家时 DeepSeekMoE 与 GShard x 1.5 的 Pile loss 对比。图片来自文献[4]。&lt;/p&gt; 
&lt;p&gt;随着禁用路由专家比例的增加，DeepSeekMoE 的 Pile loss 持续高于 baseline，表明其路由专家具有更强的专业性，因此更难被其他专家替代。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 DeepSeekMoE 是否能够减少知识冗余？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;按照类似的思路，作者还尝试禁用共享专家并额外激活了一个路由专家，以观察共享专家是否可被替代。&lt;/p&gt; 
&lt;p&gt;实验结果显示&quot;Pile loss 从 1.808 明显上升，至 2.414&quot;，这证明了共享专家学习的知识具有独特性，而路由专家未能充分覆盖该部分知识。换言之，路由专家具有更高专业性且冗余度更低。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Summary&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本文通过餐厅案例进行类比，解析了 DeepSeek-V2、DeepSeek-V3 等模型的核心架构创新之一 ------ DeepSeekMoE。&lt;/p&gt; 
&lt;p&gt;具体而言，本文首先介绍了通用 MoE 的工作原理、优势及面临的挑战，以及 expert specialization 与 knowledge sharing 之间的权衡关系。随后重点解析了 DeepSeekMoE 的两大核心设计：更细粒度的专家分割（fine-grained expert segmentation）与共享专家隔离（shared expert isolation），并通过实验验证了其有效性。&lt;/p&gt; 
&lt;p&gt;核心结论：DeepSeekMoE 在保持与通用 MoE 架构相当计算成本的条件下，通过促进专家的专业化实现了更优效果，从而实现更高的计算效率。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] DeepSeek（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepseek.com%2F%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://www.deepseek.com/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] DeepSeek-V3 Technical Report（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FDeepSeek-V3%2Fblob%2Fmain%2FDeepSeek_V3.pdf%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2401.06066）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2006.16668%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2006.16668）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] Hash Layers For Large Sparse Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2106.04426%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2106.04426）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2101.03961%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2101.03961）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2408.15664%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2408.15664）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Shirley Li&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I am a Machine Learning Engineer working on building multi-modality models to solve real-world problems.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;文章中的餐厅厨师类比是否帮助你理解了这个概念？如果让你用身边的例子来解释 DeepSeekMoE 架构，你会用什么比喻？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.gopubby.com%2Fdeepseek-v3-explained-2-deepseekmoe-106cffcc56c1&quot; target=&quot;_blank&quot;&gt;https://ai.gopubby.com/deepseek-v3-explained-2-deepseekmoe-106cffcc56c1&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17961367</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17961367</guid>
            <pubDate>Sun, 23 Mar 2025 03:11:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>ARC-AGI-2 基准测试发布：AI 模型表现惨淡，效率指标成智能评估新维度</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Arc Prize Foundation 近日推出全新 AGI 基准测试&lt;strong&gt;ARC-AGI-2&lt;/strong&gt;，旨在更精准衡量 AI 模型的通用智能水平。&lt;/p&gt; 
&lt;p&gt;测试结果显示，当前主流模型的平均得分仅为 1%-1.3%，远低于人类平均 60% 的基准。该测试由知名 AI 研究者 François Chollet 联合发起，通过视觉逻辑谜题评估 AI 的跨领域推理能力，并首次引入「效率」指标，直指行业长期忽视的算力成本问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;测试设计：防止暴力破解，强调模式泛化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;ARC-AGI-2 由多色方格组成的动态谜题构成，要求 AI 从未见过的模式中推导答案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a37b4b4ccb6de16539a4e754d02e1504cfa.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;相比前代测试，新版通过两项关键改进堵住漏洞：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;禁止训练数据复用&lt;/strong&gt;：答案无法通过简单记忆获得，需实时推理&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;效率约束&lt;/strong&gt;：要求每道题算力成本不超过$0.42（OpenAI 此前在 ARC-AGI-1 中单题耗资$200）&lt;br&gt; Chollet 在社交平台强调，新测试更接近「真实智能」——即用有限资源快速掌握新技能的能力（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ffchollet%2Fstatus%2F123456789&quot; target=&quot;_blank&quot;&gt;X 推文&lt;/a&gt;）。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;模型表现：顶级选手集体翻车&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;根据&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farcprize.org%2Fleaderboard&quot; target=&quot;_blank&quot;&gt;Arc Prize 榜单&lt;/a&gt;，当前表现最佳的模型包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI o1-pro&lt;/strong&gt;：1.3%（推理型）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek R1&lt;/strong&gt;：1.1%（推理型）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPT-4.5/Claude 3.7/Gemini 2.0&lt;/strong&gt;：约 1%（非推理型）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对比人类测试者平均 60% 的正确率，差距显著。值得注意的是，此前在 ARC-AGI-1 中达到人类水平的 OpenAI o3（低配版），在 ARC-AGI-2 中仅获 4% 得分，突显新测试的挑战性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e504f2c4b02012584b8e6ce920c3e0ab9c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;行业启示：算力竞赛转向效率战场&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Arc Prize 联合创始人 Greg Kamradt 在&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farcprize.org%2Fblog&quot; target=&quot;_blank&quot;&gt;博客&lt;/a&gt;中指出，AI 行业需重新定义智能标准：「如果解决一个问题需要消耗一座核电站的能源，这种‘智能’对人类社会毫无意义。」&lt;/p&gt; 
&lt;p&gt;该观点与 Hugging Face 联合创始人 Thomas Wolf 近期呼吁相呼应——行业亟需能衡量创造力、成本效益的新评估体系。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;开发者挑战：$0.42 预算冲击 85% 准确率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;伴随新测试发布的还有&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farcprize.org%2Fcontest&quot; target=&quot;_blank&quot;&gt;Arc Prize 2025 竞赛&lt;/a&gt;，要求参赛者在单题$0.42 的算力约束下冲击 85% 准确率。这场低成本高难度的挑战，或将推动小参数模型与新型训练范式的突破。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;最后欢迎大家参加讨论：当算力成本成为智能评估标准，MoE 架构与蒸馏技术会否迎来新爆发？&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340814/a-new-challenging-agi-test-stumps-most-ai-models</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340814/a-new-challenging-agi-test-stumps-most-ai-models</guid>
            <pubDate>Sun, 23 Mar 2025 03:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>mcp-filesystem-server —— Go 实现的模型上下文协议</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;一个用 Go 语言实现的模型上下文协议（Model Context Protocol, MCP）项目，旨在实现大语言模型（LLM）应用与外部数据源及工具的无缝集成。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;该项目的主要目的是学习&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;github.com/metoro-io/mcp-golang&lt;/code&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;。由于&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;github.com/mark3labs/mcp-filesystem-server&lt;/code&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;已存在文件系统服务器实现，本项目也基于此进行开发。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/mcp-filesystem-server</link>
            <guid isPermaLink="false">https://www.oschina.net/p/mcp-filesystem-server</guid>
            <pubDate>Sun, 23 Mar 2025 02:59:00 GMT</pubDate>
        </item>
        <item>
            <title>猎豹移动 CEO 傅盛：最近沉迷敲代码，打算让所有员工都去学习 AI 编程</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;3 月 23 日，猎豹移动 CEO 傅盛在社交平台&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1554710050%2FPjQReaWyL%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;发布视频称&lt;/a&gt;&lt;/u&gt;，自己最近沉迷敲代码，还打算让所有员工都去学习 AI 编程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/105435_G9Ao_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;傅盛称，自己大学毕业以后就没真正写过程序，就当一个产品经理。现在产品经理要被淘汰了，人人都是程序员了。视频中，傅盛还谈及「AI 编程都这么厉害了，还有没有必要学编程」的问题。&lt;/p&gt; 
&lt;p&gt;傅盛表示，AI 能写代码和学编程完全不冲突，因为程序就是构建我们未来世界的基础。傅盛称，学代码有两个好处，尤其是青少年。第一个是学习编程以后，才知道未来的世界是如何运作，得懂基本原理。第二个，由于 AI 编程很厉害，所以现在学编程能极大提高工作效率。他觉得不仅是青少年要学编程，每个人都应该学编程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/340717/ibms-ceo-doesnt-think-ai-will-replace-programmers-anytime-soon&quot; target=&quot;news&quot;&gt;IBM CEO：AI 短期内不会取代程序员&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338784&quot; target=&quot;news&quot;&gt;计算机科学家吴恩达对「AI 将取代程序员」的看法&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/338372/anthropic-ceo-ai-will-be-writing-90-of-code-in-3-6-months&quot; target=&quot;news&quot;&gt;Anthropic CEO：未来 3-6 个月内，90% 的代码将由 AI 编写&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/337519/anthropic-mike-krieger-how-software-engineering-work-changing&quot; target=&quot;news&quot;&gt;未来三年，软件工程师或将转型为 「AI 代码审核员」&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/259402&quot; target=&quot;news&quot;&gt;GitHub CEO：AI 无法取代程序员&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/282381&quot; target=&quot;news&quot;&gt;李彦宏：未来可能不会存在程序员这种职业&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340806</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340806</guid>
            <pubDate>Sun, 23 Mar 2025 02:56:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 领导层改组，CEO 奥尔特曼将更专注于研究和产品开发</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fleadership-updates-march-2025%2F&quot; target=&quot;_blank&quot;&gt;OpenAI 宣布领导层改组&lt;/a&gt;&lt;/u&gt;，首席执行官萨姆・奥尔特曼（Sam Altman）将更专注于研究和产品开发。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/104903_xosp_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;奥尔特曼表示，随着公司业务规模持续扩张，三位核心高管将承担更多职责，以推动前沿 AI 研究并加速实现造福全人类的 AGI 使命。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;马克・陈（Mark Chen）升任首席研究官（Chief Research Officer）：统筹科研进展，确保在 AI 能力与安全领域持续突破。他将加强研究与产品开发整合，加速科研成果向用户喜爱产品的转化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;首席运营官（Chief Operating Officer）布拉德・莱特卡普（Brad Lightcap）职权进一步扩展：全面负责公司业务与日常运营，重点包括领导全球部署，聚焦商业战略、关键合作伙伴关系、基础设施与卓越运营。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Julia Villagra 上任首席人才官（Chief People Officer）：继续支持公司全球扩张，确保 OpenAI 持续吸引顶尖 AGI 人才等等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340803/openai-leadership-updates-march-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340803/openai-leadership-updates-march-2025</guid>
            <pubDate>Sun, 23 Mar 2025 02:49:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>华为前副总裁加入智元机器人，任董事长兼 CEO</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;据国家企业信用信息公示系统网站，近期上海智元新创技术有限公司（简称「智元机器人」）发生工商变更，公司注册资本增加至 8,045.8159 万元，值得关注的是，公司法定代表人由舒远春变更为邓泰华。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/103603_nnhN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据中证金牛座从知情人士处了解到，邓泰华已担任智元机器人董事长、CEO。邓泰华是华为公司原副总裁、计算产品线原总裁。&lt;/p&gt; 
&lt;p&gt;而在昨日，据科创板日报报道，从知情人士方面了解到，智元机器人近期已完成了新一轮融资，腾讯领投。此次是腾讯投资在具身智能领域首次出手，本次有多家产业方及老股东跟投，包括龙旗科技、卧龙电气、华发集团、蓝驰创投等。据了解，智元机器人还在以 150 亿估值进行新一轮融资接洽。&lt;/p&gt; 
&lt;p&gt;智元机器人由原「华为天才少年」彭志辉（稚晖君）所创立，专注于具身智能。2024 年 9 月，智元机器人完成了 A++ 轮融资，并且估值已经超过 70 亿元人民币。&lt;/p&gt; 
&lt;p&gt;近日，智元机器人正式发布其最新研发的全能探索机器人「灵犀 X2」以及首个通用具身基座大模型「智元启元大模型（Genie Operator-1）」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/340642&quot; target=&quot;news&quot;&gt;腾讯领投，智元机器人完成新一轮融资&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/337908&quot; target=&quot;news&quot;&gt;智元发布首个通用具身基座大模型 GO-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/333319&quot; target=&quot;news&quot;&gt;稚晖君创业公司智元近日在深圳新设立「灵犀」产品线&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340801</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340801</guid>
            <pubDate>Sun, 23 Mar 2025 02:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度搜索 T11 职级大神辜斯缪离职</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5v7nsBbMpTZ4ou0_MGqPlw&quot; target=&quot;_blank&quot;&gt;据知情人士透露&lt;/a&gt;&lt;/u&gt;，百度搜索策略首席架构师（T11）辜斯缪离职，去向暂时未知。&lt;/p&gt; 
&lt;p&gt;据公开信息，辜斯缪毕业于北京交通大学，2009 年加入百度，任职于百度核心搜索部门，曾负责百度搜索时效性、需求分析、阿拉丁策略、知识图谱建设、搜索推荐、百度信息流和交互算法等业务。&lt;/p&gt; 
&lt;p&gt;2017 年，任职于百度推荐技术平台部，主要负责百度内容消费体系中基础排序和召回算法、垂直推荐技术、推荐中台化、微视频推荐技术等。&lt;/p&gt; 
&lt;p&gt;在百度的 T 序列职级中，T12 级是最高的，但百度 25 年的历史上，只有威廉张和吴恩达这两位百度首席科学家是 T12。T11 基本是工程师的天花板了，百度在职的 T11 职级人数也就十个人左右。&lt;/p&gt; 
&lt;p&gt;此前，百度比较有名的 T11 有，前百度云与大数据首席架构师林仕鼎、前百度美研主任架构师、百度无人车首席架构师、小马智行联合创始人彭军（小马智行另外一个联合创始人，楼天城的职级是 T10）、前小度 CTO 朱凯华等。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340799</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340799</guid>
            <pubDate>Sun, 23 Mar 2025 02:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>苹果 AI 中文版即将正式登场</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;今日，苹果向 iPhone 和 iPad 用户推送了 iOS / iPadOS 18.4 RC 更新（内部版本号：22E239），本次更新距离上次发布 Beta / RC 间隔 7 天。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/102757_0aOt_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中 Apple 智能（Apple Intelligence）新增支持法语、德语、意大利语、葡萄牙语（巴西）、西班牙语、日语、韩语和&lt;span style=&quot;color:#16a085&quot;&gt;&lt;strong&gt;简体中文&lt;/strong&gt;&lt;/span&gt;，以及新加坡和印度的本地化英语。而这也意味着，国行版的苹果 AI 又能再进一步。&lt;/p&gt; 
&lt;p&gt;此外，iOS 18.4 引入了「优先级通知」功能，系统会自动判断哪些通知最为重要，并在锁屏上以醒目方式展示；而 AI 图片生成功能 Image Playground 新增「手绘风格」选项，用户可以生成类似手绘的图像。&lt;/p&gt; 
&lt;p&gt;此前，据彭博社报道，有知情人士透露，苹果公司计划在 2025 年中期之前，在国行版 iPhone 上引入 AI 功能。在 2 月 13 日，在阿联酋迪拜举办的 World Governments Summit 2025 峰会上，阿里巴巴联合创始人、董事局主席蔡崇信&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333543&quot;&gt;确认&lt;/a&gt;&lt;/u&gt;了苹果与阿里巴巴共同中国 iPhone AI 功能一事。&lt;/p&gt; 
&lt;p&gt;同时，据 The Information 报道，有两位知情人士透露，虽然苹果公司已经与阿里巴巴达成合作，将为国行版的 iPhone 用户提供 AI 功能，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333667/apple-continues-to-work-with-baidu-on-a&quot;&gt;但苹果仍在继续与百度合作&lt;/a&gt;&lt;/u&gt;，共同为中国的 iPhone 用户开发人工智能功能。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/news/338319&quot;&gt;苹果智能（Apple Intelligence）中文版要来了&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/337918/apple-says-some-ai-improvements-siri-delayed&quot; target=&quot;news&quot;&gt;苹果推迟上线 Siri 中的 AI 相关功能&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340797</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340797</guid>
            <pubDate>Sun, 23 Mar 2025 02:29:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>