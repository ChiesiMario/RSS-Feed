<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 11 Jun 2025 07:41:37 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>开源网盘应用 Alist 原开发者称项目已交由公司运营</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免费开源、支持多存储的自建网盘程序 (文件列表程序)，可以轻松在 VPS 服务器、NAS、普通电脑 Win、Mac、Linux 上部署。它除了能作为一款自建网盘 (将文件保存在设备硬盘上) 外，最大的特色就是支持「挂载各大主流网盘」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在该项目 GitHub 仓库提交 issue，反馈官网出现 404 问题，并提出」项目是否被卖了」的疑问。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原开发者 Xhofe 今日在订阅频道发布公告，&lt;strong&gt;称项目已交由公司运营&lt;/strong&gt;，之后会帮助审查开源版本仓库的代码，确保 release 分支由 CI 自动构建。此外&amp;nbsp;main 分支已开启分支保护，后续所有提交均需经过 PR 审核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Wed, 11 Jun 2025 07:06:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式发布了豆包大模型 1.6、豆包·视频生成模型 Seedance 1.0 pro、豆包·语音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新发布的豆包大模型 1.6 系列由三个模型组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的综合模型，是国内首个支持 256K 上下文的思考模型，支持深度思考、多模态理解、图形界面操作等多项能力。支持选择开启或关闭深度思考、自适应思考三种方式，其中自适应思考模式可根据提示词难度自动决定是否开启思考，提升效果的同时大幅减少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的强化版本；在代码、数学、逻辑推理等基础能力上进一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的极速版本，支持深度思考、多模态理解、256K 上下文；延迟极低，TOPT 仅需 10ms；视觉理解能力比肩友商旗舰模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在价格方面，&lt;strong&gt;豆包大模型 1.6 采用统一定价模式，首创按「输入长度」区间定价&lt;/strong&gt;，在企业使用最多的输入区间 0-32K 范围内，豆包大模型 1.6 的价格为输入 0.8 元/百万 tokens、输出 8 元/百万 tokens，综合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相当于每生成一条 5 秒的 1080P 视频只需 3.67 元，行业最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·实时语音模型已全量上线火山方舟，对企业客户开放使用。该模型支持自然语言高级指令控制，具备唱歌表演、声线模仿、方言演绎等多种能力，语气、用语、思考方式等拟人感大幅提升，能随时打断与主动搭话。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sun, 11 May 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供为期两周的免费 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 与 AI 代码工具开发商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，为 Cline 用户提供为期两周的 Grok 3 模型免费访问权限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需注册 Cline 账户，即可在 Cline 的提供商中选择并免费使用 x-ai/grok-3 模型进行编码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是开源 AI 编程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 双模式，具有终端执行能力和 Model Context Protocol (MCP) 特性。它能够分析用户的项目文件结构、源代码等，帮助用户创建和编辑文件、执行终端命令、使用浏览器进行测试等，还可以通过 MCP 协议扩展其功能，添加自定义工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sun, 11 May 2025 06:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再获数千万美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣布再次完成数千万美元的 Pre-A+轮融资，同时正式发布了全球首个 AI 驱动的一站式 3D 工作台 Tripo Studio，并即将推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;据称此次融资将重点投入 Tripo 系列大模型研发及 Tripo Studio 产品及生态平台建设，加速构建「AI+3D」全产业链条，打造「基础模型 + 生态插件 + 原生工作台」的端到端产品体系，从而构建覆盖专业级（PGC 生产者）、达人级（PUGC 创作者）到大众级（UGC 用户）的创作者画像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，VAST 成立于 2023 年 3 月，是一家专注于通用 3D 大模型研发的 AI 公司，致力于通过打造大众级 3D 内容创作工具建立 3D UGC 内容平台，使基于 3D 的空间成为用户体验升级、内容表达创新和新质生产力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持续迭代 Tripo 大模型，先后推出 Tripo1.0 至 Tripo2.5 等数十亿参数规模的 3D 大模型系列，同时发布 TripoSR、TripoSG、TripoSF 等广受全球开源社区认可的 3D 基础模型，并配套开发了系列 3D 软件生态插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新开源：通用自动骨骼绑定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 开源基础 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sun, 11 May 2025 03:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度百舸万卡集群的训练稳定性系统设计和实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 训练稳定性的演进历程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 竞赛中 AlexNet 的横空出世，开启了现代 AI 发展的新纪元。彼时我们不会想到，十年后支撑 AI 训练的 GPU 集群会从研究室里的几台服务器，发展成需要专门供电系统的万卡级计算矩阵。在这个算力爆发式增长的过程中，训练系统的稳定性管理正经历着从「简单运维」到「精密工程」的深刻变革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 标早期的小模型时代：手动运维的黄金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 训练，更像是手工作坊式的精雕细琢。大多数训练任务只需十几块 GPU，利用 PyTorch 或 TensorFlow 的数据并行功能就能轻松应对。记得那时算法工程师们有个共识：如果训练遇到问题，重启往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;当时我们构建的监控系统就像汽车仪表盘，只能显示最基本的任务状态。当训练意外中断时，工程师们会像侦探一样翻查日志 —— 如果发现是 GPU 报错，就联系运维同事。运维人员则带着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到机房巡检，像老中医把脉般通过温度、功耗等指标判断硬件状态。这种工作模式虽简单，但应对数十卡规模的集群还算游刃有余。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型风暴：从量变到质变的冲击&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登场如同打开潘多拉魔盒，将 AI 训练带入新的纪元。当我们开始部署千卡/万卡集群时，才发现原有的运维体系就像用小渔网捕鲸鱼 —— 完全无法匹配新需求。&lt;/p&gt; 
&lt;p&gt;让我们通过百度百舸经历过的一个真实案例来深入理解这个问题：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸帮助一家 AIGC 创业公司迅速将其训练规模从百卡扩展到千卡级别。然而在训练数天后的某个周末凌晨，训练进程意外发生了 hang 死。由于当时缺乏有效的故障感知和容错机制，直到第二天算法工程师发现任务超时退出时，已经耽误了数小时宝贵的训练时间。更糟糕的是，任务日志中除了简单的 timeout 报错外毫无线索，平台监控也显示所有训练节点状态正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢复训练的算法工程师没有立即上报问题，而是选择直接重新提交任务。但不幸的是，新任务运行数小时后再次出现相同的超时退出。这时他们才不得不寻求技术支持，但值班工程师面对这种任务 hang 死的问题也缺乏诊断经验，只能通过二分法慢慢定位。最终发现是某个节点的静默故障（SDC）导致了训练进程假死。等问题得到解决时，距离首次故障已经过去将近 30 小时，这意味着损失了价值巨大的千卡算力资源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集群训练稳定性全景图&lt;/h1&gt; 
&lt;p&gt;站在现在的时间点回望，AI 训练稳定性已从辅助功能演变为核心基础设施。就像现代建筑中的抗震结构，它虽不直接参与空间构成，却是万丈高楼得以屹立的关键。当行业向着数万卡集群迈进时，这套隐形护甲的质量，将直接决定 AI 进化的速度与边界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸对训练过程的生命周期进行了更细致的拆分，提出了「无效训练时间」这一关键指标，并致力于将其最小化。具体来说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任务无效训练时间 = 故障中断次数 × 任务故障恢复时长 + 任务常态写 Ckpt 总时长&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任务故障恢复时长 = 故障感知召回耗时（自动/人工定位）+ 任务调度耗时 + 任务初始化耗时 + 任务重算时长。&lt;/p&gt; 
&lt;p&gt;通过这个公式可以看出，要降低无效训练时间，需要「围绕基础设施稳定性」、「任务容错」两个维度来系统展开，重点解决三个方面的问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基础设施的交付质量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任务故障容错的召回率、准确率和时效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化 checkpoint 机制，减少保存时间和恢复时的重算时间。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过容错架构的整体变革，百度百舸形成了从 「任务负载 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基础架构」全链路的自动异常感知、诊断、恢复能力，可覆盖 90%+ 的训练异常场景，时效性最快可以实现秒级异常感知、分钟级定位，以及平均 3 分钟的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基础设施交付质量保障&lt;/h1&gt; 
&lt;p&gt;基础设施的交付质量保障是稳定性的基础。&lt;/p&gt; 
&lt;p&gt;CPU 时代，机器的交付前可能仅会跑一些常规的 CPU 计算、网络的压力测试，并不会从业务视角去评估基础架构，机器交付后硬件异常的故障频率相对较少。有硬件故障时，通常走工单系统人工换机用户相对是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 时代，AI Infra 的交付则需要考虑 CPU、GPU、RDMA 网络、存储，甚至机房的功率、温度等各方面因素，遗漏任何一个环节都会成为后续稳定性的隐患。在交付给客户后，机器也可能会由于长时间的高负载运行频繁出现硬件故障，而 GPU 机器的高昂成本，使客户对节点故障感知、换机的时效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸对 GPU 机器交付前及交付后的稳定性质量进行了系统性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸会对机器进行 200 多项指标检测，然后进行 48 小时烤机，以及 NCCL-Test 的机内、机间的大环、同号卡通信性能基准测试，端到端的大模型训练、推理性能基准测试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付后，需要能够实时的感知节点故障及定期巡检，并具备分级处理的自愈能力，例如 Error 级别的故障实现自动排水、重启，Fault 级别故障实现自动换机。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任务容错的准召率保障&lt;/h1&gt; 
&lt;p&gt;任务层面稳定性最核心的就是做好容错，能够让业务在无论遇到何种故障时都能快速恢复。&lt;/p&gt; 
&lt;p&gt;那么，首要的工作就是我们能够准确的识别出异常，然后对故障进行诊断定位，最后能够自动化的从异常中恢复。&lt;/p&gt; 
&lt;p&gt;因此，任务容错需要能够从端侧（即每个训练 worker）探测到进程与环境的各类异常，同时有个中心服务（Master）从任务全局的视角去诊断、定位异常，最终做出相应的决策来使任务能够快速从异常中恢复。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任务容错最重要的就是提升故障的召回率与准确率，即如何能够尽可能的准确识别、定位所有故障。我们将故障分类两类：显式故障和隐式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;显式的故障通常比较容易召回，我们将实践积累的各种进程异常状态及各类报错 pattern 形成专家知识库，再结合硬件感知服务（HAS Agent）的硬件全链路 10 秒级监控能力，可以实现显式故障的召回率达到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隐式的异常则往往很难轻易的识别，例如训练进程 hang、慢节点就是典型的隐式故障，需要丰富的经验积累才能准确的识别出异常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我们就以最典型的隐式故障场景 —— 训练进程 hang 死为例，来看下如何能够做好 hang 自动感知、诊断。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 训练****hang 的自动感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;训练任务发⽣ hang 之后，绝⼤多数情况都会以 timeout 的⽅式报错并退出进程，最常⻅的就是在通信过程中如果发⽣ hang，NCCL 的 watchdog 会中断通信，并有报如下 timeout 报错，然后再由 pytorch 的 torchrun 进程感知并中断训练过程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默认为 10 分钟 NCCL 通信超时，而 Megatron-LM 为 30 分钟。在万卡规模训练场景中，意味着一万张卡要至少浪费 30 分钟才能被发现。这个时效性是不可接受的。而且当 30 分钟超时后程序会立马退出，很难有机会进行下一步定位，需要一些时效性更高的感知机制，并且在程序退出前获取一些有效信息供后续诊断分析。&lt;/p&gt; 
&lt;p&gt;很多公司、实验室在面对 hang 的问题时，会在采用框架层插桩的方式来 trace 训练进程，这种方式通常是比较直接且准确的，但是有比较强的侵入性，而且可能还会有一些性能开销。对于云厂商来说，需要寻找对用户更透明、更无损的方式来感知、定位 hang 异常。&lt;/p&gt; 
&lt;p&gt;如何感知训练 hang，以百度百舸的产品设计思路为例，我们可以从以下几个方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练进程 hang 的最直观表现是什么？&lt;/p&gt; &lt;p&gt;人工判断一个任务是否 hang 了，最直接的方式就是看是否所有 worker 的任务日志一段时间内都不输出日志了，所以 hang 自动感知的第一种方法就是采集所有 worker 的日志，并判断所有 worker 日志中最后一行日志是否为 x 分钟前的（x 小于 Pytorch 的通信超时时间，例如 8 分钟），如果是则基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时进程有什么样的表现？&lt;/p&gt; &lt;p&gt;任务 hang 时，可能进程的调用栈都不在发生变化，进程的调用栈可以通过 py-spy/pystack 等工具进行探测，所以我们可以用此类工具对所有训练任务进行一个定时采样，当采集 n 个样本所有进程栈都没有变化时，可以判定一次 hang，这种方式通常可以将 hang 感知缩小至 3～5 分钟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时监控指标有哪些变化？&lt;/p&gt; &lt;p&gt;训练进程中的 CUDA 算子计算、集合通信操作通常都是在毫秒，甚至微秒、纳秒内完成的，当任务在正常迭代过程中发生了 hang，我们常遇到的情况是所有 rank 的 RDMA 流量会降到 0，而 GPU 的利用率为 100%、SM 利用率则在很低的水位。如果持续几分钟都是这种状态时，意味着训练进程已经计算完成，在等着集合通信完成，这种情况下基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信库中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常单次集合通信操作都是在 ms 级的，如果一次操作在 30 秒钟都没有完成，那就可以判定为通信 hang 死了。百度自研的 BCCL 集合通信库层可以对每一次集合通信操作都进行打点，来实现通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述几种方法，我们可以分别实现一种探针，来抓取相应的特征到中心端 master 组件进行下一步诊断和容错决策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信库 BCCL 是百度智能云推出的一款面向大模型训练场景优化的集合通信库。&lt;/p&gt; 
 &lt;p&gt;BCCL 基于开源的 NCCL 进行了功能扩展和能力增强，针对大模型训练场景在可观测性、故障诊断、稳定性等方面进行优化，进一步提升集合通信库的可运维能力。相比 NCCL，BCCL 的关键特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可观测性：新增集合通信带宽实时统计能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障诊断：新增集合通信 hang 时的故障诊断能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;稳定性：增强网络稳定性和故障容错能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能优化：提升大模型训练主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;训练 hang 的自动诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我们需要进一步的诊断、定位，来确定是否真的发生了 hang，以及 hang 的具体位置。具体的来讲，master 收集到各类 agent 的数据后，会做一些综合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的发生了 hang？&lt;/p&gt; &lt;p&gt;感知阶段各种探针只能探测到 hang 的一种特征，并没有办法 100% 的确定是否真的 hang 住了，事实上不侵入用户进程是很难做到 100% 确定 hang 的。因此，为了提高 hang 的判定准确率，我们需要将各种特种综合起来判断，探针上报到 master 后，由一个 hang 诊断模块，按照一个时间窗口（例如 5 分钟），进行综合判断。如果在时间窗口内日志、监控、进程调用栈、通信库中有 2 条以上都处于不处于活跃状态时，我们判断任务真正发生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具体发生的位置？&lt;/p&gt; &lt;p&gt;确定任务 hang 了之后，我们需要找到 hang 所在的节点来对它进行隔离。因此诊断模块需要在探针上报的数据中进一步找寻特征，来确定 hang 发生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 诊断：在感知阶段，BCCL 可以在通信库层面对所有 rank 的通信进行打点。如果有节点一直未完成通信则是发生了 hang。但是此节点可能并非真正发生 hang 的源头，有可能是在等待其他节点完成通信。诊断模块可以根据 BCCL 打印的通信组信息，进行交叉判断，如果某个节点在多个通信组中都未完成通信，那这个节点就是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指标诊断：上文中我们提到，通信阶段发生 hang 之后，所有 rank 的 RDMA 流量都会降到 0，而同时绝大部分 rank 的 GPU 利用率持续为 100%，只有某一两个 rank 的 GPU 利用率为 0，那这个 rank 很有可能是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调用栈诊断：进程调用栈也可以作为一个 hang 源头诊断的重要参考。当发生 hang 之后，绝大部分的 rank 都要么处于 barrier 等待状态，要么处于通信等待阶段。只有个别的 rank 卡在其他函数上，那么通过对比分析，可以将调用栈与其他 rank 不同的节点初步判定为 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;综合诊断：上面 3 种特征为我们提供了 hang 的诊断依据，将 3 者关联起来分析后，我们基本上可以比较准确的确定一个具体的 hang 的源头，再结合硬件故障感知的相关信息可以进一步明确根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基于 eBPF 的隐式故障感知与诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在复杂的大规模分布式训练场景中，传统用户态监控往往难以捕获系统内核层面的异常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基于 eBPF（Extended Berkeley Packet Filter）技术的隐式故障感知体系，能够在不侵入用户代码的前提下，对训练进程的系统调用、网络通信、CPU 调度等内核态行为以及训练框架关键函数运行时间建立立体观测能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探针部署原理通过在内核关键路径注入轻量级探针，实现低开销的系统级行为捕获。针对训练场景特点，主要聚焦 4 类事件跟踪：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练关键函数跟踪：微秒级跟踪训练过程中，前向计算、反向计算、集合通信操作等关键函数执行耗时，记录函数间调用关系。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调度阻塞跟踪：挂钩 sched_switch 事件，检测进程在 TASK_UNINTERRUPTIBLE 状态持续时间，当单次持续超过阈值（如 5 秒）时捕获调用栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 运行时 API 监控：通过 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等关键库注入探针，记录 CUDA API 调用耗时分布。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 级通信监控：在 ibv_post_send/ibv_poll_cq 等核心通信接口设置观测点，统计通信时延分布。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合上面 4 类事件，完成以下 2 类数据分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单体异常探测基线与实时数据对比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;群体一致性检测。采用卡间对比算法，当某一 rank 的以下指标偏离集群中位数超过阈值时判定异常，包括系统调用频率、进程就绪队列等待时长、NVLink/RDMA 带宽利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上所述方法，百度百舸针对以下 2 类典型的隐式故障进行诊断：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练 hang 根因定位。通过关联 eBPF 捕获的多维度数据进行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当检测到某 rank 的 GPU &amp;nbsp;Kernel 执行出现分钟级空跑（SM 利用率 &amp;gt; 70% 但无有效计算输出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时伴随该节点 RDMA QP 状态停滞（ibv_poll_cq 无新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内核调度器显示进程处于 D 状态超过阈值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖动溯源。基于 eBPF 火焰图、时序图等进行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取发生性能下降时段的 CPU on-cpu/off-cpu 堆栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对比正常时段数据，识别出异常的锁竞争（futex 调用占比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结合 NUMA 内存访问统计，定位跨 NUMA 内存访问导致的 TLB 颠簸问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此类技术已在百度百舸的万卡规模训练集群中验证，相比单纯依赖应用层监控的方案，将隐式故障的平均检测时间从分钟级缩短至秒级，诊断准确率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通过与既有硬件故障感知服务、BCCL 通信库监测体系联动，百度百舸形成了覆盖从硬件到系统内核再到应用层的立体化诊断能力。&lt;/p&gt; 
&lt;h1&gt;05 任务故障恢复的时效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢复的时效性也是容错能力的一个重要指标，反映的是任务从故障发生到再次重新进入训练迭代的时间，恢复效率越高则算力浪费越少。影响到任务恢复效率有 2 个重要因素，一是任务平均中断时间，二是训练重算时间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多级重启策略减少故障中断时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任务发生异常后，上文中我们提到需要经过故障自动感知、诊断和自愈等 3 个环节，那么减少中断时间的核心思想，就是尽可能的缩短这 3 个环节的时间，通过多维度的感知、诊断手段可以将故障发现、定位的时效性降低至分钟级甚至秒级。自愈则需要能够根据不同的诊断结果进行分级恢复和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单点显式故障：重调度异常节点（replace），对节点进行集群级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;单点隐式故障：重调度异常节点，对节点进行任务级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非单点故障：原地重启尝试恢复（restart），无法恢复时重新调度所有节点（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过多级重启策略，尽可能避免单点故障引发全部节点的重新调度。在万卡级别的训练场景中，百度百舸将大部分训练异常场景恢复时间从过去的 30min 缩短至现在的 30s 内，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;触发式 checkpoint 减少训练重算时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多级任务重启策略外，另一个提高任务故障恢复效率的重要手段就是减少训练重算时间。在探讨具体技术方案之前，我们先来看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;传统的 checkpoint 保存通常采用固定间隔策略，比如每隔 N 个 step 或每隔 T 小时保存一次，这种方式实现简单但缺乏灵活性，可能会产生大量冗余存储，同时在故障发生时可能会损失较多训练进度。&lt;/p&gt; 
&lt;p&gt;而触发式 checkpoint 则是一种更智能的方案，它根据特定条件或异常事件（如故障、显存不足、显式指令等）动态触发模型状态保存。其核心目标是通过灵活的控制保存时机，减少不必要的存储开销和训练中断时间，从而降低因频繁或冗余保存导致的重算时间浪费。&lt;/p&gt; 
&lt;p&gt;随着大模型训练规模的扩大，还有一种更激进的「零重复 checkpoint」技术，即在每个训练 step 都保存一次 checkpoint。这种方案的优势在于可以将重算时间降到最低，确保故障发生时能够从最近的 step 恢复，几乎不会损失训练进度。但其显著的缺点是存储开销巨大，即使采用增量式存储，仍然需要相当大的存储空间和 I/O 带宽。此外，频繁的 checkpoint 操作也可能影响训练性能。&lt;/p&gt; 
&lt;p&gt;相比之下，触发式 checkpoint 走的是一条平衡之路。我们来看下它实现的几个核心要点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容错：训练进程集成容错的故障感知与定位机制，在进程退出前自动触发保存。这种主动感知机制能够在故障发生的第一时间保存训练状态，最大限度减少进度损失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速转储：异步 checkpoint 保存机制会将 checkpoint 暂存到共享内存中，再由外部程序转储至磁盘。当某个节点异常时，容错组件会拉起新节点，并在新节点训练进程启动前，利用 RDMA 技术实现 checkpoint 快速从故障节点转储至新节点，这大大减少了从远程存储拉取 checkpoint 的时间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗余备份：触发式 checkpoint 也并非完美无缺，例如在节点发生内核 crash 等严重故障时，可能无法触发自动保存。因此，需要通过定期的冗余备份机制进行兜底，确保 checkpoint 不会完全丢失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实践表明，当触发式 checkpoint 与异步、增量式的 checkpoint 机制结合使用时，可以在保证数据安全性的同时，显著提高 checkpoint 保存效率，减少训练重算时间。&lt;/p&gt; 
&lt;p&gt;相比零重复 checkpoint 的重型方案，触发式 checkpoint 提供了一个更实用的折中方案，在合理的存储开销下实现较好的容错效果。当然，具体选择哪种方案，还需要根据实际的训练规模、硬件条件和可用资源来权衡。&lt;/p&gt; 
&lt;p&gt;随着分布式训练规模的持续增长，相信未来会出现更多创新的 checkpoint 方案，比如基于预测的主动保存策略、多级存储架构的智能调度等，这些都将为提高大规模训练的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 业务发展对稳定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 训练的稳定性管理已经演变为智能时代的精密工程。从最初靠人工重启解决问题的摸索阶段，到如今能自动感知异常、快速恢复的智能系统，每一次进步都映照着算力规模的跨越式发展。&lt;/p&gt; 
&lt;p&gt;让人不禁思考，在未来十万卡集群的算力洪流中，或许会出现更精妙的动态平衡方案：既能像鹰隼般敏锐捕捉故障征兆，又能如雁群迁移般智能调度资源，在秒级恢复与 PB 级存储成本之间找到新的平衡支点。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持厂内千卡和万卡集群有效训练时长已经可达 99.5%，为客户大模型的预训练保驾护航，比如国内第一个数学大模型——九章算术，国内第一个类 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增强语义嵌入的模型算法综述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持续推进「人工智能＋」行动，百度智能云+DeepSeek 为何成为国有企业首选？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 云服务器的软件系统设计和实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基于 Flink 的配置化实时反作弊系统&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能云 xDeepSeek，最具性价比的 DeepSeek 一体机合集来了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sun, 11 May 2025 03:02:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Hugging Face 发布开放权重模型贡献榜：Qwen 与 DeepSeek 跻身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;发布&lt;/a&gt;开放权重模型贡献榜，中国团队 Qwen 和 DeepSeek 成功入围前 15 名。该榜单表彰为开源社区提供高质量模型权重的团队，其模型广泛应用于学术与产业创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴云智能集团支持的 Qwen 团队，以 Qwen3 系列模型在指令跟随、代码生成等任务中的优异表现受到社区青睐。Qwen2.5-72B 系列位列开源大语言模型前列，其轻量化模型 QwQ-32B 通过强化学习优化，在数学推理和代码生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 则以低成本、高性能的 R1 系列模型闻名。R1-0528 在 LiveCodeBench 排行榜中超越多个国际竞品，仅次于 OpenAI 顶尖模型。其轻量化版本 DeepSeek-R1-0528-Qwen3-8B 通过知识蒸馏技术，单 GPU 即可运行，在 AIME2025 数学测试中击败 Google 的 Gemini2.5Flash，展现了在特定领域的竞争优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中国 AI 团队在开源生态中的崛起。Hugging Face 负责人表示，两团队的贡献为全球开发者提供了高效资源。NVIDIA 首席执行官黄仁勋也赞扬其性能与成本平衡正在重塑 AI 格局。未来，Qwen 计划探索多模态技术，DeepSeek 则将推出 R2 模型，持续推动 AI 创新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sun, 11 May 2025 02:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥 Solon Flow 设计器入门</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索视频：&lt;/p&gt; 
&lt;p&gt;&lt;iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114657104759990&amp;amp;bvid=BV1opT6z5EiJ&amp;amp;cid=30416702034&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354770</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354770</guid>
      <pubDate>Sun, 11 May 2025 02:51:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Android 16 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌发布了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为今年的第一次大版本升级，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按键式导航（三大金刚）的预测性返回手势&lt;/li&gt; 
 &lt;li&gt;强制通知分组&lt;/li&gt; 
 &lt;li&gt;以进度为中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 设备的桌面模式（开发者选项）&lt;/li&gt; 
 &lt;li&gt;低功耗蓝牙听力辅助设备支持&lt;/li&gt; 
 &lt;li&gt;自定义键盘快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截图优化&lt;/li&gt; 
 &lt;li&gt;以旧换新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性详细介绍查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sun, 11 May 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 推迟开源模型的发布时间</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席执行官山姆·奥特曼宣布，原计划于今年初夏发布的公开权重的开源模型预计&lt;strong&gt;将推迟至夏末发布&lt;/strong&gt;，而不是 6 月与公众见面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究团队做了一些出乎意料且非常令人惊奇的事情，这非常值得等待，但需要更长的时间。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣布将发布自 GPT-2 以来的首个「开源」语言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最强」开源模型，计划今年初夏发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sun, 11 May 2025 02:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首个推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣布推出&lt;/a&gt;其首个推理模型系列 Magistral，采用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高数学和物理等主题的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有两种版本：Magistral Small 和 Magistral Medium。Magistral Small 拥有 240 亿个参数，在 Apache 2.0 协议下开源。Magistral Medium 是一款功能更强大的模型，目前已在 Mistral 的 Le Chat 聊天机器人平台、该公司的 API 以及第三方合作伙伴云平台上提供预览。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中写道：「Magistral 适用于各种企业用例，从结构化计算和程序逻辑到决策树和基于规则的系统。这些模型针对多步骤逻辑进行了微调，提高了可解释性，并以用户的语言提供了可追溯的思维过程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立于 2023 年，该公司得到了 General Catalyst 等风险投资机构的支持，迄今已筹集超过 11 亿欧元（约合 12.4 亿美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;尽管 Mistral 资源雄厚，但在某些领域，例如推理模型开发，Mistral 仍落后于其他领先的人工智能实验室。从 Mistral 自身的基准测试来看，Magistral 似乎也并非一款特别有竞争力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 测试中，Magistral Medium 的表现不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的编程基准 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或许正因如此，Mistral 在其博客文章中大力宣扬 Magistral 的其他优势。声称 Magistral 在 Le Chat 中提供答案的速度是竞争对手的「10 倍」，并且支持多种语言，包括意大利语、阿拉伯语、俄语和简体中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的发布是在 Mistral 推出「vibe coding」客户端 Mistral Code 之后。在此之前的几周，Mistral&amp;nbsp;推出了几款专注于编码的模型，并推出了 Le Chat Enterprise，一项面向企业的聊天机器人服务，提供 AI 代理构建器等工具，并将 Mistral 的模型与 Gmail 和 SharePoint 等第三方服务集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>【运维实操指南】2 分钟定制雷池 WAF 认证页：从「标准表单」到「视觉升级」全攻略</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;在，通用设置 &amp;gt; 防护配置，模块下，找到 [自定义 HTML] 模块&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="341" src="https://oscimg.oschina.net/oscnet//30cd12a12b9b01facd09506982aa5867.jpg" width="716" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;就像写一个普通的 html 页面一样，你可以同时写入 style、script 等标签, 所以用 css 就能修改中心区域的样式啦。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;把文末的示例代码复制到&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="449" src="https://oscimg.oschina.net/oscnet//4116eaeb2f8f24a9d1bf87150294cc81.jpg" width="725" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;效果图:&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="346" src="https://oscimg.oschina.net/oscnet//679bc9d16ccf472845db825ecfd23844.jpg" width="746" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log('Im a console.log, which is written in a script tag');
&amp;lt;/script&amp;gt;
&amp;lt;style type="text/css"&amp;gt;
  body {
    background: #395180;
    margin: 0;
  }
  body #slg-box {
    background-color: grey;
    width: 400px;
    height: 100%;
    top: 0;
    left: 0;
    transform: translate(0, 0);
    padding: 100px 20px;
  }
  body #slg-usergroup-username,
  body #slg-usergroup-password {
    background-color: grey;
    color: #fff;
  }
  body #slg-box-title {
    color: #e15ccf;
  }
  body #slg-usergroup-btn {
    color: grey !important;
  }
  body #slg-with-more-title div:nth-child(2) {
    background-color: transparent;
    width: 100%;
    height: 30px;
    line-height: 30px;
    text-align: center;
    border: 1px solid;
  }
  body #slg-with-more-title div:nth-child(1) {
    display: none;
  }
  body #slg-tabs &amp;gt; div {
    fill: green;
  }
  body #slg-usergroup-container input {
    border-style: dashed;
  }
&amp;lt;/style&amp;gt;

&amp;lt;div
  style="
    background-color: grey;
    width: 200px;
    height: 100px;
    text-align: right;
    top: 50%;
    position: relative;
    left: calc(50% + 200px);
    position: relative;
    transform: translate(-50%,-50%);
    border-radius: 10px;
    font-size: 30px;
    line-height: 100px;
    text-align: center;
  "
&amp;gt;
  hello world
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354756</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354756</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 发布 o3-pro：更强大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;发布&lt;/a&gt;了 o3-pro 推理模型，基于 o3 所打造，拥有更强的数学、科学、编程等领域的表现。&lt;/p&gt; 
&lt;p&gt;据介绍，o3-Pro 可，自动调用多种工具，包括可以搜索网页、分析文件、推理视觉输入、使用 Python、通过记忆功能个性化回复等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由于调用的工具较多，所以，思考的时间比 o1 Pro、o3 更长。&lt;/strong&gt;o3-pro 与 o3 系列一样拥有 200K 的上下文窗口和 100K 的输出，但价格却比它们暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表现上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在专家评估中，评审人员普遍认为 o3 Pro 在多方面都比 o3 模型更进一步，尤其适合用在科学、教育、编程、商业和写作这些需要深度输出的任务中。&lt;/li&gt; 
 &lt;li&gt;在学术评估的基准测试中，o3-pro 的整体表现持续优于 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 还通过四次尝试获取正确答案的方式进行实验发现，o3-pro 能保持较好的性能表现。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用户提供，取代 o1-pro；企业版和教育版用户将在下周获得使用权限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;价格方面，o3-pro 输入为 20 美元/百万 token，输出 80 美元/百万 token；而 OpenAI CEO Sam Altman 昨晚宣布，o3 降价 80%——因此 o3 价格来到了输出 2 美元/百万 token、输入 8 美元/百万 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sun, 11 May 2025 02:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>KubeCon+CloudNativeCon China 2025 在香港盛大开幕，共绘云原生未来</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p&gt;2025 年 6 月 10 日，中国香港 —— 今日，由云原生计算基金会（CNCF）和 Linux 基金会联合主办的全球云原生计算领域顶尖盛会 KubeCon + CloudNativeCon China 2025 于香港隆重启幕。来自全球的开发者、技术专家、企业决策者及行业领袖共聚一堂，探索云原生技术未来蓝图，共推云计算生态繁荣发展。&lt;/p&gt; 
 &lt;p&gt;盛会首日，汇集了来自 Linux 基金会、CNCF、华为、Akamai、阿里云、Arm、AWS、Intel、LFOSSA、DaoCloud、F5、Fortinet、ICON、KubeWharf、ManageEngine、SUSE、KubeDB、科大讯飞等头部企业与组织的技术专家、企业代表及开源领袖。为期两天的议程将呈现约 100 场主题演讲、闪电演讲及项目展示，聚焦云原生与 AI 融合、安全合规、多云架构、数据处理与存储等多项前沿技术，为现场观众带来深度技术实践与战略洞察。&lt;/p&gt; 
 &lt;p&gt;聚焦核心议程，首日的开幕致辞与主题演讲环节亮点频现，重量级嘉宾相继登台。&lt;/p&gt; 
 &lt;p&gt;Linux 基金会执行董事 Jim Zemlin 为大会致开场词。Jim Zemlin 鼓励科技公司使用开源软件来帮助创新。他指出，长期以来，有很多公司反对开源，试图保持专有的地位，最终要么以低估值被收购，要么只能退出一些业务领域。为什么开源在所有的技术创新中的作用如此巨大？Jim Zemlin 表示，答案是因为它在经济上非常有价值，「我们与哈佛商学院进行了一项研究，如果必须购买所有用来创建技术、产品和服务的开源软件，那需要花费的成本高达 9 万亿美元，这就是开源如此强大的原因。」&lt;/p&gt; 
 &lt;p&gt;&lt;img height="507" src="https://oscimg.oschina.net/oscnet/up-3148dadc1499f9a5e77b67236866f6c5967.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;CNCF 首席技术官 Chris Aniszczyk 为大会做社区开幕致词。Chris Aniszczyk 高度认可中国在云原生技术领域的创新与贡献。中国在科技创新，尤其云原生领域展现重大贡献，是 CNCF 最早且最强大的生态系统之一，开源贡献位居全球第二，孕育出如 Volcano、Dragonfly、KubeEdge、OpenYurt 等多个具有全球影响力的项目，彰显了在边缘计算、容器调度、分布式处理等多方面的卓越能力。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="513" src="https://oscimg.oschina.net/oscnet/up-a458d49baccea2f5a94b050de918d9924e6.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;Odyssey Cloud 联合创始人 Amit Dsouza 和 Nirmata 社区负责人 Cortney Nickerson 发表《Crossplane Is the Answer! but What Is the Question?》主题演讲。二人介绍了 IaC 工具 Crossplane 在平台工程方面的赋能作用，比如通过扩展 Kubernetes API，以声明式的方式管理基础设施和应用程序等。此外，Crossplane + ArgoCD + Kyverno 堆栈还可以实现 GitOps 驱动的自动化，确保部署符合组织合规性和安全策略。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-b39291f8c25f9ae68378b06ecbccac514ff.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;华为首席开源联络官，CNCF 董事会成员任旭东发表《迈向人工智能集群云》主题演讲。任旭东指出，人工智能硬件基础设施正朝着大型处理器集群的方向发展，需要我们在构建和管理云的方式上进行重大变革，而借助 Linux、Volcano 和 Karmada 等项目，我们可以实现向人工智能集群云的演进。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="513" src="https://oscimg.oschina.net/oscnet/up-2981a2c77bb968828df1b6e8df65eed5037.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;Second State 创始人 Michael Yuan 发表了《针对 GenAI 工作负载优化的 Linux 堆栈》主题演讲。Michael Yuan 介绍了 Flatcar 的基础知识及其对 Wasm 运行时的支持，讨论了 WasmEdge 对可移植 AI 模型和推理应用程序的支持，并演示了一个可在 Flatcar 中跨 GPU 和 CPU 运行的 GenAI 应用程序。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="506" src="https://oscimg.oschina.net/oscnet/up-b3c6a0bdb509152e9f34e215bf552e6a93b.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;华为云软件工程师 Xuzheng Chang 和科大讯飞平台架构师 Dong Jiang 发表《利用 Volcano 进行扩展模型训练：科大讯飞的 Kubernetes 突破》主题演讲。据介绍，科大讯飞在大规模模型训练中，通过利用 Volcano，将 GPU 利用率提升了 40% 以上，并将故障恢复时间缩短了 70%。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="515" src="https://oscimg.oschina.net/oscnet/up-2098f237a664232ed1ddce8a1bd6d078672.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;香港环球航空学会科技主管、主任助理 Aaron Xu 和 DaoCloud 首席执行官兼创始人 Roby Chen 发表《香港人工智能的未来：从本地创新到全球影响力》主题演讲。据介绍，HKGAI V1 的发布标志着香港人工智能发展翻开了新的篇章。HKGAI 团队充分发挥本土互联和全球布局的优势，拥抱开源社区，共同应对从优化高性能计算集群到探索前沿人工智能模型等诸多挑战。未来，香港将进一步整合内地和国际资源，深化技术创新和应用拓展，为全球人工智能标准和应用贡献「香港方案」。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="500" src="https://oscimg.oschina.net/oscnet/up-0b36a5534d137948137e29dbcaa96ffceb9.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;此外，大会现场还特别设立了项目展厅，展示全球多个顶级开源项目，呈现开源技术生态的最新进展和创新成果。&lt;/p&gt; 
 &lt;p&gt;首日盛况已燃，精彩远未落幕！在接下来的议程中，与会者将有机会深入技术细节，参与更多深度对话。大会还将带来近百场分技术演讲及特色活动，聚焦微服务治理、可观测性、安全、平台工程等热点议题，更多来自全球顶级企业与创新团队的洞见与实践将精彩呈现。敬请期待，共同见证云原生与 AI 融合新纪元的无限可能！&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;感谢赞助商&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;KubeCon + CloudNativeCon China 2025 的成功举办，得益于赞助商们的大力支持。在此感谢以下赞助商：&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;关于&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;云原生计算基金会&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;云原生计算能协助组织利用开源软件栈，在公共云、私有云和混合云等各种云环境中构建和运行可扩展的应用程序。云原生计算基金会 (CNCF) 托管包括 Kubernetes、Prometheus 和 Envoy 在内的全球技术基础设施的关键组件。&lt;/p&gt; 
 &lt;p&gt;CNCF 汇集了行业顶尖的开发者、终端用户和供应商，并举办世界上最大的开源开发者会议。作为非营利性 Linux 基金会的部分，CNCF 得到了超过 800 个成员的支持，其中包括全球最大的云计算和软件公司，以及 200 多个创新型初创企业。有关更多信息，请搜索 CNCF 官网。&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;关于&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;Linux 基金会&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;Linux 基金会是全球领先的开源软件、硬件、标准和数据协作平台。Linux 基金会的项目对全球基础设施至关重要，涵盖 Linux、Kubernetes、Node.js、ONAP、PyTorch、RISC-V、SPDX、OpenChain 等。Linux 基金会致力于采纳最佳实践，满足贡献者、用户以及解决方案提供者的需求，打造可持续的开放合作模式。有关更多信息，请搜索 Linux 基金会官网。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354700</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354700</guid>
      <pubDate>Sat, 10 May 2025 14:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>iOS 26 新增实时翻译：基于端侧并向第三方开放接口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2e75214ed6a7bf091530afec2180ff3869d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开发者朋友们大家好：&lt;/p&gt; 
&lt;p&gt;这里是 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; ，每天和大家一起看新闻、聊八卦。&lt;/p&gt; 
&lt;p&gt;我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 &lt;strong&gt;技术&lt;/strong&gt; 」、「有亮点的 &lt;strong&gt;产品&lt;/strong&gt; 」、「有思考的 &lt;strong&gt;文章&lt;/strong&gt; 」、「有态度的 &lt;strong&gt;观点&lt;/strong&gt; 」、「有看点的 &lt;strong&gt;活动&lt;/strong&gt; 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。&lt;/p&gt; 
&lt;p&gt;本期编辑：@赵怡岭，@鲍勃&lt;/p&gt; 
&lt;h2&gt;01 有话题的技术&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Direct3D-S2：影视级 3D 生成模型，仅需 8 块 GPU 即可训练，效果超越许多闭源商用模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DreamTech 与南大、复旦和牛津联合推出的 Direct3D-S2 开源 3D 生成模型，在 HuggingFace 热榜中表现卓越，仅需 8 块 GPU 即可训练，效果超越许多闭源商用模型，达到了影视级精细度。其核心创新 —— 空间稀疏注意力机制（SSA）显著提升了生成效率和细节表现，解决了传统 3D 建模面临的计算压力和复杂度问题。&lt;/p&gt; 
&lt;p&gt;在 Direct3D-S2 中，DreamTech 团队提出了一项核心创新——空间稀疏注意力机制（Spatial Sparse Attention， SSA）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfaba50ee60f71dfe7e6d2905c689c38efe.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一机制专为解决当前 Diffusion Transformer（DiT）在处理高分辨率 3D 生成时效率低、精细度差的问题而设计，堪称 3D 生成领域的效率引擎。&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2505.17412" target="_blank"&gt;https://arxiv.org/pdf/2505.17412&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FDreamTechAI%2FDirect3D-S2" target="_blank"&gt;https://github.com/DreamTechAI/Direct3D-S2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.neural4d.com%2Fresearch%2Fdirect3d-s2%2F" target="_blank"&gt;https://www.neural4d.com/research/direct3d-s2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相关链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fwushuang98%2FDirect3D-S2-v1.0-demo" target="_blank"&gt;https://huggingface.co/spaces/wushuang98/Direct3D-S2-v1.0-demo&lt;/a&gt; （@新智元、@果比 AI）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、Neuralink 和 Grok 合作，脑机芯片为渐冻症患者赋予「发声」能力&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;近日，马斯克在 X 上转发的一则案例显示：Neuralink 和 Grok 正合作使渐冻症患者重新「发声」。&lt;/p&gt; 
&lt;p&gt;通过脑机接口技术，一名渐冻症患者成功实现了用意念输出文字，并借助 AI 完成语句补全和声音克隆，最终以接近本人的声音「说话」。这一突破性进展源于 Neuralink 的脑机芯片植入技术，以及 Grok 强大的自然语言处理能力。&lt;/p&gt; 
&lt;p&gt;具体来说，患者只需通过思考即可移动光标生成文本，Grok 助手则像「读心术」一样自动更正并补全文本，最后通过 AI 克隆出患者原本的声音，让交流更加自然。&lt;/p&gt; 
&lt;p&gt;马斯克转发的帖子原出处 Mario Nawfal 此前介绍，患者 Bradford Smith 因为渐冻症丧失了行动和说话能力，而 Neuralink 使其能够通过思考来生成文本，Grok 则可以实现「读心术」式的自动更正，再通过另一个 AI「克隆」的其真实声音，从而使他「说话」时能够拥有听起来就像本人的声音。&lt;/p&gt; 
&lt;p&gt;今年 5 月，Neuralink 的脑机接口设备 Link 获得了美国 FDA 的「突破性设备」认证，专门用于帮助严重语言障碍患者恢复沟通能力。&lt;/p&gt; 
&lt;p&gt;新闻链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ithome.com%2F0%2F859%2F328.htm" target="_blank"&gt;https://www.ithome.com/0/859/328.htm&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;X 链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FMarioNawfal%2Fstatus%2F1928406038803558837" target="_blank"&gt;https://x.com/MarioNawfal/status/1928406038803558837&lt;/a&gt; （@IT 之家、@新智讯）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、开源框架 Rowboat：快速构建智能助手，支持 MCP、Agent SDK&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由 Y Combinator 支持的开源多智能体开发框架 Rowboat 亮相，支持 MCP 服务和 OpenAI Agent SDK。框架由 Agent、Playground 和 Co pilot 三大模块构成，方便用户快速构建、测试和部署智能助手。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Agent，主要负责处理对话的特定部分，并能依据指令使用工具执行任务。其亮点在于可通过自然语言指令进行配置，能以图的形式在智能体之间进行编排，还可访问工具和 RAG。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Playground，这是一个交互式环境，方便用户在构建助手时以对话方式进行测试。它具备实时测试和调试功能，可在界面内检查工具调用的参数和结果，能与单个智能体或整个助手进行对话。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Copilot，由 AI 驱动的辅助工具，可代用户创建和更新智能体与工具。能感知包括演练场在内的所有组件的上下文，可根据对话和反馈优化智能体，能理解用户以自然语言提出的请求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;用户可创建多智能体，如信用卡助手，实现任务协同。Rowboat 还提供 HTTP API 和 Python SDK，适应多样开发场景。目前，Rowboat 在 Github 已经超过 2000 颗星。&lt;/p&gt; 
&lt;p&gt;开源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frowboatlabs%2Frowboat%3Ftab%3Dreadme-ov-file%25EF%25BC%2588%40AIGC" target="_blank"&gt;https://github.com/rowboatlabs/rowboat?tab=readme-ov-file（@AIGC&lt;/a&gt; 开放社区、@OneThingAI Lab）&lt;/p&gt; 
&lt;h2&gt;02 有亮点的产品&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Apple Intelligence 实时翻译功能：基于端侧、横框多个应用、向第三方开发者开放&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Apple 最新发布的 iOS 26 中，Apple Intelligence 支持实时翻译功能，这个功能横跨电话、信息与 Facetime 三个通讯软件，当你收到外语信息时，系统会自动将其翻译成你的语言；相关功能已集成到信息、电话等 App 中，能够实现即时翻译文本和音频，从而帮助用户跨越语言障碍。&lt;/p&gt; 
&lt;p&gt;同样的，你发出的内容也会被实时翻译成对方的语言，让跨语言交流变得前所未有的顺畅。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a1581d62c50fe6604340d5a10ba25be1442.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;实时翻译功能完全基于端侧，你的对话内容不会由此流通到任何未经允许的地方。&lt;/p&gt; 
&lt;p&gt;由 Apple Intelligence 驱动的实时翻译功能将通过 API 接口，向所有第三方开发者开放，开发者可以将实时翻译功能集成到任何通讯软件中。&lt;/p&gt; 
&lt;p&gt;过去一年，苹果在海外推出了如 Genmoji、图乐园等 AI 功能，帮助用户更自由、有趣地表达内容，而外界最为关心的 AI Siri 将什么时候落地，在今年 WWDC 依旧并没有给出具体的日期。&lt;/p&gt; 
&lt;p&gt;语言适配方面倒是有所进展，Apple 智能将在今年年底前支持这些语言：丹麦语、荷兰语、挪威语、葡萄牙语、瑞典语、土耳其语、繁体中文和越南语。&lt;/p&gt; 
&lt;p&gt;苹果宣布推出 Foundation Models Framework。这是一项全新的 API，允许第三方开发者调用 Apple Intelligence 核心的大型语言模型（LLM），并将其集成到自家应用中。&lt;/p&gt; 
&lt;p&gt;开发者无需构建自己的 AI 模型，也不必依赖云端服务，就能在自己的 App 中调用一个功能强大、响应快速、且重视隐私保护的智能助手。更重要的是，不怕断网，离线也能运行。 （@APPSO、@IT 之家）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、Talking Tours：Google 发布的 AI 导游，支持实时对话互动&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-32abd937a92b609d665aa4542e702d431b0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;打开 Talking Tours 页面，你会看到一张互动地图，涵盖全球多个文化地标和自然景观，分为多个主题：文化机构（博物馆、图书馆、剧院）、地标建筑、古迹和自然景观（森林、洞穴、沙漠、园林、海洋）。&lt;/p&gt; 
&lt;p&gt;点击地图上的座标，即可进入对应地点的沉浸式街景视图。AI 导游会通过语音讲解该地点的背景信息，比如某所博物馆的建筑风格、历史典故，甚至细节到展厅里壁纸的设计灵感。&lt;/p&gt; 
&lt;p&gt;切换画面后，点击「take a snapshot」按钮，AI 会基于新画面重新生成一段讲解，换个角度看，同一地点也可能讲出不同的故事。还可以点击右下角的「🙋」图标，对 AI 导游发起提问。&lt;/p&gt; 
&lt;p&gt;体验链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartsandculture.google.com%2Fexperiment%2F8AGlfzgsYmBeIA" target="_blank"&gt;https://artsandculture.google.com/experiment/8AGlfzgsYmBeIA&lt;/a&gt; （@Founder Park）&lt;/p&gt; 
&lt;h2&gt;03 有态度的观点&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、任正非：AI 也许是人类社会最后一次技术革命&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;《人民日报》6 月 10 日头版刊文消息，近日，在深圳华为总部，围绕大众关心的一些热点话题，人民日报记者一行与华为 CEO 任正非面对面交流。 交流中，任正非透露，在「面对外部封锁打压，遇到很多困难」时，自己坚信「不去想困难，干就完了，一步一步往前走」。&lt;/p&gt; 
&lt;p&gt;面对「人工智能（AI）的未来前景怎么看」时，任正非表示，「人工智能也许是人类社会最后一次技术革命」。其解释称：&lt;/p&gt; 
&lt;p&gt;人工智能发展要经历数十年、数百年。不要担心，中国也有很多优势。任正非还强调，人工智能在技术上的要害，是要有充足的电力、发达的信息网络。发展人工智能要有电力保障，中国的发电、电网传输都是非常好的，通信网络是世界最发达的，东数西算的理想是可能实现的。&lt;/p&gt; 
&lt;p&gt;另外，任正非还提到了其他优势：芯片问题其实没必要担心，用叠加和集群等方法，计算结果上与最先进水平是相当的。软件方面，将来是千百种开源软件满足整个社会需要。(@ APPSO)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、OpenAI 前首席科学家：AI 会完成我们能做的一切&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;日前，OpenAI 前首席科学家 Ilya Sutskever 返回母校多伦多大学，在接受荣誉博士学位时发表了个人演讲。&lt;/p&gt; 
&lt;p&gt;Ilya 开篇就分享了个人心态：接受现实，尽量不去后悔过去，努力改善现状。接着，他表示，大家都处在一个真正不同寻常的时代——因为 AI 的出现。&lt;/p&gt; 
&lt;p&gt;Ilya 坦言，如今的 AI 已经在很大程度上改变了「学生」的含义，并且远不止于此。Ilya 表示，AI 能做的事情已经远超想象，而我们眼下的挑战是「AI 会如何影响我们的工作和职业」，同时也有更深层次的挑战——未来 AI 的发展将是前所未有、极其剧烈的。&lt;/p&gt; 
&lt;p&gt;他还强调：「任何我能学到的东西，任何你们中的任何一个人能够学到的东西，AI 都能学会。那么，为什么我这么确信呢？我们怎么知道 AI 将来能做这些事情呢？原因是，我们每个人的大脑都是一个生物计算机。我们有大脑，就是因为它是一个生物计算机。那么，既然人类的生物计算机能做这些事情，为什么数字计算机、也就是数字大脑不能做同样的事呢？这就是为什么我认为 AI 最终能做到所有我们能做到的事情的原因。」&lt;/p&gt; 
&lt;p&gt;对于「当 AI 能做我们所有的工作时，会发生什么？」这一问题，Ilya 认为十分需要重视。他提醒：「你可能不关心 AI，但 AI 会主动来关心你」。&lt;/p&gt; 
&lt;p&gt;因此，Ilya 建议大家，在 AI 时代下，只要你开始使用 AI，去了解当下最先进的 AI 能做些什么，你就会逐渐建立起一种直觉。「我认为，通过使用 AI 并观察当今最先进的 AI 能做什么，你会形成一种直觉。随着 AI 在一年、两年、三年内不断改进，这种直觉会变得更强烈」。慢慢的，我们能对 AI 的发展有一定的概念，自然也不会再对 AI 产生恐惧，并能够掌控 AI，激发新技术给我们带来的力量。&lt;/p&gt; 
&lt;p&gt;最后，Ilya 强调：&lt;/p&gt; 
&lt;p&gt;AI 带来的挑战是人类历史上最大的挑战。但如果我们应对得当，所获得的回报也将是人类历史上最大的回报。&lt;/p&gt; 
&lt;p&gt;演讲全程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FzuZ2zaotrJs%3Ffeature%3Dshared" target="_blank"&gt;https://youtu.be/zuZ2zaotrJs?feature=shared&lt;/a&gt; （@APPSO、@机器之心）&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fa92df803a9e43d2a75ae183d839112a4a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多 Voice Agent 学习笔记：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGe3xHvHjsvm3cNEMxiLIEQ" target="_blank"&gt;实时多模态如何重塑未来交互？我们邀请 Gemini 解锁了 39 个实时互动新可能丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSqXLZvq_zwWDcOVKbAb7HQ" target="_blank"&gt;级联 vs 端到端、全双工、轮次检测、方言语种、商业模式…语音 AI 开发者都在关心什么？丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7QPgzp8kDR_9iHUa4oFeiA" target="_blank"&gt;a16z 最新报告：AI 数字人应用层即将爆发，或将孕育数十亿美金市场丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUM1qs2IT1S6kJ4sZf_k3uA" target="_blank"&gt;a16z 合伙人：语音交互将成为 AI 应用公司最强大的突破口之一，巨头们在 B2C 市场已落后太多丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWI0gE4x-TZG0gdgSV_bVSA" target="_blank"&gt;ElevenLabs 33 亿美元估值的秘密：技术驱动+用户导向的「小熊软糖」团队丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVsgDF8F1hxy3-e5-ntGbw" target="_blank"&gt;端侧 AI 时代，每台家居设备都可以是一个 AI Agent 丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4K5wdUEDxrs1afHZSAIuqg" target="_blank"&gt;世界最炙手可热的语音 AI 公司，举办了一场全球黑客松，冠军作品你可能已经看过&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJCYzc1Ig-HFFAN3sTQDYbw" target="_blank"&gt;多模态 AI 怎么玩？这里有 18 个脑洞&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrN9poD_X6SDxRLMsudg_xg" target="_blank"&gt;AI 重塑宗教体验，语音 Agent 能否成为突破点？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeFS1mnAbUpAJdiLSSGWpSA" target="_blank"&gt;对话 TalktoApps 创始人：Voice AI 提高了我五倍的生产力，语音输入是人机交互的未来&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;写在最后：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们欢迎更多的小伙伴参与 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。&lt;/p&gt; 
&lt;p&gt;对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8e54bdf0d246189e94f7cf3b2e418da213.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;素材来源官方媒体/网络新闻&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354682</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354682</guid>
      <pubDate>Sat, 10 May 2025 11:42:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>微软开始测试 Windows 11 的新版「开始」菜单</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软现在&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F06%2F09%2Fannouncing-windows-11-insider-preview-build-26200-5641-dev-channel%2F" target="_blank"&gt;允许&lt;/a&gt;&lt;/u&gt; Windows 11 测试人员试用全新、更大的「开始」菜单，该菜单包含可滚动的界面、新的视图和更多可自定义功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-133f02d0def812a3023b1918667ec4cbb4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows Insider 团队解释说：「我们更新了可滚动的「开始」菜单，让您可以更轻松地启动应用。」 这个可滚动的「开始」菜单意味着所有应用现在都位于顶层，因此您无需导航到第二个页面即可找到应用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95c628f3783c80a5c0be69c6167b9d9f144.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更新后的「开始」菜单有两个新视图可供选择&lt;/p&gt; 
&lt;p&gt;您还可以禁用推荐部分，以便查看更多应用，并选择两种新视图：类别视图和网格视图。默认类别视图按类别对应用进行分组，而网格视图则按字母顺序排列，更像传统的列表视图。&lt;/p&gt; 
&lt;p&gt;微软还根据设备或显示器的屏幕尺寸放大了「开始」菜单。Windows Insider 团队表示：「在较大的设备上，用户可以在「开始」菜单中看到 8 列固定应用、6 条推荐和 4 列类别。在较小的设备上，你将看到 6 列固定应用、4 条推荐和 3 列类别。」&lt;/p&gt; 
&lt;p&gt;开始菜单上还新增了一个移动设备按钮，可用于展开或折叠与开始菜单一起显示的「Phone Link」界面。微软还允许 Windows 11 用户选择显示哪些锁屏小部件，允许添加或删除小部件，并重新排列它们以适应锁屏。&lt;/p&gt; 
&lt;p&gt;最后，最新的 Dev Channel 版本还包含一个新的 Gamepad 键盘更新，可让您使用控制器通过 PIN 码登录 PC。这是微软改进 Windows 11 在手持游戏设备（例如最近发布的 ROG Xbox Ally 设备）上的运行效果的一部分。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美团发布 AI Coding Agent 工具「NoCode」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;美团&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FdByPiajMM7fX109GSotLVQ" target="_blank"&gt;上线&lt;/a&gt;了名为「NoCode」的&amp;nbsp;&lt;/span&gt;AI Coding Agent 工具&lt;span&gt;，用户通过自然语言对话即可生成网页、小程序等应用，并支持实时修改、一键部署。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;NoCode 是一款无需编程背景和经验，通过自然语言和对话形式，即可快速生成应用的平台。可帮助不同角色以"零代码"的方式创建个人提效工具、产品原型、可交互页面等，降低开发门槛，实现创意释放。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;NoCode&lt;/span&gt;功能亮点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自然语言编程&lt;/strong&gt;：使用自然语言描述想法，NoCode 自动解读并转化为完整功能，无需编程经验即可生成可用能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时预览效果&lt;/strong&gt;：根据对话内容即时渲染、呈现页面，可实时查看每次对话后的实际效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;局部定位修改&lt;/strong&gt;：使用 Visual Edit 功能，可针对定位内容进行局部修改及完善；同时支持版本间对比、回退，保障每一步都「有迹可循」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;一键部署分享&lt;/strong&gt;：应用完成后，代码将自动上传到仓库，可直接分享链接给他人使用，简化发布流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0610/184826_5IfE_2720166.png" width="750" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;体验地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnocode.cn%2F" target="_blank"&gt;https://nocode.cn/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354675/meituan-nocode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354675/meituan-nocode</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>法国 AI 初创公司 Mistral 将发布推理模型 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F06%2F10%2Fmicrosoft-backed-ai-lab-mistral-debuts-reasoning-model-to-rival-openai.html" target="_blank"&gt;根据 CNBC 的报道&lt;/a&gt;，法国 AI 初创公司 Mistral 将推出其首个推理模型 Magistral，加入与 OpenAI、DeepSeek 等全球领先企业的竞争。&lt;/p&gt; 
&lt;p&gt;&lt;img height="898" src="https://static.oschina.net/uploads/space/2025/0610/183614_pyVq_2720166.png" width="2104" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mistral 首席执行官亚瑟・门施介绍道，Magistral 不仅擅长数学和编码，还能够实现欧洲语言的逻辑推理，突破了美国和中国模型的语言局限性。&lt;/p&gt; 
&lt;p&gt;今年 3 月，Mistral 已发布 240 亿参数的 Mistral Small 3.1 模型，该模型以低成本实现本地运行，部分性能甚至超越 OpenAI 的 GPT-4o mini。5 月，Mistral 进一步推出了 Medium 3 模型，这款中量级模型在保持前沿性能的同时，显著降低了企业使用成本，每百万 Token 输入仅需 0.4 美元。&lt;/p&gt; 
&lt;p&gt;Mistral 通过技术创新，正逐步提升其在全球 AI 市场的竞争力，并为多语言应用场景提供更优解决方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</guid>
      <pubDate>Sat, 10 May 2025 10:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度网盘、文库联合发布「AI 相机」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;6 月 10 日，在百度 AI Day 开放日上，百度网盘、文库联合发布行业首个「拍存管一体」的「AI 相机」，具备全模态输入、处理、输出的系统化完整交付 AI 能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-acb055f53ca9b3a5f087e132e834b1d7f25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 相机已在百度网盘 App 上线，并已接入百度文库 App。百度文库还宣布多智能体协作能力「GenFlow 超能搭子」全新升级为 2.0 版本，使其成为率先实现全场景满足、全链路覆盖的多智能体协作应用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/183107_JyHR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GenFlow 超能搭子 2.0 依托于文库、网盘海量的公私域数据和用户记忆库，可完整交付更懂用户的个性化内容；它可以自主调用各种模型和工具，一次性并行生成多模态、多格式内容；它还支持后链路的编辑环节，在内容创作上灵活度更高。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354672</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354672</guid>
      <pubDate>Sat, 10 May 2025 10:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 时代的「数据之困」，什么是 AI-Ready Data</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;人工智能（AI）无疑是当今科技领域最激动人心的变革力量，它横跨各个行业，展现出重塑未来的巨大潜力。从智能客服到精准医疗，从自动驾驶到个性化推荐，AI 的触角几乎无所不至。然而，在这股 AI 浪潮之下，一个普遍的困境也日益凸显：许多雄心勃勃的 AI 项目在起步后便步履维艰，难以实现预期的投资回报，甚至大量试点项目最终未能成功转化为生产力。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;这种「雷声大，雨点小」的现象，不禁让人深思：&lt;strong&gt;AI 的理想与现实之间，究竟横亘着怎样的鸿沟？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;追根溯源，这一困境的核心往往直指 AI 的「食粮」——数据。数据是驱动 AI 系统洞察、预测和决策的燃料。然而，企业在将数据应用于 AI 时，普遍面临着一系列严峻挑战：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据质量参差不齐&lt;/strong&gt;：不准确、不完整、标签错误或充满噪声的数据是 AI 项目失败的常见元凶。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E5%25AD%25A4%25E5%25B2%259B%26zhida_source%3Dentity" target="_blank"&gt;数据孤岛&lt;/a&gt;&lt;/span&gt;与集成难题&lt;/strong&gt;：数据往往散落在企业内部各个孤立的系统中，格式各异，难以有效整合和统一访问。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;缺乏标准化与有效治理&lt;/strong&gt;：数据格式不统一、元数据缺失、数据血缘关系不清晰以及&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E6%25B2%25BB%25E7%2590%2586%26zhida_source%3Dentity" target="_blank"&gt;数据治理&lt;/a&gt;&lt;/span&gt;机制的薄弱，都为 AI 应用埋下了隐患。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;这些普遍存在的数据问题，实际上反映了许多企业在 AI 战略上的一个深层错位：即，&lt;strong&gt;对 AI 技术本身抱有极高期望，却忽视了构建坚实数据基础的重要性&lt;/strong&gt;。企业纷纷投入巨资采购先进的 AI 工具和算法，但如果供给这些「智能引擎」的是劣质「燃料」，那么再强大的算法也难以发挥其应有的效能。AI 的雄心壮志与薄弱的数据能力之间形成的巨大反差，正是导致众多 AI 项目折戟的关键。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;面对 AI 时代的「数据之困」，企业迫切需要一种能够有效解决上述问题、真正释放 AI 潜能的数据形态。于是，「AI-ready Data」 的概念应运而生。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;什么是 AI-ready Data？为何如此重要？&lt;/strong&gt;&lt;/h2&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//be5fce4d40a25157514e64dbd6664171.jpg" width="1024" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data：超越数据的「数据」&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data，顾名思义，是指那些经过精心准备、结构化处理和严格验证，能够以最佳效能服务于人工智能应用的数据。这类数据使得 AI 算法能够高效地学习模式、做出准确预测并生成有价值的洞察。它强调的不仅仅是拥有海量数据，更在于数据的质量、结构和相关性，确保数据能够被 AI 算法高效处理和分析。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;打个比方，如果说 AI 是一个高性能引擎，那么 AI-ready Data 就是为其量身定制的、经过提纯的高辛烷值燃料，确保引擎能够以巅峰状态持续运转。它不是原始、未经雕琢的「数据矿石」，而是经过精炼、可以直接投入 AI「熔炉」的「高品位原料」。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data 不可或缺的价值&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 之所以关键，在于它能为 AI 的成功应用带来一系列实实在在的好处。高质量、准备充分的数据是训练出高精度、高可靠性 AI 模型的基础，直接决定了模型的准确性和有效性，正所谓「Garbage in, Garbage out」。通过大幅减少数据科学家在数据清洗和整理上耗费的巨量时间，AI-ready Data 能够显著加速 AI 项目的落地进程，使团队更专注于模型创新与优化。它是构建稳健、可扩展 AI 系统，使其能处理复杂任务并大规模有效运作的基石，最终通过驱动更明智决策、提升运营效率、降低成本和增强市场竞争力，为企业创造切实的商业价值。同时，清晰、可溯源且管理良好的数据还有助于企业遵守日益严格的数据法规与 AI 伦理规范，为 AI 系统的透明度和问责制提供保障。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;理解 AI-ready Data 的价值，更要认识到它并非一劳永逸的静态目标，而是一个持续演进的动态过程，需要随 AI 发展、业务变化及法规更新不断调整优化，其及时性、可扩展性和定期刷新的需求都印证了这是一项长期投入。追求 AI-ready Data 的本质，是将数据管理从单纯的「收集」提升到战略性的「策展」与「价值创造」层面，要求企业带着明确的 AI 应用目标有意识地准备数据，使数据管理从后端支持转变为驱动创新的核心环节。更深远地看，实现数据 AI 就绪的努力将催化组织在数据治理、数据素养和跨部门协作等方面的全面成熟，打破数据孤岛，提升整体数据能力，从而孕育出惠及企业全局的数据驱动文化，这其中，人的因素和流程优化与技术平台同等重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;不同领域的 AI-ready Data 特征上有什么区别？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;尽管 AI-ready Data 的核心原则具有普适性，但在不同的 AI 细分领域，其具体的形态、准备的侧重点以及在模型训练和推理阶段的要求，都会呈现出显著的差异。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;机器学习中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;传统的机器学习是许多企业 AI 应用的起点，其对数据的要求相对成熟和明确。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：ML 模型的数据通常是结构化的表格数据，例如 CSV 文件或数据库中的表，其中每一行代表一个样本，每一列代表一个特征。对于监督学习任务，数据中还会包含一个目标列或标签列，用以指示模型需要预测的结果 。虽然 ML 也可以处理文本、图像等非结构化数据，但这往往需要通过复杂的特征工程将其转换为结构化的数值特征，才能被传统 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：ML 模型的数据通常是结构化的表格数据，例如 CSV 文件或数据库中的表，其中每一行代表一个样本，每一列代表一个特征。对于监督学习任务，数据中还会包含一个目标列或标签列，用以指示模型需要预测的结果 。虽然 ML 也可以处理文本、图像等非结构化数据，但这往往需要通过复杂的特征工程将其转换为结构化的数值特征，才能被传统 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：用于预测客户流失的数据集，可能包含客户的人口统计信息、消费行为、服务使用频率等特征；用于垃圾邮件检测的已标注邮件数据集。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//3911ebe7c46166407d1fad003e28b19d.jpg" width="600" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;深度学习中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;深度学习以其处理复杂模式和大规模数据的能力，在图像识别、自然语言处理等领域取得了革命性进展，其对数据的需求也更为「贪婪」。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：深度学习模型的训练通常依赖于大规模的非结构化以及多模态数据，如图像、音频、文本和视频。这些数据往往需要进行大量且精准的标注，例如物体检测任务中的边界框、图像分割的掩码、语音识别的文本转录等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：数据的「量」和「多样性」是深度学习成功的关键。同时，标注的一致性和准确性对模型性能至关重要，高质量的数据集是实现准确语音识别等任务的基础。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：著名的 ImageNet 数据集包含数百万张标注图像；LibriSpeech 数据集包含数千小时的转录音频；维基百科的文本转储等大型文本语料库。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//22383fbb9f6e44994f6c4a867cb18fce.jpg" width="700" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E7%2594%259F%25E6%2588%2590%25E5%25BC%258FAI%26zhida_source%3Dentity" target="_blank"&gt;生成式 AI&lt;/a&gt;&lt;/span&gt;与 RAG 系统中的 AI-Ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;具体到生成式 AI 领域，其对 AI-ready data 的需求首先体现在模型预训练和微调阶段。基础模型的构建依赖于规模宏大、内容多样甚至多模态的数据集，涵盖了从公开网页文本、专业书籍到代码、图像和音视频等广泛来源。而模型的微调则更侧重于特定领域内高质量、高相关性的专业数据集。贯穿始终的是对数据合规性、版权以及潜在偏见的严格审视与伦理考量，负责任的数据策略是实现 AI 价值的前提。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在众多生成式 AI 应用中，检索增强生成（RAG）架构尤为依赖 AI-ready data 的精细化准备。RAG 通过引入外部知识源来提升模型输出的准确性、时效性和深度，其核心挑战在于如何将这些外部知识高效、准确地「喂」给 LLM。这一过程的关键瓶颈与优化焦点在于数据切片（Chunking）。当前主流的数据切片方法往往显得「粗糙」。许多系统简单地采用固定字符数、按句子或段落等规则进行切分，这种方式极易破坏文本原有的语义完整性，可能导致一个完整的逻辑思路或上下文联系在切分中断裂，进而影响大模型对信息的准确理解和答案生成的质量。同时，这些简单方法常常忽略文档的内在结构，如章节、标题、列表和表格等，而这些结构本身就承载着重要的语义信息。面对不同类型（如法律合同、技术手册、研究论文或代码）和复杂格式的文档，通用的「一刀切」切片策略往往难以达到理想效果。切片的大小也需精妙平衡：过小则可能上下文不足，难以支撑复杂问答；过大则可能引入过多噪声，稀释关键信息。此外，多数在数据预处理阶段完成的静态切片，也缺乏对用户动态查询意图的灵活适应性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;因此，理想的 RAG 数据切片策略应向更智能化、语义驱动的方向演进。其核心目标是&lt;strong&gt;最大程度地保持语义单元的完整性&lt;/strong&gt;，切分点应尽可能选在自然的语义边界。同时，要充分感知并利用文档的固有结构信息，如将标题及其对应内容作为一个单元，或整体处理表格及其注释。为了保持切分后各知识块之间的上下文连贯，可以采用重叠切片技术，或构建具有内在联系的层级式块结构，并通过元数据明确记录它们之间的逻辑关系。针对不同内容特性，应采用内容自适应的切片逻辑。至关重要的是，每个切分后的数据块都应附带丰富的元数据，如原始文档出处、章节信息、主题标签等，这些元数据不仅能提升检索的精确度，还能为大模型提供更全面的背景知识，从而增强其输出内容的可信度和可溯源性。&lt;/p&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f2fb964dde666532d21ce8a16e7310fe.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DPhysical%2BAI%26zhida_source%3Dentity" target="_blank"&gt;Physical AI&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Physicla AI，如机器人和自动驾驶系统，需要在复杂的物理世界中进行感知、决策和行动，其数据需求具有独特性和挑战性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;训练数据&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：来自多种传感器的融合数据，包括激光雷达的点云数据、摄像头的图像/视频流、雷达信号、惯性测量单元数据、GPS 定位信息、触觉传感器数据等。此外，还包括机器人的关节状态、运动轨迹、与环境的交互数据，以及大量来自模拟环境的合成数据。这类数据通常是时间序列数据，需要精确的时间同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：要求数据能够高保真地复现真实世界的物理特性和动态变化，覆盖多样化的环境条件（如不同天气、光照）、复杂的交互场景和罕见的边缘案例。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：自动驾驶领域的&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DWaymo%2BOpen%2BDataset%26zhida_source%3Dentity" target="_blank"&gt;Waymo Open Dataset&lt;/a&gt;&lt;/span&gt;、&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DnuScenes%25E6%2595%25B0%25E6%258D%25AE%25E9%259B%2586%26zhida_source%3Dentity" target="_blank"&gt;nuScenes 数据集&lt;/a&gt;&lt;/span&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;推理数据&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：来自机器人或车辆上搭载的各种传感器的实时、连续的数据流。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：数据处理的低延迟性对于物理 AI 系统做出及时、安全的决策和行动至关重要。系统还需要对传感器噪声、数据丢失或遮挡等情况具有鲁棒性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f6effd68cabc43be465afc81f71a66c4.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;审视这四大 AI 领域对数据的需求演变，可以发现一个清晰的趋势：AI 模型对数据的「胃口」越来越大，要求的数据集规模日益庞大，多样性和复杂性也与日俱增。从机器学习对结构化数据的依赖，到深度学习对海量非结构化数据的渴求，再到生成式 AI 对网络规模多模态数据的吞噬，以及 Physical AI 对高维、多传感器融合数据的整合，无不体现了这一趋势。这种趋势意味着，数据的「AI 就绪」不仅关乎数据本身的质量和形态，也对底层的数据存储、处理和管理技术平台提出了更高的要求。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;打造 AI 的坚实基础：通往 AI-ready Data 之路&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;将原始数据转化为 AI-ready Data，是一项涉及多个步骤的持续性系统工程，而非一蹴而就的任务。这需要随着 AI 技术、业务需求和数据源的变化而不断演进和优化，是一个动态的、持续改进的过程。一个典型的数据准备流程始于数据收集与获取，即从多样化的内外部来源汇集原始数据，&lt;strong&gt;尤其值得强调的是，在 AI 时代，企业自身积累的、独特的内部数据是构建差异化竞争优势和深化护城河的核心战略资产，对其的有效盘活与利用是首要任务。&lt;/strong&gt;随后是数据清洗与预处理，旨在识别并修正原始数据中的错误、不一致、缺失值和重复项，以提升数据质量。接着进行数据转换与丰富，将数据转化为适合 AI 模型的格式，可能包括特征工程、数据聚合，并通过添加元数据等方式增强数据上下文。对于监督学习任务，准确的数据标注是不可或缺的一环。在数据投入训练之前，需进行严格的数据验证与质量保证。最后，贯穿整个数据生命周期的是数据治理与安全，要求企业建立清晰的管理政策，确保数据合规、安全。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 并非遥不可及的理想概念，而是成功且可靠的人工智能应用的坚实基石。正如高质量原材料是优质产品的先决条件，高质量的 AI-ready Data 是构建高性能 AI 模型的根本保障，&lt;strong&gt;特别是当这些数据源自企业内部，承载着特定业务洞察和运营经验时，其转化为 AI 洞察的能力，将直接赋能企业构建难以复制的竞争壁垒。&lt;/strong&gt;它能够显著提升模型的准确性和可靠性，加速 AI 应用的研发部署，并最终驱动商业价值和创新突破。因此，企业应将提升数据就绪水平，尤其是内部数据的「AI 就绪」水平，视为一项战略要务，而非项目启动后的被动补救。通往 AI 驱动的创新之路，很大程度上是由对自身独特数据资产的深度挖掘和高质量准备铺就的。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;拥抱 AI-ready Data，意味着正视数据的挑战，投入必要资源，建立完善的流程和文化，核心目标在于充分释放企业内部沉淀数据的潜在价值。这无疑是一项艰巨的任务，但其回报——通过人工智能洞察自身运营、优化决策、创新产品与服务，从而在市场竞争中占据领先地位——将是无可估量的。生成式 AI 并非短暂趋势，而是一场深刻的变革，而适配这种变革的数据基础设施和数据就绪能力，&lt;strong&gt;特别是将企业独有的内部数据转化为驱动 AI 的优质燃料的能力，将是企业在这场变革中深化护城河、立于不败之地的关键。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354670</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354670</guid>
      <pubDate>Sat, 10 May 2025 10:26:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>RWKV 2025 生态内容征集大赛 | 5 月投稿作品及评审结果</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;大家好，我们在 2024 年底推出了 「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生态内容征集大赛&lt;/a&gt;」，公开征集 RWKV 相关的作品，包括但不限于 RWKV 相关的论文、讲解 RWKV 的教程，以及基于 RWKV 的应用等。&lt;/p&gt; 
&lt;p&gt;2025 年 5 月，活动共收到 RWKV 生态作品投稿 &lt;strong&gt;2 份&lt;/strong&gt;，包括 &lt;strong&gt;1 篇论文、1 个教程&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文将公布 2025 年 5 月的活动投稿作品及评审结果。&lt;/p&gt; 
&lt;h2&gt;评审结果&lt;/h2&gt; 
&lt;h3&gt;评审结果省流版&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名称&lt;/th&gt; 
   &lt;th&gt;作品分类&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初评奖项&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;biomems&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-V7 模型解析与实战：架构原理、机制剖析及自定义微调模型效果展示&lt;/td&gt; 
   &lt;td&gt;教程&lt;/td&gt; 
   &lt;td&gt;坤&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下面是「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生态内容征集大赛&lt;/a&gt;」 5 月投稿获奖的作品介绍。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;论文类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.11165" target="_blank"&gt;https://arxiv.org/abs/2505.11165&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：biomems&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;项目介绍：论文提出了一种新的异步到同步框架 EVA，用于实时事件相机数据处理&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;该框架基于 RWKV-6 构建了高效的异步编码器，实现了逐事件的表示更新，并采用自监督学习方法获得具有高度泛化能力的事件表示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="Maximizing Asynchronicity" src="https://oscimg.oschina.net/oscnet/up-3ca302b9d83762576c1d83a5c2add0e09c0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;教程类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-V7 模型解析与实战：架构原理、机制剖析及自定义微调模型效果展示&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F1904346608985944244%3Fshare_code%3D1nLMwML5XPvsB%26utm_psn%3D1904552110802055283" target="_blank"&gt;https://zhuanlan.zhihu.com/p/1904346608985944244?share_code=1nLMwML5XPvsB&amp;amp;utm_psn=1904552110802055283&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：坤&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;项目介绍：从原理解析到微调实践的全流程教程&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;首先带领初学者一起初步理解 RWKV 架构，然后使用 RWKV-PEFT 微调仓库进行了全流程的微调并展示了微调效果，在学习原理的同时，微调属于自己的 RWKV。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="RWKV-V7 模型解析与实战" src="https://oscimg.oschina.net/oscnet/up-0c74d7e4f003a4e0322e3aee4c8f3e90ec4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;奖品/奖金发放规则&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;实物奖品（RWKV 周边等）&lt;strong&gt;以&lt;/strong&gt;顺丰快递&lt;/strong&gt;方式发出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;奖金&lt;/strong&gt;以&lt;strong&gt;转账或第三方线上平台&lt;/strong&gt;等方式发放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情况下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;领取奖金，团队内部&lt;strong&gt;自行协商分配奖金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿与奖项升级&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均会获得&lt;strong&gt;评审意见&lt;/strong&gt;。请根据评审意见优化你的作品，然后可&lt;strong&gt;再次投稿以升级奖项&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;奖项成功升级时，我们将补发&lt;strong&gt;前后两个奖金的差价&lt;/strong&gt;。例如投稿作品从铁奖（888 元）升级到银奖（2888 元），则补发 2888-888=2000 元奖金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活动海报&lt;/strong&gt;，欢迎各位转发！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4e11c3df39730d4d504ca57e04f84ed60f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活动最终解释权归元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354657</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354657</guid>
      <pubDate>Sat, 10 May 2025 09:42:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
  </channel>
</rss>
