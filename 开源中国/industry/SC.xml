<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 19 Jun 2025 12:45:02 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>马斯克驳斥 xAI 巨额亏损传闻：每月烧钱 10 亿美元纯属无稽之谈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有媒体报道称，科技巨头埃隆・马斯克创办的人工智能初创公司 xAI 每月烧钱高达 10 亿美元，这一说法引发了广泛关注。消息称，xAI 在构建先进的 AI 模型方面的成本远远超过其收入增长，公司的资金需求愈加迫切。对此，马斯克进行了强烈反驳，称这些报道 「纯属胡说八道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-34a4735e7445256b266cb4625e29a62693a.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 自 2023 年成立以来，正积极寻求通过债务和股权融资来填补资金缺口，目标是融资 93 亿美元。尽管如此，马斯克合并了 xAI 与社交媒体平台 X，令合并后的新公司的估值达 1130 亿美元，其中 xAI 的估值为 800 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据相关人士透露，xAI 的支出速度在整个 AI 行业中显得尤为显著。公司预计在未来三个月内将花费超过一半的融资金额，而全年亏损预计达到 130 亿美元。相比之下，竞争对手 OpenAI 预计在 2025 年的收入将达到 127 亿美元，而 xAI 在同年仅预计收入 5 亿美元，明年才有可能突破 20 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;马斯克的巨大个人魅力和资源，使得 xAI 有理由保持乐观。他曾在特斯拉和 SpaceX 的早期阶段也经历了类似的巨额亏损，然而这些项目最终都取得了成功。马斯克相信，xAI 将在 2027 年实现盈利，尽管当前仍需与时间赛跑，以应对巨额支出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 计划利用与 X 平台的整合，利用其庞大的数据档案来训练 AI 模型，从而降低昂贵的数据费用。虽然目前 xAI 正在进行大规模的资金筹集，但公司对于未来的发展前景充满信心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356227</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356227</guid>
      <pubDate>Sun, 11 May 2025 10:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Boot 启动优化实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网服务器团队- Liu Di&lt;/p&gt; 
 &lt;p&gt;本文系统性分析并优化了一个 Spring Boot 项目启动耗时高达 280 秒的问题。通过识别瓶颈、优化分库分表加载逻辑、异步初始化耗时任务等手段，最终将启动耗时缩短至 159 秒，提升近 50%。文章涵盖启动流程分析、性能热点识别、异步初始化设计等关键技术细节，适用于大型 Spring Boot 项目的性能优化参考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;文章太长？1 分钟看图抓住核心观点👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//de4a19ad8ae5ee03f930e1ffa71b9716.gif" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、前言&lt;/h1&gt; 
&lt;p&gt;随着业务的发展，笔者项目对应的 Spring Boot 工程的依赖越来越多。随着依赖数量的增长，Spring 容器需要加载更多组件、解析复杂依赖并执行自动装配，导致项目启动时间显著增长。在日常开发或测试过程中，一旦因为配置变更或者其他热部署不生效的变更时，项目重启就需要等待很长的时间影响代码的交付。加快 Spring 项目的启动可以更好的投入项目中，提升开发效率。&lt;/p&gt; 
&lt;p&gt;整体环境介绍：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Spring 版本：4.3.22&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Spring Boot 版本：1.5.19&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU：i5-9500&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内存：24GB&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化前启动耗时：280 秒&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、Spring Boot 项目启动流程介绍&lt;/h1&gt; 
&lt;p&gt;Spring Boot 项目主要启动流程都在 org.spring-&lt;/p&gt; 
&lt;p&gt;framework.boot.SpringApplication#run(java.lang.String...) 方法中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public ConfigurableApplicationContext run(String... args) {
    StopWatch stopWatch = new StopWatch();
    stopWatch.start();
    // Spring 上下文
    ConfigurableApplicationContext context = null;
    FailureAnalyzers analyzers = null;
    configureHeadlessProperty();
    // 初始化 SpringApplicationRunListener 监听器
    SpringApplicationRunListeners listeners = getRunListeners(args);
    listeners.starting();
    try {
        ApplicationArguments applicationArguments = new DefaultApplicationArguments(
                args);
        // 环境准备
        ConfigurableEnvironment environment = prepareEnvironment(listeners,
                applicationArguments);
         // 打印 banner
        Banner printedBanner = printBanner(environment);
        // 创建上下文
        context = createApplicationContext();
        analyzers = new FailureAnalyzers(context);
        // 容器初始化
        prepareContext(context, environment, listeners, applicationArguments,
                printedBanner);
        // 刷新容器内容
        refreshContext(context);
        afterRefresh(context, applicationArguments);
        // 结束监听广播
        listeners.finished(context, null);
        stopWatch.stop();
        if (this.logStartupInfo) {
            new StartupInfoLogger(this.mainApplicationClass)
                    .logStarted(getApplicationLog(), stopWatch);
        }
        return context;
    } catch (Throwable ex) {
        handleRunFailure(context, listeners, analyzers, ex);
        throw new IllegalStateException(ex);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到在启动流程中，监听器应用在了应用的多个生命周期中。并且 Spring Boot 中也预留了针对 listener 的扩展点。我们可以借此实现一个自己的扩展点去监听 Spring Boot 的每个阶段的启动耗时，实现如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Slf4j
public class MySpringApplicationRunListener implements SpringApplicationRunListener{
    private Long startTime;
    public MySpringApplicationRunListener(SpringApplication application, String[] args){
    }
    @Override
    public void starting(){
        startTime = System.currentTimeMillis();
        log.info("MySpringListener 启动开始 {}", LocalTime.now());
    }
    @Override
    public void environmentPrepared(ConfigurableEnvironment environment){
        log.info("MySpringListener 环境准备，准备耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextPrepared(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文准备，耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextLoaded(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文载入，耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
   @Override
   public void finished(ConfigurableApplicationContext context, Throwable exception){
        log.info("MySpringListener 结束，耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接着还需要在 classpath/META-INF 目录下新建 spring.factories 文件，并添加如下文件内容：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;org.springframework.boot.SpringApplicationRunListener=com.vivo.internet.gameactivity.api.web.MySpringApplicationRunListener
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;至此，借助 Listener 机制，我们能够追踪 Spring Boot 启动各阶段的耗时分布，为后续性能优化提供数据支撑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e19075cd485d32e7d5029945fd7ba604.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;contextLoaded 事件是在 run 方法中的 prepareContext() 结束时调用的，因此 contextLoaded 事件和 finished 事件之间仅存在两个语句：refreshContext(context) 和 afterRefresh&lt;/p&gt; 
&lt;p&gt;(context,applicationArguements) 消耗了 285 秒的时间，调试一下就能发现主要耗时在 refreshContext() 中。&lt;/p&gt; 
&lt;h1&gt;三、AbstractApplicationContext#refresh&lt;/h1&gt; 
&lt;p&gt;refreshContext() 最终调用到 org.spring-framework.context.support.AbstractApplicationContext#refresh 方法中，这个方法主要是 beanFactory 的预准备、对 beanFactory 完成创建并进行后置处理、向容器添加 bean 并且给 bean 添加属性、实例化所有 bean。通过调试发现，finishBeanFactoryInitialization(beanFactory) 方法耗时最久。该方法负责实例化容器中所有的单例 Bean，是启动性能的关键影响点。&lt;/p&gt; 
&lt;h1&gt;四、找出实例化耗时的 Bean&lt;/h1&gt; 
&lt;p&gt;Spring Boot 也是利用的 Spring 的加载流程。在 Spring 中可以实现 InstantiationAwareBeanPost-&lt;/p&gt; 
&lt;p&gt;Processor 接口去在 Bean 的实例化和初始化的过程中加入扩展点。因此我们可以实现该接口并添加自己的扩展点找到处理耗时的 Bean。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class TimeCostCalBeanPostProcessor implements InstantiationAwareBeanPostProcessor {
    private Map&amp;lt;String, Long&amp;gt; costMap = Maps.newConcurrentMap();

    @Override
    public Object postProcessBeforeInstantiation(Class&amp;lt;?&amp;gt; beanClass, String beanName) throws BeansException {
        if (!costMap.containsKey(beanName)) {
            costMap.put(beanName, System.currentTimeMillis());
        }
        return null;
    }
    @Override
    public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {
        return true;
    }
    @Override
    public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException {
        return pvs;
    }
    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        return bean;
    }
    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
         if (costMap.containsKey(beanName)) {
            Long start = costMap.get(beanName);
            long cost = System.currentTimeMillis() - start;
            // 只打印耗时长的 bean
             if (cost &amp;gt; 5000) {
                System.out.println("bean: " + beanName + "\ttime: " + cost + "ms");
            }
        }
         return bean;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;具体原理就是在 Bean 开始实例化之前记录时间，在 Bean 初始化完成后记录结束时间，打印实例化到初始化的时间差获得 Bean 的加载总体耗时。结果如图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//28a73a7adfed28c5eff40855c8260121.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到有许多耗时在 10 秒以上的类，接下来可以针对性的做优化。值得注意的是，统计方式为单点耗时计算，未考虑依赖链上下文对整体加载顺序的影响，实际优化还需结合依赖关系分析。&lt;/p&gt; 
&lt;h1&gt;五、singletonDataSource&lt;/h1&gt; 
&lt;pre&gt;&lt;code&gt;@Bean(name = "singletonDataSource")
public DataSource singletonDataSource(DefaultDataSourceWrapper dataSourceWrapper) throws SQLException {
    //先初始化连接
    dataSourceWrapper.getMaster().init();
    //构建分库分表数据源
    String dataSource0 = "ds0";
    Map&amp;lt;String, DataSource&amp;gt; dataSourceMap = new HashMap&amp;lt;&amp;gt;();
    dataSourceMap.put(dataSource0, dataSourceWrapper.getMaster());
    //分库分表数据源
    DataSource shardingDataSource = ShardingDataSourceFactory.createDataSource
    (dataSourceMap,shardingRuleConfiguration, prop);
    return shardingDataSource;    
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;singletonDataSource 是一个分库分表的数据源，连接池采用的是 Druid，分库分表组件采用的是公司内部优化后的中间件。通过简单调试代码发现，整个 Bean 耗时的过程发生在 createDataSource 方法，该方法中会调用 createMetaData 方法去获取数据表的元数据，最终运行到 loadDefaultTables 方法。该方法如下图，会遍历数据库中所有的表。因此数据库中表越多，整体就越耗时。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//05283b802a6c9c0a6c8653f9a7f080cd.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;笔者的测试环境数据库中有很多的分表，这些分表为了和线上保持一致，分表的数量都和线上是一样的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//eee1a3f0f0dd73861b2894776a40850b.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此在测试环境启动时，为了加载这些分表会更加的耗时。可通过将分表数量配置化，使测试环境在不影响功能验证的前提下减少分表数量，从而加快启动速度。&lt;/p&gt; 
&lt;h1&gt;六、初始化异步&lt;/h1&gt; 
&lt;p&gt;activityServiceImpl 启动中，主要会进行活动信息的查询初始化，这是一个耗时的操作。类似同样的操作在工程的其他类中也存在。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class ActivityServiceImpl implements ActivityService, InitializingBean{
     // 省略无关代码
     @Override
     public void afterPropertiesSet() throws Exception {
        initActivity();
    }
     // 省略无关代码
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以通过将 afterPropertiesSet() 异步化的方式加速项目的启动。&lt;/p&gt; 
&lt;p&gt;观察 Spring 源码可以注意到 afterPropertiesSet 方法是在 AbstractAutowireCapableBeanFactory#&lt;/p&gt; 
&lt;p&gt;invokeInitMethods 中调用的。在这个方法中，不光处理了 afterPropertiesSet 方法，也处理了 init-method。&lt;/p&gt; 
&lt;p&gt;因此我们可以写一个自己的 BeanFactory 继承 AbstractAutowireCapableBeanFactory，将 invokeInitMethods 方法进行异步化重写。考虑到 AbstractAutowireCapableBeanFactory 是个抽象类，有额外的抽象方法需要实现，因此继承该抽象类的子类 DefaultListableBeanFactory。具体实现代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitListableBeanFactory extends DefaultListableBeanFactory{
     public AsyncInitBeanFactory(ConfigurableListableBeanFactory beanFactory){
         super(beanFactory);
    }
     @Override
     protected void invokeInitMethods(String beanName, Object bean, RootBeanDefinition mbd)throws Throwable {
        if (beanName.equals("activityServiceImpl")) {
            AsyncTaskExecutor.submitTask(() -&amp;gt; {
                try {
                      super.invokeInitMethods(beanName, bean, mbd);
                } catch (Throwable throwable) {
                    throwable.printStackTrace();
                }
            });
        } else {
              super.invokeInitMethods(beanName, bean, mbd);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;又因为 Spring 在 refreshContext() 方法之前的 prepareContext() 发放中针对 initialize 方法提供了接口扩展 (applyInitializers())。因此我们可以通过实现该接口并将我们的新的 BeanFactory 通过反射的方式更新到 Spring 的初始化流程之前。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public interface ApplicationContextInitializer&amp;lt;C extends ConfigurableApplicationContext&amp;gt; {
     /**
     * Initialize the given application context.
     * @param applicationContext the application to configure
     */
    void initialize(C applicationContext);

}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;改造后的代码如下，新增 AsyncAccelerate-&lt;/p&gt; 
&lt;p&gt;Initializer 类实现 ApplicationContextInitializer 接口：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncBeanFactoryInitializer implements ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt; {
    @SneakyThrows
    @Override
    public void initialize(ConfigurableApplicationContext applicationContext){
        if (applicationContext instanceof GenericApplicationContext) {
            AsyncInitListableBeanFactory beanFactory = new AsyncInitListableBeanFactory(applicationContext.getBeanFactory());
            Field field = GenericApplicationContext.class.getDeclaredField("beanFactory");
            field.setAccessible(true);
            field.set(applicationContext, beanFactory);
        }
    }
}
public class AsyncBeanInitExecutor{
    private static final int CPU_COUNT = Runtime.getRuntime().availableProcessors();
    private static final AtomicReference&amp;lt;ThreadPoolExecutor&amp;gt; THREAD_POOL_REF = new AtomicReference&amp;lt;&amp;gt;();
    private static final List&amp;lt;Future&amp;lt;?&amp;gt;&amp;gt; FUTURES = new ArrayList&amp;lt;&amp;gt;();
     /**
      * 创建线程池实例
      */
     private static ThreadPoolExecutor createThreadPoolExecutor(){
         int poolSize = CPU_COUNT + 1;
         return new ThreadPoolExecutor(poolSize, poolSize, 50L, TimeUnit.SECONDS, new LinkedBlockingQueue&amp;lt;&amp;gt;(), new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }
    /**
     * 确保线程池已初始化（线程安全）
     */
     private static void ensureThreadPoolExists(){
         if (THREAD_POOL_REF.get() != null) {
              return;
        }
        ThreadPoolExecutor executor = createThreadPoolExecutor();
         if (!THREAD_POOL_REF.compareAndSet(null, executor)) {
            executor.shutdown(); // 另一线程已初始化成功
        }
    }
    /**
     * 提交异步初始化任务
     *
     * @param task 初始化任务
     * @return 提交后的 Future 对象
     */
    public static Future&amp;lt;?&amp;gt; submitInitTask(Runnable task) {
        ensureThreadPoolExists();
        Future&amp;lt;?&amp;gt; future = THREAD_POOL_REF.get().submit(task);
        FUTURES.add(future);
        return future;
    }
    /**
     * 等待所有初始化任务完成并释放资源
     */
    public static void waitForInitTasks(){
        try {
            for (Future&amp;lt;?&amp;gt; future : FUTURES) {
                future.get();
            }
        } catch (Exception ex) {
            throw new RuntimeException("Async init task failed", ex);
        } finally {
            FUTURES.clear();
            shutdownThreadPool();
        }
    }
     /**
     * 关闭线程池并重置引用
     */
     private static void shutdownThreadPool(){
        ThreadPoolExecutor executor = THREAD_POOL_REF.getAndSet(null);
         if (executor != null) {
            executor.shutdown();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;实现类后，还需要在 META-INF/spring.factories 下新增说明 org.springframework.context.&lt;/p&gt; 
&lt;p&gt;ApplicationContextInitializer=com.xxx.AsyncAccelerateInitializer，这样这个类才能真正生效。&lt;/p&gt; 
&lt;p&gt;这样异步化以后还有一个点需要注意，如果该初始化方法执行耗时很长，那么会存在 Spring 容器已经启动完成，但是异步初始化任务没执行完的情况，可能会导致空指针等异常。为了避免这种问题的发生，还要借助于 Spring 容器启动中 finishRefresh() 方法，监听对应事件，确保异步任务执行完成之后，再启动容器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitCompletionListener implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt;, ApplicationContextAware, PriorityOrdered{
    private ApplicationContext currentContext;
    @Override
    public void setApplicationContext(ApplicationContext applicationContext)throws BeansException {
         this.currentContext = applicationContext;
    }
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event){
        if (event.getApplicationContext() == currentContext) {
            AsyncBeanInitExecutor.waitForInitTasks();
        }
    }
    @Override
    public int getOrder(){
         return Ordered.HIGHEST_PRECEDENCE;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;七、总结&lt;/h1&gt; 
&lt;p&gt;启动优化后的项目实际测试结果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2f535724d8b21204e9e881711c6acf6f.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过异步化初始化和分库分表加载优化，项目启动时间从 280 秒缩短至 159 秒，提升约 50%。这对于提升日常开发效率、加快测试与联调流程具有重要意义。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18627678</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18627678</guid>
      <pubDate>Sun, 11 May 2025 09:43:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>数据「熵增」时代，AI 如何以标准重构治理秩序?</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;Agent 热潮不减,但数据分析与治理状况却仍存在短板。据 Gartner 公司预测,到 2027 年,80% 的数据和分析治理举措或将因各类原因而失效。如何在 AI 时代重塑数据治理体系,让混乱数据重归有序,成为企业智能转型的关键命题。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;近日,在 infoQ 举办的全球人工智能开发与应用大会上,瓴羊智能数据建设与治理产品 Dataphin 高级技术专家，周鑫，受邀出席,以&lt;strong&gt;「基于统一标准的智能数据治理&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;Dataphin&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;的落地实践」&lt;/strong&gt;为主题,系统阐述了以数据标准为核心,实现可持续数据治理的方法论,以及以 AI 赋能自动化数据治理、重构复杂业务流程的实践路径。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;01&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;数据「&lt;/strong&gt;&lt;strong&gt;熵减」之道:基于统一标准,打造数据治理方法论&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「事物天生具有‘变混乱’的趋势,数据也是如此。如何将无序变得有序?按照热力学第二定律,需要从外界输入能量,并且具备感知能力。」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示:「对于数据治理来说,能量就是治理工具,感知就是标准规范。」数据治理是实现数据世界的「熵减」,它可以通过&lt;strong&gt;现状评估、制定目标、执行计划、持续监测&lt;/strong&gt;四个治理阶段,帮助数据生产者打破孤岛,实现低成本数据开发,帮助数据管理者做好资产盘点,确保数据质量与安全,帮助数据使用者便捷用数,助力决策分析。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//5ca3fd8084d8b3ffa1e3874b915a46b8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;但在现实情况中,许多数据治理的结果通常会面临失败,周鑫将其归结为四个原因:1) 治理动作分散,缺乏体系化方法论;2) 治理流程复杂,重度依赖人的能力和素质;3) 缺乏工具支撑,导致理论与实施脱节;4) 无法持续治理,治理策略难以快速调整。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c19a9aa3073e13c96e65f3ea454ed7c5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面对以上四类问题,Dataphin 提出了一套以数据标准为中心的数据治理方法论及产品化的落地。其核心逻辑为:&lt;strong&gt;聚焦&lt;/strong&gt;&lt;strong&gt;Data x AI&lt;/strong&gt;&lt;strong&gt;,用中台方法论构建统一的数据标准&lt;/strong&gt;,打造企业级好数据,帮助企业形成数据生产、数据消费、行业数据流通的数据要素服务链,驱动数据价值的释放。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「方法论的核心关键,在于以数据标准为中心。数据标准贯穿数据整个生命周期,它让数据治理具备核心抓手,不会漫无目的」,周鑫表示,&lt;strong&gt;企业需从核心业务入手,先行试点开展业务梳理与盘点工作,将相关统一纳入&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;DataCatalog&lt;/strong&gt;&lt;strong&gt;,并在此过程中逐步形成对应的数据标准。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;标准梳理完成后,平台即可开展标准构建:通过统一的数据标准,自动实现质量监控与安全分类,保障开发过程规范,阻断不规范数据开发。同时,统一标准可提升数据的可理解性与细节清晰度,实现数据从生成、开发到消费的全生命周期标准化管理。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a79214da341aeb304b867992344fd1c8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「整个治理链路就是以数据标准为中心,将传统的复杂的治理手段,简化成数据标准的梳理与治理效果的评估过程,数据符合标准的程度越高,整体数据质量也就越好」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,该方案以数据标准为核心,通过插件集成、API 注册和准实时同步等多种方式采集元数据,并统一纳入 DataCatalog,结合质量规则和安全策略进行自动识别与治理。这一方法论具备三大优势:一是&lt;strong&gt;体系化&lt;/strong&gt;,明确治理目标与路径;二是&lt;strong&gt;易落地&lt;/strong&gt;,借助一体化工具和 AI 能力,贯穿数据全生命周期;三是&lt;strong&gt;可持续&lt;/strong&gt;,以标准驱动模式便于应对业务变化,有效降低治理成本与复杂度。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;02&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;语义知识&lt;/strong&gt;&lt;strong&gt;+&lt;/strong&gt;&lt;strong&gt;流程提效,智能&lt;/strong&gt;&lt;strong&gt;Agent&lt;/strong&gt;&lt;strong&gt;多场景赋能数据治理&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;许多企业在应用 Agent 时都难免遇到一个难题:Agent 虽然具备一定的智能和对话能力,但在复杂业务场景中常常「空转」,无法真正理解业务语境、解决预期的实际问题。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,造成这一现象的根本原因,「在于数据质量偏低或数字化基础薄弱,导致 Agent 无法有效发挥价值,最终企业只能被迫放弃」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;AI 时代,优质数据至关重要,但「好数据」应如何获取?AI 又该如何赋能数据治理?&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;首先,「Agent 在没有丰富准确的语义知识下,不可能达到可生产使用的准确率」,周鑫认为,&lt;strong&gt;企业获取好数据,需要构建准确且丰富的语义知识体系&lt;/strong&gt;。Dataphin 针对这一需求,打造了包含&lt;strong&gt;元数据&lt;/strong&gt;、&lt;strong&gt;数据标准&lt;/strong&gt;、&lt;strong&gt;数据模型&lt;/strong&gt;、&lt;strong&gt;业务知识&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;四大语义知识体系。企业可以通过采集丰富且统一的元数据,建立涵盖码表、词根、值域及安全分类分级的标准体系,依托 Dataphin 智能构建的概念模型、逻辑模型和物理模型,以及对业务词条和逻辑的高效管理,实现对复杂业务知识的精准映射和应用。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e35e9b9658db17cdacdbbccf911c6633.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 为例,Dataphin 通过引入业务语义,不仅提升了问题泛化能力,还大幅提高了 SQL 匹配的准确率,显著增强了对自然语言的理解能力。实测数据显示,在 Dataphin 开放数据共享模型涵盖的 45 个典型问题中,&lt;strong&gt;简单问题的&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;strong&gt;准确率从&lt;/strong&gt;&lt;strong&gt;70%&lt;/strong&gt;&lt;strong&gt;提升至&lt;/strong&gt;&lt;strong&gt;80%&lt;/strong&gt;&lt;strong&gt;,而中等及复杂问题的准确率更是从&lt;/strong&gt;&lt;strong&gt;10%&lt;/strong&gt;&lt;strong&gt;跃升至&lt;/strong&gt;&lt;strong&gt;60%&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;其次,企业还需借助 AI,对数据治理链路进行提效。基于 TaskWeaver 改造,Dataphin 构建了具备生产化能力的 Agent 框架,覆盖研发、治理、资产问答等多个场景,显著提升了现有流程效率,拓展了 Agent 的应用边界。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 为例,系统可在识别信息不全时自动发起反问,补全后再继续处理,确保复杂业务场景下依然具备高理解力与执行准确率。同时,Dataphin 的开放能力不断演进,从传统的 API 和数据服务扩展至 MCP 模式,支持更灵活的接入方式,适配非固定流程和动态交互等复杂需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;智能找表&lt;/strong&gt;场景,Dataphin 有效解决了用户将复杂业务问题,转化为准确搜索词的难题。「引入 AI 后,你可以用业务的语言直接问,比如‘我要做客户分层’,‘我要用哪张表’,AI 会用大模型去对业务问题进行拆解和泛化,最后找关联到你已有的全域资产」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 5.png" height="366" src="https://oscimg.oschina.net/oscnet//44b7bd5fb943546e95785c6a26a72115.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;数据分析&lt;/strong&gt;场景,Dataphin 通过专辑机制与丰富的语义知识,解决了因语义知识的缺失或混乱,相似口径和命名干扰、以及海量表格带来的找表难题,显著提升了找表的效率与准确率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 6.png" height="366" src="https://oscimg.oschina.net/oscnet//5484c3d0938ae4172448aca47dd0d73a.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;数据治理&lt;/strong&gt;场景,Dataphin 通过「性别」等复杂字段特征识别,解决了正则表达式「不会写」、「看不懂」难题,取代了传统人工探查的繁琐过程,以往需要耗费十几分钟的特征识别,如今只需几十秒即可完成。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 7.png" height="460" src="https://oscimg.oschina.net/oscnet//5ada55aa58b287d443496c220aa124d5.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;数据管家&lt;/strong&gt;场景中,资产上架往往涉及表描述、字段注释、目录归属、标签分类等复杂操作,尤其在字段数量众多时,人工维护工作量大、耗时长且易出错。通过引入 AI 能力,Dataphin 支持属性信息的智能生成,可一键生成表/字段描述信息、目录、标签等,使人力成本与操作门槛大大降低。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 8.png" height="359" src="https://oscimg.oschina.net/oscnet//004299cfcc7d5766516ace7402af26ad.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;随着 AI 对复杂节点的处理能力增强,Dataphin 正在以「智能工作台」有机整合独立模块,重构整体业务流程。 「有了 AI 之后,工作台模式可以让很少的人,完成复杂的业务,每个环节都有大量 AI 和自动化能力支撑,人们干的最多的事情是进行确认」,周鑫表示,未来,AI 还将在更多场景中深度参与,从辅助提效逐步向自动化、智能化方向迈进,推动企业实现数据治理范式的全面升级。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356211</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356211</guid>
      <pubDate>Sun, 11 May 2025 08:27:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Workout.cool —— 现代开源健身教练平台</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;一个全面的健身指导平台，可以为你制定锻炼计划、跟踪进度并访问包含详细说明和视频演示的庞大锻炼数据库。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;项目包含一个全面的练习数据库。要导入练习样本，请执行以下操作：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;导入的先决条件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;准备 CSV 文件&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你的 CSV 应该包含以下列：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以使用提供的示例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;导入命令&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Import exercises from a CSV file&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full /path/to/your/exercises.csv

&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Example with the provided sample data&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full ./data/sample-exercises.csv&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;CSV 格式示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,TYPE,STRENGTH
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,PRIMARY_MUSCLE,QUADRICEPS&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可用的属性类型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRENGTH&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CARDIO&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;PLYOMETRICS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRETCHING&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRIMARY_MUSCLE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;QUADRICEPS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CHEST&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BACK&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;SHOULDERS&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SECONDARY_MUSCLE&lt;/strong&gt;: Secondary muscle groups targeted&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EQUIPMENT&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BARBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;DUMBBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BODYWEIGHT&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;MACHINE&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MECHANICS_TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;COMPOUND&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ISOLATION&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/workout-cool</link>
      <guid isPermaLink="false">https://www.oschina.net/p/workout-cool</guid>
      <pubDate>Sun, 11 May 2025 08:20:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenBMB 开源轻量级 CUDA 推理框架 CPM.cu</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 推出了 CPM.cu，这是一个轻量级且高效的开源 CUDA 推理框架，专为端侧大型语言模型（LLMs）的部署而设计，并为&lt;a href="https://www.oschina.net/news/354328"&gt;MiniCPM4&lt;/a&gt;提供优化，核心支持&lt;strong&gt;稀疏架构&lt;/strong&gt;、&lt;strong&gt;投机采样&lt;/strong&gt;和&lt;strong&gt;低位宽量化&lt;/strong&gt;等前沿技术创新。&lt;/p&gt; 
&lt;p&gt;CPM.cu 亮点包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集成了 InfLLM v2 可训练稀疏注意力内核，可加速长上下文预填充和解码；&lt;/li&gt; 
 &lt;li&gt;FR-Spec（频率排序推测采样）通过压缩词汇空间提高草稿效率，显著降低计算开销；&lt;/li&gt; 
 &lt;li&gt;结合了 EAGLE-2 推测采样、4 位量化和基于滑动窗口注意力的长上下文支持，从而在资源受限设备上实现高效部署。&lt;/li&gt; 
 &lt;li&gt;性能方面，在 128K-token 序列上，预填充速度比 Qwen3-8B 快 2-4 倍，解码速度快 4-6 倍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CPM.cu&amp;nbsp; 框架结构：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CPM.cu/
├── src/
│   ├── flash_attn/ # 修改后的 Flash-Attention, 支持稀疏和投机采样
│   ├── model/
│   │   ├── minicpm4/ # minicpm4 模型
│   │   │   ├── minicpm4_model.cuh # 模型的核心实现
│   │   │   └── minicpm4_eagle.cuh # 投机采样实现
│   │   ├── model.cuh # 其他代表性模型
│   │   ├── w4a16_gptq_marlin/ # GPTQ 量化计算 kernel
│   │   ├── memory.cuh # 显存分配
│   │   └── layer.cuh # 通用层
│   ├── entry.cu # pybind: 连接 C/CUDA 和 Python
│   └── ...
├── cpmcu/ # python interface
└── ...&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;cpmcu/ 代码提供了一个 python 的调用接口，里面涉及在 Python 侧 tokenize，调用 C 代码得到模型的输出 logits，在 Python 侧根据 logits 采样并 detokenize 这些过程。我们使用了 pybind 将 C 代码与 Python 代码进行绑定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/memory.cuh 这里实现了整个推理框架的内存管理，这里我们采用了先分配模型权重，再分配模型中间计算结果所需的空间，最后把所有剩余显存分配给 kv-cache 的内存管理策略。这一点设计上是和 vLLM, SGLang 类似的。分配中间计算结果的空间时可以考虑一下中间计算结果的生命周期，做一点显存复用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/w4a16_gptq_marlin/ 量化的计算 kernel。这里直接使用了 vLLM 的 Marlin 代码。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/minicpm4/ 这里是模型的架构实现。src/model/下也有其他代表性模型实现。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/flash_attn/ 我们基于 flash_attn 2.6.3 版本，在上面增加了对 InfLLM v2、投机采样的适配支持。下面我们主要介绍这一部分，也是整个框架实现的难点。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;开源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FCPM.cu" target="_blank"&gt;https://github.com/OpenBMB/CPM.cu&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356197</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356197</guid>
      <pubDate>Sun, 11 May 2025 07:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源模型上下文协议 MCP 更新规范文档，添加对结构化工具输出的支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源模型上下文协议 MCP 昨天更新了规范文档，主要变更如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;移除对 JSON-RPC 批处理的支持（PR #416）&lt;/li&gt; 
 &lt;li&gt;添加对结构化工具输出的支持（PR #371）&lt;/li&gt; 
 &lt;li&gt;将 MCP 服务器归类为 OAuth 资源服务器，添加受保护资源元数据以发现相应的授权服务器。（PR #338）&lt;/li&gt; 
 &lt;li&gt;要求 MCP 客户端按照 RFC 8707 中描述的方式实现资源指示器，以防止恶意服务器获取访问令牌。（PR #734）&lt;/li&gt; 
 &lt;li&gt;在授权规范中阐明安全注意事项和最佳实践，并在新的安全最佳实践页面中说明。&lt;/li&gt; 
 &lt;li&gt;增加引导支持，使服务器能够在交互过程中向用户请求更多信息。（PR #382）&lt;/li&gt; 
 &lt;li&gt;在工具调用结果中增加资源链接支持。（PR #603）&lt;/li&gt; 
 &lt;li&gt;在使用 HTTP 时，后续请求中需通过&amp;nbsp;&lt;code&gt;MCP-Protocol-Version&lt;/code&gt;&amp;nbsp;头指定协商的协议版本。（PR #548）&lt;/li&gt; 
 &lt;li&gt;将生命周期操作中的 SHOULD 改为 MUST&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fspecification%2F2025-06-18%2Fchangelog" target="_blank"&gt;https://modelcontextprotocol.io/specification/2025-06-18/changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356195</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356195</guid>
      <pubDate>Sun, 11 May 2025 07:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源代码编辑器 Zed 上线「调试器」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源代码编辑器 Zed &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fdebugger" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;推出「调试器（Debugger）」功能，称这是向 Zed 1.0 迈出的重要一步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;调试器特性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;快速&lt;/strong&gt; ：减少上下文切换时间，让用户能更专注于调试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;熟悉&lt;/strong&gt; ：与 Zed 的设计语言保持一致，支持典型的调试流程，方便用户快速上手。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可配置&lt;/strong&gt; ：用户可自定义 UI、键绑定、调试配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-43c899b5d73c5470109aecf601bbff05ba7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Zed 开箱即支持调试多种流行编程语言，包括 Rust、C/C++、JavaScript、Go 和 Python。通过扩展系统，Zed 可以支持任何实现调试适配器协议（DAP）的调试适配器。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;技术架构&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   采用两层架构，数据层与调试适配器直接通信，UI 层从数据层获取数据进行界面渲染。
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   数据层负责维护会话状态、缓存响应、使失效数据，UI 层按需请求数据，避免不必要的请求，便于后续实现协作调试。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;调试适配器集成&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   扩展了 Zed 的扩展 API 以支持调试器集成，通过定义自定义架构等方式，让扩展作者能轻松将调试适配器集成到 Zed 中。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;内联变量值实现&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   利用 Tree-sitter 查询准确识别当前执行范围内的变量，无需依赖 LSP 服务器与调试适配器的紧密集成，目前支持 Python、Rust、Go 等语言。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fdocs%2Fdebugger" target="_blank"&gt;https://zed.dev/docs/debugger&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356190/zed-debugger</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356190/zed-debugger</guid>
      <pubDate>Sun, 11 May 2025 06:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源 Rust 浏览器引擎 Servo 支持 GIF</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Servo 是一款开源的浏览器引擎，最初由 Mozilla 开发。它使用 Rust 语言编写，旨在提供高效、安全的网页渲染能力，并且采用并行渲染技术，以提高网页加载速度和性能。&lt;/p&gt; 
&lt;p&gt;近日，Servo 团队介绍了最近的更新内容，其中一项重要新功能是&lt;strong&gt;支持显示动态 GIF&lt;/strong&gt;，并且还可以通过 HTML "img"标签加载 SVG 图像。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/142856_yG2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 还在推进其 Trusted Types API、输入类型 &amp;lt;input type=color&amp;gt; 支持、更好的布局和 CSS 支持，以及支持各种其他 API 和功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f8cd0cc574887e5f2e0cc055fb9586cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 还在继续努力提升围绕 Servo 嵌入支持的开发者体验，以 Servo 作为 Chromium 的 CEF 替代方案在应用程序中利用 Servo。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2025%2F06%2F18%2Fthis-month-in-servo%2F" target="_blank"&gt;https://servo.org/blog/2025/06/18/this-month-in-servo/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</guid>
      <pubDate>Sun, 11 May 2025 06:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美国科技巨头推动联邦立法，禁止各州单独监管 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《金融时报》报道称，近日美国多家大型科技公司正积极推动一项联邦禁令，旨在禁止各州自行制定人工智能（AI）监管法规。此次立法倡议得到了亚马逊、谷歌、微软和 Meta 等公司的支持，目的是避免各州在 AI 监管方面各自为政，影响行业的整体发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士透露，这项禁令提案已经被纳入众议院版本的 「大而美」 预算法案中。参议院也计划在近期推出自己的版本，并希望能够在 7 月 4 日之前完成相关立法工作。前联邦众议员、现任 INCOMPAS 首席执行官 Chip Pickering 是这项提案的重要推动者，他表示，保持美国在技术领域的领导地位是确保国家竞争力的关键。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;INCOMPAS 组织于 2024 年成立了 「人工智能竞争中心」（AICC），专注于游说国会与监管机构，以适应快速发展的 AI 行业。随着 AI 监管讨论的加剧，尤其是在欧盟出台新规后，亚马逊和 Meta 也加入了该组织，试图通过统一监管来增强竞争力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，此提案引发了广泛的争议。反对者认为，大型科技公司推动禁令的真正目的是为了巩固自身在 AGI（通用人工智能）竞争中的垄断地位。范德比尔特大学的政策加速中心 AI 与科技政策主任 Asad Ramzanali 表示，负责任的创新不应该惧怕法律的约束。同时，麻省理工学院的教授 Max Tegmark 也批评称，这种行为是科技巨头为了进一步集中财富和权力的扩张。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，支持禁令的人士认为，联邦层面的统一监管将有助于避免各州的分歧，保持行业的创新能力，从而在全球 AI 竞争中处于有利地位。AI 安全倡导者如 Anthropic 联合创始人 Dario Amodei 则警告称，如果完全依赖企业自我监管，可能会带来严重的社会风险。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356176</guid>
      <pubDate>Sun, 11 May 2025 06:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度垂搜数据管理系统弹性调度优化实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;百度垂直搜索系统将搜索核心能力赋能阿拉丁（百度搜索特型结果）、垂直领域搜索、应用内搜索等场景，支撑了数百个检索场景、百亿级内容数据的检索。随着接入业务数量和数据量不断增长，系统在海量数据管理与调度上遭遇新的挑战，通过垂搜数据管理系统弹性调度优化实践来满足业务增长需求。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 简介&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;百度垂搜架构的召回引擎经过历史架构演进确定了&lt;strong&gt;&lt;strong&gt;异构&lt;/strong&gt;&lt;/strong&gt;部署的架构模型，相较于同构部署在容量自动调整、数据按需存储等方面更具效率与成本的优势，同时在海量数据和海量检索方面也实现了高可用和高性能。目前系统已承接 80+业务，全机房部署了数百个检索服务，数千个索引库，共计数百亿文档收录。随着接入新业务数量的增加，以及存量业务的深入迭代，我们遇到了更加复杂多样的场景，进而对系统提出更高的要求。本文主要介绍我们的系统在海量数据管理与调度上面临的问题， 以及各项优化工作落地后在系统扩展性、稳定性等方面取得的效果。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&amp;nbsp;当前数据管理架构存在的问题&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此前我们的系统设计了弹性伸缩机制应对流量和数据量的上涨，冷热分离机制实现了资源按需部署。随着接入业务的增加，系统逐渐暴露出一些新的问题，主要体现在以下几点:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;元信息管理瓶颈。系统使用 ETCD 进行服务发现和心跳管理， 然而所有业务实例&lt;strong&gt;&lt;strong&gt;直连 ETCD&lt;/strong&gt;&lt;/strong&gt;存在严重读写放大问题， 导致 ETCD 负载超发出现&lt;strong&gt;&lt;strong&gt;单点瓶颈&lt;/strong&gt;&lt;/strong&gt;, 限制集群规模进一步增长。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依靠人工评估资源。新业务的接入或者一些大事件运营保障依赖人工估算所需资源，&lt;strong&gt;&lt;strong&gt;不仅耗费人力，而且不够准确&lt;/strong&gt;&lt;/strong&gt;，估算过高，服务长期处于低负载会造成资源浪费，估算过低，服务容易过载，进而导致稳定性问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据量增长瓶颈。 当前的架构可以在无需重新建库的情况下原地扩分片，但是分片数只能倍数扩展，并且&lt;strong&gt;&lt;strong&gt;分片数量有限制&lt;/strong&gt;&lt;/strong&gt;，大库场景容易触发上限，进而导致数据量无法继续增长。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;02 检索系统与数据管理系统架构&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1&amp;nbsp;检索系统架构概览&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先简单介绍下垂搜检索系统的各模块，如下图所示:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6fa6c464ffb4e6ea05cb47989be85fcbaf.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;RANK。检索精排模块，负责 query 理解、请求构造、多队列拆分、正排数据获取、策略因子计算、算分排序、返回结果组装等流程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS。检索召回引擎，负责基础召回/粗排，根据基础相关性等权重因子进行数据的粗筛，支持基于 term 倒排拉链和 ANN 向量基础召回。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BUILD。数据建库模块，负责数据处理、切词、生成正排/倒排/向量/摘要等功能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;每个垂类 (业务) 拥有一套独立的上述检索系统服务，数据管理系统为每个业务的检索系统提供&lt;strong&gt;&lt;strong&gt;实例调度、容量管理、服务发现、心跳管理、路由控制&lt;/strong&gt;&lt;/strong&gt;等能力，数据管理系统面向的核心管理对象是召回引擎 (BS)。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1&amp;nbsp;垂搜召回引擎&lt;/h3&gt; 
&lt;p&gt;如下图所示，百度垂搜的召回引擎是一个&lt;strong&gt;&lt;strong&gt;流式、多分片、异构、有状态的倒排+向量&lt;/strong&gt;&lt;/strong&gt;索引引擎:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6a59f451eae4330c4d002228c9ca5d20b51.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;流式。业务经过离线建库环节产出建库包并生效到 Kafka 中，召回引擎再从 Kafka 消费，数据从建库到检索可实现&lt;strong&gt;&lt;strong&gt;秒级生效&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多分片。业务数据量超过单机存储上限，会被拆分成多个分片 (slice)，每个分片由 PaaS 层面实例承载，并对应 Kafka 的一段 partition 区间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;异构。单个业务的若干个资源号 (resource) 之间支持独占或者混部，一般根据服务负载设置不同副本数，根据数据量设置不同分片数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;有状态。每个实例承载一个或多个分片数据，周期性汇报心跳，消费分片由中控服务统一调度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;名词解释:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;resource(资源号): 一类或者一个场景的数据集合，即一个&lt;strong&gt;&lt;strong&gt;索引库&lt;/strong&gt;&lt;/strong&gt;，一个业务通常包含多个资源号 (如图中 mobile_game，pc_game， game_video 等)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slice(分片):数据调度基本单位，一个 resource 根据数据量可能会拆分成多个 slice(mobile_game 有三个 slice, pc_game 和 game_video1 个)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slot:数据划分的基本单位，一个 slice 下有若干个 slot， 与 Kafka 的 partition 一一对应，在业务接入时根据数据量级确定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;pod:PaaS 层面实际的物理存储容器，一个 pod 会承载一个或多个 slice，由中控服务统一调度。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&amp;nbsp;动态化数据管理系统&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;动态化数据管理系统负责召回引擎的每个实例从建库到检索，从部署到下线的全生命周期管理。经过&lt;strong&gt;&lt;strong&gt;服务重构、架构升级、新功能建设&lt;/strong&gt;&lt;/strong&gt;等方面的优化工作，形成了包括中控服务，心跳服务 (HeartbeatService), 名字服务 (NamingService), 存储 ETCD 等模块的现有系统架构:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-da1b5525954986be5194f44d536e0d8d45b.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1&amp;nbsp;中控服务&lt;/h3&gt; 
&lt;p&gt;整个动态化数据管理系统的核心模块，负责各类调度任务的发起、控制等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;资源号接入/下线。新增资源号 (索引库)，为每个资源号根据副本数、资源号之间部署关系等调度实例；下线资源号， 对应资源号的数据发起清理以及实例回收。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;副本保活。每个资源号实际副本数可能由于扩缩副本或 PaaS 层面迁移，导致与目标副本数不一致，中控服务负责定期轮训所有资源号 (分片)，维持副本数与目标一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;容量管理。自动扩缩容服务/人工基于负载调整资源号的副本数，并通过副本保活生效，基于数据量调整资源号分片数，通过任务控制器生效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可用度控制。上线重启需要保证分片维度的可用度，变更由 PaaS 发起，每个实例重启前需要请求中控服务的探针，中控服务根据当前分片可用度决定实例是否可以重启。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2&amp;nbsp;名字服务 NamingService&lt;/h3&gt; 
&lt;p&gt;提供服务发现，实例屏蔽，建库路由控制等能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;服务发现。周期性加载并更新全量业务的资源号检索路由拓扑信息，对每个分片过滤心跳丢失、未消费完成、重启中等暂不可用实例。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实例屏蔽。支持异常实例的分片维度/App 维度屏蔽，线上快速止损，并保留现场便于后续问题追查。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建库路由控制。提供离线建库侧全量业务资源号与 Kafka partition 映射关系查询，资源号倒排索引双写控制。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.3&amp;nbsp;心跳服务 HeartbeatService&lt;/h3&gt; 
&lt;p&gt;负责召回引擎 (BS) 实例、分片心跳信息收集并持久化，实例消费区间信息传递等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;心跳管理。收集召回引擎实例上报的心跳信息，包括实例自身心跳以及消费分片信息， 并将心跳信息聚合后写入 ETCD。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实例调度信息传递。获取由中控调度下发的最新消费分片信息，写入心跳请求 response，实例感知到消费分片发生变化后，清理旧分片数据，并重新消费新分片数据。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.4&amp;nbsp;存储 ETCD&lt;/h3&gt; 
&lt;p&gt;动态化数据管理系统各类元信息持久化存储:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;实例心跳信息。包括版本号，实例唯一标识，上报时间戳，消费分片等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分片路由拓扑信息。分片下全量副本状态信息，包括 endpoint，snapshot 版本，上报时间戳，消费状态等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;业务资源号拓扑信息、建库路由信息。单业务视角下全量资源号信息，包括版本号，分片数，副本数，对应 Kafka partition 区间，rpc 参数配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;03 弹性调度机制优化实践&lt;/h1&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1&amp;nbsp;服务发现、心跳管理模块重构&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.1&amp;nbsp;原有架构&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f12910e29c40a1a821609e09c774e7296d.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到在原有架构，业务 RANK 和 BS 实例都是直连 ETCD，随着业务接入数量的增加逐渐暴露出一些问题:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;读流量放大。同业务的不同 RANK 实例会各自访问 ETCD 获取相同的路由拓扑，导致读流量放大，对于 RANK 实例数多的业务放大现象愈发明显。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;写流量放大。每个分片含有多个副本，在进行更新时，一轮周期内同一个分片会被写入多次，导致写流量放大，对于副本数多的分片写竞争愈发激烈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;升级改造困难。路由筛选策略、心跳上报策略均内嵌在 sched-lib 中, 进行升级需要给每个业务 RANK/BS 上线，人力成本巨大。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为了解决上述问题，我们对心跳管理和服务发现模块进行了微服务拆分，新增心跳服务 (以下简称 HS) 和名字服务 (以下简称 NS) 避免了业务实例直连 ETCD，同时引入了 Prometheus，对心跳上报状态和路由获取状态等信息进行监控和可视化展示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bb9efb9826cf2b2ebe1bae522ce0df14546.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.2&amp;nbsp;NS(NamingService) 设计&lt;/h3&gt; 
&lt;p&gt;我们对 NS 的定位是作为 ETCD 的 cache，采用 Read-Through 的模式，对全量业务的 RANK 提供拓扑信息查询，RANK 不再直接访问 ETCD:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;NS 本身设计为一个&lt;strong&gt;&lt;strong&gt;无状态服务&lt;/strong&gt;&lt;/strong&gt;， RANK 可以访问任意一台 NS 获取拓扑，NS 实例之间拓扑路由&lt;strong&gt;&lt;strong&gt;保证最终一致性&lt;/strong&gt;&lt;/strong&gt;，NS 在拓扑变更时返回拓扑信息+MD5(拓扑)+更新时间戳，未变更时仅返回 MD5 和时间戳， RANK 基于 MD5 和时间戳自行判断是否需要更新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;拓扑更新策略下沉到 NS 中，RANK 获取到的拓扑即为直接可用拓扑，针对不同业务提供不同的控制策略并且后续升级改造只需上线 NS，成本大幅降低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;单机房 3 台 NS 实例即可支撑全部业务拓扑查询，重构前后 ETCD 读流量比例为 M:3，M 为平均每个业务 RANK 实例数，假设 N 取 30，则读流量下降 90%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-93ea29c3774379e1a2cabf37f1ed095a248.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.3&amp;nbsp;HS(HeartbeatService) 设计&lt;/h3&gt; 
&lt;p&gt;HS 负责收集 BS 实例本身的心跳以及实例消费的分片的心跳，周期性&lt;strong&gt;&lt;strong&gt;聚合写入&lt;/strong&gt;&lt;/strong&gt;ETCD，并且向 BS 实例返回其最新的消费分片信息:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;HS 采用无主节点设计，也支持任意水平扩展。同一个业务的不同 BS 实例通过&lt;strong&gt;&lt;strong&gt;一致性 hash&lt;/strong&gt;&lt;/strong&gt;方式请求同一台 HS 实例, 便于 HS 进行分片维度的信息聚合，这样在大部分时间，每个分片无论有多少个副本一个周期内只会被写入一次，实例本身的心跳采用批量更新形式，写竞争大幅降低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 在上报心跳的同时会从 HS 的 response 中获取自身消费的最新分片信息，如果分片信息变化，则清理老分片数据，消费新分片数据，后续只上报新分片状态信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;单机房 3 台 NS 实例即可支撑全部业务心跳更新，重构前后 ETCD 写流量比例为 N:1，N 为平均每个分片副本数，假设 N 取 5，则写流量下降 80%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f141ad59566f2bbe45c04a1a0dac2046805.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_17"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;自动扩缩容&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1&amp;nbsp;当前现状&lt;/h3&gt; 
&lt;p&gt;BS 是一个&lt;strong&gt;&lt;strong&gt;多分片、异构&lt;/strong&gt;&lt;/strong&gt;服务，即每个 App 内通常部署了多个资源号，各业务 App 在 PasS 层面隔离部署，在资源利用率、扩缩容管理等方面我们遇到以下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;整体资源利用率低。全机房拥有上百个 BS 业务 App、上千个资源号，PaaS 层面的整体平均峰值 CPU 利用率低于平均水平，峰值 CPU 超过 70% 的资源号占比不足 20%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依赖人工进行资源号副本数调整。一般上线前通过人工压测评估放量后所需的资源然后进行申请，有时候通过压测难以估算真实的资源，并且后续业务迭代或者流量变化也会引起资源使用的变化，如果负载超发，服务稳定性难以保障，如果负载太过空闲，也会造成资源浪费。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;无法直接接入 PaaS 层面自动扩缩容能力。一方面 PaaS 无法感知每个 App 内资源号维度负载信息，另一方面每个实例承载分片信息只能由中控服务调度，因此无法直接服用 PaaS 层面自动扩缩容能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-05f53f5b84434e08c78529d148cd54a6dcb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2&amp;nbsp;自动扩缩容实现&lt;/h3&gt; 
&lt;p&gt;为了实现容量自适应调整，我们开发了一个自动扩缩容服务，对全量资源号进行容量管理。自动扩缩容服务周期性计算资源号维度负载，根据负载情况，触发中控服务进行资源号副本数调整，或者 PaaS 层面实例数调整。对于扩容，优先调度存量资源池中实例，如果存量实例不足则触发 PaaS 扩容；对于缩容，先将空闲副本数回收至空闲资源池，再触发 PaaS 缩容。对于自动扩缩容服务的设计我们主要考虑了以下几点:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-53d9ad28a3b34ec0ecb4706a0bc8f9316eb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;负载指标选取&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;垂搜系统大部分业务 BS 为纯内存版本，且几乎没有下游网络请求，属于典型的计算密集型业务， 因此我们选择 CPU 作为负载计算参考指标，另外资源号混部场景进一步结合 QPS 和 Latency 进行判断。此前我们已经实现了基于 Prometheus 采集实分片维度 CPU、MEM、QPS、Latency、建库数据量等指标全量业务覆盖，因此可以低成本的获取到全量&lt;strong&gt;&lt;strong&gt;资源号维度&lt;/strong&gt;&lt;/strong&gt;的负载数据。&lt;/p&gt; 
&lt;span id="OSC_h4_21"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;负载状态流转&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;每个资源号从扩容到缩容，共定义如下 7 种状态：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;enum LoadStatus { LOAD_STATUS_LOAD_OK = 0; //正常负载 LOAD_STATUS_OVERLOAD = 1; //超负载 LOAD_STATUS_IDLELOAD = 2; //低负载 LOAD_STATUS_BS_ADD_REPLICA = 3; //bs 扩副本中 LOAD_STATUS_BS_REMOVE_REPLICA = 4; // bs 缩副本中 LOAD_STATUS_TRIGGER_PAAS_EXPENSION = 5; // PaaS 扩容中 LOAD_STATUS_TRIGGER_PAAS_SHRINK = 6; // PaaS 缩容中 }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;每个资源号根据负载情况在上述状态之间流转:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8fa2f7581ed63466a8f24640ad7258bba52.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_22"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;扩缩容执行流程&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;扩副本&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优先调度 App 内空闲实例，不足则触发 PaaS 层面实例数扩容，循环执行直到负载恢复正常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-edfbd8b326a5709833d414a5fb013f357ed.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;缩容&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;先将资源号多余副本释放为空闲实例，再触发 PaaS 层面缩容，循环执行直到资源号负载以及空闲实例数回到正常水平。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-504ce96574f2dc384b323509ab32bd78022.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3&amp;nbsp;&lt;strong&gt;资源号扩分片进阶&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;每个资源号随着数据量级不断增长，分片数也需要动态扩展，否则会出现分片内存超发的情况。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.1&amp;nbsp;&lt;strong&gt;当前扩分片方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;每个资源号按 resource-&amp;gt;slice-&amp;gt;slot 的层级划分，slot 是数据划分最小单位与 kafka partion 一一对应，在业务接入时每个资源号 slot(partion) 的数量已经确定。扩层时，资源号的 slot 数量不变，&lt;strong&gt;&lt;strong&gt;分片数变成原来 2 倍， 每个分片的 slot 数则为原来的 1/2&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8db852d84d0b6a8d63c9bac9fed576d9490.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;原有的扩分片方案可以在无需重新建库的情况下实现业务无感的原地分片扩缩操作，然而依旧存在两个问题:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;分片数按指数增长，当分片数超过一定数值，将带来不容忽视的资源成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果初始分配 slot 数太少，当 slice:slot=1:1 时，无法再扩层，数据增长出现瓶颈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.2&amp;nbsp;&lt;strong&gt;进阶扩展方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;对于分片无法继续扩展但是依旧需要继续建库的情况，先前的方案只能是重建一个新的资源号，需要业务、架构共同介入，历史上我们使用原方案迁移一个资源号，前后&lt;strong&gt;&lt;strong&gt;投入近 3 周时间&lt;/strong&gt;&lt;/strong&gt;，耗费成本巨大，因此我们需要一个成本更低的方案。通过分析，当前分片的扩展瓶颈主要有以下三个限制条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;每个资源号的 slots 是一段连续的区间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 的 slot 与 Kafka 的 partition 一一对应。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始分配 slot 数太少，且后续不支持调整。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;只需要打破其中任意一个条件，则可以消除瓶颈。综合考虑改造成本、扩展灵活性、实现难度等因素，我们选择从条件三入手，在新的 partition 区间重建分片，分片数和 slot 数根据数据量设置，将旧分片的数据全量复制到新的分片上，再将新分片替换旧分片，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1534a9d4b6b75072160e0a0470563a1c8c8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_26"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;整体实现&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;对于一个流式建库系统，业务可能时刻都在进行数据建库，我们希望做到迁移过程中业务依旧可以持续建库，并且保证数据不丢失、时序不错乱。我们的方案是将数据分为存量数据 (老分片中的全量数据) 和增量数据 (实时写入的新数据)，对于增量数据可以通过双写机制，同时写入新旧分片，存量数据则通过构建 snapshot 的方法迁移至新分片，新分片数据 ready 后，再由服务发现层将检索流量切换至新分片，整体流程如下:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;离线侧开启双写，保证增量倒排索引数据同时写入新旧分片，正排和摘要部分数据无需变化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于旧分片构建新分片 snapshot, 并记录构建时间点。将该时间点前旧分片所有数据进行 resharding 构建新分片 snapshot。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新分片的 BS 实例加载构建好的 snapshot，然后每个 partition 的消费 offset&lt;strong&gt;&lt;strong&gt;回退到 snapshot 构建时间点开始重新消费&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;服务发现层将资源号到 slot 区间映射切换到新分片上，检索流量从老分片迁移至新分片。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将旧分片 BS 实例回收，并关闭双写。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2cc22fbbf1492e639ef2bf5cbd76b4f8c3a.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_27"&gt;&lt;/span&gt; 
&lt;h1&gt;04 总结与展望&lt;/h1&gt; 
&lt;span id="OSC_h2_28"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1&amp;nbsp;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本文介绍了百度垂搜检索数据管理架构在弹性机制建设上的一系列优化工作，并且在扩展性、稳定性、以及成本效率等方面均取得了预期成果:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;扩展性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 负载下降一个量级，单机房 BS、RANK 集群规模提升两个量级， 单分片副本数上限提升至 5000+。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;分片扩展数量不再受限，解决了部分存量业务无法扩展分片导致的内存超发问题，并支持搜索创新业务数据量从百万级逐步增加至数十亿量级。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;稳定性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;存量调度问题被修复，新增多种路由调度策略以应对不同场景，分片可用度不足干预时间从小时级缩短至分钟级。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 负载不再超发，慢查询基本消失，稳定性风险基本消除，心跳上报、拓扑获取状态建立监控，异常情况及时感知。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成本效率&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;全机房 BS 接入自动扩缩容，实现容量自适应调整，整体峰值 CPU 利用率提升了 15%+，同时相比之前减少了 80% 人工介入容量调整的情况出现。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;部分业务通过分片合并，最终使用存储资源为下降至原来的 20%，并且检索 97 分位耗时降低了 20ms，业务侧效果与先前打平。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_29"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2&amp;nbsp;&lt;strong&gt;展望&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;目前索引库的自动扩缩容机制实现了副本数随负载 (CPU) 的自动调整，后续将实现分片数随数据量的自动调整。另外，在大库场景将持续建设流批一体机制，以追求用更低的存储成本实现更高的检索性能。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18627327</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18627327</guid>
      <pubDate>Sun, 11 May 2025 03:11:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Sam Altman 透露将在今年夏季发布 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 发布了其联合创始人兼首席执行官 Sam Altman 的 40 分钟深度专访。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/105636_pUBl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1935357512011890815" target="_blank"&gt;透露&lt;/a&gt;&lt;/u&gt;，备受瞩目的 GPT-5 预计将于今年夏天推出，不过具体发布日期尚未确定。&lt;/p&gt; 
&lt;p&gt;据报道，GPT-5 性能将远超 GPT-4，测试者表示其在多方面有显著进步。据悉，这款新模型将整合 OpenAI 的核心技术，融合 GPT-4o 自然语言处理的灵活性与 o3 在代码及科学推理方面的优势，打造更强大的统一系统。&lt;/p&gt; 
&lt;p&gt;Altman 暗示，GPT-5 或许不仅是性能上的升级，更可能是 OpenAI 迈向统一、类似代理模型的重要一步，使其向人工通用智能（AGI）目标更进一步。&lt;/p&gt; 
&lt;p&gt;此外，据 AI 工程师 Tibor Blaho 和投资者「Chris（chatgpt21）」消息透露，OpenAI 或将在 7 月发布一个大规模模型，而该模型有望为 GPT-5。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/354761" target="news"&gt;OpenAI 推迟开源模型的发布时间&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356142</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356142</guid>
      <pubDate>Sun, 11 May 2025 02:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 终止与 Scale AI 合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 发言人当地时间周三向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-18%2Fopenai-is-phasing-out-its-work-with-scale-ai-after-meta-deal" target="_blank"&gt;彭博社&lt;/a&gt;透露，在 Meta 与 Scale AI 达成交易后，OpenAI 将逐步停止与 Scale AI 的合作，并切断与该数据供应商的联系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 表示，早在 Meta 上周宣布向这家初创公司投资数十亿美元并任命 Alexandr Wang 担任首席执行官之前，该公司就已开始逐步结束与 Scale AI 的合作。OpenAI 一直在寻找其他供应商来获取更专业的数据，以开发日益先进的 AI 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="336" src="https://oscimg.oschina.net/oscnet/up-77faf9c892257b37289b5ccb5a6d4304d54.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 断绝关系的决定引发了人们对 Scale AI 核心数据标签业务的质疑。上周，路透社报道称，谷歌也在讨论放弃 Scale AI 作为数据提供商的计划。随着 Meta 与 Scale AI 达成合作，Scale AI 的一些竞争对手表示，他们收到了大量寻求「中立」合作伙伴的 AI 模型供应商的兴趣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在周三发布的一篇博客文章中，Scale AI 的总法律顾问试图驳斥 Meta 将在此次交易后获得优待的说法。Scale AI 的高管表示，公司不会与 Meta 分享其他客户的机密信息，并且新任首席执行官 Wang 不会直接参与公司的日常运营。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在周三发布的另一篇博客文章中，Scale AI 的临时首席执行官 Jason Droege 则表示，公司将「加倍投入」其应用程序业务，其中包括为政府和企业构建定制的 AI 应用程序。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</guid>
      <pubDate>Sun, 11 May 2025 02:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Midjourney 发布首个 AI 视频生成模型 V1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 初创公司 Midjourney &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1935377193733079452" target="_blank"&gt;宣布&lt;/a&gt;推出其备受期待的首款 AI 视频生成模型 V1，支持图像到视频的生成，并可实现从文本直接生成视频。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1216" src="https://static.oschina.net/uploads/space/2025/0619/102551_SwUy_2720166.png" width="1286" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;V1 目前仅通过 Discord 平台的网页端提供服务，基础订阅费为每月 10 美元。&lt;/p&gt; 
&lt;p&gt;根据 Midjourney 的官方介绍，V1 基于此前的图像模型生态进行打造。&lt;/p&gt; 
&lt;p&gt;Midjourney V1 操作分为自动和手动两种模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动模式下，平台会根据用户生成的图片，自动创建「动作提示词」并让画面运动起来；&lt;/li&gt; 
 &lt;li&gt;手动模式则是由用户提供提示词。同时，Midjourney V1 也分为「低动态」和「高动态」两种运动模式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;V1 的发布让 Midjourney 加入与 OpenAI 的 Sora、Runway 的 Gen 4 等 AI 视频模型的竞争。其目标不止于为好莱坞或广告业生成素材，公司 CEO David Holz 称这是迈向 「实时开放世界模拟」 AI 模型的一步，后续还计划开发 3D 渲染和实时 AI 模型。 &amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 考虑赴港 IPO？知情人士：属实，仍处于初步筹备阶段</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息称，AI 独角兽稀宇科技 (MiniMax) 正考虑在香港进行首次公开募股（IPO）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对此，有接近 MiniMax 的知情人士向澎湃新闻记者表示，MiniMax 内部确实有类似想法，但目前仍处于初步筹备阶段。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-1c8fdc630a51d77c2dbbdb3ff2131f20e68.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官网介绍显示，MiniMax 是全球领先的通用人工智能科技公司。自 2022 年初成立以来，以「与所有人共创智能」为使命，致力于推动人工智能科技前沿发展，实现通用人工智能 (AGI）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，MiniMax 已自主研发了一系列多模态通用大模型，包括 MiniMax M1、Hailuo-02、Speech-02 和 Music-01，具备超长上下文处理能力，能够理解、生成并整合包括文本、音频、图像、视频和音乐在内的多种模态。并基于这些自研模型推出一系列 AI 原生产品，包括 MiniMax、海螺 AI、MiniMax Audio、星野等，以及面向企业和开发者的开放平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 3 月，MiniMax 获 6 亿美元 A 轮融资，投后估值 25 亿美元，由阿里巴巴领投，此前融资的投资方也包括腾讯等。据媒体报道称，MiniMax 的实际估值目前已经超过 2024 年所报道过的「25 亿美元」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356108</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>融云 AI 机器人上线，独家直连 AI 平台，加速落地创新探索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 技术的爆发为各行各业带来了前所未有的机遇，各类创新应用如雨后春笋般涌现——从图像生成、视频创作，到智能搜索引擎、代码助手，AI 正在重塑人们的工作与生活方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;而在这一波浪潮中，ChatBot 类产品及其衍生形态——如虚拟角色、智能客服和 AI 助理——作为 AI 普及的「OG」，始终占据着核心地位。无论是全球科技巨头的布局，还是创业团队的创新尝试，这一领域依然活力十足，不断有优秀的新产品崭露头角。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;深度整合 IM 对话与 AI 能力，融云 AI 机器人正式上线。&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;独立的机器人用户类型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，拥有&lt;/span&gt;&lt;strong&gt;&lt;span&gt;详细的事件回调能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，&lt;strong&gt;独家直连 AI 平台&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，大幅降低开发者落地 AI 社交、智能回复等业务的成本，给开发者的创新探索加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;无论是以全新产品角逐市场，还是在现有产品中增加附加玩法。融云 AI 机器人都可以&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效缩短业务上线周期，助力开发者快速探索充满潜力的 AI 赛道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;无论是以全新产品角逐市场，还是在现有产品中增加附加玩法。融云 AI 机器人都可以&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效缩短业务上线周期，助力开发者快速探索充满潜力的 AI 赛道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;场景丰富，响应稳定&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融云 AI 机器人支持基于指定机器人的详细事件回调，方便开发者精准掌握用户与机器人的互动，如单聊消息、群聊@指令等，并基于不同事件进行定制化处理，灵活响应各类业务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;无论是自动回复、任务触发，还是群聊助手，都可以借助融云 AI 机器人轻松实现更智能、更丰富的交互，&lt;/span&gt;&lt;span&gt;&lt;span&gt;提升产品的用户体验及业务运营效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;以单聊和群聊两种主要对话场景来看：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在单聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过与机器人对话，可触发多轮智能对话、内容生成等功能，支持流式或非流式输出，适用于&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 陪伴、角色扮演&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等社交场景&lt;/span&gt;&lt;span&gt;&lt;span&gt;及&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 知识问答、智能客服&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等商务社交场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="636" src="https://oscimg.oschina.net/oscnet/up-faa3c43ddca6e7fdc989dafeddb8f0d1286.png" width="585" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;除了稳定高效的多轮对话支持外，还可以实现智能任务执行功能，响应用户发起的智能操作请求，如「生成北京出行计划」、&lt;span&gt;「写一封邮件」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;等；或&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;查询个人事务，如「我今天还有哪些未完成的任务」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在群聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过 @ 机器人，触发与 AI 机器人的沟通或智能业务处理流程，如：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;FAQ 问答：解析用户意图并自动回复；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;工单创建：识别需求并提交至工单系统；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;日程提醒：识别时间表达并添加到日历服务。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;快速上线，降本增效&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;提供独立的机器人类型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;融云 IM 提供独立的机器人服务，自带区别于真实用户类型的业务逻辑，大幅降低开发者在 AI 对话类业务实现时针对机器人的特殊处理逻辑，从底层能力上满足开发者灵活创新的 AI 对话需求，极具拓展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;独家直连&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;&amp;nbsp;AI 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;融云 AI 机器人业内独家实现了与第三方 AI 平台的对接，开发者无需进行繁琐的中间处理，即可快速接入 AI Agent 创建调试及大模型推理服务，显著降低开发难度，为开发者的 AI 社交、智能客服等业务落地打开了一个「绿色极速通道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;此前，开发者若想借助 AI 平台赋能自身的 AI 对话类业务，需要自行实现中间的需求中转和消息流转，链路长、问题多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通过融云 AI 机器人，开发者可在简单调用接口后实现对 AI 平台能力的关联，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;链路稳定、响应高效&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并可以在融云&lt;/span&gt;&lt;strong&gt;&lt;span&gt;流式消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等底层能力和&lt;/span&gt;&lt;strong&gt;&lt;span&gt;内容审核&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等周边服务的配套支持下实现灵活的业务需求。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;接入便捷，灵活搭建&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融云 AI 机器人支持 Webhook 回调、Dify 平台对接，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方便开发者根据自身的业务情况选择对接方式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;设置 Webhook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可通过 Webhook 回调，将用户向机器人发送的消息同步到自己的业务服务器，由业务服务器自由对接自研或私有大模型自建服务（&lt;em&gt;如私有部署的 LLM、LangChain、RAG 检索系统等&lt;/em&gt;）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通过这一方式可以实现灵活的消息接入、参数定制、响应策略，&lt;/span&gt;&lt;span&gt;&lt;span&gt;适合有高度定制化、私有化部署、安全隔离等要求的业务场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;对接 AI Agent 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;支持对接已&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;接入 OpenAI、Claude、Gemini 等多种大模型的 Dify 平台。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可在 Dify 平台上创建一个自己的 AI Agent（&lt;/span&gt;&lt;em&gt;&lt;span&gt;如：聊天机器人&lt;/span&gt;&lt;/em&gt;&lt;span&gt;），同时在融云服务端创建一个机器人，并将该机器人通过配置直接与 Dify 平台创建的 AI Agent 进行对接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;这样，&lt;/span&gt;&lt;span&gt;&lt;span&gt;无需自行搭建模型服务，就可以实现多轮 AI 对话、知识库问答、RPA 流程（&lt;em&gt;机器人流程自动化&lt;/em&gt;）等&lt;/span&gt;&lt;span&gt;&lt;span&gt;高级功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="148" src="https://oscimg.oschina.net/oscnet/up-7518cc39e9922c3ad838434add534928cc3.png" width="580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;快速搭建 AI 陪伴应用示例&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;以 AI 陪伴应用为例，融云提供从 AI 角色配置、Prompt 预设到 IM 对接的全链路服务，&lt;/span&gt;&lt;span&gt;&lt;span&gt;快速搭建 AI 陪伴应用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在 Dify 中创建和调试 AI Agent&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪创建聊天助手&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪填写人设&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪设置 LLM 和参数&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪配置开场白&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在融云服务端创建机器人并完成关联&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通过 Server API 创建机器人&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通过&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;Agent 地址&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;设置机器人的回调配置信息，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;关联 AI Agent&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑在客户端集成 IM SDK， AI 角色便可出现在 App 中，提供&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能破冰、AI 陪伴等能力，助力应用提升用户粘性和商业价值。&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;详细接入流程可见本期推文次条&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;更多详情见&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;em&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.rongcloud.cn%2Fplatform-chat-api%2Fbot%2Foverview" target="_blank"&gt;开发者文档&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356103</guid>
      <pubDate>Sun, 11 May 2025 02:01:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Firefox 139 测试内置 Perplexity AI 搜索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;负责 Firefox 搜索的产品经理&amp;nbsp;Gayatri &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconnect.mozilla.org%2Ft5%2Fdiscussions%2Ftry-out-perplexity-ai-search-in-firefox-139%2Ftd-p%2F98352" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;团队正在与 Perplexity 合作，将&amp;nbsp;Perplexity AI 搜索内置到 Firefox 139 中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db094748597759caee52fd4a82e08cdcb33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0618/191849_B1yu_2720166.png" width="1390" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Perplexity 是一个 AI 驱动的搜索引擎，能直接以对话形式回答你的问题——无需翻阅大量搜索结果。它特别适用于以下情况：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅&amp;nbsp;需要快速简洁的答案，避免在多个信息源中迷失&lt;/li&gt; 
 &lt;li&gt;📚&amp;nbsp;在研究或学习时需要准确且引用充分的资料&lt;/li&gt; 
 &lt;li&gt;✍️&amp;nbsp;在创作或处理技术内容，如博客文章或代码片段&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Firefox 团队表示，这是他们更广泛目标的组成部分，即在使用搜索方式以及信任哪些工具来帮助他们完成任务方面为用户提供更多选择。如果体验良好，可能会考虑在未来支持更多 AI 回答或搜索选项。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepEP —— 开源 EP 通信库</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;DeepEP 是专为&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Mixture-of-Experts (MoE)&lt;/span&gt;&amp;nbsp;和 &lt;span style="background-color:#ffffff; color:#1f2328"&gt;expert parallelism (EP)&lt;/span&gt;&amp;nbsp;定制的通信库。它提供高吞吐量和低延迟的&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;all-to-all&lt;/span&gt;&amp;nbsp;GPU 内核，也就是所谓的 MoE 调度和组合。该库还支持低精度操作，包括 FP8。&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;为了与 DeepSeek-V3&amp;nbsp;论文中提出的 group-limited gating algorithm 保持一致，DeepEP 提供了一组针对非对称域带宽转发（例如将数据从 NVLink 域转发到 RDMA 域）进行优化的内核。这些内核提供高吞吐量，使其适合训练和推理预填充任务。此外，它们还支持 SM (Streaming Multiprocessors)&amp;nbsp;数量控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对于延迟敏感的推理解码，DeepEP 包含一组具有纯 RDMA 的低延迟内核，以最大限度地减少延迟。该库还引入了一种 hook-based 通信计算重叠方法，该方法不占用任何 SM 资源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;要求&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;Hopper GPU（以后可能支持更多架构或设备）&lt;/li&gt;
&lt;li style="text-align:start"&gt;Python 3.8 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;CUDA 12.3 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;PyTorch 2.1 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;用于节点内通信的 NVLink&lt;/li&gt;
&lt;li style="text-align:start"&gt;用于节点内通信的 RDMA 网络&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepep</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepep</guid>
      <pubDate>Sat, 10 May 2025 10:35:00 GMT</pubDate>
    </item>
    <item>
      <title>Gitee MCP 现已支持远程访问：无需本地部署，AI 助手即插即用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今年三月，&lt;a href="https://www.oschina.net/news/338794/gitee-mcp-server"&gt;Gitee 正式发布了官方 MCP Server&lt;/a&gt;，让 AI 助手深度参与代码仓库的管理，助力开发者更高效地工作。&lt;/p&gt; 
&lt;p&gt;今天，Gitee MCP 正式支持远程访问，上线了&lt;code&gt;Remote mcp-gitee&lt;/code&gt;：无需安装、即开即用，让 AI 助手可以远程、安全地与 Gitee 交互，真正做到「即连即用」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源地址：&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;什么是 Remote mcp-gitee？&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;是 Gitee 推出的远程版 MCP Server，无需本地部署，默认运行在云端，同时也拥有全面的接口能力，支持仓库、文件、Issue、PR、用户信息获取、评论等众多操作，满足常见开发协作需求。&lt;/p&gt; 
&lt;p&gt;你可以通过简单配置直接将其接入任意支持 MCP Streamable HTTP 协议的客户端，&lt;strong&gt;无需安装依赖、编译构建，也无需配置本地环境&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;与此前的本地部署方式不同，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;将服务完全托管在云端，为用户提供了开箱即用、跨平台、跨设备的一致使用体验。&lt;/p&gt; 
&lt;h2&gt;远程 MCP 有哪些使用场景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI 驱动的协作&lt;/strong&gt;：通过&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手能够自动创建 Issue、提取任务、拆解子任务、发起/合并 PR，减轻日常操作负担。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;低门槛接入&lt;/strong&gt;：无需本地搭建或安装依赖，企业或个人团队只需配置一次，即可将 MCP 能力集成至工作流中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨团队标准化流程&lt;/strong&gt;：所有操作通过远端 MCP 接入，统一管理权限、审计、日志，便于追踪和审查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;无需部署即可读写代码仓库&lt;/h2&gt; 
&lt;p&gt;借助&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手将具备完整的上下文访问能力，能够直接调用 Gitee 接口，获取仓库结构、读取文件内容、创建 Issue、生成 PR，甚至合并代码、发布版本。&lt;/p&gt; 
&lt;p&gt;你只需要准备一个 Gitee 访问令牌，并将其配置在客户端中，即可激活整个智能协作流程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"gitee": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"https://api.gitee.com/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"headers": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Authorization":&amp;nbsp;"Bearer &amp;lt;YOUR PERSONAL ACCESS TOKEN&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;本方法适用于 Cursor、Trae 等多种主流客户端，配置完毕后，即可直接连接 Remote mcp-gitee。&lt;/p&gt; 
&lt;h3&gt;在 Cursor 中连接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;进入 Cursor 设置页面，选择&lt;code&gt;Tools &amp;amp; Integrations&lt;/code&gt;，新建一个 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182420_lanO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将配置信息复制到文件中，填入 Gitee 账号的私人令牌，保存即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182431_KJ6X_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;返回设置页面，可以看到 mcp-gitee server 已正常连接。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182440_lOSn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;在 Trae 中连接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择任意一种方式进入 MCP 设置页面。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182451_sEtI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;搜索 Gitee 并添加。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182501_L5XD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将配置信息复制到文件中，填入 Gitee 账号的私人令牌（Trae 暂时未支持远程连接，需手动复制远程连接的配置信息）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182511_Y51c_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;确认后，mcp-gitee server 已成功连接至 Trae。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="360" src="https://static.oschina.net/uploads/space/2025/0618/182521_D6Qz_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182549_TvrI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;同时，开发者也可选择自行部署 Remote mcp-gitee 至本地，具体流程可访问项目仓库查看：&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;即插即用的智能协作，就在 Gitee&lt;/h2&gt; 
&lt;p&gt;Gitee 始终致力于在 AI 时代持续探索智能开发的边界。无论是底层协议支持，还是工具链能力拓展，我们都希望为开发者&lt;strong&gt;提供更开放、更易用、更高效、更先进的基础设施&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;让 Gitee MCP 能力以即插即用的方式走进开发者日常。无需安装、无需配置环境，只需一段 JSON 与私人令牌，就能让 AI 真正参与项目开发的各个环节。&lt;/p&gt; 
&lt;p&gt;现在，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;已全面开放使用，欢迎体验轻量、流畅的智能协作能力，欢迎访问项目仓库了解更多信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee" target="_blank"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356026</guid>
      <pubDate>Sat, 10 May 2025 10:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国家互联网信息办公室：中国已有 433 款大模型完成备案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 上海世界移动通信大会（MWC 上海 2025）开幕式上，国家互联网信息办公室副主任王京涛在致辞中指出，截至目前，中国已经有 433 款大模型完成备案，上线提供服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京涛表示，目前中国已成为全球最大的互联网市场，拥有全球最多的网民和移动互联网的用户，以及最活跃的数字技术和应用创新生态，建成了全球规模最大、技术领先、性能优越的网络基础设施。在追求自身发展的同时，中国也积极地推进各国共享互联网发展机遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向未来，中国要坚持发展与安全并重研究，加强发展战略、治理规则和技术标准的对接协调，推动人工智能朝着有益、安全、公平的方向健康、有序发展。要尊重各国网络主权，尊重各国的互联网发展道路和治理模式，共同构筑和平、开放、安全、合作、有序的网络空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京涛还表示，以人工智能为代表的新的数字技术，给人类生产生活带来前所未有的机遇的同时，不同地区、国家、群体间享受数字红利的差距依然较大。对此，他建议，秉持人类共同体理念，广泛开展人工智能国际合作，帮助发展中国家加强能力建设，提高人工智能的技术的可及性，弥合全球智能鸿沟，释放更多的智能红利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356024</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356024</guid>
      <pubDate>Sat, 10 May 2025 10:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「最火 AI 编程软件」 Cursor 备受风投公司青睐，公司估值超过 180 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-17%2Fai-startup-anysphere-fields-vc-offers-at-over-18-billion-valuation"&gt;据彭博援引知情人士报道&lt;/a&gt;，近几周来，投资者已与 Cursor 开发商 Anysphere 接洽，商讨一项融资协议，该协议将使这家初创公司的估值达到 180 至 200 亿美元。该提议是在这家 AI 初创公司年收入超过 5 亿美元后不久提出的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/180654_RHv6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;知情人士透露，该公司并未主动寻求新一轮融资，而是投资者主动接洽。&lt;/p&gt; 
&lt;p&gt;Anysphere 首席执行官 Michael Truell 此前透露，超过半数财富 500 强企业使用 Cursor，日活用户超过 100 万人。OpenAI、Spotify、美国职业棒球大联盟和 Instacart 等知名公司均为其用户。&lt;/p&gt; 
&lt;p&gt;这家成立于 2023 年的公司年化收入已突破 5 亿美元，被硅谷投资者誉为 「史上收入增长最快的初创公司」。虽然公司目前并不缺乏现金，但考虑到有利的融资条件，Anysphere 可能会选择增加更多资本储备。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356022</guid>
      <pubDate>Sat, 10 May 2025 10:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
