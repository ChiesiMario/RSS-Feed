<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 17 Mar 2025 07:37:29 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>谷歌 Gemini 2.0 Flash 模型增加去水印功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌旗下最新模型 &lt;a href=&quot;https://www.oschina.net/news/338720/gemini-2-0-flash-native-image-generation&quot;&gt;Gemini 2.0 Flash &lt;/a&gt;被&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fabdiisan%2Fstatus%2F1900147597571977631&quot; target=&quot;_blank&quot;&gt;发现&lt;/a&gt;可以用来去除图片中的水印，包括 Getty Images 等知名图库的水印。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-64731f3f85efa2187a99f37056db1a379b3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-23233ba4643e6ec781bc9bffdc6668351a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e55cf346cfad2540b6702a110098d654c58.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根据网友的反馈，Gemini 2.0 Flash 可以轻松生成描绘名人和受版权保护人物的图片，不仅如此，它还可以去除现有照片上的水印，同时还能填补因删除水印而产生的空白。有网友表示，其他大模型其实也能做到这一点，但 Gemini 2.0 Flash 在这方面特别娴熟，而且免费使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f59dcdf9ca70258e7afc58feab3154a3b1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;需要说明的是，Gemini 2.0 Flash 的图像生成功能目前被标注为 「试验性 」和 「非生产性使用」，并且只在谷歌面向开发者的工具（如 AI Studio）中可用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339380/gemini-2-0-flash-remove-watermarks</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339380/gemini-2-0-flash-remove-watermarks</guid>
            <pubDate>Mon, 17 Mar 2025 06:54:09 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>基于 Flink 的配置化实时反作弊系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;本文详细阐述了基于 Flink 构建的实时反作弊流式过滤系统，针对大流量场景下的复杂特征计算、高频策略热更新、模拟过滤验证及多场景数仓对接等核心挑战，提出来多项解决方案，实现了秒级特征计算的实时过滤功能，有效支撑高并发场景下的精准风控判定，并通过 ClickHouse 与图灵双链路数据输出，满足实时监控与离线分析的多样化需求，为互联网业务提供了高吞吐、低延迟、强稳定的实时反作弊解决方案。&lt;/p&gt; 
&lt;h1&gt;01 简介&lt;/h1&gt; 
&lt;p&gt;在互联网业务高速发展的今天，反作弊已成为 APP 厂商生态稳定运行的重要保障。作弊行为层出不穷，包括恶意点击、刷单、羊毛党等，这些行为不仅会破坏平台公平性，还可能造成巨大的经济损失。因此，构建一个高效、灵活、可扩展的实时反作弊系统变得尤为重要。&lt;/p&gt; 
&lt;p&gt;反作弊系统根据业务属性和时效性可分为三类：在线反作弊、实时反作弊与离线反作弊。其中，在线反作弊具备最高的时效性，能够即时响应风险；离线反作弊依托最全面的信息，支持深度分析与建模；而实时反作弊则兼具二者优势，提供平衡的时效性与信息丰富度。&lt;/p&gt; 
&lt;p&gt;在线反作弊系统通过快速处理简单指标进行判断，例如分析当前请求携带的字段信息，并结合基于 Redis 的简单累计值（如访问频率或特定行为计数）来制定策略。这种系统以低延迟为核心，能够在毫秒级别响应反作弊判定结果，适用于拦截时效要求高的风控需求。&lt;/p&gt; 
&lt;p&gt;离线反作弊系统通过对完整的离线数据进行大规模、长周期的数据挖掘和样本分析，为优化线上策略、构建特征黑产库和训练高精度模型提供支持。然而，由于依赖离线数据的批量处理，其时效性相对较低，通常难以满足实时风控的需求，更适合用于长期策略优化和深度分析场景。&lt;/p&gt; 
&lt;p&gt;实时反作弊系统能够在秒级别和分钟级别对用户的异常行为做出反馈，及时识别作弊用户并对业务进行止损。虽然其时效性略低于在线反作弊，但得益于对丰富维度和行为序列特征的分析，实时反作弊可以实现更加精准的策略判定，在精准性与时效性之间达到良好的平衡。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c8daaeef5688e23daf976cf98290b5df2eb.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本篇文章我们将重点分析实时反作弊流式系统的相关实现。&lt;/p&gt; 
&lt;h1&gt;02 流式系统面临的核心问题&lt;/h1&gt; 
&lt;p&gt;在实际建设过程中，我们需要解决以下关键挑战。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1&lt;/strong&gt; &lt;strong&gt;复杂的特征计算&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在实时反作弊场景中，用户行为数据规模庞大且动态变化（如电商大促、搜索点击等），系统需要处理海量的用户行为数据，并需基于时间窗口快速计算多维特征（如用户点击频率、IP 集中度、设备关联账户数）。这些特征需覆盖不同窗口粒度（秒级、分钟级、天级）和窗口类型（滑动、滚动、会话窗口），以捕捉异常行为模式。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;窗口特征计算的挑战（多维度多窗口多指标聚合）&lt;/strong&gt;：反作弊策略通常需要基于不同时间窗口（如分钟级、小时级、天级），不同维度（用户、设备、IP 等）进行特征累积计算。例如，计算某个用户在过去 1 小时内的点击次数，或者某个 IP 在过去 24 小时内的访问频率。这些计算涉及滑动窗口、滚动窗口等多种窗口类型，计算量大且复杂。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;数据乱序问题&lt;/strong&gt;：网络延迟或分区消费不均可能导致事件乱序到达，若未正确处理，会导致特征计算不准确，进而影响反作弊策略的判定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高并发下的状态存储优化&lt;/strong&gt;：在高并发场景下，特征累积计算需要频繁访问状态后端（如 RocksDB），导致性能瓶颈。例如，当 QPS 达到数十万甚至上百万时，状态后端的访问压力会显著增加，影响系统的吞吐量和延迟。长周期窗口（如月级）到期时，大量 Key 需同时清理状态，引发瞬时资源争抢，导致作业卡顿。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详见 3.2 大规模窗口特征计算，通过，内存缓存+微批处理减少状态访问、事件时间排序缓解乱序影响、keyBy 和 trigger 优化降低状态后端压力，最终支撑高吞吐场景下的精准计算。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&lt;/strong&gt; &lt;strong&gt;高频的策略更新迭代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;反作弊策略需要快速响应新型作弊行为。例如，当出现新的刷单手段或恶意点击行为时，风控团队需要迅速调整策略，以应对新的威胁。此外，不同业务场景（如广告点击、电商交易、社交互动）的反作弊策略差异较大，策略的复杂性和多样性增加了系统维护的难度。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高频迭代需求：&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;反作弊策略需要根据业务需求和作弊手段的变化进行高频更新，传统开发模式（修改代码→测试→发布）无法满足时效性。部分策略需「热生效」，避免作业重启导致数据丢失或计算中断。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;策略复杂性升级：&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多规则嵌套：单一策略可能需组合字段匹配（如 IP 黑名单）、模型评分（如行为异常概率＞90%）、时间窗口特征（如近 5 分钟同一设备注册账号数＞3）等多层条件，这些策略的复杂性增加了开发和维护的成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;配置管理风险&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;人工修改配置文件易出错 (如语法错误、字段误配),导致作业崩溃或策略漏判。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详见 3.3 配置化，通过全流程的配置化升级和配置文件托管，将策略规则、特征计算、字段抽取等逻辑抽象为配置文件，支持快速策略调整和上线，减少对底层代码的依赖，提升策略迭代效率。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3&lt;/strong&gt; &lt;strong&gt;模拟过滤的支持&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在反作弊策略上线前，风控团队需要对策略进行测试和验证，以确保其有效性和稳定性，这一过程称为模拟过滤。在实时反作弊系统中，模拟过滤是策略上线前的核心验证环节，其必要性体现在以下三个关键维度：&lt;/p&gt; 
&lt;p&gt;提前规避线上风险，防止「误杀」与「漏杀」：直接在生产环境上线新策略存在风险，可能导致误判或漏判，影响业务正常运行。因此，需要在测试环境中对策略进行模拟过滤，确保其准确性和稳定性。&lt;/p&gt; 
&lt;p&gt;验证策略性能，避免作业过载：模拟过滤历史峰值流量（如大促期间数据），验证作业在极限负载下的稳定性。&lt;/p&gt; 
&lt;p&gt;历史回溯与极端场景覆盖：从 HDFS 读取数月前的全量数据（如黑产攻击事件日志），验证策略对历史攻击的检测能力和进行数据回溯。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bd404e46079b8882bd219e2e8e2afdac799.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;详见 3.4 模拟过滤的实现，通过配置化、线上流与测试流隔离、数据 Source 改造等方式，加速策略效果验证环节。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.4&amp;nbsp;多场景数仓对接与平台整合&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;我们的系统产出的数据需要支持业务方的复杂分析需求。例如，基于反作弊结果进行策略优化，实时监控作弊行为的影响，对历史数据进行深度挖掘。&lt;/p&gt; 
&lt;p&gt;目前我们支持多种数仓形式（如实时 ClickHouse 与离线 Hive）的数据产出，满足不同业务场景下的需求，包括实时数据看板、策略评估、历史回溯等应用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;数据产出的便利性：反作弊系统需要将计算结果输出到多种存储系统（如 ClickHouse、Hive、Redis 等），以满足不同业务场景的需求。例如，实时数据需要写入 ClickHouse 用于实时监控，离线数据需要写入 Hive 用于历史分析。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自助分析能力：业务方需要对反作弊结果进行多维度的分析，例如按时间、地域、用户群体等维度进行统计分析。传统的固定报表无法满足这种灵活的分析需求。所以支持业务方进行自助分析，能够根据需求灵活查询和分析数据，而不依赖开发团队的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详见 3.5 便捷的数据分析，通过将反作弊结果输出到 ClickHouse 和 Hive，支持实时和离线分析。同时，接入 TDA（Turing Data Analysis 自助分析平台），业务方可以通过简单的 SQL 查询或可视化工具，灵活分析反作弊数据，满足复杂的分析需求。&lt;/p&gt; 
&lt;h1&gt;03 反作弊流式框架介绍&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 反作弊系统整体框架&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;整个实时反作弊的生效流程图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c6b95b7fffe05b73f639c2b18a36ea422dd.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上图展示了 Flink 反作弊流式实时过滤系统，的整体架构，包括，风控平台、实时作业、外部存储，三大核心模块，整体流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;风控平台（配置分发）&lt;/strong&gt;：反作弊工程师在平台上编辑策略规则、配置特征计算逻辑，并一键生成配置文件和启动模拟过滤验证策略效果。测试通过后，策略配置通过平台分发至实时作业。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时作业（配置解析与执行）&lt;/strong&gt;：Flink 作业解析平台下发的配置文件后，构建作业各个模块，包括数据接入、ETL 处理、特征计算、规则匹配等，最后提交并执行流式任务。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;作业结果存储（结果输出）&lt;/strong&gt;：ClickHouse，存储实时计算结果，支持快速查询与监控。Hive：存储离线数据，用于历史回溯与深度分析。Redis：提供低延迟查询，支持在线服务实时访问反作弊结果。消息队列：将判定结果传输至下游业务系统，供下游实时决策。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Flink 作业内部，实时流运行各个模块拆解如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-17b1acbc8844964c1987f9ca0d0cd7976d9.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;流式作业的主要模块可以分为：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;数据接入 Source&lt;/strong&gt;：业务事件日志数据（用户行为、支付、点击、搜索等）接入。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;数据 ETL 处理&lt;/strong&gt;：数据清洗、转换、标准化；简单维度拼接（ip 映射城市等）；第三方字段请求（风险评分、黑设备、用户画像等）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多重窗口特征计算&lt;/strong&gt;：时间窗口（分钟级、小时级、天级、周级、月级）、滑动、滚动窗口等，多种维度多种聚合函数进行特征累积聚合。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Join 阶段&lt;/strong&gt;：负责将特征和原始日志进行 join。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;规则策略匹配与判定&lt;/strong&gt;：机器学习模型打分，配置化规则引擎基于之前的所有信息进行最终判定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下游输出&lt;/strong&gt;：实时反馈给线上服务、下发给业务方、入数仓表等方式将判定结果进行输出落盘。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;大规模窗口特征计算&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;对于整个作业而言，主要计算资源就是用于累积基于窗口的特征。对于业务需求而言，不同窗口下的特征聚合结果是提升判定的准确率和召回率最重要的信息。&lt;/p&gt; 
&lt;p&gt;我们的窗口累积逻辑主要基于 Flink 窗口功能实现，包括 TumblingWindows、SlidingWindows 和 SessionWindows，Session 窗口使用较少。我们未使用其原生 Aggregate 函数，而是采用了更底层的 WindowProcessFunction 实现窗口聚合逻辑。这种方式的优势在于为后续优化提供了更大的灵活性和定制空间。&lt;/p&gt; 
&lt;p&gt;为了满足业务诉求，我们也对原生的窗口机制进行了多项优化，主要升级点有以下几个：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提前触发&lt;/strong&gt;：无需等待窗口结束即可实时下发累积结果，满足业务对于数据时效性的要求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;批量更新和抗乱序&lt;/strong&gt;：采用批量状态更新方式，减少频繁读取与写入，同时在微批更新时进行局部重排序，以降低乱序影响。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;键缩减-粗粒度 KeyBy&lt;/strong&gt;：优化 keyBy 和窗口触发器设计，减少状态访问频次，提高缓存命中率，降低计算开销。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下边将分别进行介绍。&lt;/p&gt; 
&lt;h3&gt;3.2.1 时效性优化-提前触发&lt;/h3&gt; 
&lt;p&gt;默认情况下，Flink 的每个窗口自带一个触发器（Trigger），在窗口结束时触发计算并生成聚合结果。然而，在实时性要求较高的反作弊场景中，如果窗口长度长达一天，等待窗口结束再下发结果显然不符合要求的。因此，我们需要在窗口尚未结束时，通过特定条件提前触发窗口计算，这种机制称为「&lt;strong&gt;提前触发&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;Flink 提供了多种现成的窗口触发方式，包括按 ProcessTime 定时触发、按 EventTime 定时触发、按固定条数触发等，同时也支持自定义触发方式。针对我们的业务需求，目前采用的是按事件时间的间隔提前触发方式。具体触发间隔依据不同业务场景设定，能够在秒级或分钟级就能得到窗口的聚合结果。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-80c3ba5492f6c98f0b38c449c67a83bef8f.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;上图:&lt;/strong&gt; 展示了 Flink 原生窗口的触发机制及其聚合过程。每个绿色矩形表示一个窗口，窗口范围内累积了多个事件，编号为 1、2、3 、4、5。红色圆圈表示触发时下发的特征数据，从上图可以看到，窗口触发是在窗口结束时统一执行的，下发了 2、5、3、1 四条特征。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;下图&lt;/strong&gt;：改造后 - 提前触发机制**，**展示了优化后的窗口触发机制，通过提前触发减少延迟。每个绿色矩形依旧表示一个窗口，但触发时间提前，避免了窗口结束时的集中计算，红色圆圈同样表示输出结果。提前触发机制在窗口中按事件到达顺序多次输出，窗口中的事件可以更早地被处理，提升了时效性。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;3.2.2&amp;nbsp;乱序和性能优化-批量更新和乱序纠正&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在大流量场景下的测试表明，当前吞吐瓶颈主要受限于窗口聚合时 RocksDB 状态后端读写。由于一条数据会抽取多条特征，所以特征窗口累积算子会对 Source 输入数据进行爆炸式扩展，例如当输入数据 QPS 达到 10 万时，特征累积算子的 QPS 可能攀升至数十万甚至上百万，导致大量状态读写请求集中在 RocksDB，使其难以支撑高吞吐需求。&lt;/p&gt; 
&lt;p&gt;Flink 默认的窗口机制会在每条数据到达时更新累积值，并与状态后端交互，进一步加剧了 RocksDB 的负担。为优化性能，我们将窗口触发和累积调整为&lt;strong&gt;微批模式&lt;/strong&gt;，每次批量更新数据，并引入&lt;strong&gt;内存缓存层&lt;/strong&gt;，微批内优先访问内存缓存，有效减少状态的访问次数。&lt;/p&gt; 
&lt;p&gt;在百度搜索和点击流量场景下的测试结果显示，该优化方案使&lt;strong&gt;内存缓存命中率提升至 90% 以上&lt;/strong&gt;，意味着特征累积阶段减少了约 90% 的状态后端访问。&lt;/p&gt; 
&lt;p&gt;同时，在微批数据内部，我们会进行排序，还能有效缓解数据乱序问题，提高计算准确性。如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7ca0739f1ae258fe5b426d4fb3bb292d867.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上图：Flink 默认窗口累积机制，**绿色矩形代表窗口的时间范围，窗口中的每一条数据（标记为 1、2 等）都会触发累积操作。图示中展示了 5 条 pv 的状态后端访问，每条 pv 都需要与，状态后端（图中黄色区域）进行交互，包括查询、更新、写入等操作。红色圆圈是输出的累积结果，红色边框标记的条目表示乱序数据。上图存在两个问题，第一，对状态后端的频繁随机访问会导致性能瓶颈，尤其是在高并发和大流量场景下。第二，输入数据是乱序的情况下，输出数据也是乱序的。&lt;/p&gt; 
&lt;p&gt;下图：优化后的窗口累积机制，**优化引入了内存缓存和微批模式。数据小批量更新（如标记为 2、1、4 为一批、3、5 为一批）。每次窗口触发时，首先会对本次微批内的数据进行排序 (2,1,4 被纠正为 1,2,4)，然后再累积。累积时，窗口内的累积查询会先访问内存缓存，如果内存 miss，再访问状态后端。最终图示中仅有 4 次状态后端交互，较优化前的 15 次减少 11 次。数据乱序也得到了缓解。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;3.2.3 大流量场景优化-键缩减 (粗粒度 KeyBy)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;窗口聚合过程中累积器需要频繁读写状态后端。此前，我们通过引入缓存层和微批模式大幅减少窗口累积器对状态的访问频次，优化效果显著。然而，在实际应用中，我们发现窗口触发器（Trigger） 也会频繁访问状态后端，带来额外的性能开销。&lt;/p&gt; 
&lt;p&gt;在实际业务场景中，特征累积的窗口划分通常较细粒度，例如基于 ip、query、uid 进行 keyBy，且随着业务接入的线索和特征增多，key 的数量变多，计算压力进一步加大。这导致两个主要问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key 数量激增，触发频繁访问状态&lt;/strong&gt;：keyBy 后的 Key 量级极大，每个 Key 维护独立的 Trigger，这些 Trigger 需要不断访问状态后端进行触发注册，造成高频状态交互，影响吞吐。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;窗口清理（clear）导致计算压力骤增&lt;/strong&gt;：当水位（watermark）推进到窗口末端时，大量 Key 需要同时触发 Clear 操作，瞬时状态访问量暴增，可能导致作业卡顿甚至崩溃，特别是在窗口长度较长、窗口内 Key 数量庞大的情况下。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;针对上述问题，我们探索了更高效的 Trigger 机制，以降低状态访问开销，提高作业稳定性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第一，减少 Trigger 数量：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;举个例子，我们基于 UID 进行特征聚合，如果我们在对特征数据执行 keyBy 操作时，直接按照最细粒度的 UID 维度进行分区处理。那么每个唯一的 key 都会绑定一个触发器（trigger），而触发器的数量直接影响状态访问的频次和资源占用。&lt;/p&gt; 
&lt;p&gt;为了解决这个问题，我们采用了按 UID 进行取模分区的方式（例如按 uid%100 进行 keyBy 分区）。这种方式显著减少了触发器的数量，从而降低了状态存储和访问的开销。同时我们定制了聚合函数，保证每个分区内进行聚合计算的时候还是会按照原本的 UID 作为 key 进行特征累积，保证特征累积的准确性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第二，状态放入内存：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进一步优化时，我们发现，当按照固定数量（如 100 个分区）取模后，key 的数量和值是确定且有限的。基于此特性，我们将触发器的状态从 Flink 的状态后端迁移到内存中管理，这样能够进一步提升性能，避免频繁访问状态存储带来的开销。&lt;/p&gt; 
&lt;p&gt;有人可能担心：触发器状态迁移到内存后，作业一旦发生重启，内存中的数据会丢失，这可能导致窗口数据无法正常触发。例如，若按 UID 进行 keyBy 计算，某个 UID 仅有一条数据，且此时作业重启导致其触发器状态丢失，那么作业恢复后这条数据永远可能无法下发。&lt;/p&gt; 
&lt;p&gt;但通过固定分区取模（如按 %100 分区）后，我们有效解决了这个问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;取模分区的 key 数量是有限的（如 100 个），并且这样能保证每个分区会持续接收到新的数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当作业重启时，新数据的到来会自动重新注册触发时间，即便原有内存状态丢失，后续的数据流动能够重新触发正常的处理逻辑。因此，即使触发器状态短暂丢失，取模后的分区会很快自愈，确保数据下发的正确性和完整性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-db078d3b573516691731e8c08cf5c321a52.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上图最左边-原始设计，数据流按照 uid 进行 keyBy 分组，每个 uid 都对应一个独立的 trigger。每个 trigger 需要与状态后端 (StateBackend) 频繁交互，包括保存和更新状态。存在问题是：状态后端需要频繁访问，尤其在高并发场景下，性能瓶颈明显。每个 uid 都维持一个独立的窗口触发器，资源消耗较高。&lt;/p&gt; 
&lt;p&gt;上图中间-第一版优化，将原始 uid 进行取模操作 (uid % 100)，将原本细粒度的分组合并为粗粒度的分组。即多个 uid 合并到同一个分组中，减少了窗口触发器的数量。状态后端的访问频率有所减少，降低资源消耗，提升了整体吞吐量。&lt;/p&gt; 
&lt;p&gt;上图右边-第二版优化，内存的引入，每个 trigger 相关的信息存储于内存中，而不是直接与状态后端交互。大幅减少状态后端的访问次数。提升了系统性能，确保作业稳定运行。&lt;/p&gt; 
&lt;p&gt;综上，在 Flink 反作弊系统的窗口特征累积优化中，我们针对高吞吐、低延迟、抗乱序等业务需求，进行了多项改进。&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;提升时效性&lt;/strong&gt;：反作弊策略依赖实时特征，默认窗口触发方式无法满足业务需求。因此，我们采用提前触发机制，基于事件时间间隔触发计算，使特征聚合结果能够秒级或分钟级输出，避免长窗口带来的数据滞后问题。&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;优化性能瓶颈&lt;/strong&gt;：在高并发场景下，特征计算涉及海量状态存储访问，容易导致 RocksDB 负载过高，影响作业稳定性。我们引入批量更新、内存缓存 、trigger 优化、分区缩减等方式，大幅提升吞吐量。&lt;/p&gt; 
&lt;p&gt;综合优化后，该方案使 Flink 反作弊系统具备更快的特征计算能力、更高的吞吐性&lt;strong&gt;能&lt;/strong&gt;，有效支撑高并发业务场景下的实时风控需求。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;3.3&amp;nbsp;配置化&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;为了满足反作弊策略的高频上线和模拟过滤等需求，我们的实时系统实现了高度配置化。并且配置文件全部托管到风控平台。通过配置化驱&lt;strong&gt;动&lt;/strong&gt;的架构，无论是字段抽取、特征加工、策略规则定义和数仓产出，均可以通过简单的配置操作快速完成，极大地缩短了开发周期，同时降低了对底层框架代码开发的依赖。只需要在风控平台上编辑好策略，就可以一键分发并启动对应的测试或线上作业。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-33c428c7da855a9dd66a4834ea9ebbe4184.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，相关配置文件可以分为两类分别是工程配置（绿色）和策略配置（黄色），策略配置主要用于定义业务过滤规则和逻辑，工程配置侧重于系统的底层运行，比如输入输出、并行度等配置。并且部分配置文件为非必需项，这意味着如果某个计算模块不需要使用，则相应的配置文件可以省略。&lt;/p&gt; 
&lt;h2&gt;3.3.1 工程配置&lt;/h2&gt; 
&lt;p&gt;工程配置是管理流式作业运行的系统层面参数。针对反作弊场景的实时流式任务，与 Flink CDC YAML 的设计思路类似，也是通过 YAML 文件对通用工程配置进行抽象和统一管理，确保流式作业能够灵活适配多种业务场景。&lt;/p&gt; 
&lt;p&gt;为了保证一个 Flink 流式作业的正常运行，完整的工程配置需要包含以下几个关键部分：输入配置、输出配置、并发配置。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;输入配置：决定了 Flink 作业如何接收和解析源数据，定义数据源类型（如 Kafka、HDFS）、连接参数、消费策略等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;输出配置：定义了 Flink 作业的计算结果如何存储或传输到下游系统，指定结果存储方式（如 ClickHouse 表、Redis 集群、Kafka Topic）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;并发配置：直接影响 Flink 作业的性能、吞吐量以及资源使用情况，设置算子并行度、检查点间隔等，优化作业性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.3.2&amp;nbsp;策略配置&lt;/h3&gt; 
&lt;p&gt;策略配置是指将反作弊拦截策略的核心逻辑规范化，以配置文件的形式灵活定义和管理。通过策略配置化设计，能够快速调整或部署反作弊策略，无需修改底层代码。&lt;/p&gt; 
&lt;p&gt;策略的配置主要由字段抽取配置、特征配置、词表配置、模型配置和规则配置等组成。&lt;/p&gt; 
&lt;p&gt;字段抽取配置：字段是反作弊策略和数仓的最基础的信息，根据抽取方式不同分为：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;基础字段：直接从原始数据流中提取的字段，例如设备 ID、用户 ID 等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;二次计算字段：通过基础字段计算生成的派生字段，设备 ID 是否合法，UID 是否为历史黑用户等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;外部服务字段：通过调用外部服务接口动态获取的字段，例如 IP 地址归属地、安全风控标签等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;维表字段：通过查询词表映射关系获得的字段，例如黑名单匹配结果、分类标签等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们将字段抽取逻辑进行了配置化抽象，策略开发人员使用类似于写 sql 的方式即可完成简单字段的 etl 逻辑的开发，如常见的 json 字段抽取，字符串处理，反作弊内部的常用 UDF 等，配置能覆盖大部分字段抽取，对于复杂的字段抽取逻辑仍旧使用 Flink 的 Datastream API 开发实现。&lt;/p&gt; 
&lt;p&gt;特征配置：特征是策略的重要判定依据，特征配置包括以下几个关键方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;特征类型：数据的聚合方式，如 sum、count、distinct 等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;窗口信息：设置聚合特征的时间窗口范围和窗口形式，时间范围如：1 分钟、1 小时等，窗口形式如：滑动窗口、滚动窗口等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;特征维度：特征的聚合维度，如用户、设备、IP 地址等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;词表配置：词表通常是离线挖掘得到的黑名单、字段映射（如 ip 映射城市）等固定维表信息，配置内容需包括以下几个方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;词表路径：指定词表的存储位置，支持文件路径或分布式存储地址。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;词表类型：支持多种形式的词表，包括集合（set）、键值对映射（kv）、正则表达式（regex）等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模型配置：通过模型实现复杂的行为预测和风险判定，关键配置内容包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;模型路径：指定模型的存储位置，支持本地或远程加载。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型类型：支持多种模型形式，例如线性回归、GBDT 等，目前模型的加载是通过 PMML 框架实现的。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型输入输出：明确模型所需的输入字段和输出字段等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;规则配置&lt;/strong&gt;：规则配置决定了作弊行为的最终判定规则和处置方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;策略判定阈值：定义触发策略的条件，例如基础字段匹配、词表匹配、风险评分的阈值、特征累积阈值、模型打分阈值等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;策略判黑等级：设定风险等级，区分低、中、高风险及对应的处置措施。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如下图所示，规则配置能够获取所有字段信息，并基于这些信息进行最后的策略判定。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3e2b45a57ad48af62f1e82de4627311d047.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这张图展示了反作弊规则的判定流程：&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;输入数据&lt;/strong&gt;：每条 PV 包含多个字段**，**包括基础字段（如 IP、手机号、UID 等）、外部抽取字段（如 IP 归属地、是否异常等）、计算得到的特征（如统计特征 fea1、fea2 等）以及模型得分（多个模型计算的分值）。&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;策略判定&lt;/strong&gt;：系统基于预设的反作弊规则，对各字段、特征、模型分数进行综合评估。例如，规则 1 要求【fea1 &amp;gt; 100 &amp;amp;&amp;amp; model2 &amp;gt; 0.95】，规则 2 要求 【IP like &#39;192.%&#39; &amp;amp;&amp;amp; fea2 &amp;gt; 100 &amp;amp;&amp;amp; model1 &amp;gt; 0.65】。多个规则都会执行判定逻辑，判断是否命中。&lt;/p&gt; 
&lt;p&gt;3.&lt;strong&gt;结果输出&lt;/strong&gt;：最终的 PV 数据会带上反作弊命中结果。例如，在示例中，该 PV 数据命中了规则 2，表明该行为可能存在风险。&lt;/p&gt; 
&lt;p&gt;以上就是策略配置的所有介绍，通过配置化管理字段、特征、词表、模型和规则，反作弊系统能够快速响应业务需求，灵活调整检测逻辑。同时，配置化设计大幅降低了开发部署成本，提高了策略迭代效率。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.4&amp;nbsp;模拟过滤的实现&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;通过配置化的支持，可以方便地切换数据输入和输出，所以仅需调整测试配置文件，即可启动模拟过滤作业，提升测试效率。同样的模拟过滤功能也接入了风控平台，开发者可以直接一键调启模拟过滤任务。&lt;/p&gt; 
&lt;p&gt;对于直接接入实时消息队列进行模拟过滤，基本无需修改输入配置，然而，基于实时消息队列的模拟过滤存在一定局限性，首先运行耗时较长，需要 1:1 的时间来进行测试。如过滤 24 小时数据需 24 小时，难以快速验证策略长期效果，其次消息队列仅保存最近几天的数据，历史数据回溯能力有限。一般仅适用于简单工程测试和策略模拟过滤。&lt;/p&gt; 
&lt;p&gt;为此，我们扩展了 Flink 的 HDFS Source 组件，支持直接读取 HDFS 上的 Parquet 文件进行模拟过滤。在读取 Parquet 文件时，因为是流式计算，主要挑战在于数据顺序问题，为确保数据时序一致性，我们采取了以下优化策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件级别排序&lt;/strong&gt;：在读取数据时，按照文件路径和名称进行排序，确保数据按时间顺序加载。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;顺序读取文件&lt;/strong&gt;：严格按照排序后的顺序依次读取 Parquet 文件，避免乱序问题，保证数据的时序性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过这一优化方案，我们在策略模拟过滤中与线上对比测试，准确率达到 99% 左右，大幅提升了模拟过滤的可靠性和一致性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cbc609f6de7bc91ac2b4a0563226cd94838.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;除了 Source 组件适配了读取离线数据外，其他组件跟线上完全一致，这样就保证了模拟过滤的准确性。极端场景下（如线上作业出错需重新回溯数据），可通过此方式对离线数据再次模拟流式过滤，实现数据修正。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.5&amp;nbsp;便捷的数据分析&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在实时反作弊系统中，数据分析不仅是风控团队优化策略的核心工具，也是业务方监控风险、评估影响的重要支撑。为了满足不同角色的分析需求，系统提供了离线和实时的数仓产出，帮助进行便捷的数据分析。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a414bc27b82636814d788831804ca209d97.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上图展示了我们的数仓方案，其中 Flink 负责实时数据流的计算和处理，最终将数据分别存储到 HDFS（Parquet 格式） 和 ClickHouse。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;离线 Hive 表&lt;/strong&gt;：Flink 将数据以 Parquet 格式，存储到 HDFS，支持按刻钟或小时级别分区产出数据，并挂载到图灵表中，便于后续使用 Hive、Spark 进行批量计算和查询。也可以作为后续回溯和测试模拟过滤的直接输入。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时 ClickHouse 表&lt;/strong&gt;：支持实时数据产出，用于高性能的 OLAP 分析，可用于快速分析策略上线效果、构建实时看板以及告警监控等场景。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种架构能够同时满足，实时查询，和 离线存储分析，需求，实现高效的数据流式处理与存储。&lt;/p&gt; 
&lt;p&gt;高效便捷的数据分析主要满足了如下需求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时监控与告警&lt;/strong&gt;：业务方需实时了解反作弊策略的执行效果（如拦截量趋势、高风险用户分布）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于 ClickHouse 的秒级查询能力，支持实时生成监控看板（如「近 1 小时拦截量 TOP 10 IP」）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;配置告警规则（如「拦截量突增 50%」），通过邮件或消息推送及时通知相关人员。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自助分析与可视化&lt;/strong&gt;：业务方能够灵活分析作弊行为特征（如羊毛党设备型号分布、异常行为时间规律）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;接入 TDA 自助分析平台，支持 SQL 查询与拖拽式可视化分析，无需依赖数据团队。预置常用分析仪表盘，降低使用门槛。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;离线挖掘与模型优化&lt;/strong&gt;：数据同学能够于历史数据挖掘作弊模式，优化策略规则与机器学习模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将全量数据存储至 Hive，支持 Spark、Flink 等分布式计算引擎进行进一步的复杂分析。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过便捷的数据分析能力，系统不仅提升了风控策略的迭代效率，还赋能业务方自主探索数据价值，实现从「被动响应」到「主动洞察」的转变。&lt;/p&gt; 
&lt;h1&gt;04 总结&lt;/h1&gt; 
&lt;p&gt;本文介绍了基于 Flink 的实时反作弊流式过滤系统，围绕架构设计、挑战应对及优化方案展开。通过特征计算和配置化管理，提升了系统的检测效率和稳定性。实践表明，该方案在提升数据处理时效性与反作弊效果方面均取得显著成效。未来，将进一步优化策略检测机制，提升检测精准度，并探索更智能的风险识别手段。&lt;/p&gt; 
&lt;p&gt;------END-----&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度智能云 xDeepSeek，最具性价比的 DeepSeek 一体机合集来了！&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604157%26idx%3D1%26sn%3D4f72a1ce996776b78cf02f13e7e74c2c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;图引擎在智能体开发场景的应用实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604082%26idx%3D1%26sn%3D997d754d2058e4d0fc83d6209da36c28%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;直播间互动框架性能优化与稳定性实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604026%26idx%3D1%26sn%3Db6c6367e9bcbe2dab70a1282140ea740%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度网盘防雪崩架构实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603987%26idx%3D1%26sn%3D4a88159ec791a37e75053139e0b4682c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何在百度百舸部署满血版 DeepSeek-V3、DeepSeek-R1 模型&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4939618/blog/17819722</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17819722</guid>
            <pubDate>Mon, 17 Mar 2025 06:49:09 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>国家统计局：国产人工智能大模型异军突起</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国家统计局新闻发言人、国民经济综合统计司司长付凌晖在国务院新闻办公室举行的新闻发布会上表示，从前两个月情况来看，科技创新不断取得新突破，新产业发展向好，数字经济、绿色经济持续壮大，传统产业转型升级步伐稳步推进，新质生产力发展取得新进展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新兴产业保持较快增长。前两个月，规模以上高技术制造业增加值同比增长 9.1%，比上年全年加快 0.2 个百分点。国产人工智能大模型异军突起，「人工智能+」等创新产品跑出了加速度，推动生产方式变革，带动高端制造快速发展。1-2 月份，集成电路圆片、工业机器人、动车组、民用无人机等高技术产品产量同比分别增长 19.6%、27%、64%、91.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;数字经济活力不断释放。各地区各部门加快推进产业数字化和数字产业化，数字经济发展势头向好。从行业来看，前两个月，规模以上数字产品制造业增加值同比增长 9.1%，信息传输软件和信息技术服务业生产指数增长 9.3%。从产品来看，3D 打印设备、虚拟现实设备等智能产品产量分别增长 30.2%、37.7%。5G 规模化应用持续推进，春节期间 5G 移动互联网用户接入流量比上年同期增长 35%，占移动互联网用户接入流量的比重达到 60.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;绿色经济打造新增长点。绿色转型扎实推进，为新质生产力的发展注入了新动力。前两个月，规模以上工业风力、太阳能发电量同比分别增长 10.4% 和 27.4%，新能源汽车、汽车用锂离子动力电池、碳纤维及其复合材料等绿色产品的产量分别增长 47.7%、35.4%、51.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;产业转型升级步伐稳健。产业数字化转型、智能化升级为新质生产力发展增添新来源。前两个月，制造业技改投资同比增长 10%，快于全部投资 5.9 个百分点。目前，我国已经建成了 3 万多家基础级智能工厂、1200 余家先进级智能工厂、230 余家卓越级智能工厂，将有效赋能产业转型升级。(来源：光明网)&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339377</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339377</guid>
            <pubDate>Mon, 17 Mar 2025 06:46:09 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>小米大模型团队登顶音频推理 MMAU 榜</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;@小米技术，官微今日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6486870325%2FPiWm5dWt9%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;发文称&lt;/a&gt;&lt;/u&gt;，小米大模型团队在音频推理领域取得突破性进展。&lt;strong&gt;受 DeepSeek-R1 启发，团队率先将强化学习算法应用于多模态音频理解任务，仅用一周时间便以 64.5% 的 SOTA 准确率登顶国际权威的 MMAU 音频理解评测榜首，现同步开源&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0317/143932_ioaO_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0317/144349_iKQr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;官方全文如下：&lt;/p&gt; 
&lt;h3&gt;强化学习展现「反直觉」优势 —— 小米大模型团队登顶音频推理 MMAU 榜&lt;/h3&gt; 
&lt;p&gt;面对一段汽车行驶中的座舱录音，AI 能否判断出汽车是否存在潜在的故障？在交响乐演出现场，AI 能否推测出作曲家创造这首音乐时的心情？在早高峰地铁站混乱的脚步声潮中，AI 能否预判闸机口可能发生的冲撞风险？在大模型时代，人们已经不满足于机器仅仅识别说话的内容、声音的种类，更期望机器具备复杂推理的能力。&lt;/p&gt; 
&lt;p&gt;MMAU（Massive Multi-Task Audio Understanding and Reasoning）评测集（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2410.19168&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2410.19168&lt;/a&gt;）是这种音频推理能力的量化标尺，它通过一万条涵盖语音、环境声和音乐的音频样本，结合人类专家标注的问答对，测试模型在 27 种技能，如跨场景推理、专业知识等应用上的表现，期望模型达到接近人类专家的逻辑分析水平。&lt;/p&gt; 
&lt;p&gt;作为基准上限，人类专家在 MMAU 上的准确率为 82.23%。这是一个很难的评测集，目前 MMAU 官网榜单上表现最好的模型是来自 OpenAI 的 GPT-4o，准确率为 57.3%。紧随其后的是来自 Google DeepMind 的 Gemini 2.0 Flash，准确率为 55.6%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3b140b978b8e575f07877afe084fdcbad6f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;MMAU 任务示例图片来自 MMAU 论文&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;来自阿里的 Qwen2-Audio-7B 模型在此评测集上的准确率为 49.2%。由于它的开源特性，我们尝试使用一个较小的数据集，清华大学发布的 AVQA 数据集（https://mn.cs.tsinghua.edu.cn/avqa/），对此模型做微调。AVQA 数据集仅包含 3.8 万条训练样本，通过全量有监督微调（SFT），模型在 MMAU 上的准确率提升到了 51.8%。这并不是一个特别显著的提升。&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 的发布为我们在该项任务上的研究带来了启发。DeepSeek-R1 的 Group Relative Policy Optimization (GRPO) 方法，让模型仅通过 &quot;试错-奖励&quot; 机制就能使自主进化，涌现出类似人类的反思、多步验证等推理能力。在同一时间，卡内基梅隆大学发布的论文预印本「All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine-Tuning (https://arxiv.org/abs/2503.01067) 」，通过精巧的实验得出了一个有趣的论断：当任务存在明显的生成-验证差距（Generation-Verification Gap），即任务生成结果的难度远大于验证结果正确性的难度时，强化学习比起有监督微调具有独特优势，&lt;strong&gt;而 AQA 任务恰好是完美的生成-验证差距显著的任务。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;打个比方来说，离线微调方法，如 SFT，有点像背题库，你只能根据已有的题目和答案训练，但遇到新题可能不会做；而强化学习方法，如 GRPO，像老师在要求你多想几个答案，然后老师告诉你哪一个答案好，让你主动思考，激发出自身的能力，而不是被「填鸭式」教学。当然，如果训练量足够，比如有学生愿意花很多年的时间来死记硬背题库，也许最终也能达到不错的效果，但效率太低，浪费太多时间。而主动思考，更容易快速地达到举一反三的效果。强化学习的实时反馈可能会帮助模型更快锁定高质量答案的分布区域，而离线方法需要遍历整个可能性空间，效率要低得多。&lt;/p&gt; 
&lt;p&gt;基于上述洞察，&lt;strong&gt;我们尝试将 DeepSeek-R1 的 GRPO 算法迁移到 Qwen2-Audio-7B 模型上&lt;/strong&gt;。令人惊喜的是，在仅使用 AVQA 的 3.8 万条训练样本的情况下，&lt;strong&gt;强化学习微调后的模型在 MMAU 评测集上实现了 64.5% 的准确率，这一成绩比目前榜单上第一名的商业闭源模型 GPT-4o 有近 10 个百分点的优势。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有趣的是，当我们在训练中强制要求模型输出 &amp;lt;thinking&amp;gt;&amp;lt;/thinking&amp;gt; 推理过程时（类似传统思维链方法），准确率反而下降至 61.1%。这说明显式的思维链结果输出可能并不利于模型的训练。&lt;/p&gt; 
&lt;p&gt;我们的实验揭示了几个和传统认知不同的结论：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;关于微调方法：强化学习在 3.8 万条数据集上的表现显著超过监督学习在 57 万条数据集上的结果&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;关于参数规模：相比千亿级模型，7B 参数的模型通过强化学习也可展现强推理能力&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;关于隐式推理：显式思维链输出反而成为性能瓶颈&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;尽管当前准确率已突破 64%，但距离人类专家 82% 的水平仍有差距。在我们当前的实验中，强化学习策略还是比较粗糙，训练过程对思维链的引导并不充分，我们会在后续做进一步探索。&lt;/p&gt; 
&lt;p&gt;此次实验验证了强化学习在音频推理领域的独特价值，也为后续研究打开了一扇新的大门。当机器不仅能 &quot;听见&quot; 声音，还能 &quot;听懂&quot; 声音背后的因果逻辑时，真正的智能听觉时代将会来临。&lt;/p&gt; 
&lt;p&gt;我们把训练代码、模型参数开源，并提供了技术报告，供学术界产业界参考交流。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;训练代码：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxiaomi-research%2Fr1-aqa&quot; target=&quot;_blank&quot;&gt;https://github.com/xiaomi-research/r1-aqa&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;模型参数：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmispeech%2Fr1-aqa&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/mispeech/r1-aqa&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;技术报告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.11197&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2503.11197&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;交互 Demo：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2F120.48.108.147%3A7860%2F&quot; target=&quot;_blank&quot;&gt;http://120.48.108.147:7860/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339374</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339374</guid>
            <pubDate>Mon, 17 Mar 2025 06:43:09 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>深圳市监局回应翻新机流入「百亿补贴」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 14 日，深圳市场监管官方账号&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F3096706037%2FPivbVcoJ8%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;发布了如下情况通报&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0317/142845_zd5R_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;深圳市场监管局表示，「近日有媒体报道称，华强北市场有翻新手机流入某电商平台「百亿补贴」活动。此前其已联合辖区公安局、属地街道办等单位对后封机、翻新机的生产、销售链条开展了多轮专项治理；针对报道中提及的线索，深圳市场监管局高度重视，已第一时间组织执法人员到华强北及周边手机销售市场进行核查。」&lt;/p&gt; 
&lt;p&gt;此前，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FOhcR-SyMPDXAiHeu0rH3iw&quot; target=&quot;_blank&quot;&gt;据新京报贝壳财经记者暗访发现&lt;/a&gt;&lt;/u&gt;，位于深圳的华强北市场有大量翻新机、改装机、瑕疵机进行二次包装后，通过购物平台的「百亿补贴」专区流入市场，但因平台上店铺信息不透明、不公开等原因，导致消费者维权难，甚至维权失败。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;344&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0317/143320_EUun_2720166.png&quot; width=&quot;1266&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0317/143355_fGc2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;14&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0317/143331_Ri6R_2720166.png&quot; width=&quot;14&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;报道指出，《产品质量法》明确规定，对于不具备产品应具备使用性能而事先未作说明或不符合产品说明、实物样品等方式表明的质量状况等，销售者应当负责修理、更换、退货并赔偿损失。因此，如果平台对消费者拒绝履行以上法定义务的，就侵犯了消费者的合法权益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339373</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339373</guid>
            <pubDate>Thu, 06 Mar 2025 06:34:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百川智能联合创始人焦可、陈炜鹏出走，均开启 AI 领域创业</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蓝鲸新闻从多位知情人士处独家获悉，大模型六小虎之一的百川智能创始团队出现变动，其中，联合创始人焦可已经离职，另一位联合创始人陈炜鹏也将离职，目前还在走内部流程。另据知情人士称，焦可和陈炜鹏两人都已经分别开始 AI 领域的创业。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;焦可和陈炜鹏都是在百川智能创立早期就加入公司的创始团队成员。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;焦可在本科期间就读于清华大学计算机专业，和王小川是校友，之后硕士就读于中国科学院计算技术研究所硕士。知情人士称，在百川智能期间，焦可主要负责互联网业务。知情人士透露，目前焦可已经在 AI 语音方向创业，且正在寻求融资。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ace6aceb943f52a522046a798c49026095.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;em&gt;前百川智能联合创始人焦可&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一位联合创始人陈炜鹏在百川智能期间主要负责大语言模型技术部分，同时也曾在搜狗担任高管。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;资料显示，陈炜鹏 2012 年毕业于哈尔滨工业大学，在搜狗时，陈炜鹏曾担任搜狗搜索研发总经理，负责搜狗通用/垂直搜索和推荐系统的研发工作。搜狗被腾讯收购后，陈炜鹏加入 Soul，担任技术 VP，负责算法能力建设，推动内容理解、推荐技术和 AIGC 技术在社交场景的应用和落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;317&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d0101b72f1883ead7d60a06095868407a36.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;em&gt;百川智能联合创始人陈炜鹏&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;知情人士透露，虽然还没走完离职流程，但陈炜鹏目前已经在筹备创业，项目为 AI Coding 方向，并在陆续接触一些投资人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;百川的这两位联创变动或与公司 All in AI 医疗的战略调整有关。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339369</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339369</guid>
            <pubDate>Thu, 06 Mar 2025 06:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>华为余承东预热「想不到」新品：它确实是手机，又不止是手机</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;为常务董事、终端 BG 董事长、智能汽车解决方案 BU 董事长余承东今日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1100856704%2FPiVvlj04a%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;发布一条预热视频&lt;/a&gt;&lt;/u&gt;：&lt;strong&gt;「想不到」新品确实是手机，又不止是手机&lt;/strong&gt;，3 月 20 日揭晓答案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-145f75d4bd3807389c982517da61f8c9d79.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从视频中可以看到，余承东手持一款居中打孔的手机产品，但未能透露更多信息。此前官方宣称「1610 大开想象」，有网友猜测该数字在暗示新机的屏幕比例变为 16:10。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-27a5d1a209516e8e4542880996f440a648e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338389&quot; target=&quot;news&quot;&gt;余承东预告：首款原生鸿蒙正式版手机下周发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339367</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339367</guid>
            <pubDate>Thu, 06 Mar 2025 06:16:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>广东组建总规模 100 亿元的人工智能与机器人产业投资基金</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;恒健控股公司与中国工商银行广东省分行、工银金融资产投资有限公司 3 月 16 日签约，共同推动组建总规模 100 亿元的人工智能与机器人产业投资基金。该基金是在国家进一步扩大金融资产投资公司（AIC）股权投资试点后，由广东省金融系统和国资系统共同组建的首只广东省属 AIC 股权投资基金。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据合作协议，人工智能与机器人产业投资基金总规模 100 亿元，首期规模 20 亿元，将重点围绕省内外人工智能、机器人等科技创新和先进制造领域产业链进行投资布局，为相关项目提供行业上下游资源以及相关服务赋能，助力加快发展壮大新质生产力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;340&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67e9d0200a6951938b5f73473343a7992bb.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，该基金已储备拟投资项目 10 余个。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「接下来，基金将发挥签约三方作为耐心资本的优势，通过提供全生命周期的投贷联动服务，充分挖掘全国产业链链主项目、上下游优质项目和省级重点科技项目，重点投资人工智能与机器人产业链中的科技型、制造业核心企业，支持广东省人工智能及机器人产业链关键核心领域高质量发展，助力广东打造全球人工智能与机器人产业创新高地。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339365</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339365</guid>
            <pubDate>Thu, 06 Mar 2025 06:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>傅利叶开源全尺寸人形机器人数据集 Fourier ActionNet</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海机器人企业傅利叶&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FOUnrU8UTjlaBsvVUYFtyag&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;正式开源全尺寸人形机器人数据集 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faction-net.org%2F&quot; target=&quot;_blank&quot;&gt;Fourier ActionNet&lt;/a&gt;，并发布全球首个全流程工具链。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;首批上线超 3 万条高质量真机训练数据，包含多种自由度灵巧手的训练数据及专门针对手部任务的模仿学习数据，面向全球开发者及科研机构开源共享，提供从数据采集、训练、部署的一站式解决方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，Fourier ActionNet 数据集囊括傅利叶 GRx 系列所有机型的各类任务训练，完整记录机器人在真实环境中的任务执行数据，涵盖了对常用工具、家居用品、食物等多种物体的精确取放、倾倒等操作，以及在不同环境条件下实现泛化执行。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;多模态+高质量+万级体量：&lt;/strong&gt;万级真机训练数据，包含专门针对手部任务的模仿学习数据，适配多自由度灵巧手任务；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;356&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1a209cbc17be4d851c785485ac5d53783d3.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;VLM 标注+人工核验：&lt;/strong&gt;所有数据均采用视觉语言模型（VLM）进行自动标注，并通过人工二次核验，确保数据精度与准确性。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了数据集的开源以外，傅利叶同步开放了全球首个包含采集算法、训练算法以及数据部署算法的全流程工具链。开源的训练框架（如 DP、ACT、iDP3）和部署工具，进一步降低了人形机器人技术研发门槛。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;自带数据质量评估：&lt;/strong&gt;基于扩散策略（DP）、Transformer 动作分块策略（ACT）及改进 3D 扩散策略（iDP3）对数据集进行系统性验证，在 GRx 全系列机型中均可稳定执行开柜门、抓取柠檬、倾倒豆子等高难度任务；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;224&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e17b14af3900b54606079ee3bcdd1ae14ba.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;配套开发工具支持：&lt;/strong&gt;同步开源基于 LeRobot 生态的 DP、ACT、iDP3 等主流训练框架和部署框架，提供从数据管理到算法部署的全流程支持。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339341</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339341</guid>
            <pubDate>Thu, 06 Mar 2025 05:44:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>得物 Android Crash 治理实践</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、前言&lt;/h1&gt; 
&lt;p&gt;通过修复历史遗留的 Crash 漏报问题（包括端侧 SDK 采集的兼容性优化及 Crash 平台的数据消费机制完善），得物 Android 端的 Crash 监控体系得到显著增强，使得历史 Crash 数据的完整捕获能力得到系统性改善，相应 Crash 指标也有所上升，经过架构以及各团队的共同努力下，崩溃率已从最高的万 2 降至目前的万 1.1 到万 1.5，其中疑难问题占比约 90%、因系统 bug 导致的 Crash 占比约 40%，在本文中将简要介绍一些较典型的系统 Crash 的治理过程。&lt;/p&gt; 
&lt;h1&gt;二、DNS 解析崩溃&lt;/h1&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;Android11 及以下版本在 DNS 解析过程中的有几率产生野指针问题导致的 Native Crash，其中 Android9 占比最高。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;堆栈与上报趋势&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;at libcore.io.Linux.android_getaddrinfo(Linux.java)
at libcore.io.BlockGuardOs.android_getaddrinfo(BlockGuardOs.java:172)
at java.net.InetAddress.parseNumericAddressNoThrow(InetAddress.java:1631)
at java.net.Inet6AddressImpl.lookupAllHostAddr(Inet6AddressImpl.java:96)
at java.net.InetAddress.getAllByName(InetAddress.java:1154)

#00 pc 000000000003b938  /system/lib64/libc.so (android_detectaddrtype+1164)
#01 pc 000000000003b454  /system/lib64/libc.so (android_getaddrinfofornet+72)
#02 pc 000000000002b5f4  /system/lib64/libjavacore.so (_ZL25Linux_android_getaddrinfoP7_JNIEnvP8_jobjectP8_jstringS2_i+336)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//cace5743475094d99aeed5e0d4c7bb62.jpeg&quot; alt=&quot;上报趋势.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;问题分析&lt;/h2&gt; 
&lt;p&gt;崩溃入口方法 InetAddress.getAllByName 用于根据指定的主机名返回与之关联的所有 IP 地址，它会根据系统配置的名称服务进行解析，沿着调用链查看源码发现在 parseNumericAddressNoThrow 方法内部调用 Libcore.os.android_getaddrinfo 时中有 try catch 的容错逻辑，继续查看后续调用的 c++的源码，在调用 android_getaddrinfofornet 函数返回值不为 0 时抛出 GaiException 异常。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;https://cs.android.com/android/platform/superproject/+/android-9.0.0_r49:libcore/ojluni/src/main/java/java/net/InetAddress.java

static InetAddress parseNumericAddressNoThrow(String address) {
       // Accept IPv6 addresses (only) in square brackets for compatibility.
       if (address.startsWith(&quot;[&quot;) &amp;amp;&amp;amp; address.endsWith(&quot;]&quot;) &amp;amp;&amp;amp; address.indexOf(&#39;:&#39;) != -1) {
           address = address.substring(1, address.length() - 1);
       }
       StructAddrinfo hints = new StructAddrinfo();
       hints.ai_flags = AI_NUMERICHOST;
       InetAddress[] addresses = null;
       try {
           addresses = Libcore.os.android_getaddrinfo(address, hints, NETID_UNSET);
       } catch (GaiException ignored) {
       }
       return (addresses != null) ? addresses[0] : null;
   }
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;https://cs.android.com/android/platform/superproject/+/master:libcore/luni/src/main/native/libcore_io_Linux.cpp?q=Linux_android_getaddrinfo&amp;amp;ss=android%2Fplatform%2Fsuperproject

static jobjectArray Linux_android_getaddrinfo(JNIEnv* env, jobject, jstring javaNode,
        jobject javaHints, jint netId) {
    ......
    int rc = android_getaddrinfofornet(node.c_str(), NULL, &amp;amp;hints, netId, 0, &amp;amp;addressList);
    std::unique_ptr&amp;lt;addrinfo, addrinfo_deleter&amp;gt; addressListDeleter(addressList);
    if (rc != 0) {
        throwGaiException(env, &quot;android_getaddrinfo&quot;, rc);
        return NULL;
    }
    ......
    return result;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;解决过程&lt;/h2&gt; 
&lt;p&gt;解决思路是代理 android_getaddrinfofornet 函数，捕捉调用原函数过程中出现的段错误信号，接着吃掉这个信号并返回-1，使之转换为 JAVA 异常进而走进 parseNumericAddressNoThrow 方法的容错逻辑，和负责网络的同学提前做了沟通，确定此流程对业务没有影响后开始解决。&lt;/p&gt; 
&lt;p&gt;首先使用 inline-hook 代理了 android_getaddrinfofornet 函数，接着使用字节封装好的 native try catch 工具做吃掉段错误信号并返回-1 的，字节工具内部原理是在 try 块的开始使用 sigsetjmp 打个锚点并快照当前寄存器的值，然后设置信号量处理器并关联当前线程，在 catch 块中解绑线程与信号的关联并执行业务兜底代码，在捕捉到信号时通过 siglongjmp 函数长跳转到 catch 块中，感兴趣的同学可以用下面精简后的 demo 试试，以下代码保存为 mem_err.c，执行 gcc ./mem_err.c;./a.out&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;setjmp.h&amp;gt;

struct sigaction old;
static sigjmp_buf buf;

void SIGSEGV_handler(int sig, siginfo_t *info, void *ucontext) {
    printf(&quot;信号处理 sig: %d, code: %d\n&quot;, sig, info-&amp;gt;si_code);
    siglongjmp(buf, -1);
}

int main() {
    if (!sigsetjmp(buf, 0)) {
        struct sigaction sa;

        sa.sa_sigaction = SIGSEGV_handler;
        sigaction(SIGSEGV, &amp;amp;sa, &amp;amp;old);

        printf(&quot;try exec\n&quot;);
        //产生段错误
        int *ptr = NULL;
        *ptr = 1;
        printf(&quot;try-block end\n&quot;);//走不到
    } else {
        printf(&quot;catch exec\n&quot;);
        sigaction(SIGSEGV, &amp;amp;old, NULL);
    }
    printf(&quot;main func end\n&quot;);
    return 0;
}

//输出以下日志
//try exec
//信号处理 sig: 11, code: 2
//catch exec
//main func end
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;inline-hook 库: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2Fandroid-inline-hook&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/android-inline-hook&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;字节 native try catch 工具: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2Fandroid-inline-hook%2Fblob%2Fmain%2Fshadowhook%2Fsrc%2Fmain%2Fcpp%2Fcommon%2Fbytesig.c&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/android-inline-hook/blob/main/shadowhook/src/main/cpp/common/bytesig.c&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;三、MediaCodec 状态异常崩溃&lt;/h1&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;在 Android 11 系统库的音视频播放过程中，偶尔会出现因状态异常导致的 SIGABRT 崩溃。音视频团队反馈指出，这是 Android 11 的一个系统 bug。随后，我们协助音视频团队通过 hook 解决了这一问题。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;堆栈与上报趋势&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;#00 pc 0000000000089b1c  /apex/com.android.runtime/lib64/bionic/libc.so (abort+164)
#01 pc 000000000055ed78  /apex/com.android.art/lib64/libart.so (_ZN3art7Runtime5AbortEPKc+2308)
#02 pc 0000000000013978  /system/lib64/libbase.so (_ZZN7android4base10SetAborterEONSt3__18functionIFvPKcEEEEN3$_38__invokeES4_+76)
#03 pc 0000000000006e30  /system/lib64/liblog.so (__android_log_assert+336)
#04 pc 0000000000122074  /system/lib64/libstagefright.so (_ZN7android10MediaCodec37postPendingRepliesAndDeferredMessagesENSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERKNS_2spINS_8AMessageEEE+720)
#05 pc 00000000001215cc  /system/lib64/libstagefright.so (_ZN7android10MediaCodec37postPendingRepliesAndDeferredMessagesENSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEi+244)
#06 pc 000000000011c308  /system/lib64/libstagefright.so (_ZN7android10MediaCodec17onMessageReceivedERKNS_2spINS_8AMessageEEE+8752)
#07 pc 0000000000017814  /system/lib64/libstagefright_foundation.so (_ZN7android8AHandler14deliverMessageERKNS_2spINS_8AMessageEEE+84)
#08 pc 000000000001d9cc  /system/lib64/libstagefright_foundation.so (_ZN7android8AMessage7deliverEv+188)
#09 pc 0000000000018b48  /system/lib64/libstagefright_foundation.so (_ZN7android7ALooper4loopEv+572)
#10 pc 0000000000015598  /system/lib64/libutils.so (_ZN7android6Thread11_threadLoopEPv+460)
#11 pc 00000000000a1d6c  /system/lib64/libandroid_runtime.so (_ZN7android14AndroidRuntime15javaThreadShellEPv+144)
#12 pc 0000000000014d94  /system/lib64/libutils.so (_ZN13thread_data_t10trampolineEPKS_+412)
#13 pc 00000000000eba94  /apex/com.android.runtime/lib64/bionic/libc.so (_ZL15__pthread_startPv+64)
#14 pc 000000000008bd80  /apex/com.android.runtime/lib64/bionic/libc.so (__start_thread+64)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6005703c8fc9279c6cdaef63e6e46c30.jpeg&quot; alt=&quot;状态异常崩溃上报趋势.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;问题分析&lt;/h2&gt; 
&lt;p&gt;根据堆栈内容分析 Android11 的源码以及结合 SIGABRT 信号采集到的信息 (postPendingRepliesAndDeferredMessages: mReplyID == null, from kWhatRelease:STOPPING following kWhatError:STOPPING)，找到崩溃发生在 onMessageReceived 函数处理 kWhatRelease 类型消息的过程中，onMessageReceived 函数连续收到两条消息，第一条是 kWhatError:STOPPING，第二条是 kWhatRelease:STOPPING 此时因 mReplyID 已经被置为空，因此走到判空抛异常的逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.android.com%2Fandroid%2F_%2Fandroid%2Fplatform%2Fframeworks%2Fav%2F%2B%2Frefs%2Ftags%2Fandroid-11.0.0_r48%3Amedia%2Flibstagefright%2FMediaCodec.cpp%3Bl%3D2280%3Bdrc%3D789055bbcb4560b42faf19103b1cda5534e8f9cb%3Bbpv%3D0%3Bbpt%3D0&quot; target=&quot;_blank&quot;&gt;https://cs.android.com/android/_/android/platform/frameworks/av/+/refs/tags/android-11.0.0_r48:media/libstagefright/MediaCodec.cpp;l=2280;drc=789055bbcb4560b42faf19103b1cda5534e8f9cb;bpv=0;bpt=0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2e886281ace270773ec46a5dddcccff5.jpeg&quot; alt=&quot;问题分析 1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//384b879e4dd29cd1ebaa36ab92bbc4fb.jpeg&quot; alt=&quot;问题分析 2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b427bf5aad2f88d2301a5b30a09292c.jpeg&quot; alt=&quot;问题分析 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b5cf5aab8238a793cd8a1e8ed5fea76b.jpeg&quot; alt=&quot;问题分析 4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 对比 Android12 的源码，在处理 kWhatRelease 事件且状态为 STOPPING 抛异常前，增加了对 mReplyID 不为空的判断来规避这个问题。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.android.com%2Fandroid%2F_%2Fandroid%2Fplatform%2Fframeworks%2Fav%2F%2B%2Fca0c3286a4790a4de2d90cb275ae89a9601b805b%3Amedia%2Flibstagefright%2FMediaCodec.cpp%3Bdlc%3D7327aab894f6c456ea16c95b64134841da8d5737&quot; target=&quot;_blank&quot;&gt;https://cs.android.com/android/_/android/platform/frameworks/av/+/ca0c3286a4790a4de2d90cb275ae89a9601b805b:media/libstagefright/MediaCodec.cpp;dlc=7327aab894f6c456ea16c95b64134841da8d5737&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c877bb10835e29a63132081ad488047e.jpeg&quot; alt=&quot;规避这个问题.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;解决过程&lt;/h2&gt; 
&lt;p&gt;Android12 的修复方式意味着上述三个条件结合下吃掉异常是符合预期的，接下来就是想办法通过 hook Android11 使逻辑对齐 Android12。&lt;/p&gt; 
&lt;p&gt;【初探】最先想到的办法是代理相关函数通过判断走到这个场景时提前 return 出去来规避，音视频的同学尝试后发现不可行，原因如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;void MediaCodec::postPendingRepliesAndDeferredMessages(std::string origin, status_t err): 匹配 origin 是否为特征字符串 (postPendingRepliesAndDeferredMessages: mReplyID == null, from kWhatRelease:STOPPING following kWhatError:STOPPING)；很多设备找不到这个符号不可行；&lt;/li&gt; 
 &lt;li&gt;void MediaCodec::onMessageReceived(const sp&amp;amp;msg): 已知 MediaCodec 实例的内存首地址，需要通过 hardcode 偏移量来获取 mReplay、mState 两个字段，这里又缺少可供校验正确性的特征，风险略大担心有不同机型的兼容性问题 (不同机型新增、删除字段导致偏移量不准)。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;【踩坑】接着尝试使用与修复 DNS 崩溃类似思路的保护方案，使用 inline-hook 代理 onMessageReceived 函数调用原函数时使用 setjmp 打锚点，然后使用 plt hook 代理_android_log_assert 函数并在内部检测错误信息为特征字符串时通过 longjmp 跳转到 onMessageReceived 函数的锚点并作 return 操作，精简后的 demo 如下：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Plt-hook 库: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fiqiyi%2FxHook&quot; target=&quot;_blank&quot;&gt;https://github.com/iqiyi/xHook&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;setjmp.h&amp;gt;
#include &amp;lt;csignal&amp;gt;

static thread_local jmp_buf _buf;
void *origin_onMessageReceived = nullptr;
void *origin__android_log_assert = nullptr;

void _android_log_assert_proxy(const char* cond, const char *tag, const char* fmt, ...) {
    //模拟 liblog.so 的__android_log_assert 函数
    std::cout &amp;lt;&amp;lt; &quot;__android_log_assert start&quot; &amp;lt;&amp;lt; std::endl;
    if (!strncmp(fmt, &quot;postPendingRepliesAndDeferredMessages: mReplyID == null&quot;, 55)) {
        longjmp(_buf, -1);
    }
    //模拟调用 origin__android_log_assert，产生崩溃 
    raise(SIGABRT);
}

void onMessageReceived_proxy(void *thiz, void *msg) {
    std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy start&quot; &amp;lt;&amp;lt; std::endl;
    if (!setjmp(_buf)) {
        //模拟调用 onMessageReceived 原函数 (origin_onMessageReceived) 进入崩溃流程
        std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy 1&quot; &amp;lt;&amp;lt; std::endl;
        _android_log_assert_proxy(nullptr, nullptr, &quot;postPendingRepliesAndDeferredMessages: mReplyID == null, from kWhatRelease:STOPPING following kWhatError:STOPPING&quot;);
        std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy 2&quot; &amp;lt;&amp;lt; std::endl;//走不到
    } else {
        //保护后从此处返回
        std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy 3&quot; &amp;lt;&amp;lt; std::endl;
    }
    std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy end&quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    std::cout &amp;lt;&amp;lt; &quot;main func start&quot; &amp;lt;&amp;lt; std::endl;
    /**
     inline-hook: shadowhook_hook_sym_name(&quot;libstagefright.so&quot;,&quot;_ZN7android10MediaCodec17onMessageReceivedERKNS_2spINS_8AMessageEEE&quot;,(void *) onMessageReceived_proxy, (void **) &amp;amp;origin_onMessageReceived);
     plhook: xh_core_register(&quot;libstagefright.so&quot;, &quot;__android_log_assert&quot;, (void *) (_android_log_assert_proxy), (void **) (&amp;amp;origin__android_log_assert));
     */
    //模拟调用 libstagefright.so 的_ZN7android10MediaCodec17onMessageReceivedERKNS_2spINS_8AMessageEEE 函数
    onMessageReceived_proxy(nullptr, nullptr);
    std::cout &amp;lt;&amp;lt; &quot;main func end&quot; &amp;lt;&amp;lt; std::endl;
    return 0;
}

/**
日志输出
 main func start
onMessageReceived_proxy start
onMessageReceived_proxy 1
__android_log_assert start
onMessageReceived_proxy 3
onMessageReceived_proxy end
main func end
*/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;线下一阵操作猛如虎经测试保护逻辑符合预期，但是在灰度期间踩到栈溢出保护导致错误转移的坑，堆栈如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;#00 pc 000000000004e40c  /apex/com.android.runtime/lib64/bionic/libc.so (abort+164)
#01 pc 0000000000062730  /apex/com.android.runtime/lib64/bionic/libc.so (__stack_chk_fail+20)
#02 pc 000000000000a768 /data/app/~~JaQm4SU8wxP7T2GaSWxYkQ==/com.shizhuang.duapp-N5RFIB8WurdccMgAVsBang==/lib/arm64/libduhook.so (_ZN25CrashMediaCodecProtection5proxyEPvS0_)
#03 pc 0000000001091c0c  [anon:scudo:primary]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;*关于栈溢出保护机制感兴趣的同学可以参考这篇文章&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.kanxue.com%2Fthread-221762-1.htm&quot; target=&quot;_blank&quot;&gt;https://bbs.kanxue.com/thread-221762-1.htm&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;（CSPP 第 3 版 &quot;3.10.3 内存越界引用和缓冲区溢出&quot;章节讲的更详细）*&lt;/p&gt; 
&lt;p&gt;longjmp 函数只是恢复寄存器的值后从锚点处再次返回，过程中也唯一可能会操作栈祯只有 inline-hook，当时怀疑是与 setjmp/longjmp 机制不兼容，由于 inline-hook 内部逻辑大量使用汇编来实现排查起来比较困难，因此这个问题困扰比较久，网上的资料提到可以使用代理出错函数 (__stack_chk_fail) 或者编译 so 时增加参数不让编译器生成保护代码来绕过，这两种方式影响面都比较大所以未采用。有了前面的怀疑点想到使用 c++的 try catch 机制来做跨函数域的跳转，大致的思路同上只是把 setjmp 替换为 c++的 try catch，把 longjmp 替换为 throw exception，精简后的 demo 如下：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;c++异常机制介绍: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaiy.cn%2Fdoc%2Fcpp%2Finside_exception.htm&quot; target=&quot;_blank&quot;&gt;https://baiy.cn/doc/cpp/inside_exception.htm&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;csignal&amp;gt;

void *origin_onMessageReceived = nullptr;
void *origin__android_log_assert = nullptr;

class MyCustomException : public std::exception {
public:
    explicit MyCustomException(const std::string&amp;amp; message)
            : msg_(message) {}

    virtual const char* what() const noexcept override {
        return msg_.c_str();
    }

private:
    std::string msg_;
};

void _android_log_assert_proxy(const char* cond, const char *tag, const char* fmt, ...) {
    //模拟 liblog.so 的__android_log_assert 函数
    std::cout &amp;lt;&amp;lt; &quot;__android_log_assert start&quot; &amp;lt;&amp;lt; std::endl;
    if (!strncmp(fmt, &quot;postPendingRepliesAndDeferredMessages: mReplyID == null&quot;, 55)) {
        throw MyCustomException(&quot;postPendingRepliesAndDeferredMessages: mReplyID == null&quot;);
    }
    //模拟调用 origin__android_log_assert，产生崩溃
    raise(SIGABRT);
}

void onMessageReceived_proxy(void *thiz, void *msg) {
    std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy start&quot; &amp;lt;&amp;lt; std::endl;
    try {
        //模拟调用 onMessageReceived 原函数 (origin_onMessageReceived) 进入崩溃流程
        std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy 1&quot; &amp;lt;&amp;lt; std::endl;
        _android_log_assert_proxy(nullptr, nullptr, &quot;postPendingRepliesAndDeferredMessages: mReplyID == null, from kWhatRelease:STOPPING following kWhatError:STOPPING&quot;);
        std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy 2&quot; &amp;lt;&amp;lt; std::endl;//走不到
    } catch (const MyCustomException&amp;amp; e) {
        //保护后从此处返回
        std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy 3&quot; &amp;lt;&amp;lt; std::endl;
    }
    std::cout &amp;lt;&amp;lt; &quot;onMessageReceived_proxy end&quot; &amp;lt;&amp;lt; std::endl;
}

int main() {
    std::cout &amp;lt;&amp;lt; &quot;main func start&quot; &amp;lt;&amp;lt; std::endl;
    /**
     inline-hook: shadowhook_hook_sym_name(&quot;libstagefright.so&quot;,&quot;_ZN7android10MediaCodec17onMessageReceivedERKNS_2spINS_8AMessageEEE&quot;,(void *) onMessageReceived_proxy, (void **) &amp;amp;origin_onMessageReceived);
     plhook: xh_core_register(&quot;libstagefright.so&quot;, &quot;__android_log_assert&quot;, (void *) (_android_log_assert_proxy), (void **) (&amp;amp;origin__android_log_assert));
     */
    //模拟调用 libstagefright.so 的_ZN7android10MediaCodec17onMessageReceivedERKNS_2spINS_8AMessageEEE 函数
    onMessageReceived_proxy(nullptr, nullptr);
    std::cout &amp;lt;&amp;lt; &quot;main func end&quot; &amp;lt;&amp;lt; std::endl;
    return 0;
}

/**
日志输出
 main func start
onMessageReceived_proxy start
onMessageReceived_proxy 1
__android_log_assert start
onMessageReceived_proxy 3
onMessageReceived_proxy end
main func end
*/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;灰度上线后发现有设备走到了_android_log_assert 代理函数中的 throw 逻辑，但是未按预期走到 catch 块而是把错误又转移为&quot; terminating with uncaught exception of type&quot; ，有点搞心态啊。&lt;/p&gt; 
&lt;p&gt;【柳暗花明】C++的异常处理机制在 throw 执行时，会开始在调用栈中向上查找匹配的 catch 块，检查每一个函数直到找到一个具有合适类型的 catch 块，上述的错误信息代表未找到匹配的 catch 块。从转移的堆栈中注意到没有 onMessageReceived 代理函数的堆栈，此时基于 inline-hook 的原理 (修改原函数前面的汇编代码跳转到代理函数) 又怀疑到它身上，再次排查代码时发现代理函数开头漏写了一个宏，在 inline-hook 中 SHADOWHOOK_STACK_SCOPE 就是来管理栈祯的，因此出现找不到 catch 块以及前面 longjmp 的问题就不奇怪了。加上这个宏以后柳暗花明，重新放量后保护逻辑按预期执行并且保护生效后视频播放正常。和音视频的小伙伴一努力下，经历了几个版本终于解决了这个系统 bug，目前仅剩老版本 App 有零星的上报。&lt;/p&gt; 
&lt;h1&gt;四、bio 多线程环境崩溃&lt;/h1&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;Android 11 Socket close 过程中在多线程场景下有几率产生野指针问题导致 Native Crash，现象是多个线程同时 close 连接时，一个线程已销毁了 bio 的上下文，另外一个线程仍执行 close 并在此过程中尝试获取这个 bio 有多少未写出去的字节数时出现野指针导致的段错误。此问题从 21 年首次上报以来在得物的 Crash 列表中一直处于较前的位置。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;堆栈与上报趋势&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-Java&quot;&gt;at com.android.org.conscrypt.NativeCrypto.SSL_pending_written_bytes_in_BIO(Native method)
at com.android.org.conscrypt.NativeSsl$BioWrapper.getPendingWrittenBytes(NativeSsl.java:660)
at com.android.org.conscrypt.ConscryptEngine.pendingOutboundEncryptedBytes(ConscryptEngine.java:566)
at com.android.org.conscrypt.ConscryptEngineSocket.drainOutgoingQueue(ConscryptEngineSocket.java:584)
at com.android.org.conscrypt.ConscryptEngineSocket.close(ConscryptEngineSocket.java:480)
at okhttp3.internal.Util.closeQuietly_aroundBody0(Util.java:1)
at okhttp3.internal.Util$AjcClosure1.run(Util.java:1)
at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:3)
at com.shizhuang.duapp.common.aspect.ThirdSdkAspect.t(ThirdSdkAspect.java:1)
at okhttp3.internal.Util.closeQuietly(Util.java:3)
at okhttp3.internal.connection.ExchangeFinder.findConnection(ExchangeFinder.java:42)
at okhttp3.internal.connection.ExchangeFinder.findHealthyConnection(ExchangeFinder.java:1)
at okhttp3.internal.connection.ExchangeFinder.find(ExchangeFinder.java:6)
at okhttp3.internal.connection.Transmitter.newExchange(Transmitter.java:5)
at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:5)

#00 pc 0000000000064060  /system/lib64/libcrypto.so (bio_ctrl+144)
#01 pc 00000000000615d8  /system/lib64/libcrypto.so (BIO_ctrl_pending+40)
#02 pc 00000000000387dc  /apex/com.android.conscrypt/lib64/libjavacrypto.so (_ZL45NativeCrypto_SSL_pending_written_bytes_in_BIOP7_JNIEnvP7_jclassl+20)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//762b069e36bfdf6a16969929dc4820ab.jpeg&quot; alt=&quot;bio 多线程.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;问题分析&lt;/h2&gt; 
&lt;p&gt;从设备分布上看，出问题都全是 Android 11 且各个国内厂商的设备都有，怀疑是 Android 11 引入的 bug，对比了 Android 11 和 Android 12 的源码，发现在 Android12 崩溃堆栈中的相关类 com.android.org.conscrypt.NativeSsl$BioWrapper 有四个方法增加了读写锁，此时怀疑是多线程问题，通过搜索 Android 源码的相关 issue 以及差异代码的 MR 描述信息，进一步确认此结论。通过源码进一步分析发现 NativeSsl 的所有加锁的方法，会分发到 NativeCrypto.java 中的 native 方法，最终调用到 native_crypto.cc 中的 JNI 函数，如果能 hook 到相关的 native 函数并在 Native 层实现与 Android12 相同的读写锁逻辑，这个问题就可以解决了。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.android.com%2Fandroid%2Fplatform%2Fsuperproject%2F%2B%2Fandroid-12.0.0_r1%3Aexternal%2Fconscrypt%2Frepackaged%2Fcommon%2Fsrc%2Fmain%2Fjava%2Fcom%2Fandroid%2Forg%2Fconscrypt%2FNativeSsl.java&quot; target=&quot;_blank&quot;&gt;https://cs.android.com/android/platform/superproject/+/android-12.0.0_r1:external/conscrypt/repackaged/common/src/main/java/com/android/org/conscrypt/NativeSsl.java&lt;/a&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.android.com%2Fandroid%2Fplatform%2Fsuperproject%2F%2B%2Fandroid-11.0.0_r48%3Aexternal%2Fconscrypt%2Frepackaged%2Fcommon%2Fsrc%2Fmain%2Fjava%2Fcom%2Fandroid%2Forg%2Fconscrypt%2FNativeCrypto.java&quot; target=&quot;_blank&quot;&gt;https://cs.android.com/android/platform/superproject/+/android-11.0.0_r48:external/conscrypt/repackaged/common/src/main/java/com/android/org/conscrypt/NativeCrypto.java&lt;/a&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.android.com%2Fandroid%2Fplatform%2Fsuperproject%2F%2B%2Fandroid-11.0.0_r48%3Aexternal%2Fconscrypt%2Fcommon%2Fsrc%2Fjni%2Fmain%2Fcpp%2Fconscrypt%2Fnative_crypto.cc&quot; target=&quot;_blank&quot;&gt;https://cs.android.com/android/platform/superproject/+/android-11.0.0_r48:external/conscrypt/common/src/jni/main/cpp/conscrypt/native_crypto.cc&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;解决过程&lt;/h2&gt; 
&lt;p&gt;通过 JNI hook 代理 Android12 中增加锁的相关函数，当走到代理函数中时，先分发到 JAVA 层通过反射获取 ReadWriteLock 实例并上锁再通过跳板函数调用原来的 JNI 函数，此时就完成了对 Android12 增量锁逻辑的复刻。经历了两个版本的灰度 hook 方案已稳定在线上运行，期间无因 hook 导致的网络不可用和其它崩溃问题，目前开关放全量的版本崩溃设备数已降为 0。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1d7fbf50827b984c3a640932e1cc29f8.jpeg&quot; alt=&quot;解决过程.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;JNI hook 原理，以及详细修复过程: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.dewu-inc.com%2Farticle%2FMTMwNDU%3FfromType%3Dpersonal_blog&quot; target=&quot;_blank&quot;&gt;https://blog.dewu-inc.com/article/MTMwNDU?fromType=personal_blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;五、小米 Android15 焦点处理空指针崩溃&lt;/h1&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;随着 Android15 开放公测，焦点处理过程中发生的空指针问题逐步增多，并在 1 月份上升到 Top。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;堆栈与上报趋势&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;java.lang.NullPointerException: Attempt to invoke virtual method &#39;android.view.ViewGroup$LayoutParams android.view.View.getLayoutParams()&#39; on a null object reference
at android.view.ViewRootImpl.handleWindowFocusChanged(ViewRootImpl.java:5307)
at android.view.ViewRootImpl.-$$Nest$mhandleWindowFocusChanged(Unknown Source:0)
at android.view.ViewRootImpl$ViewRootHandler.handleMessageImpl(ViewRootImpl.java:7715)
at android.view.ViewRootImpl$ViewRootHandler.handleMessage(ViewRootImpl.java:7611)
at android.os.Handler.dispatchMessage(Handler.java:107)
at android.os.Looper.loopOnce(Looper.java:249)
at android.os.Looper.loop(Looper.java:337)
at android.app.ActivityThread.main(ActivityThread.java:9568)
at java.lang.reflect.Method.invoke(Native Method)
at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:593)
at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:935)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;问题分析&lt;/h2&gt; 
&lt;p&gt;通过分析 ASOP 的源码，崩溃的触发点是 mView 字段为空。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.android.com%2Fandroid%2Fplatform%2Fsuperproject%2Fmain%2F%2B%2Fmain%3Aframeworks%2Fbase%2Fcore%2Fjava%2Fandroid%2Fview%2FViewRootImpl.java%3Bdrc%3D98e96368cc73432efbacd6fbcf61fe789dcec0ee%3Bl%3D7243%3Fq%3DViewRootImpl&quot; target=&quot;_blank&quot;&gt;https://cs.android.com/android/platform/superproject/main/+/main:frameworks/base/core/java/android/view/ViewRootImpl.java;drc=98e96368cc73432efbacd6fbcf61fe789dcec0ee;l=7243?q=ViewRootImpl&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6ef92423ea54dacac32d11f199709f51.jpeg&quot; alt=&quot;问题分析 5.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 源码中 mView 为空的情况有两种：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;未调用 setView 方法前触发窗口焦点变化事件（只有 setView 方法才会给 mView 赋不为空的值）。&lt;/li&gt; 
 &lt;li&gt;先正常调用 setView 使 mView 不为空，其它地方置为空。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合前置判断了 mAdded 为 true 才会走到崩溃点，在源码中寻找到只有先正常调用 setView 以后在调用 dispatchDetachedFromWindow 时才满足 mAdded=true、mView=null 的条件，从采集的 logcat 日志中可以证明这一点，此时基本可以定位根因是窗口销毁与焦点事件处理的时序问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//05361c2af0c5fdaacfe67f2ce9943873.jpeg&quot; alt=&quot;时序问题.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//07d6ba4611ff6ac317c0dd892538a158.jpeg&quot; alt=&quot;时序问题 2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;解决过程&lt;/h2&gt; 
&lt;p&gt;在问题初期，尝试通过 Hook 拦截 handleWindowFocusChanged 方法增加防御：当检测到 mView 为空时直接中断后续逻辑执行。本地验证阶段，通过在 Android 15 设备上高频触发商详页 Dialog 弹窗的焦点获取与关闭操作，未复现线上崩溃问题。考虑到 Hook 方案的侵入性风险 ，且无法本地测试，最终放弃此方案上线。&lt;/p&gt; 
&lt;p&gt;通过崩溃日志分析发现，问题设备 100% 集中在小米/红米机型，而该品牌在 Android 15 DAU 中仅占 36% ，因此怀疑是 MIUI 对 Android15 某些定制功能有 bug。经与小米技术团队数周的沟通与联合排查，最终小米在 v2.0.28 版本修复了此问题，需要用户升级 ROM 解决，目前&amp;gt;=2.0.28 的 MIUI 设备无此问题的上报。&lt;/p&gt; 
&lt;h1&gt;六、总结&lt;/h1&gt; 
&lt;p&gt;通过上述问题的治理，系统 bug 类的崩溃显著减少，希望这些经验对大家有所帮助。&lt;/p&gt; 
&lt;p&gt;文 / 亚鹏&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/17893964</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/17893964</guid>
            <pubDate>Thu, 06 Mar 2025 03:57:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>腾讯应用宝专区全量上线微软应用商店</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;腾讯应用宝刚刚&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC38ZfBMSqw8irkXtwlqFGQ&quot; target=&quot;_blank&quot;&gt;发布公告&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;3 月 17 日，&lt;strong&gt;微软应用商店腾讯应用宝专区（Tencent MyApp Hub）在 Windows 端全面上线&lt;/strong&gt;，中国区系统在 Windows 10 version 1903 build 18362 以上版本的电脑用户，可以在桌面任务栏或开始菜单中打开微软应用商店（版本需为 22502.1401.4.0 或更高），通过腾讯应用宝专区下载安装热门移动应用，安装完成的移动应用会在桌面生成快捷方式，双击即可打开使用。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;608&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0317/114340_PJlu_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;腾讯应用宝专区的上线不仅为用户在 PC 场景提供了更加便捷的移动应用使用体验，同时也为应用开发者开辟了全新的市场增长机遇。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据介绍，此次腾讯应用宝与微软应用商店的合作，是微软在国内首次给第三方开放系统级的入口和资源组件，颠覆了原来下载需要历经：安装下载器 - 安装市场 - 安装 apk- 打开应用的过程，缩短了转化链路，为移动应用开发者提供了全新的 PC 端分发渠道。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0317/114453_IUAc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;深度适配的应用和游戏不仅可以在微软应用商店腾讯应用宝专区下载安装，还能通过 Windows 搜索栏以及开始菜单中的推荐栏等多渠道进行推广，助力开发者大幅提升曝光率与用户增长。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;720&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0317/114536_f0hO_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在技术层面，针对移动应用开发者，腾讯应用宝为其提供了适配指导文档、开发工具链与专属的技术对接团队，通过腾讯应用宝内置的跨端引擎技术，开发者能够将手机应用的 ARM 指令实时翻译为 PC 端的 X86 指令，无需重新打包应用即可在 PC 上流畅运行，大幅降低了中小开发者的适配门槛，不仅为开发者节省了大量的时间和资源投入，也让他们能够更加专注于核心产品的创新与优化。&lt;/p&gt; 
&lt;p&gt;基于微软应用商店腾讯应用宝专区与移动应用进行的深度适配，用户在 PC 上可以享受与移动端一致的原生体验，同时借助 PC 硬件优势（如键鼠操作、大屏幕显示等）获得更高效的操作体验。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;阅读更多：&lt;a href=&quot;https://www.oschina.net/news/294797&quot; target=&quot;news&quot;&gt;腾讯应用宝与 Microsoft Store 达成合作，Windows 可直接运行移动应用&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339214</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339214</guid>
            <pubDate>Thu, 06 Mar 2025 03:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>在 DeepSeek 带飞 AI Infra 的前夜</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;AI Infra&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;再次起飞的前夜，回顾从大数据到大模型，Data &amp;amp; AI Infra 的演进之路 1.0-&amp;gt; 2.0 -&amp;gt; 3.0&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;img alt=&quot;&quot; height=&quot;768&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bbc5bb93a3c4f256dd3b4639c284c7d4093.jpg&quot; width=&quot;1024&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;（题图由即梦 AI 生成）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;引子：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最近，笔者参加一场现场直播，直播题目是《AI Infra 起飞前夜：开源、免费的模型有了，如何实现算力自由》，跟业内专家一起聊 AI Infra 的相关议题。我在直播访谈中，梳理了 Data Infra 和 AI Infra 的几个发展阶段。之后，在杭州参加开放原子基金会 TOC 的讨论，跟朋友们交流了 DeepSeek 等大模型对 Data Infra 和 AI Infra 对影响，以及我们如何进行前瞻性的研发和应对，那次讨论很热烈，也让我受益匪浅。之后，我又搜集了一些相关资料，有了更深的理解和感悟。作为曾经参与创建中国互联网行业第一个 Inf 部门（百度基础架构部），之后又在国内推动以实时特征计算、「Data-Centric AI vs Model-Centric AI」&lt;/span&gt; （&lt;span&gt;Data-Centric AI &lt;/span&gt;&lt;span&gt;强调以高质量的数据驱动 AI 模型优化，而 Model-Centric AI 则侧重于模型结构和算法的创新）为主要特点的的 AI Inf 1.0 的建设和采纳，现在预感到 DeepSeek 的出现将大大普及 AI 大模型的应用，从而推动 AI Infra 的再次起飞。值此 AI Infra 再次起飞的前夜，我写下此文。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;前言：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;数据是新时代的石油」，这句话深刻揭示了数据在数字经济中的核心地位。Data Infra（数据基础设施）与 AI Infra（人工智能基础设施）正是承载这份宝贵「石油」的管道和炼油厂，它们的发展历程不仅是技术浪潮的缩影，更预示着未来智能世界的图景。本文将追溯 Data &amp;amp; AI Infra 走过的三个关键阶段，剖析其核心特征、关键技术及应用场景，并着重关注中国在这场科技变革中的崛起，最终展望未来的发展趋势。Data &amp;amp; AI Infra 的每一次迭代，都源于对更高效数据处理和更强大智能应用的不断追求，二者相辅相成，共同驱动着数字经济的蓬勃发展。。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;大数据时代的起源（2003-2012）：奠定数据处理的基石，我称之为 Data Infra 1.0 时代。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2003&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年起到 2006 年，Google 发表了 GFS（Google File System）、MapReduce 和 Bigtable 三篇堪称划时代的论文，标志着大数据时代的开始。其中 2003 年 10 月发表的 GFS 论文，详细介绍了 Google 内部是如何采用大批廉价硬件，通过数据冗余和错误检测机制，实现了大规模的数据存储，满足了 Google 把全世界的网页进行索引建库的需求，更是被认为是 Data Infra 的开山之作。可惜 Google 只公开了论文，并没有开源相关项目。而从 2006 年起，Doug Cutting 等开创的 Apache Hadoop 项目作为这些思想的开源实现，迅速成为业内分布式大规模数据存储和计算的事实标准。这一时期的主要业务是离线批处理，其主要目标是解决海量数据的存储和分析难题，为后续的更多数据应用奠定基础。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;360&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2e8ab4919a1b2cb3fb2ae33f9b067e0b037.png&quot; width=&quot;1200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;核心技术：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Hadoop &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;生态系统：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 其中，HDFS（Hadoop Distributed File System）创新性地解决了海量数据的分布式存储问题，MapReduce（分布式计算框架）实现了对大规模数据的并行处理，而 Hive 和 Pig 则在上层提供了更高级的数据查询和分析能力，降低了大数据处理的门槛。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;NoSQL &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;数据库的兴起：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 随着数据类型的日益丰富，以 MongoDB 和 Cassandra 为代表的 NoSQL 数据库开始涌现，为非结构化数据的存储和管理提供了新的选择。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;AWS S3&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 亚马逊推出的简单存储服务（Simple Storage Service）凭借其高可用性、可扩展性和低成本，迅速成为云存储的行业标杆，也为后续的云计算发展奠定了基础。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;主要应用场景：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;日志分析：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 那时候，互联网公司率先利用 Hadoop 来进行离线分析用户行为日志，提供给产品经理，以方便他们更深入地理解用户偏好，从而优化产品和服务。例如，搜索引擎通过分析搜索日志改进搜索算法，电商平台则开始探索基于用户浏览行为的初步个性化推荐。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;数据挖掘：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 企业开始尝试通过对历史数据的分析，发现潜在的商业机会，例如通过分析销售数据预测未来趋势。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;商业智能（BI）：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 传统 BI 系统开始与大数据技术融合，为企业提供更全面的决策支持，提升运营效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;关键数据：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根据 IDC 的报告，全球数据总量从 2010 年的 1.2ZB 增长到 2013 年的 4.4ZB，年复合增长率超过 50%。这一惊人的增长速度充分印证了大数据时代的来临，也驱动了对更强大数据处理能力的需求。Hadoop 生态系统在这个时期迅速壮大，并在全球各大互联网公司得到广泛应用，成为 Data Infra 1.0 时代的基石。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;代表技术公司&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以 Hadoop 开源技术为基础的 Hortonworks 和 Cloudera，后来这两家合并为 Cloudera。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;MongoDB&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;公司开源文档数据库，并推动了「NoSQL」概念的流行。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;中国的发展：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国互联网企业也敏锐地捕捉到了这一趋势。百度从 2008 年开始研究 Hadoop 开源技术，并在其系统部内搭建相当规模的 Hadoop 集群，2010 年整合多个部门相关技术人员，成立了基础架构部，集中搭建并提供 HDFS 集群服务，之后还仿照 Hadoop 的实现，重新用 C++实现并上线了多套分布式文件系统，例如 CCDB-NFS、AFS 等分布式文件系统。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阿里巴巴、腾讯等公司也纷纷仿照，建立了自己的 Hadoop 集群，还自研分布式文件系统例如 TFS（Taobao File System）等，用于处理日益增长的海量数据，支撑其核心业务发展。与此同时，中国的开源社区也开始活跃起来，涌现出一批优秀的 Hadoop 开发者和贡献者，例如 HBase 的 pmc 主席张铎等，为中国大数据技术的发展注入了活力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;br&gt; 我认为这是 Data Infra 的 1.0 时代，很多技术和标准时至今日仍然是主流，例如 HDFS 的接口标准，S3 的接口标准等，几乎后来的每个 Data Infra 或者 AI Infra 的实践者都支持 HDFS 和 S3 的接口标准等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;2. AI 1.0 &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;发展期（2012-2023）：实时智能化的演进，Data Infra 的 2.0 时代&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2012&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年 AlexNet 在 ImageNet 图像识别大赛中一举夺魁，优势相当显著，成绩断崖式领先，它证明了深度学习算法的有效性，从此工业界开始进入了 AI 1.0 时代。这一时期的特点是 AI 1.0 即判别式 AI，主要包含图像识别、文字识别、语言识别等多个识别性任务，以及用于搜索、广告、推荐、金融风控场景下的多种判定性任务。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互联网大厂的「搜索/广告/推荐」场景，俗称「搜广推」，例如百度、阿里、字节等的广告推荐、购物推荐、短视频推荐等，都是商业价值极高的场景，推荐的准确性和召回率可以直接影响这些企业的营收，推荐效果上每提升一个百分比，都意味着巨大的收益。这些企业都花了大量的人力和机器资源进行长期投入，所以每个公司都有相应的团队，包括负责算法和策略的科学家团队，以及负责工程和数据的 Infra 团队。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在技术上，数据的高质量实时供给是算法和策略保证 AI 最终效果高性能的核心，同时也是良好用户体验和优秀商业闭环的关键。所以，对大规模数据处理的速度和实时性提出了更高的要求，传统的 MapReduce 离线处理方式已经无法满足在线应用的需求，Spark、Flink 等更高效的批/流计算技术应运而生，数据湖架构也逐渐成熟，为构建更加灵活和智能的数据平台提供了基础。这一时期的核心技术特征是实时计算，数据分析从过去的「事后分析」走向「实时洞察」，推荐系统也从离线训练走向离在线结合的阶段，例如某些互联网大厂的在线推荐场景，采用每天一次全量线下训练，每 15 分钟一次增量训练的方式，以提高推荐的准确率和召回率。同时，对在线推理的性能要求也非常高，部分人工智能场景的推理请求需要在 100ms 甚至 10ms 级别的时间内返回，才能保证用户体验和满足业务的实时性要求（例如金融的实时风控场景）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2021&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年，著名 AI 科学家和企业家吴恩达提出了「Data-Centric AI」，他认为「Model-Centric AI」即算法已经达到了瓶颈，相反数据更重要。他是针对图像识别的实际场景有感而发的，他通过他创办的 landing.ai 公司进行 AI 商业落地的实践发现这一点的。不过他也没想到随后几年大模型在算法上的进步如此之快，彻底改变了 AI 的整个产业。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这个时候，我认为是 Data Infra 的 2.0 时期，也是 AI Infra 的 1.0 时期。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;443&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f98b85df4a828e4a13ae8888a1f4924837.jpg&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;（Apache Flink 的 logo，它是最流行的流式计算框架）&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;677&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0f19562c2077a287b7d44561ada32492f05.jpg&quot; width=&quot;1197&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;（吴恩达关于 Data-Centric AI 的一次演讲的材料总结）&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;核心技术：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Spark &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;和 Flink：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 这两种分布式计算框架提供了远超 MapReduce 的高效实时计算和流处理能力，能够以毫秒级的延迟处理数据，满足了在线推荐、实时监控等场景的需求。Spark 还在数据批处理、流处理、机器学习和图计算等方面提供了统一的平台。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Kafka&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 作为一款高吞吐量、低延迟的分布式流处理平台，Kafka 实现了海量数据的实时传输和订阅，成为构建实时数据管道的关键组件。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;GPU &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;加速：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 图形处理器（GPU）凭借其强大的并行计算能力，在加速深度学习模型的训练和推理方面发挥了关键作用，极大地推动了人工智能的应用普及。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;TensorFlow &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;、PyTorch、&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot;&gt;PaddlePaddle&lt;/a&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 这几大深度学习框架凭借其灵活性、易用性和强大的社区支持，迅速成为主流的深度学习平台，极大地降低了开发和部署人工智能应用的门槛。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;数据湖技术：Databricks Delta Lake 和 Apache Iceberg&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;&lt;span&gt;等数据湖技术的出现，通过引入事务性、模式演进等特性，显著提高了数据湖的数据质量和数据管理能力，使得数据湖能够更好地支持复杂的分析和机器学习工作负载。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;特征平台 Tecton 等：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 特征工程在机器学习中至关重要，而 Tecton 等特征平台的兴起，通过提供统一的特征定义、存储和管理能力，极大地提高了机器学习的效率和可重复性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;业务形态：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;实时推荐：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 电商平台和内容平台（如 Netflix、抖音）开始利用实时数据分析用户行为，进行个性化商品或内容推荐，显著提升了用户体验和转化率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在线广告：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 广告平台利用实时竞价技术，根据用户的实时行为和上下文信息进行精准广告投放，提高了广告效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;金融风控：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 银行和金融机构利用实时数据流监测交易风险，识别和防止欺诈行为，保障了金融安全。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;图像识别和语音识别的普及：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 深度学习技术在图像识别（如人脸识别支付、智能安防）和语音识别（如智能语音助手、语音输入）等领域取得了突破性进展，开始融入人们的日常生活。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;关键数据：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根据 Gartner 的统计，到 2020 年，全球人工智能市场规模达到了 215 亿美元。同时，主流深度学习框架如 TensorFlow 和 PyTorch、&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot;&gt;PaddlePaddle&lt;/a&gt; 的用户数量和应用案例呈现指数级增长，标志着人工智能技术进入快速发展期。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;代表技术公司&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Databricks&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：由 Apache Spark 的创建者建立，提供了基于云的数据分析平台，堪称这一时代的王者。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Tecton&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：由 Uber 机器学习平台的团队建立的创业公司，主打 Feature Store 产品，主要特性是机器学习所需要的特征的高质量实时供给。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;中国的发展：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国在 AI Infra 1.0 或者 Data Infra 2.0 时期，相对在 Data Infra 1.0 时期是完全跟随并且跟国际一流水平差距在 5 年左右不一样的是，中国大幅度缩短了跟世界一流水平的差距，在局部领域取得了相当令人瞩目的进展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这里仍然要先提一下百度，百度是业内第一个把深度学习用于商业广告系统并实现了巨大商业利益的公司，也是国内外第一个组建深度学习 Lab 的公司。百度从 2011 年起，在百度凤巢架构师戴文渊、陈雨强等的带领下，把百度商业广告系统的底层算法彻底重写，换成深度学习算法，显著的提升了百度搜索广告系统的效果，比 Google 大规模采用深度学习来重构谷歌广告系统还要早一些。为此，百度凤巢的工程团队以及基础架构部，一起为这些科学家们提供了高质量的数据平台、AI 训练和推理平台，来支撑了这一改变。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阿里巴巴、腾讯等互联网巨头纷纷也加大在人工智能领域的研发投入，并在语音识别、图像识别、自然语言处理等领域取得了很好的地位。同时，中国的人工智能创业公司也如雨后春笋般涌现，涌现出了一批在特定行业具有创新优势的企业，比如有「CV 4 小龙」之称的商汤、旷视、云从、依图等，在机器学习平台卓有建树的第四范式公司（创始人正是从百度出去的戴文渊和陈雨强）等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：这段时间我认为是 Data Infra 的 2.0 时期，或者称之为 AI Infra 的 1.0 时期，技术特点是大规模数据实时计算以及 Data-Centric AI 的理念兴起，支撑 AI 1.0 时期的判别式 AI 场景应用。但是比较遗憾的是，因为在此阶段 AI 1.0 的场景应用不多，「搜广推」虽然价值很高，但是能有这么大流量的公司并不多，而需求决定供给，造成 AI Infra 仅仅在小范围内局部流行。虽然也出现了一些大企业例如 Databricks，但是总体来说没有达到相关业内从业者的期望值。所以我认为，这个时期是 AI Infra 想起飞却没有飞起来的时期。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;3. AI 2.0 &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;爆发期（2023 至今）：大模型时代的挑战与机遇，即 Data Infra 3.0 时期，也是 AI Infra 2.0 时期&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2023&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年以来，以 ChatGPT 为代表的大模型和对话式应用的涌现，将人工智能的发展推向了前所未有的高度，我们称之为 AI 2.0 时代，即生成式 AI 时代。在这个阶段，这些大模型的参数规模呈指数级增长，展现出惊人的通用能力，但也对底层的算力、数据和算法提出了空前严峻的挑战。这一时期的核心特征是语言大模型和多模态大模型的训练和推理，以及构建在这些大模型之上的应用，包括 MaaS（Model as a Service）以及各种 AIGC 应用（例如文生图、文生视频等）。按照陆奇博士的说法，一个产业爆发的时刻就是边际成本变为固定的时刻。通用大模型的泛化能力可以解决很多场景的问题，尤其是开源大模型的能力提升到一个商业可用的级别，业内进一步降低了使用大模型的成本，人工智能正加速从特定任务走向通用智能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;759&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c02b5d8abd2604ce6688036da49c3315515.png&quot; width=&quot;1340&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;br&gt; （图片为 transformer 架构图）&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此阶段的 AI Infra 主流形式是 AI Infra 平台，主要功能包括三大能力：算力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;管理、模型管理、应用管理，其中算力管理主要提供计算、存储、网络、安全等基础资源服务，模型管理则提供模型开发和应用的各种基础工具和组建，例如数据治理、模型训练、精调、部署、推理等，应用管理则主要负责资源管理、运营管理和运维管理等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;核心技术：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Transformer &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;架构：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 这种基于自注意力机制的网络架构成为构建大模型的主流选择，极大地提升了模型处理长序列数据的能力，尤其在自然语言处理领域取得了革命性的突破。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;大规模分布式训练：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 为了训练拥有数千亿甚至万亿参数的大模型，需要借助大规模分布式计算集群，并采用模型并行、数据并行、流水线并行等先进的训练技术。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;向量数据库和知识图谱：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 向量数据库能够高效地存储和检索高维向量数据，为大模型提供快速的语义检索能力。知识图谱则能够为大模型提供结构化的知识，提升其理解和推理能力，更好地支持大模型在问答、搜索等领域的应用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;新型 AI 芯片：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 针对大模型训练和推理的需求，NVIDIA 推出了 A100、H100 等高性能 AI 芯片，而国内的华为、沐曦等公司也在积极研发自主可控的 AI 芯片，以满足日益增长的算力需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;业务形态：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;自然语言处理：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 语言大模型在文本生成、机器翻译、智能问答、文本摘要、情感分析等 NLP 任务上取得了前所未有的进展，使得机器能够更好地理解和生成人类语言。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;智能对话能力的提升：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 聊天机器人变得更加智能和人性化，能够进行更自然的对话，应用于智能客服、虚拟助手等场景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;通用内容生成：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 大模型不仅能生成高质量的文本，还能生成图像、音频和视频等多种模态的内容，催生了 AIGC（AI-Generated Content）的新业态。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;跨模态 AI 和 AI Agent 的探索：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 人工智能开始向处理多种模态数据（如文本、图像、音频、视频等）以及自主完成复杂任务的智能代理（AI Agent）方向发展，预示着更智能化的未来。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;商业形态：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/strong&gt;&lt;span&gt;&lt;span&gt;跟 AI Infra 1.0 时期不一样的是，那个时期因为应用场景少，绝大多数从业者集中在科技大厂的内部，负责一些高价值的「搜广推」业务和智慧安防等业务，而在 AI Infra2.0 时期，云服务厂商逐渐成为了主流，出现了大量公有云、私有云的 AI 平台服务，尤其是 Maas（Model as a service），在云上提供模型的 API 服务，以 token 的方式进行计价的厂家。据 DeepSeek 在 2025 年 3 月 1 日的报告披露，在云上提供收费的模型 API 服务，理论上成本利润率可以达到 545% 之高。此外，通过提供软硬一体的 AI 一体机服务，内置 AI 大模型和 AI Infra 软件平台以及相关 CPU/GPU 硬件，可以大大缩短大模型服务交付时间，同时也满足甲方客户对于数据隐私，控制信息泄露的需求，近几个月来是一个猛然爆发的市场。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;关键数据：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的 GPT-3 模型参数量达到了 1750 亿，而最新的 GPT-4 模型参数量据估计已经超过万亿。DeepSeek V3 的模型参数量是 6710 亿。大模型在各个领域的应用案例不断涌现，例如在代码生成、药物发现、教育辅导等领域都展现出巨大的潜力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;中国的发展：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国在大模型领域也迅速崛起，百度发布了「文心一言」、阿里巴巴推出了「通义千问」、腾讯推出了混元大模型等一系列具有影响力的中文大模型。特别值得一提的是，中国杭州 DeepSeek 公司推出的 DeepSeek R1 和 V3 模型，以低成本、高性能、开源的特性，赢得了国内外产业的一致认同。同时，中国的 AI 芯片公司也在努力突破技术瓶颈，希望在大模型时代占据一席之地。中国政府也加大了对人工智能基础设施的投入，例如建设国家级的算力中心，以更好地支持大模型的研究和应用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;据赛迪顾问发布的《2025 中国 AI Infra 平台市场发展研究报告》指出，2023 年，中国 AI Infra 平台市场规模为 12.7 亿元。在企业级 AI 应用场景持续拓展、AI 应用私有化部署需求强劲、AI 运营能力要求提升等因素的驱动下，中国 AI Infra 平台市场规模将保持高速增长，预计 2024 年、2025 年将分别达到 19.4 亿元和 36.1 亿元，2025 年同比增长将超过 86%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;新的技术趋势：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;（1）Data Infra &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;和 AI Infra 的深度融合，以适应大模型时代的需求&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Data Infra &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;和 AI Infra 将不再是彼此独立的系统，而是走向更深度的融合，以满足大模型时代对数据处理和智能应用提出的极致需求。这种融合体现在多个层面：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先，&lt;strong&gt;存储系统的升级换代将直接服务于 AI 工作负载&lt;/strong&gt;。传统的数据存储方案无法高效地支持大模型训练和推理过程中的海量数据吞吐和低延迟访问需求。以近期备受关注的 &lt;strong&gt;DeepSeek &lt;/strong&gt;开源周上发布的&lt;strong&gt; 3FS（Fire-Flyer File System）&lt;/strong&gt; 为例，这正是面向，大规模 AI 训练和推理场景设计的高性能分布式文件系统。3FS 专注于充分发掘和利用现代 SSD 存储和，现代 RDMA 网络的能力，实现了惊人的聚合读取吞吐量（例如，在拥有 180 个节点的集群下达到了 6.6 TiB/s）。这种专为 AI 设计的文件系统，能够像 AI 时代的「数据高速公路」一样，极大地加速数据从存储到计算的流动，解决 AI 模型训练过程中的数据瓶颈问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其次，&lt;strong&gt;计算基础设施将更加紧密地与数据管理和调度相结合&lt;/strong&gt;。AI 模型训练需要消耗大量的计算资源，而这些计算资源需要高效地访问和处理海量数据。未来的 AI Infra 不仅需要提供强大的算力，更需要与 Data Infra 深度整合，实现数据和计算资源的智能调度和优化。例如，AI 训练平台需要能够感知底层数据存储的状态，根据数据分布和模型需求，智能地分配计算任务，从而提高整体效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;（2）AI Infra &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;和底层操作系统的深度融合&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先，我们可以看到 AI 基础设施在资源管理方面也开始借鉴成熟的操作系统的理念。例如，vLLM（一个用于快速且轻量级 LLM 推理的库）中引入的 Page Attention 机制，其核心思想与操作系统中的内存分页管理非常相似。通过将模型的 KV Cache 分割成更小的块进行动态管理，Page Attention 有效提升了 GPU 显存的利用率，减少了碎片化&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其次，AI 应用对底层资源的管理提出了新的需求，这促使 AI 基础设施在某些方面借鉴甚至直接整合操作系统的功能。未来的操作系统需要进行专门的优化，以更好地支持 AI 工作负载，例如提供更细粒度的 GPU 资源管理、优化的内存管理机制（如 Page Attention）、以及对特定 AI 硬件（如 NPU）的更好支持。这种融合旨在为开发者提供更加统一和便捷的开发和部署体验，直接在操作系统层面利用 AI 加速能力。未来的操作系统也可能直接暴露底层 AI 加速硬件的能力，例如提供标准的 API 供应用程序直接调用，而无需通过额外的中间层。尽管面临操作系统的复杂性和硬件多样性等挑战，AI Infra 和操作系统的深度融合将是提升 AI 应用性能和效率的重要趋势。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;总之，以后应该没有 Data Infra 和 AI Infra 之分了，更多的统一称呼为 AI Infra；AI Infra 的边界也会扩大，包括传统的操作系统、网络等层面，变成更大范围的 AI Infra，一起为上面的大模型和应用，提供数据和计算能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;应用趋势：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型在各行各业的深度应用，例如医疗、金融、教育、交通等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;人工智能在科学研究领域的突破，例如新药研发、材料科学、气候变化等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;技术上的挑战与机遇：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;训练瓶颈：大模型的训练远远还没有达到瓶颈，尽管 Ilya Sutskever 认为「预训练已死」，但他指的是在当前算法和架构下，预训练部分的效果提升与算力投入不再呈线性关系，即投入更高一个级别的算力可能无法获得相应比例的效果提升。然而，这并不意味着预训练的终结，未来仍可能出现新的算法突破。而且，在后训练部分，通过强化学习增强模型的推理能力才刚刚开始，仍有巨大的提升空间。因此，从长远来看，模型训练仍然需要更多的算力支持。。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;推理瓶颈：同时因为大模型应用普及带来的上千倍甚至上万倍的推理需求的暴增，生成式 AI 将进入千行百业，彻底改变人们的工作和生活。未来花在推理上的算力需求，将是花在训练上的算力需求的上万倍不止。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;实时个性化需求：参照 AI 1.0 时代的需求变化，未来的大模型应用会越来越向个性化、实时化发展，会涌现出更多为个人贴身定制的应用，就像抖音可以准确把握个人的短视频喜好一样，未来的多个 AI 应用（例如个人智能助手）也会准确理解个人喜好和当前使用环境，给出更符合个人当前需要的服务来。而对实时个性化的需求，将诞生一系列优秀的公司来在产业上下游的细分场景下做出好的产品和项目出来。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;中国特有的机遇和挑战：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国拥有庞大的数据资源和应用场景，为人工智能的发展提供了良好的基础。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国政府高度重视人工智能发展，出台了一系列政策支持人工智能产业的发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国企业在人工智能领域取得了显著进展，具备了与国际巨头竞争的实力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同时欧美芯片限制出口，中国要获取高端 GPU 算力芯片受到很大的限制，同时也给国内各算力芯片厂家提供了非常好的市场机遇。另外新架构下的芯片，例如 RISC-V 架构的芯片如何迎合这一趋势，看看能否在边缘侧或端侧率先做出突破出来。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;总结：当前处于 Data &amp;amp; AI Infra 3.0 的初始阶段，即将腾飞。因为以 DeepSeek 为代表的开源大模型的普及，大模型应用即将爆发，对广大 Infra 相关的从业者来说都是一个非常好的消息。当然，新时代的变化将会相当剧烈，技术迭代的速度会越来愈快，而且会有更多打破传统边界的创新出来，我们要更快的拥抱变化，不断学习，不断实践，才能在这个风起云涌的时代占据一席之地。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;全文结论&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Data &amp;amp; AI Infra &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的发展永不止步。从奠定数据处理基石的 Data Infra 1.0，到实现实时智能化的 Data &amp;amp; AI Infra 2.0，再到如今以大模型为核心的 Data &amp;amp; AI Infra 3.0，每一次飞跃都伴随着激动人心的变革。站在 AI Infra 再次起飞的前夜，我们有理由相信，未来的智能世界将更加精彩纷呈，而 Data &amp;amp; AI Infra 将继续扮演着至关重要的引擎角色。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;回顾这段波澜壮阔的演进历程，我深切感受到技术浪潮的澎湃力量以及创新者们的不懈努力。对于我们每一位身处这个时代的参与者而言，这不仅仅是一段值得了解的技术发展史，更蕴藏着无数个人成长的机遇。无论是深耕于数据和 AI 基础设施领域的工程师、架构师，还是希望借助 AI 力量赋能业务的各行业人士，亦或是对前沿科技充满好奇的探索者，理解这些变革的脉络和未来的趋势至关重要。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0cm; margin-right:0cm&quot;&gt;&lt;span&gt;&lt;span&gt;因此，我希望这篇文章不仅能帮助大家梳理 Data &amp;amp; AI Infra 的发展历程，更能激发大家积极拥抱变化，主动学习和掌握相关技术，洞察新的商业模式和创新方向。抓住 AI 大模型带来的新一轮技术红利，或许下一个引领行业变革的创新者，就诞生在你们之中。让我们共同迎接这个充满机遇与挑战的智能时代！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3742410/blog/17917794</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3742410/blog/17917794</guid>
            <pubDate>Thu, 06 Mar 2025 03:43:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>深度求索公司申请多枚 DeepSeekChat 商标</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 APP 资料显示，杭州深度求索人工智能基础技术研究有限公司近日申请注册多枚 DeepSeek Chat 商标，国际分类涉及教育娱乐、广告销售等，当前商标状态为等待实质审查中。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;323&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d483a5258f2222951400c26dfdaa871c06.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339209</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339209</guid>
            <pubDate>Thu, 06 Mar 2025 03:22:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英特尔新任华人 CEO 陈立武薪酬曝光：最高可达 5 亿元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;据媒体报道，英特尔公司近日公布了其新任 CEO 陈立武 (Lip-BuTan) 的薪酬方案。根据英特尔在周五提交的监管文件，如果陈立武能够在未来几年实现设定的绩效目标，他的总薪酬将达到大约 6900 万美元（约合 5 亿元人民币）。&lt;/p&gt; 
&lt;p&gt;据了解，陈立武的薪酬组合包括多个部分：100 万美元的基本工资、相当于基本工资 200% 的绩效奖金，以及价值 6600 万美元的长期股权奖励、股票期权和入职激励。此外，陈立武还同意在上任后的前 30 天内购买价值 2500 万美元的英特尔股票。英特尔在一份声明中称「陈立武的购股行为反映出他对英特尔的信心，以及致力于创造股东价值的承诺。」&lt;/p&gt; 
&lt;p&gt;陈立武将于 3 月 18 日正式上任，并同时重新加入英特尔董事会。值得一提的是，他的任命具有里程碑式的意义，因为他是英特尔成立 57 年来首位华人 CEO。在英特尔宣布这一任命后，其股价在周四飙升了 15%，今年累计涨幅已达到 20%。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#d35400&quot;&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338619/lip-bu-tan-remaking-intel-future&quot; target=&quot;news&quot;&gt;英特尔新任 CEO 陈立武发布全员信：目标重新成为世界级产品公司&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338502/intel-appoints-lip-bu-tan-chief-executive-officer&quot; target=&quot;news&quot;&gt;英特尔迎来首位华裔掌舵人——任命陈立武为 CEO&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339206</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339206</guid>
            <pubDate>Thu, 06 Mar 2025 03:13:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>特斯拉中国版 FSD 首个迭代曝光：支持 HW3.0 车型、内部员工已收到推送</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 15 日消息，有自称是特斯拉中国员工的用户在 NGA 论坛发文称，搭载 HW4.0 芯片的特斯拉车型已经收到第一批 FSD 推送，效果不是很理想，堪比「一个美国老司机还没拿到中国驾照就直接上路」。&lt;/p&gt; 
&lt;p&gt;据称，他自己（他有两台车）搭载 HW3.0 的 Model3 性能版已于前天收到 V12.6.4 内测版推送，目前已经完成 350 公里测试，这也是特斯拉中国版 FSD 首个迭代版本，或者说第二个特斯拉 FSD 中国版。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1216865105d3d3303233a753e0d45abf157.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，第二个版本相比首个版本进步神速，没有出现任何一次闯红灯和严重违章情况。「上下班 120 公里 80% 国道 20% 城区，退出接管不超过 3 次，不退出接管大概 5-8 次吧。」他认为，特斯拉中国版 FSD 现阶段还处于训练中。由于 HW4.0 车型版本更高且拥有更高的算力上限，他认为新版本相比之前的测试表现会实现更超预期的提升。&lt;/p&gt; 
&lt;p&gt;此前还有消息称，特斯拉正在与百度合作以提升其 FSD 驾驶辅助系统的性能表现，&lt;span style=&quot;color:#d35400&quot;&gt;&lt;strong&gt;但特斯拉方面予以否认，称其和百度的合作仅限于地图导航层面&lt;/strong&gt;&lt;/span&gt;。特斯拉 2 月 25 日宣布在中国大陆推送类似于美国市场推出的具有全自动驾驶能力的 FSD 功能——城市道路 Autopilot 自动辅助驾驶，但实际表现褒贬不一，引起大范围争议。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339201</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339201</guid>
            <pubDate>Thu, 06 Mar 2025 03:01:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Gemini 将取代 Google Assistant</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌在官方博客发文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgemini%2Fgoogle-assistant-gemini-mobile%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;，将用 AI 模型 Gemini 全面取代 Android 手机上的 Google Assistant。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;618&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0317/104957_VvA7_2720166.png&quot; width=&quot;1918&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;除了运行 Android 9 或更早版本，并且 RAM 小于 2GB 的手机，其余 Android 手机上的原版 Google Assistant 将在今年晚些时候停用，并从商店下架。&lt;/p&gt; 
&lt;p&gt;谷歌还宣布，Android 手表、汽车、平板电脑和耳机等设备上的 Google Assistant 也将升级到 Gemini，并将在未来几个月内让 Gemini 支持音箱、显示器和电视，目前正在 Nest Mini 和 Audio 上测试。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-82c614a858bcd93ce49af43e8538394dc81.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Google Assistant 最初发布于 2016 年 5 月，最初只支持 Pixel 系列手机，后来陆续开放给其他各类 Android 设备，并推出 iOS 应用。Google Assistant 依托谷歌的自然语言处理算法，交互类似于更早的 Google Now，但是可以双向对话，结果以卡片形式呈现。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339198/google-assistant-upgrading-to-gemini-mobile</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339198/google-assistant-upgrading-to-gemini-mobile</guid>
            <pubDate>Thu, 06 Mar 2025 02:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中金：人形机器人有望提升社会效能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中金公司研报称，人形机器人有望提升社会效能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在力量型、灵巧型和空间移动导航等领域，人形机器人效率或将高于人工；在公共服务领域，从商业表演到迎宾接待，已有人形机器人的应用，未来有望拓展到更复杂的交互场景；在特种场景中，某企业的先行者系列已可在高危环境巡检，未来救援等场景应用潜力大。总体而言，人形机器人的发展趋势是从专用场景向通用场景渗透。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;233&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5bbbb9066f3724346ba8ccbda092e29cb52.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;并且有望填补劳动力缺口。全球人口增速放缓，联合国人口司数据显示，2023 年全球总人口增速为 0.9%，较 1980 年 1.8% 的增速呈现大幅放缓，此外，老龄化人口占比扩大，劳动力人口占比下降，根据联合国人口司预计，未来 10 年主要经济体的老龄化人口占比继续扩大，或全部达到 20% 以上份额。这导致用工成本上升，人形机器人有望弥补劳动力缺口，提高工作效率，助力企业降本增效，应对未来劳动力结构新形势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人形机器人作为提升生产效率的利器，比工业机器人更灵活，可胜任更多任务，推动生产柔性化，提高生产效率。其发展可带动产业链技术升级，核心零部件技术虽相对成熟，但国产力量仍需提升，中国应着眼全产业链布局，以人形机器人为抓手带动上游零部件技术攻关与产业升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;预测随着成本的降低，未来中国人形机器人市场将较快增长。2030 年出货量有望达到 35 万台，2024 至 2030 年的复合增长率有望达到 317%；市场规模也将迅速扩张，2030 年预计达 581 亿元，复合增长率 259%，有望成为经济增长重要驱动力。随着市场扩大，关键零部件的需求有望大增，以后对供应质量和稳定性要求会更高，产业协同发展是趋势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;233&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6a227a5885514545a3bac17ca560eb81061.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339195</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339195</guid>
            <pubDate>Thu, 06 Mar 2025 02:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>仓颉开源智能体开发框架：Cangjie Magic</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;仓颉社区正式推出 Agent 开发框架 Cangjie Magic。&lt;/p&gt; 
&lt;p&gt;作为首个基于仓颉编程语言原生构建的 LLM Agent 开发平台，该框架通过三大核心技术突破重构智能体开发范式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;独创 Agent DSL 架构 - 基于仓颉语言特性设计的领域专用语言，实现智能体建模的声明式编程；&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;原生支持 MCP（Model Context Protocol）通信协议；&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;智能调度引擎 - 集成模块化服务调用机制与动态任务规划算法&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其核心组件 Cangjie Agent DSL 通过语义化建模语言，为开发者提供从智能体定义、行为编排到运行监控的全生命周期管理方案，显著降低多智能体系统开发复杂度。目前该框架已完成对鸿蒙、Windows、macOS 及 Linux 系统的全平台适配，形成桌面端生态闭环。&lt;/p&gt; 
&lt;p&gt;值得关注的是，官方技术路线图披露，基于仓颉语言的跨平台编译能力，计划于 Q3 季度通过突破性移动端支持方案，实现 Android/iOS 原生接口的智能体调用能力。这一技术演进将打通智能体开发的&quot;最后一公里&quot;，为构建全域智能应用奠定基础。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Cangjie Magic 项目介绍&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;仓颉 AgentDSL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型轻松适配 | 多 Agent 协同 | 极简开发&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0c787707a9f3e2148b2284039d6636a751f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cangjie Agent DSL 是一个用于定义和管理 Agent 的专用语言。它允许开发人员通过结构化的系统提示词、工具和各类协作策略来增强 Agent 的功能。通过结构化的系统提示词、工具以及各类协作策略，极大地增强了 Agent 的功能与灵活性。&lt;/p&gt; 
&lt;p&gt;Cangjie Agent DSL 被设计为仓颉语言的 eDSL，即在仓颉语言中通过元编程机制实现了嵌入式的 DSL，且仓颉语言作为它的宿主语言。这意味着 Agent DSL 编写的代码最终都被转换为普通的仓颉代码，并最终由仓颉编译器完成编译。&lt;/p&gt; 
&lt;p&gt;仓颉编程语言具有多范式编程，高性能，高并发，易扩展等特性，基于仓颉编程语言构建的 LLM Agent 开发框架将会为 AI Agent 开发带来全新开发体验。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开发者可通过以下链接访问 Cangjie Magic 项目并获取更多详细信息：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.com%2FCangjie-TPC%2FCangjieMagic&quot; target=&quot;_blank&quot;&gt;https://gitcode.com/Cangjie-TPC/CangjieMagic&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339193</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339193</guid>
            <pubDate>Thu, 06 Mar 2025 02:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>效力 14 年后，特斯拉 CAE 碰撞安全首席工程师宣布离职</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;特斯拉 CAE 碰撞安全首席工程师 Petter Winberg 在为公司效力 14 年后，于近日宣布离职。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他在 linkedin 的离职声明中写道：「&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Elon，2011 年：「我希望特斯拉汽车成为地球上最安全的汽车」 我：「接受挑战」&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在开发了 Model S、S-DM、X、3、Y、Y-SP 以及未来的碰撞架构之后，我认为现在是时候离开了。谢谢特斯拉，继续勇往直前！多么了不起的团队，我会想念你们所有人。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-658a279c3c89276e9a272539459a1c4ea04.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;electrek 主编、联合创始人 Frederic Lambert 称，过去十多年来，Petter Winberg 一直领导特斯拉的碰撞安全架构。他和他的团队打造了特斯拉在独立碰撞测试中令人难以置信的被动安全性能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339192</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339192</guid>
            <pubDate>Thu, 06 Mar 2025 02:23:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯官宣本周开启「混元 3D 开源日」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，腾讯混元&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6VH7X7H_D5EF2kXbgo7oPQ&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;，分别在 3 月 18 日和 3 月 19 日两天（都为上午 11 时）开启「混元 3D 开源日」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e77bc8110354770d668fd8d0db665309982.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;今年 1 月，腾讯混元宣布正式开源 3D 生成大模型 2.0 版本（Hunyuan3D-2.0），同时上线业界首个一站式 3D 内容 AI 创作引擎。&lt;/p&gt; 
&lt;p&gt;据官方介绍，Hunyuan3D-2.0 相较于 1.0 版本，在 3D 模型生成效果上有显著提升，在几何结构上更加精细，纹理色彩更加丰富；根据 CLIP Maximum Mean Discrepancy (CMMD)、Frechet Inception Distance (FID) 和 CLIP-score 指标，Hunyuan3D-2.0 模型的整体表现，在业界处于领先梯队。&lt;/p&gt; 
&lt;p&gt;而一同上线的腾讯混元 3D AI 创作引擎，可通过提示词或图片，直接生成高质量 3D 模型，并且还有 3D 功能矩阵、3D 编辑、3D 生成工作流、创作素材库等多种功能；混元 3D AI 创作引擎还支持设计 3D 生成工作流，用户只需要输入提示词，或上传图片，调整节点生成参数，即可一键生成具有特定风格和特征的 3D 资产。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339188</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339188</guid>
            <pubDate>Thu, 06 Mar 2025 02:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>