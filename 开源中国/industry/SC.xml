<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 19 May 2025 03:28:42 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>张朝阳：如果晚生 30 年，自己也会卷入到 AI 里面</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在最近召开的 2025 搜狐科技年度论坛上，搜狐创始人、董事局主席兼首席执行官张朝阳，与清华大学讲席教授张亚勤及猎豹移动董事长兼 CEO 傅盛等三位不同领域人士，围绕人工智能（AI）、人形机器人和脑科学等前沿科技展开了深入的讨论。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-d1f6ff151f11d7f2624bff8dbdb8b1e473d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;张朝阳在讨论中表示，&lt;strong&gt;如果晚生 30 年，自己也会卷入到 AI 里面，包括人形机器人，脑科学&lt;/strong&gt;。他认为，目前正是一个比特与分子、原子交汇的时代，物理世界和生物世界的融合为年轻人提供了追逐新兴风口的机会。在他的视角中，年轻人可以在这一时代中大胆尝试，而年长者则更倾向于优化现有的商业模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在谈及中美之间的 AI 差距时，傅盛强调了中国在工程化和应用创新方面的潜力，特别是在智能体等贴近实际应用的领域中，中国有望超越对手。张亚勤则指出，人才的积累是核心竞争力，并提到年轻人在人工智能领域的进展速度令人瞩目，清华大学的相关研究成果是美国的五倍左右。他认为，人工智能最大的创新发生在过去五年，未来五年也将是一个关键期。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;张朝阳总结道，中国在 AI 和科技领域的竞争力源于人们的聪明才智和勤奋工作，加上庞大的人口基数，这种竞争环境推动了中国在各个科技领域的追赶与超越，包括芯片技术和算力问题的解决。他对中国在人工智能领域的未来充满信心，认为我们正处于一个充满机遇的时代。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350569</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350569</guid>
      <pubDate>Mon, 19 May 2025 02:53:40 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>StarRocks MCP Server 开源发布：为 AI 应用提供强大分析中枢</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;过去，开发者要让大模型（LLM）使用数据库查询数据，往往需要开发专属插件、设计复杂的接口或手动构建 Prompt，这不仅费时费力，而且很难在不同模型之间复用。StarRocks MCP Server 提供了一个「通用适配器」接口，让各种 LLM（如 Claude、OpenAI、Gemini）都能标准化地访问 StarRocks，使得模型能够直接执行 SQL 查询并探索数据库内容，无需复杂的配置或集成。&lt;/p&gt; 
&lt;p&gt;这意味着：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;无需开发专用 Agent 插件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型自动发现和调用 StarRocks 暴露的查询/分析工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;构建数据问答、智能分析、自动报表等应用变得更简单&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;👉🏻 项目地址：https://github.com/StarRocks/mcp-server-starrocks&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;什么是 MCP？&lt;/h2&gt; 
&lt;p&gt;首先，我们来了解什么是 MCP。&lt;strong&gt;MCP（Model Context Protocol）&lt;/strong&gt; 是一种用于规范模型与上下文交互的通信协议，旨在标准化模型输入输出的数据结构、元信息传递及上下文管理机制。它通过定义统一的接口协议（如请求/响应格式、状态跟踪、多轮对话标识等），确保模型在复杂应用场景（如多模态交互、长上下文推理）中高效处理上下文依赖关系，同时支持动态上下文更新与历史信息检索。典型应用包括大语言模型（LLM）的对话系统、知识增强推理等。&lt;/p&gt; 
&lt;p&gt;通俗的来说，MCP 就像 AI 世界的「USB 接口」，它提供了一种通用标准，让各种 AI 模型和智能代理（agents）能够无缝连接、交换信息，就像 USB 让不同品牌的设备（鼠标、键盘、硬盘等）都能即插即用一样。通过 MCP，不同 AI 组件可以像乐高积木一样自由组合，使 AI 变得更加智能、灵活和协作高效。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="719" src="https://oscimg.oschina.net/oscnet/up-90681374f708b3497f242a553ae2aa52a2a.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（MCP 架构示意图）&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;MCP 核心组件&lt;/h2&gt; 
&lt;p&gt;MCP 的核心是一个简单但强大的客户端-服务器架构，用于将语言模型与现实世界的功能连接起来。&lt;/p&gt; 
&lt;p&gt;你可以把它想象成一个智能家居中控系统：&lt;/p&gt; 
&lt;p&gt;MCP Host（宿主） = 智能助手（如小爱同学、Alexa）&lt;/p&gt; 
&lt;p&gt;MCP Client （客户端）= 控制中枢&lt;/p&gt; 
&lt;p&gt;MCP Server （服务器）= 各种设备（灯、空调、门锁等）&lt;/p&gt; 
&lt;p&gt;你对智能助手说「打开空调」，你不需要知道空调的品牌、遥控器协议或者哪个网关。系统会通过统一协议找到正确的设备、下发正确的指令。在 MCP 里，LLM 也是这样发起一个请求，比如「获取销售报表」，Client 就会找到对应的数据源 Server，并返回数据。&lt;/p&gt; 
&lt;p&gt;这三大组件的作用如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Host：&lt;/strong&gt;基于 LLM 的应用程序，如 Claude Desktop 或未来集成 AI 的 IDE，用户通过它提出问题或发起操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Client：&lt;/strong&gt;处理连接逻辑。每个客户端与一个服务器建立连接，负责通信和协调。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Server：&lt;/strong&gt;暴露具体能力，如文件访问、天气 API 等。每个服务器通过标准接口提供一组特定的工具、资源或提示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCP Server 提供三类核心能力：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具（Tools）&lt;/strong&gt;：模型可以调用的可执行函数，如「获取天气预报」或「运行 shell 命令」。模型可自行决定何时使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;资源（Resources）&lt;/strong&gt;：如文件、日志或 API 响应等。这些是模型可以读取但不能修改的上下文信息。客户端负责决定何时展示哪些资源。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示词（Prompts）&lt;/strong&gt;：预设的模板，引导模型如何互动。例如生成提交信息、进行调试指导。通常由用户选择，而非模型自行决定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;StarRocks MCP 功能介绍&lt;/h2&gt; 
&lt;p&gt;StarRocks MCP Server 充分利用了 MCP 的核心能力，为大语言模型提供了与 StarRocks 数据库进行深度交互的强大工具集和丰富的上下文资源。具体来说，它实现了以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具 (Tools)&lt;/strong&gt;：这些是模型可以按需调用的「技能」，使其能够主动与 StarRocks 交互：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;db_overview&lt;/code&gt;&lt;/strong&gt;：获取指定数据库中所有表的概览信息。模型可以提供数据库名（若未提供且配置了默认数据库，则使用默认库）。此工具会遍历库中所有表，并为每张表调用 &lt;code&gt;table_overview&lt;/code&gt; 的逻辑获取其详情。同样支持缓存和强制刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;table_overview&lt;/code&gt;&lt;/strong&gt;：快速获取指定表的概览信息。模型只需提供表名（可包含数据库名，如 &lt;code&gt;db_name.table_name&lt;/code&gt;；若未指定数据库名且配置了默认数据库，则使用默认库）。此工具会返回表的列定义 (&lt;code&gt;DESCRIBE table&lt;/code&gt;)、总行数 (&lt;code&gt;COUNT(*)&lt;/code&gt;) 以及少量样本数据 (&lt;code&gt;SELECT * FROM table LIMIT 3&lt;/code&gt;)。为了提高效率，该信息会被缓存，并可通过 &lt;code&gt;refresh=true&lt;/code&gt; 参数强制刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;read_query&lt;/code&gt;&lt;/strong&gt;：执行只读的 SQL 查询（如 &lt;code&gt;SELECT&lt;/code&gt; 语句），并以 CSV 格式返回结果集，包含列名和数据行。这使得模型可以直接获取和分析数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;write_query&lt;/code&gt;&lt;/strong&gt;：执行数据定义语言 (DDL) 或数据操作语言 (DML) 等写操作，如 &lt;code&gt;CREATE TABLE&lt;/code&gt;, &lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;，并返回操作结果（如影响行数、执行时间）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;query_and_plotly_chart&lt;/code&gt;&lt;/strong&gt;：一个强大的分析工具，它首先执行用户提供的 SQL 查询从 StarRocks 获取数据，然后利用该数据和用户指定的 Plotly Express 表达式（一个 Python 函数调用字符串）动态生成图表。图表最终以 Base64 编码的图片形式返回给模型，极大增强了数据洞察的可视化能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;资源 (Resources)&lt;/strong&gt;：这些是模型可以读取的上下文信息，帮助模型理解 StarRocks 的结构和状态：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///databases&lt;/code&gt;&lt;/strong&gt;：列出 StarRocks 集群中的所有数据库名称。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///{db}/tables&lt;/code&gt;&lt;/strong&gt;：列出指定数据库 (&lt;code&gt;{db}&lt;/code&gt;) 中的所有表名。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///{db}/{table}/schema&lt;/code&gt;&lt;/strong&gt;：获取指定数据库 (&lt;code&gt;{db}&lt;/code&gt;) 中特定表 (&lt;code&gt;{table}&lt;/code&gt;) 的创建语句 (&lt;code&gt;SHOW CREATE TABLE {db}.{table}&lt;/code&gt; 的结果），详细展示表的结构信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;proc:///{+path}&lt;/code&gt;&lt;/strong&gt;：访问 StarRocks 内部的 &lt;code&gt;/proc&lt;/code&gt; 路径（如 &lt;code&gt;/proc/backends&lt;/code&gt;, &lt;code&gt;/proc/dbs/{db_id}&lt;/code&gt;），获取集群、节点、数据库、表、事务、作业等详细的运行时状态和元数据信息，类似于 Linux 的 &lt;code&gt;/proc&lt;/code&gt; 文件系统。这为模型提供了深入了解 StarRocks 内部运作的窗口。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示词 (Prompts)&lt;/strong&gt;：目前 StarRocks MCP Server 暂未定义特定的预设提示词。MCP 的设计允许未来根据场景需求灵活添加，以更好地引导模型与 StarRocks 进行特定类型的交互。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;通过这些精心设计的工具和资源，StarRocks MCP Server 使大语言模型能够像经验丰富的数据分析师一样，自主地探索数据、执行分析任务，并以多样化的形式（文本、图表）呈现结果，从而将 StarRocks 的强大 OLAP 能力无缝对接到 AI 应用中。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;StarRocks MCP Server 应用场景&lt;/h2&gt; 
&lt;p&gt;了解了什么是 MCP 之后，来了解一下 StarRocks MCP Server 能应用在哪些场景中：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.实时数据分析与 AI 增强决策&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：让 AI 模型（如 LLM）能够实时查询 StarRocks 中的业务数据，并结合历史上下文生成更精准的分析报告或建议。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;金融风控&lt;/strong&gt;：AI 结合 StarRocks 的实时交易数据，动态评估风险并生成预警。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;电商推荐&lt;/strong&gt;：基于用户实时行为（如浏览、加购）和 StarRocks 的 OLAP 分析，优化个性化推荐策略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.自动化数据报表与 BI 增强&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：通过 MCP 协议，让 AI 自动生成 SQL 查询、执行聚合计算，并返回可视化报表，减少人工干预。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;广告投放分析&lt;/strong&gt;：AI 自动查询 StarRocks 的广告曝光、点击数据，生成优化建议。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;运营驾驶舱&lt;/strong&gt;：结合自然语言交互（如「显示最近 7 天销售额趋势」），自动从 StarRocks 拉取数据并生成 Dashboard。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.复杂查询的 AI 优化与加速&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：利用 MCP 管理查询上下文，让 AI 辅助优化 StarRocks 的多表 JOIN、聚合计算等复杂操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;用户画像分析&lt;/strong&gt;：AI 自动构建 Roaring Bitmap 查询，计算用户留存、漏斗分析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨业务分析&lt;/strong&gt;：AI 解析业务需求，自动生成高效 StarRocks SQL，避免全表扫描。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.统一数据湖与 AI 增强查询&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：通过 MCP 让 AI 同时访问 StarRocks 和外部数据源（如 Hive、Elasticsearch），实现联邦查询。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;混合分析&lt;/strong&gt;：AI 自动组合 StarRocks 的聚合数据和 Hive 的原始日志，生成完整业务洞察。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知识增强&lt;/strong&gt;：AI 查询 StarRocks 的业务数据 + 外部知识库（如论文、行业报告），生成深度分析。&lt;/p&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;StarRocks x MCP 快速上手&lt;/h3&gt; 
&lt;p&gt;StarRocks 是首批通过内置 MCP Server 原生集成 MCP 协议的引擎之一。这使得 StarRocks 不再只是一个高性能查询引擎，而是升级为一个专为智能 Agent 交互优化的分析执行环境。&lt;/p&gt; 
&lt;p&gt;这一切都构建在 StarRocks 现代化的执行引擎之上——向量化、高并发、C++ 编写，自设计之初就面向低延迟和高并发场景。&lt;/p&gt; 
&lt;p&gt;通过将面向 Agent 的标准协议（MCP）与面向现代工作负载的执行引擎结合，StarRocks 为从探索到生产部署的 Agent 驱动分析工作流提供了直接路径。你无需重新设计架构，就可以立即开始构建智能分析应用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.部署 StarRocks 集群，准备数据&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;部署 Starrocks 集群，假设部署到本地 localhost

导入 quickstart 中的 crashdata 数据
https://docs.starrocks.io/docs/quick_start/shared-nothing/#new-york-city-crash-data

CREATE TABLE IF NOT EXISTS crashdata (
    CRASH_DATE DATETIME,
    BOROUGH STRING,
    ZIP_CODE STRING,
    LATITUDE INT,
    LONGITUDE INT,
    LOCATION STRING,
    ON_STREET_NAME STRING,
    CROSS_STREET_NAME STRING,
    OFF_STREET_NAME STRING,
    CONTRIBUTING_FACTOR_VEHICLE_1 STRING,
    CONTRIBUTING_FACTOR_VEHICLE_2 STRING,
    COLLISION_ID INT,
    VEHICLE_TYPE_CODE_1 STRING,
    VEHICLE_TYPE_CODE_2 STRING
);

curl --location-trusted -u root             \
    -T ./NYPD_Crash_Data.csv                \
    -H "label:crashdata-0"                  \
    -H "column_separator:,"                 \
    -H "skip_header:1"                      \
    -H "enclose:\""                         \
    -H "max_filter_ratio:1"                 \
    -H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i'),BOROUGH,ZIP_CODE,LATITUDE,LONGITUDE,LOCATION,ON_STREET_NAME,CROSS_STREET_NAME,OFF_STREET_NAME,NUMBER_OF_PERSONS_INJURED,NUMBER_OF_PERSONS_KILLED,NUMBER_OF_PEDESTRIANS_INJURED,NUMBER_OF_PEDESTRIANS_KILLED,NUMBER_OF_CYCLIST_INJURED,NUMBER_OF_CYCLIST_KILLED,NUMBER_OF_MOTORIST_INJURED,NUMBER_OF_MOTORIST_KILLED,CONTRIBUTING_FACTOR_VEHICLE_1,CONTRIBUTING_FACTOR_VEHICLE_2,CONTRIBUTING_FACTOR_VEHICLE_3,CONTRIBUTING_FACTOR_VEHICLE_4,CONTRIBUTING_FACTOR_VEHICLE_5,COLLISION_ID,VEHICLE_TYPE_CODE_1,VEHICLE_TYPE_CODE_2,VEHICLE_TYPE_CODE_3,VEHICLE_TYPE_CODE_4,VEHICLE_TYPE_CODE_5" \
    -XPUT http://localhost:8030/api/quickstart/crashdata/_stream_load
    &lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2.启动 MCP Client&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2.1 配置客户端添加 mcp-server-starrocks，客户端使用的是 DeepChat&lt;/p&gt; 
&lt;p&gt;大家可以使用这个优化过的版本：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdecster%2Fdeepchat" target="_blank"&gt;https://github.com/decster/deepchat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-c56f1c9bcdcd53827339f3ed235c5884640.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-86469cacb7fd6f7c162e6ae3b9310861b86.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-27900bd2f64691dd1af2f7ae19b109d82a8.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2.2 配置成功后在对话选项中可以添加使用 mcpserver&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-9c20710df0b7cb55fa3b54c2f22b6ba6fba.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;补充说明：在本次 Demo 中，我们使用的是 DeepChat 作为 MCP Client。除此之外，市面上还有如 Claude Desktop、Cline 等主流客户端，用户可根据个人偏好进行配置。需要注意的是，由于我们期望返回结果包含表格和图片，部分客户端可能不支持图片显示，选择时建议将此因素一并考虑。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Demo 演示&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下面的视频中演示了如何以对话形式对 StarRocks 中的数据集进行可视化分析&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV195EizWEFT%2F%3Fvd_source%3D1cb452610138142d1300dd37a6162a88" target="_blank"&gt;https://www.bilibili.com/video/BV195EizWEFT/?vd_source=1cb452610138142d1300dd37a6162a88&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;最后，我们总结一下 StarRocks MCP server 的核心价值：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;让 AI 具备实时 OLAP 能力，减少人工 SQL 编写和数据分析成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;增强决策智能，结合历史数据和实时计算，提供更精准的业务建议。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;统一数据访问层，让 AI 无缝对接结构化数据（StarRocks）与非结构化数据（文档、日志）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;未来，随着 MCP 生态的扩展（如支持更多数据库、BI 工具），这种结合将在，金融、电商、IoT、医疗，等领域发挥更大作用。StarRocks 的朋友们，快来开启更多智能应用！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5658056/blog/18414667</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5658056/blog/18414667</guid>
      <pubDate>Mon, 19 May 2025 02:45:40 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>超拟人 AI 老师、因材施教 AI 辅导，大模型技术在教育中能做好哪些事？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p style="text-align:justify"&gt;&lt;span style="display:none"&gt;&amp;nbsp;&lt;/span&gt;在生成式人工智能重塑各行业版图的当下，教育领域也正经历着一场静水深流的技术变革。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;大模型不再只是实验室里的概念验证，而是逐步渗透进作业批改、个性化辅导、学情分析等教育核心场景，推动着"千人千面"教育理想的落地。在这场技术与教育的双向奔赴中，如何平衡技术创新与教育本质？如何让 AI 真正成为教育公平的推进器而非技术泡沫？我们与深耕 AI 教育应用多年的专家丁小晶展开对话。作为百度小度教育技术负责人，他带领团队打造的 AI 教师系统已成为行业标杆，其团队在教育大模型应用层面积累的实战经验与冷思考，或许能帮助我们更清晰地看到技术赋能教育的可行路径。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;丁小晶 &lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;百度资深工程师/小度教育技术负责人/大模型应用技术专家&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;资深大模型 AI 应用技术专家与管理者，技术创新与项目管理的复合型人才，致力于 AI 大模型应用创新。硕士毕业于中国科学院计算技术研究所，从事高性能计算技术研究。先后在百度、三星等世界知名企业工作，并有多年旅日工作经历。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;拥有超过 15 年的计算机及 AI 领域经验、10 年 AI 及 5 年团队管理经验，精通大模型技术及多语言编程，屡获荣誉，持多项专利。目前作为小度教育业务技术负责人，研究基于大模型 AI 教育产品创新，引领小度教育成为行业先锋。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;丁小晶、崔远，编著《&lt;strong&gt;深度剖析 DeepSeek 大模型： 原理、开发与优化部署&lt;/strong&gt;》&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fitem.m.jd.com%2Fproduct%2F14401797.html" rel="nofollow" target="_blank"&gt;https://item.m.jd.com/product/14401797.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：目前大模型在教育领域的主要应用场景有哪些？能否结合具体案例说明其效果？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;目前大模型技术对教育行业进行深入重构，今年 4 月份的 2025 年教育装备展上明显能看到，教育从业公司都在往大模型应用方向转型。个性化 AI 老师是一个主流趋势。借助大模型技术，可以实现个性化 1v1 的授业、答疑、解惑，大幅降低教育成本，解决教育资源分布不均衡的问题。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;比如 AI 作业批改和 AI 讲题答疑的效果提升，在目前的 AI 自习室行业已经大面积使用，通过 AI 老师逐步降低学生对真人老师的依赖，还可以培养自主学习的习惯，已经逐步在颠覆传统教培行业。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：多模态技术在教育中的应用进展如何？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;多模态技术非常重要，甚至可以说，没有多模态技术效果的快速提升，教育行业不可能如此迅猛发展。比如在前面提到的 AI 作业批改和 AI 讲题答疑方向，完全靠纯文本大模型是无法满足需求的，非常依赖对大模型的图片理解能力。还比如超拟人 AI 老师，语音情感大模型就起来非常关键的作用。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：大模型存在幻觉，在教育中，这是否会导致输出一些错误知识，如错误公式推导等，如何避免这种情况，或者是否可以「自主纠错机制」？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;确实目前即使最好的大模型也还会存在一定的幻觉，比如数学上的一些逻辑计算问题，解决大模型幻觉一直是教育行业的难点。但是在这方面我们还是做了很多创新，比如 SFT 微调、Prompt 约束、Fewshot 规范以及 Tools 校验等技术手段，目前来看效果还是很不错的，也获得用户的认可。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：教育大模型需持续吸收新知识，但传统微调易导致旧知识遗忘。在模型动态更新过程中，如何平衡知识扩展与核心能力稳定性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;这个确实是一个难点。我们自己的经验来看，分两个阶段：24 年 Q4 之前，各家大模型的基座能力确实在教育垂类应用上，受限于没有大量教育优质数据，无论是知识扩展和核心能力都还有欠缺，需要我们进行不断 SFT。但是从 24 年 Q4 往后，特别是 DeepSeek 出来之后，大模型的基座能力提升非常明显。我们对于微调的使用比较谨慎，更倾向于微调非核心能力，比如微调 AI 老师的讲题范式，微调 AI 老师的拟人风格等。在知识扩展方面，我们更倾向于 Agent 架构思想，通过 RAG，More&amp;nbsp;Tools，MCP 等手段来扩展，而不是大模型的微调。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：基座大模型的很多训练数据来自英语，可能导致文化偏见。在中文教育场景中，这是否会影响教育结果？是否有解决机制？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;我们没有这方面问题。我们主要用的是百度文心大模型，很擅长中文。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：教育大模型是否解决传统教育中的「因材施教」难题？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;答：&lt;/strong&gt;大模型技术是解决传统教育「因材施教」难题的最佳方法。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;首先，通过大模型能够更加懂学生。我们的 AI 老师是覆盖家庭教育全场景的，从薄弱项诊断、家长反馈、学习规划到作业辅导，持续更新学生的学习情况。比如在智能作业批改场景，传统 AI 只能判断对错，但是基于大模型我们现在能过做到归因分析，每一步错在哪里都能诊断出来。例如是漏了题目条件，还是对基础概念的理解有误，都能诊断出来。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;其次，只有大模型才能实现真正的 1v1 教学。以为题目答疑为例，传统 AI 对所有学生，都只能有文字解析，或者是一个讲题视频，让学生去看，至于懂不懂，懂多少，那就不知道了。但是基于大模型技术的 AI 老师可以和学生进行交互，在交互中识别孩子们是否真的懂了，进而根据理解的多与少，可以调整讲题思路，一步一步的引导，让孩子真正的理解题目，而这都是传统 AI 无法实现的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们做 AI 老师的初衷，就是为了能够复刻名师，通过大模型技术，我们有机会，让每个家庭、每个孩子都能有一个 AI 名师，即使是在偏远贫困的山区，也能有一个清华北大的 AI 私教。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：当大模型能自动生成个性化习题、教案甚至虚拟实验时，传统教师的角色将如何演变？是转型为「AI 训练师」专注设计提示词，还是强化人类独有的元认知培养能力？这类变革对师范教育体系会产生何种冲击？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;答：&lt;/strong&gt;我和很多老师交流，他们都有这个焦虑。但是我感觉这个问题不仅仅是教育行业存在的，其他行业都会有，比如&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Midjourney&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;我们的 UI 工程师就很焦虑，还有 C&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;oursor&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;也让很多程序员也很焦虑。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我可以谈几点我对这个问题的几点思考：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;老师们也要快速拥抱大模型。大模型短时间内还是不会替代真人老师的，但是善于使用大模型工具的老师一定会更有竞争力，因为他们的效率更高。所以压力不是来自于大模型，而是会使用大模型的同事们。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;对大模型来说，传统的教育经验是非常有价值的。目前所有的大模型都还是在复刻老师。复刻的方法都是在学习老师的教育经验，没有这些教育经验，大模型还是难以替代真人的。我们目前遇到的一个难题是，如何将不同老师的个性化的教育经验，抽象归纳成一套教育方法论，并且能数据化输入给大模型，目前还很难，可能对一些懂大模型的老师是一个机会。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;真人老师除了传道授业解惑之外，言传身教会对学生人生观、价值观也会深深影响，毕竟人是有社会属性的，这种面对面的情感价值，至少是目前的大模型技术还没有办法替代的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：作为小度教育的技术负责人，您带领团队做了哪些 AI 教育产品的创新？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;答：&lt;/strong&gt;大模型技术起来之前，我们小度教育就一直在做 AI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;教育的创新，那个时候也是围绕作业批改和讲题答疑来做的，但是效果一直比较受限。随着大模型技术的快速发展，我们的 AI 能力效果已经做到了行业顶尖水平。特别是我们 2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年发布的 AI 老师，是行业内首创推出超拟人 AI 老师，围绕&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;家庭最普遍的日常学习和作业场景，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;模拟真人家&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;教辅导&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的核心&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;流程&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;从&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;诊断、反馈、规划&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;个性化&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1v&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;辅导学习，系统化的实现了家庭教育场景和大模型技术的深度融合。目前 AI 老师已经成为学习机行业标杆，引领了行业发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：对 AI 从业者而言，面对技术迭代加速的「百模大战」，哪些核心能力将成为竞争壁垒？您会建议青年开发者深耕哪些技术方向？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/span&gt;这个问题就比较宽泛了，仁者见仁，智者见智。我只能从 AI 应用创新从业者的视角来看，识别大模型的能力边界是个很重要的核心能力。大模型能干什么？不能干什么？能干到什么程度？你只有非常清楚，才能做好产品创新。把握的好就是事半功倍，把握的不好那就是事倍功半。而且大模型的能力边界是在持续变化的，要动态的看这个问题，而不是静态的，要对未来有预见性和判断力。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;建议就不太好给了，我也是青年哈，我只能谈几点我自己正在看的几个方向：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一、多模态大模型（特别是视觉大模型）还在快速升级。很多应用场景都需要多模态的支持；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二、Agent 架构迭代很快。比如年初的 Manus，还有最近的 MCP 协议等都在加速智能体架构的发展；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第三、端侧大模型不可忽视。随着 iPhone 的引领，端侧大模型会成为手机行业标配，那也会催生端侧大模型应用爆发。预计今年设备端有希望能跑 1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;0&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;B 小模型了，从能力角度看，已经可以干很多事情了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:none"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18426743</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18426743</guid>
      <pubDate>Mon, 19 May 2025 02:38:40 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>微软裁员风暴：软件工程岗成为 AI 冲击的重灾区</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;《财富》杂志近日发文对微软近日裁员进行了针对性报道，社评认为微软近日的大规模裁员计划引发科技行业对人工智能时代就业结构变革的广泛关注。&lt;/p&gt; 
&lt;p&gt;据华盛顿州官方文件披露，&lt;strong&gt;在微软总部所在地的裁员中，软件工程岗位成为受冲击最严重的领域，占该州约 2000 名被裁员工的 40% 以上。微软本周二确认，其全球裁员规模约 6000 人，华盛顿州裁员人数占总数的三分之一&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-28c5f1e9e5bbf3a6ed55da0a3a7e813d2ea.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次裁员呈现显著的岗位结构性特征：除软件工程师外，软件项目管理岗位亦面临较大调整，华盛顿州被裁的产品管理和技术项目管理岗位合计约 600 人，占该州总裁员数的 30% 左右。&lt;/p&gt; 
&lt;p&gt;知情人士透露，部分参与人工智能项目的管理人员与员工也在裁员范围内，而客户服务类岗位（如销售和市场营销）受影响相对较小，微软对此未作公开置评。&lt;/p&gt; 
&lt;p&gt;行业分析指出，微软的裁员举措与科技企业在人工智能领域的战略转型直接相关。随着微软及其竞争对手持续加码人工智能投资，企业正通过严格审视运营成本、调整预算结构以优化资源配置。&lt;/p&gt; 
&lt;p&gt;微软高管近期承诺，在巨额数据中心建设投资背景下，将严控总体支出。值得关注的是，人工智能驱动的开发工具已展现出代码编写与分析能力，正逐步替代传统工程师手动完成的部分开发任务。微软首席执行官萨蒂亚·纳德拉今年 4 月透露，在公司部分项目中，已有 30% 的代码由 AI 生成。&lt;/p&gt; 
&lt;p&gt;这一现象并非微软独有，多家科技企业正同步推进人力结构重构以适应人工智能转型。例如，Salesforce 今年初宣布裁员逾 1000 人，同时计划持续招聘人工智能相关销售岗位，并明确到 2025 年将减少工程师招聘需求，因其认为人工智能已能替代部分岗位职能；Workday 今年 2 月裁员时，首席执行官卡尔·埃申巴赫亦强调将在人工智能等战略重点领域加大招聘力度。&lt;/p&gt; 
&lt;p&gt;对于裁员目的，微软方面表示主要是精简管理层级，但目前精简成效尚未明确。文件显示，华盛顿州被裁员工中约 17% 为管理职位，这与微软 2023 年底向美国平等就业机会委员会提交的人力资源报告中整体管理人员占比基本一致。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350287</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350287</guid>
      <pubDate>Fri, 16 May 2025 11:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>加速项目管理效率，Gitee PPM 驱动软件工厂的智能化转型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：Gitee DevSecOps 产品经理，李颖萍&amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在高速发展的软件开发时代，企业如何高效管理多个项目、协调团队合作、优化资源配置，已成为推动技术进步的关键。尤其是在多任务、多项目并行的复杂环境下，&lt;strong&gt;Gitee 项目组合管理（PPM）作为一款智能化工具，正成为软件工厂的重要推动力量&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;软件工厂：标准化与自动化的未来&lt;/h2&gt; 
&lt;p&gt;传统开发模式中，企业依赖多个独立工具支撑不同的开发任务和项目。随着软件工厂理念的提出，开发模式发生根本性转变：软件工厂强调的是一个完整的生产体系，由「标准化流程 + 自动化执行 + 可复用构件」构成的生产线。&lt;/p&gt; 
&lt;p&gt;在多项目并行背景下，如何通过高效的项目组合管理优化资源分配、提升执行效率，已成为企业面临的重要挑战。Gitee PPM 正是在此背景下应运而生，&lt;strong&gt;以全新的项目管理方式，推动软件工厂智能化转型&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;Gitee PPM：项目管理的智能调度与透明协作&lt;/h2&gt; 
&lt;p&gt;Gitee PPM 通过智能调度与跨团队协作机制，为软件工厂提供有力支撑。无论资源调度还是多项目并行推进，Gitee PPM 都能高效保障项目执行：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;实时任务进度跟踪：Gitee PPM 提供实时任务进度跟踪功能。通过清晰的进度条和状态标识，团队可随时掌握当前项目状态，管理者也能及时识别需要重点关注和调整的环节。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/161929_chRv_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;精准资源调配：用户可清晰查看每个项目的资源使用情况。系统根据需求智能调度资源，避免浪费与冲突，提升整体研发效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/161945_oCBD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;风险预警与问题追踪：借助任务进度和风险管理模块，Gitee PPM 能及时识别潜在风险并发出预警，帮助项目经理在问题发生前做出调整，确保按时交付。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162000_wLN0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;全生命周期管理：从项目立项到交付，Gitee PPM 贯穿始终&lt;/h2&gt; 
&lt;p&gt;Gitee PPM 的亮点之一是全生命周期管理能力。从立项、排期、执行、监控，到最终交付，Gitee PPM 涵盖项目管理的每一环节，确保每个项目都能够高效且有序地推进。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;项目立项与资源规划：提供标准化立项流程，并通过资源规划功能助力前期准备。人员配置、时间安排、预算分配均可系统化管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;动态调整与进度追踪：在项目推进过程中，Gitee PPM 提供灵活的进度追踪与调整功能，通过直观的进度条与任务分配，管理者可以轻松地进行任务调度和进度优化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;协作与透明化：Gitee PPM 不仅支持项目经理和团队成员之间的沟通，还通过任务审批和资源访问权限的透明化管理，确保每个环节都能得到准确、及时的反馈。团队成员可以实时查看项目状态，随时参与决策，提升工作效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162015_kOQP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;未来趋势：智能化与自动化助力软件工厂的跨越式发展&lt;/h2&gt; 
&lt;p&gt;随着人工智能和自动化技术的迅速发展，未来的 PPM 更加注重智能与自动化融合。Gitee PPM 将持续深化智能分析与预测能力，提前识别风险并提供决策支持。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;无缝集成 DevSecOps 流程：Gitee PPM 将与 DevSecOps 深度融合，支持 CI/CD 等敏捷方法，提升软件交付速度与质量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全生命周期智能管理：随着项目规模与复杂性增长，Gitee PPM 将扩展管理范围，覆盖研发、测试、交付和运维等各环节的智能化管理。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Gitee PPM，赋能软件工厂的未来&lt;/h2&gt; 
&lt;p&gt;在软件工厂的智能化转型过程中，Gitee PPM 无疑是其中最为关键的一环。通过智能化的项目管理，精准的资源调配，全面的风险控制以及高效的跨部门协作，Gitee PPM 正在为软件开发行业带来革命性的变化。&lt;/p&gt; 
&lt;p&gt;未来，Gitee PPM 将继续不断创新，推动软件工厂向更高效、更智能、更安全的方向发展，成为企业实现研发目标、提升交付质量、加速业务增长的核心竞争力。&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的现代化研发生态&lt;/h2&gt; 
&lt;p&gt;Gitee DevSecOps 是一站式国产化研发与交付平台，集成了代码托管（Code）、项目协作（Team）、持续集成（CI）、持续部署（CD）、代码安全（Scan）、数据洞察（Insight）等多项能力，致力于打造具备全生命周期管控能力的现代软件工厂。&lt;/p&gt; 
&lt;p&gt;&lt;img height="489" src="https://static.oschina.net/uploads/space/2025/0516/162034_3TT9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitee.cn%2Ffactory" target="_blank"&gt;https://gitee.cn/factory&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;平台设计充分考虑关键领域行业对安全性、可控性、合规性的极高要求，具备以下核心特征：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;国产化适配与私有化部署能力：全面兼容国产操作系统与基础设施，支持灵活部署于内网环境，保障数据主权；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全流程 DevSecOps 管控体系：代码从提交、审核、构建、扫描、部署到发布全流程可视、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模块化产品结构：各能力模块（如 Code、Team、Repo、Pipe、Scan、Insight 等）可灵活组合、渐进集成，适配多样化团队与流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度可观测与度量体系：内置研发效能度量与数据洞察引擎，支撑管理者宏观掌控项目态势与交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="599" src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多个国家级重大项目与关键领域单位落地实践中，Gitee DevSecOps 已成为构建「自主、可控、高效、安全」的软件工程体系的重要基石。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350255</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350255</guid>
      <pubDate>Fri, 16 May 2025 08:21:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>🔥 Solon Ai Flow 编排开发框架发布预告（效果预览）</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;Solon Ai 在推出 Solon Ai Mcp 后，又将推出 Solon Ai Flow。&lt;/p&gt; 
&lt;h3&gt;1、Solon Ai Flow 是个啥？&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Solon Ai Flow 是一个智能体编排开发框架。它是框架！不是工具，不是产品（这与市面上流行的工具和产品，有较大差别）。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;使用 yaml 格式编排，很像 docker-compose 的观感。&lt;/p&gt; 
&lt;h3&gt;2、发布预告&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;预计下周（2025 年农历小满）发布首个版本。&lt;/p&gt; 
&lt;h3&gt;3、效果预览&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;简单的聊天智能体&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;chat_case1&lt;/span&gt;
&lt;span style="color:#986801"&gt;layout:&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextInput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;text:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你好"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是个聊天助手"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;RAG 知识库智能体&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;rag_case1&lt;/span&gt;
&lt;span style="color:#986801"&gt;layout:&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextInput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;text:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"Solon 是谁开发的？"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@EmbeddingModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;embeddingConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.embedding.EmbeddingConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"bge-m3"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/embed"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@InMemoryRepository"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;documentSources:&lt;/span&gt;
        &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"https://solon.noear.org/article/about?format=md"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;splitPipeline:&lt;/span&gt;
        &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"org.noear.solon.ai.rag.splitter.RegexTextSplitter"&lt;/span&gt;
        &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"org.noear.solon.ai.rag.splitter.TokenSizeTextSplitter"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是个知识库"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;两个智能体表演相声式吵架（llm 与 llm 讲相声）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;pk_case1&lt;/span&gt;
&lt;span style="color:#986801"&gt;layout:&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;type:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"start"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextInput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;text:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你好"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;model_a&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是一个智能体名字叫「阿飞」。将跟另一个叫「阿紫」的智能体，表演相声式吵架。"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatSession:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"A"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;prefix:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"阿飞: "&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;model_b&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是一个智能体名字叫「阿紫」。将跟另一个叫「阿飞」的智能体，表演相声式吵架。"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatSession:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"B"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;prefix:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"阿紫: "&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;type:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"exclusive"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;link:&lt;/span&gt;
      &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;nextId:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;model_a&lt;/span&gt;
        &lt;span style="color:#986801"&gt;condition:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;'context.counter().incr("demo") &amp;lt; 10'&lt;/span&gt;
      &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;nextId:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;end&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;type:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"end"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"end"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4、如何运行？&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;case2, csae3, case4 是用 TextInput，TextOutput 作输出输入。通过流引擎和引上下文，即可运行。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@SolonTest&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;ChatTest&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    FlowEngine flowEngine;
    
    &lt;span style="color:#4078f2"&gt;@Test&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case2&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case2"&lt;/span&gt;);
    }
    
    &lt;span style="color:#4078f2"&gt;@Test&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case3&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case3"&lt;/span&gt;);
    }
    
    &lt;span style="color:#4078f2"&gt;@Test&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case4&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case4"&lt;/span&gt;);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;csae1 则是用 ChatInput 和 ChatOutput 作输入输出（基于 Context.current() 输入和输出），需要正常的 web 聊天场景&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;DemoController&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    FlowEngine flowEngine;

    &lt;span style="color:#986801"&gt;ChatSession&lt;/span&gt; &lt;span style="color:#986801"&gt;chatSession&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;ChatSessionDefault&lt;/span&gt;();

    &lt;span style="color:#4078f2"&gt;@Mapping("case1")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case1&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span style="color:#a626a4"&gt;throws&lt;/span&gt; Exception {
        &lt;span style="color:#986801"&gt;FlowContext&lt;/span&gt; &lt;span style="color:#986801"&gt;flowContext&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;FlowContext&lt;/span&gt;();
        flowContext.put(Attrs.CTX_CHAT_SESSION, chatSession); &lt;em&gt;//传递聊天会话&lt;/em&gt;

        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case1"&lt;/span&gt;, flowContext); 
    }
}&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350236</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350236</guid>
      <pubDate>Fri, 16 May 2025 07:32:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>SpringBoot3 使用 SolonMCP 开发 MCP</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;之前发了个 「《SpringBoot2 可以使用 SolonMCP 开发 MCP（江湖救急）》」。然后，有人问：SpringBoot3 能不能用 SolonMCP？&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;其实 SpringBoot3 可以使用 Spring AI 或者 Spring AI Alibaba（都有 MCP 功能）。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;既然问了，就再发一个文。另外 SpringBoot3 使用 SolonMPC 和 SpringBoot2 的情况，差不多。只一个依赖包有不同。&lt;/p&gt; 
&lt;h3&gt;1、SolonMCP 简介&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;SolonMCP（全称：solon-ai-mcp）是 solon ai 的一个扩展。支持内嵌到 jfinal，vert.x，springboot2，springboot3 等框架使用。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Maven 主要依赖包：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-ai-mcp&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;具体的示例参考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3"&gt;https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3-newstyle"&gt;https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3-newstyle&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2、MCP 服务端开发&lt;/h3&gt; 
&lt;h4&gt;2.1、添加入口类&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.HelloApp&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@SpringBootApplication&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;HelloApp&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; {
        SpringApplication.run(HelloApp.class, args);
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.2、添加个空接口&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.mcpserver.IMcpServerEndpoint&lt;/code&gt;&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;用于识别端点组件类&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;interface&lt;/span&gt; &lt;span style="color:#c18401"&gt;IMcpServerEndpoint&lt;/span&gt; { }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.3、添加&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.mcpserver.McpServerConfig&lt;/code&gt;&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;拖管 solon 的生命周期。收集 IMcpServerEndpoint 组件，并转为 McpServerEndpointProvider&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@Configuration&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpServerConfig&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@PostConstruct&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;start&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        Solon.start(McpServerConfig.class, &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;String&lt;/span&gt;[]{&lt;span style="color:#50a14f"&gt;"--cfg=mcpserver.yml"&lt;/span&gt;});
    }

    &lt;span style="color:#4078f2"&gt;@PreDestroy&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;stop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt; (Solon.app() != &lt;span style="color:#0184bb"&gt;null&lt;/span&gt;) {
            Solon.stopBlock(&lt;span style="color:#0184bb"&gt;false&lt;/span&gt;, Solon.cfg().stopDelay());
        }
    }

    &lt;span style="color:#4078f2"&gt;@Bean&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; McpServerConfig &lt;span style="color:#4078f2"&gt;init&lt;/span&gt;&lt;span&gt;(List&amp;lt;IMcpServerEndpoint&amp;gt; serverEndpoints)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;for&lt;/span&gt; (IMcpServerEndpoint serverEndpoint : serverEndpoints) {
            &lt;em&gt;//这里注意一下，如果有代理的话需要用 AnnotationUtils 获取注解&lt;/em&gt;
            &lt;span style="color:#986801"&gt;McpServerEndpoint&lt;/span&gt; &lt;span style="color:#986801"&gt;anno&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; AnnotationUtils.findAnnotation(serverEndpoint.getClass(), McpServerEndpoint.class);

            &lt;span style="color:#a626a4"&gt;if&lt;/span&gt; (anno == &lt;span style="color:#0184bb"&gt;null&lt;/span&gt;) {
                &lt;span style="color:#a626a4"&gt;continue&lt;/span&gt;;
            }

            &lt;span style="color:#986801"&gt;McpServerEndpointProvider&lt;/span&gt; &lt;span style="color:#986801"&gt;serverEndpointProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpServerEndpointProvider.builder()
                    .from(serverEndpoint.getClass(), anno)
                    .build();

            serverEndpointProvider.addTool(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;MethodToolProvider&lt;/span&gt;(serverEndpoint));
            serverEndpointProvider.addResource(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;MethodResourceProvider&lt;/span&gt;(serverEndpoint));
            serverEndpointProvider.addPrompt(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;MethodPromptProvider&lt;/span&gt;(serverEndpoint));

            serverEndpointProvider.postStart();

            &lt;em&gt;//可以再把 serverEndpointProvider 手动转入 SpringBoot 容器&lt;/em&gt;
        }

        &lt;em&gt;//为了能让这个 init 能正常运行&lt;/em&gt;
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#c18401"&gt;this&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@Bean&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; FilterRegistrationBean &lt;span style="color:#4078f2"&gt;mcpServerFilter&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        FilterRegistrationBean&amp;lt;SolonServletFilter&amp;gt; filter = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;FilterRegistrationBean&lt;/span&gt;&amp;lt;&amp;gt;();
        filter.setName(&lt;span style="color:#50a14f"&gt;"SolonFilter"&lt;/span&gt;);
        filter.addUrlPatterns(&lt;span style="color:#50a14f"&gt;"/mcp/*"&lt;/span&gt;);
        filter.setFilter(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;SolonServletFilter&lt;/span&gt;());
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; filter;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.4、添加&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.mcpserver.tool.McpServer&lt;/code&gt;（实现 Handler、IPlugin 接口）&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;这里是重点了，添加 mcp server 端点（支持多个端点）。这里是正常的 SpringBoot 组件开发了。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@Component&lt;/span&gt; &lt;em&gt;//注意这个注解别用错了（solon 里也有同名的）&lt;/em&gt;
&lt;span style="color:#4078f2"&gt;@McpServerEndpoint(name="demo1", sseEndpoint = "/mcp/demo1/sse")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpServerTool&lt;/span&gt; &lt;span style="color:#a626a4"&gt;implements&lt;/span&gt; &lt;span style="color:#c18401"&gt;IMcpServerEndpoint&lt;/span&gt; {
    &lt;em&gt;//&lt;/em&gt;
    &lt;em&gt;// 建议开启编译参数：-parameters （否则，最好再配置参数的 name）&lt;/em&gt;
    &lt;em&gt;//&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@ToolMapping(description = "查询天气预报")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getWeather&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param(description = "城市位置")&lt;/span&gt; String location)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"晴，14 度"&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@ResourceMapping(uri = "config://app-version", description = "获取应用版本号")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getAppVersion&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"v3.2.0"&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@ResourceMapping(uri = "db://users/{user_id}/email", description = "根据用户 ID 查询邮箱")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getEmail&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param(description = "用户 Id")&lt;/span&gt; String user_id)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; user_id + &lt;span style="color:#50a14f"&gt;"@example.com"&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@PromptMapping(description = "生成关于某个主题的提问")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; Collection&amp;lt;ChatMessage&amp;gt; &lt;span style="color:#4078f2"&gt;askQuestion&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param(description = "主题")&lt;/span&gt; String topic)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; Arrays.asList(
                ChatMessage.ofUser(&lt;span style="color:#50a14f"&gt;"请解释一下'"&lt;/span&gt; + topic + &lt;span style="color:#50a14f"&gt;"'的概念？"&lt;/span&gt;)
        );
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.5、编译后运行&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;或者开发时，直接运行&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;HelloApp:main&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法&lt;/p&gt; 
&lt;h3&gt;3、MCP 客户端开发&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;客户端简单些&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpClientTest&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span style="color:#a626a4"&gt;throws&lt;/span&gt; Exception {
        &lt;span style="color:#986801"&gt;McpClientProvider&lt;/span&gt; &lt;span style="color:#986801"&gt;toolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientProvider.builder()
                .apiUrl(&lt;span style="color:#50a14f"&gt;"http://localhost:8080/mcp/sse"&lt;/span&gt;)
                .build();

        &lt;em&gt;//工具调用&lt;/em&gt;
        Map&amp;lt;String, Object&amp;gt; map = Collections.singletonMap(&lt;span style="color:#50a14f"&gt;"location"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"杭州"&lt;/span&gt;);
        &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; toolProvider.callToolAsText(&lt;span style="color:#50a14f"&gt;"getWeather"&lt;/span&gt;, map).getContent();
        System.out.println(rst);
        &lt;span style="color:#a626a4"&gt;assert&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"晴，14 度"&lt;/span&gt;.equals(rst);
        
        
        &lt;em&gt;//资源读取&lt;/em&gt;
        resourceContent = toolProvider.readResourceAsText(&lt;span style="color:#50a14f"&gt;"config://app-version"&lt;/span&gt;).getContent();
        System.out.println(resourceContent);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4、MCP 客户端作为 LLM（ChatModel） 的工具集使用&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;也比较简单。使用 ollama 做为 llm 提供者，方便本地测试。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpClientTest&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;final&lt;/span&gt; &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;apiUrl&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;final&lt;/span&gt; &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;provider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;final&lt;/span&gt; &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;model&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;; &lt;em&gt;//"llama3.2";//deepseek-r1:1.5b;&lt;/em&gt;
    
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span style="color:#a626a4"&gt;throws&lt;/span&gt; Exception {
        &lt;em&gt;//构建 mcp client&lt;/em&gt;
        &lt;span style="color:#986801"&gt;McpClientProvider&lt;/span&gt; &lt;span style="color:#986801"&gt;toolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientProvider.builder()
                .apiUrl(&lt;span style="color:#50a14f"&gt;"http://localhost:8080/mcp/sse"&lt;/span&gt;)
                .build();

        &lt;em&gt;//构建 llm 接口&lt;/em&gt;
        &lt;span style="color:#986801"&gt;ChatModel&lt;/span&gt; &lt;span style="color:#986801"&gt;chatModel&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; ChatModel.of(apiUrl)
                .provider(provider)
                .model(model)
                .defaultToolsAdd(toolProvider) &lt;em&gt;//添加默认工具（这是 mcp client）&lt;/em&gt;
                .build();
        
        &lt;em&gt;//请求&lt;/em&gt;
        &lt;span style="color:#986801"&gt;ChatResponse&lt;/span&gt; &lt;span style="color:#986801"&gt;resp&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; chatModel.prompt(&lt;span style="color:#50a14f"&gt;"杭州今天的天气怎么样？"&lt;/span&gt;)
                .call();

        System.out.println(resp.getMessage());
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5、SpringBoot3 和 SpringBoot2 使用 SolonMCP 有什么区别？&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;仅一个 servlet 的依赖包不同（由 java-ee 改名引起的）。SpringBoot3 使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;solon-web-servlet-jakarta&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;依赖包；SpringBoot2 则使用 solon-web-servlet-jakarta 依赖包。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350221</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350221</guid>
      <pubDate>Fri, 16 May 2025 06:50:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>【最后今天】LFOSSA 技能焕新季 85 折限时福利活动即将结束！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="微信图片_85 折.png" src="https://oscimg.oschina.net/oscnet//23abacdd7a61a2ef402c028b04dfb5a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;Linux Foundation&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;开源软件&lt;/strong&gt;&lt;strong&gt;学园（LFOSSA） 于 5 月 7 日至 5 月 16 日，推出&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;L&lt;/strong&gt;&lt;strong&gt;FOSSA 技能焕新季限时福利活动&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff"&gt;，&lt;span style="color:#ff0000"&gt;&lt;strong&gt;全场 LF 官方认证考试及课程 &amp;nbsp;&lt;span style="color:#00b050"&gt;85 折&amp;nbsp;&lt;/span&gt;起&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffff00; color:#ff0000"&gt;&lt;strong&gt;活动仅剩最后&amp;nbsp;&lt;span style="color:#00b050"&gt;今&lt;/span&gt;&amp;nbsp;天，机会不容错过！&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;快速提升你的开源技能，抢跑&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;新时代&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技能焕新季 · LF 认证限时福利详情&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;活动时间&lt;/strong&gt;：&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;5 月 7 日 - 5 月 16 日&lt;span style="background-color:#ffff00"&gt;（活动仅剩最后&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天！）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;适用产品：&lt;/strong&gt;&lt;strong&gt;LF&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;官方认证考试及课程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向个人专属福利：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;部分机构热门课程低至&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;7&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;折&lt;/span&gt;&lt;/strong&gt;，&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;添加 LFOSSA 官方微信，限时领取&amp;nbsp;&lt;span style="color:#00b050"&gt;认证培训首节课程免费试听&amp;nbsp;&lt;/span&gt;资格&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向企业专属福利（阶梯折扣）：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 采购 5-20 个认证：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;85&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;优惠&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 采购 21-50 个认证：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;优惠&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;3. 采购 50 个以上认证：&lt;/strong&gt;联系官方客服，获取定制专属方案&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368565314179.png" height="1000" src="https://oscimg.oschina.net/oscnet//dcb6214ff743fa4e8bbe17fc11a9cee5.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;有关&amp;nbsp;&lt;/strong&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;LFOSSA 技能焕新季限时福利活动&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;，可点击以下链接了解详情：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542784%26idx%3D1%26sn%3D236a3bfdcf36dec0bf41f462cc0c91d8%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;抢跑 AI 时代，焕新开源技能！LFOSSA 技能焕新季 85 折限时福利活动开启！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542805%26idx%3D1%26sn%3D4af4c9ac39d950df1de31477624b659e%26scene%3D21%23wechat_redirect" target="_blank"&gt;【最后 2 天】LFOSSA 技能焕新季｜企业采购折扣限时福利活动即将截止，抓紧最后机会！&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;联系我们&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;如需&amp;nbsp;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;体验&lt;/strong&gt;&lt;strong&gt;认证培训课程免费试听首节课&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;，或为&lt;span style="color:#ff0000"&gt;&lt;strong&gt;贵单位定制认证学习路径以及批量采购方案&lt;/strong&gt;&lt;/span&gt;，欢迎扫码添加官方客服，我们将为你提供一对一的采购咨询与支持服务。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="background-color:rgba(255, 246, 122, 0.8); color:#ff0000"&gt;&lt;strong&gt;活动截止时间：2025 年 5 月 16 日（仅剩最后&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;限时折扣，错过不再，快来锁定优惠名额！&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368673326323.jpeg" height="260" src="https://oscimg.oschina.net/oscnet//86a0e91efbe8dabcc8f184b71cdb50ad.jpeg" width="260" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span style="color:#8f959e"&gt;扫码添加客服&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368808706235.png" height="311" src="https://oscimg.oschina.net/oscnet//6a2c4a0154fe65c0ed86ca1afc9639a8.png" width="1600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;查看更多 LFOSSA 培训、认证及套购产品，请访问以下链接：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;培训：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"&gt;https://training.linuxfoundation.cn/courses&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;认证：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"&gt;https://training.linuxfoundation.cn/certificates&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;套购：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank"&gt;https://training.linuxfoundation.cn/pack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;立即点击&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank"&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;这里&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;进入 LFOSSA 官网，选购官方认证考试及培训课程产品。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350219</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350219</guid>
      <pubDate>Fri, 16 May 2025 06:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软 VS &amp; VS Code 每月活跃开发者数量达到 5000 万</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软今天&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fblog%2Fcelebrating-50-million-developers-the-journey-of-visual-studio-and-visual-studio-code" target="_blank"&gt;宣布了&lt;/a&gt;其 Visual Studio 产品系列的一个重要里程碑：Visual Studio 和 Visual Studio Code 现在每月为超过 5000 万活跃开发人员提供服务。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.cnbetacdn.com/article/2025/0516/0b34a4bdf1bdfd2.jpg" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-51990187483c55d75a61f86af17b234b4ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fc7a64f6ab1f22d5860bdce786e8832ef8b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Visual Studio 于 28 年前首次推出，至今仍是领先的集成开发环境 (IDE)，这主要得益于 Windows 生态系统的普及。多年来，它不断发展，现已支持跨平台开发、云原生应用程序、游戏开发、数据科学工作流等。它仍然是少数几个开箱即用地包含编译器、调试器、分析器、设计器和语言服务的 IDE 之一。&lt;/p&gt; 
&lt;p&gt;Visual Studio 的数据：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Visual Studio Marketplace 上有 25000 多个扩展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;超过 100000 名开发人员贡献反馈、问题报告和功能创意&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;社区论坛中数十万个问答&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;每个季度更新平均修复 800 多个社区报告的问题&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;十年前，随着 Windows 开始被 iOS 和 Android 等移动平台蚕食，微软在当时推出了 Visual Studio Code，这一举动令许多人感到意外。与其功能齐全的兄弟版本不同，Visual Studio Code 采用轻量级开源模式。它并非提供所有开箱即用的功能，而是允许开发人员通过庞大的扩展生态系统自定义其开发环境。&lt;/p&gt; 
&lt;p&gt;Visual Studio Code 的数据：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 市场中有 100000 多个扩展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 代码库已获得 37000 多个 GitHub 星标&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;来自世界各地的数千名贡献者&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;微软开发者部门 CVP 兼产品主管、微软第一方工程系统总经理 Amanda Silver 就这一里程碑写道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在我们庆祝这一里程碑的同时，我们也正站在软件开发新时代的开端。人工智能编程革命正在从根本上改变我们编写代码的方式，而我们仅仅触及了未来可能性的皮毛。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;为了庆祝 5000 万里程碑，微软还发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2F" target="_blank"&gt;Visual Studio 和 Visual Studio Code 的周年纪念特别壁纸&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eaef23439a2406d17ad3b98418b1733e23a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;下载地址如下，分别用于桌面、手机与智能手表：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fdesktop" target="_blank"&gt;https://visualstudiowallpapers.com/desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fphone" target="_blank"&gt;https://visualstudiowallpapers.com/phone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fwatch" target="_blank"&gt;https://visualstudiowallpapers.com/watch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在下周即将举行的 Build 开发者大会上，微软预计将发布这两款工具的更新，旨在进一步提升开发者体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</guid>
      <pubDate>Fri, 16 May 2025 06:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软将于 8 月 11 日关闭 Bing Search API 服务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fbing%2Fapis%2Fbing-web-search-api" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;将于 2025 年 8 月 11 日正式关闭 Bing Search API 服务，届时所有使用 Bing Search API 的实例将完全停用，同时不再接受新用户注册。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135843_cSSP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微软建议用户考虑使用 Azure AI Agents 中的「Grounding with Bing Search」作为替代方案，但该替代方案并非完美。&lt;/p&gt; 
&lt;p&gt;「Grounding with Bing Search」可以在生成回应时引用实时公开网络数据，但开发者和用户无法直接访问 Bing 搜索的原始数据内容，这意味着它无法完全替代 Bing Search API 的功能。&lt;/p&gt; 
&lt;p&gt;此次停用决定主要影响 Bing Search F1 及 S1 到 S9 资源的用户，以及 Custom Search F0 与 S1 到 S4 资源的用户。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;不过受影响的主要为 Bing Search APIs 的自助式或小型用户，像 DuckDuckGo 这样的大型客户，由于与微软签署了直接协议，仍可继续使用这些 API。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，微软在 ChatGPT 于 2022 年首次亮相后，已将 Bing Search APIs 的价格提高了 10 倍，此次直接关闭 API 服务，可能是微软在 AI 时代对搜索服务战略调整的一部分。&lt;/p&gt; 
&lt;p&gt;此外有分析指出，微软停用 Bing API 可能会对正在审理中的 Google 搜索垄断案产生影响。&lt;/p&gt; 
&lt;p&gt;由于 Google Search APIs 价格昂贵且限制较多，许多开发者更倾向于使用 Bing API，微软的这一决定可能会迫使 Google 在搜索 API 资源方面做出更多让步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350213/bing-web-search-api-retired</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350213/bing-web-search-api-retired</guid>
      <pubDate>Fri, 16 May 2025 05:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元图像（Hunyuan Image）2.0 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯混元图像 2.0 模型（Hunyuan Image2.0）已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNEg5Wop9EPw3Z6Lx5ik7Mg" target="_blank"&gt;正式发布&lt;/a&gt;。该模型主要有两大特点：&lt;strong&gt;实时生图、超写实画质。&lt;/strong&gt;目前已在腾讯混元官方网站上线（https://hunyuan.tencent.com/），并对外开放注册体验。&lt;/p&gt; 
&lt;p&gt;&lt;img height="607" src="https://static.oschina.net/uploads/space/2025/0516/134524_sRBm_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方数据显示，在图像生成领域专门测试模型复杂文本指令理解与生成能力的评估基准 &amp;nbsp;GenEval（Geneval Bench）上，腾讯混元图像 2.0 模型准确率超过 95%，远超其他同类模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134745_rlGs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是混元图像（Hunyuan Image）2.0 模型生成的图片：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;人像摄影风格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="512" src="https://static.oschina.net/uploads/space/2025/0516/134725_ADPH_2720166.png" width="854" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;动漫风格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="532" src="https://static.oschina.net/uploads/space/2025/0516/134738_PKYz_2720166.png" width="888" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;真实人物风格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134836_gwyW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次模型升级还带来了发布了实时绘画板功能，基于模型的实时生图能力，用户在绘制线稿或调整参数时，预览区同步生成上色效果，突破了传统「绘制-等待-修改」的线性流程，可助力专业设计师的创作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135145_kura_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;实时绘画板支持多图融合，用户上传多图后，可将多个草图叠加至同一画布自由创作，经过 AI 自动协调透视与光影，按照提示词内容生成融合图像，进一步丰富了 AI 生图的交互体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350209</guid>
      <pubDate>Fri, 16 May 2025 05:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Windsurf 发布 Wave 9 模型家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windsurf (原 Codeium) 发布了 Wave 9 模型家族，包括 SWE-1、SWE-1-Lite 和 SWE-1-Mini。&lt;/p&gt; 
&lt;p&gt;SWE-1 是一个前沿模型，专门为软件工程任务设计，在内部评估和产品使用中，其性能接近甚至超越现有前沿模型。&lt;/p&gt; 
&lt;p&gt;SWE-1-Lite 是一个更强大的新模型，将取代原有的 Cascade Base，对所有用户免费。SWE-1-Mini 是用于 Windsurf 中 tab 补全的改进模型。SWE-1 目前对 Pro 用户限时免费。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/133759_d7AQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据 Windsurf 介绍，SWE-1 是其中最大、能力最强的 AI 模型，旨在突破现有大模型在软件工程实际需求上的局限。&lt;/p&gt; 
&lt;p&gt;相比只关注代码生成和单元测试的传统模型，SWE-1 更强调对开发流程中多种状态和上下文的感知能力（flow awareness），它能够在人机协作、任务未完成等复杂场景下持续推进工作。&lt;/p&gt; 
&lt;p&gt;根据基准测试，SWE-1 在 「对话式 SWE 任务基准」 和 「端到端 SWE 任务基准」 这两项核心指标上，都已经接近目前行业最强的前沿模型。特别是独立的端到端任务中，它的表现几乎和 Claude 系列最新模型能力相当。&lt;/p&gt; 
&lt;p&gt;在对话式任务中（任务做到一半，用户和模型交替操作，模型需要接着用户的进度继续完成任务），它目前的能力相当于 Claude 3.5 Sonnet。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-80a326122f0a65adc98949e8bf1c2bc890e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fcb9655b8e9ddf4084175265b446815c9f2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;参考来源：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindsurf.com%2Fblog%2Fwindsurf-wave-9-swe-1" target="_blank"&gt;https://windsurf.com/blog/windsurf-wave-9-swe-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FOS6Tz1nfUxgi0n4Dcf3bvg" target="_blank"&gt;https://mp.weixin.qq.com/s/OS6Tz1nfUxgi0n4Dcf3bvg&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</guid>
      <pubDate>Fri, 16 May 2025 05:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>深入对比谷歌 A2A 与 ANP：找到协议的原点</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;作者：常高伟，智能体协议 ANP 发起人。&lt;/p&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;关于 ANP：Agent Network Protocol (ANP) 是一个开源的智能体通信协议，目标是成为智能体互联网时代的 HTTP。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;谷歌的&lt;/span&gt;&lt;span&gt;A2A&lt;/span&gt;&lt;span&gt;协议出来后，很多关注 ANP 社区的朋友第一时间发来消息，问对我们影响大不大，并且给我们献言献策，再次感谢。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我认为 A2A 对&lt;/span&gt;&lt;span&gt;ANP&lt;/span&gt;&lt;span&gt;最大的影响是，有了谷歌的「盖章「 Follow：ANP 的路线是对的，ANP 看的很长远，我也来了&amp;nbsp;&lt;/span&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;我不用再去解释为什么智能体通信协作重要了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;当天我花了半天的时候研究，写了一篇文章：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4NjIwOTM5Mw%3D%3D%26mid%3D2654085211%26idx%3D1%26sn%3D22d52145d41b02fc217469278c8857f5%26scene%3D21%23wechat_redirect" target="_blank" rel="nofollow"&gt;多角度全面对比 Google 最新的 A2A、ANP、MCP&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;后来又花了一天的时间仔细研究了 A2A，与 ANP 做了一个深度的对比，我认为我应该找到了 A2A 的原点，我也看到了 A2A 与 ANP 的更深层次的差异&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;一句话总结：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;MCP 的原点是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;模型与工具、资源的连接&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;A2A 的原点是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;企业内部智能体之间的复杂协作&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;ANP 的原点是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;智能体在互联网上的连接与协&lt;/span&gt;作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;技术层面的差异对比&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;虽然说 A2A 和 ANP 都是解决智能体通信与协作，但是从技术层面，A2A 与 ANP 还是有很大的差异。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能体描述与信息组织&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在协议设计中，一个智能体如何对另外一个智能体暴露其信息，是一个关键的问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能体描述方面，A2A 使用了一个名为 Agent Card 的 JSON 格式的文档，用于描述智能体的能力、技能、身份认证方法等，Agent Card 的核心是技能（skill），表达智能体能够干什么事情，比如能够进行地图路径规划等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ANP 也是用的 JSON，不过基于 JSON-LD（&lt;/span&gt;&lt;span&gt;Linked Data&lt;/span&gt;&lt;span&gt;）和 schema.org 描述智能体信息（基本信息、身份验证、对外产品/服务、交互 Interface），这是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;语义网&lt;/span&gt;&lt;span&gt;的技术，目的是提高两个智能体对信息理解的一致性，以及让智能体的公开信息能够链接成一个数据网络，智能体描述文件是网络的入口：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="374" src="https://oscimg.oschina.net/oscnet/up-d01d5d7307d80461908b85ccbf5bf33a731.png" width="866" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，一个酒店智能体，使用 ANP，可以将酒店的房间、设施、服务、交互接口等信息（包括图片）描述出来，并且链接成一个数据网络，让其他智能体能够爬取并且理解。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这也导致，在智能体的交互上，A2A 与 ANP 有非常大的差异：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;A2A 通过 Agent Card 描述智能体的技能（skills），其他智能体获取 skills，然后通过 JSON-RPC 发送一个任务请求，任务使用自然语言描述，并且携带任务需要的相关信息。任务完成后返回结果。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="899" src="https://oscimg.oschina.net/oscnet/up-6520f035e7c07da9e2c01587383e4349789.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;ANP 则是通过智能体描述文档（Agent Description），将智能体对外提供的产品、服务、交互接口等信息用 URL 连接到一起，另外一个智能体像一个网络爬虫，通过 URL 不断的爬取自己需要的信息。这个过程中可以通过自然语言接口与智能体进行交互，也可以通过结构化接口与智能体进行交互。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1037" src="https://oscimg.oschina.net/oscnet/up-6b28fc14add696a2b8229dff90d88f23df6.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这里的核心差异：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;A2A 是智能体对外公开自己的技能，另外一个智能体发送处理任务过来，处理完成后返回结果。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;ANP 是智能体对外公开自己信息（包含交互接口），其他智能体爬取信息进行处理，必要的时候通过自然语言接口或结构化接口与智能体进行交互&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能体发现&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能体的发现上 A2A 的方案和 ANP 基本是一样的，都是在域名的.well-known 目录下增加一个元数据文档，A2A 的文件名是 agent.json，ANP 的文件名是 agent-descriptions。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同时也都支持智能体主动注册到私有注册表，这个在局域网中的协作是非常有必要的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不同的地方在于，A2A 是直接将 Agent Card 内容放到.well-known/agent.json 中，而 ANP 则是在.well-known/agent-descriptions 中存放智能体描述文件的 URL。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 目前看起来是一个域名一个 Agent Card（还要进一步确认），ANP 则是一个域名可以有很多个智能体。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;身份验证&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在身份验证上，A2A 和 ANP 有所不同。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 智能体在 A2A 协议中并不交换身份信息。相反，它们通过带外方式获取认证材料（如 token），并通过 HTTP 头部传递这些材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;所谓的带外，是指通过 A2A 之外的其他协议获取认证材料。A2A 遵循 OpenAPI 的身份认证规范进行身份认证，支持包括 HTTP Basic Auth、API Key、OAuth 2.0 等多种认证方式，具体由每个智能体在其 Agent Card 中声明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="480" src="https://oscimg.oschina.net/oscnet/up-d447565d2bd93d80f90c7ecb282f4ef5cc6.png" width="852" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 则基于 W3C DID 技术构建去中心化的身份认证，在协议中直接携带身份信息，包括身份验证信息。智能体使用自己的身份就能够和其他所有的智能体进行交互，不需要带外获得身份验证材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不过，在某些场景中，带外获取身份验证材料是必要的，特别是在企业级应用中。ANP 未来会支持带外身份验证材料的获取，设计上预留了扩展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b3dfb6efb5e2de6b145ed311e0f9e726f08.png" width="948" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差异：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 采用带外获取身份验证材料，是为了最大程度兼容美国主流企业应用生态的安全合规要求，复用现有的企业身份认证体系，确保协议本身轻量、灵活且安全。核心是为了解决企业级应用的身份问题，并且没有解决互联网上智能体互联互通的身份问题。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 则是未来解决智能体在互联网上如何进行身份认证的问题，核心是让互联网上任意两个智能体都能够互联互通，这需要一个互操作性更好的身份认证方案。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;核心概念&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 与 ANP 在协议的核心概念上有很大差异。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;A2A 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括 Skill（技能）、Task（任务）、Artifact（产物）、Message（消息）、Part（部分）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同时，Task 又定义了多种状态，包括：submitted（已提交）、working（处理中）、input-required（需要输入）、completed（完成）、canceled（取消）、failed（失败）、unknown（未知）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Task 也定义了一些操作，包括：Send（发送）、Get（获取）、Cancel（取消）等，以及一些通知相关的操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;ANP 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括描述信息与接口（Interface）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;描述信息主要是 JSON-LD 格式的文档，以及 JSON-LD 文档中通过 URL 链接到的其他资源，包括图片、音频、视频等多媒体文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Interface 又分为自然语言接口（Natural Language Interface）和结构化接口（Structured Interface）。结构化接口支持现有大部分的规范，比如 OpenAPI、JSON-RPC 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差异：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 在协议层面定义了详细的任务协作概念，包括任务的状态、操作等，这有助于解决智能体之间复杂任务的协作问题。缺点是会导致两个智能体之间的耦合度较高。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 简化了智能体之间的交互，降低了智能体之间的耦合度，在跨平台的智能体协作场景下有较大的优势。缺点是原生协议不支持复杂任务协作，需要自己定义 Interface 来实现。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;A2A 与 ANP 的原点&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;要想真正的理解一个协议的设计，必须找到这个协议的原点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，ANP 的原点一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;智能体在互联网上的连接与协作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。MCP 的原点一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;模型与工具、资源的连接&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，构建更好的智能体。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;通过上面的技术分析，我们可以确认 A2A 的原点是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;企业内部智能体之间的复杂协作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;协议的官网并没有明确的说出这一点，但是谷歌的新闻发布稿中有提到过一些：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;AI 智能体为人们带来了独特的机会，能够通过自主处理许多日常重复性或复杂任务，帮助提升工作效率。如今，企业越来越多地构建并部署自主智能体，以帮助在整个工作场景中实现规模化、自动化并优化各类流程——从订购新笔记本电脑，到辅助客户服务代表，再到协助供应链规划。（https://developers.googleblog.com/en/a2a&lt;/span&gt;&lt;span&gt;&lt;span&gt;-a&lt;/span&gt;&lt;/span&gt;&lt;span&gt;-new-era-of-agent-interoperability/）&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;从 A2A 生态企业的分布也大概可以看出这一点，大部分都是 AI 平台与服务、软件、SaaS 和企业平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-2defdfdfeb005bbfae4fe07af3e72afe1a4.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="693" src="https://oscimg.oschina.net/oscnet/up-8026f8e9b8cc4e73963d2737dd793f74d30.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;从技术上看，目前&lt;strong&gt;A2A 的实现也不大适合智能体互联网的需求&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;以个人助手使用 A2A 去酒店智能体预订房间为例，按照目前 A2A 的实现，个人助手需要发送一个任务，用自然语言描述用户的要求（价格、房型、时间等）信息，酒店智能体处理后返回任务执行信息。在中间可能要经过多次的任务交互、任务状态的迁移等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这会有两个问题：一个是用户的隐私可能会被泄露，因为个人助手要将任务发送给另外一个智能体执行；另外一个就是交互耦合度过高。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 的逻辑则是个人助手爬取酒店智能体的信息在本地进行处理，需要交互的时候才调用酒店智能体的接口。这是本质的区别。当然，除此之外 A2A 还有智能体在互联网上的身份互联互通问题没有解决。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不过，&lt;strong&gt;也不排除未来 A2A 通过协议升级扩展到智能体互联网的场景&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;未来智能体协议的一些预判&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;短期内 MCP 成为模型连接工具和资源的事实标准，这个基本上已经确定，目前很难有第二个 MCP 出现。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;中长期来看，我认为有一个趋势大概率会发生：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;工具智能体化，智能体工具化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果这个趋势发生，那么智能体协议会挤压 MCP 的空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;更长期来看，AGI 实现后，也许人类设计的协议是 AI 的束缚而非助力，AI 有办法自己设计协议并达成共识。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不过，在当下智能体协议是非常重要的，它是智能体的重要拼图，也是智能体与互联网交互最 AI 原生的方式，是比 Computer Use、Browser Use，甚至 AI 浏览器都更高效的连接方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;无论如何，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;ANP 最有价值的部分，是社区对未来智能体互联网的设想，是社区独特的互联网理念（连接即权力），以及 DID+语义网的技术路线。这是支撑 ANP 走下去的核心动力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;关于创新&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 出来之后看着"炸裂、一夜变天、颠覆"这些标题心情复杂，特别是我们做 ANP 做了一年，也推广了很长时间。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们都在说，我们需要"0 到 1"的创新——我们不单需要创新者，也需要媒体能够去发现这些创新者。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;最后感谢开源社区的每一位贡献者和开发者，现在已经有 40 多位开发者了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;也感谢公众号、社区对我们的支持，包括 RTE 开发者社区、OSC 开源社区、&lt;/span&gt;&lt;span&gt;Founder Park&lt;/span&gt;&lt;span&gt;、觉察流、侯宏文存、AIGCLink、智能体 AI 等等（可能不全），还有很多给我们提供分享机会的组织，以及为社区提供服务器资源的 AWS 和阿里云。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;最后&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;如果你也认可我们的理念，认可我们对未来智能体互联网的设想，欢迎加入我们，无论是以个人，还是以公司名义，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;我们需要你的支持&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们正在筹备 ANP 开源技术社区创始委员会，这是一个临时委员会，目的是为了让社区能够走向正轨，成长为一个更加开放的社区。感兴趣可以联系我。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;联系方式：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;开源项目 GitHub：https://github.com/agent-network-protocol/AgentNetworkProtocol&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;Discord: https://discord.gg/sFjBKTY7sB&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;官网：https://agent-network-protocol.com/&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;微信：flow10240&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9297178/blog/18398047</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9297178/blog/18398047</guid>
      <pubDate>Fri, 16 May 2025 05:07:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>NebulaGraph 图数据库开源六周年</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-347a643f66a66a9edf9d5760c1e8d2f4686.png" referrerpolicy="no-referrer"&gt;&lt;/strong&gt;&lt;/strong&gt;‍‍&lt;/p&gt; 
&lt;p&gt;2025 年 5 月 15 日，NebulaGraph 迎来开源六周年的里程碑。作为国产开源图数据库的标杆项目，回望 NebulaGraph 的六年发展历程，不仅是一部技术迭代的编年史，更是中国开源社区在全球基础软件领域崛起的缩影。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、诞生：在数据关系的浪潮中扬帆起航&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 8 月 31 日， @Sherman-the-tank 在 nebula 仓库中提出第一个 issue ‘Create a parser framework to process GQL.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 9 月 5 日， @dutor 提交了第一个 PR ‘Added some concurrent utilities, GenericThreadPool, etc.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph PMC Sherman Ye 曾参与多个分布式数据库研发工作，当社交网络爆发式增长，引发数据关系挖掘需求井喷时，他敏锐地意识到：图数据库是表示和理解关系最天然的工具，然而当时的图数据库或受限於单机性能，或困于扩展性不足，难以承载千亿节点、万亿边级的超大规模数据。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我们必须打造一款开源的、分布式的、支持线性扩容的世界级图数据库，能够容纳千亿顶点和万亿边。&lt;/strong&gt;」Sherman 的愿景，从一开始就超越了代码本身。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-4e970720b415322cc5254ac4b46dd587181.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 诞生于一间小公寓，初期核心团队在这里办公）&lt;/p&gt; 
&lt;p&gt;NebulaGraph 采用 Shared-Nothing 架构与存储计算分离设计，为 NebulaGraph 注入了宇宙级的基因——每个节点独立处理数据，如同星云中的星辰，既自由又协调；存储与计算分离，则让扩容像星云膨胀般自然。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我们写下 NebulaGraph 第一行代码时，就认识到它必须是一款开源的图数据库&lt;/strong&gt;。」不忘开源初心，八个月后，NebulaGraph 遵循 Apache 2.0 开源协议，在 GitHub 开源 alpha 版本，从此开启了突破国产图数据库技术的星辰大海征程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a9d672008ac303c7c9a6d86aa9b3c44aa2e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（一张开源纪念截图）&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、应用：在产业实践的土壤中扎根&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 10 月 29 日，携程云原生技术总监周昕毅先生在上海 nMeetup 上充分肯定了 NebulaGraph 作为开源解决方案在企业中的应用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用户的选择是最好的背书。六年来，NebulaGraph 用户覆盖金融、互联网、通信、电商、保险、安全等多个行业。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d2338012c10f02d334d817be194af6c777f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 部分用户）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;携程集团已有包括酒店、机票、金融在内的 16 个部门使用 NebulaGraph, 在风控场景，构建了实时图特征平台的应用逻辑闭环，额外获取了 55% 的关联业务信息，使得该场景下的覆盖率提升了 32%&amp;nbsp;；奇富科技打造了智能化的金融反欺诈系统系统，累计报送涉骗阻断预警 59 万次，拦截潜在被骗者 9.5 万人，帮助用户避免损失 11.35 亿元；OPPO 从 JanusGraph 切换到 NebulaGraph 后，导入性能提升了 10 倍，且查询性能以及并发能力都有 3-6 倍的提升。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;NebulaGraph 是开源项目，用户在真实使用场景中，为解决业务需求，会自然地参与共建，这种集体智慧加快了 NebulaGraph 的迭代：企查查贡献了 Node 客户端，奇富科技阿旺把自己做的 nebula-console-intellij-plugin 捐给了社区，笃笃科技大叶开发了 NebulaGraph 图数据库客户端星影 StarShadow.&lt;/p&gt; 
&lt;p&gt;一幅技术扎根产业、需求反哺产品的共生图景已然成形。这正是 NebulaGraph 在真实商业土壤中向下扎根、向上生长的最佳注脚。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、生态：在开源共治的生态中繁荣&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 3 月，NebulaGraph 在 GitHub star 数突破 10,000 大关&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph 社区构建了一套自由且开放的「双轨成长体系」：开发者（Dev Group）聚焦代码贡献，用户（User Group）专注实践传播。细分来看，还有学习者、布道师、文档贡献者等角色，每种角色都能拥有自己的话语权，找到自己的存在价值，他们不会被统一地转化成某一类角色，他们被允许以某一种角色停留在社区里，比如仅仅作为用户，或者仅仅作为一次性的代码贡献者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-4781abc41f59cc55d7d129c6444f502e901.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph Community 成长体系）&lt;/p&gt; 
&lt;p&gt;作为开源项目，我们始终重视代码共建共享。连续 5 年参与中国科学院软件研究所发起的开源之夏，鼓励全球高校开发者参与开源贡献，为社区注入新鲜血液；举办 NebulaGraph Hackthon，设立 150,000 奖金池，从内核到周边，让广大图数据库及 NebulaGraph 爱好者尽情探索图世界。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a5cadecf20779c82bcf80c9e7896d7e77cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（来自开发者的认可）&lt;/p&gt; 
&lt;p&gt;线下活动同样精彩纷呈。从 NUC 2021、2022，到足迹遍布全国的 nMeetup，我们珍惜每次与用户、开发者面对面交流的机会。也许大家素未谋面，但因为同在 NebulaGraph 社区，见证了万星开源项目的崛起，每次线下探索图数据库的世界都能像老朋友一样碰撞出思维的火花和久违的默契。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-9d32d3464c875255314f68fc03f7487fc59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（社区可爱的小伙伴们）&lt;/p&gt; 
&lt;p&gt;我们始终以包容的姿态，让每个社区参与者的独特贡献汇聚成生态繁荣的星河。&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、未来：在云与 AI 的浪潮中领航&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph Cloud&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2020 年，NebulaGraph 决定打造云产品&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;NebulaGraph 从诞生之初起，不仅坚定走开源路线，还坚持云原生理念。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如今，NebulaGraph Cloud 作为一套集成了 NebulaGraph 数据库和数据服务的云上服务，支持一键部署 NebulaGraph 和相关可视化产品。用户可以在几分钟内创建一个图数据库，并快速扩展计算、存储等资源，无需在本地搭建和维护复杂的图数据库基础设施，从而能够更加专注于核心业务的发展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-0f3996764f2cbb028787d68755889da4bdc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 控制枱界面）&lt;/p&gt; 
&lt;p&gt;NebulaGraph Cloud 除了在 AWS 上提供全托管服务，还计划全面支持 Azure 和 Google Cloud Platform (GCP) 等主流公有云厂商，企业可够根据自身需求和业务场景，选择最适合的云厂商。&lt;/p&gt; 
&lt;p&gt;申请试用⬇️&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.nebula-graph.io%2Flogin" target="_blank"&gt;https://cloud.nebula-graph.io/login&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph AI 应用平台&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2023 年 8 月 16 日，@wey-gu 与 LlamaIndex 联合发布 GraphRAG.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;正如 NebulaGraph 诞生之初，我们又一次站在高处看未来——洞察到图结构在知识处理中的革命性潜力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2023 年 8 月，在 RAG 技术还未被称为 RAG，而是上下文学习方法的时候，我们就意识到以图的方式处理知识会对解决「大海捞针」等特定问题有很大帮助，因此&amp;nbsp;@wey-gu 提出了将图数据库与 RAG 结合的想法，向 LlamaIndex 提了第一个 PR，将 KG-RAG 转变为 GraphRAG.&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-94fd0e2ef4e5265750786d1f60e9423f893.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph GenAI Team Leader @wey-gu）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GraphRAG 仅仅是 NebulaGraph 探索 GenAI 的「第一步」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随后，我们和 Researcher: Diego 一起讨论，做了图索引之上 Chain of Exploration 的工作，这种探索链不仅可以帮助 Agent 理解图谱，还能从非结构化数据中提取出半结构化的知识图谱‌。&lt;/p&gt; 
&lt;p&gt;在一系列 Graph based RAG 的落地实践中，GenAI Team 又一次突破技术边界，提出了 Fusion GraphRAG：融合了高级 RAG 技术，通过图状结构存储文档层级、章节关系及特殊元素（如公式、表格），实现高效、灵活的检索。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-b04608e8eedc97b778355eed434fc9280f4.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（Fusion GraphRAG 是更高级的 RAG 技术）&lt;/p&gt; 
&lt;p&gt;但不止于此，NebulaGraph 把视角转向企业级应用，基于 FusionGraphRAG 与 Agentic RAG 技术，打造了一个全新的高级知识库与低门槛应用平台 —— NebulaGraph AI 应用平台（内部命名为 「Catalyst」，即催化剂），无需构建复杂 Workflow 和编写繁琐 Prompt，更智能地激活与应用企业内部知识。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-2cbc7e0b1c9bf670db137f17cbee8b6f5dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（用户只需将对私有知识的理解转化为对不同「知识篮子」的定义）&lt;/p&gt; 
&lt;p&gt;从 GraphRAG 到 NebulaGraph AI 应用平台，我们始终相信：真正的技术革命，不在于创造更复杂的工具，而在于让复杂技术变得触手可及。当每个企业都能像调配催化剂一样轻松激活知识资产，我们离智能时代的真正到来，便又近了一步。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;六周年快乐🎉&lt;/h1&gt; 
&lt;p&gt;六载春秋，NebulaGraph 从一颗种子长成参天大树，其根系已深入全球开发者土壤，枝叶则伸向云与 AI 的星辰大海。NebulaGraph 的开源历程，证明了通过开源共治，我们能打造出一款世界一流的图数据库产品，更证明了这群活跃在开源社区的极客，有着无限的探索精神和创新能力。&lt;/p&gt; 
&lt;p&gt;因为开源，这场图数据库技术革命，没有终点，只有新的起点。&lt;/p&gt; 
&lt;p&gt;因为有你，这场开源协作的星辰征途，没有孤岛，只有携手同行的辽阔未来。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;开源最大的意义，莫过于代码开放，共建共享，以用户/开发者的力量推动产品迭代。&lt;/p&gt; 
&lt;p&gt;陪伴 NebulaGraph 共同成长的你，是使 NebulaGraph 愈发闪耀的星光。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-98d9a5b4f678bcb55a625b31b4cefe5e359.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.nebula-graph.com.cn%2Ft%2Ftopic%2F16781" target="_blank"&gt;在 NebulaGraph 论坛&lt;/a&gt;&amp;nbsp;分享你与 NebulaGraph 的故事，让更多小伙伴感受到开源的力量。（分享即送星云仔 T 恤，点赞 top3 可获得全套社区周边）&lt;/p&gt; 
&lt;p&gt;六月，NebulaGraph 社区将在北京举办 nMeetup，欢迎扫码提交议题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" height="100" src="https://oscimg.oschina.net/oscnet/up-780ef5d7632ee90c872ab50c1333b6c1ddc.png" width="100" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;‍&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;如果你觉得 NebulaGraph 能帮到你，或者你只是单纯支持开源精神，可以在 GitHub 上为 NebulaGraph 点个 Star！每一个 Star 都是对我们的支持和鼓励✨&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvesoft-inc%2Fnebula" target="_blank"&gt;https://github.com/vesoft-inc/nebula&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4169309/blog/18403236</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4169309/blog/18403236</guid>
      <pubDate>Fri, 16 May 2025 03:53:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Hugging Face 牵头推动 Transformers 库模型架构标准化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Ftransformers-model-definition" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;联合多家机构推动将&lt;code&gt;transformers&lt;/code&gt;库作为模型架构标准，提升 AI 生态兼容性。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1238" src="https://static.oschina.net/uploads/space/2025/0516/114028_tsZR_2720166.png" width="1718" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Hugging Face 表示正与 vLLM、LlamaCPP、SGLang、Mlx、Qwen、Glm、Unsloth、Axoloth、Deepspeed、IBM、Gemma、Llama、Deepseek、Microsoft、Nvidia、InternLM、Llava、AllenAI、Cohere、TogetherAI 等众多生态系统参与者共同努力，将&amp;nbsp;&lt;code&gt;transformers&lt;/code&gt;&amp;nbsp;库中的模型定义代码作为标准，旨在为所有模型提供一个统一的真实来源。&lt;/p&gt; 
&lt;p&gt;Hugging Face 目前正在与最流行的推理引擎（vLLM、SGLang、TGI、...）紧密合作，让它们使用&lt;code&gt;transformers&lt;/code&gt;作为后端：只要模型被添加到&lt;code&gt;transformers&lt;/code&gt;，便支持在这些推理引擎中使用，同时利用每个引擎的优势：推理优化、专用内核、动态批处理等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-dc6ac94d98590b08d7bb511a05cf4e82e7e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这项联合工作将极大地提高不同模型架构在整个 AI 生态系统中的兼容性和互操作性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350188/huggingface-transformers-model-definition</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350188/huggingface-transformers-model-definition</guid>
      <pubDate>Fri, 16 May 2025 03:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>得物自研 DSearch3.0 搜索核心引擎升级之路</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;&lt;span&gt;&lt;strong&gt;一、背景&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p style="text-align: left"&gt;&lt;span&gt;随着交易和社区搜索业务稳步快跑，基建侧引擎越来越复杂，之前搜索底层索引查询结构已经存在较为严重的性能瓶颈。成本和运维难度越来越高。在开发效率上和引擎的稳定性上，也暴露出了很多需要解决的运维稳定性和开发效率短板。而在引擎的业务层部分也需要逐步升级，来解决当前引擎中召回层和业务层中各个模块强耦合，难维护，迭代效率低下等问题。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/de1274b479a3468eb2c8c9732f943b6d~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=yG8v2qkQHq9NYLqIZ%2Bfln4tsbMw%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;h1 style="text-align: left" class="pgc-p"&gt;&lt;span&gt;&lt;strong&gt;二、引擎开发技术方案&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;h2 style="text-align: left" class="pgc-p"&gt;&lt;span&gt;&lt;strong&gt;DSearch1.0 索引层整体结构&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;DSearch1.0 的索引结构比较特殊一些，总体上使用了全局 rcu 的设计思想，整体架构上单写多读，所以实现了并发高性能无锁读，内部数据结构都是无锁数据结构，所以查询性能高。在写操作上因为 rcu 机制实现写入无锁。整体上优点读性能高，没有传统段合并操作带来的磁盘抖动。缺点是索引地址和操作系统强相关，运维复杂，热更新受限。全局地址分配难以并行写入，构建瓶颈明显。无法对浪费的内存进行回收导致内存空间利用率低，索引空间占用大。总体结构如图所示：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/90b13bdb5afb4c739e88babf772c494b~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=sBcaXhhCtFSFO6CLTcQ7Ldypf5o%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;h2 style="text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch2.0 的索引升级&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch2.0 分段索引整体设计&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;引擎 2.0 索引升级采用经典段合并架构，除了继承了段合并中优异的高性能写入性能和查询已经索引合并等优势外，针对段合并中频繁的正排字段更新等带来的高 IO 缺点。我们设计了新的正排字段原地更新索引，使新的 DSearch2.0 引擎拥有 Redis 的高性能写入和查询，也拥有 lucene 的紧凑索引和索引合并带来的内存空间节省的优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 索引段结构&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每个索引段包含了文档文件，用于紧凑存放 document 中的各个字段的详细信息。字符串池文件是对 document 中所有的字符串进行统一顺序存储，同时&lt;strong&gt;对字符串进行 ID 化&lt;/strong&gt;，每个字符串 ID 就是对应于字符串池中的&lt;strong&gt;offset 偏移&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;可变数组文件是专门存放数组类型的数据，紧凑型连续存放，当字段更新的时候采用文件追加 append 进行写。最终内存回收通过段&lt;strong&gt;之间的 compaction 进行&lt;/strong&gt;。FST 索引文件是专门存放 document 中全部字符串索引。每个 fst 的 node 节点存放了该字符串在字符串池中的偏移 offset。而通过字符串的 offset，能够快速在倒排 termoffset 数组上二分查找定位到 term 的倒排链。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;倒排文件是专门存放倒排 docid，词频信息、位置信息等倒排信息，其中 docid 倒排链数据结构会根据生成段的时候计算 docid 和总 doc 数的密度来做具体判断，&lt;strong&gt;如果密度高于一定阈值就会使用 bitmap 数据结构，如果小于一定阈值会使用 array 的数据结构&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;标记删除 delete 链主要是用于记录段中被删除的 document，删除操作是软删除，在最后查询逻辑操作的时候进行最后的过滤。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;实时增量的 trie 树结构，实时增量段中的前缀检索和静态段中的前缀检索数据结构不一样，trie 因为能够进行实时更新所以在内存中使用 trie 树。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;段中的 metadata 文件，metadata 文件是记录每个段中的核心数据的地方，主要记录段内 doc 数量，段内 delete 文档比例，实时段的 metadata 会记录 kafka 的 offset 等核心数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/24c940a2b35e4d15a162fe3ebf200d0f~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2BYmQsxTR%2FExv2AC40UdCJ0azAwA%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;Document 文档和索引结构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ Document 文档数据结构&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;Document 文档使用紧凑型存储，其中 array 和字符串类型单独存放，其他字段连续存放，string 和 array 字段存放。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;array 字段类型数据直接存放在可变数组文件区，连续追加写。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;string 字符串池对所有字符串进行连续存放，多个 doc 中同一个字符串引用同一个字符串地址，节省大量字符串存放空间。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 倒排索引文件结构&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;倒排索引文件存放 docid 倒排和 Tf 以及位置 position 数据。其中内存实时段中的倒排索引数据结构是固定一种类型 array 类型。而内存实时段固化为静态段的时候，倒排数据结构会根据 docid 中的密度进行选择 array 和 bitmap 存储。当 docid 密度大于一定阈值是 bitmap，反之是 array 结构。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;Tf 数据结构是一个 uint16 的数组，数组长度和 docid 的数组长度一致，所以当确定了某个 docid 时候，也随即确定了它的 tf 信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;postion 信息存储是一个二维数组的格式，第一层数组存放的是对应于 term 的在字符串池的 offset，因为 term 在字符串池中已经 ID 化，所以 offset 可以表示唯一 term。第二层数组是该 term 在字段中多次出现的位置，使用 uint16 存储。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 前缀检索文件&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;FST 静态段文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;a. 静态段中前缀是 fst 的数据结构，因为 fst 一旦建立是不能够进行修改的，所以在段合并的时候需要对所有 term 进行排序然后再构建 fst 结构。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;b. fst 的 node 节点存放了对应于 term 的字符串池的 offset。当需要查询一个 term 的倒排结构时候，需要先查询该 term 的字符串池的 offset，然后拿该 offset 去倒排的 termoffset 文件中二分查找找到对应的倒排 positionlist 结构拿到对应倒排。所以一次 term 到倒排的查询需要查询一次 fst+一次二分查询。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;c. term 到倒排的查询一次 fst+一次二分查找效率不高，所以针对 term 到倒排查询，新增了第二种 HashMap 索引，直接通过 term 到倒排的 offset 索引，这个选项在建表的时候可以配置。&lt;/span&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;实时段 RcuTrie 树索引&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;a. 实时段中需要支持边写边读，前缀检索需要支持并发读写。引擎中 trie 树是 rcu 实现，单线程更新，多线程并发读，trie 树写更新节点内存延迟回收。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/1a4ee53847174e60b8ac7df104a5d5b6~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=HOQHf%2Fr42ewivfi%2BZbf2pws0nLo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;倒排索引和查询树逻辑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 倒排链优化&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;DSearch1.0 的 roaringbimap 倒排索引在低密度数据量上存在一些瓶颈，比如对于倒排链比较短的情况下，roaringbitmap 的 container 大部分都是 array 结构，在倒排链查询和合并都会进行一次二分查找，在大面积的倒排链合并中是个相当大的性能瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;针对上面所说的情况对 roaringbitmap 进行了精简，只存 array 或者 bitmap 合并的时候不需要查找，直接链式合并。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 逻辑树合并优化&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;DSearch2.0 重点从逻辑语法树和倒排入手，优化语法树，减少合并树高，从二叉树合并变成单层合并。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;优化倒排链合并方式，采用原地倒排链合并，消除倒排合并临时对象，同时引入多线程并行合并，减少长尾提高性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a324c1263d7045f6a4346f99c7f97124~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=DxtCm2sohwPSMuxM%2Flr5%2BTSP4kg%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;增量更新逻辑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 增量实时写入逻辑&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;引擎支持多个并发实时段，这个由配置文件通过配置来进行配置。多个实时段能够提升并发写入的性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每个实时段对应一个写入队列，提高并发写入吞吐。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每个段真实写入一条信息会同步原子更新消费的 kafka 的 offset，用于对后面进程重启等恢复数据做准备。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;当进程重启或者异常退出时候，会读取 metadata 文件中的最后一条 kafka offset 进行重新消费增量在内存中重新构建新的正排、文档和倒排等信息，完成数据的恢复。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/4a6eba83cdd74c1587d9aa76bf35ddbd~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=okNAsDWIX8ozfo9pqhZbj2DF39Q%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;实时段固化和段合并策略&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 实时段固化逻辑：&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;当实时段内随着增量写，doc 文件大小超过 128M 时候会进行内存实时段固化操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;固化操作开始时，会先生成新的内存实时段，老的内存实时段会变成只读内存段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;遍历按整个只读内存段，构建新的索引和新的正排结构生成新的静态段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 段合并策略：&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;实时段固化的小静态段因为大小比较小，会优先和之前固化后的小段进行合并，按照 1，2，4，8 进行合并，逐步合并成静态段最大的上限。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;静态段的合并触发策略是当静态段中 delete 的 doc 比例超过了 30% 会触发静态段之间的合并，合并会按照近邻合并原则，从左右近邻中选取一个最小 doc 数的段进行合并，进而新生成一个新的段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/08582c715cbd47d0b298435e57bac25f~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=40FqkO626yUPY%2BI3uTtsbA1Ihwo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;查询和更新中的并发控制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 查询流程&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;引擎查询时候，先遍历查询实时段，然后再查询静态段。实时段查询存在最大增量查询截断，当实时段查询到最大增量截断时实时段停止查询。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;实时段查询后，查询静态段。静态段中包含了全量构建索引的全量最大 offset 记录同时全量的 doc 是通过质量分进行排序，所以在全量段查询的时候，先遍历质量分最大的全量段，逐步往后面静态段查询，直到查询到全量截断。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;实时段查询和静态段查询结果进行 merge 作为最终的查询结果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 更新并发控制&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;因为 DSearch2.0 的索引更新是直接在实时段或者静态段进行更新，所以存在多线程读写问题。尤其是正排字段更新写入量大更新频繁。同时更新涉及到所有的实时段和静态段，较为复杂。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;为了解决正排字段和倒排的更新问题，新版本引擎引入了 document 文档锁池，对每个 doc 进行 hash 计算落到锁池中具体一个锁上来减少锁冲突，当前锁池内有多个个文档锁。文档锁在文档进行拷贝和更新的时候会进行锁住。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch3.0 搜索核心升级&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;异步非阻塞图调度框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7e1821341e54416a99384f4ae1016048~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=Ugikrdj%2Fc%2FMZkAFTUtc7L9JVcG0%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="color: rgb(62, 62, 62)"&gt;&lt;strong&gt;图框架支持 RPC 异步非阻塞请求：&lt;/strong&gt;&lt;/span&gt;&lt;span style="font-size: 0.882em"&gt;引擎图框架 RpcServer 服务使用 brpc 的异步处理无需同步阻塞等待调度完成，只需框架调度完算子返回结果，不阻塞 RpcServer 线程，例如：当前引擎调用 neuron 服务是同步调用，当 neuron 服务负载高阻塞时，同步调用会导致拖住引擎 RpcServer 处理线程，新的异步非阻塞模式引擎 client 在调用引擎后已经返回，等待引擎 RpcServer 中异步调度框架中 remote 异步算子回调，减少外部服务影响引擎。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;减少线程切换：&lt;/strong&gt;图框架调度器会优先调度当前运行线程，同时使用 M:N 类型的 bthread 线程池，线程切换会更小，执行效率高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;RPC 服务和框架算子独立：&lt;/strong&gt;引擎 RPC 服务和框架算子完全解耦，跨集群部署算子服务无需任何改造，实现算子脱离运行环境。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;高效的算子异常处理和超时机制：&lt;/strong&gt;每个算子维护自己的运行超时时间和请求到算子调度执行的超时时间，对整个请求流程中各算子执行更加精准。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;动态图支持：&lt;/strong&gt;图框架支持静态图和动态图业务组合式调用。支持静态子图和动态子图调用等复杂业务组合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;复杂子图支持：&lt;/strong&gt;图框架支持嵌套子图，支持自调用模型，可以实现复杂单节点多功能调用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;算子间数据交换 Table 设计&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3bf931610dd74d5da3be98d3395310ab~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=n4lk8KDSCTKVPt6uIgyIxo9v%2FPw%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;列式数据共享优化：&lt;/strong&gt;算子交换数据全部存放在 Table 列中，Table 中全部共享列式数据，省去大面积数据拷贝，大幅提升引擎业务执行性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;兼容引擎索引中 doc 数据：&lt;/strong&gt;引擎索引中 doc 行式存储有很多优点，比如多字段访问效率高等，Table 设计中考虑了行式存储优点，不仅存高频的列字段也储存了引擎内部的 doc*以及对应 FieldDef*，能直接方便访问索引数据，接口统一，易于迭代。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;打通 FlatBuffer 序列化协议：&lt;/strong&gt;当前引擎 FlatBuffer 序列化传输协议和引擎内部数据出口需要多次遍历转换，需要拷贝很多数据，新 Table 的设计内部数据列和 FlatBuffer 内部的数据列互转互通，节省大量内部拷贝同时避免了字段兼容等问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;支持原地排序和标记删除：&lt;/strong&gt;Table 数据表，支持原地 sort 操作和标记删除操作，节省数据排序时大量数据的拷贝和删除操作中导致的数据重排等拷贝操作，提升性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;算子间数据交换 Table 设计&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a96224208f0d46f2b9abffe520367ac1~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=zR%2B1sBPOMWcKSWcnoqSS3HtpR%2Bo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;动态图支持：&lt;/strong&gt;DSsearch3.0 支持动态图编排，主要通过业务方通过动态编排请求来组织对应的算子编排逻辑，实现业务方自主编排调度逻辑，方便整体业务开发。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;Remote 远程调用支持：&lt;/strong&gt;通过开发远程异步调用算子，支持 DSearch3.0 跨集群调用，实现多机算子化互联互通。提高引擎的整体纵向拓展能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;引擎算子库复用：&lt;/strong&gt;通过设计统一的算子接口，开发基础的可复用框架算子，支持配置化组合运行图，实现业务逻辑快速复用和开发，提高整体引擎开发效率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;三、性能和效果提升&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;DSearch 在 2024 年 Q1 季度索引升级开发完成后逐步推全到交易和社区等各个主场景业务中，最后拿到了很多超预期结果：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;索引内存优化超出预期：&lt;/strong&gt;社区搜索和交易搜索总索引单分片优化 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;构建和写入性能优化超出预期：&lt;/strong&gt;社区搜索和交易搜索主表写入性能提升 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;索引更新优化超预期：&lt;/strong&gt;社区和交易主表更新时间提升接近 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;性能优化符合预期：&lt;/strong&gt;社区搜索平均 rt 降低一倍，P99 晚高峰降低 2 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;四、总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;DSearch 引擎从开始的 DSearch1.0 的搜索引擎逐步经历了 DSearch2.0 的分段式索引改造升级，又经历了 DSearch3.0 的全图化引擎升级。逐步将 DSearch 引擎升级到业界较为领先的支持内存型、磁盘型多段式搜索引擎，为支持得物业务的发展做出了重要的贡献，后续 DSearch 会围绕着通用化、自迭代、高性能等多个方向继续升级，将 DSearch 引擎迭代到业界领先的引擎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;算法团队大量 HC，欢迎加入我们：&lt;/strong&gt;得物技术大量算法岗位多地上线，「职」等你来！&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;1. 以细节诠释专业，用成长定义价值——对话@孟同学 ｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;2. 最近爆火的 MCP 究竟有多大魅力？MCP 开发初体验｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;3. 得物可观测平台架构升级：基于 GreptimeDB 的全新监控体系实践&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;4. 得物自研 DGraph4.0 推荐核心引擎升级之路&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;5. 大语言模型的训练后量化算法综述 | 得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;文 / 苏黎&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;关注得物技术，每周更新技术干货&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18387813</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18387813</guid>
      <pubDate>Fri, 16 May 2025 03:36:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Dify.AI 开源两周年更新品牌形象，坚持「让每一个想法变成 AI Agent」的使命</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源 AI 应用开发平台 Dify.AI &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdify.ai%2Fblog%2Four-vision-takes-shape-imagine-if" target="_blank"&gt;迎来了两周年&lt;/a&gt;。在庆祝之际，Dify 发布了全新的品牌形象和外观。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/111845_qi60_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a96b9b86bb6e4f0894313ba038203e4ef27.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Dify 的使命保持不变，即让每一个想法都能变成 AI Agent。新的品牌口号强调&lt;strong&gt;「如果」你能想到，通过 Dify 你就能构建它&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/111557_HOat_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350181</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350181</guid>
      <pubDate>Fri, 16 May 2025 03:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>2030 年我国数据产业规模将达 7.5 万亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;2025 数据安全发展大会上介绍，我国将培育壮大一批数据要素产业链上下游企业，预计到 2030 年，我国数据产业规模将达到 7.5 万亿元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作为全球首个将数据纳入生产要素的国家，我国已初步构建起门类齐全的数据产业链。数据显示，2024 年我国年度数据生产总量达 41.06 泽字节，同比增长 25%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;截至目前，我国数据领域相关企业超 19 万家，数据产业规模超 2 万亿元。按照 20% 以上的年均增长率测算，2030 年我国数据产业规模将达 7.5 万亿元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-8974708623b157a8be63e50fae982623dce.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;国家数据局局长刘烈宏表示：探索适应数据特征的产权配置、流通模式和安全治理机制，培育壮大一批数据要素产业链上下游企业。当前我们正谋划构建横向联通、纵向贯通，协调有力的数据基础设施体系，到 2029 年要基本建成国家数据基础设施主体结构。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公共数据开放共享成为数据要素市场化的重要突破口。2024 年全国地市级以上的地方公共数据开放平台数量增长 7.5%，开放数据量增长 7.1%，高质量数据集数量同比增长 27.4%。在数据要素与产业融合方面，国家正加快打通公共数据共享开放壁垒，推动公共数据与企业数据深度融合，激活海量「沉睡数据」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350559</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350559</guid>
      <pubDate>Sun, 11 May 2025 02:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>如何用好 「对话式编程」？牢记这十二条策略</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 如何有效利用大语言模型（LLMs）生成高质量代码？这是当下开发者们比较关心的一个问题。在生成代码的过程中，提示词的设计是否精确，直接决定了模型输出的质量。&lt;/p&gt; 
 &lt;p&gt;本文深入探讨了提示词优化的 12 条策略，给出了清晰的操作指南和示范案例，读者可以了解到如何通过精准编写提示词引导模型生成性能优越、符合实际需求的代码。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Ayush Thakur@Potpie&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpotpie-ai%2Fpotpie" target="_blank"&gt;https://github.com/potpie-ai/potpie&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;大语言模型（LLMs）已经彻底改变了代码生成领域，但要想获得高质量、有用的输出结果，编写有效的提示词至关重要。LLMs 生成代码的质量高度依赖于所提供提示词的质量。&lt;strong&gt;一句表述不当的提示词可能导致不完整、不正确或虽然正确但不具备针对性的响应，而逻辑性、完整性和易读性良好的提示词则能最大化发挥模型的潜力。&lt;/strong&gt; 本文将探讨编写有效提示词的高级策略，以便使用 LLMs 生成高质量的代码。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 提供详细的上下文&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在与 LLMs 进行交互生成代码时，所提供上下文的深度和质量直接影响模型输出的相关程度和准确程度。&lt;/p&gt; 
&lt;p&gt;上下文需要包含的关键要素有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Specific problem domain（译者注：指的是你试图解决的问题所在的特定专业或技术领域。例如，如果你正在开发一个系统来处理金融交易，那么你的问题领域就是金融科技（FinTech）。）&lt;/li&gt; 
 &lt;li&gt;Existing codebase characteristics（译者注：指的是当前项目中已有代码的特点、风格和结构等信息。）&lt;/li&gt; 
 &lt;li&gt;Implementation constraints（译者注：在实现解决方案时必须遵守的各种限制条件，如只能使用某些技术栈等。）&lt;/li&gt; 
 &lt;li&gt;Performance requirements（译者注：指的是系统或应用程序需要达到的性能标准。）&lt;/li&gt; 
 &lt;li&gt;Architectural patterns already in use（译者注：指的是在当前项目或组织中已经采用的软件架构模式。架构模式是一种通用的、可重复的设计模板，用于解决软件架构中的常见问题。例如，微服务架构、分层架构（n-tier architecture）或是事件驱动架构等。）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，你可以使用 &lt;a href="https://my.oschina.net/references"&gt;@references&lt;/a&gt; 指向特定文件或函数（译者注：大部分「对话式编程」 Apps 都支持该功能），使你的请求更加精准。与其用文字描述某个函数，不如直接引用它。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❌ 欠佳的提示词：创建一个用户身份验证系统。&lt;/p&gt; 
 &lt;p&gt;✅ 更好的提示词：为我们的 Node.js Express API 创建一个基于 JWT 的身份验证系统，该系统需要与 MongoDB 的 user 集合集成。该系统应使用 bcrypt 处理密码哈希，签发有效期为 24 小时的令牌，并实现刷新令牌（refresh token）轮换机制增强安全性。现有的中间件模式采用 async/await 语法。请参考 @authMiddleware.js 的中间件结构和 @userModel.js 的 user 集合结构。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;通过使用 @authMiddleware.js 和 @userModel.js，可以确保生成的代码与现有架构保持一致，减少一些集成问题和手动调整工作量。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 将问题分解为多个步骤&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;复杂的编码任务需要系统性地拆解为可管理单元。该方法论的实施路径如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;从明确的功能需求出发&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分析目录结构和代码组织方式&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;引导 LLM 按照逻辑步骤实现目标功能，同时遵循既定的架构边界和设计模式。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;例如，在实现一个数据处理 pipeline 时，首先需明确输入的数据结构、转换逻辑、错误处理的相关要求及预期的输出格式。随后分析目录结构，并确定新功能的实现位置。&lt;/p&gt; 
&lt;p&gt;需要综合考量代码之间的依赖关系（dependency relationships）、模块的职责划分与隔离（module boundaries）以及代码的目录结构与命名规范（code organization principles）。这一步骤可确保生成的代码能无缝集成到现有代码库中。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 选择合适的模型完成任务&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;不同 LLM 在代码生成任务中展现出的优势不同。&lt;strong&gt;某模型可能擅长理解复杂需求并生成逻辑一致性强的代码，而另一模型可能在特定编程语言或框架上具有优势。&lt;/strong&gt; 在评估使用哪种 LLM 时，需着重关注以下技术因素：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文窗口大小（处理大型代码库时至关重要）&lt;/li&gt; 
 &lt;li&gt;对编程语言/技术框架的掌握程度&lt;/li&gt; 
 &lt;li&gt;特定领域的专业知识&lt;/li&gt; 
 &lt;li&gt;多轮交互的稳定性&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对比示例：&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;任务类型&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;模型选择考量因素&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;复杂的企业级架构&lt;/td&gt; 
   &lt;td&gt;更大的上下文窗口大小有助于在大型代码库中保持多轮交互的稳定性&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;机器学习 pipeline&lt;/td&gt; 
   &lt;td&gt;数学基础扎实且经过数据科学专项训练的模型更具优势&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;前端组件&lt;/td&gt; 
   &lt;td&gt;采用新近框架数据训练的模型，可输出符合业界最新标准的代码模式&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;&lt;strong&gt;04 具体参照现有的代码实现模式&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在提示词中明确具体细节能大大提升代码生成的质量。&lt;/strong&gt; 技术细节需明确指向代码库中的既有实现范式，而非笼统要求通用方案。例如：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❌ 欠佳的提示词： 「写一个处理用户数据的函数」&lt;/p&gt; 
 &lt;p&gt;✅ 更优的提示词：「在 UserProcessor 类 (src/services/UserProcessor.js) 中创建一个新方法，沿用 transformPaymentData 方法的函数式编程风格实现用户数据的转换。因采用异步机制，实现时应以可读性为第一准则，性能次之。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;该方法也同样适用于命名规范、编码标准和架构模式。需明确说明采用函数式或面向对象范式，指定设计模式类型，并澄清性能与代码可读性的优先级。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 请重新生成而非回滚&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;当生成的代码出现问题时，重新生成有问题的模块通常比逐步去修复代码中的问题效果更好。&lt;/strong&gt; 此方法源于大语言模型理解上下文和生成模型响应的机制。&lt;/p&gt; 
&lt;p&gt;为何重新生成效果更好？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;脱离原有错误实现方式的思维定式&lt;/li&gt; 
 &lt;li&gt;防止旧代码中的错误代码逻辑污染新的代码实现&lt;/li&gt; 
 &lt;li&gt;支持加入新的约束条件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种方法对解决一些算法难题或实现复杂的代码逻辑特别有效，因为在这些场景下一点细微的错误都可能影响整体解决方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「请尝试用不同的方法实现排序算法。当前版本的时间复杂度为 O(n²)，无法满足数据集规模要求，请基于我们其他的数据处理函数使用的归并排序模式，重新生成 O(n log n) 时间复杂度的解决方案」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;06 决策前请生成多套方案进行对比&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;利用大语言模型能够生成多套解决方案的能力，通过对比分析提升代码质量。首先，要求模型生成 2-3 种不同的实现策略，每种策略需包含对该方案优缺点的分析。&lt;/p&gt; 
&lt;p&gt;生成多套方案后，引导模型分析时间复杂度、空间复杂度、代码可读性和可维护性等因素，并分析如何权衡这些因素。这一反思（reflection）过程使模型能根据具体需求选择并完善最合适的解决方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「请为 API 响应缓存系统（caching system for our API responses）提供三套实现方案：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;基于自定义数据结构的 LRU 内存缓存方案&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;基于 Redis 的分布式缓存方案&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;支持 TTL 的本地文件系统缓存&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;请分别分析各方案的时间复杂度、内存占用、多服务器扩展能力和实现复杂度」&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 实施自我审查机制&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Self-review prompting 可通过引导大语言模型对其生成的代码进行系统化评估来提升代码质量。具体实施时需明确要求模型在完成代码生成后交叉检查其生成的代码。自我审查（Self-review）应评估以下这几个方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;代码正确性（是否有逻辑错误）&lt;/li&gt; 
 &lt;li&gt;效率（是否存在性能问题）&lt;/li&gt; 
 &lt;li&gt;边界情况的处理情况&lt;/li&gt; 
 &lt;li&gt;安全漏洞&lt;/li&gt; 
 &lt;li&gt;是否严格满足需求&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在自我审查过程中，模型可识别潜在问题，例如并发代码中的竞态条件漏洞（译者注：一种常见安全漏洞，源于系统或程序在处理并发操作时因时序问题导致的逻辑错误。）、资源管理中的内存泄漏，或直接影响系统安全的核心逻辑中的漏洞风险点。发现问题后，模型可立即优化代码实现来解决问题。此方法对应成熟的软件工程实践（如代码审查和静态分析），但将其置于同一 prompt-response 周期内执行，大大提升了初始的代码生成质量。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;08 为模型赋予技术人设或给出参考框架&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;为大语言模型分配技术人设，可确保其代码生成保持统一的专业视角。当要求模型以"精通分布式系统的高级后端工程师"的思维模式运作时，其生成的代码会优先考虑可扩展性、容错性和性能优化。同理，若赋予"安全专家"人设，其生成的代码会重点强化内容输入区的验证、规范认证流程，并预先规避潜在的漏洞风险。&lt;/p&gt; 
&lt;p&gt;技术参考框架需与任务需求相匹配。&lt;/p&gt; 
&lt;p&gt;根据不同任务选择不同的专业人设：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;后端系统："具备分布式系统专业知识的高级后端工程师"&lt;/li&gt; 
 &lt;li&gt;安全模块："熟悉 OWASP 规范的安全架构师"&lt;/li&gt; 
 &lt;li&gt;基础设施："专攻云原生解决方案的 DevOps 工程师"&lt;/li&gt; 
 &lt;li&gt;前端开发："关注用户体验且具有无障碍化开发经验的前端工程师"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种方法利用模型模仿领域专家的能力，使生成的代码更精准体现特定技术领域的行业最佳实践。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「扮演高级安全工程师进行代码审查。用 Python/Django 创建用户注册系统，需实现合规的密码处理、输入验证功能，并防御常见 Web 漏洞。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;09 明确编程语言、开发框架或第三方库的限制条件&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;明确说明技术限制条件，才能确保代码与运行环境完美兼容。首先应清晰说明编程语言版本（例如 Python 3.9、TypeScript 4.5），确保生成的代码所使用的语言特性在生产环境中可用。同时需指定框架版本及其特定规范，例如"使用 Pydantic v2 模型的 FastAPI 0.95 进行数据验证"。&lt;/p&gt; 
&lt;p&gt;此外，还要交代清楚：用哪些第三方库、具体怎么接入。例如，在请求生成数据库交互代码时，应指定使用 SQLAlchemy 等 ORM 还是原始的 SQL queries，并明确数据库连接的处理要求。抠到这种细节程度，才可以避免生成依赖了不可用的组件或版本不兼容的代码。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「请使用以下技术栈开发 REST API 接口：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Python 3.9&lt;/li&gt; 
  &lt;li&gt;搭载 Pydantic v2 模型的 FastAPI 0.95 框架&lt;/li&gt; 
  &lt;li&gt;使用 SQLAlchemy 2.0 执行数据库操作&lt;/li&gt; 
  &lt;li&gt;通过 auth_utils.py 文件中现有 AuthManager 实现 JWT 身份认证&lt;/li&gt; 
  &lt;li&gt;必须兼容 PostgreSQL 13 数据库」&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;10 实施思维链这一提示词工程技术&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;思维链（Chain of thought prompting）通过引导大语言模型进行逻辑推理，可以大大提升代码生成质量。这个方法的精髓是：让 AI 先拆解问题再写代码。&lt;/p&gt; 
&lt;p&gt;要求模型按这个顺序分步思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;用大白话解释实现思路&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;搭建解决方案的伪代码框架&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;每个模块的具体实现逻辑&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;最终完整可运行的代码成品&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;思维链技术对于包含复杂逻辑或数据转换的算法特别有效。这种方法可以减少逻辑错误，提高代码的一致性，并可视化模型的推理过程，便于在最终代码生成前进行修正。&lt;/p&gt; 
&lt;p&gt;与侧重任务分解的"分步执行"方法不同，思维链技术着重于显性化模型的推理路径，确保在确认最终方案前保持逻辑的严谨性。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;11 针对不同大语言模型（LLM）的特长设计专属的提示词策略，以最大化发挥其优势&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;不同的大语言模型具备各自独特的优势，通过针对性的提示词技巧可以充分发挥它们的潜能。&lt;/p&gt; 
&lt;p&gt;提示词策略如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;针对上下文窗口有限的模型：聚焦分步算法指导&lt;/li&gt; 
 &lt;li&gt;针对擅长函数式编程的模型：使用函数式思维提问&lt;/li&gt; 
 &lt;li&gt;针对精通某一特定开发框架的模型：直接使用该框架的核心 API、类名或设计模式等特定术语提问，减少解释成本。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;了解模型在训练过程中接触的数据集特点是优化提示词的关键。&lt;/strong&gt; 不同的模型因其训练数据分布不同，往往只对特定编程范式或语言有更强的理解力。例如，若某模型在训练中接触了大量函数式编程内容，那么当问题本身适合使用函数式编程解决时，用函数式编程术语构建提示词，将获得更精准的响应。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;12 指定边界情况和约束条件&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;全面覆盖边界场景能大幅提升代码健壮性 &amp;nbsp;。技术领域的边界情况因场景而异，但通常包含临界值（译者注：如数值溢出、空输入）、资源限制（译者注：如内存耗尽、超时）和异常状态（译者注：如网络中断、并发冲突）。在向模型发送请求生成代码时，应明确列出这些要素，例如说明数据处理函数应如何处理空输入、格式错误的数据或超出预期范围的值。&lt;/p&gt; 
&lt;p&gt;通过预先考虑这些约束条件，生成的代码可包含与指定限制条件相匹配的验证逻辑、错误处理机制和性能优化方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「实现一个能处理以下情况的文件处理函数：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;空文件（返回空结果）&lt;/li&gt; 
  &lt;li&gt;超过 1GB 的文件（分块读取处理）&lt;/li&gt; 
  &lt;li&gt;格式错误的 CSV 数据（记录错误并跳过错误行，继续处理后续有效行）&lt;/li&gt; 
  &lt;li&gt;多进程/线程同时操作同一文件（需加锁（如文件锁、数据库锁）避免数据竞争）&lt;/li&gt; 
  &lt;li&gt;网络中断（需支持断点续传）」&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;掌握代码生成的提示词工程既是一门艺术，也是一门科学，它能大幅提升开发效率。通过运用这些策略方法，开发者可以将大语言模型（LLM）从简单的代码生成工具升级为智能开发助手，从而打造出更健壮、高效且易于维护的软件系统。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Ayush Thakur&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Developer Advocate | Community Manager | Technical Writer&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;文中提到「重新生成代码优于修复 Bugs」，你在实际使用「对话式编程」时有这种感受吗？&lt;/strong&gt; &lt;strong&gt;欢迎在评论区分享~&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文经原作者授权，由&lt;/strong&gt; &lt;strong&gt;Baihai IDP&lt;/strong&gt; &lt;strong&gt;编译。如需转载译文，请联系获取授权。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpotpie-ai%2Fpotpie%2Fwiki%2FHow-to-write-good-prompts-for-generating-code-from-LLMs" target="_blank"&gt;https://github.com/potpie-ai/potpie/wiki/How-to-write-good-prompts-for-generating-code-from-LLMs&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18426598</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18426598</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>OpenAI 发布编程 Agent「Codex」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式发布编程 Agent 产品「Codex」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0e12276316926445f454385b24aee64ca00.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Codex 是一款支持并行处理多个任务的云端编程 Agent，能够提供如编程功能、回答代码库的问题、修复错误等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0519/100634_jTO9_2720166.png" width="1336" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1578" src="https://static.oschina.net/uploads/space/2025/0519/100843_qXsH_2720166.png" width="1190" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Codex 基于 codex-1 模型驱动，OpenAI 方面表示这一模型由 o3 模型针对编程进行优化而得来。codex-1 通过强化学习在各种环境中，对现实世界的编码任务进行训练，从而能够生成接近人类风格和 PR 偏好的代码。&lt;/p&gt; 
&lt;p&gt;在 OpenAI 自己的代码评估和内部基准测试中，codex-1 即使没有 AGENTS.md 文件或自定义脚手架（custom scaffolding）也表现出色。&lt;/p&gt; 
&lt;p&gt;目前，Codex 提供的是研究预览版。使用方面，OpenAI 将会优先为 ChatGPT Pro 用户、企业或团队用户提供 Codex，Plus 用户和教育用户也即将能体验到。&lt;/p&gt; 
&lt;p&gt;另外，OpenAI 还同时公布了 codex-1 的小号版本，基于专为 Codex CLI 设计的 o4-mini 打造。模型型号为「codex-mini-latest」，API 定价为每百万输入 token 1.5 美元，每百万输出 token 6 美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多详细内容查看 Codex 技术报告：&lt;/strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-codex%2F" target="_blank"&gt;https://openai.com/index/introducing-codex/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350557/openai-codex</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350557/openai-codex</guid>
      <pubDate>Sun, 11 May 2025 02:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
