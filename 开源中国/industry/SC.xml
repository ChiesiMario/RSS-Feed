<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 17 Feb 2025 12:37:16 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>OpenAI 对 GPT-4o 模型进行更新</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI CEO 萨姆・奥特曼在社交平台 X 上表示，该公司对 GPT-4o 进行了更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1f3df4ef62755ac81ca803cc24807853ec5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，GPT – 4o 的表现非常出色，在评论区他还说道，&lt;strong&gt;GPT–4o 是「网上最好的搜索产品之一」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;根据相关测试数据，GPT-4o 更新后性能相当强悍，从 Lmarena 竞技榜的第 5 名上升至第 1 名，而且是全方位的领先。从总体情况、创意写作、编码、指令遵循、长提示到多轮对话。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7e1a2d8ec03fcda8d64e38cf2bd2b4c962d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 于去年 5 月发布了 GPT-4o，其中的「o」代表「omni」（即全面、全能的意思），这个模型同时具备文本、图片、视频和语音方面的能力，甚至就是 GPT-5 的一个未完成版。&lt;/p&gt; 
&lt;p&gt;而在同年 7 月，OpenAI 官宣推出 GPT-3.5 Turbo 的替代品——GPT-4o mini，这是 GPT-4o 更小参数量的简化版本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334403</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334403</guid>
            <pubDate>Sat, 08 Feb 2025 11:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「AI 公务员」来了！广东深圳首批 70 名正式上岗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;广东深圳福田区日前推出基于 DeepSeek 开发的 AI 数智员工，上线福田区政务大模型 2.0 版，除了有 DeepSeek 通用能力外，还结合各部门各单位实际业务流程，量身定制个性化智能体，首批满足 240 个业务场景使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;253&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-046e1231afd4b4ffadd892d508d61fea619.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据悉，福田区政务大模型 2.0 版以全尺寸 DeepSeek R1 为核心底座，凭借混合专家架构（MoE）与强化学习技术，有效破解传统政务大模型算力消耗高、响应不稳定和专业性不足的痛点，依托国产算力平台实现本地化细分领域训练，确保符合不同行业不同单位的具体需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，福田区已上线 11 大类 70 名「数智员工」，覆盖政务服务全链条。通过 240 个政务场景终端的精准解析，覆盖公文处理、民生服务、应急管理、招商引资等多元场景。个性化定制生成时间从 5 天压缩至分钟级。公文格式修正准确率超 95%，审核时间缩短 90%，错误率控制在 5% 以内。「AI 任务督办助手」跨部门任务分派效率提升 80%，按时完成率提升 25%。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334385</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334385</guid>
            <pubDate>Sat, 08 Feb 2025 09:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国科技「7 巨头」已悄然形成：阿里/腾讯/美团/中芯/小米/联想/比亚迪</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;美国有科技 7 姐妹（苹果、谷歌、亚马逊、微软、Meta、特斯拉、英伟达），那么中国对飙的 7 巨头也随之而来。&lt;/p&gt; 
&lt;p&gt;多家机构给出的报告显示，中国科技股七巨头已经悄然形成，其分别是：&lt;strong&gt;小米、联想、比亚迪、中芯国际、阿里巴巴、腾讯、美团&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这七家公司涵盖&lt;strong&gt;硬件制造、云计算、半导体、智能终端、本地生活&lt;/strong&gt;等核心领域，其中以腾讯市值 4.3 万亿港元居首。&lt;/p&gt; 
&lt;p&gt;报告指出，以苹果、谷歌、亚马逊、微软、Meta、特斯拉、英伟达为代表的科技七巨头凭借稳健的业绩增长和在 AI 等前沿领域持续创新，已成为美股科技核心资产。&lt;/p&gt; 
&lt;p&gt;受到 AI 人工智能的风口催化，上述中国 7 巨头的股价都不同程度的迎来了暴涨，而不少外资也是旗帜鲜明地看多和做多这 7 巨头。报告指出各科技企业的优势。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;小米：端侧 AI 落地主要受益者之一。&lt;/li&gt; 
 &lt;li&gt;联想：大模型落地推动 AI PC 和服务器加速发展。&lt;/li&gt; 
 &lt;li&gt;比亚迪：电动车龙头智能化转型机遇。&lt;/li&gt; 
 &lt;li&gt;中芯国际：全球产业链重构主要受益者之一。&lt;/li&gt; 
 &lt;li&gt;阿里巴巴：中国大陆领先云服务厂商，受益 AI 需求迸发。&lt;/li&gt; 
 &lt;li&gt;腾讯：AI 赋能社交广告，混元大模型未来可期。&lt;/li&gt; 
 &lt;li&gt;美团：本地生活消费龙头，零售+科技战略落地为公司带来长期成长。&lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334382</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334382</guid>
            <pubDate>Sat, 08 Feb 2025 09:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯元宝再更新：DeepSeek R1+腾讯混元 T1「双核」驱动</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;继上周接入「满血版」DeepSeek-R1 后，腾讯元宝宣布又上线腾讯混元最新「深度思考模型」Thinker（T1），目前已开启小范围灰测，用户可以自行选用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e1d07289adca12841e6e46c8ea7703d63e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，无论是使用混元 T1，还是使用 DeepSeek，均支持联网搜索，覆盖公众号等腾讯生态内容及互联网权威信源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;用户在元宝里提问时，可以选择从微信里上传文件；也可以通过元宝小程序在微信里上传文件，元宝一键解析，无需多余步骤，大幅减少操作成本。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334365</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334365</guid>
            <pubDate>Sat, 08 Feb 2025 08:57:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Fedora 整合至 WSL 即将完成，官方发起「捉虫」测试活动</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Fedora 与微软 Windows Subsystem for Linux (WSL) 的整合即将完成，Fedora 团队正在召集社区提供帮助。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/165215_oE96_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffedoraproject.org%2Fwiki%2FTest_Day%3A2025-02-17_WSL&quot; target=&quot;_blank&quot;&gt;https://fedoraproject.org/wiki/Test_Day:2025-02-17_WSL&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;测试活动定于 2025 年 2 月 17 日（星期一）举行，在 Fedora 正式发布之前，爱好者们将有机会在 WSL 下试用 Fedora。如果您装有 Windows 10 或 11，并且有空闲时间，那么现在就是您贡献力量的时候了。&lt;/p&gt; 
&lt;p&gt;这次 Fedora 测试活动本质上是一次社区组织的寻找 bug 的活动。无论您是 Fedora 的忠实支持者，还是仅仅对 Windows 中的 Linux 理念感兴趣，都欢迎您的参与。参加测试的要求包括：&lt;strong&gt;具有虚拟化功能的 x86 或 AArch64 设置、愿意遵守测试准则，以及有能力下载大型测试镜像&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;所有必要的资源，从安装程序到故障排除建议，都在 Fedora WSL 测试日维基上有详细说明。Fedora 团队鼓励参与者在测试后通过 Fedora 测试周在线平台提交他们的发现。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334363/test-fedora-microsoft-windows-subsystem-linux-wsl</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334363/test-fedora-microsoft-windows-subsystem-linux-wsl</guid>
            <pubDate>Sat, 08 Feb 2025 08:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>如何公正评价百度开源的贡献？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;本文转载自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcIXVXI-QNK0GqVqlQBMQxw&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/cIXVXI-QNK0GqVqlQBMQxw&lt;/a&gt;&lt;br&gt; 作者：谭中意&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;引子&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;近日，因百度宣布开源文心大模型而引发热议，不少媒体与业内人士对李彦宏及百度此前的言论提出质疑，发表例如「李彦宏「推翻」李彦宏」，「李彦宏此前言论遭「打脸」类似的文章，甚至有人认为百度的「开源」只是表面文章。&lt;/p&gt; 
&lt;p&gt;面对这些质疑，涉及对企业开源贡献评价标准的不同理解。其实人的看法会因为世事变化发生很大的变化，出现打脸是在所难免的。但是，公正的评价一个企业的开源贡献，不能只看他们说了什么、谋求了多大商业利益，而应从开源世界的标准出发，看他们到底做了什么、贡献了什么。&lt;/p&gt; 
&lt;p&gt;本文将从如何客观评价企业开源贡献的方法入手，并结合百度多年来的优秀开源项目，给出一个公正的评价。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;一、如何公正评价企业的开源贡献&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;评价一个企业的开源贡献，关键在于&lt;strong&gt;看做了什么&lt;/strong&gt;而非&lt;strong&gt;说了什么&lt;/strong&gt;。以下几点是常用的评价方法：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;项目质量与长期价值&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;（1）项目本身质量&lt;/strong&gt;：优秀的开源项目应该能够在工业界得到广泛的应用。它应该是在它的技术生命周期内，在解决一些开发者实际的问题上有独到之处，这是这个项目的最根本的技术价值。即开源项目本身得有用，而且确实被工业界广泛使用了。例如，可以考察这个开源项目被企业和开发者实际使用的案例数量等指标。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;（2）项目长期价值&lt;/strong&gt;：一个项目被开源出来，如果不能长期迭代，不断解决各种新的问题，而只是开源了一个版本然后就没有更新了，那么这个项目虽然也有一点点价值，但是价值很有限。持续的代码提交、定期的版本发布（尤其是对高危漏洞的及时修复版本）、积极的社区维护，都是项目长期价值的体现。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;人才培养&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;企业开源不仅是代码的贡献，更是培养开发人才、推动整个行业技术进步的重要途径。企业通过开放项目，不仅提升了自身技术水平，也为整个生态输送了大量高质量的人才。所以看企业开源的价值，围绕开源项目带来的人才培养也是重要的一个方面。例如，可以考察该企业是否围绕这个开源项目开展了相关的培训、认证、开发者活动，以及开源社区中涌现出的优秀开发者和贡献者是否得到了行业的认可和发展，而不仅仅只局限在这一个项目上。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;对行业的长期技术推动与生态效应&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;评价企业开源贡献，还需关注其在行业内对标准制定、技术创新和生态构建方面的影响。一个企业的开源行为如果能推动整个产业技术进步，形成广泛的影响力，则其贡献不可小觑。例如，可以考察企业开源项目是否参与了行业标准的制定，是否引领了新的技术方向，是否构建了开放协作的生态系统，吸引了产业链上下游的参与者。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;总之，公正评价应着眼于实际成果——开源项目的本身质量和长期价值，以及企业对人才培养与生态建设的长远贡献，而非仅凭商业成功或单纯的口号来论断。&lt;/p&gt; 
&lt;p&gt;另外，国内某些媒体往往只以开源商业化的成功以否来评价一个企业开源的价值，其实企业开源只是该企业其整体商业战略的一个环节，企业商业的成功取决于多个因素，市场、营销、渠道、交付、团队等等，开源只是其中一个因素而已。&lt;/p&gt; 
&lt;p&gt;所以业内也有不少企业，开源项目做的相当不错，但是对应的商业化做的不怎么成功。例如云原生领域内的基石项目 Kubernetes 的创始方是 Google 公司，但是容器云即基于 kubernetes 搭建的云服务，在全球公有云市场份额最大的是 AWS。（根据&amp;nbsp;&lt;strong&gt;perplexity.ai 搜索 2023 年容器云全球市场份额得到 2023 年全球容器云市场份额的前三名是亚马逊 AWS、微软 Azure 和谷歌云，分别占据 32%、20% 和 9% 的市场份额。&lt;/strong&gt;）&lt;/p&gt; 
&lt;p&gt;这充分说明，开源项目的成功与其商业化成果之间不能简单划等号。虽然谷歌云在容器云市场份额不如 AWS 和 Azure，但是任何行内人都不会否定 Google 在云原生领域内的突出贡献，是它开源的 kubernetes 并加上 docker 共同创造崭新的云原生产业。因此不能拿商业的不成功，来否定开源项目本身的成功，进而否定该公司开源的不成功。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;&lt;strong&gt;二、百度的优秀开源项目举例&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;百度多年来在开源领域的探索和投入不容小觑，其多个开源项目在国内外都产生了深远影响。笔者简单列举几个笔者熟悉的项目，而这些项目仅仅是百度众多开源项目中的几个。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Apollo&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;作为开放的自动驾驶平台，百度 Apollo 自 2017 年开源 1.0 以来持续迭代，引领了自动驾驶技术的开源潮流，不仅树立了技术标杆，也促使更多企业和研究机构加入开放合作，共同推动产业进步。据了解，国内众多自动驾驶车厂和技术提供商，要么基于 Apollo 的开源代码魔改，要么借鉴其开源的架构设计和源码实现之后再构建自己的系统，这充分体现了 Apollo 的技术价值。&lt;/p&gt; &lt;p&gt;同时，Apollo 在&lt;strong&gt;人才培养&lt;/strong&gt;和&lt;strong&gt;生态建设&lt;/strong&gt;上的贡献同样突出。其开源平台为高校、科研机构和初创公司提供了宝贵的学习和实践机会，培养了众多自动驾驶领域的技术人才。此外，Apollo 开放的架构和工具链降低了行业技术门槛，推动了自动驾驶技术的普及，并吸引了车企、芯片厂商等产业链伙伴，共同加速技术落地。可以说，Apollo 不仅贡献了技术，还通过开源促进了人才成长和产业生态的发展。有行业专家指出，Apollo 的开源模式加速了中国自动驾驶技术的发展进程，降低了整个行业创新的成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PaddlePaddle（飞桨）&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;作为中国首个产业级深度学习平台，飞桨为广大开发者提供了全面的 AI 解决方案，推动了人工智能技术的普及和商业落地，其生态已辐射众多产业领域。笔者个人觉得尤其重要的是，PaddlePaddle 在教育界和产业界长期进行了大量的培训和推广工作，成功培养了大批人工智能的开发者和科学家，为后来大模型研发的遍地开花奠定了坚实的基础。飞桨平台在推动中国人工智能人才培养方面发挥了重要作用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ECharts&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;ECharts 是源于百度的一款基于 JavaScript 的数据可视化库，现在是隶属于 Apache 开源软件基金会的顶级项目。自开源以来在数据可视化领域取得了显著的成就和广泛的应用.截至目前，ECharts 在 GitHub 上已获得超过 6.19 万 Star，在同类数据可视化库中名列前茅 (数据来源： GitHub)。它广泛地被各种数据 BI 产品所集成，例如 Apache Superset 等等。还在国内外多个行业内被广泛使用，例如数据分析、交互教育等。比较难得的是，虽然是源于百度的开源项目，但是项目的贡献者是来自多个公司的志愿者，并没有来自百度的全职维护者。社区的长期发展一直得到足够保证，目前正在筹备下个大版本 ECharts 6.0 的发布。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;brpc&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;作为起源于百度的一款高性能、分布式的远程调用（RPC）框架，在特别吃性能的大规模分布式场景下使用很多，例如各大互联网公司的搜索、广告、推荐、存储等系统上。它同样是 Apache 开源软件基金会的顶级项目，开源至今培养了大批高性能应用的开发者。目前的维护者是来自多家公司的志愿者，也同样没有百度全职员工的投入，但一直在不断的往前发展，包括增加新特性，发布安全修复版本等。2016 年开源至今一直不断发展新的 Committer，还发布了数十个新的版本。今年 1 月份他们还发了两个版本，增加一些新的特性和修复了一些 Bugs。brpc 项目的持续迭代和社区活跃度，体现了其强大的生命力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;当然，这几个项目只是本人比较熟知的几个项目，只是冰山下的一角。除此之外，还有 Doris、BFE、SAN 等数百个项目。通过这些项目，我们可以看到百度不仅在核心技术上做出了实际贡献，而且通过开源模式推动了整个技术生态的发展和人才的培养。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;&lt;strong&gt;三、结论&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;评价一个企业的开源贡献，应从源于这个企业的开源项目的技术质量、社区影响、人才培养以及对产业生态的推动等多方面进行综合考量。百度在这些方面都有着突出表现——&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其开源项目如 Apollo、paddlepaddle、ECharts、brpc 等，不仅在技术上具备先进性，还被广泛应用于工业界；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时，百度还通过开源平台培养了大量技术人才，推动了自动驾驶、人工智能等多个行业的进步。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，&amp;nbsp;&lt;strong&gt;综合来看，&lt;/strong&gt;&amp;nbsp;百度的开源努力为中国乃至全世界的技术进步和产业生态建设做出了&lt;strong&gt;积极&lt;/strong&gt;贡献，而针对&lt;strong&gt;部分&lt;/strong&gt;过激言论，则显然是片面的、不够全面的评价。&lt;strong&gt;当然，我们也应该看到，企业开源是一个复杂而动态的过程，百度的开源之路也面临着很大的挑战和改进空间。&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;&lt;strong&gt;四、最后&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;百度不惜「打脸」自己，成为业内首个从闭源路线转向开源路线的大模型厂商，这一决定本身就展现了相当的魄力。&lt;/p&gt; 
&lt;p&gt;从商业角度来看，开源意味着放弃部分技术封锁带来的竞争壁垒，承担更多的不确定性，但百度依然选择开放文心大模型，表明其对技术共创和生态繁荣的认可。&lt;/p&gt; 
&lt;p&gt;从行业角度来看，百度的这一举措不仅为国内大模型开源生态注入了新的活力，也为其他厂商提供了新的参考路径，推动国内人工智能技术的开放合作与良性竞争。&lt;/p&gt; 
&lt;p&gt;有评论认为，无论如何，百度这次的选择，都是中国 AI 开源发展史上具有里程碑意义的一步，但是从长期来看，仍然有待时间和市场的检验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334357</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334357</guid>
            <pubDate>Sat, 08 Feb 2025 08:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国移动申请 AI 数智人相关商标</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;天眼查知识产权信息显示，中国移动通信集团有限公司近日申请注册「中移智安麒」「中移安麒」商标，国际分类为通讯服务、科学仪器，当前商标状态均为等待实质审查。&lt;/p&gt; 
&lt;p&gt;根据介绍，作为中国移动自主研发的专家型数字员工，中国移动 AI 数智人安麒以大数据为基础、人工智能算法为驱动、安全专家知识为核心，具备自动化安全测试、个性化安全培训等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;176&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d48730a8b9bfcb58999469412369d80ce2.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334342</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334342</guid>
            <pubDate>Sat, 08 Feb 2025 07:47:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 提出「CodeI/O」：通过代码输入-输出预测提炼推理模式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 团队最近提出了一种名为「CodeIO」的新方法，用来提升大型语言模型（如 ChatGPT 等）的推理能力。传统方法通常专注于训练模型解决数学题或生成代码，但其他类型的推理任务（如逻辑推理、科学推理）由于缺乏高质量的训练数据，效果往往不佳。&lt;/p&gt; 
&lt;p&gt;这项研究的核心思路是：&lt;strong&gt;用代码教模型「解题思维」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;代码中其实隐藏着丰富的「解题套路」。例如，一段计算阶乘的代码，本质上包含了「从 1 连乘到 n」的数学推理步骤。&lt;/p&gt; 
&lt;p&gt;CodeIO 的巧妙之处在于：&lt;/p&gt; 
&lt;p&gt;1. 把代码变成「输入-输出」练习题：给定一个代码函数和输入，让模型预测输出；或者给定代码和输出，让模型反推输入。&lt;br&gt; 2. 用自然语言描述推理过程：模型需要像学生写解题步骤一样，用文字说明「为什么输入 A 会得到输出 B」，而不是直接生成代码。这种「思维链」训练让模型学会通用的推理方法，比如如何拆解问题、如何验证条件等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-329627648b1420a4bd96c277796e656e498.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-53304e171496cc07dddbbf90f1d4d56f5c6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如何实现？&lt;/p&gt; 
&lt;p&gt;⭐收集代码：从算法题库、数学问题等来源筛选 45 万多个代码函数。&lt;br&gt; ⭐生成练习题：为每个代码函数自动生成多组输入输出对，例如测试阶乘函数时，输入 5 对应输出 120。&lt;br&gt; ⭐让模型「写解题步骤」：使用一个强大的开源模型（DeepSeek-V2.5）为每个练习题生成自然语言的推理过程。&lt;br&gt; ⭐纠错升级（CoDEI/O++）：如果模型预测错误，系统会通过执行代码得到正确答案，并让模型根据反馈重新生成推理步骤。类似老师批改作业后让学生订正。&lt;/p&gt; 
&lt;p&gt;效果如何？&lt;/p&gt; 
&lt;p&gt;⭐在 14 个不同类型的推理测试中（涵盖数学、逻辑、常识等），经过 CoDEI/O 训练的模型表现更全面：&lt;br&gt; ⭐不偏科：传统方法可能在数学题上得分高，但逻辑题得分低，而 CoDEI/O 在所有任务中均有提升。&lt;br&gt; ⭐验证可靠：模型的推理步骤可以通过代码执行直接验证，确保正确性。&lt;br&gt; ⭐开源共享：所有训练数据和模型已公开（GitHub），方便后续研究。&lt;/p&gt; 
&lt;p&gt;总结一下，CodeI/O 就像是一种新的「思考训练营」，它利用代码这种结构化的信息，让 AI 学习更通用、更可靠的推理能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;详细介绍：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodei-o.github.io%2F&quot; target=&quot;_blank&quot;&gt;https://codei-o.github.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;论文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.07316&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.07316&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334339</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334339</guid>
            <pubDate>Sat, 08 Feb 2025 07:34:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>最新尸检报告认定 OpenAI「吹哨人」死因为自杀</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 11 月 26 日，前 OpenAI 员工 Suchir Balaji 在旧金山的公寓中被发现死亡，年仅 26 岁。时至今日，旧金山法医部门在最新公布的尸检报告裁定 Balaji 的死因为开枪自杀，驳斥了 Balaji 家人有关他杀的怀疑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;344&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1a05ba4a3131262dbb151b1411f9a3d8cd9.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;资料显示，Balaji 是一名印度裔美国人，曾在加州大学伯克利分校学习并获得了计算机科学学士学位。大学期间，他于 2019 年在 Scale AI 实习，并于 2021 年毕业后加入 OpenAI，参与过 WebGPT 的研发，后来又加入 GPT-4 的预训练团队，o1 的推理团队以及 ChatGPT 的后训练团队。2024 年 8 月，他因对公司的商业行为感到失望后离职，并公开表达了自己的担忧：「如果你相信我所相信的，你就必须离开公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;10 月份，Balaji 因指控 OpenAI 非法使用受版权保护的材料来训练其 AI 模型而广受关注。《纽约时报》后来将他列为该报对 OpenAI 的诉讼中「拥有独特和相关文件」的关键人物。彼时，OpenAI 正在被众多著名作家和新闻出版商起诉侵犯版权。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;离开 OpenAI 后，Balaji 表示自己一直在从事「个人项目」。据他母亲说，他计划创建一个以机器学习和神经科学为中心的非营利组织。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334332/death-of-openai-suchir-balaji</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334332/death-of-openai-suchir-balaji</guid>
            <pubDate>Sat, 08 Feb 2025 07:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Asahi Linux 创始人宣布辞去项目负责人职务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;上周，Hector Martin 辞去了 Linux 内核 Apple Silicon 代码的上游维护工作。当时他仍然计划为 Asahi Linux 项目的下游内核做出贡献，但就在前两天，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarcan.st%2F2025%2F02%2Fresigning-as-asahi-linux-project-lead%2F&quot; target=&quot;_blank&quot;&gt;他出人意料地决定辞去 Asahi Linux 项目负责人的职位&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/143821_rzmV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Asahi Linux 项目创始人 Hector Martin 在博客宣布，他将辞去项目负责人的职务。Martin 说道，随着时间的推移，参与项目变得越来越没有乐趣，并注意到了关于 Asahi Linux 在 Apple Silicon 上缺乏 Apple M3/M4 支持以及其他缺失功能（如 Thunderbolt 和 USB-C 显示器）的用户投诉。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由于围绕 Apple 芯片硬件上 Asahi Linux 的用户期望感到沮丧，并且最近还与 Linux 内核中 Rust 代码的上游挫折/争论/挑战以及其他因素相关，Hector Martin 决定辞职&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「我立即辞去 Asahi Linux 项目负责人的职务。Asahi Linux&amp;nbsp;项目将继续进行，我正在与团队的其他成员一起处理职责和行政凭证的移交。我的个人 Patreon 将暂停，那些曾向我个人捐赠的用户建议转移到 Asahi Linux OpenCollective（GitHub Sponsors 不允许我单方面暂停付款，但我的赞助者将被告知这一变化，以便他们可以手动取消赞助）。&lt;/p&gt; 
 &lt;p&gt;我想感谢整个 Asahi Linux 团队，没有你们，我独自一人根本无法取得任何进展。我还对我的所有 Patreon 和 GitHub 赞助者表示最深切的感激，是你们让这个项目从一开始就成为一个可行的现实。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Martin 在博客中也表达了对 Linus 的失望：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Rust for Linux 作为一个上游 Linux 项目所遇到的问题已经有详细的记录，我就不在此赘述了。我只想说，我认为 Linus 在处理将 Rust 整合到 Linux 中的问题上是其作为领导者的一大败笔。&lt;strong&gt;这样一个大型项目需要得到主要利益相关者的大力支持才能生存下去，而他的做法似乎只是静观其变&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;与此同时，在他下游的多个子系统维护者却竭力阻挠或妨碍项目的进行，发出令人无法接受的辱骂，并普遍打击士气。几个月前，一位主要的 Rust for Linux 维护者已经辞职。&lt;/p&gt; 
 &lt;p&gt;当苹果发布 M1 时，Linus Torvalds 希望它能运行 Linux，但并不抱太大希望。我们实现了这一愿望，Linux 5.19 从运行 Asahi Linux 的 M2 MacBook Air 上发布。我曾希望他的热情能转化为对我们社区的支持，并帮助我们解决上游问题。&lt;/p&gt; 
 &lt;p&gt;遗憾的是，这一切都没有实现。2023 年 11 月，我向他发出邀请，与他讨论内核贡献和维护方面的挑战，看看我们能提供什么帮助。他从未回复。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Asahi Linux 博客也&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fasahilinux.org%2F2025%2F02%2Fpassing-the-torch%2F&quot; target=&quot;_blank&quot;&gt;已确认了 Hector 的辞职&lt;/a&gt;，而剩余的开发者计划继续推动 Linux 在 Apple Silicon 硬件上的发展。&lt;/p&gt; 
&lt;p&gt;当前 Asahi Linux 成员包括 Alyssa Rosenzweig、chaos_princess、Davide Cavalca、Neal Gompa、James Calligeros、Janne Grunau 和 Sven Peter。剩余的开发者表示他们仍将专注于将代码提交到 Linux 内核。预计 Apple M3 和 M4 硬件支持将在他们更多的代码被提交到上游以及持续集成取得进展之后才会实现。&lt;/p&gt; 
&lt;p&gt;对于今年的 Apple M1/M2 硬件，他们希望实现 DP Alt Mode、Vulkan 驱动程序中的稀疏图像以及内置麦克风支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead</guid>
            <pubDate>Sat, 08 Feb 2025 06:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>GNOME 官网全新改版</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;GNOME 全新官网已&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnome.org%2F&quot; target=&quot;_blank&quot;&gt;上线&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;screenshot&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142818_JmM4.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新的设计看起来既时尚又现代，它简化了头部设计、空间更宽敞，色彩更鲜艳，还有简单而有效的动画，等等，比之前（相对单调）的旧版本更能传达 GNOME 充满活力、以用户为中心的理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142819_RWzj.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;文档方面，GNOME 开发文档和设计指南现在各自拥有专门的章节，并附上了相关链接，还有一个部分展示了支持 GNOME 的组织列表（包括 Canonical），以强调 GNOME 在更广泛的 Linux 生态中扮演的关键角色。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142820_bW25.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;详情访问 GNOME 官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnome.org%2F&quot; target=&quot;_blank&quot;&gt;https://www.gnome.org/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334308/gnome-website-revamp-goes-live</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334308/gnome-website-revamp-goes-live</guid>
            <pubDate>Sat, 08 Feb 2025 06:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「天工」成为全球首例登百级台阶的人形机器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国地共建具身智能机器人创新中心宣布，在户外真实地形测试中，「天工」机器人连续攀爬多级阶梯，成功登上北京通州区海子墙公园最高点，成为全球首例可在室外连续攀爬多级阶梯的人形机器人。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国创中心持续提升具身小脑能力，实现了基于视觉的感知行走，可实现无磕碰、不踩棱、不踏空地跨越连续多级楼梯和 35 厘米大高差台阶，奔跑时速提高至 12km/h，并且能在雪地进行高速奔跑，同时具备更强的抗干扰能力，大外力冲击下仍可保持平衡。应对复杂地形的移动能力提升，将成为人形机器人走出实验室，在真实环境执行任务，甚至在山地、雪地救援、废墟等极端环境下作业的基础，为具身智能机器人规模化应用夯实技术底座。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fb4868df102f12e166908215d6ce18410f2.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，升级后的「天工」能够轻松应对超 10KG 重物落下所造成的高达 45Ns 冲量，相当于一名职业拳击手以 450 N 的力，重击对手的一瞬间打出的力道，即使在光滑的雪地上从各个方向突然出现的各类干扰等，「天工」均能保持稳定平衡不发生摔倒，达到业内领先水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通过具身小脑所带来的全身控制能力升级，「天工」面对复杂环境的移动能力再次大幅提升，首次真正发挥出双足结构为人形机器人带来的多地形通用性优势，在实现全地形场景技术闭环的同时，更为行业确立了复杂环境移动能力的全新标杆。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;未来，该技术也将纳入国创中心所打造的开源开放生态汇总，通过技术共享降低行业创新门槛将加速具身智能机器人在千行百业的规模化落地，为具身智能产业化开辟更具想象力的落地路径。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289801&quot; target=&quot;_blank&quot;&gt;北京人形机器人创新中心发布全球首个纯电驱拟人奔跑的全尺寸人形机器人 「天工」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334302</guid>
            <pubDate>Sat, 08 Feb 2025 06:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ReasonFlux：通过分层模板缩放提升 LLM 推理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大型语言模型（LLMs）已经展现出了卓越的问题解决能力，然而，复杂的推理任务——例如竞技级别的数学问题或复杂的代码生成——仍然具有挑战性。这些任务需要精确地穿越庞大的解空间，并进行细致的逐步思考。现有的方法虽然在提高准确性方面有所改进，但往往面临着高计算成本、僵化的搜索策略以及难以跨不同问题进行泛化的难题。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.marktechpost.com%2F2025%2F02%2F15%2Freasonflux-elevating-llm-reasoning-with-hierarchical-template-scaling%2F&quot; target=&quot;_blank&quot;&gt;https://www.marktechpost.com/2025/02/15/reasonflux-elevating-llm-reasoning-with-hierarchical-template-scaling/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在这篇论文中，研究人员介绍了一个新的框架，&lt;strong&gt;ReasonFlux&lt;/strong&gt;，它通过重新构想 LLMs 如何使用分层、模板引导的策略来规划和执行推理步骤，从而解决了这些局限性。 最近用于增强大型语言模型推理的方法分为两大类：&lt;em&gt;深思熟虑的搜索_和_奖励引导的方法&lt;/em&gt;。像思维树（ToT）这样的技术使 LLM 能够探索多个推理路径，而蒙特卡洛树搜索（MCTS）则将问题分解为步骤，这些步骤由过程奖励模型（PRM）引导。&lt;/p&gt; 
&lt;p&gt;尽管这些方法有效，但由于采样过多和手动搜索设计，它们的可扩展性较差。例如，MCTS 需要遍历成千上万的潜在步骤，这使得它在实际应用中计算成本过高。与此同时，像思维缓冲（BoT）这样的检索增强生成 RAG 方法利用存储的问题解决模板，但在适应性地整合多个模板方面存在困难，这限制了它们在复杂场景中的效用。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1066&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/135909_MMin_3820517.png&quot; width=&quot;1750&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;ReasonFlux 引入了一个结构化的框架，该框架结合了精选的高层次思维模板库与分层强化学习（HRL），以动态规划和优化推理路径。它不是优化单个步骤，而是专注于配置最优的 &lt;em&gt;模板轨迹&lt;/em&gt;——从结构化知识库中检索出的抽象问题解决策略序列。这种方法简化了搜索空间，并使高效适应子问题成为可能。该框架由三个主要组件组成：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;结构化模板库&lt;/strong&gt;：研究团队构建了一个包含 500 个思维模板的库，每个模板封装了一种问题解决策略（例如，「三角代换优化积分」）。模板包含元数据——名称、标签、描述和应用步骤——以实现高效的检索。例如，一个标记为「有理函数优化」的模板可能会指导大型语言模型（LLM）应用特定的代数替换。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分层强化学习&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;基于结构的微调&lt;/strong&gt;：将基本 LLM（例如，Qwen2.5-32B）微调以将模板元数据与其功能描述关联起来，确保它理解何时以及如何应用每个模板。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;模板轨迹优化&lt;/strong&gt;：利用偏好学习，该模型学会根据效果对模板序列进行排序。对于给定的问题，会采样多个轨迹，并根据它们在类似问题上的成功率来确定奖励。这训练模型优先考虑高奖励序列，从而提高其规划能力。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自适应推理缩放&lt;/strong&gt;：在推理过程中，ReasonFlux 充当「导航员」，分析问题以检索相关模板，并根据中间结果动态调整轨迹。例如，如果一个涉及「多项式因式分解」的步骤产生了意外的约束，系统可能会转向「约束传播」模板。这种规划和执行之间的迭代互动反映了人类的解决问题方式，其中部分解决方案会指导后续步骤。&lt;/p&gt; &lt;img height=&quot;376&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/135928_eZy6_3820517.png&quot; width=&quot;1686&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ReasonFlux 在 MATH、AIME 和 OlympiadBench 等竞争级基准测试中进行了评估，超越了前沿模型（GPT-4o、Claude）以及专业开源模型（DeepSeek-V3、Mathstral）。关键结果包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MATH 准确率达到 91.2%，超过 OpenAI 的 o1-preview 6.7%。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 准确率为 56.7%，超出 DeepSeek-V3 45%，与 o1-mini 相当。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OlympiadBench 准确率为 63.3%，比先前方法提高了 14%。&lt;/strong&gt;此外，结构化模板库展示了强大的泛化能力：当应用于不同的问题时，它将小型模型（例如，7B 参数）的能力提升至能够通过直接推理超越大型模型。此外，ReasonFlux 实现了更好的探索-利用平衡，在复杂任务上比 MCTS 和 Best-of-N 需要少 40% 的计算步骤（见图 5）。 总结来说，ReasonFlux 重新定义了 LLMs 处理复杂推理的方式，通过将高级策略与逐步执行解耦。其分层模板系统减少了计算开销，同时提高了准确性和适应性，解决了现有方法中的关键差距。通过利用结构化知识和动态规划，该框架为高效、可扩展的推理设定了新的标准——证明即使是小型、有良好指导的模型也能与最大的前沿系统相媲美。这一创新为在资源受限的环境中部署高级推理开辟了道路，从教育到自动化代码生成。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334301/reasonflux-llm</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334301/reasonflux-llm</guid>
            <pubDate>Sat, 08 Feb 2025 06:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>FocusAny 支持 DeepSeek 模型，每天可领取 100W Token</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:0&quot;&gt;近日，领先的 AI 工具平台 FocusAny 接入 DeepSeek 模型，正式集成其先进的大语言模型。此次合作旨在为用户提供更强大的 AI 支持，进一步提升工作效率和创造力。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//9c01f3c5c8b3e42afb8182d15f5b275e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;每日免费领取 100W Token&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;为庆祝此次合作，FocusAny 推出限时福利：即日起，所有用户每天可免费领取 100W Token，用于体验 DeepSeek 模型的强大功能。无论是文本生成、代码编写，还是数据分析，DeepSeek 模型都能为用户提供高效、精准的解决方案。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//5038c86744ea401feae4ac2c6e409313.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;DeepSeek 模型：智能助手的新标杆&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;DeepSeek 模型以其卓越的自然语言处理能力和广泛的应用场景著称。通过与 FocusAny 的集成，用户可以在日常工作中轻松调用 DeepSeek 模型，享受智能化的写作、编程和决策支持。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//036551e3cdfcc5944030070159b6789f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;strong&gt;&lt;span&gt;关于 FocusAny&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;FocusAny 作为一家致力于提供高效、便捷 AI 服务的平台，此次接入 DeepSeek 无疑将为用户带来更加丰富的功能和体验。通过&amp;nbsp;FocusAny，用户可以轻松接入 DeepSeek 模型，利用其强大的推理能力解决各种问题。同时，每天可领取的 100 万 Token 也为用户提供了充足的资源，让他们能够尽情体验 DeepSeek 模型的各项功能。&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//d77626550ffe45ef7e3be5e04b0d8c4e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;关于 DeepSeek&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;DeepSeek 是由幻方量化创立的人工智能公司推出的一系列 AI 模型，包括 DeepSeekCoder、DeepSeekLLM、DeepSeek-V2、DeepSeek-V3 和 DeepSeek-R1 等多个版本。这些模型在技术架构上展现出了前所未有的突破，采用了混合专家架构（MoE）、多头潜在注意力（MLA）机制等创新技术，极大地提升了模型的处理效率和准确性。DeepSeek 模型在自然语言处理、代码生成与编程辅助、多模态数据处理等多个领域内展示了卓越的能力，成为了众多企业和开发者首选的解决方案。&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;随着 AI 技术的不断发展，DeepSeek 系列模型的应用场景也将越来越广泛。FocusAny 接入 DeepSeek，无疑将为 AI 技术的应用和发展注入新的活力。我们期待未来 FocusAny 能够为用户带来更多惊喜和突破，共同推动 AI 技术的进步和发展。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334299</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334299</guid>
            <pubDate>Sat, 08 Feb 2025 05:57:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>微软开源「专业领域知识-推理能力 RAG」 —— PIKE-RAG</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近年来，大语言模型（LLM）凭借强大的文本生成能力在各个领域引起了广泛关注。它们不仅能写文章、翻译语言，还能完成创作任务。但当遇到需要专业领域知识支持的工业级问题时，比如半导体设计、制药研发或法律条文解读，这些模型往往力不从心。这不仅因为训练数据中缺少足够的专业信息，还因为单靠「生成」能力，难以构建严谨的逻辑推理和多层次的信息整合。&lt;/p&gt; 
&lt;h2&gt;为什么传统方法会遇到瓶颈？&lt;/h2&gt; 
&lt;p&gt;目前，为了解决这一问题，业界提出了「检索增强生成」（Retrieval-Augmented Generation，简称 RAG）的思路。其核心理念是在生成答案之前，先从一个庞大的外部知识库中检索出相关信息，再将这些信息融入生成的上下文中，从而使回答更准确、更有事实依据。&lt;/p&gt; 
&lt;p&gt;然而，传统 RAG 方法存在以下几个问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知识来源复杂&lt;/strong&gt;：现实中的数据不仅仅是纯文本，还包括表格、图表、图片等多种格式。单一的文本检索难以捕捉这些多样信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;专业领域知识不足&lt;/strong&gt;：工业应用中的专业知识具有特定术语和逻辑，普通模型难以准确提取和理解，从而导致回答不够严谨。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「一刀切」的策略&lt;/strong&gt;：不同类型的问题（如简单事实问答与需要多步推理的复杂问题）要求不同的处理策略，而传统方法往往采用统一流程，无法兼顾所有需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PIKE-RAG 的创新之处&lt;/h2&gt; 
&lt;p&gt;为了解决上述不足，微软亚洲研究院提出了 PIKE-RAG —— 一种专注于「知识」和「推理」增强的生成框架。PIKE-RAG 不仅帮助模型检索相关知识，更注重如何理解、拆解和合理组织这些信息，从而构建出严谨的推理链。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;788&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121127_pF8y_3820517.png&quot; width=&quot;2072&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;792&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121200_n64m_3820517.png&quot; width=&quot;2058&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;810&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121040_68c7_3820517.png&quot; width=&quot;2088&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面我们来看看它的核心设计：&lt;/p&gt; 
&lt;h3&gt;1. 分级任务设计&lt;/h3&gt; 
&lt;p&gt;论文将问题大致分为四类：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事实型问题&lt;/strong&gt;：例如「这款 LED 产品的额定电流是多少？」&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;链式推理问题&lt;/strong&gt;：需要跨多个信息点进行关联，比如比较多个产品的性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;预测型问题&lt;/strong&gt;：例如「未来 5 年半导体技术可能有哪些突破？」&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;创造型问题&lt;/strong&gt;：要求模型发挥创造力，提出新见解。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种分类使得系统能根据问题的难度和性质，采用针对性的处理策略，从而「量体裁衣」地提升答案的准确性和逻辑性。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1246&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/120535_p84F_3820517.png&quot; width=&quot;1124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;2. 知识「原子化」与任务分解&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知识原子化&lt;/strong&gt;：面对复杂问题，系统会将长文档或复杂数据拆分成最基本的信息单元（知识原子）。这种拆分类似于把大问题拆成小问题，每个小单元便于独立检索和理解。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知识感知的任务分解&lt;/strong&gt;：系统根据问题需求，动态分解任务，并利用已提取的知识原子构建逻辑推理链。这样一来，即使是多步推理的问题，系统也能循序渐进地「拼凑」出最终答案。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;任务分解器训练&lt;/strong&gt;：为实现高效分解，系统还引入了可训练的任务分解模块，通过大量领域数据学习如何将问题正确拆解并合理组合各个知识点。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 分阶段系统构建&lt;/h3&gt; 
&lt;p&gt;PIKE-RAG 采用了分阶段的开发策略，逐步提升系统的处理能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;初级阶段&lt;/strong&gt;：专注于构建一个多模态知识库。系统会从文本、表格、图像等多种格式中抽取信息，并利用解析算法将它们统一组织成一个结构化、关联紧密的知识网络。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中级阶段&lt;/strong&gt;：在事实型问题上引入多粒度检索技术，结合增强型文本切分和自动标记机制，确保能精确提取出关键信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高级阶段&lt;/strong&gt;：逐步引入链式推理模块、知识原子化处理和任务分解器，使系统不仅能够检索信息，更能在多跳推理、预测和创造性回答等复杂任务中表现优异。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;实现原理：如何让系统「知晓」与「推理」&lt;/h2&gt; 
&lt;p&gt;在 PIKE-RAG 系统中，设计者采用了层次化、分阶段的实现策略，确保系统能逐步提升对复杂问题的处理能力。下面详细介绍各个主要环节的实现原理：&lt;/p&gt; 
&lt;h3&gt;1. 知识库构建（Level-0）&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;文件解析&lt;/strong&gt;：系统首先从各种格式的数据中抽取信息，将非结构化数据（如扫描文档、表格、图片中的文字）经过专门算法转换为统一的文本数据。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知识组织&lt;/strong&gt;：解析后的信息被组织成一个多层次的异构图，各类数据节点（例如产品技术规格、图表、说明文字等）通过超链接、引用关系等方式互相连接，形成结构化的知识库，便于后续的高效检索和利用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 专门模块针对不同问题&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;事实型问题模块（Level-1）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;增强型切分与自动标记&lt;/strong&gt;：长文档被切分成更小的信息块，并自动为每个信息块打上标签，以便在检索时更精确地匹配查询内容。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;多粒度检索&lt;/strong&gt;：系统在检索时不仅搜索全文，还能在不同层级和粒度上查找相关信息，提高检索的准确性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;链式推理问题模块（Level-2）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;知识原子化&lt;/strong&gt;：将大块复杂知识拆解成最小的基本单元，使得每个单元都能独立检索并参与推理。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;任务分解&lt;/strong&gt;：针对复杂问题，系统动态分解成多个子任务，每个子任务依次解决后再组合成最终答案。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;训练可调的任务分解器&lt;/strong&gt;：通过大量领域数据训练，系统学会如何针对不同专业问题设计合适的分解策略和推理流程。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;预测型与创造型问题模块（Level-3 &amp;amp; Level-4）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在高级阶段，系统不仅能处理已知信息，还能在已有数据基础上推演预测未来趋势或提出创造性观点，从而满足更高层次的应用需求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;684&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/120551_g5tH_3820517.png&quot; width=&quot;828&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3. 分阶段开发策略&lt;/h3&gt; 
&lt;p&gt;整个系统从构建基础知识库开始，逐步引入不同层次的检索与推理模块。每个阶段的开发都以解决特定问题为目标：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;初级阶段&lt;/strong&gt;确保系统在简单事实问答上表现出色；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中级阶段&lt;/strong&gt;引入多跳推理和任务分解，处理更复杂的问题；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高级阶段&lt;/strong&gt;则针对预测和创造性任务进行优化，使系统具备更强的灵活性和适应性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;实验效果与应用前景&lt;/h2&gt; 
&lt;p&gt;通过大量实验验证，PIKE-RAG 在开放领域和法律领域的问答任务中均展现了卓越的性能。得益于知识原子化、任务分解以及多粒度检索技术，该系统在处理多步推理和复杂查询时表现尤为出色。这不仅为工业级问答系统的发展提供了新思路，也为未来在更多复杂场景中的应用奠定了基础。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FPIKE-RAG&quot; target=&quot;_blank&quot;&gt;https://github.com/microsoft/PIKE-RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpike-rag.azurewebsites.net%2F&quot; target=&quot;_blank&quot;&gt;https://pike-rag.azurewebsites.net&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334286/microsoft-pike-rag</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334286/microsoft-pike-rag</guid>
            <pubDate>Sat, 08 Feb 2025 04:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OBS Studio 批评 Fedora 的 Flatpak 打包，称其是恶意分支</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;开源屏幕录制和直播应用 OBS Studio 近日向 Fedora 提出了批评，指出它对该应用程序的 Flatpak 打包存在问题，并威胁说如果不加以解决，将采取法律行动。&lt;/p&gt; 
&lt;p&gt;三周前 OBS Studio 团队就提交了&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.com%2Ffedora%2Fsigs%2Fflatpak%2Ffedora-flatpaks%2F-%2Fissues%2F39%23note_2344970813&quot; target=&quot;_blank&quot;&gt;Fedora Flatpak SIG 工单&lt;/a&gt;&amp;nbsp;—— 关于 Fedora 提供「损坏」的 OBS Studio Flatpak 被视为官方软件包：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「Fedora Flatpaks 应用商店提供的非官方 OBS Studio Flatpak 似乎打包不佳且已损坏，导致用户向上游投诉，因为他们认为这是 OBS Studio 的官方软件包。这种情况在 OBS Studio 之外也存在多个例子，许多用户对 Fedora Flatpaks 被强制推广，缺少或没有明确的选项退出感到不满。&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.gnome.org%2FGNOME%2Fgnome-software%2F-%2Fissues%2F2754&quot; target=&quot;_blank&quot;&gt;https://gitlab.gnome.org/GNOME/gnome-software/-/issues/2754&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpagure.io%2Ffedora-workstation%2Fissue%2F463&quot; target=&quot;_blank&quot;&gt;https://pagure.io/fedora-workstation/issue/463&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;我们希望请求将该软件包移除，或者明确指出它是一个第三方软件包。&lt;strong&gt;确保下游软件包正常工作不应是上游的责任，尤其是当它们覆盖官方软件包时&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;我还想了解为什么有人认为将一个运行得非常完美的 Flatpak 版本破坏后，以更高的优先级发布到我们的官方构建中是一个好主意。我们在官方 Flatpak 上投入了大量的努力，以确保它们在 Flathub 上发布时能尽可能地正常运行。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;但然后在过去的一天里，Fedora 不但没有删除，似乎还和 OBS Studio 团队对骂起来，这让后者非常不爽，因此认定 Fedora Flatpak 上的 OBS Studio 是个恶意分支，并威胁采取法律行动：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于目前很明显 Fedora 对此没有兴趣进行理性讨论，并决定诉诸于人身攻击，我们现在将 Fedora Flatpaks 分发的 OBS Studio 视为恶意分支。&lt;/p&gt; 
 &lt;p&gt;这是一个正式请求，要求从您的分发中移除我们所有的品牌标识，包括但不限于我们的名称、我们的标志、属于 OBS 项目的任何附加知识产权。&lt;/p&gt; 
 &lt;p&gt;如果不遵守，可能会导致采取进一步的法律行动。我们期望在接下来的 7 个工作日内收到回复（截至 2025 年 2 月 21 日星期五）。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334282/obs-studio-poor-fedora-flatpak</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334282/obs-studio-poor-fedora-flatpak</guid>
            <pubDate>Sat, 08 Feb 2025 03:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 快速集成和使用 solon-flow 规则与流引擎（用 yaml 编写业务规则）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本文参考自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnblogs.com%2Fstudyjobs%2Fp%2F18125096&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/studyjobs/p/18125096&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;规则引擎技术的主要思想是将应用程序中的业务规则分离出来，业务规则不再以程序代码的形式驻留在系统中，而是存储在独立的文件或者数据库中，完全独立于程序。业务人员可以像管理数据一样对业务规则进行管理。业务规则在程序运行时被加载到规则引擎中供应用系统调用。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 是新的规则引擎技术，由 OpenSolon 开源组织提供的基于 Java 语言开发的开源规则引擎，可以将复杂且多变的业务规则从硬编码中解放出来，以 yaml 规则脚本的形式存放在文件或特定的存储介质中（例如数据库），使得业务规则的变更不需要修改项目代码、不需要重启服务器就可以立即生效。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本篇博客的 demo 以个税计算器为例，介绍如何使用 solon-flow 规则引擎，有关具体技术细节，限于篇幅有限，这里不会介绍，具体细节可以参考官网。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 官网地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2Flearn-solon-flow&quot; target=&quot;_blank&quot;&gt;https://solon.noear.org/article/learn-solon-flow&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 源码下载地址：&lt;a href=&quot;https://gitee.com/opensolon/solon/tree/main/solon-projects/solon-flow/solon-flow&quot;&gt;https://gitee.com/opensolon/solon/tree/main/solon-projects/solon-flow/solon-flow&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1、搭建工程&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;搭建一个 solon 工程，结构如下：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a2c3e430e7024d75925e6ced1b180c30.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 规则引擎将规则编写在以 .yml （很流行的配置文）为后缀的文件中，yml 文件默认也是使用 yaml + java 语言编写，所以学习起来很容易。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;一般情况下，我们使用 IDEA 编写业务规则，默认情况下 .yml 文件会被打包到项目 jar 包中，为了方便后续调整规则，我们可以将 yml 文件的内容，存储到数据库中或者 oss 云盘中，程序在运行时从 jar 包外部读取规则内容。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;完束上的 pom 文件的内容：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;&amp;lt;?xml version=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;1.0&quot;&lt;/span&gt; encoding=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;project&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;xmlns&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://maven.apache.org/POM/4.0.0&quot;&lt;/span&gt;
         &lt;span style=&quot;color:#986801&quot;&gt;
                xmlns:xsi&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt;
         &lt;span style=&quot;color:#986801&quot;&gt;xsi:schemaLocation&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;modelVersion&lt;/span&gt;&amp;gt;&lt;/span&gt;4.0.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;modelVersion&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-parent&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;3.0.8&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;relativePath&lt;/span&gt; /&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.example&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;demo-rule&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;java.version&lt;/span&gt;&amp;gt;&lt;/span&gt;11&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;java.version&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-web&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;em&gt;&amp;lt;!-- 规则与流引擎 --&amp;gt;&lt;/em&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-flow&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-logging-simple&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.projectlombok&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;lombok&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;provided&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-test&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;test&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;build&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;finalName&lt;/span&gt;&amp;gt;&lt;/span&gt;${project.artifactId}&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;finalName&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;plugins&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;plugin&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-maven-plugin&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;plugin&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;plugins&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;build&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;project&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2、代码细节展示&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;此文的 demo 是个税计算器，我们创建一个用于向规则引擎传递数据的实体类&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#a626a4&quot;&gt;package&lt;/span&gt; com.example.demo.model;

&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; lombok.Data;

&lt;span style=&quot;color:#4078f2&quot;&gt;@Data&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;Calculation&lt;/span&gt; {
    &lt;em&gt;//税前工资&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wage;
    &lt;em&gt;//应纳税所得额&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wagemore;
    &lt;em&gt;//税率&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; cess;
    &lt;em&gt;//速算扣除数&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; preminus;
    &lt;em&gt;//扣税额&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wageminus;
    &lt;em&gt;//税后工资&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; actualwage;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;这里不考虑缴纳社保和专项扣除等因素，个税计算的规则如下：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img height=&quot;250&quot; src=&quot;https://oscimg.oschina.net/oscnet//ebd65a9942d8b3bc121987723eeaa014.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;之后我们在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;flow/rule.yml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中编写的规则如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;rule&lt;/span&gt;
&lt;span style=&quot;color:#986801&quot;&gt;nodes:&lt;/span&gt;
  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_setWagemore&quot;&lt;/span&gt; &lt;em&gt;#计算应纳税所得额&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      import java.time.LocalDate;
      //2022-10-1 后生效
      return cal.getWage() &amp;gt; 0 &amp;amp;&amp;amp; LocalDate.now().compareTo(LocalDate.of(2022,10,1)) &amp;gt; 0;
&lt;/span&gt;    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      double wagemore = cal.getWage() - 5000;
      cal.setWagemore(wagemore);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_3000&quot;&lt;/span&gt;  &lt;em&gt;#设置税率、速算扣除数&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;lt;= 3000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.03);//税率
      cal.setPreminus(0);//速算扣除数
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 3000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.1);//税率
      cal.setPreminus(210);//速算扣除数
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_25000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 12000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 25000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.2);
      cal.setPreminus(1410);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_35000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 25000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 35000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.25);
      cal.setPreminus(2660);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_55000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 35000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 55000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.25);
      cal.setPreminus(2660);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 55000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.35);
      cal.setPreminus(7160);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_max&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.45);
      cal.setPreminus(15160);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_result&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWage() &amp;gt; 0 &amp;amp;&amp;amp; cal.getWagemore() &amp;gt; 0 &amp;amp;&amp;amp; cal.getCess() &amp;gt; 0&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      //扣税额
      double wageminus = cal.getWagemore() * cal.getCess() - cal.getPreminus();
      double actualwage = cal.getWage() - wageminus;
      cal.setWageminus(wageminus);
      cal.setActualwage(actualwage);
      System.out.println(&quot;--税前工资：&quot;+cal.getWage());
      System.out.println(&quot;--应纳税所得额：&quot;+cal.getWagemore());
      System.out.println(&quot;--税率：&quot; + cal.getCess());
      System.out.println(&quot;--速算扣除数：&quot; + cal.getPreminus());
      System.out.println(&quot;--扣税额：&quot; + cal.getWageminus());
      System.out.println(&quot;--税后工资：&quot; + cal.getActualwage());
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本 demo 设定每次被调用时，都去读取 rule.yml 的内容（可时实生效），具体代码在 RuleService 中实现：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#a626a4&quot;&gt;package&lt;/span&gt; com.example.demo.dso;

&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; com.example.demo.model.Calculation;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.annotation.Component;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.flow.ChainContext;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.flow.FlowEngine;

&lt;span style=&quot;color:#4078f2&quot;&gt;@Component&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;RuleService&lt;/span&gt; {
    &lt;em&gt;//调用 Drools 规则引擎实现个人所得税计算&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Calculation &lt;span style=&quot;color:#4078f2&quot;&gt;calculate&lt;/span&gt;&lt;span&gt;(Calculation calculation)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; Throwable {
        &lt;span style=&quot;color:#986801&quot;&gt;FlowEngine&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;flowEngine&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; FlowEngine.newInstance();
        flowEngine.load(Chain.parseByUri(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;file:src/main/resources/flow/rule.yml&quot;&lt;/span&gt;)); &lt;em&gt;//动态加载源码下的文件，修改后实时生效&lt;/em&gt;

        &lt;em&gt;//构建上下文&lt;/em&gt;
        &lt;span style=&quot;color:#986801&quot;&gt;ChainContext&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;ctx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;ChainContext&lt;/span&gt;();
        ctx.put(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal&quot;&lt;/span&gt;, calculation);

        &lt;em&gt;//执行规则&lt;/em&gt;
        flowEngine.eval(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;rule&quot;&lt;/span&gt;, ctx);

        &lt;em&gt;//返回运行算后的&lt;/em&gt;
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; calculation;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;然后在 RuleController 中对外提供计算个税的接口，只需要传递一个税前工资额即可计算得出结果&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;rule&quot;)&lt;/span&gt;
&lt;span style=&quot;color:#4078f2&quot;&gt;@Controller&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;RuleController&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    RuleService ruleService;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;calculate&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Calculation &lt;span style=&quot;color:#4078f2&quot;&gt;calculate&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wage)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; Throwable {
        &lt;span style=&quot;color:#986801&quot;&gt;Calculation&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;calculation&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;Calculation&lt;/span&gt;();
        calculation.setWage(wage);
        calculation = ruleService.calculate(calculation);
        System.out.println(calculation);
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; calculation;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3、验证成果&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;启动后，可以访问接口&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;http://localhost:8080/rule/calculate?wage=10000&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;即可查看到静态页面，输入 10000 元计算个税，如下图：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df17e27488d65c9710b199cfd67a33fb.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;结果可以发现，税率是 0.1，执行的是 rule.yml 文件中的名称为 tax_12000 的规则，此时你可以使用 IDEA 修改一下，比如将税率修改为 0.2&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 3000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.2);//这里故意将税率修改为 0.2
      cal.setPreminus(210);//速算扣除数
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;注意不需要重启 IDEA 的项目（可时实生效），此时重新点击页面中的计算，发现刚刚修改的规则生效了，如下图所示：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3887df8f59e854e1ad073beefcebd3da.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;好了，以上就是有关 solon-flow 规则引擎的介绍（在 spring 里差不多），有兴趣的话可以下载源代码进行验证。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本示例，源码下载地址：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;a href=&quot;https://gitee.com/opensolon/solon-flow_rule-demo&quot;&gt;https://gitee.com/opensolon/solon-flow_rule-demo&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            
            
            </description>
            <link>https://www.oschina.net/news/334278</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334278</guid>
            <pubDate>Sat, 08 Feb 2025 03:33:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>2024 年 Rust 社区调查报告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Rust 调查团队很高兴与大家分享我们关于 Rust 编程语言的 2024 年调查结果，该调查于 2024 年 12 月 5 日至 2024 年 12 月 23 日进行。与往年一样，2024 年的 Rust 状态调查旨在收集 Rust 用户以及更广泛地关注 Rust 未来的所有人的见解和反馈。&lt;/p&gt; 
&lt;p&gt;这份调查的第九版揭示了来自全球 Rust 语言社区的全新见解和学习机会，以下我们将进行总结。除了这篇博客文章外，&lt;strong&gt;我们还&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fraw.githubusercontent.com%2Frust-lang%2Fsurveys%2Fmain%2Fsurveys%2F2024-annual-survey%2Freport%2Fannual-survey-2024-report.pdf&quot; target=&quot;_blank&quot;&gt;准备了一份报告&lt;/a&gt;&lt;/u&gt;&lt;/strong&gt;，其中包含了调查中所有问题的汇总结果图表。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我们对每一位在过去一年中抽出时间表达对 Rust 看法和体验的社区成员表示最诚挚的感谢。您的参与将帮助我们使 Rust 对每个人来说都变得更好。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下文包含了大量数据，所以请坐稳，享受阅读！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参与&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111550_gaCL_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，2024 年，我们收到的调查查看次数比上一年少。这可能是由于调查仅进行了两周，而上一年调查进行了近一个月。然而，完成率也有所下降，这似乎表明调查可能有点太长了。我们将考虑这一点，为下一次调查的版本进行调整。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;社区&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Rust 状态调查不仅为我们提供了关于世界各地有多少 Rust 用户在使用和体验该语言的宝贵见解，而且还让我们了解了我们全球社区的结构。这些信息让我们了解到语言的使用情况以及随着时间的推移，我们可能需要解决的接入差距。我们希望这些数据和我们的相关分析能进一步促进关于我们如何继续优先考虑 Rust 社区的全球接入和包容性的重要讨论。&lt;/p&gt; 
&lt;p&gt;与往年一样，我们询问了受访者他们居住在哪个国家。排名前十的国家依次是：美国（22%）、德国（14%）、英国（6%）、法国（6%）、中国（5%）、加拿大（3%）、荷兰（3%）、俄罗斯（3%）、澳大利亚（2%）和瑞典（2%）。我们很高兴看到 Rust 受到世界各地用户的喜爱！您可以在下面的图表中尝试找到您的国家：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111604_Xkme_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们也询问了受访者是否认为自己属于一个边缘化社区的一员。在回答者中，74.5% 选择了「否」，15.5% 选择了「是」，10% 选择不愿意透露。&lt;/p&gt; 
&lt;p&gt;我们询问了选择「是」的群体，他们将自己识别为哪些特定群体的成员。将自己视为技术领域中被代表性不足或边缘化群体成员的大多数人将自己识别为女同性恋、男同性恋、双性恋或其他非异性恋。其次是神经多样性群体，占比 46%，其次是跨性别群体，占比 35%。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111617_hrzo_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;每年，我们必须承认 Rust 社区和开源整体在多样性、公平性和包容性（DEI）方面的差距。我们相信，Rust 基金会在推进 Rust 社区聚会全球访问和在每个周期向多元化的维护者群体分配补助金方面正在开展出色的工作，您可以在这里了解更多信息。即便如此，全球包容性和访问性只是 DEI 的一个要素，调查工作组将继续在这个领域推动进步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust 使用情况&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自认是 Rust 用户的人数与去年相当，大约为 92%。这个高比例并不令人惊讶，因为我们主要针对现有的 Rust 开发者进行这项调查。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111627_7qhc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;同样地，像去年一样，大约 31% 的未将自己标识为 Rust 用户的人士将难度感知作为不使用 Rust 的主要原因。不使用 Rust 的最常见原因是受访者们还没有机会尝试它。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111639_1Cns_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在参与 2024 年调查的前 Rust 用户中，36% 的人士将不可控因素列为他们不再使用 Rust 的原因，这比去年下降了 10 个百分点。&lt;/p&gt; 
&lt;p&gt;今年，我们还询问受访者如果有机会，他们是否会考虑再次使用 Rust，结果发现很大一部分受访者（63%）会这么做。这真是令人欣慰！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111652_RnJ5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;标记为 N/A 的封闭答案在调查的前一个版本中并未出现。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;不再使用 Rust 的人告诉我们，这主要是因为他们实际上并不需要它（或他们公司的目标发生了变化），或者因为它不是这项工作的合适工具。少数人报告称，他们被这种语言或其生态系统整体所压倒，或者认为转向或引入 Rust 在人力成本上过于昂贵。&lt;/p&gt; 
&lt;p&gt;在 2024 年使用 Rust 的人中，有 53% 的人是每天（或几乎每天）使用它——比上一年增加了 4 个百分点。我们可以观察到，在过去的几年中，Rust 的使用频率呈上升趋势，这表明 Rust 在工作场所的使用越来越多。这一点也由下文「Rust at Work」部分中提到的其他答案所证实。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111737_L7g6_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rust 的专业技能在我们的受访者中也持续增长！20% 的受访者能够编写（仅）简单的 Rust 程序（相比 2023 年下降了 3 个百分点），而 53% 的人认为自己使用 Rust 是高效的——这一比例在 2023 年为 47%。虽然这项调查只是衡量 Rust 整体技能变化的一个工具，但这些数字令人鼓舞，因为它们代表了每年回归调查的许多 Rustaceans 的知识增长。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111747_VI2v_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不出所料，最受欢迎的 Rust 版本是最新稳定版，无论是最新版本还是与用户的 Linux 发行版一起提供的版本。几乎三分之一的用户也使用最新的夜间版本，由于各种原因（见下文）。然而，似乎 beta 工具链的使用并不多，这有点遗憾。我们希望鼓励 Rust 用户更多地使用 beta 工具链（例如在 CI 环境中），以帮助测试即将稳定化的 Rust 版本。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111759_RPoz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;人们使用夜间工具链主要是为了获取特定的不稳定语言功能。也有几位用户提到，他们对夜间版本的 rustfmt 更满意，或者他们使用夜间编译器是因为编译速度更快。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111809_jJfZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;学习 Rust&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;要使用 Rust，程序员首先必须学习它，所以我们总是对他们是怎样学习的很感兴趣。根据调查结果，似乎大多数用户通过 Rust 文档以及《Rust 编程语言》这本书来学习，这本书长期以来一直是新 Rustaceans 最喜欢的学习资源。许多人似乎也通过阅读 Rust crate 的源代码来学习。事实上，成千上万 Rust crate 的文档和源代码都可在 docs.rs 和 GitHub 上找到，这使得学习变得更加容易。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111822_KHvR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;关于属于「其他」类别的回答，它们可以归纳为三个类别：使用 LLM（大型语言模型）助手（如 Copilot、ChatGPT、Claude 等）、阅读官方 Rust 论坛（Discord、URLO）或在贡献 Rust 项目时接受指导的人。我们想向那些使我们的空间对新来者友好和欢迎的人表示衷心的感谢，因为这是一项重要的工作，而且它是有回报的。有趣的是，相当数量的人通过「做中学」来学习，并使用 rustc 错误信息和 clippy 作为指南，这是 Rust 诊断质量的良好指标。&lt;/p&gt; 
&lt;p&gt;至于正规教育，似乎 Rust 尚未渗透到大学课程中，因为这是一个通常发展缓慢的领域。只有极少数受访者（大约 3%）曾上过大学的 Rust 课程或使用过大学学习材料。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111833_l4Zn_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编程环境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;关于 Rustaceans 使用的操作系统，Linux 是最受欢迎的选择，而且它似乎每年都在变得越来越受欢迎。其次是 macOS 和 Windows，它们的使用份额非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111844_giEi_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9695c9f7f5975eb79647c3db5c61467af25.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;顺便提一下，如您在词云中看到的，还有一些用户更喜欢 Arch。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Rust 程序员使用他们的 Rust 程序针对一系列的平台。我们发现针对嵌入式和移动平台的目标用户有所增加，但除此之外，平台分布与去年大致相同。由于 WebAssembly 目标相当多样化，我们这次将其分为两个单独的类别。根据结果，很明显，在使用 WebAssembly 时，它主要是在浏览器（23%）的上下文中，而不是其他用例（7%）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111901_JLWt_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当然，我们不能忘记许多程序员最喜爱的主题：他们使用哪个 IDE（开发环境）。尽管 Visual Studio Code 仍然是最受欢迎的选择，但今年的市场份额下降了 5 个百分点。另一方面，Zed 编辑器似乎最近获得了相当大的关注度。选择「其他」的少数人正在使用各种各样的不同工具：从 CursorAI 到经典如 Kate 或 Notepad++。特别提一下使用「ed」的 3 个人，这真是一项了不起的成就。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111912_hDw1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e87b497c85dbd1dced8a457b81fc3d05e46.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;您还可以查看词云，它总结了对此问题的开放性回答（「其他」类别），以了解其他哪些编辑器也受欢迎。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Rust 在工作中的使用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们很高兴看到越来越多的人在工作时使用 Rust 进行大部分编码，从去年的 34% 上升到 38%。在过去几年中，这一指标呈现出明显的上升趋势。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111924_MVQm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rust 在公司中的使用似乎也在增加，因为 45% 的受访者表示他们的组织在 Rust 上的使用并非微不足道，这比 2023 年增加了 7 个百分点。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111934_YhGk_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再次强调，我们调查受访者雇主投资 Rust 的首要原因是可以构建相对正确且无 bug 的软件。其次受欢迎的原因是 Rust 的性能特性。21% 在工作中使用 Rust 的受访者这么做是因为他们已经熟悉它，因此它是他们的默认选择，比 2023 年增加了 5 个百分点。这似乎表明，Rust 正成为越来越多公司选择的基础语言之一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111945_PfzP_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与上一年相似，很大比例的受访者（82%）报告说 Rust 帮助他们的公司实现了目标。总的来说，似乎程序员和公司对他们在 Rust 上的使用感到非常满意，这真是太好了！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111956_tivA_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在技术领域，情况与前一年相当相似。Rust 似乎特别受欢迎，用于创建服务器后端、Web 和网络服务以及云计算技术。它似乎也在嵌入式用例方面获得了更多的关注。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112012_w7WV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;您可以向右滚动图表以查看更多领域。请注意，在 2023 年的调查中，汽车领域并未作为封闭答案提供（它只是通过开放式答案输入的），这或许可以解释为什么会有如此大的跳跃。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;看到专业 Rust 使用的持续增长以及许多用户对其性能、控制、安全性、安全性、愉悦性等方面的信心，这令人兴奋！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正如往常一样，State of Rust 调查的主要目标之一是揭示过去一年 Rustaceans 心中的挑战、担忧和优先事项。&lt;/p&gt; 
&lt;p&gt;我们询问了用户关于限制他们生产力的 Rust 方面。不出所料，缓慢的编译速度位列榜首，这似乎一直是 Rust 用户的永久性担忧。一如既往，有努力正在进行中以提高编译器的速度，例如启用并行前端或默认切换到更快的链接器。我们邀请您测试这些改进，并告诉我们如果您遇到任何问题。&lt;/p&gt; 
&lt;p&gt;其他挑战包括对 Rust 调试的支持不佳以及 Rust 编译器工件的高磁盘使用量。另一方面，大多数 Rust 用户似乎对它的运行时性能、编译器的正确性和稳定性以及 Rust 的文档都非常满意。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112026_HY9X_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;关于 Rust 用户希望稳定（或实现）的具体不稳定（或缺失）功能，最希望的是异步闭包和 if/let while 链。嗯，好消息是！异步闭包将在 Rust 的下一个版本（1.85）中稳定，而 if/let while 链有望在 Edition 2024 发布后不久跟进很快之后，这次发布也将发生在 Rust 1.85 中。&lt;/p&gt; 
&lt;p&gt;其他备受渴望的功能包括生成器（同步和异步）以及更强大的泛型常量表达式。您可以关注 Rust 项目目标以跟踪这些（以及其他）功能的进展。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112038_zfN3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在对此问题的公开回答中，人们真的很有帮助，并尽力描述限制他们生产力的最显著问题。我们看到了关于异步编程（永恒的宠儿）的挑战，错误的可调试性（人们普遍喜欢，但并不适合每个人）或 Rust 工具缓慢或资源密集（rust-analyzer 和 rustfmt）的提及。一些用户还希望有更好的 IDE 故事和与其他语言的改进互操作性。&lt;/p&gt; 
&lt;p&gt;今年，我们还增加了一个关于 Rust 进化速度的新问题。虽然大多数人似乎对现状感到满意，但回答此问题的人中有超过四分之一的人希望 Rust 能够更快地稳定和/或添加新功能，只有 7% 的受访者希望 Rust 放慢或完全停止添加新功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112052_mhgg_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有趣的是，当我们询问受访者关于他们对 Rust 未来发展的主要担忧时，其中一个最常提到的答案是担心 Rust 会变得过于复杂。这似乎与上一个问题的答案形成了对比。也许 Rust 用户仍然认为 Rust 的复杂性是可控的，但他们担心有一天它可能会变得过于复杂。&lt;/p&gt; 
&lt;p&gt;我们很高兴地看到，对 Rust 项目治理和 Rust 基金会支持不足的担忧在 2023 年下降了约 6 个百分点。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112103_2fAx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展望未来&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每年，Rust 状态调查的结果都有助于揭示 Rust 项目和生态系统中许多需要改进的领域，以及对我们社区运作良好的方面。&lt;/p&gt; 
&lt;p&gt;如果您对 Rust 年度调查有任何建议，请告诉我们！&lt;/p&gt; 
&lt;p&gt;我们非常感谢参与 2024 年 Rust 状态调查并帮助其创建的人们。虽然开发和维护一种编程语言总是伴随着挑战，但今年我们很高兴看到高水平的调查参与和坦率的反馈，这将真正帮助我们让 Rust 更好地服务于每个人。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334273/2024-state-of-rust-survey-results</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334273/2024-state-of-rust-survey-results</guid>
            <pubDate>Sat, 08 Feb 2025 03:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 首届全球开发者大会定档 2 月 21 日，研讨 RWKV-7 架构与未来趋势</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;新一代大模型架构 RWKV 将于 &lt;strong&gt;2025 年 2 月 22 日&lt;/strong&gt;在&lt;strong&gt;上海&lt;/strong&gt;举办首届主题为 &lt;strong&gt;《RWKV-7 架构与未来趋势》&lt;/strong&gt; 的开发者大会，大会将深入探讨 RWKV-7 的独家技术亮点、应用场景以及未来趋势，展示 RWKV 在推动全球 AI 发展中的前瞻性与领导力。&lt;/p&gt; 
&lt;p&gt;RWKV-7 架构采用动态状态演化（dynamic state evolution）机制，超越了传统的 attention/linear attention 范式，拥有强大的上下文学习（in-context learning）能力和持续学习能力。RWKV-7 模型在推理过程中就能不断自动根据新的数据进行自我优化和改进（test-time training），从而显著提升了模型的理解力和处理能力。例如 RWKV-7 2.9B 模型的英文和多语言能力（英文评测 71.1%，多语言评测 62.3%），均显著超越所有同尺寸模型，包括 Llama 3.2 3B（英文评测 68.7%，多语言评测 57.3%）、Qwen2.5 3B（英文评测 68.6%，多语言评测 57.0%）等知名优秀开源模型。且 RWKV-7 2.9B 只训练了 3T tokens，另两者训练了接近 20T tokens。更大规模的 RWKV-7 也在训练中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0dde119f43dfd830ac5ecc616e6a70e1783.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此次大会将汇聚来自全球的技术专家、顶尖大学教授、行业领袖与创业者，预计超过 3000 名开发者和 AI 技术爱好者将参与其中。大会将设有多个&lt;strong&gt;分享和互动环节&lt;/strong&gt;，为参与者提供一个宝贵的交流与合作平台，帮助全球开发者共同探索 AI 的未来发展方向。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV 开发者论坛演讲嘉宾及议程：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a9aff24ab7e5cc3158b5d66b43b45612a83.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV 开发者大会 | 大会信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;时间：2025 年 2 月 22 日 14:00&lt;/li&gt; 
 &lt;li&gt;地点：上海漕河泾现代服务园大厦 A6 号楼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;RWKV 开发者大会 | 报名二维码：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1646ff713189f4ad7d2790a64066d4124a6.jpg&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;未来，RWKV 将继续通过持续创新和生态建设，致力于为全球开发者提供强大的技术支持与资源，推动 AI 技术的普及与应用，敬请期待！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334263</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334263</guid>
            <pubDate>Sat, 08 Feb 2025 02:51:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Zadig：首个深度集成 DeepSeek 的 DevOps 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img height=&quot;383&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2230cda1042253217386ec9e74ab4b9bf7b.png&quot; width=&quot;898&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言：当工程效能遭遇数据迷雾&lt;/h1&gt; 
&lt;p&gt;在微服务与云原生架构普及的今天，DevOps 团队正面临双重挑战：日均千次的流水线执行产生 TB 级数据，却难以转化为有效洞见；K8s 生产环境复杂度指数级增长，人工巡检如同大海捞针。Zadig 与 DeepSeek 的深度协同，首次将 AGI 技术注入 DevOps 全生命周期，推出「&lt;strong&gt;AI 效能分析&lt;/strong&gt;」与「&lt;strong&gt;AI 环境巡检&lt;/strong&gt;」两大核心能力，实现从经验驱动到智能决策的范式转移。现已面向社区用户全面开放，开源力量再进化！&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;AI 效能诊断：让数据说话，精准定位效能瓶颈&lt;/h1&gt; 
&lt;p&gt;传统工程效能分析往往依赖人工统计与经验判断，效率低且易受主观因素影响，而 Zadig 沉淀了研发过程的构建、部署、测试等大量效能数据，基于 DeepSeek 的 AI 能力，通过智能分析数据，为团队提供客观、可操作的改进建议。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能数据分析&lt;/strong&gt;：通过自然语言交互（Prompt 方式），AI 可快速分析流水线、构建、测试等环节的效能数据，识别瓶颈问题。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1530&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74e2b55272658d6609a7f07b0434738960b.png&quot; width=&quot;2942&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;问题精准定位&lt;/strong&gt;：无论是构建耗时过长、测试通过率低，还是资源利用率不足，AI 都能清晰指出问题所在。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1486&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-888422976ca2585f16a7cfc4a352681b7ad.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;科学改进建议&lt;/strong&gt;：基于分析结果，AI 提供具体的优化建议，例如并行测试策略、资源分配调整等，帮助团队快速提升效能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1486&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d89c13f6e249b6d1517a5d28bd169d63f7d.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;场景价值：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;无需手动分析海量数据，AI 自动生成效能报告，节省大量时间。&lt;/li&gt; 
 &lt;li&gt;通过数据驱动的优化建议，团队可快速落地改进措施，提升交付效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;AI 环境巡检：全天候守护，让环境问题无所遁形&lt;/h1&gt; 
&lt;p&gt;面对复杂的 Kubernetes 生产环境，传统人工巡检耗时费力，且难以覆盖潜在风险。Zadig 的 AI 环境巡检功能，通过定时巡检与智能告警，确保环境稳定性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;定时自动巡检&lt;/strong&gt;：AI 定期对 Kubernetes 环境进行全方位检查，覆盖资源状态、服务健康度等关键指标。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;2170&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6351737e713118924456d4aa5a02c16d82b.png&quot; width=&quot;3410&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能问题识别&lt;/strong&gt;：自动识别常见环境问题，如 Pod 异常、资源不足、配置错误等，并给出相应的解决方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1530&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f291d5d35f8a63fbb52c7f1a73cd20d7696.png&quot; width=&quot;2942&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;即时告警推送&lt;/strong&gt;：巡检结果通过 IM 工具（如飞书、钉钉、企业微信等）实时通知相关责任人，确保问题第一时间被处理。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1666&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c8ddc2f1472da2e9cebbc2efb6f9a52cdef.png&quot; width=&quot;2234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;场景价值：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;无需手动巡检，AI 自动完成环境健康检查，大幅降低人力成本。&lt;/li&gt; 
 &lt;li&gt;通过即时告警，团队可快速响应环境问题，避免小问题演变为大故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;结语&lt;/h1&gt; 
&lt;p&gt;Zadig 通过集成 DeepSeek 的 AI 能力，将智能技术深度融入 DevOps 流程，为研发运维团队带来了前所未有的效能提升和环境稳定性保障。未来，随着 AI 技术的不断发展，Zadig 将继续探索更多创新应用场景，助力企业实现数字化转型，提升核心竞争力。&lt;/p&gt; 
&lt;p&gt;Zadig 免费基础版已全面支持 AI 能力，0 成本解锁智能 DevOps！&lt;/p&gt; 
&lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;即日起，Zadig 新版发布&lt;br&gt; 扫码咨询抢先体验&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191b1f; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;943&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0c7876673ed701ed97107bb53b607d661dd.png&quot; width=&quot;1797&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Zadig 在 Github&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://gitee.com/koderover/zadig&quot; rel=&quot;nofollow&quot;&gt;Zadig 在 Gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;&lt;span&gt;推荐阅读：&lt;/span&gt;&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#002a64; margin-left:0; margin-right:0&quot;&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/11210095&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Zadig 官网博客正式发布，技术干货实践管饱&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/16492101&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;流水线早已 out 了？你需要更高效能的工作流&lt;/a&gt;&amp;nbsp;/&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10316143&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Jenkins 迁移 Zadig，新项目实施上线效率提升 6 倍&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/16507771&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;🚀 重大更新！Zadig V3.2.0 重塑工作流体验，强势推出迭代管理&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/koderover/blog/17622087</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/17622087</guid>
            <pubDate>Sat, 08 Feb 2025 02:44:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>