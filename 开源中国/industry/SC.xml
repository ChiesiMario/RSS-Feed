<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 01 Aug 2025 07:45:53 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Vercel 发布 AI SDK 5，构建全栈 AI 应用的开发工具包</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Vercel 发布了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-sdk-5" target="_blank"&gt;AI SDK 5&lt;/a&gt;，这是一个用于构建全栈 AI 应用的开发工具包，它在前代基础上进行了全面升级，提供了更强大的功能、更高的灵活性和更好的开发体验。&lt;/p&gt; 
&lt;p&gt;&lt;img height="565" src="https://static.oschina.net/uploads/space/2025/0801/153828_B1BV_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是 AI SDK 5 的主要更新内容：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;聊天功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;彻底重建&lt;/strong&gt;：引入了两种不同的消息类型——&lt;code&gt;UIMessage&lt;/code&gt; 和 &lt;code&gt;ModelMessage&lt;/code&gt;，解决了开发者在状态管理和聊天历史持久化方面的挑战。&lt;code&gt;UIMessage&lt;/code&gt; 是应用程序状态的「真实来源」，包含所有消息、元数据和工具结果，推荐用于持久化存储；&lt;code&gt;ModelMessage&lt;/code&gt; 则是为语言模型优化的简化表示。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;类型安全&lt;/strong&gt;：开发者可以创建自定义的 &lt;code&gt;UIMessage&lt;/code&gt; 类型，并在服务器和客户端之间传递，实现端到端的完全类型安全。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;流式传输&lt;/strong&gt;：引入了 &lt;code&gt;Data Parts&lt;/code&gt; 功能，允许开发者发送自定义数据块，如状态更新或部分工具结果，同时保持代码的可维护性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Agent 构建&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;精确的执行流控制&lt;/strong&gt;：&lt;code&gt;stopWhen&lt;/code&gt; 参数允许开发者定义工具调用循环的停止条件，例如达到特定步数或调用了某个特定工具；&lt;code&gt;prepareStep&lt;/code&gt; 钩子则允许在每一步执行前动态调整参数，如更换模型、修改系统提示或启用/禁用特定工具。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;面向对象封装&lt;/strong&gt;：新增的 &lt;code&gt;Agent&lt;/code&gt; 类为构建 Agent 提供了面向对象的封装。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;语音功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;统一提供商抽象&lt;/strong&gt;：通过 &lt;code&gt;experimental_generateSpeech&lt;/code&gt; 和 &lt;code&gt;experimental_transcribe&lt;/code&gt; API，为 OpenAI、ElevenLabs、DeepGram 等提供商的语音生成和转录服务提供了统一、类型安全的接口。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;工具调用增强&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;动态工具&lt;/strong&gt;：支持动态工具、提供商执行的工具（如 OpenAI 的网页搜索）以及更精细的生命周期钩子。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;其他更新&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;流媒体协议&lt;/strong&gt;：将 &lt;code&gt;SSE&lt;/code&gt; 作为标准的流媒体协议。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;全局提供商&lt;/strong&gt;：引入全局提供商（默认为 Vercel AI Gateway），简化模型 ID 的使用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;访问原始数据&lt;/strong&gt;：支持访问原始请求和响应数据以增强调试和控制能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zod 4 支持&lt;/strong&gt;：增加了对 Zod 4 的支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;迁移工具&lt;/strong&gt;：为帮助用户平滑迁移，Vercel 提供了自动化的代码修改工具（&lt;code&gt;codemods&lt;/code&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-sdk-5" target="_blank"&gt;点此查看发布说明&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363628/vercel-ai-sdk-5</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363628/vercel-ai-sdk-5</guid>
      <pubDate>Fri, 01 Aug 2025 07:42:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软向报告 .NET 漏洞的用户支付高达 40000 美元的报酬</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;许多公司提供漏洞赏金计划，鼓励人们搜索并发现软件中的安全漏洞，并私下向供应商报告，以便在恶意攻击者利用漏洞之前实施并应用修复程序。安全研究人员和其他公众会获得金钱奖励，从而获得经济激励。&lt;/p&gt; 
&lt;p&gt;现在，微软已宣布对其 .NET Bounty 计划进行重大更新。&lt;/p&gt; 
&lt;p&gt;奖励金额现从 7000 美元起，最高可达令人垂涎的 40000 美元。请注意，最高奖励仅适用于私下披露远程代码执行 (RCE) 或特权提升 (EoP) 漏洞，并提供完整文档且造成严重影响的情况。&lt;/p&gt; 
&lt;p&gt;各奖励等级的细分如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/153421_aSuq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，.NET 赏金计划主要围绕 .NET 和 ASP.NET&amp;nbsp;Core 展开，包括 Blazor 和 Aspire。但新的产品类别现在涵盖了所有受支持的 .NET 和 ASP.NET 版本、适用于 .NET Framework 的 ASP.NET&amp;nbsp;Core、上述内容提供的模板、其存储库中的 GitHub Actions 以及 F# 等相关技术。&lt;/p&gt; 
&lt;p&gt;更新后的奖励结构确保了严重性等级的明确定义，以便高影响的问题获得更高的奖励，同时还提供了关于如何将报告视为「完整」的指南。您可以在微软的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmsrc.microsoft.com%2Fblog%2F2025%2F07%2F.net-bounty-program-now-offers-up-to-40000-in-awards%2F" target="_blank"&gt;专门博客文章&lt;/a&gt;中找到更多信息。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363626/dotnet-bounty-program-now-offers-up-to-40000-in-awards</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363626/dotnet-bounty-program-now-offers-up-to-40000-in-awards</guid>
      <pubDate>Fri, 01 Aug 2025 07:35:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>没有套路，真的免费：模力方舟全免费的模型都在这了</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;想找无套路，真免费，不限额度的大模型？别再满世界找了——来模力方舟就够。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;立即访问模力方舟 AI 模型广场：&lt;a href="https://ai.gitee.com/serverless-api"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本文整理了目前模力方舟上完全免费开放使用的模型， 不是「每天送你 10 次体验」，也不是「注册送额度」，更不是「邀请获礼金」，而是&lt;strong&gt;不限次数、毫无限制、直接免费用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;无论你是想&lt;strong&gt;生成文本、写代码、合成语音、做推理，还是想过滤下内容风险&lt;/strong&gt;，模力方舟都准备好了免费的相关模型，&lt;strong&gt;全部 0 元接入、不限次数&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;通用语言模型：超能聊，跑得快&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen3-8B / Qwen3-4B / Qwen3-0.6B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151643_pivg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;国产开源的 Qwen3 系列，从轻量级到中型参数都有，支持「思考模式」与「对话模式」自由切换，还能写代码、讲英文、做推理。模型权重与 API 已全面开放，商用也不用担心授权问题。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen2-7B-Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151659_Ojcp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;升级版 Qwen 架构，专为「你让它干啥它就干啥」的指令模式设计，适合结构化问答、信息抽取等任务，照样免费用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;InternLM3-8B-Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;书生·浦语第三代，和 Qwen 一样属于国产头部阵营，指令跟随能力强、推理不拉胯，在 8B 量级里非常能打。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151711_9iVU_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GLM-4-9B / GLM-4-9B-Chat&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151725_ZpJL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来自智谱的通用语言模型，性能扎实，特别适合中文语境下的多轮问答和对话场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-R1-Distill-Qwen 系列（14B / 7B / 1.5B）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151739_89cE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 模型的轻量蒸馏版，覆盖大中小三种参数体型，推理性能不错但定位仍是通用语言模型，适合对资源有要求的部署场景。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;数学 / 定理证明：专精模型上场&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-Prover-V2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151756_uzEG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;专为 Lean 4 定理证明设计，具备将复杂问题拆解为子目标、合成链式推理过程的能力。模型通过 DeepSeek-V3 驱动的递归证明管线进行冷启动训练，融合非形式与形式数学推理，显著提升了定理证明效率与泛化能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;代码生成模型：小身材，大能力&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;codegeex4-all-9b&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151809_32Qh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;多语言代码生成模型，支持包括代码补全和生成、代码解释器、网络搜索、函数调用、仓库级代码问答在内的全面功能，覆盖软件开发的各种场景。是参数少于 10B 的顶尖代码生成模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;语音识别/合成模型：小体积，大用途&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;SenseVoiceSmall&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151839_AoYq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来自通义千问团队的轻量级语音模型，结合高效算法和小型化设计，提供低延迟和高准确度的语音处理能力，适用于资源受限的应用场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Spark-TTS-0.5B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151851_iZPk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来自 Spark Audio 团队的文本转语音模型，能够实现高精度、自然的语音合成。它高效、灵活、功能强大，适用于研究和生产环境。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;风控识别模型：确保内容合规&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;nsfw-classifier / Security-semantic-filtering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151909_OgHB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模力方舟提供了两种风控识别模型，分别面向图片分类和文本敏感内容过滤，确保内容合规与敏感信息保护。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;检索增强开发者福利：向量 + 重排模型也全免费&lt;/h4&gt; 
&lt;p&gt;模力方舟携手国产 GPU 伙伴，已将模型广场中 Embedding 与 Reranker 模型&lt;strong&gt;全部开放免费使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;RAG 架构必备的检索向量和重排序能力，即刻零成本上手！&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Embedding 向量模型：支持中文、英文、多语言编码，适配主流语义检索任务；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Reranker 重排序模型：优化文档排序效果，让你的检索结果相关且可信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151936_fUHW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;所有模型支持 API 调用，无需申请、无需授权、直接接入，非常适合搜索类应用、知识库问答、RAG 业务开发等场景使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;真免费，不限次，现在就能用&lt;/h3&gt; 
&lt;p&gt;马建仓再强调一次：上面这些模型&lt;strong&gt;没有「体验额度」，是「完全免费」&lt;/strong&gt;。不限制调用次数、不限制模型功能，可以直接接入使用。&lt;/p&gt; 
&lt;p&gt;立即访问模力方舟 AI 模型广场：&lt;strong&gt;&lt;a href="https://ai.gitee.com/serverless-api"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363622</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363622</guid>
      <pubDate>Fri, 01 Aug 2025 07:20:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元 3D 世界模型技术亮点速览</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;腾讯近日正式发布&lt;strong&gt;混元 3D 世界模型 1.0（HunyunWorld-1.0）&lt;/strong&gt;并全面开源。据称这是首个开源并且兼容传统 CG 管线的可漫游世界生成模型，为游戏开发、VR、数字内容创作等领域带来了全新的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/150655_8uFO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据该模型的技术报告，HunyunWorld-1.0 采用生成式架构，结合全景图像合成与分层 3D 重建技术，实现了高质量、沉浸式的可漫游 3D 场景生成。&lt;/p&gt; 
&lt;p&gt;该模型通过语义分层的 3D 场景表征与生成算法，同时支持"文生世界"和"图生世界"两种生成方式。主要技术框架包括三部分，即全景世界代理生成、基于语义的世界分层与分层世界重建。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/150932_iXbY_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;混元 3D 世界模型 1.0（HunyunWorld-1.0）是融合两类方法优势的创新框架，能够依据文本或图像输入生成沉浸式、可探索、可交互的 3D 场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;360°沉浸体验 ：通过全景图将复杂的 3D 世界高效地表征为 360 度覆盖的 2D 图像代理，为后续生成完整的 3D 世界建模提供了丰富的空间信息；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151052_YWxE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;工业级兼容性 ：生成的世界场景支持导出标准的 3D 网格格式，能够无缝导入现有 3D 建模软件和主流游戏引擎，用于二次开发；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151131_DzWQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原子级交互&amp;nbsp;：通过物体解耦的 3D 建模方式，生成物体和背景可分离的 3D 世界，支持精准的物体级交互控制，提升了生成世界的操作自由度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151149_qD74_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.21809" target="_blank"&gt;点此查看更多技术细节&lt;/a&gt;&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363621</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363621</guid>
      <pubDate>Fri, 01 Aug 2025 07:12:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动 Seed 助力清华获机器人足球世界杯冠军</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;字节跳动 Seed 发文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4e6maGpWaEtWfj1rxkhI0w" target="_blank"&gt;宣布&lt;/a&gt;，其与清华大学赵明国教授团队联合研发的人形机器人运动算法 「HumanoidKick」 在 2025RoboCup 机器人世界杯人形组成人组比赛中，成功帮助清华火神队获得冠军。这也是中国机器人足球队首次在机器人世界杯该组别夺冠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，此次夺冠的关键之一是&lt;strong&gt;基于视觉的&lt;strong&gt;&lt;strong&gt;端到端&lt;/strong&gt;&lt;/strong&gt;自主踢球算法 HumanoidKick&lt;/strong&gt;，由字节跳动 Seed 团队与清华大学赵明国教授团队联合提出并验证。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HumanoidKick 算法面向人形机器人硬件，通过基于视觉的深度强化学习，实现了「找球 - 追球 - 踢球」全过程的统一策略，在实际足球比赛中验证有效。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="368" src="https://oscimg.oschina.net/oscnet/up-28b9adf735a26eea28efb96fd06fe8b5e72.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HumanoidKick 算法尝试解决以下三项实际挑战：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;从视觉到行动的实时联动&lt;/strong&gt;：传统机器人足球方案依赖手动编程的预设策略，面对场上变化，常陷入动作卡顿的困境，错失进攻的有利时机。该算法通过端到端深度强化学习方法，构建了视觉感知与机器人运动控制的毫秒响应机制，让机器人能像人类球员一样边「看」边「动」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;从动作整合到自主决策&lt;/strong&gt;：经过数千个环境的并行训练，机器人得以将多种分散的动作技能整合为统一连贯的端到端策略，构建起「单个动作」 「赛场行为」 「竞技策略」之间的关联。面对实时变化的赛场动态，机器人可以自主决策行动，并泛化出自适应的踢球能力。这种能力进化让机器人摆脱了被动执行预设动作的局限，实现了从零散技能到完整策略的突破。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;从仿真到真实环境的适应&lt;/strong&gt;：为了让算法在真实世界中保持稳定，团队采用精确建模和域随机化结合的训练方案——在仿真环境中，建模真实世界的感知噪声和物理扰动（如地面条件、关节噪声），让机器人在仿真环境中「经历」各种现实极端场景，实现从仿真环境到真机的无缝应用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;依托仿真环境中的海量训练，HumanoidKick 算法在现实赛场中成功帮助机器人脱离既定动作流程束缚，依据瞬息万变的赛场态势，迅速自主规划行动方案。在比赛中，机器人展现出了较好的反应速度，最终取得胜利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363620</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363620</guid>
      <pubDate>Fri, 01 Aug 2025 07:09:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌开源 LangExtract，从非结构化文本提取结构化信息的 Python 库</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌开源了名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Flangextract" target="_blank"&gt;LangExtract&lt;/a&gt;的 Python 库，该库使用 LLMs 根据用户定义的指令从非结构化文本文档中提取结构化信息（诸如临床笔记或报告之类的材料），识别并整理关键细节，同时确保提取的数据与源文本相对应。&lt;/p&gt; 
&lt;p&gt;LangExtract 的核心优势在于其强大的功能特性。首先是「精确的源文本溯源」，它能将每一个提取出的信息精确映射回其在原始文本中的位置，并支持交互式高亮可视化，便于用户追溯和验证。&lt;/p&gt; 
&lt;p&gt;项目主页提供了快速上手的代码示例，演示了如何定义提示、提供示例、运行提取，并将结果保存为.jsonl 文件，最后生成交互式 HTML 可视化报告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/145804_AbcO_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;LangExtract 适用于任何领域，用户仅需提供少量示例即可定义提取任务，无需模型微调。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363619</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363619</guid>
      <pubDate>Fri, 01 Aug 2025 07:00:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>一张图解释上下文工程（Context Engineering ）</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;制图： Victoria Slocum&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-38450d8633e8576132b7439b4dd873cf590.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下为解释&lt;/p&gt; 
&lt;p&gt;---------------------------&lt;br&gt; 提示工程（Prompt Engineering）已死，上下文工程（𝗖𝗼𝗻𝘁𝗲𝘅𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴） 万岁！&lt;/p&gt; 
&lt;p&gt;（好吧，也没完全死掉——但它无疑正在进化成一种远为更强大的形态）&lt;/p&gt; 
&lt;p&gt;让我们来认识一下上下文工程（𝗖𝗼𝗻𝘁𝗲𝘅𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴）——这是一门艺术，致力于构建动态系统，从而精准地为大语言模型（LLM）提供成功完成任务所需的一切。&lt;/p&gt; 
&lt;p&gt;随着我们从简单的聊天机器人转向复杂的 AI 代理（Agent），我们正逐渐意识到，仅仅靠巧妙的提示语是不够的。真正重要的是精心编排一个完整的信息生态系统，并将这些信息输入到你的大语言模型中。&lt;/p&gt; 
&lt;p&gt;那么，这具体意味着什么呢？&lt;/p&gt; 
&lt;p&gt;它的核心在于构建动态系统，以正确的格式提供正确的信息和工具，从而让大语言模型能够切实地完成任务。&lt;/p&gt; 
&lt;p&gt;一个经过上下文工程设计的系统的构成解析：&lt;/p&gt; 
&lt;p&gt;✨用户信息 (𝗨𝘀𝗲𝗿 𝗜𝗻𝗳𝗼𝗿𝗺𝗮𝘁𝗶𝗼𝗻): 偏好、历史记录和个性化数据。&lt;br&gt; ✨工具使用 (𝗧𝗼𝗼𝗹 𝗨𝘀𝗲): API、计算器、搜索引擎——任何大语言模型完成工作所需的工具。&lt;br&gt; ✨RAG 上下文 (𝗥𝗔𝗚 𝗖𝗼𝗻𝘁𝗲𝘅𝘁): 从像 Weaviate 这样的向量数据库中检索出的信息。&lt;br&gt; ✨用户输入 (𝗨𝘀𝗲𝗿 𝗜𝗻𝗽𝘂𝘁): 当前实际的查询或任务。&lt;br&gt; ✨代理推理 (𝗔𝗴𝗲𝗻𝘁 𝗥𝗲𝗮𝘀𝗼𝗻𝗶𝗻𝗴): 大语言模型的思考过程和决策链。&lt;br&gt; ✨聊天历史 (𝗖𝗵𝗮𝘁 𝗛𝗶𝘀𝘁𝗼𝗿𝘆): 提供对话连续性的先前交互记录。&lt;/p&gt; 
&lt;p&gt;那么，它的记忆架构是怎样的呢？&lt;/p&gt; 
&lt;p&gt;✨短期记忆 (𝗦𝗵𝗼𝗿𝘁-𝘁𝗲𝗿𝗺 𝗺𝗲𝗺𝗼𝗿𝘆): 存在于上下文窗口中，处理当前对话。&lt;br&gt; ✨长期记忆 (𝗟𝗼𝗻𝗴-𝘁𝗲𝗿𝗺 𝗺𝗲𝗺𝗼𝗿𝘆): 存储在向量数据库（如 Weaviate）中，跨会话持久化存储用户偏好和过去的交互记录。&lt;/p&gt; 
&lt;p&gt;这为什么重要？&lt;br&gt; 因为当代理系统（agentic systems）失败时，很少是因为模型本身不够聪明，而是因为我们没有给它提供正确的上下文。&lt;/p&gt; 
&lt;p&gt;信息的格式同样重要。一条结构清晰的错误信息，永远胜过一大堆杂乱的 JSON 数据。就像人类一样，大语言模型也需要清晰、易于理解的沟通方式。&lt;/p&gt; 
&lt;p&gt;转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FPDFOm8vhG" target="_blank"&gt;蚁工厂，微博&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363615</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363615</guid>
      <pubDate>Fri, 01 Aug 2025 06:52:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美国上诉法院维持谷歌应用商店垄断裁决</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;位于旧金山的美国联邦第九巡回上诉法院 31 日裁定，驳回谷歌公司上诉，维持此前地方法院的陪审团裁决和法官指令。根据相关裁决和指令，谷歌将不得不改变其 Play 应用商店的一些重要管理方针，包括长期以来不允许其他应用商店在 Play 商店正常运营。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-097faa551a242c0ea617e6e9f397b03bcec.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Epic 游戏公司此前在其开发的《堡垒之夜》游戏中，通过技术手段让玩家进行应用内购买时可选择绕过谷歌的支付系统，从而避免向谷歌支付 30% 的佣金，谷歌随后将该游戏从 Play 商店中下架。Epic 游戏公司在 2020 年就此提起针对谷歌的反垄断诉讼。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;陪审团 2023 年裁决，谷歌违反了联邦和加利福尼亚州反垄断法，故意获取或维持市场垄断地位，不合理地限制交易，并非法将 Play 商店的使用与该公司的结算服务捆绑在一起。地方法官 2024 年签发针对谷歌的指令，要求该公司整改 Play 商店，消除反竞争的行为。谷歌随后提起上诉，上诉期间该指令暂缓实施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;联邦第九巡回上诉法院法官的裁决驳回了谷歌的上诉，称地方法院在审理时并未滥用自由裁量权，所发布的指令得到陪审团裁决以及地方法院自身调查结果的支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这一最新的裁决公布后，Epic 首席执行官蒂姆·斯威尼在社交媒体平台上表示，安卓版 Epic 游戏商店将登陆 Play 商店。谷歌方面则表示，会继续上诉。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;按照相关法律程序，谷歌可以选择要求第九巡回上诉法院全体法官复审此案，也可以直接向最高法院上诉。（新华社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363614</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363614</guid>
      <pubDate>Fri, 01 Aug 2025 06:50:49 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌发布面向程序员的开源字体：Google Sans Code</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌发布了一款面向程序员的开源字体：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgooglefonts%2Fgooglesans-code" target="_blank"&gt;Google Sans Code&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-94ed522f81ee53d97857a1fa258ac6bd4a3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Google Sans Code 是一个等宽字体系列，为代码带来清晰度、可读性以及一丝谷歌独特的品牌特色。&lt;/p&gt; 
&lt;p&gt;主要特性&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增强可读性：专为代码编辑器和终端中的最佳可读性而设计&lt;/li&gt; 
 &lt;li&gt;支持脚本：扩展拉丁文，支持多种语言&lt;/li&gt; 
 &lt;li&gt;变体字体：提供从 300 到 800 的广泛字重轴范围&lt;/li&gt; 
 &lt;li&gt;OpenType 功能：样式集、本地化形式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该字体源自谷歌的品牌字体设计风格，并为 Gemini 和 Android Studio 等产品开发，它确保每个字符即使在较小尺寸下也能保持清晰可辨。 此外，它还针对编程语言语法的独特排版需求进行了精细调整。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363609/googlesans-code</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363609/googlesans-code</guid>
      <pubDate>Thu, 17 Jul 2025 06:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 关联公司公布大语言模型部署方法专利</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;天眼查 App 显示，DeepSeek 关联公司杭州深度求索人工智能基础技术研究有限公司申请的「一种大语言模型的部署方法及系统」专利公布。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0afa30888a89708e3df22bbcdb8c9e1f8b2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9a97b9c49fa395a1f8e80a766f8cdd92565.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;摘要显示，该发明涉及人工智能领域，有益效果在于将预填充阶段和解码阶段分别部署在高性能计算能力和大内存的机器上，均衡负载任务，实现最大化的硬件利用，减少闲置算力，降低整体延迟，提高吞吐量，增强系统的扩展性和容错性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363608</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363608</guid>
      <pubDate>Thu, 17 Jul 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Apache Flink 2.1.0：面向实时 Data + AI 全面升级</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4c6f1a9969d29f16f70840096693dfe8b0c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作者：达龙&lt;a href="https://my.oschina.net/u/941947"&gt;@阿里云&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Apache&amp;nbsp;Flink&amp;nbsp;PMC&amp;nbsp;（项目管理委员会）很高兴地宣布&amp;nbsp;Apache&amp;nbsp;Flink&amp;nbsp;2.1.0 版本正式发布，这标志着实时数据处理引擎向&lt;strong&gt;统一&amp;nbsp;Data&amp;nbsp;+&amp;nbsp;AI&amp;nbsp;平台&lt;/strong&gt;的里程碑式演进。本次版本汇聚全球&amp;nbsp;116&amp;nbsp;位贡献者，完成&amp;nbsp;16&amp;nbsp;项改进提案（FLIPs），解决&amp;nbsp;220&amp;nbsp;多个问题，重点强化了&lt;strong&gt;实时&amp;nbsp;AI&amp;nbsp;与智能流处理的深度融合&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时&amp;nbsp;AI&amp;nbsp;能力突破&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;AI&amp;nbsp;模型&amp;nbsp;DDL，支持通过&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;与&amp;nbsp;Table&amp;nbsp;API&amp;nbsp;创建和修改&amp;nbsp;AI&amp;nbsp;模型，实现&amp;nbsp;AI&amp;nbsp;模型的灵活管理。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;扩展&lt;code&gt;ML_PREDICT&lt;/code&gt;表值函数，支持通过&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;实时调用&amp;nbsp;AI&amp;nbsp;模型，为构建端到端实时&amp;nbsp;AI&amp;nbsp;工作流奠定基础。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时数据处理增强&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;通过开放&amp;nbsp;Flink&amp;nbsp;核心能力——托管状态、事件时间流处理及表变更日志，&lt;code&gt;Process&amp;nbsp;Table&amp;nbsp;Functions(PTFs)&lt;/code&gt;使&amp;nbsp;Flink&amp;nbsp;&amp;nbsp;SQL&amp;nbsp;解锁了更强大的事件驱动型应用开发能力&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;引入&lt;code&gt;VARIANT&lt;/code&gt;数据类型，高效处理&amp;nbsp;JSON&amp;nbsp;等半结构化数据，结合&lt;code&gt;PARSE_JSON&lt;/code&gt;函数与湖仓格式（如&amp;nbsp;Paimon），实现动态&amp;nbsp;Schema&amp;nbsp;数据分析。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;重点优化流式&amp;nbsp;Join，创新性的引入&lt;code&gt;DeltaJoin&lt;/code&gt;与&lt;code&gt;MultiJoin&lt;/code&gt;策略，消除状态瓶颈，提升资源利用率与作业稳定性。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Flink&amp;nbsp;2.1.0&amp;nbsp;将实时数据处理与&amp;nbsp;AI&amp;nbsp;模型无缝集成，推动企业从实时分析迈向实时智能决策，以满足现代数据应用不断变化的需求。感谢各位贡献者的支持！&lt;/p&gt; 
&lt;h1&gt;Flink&amp;nbsp;SQL&amp;nbsp;提升&lt;/h1&gt; 
&lt;h2&gt;Model&amp;nbsp;DDLs&amp;nbsp;支持&lt;/h2&gt; 
&lt;p&gt;自&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;引入&amp;nbsp;AI&amp;nbsp;模型相关&amp;nbsp;SQL&amp;nbsp;语法后，用户可通过类似创建&amp;nbsp;Catalog&amp;nbsp;对象的方式定义模型，并在&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;中调用&amp;nbsp;AI&amp;nbsp;&amp;nbsp;模型。Flink&amp;nbsp;2.1 进一步扩展支持通过&amp;nbsp;Table&amp;nbsp;API（Java/Python）&amp;nbsp;定义模型，通过编程实现模型的灵活管理。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;创建模型&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE MODEL my_model
INPUT (f0 STRING)
OUTPUT (label STRING)
WITH (
  'task' = 'classification',
  'type' = 'remote',
  'provider' = 'openai',
  'openai.endpoint' = 'remote',
  'openai.api_key' = 'abcdefg',
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用&amp;nbsp;Java&amp;nbsp;API&amp;nbsp;创建模型&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;tEnv.createModel(
    "MyModel", 
    ModelDescriptor.forProvider("OPENAI")
      .inputSchema(Schema.newBuilder()
        .column("f0", DataTypes.STRING())
        .build())
      .outputSchema(Schema.newBuilder()
        .column("label", DataTypes.STRING())
        .build())
      .option("task", "classification")
      .option("type", "remote")
      .option("provider", "openai")
      .option("openai.endpoint", "remote")
      .option("openai.api_key", "abcdefg")
      .build(),
    true);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-437%253A%2BSupport%2BML%2BModels%2Bin%2BFlink%2BSQL" target="_blank"&gt;FLIP-437:&amp;nbsp;Support&amp;nbsp;ML&amp;nbsp;Models&amp;nbsp;in&amp;nbsp;Flink&amp;nbsp;SQL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-507%25253A%2BAdd%2BModel%2BDDL%2Bmethods%2Bin%2BTABLE%2BAPI" target="_blank"&gt;FLIP-507:&amp;nbsp;Add&amp;nbsp;Model&amp;nbsp;DDL&amp;nbsp;methods&amp;nbsp;in&amp;nbsp;TABLE&amp;nbsp;API&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;实时&amp;nbsp;AI&amp;nbsp;函数&lt;/h2&gt; 
&lt;p&gt;基于模型&amp;nbsp;DDL，Flink&amp;nbsp;2.1 扩展了&lt;code&gt;ML_PREDICT&lt;/code&gt;表值函数（TVF），支持在&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;中实时调用机器学习模型，提供内置兼容&amp;nbsp;OpenAI&amp;nbsp;API&amp;nbsp;的模型调用支持，同时开放自定义模型接口，标志着&amp;nbsp;Flink&amp;nbsp;从实时数据处理引擎向统一的实时&amp;nbsp;Data&amp;nbsp;+&amp;nbsp;AI&amp;nbsp;平台演进。未来将继续扩展&amp;nbsp;&lt;code&gt;ML_EVALUATE&lt;/code&gt;、&lt;code&gt;VECTOR_SEARCH&lt;/code&gt;&amp;nbsp;等函数，用户可以使用&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;更方便地构建端到端实时&amp;nbsp;AI&amp;nbsp;工作流。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Declare a AI model
CREATE MODEL `my_model`
INPUT (text STRING)
OUTPUT (response STRING)
WITH(
  'provider' = 'openai',
  'endpoint' = 'https://api.openai.com/v1/llm/v1/chat',
  'api-key' = 'abcdefg',
  'system-prompt' = 'translate to Chinese',
  'model' = 'gpt-4o'
);

-- Basic usage
SELECT * FROM ML_PREDICT(
  TABLE input_table,
  MODEL my_model,
  DESCRIPTOR(text)
);

-- With configuration options
SELECT * FROM ML_PREDICT(
  TABLE input_table,
  MODEL my_model,
  DESCRIPTOR(text)
  MAP['async', 'true', 'timeout', '100s']
);

-- Using named parameters
SELECT * FROM ML_PREDICT(
  INPUT =&amp;gt; TABLE input_table,
  MODEL =&amp;gt; MODEL my_model,
  ARGS =&amp;gt; DESCRIPTOR(text),
  CONFIG =&amp;gt; MAP['async', 'true']
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-2.1%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fmodel-inference%2F" target="_blank"&gt;模型推理&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-437%253A%2BSupport%2BML%2BModels%2Bin%2BFlink%2BSQL" target="_blank"&gt;FLIP-437:&amp;nbsp;Support&amp;nbsp;ML&amp;nbsp;Models&amp;nbsp;in&amp;nbsp;Flink&amp;nbsp;SQL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Process&amp;nbsp;Table&amp;nbsp;Functions(PTFs)&lt;/h2&gt; 
&lt;p&gt;Apache&amp;nbsp;Flink&amp;nbsp;现已支持&amp;nbsp;&lt;strong&gt;Process&amp;nbsp;Table&amp;nbsp;Functions（PTFs）&lt;/strong&gt;，这是&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;与&amp;nbsp;Table&amp;nbsp;API&amp;nbsp;中最强大的函数类型。从概念上讲，PTF&amp;nbsp;是所有&amp;nbsp;UDF&amp;nbsp;的「超集」，能够将&lt;strong&gt;零个、一个或多张表&lt;/strong&gt;映射为&lt;strong&gt;零个、一个或多行数据&lt;/strong&gt;。借助&amp;nbsp;PTFs，你可以实现与内置算子一样功能丰富的自定义算子，并直接访问&amp;nbsp;Flink&amp;nbsp;的托管状态、事件时间、定时器以及表级变更日志。&lt;/p&gt; 
&lt;p&gt;PTFs&amp;nbsp;支持如下操作：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对表的每一行执行转换。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可以把一张表从逻辑上拆分成不同子集，并对每个子集分别转换。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缓存已见事件，供后续多次访问。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在未来某个时间点继续处理，实现等待、同步或超时机制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;利用复杂状态机或基于规则的条件逻辑对事件进行缓存与聚合。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这显著缩小了&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;与&amp;nbsp;DataStream&amp;nbsp;API&amp;nbsp;之间的差距，同时保留了&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;生态的健壮性与易用性。&lt;br&gt; 关于&amp;nbsp;PTFs&amp;nbsp;的语法与语义细节，详见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Ffunctions%2Fptfs%2F" target="_blank"&gt;Process&amp;nbsp;Table&amp;nbsp;Functions&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;// Declare a ProcessTableFunction for memorizing your customers
public static class GreetingWithMemory extends ProcessTableFunction&amp;lt;String&amp;gt; {
    public static class CountState {
        public long counter = 0L;
    }

    public void eval(@StateHint CountState state, @ArgumentHint(SET_SEMANTIC_TABLE) Row input) {
        state.counter++;
        collect("Hello " + input.getFieldAs("name") + ", your " + state.counter + " time?");
    }
}

TableEnvironment env = TableEnvironment.create(...);

// Call the PTF in Table API
env.fromValues("Bob", "Alice", "Bob")
   .as("name")
   .partitionBy($("name"))
   .process(GreetingWithMemory.class)
   .execute()
   .print();

// Call the PTF in SQL
env.executeSql("SELECT * FROM GreetingWithMemory(TABLE Names PARTITION BY name)")
   .print();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;更多信息&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fpages%2Fviewpage.action%3FpageId%3D298781093" target="_blank"&gt;FLIP-440:&amp;nbsp;User-defined&amp;nbsp;SQL&amp;nbsp;operators&amp;nbsp;/&amp;nbsp;ProcessTableFunction&amp;nbsp;(PTF)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Variant&amp;nbsp;类型&lt;/h2&gt; 
&lt;p&gt;新增&lt;code&gt;VARIANT&lt;/code&gt;半结构化数据类型（如&amp;nbsp;JSON），支持存储任意嵌套结构（包括基本类型、&lt;code&gt;ARRAY&lt;/code&gt;、&lt;code&gt;MAP&lt;/code&gt;）并保留原始类型信息。相比&amp;nbsp;&lt;code&gt;ROW&lt;/code&gt;、&lt;code&gt;STRUCTURED&lt;/code&gt;&amp;nbsp;类型，&lt;code&gt;VARIANT&lt;/code&gt;&amp;nbsp;在处理动态&amp;nbsp;Schema&amp;nbsp;数据时更灵活。配合&amp;nbsp;&lt;code&gt;PARSE_JSON&lt;/code&gt;&amp;nbsp;函数及&amp;nbsp;Apache&amp;nbsp;Paimon&amp;nbsp;等表格式，可实现湖仓中半结构化数据的高效分析。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE t1 (
  id INTEGER,
  v STRING -- a json string
) WITH (
  'connector' = 'mysql-cdc',
  ...
);
 
CREATE TABLE t2 (
  id INTEGER,
  v VARIANT
) WITH (
  'connector' = 'paimon'
  ...
);
 
-- write to t2 with VARIANT type
INSERT INTO t2 SELECT id, PARSE_JSON(v) FROM t1;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-2.1%2Fdocs%2Fdev%2Ftable%2Ftypes%2F%23other-data-types" target="_blank"&gt;Variant&amp;nbsp;Type&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-521%25253A%2BIntegrating%2BVariant%2BType%2Binto%2BFlink" target="_blank"&gt;FLIP-521:&amp;nbsp;Integrating&amp;nbsp;Variant&amp;nbsp;Type&amp;nbsp;into&amp;nbsp;Flink:&amp;nbsp;Enabling&amp;nbsp;Efficient&amp;nbsp;Semi-Structured&amp;nbsp;Data&amp;nbsp;Processing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Structured&amp;nbsp;类型增强&lt;/h2&gt; 
&lt;p&gt;支持在&lt;code&gt;CREATE&amp;nbsp;TABLE&lt;/code&gt;语句中直接声明用户定义结构体类型（STRUCTURED），解决类型兼容性问题并提升易用性。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE UserTable (
    uid BIGINT,
    user STRUCTURED&amp;lt;'User', name STRING, age INT&amp;gt;
);

-- Casts a row type into a structured type
INSERT INTO UserTable 
SELECT 1, CAST(('Alice', 30) AS STRUCTURED&amp;lt;'User', name STRING, age INT&amp;gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;更多信息&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-520%253A%2BSimplify%2BStructuredType%2Bhandling" target="_blank"&gt;FLIP-520:&amp;nbsp;Simplify&amp;nbsp;StructuredType&amp;nbsp;handling&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-2.1%2Fdocs%2Fdev%2Ftable%2Ftypes%2F%23user-defined-data-types" target="_blank"&gt;Structured&amp;nbsp;Type&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Delta&amp;nbsp;Join&lt;/h2&gt; 
&lt;p&gt;引入一种新的&lt;code&gt;DeltaJoin&lt;/code&gt;算子，相比传统的双流&amp;nbsp;Join&amp;nbsp;方案，配合&amp;nbsp;Apache&amp;nbsp;Fluss&amp;nbsp;等流存储，可以实现&amp;nbsp;Join&amp;nbsp;算子无状态化，解决了大状态导致的资源瓶颈、检查点缓慢和恢复延迟等问题。该特性已默认启用，同时需要依赖&amp;nbsp;Apache&amp;nbsp;Fluss&amp;nbsp;存储相应版本支持，敬请关注&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Ffluss%2Fissues%2F1143" target="_blank"&gt;Support&amp;nbsp;DeltaJoin&amp;nbsp;on&amp;nbsp;Flink&amp;nbsp;2.1&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多信息&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-486%25253A%2BIntroduce%2BA%2BNew%2BDeltaJoin" target="_blank"&gt;FLIP-486:&amp;nbsp;Introduce&amp;nbsp;A&amp;nbsp;New&amp;nbsp;DeltaJoin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;级联双流&amp;nbsp;Join&amp;nbsp;优化&lt;/h2&gt; 
&lt;p&gt;使用多个级联流式&amp;nbsp;Join&amp;nbsp;的&amp;nbsp;Flink&amp;nbsp;作业经常会因&amp;nbsp;State&amp;nbsp;过大而导致运行不稳定和性能下降。在这个版本，我们引入了一种新的&lt;code&gt;MultiJoin&lt;/code&gt;算子，&amp;nbsp;通过在单个算子内直接进行多流&amp;nbsp;Join，消除中间结果存储，每条流输入的记录最多存储一份，从而实现实现&amp;nbsp;"零中间状态"&amp;nbsp;，显著提升了资源利用率与作业稳定性。目前仅支持&amp;nbsp;INNER、LEFT&amp;nbsp;JOIN&amp;nbsp;，并且需要通过参数&lt;code&gt;table.optimizer.multi-join.enabled=true&lt;/code&gt;启用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;基准测试&lt;/strong&gt;：我们进行了一项基准测试，比较了&lt;code&gt;MultiJoin&lt;/code&gt;与双流&amp;nbsp;Join&amp;nbsp;的优势，更多详情请参见&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-2.1%2Fdocs%2Fdev%2Ftable%2Ftuning%2F%23multiple-regular-joins" target="_blank"&gt;MultiJoin&amp;nbsp;Benchmark&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多信息&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-516%253A%2BMulti-Way%2BJoin%2BOperator" target="_blank"&gt;FLIP-516:&amp;nbsp;Multi-Way&amp;nbsp;Join&amp;nbsp;Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;异步&amp;nbsp;Lookup&amp;nbsp;Join&amp;nbsp;增强&lt;/h4&gt; 
&lt;p&gt;异步&amp;nbsp;Lookup&amp;nbsp;Join&amp;nbsp;在之前的版本中，即使用户将&amp;nbsp;&lt;code&gt;table.exec.async-lookup.output-mode&lt;/code&gt;&amp;nbsp;设置为&amp;nbsp;&lt;code&gt;ALLOW_UNORDERED&lt;/code&gt;，引擎在处理更新流时仍会强制回退到&amp;nbsp;&lt;code&gt;ORDERED&lt;/code&gt;&amp;nbsp;以保证正确性。从&amp;nbsp;2.1&amp;nbsp;版本开始，引擎允许并行处理无关的更新记录，同时保证正确性，从而在处理更新流时实现更高的吞吐。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-519%253A%2B%2BIntroduce%2Basync%2Blookup%2Bkey%2Bordered%2Bmode" target="_blank"&gt;FLIP-519:&amp;nbsp;Introduce&amp;nbsp;async&amp;nbsp;lookup&amp;nbsp;key&amp;nbsp;ordered&amp;nbsp;mode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sink&amp;nbsp;节点复用&lt;/h2&gt; 
&lt;p&gt;当单个作业中多个&amp;nbsp;&lt;code&gt;INSERT&amp;nbsp;INTO&lt;/code&gt;&amp;nbsp;语句更新目标表相同列时（下版本将支持不同列），优化器将自动合并&amp;nbsp;Sink&amp;nbsp;节点实现复用，该特性可以极大提升&amp;nbsp;Apache&amp;nbsp;Paimon&amp;nbsp;等湖仓格式的部分更新场景使用体验。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-506%253A%2BSupport%2BReuse%2BMultiple%2BTable%2BSinks%2Bin%2BPlanner" target="_blank"&gt;FLIP-506:&amp;nbsp;Support&amp;nbsp;Reuse&amp;nbsp;Multiple&amp;nbsp;Table&amp;nbsp;Sinks&amp;nbsp;in&amp;nbsp;Planner&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Compiled&amp;nbsp;Plan&amp;nbsp;支持&amp;nbsp;Smile&amp;nbsp;格式&lt;/h2&gt; 
&lt;p&gt;新增&amp;nbsp;Smile&amp;nbsp;二进制格式（兼容&amp;nbsp;JSON&amp;nbsp;格式）用于执行计划序列化，较&amp;nbsp;JSON&amp;nbsp;更节省内存。默认仍使用&amp;nbsp;JSON&amp;nbsp;格式，需通过显示调用&amp;nbsp;&lt;code&gt;CompiledPlan#asSmileBytes&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;PlanReference#fromSmileBytes&lt;/code&gt;&amp;nbsp;方法启用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-508%253A%2BAdd%2Bsupport%2Bfor%2BSmile%2Bformat%2Bfor%2BCompiled%2Bplans" target="_blank"&gt;FLIP-508:&amp;nbsp;Add&amp;nbsp;support&amp;nbsp;for&amp;nbsp;Smile&amp;nbsp;format&amp;nbsp;for&amp;nbsp;Compiled&amp;nbsp;plans&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFasterXML%2Fsmile-format-specification" target="_blank"&gt;Smile&amp;nbsp;格式规范&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;运行时提升&lt;/h1&gt; 
&lt;h2&gt;异步&amp;nbsp;Sink&amp;nbsp;可插拔的批量处理&lt;/h2&gt; 
&lt;p&gt;支持自定义批量写入策略，用户可根据业务需求灵活扩展异步&amp;nbsp;Sink&amp;nbsp;的批量写入逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-509%2BAdd%2Bpluggable%2BBatching%2Bfor%2BAsync%2BSink" target="_blank"&gt;FLIP-509:&amp;nbsp;Add&amp;nbsp;pluggable&amp;nbsp;Batching&amp;nbsp;for&amp;nbsp;Async&amp;nbsp;Sink&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;分片级水位线指标&lt;/h2&gt; 
&lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.1&amp;nbsp;版本，我们新增细粒度分片监控指标，涵盖水位线进度与状态统计：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;currentWatermark&lt;/code&gt;：该分片最新接收到的水位线值&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;activeTimeMsPerSecond&lt;/code&gt;：该分片每秒处于数据处理状态的时间（毫秒）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;pausedTimeMsPerSecond&lt;/code&gt;：因水位线对齐该分片每秒的暂停时间（毫秒）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;idleTimeMsPerSecond&lt;/code&gt;：每秒空闲时长（毫秒）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;accumulatedActiveTimeMs&lt;/code&gt;：累计活跃时长（毫秒）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;accumulatedPausedTimeMs&lt;/code&gt;：累计暂停时长（毫秒）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;accumulatedIdleTimeMs&lt;/code&gt;：累计空闲时长（毫秒）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-513%253A%2BSplit-level%2BWatermark%2BMetrics" target="_blank"&gt;FLIP-513:&amp;nbsp;Split-level&amp;nbsp;Watermark&amp;nbsp;Metrics&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;连接器提升&lt;/h1&gt; 
&lt;h2&gt;Keyed&amp;nbsp;State&amp;nbsp;连接器&lt;/h2&gt; 
&lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.1&amp;nbsp;中，我们为&amp;nbsp;Keyed&amp;nbsp;State&amp;nbsp;引入了一个新的&amp;nbsp;SQL&amp;nbsp;连接器。该连接器允许用户使用&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;直接查询 Checkpoint&amp;nbsp;和&amp;nbsp;Savepoint&amp;nbsp;&amp;nbsp;中的&amp;nbsp;Keyed&amp;nbsp;State，从而使得更容易探查、调试和验证&amp;nbsp;Flink&amp;nbsp;作业状态，无需定制工具，该功能对于分析长期运行的作业和验证状态迁移尤其有用。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-plaintext"&gt;CREATE TABLE keyed_state (
    k INT,
    user_id STRING,
    balance DOUBLE
) WITH (
    'connector' = 'savepoint',
    'path' = 'file:///savepoint/path'
);

-- 直接查询状态快照
SELECT * FROM keyed_state;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;更多信息：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-496%25253A%2BSQL%2Bconnector%2Bfor%2Bkeyed%2Bsavepoint%2Bdata" target="_blank"&gt;FLIP-496:&amp;nbsp;SQL&amp;nbsp;connector&amp;nbsp;for&amp;nbsp;keyed&amp;nbsp;savepoint&amp;nbsp;data&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;其他重要更新&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;PyFlink：新增支持&amp;nbsp;Python&amp;nbsp;3.12，移除&amp;nbsp;Python&amp;nbsp;3.8 支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依赖升级：flink-shaded&amp;nbsp;升级至&amp;nbsp;20.0&amp;nbsp;以支持&amp;nbsp;Smile&amp;nbsp;格式，Parquet&amp;nbsp;升级至&amp;nbsp;1.15.3&amp;nbsp;修复安全漏洞（CVE-2025-30065）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;升级说明&lt;/h1&gt; 
&lt;p&gt;Apache&amp;nbsp;Flink&amp;nbsp;社区努力确保升级过程尽可能平稳,&amp;nbsp;但是升级到&amp;nbsp;2.1&amp;nbsp;版本可能需要用户对现有应用程序做出一些调整。请参考&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Frelease-notes%2Fflink-2.1%2F" target="_blank"&gt;Release&amp;nbsp;Notes&lt;/a&gt;&amp;nbsp;获取更多的升级时需要的改动与可能的问题列表细节。&lt;/p&gt; 
&lt;h1&gt;贡献者列表&lt;/h1&gt; 
&lt;p&gt;Apache&amp;nbsp;Flink&amp;nbsp;社区感谢对此版本做出贡献的每一位贡献者：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i2/O1CN01mRiFtD1TgkOCxzNkm_!!6000000002412-2-tps-1600-758.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;更多内容&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i4/O1CN01vtIK1x1QErMoUKWNY_!!6000000001945-0-tps-2590-912.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;活动推荐&lt;/h3&gt; 
&lt;p&gt;阿里云基于 Apache Flink 构建的企业级产品-实时计算 Flink 版现开启活动： 新用户复制点击下方链接或者扫描二维码即可 0 元免费试用 Flink + Paimon &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3Futm_content%3Dg_1000395379%26productCode%3Dsc" target="_blank"&gt;实时计算 Flink 版&lt;/a&gt;（3000CU*小时，3 个月内） 了解活动详情：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3Futm_content%3Dg_1000395379%26productCode%3Dsc" target="_blank"&gt;https://free.aliyun.com/?utm_content=g_1000395379&amp;amp;productCode=sc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i4/O1CN015MhRmC1tylxDOo5RG_!!6000000005971-0-tps-1200-600.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/2828172/blog/18686708</link>
      <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/18686708</guid>
      <pubDate>Thu, 17 Jul 2025 06:37:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>字节 AI 编程工具 Trae 发布关于数据隐私与安全的说明</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;近日，字节跳动旗下的 AI 编程工具 Trae IDE&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgigazine.net%2Fnews%2F20250729-bytedance-trae-ide%2F" target="_blank"&gt; 被指存在数据隐私问题&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;开发者发现即使在关闭遥测功能后，Trae 仍会持续向字节跳动服务器上传数据，且数据量较大。此外，Trae 还被指出存在可远程激活的「热更新」机制，数据加密传输机制不透明，隐私政策中未明确列举具体收集的数据类型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a970824d275e33e0557fe63610723284865.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3499b1d590ebc12f5c824e414436afeca85.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对此，字节跳动 Trae IDE 团队回应称，为了持续优化产品体验，Trae 和业内通用做法类似，会采集部分非敏感的产品统计数据及性能监测数据，如页面点击、功能使用频率等。这类数据不涉及用户的个人身份或隐私信息。&lt;/p&gt; 
&lt;p&gt;Trae IDE 团队还解释道，Trae 采集的数据仅为非敏感的统计和性能指标，用于产品优化与性能分析，且严格遵循全球数据保护法规。Trae 的遥测机制独立于 VSCode 的遥测控制项，用户关闭的仅是 VSCode 原生模块，这导致了误解。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a3069e937ea960b8374dec97f972eb90505.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363605</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363605</guid>
      <pubDate>Thu, 17 Jul 2025 06:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Kimi K2 高速版发布，输出速度提升至每秒 40 Tokens</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;Kimi 开放平台&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqHE09ndQzz-gvd8RaymN5A" target="_blank"&gt;发文&lt;/a&gt;宣布推出 Kimi K2 高速版 —— kimi-k2-turbo-preview，参数规模与现有 kimi-k2 保持一致，但输出速度由每秒 10 Tokens 提升至每秒 40 Tokens。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同时，官方宣布特别推出限时 5 折特惠活动，该优惠将持续至 9 月 1 日，之后将恢复原价。在折扣期间：模型每百万&amp;nbsp;tokens&amp;nbsp;输入价格（缓存命中）¥2.00，输入价格（缓存未命中）¥8.00，输出价格&amp;nbsp;¥32.00。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「我们还将继续努力优化，进一步提升 kimi-k2 模型的输出速度。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="322" src="https://oscimg.oschina.net/oscnet/up-af3e364d7b9ae7f30a4699694498dd0d792.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363603</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363603</guid>
      <pubDate>Thu, 17 Jul 2025 06:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 合成孔径波导全息术新进展，微美全息加速 AI+AR 全息技术融合稳步前行</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;获悉，日前，Meta（META.US）与斯坦福大学携手开展的「合成孔径波导全息术」研究，正朝着打造总光学堆栈厚度不足 3 毫米的「VR 眼镜」这一目标稳步推进。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;合成孔径波导全息术新突破&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;其团队集结了 Meta 显示系统研究团队的两名研究员、斯坦福大学的一位副教授等，将相关研究成果已发表于题为《用于大光展量紧凑型混合现实显示器的合成孔径波导全息术》的论文中。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//2daa37e10675d715ad88326541afa3fd.png" width="659" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;据称，此显示系统的关键创新点之一，是它支持较大的有效光学扩展量。同时，该系统还与一个全新的基于 AI 人工智能的算法框架协同工作，该框架融合了隐式大光学扩展量波导模型、用于部分相干互强度的高效波传播模型，以及一个新颖的计算机生成全息框架。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;早前，英伟达（NVDA.US）的研究人员借助光瞳复制波导、空间光调制器（SLM）和几何相位透镜，实现了厚度为 2.5 毫米的真 3D 全息技术。不过该技术的视场角仅为 23°，在未启用眼动追踪时，眼区仅为 2.3 毫米。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;Meta 表示，当前，VR/MR 头显的厚度几乎完全由光学元件和显示器所决定。这无疑需要一套与现有市面上任何显示系统都截然不同的全新系统，而此次的研究正是 Meta 向这一目标迈进的重要一步。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//80898212b9cc539f66143e0f374387b3.png" width="659" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;市场蓝海崛起&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;现如今，全息显示技术无疑已经更加成熟。在刚闭幕的 2025 世界人工智能大会上，各企业携「硬科技」成果亮相，用全息「无屏而有形，隔空却可触」的全景式体验，呈现在人机交互领域的技术实力，为全球观众解锁未来智能的无限潜能。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;根据海外市场研究机构 Verified Market Reports 发布的报告，2024 年全球裸眼 3D 显示器的市场规模达到 12 亿美元，预计 2026-2033 年间的复合年增长率为 12.5%，到 2033 年市场将达到 35 亿美元。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//1534a110f7d8fe850c6ffd10de99c2e1.png" width="659" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;对此，相关业内人士指出，全息显示技术的研究正在稳步推进，而全息显示市场的高速发展，无疑将继续给行业带来积极的影响和全新的视角，也为企业对市场内容的呈现方式带去新的思路。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;微美全息呈现全新技术视角&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;让在此背景下，资料显示，微美全息（WIMI.US）作为全息 AR 技术引领者，常年来专注于计算机视觉全息云服务，业务涵盖全息 AI 合成、视觉呈现、互动软件开发、AR 广告投放、5G 全息通讯等多个环节，持续推进全息技术场景化应用。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;为突破多场景适配、跨终端联动与虚实融合协同等技术瓶颈，微美全息研发团队构建了集全息成像、编码、传输和显示于一体的系统，结合 5G 技术、AI 技术实现低延迟、高清晰度的全息通信，可应用于虚拟课堂、远程协作、工业检测等场景成熟解决方案，实现从单点深耕到多元化场景的布局跨越。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;结尾&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;当前，全球智能化浪潮风起云涌，随着长久以来相关技术的蓬勃发展，全息显示效果早就不可同日而语，同时，人工智能成为驱动时代变革的核心引擎，当全息技术与 AI 虚实融合将重构人类交互体验的底层逻辑，一场关于未来智能的探索正在全球进行，而这更将是一次成熟技术的结合与尝试。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363602</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363602</guid>
      <pubDate>Thu, 17 Jul 2025 06:28:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>阶跃星辰新一代基础大模型 Step 3 正式开源，专注多模态推理</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;阶跃星辰宣布正式开源其最新一代基础大模型 Step3。该模型采用专家混合（MoE）架构，总参数量为 321B，激活参数量为 38B，旨在为企业和开发者提供性能与成本极致均衡的推理方案。&lt;/p&gt; 
&lt;p&gt;Step3 模型在设计上专注于多模态推理，通过端到端的设计最小化解码成本，在视觉语言推理任务中表现出色。&lt;/p&gt; 
&lt;p&gt;技术上，模型采用了自研的 MFA（Multi-matrix Factorization Attention）注意力机制和 AFD（Attention-FFN Disaggregation）系统架构。MFA 旨在降低 KV 缓存开销和计算消耗，而 AFD 则将 Attention 和 FFN 计算解耦为两个子系统，通过流水线并行调度提升吞吐效率。&lt;/p&gt; 
&lt;p&gt;为支持 AFD，阶跃星辰还开源了专用的通信库 StepMesh，以实现跨卡的低延迟高带宽数据传输。&lt;/p&gt; 
&lt;p&gt;在性能评测方面，Step3 在 MMMU、MathVision、AIME 2025 等多个基准上，表现优于同类开源模型。在社区测试中，该模型也展现了不错的指令遵循和生成能力。vLLM 项目宣布已支持 Step3 模型，并报告在 Hopper GPU 上实现了高达 4,039 tok/sec/GPU 的吞吐量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/141828_z9Od_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ef1a09fb7cb19300f347b50db7de9afe917.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Step3 模型权重已在 Hugging Face 和魔搭社区发布，支持 bf16 和 block-fp8 格式。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github：https://github.com/stepfun-ai/Step3&lt;/li&gt; 
 &lt;li&gt;Hugging Face：https://huggingface.co/stepfun-ai/step3&lt;/li&gt; 
 &lt;li&gt;魔搭 ModelScope：&lt;br&gt; https://www.modelscope.cn/models/stepfun-ai/step3&lt;br&gt; https://www.modelscope.cn/models/stepfun-ai/step3-fp8&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;用户可以通过阶跃星辰开放平台（platform.stepfun.com）访问其 OpenAI 兼容的 API，上下文长度为 64K，目前提供折扣价格，输入为每百万 token 1.5 元，输出为 4 元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363599</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363599</guid>
      <pubDate>Thu, 17 Jul 2025 06:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>青云科技暂停 KubeSphere 开源版产品下载，停止提供免费技术支持</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;青云&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues%2F6550"&gt;发布&lt;/a&gt;&lt;/u&gt;了暂停 KubeSphere 开源版下载和停止提供免费技术支持的公告：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;若贵司目前仍在使用 KubeSphere 开源版，或有后续使用计划，为保障业务正常运转，敬请及时与我司客户服务团队取得联系。我们将为您量身定制商业版解决方案，涵盖专属技术支持、漏洞修复、版本升级等多项增值服务，确保您的业务系统在高效、安全的环境中稳定运行。&lt;/p&gt; 
 &lt;p&gt;以上调整仅涉及 KubeSphere 开源版产品，不涉及 KubeSphere 核心代码的开源项目，其仍将在原有开源模式下持续迭代，并保持使用 Apache License 2.0 with additional conditions。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0801/135922_dIql_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;KubeSphere 是青云科技开源的多租户容器平台，提供全栈的 IT 自动化运维的能力，简化企业的 DevOps 工作流。KubeSphere 提供了运维友好的向导式操作界面，帮助企业快速构建一个强大和功能丰富的容器云平台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363593</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363593</guid>
      <pubDate>Thu, 17 Jul 2025 06:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AutoMQ 1.5.0 开源版正式发布：构建 kafka 实时数据湖新范式</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;重磅发布｜AutoMQ 1.5.0 开源版正式发布：构建 kafka 实时数据湖新范式！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;引领云原生创新之路&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AutoMQ 开源版本 1.5.0 正式发布&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Image" src="https://oscimg.oschina.net/oscnet/up-4d1dbc53c3c358d60c4bc5ac2f1828359a1.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;实时数据湖，为何成为数据架构的下一个风口？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着数据实时化趋势席卷全球，&lt;strong&gt;"实时数据湖"（Streaming Lakehouse）正迅速成为云计算与大数据领域最受关注的技术方向&lt;/strong&gt;。Snowflake、Databricks、Confluent、AWS 等云厂商纷纷推出相关方案，希望打通从数据采集、处理到分析的一体化链路，构建下一代数据基础设施。&lt;/p&gt; 
&lt;p&gt;实时数据湖是一种支持数据实时写入与即时分析的新型架构，将流式数据直接接入数据湖，实现低延迟、低成本的数据处理与消费。相比传统的数据湖与数据仓库分离架构，&lt;strong&gt;实时数据湖融合了数据湖的弹性与数据仓的实时性，具备以下优势&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;无需复杂 ETL 作业&lt;/strong&gt;，数据可从 Kafka 等流引擎直接写入湖中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;延迟更低&lt;/strong&gt;，支持秒级甚至毫秒级分析查询&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;架构更简&lt;/strong&gt;，避免 Flink/Spark 频繁调度与维护开销&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;一致性强&lt;/strong&gt;，能与主业务系统保持 Schema 与数据同步&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在这场变革中，Kafka 被视为实时数据的入口，但其本身并不具备"入湖"能力。为此，AutoMQ 在最新发布的 &lt;strong&gt;1.5.0 开源版本中推出了重磅特性------Table Topic&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;通过将 Kafka Topic 与 Iceberg 表原生绑定，实现真正意义上的 &lt;strong&gt;Zero-ETL 流式入湖&lt;/strong&gt;，让 Kafka 成为实时数据湖的核心引擎。&lt;/p&gt; 
&lt;p&gt;这也意味着，开发者可以用最少的工具链、最少的运维成本，搭建出真正实时、开放、低成本的 Lakehouse 架构。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;一站式云原生 Kafka：开源、可控、零 ETL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AutoMQ 开源版本 &lt;strong&gt;1.5.0&lt;/strong&gt; 正式发布！作为&lt;strong&gt;首个运行于 Amazon S3 的开源 Kafka 发行版&lt;/strong&gt; ，本次版本不仅全面强化了 "云原生、低成本、强可控" 的核心能力，更以创新特性 &lt;strong&gt;Table Topic&lt;/strong&gt; 正式加入实时数据湖阵营，为企业构建 &lt;strong&gt;Zero-ETL 流式入湖能力&lt;/strong&gt;提供了真正可用、可控、开放的开源方案。&lt;/p&gt; 
&lt;p&gt;AutoMQ 基于 Apache 2.0 协议完全开源，无需商业授权即可在生产环境运行，100% 兼容 Kafka 协议，支持现有工具链无缝迁移，是真正面向未来的数据基础设施构建工具。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本次版本重点包括：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Table Topic：Kafka 与 Iceberg 表的原生绑定，真正实现 Zero-ETL 流式入湖&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;零跨 AZ 架构：全面消除跨可用区流量，Kafka 云上成本可降低高达 70%&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 Bitnami Helm Chart：一键部署至 Kubernetes，轻松搭建云原生 Kafka 集群&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过持续深化开源能力，AutoMQ 正在让云上 Kafka 更轻、更强、更开放。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;01 零 ETL，Kafka 秒变 Iceberg 表&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;数据平台构建中，如何将 Kafka 实时数据写入数据湖 Iceberg，一直是工程难题。传统做法需依赖 Spark、Flink 等复杂 ETL 作业，不仅成本高，还带来延迟、失败率、Schema 演化等问题。&lt;/p&gt; 
&lt;p&gt;AutoMQ 提出的 &lt;strong&gt;Table Topic&lt;/strong&gt; 是一种全新机制------将 Kafka Topic 原生绑定至 Iceberg 表，无需任何中间件或外部任务，实现 Kafka 到 Iceberg 的零 ETL 流式写入：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Image" src="https://oscimg.oschina.net/oscnet/up-7986bc5eb8dbffa9f36630a7749b989ab0d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单配置即可启动，自动完成 Schema 注册、演化、字段映射与 Upsert&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 GiB/s 级别的实时写入&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完整保留 Kafka 流特性，适用于 CDC、审计日志、实时分析等场景&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Kafka 不再只是消息通道，而是直接成为湖仓的实时数据源。这意味着你可以用最简化的架构，构建出高效、实时、低成本的数据系统。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;📖 推荐阅读下方相关文章，了解更多技术细节：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNzY0ODE2Ng%3D%3D%26mid%3D2247488409%26idx%3D1%26sn%3Db2bc366bf8d66434880dfa8e43eceda0%26scene%3D21%23wechat_redirect" target="_blank"&gt;为什么越来越多企业放弃 Flink/Spark，用 AutoMQ 替代传统 ETL？&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;02 零跨区流量，Kafka 云上运行也能不"烧钱"&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;云上 Kafka 最大的隐形成本就是&lt;strong&gt;跨 AZ 流量&lt;/strong&gt; 。据统计，在三可用区部署的 Kafka 集群中，&lt;strong&gt;跨区数据传输费用可占总云成本的 50%&lt;/strong&gt; ，其中包括副本同步、消费者拉取和跨区 Produce 请求等高频操作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AutoMQ&lt;/strong&gt; 通过基于 &lt;strong&gt;S3 的共享存储架构&lt;/strong&gt; ，彻底移除了生产、复制、消费路径中的跨区流量，实现真正意义上的&lt;strong&gt;跨 AZ 流量归零&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Image" src="https://oscimg.oschina.net/oscnet//06402ccf96142e4f368e54a18fb34ff1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生产路径&lt;/strong&gt;：通过智能代理和跨区代理通道，实现跨 AZ Produce 请求的就近接入&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;复制路径&lt;/strong&gt;：使用 S3 + 奇偶校验代替传统 Broker 间复制，完全消除复制带宽开销&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;消费路径&lt;/strong&gt;：每个 AZ 提供只读分区，消费者本地读取，无需跨区读流&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;成本对比&lt;/h3&gt; 
&lt;p&gt;AutoMQ vs Apache Kafka 在，多 AZ 场景下 30MiB/s 写入吞吐的成本对比&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Image" src="https://oscimg.oschina.net/oscnet/up-914401f80c6e4e14510617fc78cc305a8e3.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以典型 30MiB/s 写入负载为例，&lt;strong&gt;Kafka 每月跨 AZ 成本可达 $4,050&lt;/strong&gt; ，而 AutoMQ 架构下仅需 &lt;strong&gt;约 $158 的 S3 存储与 API 成本&lt;/strong&gt; ，&lt;strong&gt;节省超 95% 的流量费用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这一创新架构显著提升可扩展性和稳定性，同时降低运维复杂度，真正实现 Kafka 在云上的"降本增效"，是企业级 Kafka 云部署的理想方案。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;03 一键部署 Kafka？AutoMQ × Bitnami 让它变简单了！&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AutoMQ 1.5.0 现已原生支持 Bitnami Helm Charts，用户可零门槛接入 AutoMQ，在 Kubernetes 中通过熟悉的 Helm 流程实现一键部署，无需额外修改配置或编写 Operator 脚本，即可运行一个无状态、弹性伸缩、S3 原生存储的 Kafka 集群。&lt;/p&gt; 
&lt;p&gt;&lt;img height="274" src="https://oscimg.oschina.net/oscnet/up-9cf5420b017b80fe16c2c1e5d71e5499fba.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一集成为用户带来了更高的部署效率和更低的学习成本，特别适合希望快速在生产环境中验证或上线 Kafka 流处理平台的技术团队。&lt;/p&gt; 
&lt;p&gt;💡 适用于：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;AWS EKS、Google GKE、Azure AKS、阿里云 ACK、腾讯云 TKE 等主流云平台&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;私有化部署与混合云场景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从 Apache Kafka 平滑迁移至 AutoMQ 的替代方案&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;无论你是 DevOps 工程师、平台架构师，还是正在寻找开源替代方案的技术负责人，AutoMQ 与 Bitnami 的结合，都能为你提供稳定、标准化的部署体验，并显著降低维护复杂度。&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;AutoMQ：开源、自主、真正云原生的 Kafka&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;自开源以来，AutoMQ 已获得众多云原生团队与企业技术负责人认可，并在多种生产环境中成功验证。如今，越来越多公司选择与我们合作，拥抱 Kafka 的云原生未来。&lt;/p&gt; 
&lt;p&gt;AutoMQ 完全开源，免费可用，无需修改原有工具链，即可替代传统 Kafka 集群部署。&lt;/p&gt; 
&lt;p&gt;👉 下方一键快速部署指南 | 快速启动你的云原生 Kafka 之旅！&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.automq.com%2Fdocs%2Fautomq%2Fgetting-started%2Fdeploy-multi-nodes-test-cluster-on-docker%3Futm_source%3Dautomq_1_5_launch" target="_blank"&gt;https://www.automq.com/docs/automq/getting-started/deploy-multi-nodes-test-cluster-on-docker?utm_source=automq_1_5_launch&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6990971/blog/18686688</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6990971/blog/18686688</guid>
      <pubDate>Thu, 17 Jul 2025 05:56:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>谷歌 DeepMind 推出虚拟衞星 AI 模型 AlphaEarth Foundations</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;谷歌 DeepMind 近日推出了名为 AlphaEarth Foundations 的人工智能系统，该系统旨在将海量的衞星数据转化为统一的数字表示，以提高环境分析的准确性，支持食物安全、森林砍伐和水资源等问题的决策。AlphaEarth Foundations 可以被视作一种 「虚拟衞星」，它以每 10x10 米的分辨率对地球的所有陆地和沿海水域进行描绘。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="397" src="https://oscimg.oschina.net/oscnet/up-76da4876193012eb1829ee5227d378659b8.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这一模型整合了多种数据来源，包括光学衞星图像、雷达、3D 激光测绘和气候模拟。通过将这些输入数据压缩为 64 维嵌入（embedding），DeepMind 实现了数据的高效表示。其训练过程中，AlphaEarth Foundations 使用了来自全球超过 500 万个地点的超过 30 亿条观测数据，数据来源涵盖了 Sentinel-2 和 Landsat 等衞星任务，还结合了维基百科文章和物种观察等文本信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;该系统的目标是解决数据过载和信息不一致的两个核心挑战。AlphaEarth Foundations 能够穿透持续的云层，绘制南极洲的复杂地表，并揭示加拿大小麦种植中的微小变化，这些细节是人眼所无法捕捉到的。在与传统方法及其他 AI 绘图系统的对比测试中，AlphaEarth Foundations 的错误率平均低了 24%。该模型在土地利用分类、生物物理变量估算和变化检测等 15 个评估数据集上表现优异。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AlphaEarth Foundations 还能够在处理数据稀缺的情况下进行有效工作，其持续的时间分析功能使得系统可以对不完全对齐的时间段进行精确预测。该模型的 「时空精度」（STP）架构将来自同一地点的不同时期的衞星图像视作视频中的帧，这样的处理方式使系统能够学习空间、时间和测量之间的关系，从而生成捕捉局部环境和时间轨迹的嵌入表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;目前，已有 50 多家组织在现实应用中测试这一系统。全球生态系统地图（Global Ecosystems Atlas）利用该数据将以前未映射的生态系统分类，包括沿海灌丛和超干旱沙漠等。巴西的 MapBiomas 则借助这些数据深入分析农业和环境变化，尤其是亚马逊雨林等关键生态系统。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，谷歌还将在 Google Earth Engine 上发布名为衞星嵌入数据集（Satellite Embedding Dataset）的年度嵌入数据。根据 Google Earth Engine 的数据，该数据集每年生成超过 1.4 万亿个嵌入足迹，为识别全球相似环境条件、变化检测、自动聚类和更智能的分类提供了多种应用场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;为了加速科学研究，谷歌还提供最高 5000 美元的研究资助，以支持基于衞星嵌入的应用案例研究。DeepMind 的开发团队认为，AlphaEarth Foundations 是理解我们不断变化的星球状态和动态的重要一步，并期待将其与通用推理大型语言模型（LLM）结合，创造出更强大的应用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363560</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363560</guid>
      <pubDate>Thu, 17 Jul 2025 03:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>小米浏览器升级 AI 搜索功能，接入豆包大模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;小米浏览器&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FK4dYPsQQDmK8m3aM5iekXQ" target="_blank"&gt;宣布&lt;/a&gt;已升级 「AI 搜索」 功能，通过接入豆包大模型及火山方舟高代码智能体产品，进一步提升了 AI 搜索的效率与服务丰富度。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;作为数亿小米终端的系统级浏览器，小米浏览器推出「AI 搜索」功能，通过接入豆包大模型 1.5 和豆包视觉理解大模型，带来自然语言交互的搜索体验，同时进一步解锁更多服务。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;现在，点击该浏览器的「AI 搜索」，一个问题，直达结果。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height="634" src="https://oscimg.oschina.net/oscnet/up-6f3d3bed8cba7a28b2216c0b7855d9bdf4c.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同时，小米应用商店接入火山引擎扣子，用户通过扣子搭建的智能体，可以上传到小米应用商店。公告称，小米应用商店今年计划大力推广智能体模块，通过打通火山引擎扣子发布渠道至小米应用商店，共同探索更多智能体分发场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;「&lt;span style="color:#000000"&gt;未来，小米应用商店、小米浏览器将持续携手火山引擎，深入探索大模型与智能体在终端场景中的应用，拓展智能交互边界，为用户带来更高效、便捷、个性化的服务。&lt;/span&gt;」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363556</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363556</guid>
      <pubDate>Thu, 17 Jul 2025 03:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Manus 上线 Wide Research，多智能体并发处理大规模任务，月费 199 美元起</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Manus 上线了一项名为 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmanus.im%2Fzh-cn%2Fblog%2Fintroducing-wide-research" target="_blank"&gt;Wide Research &lt;/a&gt;的新功能，允许系统调用大量 AI 智能体并行处理任务，实现大规模数据的同步运算处理。这将是自今年 3 月平台发布以来最大的一次功能更新，首发版本将面向月费 199 美元的高级订阅用户开放。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/112140_q2ms_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这项功能的核心在于「智能体集群协作」：用户可以同时指派数十个智能体协同工作，完成例如「生成 50 张海报设计稿」、「评选全球前 100 MBA 项目」或「分析 1000 支股票表现」等复杂任务——这些通常对 OpenAI 的 Deep Research 等现有工具构成挑战。知情人士表示，Wide Research 将显著提升产品在通用研究和自动执行任务方面的能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/112120_zAdV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据称，该公司技术团队过去两个月一直专注研发 Wide Research，旨在通过多智能体并行计算建立产品的差异化优势。联合创始人季逸超计划以视频形式展示该功能，方式将类似于他当初发布 Manus 时的演示。目前，Manus 已将运营总部从中国迁往新加坡、东京和加州圣马特奥。其产品构建于如 Anthropic Claude 等大语言模型之上，尚未在中国市场上线。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363554/manus-wide-research</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363554/manus-wide-research</guid>
      <pubDate>Thu, 17 Jul 2025 03:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
