<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 08 Sep 2025 02:57:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>OpenAI 最新论文：语言模型为什么会出现幻觉？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 近日发表的新论文&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fwhy-language-models-hallucinate%2F" target="_blank"&gt;《Why language models hallucinate》&lt;/a&gt;&lt;/em&gt;研究了语言模型产生幻觉的核心原因，认为是现有训练与评估机制鼓励模型猜测而非承认不确定性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/104428_pwe5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该论文认为，语言模型之所以会产生幻觉（即在不确定时进行猜测，生成看似可信但错误的陈述，而不是承认不确定性），是因为现有的训练和评估程序更倾向于奖励猜测行为，而非承认不确定性的做法 。&lt;/p&gt; 
&lt;p&gt;就像面对难题的学生一样，大型语言模型在不确定时有时会进行猜测，从而产生看似合理但错误的陈述，而不是承认不确定性。&lt;/p&gt; 
&lt;p&gt;这种「幻觉」现象即使在最先进的系统中也持续存在，并会破坏信任。&lt;/p&gt; 
&lt;p&gt;我们认为，语言模型产生幻觉是因为训练和评估程序奖励猜测而非承认不确定性，我们还分析了现代训练流程中产生幻觉的统计原因。&lt;/p&gt; 
&lt;p&gt;幻觉无需被神秘化——它们源于简单的二元分类错误。如果无法将不正确的陈述与事实区分开来，那么预训练语言模型中的幻觉就会在自然的统计压力下产生。&lt;/p&gt; 
&lt;p&gt;接着我们认为，幻觉之所以持续存在，是因为大多数评估的评分方式——语言模型被优化成优秀的「考生」，而在不确定时进行猜测可以提高测试表现。&lt;/p&gt; 
&lt;p&gt;这种惩罚不确定性回答的「流行病」只能通过一种社会技术性的缓解措施来解决：修改那些虽不一致但主导着排行榜的现有基准测试的评分方式，而不是引入额外的幻觉评估。&lt;/p&gt; 
&lt;p&gt;这一改变或许能引导该领域走向更值得信赖的人工智能系统。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370863/why-language-models-hallucinate</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370863/why-language-models-hallucinate</guid>
      <pubDate>Mon, 08 Sep 2025 02:45:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>苹果计划 2025 年底在中国推出 Apple Intelligence</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;彭博社记者 Mark Gurman &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2025-09-07%2Fapple-s-iphone-17-air-event-which-new-iphone-should-i-buy-iphone-17-pro-mf9n5f9g" target="_blank"&gt;最新透露称&lt;/a&gt;，苹果目前还在继续推进 Apple Intelligence 在中国的发布计划，预计年底前才能上线，iPhone 17 首发无缘。&lt;/p&gt; 
&lt;p&gt;据悉，国行 iPhone 的 Apple Intelligence 是通过第三方提供服务，整合了阿里巴巴、百度的大模型。&lt;/p&gt; 
&lt;p&gt;其中，文心一言是核心云端引擎，阿里负责苹果内容合规审查。其实 iOS 18.5 开始，Apple Intelligence 就已经支持中文版了，苹果方面的准备已经就位，目前更多的是审核问题。&lt;/p&gt; 
&lt;p&gt;据报道，苹果正组织中国区员工对相关功能进行测试，并持续与阿里巴巴及其他合作方推进技术落地工作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370856</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370856</guid>
      <pubDate>Mon, 08 Sep 2025 02:28:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>法院在 Meta 诉 Bright Data 案中判决 Bright Data 胜诉，重申收集公共网络数据的权利</title>
      <description/>
      <link>https://www.oschina.net/news/370852</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370852</guid>
      <pubDate>Mon, 08 Sep 2025 02:11:28 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 支付 15 亿美元和解版权诉讼</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 初创公司 Anthropic 近日同意支付至少 15 亿美元，以和解一起涉及 50 万本书籍的版权侵权诉讼。这一和解协议创下美国版权案件史上的&lt;span&gt;最高&lt;/span&gt;金额记录，标志着 AI 行业与内容创作者之间版权争议的重要里程碑。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据诉讼指控，Anthropic 被指通过 Library Genesis 和 Pirate Library Mirror 等盗版网站下载了超过 700 万本电子书，并将这些内容用于训练其聊天机器人 Claude。和解协议显示，每位受影响的作家预计将获得约 3000 美元赔偿，远高于美国作家协会最初预估的 750 美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，Anthropic 还承诺销毁其下载的所有原始文件及副本。该案件于去年 8 月由作家安德里亚·巴茨、查尔斯·格雷伯和柯克·华莱士·约翰逊等人代表提起诉讼。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-faa55c0e99754ad42c61e9d8fc6f9dda387.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在法庭审理过程中，Anthropic 曾试图以"合理使用"原则为其行为辩护，但法院并未采纳这一辩解。法院认为，Anthropic 明知使用的是盗版材料，因此其合理使用主张不能成立。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;美国作家协会首席执行官玛丽·拉森伯格对和解结果表示积极态度，认为这向 AI 行业传达了明确信号:未经授权使用作家作品进行 AI 训练将面临严重法律后果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，业内分析人士指出，虽然 15 亿美元的赔偿金额看似巨大，但对于刚刚完成 130 亿美元融资、估值达 1830 亿美元的 Anthropic 而言，这笔费用相对有限。这引发了人们对科技公司可能将此类赔偿视为"发展成本"的担忧。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得注意的是，类似的版权争议并非孤立事件。苹果公司和华纳兄弟近期也因相似问题面临诉讼，显示出 AI 行业在版权问题上的普遍挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这起案件的和解反映了 AI 技术发展与知识产权保护之间的紧张关系。随着 AI 模型对大量训练数据的需求不断增长，如何在技术创新与版权保护之间找到平衡点，将成为行业发展面临的重要课题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;对于内容创作者而言，此次和解虽然带来了经济补偿，但也暴露了数字时代版权保护的复杂性。未来，相关法律法规和行业标准的完善将对 AI 技术的健康发展起到关键作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370850</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370850</guid>
      <pubDate>Mon, 08 Sep 2025 02:06:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义发布 Qwen3-Max-Preview，参数量超 1 万亿</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义 Qwen 团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJQocVWFMgBemmRnip7mzqQ"&gt;正式发布&lt;/a&gt;万亿参数大模型 Qwen3-Max-Preview，参数量突破 1 万亿级别，成为其迄今规模最大的闭源旗舰模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0908/100034_nrr2_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Qwen3-Max-Preview 在多项主流权威基准测试中展现出全球领先的性能。&lt;/p&gt; 
&lt;p&gt;在通用知识（SuperGPQA）、数学推理（AIME25）、编程（LiveCodeBench v6）、人类偏好对齐（Arena-Hard v2）以及综合性能力评估（LiveBench）评测中，Qwen3-Max-Preview 超越了 Claude-Opus 4（Non-Thinking），以及 Kimi-K2、DeepSeek-V3.1 和通义此前的开源最佳 Qwen3-235B-A22B-Instruct-2507。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0908/100102_inEl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，Qwen3-Max-Preview 已正式上线阿里云百炼平台，可通过 API 直接调用。同时，Qwen Chat 也同步上线新模型，支持免费使用。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1486" src="https://static.oschina.net/uploads/space/2025/0908/100057_i9Sv_2720166.png" width="2988" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;🔗体验地址：https://chat.qwen.ai/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370848</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370848</guid>
      <pubDate>Mon, 08 Sep 2025 02:03:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国内首个 AI 计算开放架构发布</title>
      <description/>
      <link>https://www.oschina.net/news/370846</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370846</guid>
      <pubDate>Mon, 08 Sep 2025 01:54:28 GMT</pubDate>
    </item>
    <item>
      <title>智谱推出「Claude API 用户特别搬家计划」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，美国头部大模型公司&amp;nbsp;Anthropic&amp;nbsp;&lt;a href="https://www.oschina.net/news/370416" target="_blank"&gt;宣布&lt;/a&gt;，将停止向多数股权由中国资本持有的集团出售 Claude 服务，范围涵盖中国大陆及通过海外注册或云服务间接使用的企业。&lt;/p&gt; 
&lt;p&gt;为帮助开发者平稳过渡，智谱正式推出「Claude API 用户特别搬家计划」。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;一键迁移，畅享 GLM-4.5&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;智谱已全面兼容 Claude 协议，用户&lt;strong&gt;只需&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;替换 API URL&lt;/strong&gt;&lt;/strong&gt;，即可从 Claude 无缝切换至&amp;nbsp;&lt;strong&gt;&lt;strong&gt;GLM 模型 API&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智谱将为用户提供：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;新用户&lt;/strong&gt;&lt;/strong&gt;：赠送 2000 万 Tokens 免费体验；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开发者&lt;/strong&gt;：GLM-4.5 编码专属包月套餐，价格仅为 Claude&amp;nbsp;&lt;strong&gt;1/7&lt;/strong&gt;，用量提升&amp;nbsp;&lt;strong&gt;3 倍&lt;/strong&gt;、速度更快（平均 55 Tokens/s）；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;迁移无忧&lt;/strong&gt;：从 Claude 到 GLM 的系统迁移教程，可便捷、快速地完成模型切换。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;为企业客户额外提供：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;满足业务需求的并发规模；&lt;/li&gt; 
 &lt;li&gt;更低成本的折扣优惠权益；&lt;/li&gt; 
 &lt;li&gt;1 对 1 的搬家顾问与解决方案服务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速迁移教程&lt;/h2&gt; 
&lt;p&gt;如果你在使用 Claude API，访问 bigmodel.cn，迁移到 GLM 非常简单。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;替换你访问的&amp;nbsp;base_url&amp;nbsp;为&amp;nbsp;https://open.bigmodel.cn/api/anthropic；&lt;/li&gt; 
 &lt;li&gt;在智谱开放平台申请&amp;nbsp;api_key；&lt;/li&gt; 
 &lt;li&gt;调用时使用智谱模型编码即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# 原来的 Claude 代码
import anthropic
client = anthropic.Anthropic(
    base_url="your-base-url",
    api_key="your-api-key",
)
# 迁移到智谱 AI，只需要修改三个地方
client = anthropic.Anthropic(
    api_key="your-zhipuai-api-key",  # 替换为智谱 AI API Key
    base_url="https://open.bigmodel.cn/api/anthropic"  # 配置智谱 AI base_url
)
# 模型编码使用，智谱 AI 模型，其他代码保持不变
message = client.messages.create(
    model="glm-4.5",  # 使用智谱 AI 模型
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
)&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370531</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370531</guid>
      <pubDate>Fri, 05 Sep 2025 10:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元游戏视觉生成平台正式发布 2.0 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;腾讯混元游戏视觉生成平台正式发布 2.0 版本，新增游戏图生视频、自定义模型训练、角色一键精修等能力，并大幅提升游戏 2D 生图模型能力，图生视频和文生图模型在游戏场景达到行业 SOTA 水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次升级进一步解决了游戏美术设计与宣发中的动态内容生成、风格定制化、细节优化等痛点，帮助游戏美术设计师提高效率。本次能力升级的同时，混元游戏平台宣布面向所有用户开放，用户可以通过腾讯混元官网体验，登录即可使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="274" src="https://oscimg.oschina.net/oscnet/up-881d8901997b0231d342668e831e17877df.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;新推出的游戏 AI 动画/CG 能力基于腾讯混元图生视频能力，可以让静态画面秒变动画，包括角色 360 度旋转等游戏。用户上传任意游戏图片并输入动态描述，即刻生成高质量动态视频，支持游戏角色动作、场景特效及「万物旋转」展示，适用于游戏 CG 预演、角色原画三视图创作、技能特效预览，替代传统逐帧绘制流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自定义模型训练大幅降低了生图模型精调门槛，让个人用户也可以通过少量图片微调自己专属的 LoRA 模型，解决游戏项目风格统一难题，尤其适合独立工作室打造 IP 化美术资产。混元游戏官网提供了预设风格，包括欧卡、二次元、写实 CG 等，同时支持用户使用个人数据集训练专属 LoRA 风格模型或者角色模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自定义模型训练能力基于混元生图底模，简化了 LoRA 模型的训练流程，用户只需上传数十张图片并设置触发词，系统自动打标，数小时即可完成模型训练。整个训练过程均为可视化操作，无需代码基础或复杂工具。该能力目前处于内测阶段，用户可以申请使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;角色一键精修能力主要用于对游戏角色原画的细节丰富或风格转换，提供高一致性模式和高创意性模式。高一致性模式可保留原图结构，精细化服饰纹理、光影层次，适用于角色定稿优化；高创意性模式支持将角色原画转换为国风、3D 化、二次元等风格并细化效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;混元游戏 2.0 针对平台背后的 2D 生图模型进行了升级，文生图能力达到游戏行业 SOTA 级别。混元游戏大幅提升生图模型的美学与构图，使其更能满足游戏美术创作需求，同时针对游戏独有的场景进行优化，提供游戏技能特效、环境特效与游戏交互界面等生成能力，专项优化游戏场景、游戏道具物品、游戏角色等生成效果。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370526</guid>
      <pubDate>Fri, 05 Sep 2025 10:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>联想发布全球首款垂直旋转屏 AI PC</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在德国柏林 IFA 期间举行的 2025 联想创新世界大会上，联想带来了诸多新品。其中最引人注意的就是一款 ThinkBook VertiFlex 概念机，同时这也是业界首款 14 英寸屏幕可垂直旋转笔记本电脑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="278" src="https://oscimg.oschina.net/oscnet/up-37aa8c07d9e00681e1351bdc757279581ab.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这款概念机最大特点就是配备的旋转显示系统，可以在水平和垂直方向之间双模式切换，采用 17.9 毫米和 1.39 公斤轻薄设计。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;垂直显示模式适合分屏多任务、显示代码和查看文档等场景，并且在垂直显示模式下，智能手机可以通过联想超级互联连接到 PC 上，用于传输文件和手机镜像。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="311" src="https://oscimg.oschina.net/oscnet/up-59757bf204952fc6b4dbc03f4a4839c6721.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;事实上，这并不是联想首次在笔记本电脑屏幕上的创新，此前就曾发布了透明屏、三折叠屏，以及今年即将开卖的卷轴屏 PC。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370522</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370522</guid>
      <pubDate>Fri, 05 Sep 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>全球首个「一站式」数智化生命科学研究平台 AI4S LAB 上线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;北京大学深圳研究生院与百度智能云近日联合宣布，双方携手打造的「一站式」数智化生命科学研究平台——AI4S LAB 正式上线。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该平台深度整合算力、数据、模型、实验四大要素，开发多智能体协同系统，为科研工作者带来「AI 驱动、干湿闭环、全链数智」的云端科研体验，极大提升科研效能与创新能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-4a6c75631c23cca67acff14e602a9274676.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI4S LAB 数智化支撑生态建设包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;算力：配备可伸缩的高性能计算集群，搭载面向科学智能需求的超智融合算力调度系统。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;模型：基于百度智能云千帆大模型平台开发私有化模型与数据管理能力，为 AI4S LAB 提供了 Agent 开发所需模型、Agent 编排、数据和定制化服务。匹配一站式模型效果调优工具链，为平台提供模型纳管、精调与推理支持，尤其是生物领域大语言的场景化适配与调用。具有卓越的模型推理托管能力，在配备超 10 个可直接使用的通用与生命科学垂直领域代表性模型的同时，还支持各类主流推理框架和模型的自定义导入与部署，为科研工作者提供了高度灵活的开发环境。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;数据：配备超 15 个专业数据集，提供开放共享且持续产生新数据的知识平台，提供高效数据管理功能、智能可视化数据分析工具。实验：集成超过 22 台套的先进高通量、自动化、自迭代智能实验设备，面对生命合成领域，提供工程菌株构建与优化，蛋白表达与酶工程，代谢工程与调控，非天然氨基酸整合，合成噬菌体开发等多场景提供高效科研服务。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;北京大学深圳研究生院自主研发的 AI4S 原生多智能体系统——BIOMA，是平台全链路智能化实现的核心，提供高效协同的云化研究能力，涵盖了从理论预测、实验设计、自动化执行到数据分析与迭代的各个环节，助力科研人员突破传统研究的时空限制。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;BIOMA 多智能体系统的强大能力包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;逆向智能设计： 从期望的功能或性能指标出发，智能设计全新的实验方案与材料。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能创制与表征： 自动化地执行复杂的实验流程，并对结果进行精确表征。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;科研数据智能分析与迭代： 对海量实验数据进行深度分析，并基于分析结果自主优化后续实验方案。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-42c4dd9e2e3b6665fae4d5b9511c060a767.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;BIOMA 多智能体系统由一系列功能协同的智能体构成，每个智能体在科研流程中扮演着关键角色：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#222222"&gt;理论科学家智能体（PredAgent）&lt;/strong&gt;&lt;strong style="color:#222222"&gt;，&lt;/strong&gt;在理论预测阶段，解析科研人员以自然语言输入的研究构想，并即时调用全球前沿的预测模型和工具进行模拟与计算。极大地提升了理论设计的效率，更通过算法优化增强了预测的准确性，为后续的实验研究奠定坚实理论基础。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;实验规划师智能体（ProAgent）&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;具备自主生成完整、可执行的标准化实验方案的能力。在干湿闭环&lt;strong&gt;验证&lt;/strong&gt;&lt;strong&gt;阶段&lt;/strong&gt;，通过与研究人员的多轮交互，精确提炼并完善湿实验方案的每一个细节，包括试剂选择、参数设定以及仪器调配等，从而构建出逻辑严谨、操作性强的实验流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能实验室自动化被《自然》期刊列为「2025 年值得关注的七大技术」之首。&lt;strong&gt;实验室指挥官智能体（OperAgent）&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;负责在实验执行阶段，将 ProAgent 生成的复杂实验方案转化为机器可精确执行的指令。通过对实验室超 22 台自动化设备的多线程精准调度与协同控制，成功打造 7x24 小时不间断运行的「黑灯实验室」，实现了真正意义上的无人化、自动化实验流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据分析师智能体（ComAgent），&lt;/strong&gt;致力于构建一个一体化的科研数据生态系统，提供丰富的数据分析工具与可视化图表，同时基于设定的关键性能指标，对实验数据进行深度挖掘与洞察。通过自主分析，ComAgent 生成富有洞见的优化建议，并自动规划下一轮的实验方案，从而形成可持续进化的科研闭环，加速科学发现进程。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370509</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370509</guid>
      <pubDate>Fri, 05 Sep 2025 09:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Hopp - 开源结对编程应用程序</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hopp 是一款开源结对编程应用，可让你与队友结对编程。该应用使用 Tauri 构建，WebRTC 基础架构由&lt;a href="https://livekit.io/"&gt;LiveKit&lt;/a&gt;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;img height="132" src="https://static.oschina.net/uploads/space/2025/0903/144658_hgds_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特性&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;超高品质屏幕共享&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gethopp.app/blog/latency-exploration"&gt;优化了 WebRTC&lt;/a&gt;，以获得最佳质量的屏幕共享&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.livekit.io/home/cloud/architecture/#distributed-mesh-architecture"&gt;依靠 LiveKit 网络&lt;/a&gt;实现大规模低延迟&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Mob&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;编程&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;加入房间并立即与最多 10 名队友配对&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一键配对&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;不再在聊天中与队友分享链接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开放式建造&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;希望与 OSS 社区共同打造 Hopp&lt;/li&gt;
&lt;li&gt;这带来了自托管和社区创新的好处&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/hopp</link>
      <guid isPermaLink="false">https://www.oschina.net/p/hopp</guid>
      <pubDate>Fri, 05 Sep 2025 09:24:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenDataLab 与钉钉联手推出面向企业用户的文档解析工具 DLU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;OpenDataLab 和钉钉基于 MinerU &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLg-4_0PNluM8l_pYQTjc7Q" target="_blank"&gt;推出&lt;/a&gt;了一款面向企业用户的文档解析工具——DLU&lt;/span&gt;&lt;span&gt;(Document Language Understanding)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/172338_aEbD_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MinerU 是上海人工智能实验室（上海 AI 实验室）OpenDataLab 推出的智能文档解析引擎，因精准解析能力及广泛兼容性深受用户青睐，在 GitHub 上已累计获得超 4 万星标。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/172239_vfIi_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;基于 MinerU 打造的 DLU 将于近期开源，其具备良好的文件格式兼容性，深层次的内容理解与精准的结构化输出能力，不仅支持主流的 Office 文档、PDF、Markdown 及代码文件，还涵盖钉钉自有的文档、表格与 AI 表格格式；并支持提取纯文本内容，精准解析图表、公式、插图乃至专业领域的化学分子式等复杂视觉元素，并将其有效转换为适合大模型训练的高质量语料。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370505</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370505</guid>
      <pubDate>Fri, 05 Sep 2025 09:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>拍我 AI 接入谷歌 Nano Banana，限时免费使用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;拍我 AI 已正式接入谷歌 Nano Banana（Gemini 2.5 Flash Image），并同步开启「拍我 AI 免费开放日」限时活动，从 9 月 5 日持续至 9 月 10 日，为期六天。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-31f43668eb292a7a399ef21c78092a4f3ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;在此期间，国内用户可免费体验 PixVerse Agent 创作助手，零成本生成各类创意短片。用户只需选择喜欢的模板并上传一张图片，Agent 即可自动识别图像特征，生成 5–30 秒的完整视频。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;作为国内首批接入 Nano Banana 的 AI 视频生成平台，拍我 AI 国内版同步推出更多趣味模板，包括 3D 手办制造局、和名人合照、捕获心动角色、骑龙高手等，让普通用户也能轻松上手，制作精致、有趣的短视频作品，以及更进一步制作出自己喜爱的游戏画面！目前拍我 AI 网页端和移动端 APP 均可同步体验。&lt;/p&gt; 
&lt;p&gt;今年 6 月 6 日，PixVerse 上线了中国版本拍我 AI，目前平台的全球用户规模已突破 1 亿。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370503</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370503</guid>
      <pubDate>Fri, 05 Sep 2025 09:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>VC 投资人尝试 20 天「氛围编程」，称成本高昂、易累积技术债</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Kevin Kuipers 是一名 VC 投资人，最近他&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkevinkuipers.substack.com%2Fp%2Fvc-for-vibe-coding-a-fresh-new-start" target="_blank"&gt;分享&lt;/a&gt;了「Vibe Coding」的实践经验，通过 AI 编程构建面向 VC 的全新工作平台。&lt;/p&gt; 
&lt;p&gt;Kuipers 在暑假期间尝试了沉浸式的「氛围编程（Vibe Coding）」，目标是为自己的基金打造「AI-native」（AI 原生）管理系统。他先从 Telegram 智能体起步，逐步扩展到 Web 和桌面端应用，用 AI 自动整合文章、邮件、Pitch Deck、对话等信息，构建出一个「知识云」，从非结构化数据中提炼趋势与洞见。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165630_7gXE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在技术栈上，他大量依赖 Supabase、Orq.ai、Mem0、Koyeb、Linkup、ScrapingBee 等工具，并利用 Claude 直接生成 UI/UX，大幅减少了传统 Figma 等设计流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165641_hALP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165713_UDsC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他指出，AI 编程的优势是能在几周内完成原型，显著提升迭代效率，但同时也伴随挑战：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;技术债容易累积，代码质量难控；&lt;/li&gt; 
 &lt;li&gt;成本高昂，仅 20 天就消耗约 2600 美元 Token；&lt;/li&gt; 
 &lt;li&gt;LLM 的创造力和破坏力并存，需要工程师负责架构与质量。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Kuipers 强调，「vibe coding」核心不是写代码，而是「快速建造」，让 VC 的知识管理和决策更高效。他认为，这种模式可能重塑风险投资的工作方式，也让投资人与工程师保持更深度的互动。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370500/vc-for-vibe-coding-a-fresh-new-start</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370500/vc-for-vibe-coding-a-fresh-new-start</guid>
      <pubDate>Fri, 05 Sep 2025 08:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「Nano Banana」上线不到 10 天，为谷歌 Gemini 吸引超过 1000 万名新用户</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌最新的 AI 实验项目「Nano Banana」在上周爆火，谷歌实验室副总裁 Josh Woodward 在 X 上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fjoshwoodward%2Fstatus%2F1963627742618165270" target="_blank"&gt;透露&lt;/a&gt;，自该功能上线以来，累计已完成超 2 亿次图像编辑，&lt;strong&gt;带动超 1000 万新用户尝试 Gemini 应用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;对于这款产品的受欢迎程度，他形容称导致「TPU 严重过载，SRE 警报不停。」&lt;/p&gt; 
&lt;p&gt;&lt;img height="854" src="https://static.oschina.net/uploads/space/2025/0905/164501_ZL7i_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;Gemini 2.5 Flash Image&lt;/span&gt;（内部代号 Nano Banana）是谷歌&lt;span style="background-color:#ffffff; color:#333333"&gt;最先进的图像生成与编辑模型，&lt;/span&gt;主要特点如下：&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;充分保持角色的一致性：它可以轻松地将同一个角色置于不同的环境中，或者从多个角度展示同一款产品，同时完美地保持其核心主体不变。&lt;/li&gt; 
 &lt;li&gt;基于提示的图片编辑：允许用户通过简单的自然语言指令，对图片进行精准的局部修改 。&lt;/li&gt; 
 &lt;li&gt;利用 Gemini 的现实世界知识：模型可借助 Gemini 强大的世界知识库，让图像生成变得更加「智能」。&lt;/li&gt; 
 &lt;li&gt;多幅图像融合：可以将一张图片中的物体「放」进另一张图片的场景里，整个过程只需一条提示指令就能完成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;性能表现上，Gemini 2.5 Flash Image 在多项基准测试上均为第一名，超越 OpenAI ChatGPT 4o（GPT Image 1 high）、Qwen Image Edit 等模型。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfee07407ab38e2b001fd0dbe895d36f242.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370497</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370497</guid>
      <pubDate>Fri, 05 Sep 2025 08:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>尤雨溪 VoidZero 公司 8 月成果速览</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;尤雨溪 VoidZero 公司&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fwhats-new-aug-2025" target="_blank"&gt;发布&lt;/a&gt;了 2025 年 8 月回顾，阐述了&amp;nbsp;Vite、Vitest、Oxc、Rolldown 的项目更新以及社区动态。&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-bf866c877e66b526b8d1364ddab2a5ebfa3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具体包括：&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Oxlint：类型感知 linting 和自定义 JS 插件&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Oxlint &lt;span style="color:#3d3d3d"&gt;旨在成为一款功能齐全、运行速度与原生速度一致的 Linting 替代品。本月发布了两项重大更新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;类型感知 linting&lt;/strong&gt;：基于 TypeScript 的 Go 端口和 tsgolint，支持 40 个类型感知规则，如 no-floating-promises。性能保持高效，无需牺牲速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自定义 JS 插件支持&lt;/strong&gt;：提供 ESLint 兼容 API，支持运行现有 ESLint 插件，而不牺牲性能。未来，几乎所有 ESLint 插件都能无缝兼容 Oxlint。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Vite&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vite 现已通过&lt;code&gt;@vitejs/plugin-rsc&lt;/code&gt;引入 React Server Component 支持。目标是为每个基于 Vite 的 React 框架提供统一的解决方案。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;@vitejs/plugin-react&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitejs%2Fvite-plugin-react%2Fblob%2Fmain%2Fpackages%2Fplugin-react%2FCHANGELOG.md%23500-beta0-2025-07-28" target="_blank"&gt;5.0 版本已发布&lt;/a&gt;。当检测到&lt;code&gt;rolldown-vite&lt;/code&gt;时，它会直接集成&lt;code&gt;@vitejs/plugin-react-oxc&lt;/code&gt;，因此不再需要额外安装其他插件。&lt;/li&gt; 
 &lt;li&gt;Dev server 漏洞修复，修复源代码泄露风险。详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreen.sapphi.red%2Fblog%2Faddressing-source-code-leaks-across-the-ecosystem-a-retrospective" target="_blank"&gt;阅读 Sapphi 的回顾博客文章&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvite-pwa%2Fvite-plugin-pwa%2Fpull%2F877" target="_blank"&gt;&lt;code&gt;vite-plugin-pwa&lt;/code&gt;（和其他 Vite 插件）&lt;/a&gt;的 Plugin Hooks 现已到位，使用&lt;code&gt;rolldown-vite&lt;/code&gt;时可显著提升其运行速度&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;Vitest&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vitest 在最新的 v4 测试版中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbsky.app%2Fprofile%2Ferus.dev%2Fpost%2F3luzbsen2722x" target="_blank"&gt;支持可视化回归测试&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;v4 测试版通过平均缩短 Vitest 启动时间 25%，进一步提升了测试速度。&lt;/li&gt; 
 &lt;li&gt;Vitest 的实验性&amp;nbsp;programmatic API&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitest-dev%2Fvitest%2Fpull%2F8408" target="_blank"&gt;现在可以解析测试文件，&lt;/a&gt;而不是运行它们来收集测试数据。这对于第三方服务提供商尤其有用，并且有助于未来实现更快的过滤速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Rolldown&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolldown-Vite&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitejs%2Frolldown-vite%2Fpull%2F168" target="_blank"&gt;开箱即用地支持原生插件&lt;/a&gt;。在原生标志下进行改进，并解决所有生态系统 CI 问题后，第一组插件被认为足够稳定，可以默认启用，从而提升所有构建的速度，而无需任何配置。&lt;/li&gt; 
 &lt;li&gt;消除&amp;nbsp;Dead code elimination 和 treeshaking 优化是精简 bundle 的关键。在最近的 Rolldown 版本中进行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fpull%2F5826" target="_blank"&gt;多项&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fpull%2F5829" target="_blank"&gt;改进&lt;/a&gt;，以进一步降低 bundle 大小。 
  &lt;ul&gt; 
   &lt;li&gt;新增&lt;code&gt;inlineConst&lt;/code&gt;&amp;nbsp;功能：在打包过程中内联导入的常量值（而非引用它们）。由于减少了变量查找次数，此特性可缩小打包文件体积并提升运行时性能。自 1.0.0-beta.35 版本起，此优化将默认启用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Rolldown 现在有一个&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frolldown.rs%2Freference%2Fconfig-options%23tsconfig" target="_blank"&gt;顶级&lt;code&gt;tsconfig&lt;/code&gt;选项&lt;/a&gt;。可以将其指向项目的 tsconfig 路径，从而允许解析器遵循&lt;code&gt;compilerOptions.paths&lt;/code&gt;的别名设置，并为转换配置建立默认值。此功能将取代先前引入的&lt;code&gt;resolve.tsconfigFilename&lt;/code&gt;选项。&lt;/li&gt; 
 &lt;li&gt;第一个案例研究已经发布：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fcase-study-plaid-rolldown" target="_blank"&gt;了解 PLAID Inc. 如何迁移到 Rolldown 并将其构建时间缩短 97%&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Oxc&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolldown 团队不仅致力于确保打包体积更小，Oxc 的压缩工具现在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foxc-project%2Foxc%2Fpull%2F13026" target="_blank"&gt;也会多次运行 dead code 消除&lt;/a&gt;，类似于 Rollup。这可以进一步减小打包体积，同时只增加极小的开销。&lt;/li&gt; 
 &lt;li&gt;如果你正在使用 React 和&lt;code&gt;styled-components&lt;/code&gt;，构建速度将显著提升，因为 Oxc 现在将其大部分功能作为原生转换支持。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fblob%2Fmain%2Fexamples%2Fstyled-components-native%2FREADME.md" target="_blank"&gt;如本例所示，&lt;/a&gt;它也可以在 Rolldown 中轻松启用。&lt;/li&gt; 
 &lt;li&gt;提升性能&lt;code&gt;tsgolint&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fwhats-new-aug-2025" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370495/voidzero-whats-new-aug-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370495/voidzero-whats-new-aug-2025</guid>
      <pubDate>Fri, 05 Sep 2025 08:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>这款插件让你在开源图像编辑器 GIMP 中体验谷歌 Nano Banana</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开发者 Josh Ellithorpe 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthoughts.greyh.at%2Fposts%2Fdream-prompter%2F" target="_blank"&gt;发布&lt;/a&gt;&amp;nbsp;Dream Prompter 开源插件，将谷歌最新的 Gemini 2.5 Flash Image Preview 模型（代号 「Nano Banana」）引入 GIMP。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-57d084ce880042f5d91d09d2e5a1dc48003.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该插件支持用户在 GIMP 内直接通过文字提示生成新图像，或对现有图像进行自然语言编辑，无需切换到外部工具。使用 Dream Prompter 需绑定启用计费的 Google Gemini API key，插件本身已开源并托管在 GitHub。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7dee797f30e7632220f65ce17e0f9abb13d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ellithorpe 表示，他在 Claude 模型的帮助下快速完成了插件开发。这一集成让 GIMP 用户能够在开源环境中享受与 Adobe 等商业软件类似的 AI 创作体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370492</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370492</guid>
      <pubDate>Fri, 05 Sep 2025 08:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 生成优化 Metal 内核，PyTorch 推理速度提升 87%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据 Gimlet Labs 的&lt;span&gt;最新&lt;/span&gt;研究，AI 能够自动生成优化的 Metal 内核，使得 PyTorch 推理速度提升了 87%。这一突破性成果不仅提高了性能，还在测试的 215 个 PyTorch 模块上实现了平均 1.87 倍的加速，某些工作负载的速度甚至提高了数百倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="236" src="https://oscimg.oschina.net/oscnet/up-bffbe7fb79340a185f9f81437c72a069abe.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人员选取了来自多个&lt;span&gt;顶尖&lt;/span&gt;机构的八个 AI 模型，包括 Anthropic、DeepSeek 和 OpenAI，利用这些模型为苹果设备生成优化的 GPU 内核。这一过程无需修改用户代码或使用新的框架，直接在苹果硬件上提升模型性能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在实验中，研究团队选择了 Mac Studio （搭载 Apple M4Max 芯片） 进行测试，基准设置为 PyTorch 的 eager 模式。实验采用了 KernelBench 数据集中的 215 个 PyTorch 模块，这些模块被分为三类，涵盖从简单的矩阵乘法到完整的模型架构。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;测试过程包括接收输入和 PyTorch 代码，生成 Metal 内核，并评估其正确性。数据显示，随着尝试次数的增加，AI 生成内核的正确性逐步提升。例如，在第五次尝试时，正确实现的比例达到了 94%。此外，模型们在生成内核时表现出了跨层级的能力，尽管非推理模型有时也能生成有效内核。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;实验结果表明，GPT-5 模型在某些任务上实现了 4.65 倍的速度提升。更令人惊讶的是，o3 模型在某些情况下甚至将延迟降低了 9000 倍。研究还发现，单一模型在某些任务上并不总是表现&lt;span&gt;最好&lt;/span&gt;，多个模型的结合能够生成更优的内核。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;为了进一步提升性能，研究者尝试引入额外上下文信息，如 CUDA 实现和 gputrace 的性能分析数据，结果显示这种方法在性能加速方面达到了平均 1.87 倍，相比于普通智能体的 1.31 倍提升了三倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;需要注意的是，研究人员强调，这一工作并不是为了展示最终的性能极限，而是为了验证 AI 在内核生成中的可行性，希望通过自动化减少开发人员的负担。整体而言，这项研究标志着 AI 技术在硬件优化领域的一个重要进展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370488</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370488</guid>
      <pubDate>Fri, 05 Sep 2025 08:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>WinStore 小白友好的，社区驱动的软件下载利器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1&gt;WinStore 是什么&lt;/h1&gt; 
&lt;p&gt;WinStore 是借助社区共享的力量，打造一个小白友好的，官方的软件和环境下载地址，避免在找软件时，被无良网站诱拐下载，导致电脑被恶意软件和流氓插件占领。 能够在 Windows 下一键安装使用，无需多余配置，无广告，无后门，代码纯开源，半离线模式，仅需在更新软件库时，临时给与联网权限即可。 在计划中的后续版本中，还将集成 Windows 工具箱功能，为小白提供一键的软件卸载，清理，磁盘清理，文件保险箱，免费壁纸等功能。&lt;/p&gt; 
&lt;h1&gt;为什么要使用 Winstore&lt;/h1&gt; 
&lt;p&gt;作为一个 windows 系统的习惯用户，真的对于现在 windows 的软件生态环境感到无比的难受，各种的流氓插件，各种捆绑包，全家桶，数不尽的广告牛皮癣……我们简单下载一个 steam 可能就会遇到无数的套壳，盗版，伪装的软件，更离谱的是，我亲眼看着我朋友下载了一个需要支付 49.9 元才能使用的 steam😂。还经常看到一些文员同事，和其他对于电脑维护不太了解的朋友，电脑桌面上各种的 《是兄弟就来砍我》《正版传奇》《性感发牌在线荷官😂》。导致电脑成了流氓软件的自助餐厅，疯狂恰饭。这些流氓软件不但危害了用户的电脑，还导致正版软件的口碑遭到严重影响。 WinStore 采用全官方下载，不会导致电脑被无良下载站的所谓《高速下载》《下载器下载》诱导。同时社区还会分享众多个人开发者制作的良心软件，一键下载，直达正版，让电脑的软件环境，重回安全，安逸。&lt;/p&gt; 
&lt;h1&gt;Winstore 特点&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;无广告&lt;/li&gt; 
 &lt;li&gt;无后门&lt;/li&gt; 
 &lt;li&gt;官方直达&lt;/li&gt; 
 &lt;li&gt;软件精简（安装包不到 10MB，运行占用不超过 80MB）&lt;/li&gt; 
 &lt;li&gt;社区驱动，资源不断丰富&lt;/li&gt; 
 &lt;li&gt;全免费，无收费项目和套路&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;软件界面&lt;/h1&gt; 
&lt;p&gt;如果大家觉得对你产生了帮助，请移步仓库给项目点一个 star，你的支持就是开发者最大的动力。&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;a href="https://gitee.com/MR-wind/win-store/releases/download/1.0.0/WinStoreSetup.exe"&gt;https://gitee.com/MR-wind/win-store/releases/download/1.0.0/WinStoreSetup.exe&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;仓库地址：&lt;a href="https://gitee.com/MR-wind/win-store"&gt;https://gitee.com/MR-wind/win-store&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370607</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370607</guid>
      <pubDate>Fri, 05 Sep 2025 05:30:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Firefox 将在 2026 年终止对 32 位 Linux 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Mozilla &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Ffuturereleases%2F2025%2F09%2F05%2Ffirefox-32-bit-linux-support-to-end-in-2026%2F" target="_blank"&gt;宣布&lt;/a&gt; Firefox 144 版本（预计发布于 2025 年）是最后一个仍支持 32 位 Linux 的版本。自 Firefox 145 开始，将不再提供对 32 位 Linux 的支持。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/105312_Tahd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mozilla 在公告提到，近年来大多数 Linux 发行版已普遍放弃对 32 位 Linux 的支持，导致维护这一平台变得「越来越困难且不可靠」。为了专注于为用户提供更现代、更稳定的 Firefox，Mozilla 决定撤回对 32 位 Linux 的支持。&lt;/p&gt; 
&lt;p&gt;如果你正在使用 32 位 Linux 系统上的 Firefox，Mozilla 强烈建议切换到 64 位操作系统，并安装支持持续更新的 Firefox 64 位版本。&lt;/p&gt; 
&lt;p&gt;对于暂时无法升级的用户，Mozilla 提供了过渡方案——Firefox ESR 140 的 32 位构建仍将继续提供安全更新，直到 2026 年 9 月。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370864/firefox-32-bit-linux-support-to-end-in-2026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370864/firefox-32-bit-linux-support-to-end-in-2026</guid>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
