<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 02 Apr 2025 07:37:05 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>苹果六面屏全玻璃设计 iPhone 专利曝光</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;科技媒体 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2025%2F04%2Fapple-won-a-patent-for-all-glass-device-embodiments-for-apple-watch-mac-an-iphone-that-allows-imagery-on-both-front-and-ba.html&quot; target=&quot;_blank&quot;&gt;Patently Apple&lt;/a&gt; 发文称，苹果公司最近新获得了一项适用于 Apple Watch、Mac 和 iPhone 的全玻璃设备专利，正面和背面均可作为显示屏。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;苹果在玻璃设备领域的布局可以追溯到 2014 年，此次获得的专利具有里程碑意义，首次系统地定义了多面玻璃外壳的技术方案。其他专利可以查看：&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2023%2F03%2Fapple-wins-a-patent-for-fused-glass-device-housings-for-ipad-an-apple-tv-imac-and-more.html&quot; target=&quot;_blank&quot;&gt;01&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;、&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2Fpatently-apple%2F2020%2F09%2Fapple-won-two-macbook-patents-emphasizing-the-expanded-use-of-a-glass-body-keyboard-areas.html&quot; target=&quot;_blank&quot;&gt;02&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;、&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2025%2F03%2Fapple-files-for-additional-protections-to-their-inventive-all-glass-imac-patent.html&quot; target=&quot;_blank&quot;&gt;03&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;、&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2025%2F03%2Fapple-has-invented-a-new-apple-watch-design-with-a-glass-shell-that-provides-side-touch-controls-with-various-control-interf.html&quot; target=&quot;_blank&quot;&gt;04&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;(用于 Apple Watch)。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;最新专利附图如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;图 26A-26C 展示了一种六面透明棱镜外壳，每一面都可以独立显示内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;355&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eeee8a0fbe11838830bc1709d0ca95e2057.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;图&amp;nbsp;53C-B 展示了当手机翻转时，用户界面根据确定的方向（相对于用户或绝对方向）重新定位后的 iPhone。51A-51B 描绘了 iPhone 的另一个示例，其中正面显示屏上的图像扩展到了玻璃 iPhone 的背面。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;389&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d4a79e481179558d03b335c501ed6f62198.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;图 4E 是 Mac Pro Tower 概念的透视图，其外壳呈八棱柱形状。外壳可以由玻璃制成，并且可以沿所有或基本上所有表面透明。图 57 则展示了未来可能出现的 Apple Watch，其中包括完全或基本完全由玻璃形成的外壳。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;378&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bd9c6d6d406781d60a5e5649ff261ae0a18.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;苹果方面指出，在某些情况下，iPhone 的侧面将能够根据基于力量的输入而变形和/或偏转。例如，用户可以通过挤压外壳和/或按压侧面来降低或提高音乐或内容的音量。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342450/apple-patent-for-all-glass-device</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342450/apple-patent-for-all-glass-device</guid>
            <pubDate>Wed, 02 Apr 2025 07:34:01 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>软件工程的 13 条法则</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;strong&gt;1、帕金森定律&lt;/strong&gt;：工作会膨胀以填满可用的时间。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6e9c01e7725c6b53b7800033fffdaf1f3f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、霍夫斯塔特定律&lt;/strong&gt;：事情总是比你预期的要长，即使你已经考虑了霍夫斯塔特定律。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-da20eb6f35d695eb16fe4ab9caf02c0853f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、布鲁克斯定律&lt;/strong&gt;：向一个已经延期的软件项目增加人力只会让它更加延期。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a79493a976c16e52b6258ff68e4a4e02d15.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、康威定律（及逆康威定律）&lt;/strong&gt;：组织做的设计往往是其内部沟通结构的复制品。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5adf2d562a47cf3c6774f10f54aa750762f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5、坎宁安定律&lt;/strong&gt;：在互联网上获得正确答案的最佳方式不是提问，而是发布一个错误答案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-efe2126647446248be7d4dabb9ac5d836d4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、斯特金定律&lt;/strong&gt;：90% 的东西都是垃圾。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e6656de38fcc5ded0050bdf5338d5cc75db.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7、扎温斯基定律&lt;/strong&gt;：每个程序都试图扩展，直到能够读取邮件。那些无法如此扩展的程序会被能够做到的程序所取代。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f46d91cd7b15ab18aa92eaa1a48735af5a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;8、海勒姆定律&lt;/strong&gt;：当 API 的用户数量足够多时，你在合约中承诺什么并不重要：系统的所有可观察行为都会被某些人所依赖。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a490e790d81821fcbd5d0d918259ed53a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;9、普赖斯定律&lt;/strong&gt;：在任何群体中，50% 的工作是由其总人数的平方根数的人完成的。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1bf79eb2323574b5fde92c83b8359da2890.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;10、林格尔曼效应&lt;/strong&gt;：群体中个体成员的生产力随着群体规模的增大而逐渐降低的趋势。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a7f61f02eacee4f997dc6f1bc203adbda8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;11、古德哈特定律&lt;/strong&gt;：当一项指标成为目标时，它就不再是一个好的指标。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-072a453ebe8a6968cb3d158389ec9b00ceb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;12、吉尔布定律&lt;/strong&gt;：任何你需要量化的东西，都可以通过某种方式进行测量，这总比完全不测量要好。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5bce1dfd39463accf41c3d4b96efc2c72e5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;13、墨菲定律&lt;/strong&gt;：可能出错的事就一定会出错。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-717d819db99a5b3d2d98fd38a349c465f44.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsletter.manager.dev%2Fp%2Fthe-13-software-engineering-laws&quot; target=&quot;_blank&quot;&gt;https://newsletter.manager.dev/p/the-13-software-engineering-laws&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342448/the-13-software-engineering-laws</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342448/the-13-software-engineering-laws</guid>
            <pubDate>Wed, 02 Apr 2025 07:23:01 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek-V3 技术解析」：无辅助损失函数的负载均衡</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 在混合专家模型（MoE）的实践中，负载不均衡俨然已成为制约模型性能提升的关键瓶颈之一。传统的均衡策略往往需要引入复杂的辅助损失函数，不仅增加了训练的复杂度，还可能干扰模型的核心学习目标。工程师们在提升模型效率的道路上，一直苦苦追寻着一个优雅而高效的平衡解决方案。&lt;/p&gt; 
 &lt;p&gt;DeepSeek 团队的这项研究，为这一长期困扰业界的技术难题提供了令人耳目一新的解决思路：通过在门控分数中直接添加专家层面的偏置项，在绝大部分不引入额外损失函数的情况下，实现了模型训练过程中的自适应负载均衡。更令人惊叹的是，这一方法不仅保持了模型的因果关系，还显著提升了训练的稳定性和最终性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shirley Li&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这是 DeepSeek-V3 系列文章的第三篇，我们将探讨 DeepSeek 模型[1, 2, 3]中与混合专家模型（MoE）相关的另一项关键架构突破：无辅助损失函数的负载均衡（Auxiliary-Loss-Free Load Balancing）[5]。&lt;/p&gt; 
&lt;p&gt;在本文，我们将深入解析 DeepSeek 如何解决 MoE 的隐藏瓶颈------负载均衡，同时还通过消除梯度干扰和严格遵循因果关系约束，提升了训练和推理效率，为后续专家模型的优化方向提供了标杆。&lt;/p&gt; 
&lt;p&gt;本文目录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技术背景：介绍混合专家模型（MoE）的基本原理，解释负载均衡的重要性，回顾之前的工作，包括辅助损失函数（auxiliary loss）方法和专家选择（Expert Choice）策略。&lt;/li&gt; 
 &lt;li&gt;DeepSeek 的无辅助损失函数的负载均衡：解析其运作原理&lt;/li&gt; 
 &lt;li&gt;性能评估：讨论无辅助损失函数的负载均衡的性能表现&lt;/li&gt; 
 &lt;li&gt;总结&lt;/li&gt; 
 &lt;li&gt;参考文献&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;「DeepSeek-V3 技术解析」系列其他文章：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/IDP/blog/17943880&quot;&gt;「DeepSeek-V3 技术解析」：多头潜在注意力机制（MLA）&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;「DeepSeek-V3 技术解析」：DeepSeekMoE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;01 技术背景&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1.1&lt;/strong&gt; &lt;strong&gt;MoE (Mixture-of-Experts) in Transformers&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MoE（Mixture-of-Experts，混合专家模型）在 Transformer 中的实现方式通常为：每隔若干 Transformer 层，将其中的 FFN（前馈网络）替换为多个 FFN（每个 FFN 充当一个&quot;专家&quot;）。当 input token 进入该层时，通过门控操作（Gating）选择 Top-K 个专家，并将 input token 只路由至这些被选中的 FFN，从而仅激活对应的专家网络。&lt;/p&gt; 
&lt;p&gt;下图展示了这一过程：左侧标准 Transformer 层中的 FFN 子层被替换为右侧的 MoE 层。&lt;/p&gt; 
&lt;p&gt;如需更详细的 MoE 技术解析，可参考&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;「DeepSeek-V3 技术解析」：DeepSeekMoE&lt;/a&gt;（文中通过餐厅类比直观解释了 MoE 原理）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-19ae4d0c8392f0c6fb1b110f9ebae146cb4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 1. Transformer 中的 MoE 层（红框内）示意图。图片改编自文献 [6]。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 负载均衡及其重要性&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;本系列上一篇文章&lt;/a&gt;进行的餐厅类比中，我们通过一个能够提供多种菜系菜品的餐厅解释了 MoE 的概念：餐厅的每位厨师都是专家，主厨（Head Chef）的工作类似于门控操作，将每道菜品分配给具备对应技能的特定厨师。&lt;/p&gt; 
&lt;p&gt;为确保该系统高效运作，需满足以下条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;每位专业厨师必须精通自身菜系所需技能（例如饺子厨师必须会包饺子），同时所有厨师需能共同处理所有菜品。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;主厨需充分了解所有专业厨师的专长，并能高效分配订单。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MoE 中，前者对应 expert specialization 与 knowledge sharing 的权衡（我们已在&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;介绍 DeepSeekMoE 的这篇文章中&lt;/a&gt;进行了详细讨论），后者则体现了负载均衡的重要性 ------ 这也是本文的核心主题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;为何负载均衡如此重要？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原因在于，当负载不均衡发生时，MoE 无法有效运作。&lt;/strong&gt; 最常见的问题是路由崩溃（Route Collapse）：少数专家接收大部分 input token，而其他专家的利用率极低。&lt;/p&gt; 
&lt;p&gt;因此，大部分计算由超负荷工作的专家承担，而这些专家通常分布在多个 GPU 核心上，因此会导致硬件资源浪费。&lt;/p&gt; 
&lt;p&gt;由于梯度冲突（gradient conflict），路由奔溃也会导致训练不稳定。超负荷工作的专家接收更多 input token，他们积累的梯度也会更大，学习速度也会比工作负荷不足的专家快得多；因此，两者的梯度在幅值和方向上均可能发生偏离，导致训练难以收敛。&lt;/p&gt; 
&lt;p&gt;最后，MoE 中的负载不均衡也会导致性能低下和泛化效果不佳，因为工作负荷不足的专家会因为训练 tokens 不足，而难以学习有效知识。&lt;/p&gt; 
&lt;p&gt;由于负载均衡技术对 MoE 至关重要，因此研究者们针对这一问题提出了多种解决方案。其中，最常用的策略是为负载均衡添加辅助损失函数（Auxiliary Loss）和专家选择（Expert Choice）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 带辅助损失函数的负载均衡&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一种常见的改善负载均衡的策略是在模型训练的目标函数基础上引入辅助损失函数。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5e9dccf967a447833e952d9a7a9ddee3d5f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 2. 用于强化负载均衡的辅助损失函数示例。图片编辑自文献[5]。&lt;/p&gt; 
&lt;p&gt;上图展示了一个辅助损失函数的示例，其中&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;N 是专家数量，T 是 token 数量，K 是每个 input token 激活的专家数量。&lt;/li&gt; 
 &lt;li&gt;s_{i, t} 是门控机制的输出，通过 Softmax 归一化到 [0, 1] 区间，表示第 t 个 token 选择第 i 个专家的概率。向量 u_t 是第 t 个 token 的输入隐藏状态，而 e_i 是第 i 个专家的&quot;质心&quot;，可以看作历史上路由到第 i 个专家的 token 嵌入平均值。因此，s_{i, t} 度量的是当前输入与第 i 位专家历史接收 token 的平均值的接近程度。&lt;/li&gt; 
 &lt;li&gt;因此，P_i 可视为整个输入序列选择第 i 个专家的平均概率。&lt;/li&gt; 
 &lt;li&gt;f_i 表示被路由到第 i 个专家的 token 比例。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;需要注意的是，f_i 是不可微分的，因此最小化上述损失函数实际上转化为了最小化 s_{i, t}。同时由于 f_i 依赖于 s_{i, t}，对 s_{i, t} 的调整也会影响 f_i，从而实现对各专家负载分配的调节。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然而，用这种辅助损失函数来均衡负载需要付出一定代价，因为其梯度可能会干扰语言建模目标（language modeling objective）的梯度，导致模型性能下降，在极端不平衡情况下（工作负荷过大的专家的 f_i 和 P_i 都变得极大时）尤其明显。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因此，采用这种方法进行负载均衡需要谨慎设置辅助损失函数的权重。为更清晰地说明这一点，文献[5]的作者进行了一个实验，用不同 alpha 值训练模型，结果如下图所示，其中纵轴表示困惑度指标下的模型性能，横轴表示 MaxVio（衡量负载不平衡程度的指标，MaxVio 值越高表示负载越不平衡，i 表示第 i 个专家）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-270603a291bd57664c068ed046f529e917f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 3. 辅助损失函数控制训练中负载均衡与模型性能的权衡困境。图片引自文献[5]。&lt;/p&gt; 
&lt;p&gt;如图所示，当 alpha 过小时（alpha=0），MaxVio 保持高位，说明辅助损失函数未能有效实现负载均衡目标。另一方面，当 alpha 过大时（alpha=0.01），模型最终会产生更高的困惑度。&lt;/p&gt; 
&lt;p&gt;综上，辅助损失函数控制的负载均衡是把双刃剑：若 alpha 未经仔细调校，可能损害模型性能。实际 LLM 训练中，由于资源限制，alpha 的调校过程充满挑战，这进一步增加了优化难度。&lt;/p&gt; 
&lt;p&gt;上图同时展示了本文提出的无损失函数方法在相同 Perplexity-MaxVio 座标系下的表现，该方法同时实现了低困惑度和低 MaxVio，证明了无损失函数方法的有效性。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 专家选择（Expert Choice）策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在此需提及的另一项前期工作是 Expert Choice [7]，它提出了一种简单高效的负载均衡方法，将路由策略从&quot;token choice&quot;切换为&quot;expert choice&quot;。&lt;/p&gt; 
&lt;p&gt;具体而言，MoE 路由中的门控分数通常通过对 affinity matrix（译者注：二维矩阵，用于量化 input token 与各个专家之间的匹配程度。）应用 Softmax 计算得出，如图 2 所示。传统路由方法从 token 维度应用 Softmax 为每个 token 选择专家，因此这些方法被称为&quot;token choice&quot;。问题在于，该机制下我们无法控制每个专家接收的 token 数量，最终导致负载不均衡问题。&lt;/p&gt; 
&lt;p&gt;而 Expert Choice 方法则从专家维度应用 Softmax，为每个专家选择被路由的 token。通过这种设计，每个专家接收的 token 数量能够天然达到完美均衡，因此无需依赖辅助损失函数实现负载均衡。在文献[7]中，这种方法同时展现出更优的模型性能和更快的训练速度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然而，Expert Choice 这种方法也存在局限 ------ 未来 token 泄露问题。由于每个专家需要先查看所有 token 的路由分数才能决定处理哪些 token，这违反了因果关系（causality），在文本生成、机器翻译等自回归任务中可能引发严重问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeek 的无辅助损失函数的负载均衡&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;为在不引入 gradient inference（译者注：此处或为作者笔误？应当为&quot;gradient interference（梯度干扰）&quot;，多个损失函数（或多个优化目标）的梯度方向发生冲突。） 的情况下解决负载均衡问题，DeepSeek 提出了一种名为&quot; Loss-Free Balancing&quot;的新技术，通过直接调整门控分数 s_{i,t} 实现。&lt;/p&gt; 
&lt;p&gt;如前文所述，当我们最小化图 2 所示的辅助损失函数时，最终会通过调整 s_{i,t} 来实现最小化 P_i。&lt;/p&gt; 
&lt;p&gt;因此，若能直接调整 s_{i,t}，理论上应能达到与施加辅助损失函数相似的效果。&lt;/p&gt; 
&lt;p&gt;为此，我们在每个专家的门控分数上添加了专家层面的偏置项，如下图所示。需注意 b_i 并不用于最终门控分数的计算（后文也将说明该偏置项也是不可微分的），而是用于 TopK 选择专家时：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d4c0f9d7daaae22acf77ebd4afdd50c0c9e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 4. 在门控分数中引入偏置项 b_i。图片引自文献[5]&lt;/p&gt; 
&lt;p&gt;该偏置项 b_i 的计算方式非常直观，如下图所示：首先获取分配给各专家的 token 数量平均值及所有专家的理论全局均值，然后计算给各专家分配的 token 数量与理论全局均值的差值，偏置项由该差值（或误差）的符号乘以固定更新率（fixed update rate）决定（该更新率为可调超参数）。后续章节我们将对该超参数的影响进行更多实验分析。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-648298535bc37e35360bb990b243896d409.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 5. DeepSeek 无损失函数的负载均衡算法。图片引自文献[5]&lt;/p&gt; 
&lt;p&gt;现可通过下表总结不同负载均衡方法的优势与局限：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-625befddfe0736a68e0a4968075dc2d51bf.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 6. 不同负载均衡方法对比。图片引自文献[5]&lt;/p&gt; 
&lt;p&gt;图 3 已展示该方法在模型性能与负载均衡间取得了更好的权衡，但仍有多方面需要验证。下一章节我们将深入分析实验结果。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 Evaluation&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;有三个关键问题需要回答：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek 所提出的方法能否在性能和负载均衡之间实现更好的权衡？&lt;/li&gt; 
 &lt;li&gt;图 5 中更新率 u 有什么影响？&lt;/li&gt; 
 &lt;li&gt;我们能否进一步优化偏置项更新规则（鉴于其如此之简单）？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 性能 vs. 负载均衡&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为回答第一个问题，作者在 1B 和 3B 模型上进行了实验，比较 loss-controlled 负载均衡和 loss-free 负载均衡的困惑度（Perplexity）和 MaxVio，结果如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c2829c426107ea67be1110636b5d167242f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 7. loss-controlled 负载均衡和 loss-free 负载均衡的对比。图片来自文献[5]。&lt;/p&gt; 
&lt;p&gt;上述结果与我们在图 3 中看到的结果类似：所提方法同时实现了更低的困惑度和更低的 MaxVio。&lt;/p&gt; 
&lt;p&gt;除了评估最终的 checkpoint 外，作者还展示了训练过程中的 MaxVio 曲线，以便更全面地理解该方法在整个训练过程中的表现，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-20f534fb208e8a1f89dae2e5032a07ffead.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 8. 训练过程中的 MaxVio 曲线。图片来自文献[5]。&lt;/p&gt; 
&lt;p&gt;如图中所示，在 1B 和 3B 的模型配置下，loss-free 方法在整个训练过程中都展现出更优的负载均衡能力，体现了该方法的稳定性。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 超参数的影响（更新率）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如图 5 所示，所提方法引入了一个新的超参数 u（称为更新率（update rate）），该超参数如何影响 loss-free 方法的有效性？具体而言，我们需要理解 loss-free 方法对超参数 u 的取值是敏感还是不敏感，以及如何选择一个最优值来最大化该方法的效果。&lt;/p&gt; 
&lt;p&gt;如前文所述，在门控分数中添加偏置项的概念类似于绕过损失函数的反向传播，直接对门控分数进行梯度更新。在这种情况下，更新率 u 的作用与梯度更新中的步长（step size）类似。由此可推测其影响也相似：&lt;strong&gt;过小的更新率可能会导致收敛速度缓慢。过大的更新率可能导致不稳定和引发波动。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在原文中，作者对更新率进行了实验测试（取值从 1e-4 到 1e-2），结果如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-239d0c5e83e1699cf19a5179be50163fe48.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 9. 更新率（update rate）对训练负载均衡的影响。图片来自文献[5]。&lt;/p&gt; 
&lt;p&gt;与预期一致，当 u 过小时（如 1e-4），MaxVio 下降速度较慢；而过大的 u（如 1e-2）则因波动性增强，导致训练过程中 MaxVio 持续偏高。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 其他偏置项更新规则&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为回答第三个问题，研究者尝试了多种备选策略，并将它们与 DeepSeek 提出的版本进行对比：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;策略变体 1&lt;/strong&gt;：使用 e_i 的数值（而不仅仅是符号）计算偏置项，即从 b_i = b_i +u∗sign(e_i) 改为 b_i = b_i +u∗e_i。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;策略变体 2&lt;/strong&gt;：使用乘法偏置项而非加法偏置项。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其中策略变体 2 可以更正式地描述如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-856884cefb7dacdd99e05414c42d5b08cbb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;实验表明，策略变体 1 能带来略优的负载均衡效果，但未提升模型性能：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-842152dbdd0880f205ec969a7535dc64e13.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 10. 策略变体 1 的性能表现。图片来自文献[5]。&lt;/p&gt; 
&lt;p&gt;而策略变体 2 甚至显示出略差的模型性能：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71a03da108b196cc374602ba52875add0a5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 11. 策略变体 2 的性能表现。图片来自文献[5]。&lt;/p&gt; 
&lt;p&gt;以上所有结果均表明，最简单的策略反而是最佳选择。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Summary&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在本文中，我们解释了 DeepSeek 模型的核心架构创新之一 ------ DeepSeekMoE 中使用的无辅助损失函数的负载均衡方法。&lt;/p&gt; 
&lt;p&gt;本文首先介绍了混合专家模型（MoE）的基本原理，强调了负载均衡的重要性，并回顾了先前的解决方案（包括 auxiliary loss 方法和 Expert Choice 机制）。接着，本文阐释了 DeepSeek 的无损失函数的负载均衡方法及其性能表现。&lt;/p&gt; 
&lt;p&gt;DeepSeek 的无损失函数方法在保持因果关系的同时避免了引入梯度干扰，其有效性已通过原论文的实证结果得到验证。&lt;/p&gt; 
&lt;p&gt;感谢您花时间阅读本文！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] DeepSeek（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepseek.com%2F%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://www.deepseek.com/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] DeepSeek-V3 Technical Report（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FDeepSeek-V3%2Fblob%2Fmain%2FDeepSeek_V3.pdf%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2401.06066）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2408.15664%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2408.15664）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2006.16668%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2006.16668）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Mixture-of-Experts with Expert Choice Routing（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2202.09368%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2202.09368）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Shirley Li&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I am a Machine Learning Engineer working on building multi-modality models to solve real-world problems.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;在实际工程中，您认为负载均衡对模型性能的影响有多大？除了本文提到的技术路径，您还了解哪些有效的负载均衡方案？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.gopubby.com%2Fdeepseek-v3-explained-3-auxiliary-loss-free-load-balancing-4beeb734ab1f&quot; target=&quot;_blank&quot;&gt;https://ai.gopubby.com/deepseek-v3-explained-3-auxiliary-loss-free-load-balancing-4beeb734ab1f&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/18057719</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18057719</guid>
            <pubDate>Wed, 02 Apr 2025 07:03:01 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Sam Altman：OpenAI 新产品将因产能问题延迟推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 首席执行官 Sam Altman 在 X 发帖透露示，该公司新产品将因产能不足的问题延迟推出。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我们正在控制局面，但你应该预料到 OpenAI 的新版本可能会被推迟，可能会出现问题，而且由于我们面临容量挑战，服务有时会很慢。我们正在提升效率，以确保各项工作顺利进行。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;171&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5b77f2974426a3588db4062d73b328abd76.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，OpenAI 的新图像生成功能因能重现吉卜力工作室手绘动画等风格的表现而备受关注， 同时也引发了一些争议。上周末，Altman 在 X 的帖子中表示 ，自推出以来，该公司「一直未能跟上进度」，员工们加班加点，甚至周末加班，以「保持服务正常运行」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Altman 声称，周一仅一个小时，ChatGPT 就增加了 100 万名新用户。ChatGPT 目前拥有 5 亿周活跃用户和 2000 万付费用户，其 2024 年底的用户数量和付费用户数量分别为 3 亿和 1550 万。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此为了缓解容量问题，OpenAI 推迟了面向 ChatGPT 免费用户的图像生成工具的发布时间，并暂时禁用了面向 Sora 新用户的视频生成功能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342431/sam-altman-openais-capacity-issues-product-delays</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342431/sam-altman-openais-capacity-issues-product-delays</guid>
            <pubDate>Sun, 23 Mar 2025 06:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微信公布视频号算法推荐原理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;「微信珊瑚安全」发文公布了视频号算法推荐原理，&lt;strong&gt;称视频号主要依靠社交好友关系来进行推荐&lt;/strong&gt;，若推荐的视频不符合预期，可关闭个性化推荐功能。&lt;/p&gt; 
&lt;p&gt;官方称，视频号平台将持续优化算法信息公示方式，用通俗化的语言来解释算法的基本原理、运行机制等情况，方便用户查询和理解。&lt;/p&gt; 
&lt;p&gt;据官方公布的信息，微信视频号主要依靠社交好友关系来进行推荐，在功能层面，视频号平台设计了「朋友❤️」的选项标签，并以显著提示的方式展现给用户，让用户第一时间了解到好友推荐了什么内容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对于较多朋友推荐的内容，视频号平台会提升曝光排序&lt;/strong&gt;，并增加了「朋友今天都在看」和多位好友推荐的提醒，用户可以更快、更直接地看到相关视频，从而扩展自己的信息获取半径。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0402/141552_HHSN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方称，通过这一推荐机制，用户能直观看到多位朋友推荐的内容，无需将时间过多消耗在刷视频中。&lt;/p&gt; 
&lt;p&gt;一图读懂视频号算法推荐：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;3965&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0d7ada75a7f7e7e5cf72facf18d42527d08.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;原文：&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWADcBzT4n9dSPXbxsOcKuQ&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/WADcBzT4n9dSPXbxsOcKuQ&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342428</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342428</guid>
            <pubDate>Sun, 23 Mar 2025 06:16:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>CNCF 发布 2025 年 Dapr 状态报告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025 年 Dapr 状态报告现已&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fannouncements%2F2025%2F04%2F01%2Fcloud-native-computing-foundation-releases-2025-state-of-dapr-report-highlighting-adoption-trends-and-ai-innovations%2F&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;，提供了有关项目加速采用、开发者生产力影响和在 AI 驱动应用中扩展角色的新见解。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告指出，接近一半的受访者表示正在生产环境中运行 Dapr 应用，这一比例较往年显著增加。随着组织寻求可扩展的云原生架构，Dapr 在提高开发者生产力和 AI 应用中的作用驱动了广泛采用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;360&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-def120cb3998f0c9eacfa97e880529e27ae.webp&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一些亮点内容包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前有超过 40,000 家企业利用 Dapr 实现微服务、工作流和云可移植性&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;72% 的受访者现在将 Dapr 用于关键任务应用程序&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;96% 的受访者表示节省了时间，60% 称可节省 30% 或更多的开发时间&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;84% 的受访者预计他们的 Dapr 使用量将在未来一年内增长。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Dapr（分布式应用运行时）是一个便携的运行时，使任何开发者都能轻松构建在云和边缘运行的韧性分布式应用。它提供了用于通信、状态和工作流的集成 API，帮助构建适合生产的应用。该项目于 2019 年首次推出，在 2021 年获 CNCF 接受，并在 2024 年达到毕业状态。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342424/2025-state-of-dapr-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342424/2025-state-of-dapr-report</guid>
            <pubDate>Sun, 23 Mar 2025 06:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>赚麻了！​ChatGPT 付费用户激增至 2000 万​，年化营收增长 30%</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;OpenAI 的 ChatGPT 正在经历一个快速增长的阶段。根据 The Information&lt;span&gt;最新&lt;/span&gt;报道，ChatGPT 的付费用户数量在短短三个月内突破了 2000 万，较去年年底的 1550 万增加了近 30%。这一增长表明，越来越多的用户愿意为这个能够撰写代码、文章、提供健康建议和理财规划的人工智能付费。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;根据估算，ChatGPT 目前每月的营收达到至少 4.15 亿美元，年化营收可达 50 亿美元，较去年年底的月收入 3.33 亿美元、年化 40 亿美元增长了近 30%。&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;244&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b476aa45e8eb822c5db023631270331c01.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;除了基础的 20 美元 / 月的 ChatGPT Plus 订阅外，OpenAI 还提供高达 200 美元 / 月的企业级 Pro 套餐，进一步推动了收入的增长。此外，OpenAI 的营收还来自于大量开发者和平台通过 API 调用其模型的费用，预计 API 业务在 2023 年将为公司带来约 20 亿美元的收入。若这一增长趋势持续，OpenAI 在 2025 年可能实现高达 127 亿美元的营收，远超 2024 年的 40 亿美元。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;尽管用户数量快速增加，但付费用户的比例却有所下降。从三个月前的 5% 降至当前的 4%。目前，OpenAI 每周活跃用户已达到 5 亿，较去年年底的 3.5 亿增长了 43%。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;OpenAI 表示，为了维持这部分用户并支持不断增加的免费用户，公司需要大量资金。为此，OpenAI 计划以 2600 亿美元的估值融资 400 亿美元。尽管目前公司仍处于亏损状态，OpenAI 预计距离盈利还有至少五年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342406</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342406</guid>
            <pubDate>Sun, 23 Mar 2025 03:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国首款全自研高性能 RISC-V 服务器芯片发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;睿思芯科近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJgBOwvgYbIou4mv5ruwpHA&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;推出新一代高性能&lt;strong&gt;灵羽处理器&lt;/strong&gt;，这是中国首款全自研高性能 RISC-V 服务器芯片，在算力、能效和接口配置等方面均达到国际主流水平，满足高性能计算、全闪存储与 DeepSeek 等开源大语言模型的应用场景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/112935_NMk2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;睿思芯科创始人、董事会主席及 CEO 谭章熹博士介绍了灵羽处理器性能及架构层面的关键突破，称其在单核性能和多核并行性能上均实现大幅提升，较现有主流服务器处理器具备显著优势。&lt;/p&gt; 
&lt;p&gt;灵羽处理器基于睿思芯科全自研的 CPU 核心 IP 与片上网络 IP，实现了先进乱序执行、高速数据通路与 Mesh 互联结构，同时通过软硬件结合的设计 - 工艺协同优化，在产品工程、EDA 工具链、物理设计与晶圆制造流程中实现创新，显著提升运算中的能效比以及优化总体拥有成本（TCO）。&lt;/p&gt; 
&lt;p&gt;据介绍，灵羽处理器支持 DDR5 高速内存，支持 PCIe 5.0 标准及 CXL 2.0 协议，并支持高达 8 路互联。同时，灵羽处理器具备企业级 RAS 特性，满足 RISC-V 服务器标准。&lt;/p&gt; 
&lt;p&gt;睿思芯科官网&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frivai-ic.com.cn%2Fabout%23introduce&quot;&gt;显示&lt;/a&gt;&lt;/u&gt;，睿思芯科成立于 2018 年底，是一家提供 RISC-V 高端核心处理器解决方案的公司，创始团队来自于加州大学伯克利分校 RISC-V 原创项目组。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342405</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342405</guid>
            <pubDate>Sun, 23 Mar 2025 03:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源 Java 工具 - Hutool 至大家的一封信</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;各位朋友及广大&lt;/span&gt;Hutool&lt;span&gt;的用户：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 近期大家可能注意到，&lt;/span&gt;Hutool&lt;span&gt;的项目在&lt;/span&gt;Gitee&lt;span&gt;等平台做了迁移，项目的地址从&lt;/span&gt;Dromara&lt;span&gt;组织迁移到了&lt;/span&gt;Bugotech&lt;span&gt;，这一操作短暂引起了一些热议，因此特意在此给大家做了个解释，同时也说明下&lt;/span&gt;Hutool&lt;span&gt;在未来的发展规划。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Hutool&lt;span&gt;于&lt;/span&gt;2013&lt;span&gt;年第一次开源，&lt;/span&gt;2014&lt;span&gt;年&lt;/span&gt;5&lt;span&gt;月&lt;/span&gt;28&lt;span&gt;日发布了第一个版本，至今已经持续维护了&lt;/span&gt;12&lt;span&gt;个年头，共计发布&lt;/span&gt;301&lt;span&gt;个版本，从一个小小的工具方法集合，发展为覆盖&lt;/span&gt;Java&lt;span&gt;大量常用&lt;/span&gt;API&lt;span&gt;封装的庞大工具集。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 随着用户不断积累增多，&lt;/span&gt;Hutool&lt;span&gt;也陆续建立了&lt;/span&gt;7&lt;span&gt;个&lt;/span&gt;2000&lt;span&gt;人大群，&lt;/span&gt;2&lt;span&gt;个微信群，这些群我们通过「严格」的管理，让广大用户精准快速的解决了问题，同时通过城市标注，也促成了找工作、交朋友的好氛围。在&lt;/span&gt;Github&lt;span&gt;和&lt;/span&gt;Gitee&lt;span&gt;平台，&lt;/span&gt;Hutool&lt;span&gt;处理接近&lt;/span&gt;7000&lt;span&gt;个&lt;/span&gt;issue&lt;span&gt;和&lt;/span&gt;2000&lt;span&gt;余&lt;/span&gt;PR&lt;span&gt;，我们也是采用快速解决的方式，第一时间解决用户的问题和需求。好的技术氛围以及快速响应，我想这也是&lt;/span&gt;Hutool&lt;span&gt;广受欢迎的原因。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 不过随着项目扩大，面临的很多问题也暴露出来了。首先是&lt;/span&gt;QQ&lt;span&gt;群的管理，在&lt;/span&gt;2024&lt;span&gt;年，&lt;/span&gt;Hutool4&lt;span&gt;群突然被封，经过了解后才知道是我们没有及时看群聊记录，有用户在群里吵架举报被封。这也暴露出我们创建的这些「乌托邦」并非完美，而后我们不得不随时关注群里动态，极大的分散了精力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 第二个问题来自于企业用户的认可程度，作为一个自发团队维护的开源项目，很多用户反馈在其所在企业禁止使用，换位思考一下，我们也非常理解企业的担忧，毕竟。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 第三个问题是如何良性发展。我们既希望&lt;/span&gt;Hutool&lt;span&gt;工具一如既往的为大家提供纯粹的帮助，也希望围绕广大的用户做一些新的尝试。比如前期我们卖&lt;/span&gt;T&lt;span&gt;恤、鼠标垫，算是失败了，用户说你还不如卖牛肉干，哈哈。后来我们的团队成员还尝试做了脚手架、导航页等功能，不过由于精力问题，也草草收场。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基于以上原因，我们决定采用公司化的方式来继续维护&lt;/span&gt;Hutool&lt;span&gt;，那之后有什么变化呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 所有代码层面的维护、更新均无变化，我们依旧保持高效的更新。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 主页上，只是去掉了一些团队信息，变更一下备案（从个人备案变更为企业备案），后续可能改版丰富内容。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文档方面，依旧免费开放，保证永不闭源。后期的主要变化就是穿插一些商业产品的介绍（我想大家不会介意），后续版本的文档我们会加快丰富和补充。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; QQ&lt;span&gt;和微信群方面，有专属「&lt;strong&gt;客服&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;MM&lt;/strong&gt;&lt;span&gt;」管理解答大家的问题，平时也会发布一些行业新闻什么的，陪大家闲聊。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 那&lt;/span&gt;Hutool&lt;span&gt;接下来的规划是什么呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 1&lt;span&gt;、&lt;/span&gt;Hutool-5.x&lt;span&gt;依旧以&lt;/span&gt;bug&lt;span&gt;修复为主，不再添加新特性，重要的说三遍，稳定稳定稳定！（像极了&lt;/span&gt;JDK8&lt;span&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 2&lt;span&gt;、&lt;/span&gt;Hutool-6.x&lt;span&gt;因为一直处于&lt;/span&gt;milestone&lt;span&gt;版本（测试版本），供大家尝鲜新的&lt;/span&gt;API&lt;span&gt;，并发现问题，因此一直未正式&lt;/span&gt;release&lt;span&gt;。而在开发当中，由于还是基于&lt;/span&gt;JDK8&lt;span&gt;编译，导致&lt;/span&gt;JDK11+&lt;span&gt;（尤其&lt;/span&gt;JDK17&lt;span&gt;）很多功能特性无法兼容，比如&lt;/span&gt;Jakarta&lt;span&gt;很多包变更后根本不支持&lt;/span&gt;JDK8&lt;span&gt;，&lt;/span&gt;Spring&lt;span&gt;也无法做到同时兼容，因此很有可能在更新几个&lt;/span&gt;Milestone&lt;span&gt;后停止更新。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 3&lt;span&gt;、&lt;/span&gt;Hutool-7.x&lt;span&gt;，是滴，它要来了，终于下定决心从&lt;/span&gt;JDK17&lt;span&gt;开始支持，这样就可以轻装上阵，抛掉很多兼容性代码（比如在&lt;/span&gt;6.x&lt;span&gt;中为支持新特性，不得不用反射方式调用），接下来，就是老项目继续使用&lt;/span&gt;Hutool-5.x&lt;span&gt;，新项目使用&lt;/span&gt;7.x&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 我们说，&lt;/span&gt;Hutool&lt;span&gt;的意义远不是代码本身，而是一种思维方式，一种交流方式。我们通过开源中的代码聚到一起，碰撞思维的火花，寻找志同道合的朋友，找到一起成功的伙伴，也找到自我价值的体现。我相信，因为&lt;/span&gt;Hutool&lt;span&gt;的存在，未来会有无限可能！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Hutool&lt;span&gt;团队敬上&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;2025&lt;span&gt;年&lt;/span&gt;4&lt;span&gt;月&lt;/span&gt;2&lt;span&gt;日&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342402</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342402</guid>
            <pubDate>Sun, 23 Mar 2025 03:29:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>微软重新设计 BSOD：Windows 11 将用「黑屏死机」取代「蓝屏死机」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微软宣布，它将重新设计 Windows 11 的蓝屏死机（BSOD）错误信息。新的设计摒弃了传统的蓝色背景、悲伤表情和二维码，转而采用了一个更简化的屏幕，其外观与 Windows 进行更新时看到的黑色屏幕非常相似。&lt;/p&gt; 
&lt;p&gt;目前尚不清楚微软发布最终版本更新时，这个新的 BSOD 是否会保持为黑色屏幕。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5d78b86ec91a0dda404f20261de42df560.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微软在一篇关于这一变化的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F03%2F28%2Fannouncing-windows-11-insider-preview-build-26120-3653-beta-channel%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt; 中解释道，「我们正在预览一个新的、更精简的用户界面，用于处理意外重启，这更好地符合 Windows 11 的设计原则，并支持我们尽快让用户恢复生产力的目标，我们简化了您的体验，同时保留了屏幕上的技术信息。」&lt;/p&gt; 
&lt;p&gt;Windows 内部测试者可以在 Beta、Dev 和 Canary 通道的测试版本中尝试新的蓝屏死机 (BSOD)，但在最终作为黑色或蓝色屏幕发布之前，这些测试版本中它会以绿色屏幕的形式出现。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b72bb5e17541e78eef82f333a668ab28952.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这是自微软在 Windows 8 中在屏幕上添加悲伤表情符号以来，BSOD 的第一次重大变化。这个新设计包括了 BSOD 错误或故障驱动程序，并简单地声明「您的设备遇到了问题，需要重新启动」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;up-51d3ac36bc416abe53fe1c0517c774a1824.png&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-51d3ac36bc416abe53fe1c0517c774a1824.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微软曾在 2021 年将 Windows 11 的测试版本中的 BSOD 转换为黑色屏幕，但公司随后又恢复了自 Windows 8 以来一直在使用的蓝色屏幕。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342400/windows-bsod-black-new-design</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342400/windows-bsod-black-new-design</guid>
            <pubDate>Sun, 23 Mar 2025 03:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Dolphin 开源：支持东方 40 语种+中国 22 方言的 SOTA 语音大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;海天瑞声&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fw4wY8ZgJsJRMpcHSl7M6wQ&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;携手清华大学电子工程系语音与音频技术实验室，共同推出了 Dolphin —— 一款专为东方语言设计的语音大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，Dolphin 的训练数据集整合了海天瑞声的专有数据和多个开源数据集，总时长超过 20 万小时，涵盖 40 个东方语种。其中，海天瑞声数据集包含 137,712 小时的音频，覆盖 38 个东方语种。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;核心亮点&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;支持东方 40 个语种的语音识别，中文语种支持 22 方言（含普通话）；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;训练数据总时长 21.2 万小时：其中海天瑞声高质量专有数据 13.8 万小时，开源数据 7.4 万小时；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 3 个测试集（海天瑞声、Fleurs、CommonVoice）下，与 Whisper 同等尺寸模型相比：&lt;/span&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;base 版本平均 WER 降低 63.1%；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;small 版本平均 WER 降低 68.2%；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;medium 版本平均 WER 降低 67.7%；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;large 版本平均 WER 降低 60.6%&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;base 与 small 版本模型与推理代码全面开源；Dolphin 开源的 small 版本与 Whisper large v3 相比，平均 WER 降低 54.1%。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;模型结构&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Dolphin 网络结构基于 CTC-Attention 架构，E-Branchformer 编码器和 Transformer 解码器，并引入了 4 倍下采样层，以实现高效的大规模多语言语音识别模型的训练。CTC-Attention 架构结合了 CTC 的序列建模能力和注意力机制的上下文捕捉能力，能够有效提升模型的识别准确性和效率。E-Branchformer 编码器采用并行分支结构，能够更有效地捕捉输入语音信号的局部和全局依赖关系，为模型提供了更丰富的特征表示。解码器部分则采用了在序列到序列任务中表现出色的 Transformer，能够生成高质量的文本输出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了进一步提高训练效率和性能，项目团队在模型中引入了 4 倍下采样层。这一层可以减少输入特征的序列长度，从而加速计算过程，同时保留关键的语音信息，确保模型的识别效果不受影响。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;310&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b9c613bad8be71cfd5a56a8e1a86fdb9e43.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;多任务格式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Dolphin 借鉴了 Whisper 和 OWSM 的创新设计方法，但专注于 ASR 进行了若干关键修改。Dolphin 不支持翻译任务，并且去掉了 previous text 及其相关标记的使用，这简化了输入格式并减少了潜在的复杂性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Dolphin 引入了两级语种标签系统，以便更好地处理语言和地区的多样性。第一个标签指定语种（例如&amp;lt;zh&amp;gt;、&amp;lt;ja&amp;gt;），第二个标签指定地区（例如&amp;lt;CN&amp;gt;、&amp;lt;JP&amp;gt;）。这种分层方法使模型能够捕捉同一种语言内不同方言和口音之间的差异，以及同一地区内不同语言之间的相似性，从而提高了模型区分密切相关的方言的能力，并通过在语言和地区之间建立联系增强了其泛化能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;155&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f0a949e5180d3d4ddd5c382835e9e43dc3.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;测试结果表明，Dolphin 在多种语言上的词错误率（WER）显著低于现有开源模型。例如，在海天瑞声数据集上，Dolphin base 模型的平均 WER 为 31.5%，small 模型为 24.5%，medium 模型为 22.2%；在 CommonVoice 数据集上，Dolphin base 模型的平均 WER 为 37.2%，small 模型为 27.4%，medium 模型为 25.0%。即使与 Whisper large-v3 模型相比，Dolphin 在模型规模更小的情况下，性能也更为出色。以中文为例，Dolphin 中模型的 WER 仅为 9.2%，而 Whisper large-v3 模型为 27.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;119&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06462426d56c9716d0df14b1e58a21e0632.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;170&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-11828934de37eba21c5586716cf6aea6c7b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342397</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342397</guid>
            <pubDate>Sun, 23 Mar 2025 03:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Linus 口吐芬芳：怒斥英特尔工程师提交的代码是「令人作呕的一坨」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Linux 6.15 的开源图形驱动程序更新集已合并，但 Linux 创始人 Linus Torvalds 对这次合并请求并不十分满意。&lt;/p&gt; 
&lt;p&gt;特别是，他对作为完整内核构建一部分构建的某些新的&quot;hdrtest&quot;测试代码以及它留下的「垃圾」感到不满，并认为这段代码「应该死去」，至少对于非 DRM 驱动程序开发者来说是这样。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#424242&quot;&gt;根据他们在邮件列表的讨论，这些代码是由英特尔工程师 Jani Nikula 提交的&amp;nbsp;&lt;/span&gt;DRM 驱动相关代码。DRM 是 Linux 内核管理 GPU 渲染的核心子系统，负责硬件加速、视频播放等图形处理任务。&lt;/p&gt; 
&lt;p&gt;在周五夜晚，Linus Torvalds 在邮件列表上&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Fdri-devel%2F174321011387.3019715.1646591159826097779.pr-tracker-bot%40kernel.org%2FT%2F%23t&quot; target=&quot;_blank&quot;&gt;发表评论&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「哼。我已经完成了合并，解决了（琐碎的）冲突，但注意到这最终包含了令人厌恶的「hdrtest」垃圾，&lt;/p&gt; 
 &lt;p&gt;(a) 它减慢了构建速度，因为它是为常规 allmodconfig 构建，而不是作为一些简单的东西供你们按需运行&lt;/p&gt; 
 &lt;p&gt;(b) 还会在包含目录中留下随机的 &#39;hdrtest&#39; 废物&lt;/p&gt; 
 &lt;p&gt;人们已经分别对此进行了抱怨。它绝对不应该以这种破损的形式出现在我面前。&lt;/p&gt; 
 &lt;p&gt;为什么这个测试会被当作构建的常规部分来执行？&lt;/p&gt; 
 &lt;p&gt;该死的，我们不应该为依赖项添加随机的废物文件，这会让源代码树变得一团糟。&lt;/p&gt; 
 &lt;p&gt;我注意到它仍然存在的原因是 &quot;git status&quot; 会提醒那些愚蠢的垃圾代码没有被忽略。&lt;/p&gt; 
 &lt;p&gt;但更重要的是，这些垃圾代码还会破坏文件名补全功能！所以，将它们添加到 gitignore 中实际上并不能解决问题，它只会让我更快地注意到。&lt;/p&gt; 
 &lt;p&gt;这东西需要 &lt;em&gt;消失&lt;/em&gt;。&lt;/p&gt; 
 &lt;p&gt;如果你想做那个 hdrtest 的事情，就把它作为你 &lt;em&gt;自己的&lt;/em&gt; 检查的一部分来做。不要让其他人看到那个&lt;strong&gt;令人厌恶的一坨 (disgusting turds)&lt;/strong&gt;，并在他们的树中留下这些废物。&lt;/p&gt; 
 &lt;p&gt;我现在就通过将其标记为损坏来禁用它。你们可以自己决定怎么做，但强迫别人看到这些内容并不是解决问题的办法。&lt;/p&gt; 
 &lt;p&gt;我建议你们 *不要* 将这部分内容纳入 Kconfig 设置和常规构建中，而应该是一个 &lt;em&gt;你们&lt;/em&gt; 可以在测试中运行的部分（即像「make drm-hdrtest」那样，而不是作为常规构建的一部分）。&lt;/p&gt; 
 &lt;p&gt;Linus&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;1638&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/105324_cR4r_2720166.png&quot; width=&quot;1156&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;这里的「hdr」是指 C 头文件。新的「hdrtest」代码是为 Intel Xe 内核驱动编写的，目的是尝试确保 DRM 头文件是自包含的，并且能够通过内核文档测试。对包含的 DRM 头文件进行基本的维护检查，以确保它们都处于良好状态。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-23fbc2b19b2b3a820bd285e7b3693fa80ed.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#424242&quot;&gt;后续&lt;/span&gt;英特尔工程师 Jani Nikula&amp;nbsp;&lt;span style=&quot;background-color:#ffffff; color:#424242&quot;&gt;在邮件列表中进行了回应，承诺将测试文件移至.hdrtest 子目录，并通过 kconfig 选项隔离额外检查项。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342394/linux-6-15-hdrtest-turd</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342394/linux-6-15-hdrtest-turd</guid>
            <pubDate>Sun, 23 Mar 2025 02:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>预测技术在美团弹性伸缩场景的探索与应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;管理企业大规模服务的弹性伸缩场景中，往往会面临着两个挑战：第一个挑战是精准的负载预测，由于应用实例的启动需要一定预热时间，被动响应式伸缩会在一段时间内影响服务质量；第二个挑战是高效的资源分配，即在保障服务质量的同时控制资源成本。为了解决这些挑战，美团基础技术部与中国人民大学信息学院柴云鹏教授团队展开了&quot;预测技术在弹性伸缩场景的应用&quot;科研合作，相关论文《&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdl.acm.org%2Fdoi%2F10.1145%2F3589334.3645330&quot; target=&quot;_blank&quot;&gt;PASS: Predictive Auto-Scaling System for Large-scale Enterprise Web Applications&lt;/a&gt;》在具有国际影响力的会议 The Web Conference 2024（CCF-A 类会议）上作为 Research Full Paper 发表。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4bbfa4d899326f563c39328ce707f4be8b1.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;1 背景&lt;/h2&gt; 
&lt;p&gt;在管理企业大规模服务弹性伸缩的场景下，Web 应用的负载时序数据分析和预测至关重要。然而，由于应用的周期性特征和负载的复杂性，寻找一种能够适应所有应用的预测模型成为了一项挑战。首先，应用的负载数据往往具有周期性，这就需要在进行分析和预测时，需要考虑到这种周期性的影响。其次，由于业务特征的差异，预测算法可能在不同的应用下表现出差异化的效果，不存在&quot;one-size-fits-all&quot;的情况。例如，经测试发现，虽然在线模型的预测效果大多数时候好于离线模型，但在一些规律的突增情况下，在线模型经常存在滞后性的问题。这些问题都需要在对应用负载时序数据分析和预测时，进行深入的研究和探讨。&lt;/p&gt; 
&lt;p&gt;除了准确的负载预测，还需要高效的弹性伸缩策略。目前，业界常用的弹性伸缩策略有基于规则的阈值法、基于控制论的目标追踪和排队论。然而，我们发现这些方法并不能有效地保障 QoS（Quality of Service，服务质量），尤其是 QoS 包含对尾延迟的要求时，其背后原因是这些策略的性能模型并不准确。阈值法和目标追踪的性能模型是&quot;当 QPS 或 CPU 利用率在给定的范围内时 QoS 达标&quot;。但这些阈值通常是根据人工经验设置的，并不总是准确。排队论根据统计模型推导在给定的负载和资源下业务的延迟，但它依赖的理论假设（例如用户请求到来的分布）并不总在现实中成立，使其估算的延迟和真实值有偏差。我们在测试中也发现了排队论估算的延迟会略低于真实延迟，因而导致出现服务质量不达标。此外，基于 AI 的弹性伸缩方法例如强化学习并不一定适用企业的生产环境，因为 AI 模型缺乏一定的可解释性，且可能会在线上做出有 QoS 违例风险的行为。&lt;/p&gt; 
&lt;h2&gt;2 探索分析&lt;/h2&gt; 
&lt;h3&gt;2.1 预测实验探索&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;发现 1&lt;/strong&gt;：由于预测算法的固有限制，没有一种单一的算法能够在所有类别的时序数据中都提供最佳的预测效果。多样化的预测算法对于美团丰富的业务流量预测更有效。&lt;/p&gt; 
&lt;p&gt;我们对美团的服务流量数据进行周期检测（计算 ACF 自相关系数），发现 92.80% 的应用表现出强周期性（相关系数大于 0.8），4.55% 显示出弱周期性（相关系数介于 0.5~0.8 之间），只有 2.65% 的应用没有表现出明显的周期性（相关系数小于 0.5）。因此，对于美团内的大多数服务，可以使用模型可靠地预测 QPS 流量数据。&lt;/p&gt; 
&lt;p&gt;我们使用 225 个美团真实服务流量数据对业界常用的预测算法进行了测试。实验结果表明，预测效果最好的算法并不是单一的，而是取决于业务流量的具体特征。如图 1(a) 和 (b) 所示，我们使用三个代表性服务的流量数据来说明周期因子算法（Seasonal index）和 patchTST 模型的预测效果。 在图 1(a) 中，对于服务 1，周期因子算法显著优于 patchTST，而在图 1(b) 中，对于服务 2，patchTST 却又比周期因子预测效果更好。这一实验说明了最优预测算法的动态多样性，我们需要针对业务流量特征选择最合适的预测算法。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3024fe4dc9e5d02d0ae37f5c55344098.png&quot; alt=&quot;图 1 各种预测算法的准确性和鲁棒性对比&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;发现 2&lt;/strong&gt;：在线预测提供了较高的平均预测准确度，但在&quot;突变特征&quot;表现不佳。 相比之下，离线预测可以捕获&quot;突变特征&quot;，但存在明显的&quot;振幅偏差&quot;问题。&lt;/p&gt; 
&lt;p&gt;在线预测模型实时地获取最新的数据输入，输出未来一小段时间（如：15 分钟）的预测数据。 离线预测模型无需实时数据输入，直接预测未来较长一段时间（如：1 天）的预测数据。 由于缺乏最新实时数据的输入，离线模型往往无法达到和在线模型相同的预测准确性。但在一些有规律的突增时间点，离线模型能够捕捉到突变的周期性特征，从而取得&quot;及时&quot;的预测效果。例如，在周期性&quot;突变特征&quot;的情况下，在线模型可能会表现出预测滞后（图 1(c) 中的黑色圆圈突出显示）。 这种滞后效应会持续一段时间，我们称之为&quot;脏区间&quot;。&lt;/p&gt; 
&lt;p&gt;相反，离线模型有效地捕获这些信息，从而能够及时进行预测。然而，离线模型存在着&quot;振幅偏差&quot;的问题，即特征的形状被准确地表示，但其绝对值存在差异（见图 1(d)）。&quot;突变特征&quot;在美团服务中尤其普遍，这是由于美团许多业务都存在午、晚流量高峰。虽然&quot;突变特征&quot;只占实际时间序列数据的一小部分，但这些特征的精确预测对于在生产环境中维持 QoS 至关重要。&lt;/p&gt; 
&lt;h3&gt;2.2 伸缩方法分析&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;发现 3&lt;/strong&gt;：云平台广泛使用的弹性伸缩方法并不能有效保障 QoS，特别是当 QoS 要求对尾延迟的保障时。 与平均响应时间 RT 相比，当 QoS 要求为 TP999 尾延迟时，表 1 中几种方法的 QoS 保障率都显著降低。然而，大多数业务应用都需要关于尾延迟的保障，这使得弹性伸缩方法效率并不高，要么接受 QoS 违例，要么多冗余资源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;发现 4&lt;/strong&gt;：这些弹性伸缩方法的性能模型不够准确。基于阈值的规则和目标跟踪背后的性能模型实际上是&quot;当 QPS 或 CPU 利用率在一定范围内时 QoS 达标&quot;。 而这个范围的参数是根据人工经验确定的。表 1 的结果证明它并不完全有效。另外，排队论因为过于依赖理论假设而不够准确，导致其估计的 RT 低于真实值，从而出现 QoS 违例。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//33c8571e501f85c1fac1c60a9b6e862c.png&quot; alt=&quot;表 1 三种常见弹性伸缩方法的 QoS 保障率和资源成本&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前云平台的常见弹性伸缩方法有以下几种：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;阈值法&lt;/strong&gt;：基于一系列包含阈值的规则来进行弹性伸缩。以 CPU 资源利用率为例，当资源利用率超过上限阈值时，增加资源，反之，当利用率低于下阈值时，减少资源。阈值参数通常凭经验设置。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;目标追踪&lt;/strong&gt;：一种基于反馈的控制论方法，将某个指标（例如 CPU 资源利用率）维持在特定范围内。当实际资源利用率不在设定范围内时，系统会根据当前状态自动计算需要伸缩的实例数量。例如，假设 CPU 和流量呈线性相关的前提下，当前 10 个实例的平均 CPU 资源利用率为 80%，目标值为 50%，则实例需要扩容为 80%*10/50%=16 个实例。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;排队论&lt;/strong&gt;：根据排队论模型计算性能指标（例如延迟）并进行相应的伸缩以确保 QoS 达标。常见的𝑀/𝑀/𝑠模型表示请求到达和处理的时间呈指数分布，共有𝑠服务器并行处理。阿里巴巴的弹性伸缩框架 AHPA 使用排队论作为性能模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;强化学习&lt;/strong&gt;：弹性伸缩模块充当代理并与环境交互，在每次执行伸缩操作后接收奖励反馈。它通过反复试验建立状态（当前监控指标）和动作（伸缩多少实例）之间的映射模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;大部分云平台使用的弹性伸缩方法都是简单或直接的，比如：阈值法、目标跟踪和排队论。强化学习和其他人工智能相关方法使用较少，因为它们可能会影响在线业务的性能。 我们使用若干具有代表性的后端服务测试了常用弹性伸缩方法的 QoS 保障率。由于我们的主要目的是验证 QoS 保障率，因此我们使用了阶梯式增加的工作负载。QoS 保障率和资源成本的结果如表 1 所示。QoS 保障率是用 QoS 保障时长除以总时长计算得出的。资源成本由实例数随时间（分钟）的积分得到。&lt;/p&gt; 
&lt;h2&gt;3 技术方案&lt;/h2&gt; 
&lt;p&gt;为了解决这些问题，我们提出了 PASS（Predictive Auto-Scaling System），这是一种为企业大规模在线 Web 应用定制的预测弹性伸缩系统。为了保障预测框架准确性和鲁棒性，我们根据每个应用的特征，动态匹配和校准其适合的预测算法，有效应对了业务负载的多样性。我们进一步建立了基于在线历史日志的性能模型以保障多样化的 QoS，可解释的同时不会对在线业务产生负面影响。 除了基于负载预测和性能模型的主动伸缩以外，我们还设计了响应式的兜底策略，以及时应对因不准确的预测或意外事件导致的服务质量违例。在美团广泛的业务应用和真实负载下，相对于表 1 中其它方法，PASS 表现更优于 SOTA，以更少的资源成本实现更高的负载预测准确度和更低的 QoS 违例。&lt;/p&gt; 
&lt;p&gt;PASS 的整体架构如图 2 所示。ELPA（Ensemble Learning-based Prediction Algorithm）实时准确地预测业务负载的 QPS 时序数据。通过查询基于历史日志构建的性能模型，PASS 在不违反 QoS 的前提下，预测伸缩到业务所需的实例数量。此外，PASS 还持续监控 QoS 指标，如果发现由于预测不准导致的 QoS 违例，PASS 会基于当前真实的延迟校正预测结果，并伸缩到适当数量的实例，以快速消除 QoS 违例。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//61fbe22e46122909502ea446715b12e5.png&quot; alt=&quot;图 2 PASS 整体架构，图中上半部分的黑线表示离线步骤，下半部分中的红线表示在线过程&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3.1 ELPA 预测模型&lt;/h3&gt; 
&lt;p&gt;我们提出了 ELPA（Ensemble Learning-based Prediction Algorithm）预测算法框架（如图 3 所示）。对于每一类业务的实时流量，ELPA 采用一组相应的在线和离线模型来提供预测服务。我们首先从一系列不同的在线模型中选择一个能够为当前时间序列数据提供最准确预测的模型。然后，为了更好地预测&quot;突变特征&quot;，我们使用一个表现最好的离线预测模型代替在线模型。此外，我们使用振幅调整来改善离线预测时可能出现的&quot;振幅偏差&quot;问题，从而进一步增强预测性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a5687f66d210c1b1dea023ffe9a4b9d4.png&quot; alt=&quot;图 3 预测算法框架&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a34d503f83aac0ff074dac8b77d1afbd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3.2 性能模型设计&lt;/h3&gt; 
&lt;p&gt;我们提出了基于日志的性能模型（Log-based Performance Model）。主要包括：性能模型构建与模型训练校准两部分。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能模型构建&lt;/strong&gt;：Algorithm1 说明了如何基于历史日志（不需要对应用进行画像）构建性能模型。 我们从监控系统获取服务的日志，包括 QPS、实例数、QoS 指标等信息。 输入的 QoS 由服务设置，当 QoS 发生变化时需要重新建立性能模型。我们首先按实例数量聚合输入日志并遍历所有日志（第 1-9 行）。 第 4 行按照&quot;cap&quot;的粒度（例如最大 QPS 的千分之一）聚合 QPS，以减少数据数量和算法开销。 第 5-8 行统计 QoS 违例的发生次数。由于系统故障等因素可能导致某些记录不准确，因此在评估某个 QPS 的保障率时，我们不仅计算当前的 QPS 记录，还综合考虑所有较低的 QPS 记录（第 10-19 行）。第 20 行的排序规则是优先考虑大于给定阈值𝛿的 QoS 保证率，然后按 QPS 降序排序。𝛿可以根据业务的需求进行调整（默认为 0.99），衡量对 QoS 违例的容忍度。𝛿越接近 1，容忍度越低。最后，我们将排序后的第一个 QPS 指定为当前实例数可以处理的最大流量（第 21 行）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ec7e3255dedbe18d3dafe20203fc0215.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型训练校准&lt;/strong&gt;：直接根据监控日志构建的性能模型表可能不准确。当应用程序设置的弹性伸缩参数不合理时（例如水平扩容步长较大或资源冗余过多），可能会导致某些实例数没有监控日志，或者数据量极少。这可能会导致最初构建的表中条目丢失或不准确。 为了解决这个问题，我们首先保证原表数据保持非严格单调增长，空的或较低的 QPS 被之前较高的 QPS 替换。 然后，对于实例数量增加但 QPS 不变的部分，我们根据相邻 QPS 计算斜率并更新它们。 例如，初始化的性能模型映射为{5 : 30, 7 : 20, 8 : 60}，使用实例 5 的 QPS 替换实例 6 和 7 后，则变为{5 : 30,6 : 30,7 : 30,8 : 60}。 然后，根据实例 5 和 8 之间的 QPS 差异，我们更新实例 6 和 7 的 QPS，得到{5 : 30,6 : 40,7 : 50,8 : 60}。 此外，我们在每天低峰时段使用最新的监控日志定期重建性能模型，以保持准确性。&lt;/p&gt; 
&lt;h3&gt;3.3 Hybrid Auto-scaling 方案设计&lt;/h3&gt; 
&lt;p&gt;除了预测伸缩，我们还设计了基于排队论的响应式兜底策略，用于处理由于预测不准或热点事件负载突增导致的 QoS 违例。PASS 实时监控应用程序的性能指标。如果检测到 QoS 违例，PASS 将根据 M/M/s 排队论模型修改预测的 QPS，并重新查询性能模型以快速扩容适当数量的实例。 具体而言，排队论模型如下公式所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//27e47098c8346bda5703849d788e8ca1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;𝑠表示当前实例的数量，𝑢代表每个实例的瓶颈 QPS，𝑝表示延迟的百分比，以及𝑡指的𝑝百分位尾延迟。使用排队理论来估计 QPS 而不是延迟的原因是，从排队论推导出的延迟往往低于实际值（2.2 节中排队论的 QoS 保障率偏低证明了这一点），因此从实际延迟推导出的 QPS 将高于实际值。我们基于更高的 QPS 进行扩容，以快速响应 QoS 违例并将损失降至最低。并且我们通过实验表明，这部分资源冗余并不会导致大量浪费。&lt;/p&gt; 
&lt;h2&gt;4 测试结果&lt;/h2&gt; 
&lt;h3&gt;4.1 实验环境&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;应用选择&lt;/strong&gt;：我们从美团的各个业务线中随机抽取了 225 个应用，以验证预测模型的准确性。这些应用的历史 QPS 数据是从美团内部的统一在线监控平台获得的。我们根据数据的预测难度将其分为三个不同的级别。其中，164 个服务被定义为简单（具有单一波形模式，并表现出&quot;单峰和多峰&quot;特征），48 个服务被定义为中等难度（具有单一波形模式，并表现出&quot;尖峰&quot;或&quot;方形&quot;特征），13 个服务被定义为难（混合波形模式，例如&quot;尖峰+方形&quot;）。我们还选择了几个具有代表性的应用进行端到端评估。这些应用是后端服务，提供 C 端用户基本属性、用户行为查询、搜索和聊天功能。我们记录了在线请求流量，并在离线环境中回放，以恢复真实的在线环境。为了减少时间和资源成本，我们对记录的流量进行了切片，忽略了无法触发弹性伸缩的长期稳定的低峰值负载。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对比 Baseline&lt;/strong&gt;：我们比较了各种类型的 SOTA 预测算法和弹性伸缩方法。预测算法包括：离线算法（周期因子、Prophet）和在线算法（LSTNet、PatchTST 和 TIDE）。我们评估的在线算法旨在预测从当前时刻开始的第三个时间点的值（时间粒度为 5min，也就是预测未来 15min），即 horizon 等于 3。这足以满足预测伸缩的要求，因为绝大多数的应用实例能够在 15 分钟以内完成启动。弹性伸缩方法包括：目标跟踪和 AHPA。由于目标跟踪通常可以比具有相同参数的阈值法更快地扩展到目标范围（第 2.2 节也表明目标跟踪的性能更好），我们没有比较阈值法。其中 AHPA 是阿里巴巴基于排队论的 SOTA 预测弹性伸缩方法。&lt;/p&gt; 
&lt;h3&gt;4.2 预测算法评估&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;结论 1&lt;/strong&gt;：ELPA 预测框架结合了在线和离线模型的优势，在绝大多数场景中都取得最好的预测准确度。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//248d26761d7dd534067d4a7eb42f8ba5.png&quot; alt=&quot;表 2 各种预测算法在各种数据集上的准确度总结，分为三个预测难度级别&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（每一行和每一列分别比较所有方法在特定级别的数据集和特定指标上的结果。粗体突出显示每个指标的最佳结果；𝑀𝑒𝑡𝑟𝑖𝑐𝑠_𝑎𝑣𝑔表示当前难度级别数据集的平均预测结果，而𝑊𝑖𝑛𝑛𝑒𝑟显示了按数据集类型评估的方法在准确性方面优于其他方法的比例）&lt;/p&gt; 
&lt;p&gt;我们对 ELPA 以及其他五种广泛使用的预测算法进行了评估。表 2 显示了各种预测算法的准确度比较。ELPA 明显优於单个预测算法，由于其实现了一组优化规则，用于选择最合适的在线/离线组合，并使用振幅校准来预测特定时间段的数据。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;结论 2&lt;/strong&gt;：离线模型虽然擅长捕捉数据的&quot;突变特征&quot;，但其预测结果和真实值存在显著差异。而在线模型在有效预测这些&quot;突变特征&quot;方面面临挑战。通过两个模型的集成和振幅校准的应用，ELPA 框架表现出显著的鲁棒性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f185367c2eb6c4fafef2983a5f92b637.png&quot; alt=&quot;图 4 在线模型、离线模型（包括振幅调整）和 ELPA 的预测实例化展示&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 4 提供了 ELPA 的示例，其中结合了在离线预测模型，并对离线模型进行振幅调整。需要注意的是，&quot;突变特征&quot;可以在各种类型的业务流量中表现出来。由于篇幅限制，我们选择了一个具有代表性的业务负载数据集来突出 ELPA 的稳健预测能力。图 4(a) 比较了在线模型（PatchTST）的预测与真实数据。虽然在线模型在大多数情况下显示出很高的预测精度，但在预测&quot;突变特征&quot;时存在显著的滞后问题（黑色圆圈突出显示）。在图 4(b) 中，蓝色虚线代表离线模型（周期因子）的预测结果，尽管它在大多数情况下和真实值有一定的差距，但及时地预测出了&quot;突变特征&quot;。图 4(b) 中的红色虚线表示 ELPA 在离线模型的&quot;突变特征&quot;处的振幅校准结果。最后，图 4(c) 展示了 ELPA 的结果，它集成了在线模型和校准的离线模型，表现出准确的预测效果和预测&quot;突变特征&quot;的能力。&lt;/p&gt; 
&lt;h3&gt;4.3 端到端效果评估&lt;/h3&gt; 
&lt;p&gt;结论 3：PASS 的性能模型准确有效，在所有测试场景中都实现了最高的 QoS 保障率（表 3）。 与目标跟踪和 AHPA 相比，平均 QoS 保障率分别提高了 5.54% 和 7.71%。在多个 QoS 指标的场景 6 中表现更为明显，PASS 的 QoS 保障率分别提高了 19.21% 和 22.64%。PASS 在所有场景中的平均资源成本也是最低的。 平均资源成本较 AHPA 降低 8.91%，较目标跟踪降低 17.02%。在场景 4 中降低了高达 40% 和 52.76%。只有两个场景中 PASS 的资源成本略高于 AHPA，而在所有其他测试中，PASS 的资源成本都是最低的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f8042bb94099321b5b73f1379f6fae05.png&quot; alt=&quot;表 3 三种 auto-scaling 方法在不同 QoS 和测试时长（小时）场景下的端到端性能&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（每个场景中，第一列是 QoS 保障率，第二列是资源成本（实例数*小时）； 粗体突出显示每个指标的最佳结果）&lt;/p&gt; 
&lt;p&gt;我们从两个方面来评估弹性伸缩方法的效果。QoS 保障率衡量了应用违反 QoS 的时间长度，其计算方法为 QoS 得到保证的持续时间与总时间长度的比值。资源成本通过计算实例数量和时间（以小时为单位）的积分得到。 端到端实验结果如表 3 所示（测试过程详细监控数据见图 5 和图 6，包括 QPS 系列、实例数以及 TP99、TP999 时延等 QoS 指标）。每个测试场景提供了 QoS 指标、测试时长以及三种方法的 QoS 保障率和资源成本。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//874fb9b6215cff21f99fb53ff95aa05c.png&quot; alt=&quot;图 5 Scenario1 的综合监控数据：QPS 系列、实例数和 QoS 指标&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//da94df33b5e1290de293477cd6e9d37c.png&quot; alt=&quot;图 6 Scenario6 的综合监控数据：QPS 系列、实例数和 QoS 指标&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;需要注意的是，应用实例启动时并没有进行预热（例如数据库连接初始化、缓存预测等），因此即使实例提前进行了扩容，初始大量的冷查询仍然会导致尾延迟突然增加。如果业务方在其实例启动逻辑中加入预热，我们的 QoS 保障率将会进一步提高。&lt;/p&gt; 
&lt;h2&gt;5 经验总结&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;不同企业的应用场景可能各不相同，场景复杂程度也不一，在实际落地过程中，一些顶会算法不一定适用我们场景，这个时候就需要我们仔细甄别，取长补短，围绕自身场景特点进行算法的创新简化。&lt;/li&gt; 
 &lt;li&gt;模型并不是越复杂性能越好，要结合预测的特征与场景来选择预测算法。&lt;/li&gt; 
 &lt;li&gt;除了模型性能外，模型的可落地性也是非常重要的，比如 LSTNet 支持同时预测多项时间序列，面对大规模服务时能够极大的减少模型落地的开销。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;6 合作方简介&lt;/h2&gt; 
&lt;p&gt;中国人民大学柴云鹏教授团队致力于云计算、数据库等领域的系统研究和研发，近年团队在系统和数据库等领域的重要会议 ASPLOS、SOSP、HPCA、SIGMOD、VLDB、ICDE、WWW 等发表多篇高水平论文。在云计算领域，该团队针对资源隔离、资源分配、资源调度等核心问题，提出了一系列方法，可以提升各种复杂场景下的资源利用率，同时保障应用的服务质量，推动云计算技术的进步。团队高度重视科研工作的实用价值，积极推进与科技领域企业合作，针对企业面临的核心挑战，将创新性方法在实际系统中实现，推动研究成果的实际落地与应用，同时助力合作伙伴技术能力提升和商业价值实现。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;|&lt;/strong&gt; 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024 年货】、【2023 年货】、【2023 年货】、【2022 年货】、【2021 年货】、【2020 年货】、【2019 年货】、【2018 年货】、【2017 年货】等关键词，可查看美团技术团队历年技术文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//020f49d3b7136e1cb000bb228bdbe36b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明&quot;内容转载自美团技术团队&quot;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3A%E3%80%82%E6%9C%AC%E6%96%87%E6%9C%AA%E7%BB%8F%E8%AE%B8%E5%8F%AF%EF%BC%8C%E4%B8%8D%E5%BE%97%E8%BF%9B%E8%A1%8C%E5%95%86%E4%B8%9A%E6%80%A7%E8%BD%AC%E8%BD%BD%E6%88%96%E8%80%85%E4%BD%BF%E7%94%A8%E3%80%82%E4%BB%BB%E4%BD%95%E5%95%86%E7%94%A8%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%AF%B7%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E8%87%B3tech%40meituan.com%E7%94%B3%E8%AF%B7%E6%8E%88%E6%9D%83%E3%80%82&quot; target=&quot;_blank&quot;&gt;。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 tech@meituan.com 申请授权。&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/meituantech/blog/17576489</link>
            <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/17576489</guid>
            <pubDate>Sun, 23 Mar 2025 02:49:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Meta AI 研究主管 Joelle Pineau 计划辞职</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 人工智能研究副总裁 Joelle Pineau 宣布，她将于 5 月离职，结束她在 Meta 的职务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Pineau 自两年前起担任 Meta 人工智能研究实验室 (FAIR) 主管，领导该实验室在人工智能领域的前沿研究。FAIR 是由著名科学家 Yann LeCun 领导的 Meta 内部核心研究团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;268&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ac61b95fe3a1bae2f82e2aa6f31f103781.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Pineau 的离职正值 Meta 加大其人工智能投入的关键时刻。公司在 2025 年计划投入高达 650 亿美元用于人工智能基础设施的建设，显示出 Meta 对 AI 技术的重视和未来发展的决心。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在接受彭博新闻的采访时，Meta 的一位发言人表示，目前公司尚未找到 Pineau 的接替者，但正在积极寻找合适的候选人。值得注意的是，去年 Meta 曾对公司结构进行调整，使得其人工智能研究部门直接向首席产品官 Chris Cox 汇报，这一变化也反映了公司在 AI 领域发展的战略布局。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于即将到来的离职，Pineau 表示，离职后她计划先休息一段时间，之后将开启一场新的「冒险」，但具体计划尚未透露。她在离职声明中表示，自己对未来充满期待，并期待迎接新的挑战。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342390</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342390</guid>
            <pubDate>Sun, 23 Mar 2025 02:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里将在 4 月第二周发布新模型 Qwen3</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fn5SajAM_ZDqoMTvWK8jZuQ&quot; target=&quot;_blank&quot;&gt;根据虎嗅独家报道&lt;/a&gt;&lt;/u&gt;，阿里即将在 2025 年 4 月第二周（&lt;span style=&quot;background-color:#ffffff; color:#3a3a3a&quot;&gt;即下周&lt;/span&gt;）发布新模型 Qwen3，这将是阿里在 2025 年上半年最重要的模型产品。&lt;/p&gt; 
&lt;p&gt;报道称，在 2024 年发布 Qwen2.5 后，阿里云内部的基础模型团队已经开始推动 Qwen3 相关项目。&lt;/p&gt; 
&lt;p&gt;但 2025 年初 DeepSeek 的火爆，改变了团队的部分思路与重心。在 2024 年下半年，阿里云基础模型团队对标的竞品模型主要是 OpenAI 的 o1，而在 DeepSeek-R1 发布后，DeepSeek-R1 已经成为了另一个主要对标模型。&lt;/p&gt; 
&lt;p&gt;知情人士表示，在阿里内部，基础模型团队最重要的考核维度是「模型影响力」。高层希望团队可以在业内成功塑造「最强模型」的心智。由于阿里采取模型开源策略，基于 Qwen 开源模型的衍生模型总量，被视为一个关键指标。截至目前，这一数据已经超过 10 万。&lt;/p&gt; 
&lt;p&gt;而在开发者社区的欢迎度，阿里会考虑多个具体指标，比如开源模型下载量等。据释，2024 年 Qwen 系列模型在开发者社区的下载量超过了 2 亿。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342389</guid>
            <pubDate>Sun, 23 Mar 2025 02:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 搜索创企 Perplexity：公司资金充裕、2028 年前无 IPO 规划</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;AI 搜索创企 Perplexity 联合创始人兼首席执行官 Aravind Srinivas 在 Reddit &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fperplexity_ai%2Fcomments%2F1jm2ekd%2Fmessage_from_aravind_cofounder_and_ceo_of%2F&quot; target=&quot;_blank&quot;&gt;发帖回应&lt;/a&gt;&lt;/u&gt;了网友近期对该企业状况和产品的关切。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;5518&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ec5a737796ef123a3daf35370e97fd9c3c.png&quot; width=&quot;1494&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在财务方面，他表示 Perplexity 目前资金充裕，收入正处于上升轨道，没有在 2028 年前进行 IPO 计划；此前推出的 Auto 自动选择模型搜索模式不是为了节约成本，而是为了让产品更好&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;对于 Auto 模式，Aravind Srinivas 表示目前包括 Perplexity 自身在内的 AI 模型开发企业正在快速推出新的模型产品，一个一个地添加搜索模型选项是不可持续的，Auto 模式简化了用户的学习使用流程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-07e1f07e2d722d7b2a07a6979e9844b1637.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Perplexity 还正在开发一种更为强大的深度研究智能体，可进行 30 分钟乃至更长时间的思考。该企业正为此大规模重写基础架构，以便大规模实现这一智能体所需的人机交互、工具使用、代码执行能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/340590/perplexity-rebuilding-tiktok-in-america&quot; target=&quot;news&quot;&gt;Perplexity 欲收购 TikTok 并开源其算法&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/335658/perplexity-teases-a-web-browser-called-comet&quot; target=&quot;news&quot;&gt;AI 搜索引擎 Perplexity 将开发「代理搜索」 Web 浏览器 Comet&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342330/perplexity-no-ipo-before-2028</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342330/perplexity-no-ipo-before-2028</guid>
            <pubDate>Sat, 22 Mar 2025 11:44:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>MeiliSearch AI 发布：集语义、混合搜索为一体，提供多模态能力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;MeiliSearch 原本是一个 Rust 开发的 ElasticSearch 开源替代品，在&lt;strong&gt;开发体验、部署难度、性能可用性&lt;/strong&gt;上，都是相当有竞争力的轻量级选择。&lt;/p&gt; 
&lt;p&gt;MeiliSearch 近日发布了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.meilisearch.com%2Fblog%2Fintroducing-meilisearch-ai&quot; target=&quot;_blank&quot;&gt; MeiliSearch AI&lt;/a&gt;&lt;/u&gt;，这是 Meilisearch 的新版本，具有以下特点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;语义搜索&lt;/strong&gt;&lt;/strong&gt;：不仅匹配关键词，还能理解搜索意图。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;混合搜索&lt;/strong&gt;&lt;/strong&gt;：结合全文搜索与 AI 向量搜索，提高搜索精准度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;多模态能力&lt;/strong&gt;&lt;/strong&gt;：支持图片搜索等多种搜索模式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;内置向量数据库&lt;/strong&gt;&lt;/strong&gt;：无需额外搭建向量数据库，简化基础设施。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;优化性能&lt;/strong&gt;&lt;/strong&gt;：搜索结果极速返回，延迟低于 50 毫秒。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0401/182254_M83f_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 AI 时代，搜索早已不是简单的「关键词匹配」，而是成为了用户获取知识、信息、甚至创意的&lt;strong&gt;重要入口，特别是向量数据库为如今热火朝天的 RAG 应用提供了更多的选择&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Meilisearch AI 这些新特性，在当前和未来的应用中具有非常大的价值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;全文搜索：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;纠正拼写错误&lt;/strong&gt;：例如，将「reutrn of the jedi」纠正为「return of the jedi」。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;处理精确查询&lt;/strong&gt;：适用于输入确切产品名称的情况。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;处理不完整查询&lt;/strong&gt;：如输入「return of the j」也能找到相关结果。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;无法处理模糊查询&lt;/strong&gt;：例如，输入「拿着光剑战斗的人」时，可能无法找到相关结果。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;缺乏上下文理解&lt;/strong&gt;：如搜索「冬季服装」时，可能无法全面理解用户需求。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;向量搜索：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;处理模糊查询&lt;/strong&gt;：例如，输入「第一部上映的星球大战电影」时，能够找到相关结果。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;理解上下文&lt;/strong&gt;：如搜索「冬季服装」时，能理解并提供相关的衣物推荐。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;推荐相似文档&lt;/strong&gt;：能够根据语义相似性推荐相关内容。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;无法处理精确查询&lt;/strong&gt;：对于需要精确匹配的查询，向量搜索可能不够准确。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;资源需求较高&lt;/strong&gt;：计算和存储向量表示需要更多的计算资源和存储空间。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;鉴于两者各有优缺点，&lt;strong&gt;混合搜索&lt;/strong&gt;应运而生。混合搜索结合了全文搜索的词汇匹配能力和向量搜索的语义理解能力，提供更全面和精确的搜索体验。&lt;/p&gt; 
&lt;p&gt;例如，Meilisearch 的混合搜索功能允许开发者通过统一的 API 实现这一结合。在 Meilisearch 中，您可以通过设置&amp;nbsp;&lt;code&gt;hybrid&lt;/code&gt;&amp;nbsp;参数来配置混合搜索，调整&amp;nbsp;&lt;code&gt;semanticRatio&lt;/code&gt;&amp;nbsp;的值，以平衡全文搜索和向量搜索的比重，从而优化搜索结果的相关性和精确度。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// Hybrid search with Meilisearch

const results = await client.multiSearch({
queries: [{ 
indexUid: &#39;movies&#39;, 
q: &#39;batman&#39;,
hybrid: { embedder: &#39;default&#39;, semanticRatio: 0.5 }
}]
})&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通过结合两种搜索方法的优势，混合搜索为用户提供了更智能、更高效的搜索体验。&lt;/p&gt; 
&lt;p&gt;关于向量数据库，MeiliSearch 专门写了一篇博客进行介绍：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.meilisearch.com%2Fblog%2Fwhat-are-vector-embeddings&quot; target=&quot;_blank&quot;&gt;https://www.meilisearch.com/blog/what-are-vector-embeddings&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关文档：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.meilisearch.com%2Fdocs%2Flearn%2Fai_powered_search%2Fgetting_started_with_ai_search%23getting-started-with-ai-powered-search&quot; target=&quot;_blank&quot;&gt;https://www.meilisearch.com/docs/learn/ai_powered_search/getting_started_with_ai_search#getting-started-with-ai-powered-search&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.meilisearch.com%2Fblog%2Ffull-text-search-vs-vector-search&quot; target=&quot;_blank&quot;&gt;https://www.meilisearch.com/blog/full-text-search-vs-vector-search&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342317/meilisearch-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342317/meilisearch-ai</guid>
            <pubDate>Sat, 22 Mar 2025 10:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>黑莓手机有望回归：搭载 Android 15、支持 AI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Reddit 上的一篇帖子&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fblackberry%2Fcomments%2F1jmalqp%2Fcomment%2Fmkgfbpi%2F&quot; target=&quot;_blank&quot;&gt;透露&lt;/a&gt;&lt;/u&gt;，一家英国的初创公司正悄悄努力复活 Blackberry Classic 及 Onward Mobility 未完成的产品。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-df07f63db4adb240ebafad1ec113d909b4f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Reddit 用户 u/coldheartedsigma 在黑莓 subreddit 分享了这一消息，但由于签署了保密协议，未能透露具体的品牌名称或展示完整设计。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;帖子提到，新设备将具备 5G、AMOLED 显示屏、12GB RAM 和 256GB 或 512GB 存储空间等高端配置。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;据称，新版黑莓将运行 Android 15 系统，并支持一定程度的生成式 AI 技术，同时配备电容式键盘。&lt;/p&gt; 
&lt;p&gt;此外，还有一款基于 QWERTY 键盘的新设备正在规划中，该初创公司正与黑莓洽谈专利独家许可事宜。&lt;/p&gt; 
&lt;p&gt;虽然 u/coldheartedsigma 分享了一张图片，但几乎无法辨认任何有用信息。&lt;strong&gt;从模糊的图像中只能勉强看出「Blackberry Patents」、「QWERTY」和「The world&#39;s first」这几个词。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e7b1756db87a99da9db420f8d3d4fa31820.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对于那些期待黑莓回归的人来说，这家初创公司即使成功开发出类似黑莓的设备，也可能不会使用黑莓的名字。&lt;/p&gt; 
&lt;p&gt;因为黑莓已退出智能手机市场，所以这家公司如果真的推出产品，那也只是一款外观相似的手机，而非真正意义上的「黑莓」手机。不过，这也给怀念经典 QWERTY 键盘手机的用户带来了一丝希望。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342306/reddit-says-blackberry-is-back</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342306/reddit-says-blackberry-is-back</guid>
            <pubDate>Sat, 22 Mar 2025 09:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 时代软件供应链面临重大安全危机：机密泄露激增 64%</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;JFrog 公司近日发布了《2025 年软件供应链现状报告》，揭示了在人工智能（AI）迅速发展的背景下，软件供应链所面临的严峻安全挑战。根据该报告，研究团队通过对 1400 多名专业人士的调研，以及来自 7000 多家客户的数据分析，勾勒出了一幅令人为之担忧的安全图景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告指出，过去一年中，软件供应链的安全漏洞急剧增加，其中 「秘密」 或机密信息的曝光案例同比增长了 64%，总计达到了惊人的 25229 例。这一数据表明，随着企业对机器学习（ML）模型的依赖加深，安全风险也在不断上升。尽管 94% 的公司表示使用认证清单来管理 ML 模型，但其中 37% 的公司仍依赖手动方式进行验证，显然这加大了安全隐患。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;329&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-099c553624560d1a8503e298c286617a7f9.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;与此同时，2024 年新增的安全漏洞（CVE）数量也高达 33000 个，相比 2023 年增加了 27%。令人担忧的是，只有 12% 的 CVE 被证实真的具有 「严重」 级别，这或许反映出评分系统存在 「膨胀」 现象，可能导致开发者面临不必要的修复压力和工作疲惫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;JFrog 的首席技术官 Yoav Landman 指出，尽管许多组织在积极采用公共 ML 模型推动创新，但缺乏自动化的工具链和治理流程使得安全管理愈加复杂。他呼吁，企业在快速发展的 AI 环境中，应加速自动化转型，以确保在提升创新潜力的同时，也能保障软件的安全性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;整体来看，当前的软件供应链安全问题不仅是技术上的挑战，更是企业管理与运营方式的考验。在 AI 时代，建立更为严密的安全防护措施，已经成为各大企业亟需面对的任务。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342305</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342305</guid>
            <pubDate>Sat, 22 Mar 2025 09:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>亚马逊发布可控制 Web 浏览器的 AI 智能体 Nova Act</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;亚马逊发布了 Nova Act，这是一款通用 AI 代理，可以控制网络浏览器并独立执行一些简单的操作。除了新的代理 AI 模型外，亚马逊还发布了 Nova Act SDK，这是一个工具包，允许开发人员使用 Nova Act 构建代理原型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e2681b71429ea88e9c90005a9abadc4007f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Nova Act 由亚马逊新近在旧金山开设的 AGI 实验室开发，还将为该公司即将推出的 Alexa+ 升级版提供关键功能，Alexa+ 是亚马逊广受欢迎的语音助手的生成式 AI 增强版。不过，从今天开始提供的 Nova Act 版本略显逊色。亚马逊称其为研究预览版。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1adc5835a26d72e30965641b814c1462f0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;开发人员可以通过新网站 nova.amazon.com 访问 Nova Act 工具包，该网站也是亚马逊各种 Nova 基础模型的展示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2f6e472c5dea52938cb18c4e2cde8f294d4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Nova Act 是亚马逊试图利用自己的通用人工智能代理技术与 OpenAI 的 Operator 和 Anthropic 的 Computer Use 竞争的尝试。几家领先的科技公司认为，能够为用户导航网络的人工智能代理将使当今的人工智能聊天机器人更加有用。&lt;/p&gt; 
&lt;p&gt;亚马逊可能不是第一个开发这种代理技术的公司，但通过 Alexa+，它的覆盖范围可能是最广泛的。&lt;/p&gt; 
&lt;p&gt;亚马逊表示，使用 Nova Act SDK 进行开发的开发人员应该能够代表用户自动执行基本操作，例如从 Sweetgreen 订购沙拉或预订晚餐。借助 Nova Act 工具包，开发人员可以整合工具，让 AI 代理浏览网页、填写表格或在日历上选择日期。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e7474d0e9288f2459b2a8abe46b37bc9287.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;亚马逊声称，Nova Act 在公司内部的几项测试中表现优于 OpenAI 和 Anthropic 的代理。例如，在衡量 AI 代理如何与屏幕上的文本交互的 ScreenSpot Web Text 中，Nova Act 得分为 94%，优于 OpenAI 的 CUA（得分为 88%）和 Anthropic 的 Claude 3.7 Sonnet（90%）。&lt;/p&gt; 
&lt;p&gt;不过，亚马逊并没有使用更常见的代理评估（例如 WebVoyager）来对 Nova Act 进行基准测试。&lt;/p&gt; 
&lt;p&gt;Nova Act 是亚马逊上述 AGI 实验室推出的首款公开产品，该项目由前 OpenAI 研究员 David Luan 和 Pieter Abbeel 共同领导。两人之前都创立过自己的初创公司——Luan 创办了 Adept，而 Abbeel 共同创办了 Covariant——去年亚马逊聘请他们来领导其 AI 代理工作。&lt;/p&gt; 
&lt;p&gt;虽然 AGI 实验室开发能够订购 SweetGreen 的 AI 代理似乎有些奇怪，但 Luan 认为代理是创建超级智能 AI 系统的关键一步。Luan 将 AGI 定义为「一种能够帮助您完成人类在计算机上所做的一切的 AI 系统」。&lt;/p&gt; 
&lt;p&gt;Luan 表示，他的团队设计了 Nova Act SDK，以可靠地自动执行简短的任务，并为开发人员提供工具，让他们能够精确定义何时需要人工干预代理工作流程。他希望，这将使开发人员能够创建更可靠的代理应用程序，尽管不一定是完全自主的应用程序。&lt;/p&gt; 
&lt;p&gt;亚马逊在竞争激烈的市场中推出了首款通用人工智能代理，但这是该公司寄予厚望的一项关键技术。Nova Act 的早期测试可以让人们一窥拖延已久的 Alexa+ 的一些功能，这对亚马逊的人工智能努力来说是一个成败攸关的时刻。&lt;/p&gt; 
&lt;p&gt;OpenAI、Google 和 Anthropic 的早期人工智能代理的主要问题是它们在不同领域的可靠性。在 TechCrunch 的测试中，这些系统速度很慢，难以长时间独立运行，而且容易犯人类不会犯的错误。我们很快就会看到亚马逊是否破解了密码——或者它的代理是否也存在困扰竞争对手的同样缺陷。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关链接&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aboutamazon.com%2Fnews%2Finnovation-at-amazon%2Famazon-nova-website-sdk%E3%80%81https%3A%2F%2Fgithub.com%2Faws%2Fnova-act&quot; target=&quot;_blank&quot;&gt;https://www.aboutamazon.com/news/innovation-at-amazon/amazon-nova-website-sdk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aboutamazon.com%2Fnews%2Finnovation-at-amazon%2Famazon-nova-website-sdk%E3%80%81https%3A%2F%2Fgithub.com%2Faws%2Fnova-act&quot; target=&quot;_blank&quot;&gt;https://github.com/aws/nova-act&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342304/amazon-nova-website-sdk</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342304/amazon-nova-website-sdk</guid>
            <pubDate>Sat, 22 Mar 2025 09:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>