<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 09 Sep 2025 07:41:32 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>IBM 将整合 Red Hat 后台支持部门，削减重复支出</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2025%2F09%2F08%2Fred_hatters_to_be_big%2F" target="_blank"&gt;根据 The Register 的报道&lt;/a&gt;，IBM 已通知从 2026 年起，将把 Red Hat 的后台支持部门（法律、人力资源、财务和会计等 G&amp;amp;A 团队，General &amp;amp; Administrative）并入 IBM 体系，以减少重复职能和运营成本。&lt;/p&gt; 
&lt;p&gt;虽然相关部门领导仍留在 Red Hat，但多数普通员工和支持岗位将转入 IBM，部分国家可能因法律原因延迟执行。&lt;/p&gt; 
&lt;p&gt;IBM 长期通过整合和裁撤来优化成本，曾预计此类措施每年可节省 35 亿美元。目前 Red Hat 拥有约 1.9 万名员工，G&amp;amp;A 部门占比较小。此次调整对 Red Hat 工程、销售和技术支持等核心业务的直接影响有限，但部分员工担忧公司文化进一步被稀释。&lt;/p&gt; 
&lt;p&gt;IBM 强调，Red Hat 在 2024 年的年收入达到约 65 亿美元，并继续作为其云战略的重要组成部分。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371118</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371118</guid>
      <pubDate>Tue, 09 Sep 2025 07:30:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Vidu Q1 上线「参考生图」功能，可支持 7 张参考图输入</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;生数科技旗下视频大模型 Vidu 今天正式推出 Vidu Q1 参考生图功能，能够支持 7 张参考图输入。&lt;/p&gt; 
&lt;p&gt;据介绍，Vidu &amp;nbsp;Q1 参考生图以「参考够多，还原够真」为核心，主要包括五大亮点：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;参考数量行业领先同时支持 7 张参考图输入，可控性强。&lt;/li&gt; 
 &lt;li&gt;主体一致性更强在多人、多场景、多次生成下，依旧保证人物/主体的面貌与特征不跑偏。&lt;/li&gt; 
 &lt;li&gt;高还原度，真实感更强在保持参考图特征的同时，还原度高，更贴近用户原始输入，真正做到「所见即所得」。&lt;/li&gt; 
 &lt;li&gt;创作自由度极高一张图 + 一句提示词，就能自由换装、换背景、自由合成。支持多人同场景或者多人多场景，满足复杂剧情、合影、多角色电商等场景。&lt;/li&gt; 
 &lt;li&gt;支持 1080P 高清分辨率，中文语义理解更强，审美更适合本地&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="1280" src="https://static.oschina.net/uploads/space/2025/0909/151432_p44y_2720166.png" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1280" src="https://static.oschina.net/uploads/space/2025/0909/151536_Ou1Y_2720166.png" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1280" src="https://static.oschina.net/uploads/space/2025/0909/151609_Prxr_2720166.png" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;使用示例&lt;/p&gt; 
&lt;p&gt;&lt;img height="912" src="https://static.oschina.net/uploads/space/2025/0909/151641_ikfF_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1080" src="https://static.oschina.net/uploads/space/2025/0909/151806_vv9e_2720166.png" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;体验：&lt;em&gt;https://www.vidu.cn/&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371114</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371114</guid>
      <pubDate>Tue, 09 Sep 2025 07:19:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>我如何用 Prompt 工程将大模型调教成风控专家</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作为一个交易风控的算法工程师，在日常工作中，我常常与海量的数据和复杂的模型打交道，试图在看似平静的水面下，捕捉那些隐藏的风险暗流。最近，我尝试将大语言模型（LLM）引入到我的工作流中，这段经历充满了波折、顿悟和惊喜。 今天，我想覆盘整个过程，分享我如何通过一套循序渐进的「Prompt 工程心法」，将一个「什么都懂一点，但什么都不精」的通用大模型，一步步调教成能够精准识别复杂电商风控风险的「AI 专家」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一、 引言：当算法工程师遇见「猜不透」的 AI&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;故事的起点，是我近期做的一个项目。我通过用户的行为序列 Embedding 进行聚类，希望能发现一些未知的、有组织的风险模式。算法跑完，我得到了上百个「疑似风险簇」，每个簇里都包含了行为高度相似的用户订单。 问题来了：如何高效、准确地甄别这些聚类结果？ 传统的人工审核，不仅耗时耗力，而且每个人的判断标准难以统一，效率和准确性都无法保证。于是，我自然而然地想到了正当红的大模型。 我最初的想象非常美好：把一个簇的数据丢给 AI，它就能告诉我这群用户有没有问题。但现实很快给了我一记重拳。 我最初的尝试，Prompt 大概是这样的：「帮我看看这个用户簇有没有风险」。 得到的结果五花八门：模型要么像个「老好人」，对明显的异常视而不见；要么像个「怀疑狂」，把正常的用户促销活动也标记为高风险。它就像一个刚入职的实习生，知识渊博，但完全不懂业务，无法胜任真正的工作。 我很快意识到：问题不在于模型本身，而在于我与模型沟通的方式。 我不能把它当成一个全知的黑盒，而要把它当成一个需要悉心「带教」的、潜力巨大的「实习生」。我的任务，就是设计一份完美的「岗前培训手册」——也就是我们的主角：Prompt。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;二、 第一阶段：从 0 到 1，给 AI 一本「操作手册」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;要让一个实习生能干活，首先得让他知道「干什么」和「怎么干」。我需要将我作为风控专家的「隐性知识」显性化，为 AI 提供一个结构化的分析框架。 我的关键动作有三步：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1. 角色扮演 (Role-Playing)：这是最简单也最有效的一步。我在 Prompt 的开头加入了一句魔法咒语：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「你是一名资深的电商风控专家...」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这能有效地为 AI 设定身份，激活它庞大知识库中与该角色最相关的能力和知识。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2. 定义分析维度 (Defining Dimensions)：我把我人工审核时会关注的点，明确地列为指令，引导 AI 从这几个方面入手：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;收货人信息分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;收货地址分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;商品组合与价值分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3. 结构化输入输出 (Structured I/O)：为了实现高效、准确的人机协作，我规范了数据的「进」和「出」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;输入：考虑到 Token 的消耗效率和成本，我选择了 CSV 格式来组织和输入一个簇内的多个订单数据。相比 JSON 或 Markdown 表格，CSV 格式最紧凑，能在有限的上下文中传入最多的信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;输出：我要求 AI 必须以严格的 JSON 格式返回分析结果。这便于我的后端程序直接解析，实现真正的自动化。 经过这番改造，我的 V1 版 Prompt 诞生了。它就像一本清晰的操作手册，让 AI 的输出从杂乱无章的自然语言，变成了结构化的分析报告。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阶段小结：我们迈出了从 0 到 1 的关键一步，实现了流程自动化。但此时的 AI，更像一个只会照本宣科的「初级分析员」，它有了流程，但没有灵魂，更缺乏对业务复杂性的理解，误报率依然很高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;三、 第二阶段：注入业务常识，让 AI 学会「具体问题具体分析」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;很快，我发现这个「初级分析员」开始频繁地「犯教条主义错误」。它会把一些业务中的正常现象，当作风险信号上报。我意识到，我不仅要给它规则，更要给它「规则背后的逻辑」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我开始为 Prompt 注入一系列的「豁免规则」和「背景知识」：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;挑战 1：高折扣 ≠ 风险&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 的误判：AI 看到用户实付金额极低，就判定为「薅羊毛」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的「补丁」：在 Prompt 中明确指出：「本次分析的很多订单是【新用户首单】，平台会提供高额补贴，因此高折扣是正常现象，不能仅凭此点判断风险。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;挑战 2：随机串 ≠ 假姓名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 的误判：AI 看到 w1e8192vf4rwz 这样的用户 ID，就认为是「乱码、虚假信息」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的「补丁」：明确定义「用户 ID 是系统自动生成的随机字符串，其格式本身不代表风险。你需要分析的是用户自己填写的【收货人姓名】是否存在异常模式。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;挑战 3：0 元 ≠ 异常；暱称 ≠ 虚假；权益商品 ≠ 风险&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我举一反三，陆续加入了更多「豁免规则」：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;▪&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「价格为 0 的商品通常是【赠品】，本身无风险。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;▪&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「用户出于隐私保护，使用暱称或非全名（如‘李先生’）是普遍现象，单笔订单不应视为风险。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;▪&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「‘省钱卡’等权益商品是平台推广的正常模式，与主商品一并购买不意味着风险。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阶段小结：经过这一轮「业务培训」，AI 的「情商」和「业务感」显著提升，误报率大幅下降。它不再是一个只会执行命令的机器，而是成长为了解我们业务的「中级分析师」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;四、 第三阶段：提升分析深度，教会 AI「像侦探一样思考」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;解决了误报问题后，我开始追求更高的目标：提升模型的「洞察力」，让它能发现更深层次、更隐蔽的风险。我发现，AI 能处理「单点」的异常，但看不透「协同」作案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;瓶颈 1：忽略低价值商品风险&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 的认知停留在「高价值=高风险」，只对手机、显卡等商品敏感。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的「升级」：拓宽风险定义，明确指出「【远超个人合理消费范畴】的低价值、高流通性快消品（如成百箱的饮料），是小微商户囤货套利的重要信号。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;瓶颈 2：缺乏「一致性」视角&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当多个不同账号的地址并不完全相同时，AI 很难将它们关联起来。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;◦&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的「升级」：引入「购物车一致性」概念，告诉 AI：「多个不同用户，如果购买的商品列表【完全相同或高度雷同】，这种‘抄作业’式的行为是脚本化或有组织行为的强力证据。」 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阶段小结：通过教会 AI 识别「行为指纹」，它的分析视角成功地从「订单级」提升到了「团伙级」。它学会了「串联证据」，具备了识别有组织、规模化风险的能力，成长为一名「高级分析师」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;五、 第四阶段：终极进化，让 AI 在模糊中做出「法官式裁决」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这是整个旅程中最具挑战、也最有价值的一步。我面临一个终极难题：如何区分「真团伙」与「假聚集」？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的聚类算法本身，可能就会把一些无辜的用户圈在一起。例如，平台在某个城市搞了一场营销活动，给所有新用户发了同一张券，导致大量真实用户在相近的时间购买了同款促销品。他们的行为高度相似，但他们彼此之间毫无关联。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果 AI 无法分辨这种情况，那么之前的努力都将付诸东流。我需要将它从一个「分析师」或「侦探」，升级为一位「法官」，能够在模糊的信息中做出审慎的裁决。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的解决方案是：引入「双假设裁决框架」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我在 Prompt 中，要求 AI 在两个核心假设之间进行权衡和判断：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假设 A：协同风险团伙&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假设 B：良性特征客群&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;并且，我为它定义了做出裁决的关键依据——「硬链接」证据。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;「硬链接是指能将不同账号背后指向同一个实体的决定性证据，例如【完全相同的非公共收货地址】。你的首要任务是寻找硬链接。如果找到，则基本可判定为风险团伙。如果找不到，再评估其行为是否能被营销活动等良性原因完美解释。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同时，我为它提供了正反两方面的完整 Few-Shot 示例，一个是有硬链接的风险团伙，另一个是由营销活动导致的良性客群，为它的「裁决」树立了清晰的标杆。 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阶段小结：至此，我们的 Prompt 不再是一系列零散的指令，而是一个完整的、包含世界观和方法论的【专家系统】。AI 最终进化成了一位能够在复杂模糊的信息中，基于证据、权衡不同可能性，并做出审慎判断的「风控专家」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;六、 总结与思考：我的 Prompt 工程心法&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2025-07-04-10-490PpYchBnHOMz64r.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;回顾这段从 V1 到 V4 的进化之路，我将我的经验提炼为几点「心法」，希望能对大家有所启发：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;始于模仿，终于框架：从模仿你自己的专家思考过程开始，逐步将零散的规则，抽象和沉淀为普适的、可复用的分析框架。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;规则是骨架，背景是血肉：只给规则，AI 是冰冷的机器；为规则注入业务背景、用户心理等「常识」，AI 才有智能的灵魂。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;反例是最好的老师：教会 AI「什么不是风险」和「什么是风险」同等重要。精心设计的「豁免规则」和「良性示例」，是降低误报率、提升模型可用性的关键。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从「指令」到「思维模型」：最高级的 Prompt，不是告诉 AI 一步步做什么，而是教会它一套思考问题的方法论（比如我们的「双假设裁决框架」），让它自己去分析和判断。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这次探索让我深刻地体会到，在 AI 时代，Prompt 工程绝不仅仅是「提问的艺术」，它更是一门连接领域专家与通用人工智能的、充满创造性的交叉学科。我们每个工程师，都可以通过它，将自己的专业知识和智慧，赋能给这个强大的新伙伴，去解决更多过去难以解决的问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;希望我的这段经历，能为你打开一扇新的大门。感谢阅读！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18690981</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18690981</guid>
      <pubDate>Tue, 09 Sep 2025 07:14:28 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>MCP 官方注册中心来了：MCP Registry 预览版发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Model Context Protocol（MCP）团队近日发布了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.modelcontextprotocol.io%2Fposts%2F2025-09-08-mcp-registry-preview%2F" target="_blank"&gt;MCP Registry 预览版&lt;/a&gt;，这是一个集中式目录与 API 平台，旨在解决 MCP 服务器分发与发现问题，成为可信赖的「单一事实来源」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/150221_B8yG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该项目由 MCP 创始人 David Soria Parra 与 Justin Spahr-Summers 发起，联合 PulseMCP、Goose、GitHub、Anthropic、Microsoft 等多方协作者共同推动。&lt;/p&gt; 
&lt;p&gt;新平台支持 &lt;strong&gt;公共子注册表&lt;/strong&gt;（如第三方 MCP 市场、客户端专属目录）和 &lt;strong&gt;私有子注册表&lt;/strong&gt;（企业内部自建、安全可控），为开发者和组织提供灵活扩展的能力。&lt;/p&gt; 
&lt;p&gt;MCP Registry 采用社区驱动治理：任何人都可通过 issue 举报垃圾或恶意条目，管理员可将其下架，以维护生态健康。&lt;/p&gt; 
&lt;p&gt;MCP Registry：&lt;em&gt;https://github.com/modelcontextprotocol/registry&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;目前版本为预览阶段，不保证稳定性或数据持久性，团队鼓励社区积极提交反馈和改进建议。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371109/mcp-registry-preview</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371109/mcp-registry-preview</guid>
      <pubDate>Tue, 09 Sep 2025 07:07:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AlmaLinux 10 将默认启用 CRB 仓库，提供更丰富的软件包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AlmaLinux &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falmalinux.org%2Fblog%2F2025-09-08-enabling-crb-by-default-for-almalinux10%2F" target="_blank"&gt;官方宣布&lt;/a&gt;，从 AlmaLinux OS 10.0 起，系统将默认启用 &lt;strong&gt;CRB（CodeReady Builder）仓库&lt;/strong&gt;。这一调整旨在解决长期以来用户在安装 EPEL（Extra Packages for Enterprise Linux）软件时常遇到的依赖缺失问题，例如安装 KDE Plasma 桌面时的错误。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6efb7e3b802f4da9b9dda2d1218314477a2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，&lt;strong&gt;AlmaLinux Kitten 10&lt;/strong&gt; 已通过 8 月底的更新启用了 CRB，后续在 &lt;strong&gt;AlmaLinux 10.1&lt;/strong&gt; 发布前，现有系统也会逐步收到更新。&lt;/p&gt; 
&lt;p&gt;CRB 仓库包含许多企业级 Linux 默认未启用的软件包，包括开发工具和 EPEL 依赖组件。启用后，用户在安装额外软件时将更少遇到失败提示。同时，10.1 版本还会引入 &lt;strong&gt;selinux-policy-extra&lt;/strong&gt; 包，进一步提升 SELinux 环境下的 EPEL 兼容性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-533daf9ec1cc0dd068167cdb0910c926c44.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户如需关闭该仓库，可手动运行 &lt;code&gt;dnf config-manager --disable crb&lt;/code&gt;。AlmaLinux 团队也呼吁用户积极反馈使用体验，以便进一步完善系统。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371107</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371107</guid>
      <pubDate>Tue, 09 Sep 2025 06:57:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>深圳 AI 产业规模突破 3600 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;2024 年，深圳全市人工智能产业规模突破 3600 亿元，汇聚企业超 2800 家。目前，深圳已形成从算法研发、硬件制造到场景应用的完整产业链。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;深圳市人工智能产业协会统计数据显示，2024 年深圳市企业、院校等主体全球范围内共申请人工智能相关专利 3.74 万件，其中发明专利 3.59 万件占 95.9%，实用新型专利 0.13 万件占 3.4%，外观设计专利 0.02 万件占 0.6%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4L37G1_AAZRhhK7uQ5Lhag" target="_blank"&gt;介绍&lt;/a&gt;，从 2023 年 5 月开始，深圳在先进制造、低空经济、金融服务、政务服务、城市治理、交通运输、公共安全等领域，陆续开放了近 200 个「城市+AI」应用场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="336" src="https://oscimg.oschina.net/oscnet/up-b9bd4acba183f0a941ee03db60d912c3b6e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，《深圳市打造人工智能先锋城市的若干措施》还提出「每年发放最高 5 亿元‘训力券’，最高 1 亿元‘模型券’，最高 1 亿元支持人工智能行业应用，最高 5000 万元‘语料券’」，精准支持人工智能企业的算力使用、研发创新和场景落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从数据上看，由深圳市人工智能行业协会、深圳市投控数字科技有限公司联合编制的《2025 人工智能发展白皮书》显示，截至 2024 年底，深圳市政府数据开放平台累计提供开放数据目录 4065 个，累计开放数据总量 28.2 亿多条；深圳数据交易所数据交易规模约 167 亿元，其中跨境交易 3.1 亿元，均居全国首位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，深圳已发行首期规模 20 亿元的「深圳市人工智能和具身机器人产业基金」以及规模 50 亿元的「深圳市人工智能终端产业投资基金」，构建「引导基金+天使基金+种子基金+集群基金」投资生态。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371102</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371102</guid>
      <pubDate>Sun, 07 Sep 2025 06:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯发布 AI CLI 工具 CodeBuddy Code</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtwmCoGDSr7Sv6UxQUBvRmg" target="_blank"&gt;宣布&lt;/a&gt;正式推出全新 AI CLI 工具 CodeBuddy Code，号称「用它 90% 以上的代码都可以让 AI 生成」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同时，CodeBuddy IDE 国际版已开启公测，无需邀请码，面向所有用户开放使用。用户可免费使用 CodeBuddy 国内版全系列产品，无缝调用 DeepSeek 等大模型；国际版支持 GPT、Gemini 等主流模型，IDE 与 CLI 共用额度（测试期间赠送部分体验额度）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="280" src="https://oscimg.oschina.net/oscnet/up-5b0a643c4c5b2ab555a3908c5f255fb4c03.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，早在去年，腾讯云就推出 IDE 插件「代码助手 CodeBuddy」。2025 年 7 月，「CodeBuddy IDE」作为独立产品内测，主打「对话即编程」，用户无需代码基础，通过自然语言即可完成应用从构思到部署的全流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;此次发布的&amp;nbsp;&lt;strong&gt;CodeBuddy Code&lt;/strong&gt;，则是一款面向专业工程师的 AI CLI 工具，支持在命令行中用自然语言驱动开发全流程，实现极致自动化。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;CodeBuddy Code 不是一款普通的命令行工具，而是一款深度集成 AI 能力的智能终端助手。它的核心优势可概括为：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;无缝融入现有流程：&lt;/strong&gt;支持通过管道与 Git、npm 等工具链衔接，不改变开发者习惯；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开箱即用，扩展性强：&lt;/strong&gt;内置文件编辑、命令运行等工具，支持 MCP 协议灵活扩展；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自动化复杂任务：&lt;/strong&gt;适合重构、调试、CI/CD 等批量处理场景，提升效率。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;同步上线的 CodeBuddy IDE 公测版也迎来更新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;理解能力升级：&lt;/strong&gt;增强复杂场景下的代码生成质量，尤其优化数据库交互、API 逻辑等后端能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&amp;nbsp;&lt;strong&gt;腾讯生态深度集成：&lt;/strong&gt;可直接连接云开发 CloudBase，快速搭建数据库、云函数，并一键部署至 Web、APP、小程序；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;坚持普惠模式：&lt;/strong&gt;国内版免费，国际版 Pro 额度与 CLI 通用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;CodeBuddy Code 安装指令：npm install -g @tencent-ai/codebuddy-code（完成安装后，国际版选择 Google/GitHub 登录，国内版微信登录）&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;CodeBuddy IDE（海内外版本安装包不同）&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.codebuddy.ai%2F" target="_blank"&gt;下载国际版&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcopilot.tencent.com%2Fide" target="_blank"&gt;下载国内版&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371096</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371096</guid>
      <pubDate>Sun, 07 Sep 2025 06:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度文心 X1.1 深度思考模型上线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 9 日，在 WAVE SUMMIT 深度学习开发者大会 2025 期间，百度首席技术官、深度学习技术及应用国家工程研究中心主任王海峰正式发布了文心大模型 X1.1 深度思考模型，该模型在事实性、指令遵循、智能体等能力上均有显著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e79bee7ce3d353f0b180715b3d5821bc30d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;当前，用户可以通过文心一言官网和文小言 APP 上体验并使用文心大模型 X1.1。此外，文心大模型 X1.1 已正式登陆百度智能云千帆平台，面向企业客户以及开发者全面开放应用。&lt;/p&gt; 
&lt;p&gt;据王海峰现场介绍，文心大模型 X1 是基于文心大模型 4.5 训练而来的深度思考模型，升级后的 X1.1 主要采用了迭代式混合强化学习训练框架，一方面通过混合强化学习，同时提升通用任务和智能体任务的效果；另一方面通过自蒸馏数据的迭代式生产及训练，不断提升模型整体效果。相比文心 X1，X1.1 的事实性提升 34.8%，指令遵循提升 12.5%，智能体提升 9.6%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-aa7ae4fd1c672e36cf29a1e67ee68fa267e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多个权威基准评测中，文心 X1.1 整体表现超越 DeepSeek R1-0528，在部分任务上展现出领先优势。同时，在与国际顶尖模型 GPT-5 和 Gemini 2.5 Pro 相比，效果持平。&lt;/p&gt; 
&lt;p&gt;文心大模型能够实现能力范围的拓展与运行效率的显著提升，这离不开飞桨文心二者联合优化所发挥的关键作用。在大会现场，百度重磅发布了飞桨核心框架 3.2 版本，该版本在大模型训练、硬件适配以及生态支持等多个关键领域实现了全方位升级。&lt;/p&gt; 
&lt;p&gt;与此同时，百度还对大模型开发套件 ERNIEKit 和高效部署套件 FastDeploy 进行了同步升级。值得注意的是，百度方面的最新数据显示，飞桨文心生态开发者达到 2333 万，服务企业达到 76 万家。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371093</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371093</guid>
      <pubDate>Sun, 07 Sep 2025 06:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 支持加州 AI 安全法案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;AI 公司 Anthropic 正式支持加州州长斯科特・维纳（Scott Wiener）提出的 SB53 法案。该法案计划对全球&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;最大&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;的 AI 模型开发者施加前所未有的透明度要求，成为美国首个针对 AI 安全的立法尝试。然而，矛盾的是，许多硅谷科技公司和联邦政府对此法案表示强烈反对。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-af08d19dd5268877bf8bf5dfd8ea3188746.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Anthropic 在一篇博客中指出：「尽管我们认为前沿 AI 安全问题应在联邦层面解决，而不是由各州自行规定，但强大的 AI 技术发展不会等待华盛顿的共识。」 该公司强调，制定 AI 治理标准是当务之急，而 SB53 提供了一条合理的路径。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;如果 SB53 法案获得通过，像 Anthropic、OpenAI、谷歌和 xAI 等 AI 模型开发者将需要制定安全框架，并在部署强大 AI 模型前，发布公开的安全和安保报告。此外，该法案还将为举报安全问题的员工提供保护。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该法案特别关注于限制 AI 模型对 「灾难性风险」 的贡献，定义为导致至少 50 人死亡或造成超过 10 亿美元损失的事件。SB53 侧重于防范极端 AI 风险，例如防止 AI 模型被用于生物武器的开发或网络攻击，而不涉及更近一步的 AI 深度伪造或过度迎合等问题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;加州参议院已经通过了 SB53 的初步版本，但仍需进行最终投票，才能将其送交州长签署。尽管加州州长纽森尚未对该法案表态，但他曾否决过类似的 SB1047 法案。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;反对声音主要来自硅谷及特朗普政府，认为此类法案可能限制美国在与中国竞争中的创新。安德森・霍洛维茨（Andreessen Horowitz）和 Y Combinator 等投资者对此法案进行了强烈反对，认为州政府不应干预 AI 安全问题，应该将此事交给联邦政府。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管存在这些反对意见，政策专家认为 SB53 相较于之前的 AI 安全法案显得更为温和。加州立法者在该法案的制定过程中显示了对技术现实的尊重以及一定的立法克制。Anthropic 的联合创始人杰克・克拉克（Jack Clark）表示，尽管希望有联邦标准，但现有法案为 AI 治理提供了一份不可忽视的蓝图。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371092</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371092</guid>
      <pubDate>Sun, 07 Sep 2025 06:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>上海 AI 实验室开源 XTuner V1 训练引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;上海人工智能实验室（上海 AI 实验室）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_ThFxekq291-y5iuxkc55A" target="_blank"&gt;宣布&lt;/a&gt;开源书生大模型新一代训练引擎 XTuner V1。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，XTuner V1 是伴随上海 AI 实验室「通专融合」技术路线的持续演进，以及书生大模型研发实践而成长起来的新一代训练引擎。相较于传统的 3D 并行训练引擎，XTuner V1 不仅能应对更加复杂的训练场景，还具备更快的训练速度，尤其在超大规模稀疏混合专家（MoE）模型训练中优势显著。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-ff1375d90f151fe21298719b380e9eae9c0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;XTuner V1 基于 PyTorch FSDP 进行开发，并针对 FSDP 通信量大的固有缺陷，进行了系列优化，可支持 1T 参数量级 MoE 模型训练，并首次在 200B 以上量级的混合专家模型上，实现训练吞吐超越传统的 3D 并行训练方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;针对当前主流的 MoE 后训练需求，XTuner V1 不使用序列并行就能实现 200B 量级 MoE 模型单次 forward-backward 可处理 64k 序列长度，更适合当下流行的强化学习训练场景；对专家并行依赖小，长序列训练时受专家不均衡影响小，200B 量级 MoE 无需专家并行，600B MoE 只需节点内专家并行，更适合现代 MoE Dropless 训练模式；大规模长短序列混训场景提速 2 倍以上，数据并行负载均衡，大幅减小因需序列长度不均衡导致的计算空泡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同时，为了进一步挖掘 XTuner V1 训练方案的上限，研究团队与华为升腾技术团队在 Ascend A3 NPU 超节点上进行联合优化，充分利用超节点硬件特性，实现了更高的 MFU（Model FLOPS Utilization，模型浮点运算利用率）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在理论算力落后 NVIDIA H800 近 20% 的情况下，最终实现训练吞吐超过 H800 近 5%，MFU 反超 20% 以上，该项研究成果技术报告也将于近期发布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="325" src="https://oscimg.oschina.net/oscnet/up-112050849bc1465fa1733568599509e5451.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除了训练框架，书生大模型研发中使用的 AIOps 工具 DeepTrace 与 ClusterX 也将一并开源，为大规模分布式训练提供全方位保障。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371074</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371074</guid>
      <pubDate>Sun, 07 Sep 2025 03:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>B 站（哔哩哔哩）语音团队开源新一代语音合成模型 IndexTTS2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;哔哩哔哩语音团队发布并开源了新一代零样本语音合成模型 IndexTTS2。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-12ac8ed6b44ae691d1764b19b32b2adb355.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相关论文《IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech》已在 arXiv 上线，代码与模型权重也同步在 GitHub 与 Hugging Face 公开。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/abs/2506.21619&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/index-tts/index-tts&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;该模型首次在自回归架构中引入了「时间编码」机制，支持通过显式指定 token 数量来实现毫秒级的时长控制，也可以自由生成以保留原始韵律。&lt;/p&gt; 
&lt;p&gt;IndexTTS2 由三个核心模块组成：Text-to-Semantic（T2S） 、Semantic-to-Mel（S2M） 以及 BigVGANv2 声码器 。首先，T2S 模块基于输入的源文本、风格提示、音色提示以及一个可选的目标语音 token 数，生成对应的语义 token 序列。然后，S2M 模块以语义 token 和音色提示作为输入，进一步预测出梅尔频谱图。最后，BigVGANv2 声码器将梅尔频谱图转换为高质量的语音波形，完成端到端的语音合成过程。&lt;/p&gt; 
&lt;p&gt;&lt;img height="228" src="https://static.oschina.net/uploads/space/2025/0909/112919_2T8p_2720166.png" width="877" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;IndexTTS2 整体框架&lt;/p&gt; 
&lt;p&gt;模型训练数据包含了 55K 小时的中英双语语音以及 135 小时的情感数据。在 LibriSpeech-test-clean、SeedTTS test-zh/en、AISHELL-1 等基准测试中，IndexTTS2 在词错误率和说话人相似度方面均取得了 SOTA 成绩。主观 MOS 评测显示，其情感保真度达到 4.22，情感相似度为 0.887，时长控制误差低于 0.07%。&lt;/p&gt; 
&lt;p&gt;项目已提供 WebUI 与 Python 接口，支持普通零样本合成与情绪引导模式，可即插即用于 AI 配音、有声读物、视频翻译、播客等多种场景。官方还同步上线了内测版的「原声视频翻译」功能，让用户可以体验定长语音合成的效果。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371073</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371073</guid>
      <pubDate>Sun, 07 Sep 2025 03:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>极光 GPTBots 重磅升级 AI 工作空间，以应用市场开」AI 全员化」新篇章</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;极光 GPTBots 重磅升级 AI 工作空间，以应用市场 (Marketplace) 开启「AI 全员化」新篇章&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;企业级 AI 智能体构建平台 GPTBots 近日宣布，其 AI 工作空间（Workspace）完成重磅升级，并同步推出全新的&lt;strong&gt;应用市场（Marketplace）&lt;/strong&gt;。此次升级标志着 GPTBots 从一个专业的 AI 开发工具，战略性地演变为一个「人人可用」的企业级 AI 生产力平台，旨在将强大的 AI 能力安全、便捷地融入日常工作的每一个环节。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;一、 核心升级：更强大的 AI 工作空间，赋能每一位员工&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;升级后的 AI 工作空间 (Workspace)&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;旨在将强大的 AI 能力转化为企业全员触手可及的生产力工具。&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;其能力通过两大维度得到革命性增强：强大的内置基础应用和开放的应用市场生态。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;1. 内置能力全面增强，覆盖高频核心场景&lt;/strong&gt;Workspace 内置的核心功能板块得到全面升级，为员工日常工作提供了强大的基础能力：&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;企业级 AI Search：&lt;/strong&gt;&amp;nbsp;作为一个强大的企业智能搜索入口，员工可上传图片、音频、文档进行多模态检索，并可自定义模型与提示词，快速、精准地从企业海量数据中获取洞察。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;零代码自动化 Workflow：&lt;/strong&gt;&amp;nbsp;作为一个强大的业务流程自动化引擎，员工只需通过填写表单，即可驱动复杂的业务流程自动化，轻松获得结构化报告与数据。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;2. 全新应用市场 (Marketplace) 上线，开启无限扩展可能&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;本次升级的最大亮点，是正式推出的「应用市场 (Marketplace)」&lt;strong&gt;。作为一个开放的 AI 应用分发平台，它将全球顶尖的 AI 能力封装为即插即用**的应用，&lt;/strong&gt;企业可按需选用，持续为工作空间注入新的活力。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;首发应用「Live Speechly」（智能会议助手）：&lt;/strong&gt;&amp;nbsp;作为 Marketplace 的首发重磅应用，「Live Speechly」不仅能实时翻译会议内容，还能智能总结要点、自动生成行动计划，并可配置与企业 CRM 或任务系统联动，让每一次会议的价值都能量化落地。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;未来，Marketplace 将持续上架更多官方及第三方合作伙伴的 AI 应用，覆盖从通用效率工具到垂直行业解决方案的广泛需求。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;二、 专业赋能：为开发者打造的强大构建空间&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;在赋能全员的同时，GPTBots 持续强化其面向开发者的&lt;strong&gt;开发空间&lt;/strong&gt;。它为企业中的 AI 开发者、技术专家提供了从构建、调试到部署的全流程 AI 应用开发能力。现在，开发者可选择从零开始，&lt;strong&gt;也可直接调用官方预置的业务模板（如「智能客服」、「商机挖掘」等），基于最佳实践快速启动项目，为企业打造定制化的 AI 解决方案。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;三、 平台基石：企业级的集成与安全治理&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;强大的应用生态离不开坚实的平台能力。GPTBots 在本次升级中同样强化了其底层支撑：&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;丰富的平台集成：&lt;/strong&gt;&amp;nbsp;与&lt;strong&gt;Telegram&lt;/strong&gt;的深度集成得到优化，企业现在能用一个 AI 智能体同时管理多个客服机器人，并 7x24 小时在海量群聊中主动捕捉商机或服务请求。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;全面的企业级治理：&lt;/strong&gt;&amp;nbsp;升级后的「空间管理」功能为企业提供了强大的后台治理能力，包括应用审核发布、精细化权限管理、成本控制以及定制化的无缝集成，确保 AI 应用在企业内的使用既高效又安全可控。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;「我们的愿景是让 AI 普惠化，成为像 Office 套件一样无处不在的生产力工具。」GPTBots 创始人兼首席执行官罗伟东表示，「过去，AI 是少数开发者的专属。今天，通过全面升级的工作空间和全新的应用市场，我们为每一位员工打开了通往 AI 世界的大门。」&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;四、未来展望：Multi-Agent 系统预览，揭示 AI 协同作业的广阔前景&lt;/strong&gt;最后，GPTBots 在本次更新中正式公开了&lt;strong&gt;Multi-Agent（多智能体）系统&lt;/strong&gt;的创建入口。它允许企业组建一个由多个专业 AI 构成的「AI 专家团队」，自主规划并协同执行如市场研究等复杂任务，标志着平台正向「智慧 AI 团队」迈进。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;关于 GPTBots：&lt;/strong&gt;GPTBots.ai 是企业级 AI 智能体平台，支持构建从高效的单个智能体到能够自主规划、协同执行复杂任务的 Multi-Agent「智慧 AI 团队」。通过无代码/低代码的操作体验、丰富的应用市场 (Marketplace) 和企业级的安全治理，GPTBots 助力全球企业在 AI 时代实现效率跃升、成本优化与业务创新。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371065</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371065</guid>
      <pubDate>Sun, 07 Sep 2025 03:10:00 GMT</pubDate>
      <author>作者: 开源科技</author>
    </item>
    <item>
      <title>周鸿祎：大模型可能成为新的攻击载体和攻击入口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 ISC.AI 2025 上海大模型安全论坛上，360 集团创始人周鸿祎在致辞中指出，AI 发展面临着恶意利用、内容安全、「幻觉」问题、提示词攻击等风险，大模型既是生产力工具，也可能成为新的攻击载体和攻击入口，政府和企业的数据资产、商业机密面临着前所未有的暴露风险，保障 AI 安全是一项长期而艰巨的任务，需要各方协同努力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;会上，360 还发布了国内首个多智能体协同的大模型安全衞士。具体来看，其内容安全智能体通过垂直领域专业模型训练，提供智能判定、风险内容检测及安全回复代答等关键能力。通过建立五道「内容防线」，提供超过 100 个风险类目识别能力，确保输入输出双向安全。同时以测促防，持续对模型回复内容进行评测，识别潜在攻击风险。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI Agent 安全智能体通过原生安全机制，全面保障 AI Agent 在执行任务过程中的数据安全与权限控制，有效防范自动规划与执行中可能出现的行为失控问题，把大模型能力「关在笼子里」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;幻觉抑制智能体通过搜索增强、知识增强与对齐增强技术，提升大模型推理过程的准确性，有效抑制因内容时效性缺失、数据过时等因素引发的大模型「幻觉」问题，确保生成内容真实可信。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;软件安全智能体能够高效识别开源软件，精准定位 AI 软件的安全漏洞。覆盖从模型训练到推理的全链路安全检测，支持识别模型服务相关组件、生态链漏洞扫描与多语言代码审计，保障 AI 软件供应链生命周期的安全性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，360 将大模型安全衞士融入安全运营体系，通过整合安全大模型、安全大脑平台、大模型安全衞士及终端探针工具的核心能力，构建「网数模一体化」安全运营平台，实现安全运营系统性重塑与升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;360 数字安全集团副总裁余凯表示，AI 安全是一个高门槛的技术领域，需要同时具备 AI 技术积淀、安全实战经验、真实场景验证和海量语料积累。360 通过自身大规模 AI 业务场景验证产品能力，同时沉淀了海量安全语料，构建起核心竞争力。目前，360 大模型安全衞士已在公司内外多项业务中实现深度应用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371063</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371063</guid>
      <pubDate>Sun, 07 Sep 2025 03:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>社区造数服务接入 MCP</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;一、背景&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;今年 MCP 的概念非常火，市面上也涌现出了一大批 MCP 相关工具。作为技术一线者，都会按捺不住地去实操一下，很早的时候就有个设想，如果把我们的测试工具都改造为符合 MCP 服务协议标准，然后全部接入 AI Agent，打造一个集万千工具于一体的智能管家来帮助我们提效，是不是一个很完美的设想。很多宏伟或者天马行空的想法想要真正的落地，必然需要不断向下，拆解成可落地的任务模块，这里我们先从造数开始。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;二、AI 造数设想&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在实际业务需求测试中，我们依赖的测试数据需要很多前置的数据要求，这时候会涉及到分步使用不同的造数脚本。比如团长拉新做任务，需要一个 30 天内没发过动态的账号，加入团队，发一篇动态，动态过一审，过二审，阅读数满足 300 个。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;为了完成这个场景的造数，我们需要去造数工厂、接口自动化、脚本代码等平台找对应的造数工具，分别去执行才能完成这一系列的操作。可以从下图中看到，总计需要 6 个步骤才能完成。如果不是熟悉所有的业务，哪怕有现成的造数脚本，组合起来使用还是有一定的门槛。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="1128" src="https://oscimg.oschina.net/oscnet/up-3b7fa7c586340ba3f1c00d782b0ac7c6c9d.png" width="2206" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;那么在 AI 风行的年代，我们想要实现的是：按照用户输入的测试数据要求，能够按照已有造数能力自动编排，生成对应的测试数据给用户使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;最终实现效果案例：&lt;strong&gt;&lt;u&gt;我需要一个团长拉新的测试数据，要求是 30 天内没有发过动态，进入团队 A，然后发布一条动态，需要过一审风控审核，二审标注，最后需要获得 300 个阅读数。&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;AI 造数自动去造数池子中寻找对应的造数接口，按照提问的顺序要求来依次执行造数，最后返回给用户对应的测试账号。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;这里不再重复介绍 MCP 的概念，我们参考官方给出的 client-server 通用架构图来画一个 AI 造数的架构图，便于理解在落地到 AI 造数的场景，我们可以做哪些事。本篇文章主要就讲解了图中的其中一环，落地社区造数服务的 MCP 接入。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="1394" src="https://oscimg.oschina.net/oscnet/up-465e37c8cde5953f6ad51fd69a1bd676304.png" width="2030" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;三、社区造数服务 tools&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;框架介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;社区的造数服务技术栈是基于&amp;nbsp;&lt;/span&gt;&lt;span&gt;FastAPI&amp;nbsp;&lt;/span&gt;&lt;span&gt;框架实现的，通过 uv 工具来管理依赖库、虚拟环境等，这个工具亲测的确比传统的 pip 或者 poetry 等工具更好用。从安装 uv 到启动项目，只要 4 步就能无痛搞定环境，不用担心本地其他环境的干扰。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;## uv 命令
1.&amp;nbsp;安装 uv ：&amp;nbsp;`curl -LsSf https://astral.sh/uv/install.sh | sh`
2.&amp;nbsp;创建环境 - 自定义环境名称和 Python 版本 &amp;nbsp;&amp;nbsp;`uv venv tools_venv --python 3.12`
3.&amp;nbsp;激活环境 &amp;nbsp; &amp;nbsp;`source tools_venv/bin/activate`
4.&amp;nbsp;安装依赖包 &amp;nbsp; &amp;nbsp;`uv pip install -r pyproject.toml`


## 本地启动项目
直接运行 main.py 文件中的 main 方法即可，debug 模式自己 pycharm 中设置
if&amp;nbsp;__name__&amp;nbsp;== "__main__":
&amp;nbsp; &amp;nbsp; import uvicorn
&amp;nbsp; &amp;nbsp; uvicorn.run(app, host="0.0.0.0", port=8000)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;中间件相关配置全部通过 ARK 来管理，项目结构如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;## 项目结构


```bash
├── main.py &amp;nbsp;# 启动 APP 入口文件
├── README.md &amp;nbsp;# 开发手册
├── Dockerfile &amp;nbsp;# Docker 镜像文件
├── alembic &amp;nbsp;# alembic 迁移 DB 自动生成的相关文件
│ &amp;nbsp; ├── README
│ &amp;nbsp; ├── .env.py
│ &amp;nbsp; ├── script.py.mako
│ &amp;nbsp; └── versions &amp;nbsp;# 存放每次迁移的版本，可用于回滚 DB 版本
├── alembic.ini &amp;nbsp;# alembic 配置文件
├── app
│ &amp;nbsp; ├── __init__.py &amp;nbsp;# 注册 app
│ &amp;nbsp; ├── api &amp;nbsp;# api 开发目录
│ &amp;nbsp; ├── core &amp;nbsp;# app 的全局配置
│ &amp;nbsp; ├── crud &amp;nbsp;# 每个 table 的增删改查操作
│ &amp;nbsp; ├── db &amp;nbsp;# db 配置
│ &amp;nbsp; ├── models &amp;nbsp;# 存放表结构
│ &amp;nbsp; ├── schemas &amp;nbsp;# pydantic 模型
│ &amp;nbsp; └── utils &amp;nbsp;# 工具类
├── .pre-commit-config.yaml &amp;nbsp;# 配置 git commit 时自动检测工具
└── pyproject.toml &amp;nbsp;# 依赖库管理
```&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;统一部署到公司的发布平台，通过&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;http://{造数服务域名}/tools/docs#/&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;，地址可以访问目前社区所有的造数接口。同时也对接了造数工厂，可以直接去造数工厂使用。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="661" src="https://oscimg.oschina.net/oscnet/up-eabd0a4c0427f46b6285a9eae28abc181e1.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="653" src="https://oscimg.oschina.net/oscnet/up-caeee8fd4c3d5779f5a578bc285ced9acfd.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;改造思路&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;老方案-基于 MCP Python SDK&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;早在出现&amp;nbsp;MCP 这个概念的时候，我就想过有天把我们的造数服务通过 MCP 工具暴露出来，这样就可以非常方便的集成各种 Agent，打造 AI 造数。在出现这个&amp;nbsp;&lt;/span&gt;&lt;span&gt;FastAPI-MCP&lt;/span&gt;&lt;span&gt;&amp;nbsp;框架之前，想要把造数服务改造成支持&amp;nbsp;MCP ，就需要通过引入&amp;nbsp;MCP 依赖库来实现。但这个方案对于已有的造数服务来说改造成本有些高，可以看老方案的案例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;从官方文档面向服务器开发者 - MCP 中文文档中可以找到有对应的 MCP Python SDK，主要就是安装&amp;nbsp;MCP 这个依赖库。这里举一个简单的 demo，通过手机号查询用户信息的方法。可以很清晰的看出来这个 SDK 的语法结构是需要&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;@mcp.tool()&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;&amp;nbsp;这个装饰器来修饰，那么原有的造数服务暴露出来的所有接口方法是否都需要改造，这仍有一定的成本（未考虑其他复杂场景情况下）。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# server.py
from&amp;nbsp;mcp.server.fastmcp&amp;nbsp;import&amp;nbsp;FastMCP
from&amp;nbsp;tools.tools_set&amp;nbsp;import&amp;nbsp;get_user_info
import&amp;nbsp;uvicorn
# Create an MCP server
mcp = FastMCP("Demo")


@mcp.tool()
async&amp;nbsp;def&amp;nbsp;get_user_info_tool(mobile:&amp;nbsp;str) -&amp;gt;&amp;nbsp;Coroutine[Any,&amp;nbsp;Any,&amp;nbsp;Any]:
&amp;nbsp; &amp;nbsp;&amp;nbsp;"""根据输入的手机号获取用户信息
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; Args:
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; mobile: 手机号
&amp;nbsp; &amp;nbsp; """
&amp;nbsp; &amp;nbsp; info = get_user_info(mobile)
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;info


if&amp;nbsp;__name__ ==&amp;nbsp;"__main__":
&amp;nbsp; &amp;nbsp;&amp;nbsp;"""Initialize and run the server"""
&amp;nbsp; &amp;nbsp;&amp;nbsp;# mcp.run(transport="sse")
&amp;nbsp; &amp;nbsp;&amp;nbsp;"""Start the FastAPI server with uvicorn"""
&amp;nbsp; &amp;nbsp; uvicorn.run(app, host="0.0.0.0", port=8003)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;基于上述代码 demo，我们通过&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;uvicorn&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;启动服务，当然也可以单独启动&amp;nbsp;MCP 服务。控制枱输出如下，代表启动成功，接下来我们就可以使用&amp;nbsp;MCP 客户端工具进行连接使用了，这里使用 Cursor 来做演示。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="498" src="https://oscimg.oschina.net/oscnet/up-d7ddeff3b7a42bd3ace1f86742655b9e494.png" width="1276" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;看图标显示绿色，无报错说明连接成功，这里也能看到 demo 中的&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;get_user_info_tool&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;方法作为&amp;nbsp;MCP 工具暴露了出来。演示到这里，说明了该方案是可行的。因为本文重点讲解采用的新方案，此处就不再多介绍，感兴趣的可以去看官方文档。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="737" src="https://oscimg.oschina.net/oscnet/up-adb821aa5fb8f7f0c879620b4c8074fee0a.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;四、FastAPI-MCP&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;安装运行&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;「Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth! 」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;这是引用官网介绍的第一句话，翻译过来大概的意思就是：把你的 FastAPI 服务作为&amp;nbsp;MCP 工具暴露出来成为现实！&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;安装&amp;nbsp;&lt;/span&gt;&lt;span&gt;FastAPI-MCP 库&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;uv add fastapi-mcp&amp;nbsp;&lt;/strong&gt;&amp;nbsp;or&amp;nbsp;&lt;strong&gt;&amp;nbsp;uv pip install fastapi-mcp&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;使用 FastAPI-MCP，只需要 3 行代码就能把 FastAPI 框架改造成一个&amp;nbsp;MCP 服务&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;通过&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;uvicorn&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;启动服务器，使用 http://localhost:8000/mcp 来访问 MCP server&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;from&amp;nbsp;fastapi&amp;nbsp;import&amp;nbsp;FastAPI
import&amp;nbsp;uvicorn
from&amp;nbsp;fastapi_mcp&amp;nbsp;import&amp;nbsp;FastApiMCP


# Create (or import) a FastAPI app
app = FastAPI()


# Create an MCP server based on this app
mcp = FastApiMCP(app)


# Mount the MCP server directly to your app
mcp.mount()


if&amp;nbsp;__name__ ==&amp;nbsp;"__main__":
&amp;nbsp; &amp;nbsp; uvicorn.run(app, host="0.0.0.0", port=8000)&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;用法介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自定义配置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过看源码 FastApi-MCP 类，基本能清晰的看出来各个参数的用处，这里将介绍几个常用的。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;class&amp;nbsp;FastApiMCP:
&amp;nbsp; &amp;nbsp;&amp;nbsp;"""
&amp;nbsp; &amp;nbsp; Create an MCP server from a FastAPI app.
&amp;nbsp; &amp;nbsp; """
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;def&amp;nbsp;__init__(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; self,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fastapi: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; FastAPI,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("The FastAPI application to create an MCP server from"),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; name: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[str],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("Name for the MCP server (defaults to app.title)"),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; description: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[str],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("Description for the MCP server (defaults to app.description)"),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; describe_all_responses: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;bool,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("Whether to include all possible response schemas in tool descriptions"),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;False,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; describe_full_response_schema: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;bool,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("Whether to include full json schema for responses in tool descriptions"),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;False,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; http_client: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[httpx.AsyncClient],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"""
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Optional custom HTTP client to use for API calls to the FastAPI app.
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Has to be an instance of `httpx.AsyncClient`.
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; """
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; include_operations: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[List[str]],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("List of operation IDs to include as MCP tools. Cannot be used with exclude_operations."),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; exclude_operations: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[List[str]],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("List of operation IDs to exclude from MCP tools. Cannot be used with include_operations."),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; include_tags: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[List[str]],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("List of tags to include as MCP tools. Cannot be used with exclude_tags."),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; exclude_tags: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[List[str]],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("List of tags to exclude from MCP tools. Cannot be used with include_tags."),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; auth_config: Annotated[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Optional[AuthConfig],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Doc("Configuration for MCP authentication"),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ] =&amp;nbsp;None,
&amp;nbsp; &amp;nbsp; ):
&amp;nbsp; &amp;nbsp; ...&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Server metadata&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;name：MCP 服务名&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;description：对 MCP 服务的描述&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Tool and schema descriptions&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;创建 MCP 服务器时，可以通过修改&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;describe_all_responses&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;&amp;nbsp;，把所有可能的响应模式包含在工具描述中，或通过更改&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;describe_full_response_schema&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;把完整的 json 包含在工具描述中。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;from&amp;nbsp;fastapi&amp;nbsp;import&amp;nbsp;FastAPI
from&amp;nbsp;fastapi_mcp&amp;nbsp;import&amp;nbsp;FastApiMCP


app = FastAPI()


mcp = FastApiMCP(
&amp;nbsp; &amp;nbsp; app,
&amp;nbsp; &amp;nbsp; name="My API MCP",
&amp;nbsp; &amp;nbsp; description="Very cool MCP server",
&amp;nbsp; &amp;nbsp; describe_all_responses=True,
&amp;nbsp; &amp;nbsp; describe_full_response_schema=True
)


mcp.mount()&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Customizing Exposed Endpoints&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;include_operations&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;， 暴露 operation_id=XXX 的接口&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;exclude_operations&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;， 排除 operation_id=XXX 的接口&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;include_tags&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;， 暴露 tags=XXX 的接口&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;exclude_tags&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，排除 tags=XXX 的接口&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;组合使用：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;include_operations&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;exclude_operations&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;不能同时使用&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;include_tags&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;exclude_tags&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;不能同时使用&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;include_operations&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;include_tags&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;可以组合使用，匹配任一个条件就满足&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;from fastapi import FastAPI
from fastapi_mcp import FastApiMCP


app = FastAPI()


# 案例 1：include_operations
mcp = FastApiMCP(
&amp;nbsp; &amp;nbsp; app,
&amp;nbsp; &amp;nbsp; include_operations=["get_user",&amp;nbsp;"create_user"]
)


# 案例 2：exclude_operations
mcp = FastApiMCP(
&amp;nbsp; &amp;nbsp; app,
&amp;nbsp; &amp;nbsp; exclude_operations=["delete_user"]
)


# 案例 3：include_tags
mcp = FastApiMCP(
&amp;nbsp; &amp;nbsp; app,
&amp;nbsp; &amp;nbsp; include_tags=["users",&amp;nbsp;"public"]
)


#案例 4：exclude_tags
mcp = FastApiMCP(
&amp;nbsp; &amp;nbsp; app,
&amp;nbsp; &amp;nbsp; exclude_tags=["admin",&amp;nbsp;"internal"]
)


# 案例 5：Combined
mcp = FastApiMCP(
&amp;nbsp; &amp;nbsp; app,
&amp;nbsp; &amp;nbsp; include_operations=["user_login"],
&amp;nbsp; &amp;nbsp; include_tags=["public"]
)


mcp.mount()&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;工具命名&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;FastAPI 中的路由通过&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;operation_id&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;参数来作&amp;nbsp;MCP 工具名称，如果没有显示命名，框架会自动生成一个。此处经测试，如果不显示命名，自动生成的名字不仅会很奇怪，还会影响 AI 造数的准确性，所以这里最好作好规范，必须要显示命名。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# Auto-generated operation_id (something like "read_user_users__user_id__get")
@app.get("/users/{user_id}")
async&amp;nbsp;def&amp;nbsp;read_user(user_id:&amp;nbsp;int):
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;{"user_id": user_id}


# Explicit operation_id (tool will be named "get_user_info")
@app.get("/users/{user_id}", operation_id="get_user_info")
async&amp;nbsp;def&amp;nbsp;read_user(user_id:&amp;nbsp;int):
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;{"user_id": user_id}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;五、接入造数服务&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;框架升级及改造&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="158" src="https://oscimg.oschina.net/oscnet/up-6daf0b306f68eb26a818acbcd4bc1c97e0e.png" width="362" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在接入的时候，要查一下官方文档要求的 Python，FastAPI 等版本，先进行框架升级，防止出现不兼容的问题。这项通过管理工具安装依赖库时能自动校验，其他一些兼容问题在启动服务后根据实际场景一一去解决即可。这里推荐使用 uv 工具进行管理，亲测比之前的 poetry 更好用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;列几个核心库的版本，都是验证过没有兼容问题的。在过程中也是遇到一些兼容问题花了点时间，因为 FastAPI-MCP 框架比较新，网上资料还不全，遇到没法解决的问题大家可以去项目 issue 中找，提升解决问题效率。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;python&amp;nbsp;=&amp;nbsp;"^3.12"
fastapi&amp;nbsp;=&amp;nbsp;"0.115.12"
fastapi-mcp&amp;nbsp;="0.3.1"
mcp="1.7.0"
pydantic&amp;nbsp;=&amp;nbsp;"^2.11.0"
pydantic-settings&amp;nbsp;=&amp;nbsp;"^2.2.0"&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;步骤&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;第一步：&lt;/strong&gt;引入&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;fastapi-mcp&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;第二步：&lt;/strong&gt;main.py 中添加 MCP 服务&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="1742" src="https://oscimg.oschina.net/oscnet/up-ce1141e73e95f28018c491ceb00fdda983f.png" width="3024" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;第三步：&lt;/strong&gt;也是工作量最大的一步，将每个造数接口都做显示命名，并且做好文档注释，写的越清楚 AI 造数的准确率越高，需要对应编写造数场景测试，共同完成&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="737" src="https://oscimg.oschina.net/oscnet/up-0e83a066f4c13f56252bb062799edc7c522.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;最后一步：&lt;/strong&gt;启动服务&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;uvicorn.run('main:app', host='0.0.0.0', port=8023, reload=True, workers=2)&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;，无报错基本就没有问题了。再通过 MCP 客户端工具连接使用即可&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="828" src="https://oscimg.oschina.net/oscnet/up-127999129cd482f6ef6ddfd7c16fff98e4c.png" width="1924" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;接入 Cursor&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;改造完之后的造数服务成功对外暴露了 MCP 服务，现在我们可以通过 MCP 客户端去连接使用了，这里选用了 Cursor，因为 Cursor 使用的人比较多，同时集成了市面上的主流大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;步骤&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;第一步：&lt;/strong&gt;创建一个 mcp.json，按照标准 json 配置即可&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers":&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;"fastapi-mcp":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"http://localhost:8022/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"description":&amp;nbsp;"本地开发环境 MCP 服务配置"
&amp;nbsp; &amp;nbsp;&amp;nbsp;},
&amp;nbsp; &amp;nbsp;&amp;nbsp;"tools-mcp":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"http://localhost:8011/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"description":&amp;nbsp;"本地开发环境 MCP 服务配置"
&amp;nbsp; &amp;nbsp;&amp;nbsp;},&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;"demo-mcp":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"http://localhost:8001/sse",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"description":&amp;nbsp;"本地开发环境 MCP 服务配置"
&amp;nbsp; &amp;nbsp;&amp;nbsp;},
&amp;nbsp; &amp;nbsp;&amp;nbsp;"tools-mcp-prod":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"http://XXXXXX/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"description":&amp;nbsp;"线上"
&amp;nbsp; &amp;nbsp;&amp;nbsp;}
}
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;第二步：点击右上角设置 icon，进入 Cursor Settings，选择 MCP&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="737" src="https://oscimg.oschina.net/oscnet/up-e405f6c3b39c76fefb42ed99b65eaef9493.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;第三步：&lt;/strong&gt;这里可以看到，在刚才 mcp.json 中配置的 MCP 工具均加载过来，打开开关，运行状态显示为绿色，无报错并说明了服务接入正常，接下来就可以正常使用 Cursor 中的 Agent 进行对话了&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;实操演练&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;我们现在只希望使用造数能力，因此我们可以指定刚才配置的&amp;nbsp;MCP 工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;场景化案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;需求：&lt;strong&gt;&lt;u&gt;给手机号为 11120210001 的用户发布一个点评动态，并且通过风控一审。&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;这里注意一下提问方式，因为我们没有对大模型进行特别的训练，AI 不一定知道 111 开头的是我们测试使用的虚拟手机号，有可能会误解为 userId，所以我们需要告诉 AI 这是一个手机号。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;可以看到在这个 demo 中， Agent 自动帮我们分了三步去调用对应的 MCP tool，第一步通过我们输入的手机号去获取 userId，第二步通过 userId 去发布点评动态，第三步通过点评动态 id 去通过风控一审。原本需要三步完成的造数场景，现在通过一句话描述就完成了。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-43ff74f8e9a0982ee59ab299ca26dcf2e1a.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;调优案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;需求：&lt;strong&gt;&lt;u&gt;随机创建 10 个测试账号&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ &amp;nbsp;调优之前&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;造数代码，主要看文档注释内容。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;@router.post('/create-account', operation_id="create_account",summary="创建测试账号")
async&amp;nbsp;def&amp;nbsp;c_create_account(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; env:&amp;nbsp;str&amp;nbsp;= Body(..., description='环境'),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; phonenumber:&amp;nbsp;str&amp;nbsp;= Body(..., description='手机号'),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; pwd:&amp;nbsp;str&amp;nbsp;= Body(..., description='密码'),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; usernum:&amp;nbsp;str&amp;nbsp;= Body(None, description='数量'),
) -&amp;gt;&amp;nbsp;Any:
&amp;nbsp; &amp;nbsp;&amp;nbsp;"""
&amp;nbsp; &amp;nbsp; 创建测试账号，默认 111 开头
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; args
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; env: 环境，默认：t1
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; phonenumber: 手机号
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; pwd: 密码，默认：test123
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; usernum: 数量
&amp;nbsp; &amp;nbsp; """
&amp;nbsp; &amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;把这个造数需求发送给 AI，发现报错了。我们去代码中看下为何返回了 false，原来是因为接口返回非 200，排查下来是因为 t1 环境测试账号造数默认填了 111，不需要再加 111，所以接口直接 500 了。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;这里 AI 犯了两个错误：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;因为默认手机号都是 11 位的，这里 AI 不知道只需要传 8 位就行。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;我没有输入具体的手机号，所以按照代码逻辑应该是支持自动随机生成的，但是 AI 也不知道这个逻辑，「自作主张」给我传入了一个手机号。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-a687a3ba5d6e43d967a1df706e061309d3c.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ &amp;nbsp;调优后&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过排查我们已经明确知道 AI 犯了哪些错误，那么我们针对这些错误去调优即可。所谓的调优主要就是修改文档注释，可以前后对比下注释内容。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;"""
创建测试账号，默认 111 开头，不用填写 111，只需要后面 8 位
不传手机号 phonenumber，默认随机生成手机号


args
&amp;nbsp; &amp;nbsp; env: 环境，默认：t1
&amp;nbsp; &amp;nbsp; phonenumber: 手机号，非必填，不填自动生成
&amp;nbsp; &amp;nbsp; pwd: 密码，默认：test123
&amp;nbsp; &amp;nbsp; usernum: 数量
"""&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ &amp;nbsp;最终效果&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="841" src="https://oscimg.oschina.net/oscnet/up-661edd41c61d2a9a6839eff382484e4eb7f.png" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过这个案例可以看到，准确率依赖我们对造数接口的文档注释，所以在实际使用过程中，前期需要我们不断地去调优，才能达到我们想要的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;当然随着后续迭代，可能可以用更优雅的方式完成这个工作，比如再引入静态代码分析工具，通过 AI 编程自动完成注释。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_13"&gt;&lt;/span&gt; 
&lt;h1 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;六、总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_14"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;技术实践成果&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过将社区造数服务改造成符合 MCP（Model Context Protocol） 标准的工具，我们成功实现了以下目标：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;AI 驱动的测试数据自动化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;用户通过自然语言描述需求，AI Agent 可自动编排造数接口生成复杂测试数据，将原本需手动执行 3 步的操作简化为一步指令。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;低成本框架升级&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;基于&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;fastapi-mcp&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#3e3e3e"&gt;框架，仅需少量代码改造即可将 FastAPI 服务快速接入 MCP 协议，解决了传统 SDK 方案的高适配成本问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;工具链整合&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过对接 Cursor 等 AI 工具平台，验证了 MCP 协议在跨平台协作中的可行性，为后续构建「社区智能管家」奠定技术基础。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_15"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;核心实践经验&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;注释即规范&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;AI 调用接口的准确性高度依赖代码注释的清晰度。通过优化接口文档（如参数默认值、输入格式说明），可显著提升 Agent 的任务解析成功率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;渐进式调优&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;初期需通过人工干预优化 Agent 的接口调用逻辑，未来可引入代码静态分析工具自动生成标准化注释。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_16"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;未来优化方向&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;动态编排增强&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;当前接口调用为线性执行，后续可探索基于依赖关系的动态编排（如并行执行独立步骤、自动重试失败操作）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;多 Agent 协作&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;结合领域知识库与测试断言工具，实现从「造数」到「验证」的全链路 AI 自治。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;协议扩展性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;探索 MCP 与更多协议（如 OpenAPI）的互操作性，提升工具服务的跨平台复用能力。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_17"&gt;&lt;/span&gt; 
&lt;h2 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;价值与启示&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;本次实践印证了 「AI+协议化工具」 在测试领域的巨大潜力：降低技术门槛 （非技术人员可直接描述需求）、提升执行效率 （分钟级操作秒级完成）、释放创新空间 （复杂场景的自动化长链路测试）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;随着 MCP 生态的完善，测试工程将逐步从「工具堆砌」走向「智能协作」，为研发效能带来质的突破。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_18"&gt;&lt;/span&gt; 
&lt;h1 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;七、感想&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;「我不是英雄，只是一个拿锤子的约德尔人」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;站在巨人的肩膀上总是能看的更高更远，追随技术大牛们的步伐，把 AI 应用到工作中、生活中。回想九年前初入测试行业时捧读的《Google 软件测试之道》，书中「人类智慧的最后一英尺」已然越来越近。重读了 2022 年在公司内部博客发表的《Google 软件测试之道：结合实践的总结》一文，发现仅仅过了 3 年，如果现在再去写，又是完全不一样的想法了，技术的发展已发生翻天覆地的变化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;此刻回望测试领域的演进曲线，愈发感到：「拿锤者」的价值不在于挥舞工具的姿态，而在于持续校准认知座标的能力 。当 AI 重构测试链路的每个环节时，唯以「锤者」的务实与「巨人」的视野双轨并行，方能在技术洪流中锚定价值支点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;加油吧！不忘初心，你我终将能抵达一个又一个「终点」！&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;1.CSS 闯关指南：从手写地狱到「类」积木之旅｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;2.从零实现模块级代码影响面分析方案｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;3.以细节诠释专业，用成长定义价值——对话@孟同学 ｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;4.得物可观测平台架构升级：基于 GreptimeDB 的全新监控体系实践&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;5.得物自研 DGraph4.0 推荐核心引擎升级之路&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#3e3e3e"&gt;文 / 阿凯&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#3e3e3e"&gt;关注得物技术，每周更新技术干货&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#3e3e3e"&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#3e3e3e"&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18499385</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18499385</guid>
      <pubDate>Sun, 07 Sep 2025 02:45:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>字节 Seedream 4.0 图像创作模型正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;字节跳动 Seed 团队正式发布新一代图像创作模型&amp;nbsp;Seedream 4.0。&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0909/103623_g73z_2720166.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Seedream 4.0&amp;nbsp;采用同一套构架实现文生图与通用编辑能力，融合常识和推理能力，相比前代模型 Seedream 3.0 和 SeedEdit 3.0，在多模态效果、速度和可用性上均实现显著突破。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/104012_jgFB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;使用同样 prompt，分别用 Seedream 3.0 和 Seedream 4.0 生成送货机器人的手绘草图，Seedream 4.0 在文字渲染和排版上更精致。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height="1084" src="https://static.oschina.net/uploads/space/2025/0909/103843_HlqK_2720166.jpg" width="1170" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1084" src="https://static.oschina.net/uploads/space/2025/0909/103856_vWOi_2720166.jpg" width="1170" referrerpolicy="no-referrer"&gt;&lt;br&gt; Seedream 4.0 主要亮点&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多模态玩法拓展：灵活支持文本、图像的组合输入，允许文生图、图生图、图像编辑、多图编辑、组图生成等创作模式，玩法创意多样。&lt;/li&gt; 
 &lt;li&gt;风格化美感提升：支持高度自由的艺术风格迁移，从巴洛克到赛博朋克风，风格百变，更可组合创造全新风格，美感突出。&lt;/li&gt; 
 &lt;li&gt;逻辑理解力增强：结合世界知识，提升了多模态输入理解，会「画」，更会先「想」，在涉及物理和时间约束、解谜填字、续写漫画等任务中，展现出推理生成能力。&lt;/li&gt; 
 &lt;li&gt;自适应与 4K 生成：可根据指令或参考图生成最佳比例图片，也支持用户自定义尺寸，最高分辨率从 2K 扩展至 4K 超高清。&lt;/li&gt; 
 &lt;li&gt;推理速度跃升：通过全新高效的架构设计，以及极致的蒸馏加速，DiT 生图的推理速度较 Seedream 3.0 提升超 10 倍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;目前，Seedream 4.0 已正式上线，可通过即梦、豆包、火山方舟等平台直接体验。&lt;/p&gt; 
&lt;p&gt;项目主页：https://seed.bytedance.com/seedream4_0&lt;/p&gt; 
&lt;p&gt;体验入口：&lt;/p&gt; 
&lt;p&gt;（1）即梦网页端-图片生成-上传参考图-选择图片 4.0 模型-输入 Prompt；&lt;br&gt; （2）豆包 App 对话框-AI 生图/生视频-上传参考图-输入 Prompt；&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371058</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371058</guid>
      <pubDate>Sun, 07 Sep 2025 02:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>知名 Android 第三方桌面 Nova Launcher 将停止维护</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;知名 Android 第三方桌面&lt;span&gt;启动器 Nova Launcher 创始人和原始开发者 Kevin Barry 宣布，他已经离开收购 Nova Launcher 的分析公司 Branch，并不再参与该项目。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1658" src="https://static.oschina.net/uploads/space/2025/0909/103239_Hnwx_2720166.png" width="1502" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://teslacoilapps.com/nova/solong.html&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据悉，Nova Launcher 由 Kevin Barry 带队开发，于 2022 年被 Branch 收购。当时，Branch 承诺不会将 Nova Launcher 变为订阅式付费、带有广告的普通 Android 桌面启动器。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d68adf6667956ed5f537c0b8b93ebbb0b93.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据 Kevin Barry 透露，其在过去几个月不断为 Nova Launcher 的开源进行付出。其表示，虽然 Branch 曾在收购 Nova Launcher 时承诺，其若离职，Nova Launcher 最终则会开源，但 Barry 现被要求停止开发 Nova Launcher 和终止进行开源工作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371057</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371057</guid>
      <pubDate>Sun, 07 Sep 2025 02:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义发布语音识别模型 Qwen3-ASR-Flash</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通义千问系列最新的语音识别模型 Qwen3-ASR-Flash 已正式发布，它基于 Qwen3 基座模型，经海量多模态数据以及千万⼩时规模的 ASR（自动语音识别）数据训练构建而成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101857_EGZg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 实现了⾼精度⾼鲁棒性的语⾳识别性能，⽀持 11 种语⾔和多种⼝⾳。与众不同的是，Qwen3-ASR-Flash⽀持⽤户以任意格式提供⽂本上下⽂，从⽽获得定制化的 ASR 结果，同时还⽀持歌声识别。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101903_kNR1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="664" src="https://static.oschina.net/uploads/space/2025/0909/101933_MOCR_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1395" src="https://static.oschina.net/uploads/space/2025/0909/101944_O6J2_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 单模型支持多种语言、方言和口音的精准转录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中文：包括普通话以及四川话、闽南语、吴语、粤语等主要方言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;英语：支持英式、美式及多种其他地区口音。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;其他支持语言：法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语和阿拉伯语。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Qwen3-ASR-Flash 的核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;领先的识别准确率：Qwen3-ASR-Flash 在多个中英文，多语种 benchmark 测试中表现最优。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;惊艳的歌声识别能力：支持歌唱识别,包括清唱与带 bgm 的整歌识别，实测错误率低于 8%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定制化识别：用户可以以任意格式 (如词汇表、段落或完整文档) 提供背景文本，模型能智能利用该上下文识别并匹配命名实体和其他关键术语，输出定制化的识别结果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语种识别与非人声拒识：模型能精确分辨语音的语种，自动过滤非语音片段，包括静音和背景噪声。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;鲁棒性：面对长难句、句中语言切换和重复词语等困难文本模式，以及在复杂的声学环境中，模型仍能保持高准确率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;体验方式：&lt;/p&gt; 
&lt;p&gt;ModelScope&lt;strong&gt;：&lt;/strong&gt;https://modelscope.cn/studios/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;HuggingFace:&amp;nbsp;https://huggingface.co/spaces/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;阿里云百炼 API&lt;strong&gt;：&lt;/strong&gt;https://bailian.console.aliyun.com/?tab=doc#/doc/?type=model&amp;amp;url=2979031&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371054</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371054</guid>
      <pubDate>Sun, 07 Sep 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Databricks 融资 10 亿美元，估值超 1000 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Databricks &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.databricks.com%2Fcompany%2Fnewsroom%2Fpress-releases%2Fdatabricks-surpasses-4b-revenue-run-rate-exceeding-1b-ai-revenue" target="_blank"&gt;宣布&lt;/a&gt;即将完成 10 亿美元的 K 轮融资，对应估值超过 1000 亿美元。此轮融资由 Andreessen Horowitz、Insight Partners、MGX、Thrive Capital 和 WCM Investment Management 共同领投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 表示，将利用这笔新资金加速其 AI 战略——扩展 Agent Bricks，推出全新 Lakebase 产品线，并推动全球增长。以及支持 Databricks 未来的 AI 收购，并深化 AI 研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="245" src="https://oscimg.oschina.net/oscnet/up-ba2a1094a2ce8345cb7359294aa377ea3d0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在公告中，Databricks 还透露了部分财务状况，披露其第二季度的年收入运行率超过 40 亿美元，同比增长 50%，并在过去 12 个月中实现了正自由现金流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该公司还表示，其人工智能产品的年营收运行率近期已超过 10 亿美元，净留存率超过 140%，目前有超过 650 家客户使用 Databricks 的产品，年收入超过 100 万美元。目前，共有超过 2 万家企业和组织在使用其软件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 联合创始人兼首席执行官 Ali Ghodsi 在公告中表示：「我们的团队正在构建企业未来几十年将依赖的数据和 AI 基础设施，从而取得这些成果。有了这笔新资金，我们将能够加快 Agent Bricks 的发展步伐，帮助各行各业的客户将其数据转化为生产级 AI 代理，并在创建新的 Lakebase 类别、为 AI 代理重塑数据库的过程中获得更大的发展动力。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 还指出，在前两个季度中，该公司已与微软、谷歌云、Anthropic、SAP 和 Palantir 建立或扩大了合作伙伴关系。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371049</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371049</guid>
      <pubDate>Sun, 07 Sep 2025 02:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥造物分享：流浪地球 550W（MOSS）小智 AI 生态中枢</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2186</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2186</guid>
      <pubDate>Sun, 07 Sep 2025 01:48:00 GMT</pubDate>
    </item>
    <item>
      <title>李彦宏颁发「百度最高奖」：心流团队获 100 万美元奖励</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，百度创始人李彦宏在内部活动上为技术团队颁发「百度最高奖」，获奖团队得到 100 万美元奖励，合人民币超 700 万元。「百度最高奖」已历经 15 届，语音识别、深度学习平台、大模型等大量 AI 技术均曾获奖，奖金总金额将近 4 亿元人民币。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-322339010570111171fc427256170f32b22.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据了解，「百度最高奖」于 2010 年 7 月设立，鼓励「小团队做出大事业」，是百度公司最高级别的奖项，给予每个获奖团队 100 万美元奖励。奖项评选需满足三项条件：项目意义重大；成果远超预期；团队足够小，必须是小于等于 10 人。&lt;/p&gt; 
&lt;p&gt;本次百度最高奖的获奖团队为「心流」团队。据介绍，「心流」团队率先实现了端到端的多模态内容理解与序列生成技术。李彦宏在颁奖时表示，到今天，模型发展已经非常接近临界点，很快就会有各种有价值的应用被创造出来，「我们生活在一个非常令人兴奋、非常令人期待的环境当中」。&lt;/p&gt; 
&lt;p&gt;李彦宏称，百度搜索已有近 70% 结果含有 AI 生成内容，且通过「百看」带来富媒体形式，是全球所有的搜索引擎当中改造最激进的，这也代表搜索引擎的未来。&lt;/p&gt; 
&lt;p&gt;同时，百度慧博星数字人已达到「以假乱真」的地步，「很多人看不出是数字人还是真人」；百度萝卜快跑已覆盖全球 16 座城市，代表着最新一代的无人驾驶技术。&lt;/p&gt; 
&lt;p&gt;颁奖典礼现场，李彦宏在谈及 AI 发展时指出，「AI 大模型发展到今天，其实已接近了临界点，很快就会有各种各样非常有价值的应用能够创造出来，我们正生活在一个非常令人兴奋、非常令人期待的市场环境当中。」&lt;/p&gt; 
&lt;p&gt;「我们所从事的每一项工作都代表着未来，我也希望大家和我一起去期待，去迎接、去奋斗出一个创新在 C 位的社会。」李彦宏表示。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370987</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370987</guid>
      <pubDate>Sat, 06 Sep 2025 11:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
