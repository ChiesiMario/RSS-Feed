<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 04 Aug 2025 12:40:47 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>中国开源 AI 社区 7 月高亮时刻回顾</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Hugging Face&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAdinaYakup%2Fstatus%2F1951020254269939964" target="_blank"&gt;发布&lt;/a&gt;了中国 AI 社区 7 月高亮时刻，回溯这一个月来令人眼花缭乱的开源浪潮。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1504" src="https://static.oschina.net/uploads/space/2025/0804/184858_39sJ_2720166.png" width="962" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;包括：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;✨ 另一个「DeepSeek 时刻」——Kimi K2&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;✨ Qwen 完全矩阵化- Instruct / Thinking / Coder 模型跨越 30B - 480B 参数规模&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;✨ 多模态浪潮：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;GLM-4.1V-Thinking: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Intern-S1: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wan 2.2 - Text +Image &amp;gt; video&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Skywork-R1V3: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Skywork-UniPic: Text &amp;gt; Image / Image &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Tar-7B: Any-to-Any&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ming-Lite-Omni-1.5: Any-to-Any&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Step3: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HunyuanWorld-1: Image &amp;gt; 3D&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ThinkSound: Video &amp;gt; Audio&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Neta-Lumina: Text &amp;gt; Image&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;✨ 轻量级、可部署的模型&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SmallThinker runs on 1GB RAM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;✨ Agentic 编程成为主流&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Qwen3-Coder: fully spec'd tool calling&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GLM-4.5: browser agents, IDE assistant&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen3 WebDev demo: text-to-frontend code&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;✨特定领域和实用的模型/工具/数据集&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Science one S1: Scientific model&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Agentar DeepFinance: Finance dataset&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ObjectClear: Interactive Vision Tool&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen3 MT Demo: Machine Translation Tool&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其中回顾的 7 月 31 个亮眼开源模型、1 个框架、1 个数据集，来自 16 家企业、高校或研究机构：&lt;/p&gt; 
&lt;p&gt;阿里（9 个）、月之暗面（2 个）、智谱（2 个）、阶跃星辰（1 个）、字节跳动（2 个）、昆仑万维（2 个）、智源研究院（1 个）、中国电信人工智能研究院（1 个）、蚂蚁集团（4 个）、快手（1 个）、捏 Ta（1 个）、磐石（3 个）、上海交通大学（1 个）、腾讯（1 个）、上海人工智能实验室（1 个）、复旦大学（1 个）。&lt;/p&gt; 
&lt;p&gt;1、阿里（9 个）：编程模型 Qwen3-Coder-30B-A3B-Instruct、Qwen3-Coder-480B-A35B-Instruct，深度思考模型 Qwen3-30B-A3B-Thinking-2507、Qwen3-235B-A22B-Thinking-2507，基础模型 Qwen3-235B-A22B-Instruct-2507、Qwen3-30B-A3B-Instruct-2507，CoT 音频模型 ThinkSound，统一视频生成模型 Wan2.2-TI2V-5B，文生视频 Wan2.2-T2V-A14B。&lt;br&gt; 2、月之暗面（2 个）：MoE 基础模型 Kimi-K2-Base，与 Numina 团队联合研发的数学定理证明模型 Kimina-Prover-72B。&lt;br&gt; 3、智谱（2 个）：多模态大模型 GLM-4.1V-9B-Thinking，基础模型 GLM-4.5。&lt;br&gt; 4、阶跃星辰（1 个）：基础模型 Step3。&lt;br&gt; 5、字节跳动（2 个）：智能体模型 Tar-7B，多语言翻译模型 Seed-X-Instruct-7B。&lt;br&gt; 6、昆仑万维（2 个）：多模态推理大模型 Skywork-R1V3-38B，多模态统一模型 Skywork-UniPic-1.5B。&lt;br&gt; 7、智源研究院（1 个）：文生配音视频框架 MTVCraft。&lt;br&gt; 8、中国电信人工智能研究院（1 个）：AI-Flow-Ruyi-7B-Preview0704。&lt;br&gt; 9、蚂蚁集团（4 个）：多模态推理模型 M2-Reasoning，多模态大模型 Ming-Lite-Omni-1.5，金融训练数据集 Agentar-DeepFinance-100K，交互式深度推理模型 KAG-Thinker-en-ch-7b-instruct。&lt;br&gt; 10、快手（1 个）：自适应思考模型 KAT-V1-40B。&lt;br&gt; 11、捏 Ta（1 个）：动漫风格图像生成模型 Neta-Lumina。&lt;br&gt; 12、磐石（3 个）：科学基础大模型 S1-Base-671B、S1-Base-8B、S1-Base-32B。&lt;br&gt; 13、上海交通大学（1 个）：端侧原生大模型 SmallThinker-4BA0.6B-Instruct。&lt;br&gt; 14、腾讯（1 个）：3D 世界生成模型 HunyuanWorld-1。&lt;br&gt; 15、上海人工智能实验室（1 个）：科学多模态大模型 Intern-S1。&lt;br&gt; 16、复旦大学（1 个）：语音生成模型 MOSS-TTSD-v0.5。&lt;/p&gt; 
&lt;p&gt;更多内容查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fjuly-2025-open-works-from-the-chinese-community-686586f1a8840797e477ae5a" target="_blank"&gt;https://huggingface.co/collections/zh-ai-community/july-2025-open-works-from-the-chinese-community-686586f1a8840797e477ae5a&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364138</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364138</guid>
      <pubDate>Sun, 03 Aug 2025 10:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>应用多点开花，AI 大模型从「炫技」走向「实干」</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;京东宣布旗下言犀大模型品牌全新升级为 JoyAI，并推出行业首个 100% 开源的企业级智能体 JoyAgent；由钉钉 AI 平台训练的垂类妇科大模型通过主任医师考试；网易灵动发布行业首个工程机械具身智能模型「灵掘」……近期，国产大模型频频「上新」，并不断刷新应用「进度条」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;而在近日举行的 2025 世界人工智能大会（WAIC）期间，AI 大模型也是格外引人关注。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在物流领域，仓内无人机、无人车等智能物流设施惊艳亮相；工业场景中，AR 眼镜可以辅助产业工人精准质检并推荐维修方案；零售体验台前，系统可以自动个性化推荐商品、瞬间生成海量商品广告素材……位于上海世博展览馆一号馆的京东展区内，展示了全新升级的 JoyAI 大模型深度应用的诸多场景。与此同时，京东云还正式开源 JoyAgent 智能体。作为行业首个 100% 开源的企业级智能体，JoyAgent 依托多智能体协同引擎实现高效协作，并融合大小模型优势，打通 AI 落地「最后一公里」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年以来，国内大模型迭代速度提升，加快赋能千行百业。其中，不少企业着力打造垂类大模型，推动大模型快速走向「实干」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;日前，壹生检康（杭州）生命科技有限公司研发的「豆蔻妇科大模型」成功通过国家妇产科衞生高级职称（正高）笔试考试。钉钉 CTO 朱鸿介绍，豆蔻妇科大模型是钉钉 AI 平台上诞生的第一个专业垂类大模型，双方团队只经过短短一个多月的协作，就将模型准确率提升到了 90.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「通过正高职称考试，意味着该模型已具备主任级医师的专业判断力。」壹生检康创始人王强宇表示，大模型的核心价值在于，为女性用户提供居家自诊断支持，实现「术前分流」与「院外健康管理」；针对无需就诊的情况提供科普指导与生活建议；为医疗、医美等行业机构提供专业支撑，同时可通过机构的数据训练专科模型，提升医疗效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「这一突破为 AI 在妇产科临床决策辅助、循证医学研究、患者健康教育、医学生学习考试等场景的深度应用开辟了新路径。」浙江大学医学院附属妇产科医院妇科周博士表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据悉，随着技术的不断完善和推广，豆蔻妇科大模型不仅有望在更多医疗场景中发挥重要作用，还将进一步优化医疗资源配置。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在工业领域，垂类模型也有不少突破性进展。WAIC 期间，网易旗下工程机械智能化品牌网易灵动推出全球首个专为露天矿山挖掘机装车场景打造的具身智能模型——「灵掘」。在网易灵动展位，观众通过智能座舱可以实时体验内蒙古矿山的无人挖掘机自动装车功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在内蒙古霍林河北露天煤矿的严苛环境中，「灵掘」单机装车效率已达人工的 80%，近 70% 的作业时间无需人为干预，成功适配极寒、高粉尘等严苛环境与多型号矿卡。「这项技术让 AI 成为矿山的‘铁臂战友’，装车 3 精度和连续性远超预期，为行业安全与效率提升开辟了新路径。」内蒙古某露天煤矿代表在实测后评价道。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据了解，网易灵动将首次开源「灵掘」数据集，并向全行业发起「2027 产业协同计划」。该计划将联合徐工、三一、山河智能等主机厂及各露天煤矿企业，通过技术共享平台推动联合研发、场景共创与标准制定。作为「灵掘」技术基石的端到端训练框架——「机械智心」，已支撑「灵掘」在矿山场景的成功实践，并快速向港口清舱、混凝土拌合站、地销煤等十余个场景迁移，未来将延伸至农业、智能制造等领域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;数据显示，中国目前已发布 1509 个大模型，在全球已发布的 3755 个大模型中数量位居首位。业内指出，AI 大模型正从「炫技」走向「实干」，2025 年成为大模型应用全面落地的关键转折点。这场由技术驱动、场景牵引的深度应用革命，正在重塑千行百业的生产力图谱。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364136</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364136</guid>
      <pubDate>Sun, 03 Aug 2025 10:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Taro on HarmonyOS 技术架构深度解析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;2025 年 6 月，在华为开发者大会 2025 开发者场景技术共建分论坛，本文作者进行了《京东 Taro 框架鸿蒙版本正式开源，助力鸿蒙版三方应用开发》专题演讲。期间阐述了 Taro on HarmonyOS 的技术实现方案、核心优化策略，以及开源版本的主要特性。&lt;/p&gt; 
 &lt;p&gt;本文将详细介绍 Taro on HarmonyOS 的技术架构、性能优化实践和开源进展，分享我们在跨端开发中遇到的问题和解决思路。&lt;/p&gt; 
 &lt;p&gt;期待更多人可以参与开源共建，一起交流讨论！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;回顾 Taro 的发展历程，从 2018 年 6 月开源至今，作为开放式的跨端跨框架解决方案在众多热心开源贡献者的支持下，从初出茅庐逐步迈向成熟。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_background" src="https://oscimg.oschina.net/oscnet//e99ecb394150ea01d8d0df9310c36e30.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从最初仅支持面向编译时的小程序端解决方案，到如今拥有支持多种前端框架和 UI 库的强大能力；从单一的构建工具，到通过开放生态为开发者提供 &lt;code&gt;Webpack&lt;/code&gt;、&lt;code&gt;Vite&lt;/code&gt;、&lt;code&gt;ESBuild&lt;/code&gt; 等丰富的工具选择，让团队能够定制专属的研发流程；从专注小程序开发，到覆盖各大小程序平台以及 Web、iOS、Android、HarmonyOS 等移动端场景——Taro 的每一步成长都离不开社区的力量。&lt;/p&gt; 
&lt;p&gt;这些年来，我们在 GitHub 上收获了 &lt;strong&gt;36,000+ star&lt;/strong&gt; 和&lt;strong&gt;近 5,000 fork&lt;/strong&gt;，更重要的是得到了众多企业团队和个人开发者贡献的宝贵功能特性。在此，我们要向所有支持 Taro 发展的朋友们表示衷心的感谢！&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;技术架构演进&lt;/h3&gt; 
&lt;p&gt;说到 &lt;code&gt;HarmonyOS&lt;/code&gt;，Taro 从 2022 年开始布局鸿蒙适配，走过了一条持续演进的技术路径。最初我们推出了 &lt;code&gt;JSUI&lt;/code&gt; 版本的端平台插件，为鸿蒙支持打下基础；2023 年开源了 &lt;code&gt;ETS&lt;/code&gt; 版本的端平台插件，大幅提升了开发体验和业务性能；而在最近释出的 4.1 版本中，&lt;code&gt;C-API&lt;/code&gt; 版本的 Harmony 端平台插件也正式发布了，这标志着 Taro 鸿蒙支持能力的重要突破。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_on_harmonyos" src="https://oscimg.oschina.net/oscnet//b251d41c504ba0e92bd0ce7994398d6f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，我们仍在持续优化 Harmony C-API 插件的性能表现。团队正在推进多线程以及更多版本特性的内部验证，期待在验证完成后能够将其开源，为开发者在鸿蒙端带来更优秀的研发体验。&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;面向多端研发&lt;/h3&gt; 
&lt;p&gt;面向多端的复杂场景，从来都不是一件容易的事情。在传统的多端开发中，开发者往往需要面对各端语法标准不统一、组件和 API 接口各异、开发环境复杂多样等诸多挑战。当业务逻辑需要调整时，开发者必须在多个平台上重复实现相同功能，代码复用率极低，维护工作量成倍增长。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_cross_platform" src="https://oscimg.oschina.net/oscnet//35b595f2278f17a13dd02df5716f8266.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如图所示，Taro 现已成功在 HarmonyOS 平台上实现了与 Web 端、小程序及其他平台一致的 UI 呈现效果。&lt;/p&gt; 
&lt;p&gt;基于 Taro 跨端研发标准推进业务实现，开发者只需编写一套代码，就能够在多个平台上获得统一的用户体验，最大限度地节省多端业务的研发成本，让团队能够将更多精力投入到业务创新上。&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;京东鸿蒙版&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd" src="https://oscimg.oschina.net/oscnet//473a9f8879d8cddefdbac83f93802a3a.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以京东鸿蒙版本为例，基于 Taro on HarmonyOS 解决方案，成功在研发效率与应用性能之间达成了理想平衡，其性能表现和稳定性均位居行业前列。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_jd_detail" src="https://oscimg.oschina.net/oscnet//e92b9ee175f09086507c7a5526832104.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对于商品详情页等高复杂度、高数据量的核心业务场景，该方案展现出强大的技术适配能力。仅是在单线程 C-API 架构的支持下，这些重载业务场景的运行性能已达到与原生应用相当的水准，充分验证了跨端技术在复杂场景下的可行性。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;技术架构&lt;/h2&gt; 
&lt;p&gt;为了达成这一目标，我们需要在技术架构层面进行深度优化。&lt;/p&gt; 
&lt;p&gt;Taro 在各平台的适配逻辑保持高度一致性。开发者通过统一的 &lt;code&gt;DSL&lt;/code&gt;以及标准化的组件和 API 库即可完成全部代码开发，样式规范完全遵循 &lt;code&gt;W3C&lt;/code&gt; 标准，使前端开发者能够以极低的学习成本快速上手。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_2025" src="https://oscimg.oschina.net/oscnet//ee72a5129bf8027a11211bcd29c13fa8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在编译层面，Taro 通过 CLI 工具和插件系统实现各端的差异化处理。各个端平台插件可以在编译核心中选择基于 &lt;code&gt;Webpack&lt;/code&gt;、&lt;code&gt;Vite&lt;/code&gt; 或 &lt;code&gt;Metro&lt;/code&gt; 为基础的编译流程，将开发者的源代码高效转换为各目标平台的可执行代码。&lt;/p&gt; 
&lt;p&gt;在运行时中，通过集成语法适配器、&lt;code&gt;DOM&lt;/code&gt;、&lt;code&gt;BOM&lt;/code&gt; 模拟实现以及其他核心模块，确保开发者项目能够在 HarmonyOS 等各类平台上稳定运行，真正实现一码多端的开发愿景。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;渲染层适配&lt;/h3&gt; 
&lt;p&gt;尽管 Taro 在 HarmonyOS 平台的插件架构历经多轮重大版本升级，但其核心架构设计依旧可从以下几个维度来理解：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmonyos_rendering" src="https://oscimg.oschina.net/oscnet//73d229191f933afdedd47c60cc69d5cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;代码转换流程&lt;/strong&gt;：从开发者编写的 &lt;code&gt;React&lt;/code&gt; 代码出发，通过与 &lt;code&gt;React Reconciler&lt;/code&gt; 的深度集成，系统构建出完整的虚拟节点树。随后，运行时环境通过模拟的 &lt;code&gt;DOM&lt;/code&gt; 和 &lt;code&gt;BOM&lt;/code&gt; API，实现 &lt;code&gt;React&lt;/code&gt; 节点树与 Taro 内部节点树的精确映射。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;平台适配实现&lt;/strong&gt;：结合标准化的组件库和 API 库，系统将抽象的节点结构转换为 HarmonyOS 平台的原生原子组件，最终构建出完整的 &lt;code&gt;ArkUI&lt;/code&gt; 渲染树，并呈现在用户界面上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;扩展能力支持&lt;/strong&gt;：除了核心渲染流程外，运行时还集成了布局计算、事件处理、动画效果等关键模块，并持续接入更多 HarmonyOS 平台特有能力，为开发者提供完整的跨平台开发体验。&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;架构方案迭代&lt;/h3&gt; 
&lt;p&gt;在技术架构层面，&lt;code&gt;ETS&lt;/code&gt; 方案与 &lt;code&gt;C-API&lt;/code&gt; 方案本质上都遵循着相同的设计理念。两者均构建了一套完整的三层节点树体系：应用层的 &lt;code&gt;React&lt;/code&gt; 节点树首先转换为中间层的 Taro 节点树，随后进一步映射到底层的 &lt;code&gt;ArkUI&lt;/code&gt; 节点树，最终实现界面的完整渲染。&lt;/p&gt; 
&lt;p&gt;然而，尽管在宏观架构上两种方案展现出高度的相似性，我们仍然坚定地推进从 &lt;code&gt;ETS&lt;/code&gt; 向 &lt;code&gt;C-API&lt;/code&gt; 的技术转型。这一决策的背后，是团队对性能极致追求的不懈努力。在移动应用开发的激烈竞争中，每一毫秒的性能提升都可能成为用户体验的关键差异点，而 C-API 方案正是在这样的背景下应运而生的技术选择。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmonyos_architecture" src="https://oscimg.oschina.net/oscnet//d56195a048781803635354a4f73e5b0d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;C-API&lt;/code&gt; 方案带来的性能提升是全方位的。在节点操作层面，我们彻底摒弃了传统的声明式递归构建模式，转而采用更加灵活的实现方式，这为底层节点 API 的深度优化创造了前所未有的空间。同时，通过引入指令式节点操作机制，不同节点树之间的数据交互效率得到了显著改善，原本复杂的跨树通信变得更加高效流畅。&lt;/p&gt; 
&lt;p&gt;更为重要的是，我们将样式处理、布局计算、事件管理等核心功能模块全面下沉至 &lt;code&gt;C++&lt;/code&gt; 原生层。这一架构调整不仅大幅减少了跨语言调用的频次和开销，更从根本上提升了系统的执行效率。通过这些多维度的优化措施，整个应用的性能表现实现了质的飞跃。&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;跨端研发标准&lt;/h3&gt; 
&lt;p&gt;在适配鸿蒙和其他各端能力的基础上，Taro 正在构建一套完整的跨端研发标准体系。这套标准不仅能够最大限度地节约不同端之间的适配成本，更重要的是能够充分兼容现有的前端生态系统，让团队多年积累的组件库、工具链和技术沉淀得以无缝复用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_cross_standard" src="https://oscimg.oschina.net/oscnet//2e9017e41ce210f8f74ed721a42b25bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，以 &lt;code&gt;React&lt;/code&gt; 作为 UI 基础库，该标准已涵盖了 &lt;code&gt;View&lt;/code&gt;、&lt;code&gt;Text&lt;/code&gt; 等 26 个常用组件和网络请求、图片等 88 个常用 API。在样式规范方面，我们遵循 W3C 标准实现了包含 93 条常用规范的样式子集。与此同时，我们正在持续努力扩充这套标准体系，不断增加新的组件类型、API 接口和样式规范，以满足日益复杂的业务场景需求。&lt;/p&gt; 
&lt;p&gt;更为关键的是，这套不断完善的标准体系具备良好的扩展性和兼容性，能够与团队现有的 UI 组件库、业务组件以及各类前端工具库形成有机整合。我们致力于通过标准的持续演进，确保开发团队能够在跨端开发中充分发挥既有技术资产的价值，避免重复建设带来的资源浪费，同时为未来更多端侧适配需求预留充足的扩展空间。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_style" src="https://oscimg.oschina.net/oscnet//ba286db72609455a07cb982564d36146.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为实现跨平台开发的一致性标准，我们设计了 &lt;code&gt;C++&lt;/code&gt; 底层样式处理架构。该架构整合了包括 &lt;code&gt;Yoga&lt;/code&gt; 这类成熟布局引擎，构建统一的布局计算体系，保障各端样式渲染的视觉一致性。通过将样式计算逻辑完全迁移至 &lt;code&gt;C-API&lt;/code&gt; 底层，系统获得了显著的性能优化潜力——不仅消除了对主渲染线程和业务逻辑的性能干扰，还通过 &lt;code&gt;C++&lt;/code&gt; 的高效执行特性实现了跨端样式处理的统一化管理，从根本上提升了整体渲染效率。&lt;/p&gt; 
&lt;p&gt;针对鸿蒙端的特殊需求，我们在编译阶段引入了创新的预处理机制。通过在编译流程中的 &lt;code&gt;Rust&lt;/code&gt; 插件集成 &lt;code&gt;lightingCSS&lt;/code&gt;，我们能够将标准样式预先转换为鸿蒙平台可以识别的样式，进一步节省运行时运算的负担。这一机制不仅实现了 W3C 标准属性到各端专用单位和属性值的智能转换，更为跨端样式的统一管理奠定了坚实的底层基础。&lt;/p&gt; 
&lt;p&gt;基于这套完善的 &lt;code&gt;C++&lt;/code&gt; 样式处理体系，UI 库和业务团队能够轻松应对各种复杂场景的适配需求。无论是折叠屏的多形态展示、关怀模式的无障碍优化，还是暗黑模式的主题切换，都可以通过灵活的样式选择器机制实现精准控制。同时，动画效果和过渡转场也能够通过高效的样式更新和节点刷新机制，呈现出极为流畅的用户体验。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;方案特性&lt;/h2&gt; 
&lt;p&gt;基于此架构，Taro on HarmonyOS 方案积累了丰富的核心特性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;研发效能层面&lt;/strong&gt;：通过兼容 React 生态体系和 W3C 样式规范，开发者能够充分利用前端成熟的工具链和生态资源，高效完成业务功能迭代与开发调试工作，完善鸿蒙端的开发体验。同时，开发者编写的样式代码可在鸿蒙、小程序和 Web 端无缝复用，实现真正的"一次编写，多端运行"。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生态扩展层面&lt;/strong&gt;：提供灵活的组件和 API 扩展机制，支持业务团队根据实际需求定制运行时环境。更重要的是，通过跨端统一的原生混合调用方案，Taro C++ 模块与 ArkTS 原生模块可实现双向互调，为团队间协作提供了更多可能性，有效避免重复开发，提升整体研发效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_tech" src="https://oscimg.oschina.net/oscnet//2f6fbb8105c9d720737b1c639d96f421.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;性能体验&lt;/h3&gt; 
&lt;p&gt;在 C-API 方案中，我们围绕卓越性能体验实现了多项核心特性：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;运行时性能优化&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;将 DOM Tree、事件处理、样式计算等高频操作模块完全下沉至 C++ 层，显著提升运行时执行效率。通过底层优化，减少了 JavaScript 与原生层之间的频繁通信开销，避免了数据序列化/反序列化的性能损耗。同时，C++ 层的内存管理更加高效，能够更好地控制对象生命周期，减少内存碎片，为复杂应用场景提供更稳定的性能表现。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高阶组件能力&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;img alt="taro_harmony_list" src="https://oscimg.oschina.net/oscnet//3edfae841c90d8ab8bb6b83a5fd4701b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;基于 HarmonyOS 原生的 List、WaterFlow 等组件特性，深度定制实现虚拟列表、瀑布流等高性能组件，充分发挥系统级优势。&lt;/p&gt; &lt;p&gt;这些高阶组件不仅继承了系统组件的原生性能，还针对前端开发习惯进行了接口封装，支持动态数据加载、智能缓存策略、滚动性能优化等特性。开发者可以像使用传统前端组件一样轻松实现大数据量的列表展示，无需关心底层的复杂优化逻辑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;图片处理模块&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;构建专门服务于样式渲染、背景绘制、Image 组件的图片处理系统，实现更优秀的图片加载性能和内存管理。该模块集成了多级缓存机制，支持内存缓存、磁盘缓存和网络缓存的智能调度，大幅减少重复加载时间。&lt;/p&gt; &lt;p&gt;&lt;img alt="jd_image" src="https://oscimg.oschina.net/oscnet//e1c0bf07e61ef7b88ac2337b49f4d197.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;同时提供了图片压缩、格式转换、尺寸适配等功能，能够根据设备性能和网络状况自动选择最优的图片处理策略，有效降低内存占用和网络带宽消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文字与绘图支持&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;通过 PixelMap 技术为文字组件提供丰富的字体属性和渲染能力，同时为 Canvas 组件及相关 API 提供底层支持，覆盖分享海报生成等复杂业务绘制场景。文字渲染支持多种字体格式、文字效果（阴影、描边、渐变等）和排版布局，满足不同设计需求。&lt;/p&gt; &lt;p&gt;&lt;img alt="taro_harmony_shared" src="https://oscimg.oschina.net/oscnet//443eb38b5216494391fcaf0ddc35e649.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;Canvas 绘图能力则支持路径绘制、图形变换、滤镜效果等高级功能，为数据可视化、游戏开发、创意设计等场景提供强大的图形处理能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;视频播放能力&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;基于 AVPlayer 重构 Video 组件和相关 API 实现，在 C-API 层直接接入，减少调用链路，为业务提供更灵活的视频适配方案。新的视频播放架构支持多种视频格式和编码标准，提供了精确的播放控制、实时进度反馈、音视频同步等核心功能。&lt;/p&gt; &lt;p&gt;&lt;img alt="taro_harmony_video" src="https://oscimg.oschina.net/oscnet//9f5a8a4b269af1f5b7354aaf25169c9e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;总结展望&lt;/h2&gt; 
&lt;p&gt;Taro 在 HarmonyOS 平台的深度适配，旨在为全场景应用开发开辟新的技术路径。通过构建完善的鸿蒙端能力体系，我们致力于为更广泛的业务场景提供技术支撑，推动跨平台开发在鸿蒙生态中的创新应用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd_all" src="https://oscimg.oschina.net/oscnet//61ac5ecfa77950e92954c28304b10de7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在实际应用中，Taro 成功支撑了京东鸿蒙 APP 的商业化落地。该应用的首页、搜索推荐以及核心购物流程等关键业务模块均基于 Taro 技术栈开发，在确保快速迭代交付的同时，实现了业界领先的性能表现和系统稳定性。应用上线后迅速在华为应用市场购物类别中登顶，充分验证了技术方案的商业价值。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;生态建设与合作拓展&lt;/h3&gt; 
&lt;p&gt;基于成功实践的示范效应，更多京东生态应用正在加速鸿蒙化进程，包括一号会员店、七鲜等重要业务线的鸿蒙版本已上架鸿蒙应用市场或者进入开发阶段。同时，我们的技术方案也获得了外部合作伙伴的认可，58 同城、朴朴超市等知名企业均选择采用 Taro 相关的鸿蒙开发解决方案，共同构建更加繁荣的鸿蒙应用生态。&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;未来展望&lt;/h3&gt; 
&lt;p&gt;我们将持续深化开源战略，在内部版本充分验证后，逐步向社区开放多线程等更多核心技术特性。同时不断扩展跨端标准覆盖范围，让更多组件和 API 实现跨平台一致性，为开发者提供更优质的开发体验和更完善的调试工具链，也为动态化能力构建更坚实的技术基础。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd_devtools" src="https://oscimg.oschina.net/oscnet//2aaf8134cf5e8255e8d878eacb2805a8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在性能优化方面，我们将持续推进更多核心模块向 C++ 层迁移，包括 React 的 C++ 版本实现和高频 API 运行时模块优化，同时积极借鉴节点树扁平化等社区验证的优秀实践。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd_c_react" src="https://oscimg.oschina.net/oscnet//21bfd7a53be846ef5a0b4bc0437f6180.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;虽然 Taro on HarmonyOS 的 C-API 版本插件开源时间不长，但已经吸引了众多开发者的积极参与。我们期待更多技术同仁能够加入这个充满活力的开源生态，共同推动 Taro on HarmonyOS 方案的不断完善，在开源共建的道路上续写跨端开发的新篇章。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18686949</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18686949</guid>
      <pubDate>Sun, 03 Aug 2025 10:20:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>我国连续 12 年保持全球最大工业机器人市场</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;2024 年，我国工业机器人市场销量达 30.2 万套，连续 12 年保持全球最大工业机器人市场。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中国电子学会理事长徐晓兰介绍，自 2015 年首届世界机器人大会在北京召开以来，我国机器人产业实现一系列科技创新突破。2024 年，我国机器人专利申请量占全球机器人专利申请总量的 2/3。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;产业发展方面，我国是全球第一大机器人生产国，工业机器人产量由 2015 年的 3.3 万套增长至 2024 年的 55.6 万套，服务机器人产量为 1051.9 万套，同比增长 34.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;北京、上海分别成立国家地方共建具身智能机器人创新中心、国家地方共建人形机器人创新中心，浙江、安徽、湖北、广东、四川等地均成立省级机器人创新中心，集聚区域产业优势力量，推动技术共享与联合攻关。机器人整机企业充分发挥引领作用，带动产业链上下游零部件企业配套发展，形成大中小协同、上下游联动的良好生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;应用场景方面，工业机器人已应用于国民经济 71 个行业大类、236 个行业中类，制造业机器人密度已跃升至全球第三位。服务机器人在家用服务、仓储物流、商用服务、养老助残、医疗康复等领域的渗透率显著提升。国际数据公司数据显示，2024 年，中国厂商在全球商用服务机器人市场中占据主导地位，出货量占比高达 84.7%，规模优势明显。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「人形机器人是人工智能与机器人深度融合的产物，是机器人的高阶形态和具身智能的良好载体。」徐晓兰表示，人形机器人有望在家政服务、生产制造、仓储物流、边防海防、教育医疗等场景发挥作用，拉动新消费、催生新产业、扩大新就业，推动新质生产力加快发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 世界机器人大会将于 8 月 8 日至 12 日在北京经济技术开发区北人亦创国际会展中心举办。大会期间，200 余家国内外优秀机器人企业的 1500 余件展品将亮相，企业数量较去年增长 25%。其中，首发新品 100 余款，数量是去年的近 2 倍。（人民日报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364133</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364133</guid>
      <pubDate>Sun, 03 Aug 2025 10:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>苹果组建新 AI 团队「AKI」，打造类似 ChatGPT 的 AI 搜索工具</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;彭博社记者&amp;nbsp;Mark Gurman &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2025-08-03%2Fapple-s-chatgpt-rival-from-new-answers-team-iphone-17-spotted-in-the-wild-mdvmqs6g" target="_blank"&gt;报道称&lt;/a&gt;，苹果正开发一款类似 ChatGPT、能够直接回答用户广泛问题的搜索引擎。&lt;/p&gt; 
&lt;p&gt;该项目由一个新成立的&lt;strong&gt;「Answers, Knowledge, and Information，简称 AKI」&lt;/strong&gt;（答案、知识与信息）内部团队负责。领导该新项目的是高级总监 Robby Walker，他曾负责 Siri 的研发工作。虽然该项目仍处于早期阶段，但该团队正在构建所谓的 「答案引擎」—— 一个能够抓取网页以回应通用知识问题的系统。目前正在探索开发一款独立应用，同时也在搭建新的后端基础设施，旨在为未来版本的 Siri、Spotlight 和 Safari 提供搜索功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/175856_2Ke0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;苹果最近已在其招聘网站上为该团队发布了职位空缺，他们正在为该团队招募具有搜索算法和引擎开发经验的工程师。招聘信息称：「我们的工作为苹果一些最具标志性的产品（包括 Siri、Spotlight、Safari、Messages、Lookup 等）提供直观的信息体验。加入我们，共同塑造全球与信息连接方式的未来！」&lt;/p&gt; 
&lt;p&gt;此举标志着苹果在 AI 上的重大转变，因为此前苹果高管曾多次表示，无意开发自有聊天机器人，而是选择集成第三方服务。&lt;/p&gt; 
&lt;p&gt;目前，Siri 在处理复杂问题时表现不佳，苹果与谷歌之间价值约 200 亿美元的默认搜索引擎协议正面临美国司法部的严格审查，苹果可能因此感到有必要开发自主引擎。不过与此同时，苹果正面临 AI 人才流失问题，负责开发大语言模型的团队在一个月内已有四名关键研究员离职，转投竞争对手 Meta。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364130</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364130</guid>
      <pubDate>Sun, 03 Aug 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程工具 Roo Code 支持通过对话历史提供更智能的建议</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;AI 编程助手 Roo Code 发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.roocode.com%2Fupdate-notes%2Fv3.25.4" target="_blank"&gt;v3.25.4&lt;/a&gt;更新，支持基于最近 10 条消息作为上下文来增强其代码建议，从而提供更智能、更少幻觉的响应。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/174428_JrSy_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以完全控制 API 路由和历史记录的开关，以平衡上下文和隐私需求。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Roo Code 是一个 AI 驱动的开源自主编码 Agent，它存在于您的编辑器中。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/193229_CZTb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;功能&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;用自然语言沟通&lt;/li&gt; 
 &lt;li&gt;直接在您的工作区读写文件&lt;/li&gt; 
 &lt;li&gt;运行终端命令&lt;/li&gt; 
 &lt;li&gt;自动化浏览器操作&lt;/li&gt; 
 &lt;li&gt;与任何 OpenAI 兼容或自定义的 API / 模型集成&lt;/li&gt; 
 &lt;li&gt;通过&lt;strong&gt;自定义模式&lt;/strong&gt;调整其 "个性" 和能力&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364125</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364125</guid>
      <pubDate>Sun, 03 Aug 2025 09:46:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>辩证看待 KubeSphere 闭源删库，前核心团队成员的解读</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;文章来源：微信公众号 Cloud Native Fun&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;作者：周鹏飞&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;2025 年 8 月 1 日，青云科技在 KubeSphere 社区发布消息，宣布暂停 KubeSphere 的开源版本支持（&lt;/strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues%2F6550" target="_blank"&gt;&lt;u&gt;https://github.com/kubesphere/kubesphere/issues/6550&lt;/u&gt;&lt;/a&gt;）。这一消息如同投下一颗重磅炸弹，引发了全球开源社区的强烈反响。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;作为前青云科技的高级社区经理、KubeSphere 项目的前核心维护者，我曾参与这个项目从零到一的过程。在这篇文章中，我站在一个长期开源从业者的角度，尝试用辩证的视角去还原事件背后更深层的逻辑，并回答一些几个普遍关注的问题。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;KubeSphere 自 2018 年 4 月份开始在 GItHub 写下第一行代码并开源，至今七年多的时间，曾被全球数以万计的大小企业所使用，与众多知名开源项目集成，被全球各大云厂商认可和合作，不可否认的事实是，KubeSphere 是一个非常优秀的开源项目和云原生产品，项目创始人 Ray 也是一个很有开源情怀的人。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我曾在 2018-2022 年担任青云科技的高级社区经理，在全球不遗余力地推广 KubeSphere，&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4MDcyOTc2Nw%3D%3D%26mid%3D2247485443%26idx%3D1%26sn%3D0d66089771b9ea44006666eeb4471af8%26scene%3D21%23wechat_redirect" target="_blank"&gt;从零到一构建了活跃多元化的开源社区&lt;/a&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;，创作了官网、用户文档、博客、视频教程，在全国各大城市办过几十场活动，并将 KubeSphere 孵化的 3 个子项目捐给 CNCF 基金会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-a83df931bfba4277ce01f9eb46797ef1d7d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;2020-2022 年几乎是 KubeSphere 在全球飞速发展的三年，我记得曾经几乎每天都能看到新的用户增长和使用反馈，以及来自全球不同公司的贡献者参与。说实话，那曾是我最有工作成就感和成长飞快的时光，在开源社区认识了很多优秀的开发者，也给公司带来过一些商业机会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-49bfe588b4f1c2be1102d667fadac349a14.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;一次不留余地的急转弯&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;令人遗憾的是，这次青云的决定来了个 180 度急转弯，不仅将前端代码闭源，还删除所有已发布的文档和安装镜像，彻底将 KubeSphere 推向了深渊，在全球开源社区引发了巨大的舆论和开源信任危机。巧合的是，消息发布当天正是项目创始人 Ray 宣布离职的时间点。我不知道这是否是有意为之，但属实是不讲「情面」的一个选择，也引发了国内外很多开发者对「中国式开源」的发问和深层焦虑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-1e8382254228e4b54d873e3631e7c2654cd.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;墙倒众人推，并不能让中国开源更好&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;事实上，我刚开始看到消息时也有些情绪化，因为 「KubeSphere 闭源删库」后，互联网舆论呈现了墙倒众人推的趋势，很多博主的文章以及吃瓜群众的评论，站在制高点一味地批判和指责商业公司「闭源」的行为，诋毁该开源项目的价值，甚至还有很多人直接全盘否定 「中国开源」 的努力和价值。这些带有偏见的观点，很容易误导大众的认知和情绪，并且不会让这个行业变得更好。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我也看到了很多曾经的用户、贡献者、前同事们表示唏嘘和惋惜，感叹自己曾经参与过的开源明星项目的陨落。我没有选择在第一时间发布这篇文章，在阅读了国内外很多博主的文章、讨论和用户在 GitHub 上的回复后，带着辩证的角度来分享自己的一些观点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;截止目前，我看到的可能有价值的一个讨论是，有一些用户在 GitHub 上希望通过投票和众筹的方式重新组建纯社区自发驱动的 KubeSphere 开源贡献者团队，Issue 下也有众多用户和贡献者表示支持，这让我感受到了些许欣慰，因为它展现了开源社区开发者的集体力量，但这个目标要实现的难度不亚于去经营一家公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="229" src="https://oscimg.oschina.net/oscnet/up-bab13eb637d429b475fd818bbd06bc869b5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;维护开源是商业公司应有的社会责任吗？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这是一个值得每位开源参与者深思的问题。开源项目由商业公司主导，并不意味着它对社区有「义务」无限维护。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;显然 「KubeSphere 闭源删库」 是一个唐突而又糟糕的决策，但我想说，&lt;strong style="color:#000000"&gt;选择「闭源」或核心团队撤离开源项目这件事情本身从来不是某一家商业公司的过错，&lt;/strong&gt;任何一家商业公司主导的开源项目都存在这样的「闭源」风险，这在开源界也已有多个案例。客观来说，在当前的经济下行的市场环境下，几乎所有商业公司都在收缩投资或调整战略，对于营收增长慢的项目和人力都有被优化的可能。&lt;strong style="color:#000000"&gt;维护开源项目并不是一家商业公司应有的社会责任或义务。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;但是，开源项目背后的主导公司如果希望撤资开源投入，&lt;strong style="color:#000000"&gt;需要遵循开源项目客观存在的生命周期，&lt;/strong&gt;而不是把开源社区一刀切，用开源断供来「绑架」用户，转到自家商业产品，这并不是一项精明的生意决策。实际上，&lt;strong&gt;如果青云选择将 KubeSphere 项目归档 （Archive）并选择提前一段时间在社区发布项目 Retire 的公告，同时致谢所有参与贡献的开发者和用户，那就不会出现今天的危机局面&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;失去开发者=失去企业服务信任&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「得开发者得天下」 是一个很通俗的道理，很多大小企业选择走开源的策略，也正是因为开源是一个能够低成本地快速地获取全球开发者用户的机会和建立跨企业的社区合作模式，比传统的闭源软件开发和 Marketing 传播更快，通过开源社区协作开发也更容易建立规模与行业标准。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;但很多商业公司错误地把开源作为低成本「获客」的渠道，&lt;strong style="color:#000000"&gt;把开源作为一项「免费广告」的福利，利用开发者对开源技术的关注来获取销售商机，这样的做法是对开源社区最大的伤害，也是对商业公司口碑的破坏&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;实际上，很多开源项目的开发者用户是一些企业的运维开发负责人或内部决策影响者，他们虽然可能不能直接决定公司的软件采购，但他们提供的观点和意见会直接或间接地影响企业管理层的决策。很可惜，很多开源商业化公司的 CXO 们并不懂开发者的重要性，忽视了开源社区的规模影响力。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;青云做些什么能补救？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;答案是能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;青云作为一家上市公司，公司层面一定还是会关注自己在业内的口碑以及客户的信任。这里我不适合作为局外人指点江山，但提供思路作为参考，&lt;strong style="color:#000000"&gt;毕竟在社区里还有很多用户在关注 KubeSphere 后续是否会有好的转机。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;让我们来看一个正面的例子，CNCF 毕业项目 Flux 背后的核心维护公司 WeaveWorks 在去年 2 月份虽然宣布了公司关闭停止运营，但 CEO 第一时间在联系一些大公司的用户和贡献者参与 Flux 项目的维护，并积极寻求 CNCF 的帮助，确保该项目在即使没有了 WeaveWorks 公司的支持，还能继续在社区维护和迭代。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="504" src="https://oscimg.oschina.net/oscnet/up-5c4d3b4efba258bd1ad215ef4c196d40c65.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;青云是否会考虑做一个 「git revert」 的回滚操作，来响应社区目前呼声最高的提议&lt;/strong&gt;：恢复闭源的仓库、下线的文档、历史镜像，并将开源项目交由给中立的社区自发去维护？青云作为商业公司继续去做自己的商业产品，或许还有重建信任的机会。如果公司层面担心开源项目抢了自己的商业产品的蛋糕，那必然是商业产品与服务做得还不够好。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;对 KubeSphere 开源协议的疑问？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;KubeSphere 有两个子项目的开源协议值得探讨，第一个是此次被闭源的前端 Console 项目开源协议是 AGPL-3.0，这个协议除了要求二次分发必须开源没有其它问题，一些知名项目如 Grafana 也采用该协议。还记得 KubeSphere 曾多次被国内和海外的一些大公司换 Logo 后改个名字后就拿去卖钱，AGPL-3.0 的协议某种程度上也有一定的品牌保护作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;但值得注意的是，后端开源是在 Apache 2.0 基础上加入了「附加条款」的开源协议，例如：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;禁止用于商业化 SaaS 服务&lt;/strong&gt;；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;禁止移除或修改 KubeSphere 品牌和 logo&lt;/strong&gt;；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;要求贡献者接受维护者可以在未来&lt;strong&gt;改变授权方式&lt;/strong&gt;的条款；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;对 fork 或商用做出限制。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;虽然它的目的是出于保护青云的商业产品利益和 KubeSphere 品牌，但这个修改后的协议是不符合 OSI（Open Source Initiative）定义的开源标准的，破坏了 Apache 2.0 的开放性和自由性。所以青云回复 KubeSphere 将继续保持核心代码开源的声明，是需要推敲的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;开源协议的选择，以及&lt;strong style="color:#000000"&gt;所选开源协议的开放程度和商业友好程度，会从本质上影响和决定这个项目最终是否会有众多企业级贡献者来参与&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;关于「K8s 上游贡献」的误解&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;圈子里有开源从业者提出了一个问题：&lt;strong style="color:#000000"&gt;KubeSphere 作为 K8s 发行版，秉着 「Upstream First」 的原则， KubeSphere 项目维护者在上游 K8s 社区的贡献有多少？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;实际上，研究这个问题对于分析这个事件的的意义并不大，因为 KubeSphere 不算严格意义上 K8s 发行版，因为它没有改 K8s 一行代码，没有对 K8s 进行二次分发，它是一个构建于 Kubernetes 之上的平台型项目，用户可以使用自己已有的 K8s 对接 KubeSphere，所以从产品定义层面这个说法不是非常准确；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;其次，KubeSphere 团队对 K8s 项目的贡献多少，并不会直接影响到 KubeSphere 开源项目本身的可持续性发展，上游贡献的指标仅对下游企业在 K8s 上游社区的话语权和影响力能产生影响，或对企业内部基于 K8s 做了扩展或二次修改的厂商，或是直接提供托管 K8s 云服务的云厂商，能体现技术实力。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;可持续的开源项目，有哪些共同特征？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;「一个人可以走得很快，但一群人可以走得更远。」&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;很多用户评估开源项目是否值得在企业内部特别是生产环境采用，习惯先去看这个项目的 GitHub Star 数量来评估这个项目的流行度，从而判断该项目的可持续性。实际上，这样的方式太过于片面和业余。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我如果作为用户，我认为最可靠的方式是去关注这些指标：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;有多少家公司参与了开源项目的贡献与维护？贡献比例分别是多少？（单一厂商控制的开源项目属于高风险）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源社区治理和开发流程是否公开和透明？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;有多少大的企业已经采用了该开源项目？（这通常在官网或 README 中能找到）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;该开源项目对商业化是否友好？业内是否已有多家商业公司集成和提供商业支持？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;…&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我的观点是，真正强大的开源项目，往往拥有更丰富的「社区股东」和更清晰的合作模型。&lt;strong style="color:#000000"&gt;一个开源项目的贡献者和商业生态越多元化，拥抱它的企业越多，它的可持续性将会越强大。&lt;/strong&gt;如果只有单一厂商在维护，并且只有用户生态，缺乏不同组织的贡献者，并且用户市场还局限在国内，这样的开源项目大概率是走不远的。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;我们从该事件能学到什么？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;对于希望构建开源商业化的公司&lt;/strong&gt;：开源的核心价值并不仅仅是代码和技术，而是围绕这些能力构建起来的社区生态与信任体系。如果把开源仅仅视为一种「获客渠道」，通过免费开放源码吸引用户，再通过商用版本进行转化，却忽略了社区治理、合作机制、开发者关系和中立性建设，最终可能得到短期流量，但失去长期信任。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;对开源项目使用者的启示：&lt;/strong&gt;&amp;nbsp;如何选型一个更有可持续性的项目是非常关键的，上面提到的一些指标可以作为参考。作为用户在有余力的情况下，可以思考自己作为用户如何参与到开源社区中，毕竟 「众人拾柴火焰高」。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;写在最后&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我在西雅图的周日晚午夜时分写完这篇文章，虽然我已经离开了前司青云三年多时间，但依然对曾经一起参与 KubeSphere 维护的前同事、社区贡献者和用户们合作的时光非常怀念，当时 KubeSphere 项目也确实在四海大地聚集了很有有热情和信仰的开源爱好者。如今的局面，个人还是衷心希望能有一些好的转机！&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364121</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364121</guid>
      <pubDate>Sun, 03 Aug 2025 09:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌变更 goo.gl 短链接服务「停用」计划，会保留活跃链接</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌去年&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F" target="_blank"&gt;宣布&lt;/a&gt;，它将于 2025 年 8 月 25 日关闭 Google URL Shortener 短链接服务（goo.gl/*），届时所有 goo.gl 链接将会&lt;a href="https://www.oschina.net/news/362402"&gt;停止响应&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3de2e977a212c4b76a27a10e76c003b1a75.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;距离关闭日期不到一个月时间，在依赖于 goo.gl 短链接的开发者、教育工作者和记者等表达担忧之后，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fgoogl-link-shortening-update%2F" target="_blank"&gt;谷歌改变了主意&lt;/a&gt;，采取了更温和的立场：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/173324_wscd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;它将只禁用自 2024 年底以来没有任何活动的 goo.gl 链接，如果 goo.gl 链接在活跃使用或点击，这些链接将能继续使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c970c162854ec8999ffbf88f6e05480f82b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364120/google-googl-shutdown-reversal</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364120/google-googl-shutdown-reversal</guid>
      <pubDate>Sun, 03 Aug 2025 09:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>揭秘字节跳动内部流量调度与容灾实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt; 
 &lt;div&gt;
   资料来源： 
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-开发者社区&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 摘要： 在字节跳动，平衡超大规模流量的稳定性、性能、容量与成本，是一系列产品共同面临的挑战，其中， Trafficroute GTM 起到了不可忽视的作用&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Trafficroute GTM 承载了字节跳动亿级流量、覆盖了大规模场景，是一款基于 DNS 的流量路由服务，我们将通过两期文章，揭秘字节跳动如何通过 Trafficroute GTM 巧妙应对以上挑战，实现高效流量管理！&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;上期内容中，我们主要介绍了基于 TrafficRoute GTM 的 GEO-基础路由模式进行自定义流量编排，感兴趣的小伙伴可以点击了解：《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkyNzY0OTE5Ng%3D%3D%26mid%3D2247487345%26idx%3D1%26sn%3D8240962635c24ae6f065a483be88d8eb%26scene%3D21%23wechat_redirect" target="_blank"&gt;揭秘字节跳动内部流量调度与容灾实践【上】&lt;/a&gt;》。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;本文为下期，主要介绍基于 TrafficRoute GTM 的 Perf-智能路由模式落地全智能、可观测、可微调的流量调度，主要内容包括：&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;1.TrafficRoute GTM 介绍&lt;br&gt; 2.TrafficRoute GTM 的 Perf-智能路由关键技术&lt;br&gt; 3.字节跳动智能流量调度内部实践&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;面临超大规模流量时，平衡好稳定性、性能、容量、成本，能确保用户在访问服务时获得流畅、快速且可靠的体验，这对于提高用户满意度和粘性至关重要。TrafficRoute GTM 为业务提供基于 DNS 的全球流量负载均衡、智能调度、自动容灾服务，可以帮助业务提升连续性，实现资源优化，获取更多竞争优势。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;1.火山引擎 Trafficroute GTM 简介&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;火山引擎 Trafficroute GTM 是基于 DNS 的流量路由服务。它依托全球 1100+ 分布式探测节点及 IDC 质量数据等，构建出强大的网络质量感知能力，实现了对「端-边-云」全链路流量的质量感知，从而根据 APP 应用的实时访问质量、节点负载和健康状况作出动态流量调度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;此外，Trafficroute GTM 还提供灵活的调度策略，其中 GEO-基础，路由功能丰富，包括负载均衡、会话粘性（内部使用中，暂未对外开放）和故障转移等多种特性。而 Perf-智能路由则在基础路由的基础上，进一步提供性能优先，容量优先和负载反馈等智能调度能力，以满足更高层次的调度需求。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//27f3f1197212e22ab45afebdef1b5d94.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 一图看懂 TrafficRoute GTM&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在字节跳动内部业务中，诸多业务基于 TrafficRoute GTM 的 Perf-智能路由，借助 GTM 的全球网络质量地图、APP 全链路可用性、APP 实时负载等感知能力落地了全智能、可观测、可微调的流量调度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;2.Perf-智能路由，实现流量智能调度&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;TrafficRoute GTM 的 Perf-智能路由旨在为边缘计算、IoT 物联网、多云混合等大规模分布式场景提供智能化的流量调度方案。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;用户无需人工进行流量编排，只需在 GTM 中输入目标节点地址，GTM 即刻呈现最优的流量调度策略；同时，GTM 会根据全球网络质量，目标节点健康状况等动态的更新流量调度规则，真正地实现自动、智能的流量调度。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//51866a5a42c1752611bb4008749e8321.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 凭借以下关键技术，Perf-智能路由实现了更智能、更动态的流量调度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;2.1 感知中心&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;GTM 感知中心通过分布于全球 1100+ 的节点实时采集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全球网络链路质量，反映网络链路的连通性/时延/抖动等&lt;/li&gt; 
 &lt;li&gt;目标资源健康情况，反映业务的资源节点当前健康程度&lt;/li&gt; 
 &lt;li&gt;目标资源实时负载，反映业务的资源节点当前工作负荷&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;这些数据经过预处理、转换、分析后作为策略中心的决策依据。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//755a66782dbc63a888425e5bdb229491.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 以感知中心生成的中国大陆的网络质量地图为例：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//46181b2fb4b81bfa8d7342a946b61e71.jpg" width="1005" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 该有向图表达了 6 个省份-运营商之间的网络质量，节点代表省份-运营商，边表示节点之间的连通性&amp;amp;时延&amp;amp;抖动。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在实际应用中，GTM 的策略中心亦可根据业务需求，对该有向图施加【成本系数、ISP 亲和、GEO 亲和】等约束，这些约束最终会影响到流量调度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;2.2 策略中心&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;策略中心根据感知中心上报的事件，利用实例设定的策略算法进行路由计算，进而生成动态的调度拓扑。Perf-智能路由主要有 3 种模式，分别面向对性能、容量、成本、稳定性等有不同诉求的业务场景。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//3a18a1d64b5cf0c4990422b915b0ddde.jpg" width="3412" referrerpolicy="no-referrer"&gt; 
 &lt;br&gt; 
 &lt;br&gt; 性能优先 | Perf 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  适用于量级可控、资源容量充沛、追求极致性能的业务 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：据全球网络质量，动态的将各地区的客户端调度至其访问最快的资源节点&lt;/li&gt; 
 &lt;li&gt;核心特色：以数据 （ 网络质量 ） 驱动调度而非经验，将流量调度变得更加智能、实时、精确&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//8829efb01af6d09d6e03a63deb50b9cc.jpg" width="1482" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; &lt;br&gt; 容量优先 | Perf-Cap&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;适用于量级中等，资源分布不均，要求在资源约束下实现最高性能的业务&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：根据全球网络质量，在容量限制的前提下，动态地将各地区客户端调度至其访问最快的资源节点&lt;/li&gt; 
 &lt;li&gt;核心特色：在 Perf 性能优先的基础上，引入资源节点容量的约束，能够更加智能的实现容量，性能的平衡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//fc0b6086dc2a8b0704f5e7b93fbe5d64.jpg" width="936" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 负载，反馈 | Perf-Feedback&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;适用于量级波动大，资源分布广且不均，追求容量&amp;amp;性能&amp;amp;成本的平衡，尤其适合边缘下沉场景&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：根据全局和节点负载，动态的将流量在可用节点中分配，同时兼顾性能最优和容量安全&lt;/li&gt; 
 &lt;li&gt;核心特色：以最合理的资源成本，稳定支撑量级&amp;amp;波动大的业务，实现容量/性能/成本/稳定性的平衡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//4f0e9bd329249ed0ebe8ec044f0a7a95.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; Perf-Feedback 内置两种调度倾向：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;当全局平均负载较低时，GTM 倾向于性能，将客户端流量调度至其访问最快的资源节点&lt;/li&gt; 
 &lt;li&gt;当全局平均负载较高时，GTM 倾向于稳定，确保每个节点的水位不高于全局平均负载水位&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;如下图所示，相比于 Perf-Cap，GTM 的调度输入中引入了实时负载的数据。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//fbb51d8fe9e5aeec563326aafa3b54a5.jpg" width="936" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Perf 自定义路由&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;适用于用户需要对 Perf 智能路由流量进行微调，以满足特定场景的业务&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：自定义路由规则的优先级高于 Perf 智能路由生成的路由规则优先级&lt;/li&gt; 
 &lt;li&gt;核心特色：在智能化的同时也为业务方提供更多的灵活性，满足特定业务需求&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//0f2575e23ad2499c9ac0ab47b58bb6d6.jpg" width="2850" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 2.3 流量可视化&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Perf-智能调度智慧透明，配备全面工具集，助力业务深入分析流量动态，通过 Perf-智能调度，可以观测到实时流量拓扑、客户端请求趋势、客户端地区分布等流量动态。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//725ec82c907b637a27e73d5ab3598418.jpg" width="2722" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 实时流量拓扑&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//9fc1792f281616eeef95de1b8fdb01d2.jpg" width="1864" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 客户端请求趋势&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//3da45538936e9772728e8057243a3548.jpg" width="1872" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 客户端地区分布&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;3.字节跳动智能流量调度内部实践&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在字节跳动，越来越多的业务正通过边缘计算将服务去中心化，从而实现更优的用户体验和更低的基建成本。面对边缘节点分布广泛、数量庞大、能力参差不齐的挑战，TrafficRoute GTM 的 Perf 智能路由展现出天然优势。通过 Perf -智能路由的三种调度模式，帮助字节跳动内部多个业务落地了边缘下沉，在成本、性能和稳定性上取得较大收益。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;3.1 RTC 实时音频，访问时延降低 10%+&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;字节跳动某款 APP 的 RTC 实时音频服务，在全国三个城市部署了 9 个接入节点。通过采用 TrafficRoute GTM 的 Perf 性能优先模式，确保全国的企业用户在不同工作场所均能体验到极低延迟的音频接入服务，保障了通信的高效与流畅。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//b46e6cf10f0195428eb729c7d2c6b570.jpg" width="1048" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//717de0c554e9a316da09e95cae8b0522.jpg" width="3752" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; GTM 感知中心实时感知全国网络质量，智能地为不同地区客户端动态制定调度规则，确保用户始终连接到最健康、速度最快的音频接入点，以优化通信体验。整个应用过程中，GTM 的 Perf 性能优先模式充分发挥了独特功能，涵盖了智能动态调度策略、显著降低了接入成本以及显著提升了应用性能，展现出其卓越的技术优势。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//22ae0e72f459a8d877bbd5c14643deb5.jpg" width="2442" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 采用 TrafficRoute GTM 的 Perf 性能优先模式，相比较 GEO 基础路由，最终业务实现了如下收益：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//0e9a9657ca6bffdeb34296935aadd2ec.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;成本收益：智能调度代替了人工维护，每月降低了 3 人天以上；&lt;/li&gt; 
 &lt;li&gt;性能收益：访问时延 avg 降低 10%+，p95 降低 25%；请求成功率 avg 提升 0.05%；&lt;/li&gt; 
 &lt;li&gt;稳定性收益：业务实现了分钟级全链路自动容灾，最快做到 3 分钟全国 95%+ 流量收敛。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 3.2 千万 QPS 业务，成本降低 35%，性能提升 20%&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在边缘计算浪潮的推动下，能否有效驾驭大规模边缘算力，成为业务边缘下沉成功的关键。TrafficRoute GTM 深度参与了一个超 1500 万 QPS 的业务边缘下沉项目，通过使用 Perf-Cap 容量优先模式，助力其在字节内部率先落地端-边-云一体化的架构，成为先行者。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//e7deae9af5c6d09fccc0c1904c31f291.jpg" width="3132" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 通过将中心 Region 数据面服务下沉至全国 30+ 省份、50+ 边缘节点，来实现提升用户访问体验 (边缘节点距离终端客户端更近) 和降低带宽&amp;amp;算力成本 (边缘资源成本约为中心的 20%~60%)。GTM 的 P erf-Cap 容量优先模式，根据业务的客户端请求分布、全国网络质量地图 ， 在满足各边缘节点容量约束的前提下，生成全局总时延最低的流量调度规则。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//ad93894a8582bd02fd6e4d9c63309094.jpg" width="2596" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; GTM 上实际配置如下图：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//433b27fc81232ee1a9ec89b390e0f5ed.jpg" width="1532" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 此时，用户无需繁琐的容量规划、节点统筹、流量调度，只需在 console 上填入边缘节点的元信息 (IP 地址+容量)，GTM 即刻生成&lt;em&gt;智能&lt;/em&gt;、&lt;em&gt;动态&lt;/em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;em&gt;的调度&lt;/em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;*， *&lt;em&gt;时刻保证最终客户的体验最优。&lt;/em&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;通过抖音客户端 AB 数据分析，该业务边缘下沉带来的整体收益如下：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//d60771c32ba3fa11f057436c4149292f.jpg" width="2074" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 其中，边缘下沉 x GTM Perf-Cap 模式，额外取得的收益如下：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//c2dd755e546b20a5daee185333db42d1.jpg" width="2092" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 3.3 302 服务，端上播放质量显著提升&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;字节跳动 302 服务承担了抖音、头条、西瓜等 APP 点播&amp;amp;下载的重定向功能，其流量呈现明显的波峰波谷特征，日内 QPS 在 30-350 万范围波动。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;为实现最优访问性能和最低基建成本，要求 TrafficRoute GTM 将动态波动的流量在最小资源冗余的火山引擎边缘节点上合理调度，既要保证性能全局最优，又要保证全局水位健康。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//4fcd16dcc51697e3731fb733c9e6a59c.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 采用 Perf-Feedback 负载反馈模式，302 服务实现了如下收益：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//69cfbed876af215db19663285d846b05.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;100+ 边缘节点的负载更加可控，资源利用率更加合理，节点负载跑超率从 20% 降至 0%；&lt;/li&gt; 
 &lt;li&gt;TCP 建联失败率下降明显：晚高峰 19%-&amp;gt;16.5% ，午高峰 18%-&amp;gt; 14%；&lt;/li&gt; 
 &lt;li&gt;客户端 7 层负面指标均下降 ： 其中播放 error 错误率、播放 play_break 中断率降幅超 50%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; END&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Trafficroute GTM 通过 Perf -智能路由的三种调度模式，帮助字节跳动内部 RTC 实时音频业务、千万 QPS 业务、302 服务实现了在成本、性能和稳定性上的收益，进一步助力字节跳动内部业务经受超大规模流量考验，确保始终为用户提供稳定服务。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;最后，给大家预告番外篇，后续我们将聚焦更新的 GTM 调度功能，详细阐述技术思路、关键技术和实践经验，感兴趣的小伙伴记得持续关注~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6800876/blog/18684814</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/18684814</guid>
      <pubDate>Sun, 03 Aug 2025 09:24:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>B 站上线「AI 原声翻译功能」，将加入日语等语言</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;B 站今年 5 月下架国际版 App，与国内版合并为一个统一 App。为解决海内外内容互通问题，B 站现公布一项自研的「AI 原声翻译功能」，号称可以帮助海外用户更好体验游戏、科技、二次元等主推内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;据 B 站介绍，&lt;strong&gt;目前相应功能已向海外用户开放，暂仅支持英语&lt;/strong&gt;，主要提供画面和音频两大翻译能力，在画面方面支持自动擦除原中文字幕改为英文、自动翻译弹幕、各类按钮语言。在音频方面号称可以还原 UP 主的声线、音色、气口，而非传统的机器音翻译。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img height="259" src="https://oscimg.oschina.net/oscnet/up-a4c2bba74fb87025c787b7a83000654e41b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;B 站表示，相应翻译功能的技术难点&lt;strong&gt;在于游戏、二次元等专有名词梗的密集领域「如何实现原风格精准保留与语音时长完美对应」&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;为此，相应技术团队基于大语言模型（LLM）构建翻译引擎，采用对抗式强化学习（RL）训练驱动模型；并引入 Deep Research 深度挖掘技术，专攻专有名词与流行梗点的翻译难点，确保最终译文准确传神。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;后续，B 站还将视需求为「AI 原声翻译」功能新增日语等更多语言，持续扩展在海外市场的适配能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364111</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364111</guid>
      <pubDate>Sun, 03 Aug 2025 09:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>高德发布全球首个地图 AI 原生智能体</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;高德地图正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4qsBRg16CnO1ayKe6sHiFA" target="_blank"&gt;宣布&lt;/a&gt;其全面 AI 化，结合前沿的空间智能技术，推出了全球首个 AI 原生地图应用 —— 高德地图 2025。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告称，高德地图 2025 旨在打造具备深度时空理解和自主推理决策能力的一体化出行生活智能体，以及 AI 领航、AI 即刻、AI 探索、AR 打卡等创新场景工具，为用户提炼一个更加符合习惯和喜好的个性化数字孪生世界，基于空间智能架构解决一切出行生活需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="228" src="https://oscimg.oschina.net/oscnet/up-f16397c20425bb4922c0dbd519e0b8bed5e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「空间智能是在三维空间和时间中感知、推理、和行动的能力，能够让地图实现被动感知到主动预判的跨越。」高德地图 CEO 郭宁表示，希望从高德地图 2025 开始，推动 AI 从 「对话工具」蜕变为「行动伙伴」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;即日起用户升级高德地图 APP 至最新版，搜索「空间智能」，即可体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;根据介绍，用户可与高德主智能体「小高老师」的语音交流。该语音技术以自然语言交互为核心，通过全双工语音技术实现流畅交流，支持用户随时打断指令、动态调整规划；内置的回声消除算法与异常语义拒识模型，可智能去噪以精准聆听用户声音；而情感计算模块赋予对话温度，不仅提供清晰的路线指引，更能在旅途中提供情绪陪伴。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;语音感知之后，即进入思考决策环节。基于高德与通义深度共建的大模型簇，小高老师能够进行基于空间智能的推理、计划、反思和行动，并通过 MCP 协同调用出行服务、生活服务、空间服务等子智能体和工具链，整合内外部知识库来制定最优方案。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364108</guid>
      <pubDate>Sun, 03 Aug 2025 09:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「问小白」发布第四代开源大模型 XBai o4，擅长复杂推理</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;「问小白」发布了第四代开源大模型&lt;strong&gt;XBai o4&lt;/strong&gt;（其中「o」代表「open」），该模型在复杂推理能力方面表现出色，在 Medium 模式下已全面超越&lt;strong&gt;OpenAI-o3-mini&lt;/strong&gt;，并在部分基准测试中优于&lt;strong&gt;Anthropic Claude Opus&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/163409_xSmx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;XBai o4 基于创新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRxWjzZe5WWVGKKOk2JbfJQ" target="_blank"&gt;「反思型生成范式」&lt;strong&gt;（reflective generative form）&lt;/strong&gt;&lt;/a&gt;，融合了 Long-CoT 强化学习&lt;strong&gt;与&lt;/strong&gt;过程评分学习（Process Reward Learning），使单个模型同时具备深度推理和高质量推理链路筛选的能力。通过共享过程评分模型（PRMs）和策略模型的主干网络，XBai o4 显著降低了 99% 的过程评分推理耗时。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8840d76d6357daa77dda0a67b9e0727ff4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该模型提供三种模式（low、medium、high），在多个基准测试（如 AIME24、AIME25、LiveCodeBench v5、C-EVAL 等）中均展现出强大性能，相关训练和评估代码已在 GitHub 开源。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMetaStone-AI%2FXBai-o4" target="_blank"&gt;https://github.com/MetaStone-AI/XBai-o4&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364101</guid>
      <pubDate>Sun, 03 Aug 2025 08:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI CEO 首次公开 GPT-5 对话界面</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;OpenAI CEO Sam Altman 全网首次公开了 GPT-5 的对话界面，揭示这款尚未发布的大模型在真实使用场景中的表现。&lt;/p&gt; 
&lt;p&gt;截图显示，Altman 向 GPT-5 提问：「什么是最发人深省的 AI 题材电视剧」。GPT-5 随即给出了一份详细推荐清单，内容不仅涵盖剧集名称、播出平台和评分，还深入介绍了每部剧集的核心议题与哲学内核。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2bf8d8ceeab9104926e943d4d197b5de237.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;有趣的是，网友的高赞评论却是吐槽 ChatGPT 的标点使用习惯：「请永久删除 ChatGPT 中的破折号。」&lt;/p&gt; 
&lt;p&gt;后续，Altman 还表示「很快进入 SaaS 的快时尚时代」，疑似暗示 GPT-5 不仅是一次模型升级，更可能重塑传统 SaaS 产品的形态与节奏。&lt;/p&gt; 
&lt;p&gt;&lt;img height="290" src="https://static.oschina.net/uploads/space/2025/0804/162106_XXoY_2720166.png" width="1212" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/162136_6vpA_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364098</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364098</guid>
      <pubDate>Sun, 03 Aug 2025 08:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元开源 0.5B、1.8B、4B、7B 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0szU-fwpLjc0alMomEnONA" target="_blank"&gt;宣布&lt;/a&gt;推出四款开源的小尺寸模型，参数分别为 0.5B、1.8B、4B、7B，消费级显卡即可运行，适用于笔记本电脑、手机、智能座舱、智能家居等低功耗场景，且支持垂直领域低成本微调。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，新开源的 4 个模型属于融合推理模型，具备推理速度快、性价比高的特点，用户可根据使用场景灵活选择模型思考模式——快思考模式提供简洁、高效的输出；而慢思考涉及解决复杂问题，具备更全面的推理步骤。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;测评结果：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-8d96ad4baf1db0e93295376a2b639e6be4f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="348" src="https://oscimg.oschina.net/oscnet/up-fff316007c0614bb4b57fb6b9695b5c79d3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这四个模型的亮点在于 agent 和长文能力，跟此前开源的 Hunyuan-A13B 模型一样，技术上通过精心的数据构建和强化学习奖励信号设计，提升了模型在任务规划、工具调用和复杂决策以及反思等 agent 能力上的表现，让模型实际应用中可以轻松胜任深度搜索、excel 操作、旅行攻略规划等任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，模型原生长上下文窗口达到了 256k，意味着模型可以一次性记住并处理相当于 40 万中文汉字或 50 万英文单词的超长内容，相当于一口气读完 3 本《哈利波特》小说 ，并且能记住所有人物关系、剧情细节，还能根据这些内容讨论后续故事发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;部署上，四个模型均只需单卡即可部署，部分 PC、手机、平板等设备可直接接入。并且，模型具有较强的开放性，主流推理框架（例如，SGLang，vLLM and TensorRT-LLM）和多种量化格式均能够支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;应用层面，四款小尺寸模型都能够满足从端侧到云端、从通用到专业的多样化需求，并且已经在腾讯多个业务中应用，可用性和实用性经过了实践的检验，是真正实用的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;例如，依托模型原生的超长上下文能力，腾讯会议 AI 小助手、微信读书 AI 问书 AI 助手均实现对完整会议内容、整本书籍的一次性理解和处理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在端侧应用上，腾讯手机管家利用小尺寸模型提升垃圾短信识别准确率，实现毫秒级拦截，隐私零上传；腾讯智能座舱助手通过双模型协作架构解决车载环境痛点，充分发挥模型低功耗、高效推理的特性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在高并发场景中，搜狗输入法基于模型的多模态联合训练机制使嘈杂环境下提升识别准确率；腾讯地图采用多模型架构，利用意图分类和推理能力提升了用户交互体验；微信输入法「问 AI」基于模型实现输入框与 AI 即问即答的无缝衔接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在需求各异、约束严苛的垂直行业应用中，金融 AI 助手通过 Prompt 优化和少量数据微调实现 95%+意图识别准确率，展现出金融级的高可靠性；游戏翻译和 QQ 飞车手游 NPC 充分利用模型的理解能力在多语言理解能力、方言翻译和智能对话方面有突出表现，这些能力在专业客服、内容出海甚至电商直播等场景有巨大应用潜力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364095</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364095</guid>
      <pubDate>Sun, 03 Aug 2025 08:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Eclipse SUMO - 交通模拟工具套件</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;a href="https://sumo.dlr.de/"&gt;"Simulation of Urban MObility" (SUMO)&lt;/a&gt;&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;是一个开源、高度便携、微观交通模拟包，旨在处理大型道路网络和不同的交通方式。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;它支持包括行人在内的多式联运模拟，并附带大量用于场景创建的工具。&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/eclipse-sumo/sumo
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;img alt="" height="210" src="https://static.oschina.net/uploads/space/2025/0804/151521_l9bX_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/eclipse-sumo</link>
      <guid isPermaLink="false">https://www.oschina.net/p/eclipse-sumo</guid>
      <pubDate>Sun, 03 Aug 2025 07:55:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta 有望收购 AI 视频初创公司 Pika Labs</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Meta 日前正在积极寻求与 AI 视频生成技术的初创公司建立合作伙伴关系，旨在发力视频生成领域。&lt;/p&gt; 
&lt;p&gt;知情人士称，Meta 近期与 AI 视频初创公司 Pika 就潜在合作展开了讨论，内容包括可能的收购或技术授权协议。另据透露，Meta 还与另一家专注于创作者的小型视频生成商 Higgsfield 讨论过收购事宜，但目前谈判已暂停。&lt;/p&gt; 
&lt;p&gt;据悉，Pika 以生成逼真视频的 AI 技术而知名。而据公开信息，郭文景是 Pika Labs 的联合创始人与 CEO。她与联合创始人兼 CTO Chenlin Meng 均为斯坦福大学 AI Lab 博士生，在 2023 年 4 月从斯坦福辍学、创立了 Pika Labs，致力于开发基于文本生成短视频的 AI 工具。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/144812_Lkpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，郭文景入读斯坦福读博前还曾任职于 Meta AI 研究团队。据了解，郭文景自幼展现非凡学术天赋，被誉为「学霸少女」，是浙江杭二中首个被哈佛本科提前录取的学生 。&lt;/p&gt; 
&lt;p&gt;另外，Pika 仅成立半年便爆红，团队最初只有四人，却在 2023 年完成三轮融资，筹资约 5500 万美元，估值约 2–3 亿美元；随后在 2024 年 B 轮融资约 8000 万美元，使估值上涨至近 5 亿美元。&lt;/p&gt; 
&lt;p&gt;Pika 的&lt;a href="https://www.oschina.net/news/361912"&gt;核心产品&lt;/a&gt;为「文生视频」模型，号称用户一句话描述，就能生成风格多样的动画短视频。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364087</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364087</guid>
      <pubDate>Sun, 03 Aug 2025 07:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义 Qwen3 模型拿下全球第三</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;国际知名大模型评测 Chatbot Arena 日前公布最新榜单，Qwen3-235B-A22B-Instruct-2507 斩获 1433 分，超越顶尖闭源模型 Grok4、Claude4、GPT4.1，Qwen3 位列总榜「全球第三」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1440" src="https://static.oschina.net/uploads/space/2025/0804/153306_pv7H_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据悉，Chatbot Arena 采用盲测评价机制，是 AI 大模型领域最具影响力的榜单之一。&lt;/p&gt; 
&lt;p&gt;此次 Qwen3 的 1433 分，是全球开源大模型和中国大模型的历史最高分。同时，Qwen3 还在 5 个关键能力子项中摘得「全球第一」，包括数学（math）、代码（coding）、复杂提示（hard prompts）、长文本检索（longer query）和指令遵循（instruction following）。&lt;/p&gt; 
&lt;p&gt;除 Qwen3 Instruct 模型外，Qwen3 家族多款模型也取得优秀成绩：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;推理模型 Qwen3-235B-A22B-Thinking-2507 也闯进榜单前十，数学能力并列全球第一；&lt;/li&gt; 
 &lt;li&gt;在 Chatbot Arena 专门评估编程能力的 WebDev Arena 子榜单中，编程模型 Qwen3-Coder 性能与 Gemini2.5 Pro、DeepSeek-R1、Claude4 并列第一。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="973" src="https://static.oschina.net/uploads/space/2025/0804/153340_6oDO_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="973" src="https://static.oschina.net/uploads/space/2025/0804/153435_soAg_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/153506_LT7j_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364084</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364084</guid>
      <pubDate>Sun, 03 Aug 2025 07:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>7 月 Chrome 份额达 69.98%，接近历史新高</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;Statcounter 最新数据显示，谷歌 Chrome 浏览器在 7 月的份额进一步巩固，达到了 69.98%，几乎接近历史新高，较上月增长了 3.09 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与此同时，微软 Edge 浏览器的市场份额却出现了下滑，2025 年 7 月，Edge 的市场份额从 13.06% 下降至 11.8%，流失了相当一部分用户。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-4deb5717a3ebf7e551b81308cac02cc5d2a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 Chrome 和 Edge 之外，其他浏览器的市场份额也有所下降，苹果的 Safari 以 6.51% 的市场份额位居第三，较上月下降了 1.83 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Firefox 以 5.32% 的市场份额位居第四，较上月下降了 0.52 个百分点；Opera 则以 2.2% 的市场份额位居第五，较上月下降了 0.43 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-8174cbe98fe739c689d75e4f46138fdb892.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在移动市场，Chrome 的主导地位同样明显，以 67.32% 的市场份额位居第一，苹果 Safari 以 22.42% 的市场份额位居第二，三星浏览器以 3.5% 的市场份额位居第三。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微软 Edge 虽然具备一些独特实用功能，但在移动市场上的份额仍然微不足道。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364068</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364068</guid>
      <pubDate>Sun, 03 Aug 2025 06:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>SEO 没死，生成式 AI 优化道阻且长</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;「 3 个月 5980 ，你的品牌名上不了 DeepSeek ，你来找我，我们直接退钱！ 」&lt;/p&gt; 
 &lt;p&gt;「一个词 5980 吗？」&lt;/p&gt; 
 &lt;p&gt;「对，如果你优化多个平台，会有梯度优惠，比如豆包、元宝、KIMI 。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;以上，是最近一个 GEO（ Generative Engine Optimization 生成引擎优化）业务销售与朋友的聊天记录，大概情况是：朋友是做 MCN 的，需要在 DeepSeek 、豆包、元宝等国内 AI 平台上优化自己的品牌关键词（或业务关键词），然后一个自称 GEO 营销专家的销售嗅着味就过来了，其产品 PPT 营销味之冲，令人咋舌。&lt;/p&gt; 
&lt;p&gt;整理了一些关键表述，大家评估&lt;span style="color:#8f959e"&gt;（不便直接截图，但是真人真事）&lt;/span&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;答案霸权战争开启，95% 传统 SEO 企业出局&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;未布局 GEO 企业搜索量暴跌 90%&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GEO 成本≈传统 SEO 的 1/10&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;...&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;笔者理解在一些营销场域，确实需要拽狠词儿，但不解：&lt;strong&gt;一个 2023 年随 &lt;/strong&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;strong&gt; 大火后出现的技术方向，真的有如此大的能量？&lt;/strong&gt;这不禁让笔者联想到 2022 年还有一篇文章提到：「随着 ChatGPT 取代谷歌搜索，传统的搜索引擎优化（ SEO ）正走向消亡...」&lt;/p&gt; 
 &lt;p style="text-align:center"&gt;&lt;img height="242" src="https://oscimg.oschina.net/oscnet/up-22bdf6f04662b4821e174ebc516a564ca37.png" width="640" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;但事实上，SEO 并没死，诸如 GEO、LLMO 等优化概念，也随着这几年生成式 AI 技术的发展，与传统 SEO 形成互补、协作的态势。&lt;/p&gt; 
  &lt;p&gt;闲言少敍，正片开始。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
  &lt;h3&gt;GEO、LLMO 是什么？二者有何联系？&lt;/h3&gt; 
  &lt;p&gt;严格来说，我们处于一个由人工智能技术，特别是生成式 AI （ Generative AI ）深刻变革的时代。以大语言模型为核心的生成引擎，如 ChatGPT 、Gemini 、DeepSeek 、豆包、腾讯元宝等，正以前所未有的速度渗透到&lt;strong&gt;信息检索&lt;/strong&gt;&lt;strong&gt;、内容创作、问题解答、决策辅助&lt;/strong&gt;等各个环节。&lt;/p&gt; 
  &lt;p&gt;而用户获取信息的行为也正发生转变：从过去习惯于在搜索引擎返回的「链接列表」中自行探索、筛选和整合信息，逐渐转向直接对 AI 提出问题，并期望获得一个经过 AI 理解、提炼、组织后的综合性、对话式答案。&lt;/p&gt; 
  &lt;p&gt;以上是因，果则是：&lt;strong&gt;传统的 &lt;/strong&gt;&lt;strong&gt;SEO&lt;/strong&gt;&lt;strong&gt; 策略，虽仍有价值，但不足以完全应对这场由 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 驱动的信息革命。&lt;/strong&gt;2023 年 ，GEO（生成引擎优化）这一概念被提出，随之还有 LLMO（大语言模型优化）。&lt;/p&gt; 
  &lt;p&gt;方便大家了解，笔者引用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjikensitu.com%2Fdigital-marketing%2Fgeo-vs-aio-vs-llmo%2F" rel="nofollow" target="_blank"&gt;@已见室&lt;/a&gt; 的解读，如下：&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style="text-align:center"&gt;&lt;img height="271" src="https://oscimg.oschina.net/oscnet/up-5b6cc66350d61fde4649d98327a6fcf5b66.png" width="743" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;综合来看，二者不外乎解决一件事情：&lt;strong&gt;提升品牌及其内容在生成式 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 回答中的可见度&lt;/strong&gt;。但二者也有些许不同。&lt;/p&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p&gt;我们先聊 GEO 。&lt;strong&gt;GEO 全称 Generative Engine &lt;/strong&gt;&lt;strong&gt;Optimization&lt;/strong&gt; ，指通过优化网站内容，提升其在 AI 驱动的搜索引擎（国内如 Deepseek 、百度 AI 搜索、秘塔搜索，国外如 ChatGPT 、Perplexity 、Gemini 、Copilot 和 Google AI Overviews ）中的可见度。&lt;/p&gt; 
  &lt;p&gt;例如，当用户搜索与你的产品、服务或专业领域相关的内容时，GEO 能帮助你的品牌在 AI 生成结果中获得优先展示，从而实现精准触达，最终将访客转化为品牌的忠实用户，促使他们持续回访并深度互动。&lt;/p&gt; 
  &lt;p&gt;故 GEO 多面向企业、品牌、内容创作者，以及营销人员。&lt;/p&gt; 
  &lt;p&gt;在上海源易信息发布的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmax.book118.com%2Fhtml%2F2025%2F0613%2F8051115042007077.shtm" rel="nofollow" target="_blank"&gt;《GEO 营销新增长白皮书》&lt;/a&gt;一文提出，企业要系统性地构建能被生成式 AI 优先采信的内容，可以遵循 DSS 原则，即：&lt;strong&gt;语义深度、数据支持、权威来源&lt;/strong&gt;。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;语义深度：指内容在信息丰富度、分析透彻度、逻辑严谨性、上下文关联性和满足用户深度（而非表层）需求方面的程度。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;数据支持：指内容中的观点、结论或陈述是否基于可验证的事实、可靠的数据、具体的案例或明确的证据。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;权威来源：指内容本身的出处（发布平台或作者）是否具有公认的专业性、权威性和良好的声誉，关乎内容的可信背书和行业地位。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="text-align:center"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-eb8d696dbbda568d5ceeabd83ca7aba83e2.png" width="573" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;而 &lt;strong&gt;LLMO&lt;/strong&gt;（ Large Language Model Optimization ），则聚焦于模型自身的优化，涉及模型微调、模型压缩、优化推理效率、改进上下文学习能力等，以提高模型的准确率、响应速度或多模态处理能力。&lt;/p&gt; 
    &lt;p&gt;例如：通过微调，让模型在金融行业场景下，更准确地分析财报；通过剪枝，让模型在面对一些低延时场景下，提升响应速度。&lt;/p&gt; 
    &lt;p&gt;故 LLMO 多面向 AI 开发者、数据科学家或工程师。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style="text-align:center"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-a3597395844f51aac5056b04f5e25f78b19.png" width="666" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;那么，GEO 与 LLMO 之间有何关联呢？在搞懂这一点前，不妨看看 LLM 是如何影响单一品牌出现的，从机制上：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;预训练数据：模型在预训练期间的数据、权重。换言之，LLM 不创造内容，生成什么，取决于曾经「被投喂」过什么；&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;上下文检索：在 RAG（检索增强生成）系统中，上下文检索可以定位与 query 相关的内容（如：输入输出对），而非单独依赖模型训练时的旧数据；&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;注意力机制：模型对输入的各个部分进行加权；&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;外部检索：联网搜索功能。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;p&gt;总结一下，大家可以将 LLMO 看作是为了「精准反馈用户所需要的内容」，大模型在「输出前」的自身机制优化，而 GEO 则为了优化 AI 生成结果的先后顺序，即：针对于生成式 AI 答案的「 SEO 」。二者相互协同，最终提升品牌在生成式 AI 回答中的可见度。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
   &lt;h3&gt;GEO 与 SEO 的关联与互补&lt;/h3&gt; 
   &lt;p&gt;笔者明确一个观点：&lt;strong&gt;GEO 并非完全摒弃 &lt;/strong&gt;&lt;strong&gt;SEO&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;，GEO 建立在 SEO 基础之上，并对其核心理念进行了延展。&lt;/p&gt; 
   &lt;p&gt;无论是 GEO 还是 SEO ，其核心目的都是对输出内容的先后顺序进行优化——不外乎 SEO 优化的是网站链接的先后顺序，而 GEO 优化的是 LLM 输出内容的先后顺序。&lt;/p&gt; 
   &lt;p&gt;所以，我们在 AI 搜索引擎中看到的引用链接，常常也出现在搜索引擎结果页（ SERP ）的前列。&lt;/p&gt; 
   &lt;p style="text-align:center"&gt;&lt;img height="404" src="https://oscimg.oschina.net/oscnet/up-bc73be363b81eec646d614b1d0a2db336a9.png" width="1233" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;左图（GEO）所引用的「某度百科」，为右图（&lt;/span&gt;&lt;span style="color:#8f959e"&gt;SEO&lt;/span&gt;&lt;span style="color:#8f959e"&gt;）的第二位&lt;/span&gt;&lt;/p&gt; 
     &lt;div&gt; 
      &lt;div&gt; 
       &lt;p&gt;而搜索引擎和生成式 AI 引擎的本质都是「响应用户需求」，因此 SEO 和 GEO 都需要&lt;strong&gt;先明确「用户想获取什么信息」&lt;/strong&gt;，再反向优化策略。二者的本质都是「用户需求→信息匹配→优化策略」的闭环，只是「需求载体」不同，SEO 是「搜索关键词」，GEO 是「自然语言提问」。&lt;/p&gt; 
       &lt;p&gt;且为了更好理解用户需求，搜索引擎和生成式 AI 引擎都依赖 NLP （自然语言处理），因此 GEO 和 SEO 在「语言优化」层面其实是相似的。&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;SEO 的 NLP 应用：搜索引擎通过 NLP 解析用户关键词的语义，例如「电脑卡怎么办」与「如何解决电脑卡顿」是同义需求，因此 SEO 还需要优化内容的「语义关联性」，并非单纯的关键词查询。&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;GEO 的 NLP 应用：生成式引擎的核心是理解用户的自然语言提问，例如「帮我推荐附近一家靠谱的火锅店」，GEO 不但需要负责推荐的排序，还得整合输出对应品牌的相关标签，以满足「靠谱」「附近」等词的语义解决。&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; 
       &lt;p style="text-align:center"&gt;&lt;img height="575" src="https://oscimg.oschina.net/oscnet/up-e14289629813120426b2626f1dbfcd4d078.png" width="1235" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;p&gt;至于 GEO 与传统 SEO 的互补，其实可以分为两个方面：&lt;/p&gt; 
    &lt;p&gt;1、产品形态的角度&lt;/p&gt; 
    &lt;p&gt;目前很多 AI 搜索引擎都会同时返回「 AI 输出整理」与「传统搜索引擎结果」，即：顶部显示 AI 生成式回答，下方序列显示相关网页链接。例如，在 Google 搜索「what are the 4 ps of marketing 」，会显示如下结果：&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&lt;img height="688" src="https://oscimg.oschina.net/oscnet/up-215e61c44d92f8f90341a13d6c54f3b2166.png" width="673" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;p&gt;再拓展一下，例如某音这款大家常用的短视频 APP ，也推出了「 AI 搜一搜」这类功能，搜索的答案则不会直接反馈「关联词」的短视频，而是 AI 生成的答案。&lt;/p&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
    &lt;div&gt; 
     &lt;p style="text-align:center"&gt;&lt;img height="378" src="https://oscimg.oschina.net/oscnet/up-9edb1214f4743055b60873a6eebdf878958.jpg" width="1179" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;p&gt;可见，在实际使用场景中，输出内容背后所对应的优化逻辑（ GEO/SEO ），目前仍是并行使用的。&lt;/p&gt; 
      &lt;p&gt;2、爬虫协议的角度&lt;/p&gt; 
      &lt;p&gt;传统的 SEO ，是通过网络根目录下的 robot.txt 文件去抓取网络的内容、关键词，而现在的 GEO 依旧沿用了这一爬虫协议，并诞生了更契合大模型理解的 &lt;a href="https://my.oschina.net/u/7819858/blog/18683780" rel="nofollow"&gt;llms.txt&lt;/a&gt; 协议，通过提供网站的结构化 Markdown 文档，帮助 LLM 理解哪些内容重要，哪些内容不重要、可取舍，从而减少爬虫工具对网站的抓取负担。&lt;/p&gt; 
      &lt;p&gt;目前，全球大概已有 5000+ 网站布局了 llms.txt ，以增强网站的机器可读。爬虫协议方面，robot.txt 、sitemap.xml 、llms.txt 呈现出并行支持的态势。&lt;/p&gt; 
      &lt;p style="text-align:center"&gt;&lt;img height="636" src="https://oscimg.oschina.net/oscnet/up-b958975805260123599cc2aeb73b99e8743.png" width="974" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
      &lt;div&gt; 
       &lt;div&gt; 
        &lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
        &lt;h3&gt;针对 GEO ，企业可以怎么做？&lt;/h3&gt; 
        &lt;p&gt;上文也提到，GEO 是为了让大模型更好抓取内容并理解，在「输入前」的一整套可操作的优化方案。那么「输入前」是哪个阶段呢？对于企业来说，无非是官网搭建、内容框架、分发渠道等，即：向 LLM 介绍「 who am I 」的阶段。&lt;/p&gt; 
        &lt;p&gt;针对于提高企业相关内容的能见度，我们又该怎么做呢？结合上海源易信息的解决方案，笔者用大白话为大家整理如下——&lt;/p&gt; 
        &lt;p&gt;&lt;strong&gt;内容层优化：&lt;/strong&gt;&lt;/p&gt; 
        &lt;p&gt;1、深度挖掘核心用户需求，打造具有标签性质的内容框架。例如，品牌可以通过用户调研、搜索数据分析等，建立品牌 FAQ 板块。这样不仅可以通过品牌官网解决大部分用户需求，也可以满足 LLM 信息抓取的结构化需要，毕竟在对话式 AI 语境下，大模型的输出也是一问一答。&lt;/p&gt; 
        &lt;p&gt;2、提升语义深度。品牌在搭建内容框架时，需要提供尽可能全面的信息。例如：产品背景、技术参数、专业名词解释、针对痛点、恰当类比、解决方案，以及明确导向能给用户带来的独特价值。总而言之，品牌最好要有自己独特的内容框架，别抄模板，别写一些模棱两可的话。&lt;/p&gt; 
        &lt;p&gt;3、强化数据支持。说白了，言之有理，言有出处。一方面，引用可信数据，例如来自于权威机构（政府、研究机构、行业协会）的最新数据、统计报告；另一方面，多使用图表、图像等形式让数据更直观易懂。&lt;/p&gt; 
        &lt;p&gt;4、建立 LLM 受益的文档结构。即 Snowflake 的「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.snowflake.com%2Fen%2Fengineering-blog%2Fimpact-retrieval-chunking-finance-rag%2F" rel="nofollow" target="_blank"&gt;全球文档&lt;/a&gt;」概念，指 LLM 通过将文本分解为「块」来工作，可以通过在整个文本中添加有关文档的额外信息（如财务文本的公司名称、提交日期），LLM 更容易理解并正确解释每个独立的块，从而提高回答准确率。&lt;/p&gt; 
        &lt;p style="text-align:center"&gt;&lt;img height="451" src="https://oscimg.oschina.net/oscnet/up-7fc03163e00a6cd3a1b215ade31a4158f9d.png" width="681" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
        &lt;div&gt; 
         &lt;div&gt; 
          &lt;p&gt;&lt;strong&gt;技术层优化：&lt;/strong&gt;&lt;/p&gt; 
          &lt;p&gt;1、夯实 SEO 基础（面向 AI 爬虫）：首先确保网站没有阻止 AI 爬虫访问的技术障碍（如 robots.txt 或 llms.txt 设置不当）。其次做好跨端适配，确保在各种设备上都能良好显示和使用。最后使用 HTTPS 加密，搜索引擎更倾向于优先展示 HTTPS 网站。&lt;/p&gt; 
          &lt;p&gt;2、结构化数据（ Schema Markup ）深度应用：Schema 标记是一种标准化的词汇表，可添加到网站 HTML 中，帮助搜索引擎和 AI 更精准地理解页面的含义和实体关系。基于此，Schema 标记直接向 AI 提供相关内容的「元数据」，降低 AI 理解内容的难度和歧义性，也提升了内容被准确解读和采信的可能性。&lt;/p&gt; 
          &lt;p&gt;3、实体优化：是指内容和网站结构中清晰地定义和关联这些核心实体，帮助 AI 准确识别并理解它们。例如，在内容中一致地使用品牌、产品、人物、logo 等的标准名称，建立内部链接将相关实体页面连接起来；在权威第三方平台（如维基百科、行业数据库、知识图谱网站）上建立和完善品牌相关的实体信息。&lt;/p&gt; 
          &lt;p&gt;4、建立「防御性 GEO 」机制：GEO 策略不仅要着眼于优化正面信息，更要建立常态化的品牌 AI 声誉监测体系。主动发现并追踪 AI 回答中关于品牌的潜在负面、不实或过时信息。一旦发现问题，可以通过发布和优化更权威、全面、可信的官方信息（如声明、FAQ 、事实核查文章）来「对冲」负面内容，争取让 AI 采信正面信息源。&lt;/p&gt; 
          &lt;p&gt;&lt;strong&gt;平台选择与分发策略：&lt;/strong&gt;&lt;/p&gt; 
          &lt;p&gt;我们得承认，即便内容质量再高，如果发布在 AI 不常访问或不信任的平台上，品牌被引用的效果也会大打折扣。&lt;/p&gt; 
          &lt;p&gt;所以，企业可以优先在行业内公认的网站、知名媒体或高权重平台发表内容。其次，优先在 AI 索引的主流平台发布内容，满足 LLM 抓取习惯。最后，切忌随意更换品牌的官方表述、历史声誉等信息。（笔者还认为，在分发过程中，明确内容作者的专业背景、从业经验、相关认证等，通过关联作者信息的形式，也有利于品牌的索引曝光。）&lt;/p&gt; 
          &lt;p style="text-align:center"&gt;&lt;img height="506" src="https://oscimg.oschina.net/oscnet/up-64e508687930b7aab1ed8f64aca958a8245.png" width="826" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
          &lt;div&gt; 
           &lt;div&gt; 
            &lt;p style="text-align:center"&gt;&lt;span style="color:#95a5a6"&gt;图源：上海源易信息&lt;/span&gt;&lt;/p&gt; 
            &lt;div&gt; 
             &lt;div&gt; 
              &lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
              &lt;h3&gt;目前的困难与挑战&lt;/h3&gt; 
              &lt;p&gt;总体来说，GEO 目前依旧是一个新兴的研究领域，自带历史局限性。例如，2022 年，GEO 刚被提出时，网上就出现了「如何确保优化后的内容准确可信」、「过度优化导致优质小众内容被淹没」的声音。&lt;/p&gt; 
              &lt;p&gt;而在笔者咨询了一圈企业主之后，也得到了更多的负面声音：&lt;/p&gt; 
              &lt;ul&gt; 
               &lt;li&gt; &lt;p&gt;除了需要支付 SEO 的费用，还要支付 GEO 的费用，徒增运营成本&lt;/p&gt; &lt;/li&gt; 
               &lt;li&gt; &lt;p&gt;如何防止竞争企业在 AI 平台上对品牌进行恶意抹黑&lt;/p&gt; &lt;/li&gt; 
               &lt;li&gt; &lt;p&gt;AI 生成内容对原创内容的引用、改编和合成，引发关于版权、知识产权归属的法律和伦理问题&lt;/p&gt; &lt;/li&gt; 
               &lt;li&gt; &lt;p&gt;那些跟模型厂商有合作，或者有关联的品牌，能否介入 LLM 的参数权重&lt;/p&gt; &lt;/li&gt; 
              &lt;/ul&gt; 
              &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
              &lt;p&gt;类似还有很多，笔者就不展开了。我们不得不承认：原本在 SEO 时代下存在的，恶性竞价、优化转单等问题，依旧可能在 GEO 时代发生。除此之外，生成式 AI 内容优化还自带与 AI 深度结合下的发展挑战：&lt;/p&gt; 
              &lt;ul&gt; 
               &lt;li&gt; &lt;p&gt;算法不透明、难以解释。目前，大模型的「黑箱」问题在短期内难以解决，但随着技术发展与市场监管的要求，生成引擎提供商可能会有限度地提高算法透明度，或提供更明确的内容指南，帮助创作者更好地进行优化；&lt;/p&gt; &lt;/li&gt; 
               &lt;li&gt; &lt;p&gt;网站的机器可读性低。在生成式 AI 深度介入内容生态后，「机器可读性」 的内涵已远超传统 SEO 中对 HTML 结构、标签规范的基础要求，而类似于 llms.txt 等标准，还未大范围推行；&lt;/p&gt; &lt;/li&gt; 
               &lt;li&gt; &lt;p&gt;数据偏见的固化与放大。生成式 AI 的优化能力高度依赖训练数据的质量，而历史数据中隐含的社会偏见（如性别刻板印象、地域认知偏差）会被模型学习并在优化过程中强化。这种偏见的 「代际传递」 难以通过简单的算法调整消除，因为它根植于数据反映的历史认知偏差。&lt;/p&gt; &lt;/li&gt; 
               &lt;li&gt; &lt;p&gt;GEO 还没有像 SEO 一样，走向体系化。SEO ，不仅有搜索引擎平台出的规范、教程以及适用范围，在业内同样有专业的从业资格认证，且诞生出了 SEO 优化师这一垂直岗位。反观 GEO ，就像笔者开篇所写，一个词优化就需要 6000 块，谁定的价？优化方案是？优化平台是？目前在很多方面仍不透明。&lt;/p&gt; &lt;/li&gt; 
              &lt;/ul&gt; 
              &lt;p&gt;......&lt;/p&gt; 
              &lt;p&gt;可见，让 AI 有效回答，并满足人类的实际需求，并不是一件简单的事情。但笔者还是认为：无论是 GEO ，还是 LLMO ，LLM 都可以拥有其自身的回答风格与范式，这也是目前绝大部分模型厂商的态度。至于商业品牌的曝光需求，不妨落在特定业务场景下的 AI Agent 中去解决，或许所生成的内容、提供的服务，更易被提问者接受。&lt;/p&gt; 
              &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
              &lt;p&gt;&lt;strong&gt;参考资料：&lt;/strong&gt;&lt;/p&gt; 
              &lt;p&gt;1、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmax.book118.com%2Fhtml%2F2025%2F0613%2F8051115042007077.shtm" rel="nofollow" target="_blank"&gt;上海源易信息《GEO 营销增长白皮书》&lt;/a&gt;&lt;/p&gt; 
              &lt;p&gt;2、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdigitalzoo.com.hk%2Fblog%2Fseo%25e5%25b0%2588%25e9%25a1%258c%2Fgeo-llmo-aeo-%25e5%2585%25a8%25e9%2583%25a8%25e9%2583%25bd%25e5%258f%25aa%25e6%2598%25afseo%25e8%2580%258c%25e5%25b7%25b2%2F" rel="nofollow" target="_blank"&gt;https://digitalzoo.com.hk/blog/seo%e5%b0%88%e9%a1%8c/geo-llmo-aeo-%e5%85%a8%e9%83%a8%e9%83%bd%e5%8f%aa%e6%98%afseo%e8%80%8c%e5%b7%b2/&lt;/a&gt;&lt;/p&gt; 
              &lt;p&gt;3、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmister-seo.com%2Fllmo-gaio-geo%2F" rel="nofollow" target="_blank"&gt;https://mister-seo.com/llmo-gaio-geo/&lt;/a&gt;&lt;/p&gt; 
             &lt;/div&gt; 
            &lt;/div&gt; 
           &lt;/div&gt; 
          &lt;/div&gt; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/7819858/blog/18686293</link>
      <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/18686293</guid>
      <pubDate>Sun, 03 Aug 2025 06:31:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>谷歌 Android Studio 免费 Agent 模式上线</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌在其官方开发者博客及 Google I/O2025 大会上宣布，Android Studio 正式推出免费的 Agent 模式，为安卓应用开发引入了革命性的 AI 辅助功能。这一功能的发布不仅大幅提升了开发效率，还凭借其智能化的交互方式和灵活的自定义规则支持，被业界认为是对苹果开发生态的有力挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Android Studio 的 Agent 模式是基于 Gemini2.5Pro 的 AI 辅助功能，旨在通过自然语言交互帮助开发者完成复杂、多步骤的开发任务。相较于传统的代码补全或建议功能，Agent 模式能够深入理解整个项目上下文，自动制定执行计划，并在开发者指导下完成从代码生成到错误修复的完整工作流。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="343" src="https://oscimg.oschina.net/oscnet/up-c81c59459ff6d229a26c159791d8a845b17.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心功能亮点：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;自然语言任务描述：开发者只需用自然语言描述目标，例如「修复项目中的构建错误」或「为应用添加深色模式支持」，Agent 模式即可生成跨多个文件的执行计划，自动编辑代码、添加依赖并修复错误。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;UI 代码快速修改：Agent 模式支持直接选中并修改 UI 代码。例如，开发者可以要求「在主屏幕添加一个‘关注’按钮」或「减少某个组件的内边距」，Agent 会精准定位相关文件并提出修改建议，开发者可通过「接受」或「拒绝」按钮进行审核。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;自定义规则支持：通过 Prompt Library，开发者可以设置项目特定的编码风格或技术栈偏好，例如「始终使用 Kotlin 生成简洁代码」。这些规则将自动应用于后续任务，确保输出的代码符合项目标准。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;百万 Token 上下文窗口：免费版本的 Agent 模式提供有限的上下文窗口，但订阅 Google AI Ultra 或使用 Gemini API 密钥的开发者可解锁 Gemini2.5Pro 的 100 万 Token 上下文窗口，支持处理超大规模代码库和复杂任务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌强调，Agent 模式不仅能处理常规任务，还能通过 Model Context Protocol （MCP）与外部工具集成，例如直接从 Android Studio 创建 GitHub 拉取请求，进一步扩展其功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;效率飞跃:从繁琐任务到创意开发&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式的推出旨在解放开发者，让他们从繁琐的重复性工作中解脱出来，专注于更具创造性的开发任务。例如，开发者可以委托 Agent 模式完成以下任务:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;自动化依赖更新：通过 Version Upgrade Agent，自动分析项目依赖、解析发行说明并更新到&lt;span&gt;最新&lt;/span&gt;兼容版本，同时生成详细的变更报告。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;用户旅程测试：开发者可以用自然语言描述用户旅程（如「测试登录流程」），Agent 模式会自动生成测试脚本并在虚拟或物理设备上运行，输出详细结果。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;多文件重构：如将硬编码字符串提取到 strings.xml 文件，或对整个项目进行复杂的代码重构，Agent 模式都能逐步执行并允许开发者实时审查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌表示，Agent 模式通过结合 Android Studio 的内置工具（如代码搜索、构建系统和 UI 检查器），能够以最小的监督完成从原型设计到错误修复的全流程任务，显著加速开发周期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式的免费开放被视为谷歌对苹果 Xcode 生态的强力回应。苹果的 Xcode 虽然在 iOS 开发中占据主导地位，但其 AI 辅助功能相对滞后，缺乏类似 Agent 模式的自主 AI 特性。谷歌通过免费提供 Agent 模式（默认配额充足）以及支持 Gemini2.5Pro 的付费订阅模式，降低了开发者的使用门槛，同时提供了更高的灵活性和性能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，Android Studio Narwhal Feature Drop（2025.2 版本）还引入了其他增强功能，如:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;Google Play 政策洞察：通过 Lint 检查提供 Play Store 政策合规性建议，帮助开发者避免上架问题。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;XR 开发支持：新增 Jetpack XR 项目模板和嵌入式布局检查器，优化了扩展现实（XR）应用的开发体验。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;Kotlin K2 模式：支持 Live Edit 和 Compose Preview 等功能，提升 Kotlin 开发的流畅性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式目前已在 Android Studio Narwhal Feature Drop（2025.2Canary 版本）中向所有用户开放，商业订阅用户将在未来几周内获得更完整的功能支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管该功能仍处于实验阶段，部分开发者反馈指出其在调用外部工具或处理特定场景时存在局限性，例如无法完全访问源文件或修改外部资源。谷歌已表示正在积极解决这些问题，并计划在未来版本中支持更完整的 MCP 功能，如 Streamable HTTP 传输和外部上下文资源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364062</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364062</guid>
      <pubDate>Sun, 03 Aug 2025 06:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
