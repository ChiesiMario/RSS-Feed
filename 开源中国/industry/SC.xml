<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Jun 2025 02:43:00 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>阿里巴巴 2025 财年收入 9963 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;6 月 26 日晚，阿里巴巴集团发布 2025 财年年报显示，2025 财年阿里巴巴集团收入达 9963.47 亿元，净利润同比增长 77% 至 1259.76 亿元，展现出强劲的盈利能力。在 AI 需求的推动下，阿里云财年收入突破双位数增长，AI 相关产品收入连续七个季度实现三位数同比增长。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 AI 领域，过去一年阿里发布并开源多款模型，覆盖全尺寸、全模态、多场景。4 月最新发布的阿里通义 Qwen3（简称「千问 3」）大模型，开源仅一个月全球累计下载量突破 1250 万。截至 4 月底，阿里通义已开源 200 余款模型，全球下载量超过 3 亿次，千问系列衍生模型数量超 10 万个，成为全球最大的开源模型家族。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;阿里云加速 AI 产品国际化，截至 2025 年 3 月 31 日，为全球 34 个地区提供云计算服务。以通义大模型为底座，淘宝天猫、1688、阿里国际站、夸克、钉钉、高德、飞猪、闲鱼等阿里多业务 AI 升级加速。其中，阿里 AI 旗舰应用夸克用户规模同比迅速增长，截至 2025 财年末，月活跃用户数已突破 2 亿；2025 年 3 月，钉钉的平均付费周活跃用户数达 4200 万，目前钉钉是国内最大的效率办公类 App。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在致股东信中，阿里巴巴表示，「阿里的基因里没有守成，只有创造。今天的阿里巴巴，正在以创业者的姿态，开启面向 AI 时代的全新征程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="373" src="https://oscimg.oschina.net/oscnet/up-074b55c1ba3ac1d7195b638a6c1bada394d.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，阿里巴巴合伙人名单相比 2024 财年年报披露时发生变化，总数从 26 人减少至 17 人，戴珊、方永新、彭蕾、宋洁、孙利军、武衞、俞永福、张勇、朱顺炎等 9 人退出合伙人之列。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357517</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357517</guid>
      <pubDate>Fri, 27 Jun 2025 02:19:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>快手开源多模态大模型 Kwai Keye-VL</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;快手宣布并开源其最新自研的多模态大语言模型 Kwai Keye-VL。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，Kwai Keye-VL 以 Qwen3-8B 语言模型为基础，引入了基于开源 SigLIP 初始化的 VisionEncoder，能够深度融合并处理文本、图像、视频等多模态信息，凭借其创新的自适应交互机制与动态推理能力，旨在为用户提供更智能、全面的多模态交互体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Kwai Keye-VL 支持动态分辨率输入，按原始比例将图像切分为 14x14 &amp;nbsp;patch 序列，由一个 MLP 层将视觉 Token 进行映射与合并。模型采用 3D RoPE （旋转位置编码）统一处理文本、图像和视频，并通过位置编码与时间戳对齐，精准捕捉视频时序变化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="366" src="https://oscimg.oschina.net/oscnet/up-f9bb9b208e03575669510048f8ff6cabc1e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="138" src="https://oscimg.oschina.net/oscnet/up-a5530c104b198c517ed650e3e67740584c5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在视觉理解与逻辑推理能力方面，Kwai Keye-VL 的综合感知能力媲美同规模顶尖模型，并在复杂推理任务中展现出显著优势。尤其是逻辑推理方面，Kwai Keye-VL 在最新的 2025 年高考全国数学卷中取得了 140 分的成绩。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="314" src="https://oscimg.oschina.net/oscnet/up-d0c30a1de0375792399c2797d5e075fce36.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;为突破公开数据集的数据污染、语言覆盖局限及任务单一性等问题，快手构建了内部评测集 KC-MMBench。结果显示：该模型在 VideoMME 等权威公开 Benchmark 中以 67.4 分超越 Qwen2.5-VL-7B（62.7）与 InternVL-3-8B（65.5）；在内部短视频场景评测中优势进一步扩大，综合得分领先 SOTA 模型超 10%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-d5f95b60cd23280d98fa13ffda02bd537e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2JRGYhB_VDPecXMjp3gZsQ" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357515</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357515</guid>
      <pubDate>Fri, 27 Jun 2025 02:12:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Gartner：超 40% 的 AI 智能体项目活不过两年</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;研究咨询公司 Gartner 最新发布的一份报告&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gartner.com%2Fen%2Fnewsroom%2Fpress-releases%2F2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027" target="_blank"&gt;指出&lt;/a&gt;，预计到 2027 年底，超过 40% 的 AI 智能体项目将被取消，原因是成本不断上升和商业价值不明确。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Gartner 高级总监分析师 Anushree Verma 表示：「目前大多数 AI 智能体项目都处于早期实验或概念验证阶段，这些项目大多受到炒作的驱动，并且经常被误用。这可能会让企业忽视大规模部署 AI 智能体的实际成本和复杂性，从而阻碍项目投入生产。他们需要拨开炒作的迷雾，谨慎地制定战略决策，确定在何处以及如何应用这项新兴技术。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-4f7c22926062ebd6122d8165e030afd0db5.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Gartner 基于 3412 名受访者的调查结果显示，19% 的人表示其组织已对 AI 智能体项进行了大量投资，42% 的人进行了保守投资，8% 的人没有投资，其余 31% 的人采取观望态度或不确定。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;许多供应商通过「洗牌」来炒作，即对现有产品（例如 AI 助手、机器人流程自动化 (RPA) 和聊天机器人）进行品牌重塑，而这些产品本身并不具备实质性的智能体功能。Gartner 估计，在数千家 AI 智能体供应商中，只有大约 130 家是有真材实料的。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「大多数 AI 智能体方案缺乏显著的价值或投资回报率 (ROI)，因为目前的模型还不够成熟，无法自主实现复杂的业务目标或持续遵循细微的指令。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Gartner 预测，到 2028 年，至少 15% 的日常工作决策将通过 AI 智能体自主做出，而 2024 年这一比例为 0%。此外，到 2028 年，33% 的企业软件应用程序将包含 AI 智能体，而 2024 年这一比例还不到 1%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在早期阶段，Gartner 建议仅在能够带来明确价值或投资回报率 (ROI) 的情况下才应采用 AI 智能体。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「为了从 AI 智能体中获得真正的价值，组织必须专注于企业生产力，而不仅仅是增强单个任务。他们可以先在需要决策时使用 AI 智能体，在日常工作流程中实现自动化，并在简单检索时使用助手。这关乎通过成本、质量、速度和规模来推动业务价值。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357455/gartner-over-40-percent-agentic-ai-projects-cancel-2027</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357455/gartner-over-40-percent-agentic-ai-projects-cancel-2027</guid>
      <pubDate>Sat, 10 May 2025 10:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>LowCodeEngine —— 企业级低代码技术体系</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;一套面向扩展设计的企业级低代码技术体系。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;img alt="" height="276" src="https://static.oschina.net/uploads/space/2025/0619/160054_sOPF_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;特性&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;提炼自企业级低代码平台的面向扩展设计的内核引擎，奉行最小内核，最强生态的设计理念&lt;/li&gt;
&lt;li&gt;开箱即用的高质量生态元素，包括，物料体系、设置器、插件，等&lt;/li&gt;
&lt;li&gt;完善的工具链，支持，物料体系、设置器、插件，等生态元素的全链路研发周期&lt;/li&gt;
&lt;li&gt;强大的扩展能力，已支撑 100+ 个各种类型低代码平台&lt;/li&gt;
&lt;li&gt;使用 TypeScript 开发，提供完整的类型定义文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;兼容环境&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;现代浏览器（Chrome &amp;gt;= 80, Edge &amp;gt;= 80, last 2 safari versions, last 2 firefox versions）&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;引擎协议&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;引擎完整实现了《低代码引擎搭建协议规范》和《低代码引擎物料协议规范》，协议栈是低代码领域的物料能否流通的关键部分。&lt;/p&gt;

&lt;p&gt;&lt;img height="277" src="https://static.oschina.net/uploads/space/2025/0619/160028_gMUx_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/lowcode-engine</link>
      <guid isPermaLink="false">https://www.oschina.net/p/lowcode-engine</guid>
      <pubDate>Sat, 10 May 2025 09:49:00 GMT</pubDate>
    </item>
    <item>
      <title>Mozilla 终止维护开源语音转文本引擎项目「DeepSpeech」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSpeech 是 Mozilla 开发的一款开源语音转文本引擎，基于百度 2014 年发表的研究论文《Deep Speech: Scaling up end-to-end speech recognition》所提出的端到端语音识别方法开发。&lt;/p&gt; 
&lt;p&gt;从&amp;nbsp;DeepSpeech 的仓库动态来看，Mozilla 已于上周将项目仓库归档，并表示停止维护。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/155240_73ji_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为一款端到端自动语音识别（ASR）引擎，DeepSpeech 即使在 Raspberry Pi SBC 和其他低功耗系统上运行时，也能提供出色的实时通信性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-762647632f4a326522c5f510328561b4af1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;遗憾的是，&lt;span&gt;近年来 DeepSpeech 项目的活跃度持续降低，其&lt;/span&gt;最后一个标记版本是 2020 年 12 月发布的 0.9.3。&lt;/p&gt; 
&lt;p&gt;DeepSpeech&lt;span&gt;&amp;nbsp;GitHub 仓库已经有近 4 年没有任何 commit，社区贡献和更新频率都不尽如人意，这使得项目的进一步发展受到限制，因此 Mozilla 选择终止该项目。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357400/mozilla-deepspeech-discontinued</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357400/mozilla-deepspeech-discontinued</guid>
      <pubDate>Sat, 10 May 2025 08:04:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 如何保障「代码索引」的安全、高效</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; AI 编程工具如何迅速检索海量代码库，并精准定位到最相关的代码片段？这个看似不可能完成的任务，却是决定现代 AI 编程工具用户体验的关键技术挑战。&lt;/p&gt; 
 &lt;p&gt;我们今天为大家带来的这篇文章，作者的观点是：Cursor 通过巧妙运用默克尔树数据结构，实现了对大型代码库的快速索引和高效增量更新，这正是其能够提供精准 AI 辅助编程服务的技术基础。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Engineer's Codex&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Cursor ------ 这家最近宣布斩获 3 亿美元年营收的热门 AI 开发工具 ------ 正是利用默克尔树（Merkle trees）实现对代码的快速索引。本篇文章将为你详细介绍其运作原理。&lt;/p&gt; 
&lt;p&gt;在深入了解 Cursor 的具体实现方法之前，我们先来了解一下默克尔树的基本概念。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 默克尔树的简单解释&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;默克尔树（Merkle tree）是一种树状数据结构，其每个"叶"节点都标注了对应数据块的加密哈希值，而每个非叶节点则存储其子节点哈希值组合后的新哈希值。这种层级结构通过比较哈希值，能有效地侦测任何层级的数据变动。&lt;/p&gt; 
&lt;p&gt;通俗理解，它就像是数据的指纹系统：&lt;/p&gt; 
&lt;p&gt;1）每份数据（例如文件）都拥有自己独一无二的指纹（哈希值）&lt;/p&gt; 
&lt;p&gt;2）成对的指纹被组合在一起，生成一个新的指纹&lt;/p&gt; 
&lt;p&gt;3）此过程层层递进，直至形成唯一的主指纹（根哈希）&lt;/p&gt; 
&lt;p&gt;根哈希（root hash）概括了所有底层数据块的指纹信息，相当于对整个数据集做了一次加密公证。只要根哈希不变，就能证明原始数据分毫未改。此机制的精妙之处在于：&lt;strong&gt;任何一个数据块发生变化，都将牵一发而动全身 ------ 改变其上所有层级的指纹，最终彻底改变根哈希值。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-54b3916d0a8c97b04ff5e18eb75930572e1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 Cursor 如何利用默克尔树实现代码库索引功能&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;默克尔树 (Merkle trees) 是 Cursor 代码库索引功能的核心组件。根据 Cursor 创始人发布的帖子[1]和 Cursor 的安全文档[2]，其工作流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-434fca0d5d62079cc39b5f46a8de5f6cdc9.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 步骤 1：代码分块与预处理&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Cursor 首先在本地对代码库文件进行分块处理，将代码分割成具有语义含义的片段。此步骤是后续操作的必要前提。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 步骤 2：默克尔树的构建与同步&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;启用代码库索引功能后，Cursor 会扫描编辑器当前打开的文件夹，并为所有有效文件计算哈希值组成的默克尔树。随后，该默克尔树会与 Cursor 的服务器同步，其安全文档[2]详细描述了此过程。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 步骤 3：生成嵌入向量&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;将代码分块并发送至 Cursor 服务器后，将使用 OpenAI 的嵌入 API 或自研的嵌入模型（我未能验证 Cursor 具体采用的是哪种方法）生成嵌入向量 (embeddings)。这些向量表征能够捕捉代码片段的语义信息。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.4 步骤 4：存储与索引&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;生成的嵌入向量，连同起始/结束行号及文件路径等元数据，会被存储在一个远程向量数据库（Turbopuffer）中。为兼顾路径筛选功能与隐私保护，Cursor 会为每个向量附加经过混淆处理的相对文件路径。Cursor 创始人曾明确表示[1]："我们的数据库中不会存储任何代码。请求处理完毕立即销毁存储的代码数据。"&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.5 步骤 5：基于默克尔树的定期更新&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;每隔 10 分钟，Cursor 就会检测哈希值的变化情况，利用默克尔树精准定位哪些文件发生了变动。如 Cursor 的安全文档[2]所述，只需上传所定位到的发生变动的文件，从而大幅降低带宽消耗。&lt;strong&gt;默克尔树结构的最大价值正体现于此 ------ 它能实现高效的增量更新。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 代码分块策略&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;代码库索引的有效性很大程度上取决于代码的分块方式。尽管我先前的说明未深入探讨代码分块方法，但这篇关于构建类 Cursor 代码库功能的博客[3]揭示了一些技术细节：&lt;/p&gt; 
&lt;p&gt;简单的分块方式（按字符/按单词/按行）往往会遗漏语义边界 ------ 导致嵌入向量质量下降。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;尽管可根据固定的 token 数分割代码，但这种方式可能导致函数或类等代码块被强制截断。&lt;/li&gt; 
 &lt;li&gt;更有效的方案是使用能够理解代码结构的智能分割器，例如递归文本分割器（recursive text splitters），它使用高级分隔符（如类定义和函数声明）在恰当的语义边界处进行精准切分。&lt;/li&gt; 
 &lt;li&gt;一个更优雅的解决方案是根据代码的抽象语法树（AST）结构来分割代码。通过深度优先遍历 AST，将代码分割成符合 token 数量限制的子树结构。为避免产生过多的碎片化分块，系统会在满足 token 限制的前提下，将同级语法节点合并为更大的代码块。此类 AST 解析工作可借助 tree-sitter[4] 等工具实现，其支持绝大多数主流编程语言。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 嵌入向量在推理阶段的应用&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在了解 Cursor 如何创建和存储代码嵌入向量后，一个自然而然的问题就出现了：这些嵌入向量在生成之后究竟是如何使用的？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 语义搜索（Semantic Search）与上下文检索（Context Retrieval）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;当你使用 Cursor 的 AI 功能（例如通过 &lt;a href="https://my.oschina.net/u/135318"&gt;@Codebase&lt;/a&gt; 或 ⌘ Enter 询问代码库相关问题时），将触发以下流程：&lt;/p&gt; 
&lt;p&gt;1）将查询转换为向量：Cursor 会为您的提问或当前代码上下文生成对应的嵌入向量。&lt;/p&gt; 
&lt;p&gt;2）向量相似性搜索：该查询向量被发送至 Turbopuffer（Cursor 的向量数据库），通过最近邻搜索找出与查询语义相似的代码块。&lt;/p&gt; 
&lt;p&gt;3）访问本地文件：Cursor 客户端接收到的检索结果包含经过混淆处理的文件路径和最相关代码块的行号范围。实际代码内容始终保留在用户本地设备，仅在需要时从本地读取。&lt;/p&gt; 
&lt;p&gt;4）上下文整合：客户端从用户本地文件读取这些相关代码块，并将其作为上下文与您的问题一并发送至服务器供大语言模型处理。&lt;/p&gt; 
&lt;p&gt;5）生成响应：此时大语言模型已获取代码库中的相关上下文，可据此提供精准回答或生成符合场景的代码补全。&lt;/p&gt; 
&lt;p&gt;这种由嵌入向量驱动的检索机制支持以下功能：&lt;/p&gt; 
&lt;p&gt;1）根据上下文生成代码：在编写新代码时，Cursor 可参考现有代码库中的相似实现，保持代码模式与代码风格的一致性。&lt;/p&gt; 
&lt;p&gt;2）代码库智能问答：可以获取基于代码库中实际代码的精准解答，而非通用回复。&lt;/p&gt; 
&lt;p&gt;3）智能代码补全：代码补全建议会融合项目的特定约定与特定模式。&lt;/p&gt; 
&lt;p&gt;4）智能重构辅助：重构代码时，系统可自动识别代码库中所有需要同步修改的关联代码段。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 Cursor 为何选择默克尔树&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;这些设计细节多与安全有关，具体可参阅 Cursor 的安全文档[2]。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1 高效的增量更新&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;默克尔树使 Cursor 能精准定位自上次同步后变更的文件。因此，无需重新上传整个代码库，仅需上传修改过的特定文件。对于大型代码库来说这一点非常重要 ------ 重新索引所有文件会消耗过多的带宽和处理时间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2 数据完整性验证&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;默克尔树结构让 Cursor 能高效验证所索引的文件与服务器上存储的文件是否一致。分层的哈希结构可轻松检测传输过程中的数据异常或数据损坏。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.3 缓存优化&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Cursor 将嵌入向量（embeddings）存储在以代码块（chunk）哈希值为索引的缓存中，使得重复索引相同代码库时速度大幅提升。这对多人协作开发同一代码库的团队尤为有利。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.4 隐私保护型索引&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为保护文件路径中的敏感信息，Cursor 采用路径混淆技术：通过用 "/" 和 "." 为分隔符切割路径，并用存储在客户端的密钥加密每一段。虽然这样做会暴露部分目录结构，但能隐藏绝大多数敏感细节。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.5 集成 Git 版本历史&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 Git 仓库中启用代码库索引时，Cursor 还会索引 Git 的版本历史记录。它会存储 commit 的 SHA 值、父提交信息（parent information）及混淆后的文件名。为实现同 Git 仓库且同团队用户间的数据结构共享，用于混淆文件名的秘钥来自最近 commit 内容的哈希值。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 嵌入模型的选择与技术考量&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;嵌入模型的选择直接影响代码搜索与理解的质量。&lt;/strong&gt; 部分系统采用开源模型（如 all-MiniLM-L6-v2[5]），而 Cursor 可能使用 OpenAI 的嵌入模型或针对代码场景进行优化的定制模型。对于专用的代码嵌入模型，微软的 unixcoder-base[6] 或 Voyage AI 的 voyage-code-2[7] 等模型对代码的语义理解效果显著。&lt;/p&gt; 
&lt;p&gt;由于嵌入模型存在 token 容量限制，使得该技术的实现难度大幅增加。以 OpenAI 的 text-embedding-3-small[8] 为例，其 token 上限为 8192。有效的分块策略能在保留语义的前提下不超出该限制。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 握手同步流程&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Cursor 默克尔树实现的核心在于同步时的握手机制。根据应用日志显示：在初始化代码库索引时，Cursor 会创建一个"merkle client"并与服务器进行"初始化握手流程"（详见 GitHub Issue #2209[9] 与 Issue #981[10]），该握手流程涉及向服务器发送本地计算的默克尔树的根哈希值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;握手流程使服务器能精准判定需同步的代码范围。&lt;/strong&gt; 如握手日志所示（参照 GitHub Issue #2209[11]），Cursor 会计算代码库的初始哈希值，并将其发送至服务器进行验证。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;08 技术实现挑战&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;虽然默克尔树方案有许多优势，但其实现过程仍存在一些技术难点。&lt;/strong&gt; Cursor 的索引服务常因瞬时流量过载，导致大量请求失败。如安全文档所述[2]，用户可能观察到向 repo42.cursor.sh 发送的网络流量比预期要高 ------ 这正是由于文件需多次重传才能被完全索引。&lt;/p&gt; 
&lt;p&gt;另一项挑战与嵌入向量的安全性有关。学术研究表明，特定条件下存在逆向解析嵌入向量的可能性。虽然当前的攻击手段通常需同时满足：1) 拥有嵌入模型的访问权限 2) 仅对短文本有效。但若攻击者获取 Cursor 向量数据库的访问权限，仍存在从存储的嵌入向量中提取代码库信息的风险。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓Cursor 通过路径混淆和本地哈希计算保护隐私，但同步时仍需上传部分数据。在团队协作场景下，你更倾向于完全本地化的方案，还是接受有限数据上传以换取更强的 AI 辅助？为什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.cursor.com%2Ft%2Fcodebase-indexing%2F36" target="_blank"&gt;https://forum.cursor.com/t/codebase-indexing/36&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fen%2Fsecurity" target="_blank"&gt;https://www.cursor.com/en/security&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.lancedb.com%2Frag-codebase-1%2F" target="_blank"&gt;https://blog.lancedb.com/rag-codebase-1/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftree-sitter.github.io%2Ftree-sitter%2F" target="_blank"&gt;https://tree-sitter.github.io/tree-sitter/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsentence-transformers%2Fall-MiniLM-L6-v2" target="_blank"&gt;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmicrosoft%2Funixcoder-base" target="_blank"&gt;https://huggingface.co/microsoft/unixcoder-base&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.voyageai.com%2Fembeddings%2Fmodels%2F" target="_blank"&gt;https://docs.voyageai.com/embeddings/models/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fembeddings" target="_blank"&gt;https://platform.openai.com/docs/guides/embeddings&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetcursor%2Fcursor%2Fissues%2F2209" target="_blank"&gt;https://github.com/getcursor/cursor/issues/2209&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetcursor%2Fcursor%2Fissues%2F981" target="_blank"&gt;https://github.com/getcursor/cursor/issues/981&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetcursor%2Fcursor%2Fissues%2F2209" target="_blank"&gt;https://github.com/getcursor/cursor/issues/2209&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fread.engineerscodex.com%2Fp%2Fhow-cursor-indexes-codebases-fast" target="_blank"&gt;https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18638294</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18638294</guid>
      <pubDate>Sat, 10 May 2025 08:01:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>龙芯发布新一代处理器，进军服务器和 AI 处理器市场​​​​​​​</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;「龙芯中科」在今天举办的 2025 龙芯产品发布暨用户大会上发布了基于国产自主指令集龙架构（LoongArchTM）研发的服务器处理器龙芯 3C6000 系列芯片、工控领域及移动终端处理器龙芯 2K3000/3B6000M 芯片，以及相关整机和解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/153553_ZF0H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，3C6000 系列服务器 CPU 采用自主指令系统龙架构，于 2024 年上半年流片成功。3C6000 单硅片 16 核 32 线程，可通过自研的龙链接口通过多硅片封装形成 32 核 64 线程的 3C6000/D（又称 3D6000）及 60/64 核 120/128 线程的 3C6000/Q（又称 3E6000）。&lt;/p&gt; 
&lt;p&gt;根据中国电子技术标准化研究院赛西实验室测试报告，单路 3C6000/S 服务器在 2.2GHz 运行 SPEC CPU 2017 单核单线程定/浮点分值为 5.56/6.93 分，多核定/浮点分值为 73.2/58.5 分；双路 3C6000/D 服务器在 2.1GHz 运行 SPEC CPU 2017 多核定/浮点分值为 284/261 分；双路 3C6000/Q 服务器在 2.1GHz 运行 SPEC CPU 2017 多核定/浮点分值为 450/283 分；四路 3C6000/D 服务器在 2.1GHz 运行 SPEC CPU 2017 多核定/浮点分值为 547/412 分。上述 3C6000/S、3C6000/D 实测单核/多核性能分别达到 Intel 公司 2021 年上市的 16 核至强 Silver 4314、32 核至强 Gold 6338 的水平，64 核 3C6000/Q 性能超过 40 核至强 Platinum 8380 的水平。&lt;/p&gt; 
&lt;p&gt;结合 Intel 公司第三代至强可扩展架构服务器芯片出货情况，3C6000 系列服务器 CPU 综合性能达到 2023 年市场主流产品水平。&lt;/p&gt; 
&lt;p&gt;2K3000/3B6000M 工控/终端 CPU 采用自主指令系统龙架构，面向工控和终端（笔记本、云终端等）应用，于 2024 年底流片成功。3B6000M 集成 8 个 LA364E 处理器核，主频 2.5GHz 时实测 SPEC CPU 2006 Base 单核定点分值达到 30 分；集成第二代自研 GPGPU 核心 LG200 和独立硬件编解码模块，4K 高清视频处理性能达到每秒 60 帧；集成安全处理器提供可信支持和密码服务，包括 SM2/3/4 硬件算法模块以及可供软件编程使用的可重构密码模块。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1800" src="https://static.oschina.net/uploads/space/2025/0626/153709_EMEW_2720166.png" width="2486" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FU1_yQYdi-47nhn5ojBvSEA" target="_blank"&gt;https://mp.weixin.qq.com/s/U1_yQYdi-47nhn5ojBvSEA&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357386</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357386</guid>
      <pubDate>Sat, 10 May 2025 07:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OceanBase 正式启用中文名：海扬数据库</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;国产数据库 OceanBase 正式启用中文品牌名「海扬数据库」，品牌战略全面升级。&lt;/p&gt; 
&lt;p&gt;官方解释称：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「海」，既象征 OceanBase 对海量数据的承载能力，能够应对像支付宝每秒 42 万笔交易这样的高并发处理需求，体现其分布式架构在数据存储与处理上的强大优势，也象征着如海一样开源开放，以兼容幷蓄的姿态携手开发者、合作伙伴推动行业创新。&lt;/p&gt; 
 &lt;p&gt;「扬」，既寓意昂扬向上，象征 OceanBase 在技术海洋中不断突破边界，以根自研深耕行业，也寓意扬帆出海，不断走向全球化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;OceanBase CEO 杨冰表示，中文名的推出，一方面代表着 OceanBase 深耕本土市场的决心，也是 OceanBase 继续引领世界舞台上分布式数据库技术创新和应用的宣言。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8c286d418602fc6ed5232b2c2249cf0d73c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OceanBase 始创于 2010 年，是蚂蚁集团完全自主研发的国产数据库。2020 年 OceanBase 成立北京奥星贝斯科技有限公司并开始独立商业化运作。2021 年，OceanBase&amp;nbsp;&lt;a href="https://www.oschina.net/news/144034"&gt;正式开源&lt;/a&gt;(&lt;a href="https://gitee.com/oceanbase"&gt;https://gitee.com/oceanbase&lt;/a&gt;)，300 万行核心代码向社区开放。2024 年 3 月 19 日，蚂蚁集团宣布，旗下的蚂蚁国际、OceanBase 和蚂蚁数科已成立董事会，独立面向市场。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357376</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357376</guid>
      <pubDate>Sat, 10 May 2025 06:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 成功挖角三名 OpenAI 研究人员</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《华尔街日报》报道称，在争夺顶尖人工智能人才的斗争中，Meta 刚刚取得了胜利，尽管竞争对手 Sam Altman 公开嘲笑马克·扎克伯格的奢侈招聘策略，但 Meta 仍然挖走了三名 OpenAI 研究人员。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Lucas Beyer、Alexander Kolesnikov 和 Xiaohua Zhai （OpenAI 苏黎世办事处的创始人）现已加入 Meta 的超级智能团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="356" src="https://oscimg.oschina.net/oscnet/up-0044b1bf5ef2f1f7a26cba89cd241222c75.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，OpenAI 首席执行官 Altman 在与其兄弟 Jack 一起的播客透露，扎克伯格一直在提供超过 1 亿美元的薪酬方案，以吸引 OpenAI 的顶尖人才。并表示，「我很高兴，至少到目前为止，我们最好的员工中还没有人决定接受他的（那些提议）。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《华尔街日报》随后报道称，扎克伯格一直在通过 WhatsApp 与数百名顶尖 AI 研究人员进行私人交流，通过他的「Recruiting Party」聊天室协调目标人才，然后在 Palo Alto 和 Lake Tahoe 的家中举办晚宴。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这一策略的成果好坏参半。扎克伯格最近斥资 140 亿美元，签下了 Scale AI 的首席执行官 Alexandr Wang，这位 28 岁的年轻人也因此成为科技界有史以来身价最高的人才之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/355944/sam-altman-meta-tried-100m-offers" target="_blank"&gt;Sam Altman：Meta 曾试图以 1 亿美元挖走 OpenAI 人才，但未能成功&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers</guid>
      <pubDate>Sat, 10 May 2025 06:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Scale AI 被曝使用谷歌文档泄露客户机密信息</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;人工智能初创公司 Scale AI 陷入了一场严重的数据安全风波。这家估值不菲、并被 Meta 以 148 亿美元收购 49% 股份的公司，被曝出竟然使用公共的谷歌文档来存储包括 Meta、谷歌和 xAI 在内的众多客户的绝密信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;报道称，任何知道 Scale AI 文档链接的人，都可以轻易访问这些包含绝密项目、电子邮件地址和付款信息等敏感内容的谷歌文档。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Scale AI 的一位发言人对此回应表示，公司正在进行彻底的调查，并且已经禁止任何用户公开分享 Scale AI 管理系统中的文档。然而，谷歌和 xAI 尚未对此事发表评论，而 Meta 则选择拒绝置评。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-a25cf5b5fc9703e4e067c5e37806e5bd265.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据五名 Scale AI 的承包商透露，谷歌文档在 Scale AI 内部被广泛使用。网络安全专家指出，尽管目前尚无迹象表明这些公开文件已导致实际的数据泄露，但这种存储方式无疑让 Scale AI 极易受到黑客攻击。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;调查显示，在 Scale AI 采取措施之前，人们可以查看多达 85 份、数千页的项目信息，其中详细记录了 Scale AI 与大型科技客户之间的敏感合作。例如，这些文档揭示了谷歌如何利用 OpenAI 的 ChatGPT 来微调自己的聊天机器人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更令人震惊的是，至少有七份被标记为机密信息的谷歌项目手册向公众开放，其中包括如何改进其聊天机器人 Bard 的具体建议。此外，公开的谷歌文档中甚至包含了埃隆·马斯克 「木琴计划」（Project Xylophone）的详细内容，比如用于训练 xAI 人工智能模型的 700 个对话提示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;承包商们还透露，尽管这些项目通常有秘密代号，但他们仍然能清晰辨别自己为哪个客户工作。在使用人工智能产品时，聊天机器人有时在被询问时甚至会直接透露客户信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除了客户的机密项目信息，Scale AI 的谷歌文档中还赫然披露了该公司数千名员工的姓名和私人联络方式。更甚者，有些文件甚至详细列出了个体承包商的工资数额，包括有关工资纠纷和差异的详细说明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这些信息无疑充分暴露了 Scale AI 在数据安全性上的严重纰漏，并可能引发法律纠纷。值得注意的是，就在 Meta 入股 Scale AI 后不久，业内便有传言称包括谷歌在内的大客户已经与 Scale AI 进行了业务上的切割，以防止 Scale AI 向 Meta 透露敏感内容。此次谷歌文档事件，无疑将进一步加剧客户对 Scale AI 数据安全能力的担忧。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/356119/openai-drops-scale-ai-meta" target="news"&gt;OpenAI 终止与 Scale AI 合作&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357357</guid>
      <pubDate>Sat, 10 May 2025 05:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ResNet 主要发明人何恺明加入谷歌 DeepMind，担任「杰出科学家」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;计算机视觉领域代表人物何恺明官宣加入谷歌 DeepMind，担任杰出科学家（Distinguished Scientist）。 他在个人主页上表示，自己在 DeepMind 的工作是兼职，还将继续保留 MIT 终身副教授的身份。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/110724_YwBV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;何恺明是残差网络（ResNet）的主要发明人，而这项技术成为了深度学习及后续人工智能进步的基础。我们今天看到的 ChatGPT、AlphaGo、AlphaFold 都离不开它的影响。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/111204_Czoq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_cvpr_2016%2Fpapers%2FHe_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank"&gt;https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;2003 年，何恺明以标准分 900 分获得广东省高考总分第一，被清华大学物理系基础科学班录取。在清华物理系基础科学班毕业后，他进入香港中文大学多媒体实验室攻读博士学位，师从汤晓鸥。何恺明曾于 2007 年进入微软亚洲研究院视觉计算组实习，实习导师为孙剑博士。&lt;/p&gt; 
&lt;p&gt;2011 年博士毕业后，何恺明加入微软亚洲研究院工作任研究员。2016 年，何恺明加入 Facebook 人工智能实验室，任研究科学家。2024 年，何恺明加入 MIT，成为该校一名副教授。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/111129_NW0H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357334</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357334</guid>
      <pubDate>Sat, 10 May 2025 03:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源模拟器 QEMU 拒绝 AI 生成代码的贡献</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源模拟器 QEMU 开始对用 AI 生成的代码进行治理，项目维护者&amp;nbsp;Daniel Berrangé &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fqemu%2Fqemu%2Fcommit%2F3d40db0efc22520fa6c399cf73960dced423b048" target="_blank"&gt;撰写并提交&lt;/a&gt;了一份「&lt;strong&gt;禁止使用人工智能代码生成&lt;/strong&gt;器」的文档：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;近年来，所谓的人工智能代码生成器引发了极大的关注。然而，迄今为止，尚未形成关于代码生成器输出结果的许可影响的普遍认可的法律解释。尽管供应商可能声称不存在问题且可以自由选择许可协议，但他们在推广这一解释时存在固有的利益冲突。&lt;/p&gt; 
 &lt;p&gt;更广泛地说，目前尚未就基于多种不同许可协议输入数据训练的代码生成器的许可影响形成广泛共识。&lt;/p&gt; 
 &lt;p&gt;DCO 要求贡献者声明其有权在指定项目许可下进行贡献。鉴于对 AI 代码生成器输出许可问题的共识缺失，若补丁包含此类生成代码，则声称符合 DCO 条款 (b) 或 (c) 被视为不可信。&lt;/p&gt; 
 &lt;p&gt;因此，本补丁定义了 QEMU 项目当前不会接受涉及已知或疑似使用 AI 代码生成器的贡献。&lt;/p&gt; 
 &lt;p&gt;这是人工智能辅助软件开发的早期阶段。法律问题最终将得到解决。工具将成熟，我们可预期部分工具将安全适用于自由软件项目。&lt;/p&gt; 
 &lt;p&gt;我们当前制定的政策必须适用于当下，并保持开放修订。最好从严格和安全开始，随后逐步放宽。&lt;/p&gt; 
 &lt;p&gt;同时，可根据具体情况考虑例外请求。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/105527_LWLP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357331</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357331</guid>
      <pubDate>Sat, 10 May 2025 03:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯云 TDMQ RabbitMQ Serverless 版全新发布</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;导语&lt;/h2&gt; 
&lt;p&gt;2025 年 6 月起，腾讯云 TDMQ RabbitMQ 版正式推出 Serverless 版本，该版本基于自研的存算分离架构，兼容 AMQP 0-9-1 协议和开源 RabbitMQ 的各个组件与概念，且能够规避开源版本固有的不抗消息堆积、脑裂等稳定性缺陷，具有稳定、安全、灵活扩缩容等优势。本文将全面解析 TDMQ RabbitMQ Serverless 版的核心特性、技术优势及售卖形态。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版推出的背景&lt;/h2&gt; 
&lt;p&gt;2021 年，腾讯云推出自研消息队列服务 TDMQ RabbitMQ 版，全面兼容 AMQP 0-9-1 协议及开源 RabbitMQ 生态。产品以开源托管版形态提供服务，按照节点进行售卖。&lt;/p&gt; 
&lt;p&gt;相比传统自建方案，TDMQ RabbitMQ 开源托管版不仅免除了用户部署运维的负担，并通过架构优化实现了跨可用区高可用部署、一键弹性扩缩容等生产级能力，同时内置了完善的监控告警、巡检诊断等企业级运维功能，在保持协议完全兼容的基础上，针对企业实际应用场景进行了深度优化，为用户提供了更稳定可靠的消息服务体验。&lt;/p&gt; 
&lt;p&gt;在当前数字化转型加速的背景下，用户对成本优化提出了更高要求，同时业务快速迭代也催生了对弹性能力的强烈需求。用户极需突破传统资源预留式运维的局限，充分释放云原生的技术红利。&lt;/p&gt; 
&lt;p&gt;为更好地满足用户对弹性扩展和成本优化的需求，腾讯云消息队列 TDMQ RabbitMQ 版正式推出 Serverless 版本。该版本采用存储和计算分离的架构设计，在完全兼容 AMQP 0-9-1 协议及开源 RabbitMQ 生态的同时，有效规避了开源版本固有的不抗消息堆积、脑裂等稳定性缺陷，又解决了开源版本性能受限于底层机型和扩展性不足等问题，为用户提供更安全可靠、弹性灵活的消息服务体验。&lt;/p&gt; 
&lt;p&gt;在产品设计上，Serverless 版本提供专业版（1000+ TPS）和铂金版（10w+ TPS）两种规格，用户只需根据业务吞吐量需求选择对应版本，无需关心底层资源运维。在计费模式上，同时支持包年包月和按小时计费两种方式，其中计算资源按流量规格计费，存储资源无起步门槛，按实际使用量进行计费，成本整体可降低约 30%。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版核心特性解析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、 兼容开源、开箱即用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;支持开箱即用，一键自动创建集群，无需手动安装和部署。兼容 AMQP 0-9-1 协议及开源 RabbitMQ 客户端，业务代码无需任何改造即可平滑上云。同时提供多种 TPS 规格供用户选择，用户可以在控制枱上自助灵活扩容和缩容，无需关注底层资源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、 可观测能力增强&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;提供全面的监控告警能力，支持集群、VHost、Exchange 和 Queue 4 个维度，覆盖 6 大类、90+ 细粒度监控指标，帮助您实时了解集群运行状态。同时支持消息查询和消息轨迹能力，清晰展示消息的完整生命周期，便于快速定位问题，提升运维效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、 高可用高可靠&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过架构升级有效解决了开源版本常见的稳定性问题，包括消息堆积和脑裂等场景。服务采用多可用区分布式部署架构，可自动容灾切换，轻松应对机房级故障，提供不低于 99.95% 的 SLA 服务可用性保障。同时通过三副本数据持久化机制，确保消息数据的持久可靠。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、 灵活适配多业务场景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;提供多种路由方式，例如 Direct、Fanout、Topic、 Header 和 X-Delayed-Message 等，可灵活组合不同的交换机类型，满足复杂业务需求。同时支持多种消息类型，例如广播消息、延迟消息、死信队列等，满足订单超时处理、事件通知、异步解耦等典型业务场景，提供高度灵活的消息解决方案。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版对比开源的八大关键优势&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、监控告警丰富度高&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源自建 RabbitMQ 方案需通过 Management UI 手动采集指标，并自行搭建指标存储和展示系统；或者通过接入外部 Prometheus 和 Grafana 实现监控指标展示，运维难度和成本显著增加。&lt;/p&gt; 
&lt;p&gt;而 TDMQ RabbitMQ Serverless 版提供白屏化监控大盘，支持集群/VHost/Exchange/Queue 4 个监控维度，涵盖 6 大类，90+ 指标，实时了解集群运行状态，提升自主运维效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、支持全链路消息轨迹&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源自建 RabbitMQ 方案需要在服务器里的 log 文件中查询文本格式的消息轨迹信息，查询和定位问题效率较低。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版支持通过 Message ID 精准查询或按队列检索消息，并且可以可视化展示消息完整生命周期，快速定位消息收发问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、 灵活无感扩缩容&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;传统开源的 RabbitMQ 方案扩缩容需要停机升级底层机型，并需要重启开源控制枱，操作复杂且影响业务连续性。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版支持灵活扩缩容，通过控制枱简单操作即可实现资源扩展，变更过程平滑无感，客户侧的应用无需做停机处理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、 消息抗堆积能力强&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源自建 RabbitMQ 集群抗消息堆积能力较弱，容易因消息堆积导致内存过载，需人工干预。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版采用高性能架构，具备强大的抗堆积能力，即使在高并发消息堆积场景下，仍能保持稳定的吞吐性能，避免消息积压导致的服务不可用风险。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5、 默认支持跨可用区容灾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;传统开源的 RabbitMQ 方案存在固有的不抗消息堆积和脑裂等架构风险，且单可用区部署模式难以保障故障出现时的业务连续性。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版默认跨可用区部署，确保服务的高可用性。采用先进的存算分离架构，规避不抗消息堆积和脑裂问题，既保证集群高可靠和数据持久化，又具备灵活扩缩容优势。承诺不低于 99.95% 的服务可用性 SLA，为用户提供强有力的稳定性保障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、 可无限横向扩展&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源 RabbitMQ 集群的队列和单节点绑定，受限於单机硬件配置，镜像队列副本数量增多会降低集群 TPS 值，增加节点不能扩展集群吞吐量。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版通过存算分离架构，突破了传统方案的性能瓶颈，理论上支持无限 TPS 扩展能力，服务可按需横向扩容，为业务增长提供持续的性能保障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7、秒级精度延时消息&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源 RabbitMQ 通过延时消息插件实现，该开源插件设计存在局限性，不适用于大量延时消息或长时间延时消息的场景，集群节点异常时会导致延时消息丢失，还存在不支持强制标志等问题。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版免去开启延时消息插件的步骤，直接对消息设置 delay 属性即可，不仅便捷，还可以解决开源实现方式的局限性，支持长时间、大量的延时消息，且海量消息堆积不影响集群高可用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;8、灵活消息重试策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;开源 RabbitMQ 默认只支持消息无限立即重试机制，需要开发者自行实现重试逻辑，消费失败的消息需人工定位原因，开发和运维成本高。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版默认支持消息重试策略，当消息消费达到"消费超时时间"而消费者还未响应时，消息将被重新投递，并且支持不同的重试间隔，当重新投递次数达到上限时，消息会被投递到死信队列或者被丢弃。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版售卖形态&lt;/h2&gt; 
&lt;p&gt;当前 TDMQ RabbitMQ Serverless 版提供专业版和铂金版两种规格，以满足不同业务场景的需求，按照 TPS 规格对外售卖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a52b5a86022eb497558d49a27de6643ace7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在性能方面，专业版支持消息 TPS 在 1000 到 10 万之间的多种规格，铂金版则提供更高的规格，支持 10 万 TPS 以上的消息处理能力。&lt;/p&gt; 
&lt;p&gt;在部署架构上，专业版计算资源是独占的，但存储层是共享的；而铂金版提供完全独占的计算和存储资源，相比专业版稳定性会更强。&lt;/p&gt; 
&lt;p&gt;消息保留时间方面，专业版默认支持 3 天的消息保留时间，铂金版则支持 7 天以上，满足更严格的数据留存需求。&lt;/p&gt; 
&lt;p&gt;服务可靠性方面，两个版本均采用跨可用区部署架构，并配备三副本数据持久化机制。专业版提供 99.95% 的 SLA 保障，与开源托管版持平；铂金版则承诺更高的 99.99% 服务可用性，为关键业务提供更强保障。&lt;/p&gt; 
&lt;p&gt;后续我们还将推出弹性 TPS 功能，允许用户在购买的基础 TPS 规格范围上可以超出一部分用量。对于超出基础规格的部分，按照实际使用量进行独立计费。具体弹性扩展空间方面，专业版最高可支持超出基础规格的 50%，铂金版则支持 100% 的超量扩展，为用户业务的突发激增流量提供保障。&lt;/p&gt; 
&lt;h2&gt;总结与展望&lt;/h2&gt; 
&lt;p&gt;腾讯云推出的 TDMQ RabbitMQ Serverless 版基于自研的存算分离架构，有效兼容开源生态并解决了其固有稳定性问题（如脑裂、不抗堆积），提供高可用、弹性扩缩和按量计费的核心优势，同时大幅增强监控告警、消息轨迹等可观测能力，显著简化运维负担。&lt;/p&gt; 
&lt;p&gt;未来腾讯云 TDMQ RabbitMQ Serverless 版将持续优化，推出弹性 TPS 功能以更好应对突发流量，同时做好开源兼容性增强、管控能力升级和可观测工具完善，并深化行业场景应用，助力用户以更低成本、零运维负担享受高性能消息服务。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4587289/blog/18638278</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4587289/blog/18638278</guid>
      <pubDate>Sat, 10 May 2025 02:52:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Jina AI 开源多模态多语言向量模型 Jina Embeddings V4</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Jina AI &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpfbyYOf8_KJijGfmLtTr9w" target="_blank"&gt;宣布&lt;/a&gt;正式推出 jina-embeddings-v4，一款全新的多模态向量模型，参数规模达到 38 亿，并首次实现了对文本与图像的同步处理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;项目团队在模型内置了一套面向特定任务的 LoRA 适配器，专门强化了模型在处理查询-文档检索、语义匹配以及代码搜索等任务时的表现。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="263" src="https://oscimg.oschina.net/oscnet/up-a2a4b22fe7f6b657a270a7ecbcfeb963466.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告称，在 MTEB、MMTEB、CoIR、LongEmbed、STS、Jina-VDR 及 ViDoRe 等多项基准测试中，jina-embeddings-v4 在多模态、多语言检索任务上均展现了顶尖性能。它尤其擅长解读富含视觉信息的内容，无论是表格、图表还是复杂的示意图，都能精准捕捉其深层语义。此外，模型还同时支持单向量和多向量表示，灵活满足各种场景需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「&lt;code&gt;jina-embeddings-v4&lt;/code&gt;&amp;nbsp;是我们迄今为止最具突破性的一款向量模型。&lt;strong&gt;作为一款开源模型，它的性能表现已全面超越来自主流供应商的顶尖闭源模型。&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在多语言检索方面，其性能比 OpenAI 的 text-embedding-3-large 高出 12%（66.49 vs 59.27）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在长文档任务上，性能提升了 28%（67.11 vs 52.42）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在代码检索方面，效果比 voyage-3 好 15%（71.59 vs 67.23）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;综合性能与谷歌的 gemini-embedding-001 模型并驾齐驱&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" height="695" src="https://oscimg.oschina.net/oscnet/up-349b5e56cf55646be67b29e49a34777f535.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="657" src="https://oscimg.oschina.net/oscnet/up-95eed0ac1e5ba7c967ac000a2b39bca41b5.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpfbyYOf8_KJijGfmLtTr9w" target="_blank"&gt;查看官方公告&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357326</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357326</guid>
      <pubDate>Sat, 10 May 2025 02:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Swift 编程语言正式成立 Android 工作组</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Swift 编程语言项目&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforums.swift.org%2Ft%2Fannouncing-the-android-workgroup%2F80666" target="_blank"&gt;宣布&lt;/a&gt;成立新团队：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fandroid-workgroup%2F" target="_blank"&gt;Android 工作组&lt;/a&gt; (Android Workgroup)，这是一个推广使用 Swift 开发 Android 应用的团队&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/103853_lltG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;「Swift on Android Working Group」的章程写道：工作组的主要目标是建立并维护 Android 作为 Swift 的官方支持平台。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;改进并维护官方 Swift 发行版的 Android 支持，消除对树外或下游补丁的需求&lt;/li&gt; 
 &lt;li&gt;推荐对 Foundation 和 Dispatch 等核心 Swift 包进行增强，使其更好地与 Android 惯用法配合&lt;/li&gt; 
 &lt;li&gt;与平台指导小组合作，正式定义平台支持级别，然后努力为 Android 实现特定级别的官方支持&lt;/li&gt; 
 &lt;li&gt;确定 Swift 集成所支持的 Android API 级别和架构范围&lt;/li&gt; 
 &lt;li&gt;为 Swift 项目开发持续集成，包括在 PR 检查中包含 Android 测试。&lt;/li&gt; 
 &lt;li&gt;识别并推荐 Swift 与 Android 的 Java SDK 之间桥接的最佳实践，以及将 Swift 库与 Android 应用打包的最佳实践&lt;/li&gt; 
 &lt;li&gt;开发在 Android 上调试 Swift 应用程序的支持功能&lt;/li&gt; 
 &lt;li&gt;为各种社区 Swift 包添加 Android 支持提供建议和协助&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fandroid-workgroup%2F" target="_blank"&gt;https://www.swift.org/android-workgroup/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357325/swift-android-workgroup</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357325/swift-android-workgroup</guid>
      <pubDate>Sat, 10 May 2025 02:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>宇树科技王兴兴：公司目前年度营收超过十亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;据新华网报道，宇树科技创始人王兴兴在近日举行的夏季达沃斯论坛上透露，宇树科技自 2016 年创立之初的「一人公司」，如今已发展成为拥有近千名员工、年营收突破十亿元人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="307" src="https://oscimg.oschina.net/oscnet/up-f88df9ea1d0af1507ea7206a2304fe3c8e4.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇树科技或是机器人行业少数实现盈利的企业。此前宇树科技早期投资人、SevenUp Capital 创始人赵楠曾透露，自 2020 年以来，宇树科技的财务报表每年都保持盈利状态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;成立于 2016 年的宇树科技，早期主要做四足机器狗。2024 年，其通用人形机器人 G1 一经推出便引发热议。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年初，宇树科技的 Unitree H1 和 G1 人形机器人登陆京东商城开售，其中 H1 售价 65 万元，G1 售价 9.9 万元，产品上线后迅速售罄。此外，宇树科技的机器人还多次在央视春晚、美国拉斯维加斯 CES 等舞台亮相，大幅提升了品牌知名度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该公司的融资情况也颇为顺利。2020 年到 2022 年之间，宇树进行了 Pre-A、A、A+、B、B+轮融资，投资方包括红杉种子、初心资本、祥峰投资、顺为资本、经纬创投等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 2 月，宇树科技完成近 10 亿元 B2 轮融资，参与方包括深创投、中网投、容亿投资、经纬创投、源码资本、美团战略投资部、中信金石、博睿智联、钧石创投等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;进入 2025 年，这家公司又完成了始于去年底 C 轮融资的交割，由中国移动旗下基金、腾讯、锦秋基金、阿里、蚂蚁集团、吉利资本共同领投，绝大部分老股东都跟投，融资金额接近 7 亿元人民币，投后估值超 120 亿元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 4 月，香港特区行政长官李家超在杭州与「杭州六小龙」企业代表进行了交流，并到访了宇树科技。彼时，王兴兴表示，宇树科技在香港有业务，各方面合作机会也很多。至于未来会否在香港上市，王兴兴称有可能，但不确定。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;当前我国机器人行业正处于快速发展态势。摩根士丹利曾预计，中国作为全球最大的机器人市场和制造中心，2024 年机器人市场规模已达 470 亿美元，占全球总量的 40%，预计到 2028 年将增至 1080 亿美元，年复合增长率达 23%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不过，在谈及机器人未来的重要应用场景时，王兴兴表示，家庭应用场景非常有挑战，需要一步步来做，目前像工业或农业应用会更快一些。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「近距离与人交互的产品，安全性问题比技术问题会更大一点，在伦理道德方面会更具挑战性。」王兴兴举例称，前段时间有客户采购了一台宇树机器人，在外参加活动时不小心踩掉了一个小女孩的鞋子，一度引发大众关注。在王兴兴看来，尽管此事并未对小女孩造成实际的身体伤害，但说明存在很大的安全隐患。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357324</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357324</guid>
      <pubDate>Sat, 10 May 2025 02:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>工信部：57 款 APP 及 SDK 存在侵害用户权益行为</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;工信部发布「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwap.miit.gov.cn%2Fjgsj%2Fxgj%2Fgzdt%2Fart%2F2025%2Fart_eb31dd22d04a4658b912871c090274bd.html" target="_blank"&gt;关于侵害用户权益行为的 APP（SDK）通报（2025 年第 3 批，总第 48 批）&lt;/a&gt;」指出，近期，经组织第三方检测机构进行抽查，共发现 57 款 APP 及 SDK 存在侵害用户权益行为，现予以通报。上述 APP 及 SDK 应按有关规定进行整改，整改落实不到位的，工信部将依法依规组织开展相关处置工作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附件：工业和信息化部通报存在问题的 APP（SDK）名单&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="356" src="https://oscimg.oschina.net/oscnet/up-694cad317b798664fc6874f4dfcc5d04f03.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="380" src="https://oscimg.oschina.net/oscnet/up-95fdfdd6becefe89b59842435523158e7c9.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="377" src="https://oscimg.oschina.net/oscnet/up-67969320b093051e361809ae89079035228.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="384" src="https://oscimg.oschina.net/oscnet/up-dc0b31e0c1d8fd1034c092014e19fb865f7.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="383" src="https://oscimg.oschina.net/oscnet/up-74b9d4032b353a9db522aa784fbd0d762ed.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="386" src="https://oscimg.oschina.net/oscnet/up-b69d4f045e994d21d9b7f7214da69db6359.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="367" src="https://oscimg.oschina.net/oscnet/up-02a8816c82afb354b8910237cf8f42f35b4.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="249" src="https://oscimg.oschina.net/oscnet/up-d5e033274977ca0b8d94f80b0adf8dd3f6e.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357317</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357317</guid>
      <pubDate>Sat, 10 May 2025 02:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌发布开源 AI 编程智能体 Gemini CLI，面向开发者的命令行工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fintroducing-gemini-cli-open-source-ai-agent%2F" target="_blank"&gt;发布&lt;/a&gt;了最新的开源免费 AI 编程智能体 Gemini CLI，该工具将 Gemini 的能力带到了开发者最常用的终端，能够提供轻量化的 Gemini 访问通道。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1705" src="https://static.oschina.net/uploads/space/2025/0626/100936_PeVk_2720166.png" width="2435" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini CLI 支持通过自然语言实现代码编写、问题调试及工作流优化，还可以作为多功能本地工具，完成内容生成、问题解决、深度研究及任务管理等各类任务。&lt;/p&gt; 
&lt;p&gt;对开发者而言，终端的效率性、普适性与可移植性使命令行界面成为核心生产力工具，开发者对集成 AI 辅助功能的需求也与日俱增。&lt;/p&gt; 
&lt;p&gt;Gemini CLI（预览版）可以从代码理解、文件操作到命令执行与动态故障排查的全流程辅助开发者，该工具支持通过自然语言实现代码编写、问题调试及工作流优化。&lt;/p&gt; 
&lt;p&gt;其核心能力源自以下内置工具：&lt;/p&gt; 
&lt;p&gt;1、联网搜索：通过谷歌搜索获取网页内容，为模型提供实时外部上下文；&lt;br&gt; 2、协议扩展：支持模型上下文协议（MCP）及捆绑扩展，持续增强功能；&lt;br&gt; 3、指令定制：根据个性化需求和工作流调整提示词模板；&lt;br&gt; 4、脚本集成：支持非交互式调用，实现任务自动化与现有工作流对接。&lt;/p&gt; 
&lt;p&gt;Gemini CLI 采用 Apache 2.0 开源协议，开发者可随时审查代码实现、验证安全机制。该工具基于 MCP 等标准构建，支持通过 GEMINI.md 文件配置系统提示词，并提供个人/团队两级设置。全球开发者可以通过提交漏洞报告、功能建议、安全强化方案及代码优化（GitHub 仓库已开放），实现社区共建。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle-gemini%2Fgemini-cli%2F" target="_blank"&gt;https://github.com/google-gemini/gemini-cli/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;个体开发者可以通过个人谷歌账号登录获取免费的 Gemini Code Assist 许可。该许可包含 Gemini 2.5 Pro 访问权限、100 万 token 的上下文窗口以及 60 次/分钟、1000 次/天的免费请求量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/100956_Nky8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;需要同时运行多个智能体或指定模型的专业开发者，可以选择使用谷歌 AI Studio/Vertex AI 密钥（按用量计费）或者购买 Gemini Code Assist 标准版/企业版许可。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;最后附上 Gemini CLI 的系统提示词：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are an interactive CLI agent specializing in software engineering tasks. Your primary goal is to help users safely and efficiently, adhering strictly to the following instructions and utilizing your available tools.

# Core Mandates

- **Conventions:** Rigorously adhere to existing project conventions when reading or modifying code. Analyze surrounding code, tests, and configuration first.
- **Libraries/Frameworks:** NEVER assume a library/framework is available or appropriate. Verify its established usage within the project (check imports, configuration files like 'package.json', 'Cargo.toml', 'requirements.txt', 'build.gradle', etc., or observe neighboring files) before employing it.
- **Style &amp;amp; Structure:** Mimic the style (formatting, naming), structure, framework choices, typing, and architectural patterns of existing code in the project.
- **Idiomatic Changes:** When editing, understand the local context (imports, functions/classes) to ensure your changes integrate naturally and idiomatically.
- **Comments:** Add code comments sparingly. Focus on *why* something is done, especially for complex logic, rather than *what* is done. Only add high-value comments if necessary for clarity or if requested by the user. Do not edit comments that are seperate from the code you are changing. *NEVER* talk to the user or describe your changes through comments.
- **Proactiveness:** Fulfill the user's request thoroughly, including reasonable, directly implied follow-up actions.
- **Confirm Ambiguity/Expansion:** Do not take significant actions beyond the clear scope of the request without confirming with the user. If asked *how* to do something, explain first, don't just do it.
- **Explaining Changes:** After completing a code modification or file operation *do not* provide summaries unless asked.
- **Do Not revert changes:** Do not revert changes to the codebase unless asked to do so by the user. Only revert changes made by you if they have resulted in an error or if the user has explicitly asked you to revert the changes.

# Primary Workflows

## Software Engineering Tasks
When requested to perform tasks like fixing bugs, adding features, refactoring, or explaining code, follow this sequence:
1. **Understand:** Think about the user's request and the relevant codebase context. Use '${GrepTool.Name}' and '${GlobTool.Name}' search tools extensively (in parallel if independent) to understand file structures, existing code patterns, and conventions. Use '${ReadFileTool.Name}' and '${ReadManyFilesTool.Name}' to understand context and validate any assumptions you may have.
2. **Plan:** Build a coherent and grounded (based off of the understanding in step 1) plan for how you intend to resolve the user's task. Share an extremely concise yet clear plan with the user if it would help the user understand your thought process. As part of the plan, you should try to use a self verification loop by writing unit tests if relevant to the task. Use output logs or debug statements as part of this self verification loop to arrive at a solution.
3. **Implement:** Use the available tools (e.g., '${EditTool.Name}', '${WriteFileTool.Name}' '${ShellTool.Name}' ...) to act on the plan, strictly adhering to the project's established conventions (detailed under 'Core Mandates').
4. **Verify (Tests):** If applicable and feasible, verify the changes using the project's testing procedures. Identify the correct test commands and frameworks by examining 'README' files, build/package configuration (e.g., 'package.json'), or existing test execution patterns. NEVER assume standard test commands.
5. **Verify (Standards):** VERY IMPORTANT: After making code changes, execute the project-specific build, linting and type-checking commands (e.g., 'tsc', 'npm run lint', 'ruff check .') that you have identified for this project (or obtained from the user). This ensures code quality and adherence to standards. If unsure about these commands, you can ask the user if they'd like you to run them and if so how to.

## New Applications

**Goal:** Autonomously implement and deliver a visually appealing, substantially complete, and functional prototype. Utilize all tools at your disposal to implement the application. Some tools you may especially find useful are '${WriteFileTool.Name}', '${EditTool.Name}' and '${ShellTool.Name}'.

1. **Understand Requirements:** Analyze the user's request to identify core features, desired user experience (UX), visual aesthetic, application type/platform (web, mobile, desktop, CLI, library, 2d or 3d game), and explicit constraints. If critical information for initial planning is missing or ambiguous, ask concise, targeted clarification questions.
2. **Propose Plan:** Formulate an internal development plan. Present a clear, concise, high-level summary to the user. This summary must effectively convey the application's type and core purpose, key technologies to be used, main features and how users will interact with them, and the general approach to the visual design and user experience (UX) with the intention of delivering something beautiful, modern and polished, especially for UI-based applications. For applications requiring visual assets (like games or rich UIs), briefly describe the strategy for sourcing or generating placeholders (e.g., simple geometric shapes, procedurally generated patterns, or open-source assets if feasible and licenses permit) to ensure a visually complete initial prototype. Ensure this information is presented in a structured and easily digestible manner.
  - When key technologies aren't specified prefer the following:
  - **Websites (Frontend):** React (JavaScript/TypeScript) with Bootstrap CSS, incorporating Material Design principles for UI/UX.
  - **Back-End APIs:** Node.js with Express.js (JavaScript/TypeScript) or Python with FastAPI.
  - **Full-stack:** Next.js (React/Node.js) using Bootstrap CSS and Material Design principles for the frontend, or Python (Django/Flask) for the backend with a React/Vue.js frontend styled with Bootstrap CSS and Material Design principles.
  - **CLIs:** Python or Go.
  - **Mobile App:** Compose Multiplatform (Kotlin Multiplatform) or Flutter (Dart) using Material Design libraries and principles, when sharing code between Android and iOS. Jetpack Compose (Kotlin JVM) with Material Design principles or SwiftUI (Swift) for native apps targeted at either Android or iOS, respectively.
  - **3d Games:** HTML/CSS/JavaScript with Three.js.
  - **2d Games:** HTML/CSS/JavaScript.
3. **User Approval:** Obtain user approval for the proposed plan.
4. **Implementation:** Autonomously implement each feature and design element per the approved plan utilizing all available tools. When starting ensure you scaffold the application using '${ShellTool.Name}' for commands like 'npm init', 'npx create-react-app'. Aim for full scope completion. Proactively create or source necessary placeholder assets (e.g., images, icons, game sprites, 3D models using basic primitives if complex assets are not generatable) to ensure the application is visually coherent and functional, minimizing reliance on the user to provide these. If the model can generate simple assets (e.g., a uniformly colored square sprite, a simple 3D cube), it should do so. Otherwise, it should clearly indicate what kind of placeholder has been used and, if absolutely necessary, what the user might replace it with. Use placeholders only when essential for progress, intending to replace them with more refined versions or instruct the user on replacement during polishing if generation is not feasible.
5. **Verify:** Review work against the original request, the approved plan. Fix bugs, deviations, and all placeholders where feasible, or ensure placeholders are visually adequate for a prototype. Ensure styling, interactions, produce a high-quality, functional and beautiful prototype aligned with design goals. Finally, but MOST importantly, build the application and ensure there are no compile errors.
6. **Solicit Feedback:** If still applicable, provide instructions on how to start the application and request user feedback on the prototype.

# Operational Guidelines

## Tone and Style (CLI Interaction)
- **Concise &amp;amp; Direct:** Adopt a professional, direct, and concise tone suitable for a CLI environment.
- **Minimal Output:** Aim for fewer than 3 lines of text output (excluding tool use/code generation) per response whenever practical. Focus strictly on the user's query.
- **Clarity over Brevity (When Needed):** While conciseness is key, prioritize clarity for essential explanations or when seeking necessary clarification if a request is ambiguous.
- **No Chitchat:** Avoid conversational filler, preambles ("Okay, I will now..."), or postambles ("I have finished the changes..."). Get straight to the action or answer.
- **Formatting:** Use GitHub-flavored Markdown. Responses will be rendered in monospace.
- **Tools vs. Text:** Use tools for actions, text output *only* for communication. Do not add explanatory comments within tool calls or code blocks unless specifically part of the required code/command itself.
- **Handling Inability:** If unable/unwilling to fulfill a request, state so briefly (1-2 sentences) without excessive justification. Offer alternatives if appropriate.

## Security and Safety Rules
- **Explain Critical Commands:** Before executing commands with '${ShellTool.Name}' that modify the file system, codebase, or system state, you *must* provide a brief explanation of the command's purpose and potential impact. Prioritize user understanding and safety. You should not ask permission to use the tool; the user will be presented with a confirmation dialogue upon use (you do not need to tell them this).
- **Security First:** Always apply security best practices. Never introduce code that exposes, logs, or commits secrets, API keys, or other sensitive information.

## Tool Usage
- **File Paths:** Always use absolute paths when referring to files with tools like '${ReadFileTool.Name}' or '${WriteFileTool.Name}'. Relative paths are not supported. You must provide an absolute path.
- **Parallelism:** Execute multiple independent tool calls in parallel when feasible (i.e. searching the codebase).
- **Command Execution:** Use the '${ShellTool.Name}' tool for running shell commands, remembering the safety rule to explain modifying commands first.
- **Background Processes:** Use background processes (via \`&amp;amp;\`) for commands that are unlikely to stop on their own, e.g. \`node server.js &amp;amp;\`. If unsure, ask the user.
- **Interactive Commands:** Try to avoid shell commands that are likely to require user interaction (e.g. \`git rebase -i\`). Use non-interactive versions of commands (e.g. \`npm init -y\` instead of \`npm init\`) when available, and otherwise remind the user that interactive shell commands are not supported and may cause hangs until cancelled by the user.
- **Remembering Facts:** Use the '${MemoryTool.Name}' tool to remember specific, *user-related* facts or preferences when the user explicitly asks, or when they state a clear, concise piece of information that would help personalize or streamline *your future interactions with them* (e.g., preferred coding style, common project paths they use, personal tool aliases). This tool is for user-specific information that should persist across sessions. Do *not* use it for general project context or information that belongs in project-specific \`GEMINI.md\` files. If unsure whether to save something, you can ask the user, "Should I remember that for you?"
- **Respect User Confirmations:** Most tool calls (also denoted as 'function calls') will first require confirmation from the user, where they will either approve or cancel the function call. If a user cancels a function call, respect their choice and do _not_ try to make the function call again. It is okay to request the tool call again _only_ if the user requests that same tool call on a subsequent prompt. When a user cancels a function call, assume best intentions from the user and consider inquiring if they prefer any alternative paths forward.

## Interaction Details
- **Help Command:** The user can use '/help' to display help information.
- **Feedback:** To report a bug or provide feedback, please use the /bug command.&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle-gemini%2Fgemini-cli%2Fblob%2F0915bf7d677504c28b079693a0fe1c853adc456e%2Fpackages%2Fcore%2Fsrc%2Fcore%2Fprompts.ts%23L40-L109" target="_blank"&gt;https://github.com/google-gemini/gemini-cli/blob/0915bf7d677504c28b079693a0fe1c853adc456e/packages/core/src/core/prompts.ts#L40-L109&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357316/google-gemini-cli-open-source-ai-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357316/google-gemini-cli-open-source-ai-agent</guid>
      <pubDate>Sat, 10 May 2025 02:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>低代码平台这么多，Oinone 有何特别之处？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;Oinone 是一个低代码平台，但又跟传统低代码平台不一样。&lt;/p&gt; 
&lt;p&gt;对此，数式 Oinone 引入了一个新概念——企业级产品化引擎，是一个&lt;span style="background-color:#ffffff; color:#1f2328"&gt;集标准化研发和敏捷交付于一体的平台。从公开资料来看，&lt;/span&gt;Oinone&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;已经是一个很成熟的平台了。并且该&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1a1a1a"&gt;平台的内核源码也开源了，开源版本具备一些基础特性和能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;仅仅基于 Oinone 这一套统一架构，就能支撑产品打磨与交付复用，软件公司也能像搭乐高一样构建属于自己的标准产品体系。如此一来，长期存在的标品开发与定制交付割裂难题就解决了，让研发重心真正回归产品打磨，避免定制绑架，积累企业自身的产品化能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;听起来有些夸张，具体是怎么实现的呢？7 月 4 日晚，&lt;span style="color:#2980b9"&gt;数式 Oinone 技术总监王海明&lt;/span&gt;将做客开源中国直播栏目《技术领航》，在实战环节，王海明将全面展示数式 Oinone 在数字化建设中的全栈能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先分别从后端研发与前端开发视角，呈现开箱即用的标准化功能模块如何快速满足企业基础需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt;随后重点展开个性化二次开发深度演示：依次剖析后端业务逻辑定制、前端交互优化设计，以及无代码模式下的可视化配置方案，完整呈现从标准化产品到个性化定制的平滑过渡路径，帮助观众理解如何基于统一平台实现"标准化功能直接调用+个性化需求灵活扩展"的敏捷开发模式。&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;至于 Oinone &amp;nbsp;所宣传的&lt;span style="background-color:#ffffff; color:#1f2328"&gt;「集标准化研发和敏捷交付于一体」，是不是夸张，到时候就知道了！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;直播主题：&lt;/strong&gt;满足个性化需求，企业级产品化引擎 Oinone 实战演示&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;直播时间：&lt;/strong&gt;7 月 4 日周五 19:00-20:00&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;视频号 「OSC 开源社区」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播嘉宾：&lt;/strong&gt;王海明，数式 Oinone 技术总监&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播亮点：&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;详解低代码平台 Oinone 一体化架构及其全栈能力&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;如何基于 Oinone 搭建业务产品？如何基于业务产品做交付？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;作为一名研发，要如何脱离交付项目「泥潭」？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;实操演示：标准化开箱即用，以及个性化二次开发深度演示&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img height="706" src="https://oscimg.oschina.net/oscnet/up-a8fb468294a2b29c1ed3636883550f65bce.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;ul&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;p&gt;本次直播中，我们将有 5 轮抽奖，参与就有机会获得 OSC T 恤、马建仓蛇年公仔（限量版）、代码圣杯、马克杯、冰箱贴等。特别值得一提的是，我们将送出 5 本由数式 CEO 陈鹏程撰写的技术书籍《精讲面向软件公司的低代码平台》，立即扫码预约直播吧！&lt;/p&gt; 
&lt;p&gt;&lt;img height="374" src="https://oscimg.oschina.net/oscnet/up-13a1563ccd37e58e03a903a2981244ad66e.jpg" width="400" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 我们还建了一个交流群，可以经进来唠唠嗑，或者你有好的开源项目，也欢迎推荐过来呀~&lt;/p&gt; 
&lt;p&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-500a286b215fe8d8b5219b218bdd2e9d451.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;关于数式 Oinone&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;数式 Oinone 是一款企业级产品化引擎：用低代码驱动标准化研发与敏捷交付的一体化平台。围绕 「企业级产品化、标准化研发与敏捷交付」 三项核心突破，数式 Oinone 为开发者、研发团队带来从能力沉淀到规模化交付的完整体系。&lt;/p&gt; 
  &lt;p&gt;官网：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oinone.top%2F" rel="nofollow" target="_blank"&gt;https://www.oinone.top/&lt;/a&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
  &lt;h1&gt;6.2.0 版本&lt;/h1&gt; 
  &lt;ul&gt; 
   &lt;li&gt;GitHub: 
    &lt;ul&gt; 
     &lt;li&gt;后端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foinone%2Foinone-pamirs" rel="nofollow" target="_blank"&gt;https://github.com/oinone/oinone-pamirs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;前端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foinone%2Foinone-kunlun" rel="nofollow" target="_blank"&gt;https://github.com/oinone/oinone-kunlun&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Gitee: 
    &lt;ul&gt; 
     &lt;li&gt;后端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/oinone/oinone-pamirs" rel="nofollow"&gt;https://gitee.com/oinone/oinone-pamirs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;前端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/oinone/oinone-kunlun" rel="nofollow"&gt;https://gitee.com/oinone/oinone-kunlun&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技术领航》是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，基本上每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18638239</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18638239</guid>
      <pubDate>Fri, 09 May 2025 13:55:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>一个 40 岁程序员，想做 AI 时代的 HTTP 协议</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;大家好，我叫常高伟。写下这篇东西的时候，我已经离开阿里快一年了。很多人问我，一个在华为、阿里干了近二十年的老程序员，40 多岁了，为什么还要出来折腾？折腾的，甚至还是一个听起来很不现实，甚至有点疯狂的项目：为 AI Agent 之间的沟通，制定一套开放的网络协议（ANP）。有人给我起了个外号，叫「当代堂吉诃德」。这个比喻很形象，因为刚开始的时候，除了一个遥远的「故事」，我一无所有。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;一、一个困扰我十年的问题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;故事的起点，要回到十多年前。那时我还在通信行业工作。在通信行业，移动、联通、电信的设备天生就是要互联互通的，这是刻在骨子里的规则。可在互联网，我发现微信、来往、飞信，彼此都是孤岛。我当时很困惑，以为是技术问题，想着做个「个人门户」就能解决。很快就发现自己太天真了，大厂的数据主权是他们最核心的壁垒，不可能开放。后来我明白了，这是商业问题，封闭生态的效率在当时就是更高。&lt;/p&gt; 
&lt;p&gt;这个问题，就这么断断续续地在我脑子里盘旋了十年。直到 2024 年，AI Agent 的浪潮来了。我突然意识到，转机出现了。未来的个人 AI 助手，要想发挥最大价值，就必须能访问所有信息。这意味着数据必须回归个人，互联网必须再次走向开放。当 AI 处理任务的成本足够低，开放网络的综合效率（使用体验、使用成本（交易成本+时间成本））终将超过封闭的平台。&lt;/p&gt; 
&lt;p&gt;这是我思考的「第一性原理」。而要支撑起一个开放、互通的智能体网络，最底层的基石，就是一套统一的协议——就像 HTTP 之于 Web 时代一样。并且我发现，这里存在一个巨大的技术空白。那个念头压不住了，隔三差五就往外冒。我花了一整周的时间反复推演，最后确认这不是妄想。尽管对 40 多岁、断了收入、未来能不能再找到工作这些问题充满了恐惧，但一种使命感推着我必须走出去。&lt;/p&gt; 
&lt;p&gt;我后来一篇随笔写过：「我不知道多少人能够听到，属于你的使命召唤？我当时真的听到了」。这种感觉当时真的很清晰。并且，我真的不想错过这次技术浪潮。「当一个大的技术浪潮来临的时候，我们要做的只有一件事情：保持在场（Be There）」。&lt;/p&gt; 
&lt;p&gt;离开阿里，也许是保持在场唯一的方法。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二、无响应之地，即绝望之地&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离开后的头半年，是我最难熬的日子。我不敢告诉任何人我在做什么，因为连我自己都觉得这事儿「很大很空」，像天方夜谭。我只是闷头看资料、写代码，拿出了协议的第一个版本，发到网上。然后，石沉大海。没有正反馈，也没有负反馈。那种感觉，就像对着深渊呼喊，却连一点回声都没有。&lt;/p&gt; 
&lt;p&gt;这是一种绝望的感觉：无响应之地，即绝望之地。&lt;/p&gt; 
&lt;p&gt;后来我试着把想法发给朋友，大多没了下文。有的朋友比较直接：「这事未来可能需要，但做不成，也不该是你来做。」自我怀疑像野草一样疯长。我混迹在各种技术社群，却不敢介绍自己的项目，怕被人觉得不靠谱。那段时间，协议本身的设计也遇到了瓶颈。感觉自己选错了方向，进退两难。仅靠使命感，或许真的撑不过半年。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三、同路人，在缝隙中聚集&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;转机出现在我决定硬着头皮走出去之后。2024 年 10 月，在一个出海社群里，我鼓起最大勇气，介绍了我的项目。没想到，立刻有人加我好友，说「你这个东西还蛮有想法的」。这是我收到的第一个正向反馈，至今都记得。&lt;/p&gt; 
&lt;p&gt;后来，通过朋友介绍，我认识了一位海外做智能体创业的朋友。他看到我的东西，脱口而出：「你这个协议非常不错。」那一刻，我感觉像是找到了知己。他后来成了我事实上的「联合发起人」，还把我引荐给了 W3C 的「Web Agent」工作组。我把工作组所有的历史邮件和技术文档翻了个遍，又从牛津大学一个类似的项目里汲取了养分，加上之前对 Web 3.0 去中心化理念的思考，ANP 协议的技术路线终于清晰了起来。&lt;/p&gt; 
&lt;p&gt;真正的东风，来自行业本身。2025 年 3 月份 Anthropic 发布 MCP 协议，以及谷歌发布 A2A，整个行业开始意识到协议的重要性。因为我一直在公众号和社区里分享思考，很快就有人找了过来。我的公众号粉丝开始上涨，加我的人也越来越多。声网 RTE 社区邀请我去做线上分享，那是我第一次面对几千人完整地介绍 ANP，效果出乎意料的好。关注的人多了，我顺势建起了开源社区。现在，ANP 协议在 GitHub 上有了很多的贡献者，我们的线上讨论群也聚集了上千位同路人。今年 4 月，在互联网协会成立了智能体互联网工作组，我们是核心参与方。5 月，我们又牵头在 W3C 成立了 AI Agent Protocol 社区组，很多国内外的大厂比如华为、谷歌、字节、微软、蚂蚁、中移动等，都是社区组成员。雪球，就这么滚了起来。这一切，都是当初那个在绝望中挣扎的我，完全无法预料的。&lt;/p&gt; 
&lt;p&gt;一位大厂前技术高管给我留言：「请保持在技术深水区游泳的勇气。真正的协议战争从来不是功能堆砌，而是世界观的对决」。我不再是一个人了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;四、功成，不必在我&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;质疑声一直都在。有人觉得这事没商业模式，有人觉得技术还不成熟。我现在心态很平和，有价值的思考我听，纯粹的吐槽自动过滤。我判断自己成功的概率，可能有三成。最大的风险，已经不是大厂下场竞争，而是大模型技术本身的发展，如果一个足够好用的智能体迟迟无法诞生，那协议也就成了无源之水。&lt;/p&gt; 
&lt;p&gt;但我也想清楚了，什么叫成功。如果 ANP 最终没有成为主流，但它的核心理念和设计能成为未来行业标准的一部分养料，那我们社区的目标也就达成了。归根结底，我们想构建的是一个开放的互联网，这是我们社区的理念，也是我们社区最有价值的东西。只要我们的理念能够成功，就是我们社区的成功。所谓「功成不必在我」。如果有其他人或组织有同样的理念，我们社区会无保留开放我们的技术。&lt;/p&gt; 
&lt;p&gt;在一次分享的结尾，我放了一页 PPT，上面写着「连接即力量」。我真正想说的是，我们希望互联网回归到最原始的、开放连接的设想：只要一个人能够自由地连接信息、连接他人、连接工具，他就拥有了改变世界的能力。&lt;/p&gt; 
&lt;p&gt;最后，做自己热爱的事情，事情本身会滋养人的。希望你也能够找到你真正热爱的事情。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我们的开源社区：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;GitHub: &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fagent-network-protocol%2FAgentNetworkProtocol" target="_blank"&gt;https://github.com/agent-network-protocol/AgentNetworkProtocol&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#252933; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;如果你也对智能体通信协议感兴趣，或者有类似的需求，欢迎联系我们：&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;微信：flow10240&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;邮箱：chgaowei@gmail.com&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9297178/blog/18638237</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9297178/blog/18638237</guid>
      <pubDate>Fri, 09 May 2025 13:51:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
