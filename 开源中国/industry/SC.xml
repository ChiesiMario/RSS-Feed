<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 17 Apr 2025 07:36:44 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Spark on K8s 在 vivo 大数据平台的混部实战</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网大数据团队- Qin Yehai&lt;/p&gt; 
 &lt;p&gt;在离线混部可以提高整体的资源利用率，不过离线 Spark 任务部署到混部容器集群需要做一定的改造，本文将从在离线混部中的离线任务的角度，讲述离线任务是如何进行容器化、平台上的离线任务如何平滑地提交到混部集群、离线任务在混部集群中如何调度的完整实现以及过程中的问题解决。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、在离线业务差异&lt;/h1&gt; 
&lt;p&gt;互联网数据业务服务一般可以分为在线服务和离线任务两大类，在线服务是指那些长时间运行、随时响应对实时性要求高、负载压力随着接收流量起伏的服务，如电商、游戏等服务，离线任务是指运行周期短、可执行时间提交对实时性要求低、有一定容错性、负载压力基本可控的服务，如离线计算任务、模型训练等。一般在线服务在白天时段繁忙，离线任务在凌晨繁忙，两者的业务高峰期存在错峰现象，如果按传统方式在线和离线都是分别独立机器部署，业务高峰时期需要更多机器来支持，业务低峰期又存在部分机器空闲，整体资源利用率都不高。因此行业提出来在离线混部的解决方案，在线和离线业务通过混部系统部署在同一批机器，实现共享资源并错峰互补，提高整体的资源利用率。目前业内利用混部技术可以将数据中心的 CPU 利用率提升至 40% 左右，vivo 在 2023 年混部平台投入生产也已经将部分混部集群的 CPU 利用率提升至 30% 左右，整体收益也是可观的。&lt;/p&gt; 
&lt;p&gt;混部系统需要有强大的隔离能力，绝大部分都是基于容器，所以混部的前提是在线和离线业务都容器化，对于容器管理工具如 K8s 来说是更适应于运行时间长、启停次数少、容器数量少的在线服务，在线服务也能比较容易地上容器，而对于运行时间短、启停频繁、容器数量大的离线任务，对 K8s 来说不是天然地适应，但容器化已是大势所趋，K8s 也推出了性能更好的调度器、用于离线任务的控制器，Spark 在 2.3 版本后也支持容器化，诸多技术的发展也推动离线任务实现容器化以及在离线混部的落地。&lt;/p&gt; 
&lt;p&gt;本文将从在离线混部中的离线任务的角度，讲述离线任务是如何进行容器化、平台上的离线任务如何平滑地提交到混部集群、离线任务在混部集群中如何调度的完整实现以及过程中的问题解决。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、离线任务容器化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Spark Operator 方案&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 方案对比&lt;/h3&gt; 
&lt;p&gt;vivo 离线任务大部分任务是以 Spark 作为执行引擎，Spark 任务运行在 K8s 上，目前业界有两种架构的方案：Spark on K8s 及 Yarn on K8s。两者部分优缺点对比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//944f211eda9a472ce3e9c7cc7342579a.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark on K8s 是 Spark 容器化，由 K8s 直接创建 Driver 和 Executor 的 Pod 来运行 Spark 作业，Yarn on K8s 是 Yarn 的容器化，由 K8s 创建 RM 和 NM 的 Pod，Spark 的 Driver 和 Executor 运行在 NM Pod 的 container 中，正是由于两种架构方案的区别，它们各自也会存在优缺点。&lt;/p&gt; 
&lt;p&gt;Yarn on K8s 方案可以支持原生的 Hive、Spark、Flink 等引擎，它仅需要创建一定数量的 NodeManager Pod 来满足作业需求，Pod 运行相对稳定因此对 K8s 的压力比较小，本身 Yarn 支持调度性能和调度策略也是专门为离线任务设计的，调度性能比 K8s 的强很多。由于 NodeManager ESS 服务是对磁盘有容量和读写性能要求的，混部机器的磁盘一般难以满足，所以也需要能支持不同引擎的 Remote Shuffle Service。在资源利用上，NodeManager 需要满足多个作业的资源，最小单位是 Container，Pod 的资源粒度比较大，自身也会占用一些资源，如果资源粒度得不到有效地弹性伸缩，也会造成资源的浪费，因此需要引入额外的组件来协调,根据 Kubernetes 集群节点的剩余资源，动态调整 NodeManager 的 CPU 和内存，然而这也需要一定的改造成本。在资源紧张的情况下，NodeManager Pod 如果被驱逐也就意味着整个 NodeManager 被销毁，将会影响多个任务。&lt;/p&gt; 
&lt;p&gt;Spark on K8s 方案目前在 Spark 3.1 以上版本才正式可用，它需要频繁的创建、查询、销毁大量的 Executor Pod，对 K8s 的 ApiServer 和 ETCD 等组件都会造成比较大的压力，K8s 的调度器也不是专门为离线的大批量任务设计的，调度性能也比较弱。另一方面，Spark on K8s 虽然只能支持 Spark3.X 的 RSS，不过目前有较多的开源产品可选择。在资源利用上，最小单位是 Driver 和 Executor 的 Pod，资源粒度小，可以填充到更多的碎片资源，调度时直接与 K8s 对接，资源的弹性调度更多由 K8s 来承担，不需要额外的组件，改造成本比较低。在资源紧张的情况下，Executor、Driver 的 Pod 将依次逐个被驱逐，任务的稳定性会更高。&lt;/p&gt; 
&lt;p&gt;而对于 Spark on K8s 方案，还细分 2 种实现方案：Spark Submit on K8s 和 Spark Operator on K8s。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//65d397e91ee4e5dc2fd2dc1392df5e8c.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SparkOnK8s 架构图&lt;/p&gt; 
&lt;p&gt;(图片来源：Spark 官网)&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9690ad754f277e44ce4a6a09f6f7058a.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark Operator 架构图&lt;/p&gt; 
&lt;p&gt;(图片来源：Spark Operator 开源项目)&lt;/p&gt; 
&lt;p&gt;以 spark-submit 方式提交到 K8s 集群是 Spark 在 2.3 版本后提供的原生功能，客户端通过 spark-submit 设置 K8s 的相关参数，内部再调用 K8sApi 在 K8s 集群中创建 Driver Pod，Driver 再调用 K8sApi 创建需要的 Executor Pod，共同组成 Spark Application，作业结束后 Executor Pod 会被 Driver Pod 销毁，而 Driver Pod 则继续存在直到被清理。使用 spark-submit 方式的最大好处是由 spark-submit 来与 K8s 的进行交换，提交作业的方式几乎保持一致。但是因为使用的便利性所需要的封装也会带来一些缺点，spark-submit 是通过 K8sApi 创建 Pod，使用非声明式的提交接口，如果需要修改 K8s 配置就需要重新开发新接口，二次开发复杂繁琐，虽然 Spark 提供了大量的 K8s 配置参数，但也远比不了 K8s YAML 的声明式的提交方式更加灵活，而且 Spark Application 和 K8s Workload 的生命周期还不能较好地对应起来，生命周期不能灵活控制，任务监控也比较难接入 Prometheus 集群监控。虽然 Spark 社区也不断地在推出新特性来和 K8s 集成地更加灵活，不过对于些复杂场景需要定制开发，spark-submit 的封装性也会成为阻碍。&lt;/p&gt; 
&lt;p&gt;spark-submit 还是离线任务提交的思维，而 Spark Operator 方式就更倾向于 K8s 作业的思维，作为 K8s 的自定义控制器，在集成了原生的 Spark on K8s 的基础上利用 K8s 原生能力提供了更全面管控功能。Spark Operator 使用声明式的 YAML 提交 Spark 作业，并提供额外组件来管理 Spark 作业的生命周期，SparkApplication 控制器，负责 SparkApplicationObject 的创建、更新和删除，同时处理各种事件和作业状态，Submission Runner, 负责调用 spark-submit 提交 Spark 作业，Driver 和 Executor 的运行流程是一致的，Spark Pod Monitor，负责监控和同步 Spark 作业相关 Pod 的状态。Spark Operator 最大的好处是为在 K8s 中的 Spark 作业提供了更好的控制、管理和监控的功能，可以更加紧密地与 K8s 结合并能灵活使用 K8s 各种特性来满足复杂场景，例如混部场景，而相对地它也不再像 spark-submit 那样方便地提交任务，所以如何使用 Spark Operator 优雅提交任务将是在离线混部中一项重要的工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 最终选项&lt;/h3&gt; 
&lt;p&gt;在大的架构选型上，我们选择了 Spark on K8s，一方面因为 Spark3.X 是 vivo 当前及未来 2~3 年的主流离线引擎，另一方面 vivo 有比较完善的 K8s 生态体系，内部对 K8s 研发也比较深入，环境和能力都能很好地支持，在应用的小方向上，我们选择了 Spark Operator，因为它在混部这种复杂场景下使用更加灵活、扩展性更强、改造成本更低，我们最终决定使用 Spark Operator 方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 Spark 优化&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 Spark 镜像&lt;/h3&gt; 
&lt;p&gt;Spark 任务容器化的第一步就是构建具有 Spark 相关环境的镜像，Spark 任务类型主要分为 sql 任务和 jar 任务，在实践的过程中我们发现 Spark 的镜像构建需要&lt;strong&gt;注意几个问题&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark 环境的完整性&lt;/strong&gt;：镜像中除了打入自研的 Spark 包以外，还需要打入相应的依赖如 Hadoop、ZSTD、RSS 等包，对于 SparkJar 任务还有直接调用 Hadoop 客户端的，因此 Hadoop 客户端也需要打入镜像中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JDK 版本问题&lt;/strong&gt;：K8s 使用的 Spark 是基于 3.2.0 版本，镜像打包工具默认使用 JDK11，而自研的 Spark 用的 JDK1.8，由于在 Yarn 和 K8s 上使用的 JDK 版本不同，导致在双跑验证数据一致性时发现了 hash 函数、时间戳不一致的问题，因此 Spark 镜像中的 JDK 版本需要和 Yarn 保持一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;环境变量问题&lt;/strong&gt;：镜像生成容器后需要预置如 Spark、Hadoop 的环境变量，如果镜像中相关目录的位置不能完全和 Yarn 的提交节点保持一致，则需要检查各启动脚本，如 spark-env.sh 中的环境变量的路径是否存在，发生冲突时可以修改为绝对路径。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Spark 镜像构建完成后，区分 SparkSql 任务和 SparkJar 任务实质就是启动命令的不同，事实上 SparkSql 任务也就是 SparkJar 任务的一种，只是启动的主类是固定的，两者的启动参数如下：&lt;/p&gt; 
&lt;p&gt;SparkSql 任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver -f {sql 文件}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SparkJar 任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class {jar 任务主类} {jar 任务 jar 包} {参数}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;早期不仅构建了 Spark 镜像，还构建了 Spark 日志镜像，容器组成结构会复杂一些。如图例如 Driver 容器，我们将 Spark、Hadoop 等配置文件构建了 configMap，启动 initContainer 来拉取从 configMap 拉取配置文件，然后启动 Driver 容器执行 Spark 任务，同时也使用 sidecar 创建日志上报的容器，在 Spark 任务运行完成后上报 Driver 和 Executor 日志到 Spark HistoryServer。这样的方案看似充分应用了 K8s 技术，但是在实践的过程中这些技术却被一一弃用，转而逐步地把各种功能集中到了一个 Driver 容器上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c1f0bf5a2f03578b42831a80908e1aad.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体演进如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 initContainer&lt;/strong&gt;，拉取 Spark 等配置文件步骤写在启动命令中，Spark 作业执行前执行下载配置，原因在多个 namespace 下不方便统一管理，而且 configmap 内容较大，会导致 Pod 启动时配置加载的延迟增加，影响了 Pod 创建速度，同时 K8s 的内存和 CPU 资源占用增加，对 kube-apiserver、ETCD 负载有一些影响。去掉 initContainer 还有个重要的好处就是减小 ETCD 的存储压力，事实上我们在移除 initContainer 拉取配置的功能后的一段时间内还保留着 initContainer，在任务逐渐上量后发现 ETCD 的存储比较满，分析后发现 Spark 作业中的一个 Pod 生命周期大约 8 次更新，其中 initContainer 更新会占用 2 次，移除了之后理论上是可以减少 1/4 的 ETCD 存储，实际应用中完全去除了 initContainer 也确实能减小了 ETCD 的存储压力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 sidecar 创建日志上报的容器&lt;/strong&gt;，Driver 和 Executor 日志上报步骤写在启动命令中，Spark 作业执行完后再执行脚本上报，原因是 sidecar 在同一个 Pod 中与主容器共享相同的生命周期，不使用 sidecar 方式就能更快创建 Pod，Spark 任务执行完成后能更快释放资源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对于 Spark 作业会频繁创建、更新和销毁大量的 Pod，所以去除非必要的容器，提高 Pod 生命周期流转速度，就能降低 kube-apiserver、ETCD 工作负载，也能提高 Spark 的作业效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 Spark 改造&lt;/h3&gt; 
&lt;p&gt;Spark 任务运行在 K8s 上，对于一些使用的兼容问题也进行了&lt;strong&gt;相关改造&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HistoryServer 改造&lt;/strong&gt;，因为 Spark Operator 没有存储已结束作业的日志，因此参考了 on Yarn 的方式，在 Spark 作业结束后，通过日志上传脚本把 Driver 和 Executor 的日志上传 HDFS，与 Yarn 日志聚合类似，同时也在 Spark HistoryServer 做了二次开发工作，增加了 on K8s 方式的日志查看接口，用户查看已完成的 Executor 日志时，不再请求 JobHistory Server，而是请求 Spark HistoryServer 接口。但日志上传方式需要 Executor 执行完才能查看到日志，为了能实时查看到执行中的日志，可以在 Executor 内部实现一个 HTTP 服务，根据 Pod 以及端口信息拼接出日志请求 URL，Executor 启动一个 Servlet 自动获取本地日志并返回。日志查看体验上做到了基本与 Yarn 一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主机 ip 通信&lt;/strong&gt;，Spark Driver 和 Executor 之间的通信通常是通过主机名进行的，不过随着 Spark 任务增多，CoreDNS 因为频繁的域名解释请求导致压力增大，甚至会影响到在线服务，因此我们将 Hadoop 的配置文件改为 ip 格式、设置 Driver 和 Executor 使用 ip 地址，同时去除了对应的 K8s Service，通过访问 ip 而不是域名的方式来规避这个问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件参数兼容&lt;/strong&gt;，Spark Driver 在 K8s 上是运行在某一个 Pod 中的，所以文件需要是全局可视的，如 HDFS 文件，否则就会报文件未找到的错误，但 Spark 作业运行在大数据作业平台时有的任务使用的上传的本地文件，因此对于提交到 K8s 的任务，第一步是要把上传到大数据作业平台的文件再次上传到 HDFS，第二步是改造 add jar 和--file 等命令逻辑，Spark 任务在未能读取本地文件后将再尝试读取二次上传到 HDFS 的文件，实现任务无需修改成全局可视的文件路径也能读取到文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;non-daemon 线程终止&lt;/strong&gt;，在 K8s 上运行的 Spark 任务是指定 Client 模式，Client 模式下 Driver 遇到异常时停掉 SparkContxet，等所有 non-daemon 线程结束后，Driver 才会退出，但如果存在一直运行的 non-daemon 线程，那么 Driver 一直不退出，任务就一直处于执行中。因此需要改造成 Cluster 模式的异常退出机制，即异常时以非 0 退出码退出，不再等待其他的 non-daemon 线程结束，Driver 直接终止，以确保 Driver Pod 的正常结束。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Spark Operator 优化&lt;/h2&gt; 
&lt;p&gt;随着在 K8s 上运行的 Spark 任务不断增加，K8s 集群的负载也逐渐显现。因此，需要对 Spark Operator 进行一系列优化，以减轻 K8s 集群的压力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;离线使用独立的 kube-apiserver&lt;/strong&gt;，混部集群中离线容器占了很大一部分，而且离线任务由于生命周期短，容器创建销毁更加频繁，这对 kube-apiserver 造成了很大的压力，然而在线业务需要更高的稳定性，为了减少离线对在线业务的影响，我们拆分了 kube-apiserver，离线任务通过指定 master 参数来使用独立的 kube-apiserver。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 K8s 的 HostNetwork 网络模式&lt;/strong&gt;，在 K8s 上启动 Driver 与 Executor 虽然使用的是独立 ip+固定端口，但频繁的 ip 申请和释放也对 kube-apiserver 造成了一定的压力，因此我们改为使用 HostNetwork 网络模式，同时不指定端口避免端口冲突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化 Spark Operator 控制器的队列&lt;/strong&gt;，在任务量比较大的情况下，Spark Operator 对 Pod 创建消耗效率会遇到瓶颈，排查后发现是 Spark Operator 的事件处理队列的并发数和限速桶的默认配置地太小，因此我们调低 Spark maxPendingPods 参数，调高 schedulerBacklogTimeout、 sustainedSchedulerBacklogTimeout 参数，减少 Pending Pod 个数，使 Pod 的处理效率符合集群的承载水平。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化 Spark Driver List Pod 接口&lt;/strong&gt;，使用 kube-apiserver 缓存，避免对 ETCD 产生影响，同时修改 Spark Driver 清理 Executor 逻辑，直接 Delete，减少 List Pod 对 kube-apiserver 压力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存储 emptydir + log lv 存储优化&lt;/strong&gt;，开发 CSI 插件，Spark 任务的离线日志单独存储，避免对在线业务 pod 的影响和磁盘负载高等问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark Secret 标记 immutable&lt;/strong&gt;，减少 kubelet watch secret 请求，降低 kube-apiserver 的负载。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、离线任务提交&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 平台任务提交平滑切换&lt;/h2&gt; 
&lt;p&gt;离线任务容器化方案确定后就要落地到生产，目前有 SparkSql 和 SparkJar 两种离线任务实现了容器化，这里以 SparkSql 任务为例描述 Spark 提交到混部 K8s 集群的流程并达到与传统客户端提交任务几乎无差异的平滑切换。目前 vivo 的离线任务都是通过大数据平台进行提交和调度的，平台会把主要的提交流程进行封装形成简单操作的功能，例如在平台上提交 SparkSql 任务流程一般是编写 sql、提交任务、查看 Driver 日志或在跳转到 SparkUI、执行完成后获取结果以及更新任务状态。&lt;/p&gt; 
&lt;p&gt;在平台内部，SparkSql 任务使用传统的 spark-submit&lt;strong&gt;提交流程&lt;/strong&gt;是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户编写好的 sql 上传到提交节点生成一个 sql 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交节点使用 Spark 客户端执行该 sql 文件启动 SparkSql 任务；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务启动后，通过不断地 tail 操作查询日志转存到 HBase 方便在平台页面上查询到 Driver 日志；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务结束后，再查询输出结果转存到 HBase 方便在平台页面上查询到执行结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根据提交 sql 任务命令的返回码来更新任务状态。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;传统 Spark 客户端提交任务大部分只会涉及到提交节点的客户端与平台服务器之间的交互，而 SparkSql 任务提交到混部 K8s 集群，从上节的 Spark 容器化方案的原理可知最终目的是要将 Spark 任务的任务参数按一定的格式封装好传入 Spark Operator 控制器来创建相关的容器，平台需要通过会调用容器团队提供的封装好 K8sApi 的统一接入层来创建 Spark 容器。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//15dcd589c32637e1dde5ed6757b4eed7.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在平台内部，SparkSql 任务提交到混部 K8s 集群的&lt;strong&gt;完整流程&lt;/strong&gt;为：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户编写好的 sql 上传到 HDFS 生成一个远程可访问的 HDFS 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SparkSql 任务参数封装好传入容器接入层的 createSpark 接口来调用 Spark Operator 控制器容器，再由 Spark Operator 控制器创建 Driver Pod，最后由 Driver Pod 根据 Spark 任务需要创建多个 Executor Pod，这些 Driver、Executor 的 Pod 相当于 Driver 和 Executor 的角色，共同配合执行 Spark 作业；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务启动后，通过容器接入层的 getDriverLog 接口周期性地查询 Driver 日志，实质上是查询 Driver 容器的日志，查询到的 Driver 日志会转存到 HBase 方便在平台页面上查询；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务结束后，一方面通过 Spark 启动脚本中的日志上传命令，把 Driver 和 Executor 的日志上传 HDFS，可以在改造后的 Spark HistoryServer 直接查看，另一方面执行结果也会先输出到 HDFS，再从 HDFS 转存到 HBase 方便在平台页面上查询到执行结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通过轮询接入层的 getSpark 接口根据返回的状态码来更新任务状态，在任务结束后，此时 Driver Pod 不会主动退出，首先将任务状态更新为成功，在日志和结果都存储完成后，再调用 deleteSpark 接口主动地杀死 Driver Pod 释放资源，完成整个 Spark 任务流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;可以看出 SparkSql 任务提交到混部 K8s 的执行主体是容器，因此需要增加容器接入层来管理 Spark 相关的容器，同时容器的使用更倾向于存算分离的效果，因此需要使用 HDFS 作为远程文件中转。&lt;/p&gt; 
&lt;p&gt;大数据平台上传统使用 spark-submit 和 onK8s 使用 spark-operator 的 SparkSql 任务执行流程对比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//024fa2e15ecb64123b58156eb1fd2188.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 混部任务的资源参数调整&lt;/h2&gt; 
&lt;p&gt;Spark 任务的 Driver 和 Executor，在 Yarn 上执行实质是运行在 NodeManager 节点上的，而在 K8s 上执行实质是运行在对应的 Pod 中的，由于 Spark on K8s 的提交方式和运行环境都不同于 on Yarn，任务的资源参数不能直接套用，需要做一些参数调整才能提交到 K8s 上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、资源参数提取和转换&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SparkSql 任务在 Yarn 上可以灵活地调整 sql 中的配置来满足不同特性的任务，sql 中的资源配置会覆盖客户端启动时的全局配置，因为 Executor 是运行在 NodeManager 节点上的，资源会相对充裕能满足 Executor 的资源需求，与此不同的是 Spark on K8s 的 Executor 是运行在 Executor Pod 中的，使用的资源会受到 Pod 资源规格大小的限制，而 spark-operator 的提交方式是要先获取 Executor 全局资源规格并生成相应资源规格大小的 Executor Pod，所以在提交 Spark 任务到 K8s 前就要准确地获取任务真正生效的资源参数。在大数据平台中资源参数会存在多中类型的参数中，参数的优先级为：任务配置参数 &amp;lt; 任务模板参数 &amp;lt; sql 中设置参数 &amp;lt; HBO 优化参数 &amp;lt; 平台统一参数，按此优先级顺序依次提取最终的资源参数并传入容器接入层创建 Spark 作业。另外容器接入层对于 Spark 的 arguments 和 sparkConf 参数都是要求以字符数组的方式传入，需要做好对原任务参数中的单引号、双引号、反斜杠和回车等符号以及分段落的处理和转换。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、overheadMemory 的计算&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Yarn 上 Executor 是运行在 NodeManager 节点上的，节点的资源一般都大于并能满足 container 申请的资源，所以在 Yarn 上只需要关心 container 本身申请的资源即可，而在 K8s 上 Executor 运行在对应的 Pod 中，可以把 Pod 理解为只一台独立的节点，除了要满足 container 申请的资源量，还需要一些 Pod 容运行时网络、存储等基础设施的自身开销资源，如果把 Spark 任务中 Driver 和 Executor 申请的资源直接设置为 K8s 中 Driver Pod 和 Executor Pod 的资源规格，有可能出现 OOM 情况，另外还要考虑非 JVM 内存，Spark 默认会把申请的 Executor 内存乘以一个系数或者至少预留 384 MiB 内存作为额外的非 JVM 内存缓冲区，用于堆外内存分配、非 JVM 任务以及各类系统进程的使用，可以通过设置 overheadMemory 进行覆盖。因此 K8s 的 Pod 除了要满足申请的 Memory 和运行时需要的 overheadMemory 的资源，还会再添加 100M 资源用于 Pod 运行的自身开销。&lt;/p&gt; 
&lt;p&gt;pod 的资源规格 = memory + pod overheadMemory&lt;/p&gt; 
&lt;p&gt;对于 overheadMemory 也需要先获取到并加到 Pod 的资源规格，如果任务有配置就直接使用配置的 overheadMemory，如果没有配置值则按一定计算公式来计算得到。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = overheadMemory + 100M&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;无配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = (max(384M，0.1*memory)) 向上取整到 512MB 的整数倍 + 100M&lt;/p&gt; 
&lt;p&gt;不过在实际应用中发现对于个别任务，即使 K8s 上配置的 overheadMemory 比在 Yarn 的配置多 100M，完全一样的任务在 K8s 上则有较多的 Executor OOM 情况，而在 Yarn 上却完全没有，目前排查到的现象是有 JVM 堆外的内存无法回收，如果任务需要较多的对外内存，堆外内存一直增长最终导致 OOM，但哪些内存无法回收的还未排查到。目前对于这些 OOM 过多且实际影响到运行效率的任务，在原 overheadMemory 基础上再增加 512M 后就没有 OOM 情况了，同时也有采用了大数据平台的 HBO 能力自动调整内存参数来事后规避这个问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、CPU 超分配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spark 任务申请的 CPU 使用一般不会使用完，事实上 Executor Pod 的 CPU 利用率也并不是很高，比如 Executor 申请 1 个核，通常只能利用 0.6 个核，存在 CPU 浪费的现象。Executor Pod 的资源规格是创建的时候分配的，利用容器的能力，可以采取 CPU 超分的方式提高 CPU 的利用率，例如 Executor 申请 1 核，实际用 0.6 核，如果 Pod 分配 1 核，那利用率就只有 60%，但如果 Pod 只分配 0.8 核，那利用率就有 75% 了，所以超分的策略就是申请了 1 核只给 0.8 核，但还是要按 1 核的申请量来运行任务。目前平台使用的是静态的固定比例超分设置为 0.8，实施超分配置策略后 Pod 的实际 CPU 利用率打到 80% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//29fe0829e28d1e2084e2dbba0910de3a.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 混部任务的筛选提交&lt;/h2&gt; 
&lt;p&gt;经过上面的任务提交方式的改造和任务资源参数的调整，原 SparkSql 和 SparkJar 任务就可以平滑切换提交到混部 K8s 上执行了，但在大规模切换之前平台还做了比较长期的双跑验证工作，在执行成功率、数据一致性和执行时效等方案都进行了双跑比较，双跑通过的任务才能切换到 K8s 上执行。除了双跑通过，前期还设置了其他的筛选条件如下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//698830de13538cf7b2a6cf67d0b6fa45.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前期按这些条件筛选出可以提交到 K8s 的任务，然后分批的进行 K8s 任务的参数标记，并把标记的这批任务添加监控进行跟踪。经过双跑验证、任务筛选、批量标记、监控跟踪和问题解决这一整套 SparkSql 任务上量 K8s 的流程，K8s 上的任务运行逐步稳定，K8s 的兼容问题也基本解决，因此目前取消了双跑通过的这一条件，主要保留了任务重要性、运行时长和重试次数这几个筛选指标。随着 SparkSql 任务上量和稳定，提交到 K8s 的任务类型也增加了 SparkJar 任务，SparkJar 任务无法进行双跑验证，所以在各种 K8s 兼容问题解决后再推进会更加稳妥。&lt;/p&gt; 
&lt;p&gt;目前大数据平台会定期筛选和标记一批 SparkSql 和 SparkJar 任务允许提交到混部 K8s，用户也可以自行开启，在任务配置页面只显示已开启混部，则该任务就有机会被提交到混部 K8s 上执行。当然，用户也可以手动关闭这一开关，并且手动操作的优先级最高，手动关闭后平台的自动开启功能将不再生效。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、弹性调度系统&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 弹性调度功能矩阵&lt;/h2&gt; 
&lt;p&gt;Spark 任务开启了混部也不是必定能提交到混部，最终能不能在混部集群上执行，还要根据当时混部集群的资源和运行情况等来确定，为了更好地协调离线任务和混部集群的供需关系，大数据平台构建了离线任务混部弹性调度系统。弹性调度系统的设计目是混部集群有资源了就调度离线任务，但在生产环境中不管是混部集群还是离线任务都会各自的问题需要解决和优化的需求，弹性调度系统也逐步演变成了全面管理离线任务提交到混部以实现混部资源最大化利用的功能矩阵。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.1 资源水位线调度&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//878bdd653f0ec47e7c32fe0b09e8f975.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;弹性调度的流程，任务按调度时间以任务流的形式过来，如果任务标记了允许提交到混部，那就会先去查询 K8s 的各个集群，如果某一个集群资源充足就直接提交到 K8s，如果当时没有足够资源就等待资源再判断，这里分为有三类任务，第一类是一直等 K8s 资源，永不超时，只会提交到 K8s；第二类是长时间等待，超时时间在 1 到 5 分钟，可以等久一点；第三类是短时等待，超时时间为 30-60 秒，稍微等一下，如果 K8s 没有资源就回到 Yarn 上执行，目前平台标记的任务大部分任务都是第三类短时等待。&lt;/p&gt; 
&lt;p&gt;混部集群提供给离线任务的资源是呈潮汐波动的，使用百分比的水位线方式才能更好地贴合资源的波动情况。混部集群提供的资源是指 CPU 和内存，但离线任务一般不能百分之百地获取到这部分资源，需要设置一个折算比例也就是水位线来计算出离线任务能使用的真正资源是多少，水位线的设置需要考虑&lt;strong&gt;几个因素&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、混部集群的碎片化率&lt;/strong&gt;，混部集群中的机器规格和正在运行的业务占用量都是不确定的，但一般大规格的机器多的集群碎片化率较低，所以小规格的机器多的集群的水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、资源动态分配容纳率&lt;/strong&gt;，对于开启了动态分配的 Spark 任务，无法提前知道任务所需的资源，需要留有一部分资源用于动态分配的消耗，如果同样的水位线资源规模大的混部集群容纳率会高，所以资源规模小的集群的水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、资源配比的均衡性&lt;/strong&gt;，不同的集群或者同一集群的不同时间段的 CPU 和内存配比可能会存在很大的差异，例如 Spark 任务的 CPU 和内存的平均比例是 1 核 6G，即 1:6，如果有 CPU 和内存比为 1:2 的，内存会被用完而 CPU 有剩余，此时为了内存留有部分余量，水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部资源可用量 = 混部资源提供量 * 资源水位线&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;资源水位线有 CPU 水位线和内存水位线，设计时以 CPU 或内存中的最低水位线为准，哪个资源先分配完就停止提交任务，不过在实际生产中大部分混部集群都是受内存限制较多，个别时段 CPU 比内存多但通过其他的限制手段即使 CPU 满载对任务影响不大，因此目前只开启了内存资源水位线。以上提到的 3 点可以当成集群的固有消耗需要保留有一定的余量，为了直观地控制混部资源使用率和引入优先策略，计算方式调整为：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部资源可用量 = 混部资源提供量 * (1-余量水位线) * 优先水位线&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;余量水位线根据各个集群来调整，一般为 0.05，优先水位线的范围可以在 0-1 之间。优先水位线的作用是对于一些符合优先条件的任务可以优先提交，但是任务调度是一有任务就要调度的流式调度，不能够先集中再挑选优先任务而是先到先得，所以要为优先任务预留一部分资源，例如优先水位线为 0.8，混部资源使用到 0.8 以下的时候任何任务都可以调度上来，但使用量超过了 0.8，那只有优先任务能调上来，也就是为优先任务预留了 0.2 的资源，当然即使资源使用量达到了 1，由于余量水位线的存在，实际的使用量为 0.95，混部集群仍有资源维持周转。优先水位线是最常用的调整参数，它实质就是控制混部任务提交量，不仅能调整混部资源的使用量，还在灰度测试、压力测试和问题排查等事项起到了灵活调节的作用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.2 其他调度能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1.多集群管理&lt;/strong&gt;：混部集群通常会有多个，vivo 目前就有多个生产环境的混部集群，各混部集群由于建设周期、机器规格和业务接入的不同，混部资源的规模和变化趋势都会呈现比较大的差异，因此每个集群的调度策略配置都需要做到能独立调整来适应各自的资源特点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.分时段控制&lt;/strong&gt;：每个混部集群上的在线业务一般是潮汐波动的，给到离线任务的资源也是潮汐波动的，因此每个集群需要做到在每天不同时段可以调整不同的调度策略，尤其在波峰波谷差异较大的时间段各自调整配置的差异会更大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.分散 namespace&lt;/strong&gt;：Spark 任务的 Driver Pod 和 Executor Pod 都会放在一个 namespace 中管理，如果所有任务都由一个 namespace 管理，那需要管理的 pod 数量会达到数十万的级别，会对 K8s 集群的性能和稳定性产生影响。因此需要将 Spark 任务平均分配到多个 namespace，采用的方案是轮询填充，任务优先分配到多个 namespace 中任务最少 namespace。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.失败回退 Yarn&lt;/strong&gt;：离线任务混部推进的过程中还有会有 Spark 兼容问题、混部集群异常和平台变更等问题导致的离线任务在混部 K8s 上运行失败，为了减少失败对任务的影响，任务在 K8s 上首次执行失败后就会自动回到 Yarn 重新执行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.资源准入粒度&lt;/strong&gt;：各混部集群的机器规格和碎片率是不一样的，如 executorMemory=2G 这样较小粒度的 Spark 任务即使碎片率较高的混部集群可以填充，而对于 executorMemory=16G 这样较大粒度的 Spark 任务，机器规格大的集群才更容易获取到资源，因此不同混部集群可以设置不同的准入粒度，小规格和碎片率高的集群准入粒度可以设置小一些。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6.任务偏好配置&lt;/strong&gt;：对于一些灰度任务和特殊要求的任务，例如只有在 0 到 8 点才允许提交到混部、只提交到某几个指定的混部集群等调度要求，需要支持任务偏好配置，在任务参数中调整混部控制参数实现相应的调度需求。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 弹性调度策略优化&lt;/h2&gt; 
&lt;p&gt;弹性调度的核心是通过资源水位线的调节，有混部资源就调度离线任务，但实际生产中还要考虑混部集群的运行情况，是否能稳定地接收和消化离线任务，同时在存在多个差异较大的集群时提交到哪个集群最优。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1 任务调度稳定优化&lt;/h3&gt; 
&lt;p&gt;大数据平台的离线任务提交高峰在凌晨时段而且调度时间集中在整点半点，还有 5 分和 10 分这样的整分，例如 03:00 调度的任务达 1000 个，但在 03:01 调度的任务只有 10 个，过于集中地提交任务会导致混部集群 Pending Pod 数量急剧上升，这是因为无论是查询集群资源还是 Pending 数的接口，更新数据都需要一定的周期时间，而且离线任务提交上去到获取资源也受 K8s 的调度时间的影响，所以获取集群运行情况总会滞后于任务提交。例如 03:00 查询集群是有资源的并且是健康的，由于任务开启了动态分配所以不能确定需要多少资源，此时集中提交了 1000 个任务，这 1000 个任务首先会创建 1000 个 Driver Pod，集群资源还是能满足的并且优先创建，假如每个 Driver 需要创建 100 个 Executor，如果集群没有这么多资源，那就会产生大量的 Penging Pod，严重影响集群的性能和稳定以及任务的执行效率，因此需要对弹性调度的稳定性进行优化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短时提交限制&lt;/strong&gt;：避免集中提交任务的直接方案就是根据各混部集群的资源规模设置短时提交的任务数量限制，例如 1 分钟内只能提交 100 个任务，集群短时间内 Pending Pod 数量会增加但仍在可以承受范围内，集群和任务都会稳定运行。短时提交限制相当于拦截并舍弃了部分某个时间点集中提交的任务，这里相当于舍弃了 900 个任务，那么提交的总任务量就减少了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;延迟打散提交&lt;/strong&gt;：为解决短时提交限制导致舍弃部分任务的问题，增加了短时延迟打散提交，例如 03:00 提交的 1000 个任务，随机打散到 03:00 到 03:03 的 3 分钟内，即使有短时提交限制，这 3 分钟内也可以提交 300 个任务。理论上将集中提交的任务延迟更久，能提交到混部的任务会更多，但是增加延迟时长就等于增加任务的执行时长，会影响到业务数据产出的及时性，因此延迟打散提交策略只能是短时的，进一步的优化是执行时长更久的任务延迟更久一点，但根本解决方案还是用户能将调度时间尽量打散。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集群反馈限制&lt;/strong&gt;：短时提交限制和延迟打散提交都属于静态限制，需要人为地根据各个混部集群的情况去判断和设置限制值，因此需要做到动态限制，就需要获取集群的运行情况并根据运行情况进行限制。事实上 K8s 的调度性能相比于 Yarn 还是有差距的，从提交的 Spark 任务到获取到资源运行 Pod 有一定的滞后时间差，这段时间查询内还是有剩余资源，但如果还继续提交新任务就会产生更多 Pending Pod，因此需要做集群运行情况的反馈控制，例如查询 Pending Pod 数、等待的 SparkApp 数，当数量达到一定数量就不再提交新任务。&lt;/p&gt; 
&lt;p&gt;集群反馈限制虽然是动态的能根据混部集群情况进行反馈调节，但是查询集群状态是滞后的，这种滞后的控制就容易被集中提交给打垮，所以要加上短时提交限制来上一道保险，为缓解短时提交限制造成的任务损失，就引入了延迟打散提交，而在延时打散的过程中集群能逐步消化任务，查询集群状态逐步接近真实情况，这时又可以交给集群反馈限制来动态调节，逐步从突增恢复到稳定，三个调度稳定优化策略相辅相成。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 集群分配均匀优化&lt;/h3&gt; 
&lt;p&gt;离线任务会调度到多个混部集群，每个集群的资源总量和可用资源量，以及集群运行状况都不相同，为保证离线任务的运行稳定和执行效率，需要在多个混部集群中选择一个最合适的集群。各个集群会按一定的规则进行排序，离线任务会按这个排序依次轮询各个集群，只要集群剩余资源满足且没有被短时提交限制、集群反馈限制等拒绝，离线任务就提交到该集群。集群排序的&lt;strong&gt;演化顺序&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;①初始方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排队队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;剩余资源量多的优先&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b0cade1eb777379e3744a4104790af8.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源最多的集群，保证离线任务运行稳定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于小集群剩余资源量很小一直分配不到任务容易「饿死」（事实上有的小集群全部资源量都达不到一个大集群的 20%）&lt;/p&gt; 
&lt;p&gt;② 优化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将资源使用量超过一定比例的集群放到排序队列，剩余的集群放到随机队列&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c8b8441d6a201f0d2e84113fcc307c2f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源较多的集群，即保证任务的运行稳定，随机的方式也能均匀「喂饱」每个集群&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随机分配在大任务量时相当于是平均分配，每个集群都会调度差不多的任务量，当前情况会存在整点集中提交大量任务，小集群接收和大集群同样任务量会抗不住，影响任务执行稳定和效率，小集群容易「撑死」&lt;/p&gt; 
&lt;p&gt;③再优化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加权随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;按剩余资源进行加权随机，剩余资源多的集群有更多概率分配到任务&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39918d1411bca61982582118837a610.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源较多的集群，「大集群多吃，小集群少吃」，每个集群都能填充同时保证任务的运行稳定&lt;/p&gt; 
&lt;p&gt;④ 最终方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优先队列（排序）+加权随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考虑优先队列，无视其他排序规则，优先队列里的集群将最优先，在优先队列中的集群再按资源排序&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//db44e6961fb051bfbb59cb66ff17797f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;继承上一方案的优点，同时对于特定项目或机房的离线任务，能优先调度到某些特定的集群&lt;/p&gt; 
&lt;p&gt;目前只以内存作为资源水位线的衡量标准，这里的资源量指的是内存量。最开始方案是按集群的剩余资源排序，内存资源剩余多的集群优先，缺点是小集群一直分配不到任务容易「饿死」，然后使用随机的方式也能均匀「喂饱」每个集群，但小集群接收同样任务量时容易「撑死」，于是随机队列按剩余资源进行加权随机，剩余资源多的集群有更多概率分配到任务，这样离线任务优先提交到资源较多的集群，「大集群多吃，小集群少吃」，每个集群都能填充同时保证任务的运行稳定，在此基础上增加优先队列，无视其他排序规则，优先队列里的集群将最优先，在优先队列中的集群再按资源排序，能优先调度到某些特定的集群，形成最终集群选择排序方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_21&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、混部的效果与未来规划&lt;/h1&gt; 
&lt;p&gt;经过以上的对 Spark 组件、K8s 混部系统、大数据平台以及弹性调度系统的改造和优化，目前混部集群及提交混部的离线任务运行持续稳定，每天任务调度到混部的次数达 10+万次，在凌晨的高峰期通过混部能为离线任务额外增加数百 TB 内存的计算资源，部分混部集群的 CPU 利用率提升至 30% 左右，整体收益也是可观的。&lt;/p&gt; 
&lt;p&gt;虽然目前 vivo 的在离线混部达到了一定的规模，但未来要继续提高混部的规模和收益，还有规划一些改进工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;1、提高离线任务混部规模。&lt;/h2&gt; 
&lt;p&gt;离线任务混部的节点是在线业务提供的，节点规模取决于在线业务峰值，峰值越高那么在业务低峰期能提供给离线混部资源就越多，因此提高混部规模的重要因素是提交更多的离线任务。然而目前采用的 Spark Operator 方案能提交的离线任务只有标准的 SparkSql 和 SparkJar 任务，而对于非标准的任务如脚本任务，脚本中除了调用 spark-submit 提交 Spark 作业还有额外的处理逻辑，这类任务还不能直接以 Spark Operator 的方式提交。事实上 Spark 作业更多是来自脚本任务的非标准任务，如果要继续增加离线任务的量，就必须把非标准任务也提交到混部，因此后续是选择改造 spark-submit 客户端支持 Spark Operator，或是选择使用 Yarn on K8s，还需要综合评估。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2、提高离线任务混部收益。&lt;/h2&gt; 
&lt;p&gt;目前混部节点 CPU 的平均利用率达到 30%，但仍有提升空间。从离线任务的角度来看，一方面是要增加错峰互补的时间段，例如离线任务的高峰期是 02:00 到 08:00，在线业务的高峰期是 06:00 到 23:00，在 06:00 后在线业务逐步上量开始回收资源，所以离线任务能显著提高混部集群 CPU 利用率的黄金时间是有 02:00 到 06:00 这 4 个小时，因此如果能把离线任务高峰期提前到 00:00 到 06:00，混部提效的黄金时间就能达到 6 小时。所以需要推动离线任务高峰期的前移，对于有依赖链路的任务，尽量减少调度时间的间隔，上游任务完成后能尽快调起下游任务，而对于没有依赖的任务，可以尽量提前调度时间，不过这两种调整都需要推动业务方来调整，平台也可以给予一定的计算成本优惠作为激励。另一方面是要提高混部资源的填充率，Spark 任务需要创建大量的 Executor Pod，目前混部集群的调度器为了保证调度效率就没有开启预选、优先策略，事实上 Spark 的资源粒度比较小更适合填充资源碎片，所以在不影响 K8s 调度效率的情况下优化资源调配策略，把合适的资源粒度的 Pod 分配到合适的混部节点，也是提高混部收益的方向。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18181972</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18181972</guid>
            <pubDate>Thu, 17 Apr 2025 06:42:40 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>开源多模态大模型「书生·万象 3.0」发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海人工智能实验室（上海 AI 实验室）升级并开源了通用多模态大模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frb_gVjQTuwdx0hse6KuAkA&quot; target=&quot;_blank&quot;&gt;书生·万象 3.0&lt;/a&gt;（InternVL3）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，通过采用创新的多模态预训练和后训练方法，InternVL3 多模态基础能力全面提升，在专家级基准测试、多模态性能全面测试中，10 亿~780 亿参数的全量级版本在开源模型中性能均位列第一，同时大幅提升了图形用户界面（GUI）智能体、建筑场景图纸理解、空间感知推理以及通识学科推理等方面的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;292&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1e01575a2bc4dfc8530b94281d9005d52e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在专家级多学科领域知识推理基准测试 MMMU 中再次突破开源模型极限，取得 72.2 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于司南 OpenCompass 开源评测框架，研究团队对 InternVL3 进行了全面系统的评估，包括多学科推理、文档理解、多图像 / 视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力以及以语言为中心的基准测试。评测结果显示，InternVL3 在开源多模态大模型中性能表现最优，创造了开源多模态大模型的性能新标杆，性能接近闭源模型 Gemini-2.5-Pro；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;创新提出原生多模态预训练方法，将语言和多模态学习整合于同一个预训练阶段，提升及拓展多模态能力的同时，进一步提升纯语言能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;提出混合偏好优化算法以及多模态测试阶段增强，通过负监督修正模型响应分布，大幅提升模型推理能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;公测版本：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.intern-ai.org.cn%2F%C2%A0&quot; target=&quot;_blank&quot;&gt;https://chat.intern-ai.org.cn/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345071</guid>
            <pubDate>Mon, 14 Apr 2025 06:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>豆包 1.5·深度思考模型发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今日火山引擎 AI 创新巡展杭州站现场，火山引擎总裁谭待发布了最新的豆包 1.5·深度思考模型，升级豆包·文生图模型 3.0、豆包·视觉理解模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时，面向 Agent 服务，发布 OS Agent 解决方案、GUI Agent 大模型——豆包 1.5·UI-TARS 模型；面向大规模推理，发布 AI 云原生·ServingKit 推理套件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据透露，截至 2025 年 3 月底，豆包大模型日均 tokens 调用量已超过 12.7 万亿，是 2024 年 12 月的 3 倍，是一年前刚刚发布时的 106 倍。IDC 报告显示，2024 年中国公有云大模型调用量激增，火山引擎以 46.4% 的市场份额位居中国市场第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;豆包 1.5·深度思考模型在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出。同时，模型采用 MoE 架构，总参数 200B，激活参数为 20B，低于业界同类模型参数规模的 50%，具备显著的推理成本优势。基于高效算法，豆包 1.5·深度思考模型在提供行业极高并发承载能力的同时，实现 20 毫秒极低延迟。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;363&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be145536aac0c4457023c8127490097c66a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，豆包 1.5·深度思考模型还具备视觉理解能力，可以像人类一样，不光基于文字思考，更能基于所见画面思考，思考更立体，让模型同时拥有「大脑」和「眼睛」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;升级的豆包·文生图模型 3.0 则能够实现更好的文字排版表现、实拍级的图像生成效果，以及 2K 的高清图片生成方式。可以广泛应用于影视、海报、绘画、玩偶设计等营销、电商、设计场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本的豆包·视觉理解模型具备更强的视觉定位能力，支持多目标、小目标、通用目标的框定位和点定位，并支持定位计数、描述定位内容、3D 定位。可应用于线下门店的巡检场景、GUI agent、机器人训练、自动驾驶训练等。新版本在视频理解能力上也有大幅提升，比如记忆、总结理解、速度感知、长视频理解等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRYJ2OiZM_M-Jh27x3OFEdg&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345068</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345068</guid>
            <pubDate>Mon, 14 Apr 2025 05:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌推出了超越 Sora 的 Veo 2，生成 8 秒超逼真视频</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;谷歌 DeepMind 终于将大家期待已久的 Veo 2 整合到 GeminiApp 应用中，全面开放使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/114154_vVro_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Veo 是谷歌迄今为止最强大的视频生成模型。它可以生成各种电影和视觉风格的视频，捕捉提示中的细微之处，以便在各个画面中一致呈现精致细节。&lt;/p&gt; 
&lt;p&gt;据介绍，Veo 2 可以最高生成 8 秒 720P 电影级视频，在运镜、文本语义还原、物理模拟、动作一致性等方面非常优秀，同时支持图片转视频功能。谷歌公布的测试数据显示，Veo 2 在用户偏好和提示还原方面已经超过了 Sora、可灵 1.5、Meta Movie Gen 和 Minimax。&lt;/p&gt; 
&lt;p&gt;开发者可以在 Google AI Studio 中通过 API 使用 Veo 2。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fvideo%3Fhl%3Dzh-cn&quot; target=&quot;_blank&quot;&gt;https://ai.google.dev/gemini-api/docs/video?hl=zh-cn&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345050/google-gemini-veo2</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345050/google-gemini-veo2</guid>
            <pubDate>Mon, 14 Apr 2025 03:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Reachy 2 开源人形机器人 7 万美元正式开售</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Pollen Robotics 推出其最新开源人形机器人 Reachy2，正式开启销售，定价为 7 万美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 并非面向消费市场，而是专为 AI 与机器人实验室设计，目标是推动开源机器人生态的发展。据 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fzh%2Fnews%2F17257&quot; target=&quot;_blank&quot;&gt;AIbase&lt;/a&gt;了解，这款机器人已在 Cornell 大学、Carnegie Mellon 大学及多家顶级 AI 实验室投入使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;324&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be15587448f52736ea558e37ca046b43429.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 以其高度仿人的外形与交互能力脱颖而出，主要亮点如下：&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;仿人设计：配备双臂、头部及独特的天线，Reachy2 的 7 自由度（DoF）手臂模仿成人手臂的尺寸与运动方式，可实现自然、精准的动作，每只手臂能负重高达 3 公斤。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;全向移动：其移动底盘采用三全向轮设计，结合 LiDAR 与多传感器系统，确保平滑、精准的导航，适应多样化应用场景。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;丰富的传感器阵列：集成双 1080p 摄像头、麦克风阵列、扬声器、LiDAR 及惯性测量单元（IMU），为环境感知与交互提供强大支持。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;开源与模块化：基于 ROS2 和 Hugging Face 的 LeRobotHF 框架，Reachy2 支持 Python SDK 编程，开发者可轻松扩展与定制功能，满足特定研究或应用需求。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Reachy2 已被全球 20 多个国家的 100 多台机器人部署，客户包括 Hugging Face、Accenture、CNRS、Ecole Polytechnique 等。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345048</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345048</guid>
            <pubDate>Mon, 14 Apr 2025 03:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌宣布将全球搜索流量统一重定向至 google.com</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fcountry-code-top-level-domains%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;将淘汰用于搜索的单独国家代码顶级域名（如 google.ng 或 google.com.br），并将其统一为 google.com。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;当您在 Google 上搜索时，我们致力于提供最实用的信息，这在很多情况下包括提供与本地相关的搜索结果。一直以来，为了提供本地化结果，我们都会使用国家/地区代码顶级域名 (ccTLD)，例如尼日利亚的 google.ng 或巴西的 google.com.br。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;多年来，我们提供本地化体验的能力不断提升。2017 年&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fmaking-search-results-more-local-and-relevant%2F&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;，&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;我们开始为所有使用 Google 搜索的用户提供一致的本地搜索结果体验，无论他们使用的是&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;还是其所在国家/地区的国家代码顶级域名 (ccTLD)。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;由于这项改进，国家/地区级域名已不再必要。因此，我们将开始将这些国家/地区顶级域名 (ccTLD) 的流量重定向至&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以简化用户的搜索体验。此项更改将在未来几个月内逐步推出，在此期间，您可能会被提示重新输入部分搜索偏好设置。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，虽然此更新将改变人们在浏览器地址栏中看到的内容，但它不会影响搜索的工作方式，也不会改变我们处理国家法律规定的义务的方式。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5aaedebd84aee9085474149ca6015d401f8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软发布安全提醒：攻击者滥用 Node.js 来传播恶意软件</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微软近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fsecurity%2Fblog%2F2025%2F04%2F15%2Fthreat-actors-misuse-node-js-to-deliver-malware-and-other-malicious-payloads%2F&quot; target=&quot;_blank&quot;&gt;发布博文&lt;/a&gt;&lt;/u&gt;，称 Node.js 正日益被用于传播恶意软件和其他恶意负载。自 2024 年 10 月以来，微软持续监测到针对其客户的攻击活动，部分恶意活动甚至延续至 2025 年 4 月。&lt;/p&gt; 
&lt;p&gt;尽管与 Node.js 相关的恶意软件并不普遍，但它们正迅速发展，成为威胁环境的一部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/112133_vXu9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微软表示，Node.js 是开源、跨平台的 JavaScript 运行时环境，它允许 JavaScript 代码在浏览器之外运行，被广泛使用并被开发者信任，因为它让开发者能够构建前端和后端应用程序。然而，攻击者也在利用这些 Node.js 特性来尝试将恶意软件与合法应用程序混合，绕过传统的安全控制，并在目标环境中持续存在。&lt;/p&gt; 
&lt;p&gt;微软举例称，犯罪分子利用与加密货币相关的恶意广告（malvertising）诱导用户下载伪装成来自 TradingView 或 Binance 等平台的合法文件的恶意安装程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e9b941943b28336312ced97e7c00094ce72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这个安装程序内含恶意 DLL 文件，用于收集基本的系统信息。随后，一个 PowerShell 脚本会下载 Node.js 二进制文件和一个 JavaScript 文件，并通过 Node.js 执行。&lt;/p&gt; 
&lt;p&gt;该 JavaScript 文件运行一系列程序，包括加载多个模块、向设备添加证书，以及窃取浏览器中的敏感信息。微软指出，这些行为可能预示后续的凭据窃取、规避检测或二次负载执行等恶意活动。&lt;/p&gt; 
&lt;p&gt;微软在第二个攻击实例中表示，黑客采用了 ClickFix 社交工程技术，试图欺骗受害者执行恶意的 PowerShell 命令。&lt;/p&gt; 
&lt;p&gt;该命令会启动多个组件的下载和执行，包括 Node.js 二进制文件，让 JavaScript 代码无需通过文件执行，能够直接在命令行中运行。&lt;/p&gt; 
&lt;p&gt;微软强调，尽管 Python、PHP 和 AutoIT 等传统脚本语言仍被广泛用于威胁活动，但威胁行为者正转向编译后的 JavaScript，甚至直接利用 Node.js 在命令行中运行脚本，实施恶意行为。&lt;/p&gt; 
&lt;p&gt;微软警告，这种威胁行为者技术、战术和程序（TTPs）的转变表明，尽管 Node.js 相关的恶意软件数量上相对其它攻击手段并不凸显，但正迅速融入不断演变的网络威胁。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>JetBrains 宣布推出 AI 工具免费套餐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;JetBrains 发文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2025%2F04%2F16%2Fjetbrains-ides-go-ai%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;，所有 JetBrains AI 工具（包括改进的 AI Assistant 和新的编码代理 Junie）现在都可以通过单一订阅在 IDE 中使用，并提供免费套餐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，为了让每个人都能使用 IDE 内的 AI 功能，从 2025.1 版本开始，所有的 IDE 许可证中都包含了 JetBrains AI free&amp;nbsp;套餐。AI Free 套餐为用户提供无限代码补全和本地 AI 模型访问权限，以及基于积分的云端 AI 辅助功能和编码代理 Junie。此外，免费套餐还包含 30 天的 AI Pro 访问权限。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Pro（10 美元/月）和 AI Ultimate（20 美元/月）套餐计划将为高要求的工作流程提供更高的使用配额，&amp;nbsp;All Products Pack 和 dotUltimate 订阅则将包含 AI Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7661cb02397405a130e0974ef8e9b7b5ef6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;与此同时，该公司宣布其&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI 编码助手&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;color:#585858&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsdtimes.com%2Fai%2Fjetbrains-releases-ai-coding-agent-junie%2F&quot; target=&quot;_blank&quot;&gt;Junie&lt;/a&gt;&amp;nbsp;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;现已面向所有 JetBrains 客户开放。Junie 已进行更新，能够执行更复杂的任务，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;并提供更精细的控制，实现真正的「人机交互」方法。目前，&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;Junie 已兼容 IntelliJ IDEA Ultimate、PyCharm Pro、WebStorm 和 GoLand。预计 PhpStorm、RustRover 和 RubyMine 也将很快获得支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;除了 Junie 的公开发布之外，该公司还发布了 JetBrains AI Assistant 的新版本。包含多项重大改进，旨在加速编码工作流程并减少重复性任务，为开发者提供全程开发支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI Assistant 现在拥有更多模型选择，包括 Claude 3.7 Sonnet、Google Gemini 2.5 Pro 以及 OpenAI 的最新模型，以及具备更强大的本地模型集成功能。其他更新包括改进的代码补全、更强的上下文感知、可以编辑多个文件的新编辑模式，以及从代码生成到测试到文档的整个工作流程的更智能的支持。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fjetbrains.com%2Fai-ides%2F&quot; target=&quot;_blank&quot;&gt;立即开始&lt;/a&gt;在 IDE 中使用 AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;相关阅读：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;margin-left: 0px; margin-right: 0px; text-align: start;&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/345083/intellij-idea-2025-1-released&quot; target=&quot;news&quot;&gt;IntelliJ IDEA 2025.1 现已发布&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345039/jetbrains-ides-go-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345039/jetbrains-ides-go-ai</guid>
            <pubDate>Mon, 14 Apr 2025 03:13:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>美国政府不再为 CVE/CWE 项目提供资金支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;4 月 15 日，MITRE 向 CVE 委员会发送了一封邮件，告知美国政府对 CVE/CWE 项目的资助合同将于 4 月 16 日到期。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/110904_ginQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;受此影响，CVE 漏洞可能更新受到影响，并影响 NVD 等下游的漏洞库。&lt;/p&gt; 
&lt;p&gt;CVE 项目始于 1999 年，由美国国土安全部（DHS）和网络基础设施安全局（CISA）的赞助，MITRE 负责运营，NVD（美国国家漏洞库）等下游漏洞库基于 CVE 的数据进一步加工分析。&lt;/p&gt; 
&lt;p&gt;在过去的二十多年里，CVE 是对通用漏洞标识的标准，是漏洞情报共享、漏洞库、各类安全工具的重要基础数据，这是一项非常有意义的伟大工作。&lt;/p&gt; 
&lt;p&gt;若资金链断裂，CVE 系统的崩溃将摧毁最受信赖的安全工具和流程。&lt;/p&gt; 
&lt;p&gt;前 CISA 负责人 Jean Easterly 在 LinkedIn 上警告，CVE 虽不常上头条，但却是现代网络安全最重要的支柱之一，失去它如同「同时拆除所有图书馆的卡片目录」，防御者将陷入混乱，攻击者则有机可乘。她强调，网络威胁无国界，CVE 是全球共享情报和协调行动的通用语言，失去它等于「所有人都在盲飞」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345038</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345038</guid>
            <pubDate>Mon, 14 Apr 2025 03:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 发布开源 AI 编程工具 Codex CLI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI 发布了一个名为「Codex CLI」的实验性新工具。这是一个轻量级的 AI 编程助手，可以直接在用户的终端命令行运行，旨在充分发挥 o3、o4-mini 等模型强大的推理能力，连接本地代码环境，甚至支持处理截图或草图进行多模态编程。&lt;/p&gt; 
&lt;p&gt;Codex CLI 已在 GitHub 完全开源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Fcodex&quot; target=&quot;_blank&quot;&gt;https://github.com/openai/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9e6e21608c2ed84ac64e14c0758cff7933.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Codex 有两种运行模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;「建议模式」（默认）：&lt;/strong&gt;提出命令供用户确认；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「全自动模式」&lt;/strong&gt;：禁用网络访问，让 Agent 自主工作但保持安全。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OpenAI Agent 研究团队成员 Michael 为了展示 Codex CLI 的功能，截取了一张在 X 上关于一个「图像到 ASCII 风格转换」工具的推文截图。&lt;/p&gt; 
&lt;p&gt;他将这个截图直接拖入终端，通过 Codex CLI 并利用 o4-mini 的多模态推理能力，最终成功创建了一个简单的 ASCII 风格图像转换工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-289ad265fb8a85af1f5a6e370f846aaffec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 认为 Codex CLI 是一个将其模型与用户及其计算机连接起来的最小化界面。&lt;strong&gt;Codex CLI 是为已经生活在终端的开发者设计的&lt;/strong&gt;，他们想要 ChatGPT 级别的推理能力，以及实际运行代码、操作文件和迭代的权力 —— 所有这些都在版本控制之下。&lt;/p&gt; 
&lt;p&gt;简而言之，它是一种理解并执行仓库的聊天驱动开发工具。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;零配置 — 导入 OpenAI API 密钥，即可直接使用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全自动批准，同时通过运行网络禁用和目录沙箱化确保安全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多模态 — 输入截图或图表就可以实现推理功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Codex CLI 可以在 macOS&amp;nbsp;12+、Ubuntu&amp;nbsp;20.04+/Debian&amp;nbsp;10+、Windows&amp;nbsp;11 的 WSL2 子系统中使用，要求最少拥有 4GB 内存（建议 8GB）。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345034/openai-codex-cli</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345034/openai-codex-cli</guid>
            <pubDate>Mon, 14 Apr 2025 02:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 发布 o3 与 o4-mini：开启多模态推理新时代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;距离 OpenAI 发布 &lt;a href=&quot;https://www.oschina.net/news/344606/openais-gpt-4-1-models&quot;&gt;GPT-4.1&lt;/a&gt; 仅过去两天，OpenAI 在本周再次投下「重磅炸弹」—— &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-o3-and-o4-mini%2F&quot; target=&quot;_blank&quot;&gt;正式发布&lt;/a&gt;&lt;/u&gt;其新一代推理模型 o3 与轻量级模型 o4-mini。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104452_zQp5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这两款模型在推理能力、视觉理解、个性化对话和跨领域应用等方面实现了显著飞跃，代表了当下人工智能技术的新高度。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o3：迄今为止最强的通用推理模型&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI o3 是目前最强大的推理型模型，专为应对复杂、多步骤的任务而打造，广泛适用于编程、数学、科学分析、图像理解等领域。&lt;/p&gt; 
&lt;p&gt;它在多个权威基准测试中创下新纪录，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codeforces 编程排名&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SWE-bench 软件工程测试&lt;/strong&gt;（无需构建自定义脚手架）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MMMU 多模态任务测试&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不仅如此，&lt;strong&gt;o3 在图像、图表和视觉感知任务中表现尤为出色&lt;/strong&gt;。对于需要图像分析、图表解读等多模态输入的复杂问题，o3 能给出结构化、深入且精准的回答。&lt;/p&gt; 
&lt;p&gt;外部专家评估结果显示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;o3 在处理真实、复杂任务时比 o1 少 20% 的重大错误。尤其在编程、商业咨询、科研假设等场景中，o3 表现出色，能提出新颖想法并进行深度自我审查。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;首批使用者评价 o3 是 「值得信赖的思维伙伴」，特别擅长在生物、数学和工程领域中生成并评估新假设。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104214_ZHcj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o4-mini：更小、更快、更高效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;与 o3 不同，&lt;strong&gt;o4-mini 是一款轻量级、优化后的高性价比推理模型&lt;/strong&gt;，在计算资源、响应速度与实际效果之间达成了优秀的平衡。&lt;/p&gt; 
&lt;p&gt;亮点包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 和 2025 数学竞赛中表现最佳&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在非 STEM 任务（如数据科学）中的表现超越 o3-mini&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数学、编程、图像识别任务中效率极高&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;✅ 由于模型本身更轻量，o4-mini 支持更高的调用频率和更低的成本，非常适合&lt;strong&gt;大批量、多并发、快响应&lt;/strong&gt;的应用场景。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;更自然的人机互动体验&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;无论是 o3 还是 o4-mini，这一代模型在对话体验上也有明显提升。得益于智能水平的增强与网络信息的集成支持，&lt;strong&gt;两款模型都能更好地理解用户意图，提供可验证、结构清晰的回答&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持上下文记忆引用，更贴合用户历史对话&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令遵循能力增强，响应更精准自然&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;更加个性化、情境感知的交互&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;专家评语摘要&lt;/h3&gt; 
&lt;table style=&quot;min-width:155px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;优势亮点&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o3&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;推理最强，图像理解领先，适用于高复杂任务&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o4-mini&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;高性价比，适合大规模调用，非 STEM 场景表现跃升&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;外部专家一致认为，&lt;strong&gt;新模型在可用性、可靠性和语言自然度上均优于前代产品&lt;/strong&gt;，是未来 AI 助手的重要里程碑。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI 的 o3 与 o4-mini 的发布，标志着 AI 推理模型的又一次跃迁。从性能到体验，从通用性到多模态理解，它们都展现出前所未有的能力。&lt;/p&gt; 
&lt;p&gt;如果你在寻找一个既能处理复杂问题，又能快速响应且个性化的 AI 模型，这一代产品值得你深入了解与使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</guid>
            <pubDate>Mon, 14 Apr 2025 02:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>多模态视觉理解大模型推理优化</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div class=&quot;rich_media_content js_underline_content
                       autoTypeSetting24psection
            &quot; id=&quot;js_content&quot;&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;01&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;背景&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 85px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;大模型时代是人工智能领域的一个重要发展阶段，在当今人工智能研究领域，基于 Transformer 架构的多模态视觉理解大模型（VLM）在全世界范围内引发了深度的技术关注。多模态视觉理解大模型的主要创新在于将语言和视觉两种模态进行有效的对齐，使其不仅能够进行基本的图像识别，还能执行基于视觉输入的动态内容推理和复杂问题解答。可以应用在房内家具家电识别、涉黄涉爆检测、商家店铺门头识别等多个场景，相比传统模型取得更好的效果。但是由于多模态视觉理解大模型的推理性能比传统模型低，导致整体成本高，严重阻碍了多模态视觉理解大模型的推广。提高多模态视觉理解大模型的推理性能成为研究重点。我们是多模态大模型技术部门，负责多模态大模型相关的模型研发、推理优化和推广的工作。我们在 58 的多模态视觉理解的项目场景中，对推理框架和模型进行优化，使用多种方法提高多模态视觉理解模型的推理性能。&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;02&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
     &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;场景介绍&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 58 的多模态视觉理解的项目中，都是后台提交任务对图片进行推理，没有与用户进行实时对话的场景，所以目前性能优化的重点是批量输出的场景。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;场景一：长 token 输入、短 token 输出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;多模态视觉大模型输入的是提示词+图片，输入的 token 通常都比较长，在 58 的场景内，98% 以上的推理场景是输出短 token，通常在 5 个 token 以内。比如在信安定制数据治理项目中，输出的 token 是只有「是」或者「否」。我们重点对这种场景进行性能优化。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;场景二：长 token 输入、长 token 输出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;另外 2% 的推理场景是输出长 token，比如给一张简历的 pdf 图片，让大模型识别图片中的内容，输出的 token 一般是几百个以上。这种场景的占比很少，不是性能优化的重点方向。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;03&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;性能指标&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;VLM 推理服务重点关注两个指标：&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量&lt;/span&gt;&lt;/strong&gt;&lt;span leaf=&quot;&quot;&gt;和&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;时延&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要从系统的角度来看，即系统在单位时间内能处理的 tokens 数量。由于我们的主要场景是长输入 token，短输出 token，所以吞吐量的计算以单位时间内能处理的请求作为衡量指标，即模型推理的 qpm。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;时延：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要从用户的视角来看，即用户平均收到每个 token 所需的时间。计算方法为用户从发出请求到收到完整响应所需的时间除以生成序列长度。一般来讲，当时延不大于 50 ms/token 时，用户使用体验会比较流畅。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;由&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;于我们的场景都是批量输出的场景，没有流式输出的场景，所以我们重点关注的性能指标是吞吐量。&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;04&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;优化内容&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_1&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.1 图像预处理优化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在多模态推理中 Vision Transformer (ViT) 是一个关键的模块，图像的预处理是将图像转换为适合 ViT 模型输入数据的过程。主要包括图像颜色空间转换、尺寸调整 (Resize)、划分图像块 (Patch Partitioning)、归一化（Normalize）等步骤。在 LMDeploy 框架中，图像预处理过程中主要通过 PIL(Pillow) 的 Image 模块在 CPU 上对图像进行处理，在图像 Resize 及 Partition 过程中，效率较低，耗时占整个 ViT 过程的 20% 以上。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;为了提升系统吞吐能力，减少图像预处理耗时，我们分别使用 Pillow 与 OpenCV 进行预处理测试，具体表现如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;CPU: Intel(R) Xeon(R) Silver 4410Y&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Python 3.10.12&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Pillow 10.2.0&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;opencv_python 4.8.1.78&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2000 张不同分辨率图像&lt;/span&gt;&lt;/span&gt; 
       &lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014200&quot; data-ratio=&quot;0.10252996005326231&quot; src=&quot;https://oscimg.oschina.net/oscnet/1bfb0234-fa3d-4e69-ad7e-225bcbe39f01.png&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 1：Pillow 与 OpenCV 预处理耗时对比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;使用 OpenCV 可以极大的减少图像预处理的耗时，平均处理单张图片的耗时由 23.67ms 减少到 12.03ms，性能提升 49.18%。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 Resize 过程中，虽然两个处理库对应的插值方式均使用 BICUBIC，但当图像进行下采样时效果存在明显差异，使用 OpenCV 进行处理的图像存在波纹。如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014201&quot; data-ratio=&quot;0.5472222222222223&quot; data-s=&quot;300,640&quot; src=&quot;https://oscimg.oschina.net/oscnet/b96df915-b9d8-40bd-ba95-705072874e44.png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;width: 509px;height: 279px;&quot; type=&quot;block&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-size: 15px; text-align: center; cursor: default; line-height: 2em; margin-bottom: 8px; margin-top: 8px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 2：Pillow 与 OpenCV 效果对比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;通过对比源码实现，发现二者在插值与边界处理实现上有所差异：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;插值计算方式有差异&lt;/span&gt;：二者均使用 4x4 的卷积核进行插值计算，OpenCV 直接使用三次多项式公式计算每个像素的权重，并对周围 16 个像素进行加权平均；而 Pillow 将三次卷积操作分解为两个一维卷积，先对水平方向进行卷积，然后再对垂直方向进行卷积。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;边界处理的差异&lt;/span&gt;：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;OpenCV 供多种边界处理方式，例如 BORDER_REPLICATE, BORDER_REFLECT, BORDER_WRAP 等；Pillow 通常使用边界复制的方式进行处理，即边缘像素值被复制到图像外部，以避免在边缘出现伪影。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;针对这个问题，OpenCV 说明文档中提供了相应的解决方案：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);color: rgb(0, 0, 0);&quot;&gt;To shrink an image, it will generally look best with INTER_AREA interpolation, whereas to enlare an image, it will generally look best with INTER_CUBIC (slow) or INTER_LINEAR (faster but still looks OK).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;于是我们根据不同的图像采样对插值方式进行动态调整，对图像降采样时，使用 INTER_AREA 插值，上采样时，使用 INTER_CUBIC(速度较慢，但效果最好)，调整后，Resize 结果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e376a935-28bc-49af-a8c6-cabb4db7286f.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38425925925925924&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; type=&quot;block&quot; data-imgfileid=&quot;100014202&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 3：OpenCV 优化前后与&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;Pillow 效果对比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.2 ViT 模块支持 TensorRT&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;ViT 模块是多模态推理框架中一个必不可少的组成模块，主要负责图像相关处理及编码工作。ViT 模块的处理速度，直接影响整个框架的整体推理效率。为了进一步提升框架的推理效率，我们对 ViT 模块的耗时进行了分块分析，结果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/7c067863-ae5f-4261-bc0f-f16e4b12bb25.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.10119840213049268&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; data-imgfileid=&quot;100014203&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 4：vision 模型推理耗时及内存占用情况&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;内存拷贝相关逻辑：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ce4defef-9707-41cd-88e1-c878c4646834.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5291181364392679&quot; data-type=&quot;png&quot; data-w=&quot;601&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;601&quot; data-imgfileid=&quot;100014175&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 5：LMdeploy VIT 阶段内存拷贝代码截图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;经过验证，内存拷贝耗时主要是等待 GPU 异步处理结果，所以实际上主要耗时模块为图像预处理及特征提取两部分。具体定位步骤如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;list-style-type: disc;margin-left: 8px;margin-right: 8px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;内存拷贝逻辑修改&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;ul style=&quot;list-style-type: circle;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/vl/engine.py 取消结果拷贝至 cpu 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/serve/vl_async_engine.py 取消拷贝到 cpu 及转换 numpy 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/pytorch/message.py 中修改 InputEmbeddings 及类型为 Torch.Tensor(GPU)&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
     &lt;/ul&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;内存拷贝逻辑修改引起异常的分析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;逻辑调整后，推理结果异常。在 vl/engine.py forward 增加输出结果日志后，推理正常。经验证输出结果日志操作起到同步等待作用，使用 torch.cuda.synchronize() 或者 sleep 验证猜想正确。后续在模型内增加日志输出结果或者以上两个操作，推理结果均正常。推理结果正常后定位耗时模块，定位到 ViT 中 extract_feature 为主要耗时模块。为了进一步提升推理效率，我们借鉴了 TensorRT-LLM 中的推理加速方案 TensorRT。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;TensorRT 是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。TensorRT 可对多种应用场景进行推理加速，并且支持 TensorFlow、Caffe、Mxnet、Pytorch 等几乎所有的深度学习框架。将 TensorRT 和 NVIDIA 的 GPU 结合起来，能在几乎所有的框架中进行快速和高效的部署推理。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/92358ef8-bc80-4bf8-817c-4301d087eec0.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.486&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014176&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 6：Tensorrt 优化过程图&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在对 ViT 模块进行 TensorRT 改造时，主要包含模型转换、模型优化和推理部署三个阶段。模型转化支持 TensorFlow、PyTorch、ONNX 等主流深度学习框架的模型转换和优化，本文以 ONNX 为例进行说明。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;1、模型转换&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/be6a8f15-e0da-4080-aeac-586ca6fb9964.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7807308970099668&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;602&quot; data-imgfileid=&quot;100014173&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 7&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;ONNX 模型转换代码截图&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;导出 ONNX 时可能会遇到不支持的算子，如在导出快速傅里叶变换（FFT）和快速傅里叶逆变换（IFFT）时会遇到如下错误，&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;Exporting the operator &#39;aten::fft_rfftn&#39; to ONNX opset version 17 is not supported&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;这时需要调整模型网络结构或者自定义算子。在对 ViT 模块进行 ONNX 转换过程中，部分多模态模型的 ViT 中使用了 FlashAttention2 进行注意力加速，而 FlashAttention2 中的 flash_attn_func 是作为独立的内核实现的，不是 torch.nn.Module 的实例，导致导出器无法捕获计算图，如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;/usr/local/lib/python3.10/dist-packages/flash_attn/flash_attn_interface.py:90: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;因此，对 Attention 模块进行了调整，使用 PyTorch 内部实现的缩放点积注意力（Scaled Dot-Product Attention, SDPA），如下图，至此模型便可成功转换成 ONNX 格式。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e60836a9-5141-4603-9d85-270e50fd40be.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5825&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014174&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 8&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;缩放点积注意力 (SDPA) 代码截图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2、模型优化&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;该阶段主要完成模型优化，如下图所示，在模型优化过程中会完成层间融合，精度校准等。这一步的输出是一个针对特定 GPU 平台和网络模型的优化过的 TensorRT 模型，这个 TensorRT 模型可以序列化存储到磁盘或内存中，存储到磁盘中的文件为 TensorRT planfile。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/1ef2a7d7-071f-44da-aa1f-150b5e299114.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.224&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014172&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 9：Tensorrt 模型优化及系列化流程图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;3、推理部署&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/8169cdc0-de30-4af8-9617-1e080e14ec9c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2064&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014177&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 10：Tensorrt 部署及推理流程图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署阶段将上一个步骤中的 plan 文件反序列化，并创建一个 runtime engine，输入对应的图像数据，输出推理结果。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4、推理效率&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;经过 TRT 加速后，ViT 模块 feature_extract 速度缩减 45% 左右（不包含图片预处理），feature_extract 耗时在 ViT 中占比从 60% 减少至 45.36%，整体推理耗时耗时缩减在 70ms 左右。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.3 ViT 模块支持 CudaGraph&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;推理框架 lmdeploy 在 0.6.0 版本引入了 CUDA Graph,并提升了近 30% 的推理性能：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;&amp;nbsp;Employ CUDA graph to boost the inference performance (30%)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;不过受多方因素限制，目前 lmdeploy 只在语言模型中引入了 CUDA Graphs。为了进一步提升推理速度，我们在 ViT 模块中引入了 CUDA Graphs。CUDA Graphs 可以用于优化执行过程中的 CUDA 操作，在 GPU 上实现更加高效的深度学习模型推理。在使用 CUDA Graphs 时需要对 CUDA 操作进行录制（capture）和重放（replay），以此来减少 CPU 到 GPU 的调度开销，提高整体的执行效率。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;如下图，简单展示了 CUDA Graphs 的优势。在顶部，CPU 逐个启动一系列短内核。CPU 启动开销导致内核之间出现明显间隙。如果我们用 CUDA 图替换此内核序列，最初我们需要花费一些额外的时间来构建图并在第一次启动整个图时一次性启动整个图，但后续执行将非常快，因为内核之间的间隙将非常小。当多次重复相同的操作序列时，例如在许多训练步骤中重复，差异会更加明显。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac8a403c-ee90-4fe0-81cd-65e63efbb452.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.372&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014178&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 11：CUDA Graphs 性能优势图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;首先，在 ViT 支持 CUDA Graphs 时，需要 torch.cuda.CUDAGraph 创建对应的图，然后使用 torch.cuda.graph() 对 ViT 的推理过程进行录制，在推理过程中，使用刚创建的图对录制的过程进行重放 CUDAGraph.play()。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;但是要注意，由于 CUDA Graphs 不支持动态控制流（如条件语句和循环），因此在设计算法时应尽量避免使用这些结构；其次，确保输入张量的形状在图创建时是固定的，因为 CUDA Graphs 的设计是基于静态形状的张量结构，创建 Graph 时，所有操作及其输入输出的形状必须在图创建时确定。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;而 ViT 模块在进行图像处理时，输入的图像数张量的形状是 [batch_size, channel, width, height]，其中 batch_size 是可变的且各视觉模型均已限定最大值。于是，我们在框架内部维护了 Graphs Pool，推理时使用 batch_size 索引至相应的 graph，再执行重放操作。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;增加 CUDA Graphs 后 ViT 模块平均耗时减少 30ms 左右。虽然 CUDA Graphs 可以在一定程度上提升推理的效率，但是在构建 graphs 也需要占用一些额外的显存，在使用时需要综合衡量具体的业务场景及硬件资源。&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.4 图像 Token 化处理&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;输入 token 的长度对推理耗时影响很大，多模态模型中，图像部分占据了很大比例的 token 数，降低图像转换的 Token 数可提升推理性能。如下是结果对比：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/f660d32a-1b9f-4656-98d1-dbecee5fe26c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.29894179894179895&quot; data-type=&quot;png&quot; data-w=&quot;378&quot; style=&quot;width: 382px;height: 114px;&quot; data-imgfileid=&quot;100014204&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;图 12：&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif; font-size: 15px; letter-spacing: normal; background-color: rgb(255, 255, 255); cursor: default; text-align: justify; margin-top: 8px; margin-bottom: 8px; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;Token 数和推理耗时基本成正比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;图像转换的 Token 数计算主要流程如下&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;（1）根据图像宽高比和分辨率大小将原图拆分成若干个 448*448 的 patch，拆分的原则是尽量保持图像不失真。拆分代码如下：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/30811eb3-1df8-4dc0-b6e3-6ea8f054445d.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9367088607594937&quot; data-type=&quot;png&quot; data-w=&quot;869&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014179&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 13：VLLM 中 InternVL2-8B 模型拆图代码截图&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;上述代码基本流程是，给定动态拆分的阈值范围，穷举出所有可能的目标比例，再根据原图比例匹配最佳的拆分规则，拆分逻辑图示如下图左上部分，图示中会被拆分成 6 个 path 块和一张缩略图。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/9b84a37b-1304-4f2d-84ad-324785e09a4b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.526&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014180&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 14&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;InternVL 模型整体框架图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（2）一个 448*448 的 patch 生成的 token 数计算方式如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);font-weight: normal;&quot;&gt;image_tokens_per_patch=(force_image_size // patch_size)**2 * (downsample_ratio**2))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;force_image_size=448,patch_size=14,downsample_ratio=0.5,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;这个计算后结果为 256。不同的模型值可能会有所差异。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（3）分辨率为 896*1344 的图像，经过步骤 1 处理，会拆分成 2*3=6 个 patch，再加上一张缩略图（可选，有效果会更好），最终堆叠后 shape 是[7,3,448,448]，图像转换的 token 数为 7*256=1792。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署到线上时，单卡吞吐量上不去，其中一个原因是拆图规则导致拆分后的图片数量比较多，如分辨率 612*464，最合适的宽高比是 (4, 3)，按模型的图片拆分规则，图像将被拆分成[13,3,448,448]，转化后的 token 数达到 3328，再加上 prompt 的 token，总 token 数会达到 3400+，太长的输入 token 对模型推理速度影响很大，再加上显存和算力的限制，无法做到更大 batch 的推理，使得单卡推理的吞吐量很低。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;基于此原因，我们的优化思路是降低图像的总 token 数，经实验分析，官方代码在实现上存在比较大的冗余设计，如图像分辨率为 480*360，也会转换成 3328 个 token 数，对于低分辨率图像生成太多的 token 存在资源浪费。在保持图像内容不拉伸前提下，对图像的宽高比做调整，以适应 vit 的要求，优化后，480*320 的图像只转换成 512 个 token 数，这样在推理时能做到更大的 batch 处理。在我们实际落地场景中，处理后吞吐量能提升 1 倍。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.5 prefixcache 在多模态模型里应用&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;在&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;PagedAttention 中，KV Cache 只是在一个请求内复用，而没有做到跨请求的 KV Cache 复用。长 prompt 的场景，prompt 在不同的请求中是相同的，KV Cache 的计算也是相同的，如果能把 prompt 的 KV Cache 保存下来，留给后续的请求复用，将会极大地降低首 Token 的耗时。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;在 LLM 模型里，prefixcache 分二个阶段，第一个阶段，当 prompt 第一次被推理时，是按 block_size(通常是 64) 大小对 input tokens 从前往后进行分块，计算每个分块的 hash 作为唯一标识，每个分块的 token_id 作为 key 进行缓存，这里不足 block_size 长度的块不会被缓存；第二阶段，当新 prompt 被推理时，会进行 prefix cache matching，命中就直接复用 kvcache，只计算未命中部分的 input tokens。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;多模态模型区别在于，一次任务的输入 tokens 组成由纯文本变成了文本+图片，由 system+prompt 变成了 system+image+prompt，在计算 prefix cache 时，image 对应的只是 padding tokens，那么在计算 prefix cache matching 时，不同图片可能匹配到一样的 prefix 上，这样推理结果就会出现错误。针对这个问题，在 input tokens 中对 image 进行范围标记，在计算 prefix cache 时不对 image token 进行 kvcache，只 cache image 之前的部分；在 prefix cache matching 时，也同样保证 image token 不会被复用。经实验验证，修改后能保证在开启 prefix cache 时，推理结果是正确的。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;需要注意，Prefix Caching 只节省了 prefill 阶段的耗时（也就是降低了 TTFT，Time To First Token），并不能节省解码阶段的耗时（也就是 TPOT，Time Per Output Token）。如果请求的主要耗时是在解码阶段（例如 prompt 很短而 completion 很长），或者多个请求的 prompt 并没有公共的前缀，那么 Prefix Caching 就对于整个 LLM 推理的性能提升帮助不大&lt;/span&gt;。&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.6 模型量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化是大模型领域中的一项关键技术，它通过降低模型参数的精度，将浮点数转换为整数或定点数从而实现模型的压缩和优化。模型量化可以减少模型尺寸，进而减少在推理时的显存消耗，并且在一些低精度运算较快的处理器上可以增加推理速度。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化分很多情况。从量化对象来说，量化可以是权重、激活、kv cache 和梯度；从量化的形式上来说分为线性量化和非线性量化，其中线性量化又分为对称量化和非对称量化；根据应用量化压缩模型的阶段，又可以将模型量化分为量化感知训练、量化感知微调、训练后量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;我们现阶段使用的量化方式是 AWQ 和 GPTQ，这两种量化都属于训练后量化，是针对权重的线性量化，其中 AWQ 采用对称量化，GPTQ 采用非对称量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;AWQ 量化的原理是对于 LLM，权重不是同等重要的，通过保留 1% 的显著权重可以大大减少量化误差。在此基础上采用激活感知的方法，考虑更大的激活幅度应该对应更重要的权重通道，在处理重要特征时起关键作用，逐通道确定最佳缩放因子。从而在量化所有权重的同时，最小化量化误差。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;GPTQ 对模型的每一层（通常是线性层或卷积层）进行单独处理，考虑了量化带来的误差，并通过调整未量化的权重来补偿这些误差。利用了二阶偏导 Hessian 矩阵的逆，来指导权重的调整，以减少整体的量化误差。将权重矩阵分成多个子矩阵（block），对每个子矩阵中的权重逐个进行量化，同时调整同一子矩阵内其他权重，以保持模型输出的相似性。其量化后的误差依赖一份高质量的校准数据。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;整体上来看，AWQ 相较于 GPTQ 量化的算法更直接，对校准数据依赖小；GPTQ 则更容易有比较好的量化效果，但是算法相对复杂，对校准数据依赖比较大，实际过程中用哪个更合适需要根据实际的场景选用。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在实际测试中，不论是 AWQ 还是 GPTQ 实际采用的都是 w4A16 的量化策略，在推理的时候，性能差异比较小，在 RTX4090 显卡下，我们使用 vllm，对应不同参数，并且设置最优 batch，实际测试值如下：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;针对单个请求的延时：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac7dd996-e553-40fb-b9a8-4832f70c1a3b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2084507042253521&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;710&quot; type=&quot;block&quot; data-imgfileid=&quot;100014210&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 15: 原始模型和量化模型的推理耗时比较&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;从测试结果看：在 4090 下，大 batch 的计算，使用 gemm 内核，速度不如原精度，原因是在大 batch 的情况下，增加了反量化的时间。使用 marlin 内核，计算的速度有优化，但是在大 batch 下，优化速度不明显。低 batch 的计算原精度是计算最慢的，gemm 的内核计算与 marlin 计算差别不是很大，都比原生的有大幅提高。原因是 gemm 在低 batch 下，也做了内核优化，这一点可以从原代码中验证：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/89dafcc6-de64-4e34-b8ac-72982e9aeb04.png&quot; class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.30575035063113604&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;713&quot; type=&quot;block&quot; data-imgfileid=&quot;100014211&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 16&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;VLLM 中 awq 量化模型 mul 计算逻辑代码&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: left;line-height: 2em;&quot;&gt; 
    &lt;span leaf=&quot;&quot;&gt;针对吞吐量：&lt;/span&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/c2d58729-66c8-42cd-ad10-c69be338f6b4.jpg&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.15281501340482573&quot; data-s=&quot;300,640&quot; data-type=&quot;webp&quot; data-w=&quot;746&quot; data-croporisrc=&quot;https://oscimg.oschina.net/oscnet/22f3d6f2-bfb2-465f-9504-408778ea5dbd.jpg&quot; data-cropselx2=&quot;578&quot; data-cropsely2=&quot;120&quot; data-imgfileid=&quot;100014212&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 17：原始模型和量化模型的吞吐量比较&lt;/span&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;从测试结果看，对于短输出，其实吞吐量并没有优化，还下降了一点，原因是，对于短输出，主要的耗时在 prefill，prefill 是大 batch 的计算，在推理过程中，吞吐量会下降。但是对于长输出，decode 阶段占比比较高，内核对于 decode 的优化比较明显，综合吞吐量会上升。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;总结：在实际使用中对于 W4A16 量化后的模型来说，模型占用的显存一定能节省。但是推理的整体性能和吞吐量，需要根据不同的任务特点，部署的硬件环境，调整部署的参数，以达到最优。而不是量化后的整体性能一定会优于未量化的模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;05&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp; 优化数据&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;评测模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：InternVL2-8B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;数据集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：信安群租房检测 4524 张图片&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;提示词&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：图中有 3 张以上的床，或者是有双层床，请直接给出是或者否，然后给出详细的解释。注意 1 张双层床有 2 张床&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;输出 token 数量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：max_tokens=1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;GPU&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;: RTX4090&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;对比框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;优化框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0 优化版本&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;吞吐量：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;由于我们的场景是长输入 token 和短输出 token，所以按单位时间内处理的请求数作为衡量指标。比较两个框架的推理 QPM&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/1b84899b-305c-4427-8131-5600a10b72b8.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1893687707641196&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; data-imgfileid=&quot;100014207&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p data-pm-slice=&quot;0 0 []&quot; style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 18：LMDeploy-0.6.0 优化前后召回率和吞吐量比较&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;LMDeploy-0.6.0 优化版本在推理效果不受影响的情况下，吞吐量提升到 LMDeploy-0.6.0 版本的 3.05 倍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;作者简介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;徐海芳、李海洋、朱辰、张辉，MPai 平台视觉理解大模型推理团队&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;font-size: large;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/section&gt; 
  &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;display: none;&quot;&gt; 
  &lt;mp-style-type data-value=&quot;3&quot;&gt;&lt;/mp-style-type&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color: #858585; font-size: 13px;&quot;&gt;本文分享自微信公众号 - 58 技术（architects_58）。&lt;br&gt;如有侵权，请联系 support@oschina.cn 删除。&lt;br&gt;本文参与「&lt;a href=&quot;https://www.oschina.net/sharing-plan&quot; target=&quot;_blank&quot;&gt;OSC 源创计划&lt;/a&gt;」，欢迎正在阅读的你也加入，一起分享。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5359019/blog/18160034</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5359019/blog/18160034</guid>
            <pubDate>Mon, 14 Apr 2025 02:30:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>《流浪地球 3》发布 AI 问答应用 WEi</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;电影《流浪地球 3》近日在青岛举行开机仪式，郭帆导演携主创团队齐聚亮相。在开机仪式现场，《流浪地球 3》剧组正式发布剧组专属的自研 AI 问答应用 WEi。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;365&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b58e821f644cfcd13feb137d9d2cac2428.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该应用依托大语言模型，基于 DeepSeek R1 大语言模型，NVIDIA、火山引擎作为「AI 支持合作伙伴」所开发，本地推理部分由 NVIDIA GeForce RTX 5090 D 加速，旨在为剧组提供一站式智能服务，大幅提升剧组创作效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，WEi 通过整合多元化知识库资源，包括在线信息源的专业资料、图像和影视参考，以及电影《流浪地球》系列剧本、世界观、编年史、人物小传、美术设定等内部资料，为剧组工作人员提供高效检索通道，同时期望在参考信息上既符合科学基础又保持设定一致性，提高剧组工作人员创作效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345026</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345026</guid>
            <pubDate>Mon, 14 Apr 2025 02:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 拟以 30 亿美元收购 AI 编程工具 Windsurf</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社报道称，OpenAI 正与人工智能辅助编程工具 Windsurf（前身为 Codeium）展开收购谈判，交易金额约为 30 亿美元。这一潜在收购将成为 OpenAI 迄今为止最大规模的并购交易，标志着其在 AI 驱动的开发者工具市场迈出重要一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;262&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5591fcd5e926e90d56e1521a2184484a0b3.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Windsurf 是一款广受开发者欢迎的 AI 编程助手，能够基于自然语言提示生成代码、解释现有代码并执行相关任务。它不仅支持通过插件嵌入主流代码编辑器（如 Visual Studio Code），还提供专为 AI 辅助开发设计的自定义编辑器。Windsurf 自称是首款「代理式」集成开发环境 (IDE)，强调其在自动化和智能化编程流程中的独特优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;成立于 2021 年的 Windsurf（正式名称为 Exafunction Inc.）已累计融资超 2 亿美元，投资者包括 General Catalyst、Kleiner Perkins 和 Greenoaks Capital Partners。2023 年，其在 General Catalyst 领投的 1.5 亿美元融资中估值达 12.5 亿美元，而近期与投资者的谈判显示其估值已升至 30 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;X 平台上的讨论显示，业界对此次收购的反应复杂而热烈。一方面，许多开发者对 OpenAI 整合 Windsurf 的前景表示期待，认为这可能带来更强大的 AI 编程工具;另一方面，部分观点担忧收购可能对其他 AI 编程工具（如 Cursor）造成冲击，尤其是考虑到 OpenAI 此前通过其创业基金投资了 Cursor 的母公司 Anysphere。此外，微软近期对 Visual Studio Code 生态的收紧政策可能为 OpenAI 的收购策略带来变数。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，Windsurf 近期向用户发送邮件，宣布因「本周晚些时候的重大公告」而提供锁定 10 美元/月价格的机会，这一举动被外界解读为收购谈判的间接证据。然而，交易条款尚未最终敲定，谈判仍存在变数或破裂的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次收购若达成，将成为 OpenAI&amp;nbsp;最大规模的并购交易。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345019</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345019</guid>
            <pubDate>Mon, 14 Apr 2025 02:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>xAI 发布新 AI 工具 Grok Studio：可生成文档、代码和浏览器游戏</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;xAI 宣布为旗下 AI 聊天助手 Grok 增加全新功能 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgrok%2Fstatus%2F1912318583532872166&quot; target=&quot;_blank&quot;&gt;Grok Studio&lt;/a&gt;，可以用于编辑和创建文档，以及基础应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-19a1c88ab76742bcfab01237646b8b0dc40.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Grok Studio 将在一个单独的窗口中打开，支持生成文档、代码、报告和浏览器游戏。&lt;/p&gt; 
&lt;p&gt;生成代码时，Grok Studio 会在「预览」选项卡中快速向用户展示其运行效果。HTML 代码片段可以运行 Python、C++、JavaScript、Typescript 和 Bash 脚本，也可以在此预览选项卡中查看。所有新项目都会在 Grok 回复的右侧打开。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1424&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/194259_TbOH_2720166.png&quot; width=&quot;1940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;xAI 表示，免费和付费的 Grok 用户都可以在 Grok.com 上使用该功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344972/xai-grok-studio</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344972/xai-grok-studio</guid>
            <pubDate>Sun, 13 Apr 2025 11:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯「元宝」可添加为微信好友：一键解析公众号文章、甚至把它置顶</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;就在刚刚，腾讯 AI 助手「元宝」支持添加为微信好友进行聊天。 &amp;nbsp;你可以和他对话，也可以发链接、文件给他——甚至可以把它置顶 。&lt;/p&gt; 
&lt;p&gt;如下图，在微信直接搜索「元宝」，点击「聊天」进入。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/190446_4eYx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191425_HCo3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1592&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190642_X4B1_2720166.png&quot; width=&quot;806&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;978&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190707_Op4X_2720166.png&quot; width=&quot;814&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，这是腾讯元宝 APP 入驻微信的 AI 助手，搭载了混元和 DeepSeek 双模引擎，可一键解析公众号文章和任何图片和文档，短评后会发送详解文章，支持对解读内容做各种智能互动，支持陪伴互动。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191518_XlEd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1662&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/191457_Jiq2_2720166.png&quot; width=&quot;764&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344970</guid>
            <pubDate>Sun, 13 Apr 2025 11:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国团队自研 AI 图像生成大模型 HiDream-I1 正式开源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;HiDream 智象未来团队宣布正式开源图像生成大模型 HiDream-I1 与交互编辑模型 HiDream-E1。&lt;/p&gt; 
&lt;p&gt;HiDream-I1 在权威榜单 Artificial Analysis 中 24 小时内&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-ouXGp3kyyT7AfFmQ_Y5Cw&quot; target=&quot;_blank&quot;&gt;登顶&lt;/a&gt;&lt;/u&gt;，成为首个跻身全球第一梯队的中国自研生成式 AI 模型，并在图像质量、语义理解、艺术表现三大维度刷新行业纪录，实现图像的多风格生成，涵盖动漫、肖像、科幻等场景。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;984&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/183653_vhQa_2720166.png&quot; width=&quot;1462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，设计工具 Recraft 已集成 HiDream 模型，用户 3 步即可实现 「一键出图 + 智能编辑」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175700_50WE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1&amp;nbsp; 已开源三个版本的模型，分别是：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175710_8HLD_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中 HiDream-I1-Full 是由 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhidreamai.com%2Fhome&quot; target=&quot;_blank&quot;&gt;HiDream.a&lt;/a&gt;i 团队发布的开源图像生成基础模型，具备 170 亿参数，旨在实现高质量的图像生成。该模型采用 Diffusion Transformer（DiT）架构，支持多种风格的图像生成，包括写实、卡通、艺术等，适用于多种创作场景。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心特性&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;卓越的图像质量&lt;/strong&gt;：在多个基准测试中表现出色，HPS v2.1 平均得分为 33.82，优于 SDXL、DALL·E 3 等主流模型&amp;nbsp;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;强大的提示词理解能力&lt;/strong&gt;：在 GenEval 和 DPG-Bench 等评测中，HiDream-I1 的表现优于其他开源模型，展示了其在理解和执行复杂提示词方面的能力。腾讯网+1 阿里云开发者社区-云计算社区-阿里云+1&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;开源且商业友好&lt;/strong&gt;：采用 MIT 许可证，允许用户在个人、科研和商业项目中自由使用生成的内容。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;性能评估&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在多个评测中，HiDream-I1 展示了其强大的性能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DPG-Bench&lt;/strong&gt;：在整体、实体、属性等多个维度上得分领先，展示了其在图像生成质量方面的优势。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GenEval&lt;/strong&gt;：在单目标、双目标、计数、颜色等任务中表现优异，反映了其对提示词的准确理解和执行能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HPS v2.1&lt;/strong&gt;：在动画、概念艺术、绘画、照片等风格的图像生成中，HiDream-I1 的得分均高于其他主流模型，展示了其多风格生成的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175722_YQIr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175731_9IFw_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175741_2jbr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1-Full 模型整体采用 MIT 协议开源，可自由商用，但部分依赖组件（如 LLaMA3 编码器）需遵守各自协议，商用前应留意其具体限制。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344955</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344955</guid>
            <pubDate>Sun, 13 Apr 2025 09:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节 AI Lab 将全部并入 Seed</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 科技评论独家获悉，字节 AI Lab 即将全部收归 Seed 团队下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节 AI Lab 是 Seed 成立之前字节主要的 AI 研发部门，目前由李航管理，自 2024 年开始向 Seed 时任负责人朱文佳汇报。今年 2 月下旬，原 Google DeepMind 副总裁吴永辉入职字节，成为 Seed 基础研究负责人。此后李航的汇报对象变为吴永辉。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节 AI Lab 成立于 2016 年，最初由微软亚洲研究院前常务副院长马维英负责，直接向张一鸣汇报。 AI lab 目前有多个子团队，包括机器人、AI4S 等方向，几乎覆盖人工智能领域所有前沿技术研究。2018 年其团队规模达到 150 人，为字节跳动 AI 研究的核心部门。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Lab 主要研究重点是开发为字节跳动内容平台服务的创新技术，字节推荐算法、短视频特效等功能均脱胎于此。其研究成果应用于今日头条、抖音等产品，是支持抖音成长为国民级应用的基石，并奠定了当时字节在国内 AI 领域的领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;随着抖音、TikTok 占据绝对优势的市场地位，流量商业化成为字节面临的 Top 级问题，AI Lab 在字节内部重要性下降。2020 年，AI Lab 定位从集团级前瞻性项目转为技术中台，为字节商业化团队业务提供支持，马维英的汇报对象也从张一鸣变为抖音负责人张楠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2020 年年中，马维英离开字节，AI Lab 负责人一职由李航接任至今。之后团队重组，2023 年开始，AI Lab 下属负责大语言模型的 NLP 组及开发视频生成模型的 PixleDance 被先后转入 Seed 之下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时为了应对新一轮大模型竞争，字节决定回归「始终创业」的价值观，建立独立的新组织，于是加快筹建了独立于原有组织架构的 Flow 和 Seed，前者做 AI 产品，后者做大模型研发。截至 2023 年底，两者已成为与抖音、TikTok、火山引擎等字节各大业务平级的组织。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Seed 自成立就在不断吸纳来自字节内外的人才。除收拢搜索、AML、AI Lab 等内部部门中大模型方向人才外，对外也在积极争抢人才。以面向应届博士的 Top Seed 招募计划为例，字节会给优秀候选人 3-1 职级，薪资不低于百万元。截至 2024 年底，字节 AI 研究者中超 40％比例是近两年加入的新人，对人才的渴求和重视程度可见一斑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据 AI 科技评论调查，加入字节以来，吴永辉已在字节署名三篇论文，均在强化学习方向。吴永辉于上月在 Seed 内部新建虚拟小组、缩短了汇报流程，创建一个更扁平的汇报体系，此次 AI Lab 将全部并入 Seed，也是吴永辉调整内部组织架构的一个重要举措。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344946</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344946</guid>
            <pubDate>Sun, 13 Apr 2025 09:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Notion Mail 正式发布：AI 驱动邮箱新体验</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Notion 正式推出电子邮件服务 Notion Mail，首发登陆 macOS 平台，iOS 和 Android 版即将上线。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1140&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/165124_3l5R_2720166.png&quot; width=&quot;2124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 并非要取代 Gmail，而是作为重新设计的邮箱前端，提供独特的邮件管理体验。其核心为高度模块化系统，用户可自定义收件箱配置，并整合了丰富的 AI 功能，如智能文件夹、自动分类、快速回复、写作改进及智能会议安排等。产品与 Notion Calendar 无缝衔接，核心 AI 功能提供免费使用限额，无限制需订阅付费。目前仅支持英文，未来将扩展至 13 种语言。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/165012_T6gr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail&lt;/a&gt;&lt;br&gt; 下载地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail%2Fdownload&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail/download&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344936/notion-mail</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344936/notion-mail</guid>
            <pubDate>Sun, 13 Apr 2025 08:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>从理论到落地：MCP 实战解锁 AI 应用架构新范式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：计缘&lt;/p&gt; 
&lt;p&gt;编者按：应用越智能，背后的设计会越复杂。软件的本质是解决复杂性问题，MCP 虽打开了智能的创意上限，但也给后端的设计带来了无限的复杂度。本文旨在从 MCP 的技术原理、降低 MCP Server 构建复杂度、提升 Server 运行稳定性等方面出发，分享我们的一些实践心得。文章内容较长，以下是导读大纲。（点击阅读原文，获取 78 页完整版 PPT）&lt;/p&gt; 
&lt;p&gt;1、介绍 MCP 的概念及其运作机制。&lt;/p&gt; 
&lt;p&gt;2、解释 MCP 和 Function Calling 之间的区别。&lt;/p&gt; 
&lt;p&gt;3、讲述 MCP 的本质和挑战，包括描述 MCP 信息的系统提示词的挑战，MCP Client 与 MCP Server 之间协同关系的挑战，快速构建 MCP Server，自建 Dify 的痛点等。&lt;/p&gt; 
&lt;p&gt;4、分析如何解决 MCP 的各个挑战，包括 MCP Register、MCP Server 和 Promt 的统一管理、MCP 效果验证体系和安全性保障、MCP 网关、MCP Server 的动态服务发现、Streamable HTTP、弹性效率、可观测等。&lt;/p&gt; 
&lt;p&gt;5、最后探讨 MCP 对 AI 应用架构新范式的影响，并介绍 MCP Server First 的理念。&lt;/p&gt; 
&lt;h2&gt;AI Agent 现状及架构&lt;/h2&gt; 
&lt;p&gt;人工智能（AI）在商业领域的应用正日益成为推动创新和效率提升的核心力量。其核心在于多个 AI Agent 的协作，这些 AI Agent 通过分工与合作，共同承载 AI 应用所支持的业务需求。这种协作模式不仅优化了企业运营，还展现了 AI 在解决高影响力挑战中的潜力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-76b1a0b5eb99a3069f519e05de7f8273c8f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当前的 AI Agent，无论是和各种 Tools（各类业务服务接口）交互，还是和各类 Memory（各类存储服务接口）交互，亦或是和各类 LLMs（各类大语言模型）交互，都是通过 HTTP 协议的，除了 LLM 因为基本都遵循 OpenAI 范式以外，和其他的 Tools 和 Memory 交互都需要逐一了解它们的返回格式进行解析和适配。当一个 AI 应用包含多个 AI Agent 时，或者一个 AI 应用需要和多个业务服务接口和存储服务接口交互时，整体的开发工作量是很大的，主要体现在 3 个方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;找适合该 AI 应用的业务接口和存储服务接口：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;找三方服务接口。&lt;/li&gt; 
   &lt;li&gt;在公司内部找合适的服务的接口。&lt;/li&gt; 
   &lt;li&gt;找不到就自己先开发接口。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;解析接口的返回格式：无论是三方服务接口还是公司内部的服务接口，返回格式可能都千奇百怪，需要逐一进行了解和解析。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;编排多个 AI Agent：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;有 Dify 这类流程可视化的工具辅助编排，减轻了很多编排工作，但复杂度依然不低，且运行效率和性能方面还是有瓶颈的。&lt;/li&gt; 
   &lt;li&gt;通过编码方式做编排（比如使用 Spring AI Alibaba 或 LangChain 等），虽然性能上更优，但是复杂度更高，编排效率和灵活性都有不足。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以目前很多 AI 应用就只有少数几个 AI Agent，甚至很多 AI 应用背后就只有一个 AI Agent。这也是目前 AI 应用背后的 AI Agent 依然还处在第一个阶段（Siloed, Single-Purpose Agents）的原因。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e25347863ed2a9c56ba0532f785a792e3ed.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了能使 AI Agent 进入到第二阶段（Platform-Level Agents），我们使用云原生 API 网关做了统一的接入层，通过一个网关三种不同角色的方式，解决了一部分复杂度：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;作为南北向流量网关，统一管理 AI Agent 的入口流量，核心做转发、负载、鉴权认证、安全、流控等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;作为 AI 网关，代理各类 LLMs，向 AI Agent 屏蔽了繁杂的接入，并且解决了很多生产级的问题，比如多模型切换、模型 Fallback、多 API Key 管理、安全、联网搜索等。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;AI 网关代理 LLMs 的详细文章参见：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247573215%26idx%3D1%26sn%3Df77c5dd8423a9480afb6a03fce0d997c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247573215%26idx%3D1%26sn%3Df77c5dd8423a9480afb6a03fce0d997c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/tZ0wsTlZK67r9IxNZ57TDQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;作为东西向网关，统一管理来自不同源（ACK、ECS、函数计算 FC、SAE、三方服务）的各类服务，供 AI Agent 使用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;但如我所说，这只解决了一部分复杂度问题，更核心的&lt;strong&gt;找接口&lt;/strong&gt; 和&lt;strong&gt;解析接口&lt;/strong&gt;这两个问题依然没有解决。直到 MCP（Model Context Protocol）的出现，让我们看到了真正通往第二阶段（Platform-Level Agents）的路，甚至可以尝试触摸第三阶段（Universal Agents, Multi-Agents）。&lt;/p&gt; 
&lt;h2&gt;MCP 是什么&lt;/h2&gt; 
&lt;p&gt;MCP 是模型上下文协议（Model Context Protocol）的简称，是一个开源协议，由 Anthropic（Claude 开发公司）开发，旨在让大型语言模型（LLM）能够以标准化的方式连接到外部数据源和工具。它就像 AI 应用的通用接口，帮助开发者构建更灵活、更具上下文感知能力的 AI 应用，而无需为每个 AI 模型和外部系统组合进行定制集成。MCP 被设计为一个通用接口，类似于 USB-C 端口，允许 LLM 应用以一致的方式连接到各种数据源和工具，如文件、数据库、API 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-46b7eef569ef0b1f4357d3f79f965843530.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP 目前一共有 3 个核心概念：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MCP Server：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;基于各语言的 MCP SDK 开发的程序或服务。&lt;/li&gt; 
   &lt;li&gt;基于某种&lt;strong&gt;神秘的机制&lt;/strong&gt;将现存的程序或服务进行了转换，使其成为了 MCP Server。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP Tool：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MCP Tool 所属于 MCP Server，一个 MCP Server 可以有多个 MCP Tool。可以理解为一个类里有多个方法，或者类似一个服务里有多个接口。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP Client：当一段代码，一个 Agent，一个客户端，基于 MCP 的规范去使用、去调用 MCP Server 里的 MCP Tool 时，它就是 MCP Client。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MCP 的运作机制&lt;/h3&gt; 
&lt;p&gt;要真正理解 MCP 是什么，我们需要了解它的运作机制，然后你就能知道 MCP 的调用方式和传统的 HTTP 调用方式有什么不同，可能也能隐约体会到为什么我说 MCP 可以让 AI Agent 进入第二阶段。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3316ba085c95379e9635dfbbefb726a0388.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，一次基于 MCP 的调用，一共有 6 个核心的步骤。我们先拟定一个前提：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我要开发一个获取时间的 AI Agent，用户在使用这个 AI Agent 时，只需要问类似&quot;现在几点了？&quot;这种问题即可。&lt;/li&gt; 
 &lt;li&gt;我已经有了一个关于处理时间的 MCP Server，这个 MCP Server 里有 2 个 MCP Tool，一个负责获取当前时区，一个负责获取当前时间。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;调用步骤解析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;第一步：用户向 AI Agent 问&quot;现在几点了？&quot;，此时 AI Agent 就是 MCP Client，它会把用户的问题和处理时间的 MCP Server 以及 MCP Tool 的信息一起发送给 LLM。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第二步：LLM 拿到信息后开始推理，基于用户的问题和 MCP Server 的信息，选出解决用户问题最合适的那个 MCP Server 和 MCP Tool，然后返回给 AI Agent（MCP Client）。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;这里 LLM 返回给 AI Agent 的信息是：&quot;你用 time 这个 MCP Server 里的 get_current_time 这个 MCP Tool 吧，它可以解决用户的问题&quot;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第三步：AI Agent（MCP Client）现在知道该使用哪个 MCP Server 里的哪个 MCP Tool 了，直接调用那个 MCP Tool，获取结果。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;调用 time 这个 MCP Server 里的 get_current_time 这个 MCP Tool。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第四步：Time MCP Server 返回结果（当前的时间）给 AI Agent（MCP Client）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第五步：AI Agent（MCP Client）也很懒啊，把用户的问题和从 Time MCP Server 处拿到的结果再一次给了 LLM，目的是让 LLM 结合问题和答案再规整一下内容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第六步：LLM 把规规整整的内容返回给 AI Agent（MCP Client），最后 AI Agent（MCP Client）再原封不动的返回给了用户。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MCP 的整个调用过程中有一个非常核心的点就是 MCP Server 以及 MCP Tool 的信息。从第一步，第二步可以看出，这个信息非常关键，是它让 LLM 知道了该如何解决用户的问题，这个信息就是 MCP 中最重要的 System Prompt，本质上就是 PE 工程。&lt;/p&gt; 
&lt;h3&gt;MCP System Prompt&lt;/h3&gt; 
&lt;p&gt;MCP 不像传统的协议定义，它没有一个确定的数据结构。它的核心是通过自然语言描述清楚有哪些 MCP Server，承担什么作用，有哪些 MCP Tool，承担什么作用，然后让大语言模型通过推理去选择最合适的 MCP Server 以及 MCP Tool。所以它的核心本质上还是提示词工程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-120aa561c4f9d67cebd623ba4cb5ceab2eb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-86391324e806a590732d3b9ffd5e4358359.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上面两张图是 Cline（一个 MCP Client）中的 System Prompt，可以清晰的看到它对 MCP Server 和 MCP Tool 都有明确的描述。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8c589278bba00c8154935bf90b5922f5e85.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上图是流程中的第一步，将用户的问题和 System Prompt 一起发送给 LLM 的内容。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7f1b4a7b3fc2d4626d822b43aee01b16cef.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上图是流程中的第二步，LLM 返回了解决用户问题明确的 MCP Server 和 MCP Tool 信息。&lt;/p&gt; 
&lt;h3&gt;MCP 和 Function Calling 之间的区别&lt;/h3&gt; 
&lt;p&gt;看到这，我想大家应该对 MCP 是什么有一定感觉了。MCP 是不是解决了&lt;strong&gt;找接口&lt;/strong&gt; 和&lt;strong&gt;解析接口&lt;/strong&gt;的问题？因为这两个工作都交给了 LLM。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM 负责帮 AI Agent 找到最合适的接口。&lt;/li&gt; 
 &lt;li&gt;AI Agent 调用接口，压根不用做返回结果的解析，原封不动再交给 LLM。&lt;/li&gt; 
 &lt;li&gt;LLM 结合用户问题和接口返回的结果，做内容规整处理。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;那么可能有小伙伴会问，MCP 和 LLM 的 Function Calling 又有什么区别呢？核心区别是是否绑定模型或模型厂商：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP 是通用协议层的标准，类似于&quot;AI 领域的 USB-C 接口&quot;，定义了 LLM 与外部工具 / 数据源的通信格式，但&lt;strong&gt;不绑定任何特定模型或厂商&lt;/strong&gt;，将复杂的函数调用抽象为客户端-服务器架构。&lt;/li&gt; 
 &lt;li&gt;Function Calling &lt;strong&gt;是大模型厂商提供的专有能力&lt;/strong&gt;，由大模型厂商定义，不同大模型厂商之间在接口定义和开发文档上存在差异；允许模型直接生成调用函数，触发外部 API，依赖模型自身的上下文理解和结构化输出能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b8eff8e848cb828269fb1e47357cb5a7ddb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，LLM Function Calling 需要 LLM 为每个外部函数编写一个 JSON Schema 格式的功能说明，精心设计一个提示词模版，才能提高 Function Calling 响应的准确率，如果一个需求涉及到几十个外部系统，那设计成本是巨大，产品化成本极高。而 MCP 统一了客户端和服务器的运行规范，并且要求 MCP 客户端和服务器之间，也统一按照某个既定的提示词模板进行通信，这样就能通过 MCP 加强全球开发者的协作，复用全球的开发成果。&lt;/p&gt; 
&lt;h3&gt;MCP 的本质和挑战&lt;/h3&gt; 
&lt;p&gt;根据上文的一系列解释，我们可以总结一下 MCP 的本质：&lt;strong&gt;模型上下文协议（Model Context Protocol）并不是一个确定的数据格式或数据结构，它是&lt;/strong&gt; 描述 MCP Server/MCP Tool 信息的系统提示词&lt;strong&gt;和&lt;/strong&gt; MCP Server 与 LLM 之间的协同关系&lt;strong&gt;的结合&lt;/strong&gt; &lt;strong&gt;，&lt;/strong&gt; &lt;strong&gt;解决的是&lt;/strong&gt; 找接口&lt;strong&gt;和&lt;/strong&gt; 解析接口&lt;strong&gt;的问题&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-dd0578fcdb7e680a0c9312663e7727d8586.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;明确了 MCP 本质之后，将其带入到企业级生产应用中，你就会发现，这两个核心点上会有很多挑战，或者说不足。&lt;/p&gt; 
&lt;h4&gt;描述 MCP 信息的系统提示词的挑战&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;系统提示词的安全性如何保证？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;这个最核心的系统提示词如果被污染了，LLM 就不能准确知道你有哪些 MCP Server，有哪些 MCP Tool，甚至可能告诉 LLM 错误的，有安全漏洞的 MCP Server 和 MCP Tool，那么对你的 AI 应用来说将是巨大的风险，会导致整个 MCP 流程的瘫痪。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;系统提示词如何管理？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MCP Server 或者 MCP Tool 有了新版本，系统提示词应该也许要有对应的版本管理策略。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;系统提示词写的不好，如何方便的快速调试？能不能实时生效？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系统提示词是没有标准定义的，理论上每个企业可以定义自己的系统提示词模板，类似 PE 工程。提示词不可能一次性就能写好，需要反复调试，需要有机制做快速的调整，并且可以做到使其实时生效。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 MCP Server 很多，那么系统提示词会非常长，岂不是很消耗 Token？如何缩小或精确 MCP Server 和 MCP Tool 的范围？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;如果你有几十个或更多 MCP Server，那么就有可能有上百个或更多 MCP Tool，所有的信息描述下来放在系统提示词后，这个提示词模板会非常大，显而易见的对 Token 消耗非常大，变相的就是成本高。应该需要一套机制，基于用户的问题，预圈选 MCP Server 和 MCP Tool 的范围，减少 Token，提高效率，很类似联网搜索里的意图识别。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;MCP Client 与 MCP Server 之间协同关系的挑战&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;负责做协同的是 MCP Client，但目前 MCP Client 很少，比如 Cline， Claude，Cursor 等，而且都是 C/S 工具，支持的都是 SSE 协议，企业级的 AI 应用该如何结合？能不能结合？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;基本上目前市面中的 MCP Client 都无法和企业级的 AI 应用做结合，SSE 这种有状态的协议有很多弊端，比如不支持可恢复性，服务器需要维持长期连接，仅支持服务器 → 客户端消息，无法灵活进行双向通信等。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;现存的传统业务能快速转成 MCP Server 吗？能 0 代码改动的转换吗？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;开发一个 MCP Server 是强依赖各语言的 MCP SDK 的，目前只支持 Python、Java、TS、Kotlin、C#。那如果是 Go 或者 PHP 技术栈的企业怎么办？并且那么多现存的业务全部用 MCP SDK 重构一遍，工作量巨大，也很不现实。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP Server 会很多，如何统一管理？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;有自己开发的 MCP Server，有三方的 MCP Server，还有大量通过某种神秘机制将传统业务转换而来的 MCP Server。这些都应该有一个类似 MCP Hub 或 MCP 市场的东西统一管理起来，方便 MCP Client 去使用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企业级 AI 应用中，身份认证、数据权限、安全这些如何做？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在企业级的应用中，无论哪种协议，哪种架构，哪种业务。身份认证、数据权限、安全防护这些问题都是永远绕不开的。那么在 MCP 这种协同方式下如何实现。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;AI 应用架构新范式&lt;/h2&gt; 
&lt;p&gt;我们结合 MCP 范式，以解决上述挑战点为目的，将 AI Agent 的架构进行了重构。在云原生 API 网关 &lt;strong&gt;，&lt;/strong&gt; 微服务引擎 Nacos &lt;strong&gt;两个产品中做了 MCP 增强能力，解决了上述大部分的挑战点。在&lt;/strong&gt; 函数计算 FC &lt;strong&gt;，&lt;/strong&gt; Serverless 应用引擎 SAE &lt;strong&gt;两个产品中做了 MCP 增强能力，前者解决快速开发 MCP Server 的问题，后者解决开源 Dify 性能的问题。共同构建了基于 MCP 的&lt;/strong&gt; AI 应用开发新范式。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-03e42880c942d913877ccf06ee2afa243e7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;AI 应用架构新范式剖析&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ff32b45cf513d2b21df5bf3986ed678137a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;首先我对图中的 8 步核心调用链路做以解析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步：用户向 AI 应用发起请求，请求流量进入流量网关（云原生 API 网关）。&lt;/li&gt; 
 &lt;li&gt;第二步：云原生 API 网关侧维护管理了不同类型的 AI Agent 的 API 或路由规则，将用户请求转发至对应的 AI Agent。&lt;/li&gt; 
 &lt;li&gt;第三步：AI Agent 无论以哪种方式实现，只要其中的节点需要获取数据，便向 MCP 网关（云原生 API 网关）请求获取可用的 MCP Server 及 MCP Tool 的信息。&lt;/li&gt; 
 &lt;li&gt;第四步：因为 MCP 网关处可能维护了很多 MCP 信息，可以借助 LLM 缩小 MCP 范围，减少 Token 消耗，所以向 AI 网关（云原生 API 网关）发请求和 LLM 交互。（这一步可选）&lt;/li&gt; 
 &lt;li&gt;第五步：MCP 网关将确定好范围的 MCP Server 及 MCP Tool 的信息 List 返回给 AI Agent。&lt;/li&gt; 
 &lt;li&gt;第六步：AI Agent 将用户的请求信息及从 MCP 网关拿到的所有 MCP 信息通过 AI 网关发送给 LLM。&lt;/li&gt; 
 &lt;li&gt;第七步：经过 LLM 推理后，返回解决问题的一个或多个 MCP Server 和 MCP Tool 信息。&lt;/li&gt; 
 &lt;li&gt;第八步：AI Agent 拿到确定的 MCP Server 和 MCP Tool 信息后通过 MCP 网关对该 MCP Tool 做请求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实际生产中 ③ - ⑧ 步会多次循环交互。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-10882473c8c301e063c2f4542b92db86114.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们依然基于 MCP 的两个本质来刨析这个新的架构。&lt;/p&gt; 
&lt;h4&gt;如何解决 MCP 提示词的各个挑战&lt;/h4&gt; 
&lt;p&gt;我们团队是中间件开源最多的团队，比如 Nacos，Higress，Sentinel，RocketMQ，Seata 等，并且还维护着 Spring Cloud Alibaba，Spring AI Alibaba，Dubbo 这些开源开发框架，在微服务架构领域有着丰富的经验。所以在 MCP Server 和 MCP 提示词统一管理这个点上，天然的就想到了微服务领域里基于 Nacos 做服务注册发现和配置统一管理的模式，我们将其转嫁到了 MCP 范式，大家可以想一下以下这些对应关系：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SpringCloud 服务/Dubbo 服务/Go 服务 -&amp;gt; 各类 MCP Server&lt;/li&gt; 
 &lt;li&gt;SpringCloud 服务/Dubbo 服务/Go 服务暴露的接口 -&amp;gt; 各类 MCP Server 提供的 MCP Tool&lt;/li&gt; 
 &lt;li&gt;SpringCloud 服务/Dubbo 服务/Go 服务暴露的接口描述 -&amp;gt; 各类 MCP Server 提供的 MCP Tool 的描述&lt;/li&gt; 
 &lt;li&gt;SpringCloud 服务/Dubbo 服务/Go 服务的配置文件 -&amp;gt; 各类 MCP Server 的系统提示词&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6116237b6f29c9c47ddc3920068838f27b1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所以在 MSE Nacos 这个产品中，我们做了一系列增强 MCP 的能力，使 MSE Nacos 成为统一管理 MCP Server 的 MCP Register（MCP Server 注册/配置中心）。是 AI 应用开发新范式的核心组件。&lt;/p&gt; 
&lt;p&gt;另外，MCP 官方的 Roadmap 中，也在规划 MCP Register 的能力，我们会基于 Nacos 作为 MCP Register 的方案和 MCP 在开源侧进行共建。&lt;/p&gt; 
&lt;h5&gt;MCP Register（MCP Server 注册/配置中心）&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c723b1909c83c053b67c2e0435ec0551977.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP Server 统一管理&lt;/h5&gt; 
&lt;p&gt;MCP Server 注册到 MSE Nacos 有两种方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 MSE Nacos 控制枱手动创建。也就是将 MCP Server 的 Endpoint 配置到 MSE Nacos 中。&lt;/li&gt; 
 &lt;li&gt;通过 Nacos SDK，自动将 MCP Server 注册进 Nacos。和当前 Java SpringCloud，Java Dubbo 服务逻辑一样。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MSE Nacos 中对 MCP Server 进行统一管理，可以实现对 &lt;strong&gt;MCP Server 的健康检查，负载均衡，描述信息 Json 向 XML 转换，MCP Server 上下线管控等功能&lt;/strong&gt;。&lt;/p&gt; 
&lt;h5&gt;MCP Prompt 统一管理&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-693257655e2f075fee6fe4cf19c69710116.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 MSE Nacos 中维护 MCP Server 的 Prompt 有两种方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;手动创建 MCP Server 的配置信息，配置文件的 Data ID 的命名格式为&lt;code&gt;[MCP Server name]-mcp-tools.json&lt;/code&gt;。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在配置文件中管理 MCP Tool 的提示词信息，比如整体作用描述，入参描述等。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结合 MSE 治理的能力，如果是 Java 或者 Go，可以自动感知服务的 Schema，自动生成 MCP Server 和 MCP Tool 的提示词信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MSE Nacos 中对 MCP Server 提示词进行统一管理，可以实现 &lt;strong&gt;MCP 提示词版本管理（回滚），MCP 提示词灰度管理，MCP 提示词安全管理，MCP 提示词动态调优实时生效等功能&lt;/strong&gt;。&lt;/p&gt; 
&lt;h5&gt;MCP 效果验证体系（进行中）&lt;/h5&gt; 
&lt;p&gt;上文中提到当 MCP Server 很多时，MCP Server 的各描述信息会很多，也就是 Prompt 会很长，Token 消耗很大，所以需要有机制基于用户的输入缩小 MCP Server 范围，减少 Token 消耗，增加 LLM 推理效率。除此以外，大家知道，只要是和 LLM 交互的场景，提示词的好坏是需要多次调试的，MCP 的整个流程强依赖提示词工程，如果提示词调整不好，LLM 无法返回准确的 MCP Server 和 MCP Tool，那么整个流程就是不可用的状态了。所以在 Nacos 中我们正在做一个 MCP 效果验证的体系。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-168928facd996f1d8f0df17cc8fedd1005e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;核心的原理是我们会提供一个基于 Spring AI Alibaba 开发的 AI Agent，通过用户配置的业务输入、LLM、圈定的 MCP Server 和 MCP Tool 的集合不断的做验证，将结果以视图的方式展现出来（比如成功率等）。用户可以在 Nacos 中动态的对成功率低的 MCP Server 的提示词做调整优化。&lt;/p&gt; 
&lt;h5&gt;MCP 安全性保障（持续完善中）&lt;/h5&gt; 
&lt;p&gt;无论哪种架构，哪种模式，安全性在企业生产中必然都是第一位的，MCP 领域也不例外，并且需要考虑的环节更多。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-2fa44d5a0dbc05da8d02a3a41e69d32e0ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP Server 敏感信息安全管理：注册进 MSE Nacos 的各类 MCP Server 都会有类似 API Key、AK/SK、密钥、登录密码等敏感信息。MSE Nacos 和阿里云 KMS 深度集成，可以对这些敏感信息做加密处理。&lt;/li&gt; 
 &lt;li&gt;MCP Prompt 安全管理：同样依托于 MSE Nacos 和 KMS 的深度集成，可以将 MCP Server，MCP Tool 完整的 Prompt（描述信息）做加密处理，避免 Prompt 污染。&lt;/li&gt; 
 &lt;li&gt;MCP Prompt 安全校验：结合上述的验证体系以及与内容安全做集成，实现 MSE Nacos 对 MCP Server 的 Prompt 的合法性校验。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;如何解决 MCP Client 与 MCP Server 之间协同关系的挑战&lt;/h4&gt; 
&lt;p&gt;在 MCP 范式中，其实是三个角色在互相协同：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP Client -&amp;gt; LLM&lt;/li&gt; 
 &lt;li&gt;MCP Client -&amp;gt; MCP Server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这两类协同关系本质上还是服务提供方和服务消费方之间的关系，涉及到&lt;strong&gt;代理协作&lt;/strong&gt; 和&lt;strong&gt;流量管控&lt;/strong&gt;两个核心点。在传统开发范式下，通常是由网关来负责的。所以我们在云原生 API 网关中增强了 LLM 代理和 MCP Server 代理的能力，使其同时具备流量网关，AI 网关（LLM 代理）和 MCP 网关的能力。是 AI 应用开发新范式的核心组件。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-be80748631259c1b0803fc6e483b5a0c941.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所以在企业的整体系统架构中，只需要一个云原生 API 网关，即可作为流量网关、API 网关、微服务网关、AI 网关、MCP 网关，在代理和流量管控层面实现传统业务和 AI 业务的大统一，并且再结合 AI 应用开发的新范式，平滑的将 AI 业务和传统业务相结合。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8619b9be1118c77b682923cbfbec24b5780.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;云原生 API 网关 Dog Food&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b0b6f6f53c814320166453d81b7f32b99bf.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;秉承着自己吃自己狗粮的原则，云原生 API 网关在阿里集团内部已经有很多业务在深度使用，在企业级产品能力，稳定性，性能方面已经有多个大体量业务的背书。&lt;/p&gt; 
&lt;h5&gt;AI 网关&lt;/h5&gt; 
&lt;p&gt;MCP Client 与 LLM 之间的交互和传统业务与 LLM 之间的交互本质是一样的，只要应用上生产，都会有一系列的问题需要去解决：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;成本平衡问题：比如部署 DeepSeek R1 671B 满血版模型，至少需要 2 台 8 卡 H20 机器，列表价年度超过 100W，但 2 台的 TPS 有限，无法满足生产部署中多个用户的并发请求。即使 Meta 新发布的 Llama4，也至少需要一张 H100 去运行。所以需要有方案找到 TPS 和成本之间的平衡点。&lt;/li&gt; 
 &lt;li&gt;模型幻觉问题：即使是 DeepSeek R1 671B 满血版模型，如果没有联网搜索，依然有很严重的幻觉问题。&lt;/li&gt; 
 &lt;li&gt;多模型切换问题：单一模型服务有较大的风险和局限性，比如稳定性风险，比如无法根据业务（消费者）选择最优模型。目前也没有开源组件和框架解决这类问题。&lt;/li&gt; 
 &lt;li&gt;安全合规问题：企业客户需要对问答过程做审计，确保合规，减少使用风险。&lt;/li&gt; 
 &lt;li&gt;模型服务高可用问题：自建平台性能达到瓶颈时需要有一个大模型兜底方案，提升客户大模型使用体验。&lt;/li&gt; 
 &lt;li&gt;闭源模型 QPS/Token 限制问题：商业大模型都有基于 API Key 维度的 QPS/Token 配额限制，需要一个好的方式能够做到快速扩展配额限制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以上问题都是实实在在的客户在使用过程中遇到的问题，有些是模型自身问题，有些是部署架构问题，如果要客户一个一个去解决，复杂度和时间成本都是比较高的。所以就需要 AI 网关的介入来快速的，统一的收敛掉这些核心问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-979c884967f9dd509ee14425480408fa609.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;云原生 API 网关的 AI 网关增强能力主要有四部分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多模型适配：可以代理市面上所有主流的模型托管服务，以及兼容 OpenAI 协议的 AI 服务。在这个模块中包括协议转换、多 API Key 管理、Fallback、多模型切换等多个核心功能。&lt;/li&gt; 
 &lt;li&gt;AI 安全防护：安全防护分为三个层面，一个是输入输出的内容安全防护，另一个是保护下游 LLM 服务的稳定，以及管控 AI 接口消费者。在这个模块中包括内容审核、基于 Token 的限流降级、消费者认证等多个核心功能。&lt;/li&gt; 
 &lt;li&gt;AI 插件：AI 网关的灵活扩展机制我们使用插件的形式来实现，目前有很多预置的插件，用户也可以开发自定义插件来丰富 AI 场景流量的管控。比如基于 AI 插件机制我们实现了结果缓存、提示词装饰器、向量检索等能力。&lt;/li&gt; 
 &lt;li&gt;AI 可观测：AI 场景的可观测和传统场景的可观测是有很大区别的，监控和关注的指标都是不同的，云原生 AI 网关结合阿里云日志服务和可观测产品实现了贴合 AI 应用业务语义的可观测模块和 AI 观测大盘，支持比如 Tokens 消费观测，流式/非流式的 RT，首包 RT，缓存命中等可观指标。同时所有的输入输出 Tokens 也都记录在日志服务 SLS 中，可供用户做更详细的分析。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 网关代理 LLM 更详细的方案可以参见我之前的文章： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtZ0wsTlZK67r9IxNZ57TDQ&quot; target=&quot;_blank&quot;&gt;AI 网关代理 LLMs 最佳实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ad17af83a1e5f0e85f744f7f6c2467e9eb5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP 网关&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1b333f6b4365a768b67f0134cb276dfa56f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP Client 和 MCP Server 之间的交互和传统的服务提供者和服务消费者之间的交互就有所区别了，所以我们在云原生 API 网关中增加了 MCP 相关的能力，但从产品版本划分层面，MCP 相关的能力依然包含在 AI 网关的能力范畴内。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3bd22ce32b62b13d4980394307caec2bb17.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP Server 动态发现&lt;/h5&gt; 
&lt;p&gt;上文中介绍了 MSE Nacos 作为 MCP Server 注册/配置中心，那么 MCP Client 如何来发现呢？如果是 MCP Client 直接和 MSE Nacos 交互，那么又会在 MCP Client 中引入 Nacos SDK，增加了编码的复杂度。&lt;/p&gt; 
&lt;p&gt;鉴于云原生 API 网关和 MSE Nacos 在传统服务领域早已做了深度集成，打通了云原生 API 网关自动发现注册在 MSE Nacos 中的服务，所以在 MCP 范式下，我们同样实现了云原生 API 网关自动发现注册在 MSE Nacos 中的 MCP Server 的能力。&lt;/p&gt; 
&lt;p&gt;通过这种方式，MCP Client 只需要使用云原生 API 网关的接入点，即可自动的、动态的获取到所有注册在 MSE Nacos 中的 MCP Server。云原生 API 网关（MCP 网关）就变成了一个 MCP Hub，无论如何更新、变更 MCP Server，都只需要在 MSE Nacos 操作即可，MCP Client 无需做任何修改。&lt;/p&gt; 
&lt;h5&gt;将传统服务 0 代码改造转换为 MCP Server&lt;/h5&gt; 
&lt;p&gt;在 AI 的时代下，我认为最有价值的是使用 AI 增强、提升客户的现存业务，使其变成一个 AI 应用或 AI 加持的业务，而不是完全新开发一套 AI 应用。&lt;/p&gt; 
&lt;p&gt;所以开发一个 AI 应用或者做现存业务的 AI 增强，AI Agent 是需要和大量现存业务做交互的，MCP 虽然统一的协议，但将现存业务重构为 MCP Server 的成本是非常高的，并且目前支持的开发语言有限，像 Go，PHP 都没有对应的 MCP SDK，所以会让很多企业想拥抱 MCP，但又无从下手。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bc61c6005adb6f765e14b59cdbeea0fe3d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;网关最擅长做的事情就是协议转换，Nacos 在传统微服务场景下已经注册了很多现存的传统服务，那么两者一拍即合，通过网关将注册在 Nacos 中的传统服务 0 代码改造的转换为 MCP Server。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;注册在 MSE Nacos 中的现存业务服务（SpringCloud 服务、Dubbo 服务、Go 服务）不需要做任何改变。&lt;/li&gt; 
 &lt;li&gt;在 MSE Nacos 中新增&lt;code&gt;[Server Name]-mcp-tools.json &lt;/code&gt;命名规范的配置文件，在配置文件中使用 MCP 规范对现存业务的接口进行描述。&lt;/li&gt; 
 &lt;li&gt;通过云原生 API 网关（MCP 网关），MCP Client 侧自动发现由传统服务转换来的 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;将 SSE 转换为 Streamable HTTP&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6c6e2f8f134ba0aca592c05df3946d05fc9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP 范式默认的传输协议是 SSE（Server Sent Event），本质上是一种长连接，有状态的传输协议。这种协议在企业级应用中有很多弊端：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;不支持可恢复性（Resumability）：连接断开后，客户端必须重新开始整个会话。&lt;/li&gt; 
 &lt;li&gt;服务器需要维持长期连接（High Availability Requirement）：服务器必须保持高可用性，以支持持续的 SSE 连接。&lt;/li&gt; 
 &lt;li&gt;SSE 仅支持服务器 → 客户端消息，无法灵活进行双向通信。&lt;/li&gt; 
 &lt;li&gt;目前只有少数几个 C/S 架构的客户端和 MCP 提供的用于测试验证的 Web 客户端支持 MCP 范式和 SSE 协议。无法用在企业级的生产应用中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;好在 MCP 官方也意识到了该问题，所以在 3 月下旬，发布了新的 Streamable HTTP 协议。Streamable HTTP 改变了 MCP 的数据传输方式，让协议变得更灵活、更易用、更兼容：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;更灵活：支持流式传输，但不强制。&lt;/li&gt; 
 &lt;li&gt;更易用：支持无状态服务器。&lt;/li&gt; 
 &lt;li&gt;更兼容：适用于标准 HTTP 基础设施。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;简单来说，原来的 MCP 传输方式就像是你和客服通话时必须一直保持在线（SSE 需要长连接），而新的方式更像是你随时可以发消息，然后等回复（普通 HTTP 请求，但可以流式传输）。&lt;/p&gt; 
&lt;p&gt;这里大家可以思考一下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 打破了目前几个 C 端 MCP Client 的壁垒。也就意味着任何请求方（甚至就是一段简单的 HTTP Request 代码），都可以像请求标准 HTTP API 的方式一样和 MCP Server 交互。&lt;/li&gt; 
 &lt;li&gt;换句话说，当可以使用标准 HTTP API 的方式和 MCP Server 交互后，是不是就不存在所谓的 MCP Client 了？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;虽然 Streamable HTTP 还在草案阶段，但云原生 API 网关作为 MCP 网关已经支持了将 SSE 传输协议自动转换为 Streamable HTTP 传输协议。或者说，通过云原生 API 网关（MCP 网关）代理的 MCP Server 同时支持 SSE 和 Streamable HTTP 两种传输协议供 Client 使用。&lt;/p&gt; 
&lt;h5&gt;MCP 模式下的身份认证和权限管控&lt;/h5&gt; 
&lt;p&gt;身份认证和权限管控在任何架构，任何业务场景下都是刚需，在 MCP 范式下也不例外，这里有两个层面的权限管控：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Client 有权使用哪些 MCP Server。有权使用某 MCP Server 里的哪些 MCP Tool。&lt;/li&gt; 
 &lt;li&gt;Client 通过 MCP Tool 有权获取到哪些数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6d6595b637a2f9c12b007739e38fb843885.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP Server 和 MCP Tool 的使用权限&lt;/h5&gt; 
&lt;p&gt;大家设想一下，当传统业务可以 0 代码转换为 MCP Server 后，注册在 Nacos 中的 MCP Server 和 MCP Tool 肯定会有很多，从业务领域来说，可能有和财务相关的 MCP Server，有和销售相关的 MCP Server，有和售后服务相关的 MCP Server。在返回 MCP Server 和 MCP Tool 信息时不可能将所有信息都返回，肯定只能返回 Client 身份有权使用的 MCP Server 信息。&lt;/p&gt; 
&lt;p&gt;云原生 API 网关作为 MCP 网关，通过成熟的插件机制提供了 HTTP Basic Auth，OAuth2.0，JWT，API Key，外部认证等多种认证方式，以及基于消费者认证功能，可以让用户灵活的管理和控制 Client 的身份认证和 MCP Server/MCP Tool 使用权限。&lt;/p&gt; 
&lt;h5&gt;MCP Server 和 MCP Tool 的数据权限&lt;/h5&gt; 
&lt;p&gt;当 MCP Server 是数据类服务时会比较常见，比如 Mysql MCP Server，Redis MCP Server 等。权限会下探到库级别，表级别。在这种场景下，云原生 API 网关作为 MCP 网关，可以通过插件机制，改写或增加 Request Header 的值，结合 MSE 治理将 Header 的值透传下去，然后在服务内部进一步做数据权限管控。&lt;/p&gt; 
&lt;p&gt;我举例一个通过这种方式实现的数据库读写分离的场景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-141201d3bda7f80ef0e2186996e5f78e5fa.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;如何快速构建 MCP Server&lt;/h4&gt; 
&lt;p&gt;众所周知，AI 应用里涉及到 LLM 推理的场景，大都用在调用相对稀疏的场景，MCP 范式强依赖 LLM 推理，所以无论是基于 HTTP API 模式的 AI 应用开发架构还是基于 MCP 的 AI 应用开发架构，目前也都是应用在相对稀疏调用的场景。所以这里可以延伸出两个问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在稀疏调用的场景下，运行 MCP Server 的计算资源如何优化资源利用率，说的再直白一些就是如何能做到成本最优。&lt;/li&gt; 
 &lt;li&gt;在新的业务中，如何快速构建 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在所有的计算产品中，函数计算（FC）这种 Serverless FaaS 类型的计算产品，在资源粒度、弹性策略、弹性效率方面都是最适合稀疏调用场景的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-226f328add64bac9730162c080868382b86.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;函数计算（FC）目前支持了 Python 和 NodeJS 两种语言的 MCP 运行环境（其他语言的 MCP 运行环境也马上会支持）。用户选择 MCP 运行环境创建函数后，只需要编写 MCP Tool 的业务逻辑即可，不需要考虑如何使用 MCP SDK。并且云原生 API 网关和函数计算（FC）有深度集成，可以天然适配 AI 应用开发的新范式。&lt;/p&gt; 
&lt;h5&gt;MCP Server 的弹性效率&lt;/h5&gt; 
&lt;p&gt;基于函数计算（FC）构建的 MCP Server 在弹性效率方面可以从两个维度来看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;资源规格细粒度管控。&lt;/li&gt; 
 &lt;li&gt;完全按请求弹性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;函数计算（FC）的实例规格从 0.05C 128MB 到 16C 32GB 不等，有几十种规格的组合方式，可以灵活的根据不同 MCP Server 承载的业务选择合适的资源规格。另外，在 AI 应用中，尤其是流程式构建的模式中，大多数 AI Agent 的职责都是单一的，计算逻辑不复杂的任务，所以都可以用较小资源规格的函数承载。资源规格小，在资源调度，弹性效率方面自然就会有优势。&lt;/p&gt; 
&lt;p&gt;再看函数计算（FC）的弹性机制，它是完全按照请求弹性的，有多少 QPS，就拉起对应数量的实例，并且实例可以复用，当 QPS 降下来后，空闲的实例会自动释放，整个过程完全不需要用户介入参与。在默认按请求弹性的的基础上，用户还可以自行设置按照时间定时弹，或按照指标阈值弹的策略，进一步满足复杂多变的业务场景，做到资源成本最优。&lt;/p&gt; 
&lt;h5&gt;MCP Server 的可观测&lt;/h5&gt; 
&lt;p&gt;函数计算（FC）有完善的可观测体系，也就意味着，基于函数计算（FC）构建的 MCP Server 同样具备指标、链路、日志三个维度的可观测能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b5f9da48cc9bb3dc9d0a1a704532ed62b69.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通过这套可观测体系，用户可以清晰的了解每个 MCP Server 的各类运行状态。&lt;/p&gt; 
&lt;h4&gt;如何解决开源自建 Dify 的痛点问题&lt;/h4&gt; 
&lt;p&gt;目前，Dify 基本已是可视化流程编排 AI Agent 使用最广泛的工具，但是目前还没有任何一家云厂商有 Dify 托管产品，所以很多基于开源自建 Dify 平台的客户会遇到很多共性的问题，尤其是从个人开发者、开发 Demo 转向企业级生产应用构建时，这些问题往往都是致命的。&lt;/p&gt; 
&lt;p&gt;企业基于开源自建 Dify 遇到的问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;流量防护弱：基于开源自建没有任何防护措施，很容易被穿透。&lt;/li&gt; 
 &lt;li&gt;管控与数据链路耦合：AI 应用设计与 Agent 的执行耦合在一起，在高并发场景下无法保证稳定性。&lt;/li&gt; 
 &lt;li&gt;负载均衡问题：在大流量情况下，Dify 的核心服务可能会因为流量负载不均导致稳定性下降。&lt;/li&gt; 
 &lt;li&gt;可观测缺失：开源 Dify 本身不带可观测能力，需要额外搭建可观测体系。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为了解决这些问题，阿里云上的 Serverless PaaS 类型的计算产品 Serverless 应用引擎（SAE）做了企业生产级别的 Dify 托管部署方案，旨在解决上述问题，让企业在使用 Dify 的时候不用再关心稳定性、健壮性、性能这些问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c555e83a9fc792a92b986916955d7f9752c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;快速部署 Dify&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1ba31b5a2dd05293386af6ce14de2ee831e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SAE 提供了 Dify 应用模板，可以一键拉起 Dify 应用，并且提供可视化构建的能力，可以对 Dify 里的每一个环节进行单独调整。&lt;/p&gt; 
&lt;h5&gt;保障 Dify 稳定高可用&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-32b0e7199c97341bf0d0222faacf34ca011.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SAE 部署 Dify 支持配置化，三 AZ 部署，实例粒度的自动化迁移，结合云原生 API 网关和 SAE 内置的服务治理能力，保障负载均衡稳定性，同时还支持 Dify 6 个核心服务的健康检查，以及无损上下线。&lt;/p&gt; 
&lt;p&gt;同样依托于底层 Serverless 架构，部署在 SAE 中的应用同样具备优秀的横向扩展效率，并且支持多种方式的弹性规则配置，使整套 Dify 服务可以根据不同的业务场景进行弹缩，在保证高可用的同时，又兼具成本优势。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1cd91079e9cbc4492cadd0a21b9bd65f100.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;除此以外，SAE 还支持小流量预热，CPU Burst 等能力，进一步保证 Dify 应用在极端情况下的稳定性。&lt;/p&gt; 
&lt;h5&gt;Dify 任务调度方案&lt;/h5&gt; 
&lt;p&gt;定时执行工作流做 AI 数据处理是通用的业务场景，Dify 官网已经把通过定时任务做 Dify 工作流的定时执行和状态监控作了最佳实践，可以参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.dify.ai%2Fzh-hans%2Flearn-more%2Fuse-cases%2Fdify-schedule%E3%80%82%E4%BD%86%E6%98%AF%E8%AF%A5%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84&quot; target=&quot;_blank&quot;&gt;https://docs.dify.ai/zh-hans/learn-more/use-cases/dify-schedule。但是该实践中的&lt;/a&gt; Dify Schedule 比较简陋，通过 Github Actions 做定时调度，只能调度公网的 dify 工作流，且不是一个企业级解决方案。&lt;/p&gt; 
&lt;p&gt;开源 Dify 在调度方面的痛点主要有 3 点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;执行记录过多会导致慢查询。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;执行历史记录存储在数据库中，数量太多会影响 Dify 性能，导致慢查询。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;执行记录查询不支持条件过滤。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;比如通过时间区间查询，通过任务状态查询，这些都是通用的需求，但开源 Dify 都不支持。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;没有报警监控。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任务调度系统需要监控工作流的执行状态，工作流运行失败，需要报警给对应的负责人，开源无报警监控能力。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们的方案是通过 MSE 任务调度（SchedulerX）来解决上述问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-89118308221a8bc52e81bd3914f14e5ce97.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用户在 MSE 任务调度中配置 Dify 的 Endpoint，MSE 任务调度通过 Dify API 拉取工作流应用。&lt;/li&gt; 
 &lt;li&gt;用户通过 MSE 任务调度配置定时调度和报警监控。&lt;/li&gt; 
 &lt;li&gt;Dify 工作流定时调度的时候，MSE 任务调度通过 Dify 提供的 API 调度用户的 Dify 应用，并且实时拉取执行结果和详情，存储在 MSE 的 AI 任务调度中。&lt;/li&gt; 
 &lt;li&gt;通过 AI 任务调度做报警监控、可观测增强。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MSE 任务调度集成 Dify 方案对比开源方案有以下 7 点优势：&lt;/p&gt; 
&lt;p&gt;| 功能 | MSE 任务调度 + Dify | 开源 Dify | | -------- | ---------------- | ------------------- | | 定时调度 | 有 | 无 | | 监控告警 | 有 | 无 | | 执行记录保留时长 | 保留最近 2 个月 | 无限制，但数据量太大会导致查询性能太差 | | 执行记录查询 | 支持时间区间、状态等多种查询条件 | 过滤条件有限 | | 权限管理 | 操作级别精细化权限管理 | 用户级别 | | 限流 | 应用限流、Token 限流 | 无 | | 失败自动重试 | 有 | 无 |&lt;/p&gt; 
&lt;h4&gt;AI 应用可观测体系&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8875e63ae3bd892339ee44b4da9f62c1832.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;结合阿里云可观测产品 ARMS，链路追踪 OpenTelemetry，我们构建了 AI 应用全环节的可观测体系。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f5517df414e4d4c1f132161ef3acac072f9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;AI 应用整体的可观测体系构建主要有两部分核心：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;数据采集。&lt;/li&gt; 
 &lt;li&gt;数据串联与分析。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;观测数据采集&lt;/h5&gt; 
&lt;p&gt;数据采集的核心是要覆盖足够的广，这里又分两个层面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;编程语言，开发框架要支持的足够广，足够全。&lt;/li&gt; 
 &lt;li&gt;AI 应用架构新范式里涉及到的云产品也需要以相同的标准上报数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在这两个层面，我们通过阿里云应用监控产品 ARMS 和链路追踪 OpenTelemetry 实现了全覆盖：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;遵循最新 OpenTelemetry 社区 GenAI 语义约定。&lt;/li&gt; 
 &lt;li&gt;支持常见的 AI 框架和 AI 模型，包括 Spring AI Alibaba / LLamaIndex / Langchain / 通义千问 2 / OpenAI / PromptFlow 等。&lt;/li&gt; 
 &lt;li&gt;支持 AI 应用开发的主流编程语言，Python，Java，Go。并且相比社区规范提供更加精细化的埋点和属性。&lt;/li&gt; 
 &lt;li&gt;支持在不同的调用链中传播会话信息。&lt;/li&gt; 
 &lt;li&gt;云原生 API 网关支持 OpenTelemetry 协议，网关自身和插件都会基于 OpenTelemetry 上报观测数据。&lt;/li&gt; 
 &lt;li&gt;函数计算 FC 和 Serverless 应用引擎 SAE 均与应用监控 ARMS 以及链路追踪 OpenTelemetry 版产品均做了深度集成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;数据串联与分析&lt;/h5&gt; 
&lt;p&gt;应用监控 ARMS 中，专门构建了 LLM 应用监控模块，针对 AI 应用场景提供了完善的可观测体系。&lt;/p&gt; 
&lt;p&gt;纵向的指标有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在线 AI 应用数。&lt;/li&gt; 
 &lt;li&gt;Trace 数。&lt;/li&gt; 
 &lt;li&gt;Span 数。&lt;/li&gt; 
 &lt;li&gt;大模型数。&lt;/li&gt; 
 &lt;li&gt;Token 使用情况。&lt;/li&gt; 
 &lt;li&gt;会话数。&lt;/li&gt; 
 &lt;li&gt;用户数。&lt;/li&gt; 
 &lt;li&gt;模型调用次数。&lt;/li&gt; 
 &lt;li&gt;Token 消耗情况。&lt;/li&gt; 
 &lt;li&gt;模型调用耗时。&lt;/li&gt; 
 &lt;li&gt;Token 消耗排行。&lt;/li&gt; 
 &lt;li&gt;等等...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;横向链路方面提供了专业的调用链分析功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Span 列表。&lt;/li&gt; 
 &lt;li&gt;Trace 列表。&lt;/li&gt; 
 &lt;li&gt;散点图。&lt;/li&gt; 
 &lt;li&gt;全链路聚合。&lt;/li&gt; 
 &lt;li&gt;全链路拓扑。&lt;/li&gt; 
 &lt;li&gt;错/慢 Trace 分析。&lt;/li&gt; 
 &lt;li&gt;调用链上的每个环节都会输入、输出、Token 消耗的展示。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;更多在途的功能规划&lt;/h4&gt; 
&lt;h5&gt;Dify DSL 转 Spring AI Alibaba 编码&lt;/h5&gt; 
&lt;p&gt;虽然 Dify 在做 AI Agent 开发时已足够便利，但是受限于 Dify 的开发语言（Python）和流程引擎的实现逻辑。在运行复杂 AI 应用时，性能方面是有缺陷的。所以我们在探索将 Dify 流程的 DSL 自动转换为基于 Spring AI Alibaba 开发框架的代码。&lt;/p&gt; 
&lt;p&gt;相当于只使用 Dify 低代码可视化构建 AI 应用的皮，运行的内核基于 Spring AI Alibaba 开发框架的代码，这样既具备了便捷的 AI Agent 编排能力，又具备了更好的运行性能。&lt;/p&gt; 
&lt;h5&gt;基于 LLM 编排 MCP Server&lt;/h5&gt; 
&lt;p&gt;目前的 MCP 模式，LLM 针对用户的输入，只返回一个确定的 MCP Server 和 MCP Tool，这是其实是由系统提示词控制的。理论上 LLM 可以针对用户的输入返回多个 MCP Server 和多个 MCP Tool，并且基于 MCP Server 和 MCP Tool 的描述告诉 Client 它们之间的调用顺序，相当于由 LLM 做好了 MCP Server 的编排。这个模式我们还在探索中，很类似现在的 Multi-Agent 的模式。&lt;/p&gt; 
&lt;h5&gt;提高 MCP 模式的性能&lt;/h5&gt; 
&lt;p&gt;因为 MCP 模式中，会频繁和 LLM 交互，显而易见，相比传统 API 调用，MCP 这种模式的性能是不好的，所以在一些时延敏感的业务场景中，目前大概率还不适合 MCP 模式。&lt;/p&gt; 
&lt;p&gt;目前我们也在探讨和探索如何提高 MCP 模式下的请求性能问题，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;固化 MCP Server/MCP Tool 组合，减少和 LLM 的交互。尤其当实现 LLM 编排 MCP Server 后，和 LLM 的交互可能就只存在于开发态或调试态，云形态时使用的都是固化好的 MCP Server 和 MCP Tool 的调用关系。&lt;/li&gt; 
 &lt;li&gt;函数计算探索边缘场景，将 MCP Server 运行在离用户更近的地方。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;AI 应用架构新范式对企业的影响&lt;/h2&gt; 
&lt;p&gt;至此，企业级 AI 应用架构新范式的介绍就结束了，整个架构里有很多环节，每个环节里又有许多细节，在文章中无法一一展开说明。有兴趣的同学可以联系我共同探讨。&lt;/p&gt; 
&lt;p&gt;我们可以设想一下在这个 AI 应用架构新范式下，企业的运营、产品、研发、运维团队之间的组织结构和协作关系可能会发生哪些变化？应用或系统的开发模式会发生哪些变化？&lt;/p&gt; 
&lt;p&gt;这里我来分享一下我的畅想。&lt;/p&gt; 
&lt;h3&gt;MCP Server First&lt;/h3&gt; 
&lt;p&gt;API First，前后端分离这两个概念已经存在很久了，海外企业遵循和实践的会比较好。因为我深耕在 Serverless 计算领域也有 5 年时间，对 AWS 的 Lambda 架构方案，Azure Functions 架构方案，Azure App Service 架构方案，GCP CloudFunction 架构方案，GCP CloudRun 架构方案有比较多的研究。接触了很多 Serverless FaaS 和 Serverless PaaS 架构的客户案例，包括负责落地了不少从双 A 迁移到阿里云的客户。基本上都是标准的基于 APIG+FaaS 模式的 API First 形态。但是在国内，这个模式实践的并不好，除了高德下决定使用函数计算重构了系统，实现了真正的 API First，前后端分离模式以外，鲜有客户有这种模式的实践，也许是有太重的历史包袱。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f46ebae566ede2fd2c9350a771a8dffac0e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;上图为高德前后的架构对比&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;在 AI 应用的时代，本质上依然是对各种 API 的调用，但是将 HTTP API 改成 REST API，改造成本是巨大的。但当 MCP 出现后，当我们的方案可以帮助客户 0 代码的转型 AI 应用架构新范式的时候，MCP Server First 是有可能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cb265611348b21fd749d36609d4cfaa1f74.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;运维团队：负责云产品的维护（比如云原生 API 网关，MSE Nacos，Serverless 应用引擎，PAI 这些产品的开通、升配），可观测体系的维护（也是基于云产品），和云厂商保持持续沟通。&lt;/li&gt; 
 &lt;li&gt;研发团队：理解公司业务的原子化能力，负责构建 MCP Server 池。&lt;/li&gt; 
 &lt;li&gt;运营/市场/产品：通过低代码可视化方式构建业务流程（业务编排），大白话描述业务需求，快速完成业务流程的搭建，或者说 AI 应用的构建。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以未来很有可能每个企业都有自己的 MCP Server 市场，在 MCP Server 市场里分门别类，每类 MCP Server 有专门的研发团队负责，不用太需要考虑统一返回格式，不用考虑开发语言统一。运营、市场、产品等业务方有业务需求或者有新的产品功能需求时，可以通过统一界面用大白话快速构建 AI 应用，MCP+LLM 来实现业务编排，实现 PRD 即产品（PRD as a Product）的新的开发模式。&lt;/p&gt; 
&lt;p&gt;点击&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Febook%2F8442&quot; target=&quot;_blank&quot;&gt;此处&lt;/a&gt;获取 78 页完整版 PPT&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18175077</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18175077</guid>
            <pubDate>Sun, 13 Apr 2025 08:51:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>