<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 18 Mar 2025 21:43:04 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>拼多多上线用户和商家视频通话功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbjXsabyYPkkNl12e9XFk6g&quot; target=&quot;_blank&quot;&gt;据电商派 Pro 昨日报道&lt;/a&gt;，拼多多面向用户和商家上线了视频通话功能，方便进行产品使用讲解。商家只需登录商家后台，在多多客服功能中找到客服工具，即可开通语音通话服务。&lt;/p&gt; 
&lt;p&gt;商家需选择语音通话账号，设置可视频接待的账号，点击下一步后，再选择是否在 23:00 至次日 8:00 期间接听，最后点击确认即可完成设置。&lt;/p&gt; 
&lt;p&gt;开通该功能后，商家在与消费者的聊天界面中可以向消费者发送「视频讲解邀请」卡片。消费者点击进入后，商家侧即会弹起视频通话界面。&lt;/p&gt; 
&lt;p&gt;值得注意的是，视频接通后，消费者摄像头默认关闭，需消费者手动开启，且开启后默认使用后置摄像头。&lt;/p&gt; 
&lt;p&gt;此外，平台方面还建议商家在配置语音通话账号后，尽量不要关闭商家 App，保持其前台运行状态。若商家连续两天接听率较低，系统会暂停通话功能 3 天，之后需商家重新开启。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339647</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339647</guid>
            <pubDate>Wed, 05 Mar 2025 11:20:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>使用 DeepSeek 拯救数据中台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;在数字化转型浪潮中，数据中台作为企业核心资产的&quot;枢纽站&quot;，却长期面临&quot;建而难用&quot;的尴尬境地——业务团队抱怨数据获取门槛高、技术团队困于复杂的数据治理任务，如何打通数据价值落地的&quot;最后一公里&quot;始终是行业痛点。&lt;/p&gt; 
 &lt;p&gt;PowerData 社区主理人李奇峰给出了一个充满技术想象力的答案：通过深度结合 DeepSeek 大模型的逻辑推理与结构化数据处理能力，重构数据中台的技术栈。&lt;/p&gt; 
 &lt;p&gt;3 月 22 日，PowerData 社区主理人李奇峰将出席 OSC 源创会南京站，并发表《使用 DeepSeek 拯救数据中台》主题分享，探讨如何借助大模型通用化与生成式的数据处理能力，结合数据中台中的落地痛难点，对其进行针对性的优化改造。&lt;/p&gt; 
 &lt;p&gt;在活动正式开始前，我们也和李奇峰聊了聊一些「入门级」问题，感兴趣的开发者可周六到活动现场，与李奇峰交流探讨关于数据中台的建设问题。报名链接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;800&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e193f9982c2bb3fe9fad5193d51273ce545.jpg&quot; width=&quot;552&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在众多大模型中为何选择 DeepSeek 作为数据中台改造的核心技术？与其他开源模型相比，DeepSeek 在数据处理场景下有哪些优势？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;我作为一个数据中台的从业者，核心诉求还是提升数据中台本身的能力。对于大模型的了解并不深入，其只是我的一个工具而已。所以从工具的属性来说，我选择 deepseek 主要有以下几点原因：&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;成本：无论是训练成本、还是推理成本，相较于其他模型都有显著降低。同时支持国产化硬件，在合规性方面也有保证。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;热度：在风口到来的时候，不说乘风而飞，但是至少还是需要蹭一下的。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;能力：DeepSeek R1 是 LMSYS Chinese 榜单最强的 from China 的模型，V3 是上面榜单中开源的最强非 Reasoner 模型，基础能力优越。同时相较于其他模型，DeepSeek 在逻辑推理+结构化数据解析处理的能力优秀，同时其支持的上下文窗口较大，在数据血缘解析、数据分类分级、数据质量治理等任务中，其准确性较其他模型都有显著提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;开发者最关心的部署成本问题：在私有化部署场景下，DeepSeek 模型针对数据中台做了哪些轻量化改造？是否支持量化压缩后的模型在常规 GPU 服务器集群运行？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;Deepseek 不会为企业应用场景训练各种量化模型的，市面上的量化模型都是社区和开发者上传的。如果为了降低部署成本，采购算力服务器之前先测试各个量化模型的能力能否满足应用场景，确定好使用哪版量化模型后，根据显存去采购性价比最高算力服务器，推理服务器建议买 Nvdia 游戏卡。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;能否用具体代码片段说明 DeepSeek 如何与数据中台组件集成？例如如何通过 API 调用实现&quot;自然语言转数据服务接口&quot;这类典型场景，过程中需要哪些中间件做适配？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;下面是一个非常简单的通过大模型进行数据自动标注的代码：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import openai
import pandas as pd
import json
from typing import List, Dict

class MetadataAutoTagger:
    def __init__(self, api_key: str, business_context: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.business_context = business_context  # 公司业务背景说明
        
    def generate_prompt(self, table_name: str, columns: List[str]) -&amp;gt; str:
        &quot;&quot;&quot;构造大模型提示词&quot;&quot;&quot;
        return f&quot;&quot;&quot;
        # 任务说明
        根据提供的元数据和业务背景，生成数据资产的业务标注信息，要求：
        1. 业务名称：体现数据在业务中的核心作用
        2. 业务类型：交易型/分析型/主数据/日志型...
        3. 业务实体：对应业务对象（客户/订单/产品...）
        4. 分类分级：按公司数据分类分级标准
        5. 字段说明：用业务语言解释字段含义

        # 业务背景
        {self.business_context}

        # 待标注元数据
        表名：{table_name}
        字段列表：{&#39;, &#39;.join(columns)}

        请用 JSON 格式返回结果，结构如下：
        {{
            &quot;table_name&quot;: &quot;{table_name}&quot;,
            &quot;business_name&quot;: &quot;&quot;,
            &quot;business_type&quot;: &quot;&quot;,
            &quot;business_entity&quot;: &quot;&quot;,
            &quot;data_classification&quot;: &quot;&quot;,
            &quot;columns&quot;: {{
                &quot;column1&quot;: &quot;业务说明&quot;,
                &quot;column2&quot;: &quot;业务说明&quot;
            }}
        }}
        &quot;&quot;&quot;

    def tag_metadata(self, metadata_df: pd.DataFrame) -&amp;gt; pd.DataFrame:
        &quot;&quot;&quot;批量处理元数据&quot;&quot;&quot;
        results = []
        for _, row in metadata_df.iterrows():
            response = self._call_llm(row[&#39;table_name&#39;], row[&#39;columns&#39;])
            if response:
                results.append(response)
        return pd.DataFrame(results)

    def _call_llm(self, table_name: str, columns: List[str]) -&amp;gt; Dict:
        &quot;&quot;&quot;调用大模型 API&quot;&quot;&quot;
        try:
            prompt = self.generate_prompt(table_name, columns)
            response = self.client.chat.completions.create(
                model=&quot;gpt-4&quot;,
                messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
                temperature=0.2,
                response_format={&quot;type&quot;: &quot;json_object&quot;}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f&quot;Error processing {table_name}: {str(e)}&quot;)
            return None

# 示例用法
if __name__ == &quot;__main__&quot;:
    # 初始化配置
    config = {
        &quot;api_key&quot;: &quot;your_openai_key&quot;,
        &quot;business_context&quot;: &quot;某电商公司，主要业务包含商品交易、用户画像、订单履约等...&quot;
    }

    # 示例元数据（实际从数据库或文件读取）
    sample_data = {
        &quot;table_name&quot;: [&quot;user_info&quot;, &quot;order_detail&quot;],
        &quot;columns&quot;: [
            [&quot;user_id&quot;, &quot;registration_date&quot;, &quot;last_login&quot;],
            [&quot;order_id&quot;, &quot;product_sku&quot;, &quot;payment_amount&quot;]
        ]
    }
    metadata_df = pd.DataFrame(sample_data)

    # 执行自动标注
    tagger = MetadataAutoTagger(**config)
    result_df = tagger.tag_metadata(metadata_df)
    
    # 保存结果
    result_df.to_csv(&quot;tagged_metadata.csv&quot;, index=False)
    print(&quot;标注结果示例：&quot;)
    print(result_df.head())
典型输出结果如下：
{
    &quot;table_name&quot;: &quot;user_info&quot;,
    &quot;business_name&quot;: &quot;用户基本信息表&quot;,
    &quot;business_type&quot;: &quot;主数据&quot;,
    &quot;business_entity&quot;: &quot;用户&quot;,
    &quot;data_classification&quot;: &quot;PII/LEVEL-2&quot;,
    &quot;columns&quot;: {
        &quot;user_id&quot;: &quot;用户唯一标识符，用于跨系统用户识别&quot;,
        &quot;registration_date&quot;: &quot;用户注册电商平台的具体日期&quot;,
        &quot;last_login&quot;: &quot;记录用户最近一次登录平台的时间&quot;
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在处理非结构化数据场景中（如日志解析/图片 OCR），DeepSeek 与传统 ETL 工具的结合方案是怎样的？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;非结构化数据基本用不上 Deepseek，月更好的选择，图片用多模态 LLM 可以总结，图片类型的文档用 OCR，OCR 一般用百度&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot;&gt;paddle&lt;/a&gt;，表格解析有开源的读光模型。这些都是数据处理，处理完才是抽取-转换-加载（Sqoop、Flume、Cannel、DataX）到下游。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在数据关系复杂的中台环境，如何通过 prompt engineering 确保大模型输出的 SQL/SHELL 脚本符合安全规范？是否有开发自定义的语法校验中间件？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;提示词来确保大模型输出的 SQL/SHELL 脚本符合安全规范，是有问题的。LLM 是用来理解和处理自然语言的，更多的是交互上的提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;推荐使用 sqlcheck 和 shellcheck 这种工具，脚本安全做的还可以。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;遇到模型&quot;幻觉&quot;导致的数据质量问题，是否有设计技术兜底方案？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;可以通过 RAG + 外挂知识库的方式优化幻觉问题。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;PowerData 社区在构建 DeepSeek 插件生态方面有哪些规划？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;后续会实现一些 MCP 接口。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;对想参与数据中台智能化改造的开发者，建议从哪些具体模块入手贡献？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;可以先尝试进行 text to sql 的功能开发，具体入门教程可参考此篇文章：https://mp.weixin.qq.com/s/Wk9OmB80JC7NFG2T7VjNRA&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在 Data+AI 的架构演进中，您认为未来 3 年数据中台的核心组件会发生哪些颠覆性变化？传统数据仓库工程师需要优先补充哪些 AI 工程化能力？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;颠覆性变化谈不上，数据中台的核心还是数据资产化、服务化，一切的功能目标都是往这个方向走。随着大模型的快速进化与深度结合，数据中台可能会在以下能力进行进化：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;自然语言交互：大模型出色的自然语言交互能力可准确理解用户意图，大幅提升数，据查询分析的便利性，提升用户体验&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;智能洞察分析：大模型可分析文本、图表等多维数据，智能归因、预测、总结，降，低员工利用数据、分析数据的门槛&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;集成大模型服务链路：集成 LangChain、向量检索、finetune 等大模型应用所，需技术组件，提升企业调试、使用大模型的效率&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;传统数仓需要补充哪些 AI 工程化能力？这个我们社区之前内部讨论过，工程化能力谈不上，更多的还是把 AI 当成一个全能小助手，帮助自己解决问题和提效吧。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;10567&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9b99625d6dd601dfc15f3189cd7c0bdf40c.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17938519</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17938519</guid>
            <pubDate>Wed, 05 Mar 2025 09:57:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Bolt.new 创始人：软件世界运行着万亿美元的市场，重写软件世界秩序的机会是巨大的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Bolt.new 创始人的励志故事：我们如何从即将倒闭，到成为史上增长最快的 AI 编码工具，并保持不到 20 名员工的规模。&lt;/p&gt; 
&lt;p&gt;本文整理自 Bolt.new 创始人 Eric Simons 的完整采访。他说：&quot;软件世界运行着万亿美元的市场，重写软件世界秩序的机会是巨大的。&quot;&lt;/p&gt; 
&lt;p&gt;来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FPiG719cda&quot; target=&quot;_blank&quot;&gt;https://weibo.com/1233486457/PiG719cda&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;一、从零到爆发：Bolt 的惊人增长轨迹&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Lenny 最近对 StackBlitz 的创始人兼 CEO Eric Simons 进行了一次深入采访，揭示了这个产品如何在短短几个月内从零到每年 4000 万美元的经常性收入 (ARR)，成为史上增长最快的产品之一。&lt;/p&gt; 
&lt;p&gt;StackBlitz 是一家已经存在了七年的公司，专注于基于网络的开发环境技术。然而，就在公司即将倒闭之际，他们推出了 Bolt - 一款 AI 驱动的文本到应用程序 (text-to-app) 工具，彻底改变了公司的命运。&lt;/p&gt; 
&lt;p&gt;&quot;公司在我们推出 Bolt 时几乎要倒闭了，&quot;Simons 回忆道。&quot;我们想，如果这能在未来几个月增加 10 万美元的 ARR，那就太棒了。结果在前两个月，我们从零增长到了 2000 万美元的 ARR。&quot;&lt;/p&gt; 
&lt;p&gt;现在，仅仅 5 个月后，Bolt 已经达到了 3000 万美元的 ARR，即将跨越 4000 万美元的门槛，拥有 300 万注册用户和约 100 万月活跃用户。更令人惊讶的是，StackBlitz 只有 15-20 名员工。这种爆炸性增长甚至让经验丰富的创业者和投资者都感到震惊，因为很少有公司能以这样的速度扩张。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;二、WebContainer 技术：七年锤炼的核心竞争力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功并非一蹴而就，而是建立在七年技术积累的基础上。StackBlitz 的核心技术是 WebContainer - 一种可以在浏览器中运行的操作系统，它能在 100 毫秒内启动并运行完整的开发工具链。&lt;/p&gt; 
&lt;p&gt;与市场上其他类似产品不同，Bolt 不依赖云服务器来运行应用程序。当用户使用其他&quot;文本到应用程序&quot;工具时，通常需要等待云虚拟机启动，这可能需要几分钟时间，并且经常出现问题。而 Bolt 的 WebContainer 技术利用用户自己的 CPU 和内存在浏览器中本地运行应用程序，使得整个过程更快、更可靠。&lt;/p&gt; 
&lt;p&gt;&quot;这就是为什么我们可以有一个非常宽松的免费层级，而且它极其快速和可靠，&quot;Simons 解释道。&quot;我们的 AI Agent 与这个操作系统有双向通信。它编写代码，运行开发服务器，使整个过程快速而流畅。&quot;&lt;/p&gt; 
&lt;p&gt;这种技术路线是 StackBlitz 团队经过深思熟虑的结果，受到了像 Figma 这样的成功产品的启发。Simons 指出：&quot;如果你看看其他在网络上真正成功的生产力应用程序，它们都采用这种计算模型。Figma、Google Docs - 这是唯一一种扩展到十亿用户的模型。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;三、Bolt 实战：一分钟内从文本到功能性应用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示了 Bolt 的强大功能。他只是简单地在一个文本框中输入&quot;制作一个 Spotify 克隆&quot;，然后点击回车。在不到一分钟的时间内，Bolt 在浏览器中生成了一个功能完整、视觉上令人印象深刻的 Spotify 克隆应用。&lt;/p&gt; 
&lt;p&gt;&quot;这是在浏览器中运行的完整开发环境，这是在我的浏览器中运行的真实操作系统，&quot;Simons 展示道。&quot;我可以在上面运行命令等，真正令人印象深刻的是，所有这些都是在 60 秒内完成的。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，用户可以立即部署他们的应用程序。通过集成 Netlify 等生产级托管提供商，用户可以一键获得一个实时 URL，甚至可以附加自己的域名。这使得整个过程从创建到部署变得无缝衔接。&lt;/p&gt; 
&lt;p&gt;Simons 强调说：&quot;这是有史以来构建网络应用最简单的方式。&quot;对比传统工具，他指出：&quot;那些东西（如 Wix 或 Squarespace）使用起来非常复杂。我不知道你是否见过这些工具的 UI，但它们非常复杂。而那只是为了构建一个静态网站，你根本无法用它们构建功能性应用。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;四、移动应用开发的革命：实时预览与测试&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 最近的一项重大更新是与 Expo 的合作，使用户能够创建原生移动应用。Expo 是一家专注于 React Native 工具的公司，使开发者能够更轻松地构建漂亮的应用并将其上传到应用商店。&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示了如何使用 Bolt 和 Expo 构建一个移动版 Spotify 克隆应用。用户只需扫描二维码，就能在自己的手机上实时查看和测试应用程序。当用户继续通过提示改进应用程序时，这些更改会实时反映在他们的设备上。&lt;/p&gt; 
&lt;p&gt;&quot;这是第一次，你不需要成为技术人员就能制作生产级的网络、全栈网络和移动应用，&quot;Simons 解释道。他指出，Bolt 的用户群体中有 67% 的人不是开发者，而是产品经理、设计师和企业家。&quot;这些人一直都很擅长构建产品，但以前，他们唯一能将想法转化为代码软件的方式是通过开发者的手指。现在他们可以自己处理。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;五、七年磨一剑：从技术挑战到市场突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功不仅仅是一个技术故事，更是一个关于毅力和坚持的故事。StackBlitz 在七年的时间里专注于构建 WebContainer 技术，经历了无数挑战和失败。&lt;/p&gt; 
&lt;p&gt;&quot;我们在技术第一，然后寻找问题来解决，这往往是人们告诉你不应该做的事情，&quot;Simons 承认。他的联合创始人 Albert 和他从 13 岁就开始一起编写代码，并从那时起一直在构建产品。&lt;/p&gt; 
&lt;p&gt;他们的灵感部分来自于早期的 Figma，Figma 最初是作为一个基于浏览器的深度技术项目起步的。Simons 解释说：&quot;很少有人知道 Figma 也是一个基于浏览器的深度技术项目。他们第一个 Figma 演示不是设计工具，而是在浏览器标签中展示一个 3D 球体掉入水中的效果。&quot;&lt;/p&gt; 
&lt;p&gt;类似地，StackBlitz 团队看到了浏览器技术（如 WebAssembly、共享内存和 Service Workers）的进步，并意识到可以构建一个运行在浏览器中的操作系统。他们花了大约五年时间来构建 WebContainer，然后又花了几年时间尝试找到合适的产品应用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;六、在死亡边缘找到转机：一条推文改变一切&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在公司即将耗尽资金的关键时刻，StackBlitz 团队认识到他们的 WebContainer 技术非常适合构建基于浏览器的 AI 产品。&lt;/p&gt; 
&lt;p&gt;&quot;我们与 Anthropic 合作，获得了对 Sonnet 模型的预览，&quot;Simons 回忆道。&quot;我们意识到这可能是我们的机会。我们以前尝试过构建类似 Bolt 的东西，但当时的模型不够好，代码输出不够可靠。但 Sonnet 改变了这一切。&quot;&lt;/p&gt; 
&lt;p&gt;2023 年 6 月，当 Anthropic 发布 Claude 3.5 Sonnet 模型时，StackBlitz 团队看到了机会。他们重新拾起之前搁置的项目，并通过一条简单的推文推出了 Bolt。结果超出了他们最疯狂的期望。&lt;/p&gt; 
&lt;p&gt;&quot;这就像是一个七年磨一剑的&#39;一夜成名&#39;故事，&quot;Simons 表示。StackBlitz 的生存策略也起到了关键作用，他们在整个过程中保持了极低的支出和精简的团队。&quot;我和我的联合创始人以前曾经引导一家公司直至被收购，所以我们知道如何使每一美元发挥超出任何人认为合理或可能的价值。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;七、小团队实现高速增长的秘诀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;尽管 Bolt 正在以前所未有的速度增长，但 StackBlitz 仍然是一个只有 15-20 人的小团队。当被问及如何管理这种增长时，Simons 强调了两个关键因素：技术和人员。&lt;/p&gt; 
&lt;p&gt;&quot;我们团队中有大约 5-7 人已经在这里工作了五年多，这在初创公司中相当罕见，&quot;Simons 指出。&quot;我们的策略一直是减少人员，增加每人的背景知识。每个人在公司里都了解其他所有事情，这样他们可以独立做出准确的决策。&quot;&lt;/p&gt; 
&lt;p&gt;StackBlitz 采用了每天召开全公司会议的做法，使每个人都了解正在发生的一切。尽管这听起来可能效率低下，但 Simons 辩解说：&quot;当你处于极端增长期时，你希望沟通损失接近于零。虽然这不是我们永远会做的事情，但在目前的阶段，它非常有效。&quot;&lt;/p&gt; 
&lt;p&gt;在工具方面，团队使用 Linear 进行工程任务，使用 Notion 进行产品路线图，使用 Figma 进行设计。有趣的是，他们现在也在使用 Bolt 进行许多设计和原型制作工作，因为它比传统工具更快。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;八、Anthropic 的 Sonnet 模型：AI 编码的临界点突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在访谈中一个令人惊讶的发现是，Anthropic 的 Claude 3.5 Sonnet 模型在 Bolt 的成功中起到了关键作用。Simons 称之为 AI 生成可靠代码的&quot;临界点&quot;。&lt;/p&gt; 
&lt;p&gt;&quot;在 Sonnet 之前，我们尝试过构建类似的东西，但它就是不起作用，代码输出不够可靠，应用程序要么损坏，要么看起来很丑，&quot;Simons 解释道。&quot;但当我们在 2023 年 5 月看到 Sonnet 的预览时，我们知道我们应该重新启动项目，因为这可能就是机会。&quot;&lt;/p&gt; 
&lt;p&gt;这一见解揭示了为什么自 Sonnet 发布以来，&quot;文本到应用程序&quot;工具的快速增长。Simons 指出，软件是确定性的，使其成为 AI 训练的理想领域：&quot;当你编写代码并点击运行时，它要么运行，要么不运行。这使得训练数据的创建和强化学习变得更加可靠。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，这些成功是基于 2023 年 6 月发布的模型，自那以来 Anthropic 还没有发布新模型。&quot;这是 AI 编码可能达到的最差状态，而且已经这么好了。下一个模型将使这一切变得更好，而且很快就会到来。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;九、AI 时代的职业前景：产品经理的黄金时代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;当讨论到 AI 对软件开发角色的影响时，Simons 提出了一个与许多流行观点相反的看法。他认为产品经理 (PM)，而非工程师，可能是 AI 编码革命的最大受益者。&lt;/p&gt; 
&lt;p&gt;&quot;当 Bolt 开始增长时，我们发现大多数用户不是开发者，而是产品经理、设计师和非技术企业家。这真正改变了一切，&quot;Simons 解释道。&quot;整个软件世界秩序将被重写，因为组织构建软件的方式将完全改变。&quot;&lt;/p&gt; 
&lt;p&gt;Simons 认为，产品经理精通定义范围并帮助开发者调试问题，这与成功使用 AI 开发代理所需的技能高度重合。&quot;如果你快进 1-5 年，PM 将不再只是写 JIRA 工单然后等待开发者完成，他们将能够自己进行更改。&quot;&lt;/p&gt; 
&lt;p&gt;工程师仍然很重要，但他们将专注于 LLM 不适合的智力挑战任务。&quot;这对每个人都是好事，&quot;Simons 强调。&quot;工程师可以专注于困难的挑战，而不是制作另一个 CRUD（增删改查）应用程序，而 PM 和设计师可以直接将他们的愿景转化为软件。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十、未来功能与愿景：与 Figma 和 Slack 的集成&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;展望未来，Bolt 正在开发几个令人兴奋的新功能。一个主要的即将推出的集成是与 Figma 的深度连接。用户只需在 Figma URL 前添加&quot;bolt.new&quot;并按回车，就能将设计导入 Bolt 并转换为全栈应用或移动应用。&lt;/p&gt; 
&lt;p&gt;&quot;这将是疯狂的，&quot;Simons 兴奋地说。&quot;从 Figma 到全栈应用，只需一次点击，字面意思。当你是开发者、设计师或其他角色时，将设计转化为实际的编码应用并能继续从那里提示，这真的很有趣。&quot;&lt;/p&gt; 
&lt;p&gt;另一个即将推出的功能是与 Slack 的集成，这将使团队能够直接在他们的通信中使用 Bolt。&quot;我们正在创建一个 Slack 机器人，其工作是基本上像你团队中的开发者一样行动，&quot;Simons 解释道。&quot;你可以在一个线程中说&#39;嘿，我认为我们应该添加一个主页&#39;，然后@Bolt&#39;你能快速做出这个吗？&#39;它会获取对话历史，理解需求，并生成应用程序。&quot;&lt;/p&gt; 
&lt;p&gt;这些集成反映了 Simons 对 AI 如何改变产品开发的更广泛愿景，使非技术人员能够直接创建他们想象的产品。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十一、使用 Bolt 的建议：像与开发者交流一样与 AI 交流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;当被问及给新 Bolt 用户的建议时，Simons 提供了一个简单但有力的建议：&quot;像写线程工单或 JIRA 工单一样与它交流。将它视为你团队中的开发者。&quot;&lt;/p&gt; 
&lt;p&gt;他解释说，这意味着在重要的事情上要具体，但也要允许 AI 在适当的领域发挥创意。&quot;你可以只告诉它&#39;让它更漂亮&#39;，它会做得很好。事实上，它做得非常好。&quot;&lt;/p&gt; 
&lt;p&gt;对于初次使用的人，Simons 建议从个人网站开始：&quot;这有一种魔力。你复制粘贴你的 LinkedIn 简历，说&#39;我需要一个网站。我的名字是某某。这是我的 LinkedIn 历史。我喜欢蓝色和狗。&#39;点击回车，然后你可以部署它。如果你还没有.com 域名，现在你可以拥有一个真正的个人网站。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十二、从 AOL 总部蹭住到建立价值数千万的公司&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在采访的最后，Simons 分享了他早年在硅谷的一段惊人经历。2012 年，19 岁的他参加了一个教育科技孵化器项目，该项目位于 AOL 总部。当资金耗尽时，他注意到这个办公室有沙发、食物、健身房，甚至还有淋浴和洗衣设施。&lt;/p&gt; 
&lt;p&gt;&quot;我想，也许在弄清楚这一切的同时，我可以住在这里，&quot;Simons 回忆道。&quot;所以我最终在这里住了四五个月。&quot;他通过在夜间编码来避开保安，白天和夜间轮班的保安以为他只是一个工作非常努力的员工。&lt;/p&gt; 
&lt;p&gt;生活费用？&quot;当时我的花费是每天一美元。那是麦当劳还有一美元菜单的时候。&quot;最终，一名保安发现了他并将他赶了出去，但这段经历展示了他早期的创业精神和生存能力。&lt;/p&gt; 
&lt;p&gt;Simons 的故事，从 AOL 总部蹭住到建立一家在几个月内达到 4000 万美元 ARR 的公司，展示了他一直以来的坚韧和创新精神。正如他所说：&quot;这一切都是关于保持活力，并采取尽可能多的尝试。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;结论：AI 编码的未来与更广泛的影响&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的故事不仅是关于一个成功的产品，还是关于技术进步如何彻底改变我们构建软件的方式。从这次采访中，我们可以看到几个关键趋势：&lt;/p&gt; 
&lt;p&gt;1. 文本到应用程序技术正在迅速成熟，使非技术人员能够创建以前需要专业开发团队的应用程序。&lt;/p&gt; 
&lt;p&gt;2. 基于浏览器的计算正在获得新的重要性，提供比基于云的替代方案更快、更可靠的体验。&lt;/p&gt; 
&lt;p&gt;3. AI 编码工具正在重塑公司的组织结构，可能导致产品和设计角色的重要性增加。&lt;/p&gt; 
&lt;p&gt;4. 我们可能正处于一场软件开发革命的边缘，这场革命将使创建功能全面的应用程序变得像使用文字处理器一样容易&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339630</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339630</guid>
            <pubDate>Wed, 05 Mar 2025 09:45:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>小米汽车模型训练专利公布，可解决资源消耗较大等技术问题</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查知识产权信息显示，小米汽车科技有限公司申请的「模型训练方法、使用方法、装置、设备及存储介质」专利公布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要显示，其中所述模型训练方法包括：将第一物理参数和第一性能数据输入第一模型，得到所述第一物理参数和所述第一性能数据的多个关联关系；将所述第一物理参数输入到取值模块，得到第二物理参数，所述取值模块基于所述第一物理参数计算出目标取值集合，在所述目标取值集合中选取所述第二物理参数；将所述第二物理参数输入所述第一模型，得到多个第二性能数据；基于所述多个第二性能数据，更新所述第一模型，得到第二模型。这样，能解决相关技术中存在的模型训练的精度和效率较低、资源消耗较大等技术问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-72b7dc543a47a38cd1a8d9a37c54723f663.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339627</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339627</guid>
            <pubDate>Wed, 05 Mar 2025 09:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AgentOps —— AI 代理的可观察性和 DevTool 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;AgentOps 是一个帮助开发人员&lt;/span&gt;测试、调试和部署 AI 代理和 LLM 应用程序的平台&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;。与大多数 LLM 和代理框架集成，包括 OpenAI Agents SDK、CrewAI、Langchain、Autogen、AG2 和 CamelAI。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Replay Analytics 和 Debugging&lt;/strong&gt; 代理逐步执行图&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM 成本管理&lt;/strong&gt; 跟踪 LLM 基础模型提供商的支出&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代理基准测试&lt;/strong&gt; 根据 1,000 多个评估测试您的代理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合规性和安全性&lt;/strong&gt; 检测常见的即时注入和数据泄露漏洞&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;框架集成&lt;/strong&gt; 与 CrewAI、AG2 (AutoGen)、Camel AI 和 LangChain 的原生集成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;237&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/182656_cKyN_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/agentops</link>
            <guid isPermaLink="false">https://www.oschina.net/p/agentops</guid>
            <pubDate>Wed, 05 Mar 2025 09:09:00 GMT</pubDate>
        </item>
        <item>
            <title>昆仑万维开源 R1V 视觉思维链推理模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;昆仑万维宣布正式开源首款工业界多模态思维链推理模型 Skywork R1V，即日起开源模型权重和技术报告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，Skywork R1V 具备超强的视觉理解和推理能力。「无论是日常繁琐的工作任务、复杂的数据分析、难以解答的学术问题，还是前所未见的陌生场景，都可以交给 Skywork R1V 进行高效处理。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Reasoning 推理能力方面，Skywork R1V 实现了模型的顶尖逻辑推理与数学分析能力。在权威的 MATH500 和 AIME 基准测试中，Skywork R1V 分别取得了 94.0 和 72.0 的高分，明显领先于行业内众多主流模型。Skywork R1V 在纯文本复杂推理任务中展现出卓越性能，使其在逻辑推理和数学问题求解领域展现出人类专家级别的水准。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Vision 视觉理解能力方面，Skywork R1V 成功地将其强大的文本推理与思维链推导能力高效迁移到视觉任务中。凭借创新的跨模态迁移技术与推理优化框架，Skywork R1V 能够高效解决需要多步视觉推理的问题，在 MMMU 与 MathVista 等视觉推理基准中分别取得了 69 和 67.5 的优异成绩。这些结果不仅明显超越了多个近似大小的开源竞争模型，更达到与规模更大的闭源模型媲美的水准，充分证实了 Skywork R1V 在需要视觉思维链推理的跨模态任务中的领先优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Skywork R1V 通过视觉与文本能力的深度融合和视觉思维链推理能力的突破，推动了多模态推理模型的进一步发展，标志着人工智能领域的又一重大进步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Skywork R1V 已全面开源。和开源同规模或更大规模模型的对比，Skywork R1V 38B 体现出行业显著优异的推理能力，以及领先的多模态视觉理解能力。如下图，与开源同规模或更大规模模型的对比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e032223e7b259303f6e6f7cce7dde417a6f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;与闭源头部模型性能对比，R1V 38B 模型性能媲美甚至超越更大开源模型以及主流闭源模型。如下图，与开源大尺寸模型与闭源专有模型的对比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;332&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-673a31430f860afa0908dd05aeaa3ad9c22.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339599</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339599</guid>
            <pubDate>Wed, 05 Mar 2025 07:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>理想汽车发布下一代自动驾驶架构 MindVLA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 18 日，在 NVIDIA GTC 2025 上，理想汽车发布了下一代自动驾驶架构 MindVLA。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ee07e92de4f6f16747c4c6b166e3b3f2f7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;理想汽车自动驾驶技术研发负责人贾鹏发表了主题演讲《VLA：迈向自动驾驶物理智能体的关键一步》，分享了理想汽车对于下一代自动驾驶技术 MindVLA 的最新思考和进展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b55c3282e8382e3f4257e15bbf23fee737f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;贾鹏表示：「MindVLA 是机器人大模型，它成功整合了空间智能、语言智能和行为智能，一旦跑通物理世界和数字世界结合的范式后，将有望赋能更多行业。MindVLA 将把汽车从单纯的运输工具转变为贴心的专职司机，它能听得懂、看得见、找得到。我们希望 MindVLA 能为汽车赋予类似人类的认知和适应能力，将其转变为能够思考的智能体。」&lt;/p&gt; 
&lt;p&gt;理想汽车 CEO 李想&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1243861097%2FPj5JY3Gsr%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;介绍称&lt;/a&gt;&lt;/u&gt;：「&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;MindVLA 是一个视觉-语言-行为大模型，但我们更愿意将其称为‘机器人大模型’，它将空间智能、语言智能和行为智能统一在一个模型里，让自动驾驶拥有感知、思考和适应环境的能力，是我们通往 L4 路上最重要的一步。&lt;/strong&gt;&lt;/span&gt;」&lt;/p&gt; 
&lt;p&gt;李想还表示：「MindVLA 能为自动驾驶赋予类似人类的驾驶能力，就像 iPhone 4 重新定义了手机，MindVLA 也将重新定义自动驾驶。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339597</guid>
            <pubDate>Wed, 05 Mar 2025 07:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软量子计算机研发曾遭 CEO 纳德拉否定</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微软上月&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot;&gt;宣布&lt;/a&gt;了一项重大科研进展，声称已成功制造出能够产生马约拉纳费米子的芯片，这一成果被视为量子计算领域的一大突破。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0220/104630_5Gkb_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微软方面表示，这一技术突破有望将量子设备的问世时间大幅提前，从原本预估的几十年缩短至几年之内。尽管这一消息在科技界引起了广泛关注，但并非所有物理学家都对微软的说法表示完全信服。&lt;/p&gt; 
&lt;p&gt;然而，微软 CEO 萨蒂亚·纳德拉却对此成果显得颇为满意。据悉，微软每年在量子研究上的投入高达 3 亿美元，尽管与人工智能等领域的投资相比，这一数字显得微不足道，但微软在量子领域的持续投入已累积近二十年，如今终于取得了阶段性成果。&lt;/p&gt; 
&lt;p&gt;值得注意的是，微软在量子计算领域的进展并非一帆风顺。据知情人士透露，七年前，纳德拉曾在公司内部对微软的量子研究表示怀疑，认为其缺乏商业潜力。然而，随着谷歌和 D-WaveQuantum 等竞争对手在量子计算方面取得进展，微软的科学家们也意识到自己正处于一场激烈的竞赛之中。&lt;/p&gt; 
&lt;p&gt;尽管如此，微软方面仍对自身的科研成果充满信心。负责监督相关团队的高管贾森·赞德表示，公司正准备发表《自然》论文的后续研究，并已邀请一组独立研究人员对其进行评审。&lt;/p&gt; 
&lt;p&gt;同时，微软发言人强调，公司会秉持最高的学术道德标准，确保研究成果的真实性和可靠性。&lt;/p&gt; 
&lt;p&gt;阅读更多：&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot; target=&quot;news&quot;&gt;微软发布首款量子计算芯片「Majorana 1」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339592</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339592</guid>
            <pubDate>Wed, 05 Mar 2025 07:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 首席 AI 科学家杨立昆评价人形机器人：演示惊艳、实际很蠢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;图灵奖得主、Meta 首席 AI 科学家杨立昆近日在一档播客节目中对人形机器人发表了「锐评」，他表示：「&lt;strong&gt;很多人形机器人演示令人印象深刻，但实际很蠢，不少机器人公司都在豪赌未来 3 到 5 年 AI 会突飞猛进。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/151624_dBd1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;杨立昆认为，目前我们仍然没有家用机器人，也没有能够完成猫或狗所能完成任务的机器人，更没有完全自主的 L5 级自动驾驶汽车。他强调，&lt;strong&gt;我们所欠缺的是如何训练一个系统来理解像视觉这样复杂的感官输入&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;杨立昆进一步指出，如果我们能够构建出理解物理世界、拥有持久记忆、能够推理和规划的 AI 系统，那我们就有了为机器人提供动力的 AI 基础。这样的机器人会比我们现有的机器人灵活得多。他提到，过去一两年里，成立了很多机器人公司，他们制造人形机器人和类似的技术。虽然所有的演示都令人印象深刻，但这些机器人实际上都很蠢。它们不能做人类能做的事情，不是因为它们缺乏身体能力，而是因为它们根本不够聪明，无法驾驭现实世界的复杂性。&lt;/p&gt; 
&lt;p&gt;杨立昆还提出，很多这样的公司都寄希望于 AI 在未来 3 到 5 年内会取得快速进展。他们预计到他们准备好大规模生产和销售这些机器人时，AI 的进步将使它们足够智能。&lt;/p&gt; 
&lt;p&gt;然而，杨立昆认为这是一场豪赌，他无法确定这是否能在三至五年内实现。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339582</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339582</guid>
            <pubDate>Wed, 05 Mar 2025 07:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>澳门即将全面结束 3G 时代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;澳门特区政府于 2022 年向澳门四间流动电信服务营运商延长 3G 牌照两年，&lt;strong&gt;该牌照将于 2025 年 6 月 4 日届满，澳门 3G 移动电信网络及服务将随着牌照届满而终止&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-952129e924f58e0fc3e136e05bebebc548b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;针对上述情况，澳门已敦促各运营商为 3G 退网做好准备工作。&lt;/p&gt; 
&lt;p&gt;澳门邮电局呼吁使用 3G 服务的市民及商户，请尽早联络相关电信营运商，了解转换到 4G 或 5G 服务的条件，选择最适合自身需求的服务。此外，市民及商户亦应留意手机或其他终端设备是否支持 4G 或 5G 制式，如需语音通话，有关设备更需支持 4G 语音通话功能（VoLTE），用户可按自身需要适时更换设备，确保能继续享用电信服务。&lt;/p&gt; 
&lt;p&gt;澳门邮电局局长刘惠明日前表示，随着通信业的发展进程，3G 流动电信网络及服务将于 6 月随着牌照届满而终止。刘惠明称，目前仍有约 1 万多名用户，有一部分是非活跃用户。局方正敦促营运商与合作伙伴处理有关问题，并要求营运商加强宣传推广 3G 在 6 月退场的讯息。&lt;/p&gt; 
&lt;p&gt;澳门电讯 CTM 也称，将于 2025 年 6 月起正式与 3G 网络服务告别。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-22f36d1bf91bacce6a45e473812d8130769.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;澳门电讯会通过短信通知仍使用 3G 服务的客户，及时更新服务计划及设备。客户亦可通过拨打 #183# 查询设备是否支持 4G / 5G 网络以及 VoLTE 话音功能。如有任何疑问或需协助，可亲临任何一间 CTM 门市或致电 CTM 服务第一热线：1000 查询。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339576</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339576</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「RdbStore」上线开源鸿蒙社区，助力鸿蒙应用数据访问效率大幅提升</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，由伙伴参与共建的鸿蒙关系映射数据库「RdbStore」正式上线 OpenHarmony 社区，为鸿蒙生态开发者提供了简单高效的关系映射数据库方案选择。该数据库性能和功能强大，可支持数据库自动升级、品质调优、全链路运维等，能够有效提升应用启动和访问速度，助力应用高效开发和性能提升。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;性能强大：数据访问和初始化耗时大幅优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;在应用开发过程中，数据访问的效率直接影响应用的启动和访问速度，「RdbStore」的推出让鸿蒙应用数据访问更加高效便捷。相比于其他关系映射数据库，「RdbStore」在性能方面做了诸多优化，包括：简化 DB 构建方式，优化核心框架架构；隔离同库中各表的解析创建，缩短各表的初始化耗时；抽象 SQL 语句书写方式，避免魔法值、SQL 语句方式访问 DB，便捷进行复杂 DB 操作；提升反序列化能力，优化 ResultSet 到 DTO 的构建过程，避免对象深拷贝导致的耗时。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;通过这些优化，「RdbStore」能够显著提升数据访问性能，单元测试 20 张数据表结构下，数据库访问耗时减少 76%[1]，确保数据高效读写，加速应用响应，提升用户体验。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;功能丰富：自动升级，便捷监测运行状态&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;「RdbStore」不仅具备卓越的性能，还提供了丰富的功能支持，大大降低了数据库维护成本。其具备数据库自动升级功能，可在运行时动态计算不同版本的表结构差异，自动生成迁移语句，开发者无需维护复杂易错的升级逻辑。同时支持品质调优 API，可调整日志模式、页大小等关键参数，使开发者能够灵活优化数据库性能。此外，「RdbStore」还具备全链路日志与打点功能，能够采集数据库运行时的品质数据，构建完善的数据库指标体系，帮助开发者实时监测数据库状态并进行优化调整，从而确保数据库的高效稳定运行。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;在实际应用中，「RdbStore」也展现了卓越的性能表现。运用「RdbStore」进行开发之后，该鸿蒙应用数据库加载首刷耗时 86ms，相比 Android 版 294ms 的首刷耗时，优化幅度高达 70%[2]，显著提升了应用的冷启动速度。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;无论是性能优化还是功能增强，「RdbStore」都展现了强大的技术实力，助力开发者打造更流畅、更稳定的鸿蒙应用。目前，「RdbStore」已在 OpenHarmony 社区正式上线并开源，希望更多应用厂商下载使用，并参与到共建行列，共同推进这一项目的持续优化和完善。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;欢迎更多伙伴和开发者们一起加入鸿蒙生态，贡献更多智慧与活力。未来华为也将持续携手生态伙伴共建创新，面向底座技术、通用能力、垂类行业等场景推出系列开发者场景化解决方案，不断提升鸿蒙应用的创新体验和开发效率，与广大开发者共建繁荣的鸿蒙生态。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;更多关于「RdbStore」的详细信息和使用指南，请访问「OpenHarmony 官网」，点击「开发者」——&amp;gt;「三方库中心仓」——&amp;gt;搜索「RdbStore」。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;[1]数据来源：厂商测试所得数据&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;[2]数据来源：厂商测试所得数据&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339575</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339575</guid>
            <pubDate>Wed, 05 Mar 2025 07:04:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>华科大研发领先的「玻璃光盘」技术：理论容量最高 360TB、成本仅 1/10</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FroBVlcZaikjurKymBpvpYQ&quot; target=&quot;_blank&quot;&gt;《长江日报》报道称&lt;/a&gt;&lt;/u&gt;，武汉光电国家研究中心信息存储系统教育部重点实验室研发出了一种「玻璃光盘」，存储容量目前是普通光盘的 10 倍，理论容量最高 360TB，而且几乎可以永久保存。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;921&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/145326_59D9_2720166.png&quot; width=&quot;1235&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;一块普通的玻璃如何让它有记忆的功能，报道介绍称，首先要在玻璃中产生结构，引起玻璃的化学性质变化，而完成这个任务的便是飞秒激光，类似于光刻，过去家用光刻机只能刻一层，而华科大团队能刻 400 层。制作成的玻璃存储介质从表面看只增加了一层浅灰色，而在显微镜下玻璃表面呈现出的是三维立体结构。如何把结构又快又好写进玻璃里，工艺是关键。&lt;/p&gt; 
&lt;p&gt;该技术被称之为「巨量信息低成本超长寿命玻璃多维存储技术」，目前华科大在该项技术上全球领先，国内也是独有的。相比于几年前，玻璃存储介质读写速度较过去快了 3 个数量级，单位体积的存储容量也提升了 2 个数量级，成本则下降了 1 个数量级。现在 1GB 的介质成本需要约 1 元，而玻璃存储介质 1TB 也才几十元，只有其他存储介质十分之一的成本。&lt;/p&gt; 
&lt;p&gt;目前，制造玻璃介质存储的设备已生产出原型样机，今年将推出产品样机，产品也将很快走向市场。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339573</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339573</guid>
            <pubDate>Wed, 05 Mar 2025 06:56:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 3FS 与 JuiceFS：架构与特性比较</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;近期，DeepSeek 开源了其文件系统 Fire-Flyer File System (3FS)，使得文件系统这一有着 70 多年历时的&quot;古老&quot;的技术，又获得了各方的关注。在 AI 业务中，企业需要处理大量的文本、图像、视频等非结构化数据，还需要应对数据量的爆炸式增长，分布式文件系统因此成为 AI 训练的关键存储技术。&lt;/p&gt; 
&lt;p&gt;本文旨在通过深入分析 3FS 的实现机制，并与 JuiceFS 进行对比，以帮助用户理解两种文件系统的区别及其适用场景。同时，我们将探讨 3FS 中的值得借鉴的创新技术点。&lt;/p&gt; 
&lt;h2&gt;01 架构对比&lt;/h2&gt; 
&lt;h3&gt;3FS&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2F3FS&quot; target=&quot;_blank&quot;&gt;3FS&lt;/a&gt; (Fire-Flyer File System) 是一款高性能的分布式文件系统，专为解决 AI 训练和推理工作负载而设计，该系统使用高性能的 NVMe 和 RDMA 网络提供共享存储层。3FS 由 DeepSeek 在 2025 年 2 月开源。 3FS 主要包括以下模块：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集群管理服务（Cluster Manager）&lt;/li&gt; 
 &lt;li&gt;元数据服务（Metadata Service）&lt;/li&gt; 
 &lt;li&gt;存储服务（Storage Service）&lt;/li&gt; 
 &lt;li&gt;客户端 （FUSE Client、Native Client）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-96308079c12c6210e0436722cad35b7c636.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所有模块通过 RDMA 网络通信。元数据服务和存储服务向集群管理服务发送心跳信号。集群管理服务负责处理成员变更，并将集群配置分发给其他服务和客户端。为了提高系统的可靠性和避免单点故障，会部署多个集群管理服务，其中一个被选为主节点。当主节点发生故障时，另一个管理器会被提升为主节点。集群配置通常存储在可靠的分布式服务中，例如 ZooKeeper 或 etcd。&lt;/p&gt; 
&lt;p&gt;当进行文件元数据操作（例如打开或创建文件/目录），请求被发送到元数据服务，以实现文件系统语义。元数据服务有多个，并且是无状态的，它们不直接存储文件元数据，而是依赖支持事务的键值数据库 FoundationDB 来存储这些数据。因此，客户端可以灵活地连接到任意元数据服务。这种设计使得元数据服务可以在没有状态信息的情况下独立运作，进而增强了系统的可伸缩性和可靠性。&lt;/p&gt; 
&lt;p&gt;每个存储服务管理若干本地 SSD，并提供 chunk 存储接口。存储服务采用 CRAQ （ Chain Replication with Apportioned Queries）来确保强一致性。3FS 中存储的文件被拆分为默认 512K 大小相等的块，并在多个 SSD 上进行复制，从而提高数据的可靠性和访问速度。&lt;/p&gt; 
&lt;p&gt;3FS 客户端提供两种接入方式： FUSE Client 和 Native Client。 FUSE Client 提供常见 POSIX 接口的支持，简单易用。Native Client 提供更高的性能，但是用户需要调用客户端 API ，具有一定的侵入性，下文我们还将对此作更详尽的解析。&lt;/p&gt; 
&lt;h3&gt;JuiceFS&lt;/h3&gt; 
&lt;p&gt;JuiceFS 是一个云原生分布式文件系统，其数据存储在对象存储中。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjuicedata%2Fjuicefs&quot; target=&quot;_blank&quot;&gt;社区版&lt;/a&gt;可与多种元数据服务集成，适用场景广泛，于 2021 年在 GitHub 开源。企业版专为高性能场景设计，广泛应用于大规模 AI 任务，涵盖生成式 AI、自动驾驶、量化金融和生物科技等。 JuiceFS 文件系统包括三部分组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;元数据引擎：用于存储文件元数据，包括常规文件系统的元数据和文件数据的索引。&lt;/li&gt; 
 &lt;li&gt;数据存储：一般是对象存储服务，可以是公有云的对象存储也可以是私有部署的对象存储服务。&lt;/li&gt; 
 &lt;li&gt;JuiceFS 客户端：提供 POSIX（FUSE）、Hadoop SDK、CSI Driver、S3 网关等不同的接入方式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bed8225b825f4a839eca178b415fc4b67db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;架构差异&lt;/h3&gt; 
&lt;p&gt;从模块划分上看两个文件系统差异不大，都采用了元数据与数据分离的设计，各个模块功能也较类似。不同于 3FS 和 JuiceFS 企业版，JuiceFS 社区版兼容多种开源数据库存储元数据，对元数据的操作都封装在客户端，用户不需要再单独运维一个无状态的元数据服务。&lt;/p&gt; 
&lt;h4&gt;存储模块&lt;/h4&gt; 
&lt;p&gt;3FS 使用大量本地 SSD 进行数据存储，为了保证数据存储的一致性，3FS 使用 CRAQ 这一简洁的数据一致性算法 。几个副本被组成一个 Chain，写请求从 Chain 的 Head 开始，一直到达 Chain 的 Tail 时返回写成功应答。读请求可以发送到 Chain 的所有副本，如果读到脏节点的数据，该节点会联系 Tail 节点检查状态。如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4b03df1057d9942ff363f034bee15053b6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;数据的写入是按顺序逐节点传递，因此会带来比较高的延时。如果 Chain 当中的某个副本不可用， 3FS 会把这个副本移到 Chain 的末尾，等副本可用的时候再做恢复。恢复的时候需要把整个 Chunk 的内容复制到这个副本，而非使用不可用期间的增量数据。如果要做到同步写所有副本和增量恢复数据，那写的逻辑会复杂非常多，比如 Ceph 使用 pg log 保证数据一致性。尽管 3FS 这种设计会导致写延迟，但是对于以读为主的 AI 应用场景，影响不大。&lt;/p&gt; 
&lt;p&gt;JuiceFS 利用对象存储作为数据存储解决方案，从而可享有对象存储带来的若干优势，如数据可靠性、一致性等。存储模块提供了一组用于对象操作的接口，包括 GET/PUT/HEAD/LIST 等，用户可以根据自己的需求对接具体的存储系统。比如不同云厂商的对象存储，也可以选择私有部署的对象存储比如 MinIO、Ceph RADOS 等系统。社区版 JuiceFS 提供本地缓存来应对 AI 场景下的带宽需求，JuiceFS 企业版使用分布式缓存满足更大的聚合读带宽的需求。&lt;/p&gt; 
&lt;h4&gt;元数据模块&lt;/h4&gt; 
&lt;p&gt;在 3FS 中，文件的属性以 KV 的形式存储在元数据服务中。该服务是一个无状态的高可用服务，依靠 FoundationDB 做支撑。FoundationDB 是 Apple 开源的优秀分布式 KV 数据库，具有很高的稳定性。FoundationDB 所有键值使用 Key 做全局排序，然后均匀拆分到不同的节点上。&lt;/p&gt; 
&lt;p&gt;为了优化 list 目录的效率，3FS 使用字符 &quot;DENT&quot; 前缀加父目录 inode 号和名字作为 dentry 的 Key。Inode 的 Key 是通过将 &quot;INOD&quot; 前缀与 inode ID 连接而构造的，其中 inode ID 采用小端字节序编码，以便将 inodes 分布到多个 FoundationDB 节点上。这个设计与 JuiceFS 使用的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Finternals%2F%23tkv&quot; target=&quot;_blank&quot;&gt;TKV（Transactional Key-Value Database）&lt;/a&gt; 进行元数据服务的存储方式类似。&lt;/p&gt; 
&lt;p&gt;JuiceFS 社区版的元数据模块，与存储模块类似也提供一组操作元数据的接口，可以接入不同的元数据服务，比如 Redis，TiKV 等 KV 数据库，MySQL，PostgreSQL 等关系型数据库，也可以使用 FoundationDB。JuiceFS 企业版使用自研高性能元数据服务，可根据负载情况来平衡数据和热点操作，以避免大规模训练中元数据服务热点集中在某些节点的问题（比如因为频繁操作临近目录文件的元数据引起）。&lt;/p&gt; 
&lt;h4&gt;客户端&lt;/h4&gt; 
&lt;p&gt;3FS 的客户端除了提供 FUSE 操作外，还提供了一组 API 用于绕过 FUSE 直接操作数据，也就是 Native Client，接口的调用方式有点类似于 Linux AIO。这组 API 的作用是避免使用 FUSE 模块带来的数据拷贝，从而减少 I/O 延迟和对内存带宽的占用。下面将详细解析这组 API 如何实现用户进程与 FUSE 进程之间的零拷贝通信。&lt;/p&gt; 
&lt;p&gt;3FS 通过 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存共享内存的大小，地址和其他一些属性，使用 &lt;code&gt;IoRing&lt;/code&gt; 在两个进程间通信。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-abcb70acca194a50f90a6a422695f8d89db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当用户调用接口，创建 &lt;code&gt;hf3fs_iov&lt;/code&gt; 时，会在 &lt;code&gt;/dev/shm&lt;/code&gt; 上分配内存,并创建一个指向这个共享内存的软链接，软链接的地址位于 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt;,这是个虚拟目录。3FS FUSE 进程收到创建软链接请求，并且发现它的地址位于上述虚拟目录后，就会根据软链接的名字解析出这块共享内存的相关参数，并将内存的地址注册到所有 RDMA 设备（除了 &lt;code&gt;IORing&lt;/code&gt; ）。&lt;code&gt;ibv_reg_mr&lt;/code&gt; 返回的结果被存在 &lt;code&gt;RDMABuf::Inner&lt;/code&gt; 数据结构中，用于后续发送 RDMA 请求。&lt;/p&gt; 
&lt;p&gt;同时，&lt;code&gt;IORing&lt;/code&gt; 的内存也使用 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存，只是在创建对应的软链接时，文件名中会有更多的 &lt;code&gt;IORing&lt;/code&gt; 相关的信息。如果 FUSE 进程发现这个内存是用于创建 &lt;code&gt;IORing&lt;/code&gt;，也会在它的进程内创建对应的 &lt;code&gt;IORing&lt;/code&gt;。这样设置之后，用户进程和 FUSE 进程就可以访问相同的 &lt;code&gt;IORing&lt;/code&gt; 了。&lt;/p&gt; 
&lt;p&gt;进程间协作方面，3FS 在 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt; 目录中创建 3 个不同的虚拟文件用于共享 3 个不同优先级的提交信号量 （submit sem ），用户进程将请求放到 &lt;code&gt;IORing&lt;/code&gt; 后使用这些信号量通知 FUSE 进程有新的请求。 &lt;code&gt;IORing&lt;/code&gt; 尾部包含请求完成信号量，FUSE 进程通过调用 &lt;code&gt;sem_post&lt;/code&gt; 通知用户进程 &lt;code&gt;IORing&lt;/code&gt; 上有新的请求完成。以上整个机制确保了两个进程间的高效数据通信和操作同步。&lt;/p&gt; 
&lt;p&gt;3FS 的 FUSE 客户端实现了文件和目录的基本操作，而 JuiceFS FUSE 客户端的实现更加全面。比如，在 3FS 文件系统中文件的长度是最终一致的，这意味着在写的过程中用户可能访问到不正确的文件长度。而 JuiceFS 在每次成功上传对象后会立即更新文件长度。此外，JuiceFS 还提供了以下这些常用的高级文件系统功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 BSD 锁（flock）和 POSIX 锁（fcntl）&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;file_copy_range&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;readdirplus&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;fallocate&lt;/code&gt; 接口&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除了 FUSE 客户端，JuiceFS 还提供 Java SDK，S3 Gateway，CSI Driver 等接入方式。企业版还提供 Python SDK，Python SDK 将 JuiceFS 客户端在用户进程中运行，避免了通过 FUSE 导致的额外性能开销。具体见文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcloud%2Fdeployment%2Fpython-sdk%2F&quot; target=&quot;_blank&quot;&gt;Python SDK&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;02 文件分布对比&lt;/h2&gt; 
&lt;h3&gt;3FS 文件分布&lt;/h3&gt; 
&lt;p&gt;3FS 将每个文件分成固定长度的 chunk，每个 chunk 位于一个上文提到的链上（ CRAQ 算法）。用户使用 3FS 提供的一个脚本，生成一个 chain table。然后将这个表提交到元数据服务。创建新文件时，系统会从表中选取特定数量的 chain （数量由 stripe 定义），并将这些 chain 的信息存入文件的元数据中。&lt;/p&gt; 
&lt;p&gt;因为 3FS 中的 chunk 是固定的，客户端只需要获取一次 inode 的 chain 信息，就可以根据文件 inode 和 I/O 请求，的 offset，length 计算出这个请求位于哪些 chunk 上，从而避免了每个 I/O 都从数据库查询的需求。可以通过 &lt;code&gt;offset/chunk_size&lt;/code&gt; 得到 chunk 的索引。 而 chunk 所在的 chain 的索引就是 &lt;code&gt;chunk_id%stripe&lt;/code&gt;。有了 chain 的索引就可以得到 chain 的详细信息（比如这个 chain 由哪些 target 组成）。然后，客户端根据路由信息将 I/O 请求发送到相应的存储服务。存储服务收到写请求后以 copy-on-write （COW）的方式将数据写入新的位置。原来的数据在引用数据清零前仍然是可读的。&lt;/p&gt; 
&lt;p&gt;为了应对数据不平衡问题，每个文件的第一个 chain 按照轮询（ round roubin） 的方式选择。比如当 stripe 为 3 时，创建一个文件，其选择的 chain 为：chain0，chain1，chain2。那么下一个文件的 chain 为：chain1，chain2 和 chain3。系统会将选择的 3 个 chain 做随机排序，然后存储到元数据中。下图为 stripe 为 3 时一个文件的分布示例，chain 随机排序后的顺序是：1，3，2。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cf9e25c0851f3f04955915e8e7ea4ffd658.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;JuiceFS 文件分布&lt;/h3&gt; 
&lt;p&gt;JuiceFS 按照 Chunk、Slice、Block 的规则进行数据块管理。每个 Chunk 的大小固定为 64M，主要用于优化数据的查找和定位。实际的文件写入操作则在 Slice 上执行，每个 Slice 代表一次连续的写入过程，属于特定的 Chunk，并且不会跨越 Chunk 的边界，因此长度不超过 64M。Chunk 和 Slice 主要是逻辑上的划分，而 Block（默认大小为 4M）则是物理存储的基本单位，用于在对象存储和磁盘缓存中实现数据的最终存储。更多细节可以参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Farchitecture&quot; target=&quot;_blank&quot;&gt;官网介绍&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-db8518e62e6de3e60bb23e2080a1ee55222.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS 中的 Slice 是在他文件系统中不常见的一个结构。主要功能是记录文件的写入操作，并在对象存储中进行持久化。对象存储不支持原地文件修改，因此，JuiceFS 通过引入 Slice 结构允许更新文件内容，而无需重写整个文件。这与 Journal File System 有些类似，其中写入操作仅创建新对象，而不是覆盖现有对象。修改文件时，系统会创建新的 Slice，并在该 Slice 上传完毕后更新元数据，从而将文件内容指向新的 Slice。被覆盖的 Slice 内容随后通过异步压缩过程从对象存储中删除，导致在某些时刻对象存储的使用量会暂时超过文件系统实际使用量。&lt;/p&gt; 
&lt;p&gt;此外，JuiceFS 的所有 Slice 均为一次性写入，这减少了对底层对象存储一致性的依赖，并大大简化了缓存系统的复杂度，使数据一致性更易于保证。这种设计还为实现文件系统的零拷贝语义提供了便利，支持如 copy_file_range 和 clone 等操作。&lt;/p&gt; 
&lt;h2&gt;03 3FS RPC (Remote Procedure Call) 框架&lt;/h2&gt; 
&lt;p&gt;3FS 使用 RDMA 作为底层网络通信协议，目前 JuiceFS 尚未支持，下面对此做一些分析。&lt;/p&gt; 
&lt;p&gt;3FS 通过实现一个 RPC 框架，来完成对底层 IB 网络的操作。除了网络操作外，RPC 框架还提供序列化，小包合并等能力。因为 C++ 不具有反射能力，所以 3FS 还通过模版实现了一个反射库，用于序列化 RPC 使用的 request、response 等数据结构。需要被序列化的数据结构只需要使用特定的宏定义需要序列化的属性。RPC 调用都是异步完成的，所以序列化后的数据只能从堆上分配，等待调用完成后再释放。为了提高内存的分配和释放速度，分配对象都使用了缓存。3FS 的缓存有两部份组成，一个 TLS 队列和一个全局队列。 从 TLS 队列获取缓存时不需要加锁；当 TLS 缓存为空时就得加锁，从全局队列中获取缓存。所以在最优情况下，获取缓存是不需要加锁的。&lt;/p&gt; 
&lt;p&gt;与 I/O 请求的负载不同，缓存对象的内存都未注册到 RDMA 设备中。因此，当数据到达 IBSocket 后，会被拷贝到一个在 IB 设备注册过的缓冲区中。多个 RPC 请求可能被合并为一个 IB 请求发送到对端。下图为 FUSE Client 调用 Meta 服务的 RPC 过程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//58e38641fd7da6914308fa2198428dc9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;04 特性对比&lt;/h2&gt; 
&lt;p&gt;| 对比项 | 3FS | JuiceFS 社区版 | JuiceFS 企业版 | |--------------------|-------------------------------|----------------------------------|----------------------------------------------| | 元数据 | 无状态元数据服务+FoundationDB | 独立数据库服务 | 自研高性能分布式元数据引擎（可横向扩展） | | 数据存储 | 自主管理 | 使用对象存储 | 使用对象存储 | | 冗余保护 | 多副本 | 对象存储提供 | 对象存储提供 | | 数据缓存 | 无缓存 | 本地缓存 | 自研高性能多副本分布式缓存 | | 数据加密 | 不支持 | 支持 | 支持 | | 数据压缩 | 不支持 | 支持 | 支持 | | 配额管理 | 不支持 | 支持 | 支持 | | 网络协议 | RDMA | TCP | TCP | | 快照 | 不支持 | 支持克隆 | 支持克隆 | | POSIX ACL | 不支持 | 支持 | 支持 | | POSIX 兼容性 | 少量子集 | 完全兼容 | 完全兼容 | | CSI 驱动 | 没有官方支持 | 支持 | 支持 | | 客户端 | FUSE + Native Client | POSIX（FUSE）、Java SDK、S3 网关 | POSIX（FUSE）、Java SDK、S3 网关、Python SDK | | 多云镜像 | 不支持 | 不支持 | 支持 | | 跨云和跨区数据复制 | 不支持 | 不支持 | 支持 | | 主要维护者 | DeepSeek | Juicedata | Juicedata | | 开发语言 | C++, Rust (本地存储引擎) | Go | Go | | 开源协议 | MIT | Apache License 2.0 | 商业软件 |&lt;/p&gt; 
&lt;h2&gt;05 总结&lt;/h2&gt; 
&lt;p&gt;大规模 AI 训练中最主要的需求是高读带宽，为此 3FS 采用了性能优先的设计策略，将数据存储在高速磁盘上，并且用户需要自行管理底层数据存储。这种方法提升了性能，但成本较高，维护也更繁重。此外，为了充分发挥底层硬件的性能，其架构实现了客户端到网卡的零拷贝，利用共享内存和信号量减少 I/O 延迟和内存带宽占用。此外，通过带 TLS 的 I/O buffer pool 和合并网络请求，3FS 增强了小 I/O 和文件元数据操作的能力，并引入了性能更优的 RDMA 技术。我们将继续关注 3FS 在性能优化方面的进展，并探索如何将这些技术应用于我们的场景中。&lt;/p&gt; 
&lt;p&gt;JuiceFS 使用对象存储作为底层数据存储，用户因此可大幅降低存储成本并简化维护工作。为了满足 AI 场景的对读性能的需求，JuiceFS 企业版引入了分布式缓存、分布式元数据服务和 Python SDK，从而提高文件系统的性能和扩展能力，并同时兼顾低存储成本。在接下来发布的 v5.2 企业版中，在 TCP 网络中实现了零拷贝，进一步提升数据传输效率。&lt;/p&gt; 
&lt;p&gt;JuiceFS 提供完整的 POSIX 兼容性和成熟活跃的开源生态，适应更广泛的使用场景，并支持 Kubernetes CSI，极大简化了云平台的部署和运维工作。此外，JuiceFS 还提供了 Quota、安全管理和数据灾备等多项企业级管理功能，让企业可以更便捷地在生产环境中部署和应用 JuiceFS。&lt;/p&gt; 
&lt;p&gt;希望这篇内容能够对你有一些帮助，如果有其他疑问欢迎加入 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2F&quot; target=&quot;_blank&quot;&gt;JuiceFS 社区&lt;/a&gt;与大家共同交流。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5389802/blog/17937022</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/17937022</guid>
            <pubDate>Wed, 05 Mar 2025 06:54:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Roblox 公布生成式 AI 模型 Roblox Cube</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 17 日，Roblox 公布了自己的生成式 AI 模型 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcorp.roblox.com%2Fnewsroom%2F2025%2F03%2Fintroducing-roblox-cube&quot; target=&quot;_blank&quot;&gt;Roblox Cube&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;926&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/144726_7BvT_2720166.png&quot; width=&quot;1618&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;游戏公司 Roblox 曾于去年宣布将建立一个开源的三维基础模型，用于在 Roblox 中创建三维物体与场景。&lt;/p&gt; 
&lt;p&gt;本周，Roblox 将开源名为 Cube 3D 的模型首个版本，任何人都可以在 Roblox 平台内外使用。同时发布的还有网格生成 API 的 beta 版。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1906054f0606ef1676bb4e26ab93a24aed.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;官方示例提示词：A red buggy with knobby tires（装有凸高花纹越野胎的红色越野车）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Cube 3D 可以从文字直接生成 3D 模型与环境，未来还将支持以图生模型。Roblox 期望最终模型能完成加入物体-环境-人互动维度的 4D 创造。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339570/oblox-cube</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339570/oblox-cube</guid>
            <pubDate>Wed, 05 Mar 2025 06:48:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>在 RISC-V 上构建 AI 应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;当开源指令集 RISC-V 遇上 AI 大模型，会碰撞出怎样的未来图景？&lt;/p&gt; 
&lt;p&gt;中国科学院软件研究所工程师张旭阳和他所在的团队正在研究 AI 大模型在 RISC-V 架构上的多项应用与实践。&lt;/p&gt; 
&lt;p&gt;3 月 22 日，张旭阳将出席 OSC 源创会南京站活动，发表《RISC-V 上 AI 应用与实践》，通过自主研发的 AI 助手展示如何借助 RISC-V 架构构建高效、灵活的 AI 助手，实现智能交互与数据处理。&lt;/p&gt; 
&lt;p&gt;同时张旭阳还将分享 Qwen、DeepSeek、LLama 和 Stable Diffusion 等知名模型在 RISC-V 上应用的最新进展。&lt;/p&gt; 
&lt;p&gt;在活动开始前，我们和张旭阳简单聊了聊 RISC-V + AI 的技术创新与生态构建，欢迎想了解具体如何在 RISC-V 上构建 AI 应用的开发者到现场交流，报名链接：&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1014&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-015bbdaaa23e8ca63a6d14af2bc8f95c1a0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 对 AI 来说，是「乐高积木」还是「瑞士军刀」？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;我觉得更像是乐高积木吧，因为 RISC-V 的架构更加开发，所以非常易于针对不同场景进行定制。用户根据不同的场景需要，定制化的设计芯片，可以扩展指令集，可以在 Soc 上集成各种类型的处理器。同时因为 RISC-V 的特性，做同样的工作，相比 x86 和 arm 来说，功耗更低。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;把 Qwen、DeepSeek 这些「大胖子」模型塞进 RISC-V，需要先帮它们「瘦身」吗？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;我们都知道 Qwen 是阿里推出的一系列优秀的开源模型，Qwen 的优点就是，模型参数覆盖比较广，最小的模型参数只有 1.5b 。我们目前成功在基于 TH1520 的 RUYIBOOK 上跑通了 Qwen2.0-1.5B 的小模型，以及 DeepSeek-R1-Distill-Qwen-1.5B 模型。同时在算能 SG2042 和 SG2044 的环境上，跑通了 DeepSeek-R1-Distill-Qwen-1.5B，DeepSeek-R1-Distill-Qwen-7B 等模型，借助于 TPU 的算力，这些精简的模型也可以跑出相对不错的性能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 架构上的自研 AI 助手突出优势是什么？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;我们自研的 AI 助手，可以说是 RISC-V 的原住民，也是首款基于 RISC-V 桌面生态环境的原生开发的 AI 助手，它可以原生运行在我们的自研的开源 RISC-V 笔记本 RUYIBOOK 甲辰版上，除了基础的文字问答功能之外，还有图片理解，文生图，语音合成等多模态功能。同时借助大模型的能力，可以通过文字或者语音的方式直接对操作系统做一些基础的控制。比如说调节音量，调节屏幕亮度，打开关闭应用，搜索文件并打开等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;Stable Diffusion 在 RISC-V 上画图，实测生成一张图要多久？效果如何？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;目前基于算能 SG2044 的测试情况，在 TPU 加速情况下，StableDiffusionV1.5 模型生成一张图大约 5-6s，StableDiffusionXL 模型生成一张图大约是 40-50s。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;开发者最怕「从入门到放弃」，有没有开箱即用的工具包？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;可以关注一下中科院软件所 PLCT 实验室所出的 RuyiSDK 开发工具集。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;RISC-V 开发板镜像相关信息以及下载、安装教程，便于开发者获取相关镜像（换而言之提供一个镜像站），其中涵盖多种操作系统（如基于 Debian 的 RevyOS、openEuler RISC-V 等）提供给开发者使用。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;提供 RISC-V 开发板对应的演示程序、开发资料和相关工具（含适用的编译工具链、模拟器等）的信息维护和下载，方便 RISC-V 开发者快速上手。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;在集成开发环境中增加 RISC-V 设备专有向导页面、实现开发环境和运行环境的文件传输、支持在 RISC-V 设备上调试应用程序等。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;玩转 RISC-V + AI 需要点亮哪些技能树？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;其实如果感兴趣的话，完全可以自己买一个开发板先玩起来，因为技能是可以在实践的过程中逐步去学习的。无论是 AI 相关的，还是 RISC-V 相关的。只要你有一定的计算机专业基础，然后又会一两门开发语言，比如 C,C++,python 等。那么就可以自己利用开发板来做一些研究和学习。咱们的大部分普通人的目的可能并不在于搞出一个 DeepSeek，而是看看能利用 DeepSeek 做些什么。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;预言时间：RISC-V + AI 组合拳，3 年内能 KO 传统架构吗？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;这个时间点我不好预估，因为无论是 AI 软件栈，还是 RISC-V 都在快速发展中，他们都还没有达到一个成熟期。但是呢，我认为在开源开放，合作共赢的生态下，RISC-V 和 AI 未来一定可以拿出一些标杆级的应用，可以在某些应用场景下落地生根。我们和传统的指令集架构，很长时间都是共生共存的关系。并不是说要 KO 掉谁。但我们因为灵活扩展等特性，可能未来在 AI 领域比传统指令集更加容易去开拓。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;即刻报名&lt;/strong&gt;，现场探智能体设计与使用问题&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🔥报名链接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;⏰时间：03-22 14:00 至 18:00&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🚗地点：南京瑞澜庭院酒店（南京秦淮区瑞金路街道解放路 46 号）&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;2367&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7a57781b43c33abfad271e2d16b2f1eca4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17937477</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17937477</guid>
            <pubDate>Wed, 05 Mar 2025 06:46:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>摩尔线程开源两大 AI 框架：MT-MegatronLM 和 MT-TransformerEngine</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摩尔线程近日宣布正式开源 MT-MegatronLM 与 MT-TransformerEngine 两大 AI 框架。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，通过深度融合 FP8 混合训练策略和高性能算子库，这两大框架在国产全功能 GPU 上实现了高效的混合并行训练和推理，显著提升了训练效率与稳定性。此次开源不仅为 AI 训练和推理提供了全新的国产化解决方案，更对推动国产 GPU 在 AI 大模型领域的应用具有重要意义。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MT-MegatronLM 是面向全功能 GPU 的开源混合并行训练框架，支持 dense 模型、多模态模型及 MoE（混合专家）模型的高效训练。该框架利用全功能 GPU 支持 FP8 混合精度策略、高性能算子库 muDNN 与集合通信库 MCCL，可以显著提升国产全功能 GPU 集群的算力利用率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MT-TransformerEngine 主要用于 Transformer 模型的高效训练与推理优化，通过算子融合、并行加速策略等技术，充分释放摩尔线程全功能 GPU 高密度计算的潜力和 memory bound 算子的效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;两大框架的技术突破集中体现在硬件适配与算法创新的深度协同：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;混合并行训练：支持 Dense、多模态及 MoE 模型的混合并行训练，可灵活应对不同模型架构的复杂运算场景；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;FP8 混合训练策略：结合摩尔线程 GPU 原生支持的 FP8 混合精度训练策略，能够有效提升训练效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;高性能算子库：通过高性能算子库 muDNN 与通信库 MCCL 的深度集成，系统性优化了计算密集型任务与多卡协同的通信开销；同时结合摩尔线程开源 Simumax 库，可自动进行并行策略搜索，并针对不同模型和加速环境 spec 最大化并行训练性能；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;异常训练处理：框架内置的 rewind 异常恢复机制，可自动回滚至最近稳定节点继续训练，大幅提升大规模训练的稳定性；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;完整的兼容性：两个框架兼容 GPU 主流生态，既保障了现有生态的平滑迁移，也为开发者构建自有的 AI 技术栈提供了底层支撑。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;实际应用效果&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;高效训练：&lt;/strong&gt;在全功能 GPU 集群上，Llama3 8B 模型的训练任务，可以利用 FP8 在 loss 几乎无损的情况下 MFU 达到 90% 以上；（如下图所示）&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;508&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e522512f7751e81f2884a5adceedd07045.webp&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;图注：利用摩尔线程 FP8 混合精度加速技术在 loss 无损的情况下得到 28% 的加速&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;复现 DeepSeek 满血版训练：&lt;/strong&gt;摩尔线程已深度集成并开源对 DeepSeek 并行算法 DualPipe 的高效支持，MT-DualPipe 可以完整接入 MT-Megatron 框架和 MT-TransformerEngine 框架，成功实现 DeepSeek V3 训练流程的完整复现，支持 MLA、MTP 及多种专家平衡策略；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;性能大幅优化：&lt;/strong&gt;通过多种 Transformer 算子融合技术，显著提升了内存带宽利用率，有效缓解 memory bound 瓶颈，进一步释放国产 GPU 的硬件潜力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;摩尔线程方面表示，接下来将持续优化 MT-MegatronLM 与 MT-TransformerEngine 框架，并引入一系列创新功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;Dual Pipe/ZeroBubble 并行策略：&lt;/strong&gt;进一步降低气泡率，提升并行训练效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;多种 FP8 优化策略：&lt;/strong&gt;独创的 FP8 优化策略，提高训练的性能和稳定性；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;异步 checkpoint 策略：&lt;/strong&gt;提高训练过程中的容错能力和效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;优化后的重计算策略：&lt;/strong&gt;减少计算和显存开销，提高训练速度；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;容错训练策略：&lt;/strong&gt;独创的容错训练算法，增强训练过程中的容错能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;集成摩尔线程 FlashMLA 和 DeepGemm 库：&lt;/strong&gt;进一步释放摩尔线程 GPU 的算力和 FP8 计算能力，提升计算性能和效率。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339567</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339567</guid>
            <pubDate>Wed, 05 Mar 2025 06:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Cursor 发布 Claude 3.7 Max</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Cursor 刚刚&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.cursor.com%2Ft%2Fclaude-3-7-max-out-now%2F65698&quot; target=&quot;_blank&quot;&gt;发布了最新的 AI 模型——Claude Max&lt;/a&gt;！它可不是一般的小升级，而是一次彻底的进化，强大到你难以想象！&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;核心大脑：&lt;/strong&gt;&amp;nbsp;搭载 Claude 3.7 Thinking 模型&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;超大视野：&lt;/strong&gt;&amp;nbsp;完整&amp;nbsp;&lt;strong&gt;200k 上下文窗口&lt;/strong&gt;，代码理解能力直接拉满！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具狂魔：&lt;/strong&gt;&amp;nbsp;超高工具调用限制，一次性搞定复杂操作！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;代码速读：&lt;/strong&gt;&amp;nbsp;瞬间消化海量代码&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;价格注意：&lt;/strong&gt;&amp;nbsp;按用量付费，每 prompt 和 tool call 均为 $0.05 美元。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;受众明确：&lt;/strong&gt;&amp;nbsp;不适合日常轻度用户，硬核玩家专属！&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/143434_w22S_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面带你快速了解一下它的核心优势：&lt;/p&gt; 
&lt;p&gt;🧠&lt;strong&gt; 1. 核心更聪明，创意更强大！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Claude Max 搭载了最新的 Claude 3.7 大脑，不只是智能，更具有超强的创造力。&lt;br&gt; 它不按常规套路出牌，能在其他模型失灵时脱颖而出，解决更复杂、更精妙的任务。&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;2. 一口气处理 20 万字上下文！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;过去 AI 模型总是卡在「上下文长度」上，代码量一多就开始变傻？&lt;br&gt; Claude Max 一次可加载，整整 20 万字的上下文，让你整个项目代码一次性输入，无需拆分。&lt;br&gt; 首次实现上下文越大，模型表现越好！&lt;/p&gt; 
&lt;p&gt;🛠️ &lt;strong&gt;3. 工具调用猛增到 200 次！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Claude Max 一次性可以调用多达 200 次工具调用，效率简直爆表！&lt;br&gt; 它能一口气编辑、分析、优化你的整个代码库，彻底摆脱过去 AI「小步慢走」的尴尬。&lt;/p&gt; 
&lt;p&gt;🔍&lt;strong&gt; 4. 一次读懂大量代码！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Claude Max 一次性阅读代码的量比过去大大增加，&lt;br&gt; 理解更深入、动作更少、更精准。不再浪费多余的工具调用，更加高效省时。&lt;/p&gt; 
&lt;p&gt;💰 &lt;strong&gt;5. 性能超强，但价格也超「感人」！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;注意啦，Claude Max 并非普通用户的日常选择，因为它采用了按使用量计费的方式：&lt;/p&gt; 
&lt;p&gt;- 每次请求（prompt）收费：0.05 美元&lt;br&gt; - 每次工具调用收费：0.05 美元&lt;/p&gt; 
&lt;p&gt;⚠️ 举个例子：&lt;br&gt; 如果你不小心让 Claude Max 用满 200 次工具调用，一次操作下来可能会花掉整整 10 美元。&lt;/p&gt; 
&lt;p&gt;因此，我们并不建议普通用户随便用 Claude Max。&lt;br&gt; 它更适合专业人士、资深程序员或对费用不敏感的用户。&lt;/p&gt; 
&lt;p&gt;💪&lt;strong&gt; 6. 谁最适合用 Claude Max？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;- 要一次完成超大规模复杂项目的开发者；&lt;br&gt; - 面对高难度、精细化代码编辑的高级用户；&lt;br&gt; - 想体验目前最先进 AI 模型能力，且预算充足的用户。&lt;/p&gt; 
&lt;p&gt;超过 90% 的日常代码编辑任务，用 Cursor 现有的普通模型已经绰绰有余，无需额外投入。&lt;/p&gt; 
&lt;p&gt;🚩 使用前务必注意：&lt;/p&gt; 
&lt;p&gt;Claude Max 不包含在 Cursor 的基础 Pro 套餐，中，必须额外开启「按量计费模式」才能使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339566/claude-3-7-max</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339566/claude-3-7-max</guid>
            <pubDate>Wed, 05 Mar 2025 06:34:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯混元推出 5 个开源 3D 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;腾讯混元宣布推出 5 个全新 3D 生成模型，并全部开源。这些基于 Hunyuan3D-2.0 打造的模型具有更快的生成速度、更丰富的细节和更逼真的材质表达。同时，腾讯自研的 3D AI 创作引擎也进行了升级，现已向 C 端用户全面开放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;285&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-142e80908d4b94f1fe229da4677ce363137.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在这些新模型中，Turbo 系列模型通过腾讯混元提出的 3D 生成加速框架 FlashVDM，实现了数十倍的加速，将生成过程缩短至 30 秒内完成。多视图版本模型 Hunyuan3D-2-MV 能更好地捕捉细节，生成符合用户预期的 3D 资产。轻量级 mini 系列模型通过架构优化降低了算力需求，可部署在 4080 显卡甚至苹果 M1Pro 芯片上。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;升级后的腾讯混元 3D AI 创作引擎支持多视图输入，用户只需上传 2-4 张标准视角图片，即可快速生成高质量 3D 模型，大幅降低游戏制作、3D UGC 创作等场景的制作成本。引擎的 3D 智能减面能力可自适应生成几百至数千面的三角面，提升几何边缘平滑度，在低面片基础上最大化体现模型细节。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在材质表现方面，此次升级实现了 PBR（基于物理渲染技术）的材质生成效果提升，通过物理特性模拟技术赋予模型更真实的颜色与材质表达。兼容性上，除通用 OBJ、GLB、FBX 外，还可输出 STL、USDZ 及 MP4 等主流格式，无缝连接 3D 打印工具，支持模型快速预览及移动端实时交互。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;据悉，腾讯混元 3D 生成模型已应用于 UGC、商品素材合成、游戏 3D 资产生成等场景。在游戏业务中，大模型生成的 3D 模型已能满足部分游戏 3D 资产标准，包括几何布线合理性、贴图准确性与骨骼蒙皮合理性等要求。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339557</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339557</guid>
            <pubDate>Wed, 05 Mar 2025 06:16:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>苏州：做强 AI 芯片骨干核心企业</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;《苏州市加快发展 AI 芯片产业的若干措施（征求意见稿）》公开征求意见。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中提到，充分用好人工智能产业专项母基金，重点投向本土拥有关键核心技术、发展潜力大的 AI 芯片创新型企业，撬动社会资本投向 AI 芯片领域，支持 AI 芯片企业原始创新和成果转化。加强与国家、省集成电路产业投资基金对接，争取各级基金资源支持苏州市 AI 芯片产业发展。重点支持 AI 芯片领域专精特新企业、高新技术企业进入上市后备企业库，实施重点培育。积极落实集成电路企业税收优惠政策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中提到，做强骨干核心企业。聚焦 GPU 通用型芯片、ASIC 专用型芯片、FPGA 半定制化芯片、存算一体芯片、硅光芯片等重点方向，加大招商力度，加快引育一批带动性强的优质项目、头部企业，对重点项目在空间保障、场地建设、人才引进等方面予以综合支持。推动 AI 芯片企业通过兼并重组等方式提升资源整合能力，向产业链上下游布局拓展业务，对优质 AI 芯片企业开展并购重组，鼓励县级市（区）对企业实施兼并重组给予奖励。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;228&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-41c7faa9ce5f67f92cbd0c08e8362ea840e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;苏州市加快发展 AI 芯片产业的若干措施&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;（征求意见稿）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;为抢抓人工智能技术快速迭代发展机遇期，充分发挥我市半导体与集成电路产业基础优势，加快推动 AI（人工智能）芯片产业创新突破、集聚成势，结合我市产业发展实际，制定本措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;一、做强骨干核心企业。&lt;/strong&gt;聚焦 GPU 通用型芯片、ASIC 专用型芯片、FPGA 半定制化芯片、存算一体芯片、硅光芯片等重点方向，加大招商力度，加快引育一批带动性强的优质项目、头部企业，对重点项目在空间保障、场地建设、人才引进等方面予以综合支持。推动 AI 芯片企业通过兼并重组等方式提升资源整合能力，向产业链上下游布局拓展业务，对优质 AI 芯片企业开展并购重组，鼓励县级市（区）对企业实施兼并重组给予奖励。对 AI 芯片企业获评制造业单项冠军、国家专精特新「小巨人」，分别给予 100 万元、40 万元奖励。对获得认定的 AI 芯片高新技术企业，给予最高 100 万元支持。（责任单位：市工信局、市科技局、市发改委、市委人才办，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;二、布局建设创新平台。&lt;/strong&gt;围绕 AI 芯片重点方向，加快构建龙头企业牵头、高校院所支撑、各创新主体相互协同的创新联合体，给予最高 200 万元运营经费支持。鼓励围绕 AI 芯片技术研发、成果转化等关键环节，建设 AI 芯片科技公共技术服务平台，对新建平台按总投资的 20% 给予最高 2000 万元支持。对为 AI 芯片设计企业提供 EDA 工具、系统级芯片（SoC）设计服务、多项目晶圆（MPW）、功能模拟、测试验证、「芯机」联动、快速封测、人才培训等专业化服务的平台，按照平台为本地企业提供服务收入的 20%，给予最高 300 万元奖励。（责任单位：市科技局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;三、集聚高端芯片人才。&lt;/strong&gt;聚焦 AI 芯片领域，大力引进培养处于人工智能领域科技前沿和国际一流水平，掌握关键核心技术，能够带来重大影响、重大突破的海内外人才，给予 3000 万元～1 亿元项目资助和 300 万元～1000 万元购房补贴。在苏州创新创业领军人才计划中，每年专设 100 个左右「人工智能专项」名额，特别优秀的可突破学历、来苏州时间等限制，给予 100 万元～500 万元项目资助和 100 万元～200 万元购房补贴。对入选苏州市重点产业紧缺人才计划的人才，给予最高 30 万元薪酬补贴。推动建设集教育、培训及研究为一体的产学研融合协同的集成电路产业人才公共实训基地，在 AI 芯片领域打造全产业链高技能人才团队。（责任部门：市委人才办、市科技局、市人社局、市教育局、市工信局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;四、实现关键技术突破。&lt;/strong&gt;梳理编制 AI 芯片关键核心技术清单，鼓励企业开展芯片架构、制程工艺、计算加速、异质集成、数据中心光模块等技术研究，对关键核心技术攻关项目给予最高 1000 万元支持。支持 AI 芯片设计企业开展拥有自主知识产权的工程流片验证，对首次流片、光罩制作以及测试验证等费用给予最高 50% 支持，工艺制程 12nm 以上的产品最高支持 500 万元，12nm 及以下的产品最高支持 1000 万元，鼓励有条件的县级市（区）给予联动支持。鼓励 AI 芯片企业提出技术需求，吸引国内外创新主体揭榜攻关，加快突破制约产业发展的技术瓶颈。（责任单位：市科技局、市工信局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;五、支持开展标准研制。&lt;/strong&gt;健全 AI 领域技术创新、专利保护与标准化互动支撑机制，推动创新成果的知识产权化和技术标准化，为 AI 芯片技术专利申请、软件著作权登记提供便利化服务。发挥行业协会和标准化机构作用，支持 AI 芯片龙头企业、重点院校、科研机构主导和参与 AI 芯片行业标准制定（修订），经主管部门认定后，按相应政策给予支持。支持组建芯片领域高价值专利培育中心，对成效明显的给予奖励。（责任部门：市市场监管局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;六、推进重点产品量产。&lt;/strong&gt;围绕数据中心、计算机视觉、智能网联车、智能机器人、智能语音等主要应用领域，结合关键技术清单，鼓励创新主体通过产学研合作等方式推进重点产品规模化批量生产。对 AI 芯片 IDM（垂直整合制造模式）企业开发创新产品列入省重点推广应用新技术新产品目录的，给予一次性奖励 50 万元。在苏州市科技成果转化专项中对 AI 芯片企业给予倾斜支持，加快 AI 芯片重大创新产品培育，每个项目给予最高 2000 万元支持。鼓励支持保险机构探索 AI 芯片定制化保险产品，为企业研发、生产、销售等各环节提供保险保障。（责任单位：市工信局、市科技局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;七、加快产业协同联动。&lt;/strong&gt;鼓励 AI 芯片设计企业与制造企业开展合作，支持封测企业扩大 AI 芯片产品布局。对为苏州市 AI 芯片设计企业自主研发产品提供生产线产能，并生产符合一定条件产品的集成电路制造、封测企业，按每款产品订单实际生产费用的 10% 最高给予 300 万元奖励。对使用本地企业 AI 芯片产品的终端厂商、系统方案集成商、算力中心，按当年使用金额的 10% 给予奖励，单个企业最高奖励 100 万元。对认定为省级、苏锡常首台（套）重大装备的半导体设备企业，分别给予 80 万元、50 万元奖励。对首年度生产销售重点新材料首批次应用示范指导目录内同品种、同技术参数的半导体新材料产品企业给予 50 万元奖励。组织开展「芯片—整机」「芯片—材料设备」等产业链上下游供需联动和产业对接，增强产业链协作能力。（责任单位：市工信局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;八、开放规模应用场景。&lt;/strong&gt;鼓励政府机关、企事业单位开放应用场景，支持 AI 芯片企业积极参与政务服务、交通、环衞、公共安全、教育、医疗健康等领域应用，加快 AI 芯片产品新技术迭代、新产品应用、新场景落地，培育打造具有典型意义的标杆案例。构建芯片测评标准和适配认证体系，加速 AI 芯片在智算中心训练、推理等场景的规模化应用。鼓励 AI 芯片企业整合行业资源和高质量数据，针对场景需求开展 AI 芯片产品开发，形成可复制可推广的解决方案。（责任单位：市数据局、市交通局、市城管局、市公安局、市教育局、市衞健委、市工信局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;九、着力强化金融支撑。&lt;/strong&gt;充分用好人工智能产业专项母基金，重点投向本土拥有关键核心技术、发展潜力大的 AI 芯片创新型企业，撬动社会资本投向 AI 芯片领域，支持 AI 芯片企业原始创新和成果转化。加强与国家、省集成电路产业投资基金对接，争取各级基金资源支持我市 AI 芯片产业发展。重点支持 AI 芯片领域专精特新企业、高新技术企业进入上市后备企业库，实施重点培育。积极落实集成电路企业税收优惠政策。（责任单位：市委金融办、市财政局、国家金融监管总局苏州分局、苏创投，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;十、打造多元产业生态。&lt;/strong&gt;发挥「人工智能+」城市政策牵引作用，加快构建 AI 芯片设计企业、大模型推理及训练企业、智算及数据中心及终端应用企业深度合作生态。支持龙头企业牵头组建 AI 芯片行业生态联盟，举办产业链上下游对接交流活动，为企业搭建沟通平台。鼓励 AI 芯片领域行业联盟、行业协会、智库单位等行业组织加强能力建设，为行业提供专业化服务。搭建高层次交流合作平台，鼓励开放创新与全球合作，支持打造 AI 芯片领域品牌展会和论坛等活动。（责任单位：市发改委、市科技局、市工信局、市商务局，各县级市&amp;lt;区&amp;gt;人民政府&amp;lt;管委会&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;本文件所指 AI 芯片企业是在苏州依法登记注册，以 AI（人工智能）芯片设计、制造、封测等为主营业务的企业。本文件由苏州市人民政府负责解释，具体解释工作由市工业和信息化局会同相关部门承担。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;本文件自 2025 年 X 月 X 日起施行，有效期至 2027 年 12 月 31 日。各部门政策所涉及资金按原渠道和财政体制要求落实。同一事项或项目符合市级财政多个支持政策的，均按照「就高、不重复」原则予以支持，不得重复申报。执行期间如遇上级有关政策规定调整的，从其规定。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339556</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339556</guid>
            <pubDate>Wed, 05 Mar 2025 06:10:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>MCP 有望引入新的数据传输方式：Streamable HTTP</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;MCP (Model Context Protocol) 是 Anthropic 开源的&amp;nbsp;「模型上下文协议」，该协议支持将大模型直接连接至数据源，官方介绍称 「可无缝集成 LLM 应用程序和外部数据源」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/115746_nnq5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;近日，开发者在 MCP 的 GitHub 仓库提交了一个希望采用&quot;Streamable HTTP&quot;传输代替「HTTP+SSE」的 PR，以解决当前远程 Model Context Protocol (MCP) 传输方式的关键限制，同时保留其优势。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1584&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/115359_va3x_2720166.png&quot; width=&quot;2476&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fspecification%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/specification/pull/206&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;简单来说，&lt;strong&gt;Streamable HTTP&amp;nbsp;改变了 MCP 的数据传输方式&lt;/strong&gt;，让协议变得：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更灵活&lt;/strong&gt;（支持流式传输，但不强制）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更易用&lt;/strong&gt;（支持无状态服务器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更兼容&lt;/strong&gt;（适用于标准 HTTP 基础设施）&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;💡 &lt;strong&gt;简单比喻&lt;/strong&gt;： 原来的 MCP 传输方式就像是&lt;strong&gt;你和客服通话时必须一直保持在线&lt;/strong&gt;（SSE 需要长连接），而新的方式更像是&lt;strong&gt;你随时可以发消息，然后等回复&lt;/strong&gt;（普通 HTTP 请求，但可以流式传输）。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;主要变更&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 /sse 端点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器不再单独维护 SSE（Server-Sent Events）端点。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;所有客户端 → 服务器的消息都通过 /message 端点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任何数据传输都通过 &lt;strong&gt;/message&lt;/strong&gt; 进行，不再依赖 /sse。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;服务器可以选择升级请求为 SSE&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可以根据需要&lt;strong&gt;动态升级 HTTP 请求为 SSE 流&lt;/strong&gt;，用于发送通知或请求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;客户端通过 Header 提供 Mcp-Session-Id&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可选是否需要存储 Session 信息，但客户端始终发送 Mcp-Session-Id 头部信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持无状态（Stateless）服务器&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可选择完全无状态运行，不再需要维持长期连接。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;变更的动机&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;当前的 &lt;strong&gt;HTTP+SSE 传输&lt;/strong&gt; 存在以下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;不支持可恢复性&lt;/strong&gt;（Resumability）：连接断开后，客户端必须重新开始整个会话。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;服务器需要维持长期连接&lt;/strong&gt;（High Availability Requirement）：服务器必须保持高可用性，以支持持续的 SSE 连接。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SSE 仅支持服务器 → 客户端消息&lt;/strong&gt;，无法灵活进行双向通信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新的「Streamable HTTP」传输方式解决了这些问题，并增强了系统的可扩展性和灵活性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339546/mcp-streamable-http-transport</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339546/mcp-streamable-http-transport</guid>
            <pubDate>Wed, 05 Mar 2025 04:03:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>