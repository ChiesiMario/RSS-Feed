<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 28 Jul 2025 07:44:43 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>一次线上生产库的全流程切换完整方案</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一、现状梳理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#1b1b1b"&gt;本篇介绍了一次数据库迁移的完整方案。 本次需要改造的系统为一个较为陈旧的技术栈系统，其中 MongoDB 作为核心数据存储中间件，承担着存储全部核心数据的重要任务。该系统目前的配置为 1 主 1 副本模式，涉及 1 个数据库和 2 张表，服务于 7 个不同的应用。尽管系统架构相对简单，但其在日常运营中发挥着不可或缺的作用。目前需要将 MongoDB 存储在其它介质中，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;如何能够保障在不影响线上使用的情况下，平滑切流到新库，是本文主要探讨的问题。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;二、迁移方案&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.1 迁移节奏&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;整体节奏分为 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.梳理范围，因为系统内不仅有 mongo 还同时有 mysql 数据源，需要梳理出使用 mongo 的所有业务范围&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.确定好原有的数据，应该存储在哪个介质中，确定好存储标准，需要能够 cover 住原有的所有业务，包括读写性能&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.对原有数据结构的 DAO 层进行改造&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.需要对数据进行双写并进行数据迁移&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5.R2 流量验证/测试回归/数据比对，进行验证&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6.切量:放量节奏&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//9c521ae700f248187c51d3a8d671c1b2.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.2 代码改造/数据异构&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;采用装饰器模式，统一控制双写逻辑（主写，辅写），统一控制切量逻辑，下线逻辑，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;抽取代码中原有的直接调用底层 mongodb API 的代码，将其不改业务逻辑的情况下迁移到 Dao 层。这样做的目的是为了后续做切流适配逻辑。不改逻辑及出入参的目的是为了避免对当前业务造成影响。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;选用数据源的依据为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;table style="width:auto"&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特性&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;JimKV&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HBase&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;优势&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 支持多存储引擎（SSD、AEP）- 基于 Raft 协议的强一致性和多机房容灾&amp;lt;br&amp;gt;- 完善的运维监控和弹性伸缩能力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 支持 PB 级别的存储容量- 云原生架构，支持单集群和主备集群&amp;lt;br&amp;gt;- 高吞吐性能，适合写密集型应用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;劣势&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 由于 Raft 协议，写性能低于 JimDB&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 故障恢复时间较长，约 1—2 分钟&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;适用场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 数据一致性和可靠性要求高- 数据存储量大- 读流量大于写流量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 存储量非常大（PB 级别）- 写密集且性能要求高的场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技术选型推荐理由&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- JimKV 满足存储量和吞吐量要求- 数据一致性和可靠性优于 HBase&amp;lt;br&amp;gt;- 适合读流量大于写流量的应用场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 适用于存储量极大的场景，但对一致性要求较高的场景不如 JimKV 适合&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基于以上原则,我们选用 JImKV(京东自研中间件)，Mysql 和 ES 作为 MongoDB 的替换的数据源，数据源切换 Dao 层的改造方式如下:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//6ff6bf2db84b30c9647b44e6897c3ac4.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.3 存量数据迁移&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;table style="width:auto"&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style="border-right-width:3px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;方案 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td style="border-right-width:3px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是否可实现 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td style="border-right-width:3px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;难度 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用大数据抽数任务 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;易 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用代码异步任务的方式 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;易 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DRC 同步 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从 mongo 到数据库不支持 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;略 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;考虑整体的数据量并不大单表 300w，通过大数据离线表的方式效率并不高，通过代码更加的灵活，可以随时调整速度和范围存量数据分了两部分 1、已经审核通过，申请单不会在有任何变更，可以随时迁移，比对 2、申请单处于过程中的数据，数据随时会变更。凌晨迁移，打开双写&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//91a580b4c7abb945ed8ae09b7f133e05.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.4 增量数据同步&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;创建申请单和更新不包含状态字段时的操作&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;先写 mongo 再写 mysql，以 mongo 写入成功为准，写 mysql 失败，mq 异步补偿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//679cdd023e610819ec4e401dacf3fc3f.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//d3c5ff84534b7d9e63485fe3d2d44ff1.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;三、上线三板斧 (灰度/监控/回滚)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本章节主要探讨在进行数据迁移和代码改造这些基础工作完成之后，如何保障上线没有线上问题，如何保障平滑切流和听写，工作主要聚焦于上线三板斧，可灰度，可回滚，可监控等方面，具体工作如下:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.1 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可监控 (数据对比读逻辑)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;增量数据比对&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;双写数据完成后发送 MQ，消息里面查询新库，老库的数据进行实时比对，不一致数据记录不一致字段，关键字业务报警，写入日志文件，导出分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;存量数据比对&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;遍历全量老库数据，与新库查出数据，转换成相同对象对比数据一致性，异常数据写入日志文件分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//323083f471a4d392ba9790f91ec33d9c.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.2 可监控 (对比读逻辑)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对比逻辑，引入 R2 流量回放对比，提高对比速度，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//1c840436e0907bc578b21dba45f08b9e.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.3 可灰度 (灰度切量读)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;读切流，按照供应商和采销白名单+百分比来切流&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//0c6295902850262dbf5645c3587ab417.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;切流时，由于需要根据 pin 对流量分散，但是不在同一线程内，使用 threadlocal 对商户信息进行设置和读取&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//afb0c666bda5295ebd776e317bdc9b2e.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.4 可回滚 (灰度切量写)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;写切流，分为四步&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.首先验证，写新库没问题，相当于对新加代码进行灰度，如果有问题，进行回切&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.当验证写新库没问题，需要补齐数据库数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.当数据补齐后，转换为主写新库&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.后续如果读写新库都没问题，可以彻底下线旧库存&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//640fe93d584fd444cf2dc85e46c6935e.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;四、总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#24292f"&gt;本文详细梳理了线上生产环境的全流程，包括迁移和切换的灰度方案对比。在数据源选型方面，根据实际业务需求选择合适的中间件是整个工作的基石。在代码改造和数据异构方面，选择恰当的设计模式和合理的架构方案是关键所在。存量数据迁移和增量数据同步是不可或缺的步骤。上线过程中，确保系统具备可监控、可回滚和可灰度的能力，是实现平滑切换的保障。欢迎各位同学与我交流探讨。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18685920</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18685920</guid>
      <pubDate>Mon, 28 Jul 2025 07:35:41 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>WAIC 首日 | RWKV-7s 新型高效大模型架构正式亮相</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 26 日，RWKV 携全球领先的大模型架构 RWKV-7 亮相 2025 世界人工智能大会暨人工智能全球治理高级别会议（以下简称 " WAIC 2025"），并首次公开了 RWKV-7s 架构。元始智能作为企业代表向国务院总理李强、上海市委书记陈吉宁介绍 RWKV 架构、生态和产业化近况。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="元始智能 COO&amp;amp;Co-Founder 罗璇向总理介绍 RWKV" src="https://oscimg.oschina.net/oscnet/up-45e836f5402788bffce489a460ee6b3d3db.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV 系列是全球领先的 RNN 大模型架构。其中 RWKV-7 在 RNN 架构中效率和效果世界领先。在大会首日，我们，公开了系列首个混合架构 ------ RWKV-7s。&lt;/p&gt; 
&lt;p&gt;RWKV-7s 是承接 RWKV-7 优势的 RNN + DEA（独创的 DeepEmbedAttention）新型高效大模型架构，KV cache 仅为 MLA 的 1/9 大小，兼具高效计算与强长文本性能，可适配多模态、智能体等多种应用场景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6093fc2663a245aa49e3f9e392d74cc2be8.jpg" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e6724a19136a358f0e45e7a6be8d4e63eec.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在了解 RWKV 架构作为底层技术的创新性及可为人工智能行业带来的新机遇后，李强总理给予了宝贵的指导意见，并鼓励更多 AI 从业者关注底层技术，解决更多的基础问题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="李强总理亲临 RWKV 展位指导" src="https://oscimg.oschina.net/oscnet/up-4cd734102525efae518e5c422c4f656bcea.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最后预告，纯 RNN 的 RWKV7-G0 7B 已经可以解决一些 AIME（美国数学竞赛）题，我们稍后会发布详细测试结果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math" src="https://oscimg.oschina.net/oscnet/up-378ee71ccfc10efe46f40849c447a30d72e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不仅如此，修改后的题目也能做对（将原题的 3(n+3) 修改为 2(n+3)）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math" src="https://oscimg.oschina.net/oscnet/up-a9f2f1025f4451640b8545d0ceb14baf43c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;WAIC 展览还有三天，欢迎大家在 7 月 27 日至 29 日亲临 RWKV 展位，与我们共同探讨人工智能行业发展的更多可能！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;地点：上海世博展览馆&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主展位：1 楼中庭，H2-2 门前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展位一：H3-D701&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展位二：H4-FT305&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362721</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362721</guid>
      <pubDate>Mon, 28 Jul 2025 07:24:41 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>​三星与特斯拉达成 165 亿美元 AI 芯片供应协议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;韩国科技巨头三星电子宣布与电动车制造商特斯拉达成了一项重大的合作协议，成为其 AI 芯片的主要供应商。这项价值高达 165 亿美元的交易，是三星与单一客户之间最大的订单。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="405" src="https://oscimg.oschina.net/oscnet/up-cce85318480efbbe05ec700e087771c01f4.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;随着人工智能技术的迅速发展，对高性能芯片的需求也不断增加。特斯拉在自动驾驶和智能汽车领域的布局，需要先进的 AI 芯片来提升其车辆的智能化水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;三星近年来一直在努力扭转其合同芯片制造业务的下滑趋势。通过与特斯拉的合作，三星不仅可以获得稳定的订单，还能进一步巩固在全球半导体市场的地位。这一协议的签署，预计将为三星带来可观的收入，并帮助公司在技术研发方面进行更多投资。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;特斯拉与三星的合作不仅局限于芯片供应，双方还计划在未来的研发中进行更深层次的技术交流。特斯拉希望借助三星的技术优势，加速其在电动汽车和智能驾驶领域的创新步伐。同时，三星也希望通过这次合作，获取特斯拉在汽车领域的最新需求和技术趋势，以提升自身产品的市场竞争力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这一合作协议对双方来说都具有重要的战略意义。特斯拉在 AI 技术领域的进步，将会依赖于三星提供的高效能芯片，而三星则能借此机会重塑自身在半导体行业的形象，迎接未来更大的挑战。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362720</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362720</guid>
      <pubDate>Mon, 28 Jul 2025 07:20:41 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>京东将大模型品牌正式升级为 JoyAI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;京东集团正式宣布将其大模型品牌升级为 JoyAI。此次升级的 JoyAI 大模型体系支持 3B 到 750B 全尺寸模型，具备语言、语音、图像、视频、数字人等多模态交互能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;通过动态分层蒸馏、跨领域数据治理等技术，其推理效率平均提升 30%，训练成本降低 70%。在零售领域，京东立影「秒搭」平台可 3 分钟生成 3D 内容，京点点 AIGC 平台实现商品图、文案、视频的快速生成；推出的高商业可用数字人具备逼真形象与自然动作，情感表达与场景适配能力超越 80% 真人主播，支持 24 小时不间断直播，成本仅为真人直播的十分之一，目前已有 20000 余个品牌采用其进行直播带货。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="443" src="https://oscimg.oschina.net/oscnet/up-12fa4d7a1eca57443933396144af5111c04.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;京东同步推出附身智能品牌 JoyInside，通过接入 JoyAI 大模型为机器人、玩具等终端设备注入高情商交互能力，支持角色定制与多场景应用。该品牌已与十余家头部机器人、AI 玩具品牌合作，产品涵盖快递机器人、机器狗、AI 潮玩及儿童陪伴 AI 伙伴等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，京东云正式开源行业首个 100% 企业级智能体 JoyAgent，其融合多智能体协同引擎与大小模型优势，支持高效协作与动态任务执行，具备高可用性、高性能及灵活适配特性。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362716</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362716</guid>
      <pubDate>Mon, 28 Jul 2025 07:08:41 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>WAIC 2025 速览：史上最大规模、学术顶流参会、具身智能&amp;机器人成热门版块</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;刚刚过去的周六，史上最盛大的一届世界人工智能大会（WAIC 2025）正式开幕！&lt;/p&gt; 
&lt;p&gt;今年大会不仅把重量级学术大佬「深度学习三巨头」之一、2018 年图灵奖得主、2024 年诺贝尔物理学奖得主杰弗里·辛顿都请到开幕式做演讲，连展会都是前所未有的爆场。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0728/150438_LvlE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是 WAIC 2025 亮点速览：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;史上最大规模：7 万㎡展区、800+企业、40+大模型、50+AI 终端、60+机器人、80+全球首发/中国首秀。&lt;/li&gt; 
 &lt;li&gt;学术顶流：图灵奖&amp;amp;诺奖双料得主 Geoffrey Hinton 开幕式演讲。&lt;/li&gt; 
 &lt;li&gt;门票爆火：168 元单日票被炒至 2000+。&lt;/li&gt; 
 &lt;li&gt;主题关键词：应用为王——全部可上手、可互动、可落地。&lt;/li&gt; 
 &lt;li&gt;参展方阵 
  &lt;ul&gt; 
   &lt;li&gt;国内大厂：华为、腾讯、阿里、蚂蚁、百度、联想、京东、快手、网易、中兴、三大运营商、理想、吉利等。&lt;/li&gt; 
   &lt;li&gt;国际巨头：谷歌、AWS、特斯拉、西门子、施耐德、希捷、思科等。&lt;/li&gt; 
   &lt;li&gt;AI 明星公司：商汤、讯飞、第四范式、阶跃星辰、MiniMax、智谱、月之暗面 Kimi、面壁智能等。&lt;/li&gt; 
   &lt;li&gt;缺席：字节跳动（豆包等）、百川、零一万物。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;三大热门板块 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;具身智能&amp;amp;机器人&lt;/strong&gt;：特斯拉 Bot、宇树拳击秀、智元/云深处等 20+ 新品；H3 馆单馆展出 63 款机器人、208 台人形/轮式、56 条机器狗。&lt;br&gt; &lt;br&gt; &lt;img src="https://static.oschina.net/uploads/space/2025/0728/150232_l7FK_2720166.png" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;智能硬件&lt;/strong&gt;：阿里夸克 AI 眼镜、中兴「麻薯」AI 萌宠、XREAL/Rokid 等旗舰 AR 眼镜、联想/讯飞 AI PC。&lt;br&gt; &lt;br&gt; &lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0728/150158_naTS_2720166.png" width="1000" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;AI 基础设施&lt;/strong&gt;：华为升腾 384 超节点领衔，20+ 国产 AI 芯片公司（摩尔线程、燧原、曦智等）及联想、浪潮、新华三等智算厂商同台，玻色量子、国盾量子等量子计算企业也亮相。&lt;br&gt; &lt;br&gt; &lt;img src="https://static.oschina.net/uploads/space/2025/0728/150354_lqDc_2720166.png" referrerpolicy="no-referrer"&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt;彩蛋展区：H2 馆「中国 AI 产业创新成果展」——中国 5170 家 AI 企业占全球 15%，独角兽 71 家占 26%，并展出全球大模型演进图及国产 AI 芯片/加速卡全景。&lt;br&gt; &lt;br&gt; &lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0728/150126_yNkU_2720166.png" width="1000" referrerpolicy="no-referrer"&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;来源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoeyURi8YKLxud2t_BV9Jyg" target="_blank"&gt;https://mp.weixin.qq.com/s/oeyURi8YKLxud2t_BV9Jyg&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362714</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362714</guid>
      <pubDate>Mon, 28 Jul 2025 07:05:41 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软即将发布 Visual Studio 重大升级，应对 AI 编程工具激烈竞争</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;尽管微软向客户提供了 Visual Studio Code 这款轻量级但功能强大的开源代码编辑器，但其旗舰开发环境实际上是原生版 Visual Studio。这是一个功能齐全的集成开发环境 (IDE)，具有 .NET 集成和其他功能，使其更适合复杂的项目管理。现在，一份新报告显示，微软正计划对 Visual Studio 进行重大升级。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/194445_SAV6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;媒体&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-plans-major-update-visual-studio-coding-service-ai-2025-7" target="_blank"&gt;Business Insider&lt;/a&gt;&amp;nbsp;看到了一份微软内部备忘录，其中详细介绍了该公司计划发布 Visual Studio 的重大升级。不出所料，此次更新将重点关注人工智能 (AI)，这对于与亚马逊 Kiro 等其他竞争对手竞争至关重要，亚马逊 Kiro 被誉为基于 AI 的 IDE。&lt;/p&gt; 
&lt;p&gt;这份备忘录由杰伊·帕里克（Jay Parikh）于今年 4 月撰写，他加入微软不到一年，担任执行副总裁（EVP）。帕里克领导着公司的 CoreAI 部门，该部门负责开发人员工具，因此 Visual Studio 恰好属于这位高管的职责范围。&lt;/p&gt; 
&lt;p&gt;Parikh 的备忘录将这次主要版本称为「Visual Studio 18」，考虑到 Visual Studio 目前使用的是 17 版，这颇具趣味。该 IDE 上个月发布了更新，允许开发人员访问更强大的 AI 模型，同时灵活地管理计费。值得注意的是，Visual Studio 的上一次重大更新是在 2021 年，当时微软发布了 Visual Studio 2022 和 .NET 6，因此再次发布主要版本也是合情合理的。&lt;/p&gt; 
&lt;p&gt;话虽如此，虽然 Visual Studio 的下一次重大升级有可能在今年推出，但目前尚未公布具体的时间表。备忘录还指出，这个由人工智能驱动的 IDE 版本目前正处于「早期内部测试」阶段，这意味着微软自己的员工正在积极地使用它进行测试。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362407</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362407</guid>
      <pubDate>Fri, 25 Jul 2025 11:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌短链接服务「goo.gl」将于下个月正式停用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Google 将于下个月正式弃用其网址缩短工具生成的链接。自 2025 年 8 月 25 日起，所有「&lt;span style="color:#2980b9"&gt;&lt;em&gt;https://goo.gl/*&lt;/em&gt;&lt;/span&gt;」格式的链接将不再有效，并返回 404 错误信息。&lt;/p&gt; 
&lt;p&gt;Google 于 2019 年关闭了其网址缩短服务，理由是「我们发现人们在互联网上查找内容的方式发生了变化」。此后，使用该工具创建的链接仍然有效，但 Google 去年宣布，随着缩短网址流量的下降，将开始弃用这些服务。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3de2e977a212c4b76a27a10e76c003b1a75.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Google 在其&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F" target="_blank"&gt;2024 年 7 月的博客文章&lt;/a&gt;中表示：「事实上，超过 99% 的缩短网址在过去一个月内没有任何活动。」&lt;/p&gt; 
&lt;p&gt;当时，Google 还开始在用户点击缩短的网址时显示一个警告页面，提示「此链接近期将不再有效」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bd067dfa47ef36f85743afb32cf6824b04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;距离「goo.gl」链接关闭仅剩一个月时间，如果您还没有将网址转换到其他缩短服务，现在正是转换的好时机。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362402</guid>
      <pubDate>Fri, 25 Jul 2025 11:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV7-G0 7.2B 发布，最强纯 RNN 推理模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 22 日， &lt;strong&gt;RWKV7-G0 7.2B 推理模型&lt;/strong&gt;（Reasoning Model）正式开源发布，它很可能是迄今为止人类训练过的最强纯 RNN 语言模型。&lt;/p&gt; 
&lt;p&gt;RWKV7-G0 7.2B 是在 RWKV6-World-V3-7.6B 的基础上训练 2T tokens 的纯预训练模型，但在预训练加入了大量指令/对话/推理数据，可以解决各种推理问题。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果需要后训练和对齐，最适合 RNN 的方式是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fadvanced%2FFine-Tune%2FRWKV-PEFT%2FState-Tuning" target="_blank"&gt;state-tuning&lt;/a&gt;，直接微调 RNN 的初始状态，相当于终极 context engineering。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型客观指标评测&lt;/h2&gt; 
&lt;h3&gt;英语和多语言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的基础英语和多语言能力&lt;strong&gt;均强于同规模的开源模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval" src="https://oscimg.oschina.net/oscnet/up-3961b82f0302bbedafaae3e26ce721fe159.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;得益于架构和数据的提升，RWKV7-G0 7.2B 的 MMLU 准确度为 62.7%，显著超过 RWKV6-World-V3-7.6B 的 54.2%。后续我们会发布训练 8T tokens 的满血 RWKV7-G1 7.2B，目标是 MMLU 达到 70%，看齐前沿模型。&lt;/p&gt; 
&lt;h3&gt;无法作弊的评测&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval" target="_blank"&gt;Uncheatable Eval&lt;/a&gt; 是"无法作弊的评测"，它使用最新的论文和新闻文章等实时数据，评估开源大语言模型的真实建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的 Uncheatable Eval 同样显著提升，满血 8T tokens 预计超越 Llama3 8B（这里测试 2024-07 数据，后续会测新数据，并对比 Qwen2.5、Qwen3）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="uncheatable-eval" src="https://oscimg.oschina.net/oscnet/up-00ee915e6a6642e230984bbad95c7adda04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;模型实战：解数学题&lt;/h2&gt; 
&lt;p&gt;我们发现，RWKV7-G0 7.2B 解数学题可使用 &lt;code&gt;temperature top_p penalty&lt;/code&gt; 解码参数都为 0 的纯贪心解码，且无限复读现象较少。&lt;/p&gt; 
&lt;p&gt;但贪心解码会导致推理过程探索度不足，因此可引入随机性，例如 &lt;code&gt;temperature=0.3 top_p=0.3 penalty=0&lt;/code&gt;。模型会自动进行多轮验算（类似 rollout），并可以自我纠错。&lt;/p&gt; 
&lt;p&gt;那么 &lt;code&gt;temperature=0.6 top_p=0.6 penalty=0&lt;/code&gt; 等随机性更高的参数是否更好，后续我们会通过参数扫描实验评估。&lt;/p&gt; 
&lt;p&gt;例子，第一题：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math1" src="https://oscimg.oschina.net/oscnet/up-0cd8d78f631ee7405c4bbca2340892aa1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改题目表述，模型换了种做法：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math2" src="https://oscimg.oschina.net/oscnet/up-dc97d5561c78acbb5117c3b214de082e7da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第二题，故意将原题的 99 改为 99.1，模型一开始看错，后来成功纠正了自己：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math3" src="https://oscimg.oschina.net/oscnet/up-e607d6ca88eb49ab4caf0e417262eb39b2b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第三题，原题是计算 1 的幂，改为计算 i 的幂，增加难度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math4" src="https://oscimg.oschina.net/oscnet/up-8d5d4f106fec7c3c72836c057b1de89bddd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第四题，原题是 2^8 = 4^x，改为 8^x 增加难度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math5" src="https://oscimg.oschina.net/oscnet/up-4d801cfa9f331b3dca71d086a3c05004e6c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第五题，原题的概率是 1/5，改为 1/4 测试模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math6" src="https://oscimg.oschina.net/oscnet/up-39c45f49e2a398f59a7dc87fde27cf46756.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第六题，原题是 one hat，改为 two hat（故意不加 s 复数形式）测试模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math7" src="https://oscimg.oschina.net/oscnet/up-2d56afb40928ffd13d17308fc41c6e56369.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第七题，模型有点懵，但反复验算多次后，成功确认了正确答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math8" src="https://oscimg.oschina.net/oscnet/up-7730c44785334a3421428c0e7dd153ed6ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;结论：【纯 RNN + 纯预训练】可以得到推理模型，而且它理解了一些解题方法，可以用不同方法解决修改过的题目。&lt;/p&gt; 
&lt;h2&gt;模型实战：写代码&lt;/h2&gt; 
&lt;p&gt;在此我们测试用户喜闻乐见的图像输出。生成一个有一只猫的 SVG 的网页：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code" src="https://oscimg.oschina.net/oscnet/up-06f4dbd1a7c9e178ed8408f93d7bb939c4d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用 Three.js 创建一个旋转的 3D 红色立方体（完整代码在文末的附录中）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code-1" src="https://oscimg.oschina.net/oscnet/up-5965c8a859ccc3bcc7f9db0d86caeb5f612.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;考虑到这是【纯 RNN + 纯预训练 + 只训练 2T tokens】，表现合理。后续更多数据的满血版会显著更强。&lt;/p&gt; 
&lt;h2&gt;RNN 的抗干扰能力&lt;/h2&gt; 
&lt;p&gt;最新论文 &lt;code&gt;Inverse Scaling in Test-Time Compute&lt;/code&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.14417%25EF%25BC%2589%25E5%258F%2591%25E7%258E%25B0%25E5%2589%258D%25E6%25B2%25BF%25E6%25A8%25A1%25E5%259E%258B%25E5%259C%25A8%25E2%2580%259C%25E6%2581%25B6%25E6%2584%258F%25E9%2597%25AE%25E9%25A2%2598%25E2%2580%259D%25EF%25BC%2588%25E4%25BE%258B%25E5%25A6%2582%25E5%25B8%25A6%25E5%25B9%25B2%25E6%2589%25B0%25E9%25A1%25B9%25E7%259A%2584%25E8%25AE%25A1%25E6%2595%25B0%25E3%2580%2581%25E5%25B8%25A6%25E8%2599%259A%25E5%2581%2587%25E7%2589%25B9%25E5%25BE%2581%25E7%259A%2584%25E5%259B%259E%25E5%25BD%2592%25E9%25A2%2584%25E6%25B5%258B%25EF%25BC%258C%25E7%25AD%2589%25E7%25AD%2589%25EF%25BC%2589%25E4%25BC%259A%25E5%2587%25BA%25E7%258E%25B0%25E8%25B6%258A%25E6%2583%25B3%25E8%25B6%258A%25E5%25B7%25AE%25E7%259A%2584%25E6%2583%2585%25E5%2586%25B5%25EF%25BC%259A" target="_blank"&gt;https://arxiv.org/abs/2507.14417）发现前沿模型在「恶意问题」（例如带干扰项的计数、带虚假特征的回归预测，等等）会出现越想越差的情况：&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Inverse Scaling in Test-Time Compute" src="https://oscimg.oschina.net/oscnet/up-6ae323b74fd47a196c5d2c1f9fa0e6eba61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们发现 RWKV7-G0 7.2B 可以克服干扰，得到正确答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test" src="https://oscimg.oschina.net/oscnet/up-ae61d209ca82eea02e344618caff2afca92.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;继续测试：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-1" src="https://oscimg.oschina.net/oscnet/up-514174dd1deab6244d08e752e541b0fd36e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改数字再测试：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-2" src="https://oscimg.oschina.net/oscnet/up-203991398541247ca9e64b89fa8da85280d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可见 attention 会导致 transformer 更易受前文干扰，而 RNN 在此有优势。而且 RNN 的思考过程永远匀速，不会越想越慢。我们未来训练更大的 RNN 会更有趣。&lt;/p&gt; 
&lt;h2&gt;模型下载&lt;/h2&gt; 
&lt;p&gt;下载 RWKV7-G0 7.2B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain" target="_blank"&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社区：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles" target="_blank"&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile" target="_blank"&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何使用 RWKV 模型&lt;/h2&gt; 
&lt;h3&gt;在线 demo（续写模式）&lt;/h3&gt; 
&lt;p&gt;可以在 RWKV 官方 Gradio 中试用 RWKV7-G0 7.2B 模型（为避免排队，这里限制了输入和输出长度）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank"&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Hugging Face Gradio 是续写模式，使用时需要遵循 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fbasic%2FPrompt-Format" target="_blank"&gt;RWKV 的 prompt 格式&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B &lt;strong&gt;不思考模式&lt;/strong&gt;的 QA prompt 格式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽干太平洋的水然后下去抓鱼吗？

Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如需开启&lt;strong&gt;思考模式&lt;/strong&gt;，可在 QA prompt 的基础上添加 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 标签：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽干太平洋的水然后下去抓鱼吗？

Assistant: &amp;lt;think&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;本地部署 RWKV 模型&lt;/h3&gt; 
&lt;p&gt;可以使用 RWKV Runner、Ai00、RWKV pip 等推理工具本地部署 RWKV 模型。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 模型也适配了 llama.cpp、ollama 等热门的模型推理工具。&lt;/p&gt; 
&lt;p&gt;由于 RWKV7-G0 7.2B 是新模型，目前建议使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate%2FRWKV-Runner%2FIntroduction" target="_blank"&gt;RWKV Runner&lt;/a&gt; 以保证得到正确结果。&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate" target="_blank"&gt;RWKV 官网 - 模型推理教程&lt;/a&gt;中查看上述推理工具的使用教程。&lt;/p&gt; 
&lt;h2&gt;未来训练计划&lt;/h2&gt; 
&lt;p&gt;我们也正在训练 RWKV7-G0 13.3B 模型，以及使用更多 tokens、使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;DEA&lt;/a&gt; 技术的 RWKV-7s 模型。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入 RWKV 论坛、QQ 频道和 QQ 群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 中文文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 论坛：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;QQ 频道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;BiliBili 视频教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;欢迎大家基于 RWKV-7 进行创业、科研，我们也会为基于 RWKV 的项目提供技术支持。&lt;/p&gt; 
 &lt;p&gt;如果您的团队正在基于 RWKV 创业或开展研究，请联系我们！（在「RWKV 元始智能」微信公众号留言您的联系方式，或发送邮件到「contact@rwkvos.com」。）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;附录：旋转的红色立方体&lt;/h2&gt; 
&lt;p&gt;将以下代码保存为 &lt;code&gt;3d.html&lt;/code&gt; 并双击运行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang="en"&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;meta charset="UTF-8"&amp;gt;
    &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&amp;gt;
    &amp;lt;title&amp;gt;Rotating Red Box&amp;lt;/title&amp;gt;
    &amp;lt;style&amp;gt;
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script&amp;gt;
        // Create scene
        const scene = new THREE.Scene();
        
        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;
        
        // Create renderer
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
        // Create box geometry and material
        const geometry = new THREE.BoxGeometry(1, 1, 1);
        const material = new THREE.MeshBasicMaterial({ color: 0xff0000 }); // Red color
        
        // Create box mesh
        const box = new THREE.Mesh(geometry, material);
        
        // Add lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(0, 0, 10);
        scene.add(light);
        
        // Add box to scene
        scene.add(box);
        
        // Animation loop
        let angleX = 0;
        let angleY = 0;
        
        function animate() {
            requestAnimationFrame(animate);
            
            // Update rotation angles
            angleX += 0.01;
            angleY += 0.01;
            
            // Update box rotation
            box.rotation.x = angleX;
            box.rotation.y = angleY;
            
            // Render scene
            renderer.render(scene, camera);
        }
        
        animate();
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362400</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362400</guid>
      <pubDate>Fri, 25 Jul 2025 10:54:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>谷歌 DeepMind 新架构 MoR 有望成为「Transformer 杀手」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 DeepMind 团队发表论文《Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation》，&lt;strong&gt;提出新 Transformer 架构 Mixture-of-Recursions（MoR）&lt;/strong&gt;，旨在同时实现参数共享和自适应计算，以解决大型语言模型训练和部署中的计算与内存开销问题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-17000d1f4f6bc815b75098237c70778d99f.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c76175988abdc82ca877e5b51ccc663dba8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/abs/2507.10524&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;MoR 的核心创新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;参数效率&lt;/strong&gt;：通过共享层堆栈在不同递归步骤中复用参数，减少参数量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;动态计算&lt;/strong&gt;：轻量级路由器为每个 token 动态分配递归深度，复杂 token 可深入处理，简单 token 可提前退出，从而将计算资源精准分配 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;内存优化&lt;/strong&gt;：采用递归级键值（KV）缓存机制，仅缓存活跃 token 的 KV 对，显著降低内存带宽压力并提升推理吞吐量 。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实验结果显示，在 135M 到 1.7B 参数规模的模型中，MoR 在相同训练计算量下，验证困惑度更低、少样本准确率更高，推理吞吐量相比传统 Transformer 和现有递归基线提升至多 2.18 倍，同时降低内存占用和推理延迟。&lt;/p&gt; 
&lt;p&gt;因此，MoR 被认为可能在无需承担大模型成本的情况下实现大模型质量，甚至被称为「Transformer 杀手」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362399</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362399</guid>
      <pubDate>Fri, 25 Jul 2025 10:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>三分之一美国人借助 AI 工具寻求职业转型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据东南俄克拉荷马大学（SOU）&lt;span&gt;最新&lt;/span&gt;发布的一项报告，约三分之一的美国人已开始使用 AI 工具，如 ChatGPT，来帮助他们进行职业转型。该报告基于对 1000 名来自四个不同世代的美国人的调查，旨在了解 AI 在当前美国劳动市场剧烈变化中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;调查显示，超过一半的受访者表示，他们正在积极考虑换工作或职业转型，其中以 Z 世代的 57% 比例&lt;span&gt;最高&lt;/span&gt;，随后是千禧一代的 55%，X 世代的 50%，以及仅 12% 的婴儿潮一代。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在那些表示 AI 对他们的职业转型有所帮助的受访者中，43% 的人使用 AI 工具撰写简历和求职信，47% 的人则利用 AI 进行新工作机会的研究，包括寻找薪资更高的职位。值得注意的是，近五分之一的受访者（18%）表示，AI 建议了他们之前未曾考虑过的全新职业路径。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不过，尽管有不少人依赖 AI 来提供职业建议，调查也显示大多数受访者对 AI 提供的信息持谨慎态度。60% 的受访者表示，他们更倾向于相信人类职业顾问的意见，而只有 7% 的人选择相信 AI。一部分人（17%）甚至选择遵循 AI 的建议，即使这些建议与他们之前从人类顾问那里得到的意见相悖。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在各年龄层中，受访者主要关注的职业机会集中在技术领域，其次是医疗和金融。随着 AI 技术的不断发展，许多人认为这可能导致大量白领职位的消失。例如，Anthropic 的首席执行官达里奥・阿莫德伊预测，AI 将在未来五年内消除一半的白领工作。而亚马逊首席执行官安迪・贾西也表示，AI 驱动的自动化将取代一些人类工作，同时使其他职位变得更加 「有趣」，并创造出全新的岗位。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技术公司招聘方面的数据也表明，随着 AI 工具开始接管许多原本由年轻、经验较少的员工完成的日常任务，科技公司对新近计算机科学毕业生的招聘数量有所减少。此外，在硅谷的激烈人才争夺战中，企业之间的竞争愈发激烈，特别是在人工智能研究方面的&lt;span&gt;顶尖&lt;/span&gt;人才更是稀缺。许多公司都愿意为此支付高额薪资，以吸引那些能够在技术突破中发挥关键作用的优秀研究人员。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362398</guid>
      <pubDate>Fri, 25 Jul 2025 10:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阶跃星辰发布最强开源多模态推理模型 Step3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;阶跃星辰宣布发布新一代基础大模型 Step3，主打多模态推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，这是阶跃星辰首个全尺寸、原生多模态推理模型。在国产芯片 32K 上下文推理效率最高可达 DeepSeek R1 的 300%，在英伟达 H800 芯片将推理效率提升了 70% 以上。该模型将于 7 月 31 日向全球开源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e93e689dafce5406835a7db40fe0043af4b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，阶跃星辰宣布与上海国有资本投资有限公司达成深度战略合作，并透露上海国投将参与阶跃星辰的新一轮融资。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;阶跃星辰创始人、CEO 姜大昕表示，阶跃的商业化的成果体现在了收入数字上，基于上半年的高速增长，公司将全年的冲刺目标定在 10 亿元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;会上，阶跃还将联合近 10 家芯片厂商和算力平台成立模新生态创新联盟。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362393</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362393</guid>
      <pubDate>Fri, 25 Jul 2025 10:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁数科发布金融推理大模型 Agentar-Fin-R1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;蚂蚁数科已正式发布金融推理大模型 Agentar-Fin-R1。该模型基于 Qwen3 研发，在 FinEval1.0、FinanceIQ 等权威金融评测基准上表现优异，超越同尺寸开源通用大模型及金融大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「通用大模型和产业之间仍存在知识鸿沟，尤其在金融领域。」蚂蚁数科 CEO 赵闻飙在大会上表示，构建专业金融大模型，是推动金融智能体真正落地的必由之路。这不仅是科技挑战，更直接关系金融机构在未来的智能竞争中是否拥有核心抓手。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研发团队为其构建了一套业内极为全面和专业的金融数据语料。一个覆盖了银行、证券、保险、基金、信托等全场景的金融任务体系，包含 6 大类、66 个细分场景，构成了业内最系统、最真实的金融数据集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;训练中还引入「原则类合成数据」，让模型天然遵守金融监管红线，比如数据合规、身份校验、反洗钱等细节。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-8d7c354e371db0062d5a9f25d7135f76029.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agentar-Fin-R1 采用了创新的加权训练算法，这就像一个聪明的学习方法，能够动态地发现模型的薄弱环节并针对性地进行强化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这样做的好处是，在后续的业务应用中，可以显著减少二次微调所需的数据和算力，有效降低了企业部署大模型的门槛和成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;评测结果显示，Agentar-Fin-R1 在金融基准测试中均取得最高评分。蚂蚁数科构建了全面的金融任务数据体系，覆盖银行、证券等全场景，通过可信数据合成技术显著提升模型处理复杂任务的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="231" src="https://oscimg.oschina.net/oscnet/up-a22dbbe5f4527d0a3bb44a2f3049557f6da.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-9f2fab555918f31a036c29c55510abeffde.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，Agentar-Fin-R1 推出了 32B 和 8B 两种参数版本，此外还有基于百灵大模型的 MOE 架构模型以及 14B 和 72B 的非推理版本，以满足不同机构和场景的部署需求。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362703</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362703</guid>
      <pubDate>Thu, 17 Jul 2025 06:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 中国版宣布停止服务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 27 日，由北京谋智火狐信息技术有限公司运营的 Firefox 中国版网站发布&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com.cn%2Ffarewell%2F" target="_blank"&gt;公告&lt;/a&gt;称，将于 2025 年 9 月 29 日后正式终止与 Mozilla 及 Firefox 浏览器相关的中国大陆运营。Firefox 浏览器将在中国大陆继续可用并保持全部功能。&lt;/p&gt; 
&lt;p&gt;根据公告中的背景说明，北京火狐原在中国大陆负责部分 Firefox 浏览器相关业务。2025 年 5 月 8 日，Mozilla 与北京火狐达成一致，北京火狐将不再运营 Firefox 浏览器及任何与 Firefox 有关的中国大陆业务。北京火狐将停止使用 Mozilla 授权的商标、版权及域名。同时，北京火狐将全力配合 Mozilla 确保用户的平稳过渡。后续 Mozilla 将自行或通过授权的第三方，继续在中国大陆负责 Firefox 浏览器及 Firefox 社区的相关运营。&lt;/p&gt; 
&lt;p&gt;公告称，自即日起，Firefox 火狐中文官方网站将不再提供 Firefox 浏览器的下载；中国专版的火狐通行证、火狐社区将不再接受新用户注册。自 9 月 29 日晚 24:00 起，火狐中文官方网站、火狐社区网站、火狐通行证账户服务及，火狐主页将正式停止运营，所有功能将终止。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img height="3258" src="https://static.oschina.net/uploads/space/2025/0728/112233_GG4l_2720166.png" width="1548" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362681/firefox-com-cn-farewell</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362681/firefox-com-cn-farewell</guid>
      <pubDate>Thu, 17 Jul 2025 03:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>无问芯穹发布终端本征大模型 Megrez 2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;无问芯穹联合上海创智学院（上海交通大学背景）正式发布终端本征智能大模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fws8N9Gov8MT65JFumcGZpQ" target="_blank"&gt;&lt;strong&gt;Megrez 2.0&lt;/strong&gt;&lt;/a&gt;（Megrez-2-3x7B-A3B-Preview）。&lt;/p&gt; 
&lt;p&gt;该模型通过终端本征架构，突破端侧「能效-空间-智能」不可能三角，在实现 &lt;strong&gt;21B&lt;/strong&gt; 参数（云端级智能水平）的同时，将实际计算量控制在 &lt;strong&gt;3B&lt;/strong&gt;、内存占用控制在 &lt;strong&gt;7B&lt;/strong&gt; 规模（INT4 量化下不足 4G 内存占用），适配各类终端设备 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-aa0ceca67088dab4c9dfe052153582592bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模型链接：https://www.modelscope.cn/models/InfiniAI/Megrez2-3x7B-A3B-Preview/summary&lt;/p&gt; 
&lt;p&gt;Megrez 2.0 采用重参数机制，将相邻 MoE 层分组复用专家参数，将总参数量从 21B 降至 7B，同时保持 21B 专家池空间，实现更高能效、更低内存和更强智能，其速度比同内存占用模型快 50%，精度比同尺寸稠密模型提升 36%，内存比同精度模型节约 75% 。&lt;/p&gt; 
&lt;p&gt;此外，Megrez 2.0 支持终端设备在「休眠时段」无感知地持续创造价值（如整理会议纪要），实现端侧级算力撬动云端级智能，推动 AI 智能体等应用在终端释放更大能动性 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362679</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362679</guid>
      <pubDate>Thu, 17 Jul 2025 03:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯公开 AI 产品应用全景图，开源 3D 世界模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯宣布首次公开 AI 产品应用全景图，包括 1+3+N 多项成果：混元 3D 世界模型、双智能体开发平台、具身智能开放平台等，覆盖 ToB-ToC-机器人多场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="226" src="https://oscimg.oschina.net/oscnet/up-2a518afecfb3fd34b432863c074a91586b1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与此同时，混元正式发布并开源了业界首个 3D 世界生成模型——混元 3D 世界模型 1.0。根据介绍，混元 3D 世界模型 1.0 融合了全景视觉生成与分层 3D 重建技术，能够接受文字和图片作为输入，快速生成高质量、风格多样的可漫游 3D 场景。这一技术突破极大地简化了 3D 场景的构建流程，过去需要专业建模团队数周才能完成的工作，现在通过简单的文字指令或图片上传，几分钟内即可实现。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对于游戏开发者而言，该模型能够迅速生成包含建筑、地形、植被等元素的完整 3D 场景，输出的 Mesh 文件可直接用于游戏原型搭建或关卡设计，同时支持前景物体调整和天空背景更换，满足个性化创作需求。即便是没有建模经验的普通用户，也能通过混元 3D 创作引擎，轻松生成 360°沉浸式视觉空间，并无缝导入 Vision Pro 等虚拟头显设备，享受沉浸式体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="293" src="https://oscimg.oschina.net/oscnet/up-e397af148c8e4065009e800578c020c6773.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D 世界模型 1.0 的核心优势在于其创新的「语意层次化 3D 场景表征及生成算法」。该算法将复杂的 3D 世界解构为不同语意层级，实现前景与背景、地面与天空的智能分离，不仅生成视觉效果逼真的整体场景，还能输出标准化的 3D Mesh 资产，兼容 Unity、Unreal Engine、Blender 等主流工具，便于用户对场景内元素进行独立编辑或物理仿真，实现了 AIGC 技术与传统 CG 工作流的无缝衔接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#222222"&gt;混元大模型的最新进展：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-f2e1d93b044490b121dc73e763a7d7f36d8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkaISOjFXhne5g9IG5P7ahg" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362675</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362675</guid>
      <pubDate>Thu, 17 Jul 2025 02:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中国政府倡议成立世界人工智能合作组织</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中国政府 26 日倡议成立世界人工智能合作组织，初步考虑总部设在上海。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="218" src="https://oscimg.oschina.net/oscnet/up-d0df9652b4e7e21e9148ac6f456ef0f67af.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;记者获悉，这是中方坚持践行多边主义、推动共商共建共享全球治理的重要举措，也是中方响应全球南方呼声、助力弥合数字和智能鸿沟、促进人工智能向善普惠发展的实际行动。中方期待世界人工智能合作组织作为重要的国际公共产品，实现以下目标：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;一是深化创新合作，释放智能红利。中方愿同各国分享中国式现代化带来的广阔机遇，将世界人工智能合作组织打造成供需对接平台，破除妨碍世界各国间生产要素流动的壁垒，促进中国同各国以及各国之间的人工智能务实合作，让人工智能的无限潜力充分释放，实现共同发展、共同繁荣。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;二是推动普惠发展，弥合智能鸿沟。中方将以世界人工智能合作组织为平台，持续推进落实「加强人工智能能力建设国际合作」联大决议和《人工智能能力建设普惠计划》，帮助全球南方国家加强能力建设、培育人工智能创新生态，确保发展中国家在智能化浪潮中平等受益，推动落实联合国 2030 年可持续发展议程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;三是加强协同共治，确保智能向善。中方将依托世界人工智能合作组织，加强各国之间发展战略、治理规则、技术标准的对接协调，在充分尊重各国政策和实践差异性的基础上，逐步形成具有广泛共识的人工智能全球治理框架和标准规范，确保人工智能始终沿着人类文明进步的方向发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方倡议成立世界人工智能合作组织旨在加强人工智能领域的国际合作。中方初步考虑该组织总部设在上海，希望利用中国特别是上海人工智能先发优势，凝聚国际共识，促进务实合作，让人工智能真正造福全人类。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方将秉持共商共建共享的理念，同有意愿加入的国家共同探讨相关安排。包括尊重主权原则，坚持平等相待，支持各国结合自身国情开展人工智能合作。遵循联合国宪章宗旨和原则，支持联合国发挥人工智能治理主渠道作用，为联合国及其相关机构的努力提供有益补充。采取开放包容的态度，践行真正的多边主义，通过世界人工智能合作组织进一步凝聚共识、促进合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方热忱欢迎有诚意、有意愿的国家积极参与世界人工智能合作组织的筹备工作，共同推进人工智能全球治理和国际合作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362669</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362669</guid>
      <pubDate>Thu, 17 Jul 2025 02:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>基于模型蒸馏的大模型文案生成最佳实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;大语言模型在生成高质量文案方面表现优异，然而其巨大的计算资源消耗和存储需求，使得实际应用尤其是在资源受限场景中的应用充满挑战。企业在寻求高效的文案生成时，常常面临着在性能和资源之间权衡的困境。在这种背景下，模型蒸馏技术为解决这一问题提供了新的思路。模型蒸馏是一种优化技术，旨在通过将知识从大型复杂模型中提取并转移到更小、计算更高效的模型中，使得这些小型模型能够在保留大多数性能优势的情况下显著降低资源需求。这一技术在大模型文案生成领域的应用，不仅能够保持生成质量接近原有大模型，还极大地减少了计算成本和部署难度。本文介绍如何使用 EasyDistill 算法框架以及 PAI 产品，实现基于模型蒸馏的大模型文案生成，通过这种方式节省人力成本，同时提高用户体验，推动业务的可持续增长。&lt;/p&gt; 
&lt;h2&gt;部署教师大语言模型&lt;/h2&gt; 
&lt;h3&gt;部署模型服务&lt;/h3&gt; 
&lt;p&gt;您可以按照以下操作步骤，部署教师大语言模型生成对应回复。&lt;/p&gt; 
&lt;p&gt;在 PAI-Model Gallery 选择 DeepSeek-V3 模型或者其他教师大模型，在模型部署区域，系统已默认配置了模型服务信息和资源部署信息，您也可以根据需要进行修改，参数配置完成后单击部署按钮。以 DeepSeek-V3 为例，其模型卡片如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-28df44d9861762bd4497b14e096e764f133.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;模型部署和调用&lt;/h3&gt; 
&lt;p&gt;PAI 提供的 DeepSeek-V3 预置了模型的部署配置信息，可以选择 SGLang 部署/vLLM 部署/Transformers 部署，用户仅需提供推理服务的名称以及部署配置使用的资源信息即可将模型部署到 PAI-EAS 推理服务平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cd9de19c221b06b8a1068309ddcb1fd7c0e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推理服务同样支持以 OpenAI API 兼容的方式调用，调用示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

models = client.models.list()
model = models.data[0].id
print(model)

def main():
    stream = True
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "你好，介绍一下你自己，越详细越好。",
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=stream,
    )
    if stream:
        for chunk in chat_completion:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion.choices[0].message.content
        print(result)


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多细节可以参考"一键部署 DeepSeek-V3、DeepSeek-R1 模型"。&lt;/p&gt; 
&lt;h2&gt;构建训练数据&lt;/h2&gt; 
&lt;h3&gt;构建 SFT 训练数据&lt;/h3&gt; 
&lt;p&gt;您可以按照以下操作步骤，构建 SFT 训练数据。用户可以根据如下输入数据批量调用教师大模型，输入数据格式如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "instruction": "xxx"
  },
  {
    "instruction": "xxx"
  },
  {
    "instruction": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，instruction 为调用大模型的 prompt，由任务模版和实际输入数据组成。这里，我们给出一个任务模版供您参考，实际内容可以根据业务场景和数据特征进行调整：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;你是短视频文案生成专家，专注于根据视频原始标题、视频内容，生成文案的标题和内容。
你的任务是确保文案与视频核心内容高度匹配，并且吸引用户点击。

要求
1: 信息匹配度：确保文案准确反映视频核心看点，禁止出现视频中未呈现的虚构内容。
2. 情绪契合度：文案情绪需与视频内容保持一致。严肃悲伤类内容不要使用搞笑戏谑风格。
3. 内容规范度：确保句意表达清晰、完整、通顺、连贯，没有出现无意义字符。
4. 严格按照 JSON 格式输出：
{
   "title": "",
   "body": ""
}

避免出现情况
1. 标题要求在 10 个汉字以内。
2. 内容要求在 30 个汉字以内。
3. 禁止标题党，和过度夸张的表述。
4. 不得出现高敏感内容，或者低俗用语。

请严格按照 JSON 格式输出内容，不要在输出中加入解析和说明等其他内容。

视频原始标题和视频内容分别如下所示：
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;给定上述输入数据，我们可以批量调用教师大模型生成回复，示例代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import json
from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# 获取模型
models = client.models.list()
model = models.data[0].id
print(model)

# 读取输入数据
def read_input_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

# 调用大模型获取输出
def get_model_output(instruction):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": instruction,
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=False,
    )
    return chat_completion.choices[0].message.content

# 处理输入数据并生成输出
def process_data(input_data):
    results = []
    for item in input_data:
        instruction = item.get("instruction")
        output = get_model_output(instruction)
        results.append({
            "instruction": instruction,
            "output": output
        })
    return results

# 保存输出数据到文件
def save_output_data(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump(data, file, ensure_ascii=False, indent=2)

def main(input_file_path, output_file_path):
    input_data = read_input_data(input_file_path)
    output_data = process_data(input_data)
    save_output_data(output_file_path, output_data)
    print("Data processing complete.")

if __name__ == "__main__":
    # 指定你的输入和输出文件路径
    input_file_path = "input.json"
    output_file_path = "output.json"
    main(input_file_path, output_file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;当运行完上述代码后，我们得到构造好的 SFT 训练数据，格式如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "instruction": "xxx",
    "output": "xxx"
  },
  {
    "instruction": "xxx",
    "output": "xxx"
  },
  {
    "instruction": "xxx",
    "output": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;为了保证 SFT 训练数据集的高质量，我们建议采用如下设置：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练数据量至少应在 3000 条以上，而且需要尽可能覆盖输入视频的各种主题；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成文案的任务模版可以按照实际业务需求进行修改，需要根据明确的业务需求，用自然语言精确描述生成的文案要求达到的效果和避免出现的情况；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为了保证生成文案的高质量，使用的教师大模型底座参数量需要尽可能高，例如使用满血版的 DeepSeek-V3，一般不需要使用深度思考的模型，例如 DeepSeek-R1 或 QwQ-32B；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在输入中，视频的内容可以通过 OCR、ASR 等多种途径从原始视频中抽取出来，需要保证抽取出来的内容具有较高的准确性；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建议在生成 SFT 训练数据集后人工抽样进行质量校验，并且根据校验结果，反复调整调用大模型的任务模版，以达到满意的效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;构建 DPO 训练数据&lt;/h2&gt; 
&lt;p&gt;如果您需要通过 DPO 算法继续优化较小的学生模型，则需要构造用于 DPO 算法训练的数据集。我们可以基于构造好的 SFT 训练数据进行继续构造流程。其中，DPO 数据格式示例如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  },
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  },
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，prompt 对应 SFT 训练数据集的 instruction，chosen 可以使用 SFT 训练数据集的 output 字段，rejected 为 DPO 算法中提供的低质量文案。在 DPO 算法的训练过程中，我们鼓励大模型生成高质量的 chosen 文案，惩罚大模型生成类似 rejected 的文案。因此，我们需要额外生成 rejected 文案。我们可以同样采用教师大模型生成 rejected 文案，利用 SFT 训练数据集作为输入，我们需要改变上文使用的任务模版。这里我们给出一个示例供您参考：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;你是视频文案生成初学者，尝试根据视频原始标题、视频内容生成不够吸引人的文案标题和内容。
目标是生成逻辑不清、可能误导、不够吸引用户点击的文案。

要求
1. 信息匹配度：不要求准确反映视频核心看点，甚至可以与视频内容无关。
2. 情绪契合度：文案情绪可以与视频内容不一致。
3. 内容规范度：表达可以不清晰、不完整、不通顺、不连贯，可以出现无意义字符。
4. 可不用严格按照 JSON 格式输出。

视频原始标题和视频内容分别如下所示：
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我们同样给出一个批量推理的脚本，生成上述数据，我们假设输入数据格式与 SFT 训练数据集相同，但是 instruction 字段采用上文生成低质量文案的任务模版：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import json
from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# 获取模型
models = client.models.list()
model = models.data[0].id
print(model)

# 读取输入数据
def read_input_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

# 调用大模型获取低质量文案
def get_rejected_output(instruction):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": instruction,
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=False,
    )
    return chat_completion.choices[0].message.content

# 处理输入数据并生成输出
def process_data(input_data):
    results = []
    for item in input_data:
        instruction = item.get("instruction")
        chosen = item.get("output")
        rejected = get_rejected_output(instruction)
        results.append({
            "prompt": instruction,
            "chosen": chosen,
            "rejected": rejected
        })
    return results

# 保存输出数据到文件
def save_output_data(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump([data], file, ensure_ascii=False, indent=2)

def main(input_file_path, output_file_path):
    input_data = read_input_data(input_file_path)
    output_data = process_data(input_data)
    save_output_data(output_file_path, output_data)
    print("Data processing complete.")

if __name__ == "__main__":
    # 指定你的输入和输出文件路径
    input_file_path = "input.json"
    output_file_path = "output.json"
    main(input_file_path, output_file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;为了保证 DPO 训练数据集的高质量，我们建议采用如下设置：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练数据量至少应在 1000 条以上，而且需要尽可能覆盖输入视频的各种主题；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成 rejected 文案的任务模版可以按照实际业务需求进行修改，需要和 chosen 文案在质量上有明显的差距，特别可以注重生成 chosen 文案中避免出现的情况（即负向样本）；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为了保证生成文案质量满足要求，使用的教师大模型底座参数量需要尽可能高，例如使用满血版的 DeepSeek-V3，一般不需要使用深度思考的模型，例如 DeepSeek-R1 或 QwQ-32B；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在输入中，视频的内容可以通过 OCR、ASR 等多种途径从原始视频中抽取出来，需要保证抽取出来的内容具有较高的准确性；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建议在生成 DPO 训练数据集后人工抽样进行质量校验，并且根据校验结果，反复调整调用大模型的任务模版，以达到满意的效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;通过 SFT 算法蒸馏训练较小的学生模型&lt;/h2&gt; 
&lt;p&gt;接下来我们使用 EasyDistill 算法框架，利用准备好的训练数据，训练学生模型。在 PAI-DSW 中，根据"&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1664823" title="阿里云人工智能平台 PAI 开源 EasyDistill 框架助力大语言模型轻松瘦身" target="_blank"&gt;阿里云人工智能平台 PAI 开源 EasyDistill 框架助力大语言模型轻松瘦身&lt;/a&gt;"一文安装 EasyDistill 算法包后使用如下命令进行 SFT 模型训练：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python easydistill/kd/train.py --config=sft.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，sft.json 为 SFT 蒸馏训练的配置文件，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
  "job_type": "kd_black_box_api",
  "dataset": {
    "labeled_path": "sft_train.json",
    "template" : "chat_template_kd.jinja",
    "seed": 42
  },
  "models": {
    "student": "model/Qwen/Qwen2.5-0.5B-Instruct/"
  },
  "training": {
    "output_dir": "result_sft/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "save_steps": 1000,
    "logging_steps": 1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
} 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，sft_train.json 为 SFT 训练数据集，model/Qwen/Qwen2.5-0.5B-Instruct/为学生模型路径，这里以 Qwen2.5-0.5B-Instruct 为示例，result_sft/为模型输出路径。您可以根据实际需要，在 training 字段中调整训练使用的超参数。&lt;/p&gt; 
&lt;h2&gt;通过 DPO 算法继续优化较小的学生模型&lt;/h2&gt; 
&lt;p&gt;由于 SFT 训练过程中提供给学生模型唯一的正确答案，因此这种训练存在两个限制条件：一为模型的泛化能力有限，二为缺乏更加细粒度的模型对齐。DPO 算法通过提供 chosen 和 rejected 的模型回复，进一步提升模型的对齐能力。根据准备好的 DPO 训练数据，我们在 SFT 训练完的模型 Checkpoint 基础上，使用 EasyDistill 的如下命令，进行 DPO 模型训练：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python easydistill/rank/train.py --config=dpo.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，dpo.json 为 DPO 蒸馏训练的配置文件，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-{"&gt;  "job_type": "rank_dpo_api",
  "dataset": {
    "labeled_path": "dpo_train.json",
    "template" : "chat_template_kd.jinja",
    "seed": 42
  },
  "models": {
    "student": "result_sft/"
  },
  "training": {
    "output_dir": "result_dpo/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "save_steps": 1000,
    "logging_steps": 1,
    "beta": 0.1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，dpo_train.json 为 SFT 训练数据集，result_sft/为 SFT 训练之后的学生模型路径，result_dpo/为模型输出路径。您可以根据实际需要，在 training 字段中调整训练使用的超参数。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5583868/blog/18685835</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18685835</guid>
      <pubDate>Thu, 17 Jul 2025 02:25:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>字节跳动 AI Agent 平台扣子拥抱开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;字节跳动旗下 AI Agent 开发平台扣子（Coze）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6jGoaE29S2oOrywCAB8zMg" target="_blank"&gt;宣布&lt;/a&gt;正式拥抱开源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扣子旗下共有四款子产品：「扣子空间」、「扣子开发平台」、「扣子罗盘」 及 Eino。目前，扣子开发平台 （Coze Studio）与扣子罗盘 （Coze Loop）已在 Apache 2.0 许可证下开源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="214" src="https://oscimg.oschina.net/oscnet/up-7117b00b0aec66eedb8cac42206d8cab2fa.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Coze Studio 是一个一站式的 AI Agent 可视化开发工具，此次开源的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;完整的工作流（Workflow）引擎：只需拖拽节点，就能轻松编排出复杂的业务逻辑。无论是简单的问答机器人，还是需要执行多步任务的 Agent，都能轻松实现。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;插件（Plugin）核心框架：开放了插件的定义、调用与管理机制。你可以便捷地将任何第三方 API 或私有能力封装成插件，无限扩展 Agent 的能力边界。还提供了官方开源插件作为参考，让用户立刻上手。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;开箱即用的开发环境： 你只需一键部署，即可获得一个功能完备的 Agent 开发平台，包括创建、调试、版本管理等全套界面，让你专注于创造本身。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Coze Loop 聚焦于 Agent 从开发到运维的全链路管理，此次开源的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Prompt 开发： 提供从编写、调试、一键优化到版本管理的强大能力，让你的 Prompt 工程化、系统化。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多维度评测：AI 的效果好坏不再凭感觉。Coze Loop 提供系统化的评测能力，能从准确性、简洁性、合规性等多个维度，自动化地评估 Prompt 和 Agent 的输出质量。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;全链路可观测性：Agent 的每一次执行过程都尽在掌握。提供覆盖全过程的可视化观测能力，详细记录每个环节的处理细节与状态，让 Debug 不再是大海捞针。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362658</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362658</guid>
      <pubDate>Thu, 17 Jul 2025 02:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>我国大模型数量超 1500 个</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;世界人工智能大会的最新数据显示，目前全球已发布的大模型总数达 3755 个，其中中国企业贡献了 1509 个，位居全球首位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="1124" src="https://oscimg.oschina.net/oscnet/up-76a22434fb01383b49199810b0ee2c20962.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;从中国互联网络信息中心发布的第 56 次报告中可以看出，2025 年上半年，我国的生成式人工智能在技术与应用层面均取得了全面进步，相关产品的数量也在快速增长，应用场景不断扩展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在用户方面，截至 6 月，使用生成式人工智能产品回答问题的比例高达 80.9%。从产业层面来看，预计到 2024 年，我国的人工智能产业规模将突破 7000 亿元，并且连续多年保持 20% 以上的增长率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362654</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362654</guid>
      <pubDate>Thu, 17 Jul 2025 02:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Solon 整合 LiteFlow 规则引擎：概念与实战</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;一、引言&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在现代软件开发中，规则引擎允许我们以声明式的方式定义业务逻辑和决策路径。LiteFlow 是一个轻量级、易于使用的组件式规则引擎，它可以与 Solon 应用无缝整合。本文将介绍如何在 Solon 项目中引入 LiteFlow，实现灵活的业务流程管理。&lt;/p&gt; 
&lt;h2&gt;二、LiteFlow 的核心概念&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;LiteFlow 简介&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;LiteFlow 是一个基于 Java 的轻量级流程引擎，专为简化复杂业务逻辑处理设计。通过将业务流程抽象为一系列的节点（components），LiteFlow 提供了一种清晰和可维护的方法来编排业务逻辑。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主要特点&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;组件化设计：业务逻辑分解为独立的组件，每个组件执行特定的功能。 灵活的流程控制：支持同步和异步执行，以及条件分支、循环等控制结构。 易于配置：使用 XML、YAML 或程序式配置定义流程。&lt;/p&gt; 
&lt;h2&gt;三、实战演示：在 Solon 中使用 LiteFlow&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;环境准备&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;确保你的开发环境已经安装了 JDK 1.8 或以上版本，并且项目是基于 Solon 构建的。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加依赖&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在项目的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;pom.xml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件中添加 LiteFlow 的 Maven 依赖：&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;xml 复制代码&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.yomahub&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;liteflow-solon-plugin&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;最新版本号&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;配置 LiteFlow&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;app.yml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件中配置 LiteFlow 的规则文件路径：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;liteflow:&lt;/span&gt;
  &lt;span style="color:#986801"&gt;rule-source:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;classpath:liteflow-rules.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;定义组件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;创建组件类，每个类对应一个处理步骤：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; com.yomahub.liteflow.core.NodeComponent;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Component;

&lt;span style="color:#4078f2"&gt;@Component("componentA")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;ComponentA&lt;/span&gt; &lt;span style="color:#a626a4"&gt;extends&lt;/span&gt; &lt;span style="color:#c18401"&gt;NodeComponent&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;process&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        System.out.println(&lt;span style="color:#50a14f"&gt;"执行组件 A 的逻辑"&lt;/span&gt;);
        &lt;em&gt;// 添加业务逻辑代码&lt;/em&gt;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;定义流程&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;liteflow-rules.xml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中定义业务流程，指定组件的执行顺序：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;flow&lt;/span&gt; &lt;span style="color:#986801"&gt;id&lt;/span&gt;=&lt;span style="color:#50a14f"&gt;"chain1"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;then&lt;/span&gt; &lt;span style="color:#986801"&gt;value&lt;/span&gt;=&lt;span style="color:#50a14f"&gt;"componentA,componentB,componentC"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;flow&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;触发流程执行&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在 Solon 应用中通过 LiteFlow 的 API 触发流程执行：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; com.yomahub.liteflow.flow.FlowExecutor;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;FlowController&lt;/span&gt; {

    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; FlowExecutor flowExecutor;

    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/runFlow")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;runFlow&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;try&lt;/span&gt; {
            flowExecutor.execute2Resp(&lt;span style="color:#50a14f"&gt;"chain1"&lt;/span&gt;);
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"流程执行成功"&lt;/span&gt;;
        } &lt;span style="color:#a626a4"&gt;catch&lt;/span&gt; (Exception e) {
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"流程执行失败: "&lt;/span&gt; + e.getMessage();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;测试与验证&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;启动 Solon 应用并访问&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/runFlow&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;路径，检查控制枱输出以验证流程是否按预期执行。&lt;/p&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;通过整合 LiteFlow 规则引擎，Solon 应用可以更加灵活地处理复杂的业务流程。LiteFlow 的组件化和易配置性使得管理和维护业务逻辑变得更简单。此外，借助 LiteFlow 的强大功能，开发者可以构建出更加动态和可扩展的应用系统，满足不断变化的业务需求。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362560</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362560</guid>
      <pubDate>Wed, 16 Jul 2025 05:11:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
  </channel>
</rss>
