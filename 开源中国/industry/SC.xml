<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 22 Apr 2025 02:36:28 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>荣耀在哈尔滨成立新公司，含智能机器人销售业务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查资料显示，哈尔滨星耀终端有限公司于近日成立，法定代表人为文洁，注册资本 200 万人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;206&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9a3284834040e97a1c162e0dbeec698a8f.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该公司经营范围含移动终端设备销售、家用电器销售、电子产品销售、可穿戴智能设备销售、智能机器人销售、智能无人飞行器销售、物联网设备销售等。股权全景穿透图显示，该公司由深圳星耀终端有限公司全资持股，后者为荣耀终端股份有限公司全资子公司。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345858</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345858</guid>
            <pubDate>Tue, 22 Apr 2025 02:32:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 能用 Java8 开发 MCP Server，这才是 MCP 自由（Solon AI MCP）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;目前，用 Java 开发 MCP 的情况是：&lt;/p&gt; 
&lt;table cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;框架&lt;/th&gt; 
   &lt;th&gt;JDK 要求&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;mcp-sdk&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;需要 jdk17+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;spring-ai-mcp-server&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;需要 jdk17 +&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;spring-ai-mcp-client&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;需要 jdk17 +&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;langchain4j-mcp-client&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;需要 jdk17+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;solon-ai-mcp-server&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;jdk8 +&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;solon-ai-mcp-client&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;jdk8 +&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;之前在 mcp-sdk 仓库的 issue 与人交流时。曾有人说现在都 ia 时代了，怎么能还用 java8 呢？可是 MCP 是一个协议性的框架，应该更有普适性，应该照顾更广的市场需求。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;市场的情况是，（尤其是我国）还有海量的 jdk8 服务器。所以，用 Java8 也能开发 MCP（或 MCP Server），这才是 MCP 自由！&lt;/p&gt; 
&lt;h3&gt;Solon AI MCP（一个依赖包）&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;Java AI（智能体） 全场景应用开发框架（支持已知 AI 开发的各种能力。例如：LLM，Function Call，RAG，Embedding，Reranking，Flow，MCP Server，Mcp Client）。同时支持 java8，java11，java17，java21。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;可与 Solon 集成使用，也可嵌入到 SpringBoot2、jFinal、Vert.x 等框架中使用。&lt;/p&gt; 
&lt;h3&gt;Solon AI MCP Server 示例（支持多端点）&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;下面以一个查询天气的 Mcp 工具服务为例。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;组件方式构建（和 MVC 开发像）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@McpServerEndpoint(name=&quot;mcp-case1&quot;, sseEndpoint = &quot;/case1/sse&quot;)&lt;/span&gt; 
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;McpServerTool&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@ToolMapping(description = &quot;查询天气预报&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; String &lt;span style=&quot;color:#4078f2&quot;&gt;getWeather&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#4078f2&quot;&gt;@ToolParam(description = &quot;城市位置&quot;)&lt;/span&gt; String location)&lt;/span&gt; {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;晴，14 度&quot;&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;原生 java 方式构建&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;McpServerEndpointProvider&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;serverEndpoint&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpServerEndpointProvider.builder()
        .name(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;mcp-case2&quot;&lt;/span&gt;)
        .sseEndpoint(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;/case2/sse&quot;&lt;/span&gt;)
        .build();

serverEndpoint.addTool(&lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;MethodToolProvider&lt;/span&gt;(&lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;McpServerTool&lt;/span&gt;()));
serverEndpoint.postStart();
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Solon AI MCP Client 示例&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;McpClientToolProvider&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;clientToolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientToolProvider.builder()
                .apiUrl(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://localhost:8080/case1/sse&quot;&lt;/span&gt;)
                .build();

&lt;span style=&quot;color:#986801&quot;&gt;String&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; clientToolProvider.callToolAsText(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;getWeather&quot;&lt;/span&gt;, Map.of(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;location&quot;&lt;/span&gt;, &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;杭州&quot;&lt;/span&gt;));&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345851</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345851</guid>
            <pubDate>Mon, 14 Apr 2025 01:28:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>预计中国市场 2025 年人形机器人本体产值将超 45 亿元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据 TrendForce 集邦咨询最新数据，中国市场已有 11 家主流人形机器人本体厂商启动 2024 年量产计划。其中，宇树科技、优必选、智元机器人、银河通用、众擎机器人、乐聚机器人等 6 家领先企业更是将 2025 年的量产规划设定在千台以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TrendForce 集邦咨询预计，2025 年中国市场人形机器人本体产值有望突破 45 亿元人民币。加上马斯克关于 Tesla Optimus 2025 年数千台量产目标，预计头部本体厂商的量产计划将拉动中国市场人形机器人零部件供应链生态布局与完整性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-545b82ebd4c04ad7f2c9a719209e9659c66.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;当下人形机器人产品主要应用在 B 端工业场景、高校科研以及少部分 B 端商用场景，而 C 端家用场景要求人形机器人功能多元，对机器人数据处理和自主交互能力要求较高。人形机器人从 B 端跨越到 C 端应用场景需要政策、法规、技术等行业多方面的共同努力，C 端应用场景的商业化落地仍任重道远。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345784</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345784</guid>
            <pubDate>Sun, 13 Apr 2025 09:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>得物自研 DGraph4.0 推荐核心引擎升级之路</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、前言&lt;/h1&gt; 
&lt;p&gt;DGraph 是得物自主研发的新一代推荐系统核心引擎，基于 C++语言构建，自 2021 年启动以来，经过持续迭代已全面支撑得物社区内容分发、电商交易等核心业务的推荐场景。DGraph 在推荐链路中主要承担数据海选和粗排序功能，为上层精排提供高质量候选集。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心技术特性：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;索引层 - 支持 KV（键值）、KVV（键-多值）、INVERT（倒排）、DENSE-KV（稠密键值）等。&lt;strong&gt;索引存储&lt;/strong&gt;支持磁盘 &amp;amp; 内存两种模式，在预发等延迟压力低场景，通过磁盘索引使用低规格服务器提供基本服务。线上场景使用内存索引保证服务稳定性，提供毫秒级延迟响应。&lt;strong&gt;索引更新&lt;/strong&gt;支持双 buff 热更新【内存足够】、服务下线滚动更新【内存受限】、Kafka 流式数据实时更新等三种模式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;查询层 - 支持向量检索 IVF &amp;amp; HNSW、键值 (KV) 查询、倒排检索、X2I 关联查询、图查询。对外提供 JavaSDK &amp;amp; C++ SDK。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;系统依赖架构：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;索引全生命周期管理由得物索引平台 DIP 统一管控。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;服务发现基于 ZooKeeper(zk)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;集群资源调度基于得物容器平台，目前已经支持 HPA。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;服务规模：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目前在线 100+集群，2024 年双 11 在线突破了 100W qps。&lt;/p&gt; 
&lt;p&gt;本文主要介绍 DGraph 系统在 2024 年的一些重要改进点。主要包括两次架构调整 + 性能优化 + 用户体验提升方面的一些工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、架构升级&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 垂直拆分业务集群支持&lt;/h2&gt; 
&lt;p&gt;在 2023 年前，DGraph 系统始终采用单一集群架构提供服务。该架构模式在平台发展初期展现出良好的经济性和运维便利性，但随着业务规模扩张，单集群架构在系统层面逐渐显露出三重刚性约束：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;存储容量瓶颈 - 单节点内存上限导致数据规模受限；&lt;/li&gt; 
 &lt;li&gt;网络带宽瓶颈 - 单物理机 Pod 共享 10Gbps 带宽，实际可用带宽持续承压，推荐引擎业务中部分核心集群 200 余张数据表（单表需 20 分钟级更新）的实时处理需求已遭遇传输瓶颈；&lt;/li&gt; 
 &lt;li&gt;计算能力瓶颈 - 单实例最大 64 核的算力天花板，难以支撑复杂策略的快速迭代，核心场景响应时效与算法复杂度形成显著冲突；&lt;/li&gt; 
 &lt;li&gt;稳定性 - 大规格集群对于容器调度平台不友好，在扩容、集群故障、集群发布时耗时较久；基于得物平台推荐数据量增长和算法迭代需求，我们实施业务垂直拆分的多集群架构升级，通过资源解耦与负载分离，有效突破了单节点资源约束，为复杂算法策略的部署预留出充足的技术演进空间。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;系统改进点是在 DGraph 中增加了访问了其他 DGraph 集群 &amp;amp; FeatureStore 特征集群的能力 (图 1)。为了成本考虑，我们复用了之前系统的传输协议 flatbuffers，服务发现仍基于 ZooKeeper。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c817ffca6dd3d7ecea36fdd95d20183d04a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 1 DGraph 访问架构改进&lt;/p&gt; 
&lt;p&gt;改造的难点在图化集群！&lt;/p&gt; 
&lt;p&gt;目前推荐业务的核心场景都进行了图化改造，图化查询是把多路召回、打散、融合、粗排等策略打包到一个 DAG 图中一次发送到 DGraph，DGraph 的算子调度模块根据 DAG 的描述查询索引数据 &amp;amp; 执行算子最终把结果返回给业务系统，但这些 DAG 图规模都很大，部分业务 DAG 图涉及 300+算子，因此如何在垂直拆分业务中把这些 DAG 图拆分到不同的 DGraph 集群中是一个非常复杂的问题，我们主要做了三方面改进：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DAG 管理 - 集群分主集群和从集群【多个】，DAG 图部署在存在主集群中，DIP 平台会分析 DAG 的拓步结构并把属于从集群的部分复制出来分发给从集群，为了保证 DAG 的一致性，只允许从主集群修改 DAG 图；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;集群划分 - 通常按召回划分，比如 Embedding 召回、X2I 召回、实验召回可以分别部署在不同的集群，另外也可以把粗排等算力需求大的部分单独放在一个集群，具体根据业务场景调整；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能优化 - 核心表多个集群存放，减少主集群和从集群间数据交换量。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ed9ac500b1e0e379e07f0f870f4f6ae62bb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 2 DGraph 业务垂直拆分集群&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 分布式能力支持&lt;/h2&gt; 
&lt;p&gt;垂直拆分集群，虽然把推荐 N 路召回分散到了 M 个集群，但是每个集群中每个表依然是全量。随着得物业务的发展，扩类目、扩商品，部分业务单表的数据量级已经接近单集群的存储瓶颈。因此需要 DGraph 中引入数据水平拆分的能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3da38581237c44ef46782fe58c5c0566ed6.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 3 DGraph 分布式集群架构图&lt;/p&gt; 
&lt;p&gt;在 DGraph 分布式架构设计中，重点考虑了部署成本优化与业务迁移工作量：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;分布式集群采用【分片数 2】×【双活节点 2】×【数据副本数 2】的最小拓扑结构，理论上需要 8 台物理节点保障滚动更新与异常容灾时的稳定性。针对 CPU 负载较轻的场景，为避免独立 Proxy 集群带来的额外资源开销，DGraph 将 Proxy 模块和 DGraph 引擎以对称架构部署到所有节点，通过本地优先的智能路由策略（本地节点轮询优先于跨节点访问）实现资源利用率与访问效率的平衡；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在业务兼容性方面，基础查询接口（KV 检索、倒排索引、X2I 关联查询）保持完全兼容以降低迁移成本，而 DAG 图查询需业务侧在查询链路中明确指定 Proxy 聚合算子的位置以发挥分布式性能优势。数据链路层面，通过 DIP 平台实现索引无缝适配，支持 DataWorks 原有任务无需改造即可对接分布式集群，同时增量处理模块内置分片过滤机制，可直接复用现有 Flink 实时计算集群进行数据同步。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、性能优化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 算子执行框架优化&lt;/h2&gt; 
&lt;p&gt;在 DGraph 中，基于 DGraph DAG 图 (参考图 9) 的一次查询就是图查询，内部简称 graphSearch。在一个 DAG 图中，每个节点都是一个算子 (简称 Op)，算子通过有向边连接其他算子，构成一个有向无环图，算子执行引擎按 DAG 描述的关系选择串行或者并发执行所有算子，通过组合不同算子 DAG 图能在推荐场景中灵活高效的完成各种复杂任务。&lt;/p&gt; 
&lt;p&gt;在实际应用场景中受 DAG 图规模 &amp;amp; 超时时间 (需要控制在 100ms 内) 限制，算子执行框架的效率非常重要。在最开始的版本中我们使用过 Omp &amp;amp; 单队列线程池，集群在 CPU 负载低于 30% 时表现尚可，但在集群 CPU 负载超过 30% 后，rt99 表现糟糕。在降本增效的背景下，我们重点对算子执行框架进行了优化，引入了更高效的线程池 &amp;amp; 减少了调度过程中锁的使用。优化后目前 DGraph 在 CPU 压力超过 60% 依然可以提供稳定服务。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-314750530e377031be7838774eae9b7fecd.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 4 DGraph 算子执行框架优化&lt;/p&gt; 
&lt;p&gt;线程池优化：将原 1:N 的线程池-队列架构调整为 M:N 分组模式。具体实现为将 N 个工作线程划分为 M 个执行组（每组 N/M 线程），各组配备独立任务队列。任务提交采用轮询分发机制至对应组队列，通过资源分区有效降低线程调度时的锁竞争强度。&lt;/p&gt; 
&lt;p&gt;调度器优化：在 DAG 调度过程中存在两个典型多写场景&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;前驱算子节点完成时需并行更新后继节点标记；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DAG 全局任务计数器归零判断。原方案通过全局锁（Graph 锁+Node 锁）保障原子性，但在高负载场景引发显著锁竞争开销，影响线程执行效率。经分析发现这两个状态变更操作符合特定并发模式：所有写操作均为单调增减操作，因此可将锁机制替换为原子变量操作。针对状态标记和任务计数场景，分别采用原子变量的 FetchAdd 和 FetchSub 指令即可实现无锁化同步，无需引入 CAS 机制即满足线程安全要求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 传输协议编码解码优化&lt;/h2&gt; 
&lt;p&gt;优化 JavaSDK - DGraph 数据传输过程：在 DGraph 部分场景，由于请求引擎返回的数据量很大，解码编码耗时占整个请求 20% 以上。分析已有的解码编码模块，引擎在编码阶段会把待传输数据编码到一个 FlatBuffer 中，然后通过 rpc 协议发送到业务侧的 JavaSDK，sdk 解码 FlatBuffer 封装成 List&amp;lt;map&amp;gt; 返回给业务代码，业务代码再把 List&amp;lt;map&amp;gt; 转化成 List&amp;lt;业务 Object&amp;gt;。过程中没有并发 &amp;amp; sdk 侧多了一层冗余转换。&lt;/p&gt; 
&lt;p&gt;优化方案如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;串行编码调整为根据文档数量动态调整编码块数量。各子编码块可以并发编码解码，加快编码&amp;amp;解码速度，提升整体传输性能；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sdk 侧由 Doc -&amp;gt; Map -&amp;gt; JavaObject 的转化方式调整为 Doc -&amp;gt; JavaObject，减少解码端算力开销。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-781cc5f8b62293731a12f4578bddbafd4b1.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 5 DGraph 传输编码解码过程优化&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_8&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、用户体验优化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 DAG 图调试功能优化&lt;/h2&gt; 
&lt;p&gt;目前我们已经把 DGraph DAG 图查询的调试能力集成到 DIP 平台。其原理是：DGraph 的算子基类实现了执行结果输出，由于算子的中间结果数据量极大，当调试模块发现调试标志后会先把当前算子的中间结果写入日志中，数据按 TraceID + DAGID+ NodeID 组织，最终这些数据被采集到 SLS 日志平台。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2d918720f61f5f0f7d019c68f05998aecca.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 6 DGraph DAG 图查询调试&lt;/p&gt; 
&lt;p&gt;从 DIP 平台调试 DAG 图请求，首先通过 DGraph JavaSDK 的调试入口拿到 DAG 图请求 json，填入 DIP 平台图请求调试入口，发起请求。索引平台会根据请求体自动关联 DAG 图并结合最终执行结果通过页面的方式展示。DIP 平台拿到结果后，在 DAG 图中成功的算子节点标记为绿色，失败的节点标记为红色 (图 6)。点击任意节点可以跳转到日志平台查看该节点的中间结果输出。可用于分析 DAG 图执行过程中的各种细节，提升业务排查业务问题效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 DAG 图支持 TimeLine 分析&lt;/h2&gt; 
&lt;p&gt;基于 Chrome 浏览器中的 TimeLine 构建，用于 DGraph DAG 图查询时算子性能分析优化工作。TimeLine 功能集成在算子基类中，启动时会记录每个算子的启动时间、等待时间、完成时间、执行线程 pid 等信息，这些信息首先输出到日志，然后被 SLS 日志平台采集。用户可以使用查询时的 TraceID 在日志平台搜索相关的 TimeLine 信息。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8775652c29620ccf9e0595b35dd3c9cebd3.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 7 DGraph DAG 图例子&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6a92e653aa398223b8be061bf6a425c268d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 8 使用浏览器查看 DGraph DAG 图 TimeLine&lt;/p&gt; 
&lt;p&gt;当我们拿到请求的 TimeLine 信息后，通过浏览器加载可以通过图形化的方式分析 DAG 执行过程中耗时分布。图 7 是一个 DAG 请求，它有 9 个算子节点，图 8 是它的一次请求的 TimeLine。通过分析这些算子的耗时，可以帮助我们定位当前 DAG 图查询的瓶颈点在哪里，从而精准去解决性能方面的问题。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.3 DAG 图支持动态子图&lt;/h2&gt; 
&lt;p&gt;在 DAG 图召回中，业务的召回通常都带有一些固定模式，比如一个业务在一个 DAG 图召回中有 N 路召回，每一路召回都是：① 查找数据；② 关联可推池；③ 打散； 它们之间的区别可能仅仅是召回数据表名不同或者传递的参数不同。通常我们业务调整或者算法实验调整只需要增加或者减少部分召回，原有模式下这些操作需要去新增或者修改 DAG 图，加上算法实验很多，业务维护 DAG 图的成本会非常高。&lt;/p&gt; 
&lt;p&gt;DAG 动态子图的引入就是为了解决这类问题，首先我们在 DAG 图中配置一个模板子图，它仅仅描述一个行为模式，代表会涉及几个算子，算子之间的关系如何，实际的参数以及召回路的数量则由业务方在发起请求时动态决定。子图的执行和主图的执行共用同一套调度框架，共享运行时资源以降低运行开销。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-08756615857b6bf3b35868c2f1b8d772291.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 9 DGraph 子图&lt;/p&gt; 
&lt;p&gt;图 9 是一个 DAG 召回使用 DAG 子图后的变化，它有 8 路召回，一个 Merge 节点，这些召回分为两类，一类是基于 KV 表 (ForwardSearch) 触发的向量召回，另外一类是基于 KVV 表 (IvtSearch) 触发的向量召回。引入 DAG 子图后，在主图中节点数量由 17 个降为 3 个。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_12&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、展望未来&lt;/h1&gt; 
&lt;p&gt;过去四年，DGraph 聚焦于实现得物推荐引擎体系从 0 到 1 的突破，重点完成了核心系统架构搭建、算法策略支持及业务迭代空间拓展，取得多项基础性成果。基于 2024 年底的用户调研反馈结合 DGraph 当前的发展，后续将重点提升产品易用性、开发与运维效能及用户体验，同时在系统稳定性、可扩展架构和平台化建设方面持续深化。&lt;/p&gt; 
&lt;p&gt;算法团队大量 HC，欢迎加入我们：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247537831%26idx%3D1%26sn%3Ddb1464cd87a75dd8f7bcf512fb50bf70%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物技术大量算法岗位多地上线，「职」等你来！&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;文 / 寻风&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周一、三更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18181570</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18181570</guid>
            <pubDate>Sun, 13 Apr 2025 09:35:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>字节系 Agent 产品 —— 扣子空间 (Coze Space) 开启内测</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;4 月 18 日晚间，字节系 Agent 产品 —— 扣子空间 (Coze Space) &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJlWyPmOwIYTXUD7tCvS1lg&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;开启内测，定位通用 Agent。与其他类似产品如 manus 一样，扣子空间采用了邀请码制。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0421/173325_Er29_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0421/173418_u2N4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;扣子空间有什么特点？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🌟从回答问题，到解决问题，让 Agent 帮你完成更多的工作&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;自动分析需求，拆解为多个子任务&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自主调用工具（浏览器、代码编辑器等），执行任务&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;输出完整的结果报告，例如网页、PPT 、飞书文档等&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🌟&lt;strong&gt;专家 Agent 生态，让更专业 Agent 来为你提供服务&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;「华泰 A 股观察助手」可以为你进行每日早报生成；针对股票分析问题，助手也能可以为你答疑解惑&lt;br&gt; &lt;img height=&quot;567&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0421/173807_CWme_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;「用户研究专家 」可以协助你进行用研资料深度分析，省时省力地助你获取更多用户洞察&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🌟&lt;strong&gt;探索/规划双模式，更好地和 Agent 一起协作完成高难度任务&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;探索模式：让 AI 自主动态探索，完成速度更快&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;规划模式：让 AI 深度思考，适合高复杂性任务&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🌟&lt;strong&gt;MCP 扩展集成，无限拓展 Agent 能力边界&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;首批官方支持飞书多维表格、高德地图、图像工具、语音合成等 MCP&lt;br&gt; &lt;img height=&quot;566&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0421/173727_B7jG_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;即将支持「扣子开发平台」发布 MCP 至「扣子空间」&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;扣子空间官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.coze.cn%2F&quot; target=&quot;_blank&quot;&gt;https://space.coze.cn/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345779/coze-space-preview</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345779/coze-space-preview</guid>
            <pubDate>Sun, 13 Apr 2025 09:34:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 旗下 APP 禁用苹果 Apple Intelligence</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;外媒报道称，苹果最新推出的 Apple Intelligence 功能在 Meta 旗下应用（包括 Facebook、Instagram、WhatsApp 和 Threads）中遭到禁用，用户无法使用其核心功能，如写作工具 (Writing Tools) 和自定义表情符号生成器 (Genmoji)。此举被认为与 Meta 推动自家 Meta AI 工具的战略有关。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;223&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2e17e1e4324f772634e33ac142954924659.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Apple Intelligence 是苹果于 2024 年随 iOS18 推出的 AI 功能套件，旨在通过智能写作、图像生成和个性化体验提升用户生产力。其中，写作工具可实现文本校对、改写和总结，Genmoji 则允许用户生成定制化表情符号。这些功能通常通过长按 iOS 文本输入框激活，理论上适用于大多数应用。然而，Meta 旗下应用已明确禁用这些功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;自 2024 年 12 月起，Meta 开始逐步移除对 Apple Intelligence 的支持。用户在 Facebook、Instagram、WhatsApp 和 Threads 中无法调用写作工具或 Genmoji，甚至此前可在 Instagram Stories 中使用的 Memoji 和键盘贴纸功能也被移除。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;相比之下，X（原 Twitter）、Bluesky 和 Signal 等第三方应用仍支持 Apple Intelligence 的写作工具。值得注意的是，Apple Intelligence 在浏览器版本的 Meta 服务中仍可正常使用，因为浏览器环境不受 Meta 应用的限制。苹果开发者文档显示，iOS 和 iPadOS 应用需主动选择启用 Apple Intelligence 功能，而 Meta 显然选择了禁用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 并未公开解释禁用 Apple Intelligence 的原因，但业内普遍认为，此举旨在推广其自研的 Meta AI 工具。Meta AI 基于 Llama 模型，已深度整合至 Facebook、Instagram、WhatsApp 和 Threads，提供文本生成、图像创作和搜索增强等功能。例如，在 Instagram 中，用户尝试编辑文本时，会看到「Write with AI」选项，引导至 Meta AI 界面，而非 Apple Intelligence。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345768</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345768</guid>
            <pubDate>Sun, 13 Apr 2025 08:47:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI CEO：对 GPT 说谢谢会带来千万开销</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI CEO Sam Altman 近日在社交媒体回复网友称，OpenAI 仅仅为了处理用户日常的寒暄和礼貌性交流，就需要花费「数千万美元」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fd16677fc16d984d5d09457cb0d9c467367.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，「谢谢」「请」，这些看似微不足道的礼貌用语，虽然在情感上让用户与 AI 的互动显得更有「人味」，但其背后却带来高昂的能源消耗。&lt;/p&gt; 
&lt;p&gt;最新报告指出，即使是像「不客气」这样的简短回复，大型语言模型（LLM）也需要消耗大约 40-50 毫升的水。&lt;/p&gt; 
&lt;p&gt;虽然礼貌的用语会增加 OpenAI 每月的资源支出，但该公司似乎并不介意。目前，许多用户已经不再将 AI 看作一个冷冰冰的工具，而是能够带情感化交流的「虚拟用户」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c2a9253b61a8988e0b8eb110384ab80d1b2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而据 OpenAI 和麻省理工学院的研究人员指出，随着 AI 对话越来越难以与人类对话区分开来，用户可能会对 AI 聊天机器人产生情感依赖，甚至出现成瘾的情况。而这种成瘾可能会导致用户在离开 AI 时出现类似戒断反应的症状。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345767</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345767</guid>
            <pubDate>Sun, 13 Apr 2025 08:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Intel 开源专为本地生成式 AI 设计的 AI Playground</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Intel 近日宣布，其专为本地生成式 AI 设计的 AI Playground 软件正式开源，为 Intel Arc GPU 用户提供了一个强大的 AI 模型运行平台。AI Playground 支持多种图像、视频生成模型以及大型语言模型（LLMs），通过优化本地计算资源，显著降低了 AI 应用的硬件门槛。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;401&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0f8a10ae7e6da81cf50fdc5a2b76750462c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;核心功能：多模态 AI 模型一站式支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Playground 作为一款用户友好的「AI 中心」，集成了丰富的生成式 AI 功能，涵盖图像生成、图像风格化、文本生成与聊天机器人等场景。AIbase 梳理了其支持的模型与功能:&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;图像与视频生成：支持 Stable Diffusion1.5、SDXL、Flux.1-Schnell 和 LTX-Video 模型，可实现文本到图像、图像风格化以及文本到视频生成，生成结果在分辨率与细节上表现出色。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;大型语言模型：兼容 Safetensor PyTorch 格式的 DeepSeek R1、Phi3、Qwen2、Mistral，以及 GGUF 格式的 Llama3.1、Llama3.2，结合 OpenVINO 优化的 TinyLlama、Mistral7B、Phi3mini 和 Phi3.5mini，提供高效的本地聊天与推理能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;ComfyUI 工作流：通过集成 ComfyUI，AI Playground 支持高级图像生成工作流，如 Line to Photo HD 与 Face Swap，提升创作灵活性。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Playground 不直接附带模型，用户需从 Hugging Face 或 CivitAI 下载模型并放置于指定文件夹，平台提供直观的模型加载界面，确保操作简便。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;技术架构：OpenVINO 优化本地性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Playground 基于 Intel 的 OpenVINO 框架，针对 Arc GPU 与 Core Ultra 处理器进行了深度优化。AIbase 分析，其关键技术包括:&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenVINO 加速：为聊天与图像生成提供高效推理支持，显著提升低 vRAM 设备（如 8GB Arc GPU）的性能。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Llama.cpp 与 GGUF 支持：实验性后端扩展了 GGUF 模型的兼容性，预填充模型列表简化用户配置。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;模块化设计：通过 Add Model 功能，用户可直接输入 Hugging Face 模型 ID 或本地路径，灵活加载自定义模型。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;硬件要求方面，AI Playground 支持 Intel Core Ultra-H/V 处理器或 Arc A/B 系列 GPU（最低 8GB vRAM）。尽管为开源 Beta 版，Intel 提供了详细的故障排查指南，确保用户快速上手。低 vRAM 设备在运行 SDXL 等高分辨率模型时可能速度较慢，建议优先使用 Flux.1-Schnell 等轻量化模型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345762</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345762</guid>
            <pubDate>Sun, 13 Apr 2025 08:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>【直播】如何让 AI 「跑得快」 又 「用得好」？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;当前，人工智能技术正加速向大模型时代迈进，在政务、金融、医疗、工业等领域展现出颠覆性潜力。然而，大模型的训练与部署面临算力成本高、技术生态依赖性强、行业落地门槛高三大挑战。在此背景下，升腾与国产大模型的深度结合，为破解上述瓶颈提供了新路径。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;为加速技术普惠，&lt;span style=&quot;color:#2980b9&quot;&gt;4 月 23 日晚&lt;/span&gt;，开源中国直播栏目《数智漫谈》邀请&lt;span style=&quot;color:#2980b9&quot;&gt;升腾生态技术专家与行业先行者&lt;/span&gt;，分享一线开发经验，聊一聊升腾结合大模型，如何促进创新，助力开发者与企业用户抓住国产 AI 新红利。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;🌟&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;演讲议题 1：升腾插件化接入 vLLM 加速大模型推理创新最佳实践&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;演讲专家：&lt;/strong&gt;姚圣伟，华为云 HCDE、微软 Insider Dev Tour China&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;议题简介：&lt;/strong&gt;随着大模型技术的快速发展，如何高效部署与加速推理成为业界核心挑战。基于自主研发的升腾处理器及 CANN 异构计算架构，升腾推出插件化接入方案，与开源推理框架 vLLM 深度适配，为大模型推理提供高性能、低时延的创新实践。用户可以实现自己的 Woker、ModelRunner、Attention、Communicator 以及自定义算子。在进一步促进 vLLM 多样性发展的同时，尽可能的解决了兼容性、可维护性的问题。实践案例覆盖自然语言处理、多模态交互等场景，验证了升腾生态的开放性与技术普适性，为行业提供可复用的国产化大模型部署范式，推动 AI 基础设施高效进化。&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;🌟&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;演讲议题 2：基于升腾+大模型的国内智慧园区项目实践&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;演讲专家：&lt;/strong&gt;李小雨，唐山爱尚产品总监，AI 应用探索者与出海实践者&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;议题介绍：&lt;/strong&gt;年初 Deepseek 引发了国产大模型浪潮，国内涌现大量需要通过 AI 提效、优化体验的需求。但是目前大部分传统行业对于 AI 提效的具体实践还在探索中，没有明确的 AI 落地场景。智慧园区为我们为某国企开发的系统，包括车辆道闸、人脸终端消费、考勤机、监控筒机等多种类业务、多种类设备，是集成一脸通、一平台、数据共享、数据可视的完整解决方案。本次分享，我们站在企业的角度分析 AI，能给实际业务带来哪些方式的效率提升，并结合实际的某智慧园区项目，分享如何结合升腾与大模型，在产品体验和功能形态上做出创新和提效。&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;🌟&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;演讲议题 3：基于香橙派 AI Studio 实现本地大模型部署和应用最佳实践&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;演讲专家：&lt;/strong&gt;徐洋帆，香橙派系统工程师，升腾社区核心开发者&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;议题简介：&lt;/strong&gt;随着大模型技术的快速发展，个人和企业对大模型的需求呈现爆发式增长。在云端大模型层出不穷的同时，隐私安全问题也日渐严峻。因此实现低成本的本地化 AI 大模型部署和应用势在必行。香橙派携手华为升腾，推出了 orangePi AI studio 和 orangePi AI studio Pro 产品，旨在为用户提供低成本的本地化 AI 大模型部署能力。在本次议题中，香橙派将展示算力高达 352Tops，超大的 192G 显存的 orangePi AI studio Pro 产品上极简部署 AI 大模型的步骤，半小时实现从 0 到体验本地 AI 聊天机器人。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;微信扫码，预约直播：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;930&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d0ffe73416168db3a2cde17f3629df8acb.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;另外，我们还建了一个交流群，一起聊聊自己 AI 技术～～当然啦，如果你有什么特别棒的开源项目，可以推荐过来呀～&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;559&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-579ffec27c910f889cf6d9bbcfc234e8144.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;【数智漫谈】&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OSCHINA 视频号直播畅聊栏目【数智漫谈】，每期一个技术话题，三五位专家围坐，各抒己见，畅聊开源。给大家带来最新的行业前沿、最热门的技术话题、最有趣的开源项目、最犀利的思想交锋。如果你手上也有新点子、好项目，想要跟同行交流分享，欢迎联系我们，讲坛随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18211605</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18211605</guid>
            <pubDate>Sun, 13 Apr 2025 08:02:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>GoFr —— 微服务开发框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;GoFr 旨在&lt;strong style=&quot;color:#1f2328&quot;&gt;简化微服务开发&lt;/strong&gt;，重点关注&lt;strong style=&quot;color:#1f2328&quot;&gt;Kubernetes 部署&lt;/strong&gt;和&lt;strong style=&quot;color:#1f2328&quot;&gt;开箱即用的可观察性&lt;/strong&gt;。虽然它能够构建通用应用程序，但&lt;strong style=&quot;color:#1f2328&quot;&gt;微服务&lt;/strong&gt;仍然是其核心。&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h4&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;主要特点&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简单的 API 语法&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;默认的 REST 标准&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;配置管理&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/quick-start/observability&quot;&gt;可观察性&lt;/a&gt;&lt;/strong&gt;（日志、跟踪、指标）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内置&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/http-authentication&quot;&gt;身份验证中间件&lt;/a&gt;&lt;/strong&gt;和自定义中间件支持&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/grpc&quot;&gt;gRPC 支持&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;支持断路器的&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/http-communication&quot;&gt;HTTP 服务&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/using-publisher-subscriber&quot;&gt;发布/订阅&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;所有数据源的&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/monitoring-service-health&quot;&gt;健康检查&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/handling-data-migrations&quot;&gt;数据库迁移&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/using-cron&quot;&gt;计划任务&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持无需重启即可&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/remote-log-level-change&quot;&gt;更改日志级别&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/swagger-documentation&quot;&gt;Swagger 渲染&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/handling-file&quot;&gt;Abstracted File Systems&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://gofr.dev/docs/advanced-guide/handling-file&quot;&gt;WebSockets&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/gofr</link>
            <guid isPermaLink="false">https://www.oschina.net/p/gofr</guid>
            <pubDate>Sun, 13 Apr 2025 07:59:00 GMT</pubDate>
        </item>
        <item>
            <title>微软近 5 万 star 的开源项目 —— MarkItDown 已支持 MCP</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;MarkItDown 是微软开源的 Python 实用工具库，支持将各种文件转换为 Markdown 格式，适用于索引、文本分析等用途。&lt;/p&gt; 
&lt;p&gt;MarkItDown 目前支持以下文件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;图片（EXIF 元数据和 OCR）&lt;/li&gt; 
 &lt;li&gt;音频（EXIF 元数据和语音转录）&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;基于文本的格式（CSV、JSON、XML）&lt;/li&gt; 
 &lt;li&gt;ZIP 文件（遍历内容）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该项目最近发布了一项「史诗级」更新 —— 支持 MCP。MarkItDown 现已提供 MCP（模型上下文协议）服务器 (MarkItDown-MCP)，以便与 LLM 应用程序如 Claude Desktop 集成。&lt;/p&gt; 
&lt;p&gt;MarkItDown-MCP 提供两种主要的服务器模式：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;STDIO 模式&lt;/strong&gt;（默认）：通过标准输入/输出进行通信，非常适合与命令行工具和脚本集成。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;SSE 模式&lt;/strong&gt;&lt;/strong&gt;：作为服务器发送事件 (Server-Sent Events) 服务器在指定主机和端口上运行，支持基于 Web 和网络的集成。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Docker 支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了增强可移植性和隔离性，MarkItDown-MCP 提供了 Docker 支持。这在以下情况特别有用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;确保在不同系统上的环境一致性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将转换过程与主机系统隔离&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;与 Claude Desktop 等远程服务协作&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Docker 集成包括挂载本地目录的功能，允许容器访问和转换本地文件，同时维持安全边界。&lt;/p&gt; 
&lt;p&gt;更多信息查看&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fmarkitdown%2Ftree%2Fmain%2Fpackages%2Fmarkitdown-mcp&quot; target=&quot;_blank&quot;&gt;markitdown-mcp&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345742/markitdown-mcp-server</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345742/markitdown-mcp-server</guid>
            <pubDate>Sun, 13 Apr 2025 07:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>如何使用 jiascheduler 替换 salt 批量广播执行脚本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;h2&gt;背景&lt;/h2&gt; 
&lt;/div&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;在运维场景下，我们经常要推送一些脚本到大量的机器上执行，比如我们需要修改生产所有虚机的 dns，一般而言用户需要实现这个功能可以借助譬如 salt 这样的传统运维管理工具，也可以自己开发功能，循环通过 ssh 连接到目标节点执行脚本&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;对于 salt 这类工具执行过程不透明，执行失败率较高，难以审计，主要依赖运维人员自身。&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;开发脚本的话难度较高，难以复用，耗时耗力。&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;针对以上难题，jiascheduler 默认提供广播执行模式，可以一次将脚本推送到数以万计的实例执行，并且实时收集执行结果。&lt;/p&gt; 
&lt;div&gt; 
 &lt;h2&gt;开始使用&lt;/h2&gt; 
&lt;/div&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;我们将会针对&lt;code&gt;修改 dns&lt;/code&gt;这个具体的应用场景，演示如何使用 jiascheduler。使用之前，我们需要做一些准备工作，如创建团队，创建作业，设置标签等...&lt;/p&gt; 
&lt;div&gt; 
 &lt;h3&gt;设置团队&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;code&gt;jiascheduler&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;支持根据职责设置不同团队，我们首先创建&lt;code&gt;dns 维护&lt;/code&gt;团队，后续我们可以方便的将所有运维相关脚本存放到该团队&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;902&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-48167be5490eae4866222114b6db2e9183f.jpg&quot; width=&quot;1897&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;设置过团队以后，我们可以在导航栏右上角切换不同团队&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;573&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-30cefaae3f91cee3a568bcda163fc11ccfa.jpg&quot; width=&quot;938&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;团队选择好之后，我们就可以开始创建作业了&lt;/p&gt; 
&lt;div&gt; 
 &lt;h3&gt;创建作业&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;作业对应用户的执行脚本，这里我们创建了一个修改 dns 的作业&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;949&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-808fe88c078e1b263f78741bdd8ccb0f222.jpg&quot; width=&quot;1894&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;我们可以在编辑作业时，设置执行用户，脚本超时，执行目录等，开启大盘显示后，作业的执行状态会同步展示在用户工作台中&lt;/p&gt; 
&lt;div&gt; 
 &lt;h3&gt;广播推送&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;准备好作业之后我们就可以开始广播推送了，点击启动开始配置目标执行节点。&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;img alt=&quot;广播推送&quot; src=&quot;https://oscimg.oschina.net/oscnet//fe1e76ff76aa92704ca543100d5a1a02.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;推送之后会生成一条调度记录，调度记录包含了当前作业的快照和执行该脚本的所有的目标节点，基于调度记录我们可以对调度进行重放（启动，停止）。&lt;/p&gt; 
&lt;div&gt; 
 &lt;h3&gt;查看执行结果&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;在运行列表中，我们可以实时查看节点的执行状态，并对运行中的作业进行干涉，运行状态提供了针对单个节点，单个作业的更细粒度的控制。&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;img alt=&quot;运行列表&quot; src=&quot;https://oscimg.oschina.net/oscnet//944a2e7055c794ddeb997b4588638c67.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;如果我们一次调度中的执行节点有多个，我们期望一次全部停止当前运行的作业，那么我们可以从调度记录中执行这些快捷操作，调度记录中还记录了当前调度的作业快照状态，作业的执行记录等。&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;调度详情中的执行记录汇总了当次调度中所有节点的执行结果，供用户方便的找出执行异常的实例。&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;img alt=&quot;调度记录&quot; src=&quot;https://oscimg.oschina.net/oscnet//181cab76e184e72425fbd1fc0863e9fc.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;最后，jiascheduler 把所有的执行记录放在了一个专有的菜单，供用户审计&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;img alt=&quot;执行记录&quot; src=&quot;https://oscimg.oschina.net/oscnet//e99ebddbd61b05136eb11622194b94b4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345741</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345741</guid>
            <pubDate>Sun, 13 Apr 2025 07:36:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>宇树科技将举办全球首场「人形机器人格斗大赛」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025 年 5 月至 6 月，杭州的宇树科技将举办全球首场「人形机器人格斗大赛」。据悉，宇树科技的技术团队在过去数周内进行高强度的算法训练与硬件调试，为这场比赛打造了最强的参赛机器人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次比赛将通过中央广播电视总枱的相关平台全网直播。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;360&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b3acd1231b7817a91dee16dee6276eecb65.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了预热赛事，宇树科技发布了视频《Unitree 铁甲拳王：觉醒！》。视频中，参赛的 G1 人形机器人不仅展现了卓越的灵活性与迅猛的出拳能力，还能够完成左右勾拳、侧踢等高难度格斗动作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;特别引人注目的是，在被击倒后，G1 能够迅速自我恢复并重新投入战斗。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345738</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345738</guid>
            <pubDate>Sun, 13 Apr 2025 07:29:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>H.266 席卷头部平台成主流：渗透率超 70%、比 H.265 视频减小一半</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在近期由阿里巴巴达摩院举办的视频技术前沿研究与应用研讨会上，达摩院视频技术实验室负责人叶琰介绍，新一代视频编解码标准 H.266 正从成熟走向主流，在头部视频平台的渗透率已超 70%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d7871b9c0453ba3ab7b384ad1bb0145b8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;叶琰还表示，达摩院正在积极推进自研视频编解码方案 DAMO266 的应用推广与生态共建。&lt;/p&gt; 
&lt;p&gt;当前视频应用消耗全网超过 80% 的流量，且 4K 等超高清内容占比持续上升，这就需要算法更先进、压缩性能更强的编解码技术，&lt;strong&gt;相较于 H.265 标准，H.266 在保证相同视频质量下，可减少约 50% 的数据大小与带宽成本&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0421/151436_BZat_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;叶琰指出，H.266 标准正在成为越来越多企业的选择，在国内头部视频平台中，top 5 短视频平台均已上线 H.266 服务，top 5 长视频平台中 2 家已上线、2 家正调研或计划上线。&lt;/p&gt; 
&lt;p&gt;对于企业而言，采用 H.266 标准可获得单流 50% 的带宽节省收益，约等同于 16% 的综合成本下降，并提升用户体验，如流量消耗减半、卡顿率减半等。&lt;/p&gt; 
&lt;p&gt;而阿里巴巴自研 DAMO266 是业内少数较为成熟的 H.266 标准解决方案，已在多个国民级应用落地，处理的日均视频播放量（VV）已破亿，超过 99% 的移动设备支持 DMAO266 软解。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0421/151459_Y29u_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;达摩院还积极与行业伙伴共建 H.266 生态，联合优酷、vivo 推出了业内首个 H.266 手机软解异构优化方案，在 1080P 60fps 的优酷帧享视频播放场景下实现 17% 的解码提速和 13% 的功耗下降；与高通合作，在搭载骁龙 X Elite 的 Windows 11 AI PC 上首次实现 4K 120fps 视频的流畅播放。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;参考：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTCb8FhZdf-ctegim-4N1wA&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/TCb8FhZdf-ctegim-4N1wA&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345734</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345734</guid>
            <pubDate>Sun, 13 Apr 2025 07:15:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 详解 o3、o4-mini 和 o3-mini 使用限制</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 在最近更新的一份文档中详细&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.openai.com%2Fen%2Farticles%2F9824962-openai-o3-o4-mini-and-o3-mini-usage-limits-on-chatgpt-and-the-api%23h_0151d07654&quot; target=&quot;_blank&quot;&gt;阐述&lt;/a&gt;了 o3、o4-mini 和 o3-mini 三种新推理在 ChatGPT 和 API 上的使用限制。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;具体来说，ChatGPT Plus、Team 或 Enterprise 帐户，每周可以使用 o3 访问 50 条消息，每天可以使用 o4-mini 访问 150 条消息，每天可以使用 o4-mini-high 访问 50 条消息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于 ChatGPT Pro 用户，OpenAI 称其提供「接近无限制」的 o3、o4-mini 和 4o 访问权限。前提是必须遵守一些&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fterms%2F&quot; target=&quot;_blank&quot;&gt;使用条款&lt;/a&gt;，&lt;span style=&quot;color:#1a1a1a&quot;&gt;禁止以下行为：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#1a1a1a&quot;&gt;滥用，例如自动或以编程方式提取数据。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#1a1a1a&quot;&gt;共享帐户凭据或向任何其他人提供帐户。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;转售访问权限或使用 ChatGPT 为第三方服务提供支持。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 在文档中指出：「我们已设置安全防护措施以防止滥用，并始终致力于改进我们的系统。这可能偶尔会涉及暂时限制您的使用。发生这种情况时，我们会通知您。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该公司预计将在几周内发布 OpenAI o3‑pro，并提供全面的工具支持。目前，Pro 用户仍然可以使用 o1‑pro。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;所有付费使用套餐的 API 用户均可使用 o1、o3 和 o4-mini 模型。可参阅&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Frate-limits%2Fusage-tiers&quot; target=&quot;_blank&quot;&gt;平台文档&lt;span style=&quot;color:#000000&quot;&gt;，&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;查看各套餐的速率限制。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345733/openai-o3-o4-mini-and-o3-mini-usage-limits</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345733/openai-o3-o4-mini-and-o3-mini-usage-limits</guid>
            <pubDate>Sun, 13 Apr 2025 07:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>深圳大学人工智能学院正式揭牌成立</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今天（4 月 21 日）深圳大学人工智能学院正式揭牌成立。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;853&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0421/150304_YzCt_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，深圳大学人工智能学院，是响应国家人工智能发展战略，契合大湾区产业蓬勃发展需求，在国家战略引领下积极布局的前沿学院，致力打造人工智能领域的教育与科研高地。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FyLhYKWCdvOSrwJE94SzOjQ&quot; target=&quot;_blank&quot;&gt;据报道&lt;/a&gt;&lt;/u&gt;，深圳大学人工智能学院首批汇聚了一批国内外顶尖人才，构建包含 2 位中国科学院院士、1 位日本工程院院士、5 位国家级人才、2 位国家青年人才的约 80 人教研团队。&lt;/p&gt; 
&lt;p&gt;学院构建「需求牵引、突破关键、百花齐放」的科研体系，依托全国重点实验室、国家工程实验室等强大平台，建设基础学科研究中心和算力平台，与腾讯云共建产业学院，为科研创新、技术转化和人才培养提供坚实保障。&lt;/p&gt; 
&lt;p&gt;学院以创新的学科布局，构建起全面的本硕博一体化专业体系，学科方向覆盖人工智能基础理论、具身智能等前沿。&lt;/p&gt; 
&lt;p&gt;今年 2 月 13 日，香港中文大学（深圳）正式成立人工智能学院，计划于 2025 年 9 月招收首批学生，拟开设人工智能本科专业及人工智能哲学硕士-博士项目。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345730</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345730</guid>
            <pubDate>Sun, 13 Apr 2025 07:05:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>罗永浩创业公司细红线招聘多名算法工程师</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;罗永浩今天在微博发布了一则招聘公告，为创业公司细红线招聘多名算法、研发工程师。工作地点均为上海：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;资深互联网产品经理（5 名）&lt;/li&gt; 
 &lt;li&gt;多模态大语言模型微调算法工程师（6 名）&lt;/li&gt; 
 &lt;li&gt;多模态信息检索算法工程师（4 名）&lt;/li&gt; 
 &lt;li&gt;大语言模型微调算法工程师（5 名）&lt;/li&gt; 
 &lt;li&gt;桌面端研发工程师（5 名）&lt;/li&gt; 
 &lt;li&gt;资深后端研发工程师（搜索方向）（4 名）&lt;/li&gt; 
 &lt;li&gt;AI 后端开发工程师（5 名）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;453&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5ab9b4bd073e70cc29c7664c17f163eaab.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据 XR Vision 昨日报道，罗永浩旗下细红线科技早在 2024 年已放弃 AR 智能眼镜类产品研发，继而转向为 AI 智能硬件和 AI 大模型的研发。但 2025 年年初在 AI 智能硬件完成之后，整个硬件团队已被全部裁撤，只留下 20 多个软件工程师负责 AI 软件相关产品的研发和打磨，继续完成软硬件一体的产品在海外上市和销售。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345697</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345697</guid>
            <pubDate>Sun, 13 Apr 2025 05:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>讯飞星火 X1 全新升级，基于全国产算力训练的深度推理大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;科大讯飞今日官宣，讯飞星火 X1 全新升级，号称是「&lt;strong&gt;当前&lt;strong&gt;&lt;strong&gt;业界&lt;/strong&gt;&lt;/strong&gt;唯一&lt;/strong&gt;的基于全国产算力训练的深度推理大模型」，&lt;/p&gt; 
&lt;p&gt;本次升级有这些关键信息⬇️&lt;/p&gt; 
&lt;p&gt;✨实现了数学、代码、逻辑推理、文本生成、语言理解、知识问答等通用任务效果显著提升，&lt;strong&gt;在模型参数&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;比业界同类模型小一个数量级&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;的情况下，&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;整体效果&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;对&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;标&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;OpenAI o1 和 DeepSeek R1&lt;/strong&gt;，再次证明了&lt;/strong&gt;基于国产算力训练的全栈自主可控大模型具备登顶业界最高水平的实力和持续创新的潜力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;✨融入了更多场景复杂类型数据，模型的泛化性也取得了进步，多个行业任务上展现出了业界领先的能力，&lt;strong&gt;在重点行业如教育、医疗、司法等进一步扩大了领先优势&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;✨&lt;strong&gt;首发快思考、慢思考统一模型&lt;/strong&gt;，由一个模型同时支持两种思考模式，私有化部署简便；&lt;strong&gt;全新升级模型定制优化工具链&lt;/strong&gt;，支持 SFT、强化学习两种模型定制优化方案，&lt;strong&gt;定制门槛低。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;✨&lt;strong&gt;三大核心技术创新&lt;/strong&gt;——大规模多阶段强化学习训练方法、基于快慢思考的统一训练方法、工程技术系统创新保障基于国产算力的高效长稳训练，助力星火 X1 全面升级。&lt;/p&gt; 
&lt;p&gt;✨&lt;strong&gt;星火 X1 API 已同步上线讯飞开放平台&lt;/strong&gt;，面向广大开发者和企业开放服务。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;据介绍，此次星火 X1 升级，在多个任务上效果继续突破，展现出优异的性能。根据最新测试集评测结果，&lt;strong&gt;星火 X1 在通用任务效果评测中全面对标 OpenAI o1 和 DeepSeek R1&lt;/strong&gt;，在数学、知识问答等方面表现突出。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;857&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0421/115133_nUoJ_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;星火 X1 此次全新升级，背后有三大技术创新：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、大规模多阶段强化学习训练方法&lt;/strong&gt;：提出基于问题难度的大规模多阶段强化学习方法，在复杂推理、数学、代码、语言理解等场景全面提升模型效果及泛化性；同时提出强化学习动态更新算法，基于样本采样长度动态调整强化学习更新速度，进一步提升深度思考强化学习效率及效果。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、基于快慢思考的统一训练方法&lt;/strong&gt;：提出统一模型下快慢思考混合训练方法，充分发挥快慢思考数据相互促进作用，实现基于系统指令控制模型是否深度思考，支撑下游更高效便捷地部署使用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、工程技术系统创新保障基于国产算力的高效长稳训练&lt;/strong&gt;：实现多项工程技术创新，显存动态卸载技术大幅提升长文本推理并发、训推共卡协同实现高效训推资源转换、推理引擎冬眠机制实现快速拉起和恢复，实现国产算力平台上高效和稳定的强化学习训练全流程。&lt;/p&gt; 
&lt;p&gt;访问&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxinghuo.xfyun.cn%2Fsparkapi&quot; target=&quot;_blank&quot;&gt;https://xinghuo.xfyun.cn/sparkapi&lt;/a&gt;&amp;nbsp;体验星火 X1 API&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345688</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345688</guid>
            <pubDate>Sun, 13 Apr 2025 03:53:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>CISA 扩大资金投入，确保「关键 CVE 服务不出现中断」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;CISA 表示，美国政府已扩大资金投入，以确保关键的通用漏洞和暴露 (CVE) 计划不会出现连续性问题。这家美国网络安全机构表示：「CVE 项目对网络社区至关重要，也是 CISA 的首要任务。昨晚，CISA 执行了合同中的选择期，以确保关键的 CVE 服务不会出现中断。我们感谢合作伙伴和利益相关者的耐心。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1f100a8af5b380712b4c8e12772bf8e3305.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此前，MITRE 副总裁 Yosry Barsoum 曾警告称，政府对 CVE 和 CWE 项目的资助将于今天（4 月 16 日）到期，这可能会导致整个网络安全行业出现大范围混乱。&lt;/p&gt; 
&lt;p&gt;Barsoum 表示：「如果服务中断，我们预计 CVE 将受到多重影响，包括国家漏洞数据库和公告、工具供应商、事件响应操作以及各种关键基础设施的恶化。」&lt;/p&gt; 
&lt;p&gt;MITRE 维护着&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcve.mitre.org%2F&quot; target=&quot;_blank&quot;&gt;CVE&lt;/a&gt;，这是一个被广泛采用的计划，它在讨论安全漏洞时提供准确性、清晰度和共享标准，资金来自美国国土安全部 (DHS) 的国家网络安全部门。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;新成立的 CVE 基金会&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 CISA 宣布这一消息之前，一组 CVE 董事会成员宣布成立 CVE 基金会，这是一个非营利组织，旨在确保 CVE 计划的独立性，因为 MITRE 警告称美国政府可能不会续签管理该计划的合同。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/165002_yPMw_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thecvefoundation.org%2Fhome&quot; target=&quot;_blank&quot;&gt;他们在上周三的新闻稿中表示&lt;/a&gt;： 「自成立以来，CVE 项目一直由美国政府资助，并通过合同进行监督和管理。虽然这种结构支持了项目的发展，但也引发了 CVE 董事会成员长期以来的担忧，他们担心一个全球依赖的资源与单一政府资助机构捆绑在一起，其可持续性和中立性会受到影响。」&lt;/p&gt; 
&lt;p&gt;在过去的一年里，参与启动的人员一直在制定一项战略，将该计划过渡到这个专门的基金会，消除「漏洞管理生态系统中的单点故障」，并确保「CVE 计划仍然是一个全球信赖的、社区驱动的计划」。&lt;/p&gt; 
&lt;p&gt;虽然 CVE 基金会计划在未来几天发布有关其过渡计划的更多信息，但下一步行动仍不明确，特别是考虑到 CISA 已确认 MITRE 合同的资金已延长。&lt;/p&gt; 
&lt;p&gt;欧盟网络安全局 (ENISA) 还推出了欧洲漏洞数据库 (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feuvd.enisa.europa.eu%2F&quot; target=&quot;_blank&quot;&gt;EUVD&lt;/a&gt;&amp;nbsp;)，该数据库「通过从多个来源收集公开的漏洞信息，采取多利益相关方方式」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/345117/the-cve-foundation&quot; target=&quot;news&quot;&gt;CVE 基金会成立&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/345038&quot; target=&quot;news&quot;&gt;美国政府不再为 CVE/CWE 项目提供资金支持&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345685</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345685</guid>
            <pubDate>Sun, 13 Apr 2025 03:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek-V3 技术解析」：DeepSeek-V3-Base 预训练阶段解析</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 这篇技术解析详细阐述了 DeepSeek-V3-Base 的预训练阶段所采用的关键技术。&lt;/p&gt; 
 &lt;p&gt;文章重点介绍了三项核心技术：Document Packing 技术有效解决了输入序列长度差异导致的资源浪费问题；Fill-in-the-Middle（FIM）采用 PSM 框架和特殊 tokens，使模型具备上下文感知的中间内容生成能力；基于 YaRN 的长上下文窗口扩展技术则通过频率插值策略解决了位置编码的扩展挑战。&lt;/p&gt; 
 &lt;p&gt;随后，文章详细描述了 DeepSeek-V3-Base 的预训练过程，包括数据构建、训练策略和评估结果。&lt;/p&gt; 
 &lt;p&gt;评估显示，这些技术组合使 DeepSeek-V3 每训练 1T token 仅需 180K NVIDIA H800 GPU 小时数，并在&quot;大海捞针&quot;测试中展现卓越的长文本理解能力，为后续 RL 阶段奠定了优质基座。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shirley Li&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这是 DeepSeek 系列文章的第五篇，也是首篇聚焦 DeepSeek-V3 [1, 2] 训练流程的文章。&lt;/p&gt; 
&lt;p&gt;如下图所示，DeepSeek-V3 的训练分为多个阶段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;产出 DeepSeek-V3-Base 基础模型的预训练阶段&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基于 DeepSeek-V3-Base，通过大规模强化学习（RL）分别训练出 DeepSeek-R1-Zero（无需监督式微调冷启动）和 DeepSeek-R1（含有监督式微调）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;利用 DeepSeek-R1 生成推理数据，用于 DeepSeek-V3 的监督式微调（SFT），接着是未在图中展示的 RL 阶段。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71379f71e34c5adf46d001de06b46394737.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 1. DeepSeek-V3 训练流程示意图（由原文作者绘制）&lt;/p&gt; 
&lt;p&gt;本文将重点关注产出 DeepSeek-V3-Base 的预训练阶段，阐述该阶段实现高效预训练的关键技术。后续文章将涵盖：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;群组相对策略优化（GRPO）[7]&lt;/li&gt; 
 &lt;li&gt;DeepSeek-R1-Zero 和 DeepSeek-R1 的训练细节&lt;/li&gt; 
 &lt;li&gt;DeepSeek-V3 的后训练阶段（监督式微调与 RL 阶段）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;技术背景&lt;/strong&gt;：解析 DeepSeek-V3 预训练阶段的相关技术，包括 Document Packing，Fill-in-Middle 和 long context extension。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;预训练阶段&lt;/strong&gt;：详解如何构建预训练数据、强调一些关键的训练策略，并回顾评估结果。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;01 技术背景&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本节将介绍预训练 DeepSeek-V3 过程中使用的几种技术，包括 document packing、Fill-in-the-Middle（FIM）和基于 YaRN 的长上下文窗口扩展技术。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 Document Packing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;要理解为什么需要 document packing，我们首先需要回顾一下 Transformer 模型是如何构建输入序列 tokens 的。&lt;/p&gt; 
&lt;p&gt;Transformer 模型默认情况下需要固定长度的 token 序列作为输入，然而同一 batch 的文本输入往往长度不同。为了适应这种情况，文本输入通常需要经过以下预处理步骤：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;将所有原始文本输入分词为 token 序列&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;将 token 序列截断或填充到预定义的固定长度（max_seq_len）：若原始序列过长则截断，否则用特殊 [PAD] token 进行填充&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;生成掩码 IDs 使模型在训练时能忽略填充的 token&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为了更清晰地展示这个过程，以下这个示例我们将使用 GPT-2 [10]的分词器处理两个句子：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1b9f3887a8de379742b0f676da612804903.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;运行上述脚本后，会得到如下输出，其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一句话被填充了 4 个额外的 padding token，体现在 input_ids 和 mask_ids 中；&lt;/li&gt; 
 &lt;li&gt;第二句被截断，因此无需添加 padding token。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4e4ef991506b81b0784aa5c3673b1c09afb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 2. 填充操作示例（此图由作者绘制）&lt;/p&gt; 
&lt;p&gt;上述截断和填充方法虽然能让模型处理不同长度的输入，但当输入序列长度差异过大时（这在 LLM 训练中非常常见）会引发一系列问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;对超长序列，截断可能导致有用信息丢失&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;对较短的序列，填充过多 token 会造成计算资源浪费&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，LLM 训练通常采用 document packing 技术来处理输入序列。&lt;/p&gt; 
&lt;p&gt;更具体地说，如果给定若干长度不同的文档，我们首先将其分割为较小的块（chunk），如下图所示（用不同颜色代表不同文档）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f01ac2b3145cefa739b7a42248a7574c35c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 3. 文档分割（图片改编自文献[3]）&lt;/p&gt; 
&lt;p&gt;随后，我们将不同文档的块（chunk）进行拼接，以避免对长文档进行截断和对短文档进行填充：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ac5be1d745432dc595122a730f8cb882143.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 4. 传统拼接方式（图片改编自文献[3]）&lt;/p&gt; 
&lt;p&gt;在上例中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一个输入（译者注：图 4 第一行）仅包含文档 1 的 tokens&lt;/li&gt; 
 &lt;li&gt;第二个输入（译者注：图 4 第二行）拼接自文档 1 和文档 2 的 tokens&lt;/li&gt; 
 &lt;li&gt;第三个输入（译者注：图 4 第三行）拼接自文档 2 和文档 3 的 tokens&lt;/li&gt; 
 &lt;li&gt;第四个输入（译者注：图 4 第四行）拼接自文档 3、4、5 的 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;这种方法虽能在一定程度上避免进行填充和截断，但由于仅按数据中的相对顺序拼接来自不同文档的块（chunks），无法控制最终输入序列的构建方式。&lt;/strong&gt; 例如：文档 3（紫色）被不必要地分割为两部分，尽管其实际长度小于 max_seq_len，可以完整放入。&lt;/p&gt; 
&lt;p&gt;为了解决这个问题，文献 [3] 提出了 Best-fit Packing 技术，通过两个步骤完全消除不必要的分割：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Step 1：将每个文档分割为更小的块。&lt;/li&gt; 
 &lt;li&gt;Step 2：以一种智能的方式将这些块（chunks）分组为训练序列，确保在不进一步分割任何块（chunks）的前提下生成最少量的序列。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-409730df94907d865b72f59522cd798a544.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 5. Best-fit packing 技术（此图改编自文献[3]）&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 Fill-in-the-Middle（FIM）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在传统的自回归生成中，只能以从左到右的方式训练模型，即模型只能根据前面的 tokens 预测下一个 token。&lt;strong&gt;然而在实际应用中，模型常需根据上下文生成中间缺失的内容。&lt;/strong&gt; 尤其在代码生成场景中 ------ 我们常会给定输入/输出和部分代码片段，要求模型填充中间逻辑，如下例所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e731fcaf7f46097251e8e7202a61173df28.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了适配此类需求，文献 [4] 提出了一种简单有效的方法，称为 &quot;fill-in-the-middle&quot;：即将文档随机切分为 prefix、middle 和 suffix 三部分，然后将 middle 部分移至末尾：&lt;/p&gt; 
&lt;p&gt;由于数据组织形式为 &quot;Prefix-Suffix-Middle&quot;，该方法常被称为 PSM 框架。实际实现时通过添加特殊 token 来标记各部分的边界：&lt;/p&gt; 
&lt;p&gt;其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&amp;lt;|fim_begin|&amp;gt;和&amp;lt;|fim_hole|&amp;gt;标记 prefix 部分&lt;/li&gt; 
 &lt;li&gt;&amp;lt;|fim_hole|&amp;gt;和&amp;lt;|fim_end|&amp;gt;标记 suffix 部分&lt;/li&gt; 
 &lt;li&gt;&amp;lt;|fim_end|&amp;gt;和&amp;lt;|eos_token|&amp;gt;标记 middle 部分&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以如下输入为例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f337b48ebcf7340d63b8119d0d1842db85d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;若需模型预测第二行代码，可将该行作为 middle 部分，并构造 FIM 输入如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-826b6da51a2ee6ac5b1847427cb9b4ebece.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 6. PSM 框架示意图（此图由作者绘制）&lt;/p&gt; 
&lt;p&gt;此时模型的预期输出应为：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-85f95b26c05ae4243e57b8fbca16df200af.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 基于 YaRN 的长上下文窗口扩展技术&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;现代 LLM 常需处理极长的提示词（如整个代码仓库），但直接使用 128K 等长上下文窗口进行预训练并不现实。多数 LLM 采用分阶段渐进式扩展策略：先在较小的上下文窗口进行预训练，再分多个阶段逐步扩展到更长的上下文窗口，从而大大降低训练成本。&lt;/p&gt; 
&lt;p&gt;例如，在 DeepSeek-V3 中，模型首先使用 4K 的上下文窗口完成预训练，然后再分两阶段扩展到 128K：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;第一阶段：从 4K 到 32K（1000 steps）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;第二阶段：从 32K 到 128K（再 1000 steps）&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;需特别指出的是，这种扩展不能通过简单调大上下文窗口实现，而需借助基于旋转位置编码（RoPE）改进的 YaRN（Yet another RoPE extensioN）技术对位置编码进行修改。&lt;/p&gt; 
&lt;p&gt;关于 RoPE 的详细介绍，请参阅我们之前的文章《「DeepSeek-V3 技术解析」：多头潜在注意力机制（MLA）》。&lt;/p&gt; 
&lt;p&gt;RoPE 是一种相对位置编码方法，其核心思想是通过使用复杂的旋转嵌入修改 Query 和 Key，使得二者的内积依赖于它们的相对位置：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b844eb693468aac0d86585c525f0128cec8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然而，由于余弦函数和正弦函数是周期性的，(pos_i, pos_j) 之间的内积可能看起来与 (pos_i, pos_k) 之间的内积相似，因此在固定 θ 的情况下，仅使用 1K tokens（即位置索引 1~1000） 进行预训练的模型在测试时可能会混淆，因为测试时遇到的位置索引（如 5K 或 10K）可能远远超出了预训练时的上下文窗口。&lt;/p&gt; 
&lt;p&gt;下图展示了这种现象：&lt;strong&gt;当 32K 上下文窗口的预训练模型在超出该窗口的位置测试时，困惑度（Perplexity）急剧上升&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b4570f8269f6199cd4f7f261e30d709ef95.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 7. 困惑度与上下文窗口的关系（此图由作者绘制）&lt;/p&gt; 
&lt;p&gt;那么，YaRN 是如何应对这一挑战的呢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;既然外推法（extrapolate）效果欠佳，YaRN 转而采用插值频率（interpolate the frequency）的策略。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假设我们有一个在 4 个 token 长度的输入上训练的模型，希望将其扩展到 8 个 token，且基础频率 θ=0.5。&lt;/p&gt; 
&lt;p&gt;对于原始 RoPE，直接使用 cos(θ×pos) 和 sin(θ×pos) 对 Query 和 Key 进行旋转即可。&lt;/p&gt; 
&lt;p&gt;而对于 YaRN：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，计算扩展后的上下文长度与原始长度的比值作为缩放因子，本例中为 2。&lt;/li&gt; 
 &lt;li&gt;然后，生成新频率 θ&#39; = θ / 2 = 0.25。&lt;/li&gt; 
 &lt;li&gt;再使用新频率对 Query 和 Key 进行旋转，即 cos(θ&#39;×pos) 和 sin(θ&#39;×pos)。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下图对比了 RoPE 与 YaRN 的 cos 和 sin 值：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-250d721643a9dbe2ab68b4192345a39774f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 8. YaRN 工作原理示意图（此图由作者绘制）&lt;/p&gt; 
&lt;p&gt;通过该图可观察到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 RoPE 中，cos 和 sin 值会随位置索引的增加而快速振荡，导致扩展到更长的上下文时出现问题。&lt;/li&gt; 
 &lt;li&gt;而在 YaRN 中，原始的余弦和正弦函数通过频率缩放被插值到扩展后的上下文长度（如蓝色高亮区域所示），实现了更平滑的过渡，使得模型能够更有效地处理长序列。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下图展示了 DeepSeek-V3 在&quot;大海捞针&quot;（Needle In A Haystack，NIAH）测试中的表现，表明其在 128K 以下的上下文窗口长度中均表现出色：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-db027db8caa140504a6c552ecc8436d2bae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图 9. DeepSeek-V3 的&quot;大海捞针&quot;测试结果（引自文献[2]）&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 预训练阶段&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本节将介绍 DeepSeek-V3-Base 的训练方法，重点解析数据构建流程，并强调预训练阶段中的一些关键策略。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 数据构建&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;数据规模与质量对 LLM 训练至关重要。DeepSeek-V3 的预训练语料库通过持续优化策略构建，具体优化路径如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 DeepSeek 67B [8] 中，&lt;strong&gt;训练语料采用去重-过滤-再混合策略构建。&lt;/strong&gt; 首先对 Common Crawl 语料进行去重，随后通过严格的文档质量评估标准进行过滤，最后通过数据再混合阶段解决数据不平衡问题。&lt;/li&gt; 
 &lt;li&gt;在 DeepSeek-V2 [9] 中，通过以下方式扩展训练语料：1) &lt;strong&gt;增加更多中文数据及来自不同来源的高质量数据&lt;/strong&gt; ；2) &lt;strong&gt;通过优化数据清洗流程，恢复大量此前在文献 [8] 的策略中被删除的数据。同时，通过改进基于质量的过滤算法提升数据质量。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;在 DeepSeek-V3 [2] 中，&lt;strong&gt;预训练语料进一步扩充，加入更多数学与编程样本，以及除中英文之外的多语言样本。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;收集的预训练语料会通过前文提出的 Prefix-Suffix-Middle（PSM）框架结合 FIM（Fill-in-Middle）策略进行预处理，并应用 document-packing 技术。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 训练策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;原论文[2]对预训练参数进行了详细描述，此处我们仅强调几个关键点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;长上下文窗口扩展&lt;/strong&gt;：首先在 14.8T token 上以 4K 上下文窗口进行预训练，随后通过 1000 steps 扩展到 32K 上下文，最终再通过 1000 steps 扩展到 128K 上下文。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多词元预测&lt;/strong&gt;：如我们本系列前一篇文章《「DeepSeek-V3 技术解析」：多词元预测技术（Multi-Token Prediction, MTP）》所述，DeepSeek-V3 采用了优化版的多词元预测机制，允许模型同时解码多个词元（tokens），以加速训练中的解码过程。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;以 FP8 精度进行训练&lt;/strong&gt;：DeepSeek-V3 采用混合精度计算提升效率，对部分计算使用低精度格式（如 8-bit 浮点数），在不过度影响精度的前提下减少内存占用并加速计算。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;学习率的调度&lt;/strong&gt;：在前 2K steps 中，学习率（learning rate）从 0 线性增长至 2.2e--4，并在 10T token 的训练过程中保持恒定；随后在 4.3T token 的训练过程中按照余弦曲线下降至 2.2e-5；在最后 500B token 的训练过程中，前 333B token 保持恒定的学习率，剩余 167B token 进一步降至 7.3e-6。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Batch size 的调度&lt;/strong&gt;：在前 469B token 的训练过程中，Batch size 从 3072 逐步提升至 15360，后续训练中保持恒定。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 评估结果&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;下表对比了 DeepSeek-V3 与其他开源基座模型在不同任务上的表现。&lt;strong&gt;其中 DeepSeek-V3 在多数数据集上都取得了最佳性能，尤其是在数学与代码相关的任务中表现突出。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;需特别说明，得益于本系列文章中介绍的各项创新技术，DeepSeek-V3 的优异性能是在极高的训练效率下实现的。具体而言，&lt;strong&gt;DeepSeek-V3 每训练 1T token 仅需 180K H800 GPU hours，远低于训练 72B 或 405B 稠密模型的成本。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-29ea2b2418d59f8a4f9333eed10ff77c37d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;文献[2]中的表 3&lt;/p&gt; 
&lt;p&gt;文献 [2] 还通过全面的消融实验验证了无辅助损失函数的负载均衡、多词元预测等关键技术。由于我们已在前文中讨论过相关内容，此处不再赘述。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 总结&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本文探讨了 DeepSeek-V3 预训练策略中的关键创新，旨在提升效率、可扩展性与性能。由此产生的 DeepSeek-V3-Base 模型成为更高级推理模型（如 DeepSeek-R1-Zero 和 DeepSeek-R1）的基础，而这些模型又通过知识蒸馏反哺优化 DeepSeek-V3。&lt;/p&gt; 
&lt;p&gt;除此前讨论的架构创新 ------ 多头潜在注意力（Multi-head Latent Attention）、DeepSeekMoE、无辅助损失函数的负载均衡及多词元预测（Multi-token Prediction）外，本文还引入了包括 document packing、Fill-in-the-Middle（FIM）和基于 YaRN 的长上下文窗口扩展在内的多项技术。&lt;/p&gt; 
&lt;p&gt;这些技术共同推动了大语言模型效率与可扩展性边界的突破，为高性能 AI 模型设立了新标杆。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] DeepSeek（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepseek.com%2F%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://www.deepseek.com/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] DeepSeek-V3 Technical Report（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FDeepSeek-V3%2Fblob%2Fmain%2FDeepSeek_V3.pdf%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] Fewer Truncations Improve Language Modeling（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.10830%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.10830）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] Efficient Training of Language Models to Fill in the Middle（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2207.14255%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2207.14255）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] DeepSeek-Coder: When the Large Language Model Meets Programming --- The Rise of Code Intelligence（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.14196%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2401.14196）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.11931%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2406.11931）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] YaRN: Efficient Context Window Extension of Large Language Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2309.00071%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2309.00071）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.03300%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2402.03300）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2401.02954%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2401.02954）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10] Language Models are Unsupervised Multitask Learners（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcdn.openai.com%2Fbetter-language-models%2Flanguage_models_are_unsupervised_multitask_learners.pdf%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Shirley Li&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I am a Machine Learning Engineer working on building multi-modality models to solve real-world problems.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;当前位置编码方案（RoPE/YaRN）已支持 128K 上下文，但人类书籍平均长度约 200K tokens。要实现真正无损的长文档理解，您认为下一代位置编码需要突破哪些理论瓶颈？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2Fdeepseek-explained-5-deepseek-v3-base-86c078ed5504&quot; target=&quot;_blank&quot;&gt;https://medium.com/data-science-collective/deepseek-explained-5-deepseek-v3-base-86c078ed5504&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/18210553</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18210553</guid>
            <pubDate>Sun, 13 Apr 2025 03:31:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>