<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 15 Jul 2025 13:01:10 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>北京人形发布高保真铰接物体数字资产 ArtVIP</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;随着具身智能训练对数据需求的不断放大，通过仿真&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;合成数据&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;弥补数据缺口已成为行业当前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;共识和&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;重要课题。近日，北京人形机器人创新中心（后称北京人形）与北京市建筑设计研究院（后称北京建院）联合打造的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;高保真&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;铰接物体数字资产数据集&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP（Articulated-object digital assets with Visual realism, modular Interaction, and Physical fidelity）正式发布，该数据集实现了对高复杂度铰接物品的高精度仿真，在还原物品视觉外观的同时，以高保真度复现了物品物理特性，并且开源了 6 个支持全场景交互的虚拟机器人训练场。除开源已有场景提升行业模型训练效果外，北京人形同时可针对不同场景不同物品提供定制化建模服务，为具身智能快速落地提供平台支撑。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;&lt;span&gt;项目主页：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://x-humanoid-artvip.github.io/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span&gt;&lt;span&gt;huggingface：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://huggingface.co/datasets/x-humanoid-robomind/ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;随着具身操作训练的快速进展，机器人&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在执行精准抓取拿放等动作方面已经有了长足进步&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，行业攻坚的重点转向了针对复杂物体的灵巧操作。但在此前，主流开源仿真资产数据集如&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;PartNet-Mobility、BEHAVIOR-1K&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;等在物体&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;复杂度上难以达到要求，特别是针对转椅、抽屉、冰箱等带有可活动关节的物体，始终缺乏成熟方法生成或制作此类数字资产，导致模型由仿真走向现实的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Sim2Real&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;训练和部署&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;存在巨大鸿沟。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;为解决该问题，北京人形与北京建院共同合作，将双方的机器人仿真经验与数字化建模能力相结合，由前沿的具身智能需求作为牵引，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;让现实物品在数字世界中重新觉醒&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP 构建了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;全球最&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;精细&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;复杂铰接物体库，包括 26 类共 206 种高精度可动物件，实现了对橱柜、&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;烤箱&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、折叠椅、抽屉、电风扇、剪刀等不同特性铰接结构状态的精准仿真。通过海量高复杂度物品覆盖，支持训练具身智能模型获得处理机械结构变异性的泛化能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-d5858e5619af59c5b4e81d91d5f50c8d041.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;针对物理参数的细节参数调整，让&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;实现了高物理一致性，能够充分参考物品的刚度&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;阻尼&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、摩擦力、质量、转动惯量、碰撞体积等参数，模拟不同物品的在被操作或运转时的物理特性。如办公转椅受侧向力时，各轮组会依据地面摩擦系数差异自动形成转向序列差；具备阻尼或弹簧特性的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;烤箱&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;开口打开至特定角度，在仿真场景内操作或受力后的反馈与现实中完全一致，甚至冰箱门也与现实中一样在关门时有&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;相应&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的磁吸效果。高精度动力学还原使&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;具身智能算法&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;能够&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;习得符合现实的力控制策略，为开门、推椅等需精细力觉反馈的任务提供可靠训练环境。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-18ec00e6bbebf4c5de95ab767fccc7e62b9.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-12767b0507fd61d770101480c0761ae0d7e.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;除常见的有固定形态的刚性物体外，北京人形&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;构建的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;数字资产平台&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;支持行业领先的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;刚体&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;流体&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;-柔性体全&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;物质形态&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;仿真&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。冰块在水杯中因水流改变漂动方向，衣物等柔性物体的折叠与褶皱，甚至衣物在洗衣机滚筒内的旋转翻转&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;均可被仿真复现&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，助力&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;机器人训练液态容器搬运、柔性物体整理等传统仿真无法支持的高阶任务，大幅扩展具身智能操作边界。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-812c250e960a3f0f56246760b85ee0e5d5a.gif" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99ffcaf546b2fb1ce543fb8e498204dc2bf.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-3e76fcc2392c4e2736e5dc686373e0805c3.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;不同于常见仿真资产仅支持简单场景，ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;开放 6 大数字孪生机器人训练场，方便用户直接进行使用，包括中式客厅、厨房、卧室、起居室等常见环境，以精准建模完全还原真实场景内的全部物体以及视觉氛围感，充分考虑光照及材质等不同条件，如实木地板的深浅木纹在自然光下呈现差异化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;漫反射&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，电视屏幕镜面反射随角度实时变化，显著提升视觉感知训练的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;真实性&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;对具身训练更重要的是，ArtVIP 场景内所有物品均支持交互，实现环境级物理-视觉联动机制，构建闭环交互生态。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-2d78c6514083b54f885865c7e3b7be67c9d.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;例如，在仿真环境内点按电灯开关后，基于&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;光线追踪&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;技术，系统实时计算全场景光学响应，根据光源方向及角度调整环境可见度。该机制可在具身智能模型训练中建立「操作-环境反馈」的因果认知，显著提升复杂场景下的连续决策能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-120c2e084cda3f306ddf3bddd94076eaad0.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;根据&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;同期公开的论文&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;《ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning》，通过 CLIP 空间可视化显示，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;相比于其他主流仿真数字资产，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;中数据分布与真实世界对齐度提升了 47%。仅靠&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;仿真数据训练的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Diffusion Policy&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;模型，直接操控真实&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Franka&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;机械臂&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;以零样本迁移方式在物理世界中&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;完成关门任务，成功率&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;即可达到&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;30%&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;当混合&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;少量&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;真机数据训练&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;后&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，开门任务成功率&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;迅速大幅跃&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;升至 80%&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。实验结果&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;证明了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;作为数字资产，可支撑具身模型完成高复杂度物体的交互训练，为具身智能大规模训练建立全新&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;范式&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;当前 ArtVIP 已在 Hugging Face 开源，面向高校、研究机构以及行业研究者提供支持。除已有的数字资产内容，团队还开源了包含建模流程、关节参数调优方法在内的数字资产建模流程，且支持无缝接入仿真软件 Isaac Sim。开发者可直接基于已有环境训练，也可基于标准化流程快速生成新铰接物体资产，持续扩展高质量仿真训练环境。通过统一行业仿真资产标准，激发社区共建数字孪生库，彻底改变传统仿真资产&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;碎片化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;现状，推动具身智能训练从「作坊式开发」迈向「工业化协作」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;面向应用落地，团队还将提供可针对不同场景不同物品提供定制化建模服务，支持工业产线、物流园区、特种作业等不同场景的精准数字化复现。该服务使人形机器人在实际应用部署前能在仿真环境中预演精密装配、高危设备操作等任务，将产线停机试错成本降低 80%，为&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;智能制造&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;智慧物流&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;等场景的高效落地提供基础。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP 的发布，将极大改善困扰具身智能训练的 Sim2Real 问题。通过向全球研究者和开发者提供了一套高质量、标准化、可复用的铰接物体数字资产库，以及一套成熟的生产建模服务，改变此前仿真资产匮乏且低质的现状。通过低成本、高拟真的仿真资产，ArtVIP 将显著改善具身智能模型训练缺乏数据的问题，并同时降低人形机器人等&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;智能体&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在训练真实环境部署时的风险和试错成本，助力其在工业、服务等高价值或高危场景的安全高效落地。未来，北京人形机器人创新中心将持续推进此类共性技术平台建设，为我国人形机器人产业的核心技术攻关与规模应用提供坚实支撑。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;&lt;strong&gt;获取 ArtVIP：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;数字资产：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://huggingface.co/datasets/x-humanoid-robomind/ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;项目主页：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://x-humanoid-artvip.github.io/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9021515/blog/18684644</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9021515/blog/18684644</guid>
      <pubDate>Fri, 11 Jul 2025 10:09:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Blender Studio 发布 Dogwalk：基于开源引擎 Godot 的免费游戏</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Blender Studio 发布了一款名为「Dogwalk」的免费游戏，旨在演示开源 3D 建模软件 Blender 和开源游戏引擎 Godot 的协同工作流程，展现完全使用开源软件的可能性 。&lt;/p&gt; 
&lt;p&gt;该游戏是一款短小、温和的单人游戏，玩家扮演一只可爱的小狗，带着小孩在冬日景色中探索，寻找堆雪人的材料 。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在短暂的旅程中，你要探索雪林、冰冻的池塘和幽静的小径。您的目标非常简单：找到散落的物品来堆雪人。但如何到达目的地才是整个体验的重点。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/164502_DQMM_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;https://store.steampowered.com/app/3775050/DOGWALK/&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;玩家在评论中明确表示，游戏运行时间短，仅有 20 分钟左右，下载大小适中，约为 300MB，因此更容易上手。一位玩家指出，冲刺速度过快会导致孩子在你身后翻滚。其他许多玩家则称赞这款游戏节奏轻松，并将其描述为一种治疗性的逃避游戏。&lt;/p&gt; 
&lt;p&gt;整个项目的资产、动画和代码均由 Blender 和 Godot 完成，Godot 作为完全开源的引擎，不要求开发者支付版税或许可费，适合小型工作室和独立开发者。&lt;/p&gt; 
&lt;p&gt;游戏于 7 月 11 日首次在 Steam 上线，100% 免费，玩家也可选择购买 4.99 美元的 「支持者包」 以示支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360473</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360473</guid>
      <pubDate>Fri, 11 Jul 2025 08:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>K2 编译器热点：2025.1 中的高采用率、更少的 Bug 和重大改进</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/news/351989"&gt;IntelliJ IDEA 2025.1 默认采用 K2 编译器&lt;/a&gt;，本文将概要介绍 K2 编译器的当前状态，分享其采用指标，重点介绍 2025.1 中的改进，并预告下一步的计划。&lt;/p&gt; 
&lt;p&gt;以下内容来自：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fidea%2F2025%2F07%2Fk2-mode-takes-off-high-adoption-fewer-bugs-and-major-improvements-in-2025-1%2F" target="_blank"&gt;K2 模式热点：2025.1 中的高采用率、更少的 Bug 和重大改进&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我们建议您更新到最新的 IntelliJ IDEA 版本，享受最佳的 K2 模式体验。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;采用&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;目前采用 K2 模式的用户数量已经非常高，并且还在持续增长。 在 IntelliJ IDEA 2025.1 用户中，&lt;strong&gt;95% 的 Ultimate 开发者和 9% &lt;/strong&gt;的 Community Edition 开发者使用 K2 模式。&lt;/p&gt; 
&lt;p&gt;大多数用户都会在新版本发布后的几个月内更新 IDE，因此我们也跟踪了 2024.3 和 2025.1 版本的综合使用情况。 即使算上 2024.3 版的用户，K2 模式的采用率也已超过&amp;nbsp;&lt;strong&gt;76%&lt;/strong&gt;，并且这一数字每周都在稳步增长。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fc89ef43f0cffd0a6ebe37585aabe334f13.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;感谢您的反馈&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您的反馈是我们所有改进和增强的驱动力。&lt;/p&gt; 
&lt;p&gt;我们通过&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2FnewIssue%3FdraftId%3D25-6414130" target="_blank"&gt;YouTrack 问题&lt;/a&gt;、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.slack.com%2Farchives%2FC0B8H786P" target="_blank"&gt;Slack 消息&lt;/a&gt;、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fintellijidea" target="_blank"&gt;讨论帖&lt;/a&gt;以及各种会议和聚会上的无数次面对面交流获得了宝贵的意见和建议，这些都直接影响了 Kotlin 支持的发展。&lt;/p&gt; 
&lt;p&gt;我们的专属支持团队每天都会审查和监控 YouTrack 报告，确保您提出的问题成功传达和解决。&lt;/p&gt; 
&lt;p&gt;您的反馈不仅能帮助我们解决问题，还将帮助我们塑造 Kotlin 工具的未来。 感谢您持续分享！&lt;/p&gt; 
&lt;h3&gt;Bug 报告&lt;/h3&gt; 
&lt;p&gt;这个最新版本发布后的前 3-4 周内提交的 bug 报告数量与 2024.3 版本发布后的数量相当。&lt;/p&gt; 
&lt;p&gt;其他反馈渠道也显示负面提及数量显著下降，总体情绪比预期更积极。&lt;/p&gt; 
&lt;p&gt;一些用户在 2024.3 和 2024.2 版本中使用 K2 模式。 我们强烈建议您更新到最新版本的 IntelliJ IDEA，因为 2025.1 版本在质量和功能完整性方面都为 K2 模式带来了巨大的改进。&lt;/p&gt; 
&lt;p&gt;我们来看看哪些内容有所更新。&lt;/p&gt; 
&lt;h3&gt;2025.1 中的修正和改进：&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;稳定性得到提高，意味着崩溃和冻结更少。&lt;/li&gt; 
 &lt;li&gt;超过 100 项检查和意图已得到改进并从 K1 模式迁移到 K2 模式。&lt;/li&gt; 
 &lt;li&gt;临时文件和脚本现在获得了更好的支持 (&lt;code&gt;.kts&lt;/code&gt;)。&lt;/li&gt; 
 &lt;li&gt;错误报告中的误报（例如_Constructor expected_（应为构造函数）和_Unknown symbol_（未知符号））已被修正。&lt;/li&gt; 
 &lt;li&gt;应为&lt;code&gt;String?&lt;/code&gt;但实际为&lt;code&gt;String&lt;/code&gt;类型的错误不再错误显示。&lt;/li&gt; 
 &lt;li&gt;未使用的函数或属性现在获得一项检查。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.serializer()&lt;/code&gt;获得高亮显示支持。&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Create member from usage&lt;/em&gt;（从用法创建成员）快速修复现在可以按预期工作。&lt;/li&gt; 
 &lt;li&gt;频繁重新索引触发器已减少。&lt;/li&gt; 
 &lt;li&gt;项目切换缓存问题已解决。&lt;/li&gt; 
 &lt;li&gt;所有外部和内部主要插件现在都支持 K2 模式。&lt;/li&gt; 
 &lt;li&gt;JetBrains Academy 集成功能齐全。&lt;/li&gt; 
 &lt;li&gt;多种 Spring 支持改进已经实现。&lt;/li&gt; 
 &lt;li&gt;K2 模式调试器已与其 K1 模式对等功能达到同等水平。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们还改进了 K2 模式的许多其他方面。 查看我们的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FIDEA-A-2100662435%2FIntelliJ-IDEA-2025.2-EAP-1-252.13776.59-build-Release-Notes" target="_blank"&gt;版本说明&lt;/a&gt;获取完整列表。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;em&gt;Move&lt;/em&gt;（移动）重构&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在 K2 模式中，我们重写了_Move_（移动）重构的运作方式。 现在，它更加可靠和可预测。 边缘情况会得到正确处理，生成的代码也更加清晰和准确。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2025.2 最新变化：&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;常规代码补全改进。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com.cn%2Fhelp%2Fidea%2Fauto-completing-code.html%23smart_type_matching_completion" target="_blank"&gt;类型匹配智能补全&lt;/a&gt;支持。&lt;/li&gt; 
 &lt;li&gt;Spring 支持与 K1 模式相当。&lt;/li&gt; 
 &lt;li&gt;重构，例如针对文件和函数的_Convert Enum to Sealed Class_（将枚举转换为密封类）、&lt;em&gt;Extract Interface&lt;/em&gt;（提取接口）、&lt;em&gt;Create test / Navigate to test&lt;/em&gt;（创建测试/导航到测试）、&lt;em&gt;Rearrange Code&lt;/em&gt;（重新排列代码）。&lt;/li&gt; 
 &lt;li&gt;针对回归高亮显示的修正，包括 DSL、注解和 Kotlin 特定语法的一致行为。&lt;/li&gt; 
 &lt;li&gt;针对_Constructor expected_（应为构造函数）和_Unknown symbol_（未知符号）等误报错误的修正。&lt;/li&gt; 
 &lt;li&gt;Kotlin 脚本更可靠的执行，包括独立文件和&lt;code&gt;Gradle .kts&lt;/code&gt;文件。&lt;/li&gt; 
 &lt;li&gt;脚本定义的正确加载和项目特定符号的正确解析。&lt;/li&gt; 
 &lt;li&gt;对使用&lt;code&gt;@DslMarker&lt;/code&gt;注解的函数的正确识别和高亮显示。&lt;/li&gt; 
 &lt;li&gt;所有项目配置中更可靠的_Extract Interface_（提取接口）重构。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;还有更多变化，敬请期待！&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;协程检查&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;协程是我们最受欢迎也最常被提及的功能之一，但要正确使用可能并不简单，特别是对于新手来说。&lt;/p&gt; 
&lt;p&gt;我们正在设法使它们更易使用，并且已经引入不断增加的协程检查集。 它们可以捕捉常见问题、提供实用建议，并指导您更顺畅、更自信地编写正确且惯用的协程代码。 以下是我们通过这一举措解决的一些工单：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;关于在挂起函数中调用&lt;code&gt;runBlocking&lt;/code&gt;的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-32417" target="_blank"&gt;警告&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;尽可能将 &lt;code&gt;_kotlin.coroutine.coroutineContext_&lt;/code&gt; 访问替换为 &lt;code&gt;_kotlinx.coroutines.currentCoroutineContext_&lt;/code&gt; 调用的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-34526" target="_blank"&gt;检查&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;未使用来自_kotlin.coroutines_的流时的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-17625" target="_blank"&gt;检查&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;在 ‘&lt;em&gt;Deferred&lt;/em&gt;’ 对象集合上替换 ‘&lt;em&gt;map { it.await() }’ with ‘awaitAll()&lt;/em&gt;’ 的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-34236" target="_blank"&gt;检查&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;在 ‘&lt;em&gt;Job&lt;/em&gt;’ 对象集合上替换 ‘&lt;em&gt;forEach { it.join() }’ with ‘joinAll()&lt;/em&gt;’ 的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-34346" target="_blank"&gt;检查&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;对 Kotlin 2.2 功能预览的支持&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Kotlin 2.2 将带来多种在 K2 模式下具有 IDE 支持的精彩新功能，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;when、多美元内插以及非局部_break_和_continue_中的保护条件。&lt;/li&gt; 
 &lt;li&gt;嵌套类型别名。&lt;/li&gt; 
 &lt;li&gt;对 Kotlin 中注解的使用场所默认值的改进。&lt;/li&gt; 
 &lt;li&gt;上下文形参（不稳定）。&lt;/li&gt; 
 &lt;li&gt;将具有内联类的函数暴露给 Java（不稳定）。&lt;/li&gt; 
 &lt;li&gt;上下文相关解析的原型（不稳定）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;性能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;2025.1 版本带来了显著的性能改进，2025.2 则在此基础上带来了进一步改进。&lt;/p&gt; 
&lt;p&gt;在 2025.1 中，高亮显示和_Find Usages_（查找用法）等操作变得更快、更灵敏。 为了准备 2025.2 版本，我们还提升了补全速度和内存使用情况，使日常编辑更加顺畅和高效。&lt;/p&gt; 
&lt;p&gt;这些更新是我们不断使 K2 模式更加强大的一部分。 我们将继续跟踪这些更改的影响，并在今年晚些时候分享更详细的指标。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360461</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360461</guid>
      <pubDate>Fri, 11 Jul 2025 08:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>APKLab —— VS Code 的 Android 逆向工程工作台</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1d2d35"&gt;APKLab 是一款开源 Android 逆向工程和恶意软件分析工具。它是 VS Code 的扩展，使用 TypeScript 编写。APKLab 旨在集成该领域现有的开源工具，并为常见的逆向工程任务提供更简洁的用户体验。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;APKLab 将最好的开源工具：&lt;a href="https://github.com/quark-engine/quark-engine"&gt;Quark-Engine&lt;/a&gt;、&lt;a href="https://github.com/ibotpeaches/apktool/"&gt;Apktool&lt;/a&gt;、&lt;a href="https://github.com/skylot/jadx"&gt;Jadx&lt;/a&gt;、&lt;a href="https://github.com/patrickfav/uber-apk-signer"&gt;uber-apk-signer&lt;/a&gt;、&lt;a href="https://github.com/shroudedcode/apk-mitm/"&gt;apk-mitm&lt;/a&gt;等无缝集成到优秀的 VS Code 中，因此你可以专注于应用程序分析，而无需离开 IDE 即可完成。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解码 APK 中的所有资源&lt;/li&gt;
&lt;li&gt;将 APK 反汇编为 Dalvik 字节码，又名 Smali&lt;/li&gt;
&lt;li&gt;将 APK 反编译为 Java 源代码&lt;/li&gt;
&lt;li&gt;交互式恶意软件分析报告&lt;/li&gt;
&lt;li&gt;将项目目录初始化为 Git repo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LoyieKing/Smalise"&gt;&lt;strong&gt;Smalise&lt;/strong&gt;&lt;/a&gt;提供出色的 Smali 语言支持&lt;/li&gt;
&lt;li&gt;使用功能丰富的 VS Code 进行有效分析和破解&lt;/li&gt;
&lt;li&gt;应用 MITM 补丁进行 HTTPS 检查&lt;/li&gt;
&lt;li&gt;使用 Smali 和资源构建 APK&lt;/li&gt;
&lt;li&gt;在调试模式下重建 APK 以进行动态分析&lt;/li&gt;
&lt;li&gt;在构建过程中无缝地对 APK 进行签名&lt;/li&gt;
&lt;li&gt;直接从 VS Code 安装 APK&lt;/li&gt;
&lt;li&gt;支持 Apktool 风格的项目（&lt;code&gt;apktool.yml&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;支持大多数 Apktool CLI 参数&lt;/li&gt;
&lt;li&gt;Android 资源框架管理（即将推出！）&lt;/li&gt;
&lt;li&gt;支持用户提供的密钥库进行 APK 签名&lt;/li&gt;
&lt;li&gt;下载并配置缺少的依赖项&lt;/li&gt;
&lt;li&gt;支持 Linux、Windows 和 Mac&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/apklab</link>
      <guid isPermaLink="false">https://www.oschina.net/p/apklab</guid>
      <pubDate>Fri, 11 Jul 2025 07:52:00 GMT</pubDate>
    </item>
    <item>
      <title>PHP 社区正在讨论变更许可证</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;PHP 社区近日就变更许可证&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.php.net%2Frfc%2Fphp_license_update" target="_blank"&gt;发起了提案&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;PHP 在自定义开源许可证方面有着长期的混淆、担忧和争议，而涵盖 Zend/ 目录中源代码的 Zend Engine 许可证，加剧了这种混淆并进一步复杂化了问题，因为它不是 Open Source Initiative 批准的许可证。&lt;/p&gt; 
 &lt;p&gt;本 RFC 提议对 PHP 许可证进行务实的简化，以消除这种混淆，保留所有 PHP 贡献者拥有的版权，并授予用户与原始许可证相同的权利。&lt;/p&gt; 
 &lt;p&gt;为达成此目的而提出的许可证是修正版 BSD 许可证，通常称为 3-clause BSD 许可证。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/153907_Klzo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;1. &lt;strong&gt;背景&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHP 当前使用的自定义开源许可证（PHP License 3.01 和 Zend Engine License 2.00）存在以下问题： 
  &lt;ul&gt; 
   &lt;li&gt;不被 OSI（Open Source Initiative）完全认可；&lt;/li&gt; 
   &lt;li&gt;与 GPL 不兼容；&lt;/li&gt; 
   &lt;li&gt;存在品牌控制条款（如「不得使用 PHP 名称」）；&lt;/li&gt; 
   &lt;li&gt;多个许可证并存，造成混淆；&lt;/li&gt; 
   &lt;li&gt;Debian 等发行版曾因条款模糊而拒绝使用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. &lt;strong&gt;解决方案&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;统一许可证&lt;/strong&gt;：将 PHP 和 Zend Engine 的许可证都改为 &lt;strong&gt;BSD 3-Clause License&lt;/strong&gt;（SPDX: &lt;code&gt;BSD-3-Clause&lt;/code&gt;）。 
  &lt;ul&gt; 
   &lt;li&gt;该许可证被 OSI 和 FSF 认可；&lt;/li&gt; 
   &lt;li&gt;与 GPL 兼容；&lt;/li&gt; 
   &lt;li&gt;简洁、广泛使用、无歧义。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3. &lt;strong&gt;具体变更&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;发布新的许可证版本： 
  &lt;ul&gt; 
   &lt;li&gt;PHP License 版本 4；&lt;/li&gt; 
   &lt;li&gt;Zend Engine License 版本 3；&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;删除旧许可证文件；&lt;/li&gt; 
 &lt;li&gt;替换所有源码文件头部的许可证声明；&lt;/li&gt; 
 &lt;li&gt;更新官网和文档；&lt;/li&gt; 
 &lt;li&gt;旧代码可选择继续使用旧许可证或迁移到新许可证。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;4. &lt;strong&gt;是否需要所有贡献者同意？&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;不需要&lt;/strong&gt;。因为 BSD 3-Clause 与原许可证在权利授予上无实质差异；&lt;/li&gt; 
 &lt;li&gt;但出于礼貌，将开放至少 6 个月的社区讨论期。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;5. &lt;strong&gt;是否需要 PHP Group 和 Perforce 同意？&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;需要&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;PHP Group（代表 PHP 项目）；&lt;/li&gt; 
   &lt;li&gt;Perforce Software（Zend Technologies 的母公司，拥有 Zend Engine 版权）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;6. &lt;strong&gt;投票机制&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHP 社区将通过 RFC 投票决定是否采纳该变更；&lt;/li&gt; 
 &lt;li&gt;投票选项：是否同意采用 BSD-3-Clause 作为 PHP License v4 和 Zend License v3。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;7. &lt;strong&gt;时间线&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;提案版本：PHP 9.0；&lt;/li&gt; 
 &lt;li&gt;当前状态：草案&lt;/li&gt; 
 &lt;li&gt;实施前将开放讨论期 ≥6 个月。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h3&gt;✅ 总结一句话：&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;PHP 社区计划将 PHP 和 Zend Engine 的许可证统一为 BSD 3-Clause License，以解决历史遗留的兼容性和法律歧义问题，推动 PHP 更加标准化和开源友好。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360454/php-license-update-rfc</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360454/php-license-update-rfc</guid>
      <pubDate>Fri, 11 Jul 2025 07:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>亚马逊发布全新 AI IDE「Kiro」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;亚马逊宣布推出 AI 编程工具&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkiro.dev%2F" target="_blank"&gt;Kiro&lt;/a&gt;，这是一款集成开发环境（IDE），旨在通过「规范驱动开发」（Spec-Driven Development）革新软件开发模式，解决「氛围编码」（Vibe Coding）带来的混乱和低效问题 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5ce71ce1cd37882ab5707f2d549d0b3b8fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kiro 借助 AI 智能体与开发者协作，在编写代码前自动生成需求文档、系统设计图和任务清单，并基于这些规范生成代码、测试用例和文档，实现「从氛围编码到可用代码」的转变 。&lt;/p&gt; 
&lt;p&gt;此外，&lt;strong&gt;Kiro 引入「钩子」（Agent Hooks）机制&lt;/strong&gt;，在代码保存或提交时触发自动化任务（如更新测试文件、文档、安全扫描等），确保代码与规范同步 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/152736_Ykvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前 Kiro 预览版免费，支持 macOS、Windows 和 Linux 系统，后续将推出免费版（月限 50 次交互）、专业版（19 美元/月，支持 1000 次交互）和专业增强版（39 美元/月，支持 3000 次交互）三种定价层级 。&lt;/p&gt; 
&lt;p&gt;亚马逊 CEO 安迪·杰西（Andy Jassy）表示，Kiro「有机会彻底改变开发者构建软件的方式」 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360450</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360450</guid>
      <pubDate>Fri, 11 Jul 2025 07:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>YouTrack 自 2025 年 10 月起开始实行新价格</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;JetBrains 宣布将对 YouTrack 价格做出一些调整，新价格将于 2025 年 10 月 1 日生效。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;保持不变的方面&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;YouTrack 对最多 10 个用户的团队仍然免费。&lt;/li&gt; 
 &lt;li&gt;帮助台项目对最多 3 位支持人员的团队仍然免费，报告者数量不受限制。&lt;/li&gt; 
 &lt;li&gt;YouTrack 订阅将继续免费提供全套功能、支持和 AI 辅助。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;发生改变的方面&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;所有有效的升级和支持订阅将继续有效，直至到期日期。&lt;/li&gt; 
 &lt;li&gt;2025 年 10 月 1 日之前，您可以按当前价格续订。&lt;/li&gt; 
 &lt;li&gt;10 月 1 日之后，任何续订或用户/支持人员添加都将按照新价格执行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-70e827f2f16141b0a60bf93255589c0bf32.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下文将详细说明此次变动的原因、您应如何准备，以及这对 YouTrack Cloud 和 Server 客户意味着什么。&lt;/p&gt; 
&lt;h2&gt;我们为什么要做出这一改变？&lt;/h2&gt; 
&lt;p&gt;我们的当前定价自 2020 年以来一直没有变化。 事实上，许多长期客户一直以十多年前推出的旧定价使用 YouTrack，并完全享受所有功能。&lt;/p&gt; 
&lt;p&gt;几年过去，我们已经做出了大量增值改进，包括知识库、帮助台功能、AI 辅助、应用等。 新价格反应了这些增强以及我们对 YouTrack 的持续投入。&lt;/p&gt; 
&lt;p&gt;我们对多年来选择 YouTrack 的团队表示感谢。 此次更新将帮助我们继续改进 YouTrack Cloud 和 Server，使其既适用于小型团队，也适用于大型企业。&lt;/p&gt; 
&lt;h2&gt;如何准备&lt;/h2&gt; 
&lt;p&gt;以下是许可证管理员需要了解的信息，以便提前做好规划：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您现有的 Cloud 或 Server 订阅将以当前价格保持有效，直至到期日期。 您不需要立即采取任何行动。&lt;/li&gt; 
 &lt;li&gt;不过，您可以按当前价格&lt;strong&gt;提前续订&lt;/strong&gt;。 这是 2025 年 10 月 1 日之前的最后机会。&lt;/li&gt; 
 &lt;li&gt;在此日期之后，所有续订和用户/支持人员添加都将按照&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2168%2F" target="_blank"&gt;新价格&lt;/a&gt;执行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以下是根据您的订阅类型提供的详细信息。&lt;/p&gt; 
&lt;h2&gt;针对 YouTrack Cloud 客户的更新&lt;/h2&gt; 
&lt;h3&gt;YouTrack Cloud 按用户订阅&lt;/h3&gt; 
&lt;p&gt;如果您是在 2020 年或之后开始使用 YouTrack Cloud，您很可能拥有按用户订阅。 以下是价格变化对您的团队的影响。&lt;/p&gt; 
&lt;p&gt;YouTrack 将继续向最多 10 个用户的团队免费提供，这一点没有改变。&lt;/p&gt; 
&lt;p&gt;如果您的团队有超过 10 个用户，订阅价格将从 2025 年 10 月 1 日起进行调整。 对于包月方案，新定价为&lt;strong&gt;每个用户每月 5.40 美元&lt;/strong&gt;起。 如果您喜欢包年订阅，您将获得两个月的免费使用时间，新的起始价格为&lt;strong&gt;每个用户每月 4.50 美元&lt;/strong&gt;。 您的团队越大，价格就越低，因为随着您添加用户，折扣也会增加。 您可以在我们的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2169%2F" target="_blank"&gt;常见问题解答&lt;/a&gt;中探索更新后的定价示例。&lt;/p&gt; 
&lt;p&gt;帮助台功能仍然完全包含在您的订阅中。 它对最多包含 3 位支持人员的团队免费，报告者数量不受限制。 对于 4 位或更多支持人员的团队，将采用新定价：包月方案&lt;strong&gt;每位支持人员每月 6 美元&lt;/strong&gt;，包年方案&lt;strong&gt;每位支持人员每月 5.50 美元&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;所有功能，包括 AI 辅助和支持，都将继续作为订阅的一部分，不收取额外费用。 我们还将保留面向创业公司、非营利组织、教育机构和开源项目的所有折扣。&lt;/p&gt; 
&lt;h3&gt;YouTrack Cloud 旧用户包订阅&lt;/h3&gt; 
&lt;p&gt;如果您从 2020 年之前就开始使用 YouTrack Cloud，并且还没有切换到按用户结算模式，那么您可能仍在使用带有用户包的旧版方案。&lt;/p&gt; 
&lt;p&gt;即使在 2025 年 10 月 1 日之后，这些订阅仍将照常有效，直至到期日期。 您不需要立即采取任何行动。&lt;/p&gt; 
&lt;p&gt;不过，这将是您以当前价格续订的最后一次机会。 您只能在&lt;strong&gt;2025 年 10 月 1 日&lt;/strong&gt;前按照旧条款再次续订。 此后，续订将切换到新的按用户定价。&lt;/p&gt; 
&lt;p&gt;为了方便过渡，当您切换到包年按用户订阅时，我们将&lt;strong&gt;免费提供三个月的额外时长&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;与旧方案相比，这个方案可以为您带来更多的灵活性和功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您可以按需添加或移除用户，没有固定大小的用户包。&lt;/li&gt; 
 &lt;li&gt;您还将获得更多云存储空间，每个用户 3 GB。&lt;/li&gt; 
 &lt;li&gt;您可以使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com.cn%2Fyoutrack%2Fhelpdesk%2F" target="_blank"&gt;帮助台&lt;/a&gt;项目，3 位支持人员免费，报告者数量不受限制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新的按用户定价将于&lt;strong&gt;2025 年 10 月 1 日&lt;/strong&gt;生效。 此后，包月方案起价为&lt;strong&gt;每个用户 5.40 美元&lt;/strong&gt;，包年方案起价为&lt;strong&gt;每个用户 4.50 美元&lt;/strong&gt;，随着团队人数增加，折扣也会增加。 您可以查看我们的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2170%2F" target="_blank"&gt;常见问题解答&lt;/a&gt;获取示例来估算您的成本。&lt;/p&gt; 
&lt;p&gt;与往常一样，全套功能、支持和 AI 辅助均免费提供。 面向创业公司、教育和非营利组织以及开源项目的折扣将继续有效。&lt;/p&gt; 
&lt;h2&gt;针对 YouTrack Server 客户的更新&lt;/h2&gt; 
&lt;p&gt;如果您正在使用 YouTrack Server，以下是从 2025 年 10 月 1 日起将会改变和保持不变的方面。&lt;/p&gt; 
&lt;h3&gt;保持不变的方面&lt;/h3&gt; 
&lt;p&gt;YouTrack Server 对最多 10 个用户的团队仍然免费，这一点没有改变。&lt;/p&gt; 
&lt;p&gt;如果您购买了许可证，您仍然拥有它：所有现有 YouTrack Server 许可证都是永久的，并且将继续有效。 您当前的升级和支持订阅也将一直有效，直至到期日期。&lt;/p&gt; 
&lt;p&gt;与往常一样，每个有效订阅都包含全套功能、支持和 AI 辅助，没有额外费用。 面向创业公司、非营利和教育机构以及开源项目的折扣保持不变。&lt;/p&gt; 
&lt;h3&gt;发生改变的方面&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;2025 年 10 月 1 日&lt;/strong&gt;之前，您可以按当前价格续订。 此后，所有续订和新用户或支持人员的添加都只能按新价格执行。&lt;/p&gt; 
&lt;p&gt;我们将继续提供灵活的用户包选项，从 15 个用户开始，然后扩展到 25、50、100、250、500、750、1,000、1,500、2,000 及更多。 2025 年 10 月 1 日之后，这些产品将仅按&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2116%2F" target="_blank"&gt;新价格&lt;/a&gt;提供。&lt;/p&gt; 
&lt;p&gt;如果您的团队规模超过 2,000 人，请随时&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack-support.jetbrains.com%2Fhc%2Fen-us%2Frequests%2Fnew%3Fticket_form_id%3D66282" target="_blank"&gt;联系&lt;/a&gt;YouTrack 团队获取定制报价。&lt;/p&gt; 
&lt;h3&gt;续订并节省 50%&lt;/h3&gt; 
&lt;p&gt;如果您的支持订阅仍然有效，或者已过期不到 12 个月，您可以按&lt;strong&gt;新许可证价格的 50% 续订&lt;/strong&gt;。 今后，我们将继续提供这种续订折扣。&lt;/p&gt; 
&lt;p&gt;如果您的订阅过期已超过一年，则折扣不再适用，但您仍然可以购买新许可证继续使用 YouTrack Server，您的数据将完整保留。&lt;/p&gt; 
&lt;h3&gt;帮助台价格&lt;/h3&gt; 
&lt;p&gt;帮助台项目对 3 位支持人员和无限数量的报告者免费。&lt;/p&gt; 
&lt;p&gt;自 2025 年 10 月 1 日起，对于拥有 4 位或更多支持人员的团队，价格为每位支持人员每年 72 美元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360443/new-youtrack-pricing-starting-october-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360443/new-youtrack-pricing-starting-october-2025</guid>
      <pubDate>Fri, 11 Jul 2025 07:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 宣布全球首个 1GW+ 能耗超级计算机集群即将上线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 首席执行官马克·扎克伯格通过社交媒体宣布，公司正加速推进人工智能基础设施建设，计划上线全球首个功耗超过 1 吉瓦（GW）的超级计算机集群「Prometheus」，预计于 2026 年投入使用。同时，Meta 正在规划另一个名为「Hyperion」的超大规模集群，未来几年内功耗将达到 5GW，规模堪比曼哈顿。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="372" src="https://oscimg.oschina.net/oscnet/up-e27761cb0d17660586425b83510ac2df335.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 的「Prometheus」超级计算机集群被定位为全球首个功耗超过 1 吉瓦的 AI 算力基础设施。这一集群将搭载约 130 万块 NVIDIA H100GPU，预计提供超过 2 艾克萨（exaflops）的混合精度算力，远超 Meta 此前于 2022 年推出的 AI Research SuperCluster(RSC，约 5exaflops)。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Prometheus 专为训练下一代大语言模型（如 Llama4）及通用人工智能（AGI）设计，目标是支持多模态 AI 任务，包括实时语音翻译、增强现实 (AR) 应用及元宇宙相关技术。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;与传统超级计算机不同，Prometheus 采用 NVIDIA Quantum2InfiniBand 网络架构和 Grand Teton 硬件平台（Meta 贡献给开放计算项目 OCP 的设计），优化了 GPU 间的通信效率和数据中心能效。社交媒体上，开发者对 Prometheus 的规模表示震撼，称其「重新定义了 AI 算力的上限」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了 Prometheus，Meta 还透露正在规划「Hyperion」集群，预计功耗高达 5GW，规模堪比一座小型城市。这一集群将进一步扩展 Meta 的 AI 基础设施，目标是支持更复杂的模型训练和推理任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;有分析指出，Hyperion 的能耗相当于 xAI 30 万张 GPU 集群的 20 倍。xAI 近期宣布其 Memphis&amp;nbsp;超级计算机集群（约 30 万块 GPU）功耗在 200-300 兆瓦，而微软与 OpenAI 合作的 Stargate 项目计划投资超 5000 亿美元建设 AI 数据中心。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Hyperion 的具体细节尚未完全公开，但 Meta 表示，该集群将采用液冷技术和高性能网络架构，以应对大规模 AI 训练的散热和通信需求。此外，Meta 计划在 2025 年投资 600-650 亿美元用于数据中心建设和 AI 团队扩张，以确保算力与人才储备的同步增长。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 强调，Prometheus 和 Hyperion 将延续其在开放计算（Open Compute Project）和 PyTorch 等开源生态中的承诺。集群设计基于 Grand Teton 平台，支持 RoCE 和 InfiniBand 两种网络架构，展示了 Meta 在硬件灵活性和可扩展性上的探索。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Meta 承诺在数据隐私方面采取严格措施，集群将与互联网隔离，数据传输全程加密，以保护用户数据安全。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;开发者对 Meta 的开源策略表示欢迎，认为这将进一步降低 AI 开发门槛。然而，也有用户指出，如此大规模的算力部署可能需要更透明的能源使用和碳排放报告，以回应公众对可持续性的关注。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360422</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360422</guid>
      <pubDate>Fri, 11 Jul 2025 06:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>特朗普将宣布 700 亿美元 AI 与能源投资计划</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;美国总统特朗普将于本周二在宾夕法尼亚州匹兹堡郊区宣布一项高达 700 亿美元的人工智能与能源领域投资计划。据一位不愿透露姓名的政府官员透露，该投资涉及数据中心建设、电力基础设施升级、AI 人才培训与学徒项目，来自多家私营企业的支持也将共同推动该战略落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据计划，投资项目包括多个新建数据中心、电力生产扩张与电网基础设施现代化，同时涵盖 AI 培训课程和技术学徒机制，旨在打造一个能量充沛、技术领先的人才生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;特朗普将与共和党参议员 David McCormick 一同出席此次活动，McCormick 也将主持在卡内基梅隆大学举行的首届「宾夕法尼亚能源与创新峰会」。预计将有多达 60 位能源与 AI 领域高管出席，包括贝莱德 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FBLK.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;BLK.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO 拉里·芬克，Palantir(&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FPLTR.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;PLTR.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO Alex Karp，Anthropic 联合创始人 Dario Amodei，埃克森美孚 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FXOM.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;XOM.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO Darren Woods 以及雪佛龙 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCVX.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;CVX.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO Mike Wirth。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;本次宣布的投资项目是特朗普第二任期内，兑现其「确保美国在 AI 领域全球领先」承诺的最新行动。上任以来，他采取了放宽监管、加速许可审批、吸引私营部门资本等多元策略，积极推动美国科技创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年早些时候，特朗普已宣布一项 1000 亿美元的 AI 数据中心投资，涉及软银、OpenAI 与甲骨文 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FORCL.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;ORCL.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;) 等科技巨头。同时，其政府还取消了拜登时期对 AI 芯片出口的限制措施，意在提升盟友科技能力、打击技术「脱钩」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;为保障能源基础，特朗普政府主张恢复并扩大煤炭、天然气与核电的使用，认为这是避免未来电力短缺和 AI 系统运行中断的关键。美国能源部已动用紧急授权令，延迟两座本应关闭的发电厂停运，并表示未来可能会有更多联邦介入措施。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360406</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360406</guid>
      <pubDate>Fri, 11 Jul 2025 03:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>高并发系统的艺术：如何在流量洪峰中游刃有余</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们常说的三高，高并发、高可用、高性能，这些技术是构建现代互联网应用程序所必需的。对于京东 618 备战来说，所有的中台系统服务，无疑都是围绕着三高来展开的。而对于京东庞大的客户群体，高并发的要求尤为重要。用户对在线服务的需求和期望不断提高，系统的并发处理能力成为衡量其性能和用户体验的关键指标之一。高并发系统不仅仅是大型互联网企业的专利，对于任何希望在市场中占据一席之地的公司来说，能够处理大量并发请求的能力都是至关重要的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;高并发系统的设计和实现是一个复杂且多层次的过程，涉及到硬件资源的合理利用、系统架构的精心设计、并发控制技术的应用以及性能调优等多个方面。无论是电商平台在大促期间应对突发流量，还是社交媒体在热点事件发生时的流量激增，抑或是金融系统在交易高峰期的平稳运行，都需要一个高效、稳定、可扩展的高并发系统作为支撑。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接下来我通过一张思维导图展开我的分享，帮大家梳理一下一个高并发系统所需要考虑的技术点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img alt="" src="https://oscimg.oschina.net/oscnet//01cbd4401f15d148b559f5bd9ef49a3b.png" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;单机维度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在单机维度上， 我们一般分为硬件维度和代码维度两个方向考虑。硬件维度比较简单，就是提升单机的硬件性能和网络带宽。而代码维度，则是在高并发系统架构设计时，最容易被大家忽视的，尤其是大量的脱离一线研发并进化成 PPT 架构师的今天，单机维度基本不在考量范围。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但不积跬步无以至千里，有的时候单机接口的的性能优化，会带来很高的经济成本价值。在代码维度，我这里重点介绍一种情况，关于多线程和异步方法。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;a. 多线程和异步方法的误区&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;关于多线程和异步方法的概念，我再面试候选人的时候，发现很多人对此都有误区。在此，我先详细的一下他俩的概念：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多线程：多线程是指在一个进程中可以同时运行多个线程，每个线程执行不同的任务。Java 通过 java.lang.Thread 类和 java.util.concurrent 包提供了多线程编程的支持。多线程的主要目的是为了充分利用 CPU 资源，提高程序的执行效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;异步方法：异步方法是指在调用某个方法时，不需要等待该方法执行完成即可继续执行后续代码。Java 通过 CompletableFuture 和异步回调机制提供了异步编程的支持。异步方法的主要目的是为了提高系统的响应能力和资源利用率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;b. 多线程能够解决高并发场景么&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当大家了解了多线程和异步方法的概念后，那么我们就可以认真思考一下，多线程一定能提升系统的并发能力么？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的结论是：多线程可以提升部分服务的并发能力，但并不能显著提高性能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先我们先了解，Tomcat 的 Servlet 机制是基于多线程实现的，而如果你在单次请求中在此开辟线程池进行多线程处理，在一定的并发情况下，你可能只是改善了单次请求的 TP99，但无法有效提升系统的并发能力。因为多线程的性能提升与 CPU 核心数密切相关。如果系统只有一个 CPU 核心，那么多个线程只能在该核心上轮流执行，无法实现真正的并行处理。而我们的宿主机一般也就是 8C 或者 16C，在面单机上千的 QPS 请求时，多线程只会增加 CPU 上下文切换的负担。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;举个简单并且常见的例子，批量下单接口。我们常见的做法就是在批量下单接口中开辟线程池，然后建个多个下单在线程池中并行处理。这样做的结果是，在请求量低的情况下，效果还是可以的，单次请求的 QPS 也会很低，但如果单机面临每秒上千次的下单请求，这种实现方式就会出现问题。最直观的观察，可以通过 TP99 的监控曲线发现，就是请求量跟 TP99 呈现严重的正相关性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而真正有效的提升下单接口的并发能力，是通过异步方式实现。但异步方式又会增加系统的设计复杂度，比如下单失败，异步回调设计和数据一致性设计等等，也在考量范围之内，这里就不详细展开说明。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;c. 小结&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多线程和异步方法是 Java 开发中两种重要的并发处理技术，它们在提高系统性能和响应能力方面各有优势。多线程通过并行处理任务，充分利用 CPU 资源，适用于 CPU 密集型任务和需要并行处理的场景。异步方法通过非阻塞 I/O 操作和异步回调机制，提高系统的响应能力和资源利用率，适用于 I/O 密集型任务和事件驱动架构。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外当然还有大家经常乐于讨论的 JVM 调优问题，基于 JVM 调优，包括垃圾回收器的选择，参数的合理优化，当然，还有一点，其实大家平时关注不多，就是采用更高版本的 JDK 和更新的 Spring 框架，因为高版本的框架会对性能本身有不错的优化。关于这点，我在另一篇文章中有重点介绍：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F25214%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;性能加速包: SpringBoot 2.7&amp;amp;JDK 17,你敢尝一尝吗&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;多机维度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在多机维度考虑系统的高并发性能，应该是大家最长能够想到的场景了，也是架构师们最热衷讨论的点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先是对系统的拆分角度来说，第一个是单体应用的水平扩展问题，就是我们所说的负载均衡集群，换成我们经常听到的一个词： 扩容。扩容一般针对负载均衡集群进行水平扩展，用于解决单机无法承载高并发的情况，这也是互联网公司解决高并发场景的最常用手段，就比如每次双十一或者 618 前夕，我们都会成倍的扩容我们的服务实例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对系统的另一个拆分角度，叫做垂直拆分，也就是我们常见的分布式系统。比如按照领域划分，我们将一个大的单体服务，拆分成不同的子领域系统，然后每个子领域系统单独承担各自的流量，而不会相互影响。还比如说长江的 CQRS 设计架构，翻译过来是指令查询分离的设计方式，通过查询和指令服务拆分，来讲高并发的查询场景单独拆分出来进行设计。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;既然采用了分布式的微服务架构，那么分布式系统的一些常见痛点也是高并发要考虑的，比如熔断，降级，限流，超时等设计，这些本身是为了增强分布式系统的鲁棒性，从而间接的增强系统的高并发承载能力。关于微服务架构，在此处不再赘述，有兴趣的，可以看我的另一篇文章:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F11328%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;【实践篇】教你玩转微服务--基于 DDD 的微服务架构落地实践之路&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;垂直维度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所谓垂直维度，是为了区分於单机维度和多机维度的，垂直的意思是针对一个业务系统在系统层级的垂直划分，包括业务应用和数据库。要知道，很多高并发场景，不管是写场景还是读场景，当数据库维度出现瓶颈，扩容就不想业务应用服务那么简单了，所以要区分来说。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;a. 业务应用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;唯物辩证法中有一个重要概念，就是一切从实际出发，具体问题具体分析。对于高并发系统的构建，虽然有通用的手段和方法论，但没有统一的落地方案，必须根据具体的业务应用场景进行分析和设计。比如你的系统是高并发读还是高并发写，处理思路也是完全不一样的。当然常见的手段和方法论核心包括两点：缓存和异步。但具体到相应的业务，需要仔细思考缓存逻辑怎么设计，异步流程怎么设计，如何保证数据一致性等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;这块我有一个项目案例，就是在 SAAS 商城中秒杀场景下，如何设计高性能库存扣减逻辑，我将这块内容写在了我另一篇文章里： &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F35227%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高并发场景下的库存管理，理论与实战能否兼得？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;b. 数据库&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在存储媒介这块其实高并发是不好设计的。比如关系型数据库 MySQL, 在进行扩展要比业务应用复杂不少，涉及到的就是数据库的分库分表逻辑。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这块可以参考之前我写过的一篇文章：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F12678%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;分而治之--浅谈分库分表及实践之路&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而对于读场景下的高并发请求，还有一种最常见的处理手段，就是异构存储介质，实现读写分离，最常见的就是 MySQL 关系型数据库负责写，ES 这种文档类数据库负责读。而他的技术难点则在于数据的同步和数据一致性上。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以上我分享的是一个思维导图，它描述的是当你遇到一个高并发场景时，你需要经历的思考过程。但做好以上这些也并不能说明你的系统一定能承载高并发了。还是那句话，具体问题具体分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;构建高并发系统的核心在于如何高效地处理大量同时发生的请求，保证系统的稳定性、性能和可扩展性。这里涉及到合理的业务架构设计，以及高效的并发编程模型。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此之外，也要考虑到数据一致性和事务管理，配合合理的监控和自动化运维，保证及时出现系统资源紧张和崩溃时，可以快速反应和解决问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18682939</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18682939</guid>
      <pubDate>Fri, 11 Jul 2025 03:26:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Kimi K2 在 OpenRouter 的市场份额超越 xAI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;来自中国初创公司 Moonshot AI 的开源大语言模型 Kimi K2 在 OpenRouter 平台的 token 消耗量（市场份额指标）上迅速攀升，超越 xAI 的 Grok4 和 OpenAI 的 GPT-4.1，成为近期 AI 领域的焦点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#242424"&gt;OpenRouter 作为一个统一 API 平台，允许开发者访问包括 Kimi K2、Grok4 和 GPT-4.1 在内的 400 多个模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="445" src="https://oscimg.oschina.net/oscnet/up-f9c10971955440402f4be24e32485a5fc6e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Kimi K2 是一款基于混合专家（MoE）架构的大语言模型，拥有 1 万亿总参数和 320 亿活跃参数，专为代理智能 (agentic intelligence) 优化，支持高级工具使用、推理和代码生成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;发布仅数天，Kimi K2 在 OpenRouter 平台的 token 消耗量已达到 1.5%，超越了 xAI 的 Grok4 和 GPT-4.1，位列排行榜前列。社交媒体数据显示，截至 7 月 14 日，Kimi K2 的排名已升至 OpenRouter 的第 13 位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这种快速增长得益于 Kimi K2 的开源策略和低成本定价。OpenRouter 平台上，Kimi K2 的输入 token 价格为每百万 0.15 美元（缓存命中）和 0.60 美元 (缓存未命中)，输出 token 为每百万 2.50 美元，远低于 Claude4Sonnet 和 GPT-4.1 的推理成本。这种价格优势吸引了大量开发者尝试和集成 Kimi K2，推动其市场份额迅速扩大。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360398</guid>
      <pubDate>Fri, 11 Jul 2025 02:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌计划将 ChromeOS 整合到 Android，成为统一平台</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Android 生态系统总裁 Sameer Samat 近期在回答记者的采访时表示，公司计划&lt;strong&gt;将 ChromeOS 合并到 Android，整合为统一平台&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-51dd4c07514e139b94a2701461bd9f1dfa5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Sameer Samat 在采访中透露，合并工作已启动，将耗时多年。预计短期内（如 8 月 Pixel 10 发布会）不会有重大发布，完整落地仍需数年时间。合并后，Chromebook 等设备将直接运行基于 Android 的统一系统，带来更强的 Android 应用兼容性、跨设备协同能力以及桌面级多窗口体验。&lt;/p&gt; 
&lt;p&gt;2024 年早些时候谷歌曾&lt;u&gt;&lt;a href="https://www.oschina.net/news/297021/chromeos-android-under-the-hood"&gt;宣布&lt;/a&gt;&lt;/u&gt;将 Android 内核的部分合并到 ChromeOS 中，而现在谷歌似乎正在基于该基础，将 ChromeOS 完全整合到 Android 上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360389/google-says-chromeos-will-merge-into-android</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360389/google-says-chromeos-will-merge-into-android</guid>
      <pubDate>Fri, 11 Jul 2025 02:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 或将放弃开源理念，转向闭源 AI 模型开发</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;《纽约时报》援引消息人士报道，Meta 公司新成立的&lt;span&gt;超级&lt;/span&gt;智能实验室高层成员正在讨论一项重大战略转变，放弃公司强大的下一代开源人工智能模型 Behemoth，转而开发一个封闭模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据悉，Meta 已完成 Behemoth 模型的训练，但因内部性能测试不佳而推迟发布，其测试工作在新实验室启动后也已暂停。若 Meta 最终选择放弃 Behemoth 并优先发展闭源模型，将标志着其核心 AI 理念的重大转变。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;对此，Meta 发言人向媒体表示，公司对开源 AI 的立场「没有改变」，并计划继续发布领先的开源模型，但未来会混合训练开放和封闭两种模型。该发言人并未就 Behemoth 可能被放弃一事发表评论。任何战略变更仍需 CEO 马克·扎克伯格的最终批准。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-ca858a0d41f7edf5fbd3c0579adcc15a0e2.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;扎克伯格曾高调地将 Llama 系列的开放性作为区别于 OpenAI 等竞争对手的核心战略。然而，随着 Meta 在 AI 领域投入数十亿美元（包括支付巨额薪酬招募&lt;span&gt;顶尖&lt;/span&gt;人才和兴建数据中心），公司正面临广告业务以外巨大的盈利压力。尽管拥有&lt;span&gt;顶尖&lt;/span&gt;的 AI 研究实验室，Meta 在 AI 商业化方面仍落后于 OpenAI、谷歌 DeepMind 等对手。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;转向封闭模式将赋予 Meta 对其技术更多的控制权和更清晰的盈利路径。扎克伯格本人过去也曾表态，虽支持开源，但如果某项技术强大到开源「不负责任」，就不会开源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360384</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360384</guid>
      <pubDate>Fri, 11 Jul 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程智能体 Devin 开发商宣布收购 Windsurf</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 14 日，AI 编程智能体 Devin 开发商 Cognition&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcognition_labs%2Fstatus%2F1944819486538023138"&gt;宣布&lt;/a&gt;签署最终协议，收购 AI 编程初创公司 Windsurf，包括其知识产权（如 AI 驱动的集成开发环境 IDE）、产品、商标、品牌及剩余约 250 名员工。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0715/100601_pCAH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前谷歌以 24 亿美元「反向收购」&lt;a href="https://www.oschina.net/news/360297"&gt;挖走&lt;/a&gt;了 Windsurf 的 CEO Varun Mohan、联合创始人 Douglas Chen 及核心研究团队，而 OpenAI 的 30 亿美元收购要约则因知识产权共享问题于几天前过期 。&lt;/p&gt; 
&lt;p&gt;Cognition 没有透露收购的具体价格，但表示 Windsurf 年经常性收入（ARR）已达 8200 万美元，其中企业客户 ARR 环比翻番，拥有 350 多家企业客户，日活跃用户数十万。&lt;/p&gt; 
&lt;p&gt;最让人点赞的是 Cognition 对员工的态度，与谷歌只照顾高层的做法形成了鲜明对比，公告中明确表示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% 的员工都能在此次收购中获得经济层面的参与机会，也就是可能通过股权、现金等形式分享收购带来的收益。&lt;/li&gt; 
 &lt;li&gt;免除所有人的股权归属悬崖期（vesting cliffs），无需再等待该期限即可获得对应权益。&lt;/li&gt; 
 &lt;li&gt;所有员工截至目前工作对应的股权将全部加速归属，原本可能需要分阶段、长时间获得的股权，现在可在短期内完全获得。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/101009_dpR1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对于用户来说也有好消息，Cognition 还与 Anthropic 达成协议，Windsurf 现在将再次获得 Claude AI 模型的完全访问权限。&lt;/p&gt; 
&lt;p&gt;短期内，两个团队将继续独立运作：Windsurf 团队继续开发其 AI 驱动的 IDE，Cognition 则专注于其 AI 编码代理 Devin。最终两者的技术将进行整合，打造更强大的 AI 编程工具。&lt;/p&gt; 
&lt;p&gt;未来，Cognition 计划将 Windsurf 的技术与 Devin 整合，使开发者能在单一界面中规划任务、并行委托多个 Devin 实例处理代码，并借助自动补全完成高影响力任务 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf</guid>
      <pubDate>Fri, 11 Jul 2025 02:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里 Qwen 团队提醒 Qwen3-embedding GGUF 模型使用注意事项</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里巴巴 Qwen 团队提醒开发者，在使用 Qwen3-embedding GGUF 模型时需在末尾添加特殊 token&amp;lt;|endoftext|&amp;gt; 以保证精度，并预告将发布自动处理此问题的更新版本。&lt;/p&gt; 
&lt;p&gt;阿里巴巴 Qwen 团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAlibaba_Qwen%2Fstatus%2F1944425668235977146" target="_blank"&gt;表示&lt;/a&gt;，他们在社区讨论中注意到，部分开发者在使用 Qwen3-embedding 的 GGUF 模型时，未在上下文末尾附加特殊 token&amp;lt;|endoftext|&amp;gt;，这可能会严重影响模型精度。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen3-Embedding-0.6B-GGUF" target="_blank"&gt;详细信息可查阅其 Hugging Face 模型卡&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0714/183758_kDLs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;团队表示，llama.cpp 在转换 GGUF 文件时已支持自动添加此 token。他们将很快发布一个更新的 GGUF 模型包，届时开发者将无需再手动处理此问题。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360312</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360312</guid>
      <pubDate>Thu, 10 Jul 2025 10:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>PaddleOCR 3.1 发布</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.0 自 5 月 20 日发布以来，受到业界的广泛关注，同时我们也收到了众多宝贵意见。我们积极响应、快速升级迭代，并在近日发布了 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1&lt;/strong&gt;，带来了&lt;strong&gt;3 个新升级：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;■ &lt;strong&gt;三大升级&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增 PP-OCRv5 多语种文本识别模型。支持法语、西班牙语、葡萄牙语、俄语、韩语等 37 种语言，平均识别精度提升超过 30%。同时依托文心 4.5 多模态能力，实现了数据的自动高质量标注，有效解决了多语种数据稀缺和标注成本高的问题，进一步提升了模型在多语言、多场景下的识别能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增文档翻译 PP-DocTranslation 产线。PP-DocTranslation 基于文档解析 PP-StructureV3 和文心 4.5 大模型，支持对 Markdown、PDF 和图片三种格式的文档数据进行翻译，同时支持本地传入专业术语对照表，实现关键词汇的精细化多语言翻译。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 MCP 服务器。用户可通过简单的步骤搭建 MCP 服务器，将通过本地 Python 库、云服务、自托管服务等多种方式运行的 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 核心能力统一集成到下游 AI 应用中，实现更灵活高效的应用构建。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;30+语种文字识别精度跃升 30%&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着世界各地交流合作的加深，多语种文本识别正成为智能应用领域的重要需求。为提升多语种场景下的文字识别能力，我们通过融合文心大模型的视觉和文本理解能力，实现了高效、高质量的训练数据获取，升级 PP-OCRv5 在 37 种语言文字的识别能力，包括韩文、西班牙文、法文、葡萄牙文、德文、意大利文、俄罗斯文等。与前代多语种文字识别模型相比，PP-OCRv5 在多语言场景文字&lt;strong&gt;识别准确率提升超过 30%。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a8707e8f4e09c855f8c0316f4b50560e2a4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-3ae5ee285df36995e695478a78702967ca8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-393c007aadc93cc04eff6538c720d504618.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-71116717dd646f973c9f97918ec28a609ec.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-faa32420f433405c6817bc1c4ec7902d074.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a5ce05bbee27068f72ea88ccea577ddc826.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-6ccc329e2cbe51bb431e31f36da7250a1bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-c2e4263d331578c92954d9cf161df0b773a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 关键步骤——文心 4.5 助力多语种文字高质量数据构建&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;自动文本行检测与裁剪：利用 PP-OCRv5 检测模型，自动定位并裁剪图像中的每一行文本，快速、高效地获取标准化的文本行图片。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高置信度文本内容识别：依托文心 4.5 强大的视觉和文本理解能力，对每个文本行图像进行多次独立识别，筛选出识别结果一致的样本。不仅显著提升标注数据的准确性，还有效规避了人工标注的主观误差，确保数据高质量和高可靠性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-b38cde483c65f6abb66d7f9562517e5336c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 模型精度对比&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-f19e38a90dd3436d78b4fb6f216ba9d16c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;注：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;为更全面评估多语种模型能力，本次模型研发过程中重新收集了大量来自真实场景的高难度评估数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;拉丁字母文字涵盖西班牙文、葡萄牙文、法文等 33 种语言文本。东斯拉夫语言涵盖俄文、乌克兰文、白俄罗斯文。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;▎ PP-OCRv5 多语种文字识别命令行使用方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以通过在命令行中使用--lang 参数，来进行指定语种的文本识别模型推理：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 通过 `--lang` 参数指定使用法语的识别模型

paddleocrocr-ihttps://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_french01.png \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--langfr \ # 此处为法语，刚多请参阅文档

&amp;nbsp; &amp;nbsp;&amp;nbsp;--use_doc_orientation_classifyFalse \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--use_doc_unwarpingFalse \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--use_textline_orientationFalse \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--save_path ./output \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--devicegpu:0

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述命令行的其他参数说明请参考通用 OCR 产线的&lt;strong&gt;命令行使用方式。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PP-StructureV3+文心大模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;复杂文档翻译更简单&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在全球化和信息化加速发展的背景下，文档翻译在现代社会中已成为一种不可或缺的需求，企业和个人需要高效、准确地翻译各类复杂文档。为此，我们结合 &lt;strong&gt;PP-StructureV3 和文心大模型&lt;/strong&gt;，推出了&lt;strong&gt;复杂文档翻译工具 PP-DocTranslation&lt;/strong&gt;。PP-StructureV3 具备强大的复杂文档解析能力，能够轻松应对很多复杂布局的 PDF 文档及文档图片，并高效地将其转换为 Markdown 格式输出。我们在此基础上，融合了文心大模型强大的文本理解和语义分析能力，对生成的 Markdown 结果进行进一步处理，&lt;strong&gt;实现了对相关文档的高质量多语言翻译。&lt;strong&gt;此外，为了更好地服务于各类专业领域对精准翻译的需求，该工具特别增加了用&lt;/strong&gt;户自定义词表功能&lt;/strong&gt;，用户可以根据自身业务或领域的专业术语，自定义词汇表，从而实现特定场景下更加准确、专业的翻译结果。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 效果展示&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-e362b2b43e56cbaef67a4ee6b734f10255e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-5d59816b55e1500001a12db71417a24dbb0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 文心 4.5 助力多语言翻译&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;精准翻译：依托文心 4.5 对多语言的理解，能够实现更为精准、地道的目标语言翻译效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多语言支持：借助文心 4.5 的多语言处理能力，满足多样化多语言的翻译需求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-e099b39899578a925c90895450d0b1c1e25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;▎ PP-DocTranslation 的 CLI 体验方式：&lt;/p&gt; 
&lt;p&gt;可以通过在命令行中使用--target_language 参数，来进行指定要翻译的目标语言：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;paddleocr pp_doctranslation -i&amp;nbsp;vehicle_certificate-1.png&amp;nbsp;--target_language&amp;nbsp;en&amp;nbsp;--qianfan_api_key&amp;nbsp;your_api_key﻿

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持 MCP 服务器，轻松连接大模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;发挥 OCR 的无限想象空间&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MCP 是一种开放协议，用于规范应用程序向大语言模型提供上下文信息的方式。可以将 MCP 类比为 AI 应用中的 USB 接口。正如 USB 为设备与各种外设和配件之间的连接提供了标准化方式，MCP 同样为 AI 模型与不同数据源和工具之间的连接提供了统一规范。通过支持实时调用数据或 API，MCP 能有效拓展应用场景、降低开发门槛，并提升系统安全性。如今，MCP 正逐渐成为推动 AI 生态落地的关键连接桥梁。&lt;/p&gt; 
&lt;p&gt;为了更便捷地将 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 能力集成至各类 AI 应用中，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1 版本支持用户通过几步简单操作，即可搭建 MCP 服务器。具体而言，根据 MCP 协议，AI 应用（作为 MCP 主机）通过 MCP 客户端与 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 的 MCP 服务器进行通信。&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 的 MCP 服务器则通过 Python API 或服务请求等方式调用其核心能力，并将这些能力标准化后提供给下游的 AI 应用使用。下图展示了 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 核心功能、&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器以及 AI 应用之间的关系：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-f28229dbd08038a27d3d3c4cb8f8a06db40.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;当前，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器支持以下能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;文字识别：对图像和 PDF 文件进行文本检测与识别，返包含文字座标和文字内容的 JSON 文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文档解析：从图像或 PDF 中识别和提取文本块、标题、段落、图片、表格等版面元素，并将内容结构化输出为 Markdown 文档和 JSON 文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;根据 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 的运行方式，&lt;strong&gt;MCP 服务器支持以下工作模式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;本地 Python 库：在本地直接运行 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;星河社区服务：调用托管在&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;飞桨&lt;/a&gt;星河社区的服务。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自托管服务：连接用户自行部署的 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 服务。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同时，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器支持 stdio 和 Streamable HTTP 两种传输机制，用户既可以本地部署服务实现快速集成，也可以远程调用服务，满足不同场景的使用需求。&lt;/p&gt; 
&lt;p&gt;同时，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器支持 stdio 和 Streamable HTTP 两种传输机制，用户既可以本地部署服务实现快速集成，也可以远程调用服务，满足不同场景的使用需求。&lt;/p&gt; 
&lt;p&gt;搭建 MCP 服务器并集成到 AI 应用中，仅需几个简单步骤。下面以「星河社区服务」模式为例，介绍如何在 Claude for Desktop 中使用 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器提供的工具。&lt;/p&gt; 
&lt;p&gt;1.参考 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 官方文档，在星河社区部署推理服务&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 官方文档：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpaddlepaddle.github.io%2FPaddleOCR%2Fv3.1.0%2Fversion3.x%2Fdeployment%2Fmcp_server.html" target="_blank"&gt;https://paddlepaddle.github.io/PaddleOCR/v3.1.0/version3.x/deployment/mcp_server.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;星河社区：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faistudio.baidu.com%2Fpipeline%2Fmine" target="_blank"&gt;https://aistudio.baidu.com/pipeline/mine&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;2.将 Claude for Desktop 配置文件 claude_desktop_config.json 修改如下（需安装 uv）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"paddleocr-ocr": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"command":&amp;nbsp;"uvx",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"args": [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"--from",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"paddleocr-mcp@https://paddle-model-ecology.bj.bcebos.com/paddlex/PaddleX3.0/mcp/paddleocr_mcp/releases/v0.1.0/paddleocr_mcp-0.1.0-py3-none-any.whl",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"paddleocr_mcp"
&amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"env": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_PIPELINE":&amp;nbsp;"OCR",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_PPOCR_SOURCE":&amp;nbsp;"aistudio",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_SERVER_URL":&amp;nbsp;"&amp;lt;替换为服务基础 URL&amp;gt;",&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_AISTUDIO_ACCESS_TOKEN":&amp;nbsp;"&amp;lt;替换为星河社区访问令牌&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}﻿

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3.重启 Claude for Desktop。新的 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;paddle&lt;/a&gt;ocr-ocr 工具现在应该可以在应用中使用了，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-fe758a76c5bedaedd2af8279774434e5274.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果希望使用 PP-StructureV3 的文档解析能力，只需参考上述步骤，在星河社区部署文档版面解析 V3 产线，并在配置文件中替换对应的服务基础 URL 即可。除了基本配置外，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器还提供&lt;strong&gt;丰富的可调参数&lt;/strong&gt;，用户可根据需求灵活调整，例如替换为自训练的文本识别模型、关闭不需要的功能模块等。&lt;/p&gt; 
&lt;p&gt;关于更多详细用法，请参考官方文档：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpaddlepaddle.github.io%2FPaddleOCR%2Fv3.1.0%2Fversion3.x%2Fdeployment%2Fmcp_server.html" target="_blank"&gt;https://paddlepaddle.github.io/PaddleOCR/v3.1.0/version3.x/deployment/mcp_server.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 创新案例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下展示了使用 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器结合其他工具搭建的创意案例：&lt;/p&gt; 
&lt;p&gt;Demo 1：在 Claude for Desktop 中，提取图像中的手写内容，并存到笔记软件 Notion。&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器从图像中提取了文字、公式等信息，并保留了文档的结构。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;除 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器外，此 demo 还使用 Notion MCP 服务器（&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.notion.com%2Fdocs%2Fmcp" target="_blank"&gt;https://developers.notion.com/docs/mcp&lt;/a&gt;&lt;/em&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Demo 2：在 VSCode 中，根据手写思路或伪代码一键转换为可运行并符合项目代码风格规范的 Python 脚本，并将其上传到 GitHub 仓库中。&lt;strong&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器从图像中高准确率地提取手写代码供后续步骤使用。&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;除 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器外，此 demo 还使用 filesystem MCP 服务器（&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers%2Ftree%2Fmain%2Fsrc%2Ffilesystem" target="_blank"&gt;https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem&lt;/a&gt;&lt;/em&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Demo 3：在 Claude for Desktop 中，&lt;strong&gt;将含有复杂表格、公式、手写文字等内容的 PDF 文档或图片转存为本地可编辑文件。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;PDF 转为 Word 可编辑格式&lt;/p&gt; 
&lt;p&gt;图片转为 Excel 可编辑格式：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-c7e8d117935384082bf2c28f1e7eec1d79f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-4bc497f7fba3d8291718fb8d282eeb48b60.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-4561eb49759832b5f52951d2edc59fbf26f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服务器外，此 demo 还使用 filesystem MCP 服务器（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers%2Ftree%2Fmain%2Fsrc%2Ffilesystem%25EF%25BC%2589%25E3%2580%2582" target="_blank"&gt;https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem）。&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;■ &lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.0 发布以来，我们收到了大量关于多语种识别和 MCP 支持的需求反馈。为此，我们近期推出了升级版 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1。欢迎各位开发者、研究者和行业用户下载体验 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1，并积极提出宝贵建议和反馈。大家的支持和参与将持续助力我们打造更加优质、开放和强大的 OCR 生态！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;开源地址：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FPaddlePaddle%2FPaddleOCR" target="_blank"&gt;https://github.com/PaddlePaddle/PaddleOCR&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18684322</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18684322</guid>
      <pubDate>Thu, 10 Jul 2025 10:30:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>苹果考虑收购法国 AI 初创公司 Mistral AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据彭博社&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2025-07-13%2Fis-apple-going-to-replace-ceo-tim-cook-who-is-the-next-ceo-of-apple-ternus-md1mhrj4" target="_blank"&gt;报道&lt;/a&gt;，苹果将 Mistral 视为潜在的收购对象，以弥补其在生成式 AI 领域（如 Siri）的不足 。&lt;/p&gt; 
&lt;p&gt;Mistral AI 是欧洲估值最高的 AI 初创企业，目前估值约€5.8 亿（约$6.2 亿），已融资约€1.1 亿（约$1.2 亿），并正在洽谈新一轮高达$1 亿的融资 。该公司以高效的模型和 OCR 功能闻名，其聊天机器人「Le Chat」也因快速响应受到用户好评 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8746a30a13ddc9aefb1c7186d4ee14a441c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;苹果的 AI 生态系统近年来受到批评，Siri 的升级也因内部问题被推迟至 2026 年，同时苹果近期失去了如 Ruoming Pang（基础模型团队负责人）和 Tom Gunter（资深研究员）等关键 AI 人才 。&lt;/p&gt; 
&lt;p&gt;此次收购若成行，将远超苹果 2014 年收购 Beats 的$30 亿记录，成为其史上最大并购案，但也可能面临欧盟监管阻力，因为 Mistral AI 被视为欧洲 AI 领域的重要资产 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360305</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360305</guid>
      <pubDate>Thu, 10 Jul 2025 10:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>深谋科技重磅发布真正为人类服务的新一代人形机器人核心技术</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;声波传感&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;·&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;意念&lt;/strong&gt;&lt;strong&gt;控制 ·&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;高精视觉 · 类脑智能&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;2025 世界人工智能大会（WAIC）将于 7 月 26 日至 29 日举行。作为本届大会的精英合作伙伴，深谋科技亮相 H3 馆 D710 展位。秉承「人形机器人应摆脱 ‘跑跑跳跳，图个热闹’ 的怪圈，真正满足人类需要、为人类服务，最终成为人类社会一员」 的理念，深谋将凭借全能感知、先进控制、类脑智能等一系列面向新一代人形机器人的核心技术点燃具身智能新的变革。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;2025 年，深谋自研全尺寸人形机器人「美猴王」尚未正式亮相，便已荣获德国红点大奖与美国 MUSE 金奖，成为首个同时摘得这两项国际顶级设计殊荣的人形机器人。尽管「美猴王」在设计上独树一帜，但深谋关注的从不只是单项突破，而是贯穿感知、控制与决策的一体化能力，构建具身智能要改变人类生活方式所需的全域系统闭环，实现对复杂现实与人类意图的深度适配与响应。深谋科技将在 WAIC 发布真正为人类创造价值的新一代人形机器人核心技术。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//caa0be4755bae97d2570fe9b265a9958.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;一、业界独创 | 基于 SAW 声表面波的人形机器人多物理量智能感知系统「&lt;/strong&gt;&lt;strong&gt;OmniSense&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深谋科技独创基于声表面波（SAW）的人形机器人传感系统「OmniSense」，构建出一整套类人感官网络，覆盖环境、生理、运动三大维度：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;环境感知：&lt;/strong&gt;单芯片方案可同步感知温湿度、有害气体与化学物质，适配工业与家庭场景，实现多级智能预警；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;体表监测:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;系统可感受脉搏、分析人类汗液、呼气生物成分，辅助血糖、血压等健康评估、乃至酒精、疾病检测与康养照护，实现从外部感知走向内在理解。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;运动控制:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;SAW 传感器嵌入机器人躯干，实现高灵敏度的角速度和加速度测量，嵌入机器人关节，利用声磁耦合，进行高精度的位置检测，支撑高速动态下的平衡控制与姿态校准。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;整套系统可根据不同 SAW 频率扰动，实现温度、湿度、气体、压力、磁、生物信息、六轴 IMU 等不同物理量的智能传感，结合神经网络人工智能分类识别算法，具备 MHz 级高频响应、强抗干扰、无线无源结构与生物兼容性，在提升感知灵敏度的同时显著降低功耗，为人形机器人带来更轻盈、更持久的智能感知能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;二、脑电驱动 | 人形机器人+脑电感知与控制方案「&lt;/strong&gt;&lt;strong&gt;Mindmover&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;MindMover 是深谋首创的人形机器人闭环脑机交互系统，融合多项前沿脑电感知与智能控制技术，包含「如意」SSVEP 意图识别模块与「观心」专注度检测模块，首次实现「意图识别+ 状态反馈」的双向脑机交互闭环。前端 SSVEP 模块支持校准/免校准双模式，2 秒内完成指令反馈，信息传输率最高可达 37.4 bits/min；后端注意力检测模块基于 2 通道脑电输入，结合时频联合特征与 3 分钟个性化建模，准确率达 85%，ITR 约 22.5 bits/min。系统采用多时频尺度分析与空频增强机制，具备优异的抗噪能力与跨时段稳定性，适用于便携式场景下的沉浸式人机协同任务。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;借助深谋脑机技术的赋能，「美猴王」可实现「意念控制」和「感知人类思维」的功能，无需语音或肢体输入，即可高效适配语言或行动障碍人群，在医疗辅助、教育陪护和特种作业等高要求场景中展现出独特而不可替代的价值。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;三、&lt;/strong&gt;&lt;strong&gt;力觉先锋&lt;/strong&gt;&lt;strong&gt;｜国内首个压电式六维力传感器「弹起」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在「手腕」这一最复杂、最精密的人形接口上，深谋科技率先推出国内首款压电式动态六维力传感器「弹起」。区别于传统应变式方案，我们采用石英晶体为核心力敏元件，配合小型化智能信号解耦装置，构建出一套高带宽、高分辨率、高鲁棒性的下一代力觉系统。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;三大技术优势，让机器真正拥有触觉与判断力：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;快｜毫秒级响应：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;快速捕捉高频动态力，实时应对老人摔倒预警、康复训练反馈、手术刀下刀力控。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;准｜微小力分辨：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;对微小力精准响应，敏锐感知芯片键合、病变组织切割、易碎物品抓取等复杂任务中的细微变化，做到「下手如绣花」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;狠｜超强抗干扰：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在强电磁场（如电机驱动环境）中仍能稳定工作，有效过滤肢体摆动中的低频干扰，实现精准监测。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深谋压电式六维力传感器亦可应用于:&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;医疗&lt;/strong&gt;：用于远程及微创手术，其传感器高灵敏、低延迟、抗干扰，提供稳定力反馈，提升医生感知，保障安全与精度。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;航空航天&lt;/strong&gt;：可开展飞行器风洞测试等，能在极端温度和真空下工作，高可靠、高灵敏。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;工业&lt;/strong&gt;：实时反馈用于精密装配等流程，保障精准度与质量，尤适用于铸造、锻造等高温高振闭环力控。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;四、原始创新 | 具备类人动态视觉理解能力的 6D 姿态视觉伺服系统&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在机器人动态视觉伺服领域，深谋科技构建起获多项发明专利、自成体系的技术优势，自主研发基于立方包拟合的 6D 姿态估计算法，突破传统特征点与模板匹配的局限，可针对目标三轴姿态赋予差异化权重——系统能够识别并强化对动态目标关键方向（如长轴）的跟踪与拟合，显著提升在动态环境中的操控稳定性与抓取成功率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;不仅如此，深谋进一步打通了 3D 模型投影与实例分割的耦合路径，实现几何形态与姿态信息的联合估计，让机器人不仅「看到」目标，更能「理解」其结构与空间状态。在此基础上，系统还能提取颜色、纹理、文字、标识等语义信息，构建完整的多模态认知链条，使视觉识别更精准、更具可解释性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;尤为关键的是，深谋动态视觉伺服系统针对动态任务场景进行了专项强化：通过稳健的目标跟踪机制与连续姿态更新能力，系统可在目标快速移动、遮挡或形变的情况下，实时捕捉关键特征并同步调整伺服策略，实现从动态感知到运动控制的闭环响应。不止是「看见」动态，更能在「看见中控制」，在变化中持续修正跟踪路径。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深谋科技以全链路技术布局推动视觉伺服从静态识别走向动态交互，使人形机器人真正具备「理解视觉、实时反应、精准控制」的动态伺服能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;五、&lt;/strong&gt;&lt;strong&gt;自主构建｜软硬件全&lt;/strong&gt;&lt;strong&gt;栈&lt;/strong&gt;&lt;strong&gt;自&lt;/strong&gt;&lt;strong&gt;研&lt;/strong&gt;&lt;strong&gt;的人形&lt;/strong&gt;&lt;strong&gt;机器人&lt;/strong&gt;&lt;strong&gt;具身智能&lt;/strong&gt;&lt;strong&gt;系统&lt;/strong&gt;&lt;br&gt; &amp;nbsp;深谋科技深知人形机器人未来竞争力在于软硬件全栈自研，自研范围覆盖从关键部件到核心算法的全栈技术架构，构建起支撑人形机器人感知与运动等核心功能的智能技术平台。在硬件层面，自主研发了灵巧手、六维力传感器，在研准直驱关节模组，为机器人本体提供高性能的多模态感知与执行能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在算法层面，规划与控制软件融合了模型驱动的 MPC（模型预测控制）和数据驱动的 RL(强化学习）及具身智能大模型 (VLA)，结合 ADRC（主动抗扰控制）机制、运动控制策略与动态协调系统，构建起机器人感知、决策、规划、动作的智能闭环与精准响应能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;深谋科技｜打造类&lt;/strong&gt;&lt;strong&gt;脑具身&lt;/strong&gt;&lt;strong&gt;智能新范式&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在打造人形机器人「大脑」的路径上，深谋科技又与众不同地选择了一条有别于行业主流的独立方向。认为当前依赖海量数据与无限参数的大模型，虽在语言、文本和视觉方面取得成功，也展现出一定的推理能力，但其高能耗、低效率的学习特性，与人类所具备的高效、可泛化的高级智能仍存在很大差距。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深谋科技正进行基于能量 (Energy-Based)、具备生物合理性（biologically plausible），借鉴脑科学机制的世界模型研究，将于明年发布能分时间维度提取因果关系和物理规律的通用具身智能世界模型。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;WAIC 见 · 来 H3-D710，&lt;/strong&gt;&lt;strong&gt;深&lt;/strong&gt;&lt;strong&gt;谋科技&lt;/strong&gt;&lt;strong&gt;独家展示兼具&lt;/strong&gt;&lt;strong&gt;技术锋芒与美学张力的&lt;/strong&gt;&lt;strong&gt;陆上&lt;/strong&gt;&lt;strong&gt;具身&lt;/strong&gt;&lt;strong&gt;智能&lt;/strong&gt;&lt;strong&gt;人形「美猴王」 和&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;空中具身&lt;/strong&gt;&lt;strong&gt;智能巨兽「星汉一号」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ab88f2d3c375dde9e7e68cc772534ac8.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360301</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360301</guid>
      <pubDate>Thu, 10 Jul 2025 10:03:00 GMT</pubDate>
      <author>作者: 开源科技</author>
    </item>
    <item>
      <title>飞书开源「RTV」富文本组件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;飞书近日正式将其自研的富文本组件库 RichTextVista（RTV）开源，并上线 OpenHarmony 三方库中心仓。它是鸿蒙生态首个深度集成「属性字符串」（StyledString）方案的富文本组件，兼顾性能、开放性和易用性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「该组件以领先的性能、流畅的渲染体验与高度的开放性，为鸿蒙生态提供了更高效的富文本解决方案。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-2eb284d37904c2121362a99a8cc887778ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;流畅性能：基于属性字符串，打破滑动瓶颈&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;RTV 在架构上摒弃传统基于 Component 的实现路径，采用轻量级的「属性字符串」（StyledString）渲染方案，显著减少视图层级。实测显示，即便在万级消息长列表等场景下，仍可保持 120FPS 的流畅滑动，为用户带来丝滑的交互体验。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;超高开放性：支持「自定义样式注入」&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;现有开源的富文本仓库均缺乏集成自定义样式的能力，只能使用预制的样式。RTV 是社区中唯一支持用户注入自定义样式的文本渲染器。开发者可以通过其完善的开放样式 API，轻松实现@人、自定义表情、业务组件等元素的集成与渲染，让富文本真正服务于业务创新，而不是成为创新的掣肘。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;广泛兼容与轻松接入：历经大型应用验证&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;RTV 支持包括 HTML、Markdown、Protobuf 实体在内的多种标准化数据源，开发者无需为格式转换耗费心力。同时，它提供了「开箱即用」的接入体验，包含清晰的文档、丰富的示例和预览工具，最简单的 Demo 仅需不到 10 行代码即可渲染，告别复杂的性能调优与兼容性适配工作。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，该组件已在飞书的 IM、日历、云文档、视频会议等 8 个核心业务模块中稳定运行超过半年。据飞书内部估算，RTV 的落地应用，已累计为飞书相关业务节省了超过 300 天的时间及人力开发成本，成为名副其实的「效率杠杆」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360299</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360299</guid>
      <pubDate>Thu, 10 Jul 2025 10:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌「截胡」 OpenAI，AI 编程创企 Windsurf 核心成员加入 DeepMind 团队</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windsurf 原名 Codeium，2021 年由麻省理工学院校友创立，2025 年 4 月更名，年度经常性收入超 1 亿美元，用户增长强劲。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0714/175102_k9UJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2025 年 7 月 12 日，OpenAI 以 30 亿美元收购 AI 编程初创公司 Windsurf 的交易失败（&lt;strong&gt;收购协议排他性期限到期未续签&lt;/strong&gt;&amp;nbsp;），谷歌 DeepMind 迅速 「截胡」，宣布聘请 Windsurf 创始人兼首席执行官 Varun Mohan、联合创始人 Douglas Chen 及部分研发人员加入谷歌 DeepMind 团队，专注于以 Gemini 为核心的 AI 编程（智能体编码）项目开发 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0714/175117_I0TI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;谷歌未收购 Windsurf 股权或控制权，但获得其部分技术的非独家许可（&lt;strong&gt;彭博社称相关花费约 24 亿美元&lt;/strong&gt;&amp;nbsp;）。&lt;/p&gt; 
&lt;p&gt;Windsurf 任命业务主管 Jeff Wang 为临时 CEO，全球销售副总裁 Graham Moreno 为新总裁，维持独立运营 。&lt;/p&gt; 
&lt;p&gt;科技媒体 The Verge 从谷歌发言人 Chris Pappas 那里得到了一份声明，其中写道：「Gemini 是目前最好的模型之一，我们一直在投资为其开发先进的开发者功能。我们非常高兴地欢迎 Windsurf 团队的顶尖 AI 编程人才加入谷歌 DeepMind，以推进我们在智能体编程方面的工作。」&lt;/p&gt; 
&lt;p&gt;担任临时 CEO 的 Jeff Wang 在𝕏发布了一份长文声明，写道：Windsurf 「一流」 团队的大部分成员将继续为企业打造 Windsurf 产品，并帮助我们的客户最大限度地利用这项技术。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0714/175149_lsXk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360297</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360297</guid>
      <pubDate>Thu, 10 Jul 2025 09:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
