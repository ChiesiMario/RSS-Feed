<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 19 Aug 2025 13:20:55 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>DeepSeek 刚刚更新线上模型版本至 V3.1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 在官方社群宣布，其线上模型版本已升级至 V3.1，上下文长度拓展至 128k。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0819/193913_BlOM_2720166.png" width="1196" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;欢迎前往官方网页、APP、小程序测试，API 接口调用方式保持不变。&lt;/p&gt; 
&lt;p&gt;接口信息：https://platform.deepseek.com/usage&lt;/p&gt; 
&lt;p&gt;近日市场再度传出深度求索下一代 AI 大模型 DeepSeek-R2 的发布消息，预计时间窗口为 8 月 15 日至 30 日。对此，接近 DeepSeek 人士表示，该消息不实，并确认 DeepSeek-R2 在 8 月内并无发布计划。 &lt;/p&gt; 
&lt;p&gt;DeepSeek 创始人梁文锋在内部表示，他对 R2 取得的进展并不满意，并一直在竭力投入更多的时间来研发一款能够让该公司在 AI 领域保持领先地位的先进模型。&lt;/p&gt; 
&lt;p&gt;梁文峰要求模型达到更出色的结果才批准发布，R2 的发布还因更新版模型的数据标注时间超出预期而被推迟。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367254</guid>
      <pubDate>Tue, 19 Aug 2025 11:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 总裁透露 OpenAI 的 AGI 之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在最新一期的《Latent Space》访谈中，OpenAI 总裁 Greg Brockman 深入阐述了公司迈向 AGI 的整体路线图，核心可概括为「三个转向」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技术转向：从「一次性预训练」到「强化学习推理」&lt;/li&gt; 
 &lt;li&gt;资源转向：把「算力」视为唯一稀缺资源&lt;/li&gt; 
 &lt;li&gt;落地转向：从「科研样品」到「可审计的生产 Agent」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7470bcfe83cc59abb3b2fd2b11145f80512.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Greg Brockman 透露，GPT-4 发布之后，团队内部覆盘「它为何还不是 AGI」，结论是仅靠大规模预训练无法解决可靠性不足的问题，必须让模型在与真实世界的交互中「试错—反馈—再训练」。因此 GPT-5 首次引入强化学习驱动的「动态推理」范式：模型边使用边生成数据，再用这些数据进行再训练，逼近人类「边做边学」的循环。&lt;/p&gt; 
&lt;p&gt;他将这种「推理-重训」飞轮称为「超临界学习」（supercritical learning）：当算力放大 10× 乃至 10 000× 时，模型不仅能掌握任务本身，还能推演出二阶、三阶后果，从而快速逼近 AGI。&lt;/p&gt; 
&lt;p&gt;Greg Brockman 还把「算力」视为唯一稀缺资源，他认为算法壁垒往往可通过堆算力解决；AGI 进度条几乎与可用计算量线性相关。OpenAI 已把「持续投入大规模计算」写入长期资源策略，并认为未来 AGI 的形态会是「一个模型管理器」——本地小模型按需调用云端大算力，实现自适应计算。&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;总的来说，OpenAI 的 AGI 路线图可概括为「用强化学习把模型放进真实世界，用算力把反馈循环推到极致，用安全可控的 Agent 形态把能力嵌入千行百业」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367248</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367248</guid>
      <pubDate>Tue, 19 Aug 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 143 被发现不适用于某些旧 Windows 10 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在旧版 Windows 10 上运行 Firefox 浏览器的用户即将迎来很大困扰。目前在 Nightly 频道提供的最新版本 Firefox 143 已不再适用于 1803 之前的版本。&lt;/p&gt; 
&lt;p&gt;在 Windows 10 1703、1709 或 2015 LTSB 等老版本上启动该浏览器时，用户会收到以下错误：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于未找到 api-ms-win-core-console-11-2-0.dll，代码无法继续执行。重新安装程序或许可以解决此问题。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0700df38d95ae0494d0de12f07efb1ce47d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FTheBobPony%2Fstatus%2F1955740560292999460" target="_blank"&gt;这一发现&lt;/a&gt;迅速引发了用户的讨论（他们已经对 Mozilla 向浏览器添加不必要的、耗费资源的内容&lt;a href="https://www.oschina.net/news/366029" target="_blank"&gt;感到不满&lt;/a&gt;），他们要求 Mozilla 放弃旧版 Windows 10，这并非罕见之举。尽管 Windows 10 总体上仍然受支持，但许多应用程序已无法在旧的版本上运行。&lt;/p&gt; 
&lt;p&gt;尽管如此，考虑到 Mozilla 浏览器仍然支持 Windows 7，放弃对部分 Windows 10 市场份额的支持却令人意外，不过某些旧版本（例如 2015 LTSB 和 2016 LTSC）仍然受支持。Windows&amp;nbsp;10 2015 LTSB 版本将于 2025 年 10 月停止支持，而 2016 LTSC 版本将继续获得更新，直到 2016 年 10 月。&lt;/p&gt; 
&lt;p&gt;然而事实证明，Mozilla 并没有在 1803 之前的 Windows 10 版本上淘汰 Firefox。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ffirefox%2Fcomments%2F1mph4ra%2Fstarting_with_firefox_143_it_will_now_only%2F" target="_blank"&gt;Mozilla 工程师在 Reddit 上&lt;/a&gt;迅速处理了此事，并确认 Firefox 143 Nightly 无法在旧版 Windows 10 上运行的问题只是一个 bug，而非故意为之。因此，该问题应该很快就会得到修复。您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1983020" target="_blank"&gt;在 Bugzilla 官方网站上&lt;/a&gt;跟踪发现的 bug 。&lt;/p&gt; 
&lt;p&gt;与此同时，用户创建了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faubymori%2FFirefox-OldWindows%252010-Fix" target="_blank"&gt;一个临时解决方案&lt;/a&gt;，让浏览器在 Firefox 软件工程师准备永久修复程序期间能够正常运行。这也可以提醒大家不要依赖 Nightly 版本，因为这些版本的更改有时可能会导致浏览器完全崩溃。&lt;/p&gt; 
&lt;p&gt;Mozilla 尚未宣布终止 Windows 10 支持的计划。不过，由于 Windows 7 仍受支持，因此可以预期开发人员将在相当长的一段时间内继续在 Windows 10 上更新 Firefox。另一方面，微软近日透露，Edge 浏览器在 2025 年 10 月主流支持结束后，仍将在 Windows 10 上继续支持三年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367246</guid>
      <pubDate>Tue, 19 Aug 2025 11:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Claudia —— 基于 Tauri 2 的 Claude Code 桌面客户端</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Claudia 是一款强大的桌面应用程序，作为 Claude Code 的图形化命令中心，为 AI 辅助开发工作流程提供了直观的界面。该应用基于 Tauri 2、React 和 TypeScript 构建，填补了 Claude Code CLI 与开发者全面视觉体验之间的空白。&lt;/p&gt;

&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/181014_4hpz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;Claudia 通过提供功能丰富的图形用户界面（GUI），改变了开发者与 Claude Code 的交互方式，提升了生产力并简化了 AI 辅助开发流程。该应用程序基于您现有的 Claude Code 安装，自动检测您的&lt;code&gt;~/.claude&lt;/code&gt;目录，并为项目、会话和自定义 AI 代理提供可视化界面。&lt;/p&gt;

&lt;p&gt;Claudia 为存储在&lt;code&gt;~/.claude/projects/&lt;/code&gt;中的所有 Claude Code 项目提供了可视化浏览器。您可以：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过用户友好的界面浏览项目&lt;/li&gt;
&lt;li&gt;查看并恢复带有完整上下文的过往编码会话&lt;/li&gt;
&lt;li&gt;搜索特定项目和会话&lt;/li&gt;
&lt;li&gt;查看会话元数据，包括首次消息和时间戳&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该应用程序自动检测正在运行的 Claude Code 会话，并允许您从中央界面进行管理。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/claudia-code</link>
      <guid isPermaLink="false">https://www.oschina.net/p/claudia-code</guid>
      <pubDate>Tue, 19 Aug 2025 10:39:00 GMT</pubDate>
    </item>
    <item>
      <title>XZ Utils 后门仍然潜伏在 Docker 镜像中</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;安全研究公司 Binarly &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.binarly.io%2Fblog%2Fpersistent-risk-xz-utils-backdoor-still-lurking-in-docker-images" target="_blank"&gt;发布报告称&lt;/a&gt;，曾在 2024 年曝光的 &lt;strong&gt;XZ Utils 后门&lt;/strong&gt;仍在部分 Docker 镜像中潜伏，提醒开发者和运维人员容器供应链的潜在风险仍未彻底消除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;xz-utils&lt;/code&gt; 软件包曾在 2024 年被发现存在严重后门（CVE‑2024‑3094，CVSS 10.0 分）。该后门通过 &lt;code&gt;liblzma.so&lt;/code&gt; 对 OpenSSH 函数加钩子，实现绕过 SSH 认证和远程执行权限操作。&lt;/p&gt; 
&lt;p&gt;尽管该漏洞在公开后迅速修复，但 Binarly 团队最新扫描显示，&lt;strong&gt;截至 2025 年 8 月，仍有 12 个 Debian 官方基础镜像直接包含该后门&lt;/strong&gt;，并且通过依赖关系，至少有 &lt;strong&gt;35 个镜像存在潜在传播风险&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/183442_zItb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;针对该情况，Debian 维护者回应称，这些镜像属于过时开发版，主要保留历史记录，因此选择不移除。Binarly 则提醒，即便利用条件苛刻，这些带网络触发能力的后门镜像仍可能被自动化构建或无意拉取带入生产环境，存在潜在安全威胁。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367240</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367240</guid>
      <pubDate>Tue, 19 Aug 2025 10:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>达梦数据：公司董事兼总经理被留置</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;达梦数据发布公告称，公司于近期收到湖北省应城市监察委员会下发的《立案通知书》及《留置通知书》，对公司董事兼总经理皮宇立案调查并实施留置措施。&lt;/p&gt; 
&lt;p&gt;目前，公司已对相关工作进行妥善安排，预计该事项不会对公司生产经营产生重大影响。其他董事、监事和高级管理人员均正常履职，公司及子公司日常经营情况正常，各项业务稳步推进。&lt;/p&gt; 
&lt;p&gt;&lt;img height="532" src="https://oscimg.oschina.net/oscnet/up-3b66d352d66b8255335b97b879b6b195785.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367239</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367239</guid>
      <pubDate>Tue, 19 Aug 2025 10:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>欧洲 AI 创企发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;欧洲知名 AI 初创公司 Multiverse Computing 近日发布了两款极其微小的 AI 模型，小到可以用鸡脑和蝇脑来命名。该公司声称这是全球最小但仍保持高性能的模型，能够处理聊天、语音识别，其中一款甚至具备推理能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这些超小型模型专为物联网设备设计，同时可以在智能手机、平板电脑和个人电脑上本地运行。公司创始人罗曼·奥鲁斯向 TechCrunch 表示："我们可以将模型压缩到如此程度，使其能够适配各种设备。你可以在本地运行它们，直接在 iPhone 上，甚至在 Apple Watch 上。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Multiverse Computing 总部位于西班牙多诺斯蒂亚，在全球设有办公室，员工约 100 人，是一家备受关注的欧洲 AI 初创公司。该公司由欧洲顶级量子计算和物理学教授罗曼·奥鲁斯、量子计算专家塞缪尔·穆格尔和前 Unnim 银行副首席执行官恩里克·利萨索·奥尔莫斯共同创立。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-994e0870ab2f0680c22e597e4d0461fe9b9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;今年 6 月，该公司凭借名为"CompactifAI"的模型压缩技术成功融资 1.89 亿欧元（约 2.15 亿美元）。自 2019 年成立以来，公司累计融资约 2.5 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;CompactifAI 是一种量子启发的压缩算法，能够在不牺牲模型性能的前提下减小现有 AI 模型的体积。奥鲁斯解释说:"我们拥有的压缩技术不是计算机科学或机器学习领域人员会采用的典型压缩技术，因为我们来自量子物理学背景。这是一种更加精妙和精细的压缩算法。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;该公司已经发布了大量开源模型的压缩版本，特别是流行的小型模型如 Llama4Scout 或 Mistral Small3.1，并刚刚推出了 OpenAI 两个新开源模型的压缩版本。公司还压缩了一些大型模型，比如提供 DeepSeek R1Slim 版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;专注于模型小型化的 Multiverse 将额外精力投入到创造尽可能小但功能强大的模型上。其两款新模型小到足以为几乎任何物联网设备带来聊天 AI 功能，并且无需互联网连接。公司幽默地称这个系列为"模型动物园"，因为产品是根据动物大脑尺寸命名的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;名为 SuperFly 的模型是 Hugging Face 开源模型 SmolLM2-135 的压缩版本。原始模型有 1.35 亿个参数，专为设备端使用开发。SuperFly 压缩至 9400 万个参数，奥鲁斯将其比作蝇脑的大小。他说："这就像拥有一只苍蝇，但稍微聪明一点。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;SuperFly 专为在极其受限的数据上进行训练而设计，比如设备操作数据。Multiverse 设想将其嵌入家用电器中，让用户能够通过语音命令操作设备，如对洗衣机说"开始快洗"，或询问故障排除问题。通过少量处理能力（如 Arduino），该模型就能处理语音界面，公司向 TechCrunch 进行了现场演示。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;另一款名为 ChickBrain 的模型更大，有 32 亿个参数，但功能也更强大，具备推理能力。Multiverse 表示这是 Meta Llama3.18B 模型的压缩版本，但小到足以在 MacBook 上运行，无需互联网连接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更重要的是，奥鲁斯表示 ChickBrain 在多个标准基准测试中实际上略微超越了原始模型，包括语言技能基准 MMLU-Pro、数学技能基准 Math500 和 GSM8K，以及通用知识基准 GPQA Diamond。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;需要注意的是，Multiverse 并未声称其模型动物园会在这些基准测试中击败最大的最先进模型，动物园的性能甚至可能不会出现在排行榜上。关键在于该公司的技术能够在不影响性能的情况下缩小模型尺寸。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;奥鲁斯表示，公司已在与所有领先的设备和家电制造商进行洽谈。他说:"我们正在与苹果洽谈，也在与三星、索尼和惠普对话。惠普在最后一轮融资中作为投资者参与进来。"这轮融资由知名欧洲风投公司 Bullhound Capital 领投，包括 HP Tech Ventures 和东芝在内的多家机构参与。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这家初创公司还为其他形式的机器学习提供压缩技术，如图像识别，在六年时间里已获得巴斯夫、Ally、穆迪、博世等客户。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了直接向主要设备制造商销售模型外，Multiverse 还通过托管在 AWS 上的 API 提供压缩模型，任何开发者都可以使用，通常比竞争对手收取更低的 token 费用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367238</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367238</guid>
      <pubDate>Tue, 19 Aug 2025 10:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>小米 Q2 净利润同比增长 75.4%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;小米集团公布 Q2 财报，数据显示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;小米集团第二季度营收 1159.6 亿元人民币，同比增长 30.5%，创历史新高。预估 1149.4 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;调整后净利润 108.3 亿元人民币，同比增长 75.4%，同样创下历史新高。预估 102.3 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;营业利润 134.4 亿元人民币，预估 104.3 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;研发支出 77.6 亿元人民币，同比增长 41.2%。预估 71.8 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;智能电动汽车及 AI 等创新业务分部收入达到人民币 213 亿元，其中汽车业务贡献了 206 亿元。该分部的毛利率高达 26.4%，远高于去年同期的 15.4%。财报将其归因于核心零部件成本下降、单位制造成本降低，以及高 ASP（平均售价）的 Xiaomi SU7 Ultra 交付。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="217" src="https://oscimg.oschina.net/oscnet/up-7c457b8deb1369b766421cd8022a09bb76f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心业务进展：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能电动汽车：&lt;/strong&gt;已成为绝对的增长引擎。本季度收入达 213 亿元，交付 81,302 辆新车。毛利率高达 26.4%，远超市场预期，显示出强大的成本控制和高端车型交付能力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;IoT 与生活消费产品：&lt;/strong&gt;表现亮眼，收入 387 亿元，同比猛增 44.7%，毛利率提升至 22.5%。智能大家电（空调、冰箱、洗衣机）是主要增长动力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能手机：&lt;/strong&gt;尽管出货量微增 0.6% 至 4240 万台，但收入同比下滑 2.1% 至 455 亿元，毛利率从 12.1% 降至 11.5%，主要受境外市场竞争及国内促销活动影响。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;互联网服务：&lt;/strong&gt;收入稳定增长至 91 亿元，同比增长 10.1%，但毛利率从 78.3% 微降至 75.4%。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;小米集团表示，2025 年第二季度，智能大家电的收入创历史新高，同比增长达 66.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="2551" src="https://static.oschina.net/uploads/space/2025/0819/175808_cTEa_4252687.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367233</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367233</guid>
      <pubDate>Tue, 19 Aug 2025 09:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌工程师提交补丁：Linux 内核首次支持 OOM 策略可编程</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 内核正迎来一项可能改变内存管理方式的新提案。来自谷歌的内存管理专家 Roman Gushchin 提交了一组补丁，计划允许通过 BPF（eBPF）直接定制系统在 &lt;strong&gt;内存溢出（OOM, Out-of-Memory）&lt;/strong&gt; 时的处理逻辑。这意味着，长期以来依赖内核默认 OOM killer 或用户空间工具（如 systemd-oomd）的局限性，或将被更灵活、可编程的机制取代。&lt;/p&gt; 
&lt;p&gt;&lt;img height="712" src="https://static.oschina.net/uploads/space/2025/0819/174242_BTqv_2720166.png" width="1082" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lore.kernel.org/lkml/20250818170136.209169-1-roman.gushchin@linux.dev/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;该方案的核心思路是在内核触发 OOM killer 之前，先调用 BPF 程序。运维人员或云平台可以借此决定是终止某个特定进程、清理某个内存 cgroup，甚至通过删除 tmpfs 文件来释放内存，而不必一刀切地依赖内核默认策略。同时，新的补丁还引入基于 PSI（Pressure Stall Information） 的 OOM 触发机制，更好地判断何时真正进入「内存压力」状态，从而避免系统假死或误杀关键进程。&lt;/p&gt; 
&lt;p&gt;在实现上，这些补丁增加了新的 BPF 辅助函数，例如显式杀死指定进程的 &lt;code&gt;bpf_oom_kill_process()&lt;/code&gt;，以及获取内存 cgroup 根节点的 &lt;code&gt;bpf_get_root_mem_cgroup()&lt;/code&gt;，为内核空间提供了更强的可编程接口。&lt;/p&gt; 
&lt;p&gt;如果最终被合入主线，Linux 将首次赋予开发者和运维团队在内核层面 &lt;strong&gt;「编写自己的 OOM 策略」&lt;/strong&gt; 的能力，这对数据中心、云计算平台以及对内存敏感的服务部署而言，都可能带来深远影响。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367232</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367232</guid>
      <pubDate>Tue, 19 Aug 2025 09:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Gemini API 支持抓取 URL</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌宣布其 Gemini API 中的 URL Context 工具&lt;strong&gt;已正式支持直接抓取 URL 内容&lt;/strong&gt;，无需额外脚本或中间步骤。&lt;/p&gt; 
&lt;p&gt;&lt;img height="765" src="https://static.oschina.net/uploads/space/2025/0819/172728_9w7A_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini API 提供了 &lt;strong&gt;URL Context 功能&lt;/strong&gt;，允许你在请求中直接嵌入网页链接，模型会自动访问并解析网页内容。支持的内容类型包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文本网页（HTML、JSON、TXT 等）&lt;/li&gt; 
 &lt;li&gt;PDF 文件&lt;/li&gt; 
 &lt;li&gt;图片（PNG、JPEG、WebP 等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不支持的内容：YouTube 视频、Google Docs、付费墙内容等。&lt;/p&gt; 
&lt;p&gt;✅ 使用示例（Python SDK）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
  model="gemini-2.5-flash",
  contents=[
      "总结这篇文章的内容：",
      types.Part.from_uri(
        uri="https://example.com/article",
        mime_type='text/html'
      )
  ]
)
print(response.text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;使用限制&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;每次最多支持 &lt;strong&gt;20 个 URL&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;单个 URL 内容大小上限为 &lt;strong&gt;34MB&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;抓取内容会计入 &lt;strong&gt;输入 Tokens 费用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用 &lt;strong&gt;Gemini CLI&lt;/strong&gt;，也可以通过 &lt;code&gt;web_fetch&lt;/code&gt; 工具快速抓取网页，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gemini-cli web-fetch --prompt "总结 https://example.com/article 的主要内容"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该工具会自动识别提示中的 URL 并调用 Gemini API 抓取内容。&lt;/p&gt; 
&lt;p&gt;如你正在开发基于 Gemini 的应用，&lt;strong&gt;URL Context 功能&lt;/strong&gt;已足够替代传统的爬虫或 HTML 解析器，大幅提升开发效率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关链接&lt;/p&gt; 
&lt;p&gt;https://ai.google.dev/gemini-api/docs/url-context&lt;br&gt; https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#url-context&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367231/gemini-api-url-context</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367231/gemini-api-url-context</guid>
      <pubDate>Tue, 19 Aug 2025 09:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>淘宝「AI 万能搜」功能灰度测试</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;淘宝正在灰度测试一项名为「AI 万能搜」的新功能，旨在通过大模型技术重构电商搜索体验。该功能位于淘宝搜索页的「AI 万能搜」标签页，标志着 AI 技术在电商领域的应用正从企业端（B 端）营销，加速渗透至消费者端 (C 端) 的实用阶段。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「AI 万能搜」是一款基于大模型的 AI 问答产品，能够理解用户的自然语言提问并进行深度思考。用户提问后，AI 会生成一份融合文字、商品、视频和图片的「答案报告」，以解决用户在购物过程中遇到的各种消费难题，例如购物攻略、口碑评测和优惠咨询等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;据了解，目前「AI 万能搜」主要聚焦于四大核心场景:穿搭指南、送礼清单、选购攻略和问口碑。该功能的一大亮点在于，用户可以清晰地看到 AI 的思考过程，其思考逻辑主要分为三个步骤:获取信息、查询需求和分析总结。尽管目前尚不清楚其底层大模型是否只使用了「千问」，但这一功能已经展现出 AI 在提升消费者购物决策效率上的巨大潜力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="649" src="https://oscimg.oschina.net/oscnet/up-ea057aa8125432f67b68af7319fc597d9e8.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367229</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367229</guid>
      <pubDate>Tue, 19 Aug 2025 09:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Abogen - 文本转语音工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Abogen 是一款功能强大的文本转语音工具，可轻松将 ePub、PDF 或文本文件在几秒钟内转换为带有匹配字幕的高质量音频。可以使用&lt;a href="https://huggingface.co/hexgrad/Kokoro-82M"&gt;Kokoro-82M&lt;/a&gt;将其用于有声读物、Instagram、YouTube、TikTok 的配音，或任何需要自然语音的文本转语音项目。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151846_7vpx_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151903_hNpV_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/abogen</link>
      <guid isPermaLink="false">https://www.oschina.net/p/abogen</guid>
      <pubDate>Tue, 19 Aug 2025 09:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Vercel 旗下 AI 前端开发工具 v0 推出 iOS 应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vercel 旗下 AI 前端开发工具 v0&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fv0%2Fstatus%2F1957487790205325760"&gt;宣布&lt;/a&gt;即将推出其 iOS 应用程序，目前已开放候补名单注册。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0819/164508_7TkM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;http://v0.app/ios&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;根据官方发布的信息，其宣传语为 「Anything. Anyone. Anywhere.」。用户现在可以通过官方链接加入等待列表。&lt;/p&gt; 
&lt;p&gt;Vercel v0 是一个利用自然语言提示生成全栈 web 应用的 AI 工具，其核心优势在于通过简单的文本描述即可快速生成高质量的用户界面和代码。自 2023 年首次推出以来，v0 凭借其在前端 UI 生成上的卓越表现，特别是在 React 和 Next.js 框架中的应用，赢得了开发者和企业的广泛认可。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367213</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367213</guid>
      <pubDate>Tue, 19 Aug 2025 08:51:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中山大学联合美团打造 X-SAM 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中山大学、鹏城实验室与美团三方联合研发的 X-SAM 图像分割模型近期正式发布，这款多模态大模型在图像分割领域实现了重要突破，将传统的"分割万物"能力升级为"任意分割"，显著提升了模型的适应性和应用范围。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;传统的 Segment Anything Model（SAM）虽然在生成密集分割掩码方面表现出色，但其只能接受单一视觉提示输入的设计局限性明显。针对这一技术瓶颈，研究团队创新性地提出了视觉定位分割 (Visual Grounded Segmentation， VGS) 任务框架，通过交互式视觉提示实现对所有实例对象的精确分割，为多模态大语言模型提供了像素级的理解能力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的技术架构采用了多项创新设计。模型支持统一的输入格式和输出表示，能够处理多种类型的视觉和文本查询输入。其核心的双编码器架构确保了对图像内容和分割特征的深度理解，而分割连接器则提供多尺度信息融合，大幅提升分割精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="432" src="https://oscimg.oschina.net/oscnet/up-17e3fd0c4916165c034f2f1fecd344dd8e9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最值得关注的是，X-SAM 集成了&lt;span&gt;最新&lt;/span&gt;的 Mask2Former 架构作为分割解码器，这使得模型能够在单次操作中同时分割多个目标对象，彻底突破了传统 SAM 只能处理单一对象的技术限制。这一改进不仅提高了处理效率，也为复杂场景下的批量分割任务提供了可能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在模型训练方面，研究团队采用了三阶段渐进式训练策略，通过逐步增强的学习过程确保模型性能的稳定提升。经过在 20 多个主流分割数据集上的全面测试，X-SAM 在对话生成分割任务和图文理解任务中均取得了领先的性能表现，验证了其技术方案的有效性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的发布为图像分割技术发展指明了新方向，也为构建更加智能的通用视觉理解系统提供了重要的技术基础。研究团队表示，下一步将重点探索该技术在视频领域的应用拓展，推动图像与视频分割技术的统一化发展，进一步提升机器视觉理解能力的边界。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这项研究成果不仅在学术层面具有重要意义，其在自动驾驶、医疗影像、工业检测等实际应用场景中的潜力也值得期待。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367209</guid>
      <pubDate>Tue, 19 Aug 2025 08:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ElevenLabs 上线 Eleven Music API，首款商用 AI 音乐生成接口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ElevenLabs&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Felevenlabs.io%2Fblog%2Feleven-music-now-available-in-the-api" target="_blank"&gt;宣布推出 Eleven Music API&lt;/a&gt;，这是首款基于全授权数据训练、专为开发者打造的商用 AI 音乐生成接口。自 2024 年推出以来，创作者已通过该工具生成超 75 万首歌曲，印证市场强劲需求。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;使用文档：https://elevenlabs.io/docs/cookbooks/music/quickstart&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77a672de334942fafedf640d6297bfa4453.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，该 API 突破性解决了 AI 音乐领域的版权痛点，其模型基于百万小时授权音频数据训练，采用类 GPT 的 Transformer 架构，可通过文本提示实时生成多风格、多情绪的原创音乐，彻底规避未授权数据引发的法律风险，为游戏、广告、内容创作等行业提供合规解决方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367208/eleven-music-now-available-in-the-api</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367208/eleven-music-now-available-in-the-api</guid>
      <pubDate>Tue, 19 Aug 2025 08:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达最新研究：SLM（小型语言模型）才是 Agentic AI 的未来</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;英伟达与佐治亚理工学院研究人员联合发布《Small Language Models are the Future of Agentic AI》论文，提出了一个极具颠覆性的观点：SLM（小型语言模型）才是智能代理（Agentic AI）的未来。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1054" src="https://static.oschina.net/uploads/space/2025/0819/161145_Gy8G_2720166.png" width="1760" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/pdf/2506.02153&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;论文核心观点总结：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;能力与需求匹配：&lt;/strong&gt;当前主流的 AI 代理系统（如 AutoGPT、Open Interpreter 等）普遍采用 &lt;strong&gt;大型语言模型（LLM）&lt;/strong&gt; 作为「大脑」，但这些代理的任务场景往往高度结构化、重复性强。&lt;br&gt; 英伟达指出，&lt;strong&gt;7B 级别的 SLM 在代理任务上的表现已接近 70B+ 的 LLM&lt;/strong&gt;，而资源消耗却低得多。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;经济性与可持续性：&lt;/strong&gt;使用 LLM 构建代理系统的&lt;strong&gt;成本是 SLM 的 10-30 倍&lt;/strong&gt;，且能耗巨大。SLM 的轻量级特性使其更适合边缘设备、本地部署，推动 AI 从「展示品」走向「生产力工具」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;系统架构优化：&lt;/strong&gt;论文提出一种 &lt;strong&gt;「混合型代理架构」&lt;/strong&gt;，即由多个小型专用模型（SLM）分工协作，必要时再调用 LLM 处理复杂任务，避免「杀鸡用牛刀」的资源浪费。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;研究人员在文中表示，与业界普遍追捧的大型语言模型（LLMs）相比，SLMs 不仅在特定任务上已具备足够的处理能力，其固有的经济性和适用性也更为出色，为构建高效、可持续的 AI Agent 奠定了基础。&lt;/p&gt; 
&lt;p&gt;而据研究团队透露，尽管 LLMs 在处理通用和复杂任务上取得了突破，但此类模型在许多 Agent 的专用场景中存在明显的资源冗余问题，未能达到理想的成本效益标准。&lt;/p&gt; 
&lt;p&gt;而通过将重心转向 SLMs，研究者发现模型在执行重复性、专业化的任务时表现却更加高效，并极大地降低了运算和部署成本。&lt;/p&gt; 
&lt;p&gt;论文作者强调，经济性是推动 AI 从展示品迈向生产力工具必不可少的因素，而 AI Agent 的规模化应用依赖于更精细的成本与效能的平衡。&lt;/p&gt; 
&lt;p&gt;此外，该论文还提到，从 LLM 到 SLM 的转变背后，是整个行业对 AI 资源有效利用的战略性思考。提出这一观点不仅是为了推动技术路线的演进，更旨在确保整个行业对 AI 发展的经济现实有更清醒的认识，帮助我们在性能和成本之间找到最佳平衡点。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367198</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367198</guid>
      <pubDate>Tue, 19 Aug 2025 08:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中国 GPU 厂商天数智芯拟赴港 IPO，募资或达 3-4 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据报道，上海天数智芯半导体股份有限公司正考虑在香港进行首次公开募股 (IPO)，计划募资 3 亿至 4 亿美元。知情人士透露，目前相关讨论仍处于初步阶段，IPO 规模及其他细节尚未敲定。天数智芯未回应置评请求。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1840422874854322002%26wfr%3Dspider%26for%3Dpc" target="_blank"&gt;《科创板日报》报道称&lt;/a&gt;，有接近天数智芯的人士表示，IPO 相关消息应该为真，但具体细节仍未确定。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;天数智芯成立于 2015 年，专注于开发用于运行人工智能服务的 GPU 产品，是力图与英伟达展开竞争并提升中国芯片能力的数家初创企业之一。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;天数智芯是国内第一家通用 GPU 公司，2020 年率先实现了国产通用 GPU 从「0」到「1」的重大突破，2021 年发布国内首款通用 GPU 产品天垓 100，实现 GPU 产品量产及商用；2022 年发布面向 AI 推理的智铠 100 芯片。2022 年，天数智芯曾披露天垓 100 累计销售订单已突破 5 亿元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367191</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367191</guid>
      <pubDate>Tue, 19 Aug 2025 08:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>苹果 Xcode 即将原生集成 Claude</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;继 WWDC2025 上宣布 ChatGPT 集成后，苹果正准备为 Xcode 开发环境引入 Anthropic 的 Claude AI 助手，为开发者提供更多 AI 编程选择。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据 9to5Mac 深入分析 Xcode26beta7 代码后发现，苹果已在新"智能"功能中多次提及对 Anthropic 账户的内置支持，特别是 Claude Sonnet4.0 和 5 月 14 日发布的 Claude Opus4 版本。这表明虽然 ChatGPT 目前是&lt;span&gt;唯一&lt;/span&gt;具有&lt;span&gt;第一&lt;/span&gt;方 Xcode 集成的模型，但 Claude 的原生支持基础设施已经就位。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-fe0e99cfde75612e2271f514a637c4039a8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;苹果在 WWDC24 上&lt;span&gt;首次&lt;/span&gt;推出 Swift Assist 概念，旨在打造类似 GitHub Copilot 的 AI 编程助手，但一直未正式发布。如今这一功能终于在 Xcode26 中亮相，功能范围大幅扩展：支持苹果自有 AI 模型，原生 ChatGPT 集成（含每日使用限制），支持第三方 AI 提供商 API 接入，兼容本地运行的 AI 模型。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据彭博社今年 5 月报道，苹果内部已在测试基于 Claude 的 Xcode 版本，并持续评估公开发布的可能性。当时外界仅知苹果计划扩展 Swift Assist 功能，而 ChatGPT 是&lt;span&gt;唯一&lt;/span&gt;确定的合作伙伴。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据 9to5Mac 发现的服务器端配置文件显示，Claude 不仅可能集成到 Xcode 中，还有望作为 Siri 和系统写作工具的替代选项，为用户提供更丰富的 AI 服务体验。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;对于偏好 Claude 编程能力的开发者而言，这一集成将提供更流畅的内置体验，无需繁琐的 API 配置即可享受被誉为"目前&lt;span&gt;最佳&lt;/span&gt;编码助手"的服务。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367187</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367187</guid>
      <pubDate>Tue, 19 Aug 2025 07:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软 Edge 143 将移除网络控制枱工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软 Edge 浏览器提供了名为「Network Console Tool」的开发者工具，该工具主要用于网络请求的捕获和分析，帮助开发者深入查看浏览器与服务器之间的通信，让开发者可以调试和优化网络请求。&lt;/p&gt; 
&lt;p&gt;根据微软工程师发布的 issue，他们计划从 Edge 143 版开始删除这个功能，原因是微软没有能力继续维护这个工具，接下来的主要任务是提供稳定功能并改进与 Chrome 的兼容性。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1066" src="https://static.oschina.net/uploads/space/2025/0819/155038_jRTN_2720166.png" width="1850" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/MicrosoftEdge/DevTools/issues/348&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;作为替代方案，微软建议开发者使用 Microsoft Visual Studio Code 的 REST 客户端扩展进行 API 开发和测试，微软 Edge 浏览器本身不再提供直接的替代方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367185</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367185</guid>
      <pubDate>Tue, 19 Aug 2025 07:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>基于 TinyMce 富文本编辑器的客服自研知识库的技术探索和实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、 背景&lt;/h1&gt; 
&lt;p&gt;客服知识库是一个集中管理和存储与客服相关的信息和资源的系统，在自研知识库上线之前，得物采用的承接工具为第三方知识库系统。伴随着业务的发展，知识的维护体量、下游系统的使用面临的问题愈发明显，而当前的第三方采购系统，已经较难满足内部系统间高效协作的诉求，基于以上业务诉求，我们自研了一套客服知识库。&lt;/p&gt; 
&lt;h1&gt;二、富文本编辑器的选型&lt;/h1&gt; 
&lt;p&gt;以下是经过调研后列出的多款富文本编辑器综合对比情况：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-95da411b390a1e79e0ee649585a37084e43.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;2.1 编辑器的选择&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;自研知识库要求富文本编辑器具备表格的编辑能力，由于&lt;strong&gt;Quill&lt;/strong&gt;不支持表格编辑能力（借助表格插件可以实现该能力，但经过实际验证，插件提供的表格编辑能力不够丰富，使用体验也较差），被首先被排除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;lt;!-- --&amp;gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;wangEditor&lt;/strong&gt;体验过程中发现标题和列表（有序、无序）列表两个功能互斥，体验不太好，而这两个功能都是自研知识库刚需功能，也被排除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;lt;!-- --&amp;gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lexical&lt;/strong&gt; 是 facebook 推出的一款编辑器，虽功能很丰富，但相较于&lt;strong&gt;CKEditor&lt;/strong&gt; 和&lt;strong&gt;TinyMCE&lt;/strong&gt; ，文档不够完善，社区活跃性较低，插件不成熟，故优先选择&lt;strong&gt;CKEditor&lt;/strong&gt; 和&lt;strong&gt;TinyMCE&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;CKEditor&lt;/strong&gt; 和&lt;strong&gt;TinyMCE&lt;/strong&gt; 经过对比，由于当前正在使用的第三方知识库采用的是&lt;strong&gt;TinyMCE&lt;/strong&gt; 编辑器，选择 TinyMC 在格式兼容上会更友好，对新老知识库的迁移上更有利。且 TinyMCE 在&lt;strong&gt;功能丰富度上略占优势&lt;/strong&gt; ，故最终选择&lt;strong&gt;TinyMCE 作为本系统文档知识库的编辑器&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;2.2 TinyMce 编辑器模式的选择&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;经典模式（默认模式）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于表单，使用表单某字段填充内容，编辑器始终作为表单的一部分。内部&lt;strong&gt;采用了 iframe 沙箱隔离&lt;/strong&gt;，将编辑内容与页面进行隔离。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 优势&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;样式隔离好。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 劣势&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由于使用 iframe，性能会差点，尤其对于多实例编辑器。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;内联模式（沉浸模式）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将编辑视图与阅读视图合二为一，当其被点击后，元素才会被编辑器替换。而不是编辑器始终可见，不能作为表单项使用。内容会从它嵌入的页面继承 CSS 样式表。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 优势&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;性能相对较好，页面的编辑视图与阅读视图合二为一，提供了无缝的体验，实现了真正的所见即所得。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 劣势&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;样式容易受到页面样式的影响。&lt;/p&gt; 
&lt;h1&gt;三、系统总览&lt;/h1&gt; 
&lt;h2&gt;3.1 知识创建链路&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5898f1dcecea69cb87783dd57f7f99e30a1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.2 知识采编&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;结构化段落&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了对知识文档做更细颗粒度的解析，客服知识库采用了&lt;strong&gt;结构化段落的设计思想&lt;/strong&gt; ，每个段落都会有一个唯一标志 &lt;strong&gt;，且支持对文档的每个段落单独设置标签&lt;/strong&gt;，这样在后期的知识检索、分类时，便可以精确定位到知识文档的具体段落，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b6e4ad183b36ec82c8fd1558b2e9e9fe28c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.3 应用场景&lt;/h2&gt; 
&lt;p&gt;客服知识库的主要应用场景如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知识检索&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于传统的 ES 检索能力，用于知识库的检索，检索要使用的知识，且可以直接在工作台打开对应的知识并浏览，并可以定位、滚动到具体的知识段落。同时还会&lt;strong&gt;高亮显示&lt;/strong&gt; 知识文档中匹配到的&lt;strong&gt;搜索关键字&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智能问答&lt;/strong&gt;（基于大模型能力和知识库底层数据的训练）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ RAG 出话&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;辅助客服了解用户的真实意图，可用于客服作业时的参考。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原理阐述：&lt;/strong&gt; RAG 是一种结合了检索和生成技术的人工智能系统。它是大型语言模型的一种，但特别强调检索和生成的结合。RAG 的最主要的工作流程包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;检索阶段：系统会根据用户的查询，从&lt;strong&gt;客服知识库中检索出相关信息。这些信息可能包括知识库内容、订单信息和商品信息等&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;生成阶段：RAG 使用检索到的信息来增强其生成过程。这意味着，生成模型在生成文本时，会考虑到检索到的相关信息，以生成更准确、更相关的回答。你可以直接将搜索到的内容返回给用户也可以通过 LLM 模型结合后生成给用户。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;※ 答案推荐&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以根据用户搜索内容、上下文场景（如订单信息、商品信息）辅助客服更高效的获取答案。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;流程示意：&lt;/strong&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-fcb0d05ee25406dcdf617c673affa27ab55.png" alt="" referrerpolicy="no-referrer"&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-289d81aee36a4f8ae37f0362bdc5958f98e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 联网搜索&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当 RAG 出话由于拒识没有结果时，便尝试进行联网搜索给出结果，可作为 RAG 能力失效后的补充能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原理阐述：&lt;/strong&gt; 底层使用了第三方提供的&lt;strong&gt;联网问答 Agent 服务&lt;/strong&gt; 。在进行联网搜索之前，会对用户的查询信息进行&lt;strong&gt;风控校验&lt;/strong&gt; ，风控校验通过后，再进行 &lt;strong&gt;【指定意图清单】过滤&lt;/strong&gt;，仅对符合意图的查询才可以进行联网搜索。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-74a22f9ec745dc39961d0ca9ecec27e0e37.png" alt="" referrerpolicy="no-referrer"&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-f13e784faad46f5e855ec8518dcc35be047.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;四、问题和解决方案&lt;/h1&gt; 
&lt;h2&gt;4.1 解决图片迁移问题&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在新老知识迁移的过程中，由于老知识库中的图片链接的域名是老知识库的域名，必须要有老知识库的登录台信息，才能在新知识库中访问并渲染。为了解决这个问题，我们对用户粘贴的动作进行了监听，并对复制内容的图片链接进行了替换。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;时序图&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2d03bfb759a3da15c3f8bdd111ad97c8529.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心逻辑&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/**
 * 替换编辑器中的图片 URL
 * @param content
 * @param editor 编辑器实例
 * @returns 替换后的内容
 */
export const replaceImgUrlOfEditor = (content, editor) =&amp;gt; {
  // 提取出老知识中的图片访问链接
  const oldImgUrls = extractImgSrc(content);
  // 调用接口获取替换后的图片访问链接
  const newImageUrls = await service.getNewImageUrl(oldImgUrls);
  // 将老知识库的图片链接替换成新的可访问的链接
  newContent = replaceImgSrc(newContent, replacedUrls.imgUrls);
  // 使用新的数据更新编辑器视图
  editor.updateView(newContent);
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4.2 解决加载大量图片带来的页面卡顿问题&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;知识库内含有大量的图片，当我们打开一篇知识时，系统往往因为在短时间内加载、渲染大量的图片而陷入卡顿当中，无法对页面进行其他操作。这个问题在老知识库中尤为严重，也是研发新知识库过程中我们需要重点解决的问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们对图片进行了懒加载处理：当打开一篇知识时，只加载和渲染可见视图以内的图片，剩余的图片只有滚动到可见视图内才开始加载、渲染。&lt;/p&gt; 
&lt;p&gt;由于我们要渲染的内容的原始数据是一段 html 字符串，一篇知识文档的&lt;strong&gt;最小可渲染单元是段落&lt;/strong&gt;（结构化段落），而一个段落的内容大小事先是不知道的，因此传统的滚动加载方式在这里并不适用：比如当滚动到需要加载下一段落的位置时，如果该段落的内容特别大且包含较多图片时，依然会存在卡顿的现象。&lt;/p&gt; 
&lt;p&gt;我们采用正则匹配的方式，识别出知识文档的 html 中所有的 &lt;img src="" alt="" referrerpolicy="no-referrer"&gt; 标签（将文档的 html 视作一段字符串），并给 &lt;img src="" alt="" referrerpolicy="no-referrer"&gt; 标签插入 loading="lazy" 的属性，具备该属性的图片在到达可视视图内的时候才会加载图片资源并渲染，从而实现懒加载的效果，大大节省了知识文档初次渲染的性能开销。并且该过程处理的是渲染知识文档前的 html 字符串，而非真实的 dom 操作，所以不会带来重绘、重排等性能问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知识文档渲染的完整链路&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b5d408d9e6ef53c6f040cdbce9975f13dae.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;4.3 模板缩略图&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在知识模板列表页或者在创建新知识选择模板时，需要展示模板内容的缩略图，由于每个模板内容都不一样，同时缩略图中需要可以看到该模板靠前的内容，以便用户除了依靠模板标题之外还可以依靠一部分的模板内容选择合适的模板。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在保存知识模板前，通过截屏的方式保存一个模板的截图，上传截图到 cdn 并保存 cdn 链接，再对截图进行一定的缩放调整，即可作为模板的缩略图。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;时序图&lt;/strong&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-7fbdb47a4677be9b3fc62ea8bc99c9e47c2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;实际效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;模板列表中缩略图展示效果：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-62f564d295f0d583928a08266f7ae3a890a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新建知识时缩略图展示效果：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-60dee5e8fffbeaa691d47880a0e6d636355.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;4.4 全局查找/替换&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;知识库采用了结构化段落的设计思想，技术实现上，每个段落都是一个独立的编辑器实例。这样实现带来一个弊端：使用编辑器的搜索和替换功能时，查找范围仅限于当前聚焦的编辑器，无法同时对所有编辑器进行查找和替换，增加了业务方的编辑费力度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;调研、扩展编辑器的&lt;strong&gt;查找/替换插件的源码，调度和联动多编辑器的查找/替换 API&lt;/strong&gt;从而实现全局范围内的查找/替换。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 插件源码剖析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过对插件源码的分析，我们发现插件的查找/替换功能是基于 4 个基本的 API 实现的： find 、 replace 、 next 、 prev 、 done 。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 设计思路&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过在多个编辑器中加入一个调度器来控制编辑器之间的&lt;strong&gt;接力&lt;/strong&gt; 从而实现&lt;strong&gt;全局的查找/替换&lt;/strong&gt; 。同时&lt;strong&gt;扩展插件的 API&lt;/strong&gt; ，&lt;strong&gt;辅助调度器在多编辑器之间进行调度&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 插件源码 API 扩展&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;hasMatched：&lt;/strong&gt; 判断当前编辑器是否匹配到关键字。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;hasReachTop&lt;/strong&gt;：判断当前编辑器是否已到达所查找关键字的最前一个。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;hasReachBottom&lt;/strong&gt;：判断当前编辑器是否已到达所查找关键字的最后一个。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;current：&lt;/strong&gt; 滚动到编辑器当前匹配到的关键字的位置。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;clearCurrentSelection：&lt;/strong&gt; 对编辑器当前匹配到的关键字取消高亮效果。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4aba22b768accecbba6b30d1f9d21a8a4fb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;UI 替换&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;屏蔽插件自带的查找/替换的弹窗，实现一个支持全局操作的查找/替换的弹窗：使用了 react-rnd 组件库实现可拖拽弹窗，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2a1afa88b3bf2be0bf7400d1a95490ba73d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「查找」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 期望效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当用户输入关键字并点击查找时，需要在文档中（所有编辑器中）标记出（加上特定的背景色）所有匹配到该关键字的文本，并高亮显示出第一个匹配文本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 流程图&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-64776a2ea093b841c58591a39ed8b1aed24.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;「下一个」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 期望效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当用户点击「下一个」时，需要高亮显示下一个匹配结果并滚动到该匹配结果的位置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 流程图&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-de6d015d117227125d947877b18856d5b6a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;五、总结&lt;/h1&gt; 
&lt;p&gt;在新版客服知识库的研发和落地过程中，我们基于&lt;strong&gt;TinyMce 富文本编辑器&lt;/strong&gt; 的基础上，进行了功能扩展和定制。这期间既有参考过同类产品（飞书文档、语雀）的方案，也有根据实际应用场景进行了创新。截止目前已完成&lt;strong&gt;1000+老知识库的顺利迁移&lt;/strong&gt;，系统稳定运行。&lt;/p&gt; 
&lt;p&gt;自研过程中我们解决了老版知识库系统的卡顿和&lt;strong&gt;无法满足定制化需求的问题&lt;/strong&gt; 。并在这些基本需求得到满足的情况下，通过优化交互方式和知识文档的加载、渲染性能等方式&lt;strong&gt;进一步提升了使用体验&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;后续我们会结合用户的反馈和实际使用需求进一步优化和扩展客服知识库的功能，也欢迎有同样应用场景的同学一起交流想法和意见。&lt;/p&gt; 
&lt;p&gt;&amp;lt;br /&amp;gt;&lt;/p&gt; 
&lt;h2&gt;往期回顾&lt;/h2&gt; 
&lt;p&gt;&lt;a href=""&gt;1.AI 质量专项报告自动分析生成｜得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;2.Rust 性能提升"最后一公里"：详解 Profiling 瓶颈定位与优化｜得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;3.Valkey 单点性能比肩 Redis 集群了？Valkey8.0 新特性分析｜得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;4.Java SPI 机制初探｜得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;5.得物向量数据库落地实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;lt;br /&amp;gt;&lt;/p&gt; 
&lt;p&gt;&amp;lt;br /&amp;gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文 / 煜宸&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18688668</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18688668</guid>
      <pubDate>Tue, 19 Aug 2025 07:49:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
