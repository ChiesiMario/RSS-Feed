<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 27 Mar 2025 02:42:28 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>OpenAI 预估 2025 年营收将达到 127 亿美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-26%2Fopenai-expects-revenue-will-triple-to-12-7-billion-this-year&quot; target=&quot;_blank&quot;&gt;据彭博社今日报道&lt;/a&gt;&lt;/u&gt;，OpenAI 预估其 2025 年营收将达到 127 亿美元（约合 923 亿元人民币），相比 2024 年 37 亿美元（约合 269 亿元人民币）的营收翻了超三倍。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/103323_ghkE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在该预估基础上，OpenAI 预计其 2026 年营收将达到 294 亿美元（约合 2,136.8 亿元人民币），2029 年更将超过 1,250 亿美元（约合 9085.2 亿元人民币）。&lt;/p&gt; 
&lt;p&gt;报道指出，OpenAI 此前正与软银集团进行谈判，软银计划以 2600 亿美元估值向 OpenAI 注资 400 亿美元，部分资金将用于 OpenAI 与软银、甲骨文联合成立的 Stargate 项目；此外，OpenAI 还一直在与监管机构谈判，计划从非营利组织转变为更传统的营利性公益公司。&lt;/p&gt; 
&lt;p&gt;产品迭代方面，&lt;a href=&quot;https://www.oschina.net/news/341240/openai-agents-sdk-mcp&quot;&gt;OpenAI 在今日凌晨对 Agent SDK 进行了重大更新&lt;/a&gt;：支持大模型上下文协议 MCP。&lt;/p&gt; 
&lt;p&gt;目前，OpenAI 已经在开源的 Agent SDK 中支持 MCP，API 和桌面版 ChatGPT 也将很快提供。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341252</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341252</guid>
            <pubDate>Thu, 27 Mar 2025 02:34:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>算力，并不是大模型厂商发展的护城河</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;上个月，OpenAI CEO 山姆·奥尔特曼在社交媒体上表示，号称 52 万亿参数量的 GPT-5 将在数月内发布。相较于上一代 GPT-4 的 2 万亿参数，体量上足足增长了 26 倍，虽无公布具体的训练成本，但想必也一定是个天文数字，堪称大模型领域的「力大砖飞」。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b5d3d49a58e00ea764875a0cd773ce57.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;反观 LLM 界的「黑天鹅」，DeepSeek-V3 却仅用了 2048 块英伟达 H800 ，耗费了 557.6 万美金就完成了训练，一度引起硅谷恐慌，力证了：&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;并非不可逾越的堡垒。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;一边是暴力填鸭，一边是技术深化，2025 年的大模型似乎走出了两条截然不同的道路，也逐渐撕开了 AI 行业最残酷的真相：&lt;strong&gt;早期以「&lt;/strong&gt;&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;」建立护城河的大模型厂商们，在面对新一轮技术冲击时，高成本的算力反而成为了其灵活发展的累赘。&lt;/strong&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_1&quot;&gt;&lt;/span&gt; 
 &lt;h3&gt;算力的必要性和局限性&lt;/h3&gt; 
 &lt;p&gt;作为数字经济的「新电力」，算力在大模型的训练和推理过程中确实起到了不可或缺的作用。&lt;/p&gt; 
 &lt;p&gt;以 OpenAI 为例，早期在 GPT-4 的训练中，大概就使用了 25000 个 A100 芯片。如果 OpenAI 云计算的成本是差不多 1 美元/每 A100 小时的话，那么在这样的条件下，&lt;strong&gt;仅一次训练的成本大约是 6300 万美元&lt;/strong&gt;，同期还不乏实验、试错以及其他成本。OpenAI 的技术负责人直言：「每一次模型迭代都需要近乎天文数字的算力支撑。」&lt;/p&gt; 
 &lt;p&gt;而在推理成本方面，截至 2024 年 3 月，OpenAI 就已花费 40 亿美元租用微软的服务器集群，该集群相当于 35 万个英伟达 A100 芯片，算力消耗不可谓不大。&lt;/p&gt; 
 &lt;p&gt;反观国内，同样印证了这一规律。2025 年初，南京智算中心联合寒武纪，基于 7280 块国产 AI 加速卡构建全国产化算力平台，以运行 DeepSeek 671B 大模型，在供应链优化、智能客服等零售场景实现毫秒级响应。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2f8b6f62899001ee832509d86ebb956b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;南京智算中心机房，来源：南京智算中心&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;这二者的共性在于：&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;始终是&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;研发的「基础设施入场券」&lt;/strong&gt;，正如 DeepSeek 技术白皮书所言：大模型的竞争，首先是算力基础设施的竞争。&lt;/p&gt; 
 &lt;p&gt;但其实，「算力」本质上是一种「商品化」资源，自带经济周期属性，随着硬件成本的下降和云服务的普及，算力也逐渐脱离卖方市场，一些囤货居奇的算力厂商更是很难转型。&lt;/p&gt; 
 &lt;p&gt;比如，2023 年 AI 大模型热潮期间，算力需求呈爆发式增长，英伟达 H100 8 卡节点年租金峰值达到 20 万元，而随着大模型从训练阶段转向推理阶段，算力需求骤减（训练需千卡级，推理仅需单卡级），2024 年 H100 8 卡节点年租金跌至 6 万，很多中小型企业也能依靠算力租用跑步入场。&lt;/p&gt; 
 &lt;p&gt;而在算力租赁市场，截至去年，很多算力中心都出现了出租率不高、回款周期长，甚至一些底子不深的厂商直接关停一半机房，以降低日常运营成本。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5fb3eacaa5d6decdecd8eaf02618394d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;来源：《&lt;/span&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;算力&lt;/span&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;荒，自主化智算还有必要吗？》-脑极体&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;可见，大模型厂商早期在硬件性能和算力中心上的建设，虽然能够在短期内加速模型的训练和推理，但并不意味着竞争对手无法通过硬件设施的「经济逆周期」，以及技术优化实现弯道超车，这就是「算力」这一大模型发展的必要资源所刻在骨子里的局限性。&lt;/p&gt; 
 &lt;p&gt;直至 DeepSeek 的出现，「卡多模优」的大模型发展格局，彻底失去优势。&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
 &lt;h3&gt;护城河的重构：从「堆料」到「四维壁垒」&lt;/h3&gt; 
 &lt;p&gt;相较於单纯的硬件「堆料」，模型创新、数据规模、算法工程及生态构建的四维能力矩阵，正成为越来越多大模型厂商穿越周期的关键壁垒。2025 年行业数据显示，头部厂商研发投入中，算法优化（ 38% ）与场景化工程（ 27% ）的占比已超过硬件采购（ 25% ），书写新竞争法则——&lt;strong&gt;效率优先于规模。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以 DeepSeek 为例，通过「三维创新体系」重构行业范式：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;模型层，首创「神经元动态剪枝+混合精度训练」架构，使 1.6 万亿参数模型体积压缩 80% ，推理速度提升 500%；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;数据层，构建金融/政务领域「知识-行为-反馈」三元数据闭环，标注成本降低 65%；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;而在跟算力相关的工程层，其分布式训练调度系统，将千卡集群利用率从 58% 提升至 92%。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//93414f30d7f61d6d5973d26012e11932.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;凭借这套组合拳下来，DeepSeek 训练成本降至同期竞品的 17% ，这种「技术驱动型」增长，不仅是对思维链突破、数据处理、系统优化等技术的最佳诠释，甚至使得 DeepSeek 利润猛增。&lt;/p&gt; 
 &lt;p&gt;以行业具体实施来看。在算力的制约下，长足以来，业内很多人都不太看好 MaaS 这样的商业模式，因为 MaaS 的核心成本是算力租赁，依赖 API 调用按 token 计费，本质上可以看作为「算力批发」——&lt;strong&gt;想要赚钱，你就得投入大量算力储备，保证高并发和弹性伸缩，碰上 API 价格内卷，很多厂商根本负担不起高额得硬件投入。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1ef35030fdc620a594a6096008472682.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;但随着 DeepSeek 出现，通过大规模的并行（包括数据并行和专家并行），尽可能为每个 GPU 分配均衡的计算负载、可通信负载，以技术升级，提升算力效率。根据&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27181462601&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;《DeepSeek-V3 / R1 推理系统概括》&lt;/a&gt;一文中阐述：以 24 小时计算，DeepSeek V3 和 R1 推理服务峰值占用总和 278 个节点，平均占用 226.75 个节点（每个节点为 8 个 H800 GPU ）。假定 GPU 租赁成本为 2 美金/小时，日成本为 87072 美元/天。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;而对比 24 小时所输出的 tokens 全部按照 DeepSeek R1 的定价计算，理论上一天的总收入为 562027 美元/天，成本利润率高达 545%&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//92f0b2c24548560677469843c4826cc8.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;除此之外，&lt;strong&gt;开源生态&lt;/strong&gt;正加速成为模型创新的催化剂。Meta Llama 3 通过开源策略（免费使用、多平台支持）及训练效率优化（预训练数据扩展、后训练技术），使中小企业模型部署成本显著降低；智谱 GLM-4 依托 10 万开发者社区的持续优化，在代码生成等任务上实现同参数模型的性能超越，体现了开源协作对模型迭代的推动作用。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;如此看来，这场产业革命的深层动因，不仅源于算力资源的成本周期，更源自于技术演进的内在规律：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#e74c3c&quot;&gt;&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;供给的周期调整&lt;/strong&gt;&lt;/span&gt;：2023-2025 年全球总算力复合增长率达 147%，但单位算力成本下降曲线（年降 68%）远超规模扩张速度，标志着算力正从「战略资源」向「基础建设」加速蜕变。简言之，算力主导的大模型经济，难以覆盖早期硬件设备上的成本投入；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#e74c3c&quot;&gt;&lt;strong&gt;价值创造的路径迁移&lt;/strong&gt;&lt;/span&gt;：算法创新对模型效能的贡献率从 2020 年的 38% 跃升至 2025 年的 67%。例如 DeepSeek 的算法优化、理论利润，间接证明了&lt;strong&gt;算法创新才能撬动&lt;/strong&gt;&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;效益，并也能实现很好的商业变现。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;站在 2025 年的时代座标回望，算力作为产业发展的「数字燃料」，已完成了它帮助早期模型厂商爬坡式发展的使命，随着越来越多大模型应用的加速投产，模型厂商们能依仗的绝不是训练、推理这些模型的算力规模，而是真正能让这些算力产生乘积效应的技术创新、能力整合，以及市场洞察。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;之争的终局，是通过技术让算力不再成为问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/7819858/blog/18015313</link>
            <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/18015313</guid>
            <pubDate>Thu, 27 Mar 2025 02:32:25 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>腾讯元宝支持实时预览 HTML 代码</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;3 月 26 日，首发接入 DeepSeek V3-0324 最新模型后，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FfYn2utj1aiJcuI58JuZ4zw&quot; target=&quot;_blank&quot;&gt;腾讯元宝再次发布更新&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;支持实时预览 HTML 代码&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/102015_iEXO_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，元宝的混元与 DeepSeek 两大模型均支持代码生成，覆盖前端、脚本、数据处理等多种主流语言，适配多类开发场景，适合开发者和各类用户快速上手。结合元宝双模型在代码方面的表现，也还够帮助用户代码审查相关工作。&lt;/p&gt; 
&lt;p&gt;此外，使用 DeepSeek V3-0324 模型，除了网页生成，还能完成更多类型的代码生成任务，如生成 UI 组件、构建网页、编写小游戏，甚至是生成 3D 动画等。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;810&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0327/102200_dqsd_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;现在，用户在元宝选择 DeepSeek，并关闭「深度思考」，便可使用最新的 V3-0324。该模型在代码生成稳定性、逻辑控制精准度和响应速度上均有明显提升，在数学、代码类相关评测集上取得了超过 GPT-4.5、Claude Sonnet 3.7 的得分成绩。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/341137/deepseek-v3-0324-detail&quot; target=&quot;news&quot;&gt;DeepSeek 官方详解 V3 模型「小版本」升级，各项能力全面进阶&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/340789/deepseek-v3-0324&quot; target=&quot;news&quot;&gt;DeepSeek V3 模型更新，大幅提升编程能力&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341248</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341248</guid>
            <pubDate>Thu, 27 Mar 2025 02:23:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>万字长文解读 MCP 框架，让你掌握 mark3labs/mcp-go</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、引言&lt;/h1&gt; 
&lt;div&gt;
  在 
 &lt;a href=&quot;https://my.oschina.net/qiangmzsx/blog/17987222&quot;&gt;《万字长文，带你读懂 Anthropic MCP》&lt;/a&gt;中我们介绍了 MCP 的基本框架和组件，并初步说了在 golang 中的框架 metoro-io/mcp-golang 和 mark3labs/mcp-go。本文将通过实践和源码的方式先解读 mark3labs/mcp-go。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height=&quot;298&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-803fb33e305fbbb839a0166e62ed0c18111.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、MCP-Server 的简述&lt;/h1&gt; 
&lt;div&gt;
  MCP Server 一般为轻量的服务端程序，通过一种标准的协议 (MCP) 暴露出特定资源的一些特定的能力。 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 连接生命周期&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 初始化连接&lt;/h3&gt; 
&lt;div&gt; 
 &lt;img height=&quot;1104&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-71f5896875ced4bfcd504e32c61489dd750.png&quot; width=&quot;1250&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    客户端发送带有协议版本和功能 initialize 请求。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    服务器以其协议版本和功能进行响应 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    客户端发送 initialized 通知作为确认 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    开始正常信息交换 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 信息交换&lt;/h3&gt; 
&lt;div&gt;
  初始化后，支持以下模式： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    请求-响应：客户端或服务器发送请求，对方响应 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    通知：任何一方发送单向消息 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.3 终止&lt;/h3&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;enum ErrorCode {
  // Standard JSON-RPC error codes
  ParseError = -32700,
  InvalidRequest = -32600,
  MethodNotFound = -32601,
  InvalidParams = -32602,
  InternalError = -32603
}&lt;/code&gt;&lt;/pre&gt; 任何一方都可以终止连接： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    通过 close() 干净关闭 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    传输断开 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    错误情况 
  &lt;/div&gt; 
  &lt;ol&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      请求的错误响应 
    &lt;/div&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      传输中的错误事件 
    &lt;/div&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      协议级错误处理程序 
    &lt;/div&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div&gt;
  常见错误码： 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 MCP Server 的业务能力&lt;/h2&gt; 
&lt;div&gt; 
 &lt;table cellspacing=&quot;0&quot; style=&quot;border-collapse:collapse&quot;&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Request Method&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;发起方&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;响应方&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;描述&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;initialized&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;初始化会话&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;tools-list&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;发现可用的工具&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;tools/call&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;调用工具&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;resources/list&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;发现可用的资源&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;resources/read&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;获取资源内容&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;resources/templates&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;发现可用的参数化资源&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;resources/subscribe&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;订阅特定资源，监听其变化事件&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;prompts/list&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;发现可用的提示词&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;prompts/get&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;获取特定提示词&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;roots/list&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:rgba(0, 0, 0, 0.03); text-align:center; white-space:pre-wrap&quot;&gt;列出服务器有权访问的客户端文件系统根节点（暴露目录和文件）&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;sampling/create&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Server&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;Client&lt;/td&gt; 
    &lt;td style=&quot;background-color:#ffffff; text-align:center; white-space:pre-wrap&quot;&gt;启用服务器的 AI 生成能力（ sampling creation ）&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h1_8&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、mark3labs/mcp-go 示例&lt;/h1&gt; 
&lt;div&gt;
  我们就以框架中的官方示例代码为引子一步步解读流程和框架代码。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // 创建 MCP 服务器
    s := server.NewMCPServer(
       &quot;Demo 🚀&quot;, // 服务器名称
       &quot;1.0.0&quot;,  // 服务器版本
    )

    // 添加工具
    tool := mcp.NewTool(&quot;hello_world&quot;, // 工具名称
       mcp.WithDescription(&quot;Say hello to someone&quot;), // 工具描述
       mcp.WithString(&quot;name&quot;, // 参数名称
          mcp.Required(), // 参数是必需的
          mcp.Description(&quot;Name of the person to greet&quot;), // 参数描述
       ),
    )

    // 为工具添加处理器
    s.AddTool(tool, helloHandler)

    // 启动标准输入输出服务器
    if err := server.ServeStdio(s); err != nil {
       fmt.Printf(&quot;Server error: %v\n&quot;, err) // 打印服务器错误
    }
}

func helloHandler(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    // 从请求参数中获取名字参数，并断言为字符串类型
    name, ok := request.Params.Arguments[&quot;name&quot;].(string)
    if !ok {
       // 如果断言失败，返回错误
       return nil, errors.New(&quot;name must be a string&quot;)
    }

    // 返回包含问候语的结果
    return mcp.NewToolResultText(fmt.Sprintf(&quot;Hello, %s!&quot;, name)), nil
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 搭建一个联调环境&lt;/h2&gt; 
&lt;div&gt;
  就以上面的代码为例，将上面的代码编译为二进制命令： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;$ go build -v -o server&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;再启动 mcp inspetor：&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;$ npx -y @modelcontextprotocol/inspector ./server&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img height=&quot;701&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7c0fba487d16433005ebd394b937e30063b.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt;
  这样一个简单的 MCP Client 和 MCP Server 就搭建好了，后续也为我们开发测试构建好了环境。 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、源码解读&lt;/h1&gt; 
&lt;div&gt;
  在上面的代码中 main 函数中的第一个代码就是 server.NewMCPServer，那我们就从 MCPServer 这个结构体入手。 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 MCPServer 结构体&lt;/h2&gt; 
&lt;div&gt;
  代码地址：https://github.com/mark3labs/mcp-go/blob/e183dd17cfec07072a188f6169033bf61f7bf37d/server/server.go#L135 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type MCPServer struct {
    mu                   sync.RWMutex                       // 用于保护共享资源，确保并发访问时的数据一致性
    name                 string                             // 服务器的名称，用于标识服务器
    version              string                             // 服务器的版本，用于跟踪和管理服务器的不同版本
    instructions         string                             // 服务器的指令，通常在初始化响应中返回给客户端，提供使用指南或帮助信息
    resources            map[string]resourceEntry           // 存储服务器支持的资源及其处理函数
    resourceTemplates    map[string]resourceTemplateEntry   // 存储资源模板及其处理函数，支持 URI 模板匹配多类似资源
    prompts              map[string]mcp.Prompt              // 存储服务器支持的提示，用于与用户交互
    promptHandlers       map[string]PromptHandlerFunc       // 存储处理提示请求的函数，每个提示对应一个处理函数
    tools                map[string]ServerTool              // 存储服务器支持的工具及其处理函数
    notificationHandlers map[string]NotificationHandlerFunc // 存储处理传入通知的函数，接收客户端通知并处理
    capabilities         serverCapabilities                 // 定义服务器支持的功能特性，包括资源、提示、工具和日志记录等
    sessions             sync.Map                           // 存储当前活跃的客户端会话，用于跟踪用户交互
    initialized          atomic.Bool                        // 使用原子操作标记服务器是否已初始化，确保线程安全
    hooks                *Hooks                             // 存储服务器钩子，允许在请求处理前后或返回错误前执行自定义逻辑
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;MCPServer 是 Model Control Protocol (MCP) 服务器的实现，用于处理包括资源、提示和工具在内的各种类型的请求。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;table cellspacing=&quot;0&quot; style=&quot;border-collapse:collapse; height:30px; width:1111px&quot;&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;text-align:left; white-space:pre-wrap&quot;&gt;&amp;nbsp;&lt;/td&gt; 
    &lt;td style=&quot;text-align:left; white-space:pre-wrap&quot;&gt;&amp;nbsp;&lt;/td&gt; 
    &lt;td style=&quot;text-align:left; white-space:pre-wrap&quot;&gt;&amp;nbsp;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#333333&quot;&gt;4.2 MCPServer 初始化&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt;
  看看如何创建一个 MCPServer 对象。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func NewMCPServer(
    name, version string,
    opts ...ServerOption,
) *MCPServer {
    s := &amp;amp;MCPServer{
       resources:            make(map[string]resourceEntry),
       resourceTemplates:    make(map[string]resourceTemplateEntry),
       prompts:              make(map[string]mcp.Prompt),
       promptHandlers:       make(map[string]PromptHandlerFunc),
       tools:                make(map[string]ServerTool),
       name:                 name,
       version:              version,
       notificationHandlers: make(map[string]NotificationHandlerFunc),
       capabilities: serverCapabilities{
          tools:     nil,
          resources: nil,
          prompts:   nil,
          logging:   false,
       },
    }

    for _, opt := range opts {
       opt(s)
    }

    return s
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;在 NewMCPServer() 方法中，我们需要关注的 opts ...ServerOption，进一步看看 ServerOption 有哪些选项：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;table cellspacing=&quot;0&quot; style=&quot;border-collapse:collapse&quot;&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;选项&lt;/td&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;功能&lt;/td&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;使用方式&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithResourceCapabilities&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;配置资源相关的服务器功能，如订阅和资源列表变化通知&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithResourceCapabilities(subscribe, listChanged bool)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithHooks&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;添加钩子函数，用于在请求处理前后执行特定逻辑&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithHooks(hooks *Hooks)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithPromptCapabilities&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;配置提示相关的服务器功能，如提示列表变化通知&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithPromptCapabilities(listChanged bool)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithToolCapabilities&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;配置工具相关的服务器功能，如工具列表变化通知&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithToolCapabilities(listChanged bool)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithLogging&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;启用服务器日志记录功能&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithLogging()&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithInstructions&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置服务器指令，用于在初始化响应中返回给客户端&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithInstructions(instructions string)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div&gt;
  它接受一个 Hooks 类型的指针作为参数。允许在创建 MCPServer 实例时，为服务器添加自定义的钩子函数，这些钩子函数可以在请求处理前后或返回错误给客户端之前执行。 
&lt;/div&gt; 
&lt;div&gt;
  hooks 机制对开发和流程是非常有效的。框架中给的 hooks 能力有： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;table cellspacing=&quot;0&quot; style=&quot;border-collapse:collapse&quot;&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;字段名&lt;/td&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;类型&lt;/td&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;描述&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeAny&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]BeforeAnyHookFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在请求被解析后但方法调用前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnSuccess&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnSuccessHookFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在请求成功生成结果但结果尚未发送给客户端之前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnError&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnErrorHookFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在请求解析或方法执行过程中发生错误时执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeInitialize&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeInitializeFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理初始化请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterInitialize&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterInitializeFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理初始化请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforePing&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforePingFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理 Ping 请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterPing&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterPingFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理 Ping 请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeListResources&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeListResourcesFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出资源请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterListResources&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterListResourcesFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出资源请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeListResourceTemplates&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeListResourceTemplatesFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出资源模板请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterListResourceTemplates&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterListResourceTemplatesFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出资源模板请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeReadResource&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeReadResourceFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理读取资源请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterReadResource&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterReadResourceFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理读取资源请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeListPrompts&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeListPromptsFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出提示请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterListPrompts&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterListPromptsFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出提示请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeGetPrompt&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeGetPromptFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理获取提示请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterGetPrompt&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterGetPromptFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理获取提示请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeListTools&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeListToolsFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出工具请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterListTools&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterListToolsFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理列出工具请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnBeforeCallTool&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnBeforeCallToolFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理调用工具请求前执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;OnAfterCallTool&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;[]OnAfterCallToolFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;在处理调用工具请求后执行的钩子函数。&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div&gt;
  现在模拟创建一个完整的 MCPServer： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;hooks := &amp;amp;server.Hooks{}

hooks.AddBeforeAny(func(id any, method mcp.MCPMethod, message any) {
    fmt.Printf(&quot;beforeAny: %s, %v, %v\n&quot;, method, id, message)
})
hooks.AddOnSuccess(func(id any, method mcp.MCPMethod, message any, result any) {
    fmt.Printf(&quot;onSuccess: %s, %v, %v, %v\n&quot;, method, id, message, result)
})
hooks.AddOnError(func(id any, method mcp.MCPMethod, message any, err error) {
    fmt.Printf(&quot;onError: %s, %v, %v, %v\n&quot;, method, id, message, err)
})
hooks.AddBeforeInitialize(func(id any, message *mcp.InitializeRequest) {
    fmt.Printf(&quot;beforeInitialize: %v, %v\n&quot;, id, message)
})
hooks.AddAfterInitialize(func(id any, message *mcp.InitializeRequest, result *mcp.InitializeResult) {
    fmt.Printf(&quot;afterInitialize: %v, %v, %v\n&quot;, id, message, result)
})
hooks.AddAfterCallTool(func(id any, message *mcp.CallToolRequest, result *mcp.CallToolResult) {
    fmt.Printf(&quot;afterCallTool: %v, %v, %v\n&quot;, id, message, result)
})
hooks.AddBeforeCallTool(func(id any, message *mcp.CallToolRequest) {
    fmt.Printf(&quot;beforeCallTool: %v, %v\n&quot;, id, message)
})
// 创建 MCP 服务器
s := server.NewMCPServer(
    &quot;Demo 🚀&quot;, // 服务器名称
    &quot;1.0.0&quot;,  // 服务器版本
    server.WithLogging(),
    server.WithToolCapabilities(true),
    server.WithResourceCapabilities(true, true),
    server.WithPromptCapabilities(true),
    server.WithInstructions(&quot;initialized&quot;),
    server.WithHooks(hooks),
)&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.3 Tools 模块&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_14&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.3.1 创建 Tool&lt;/h3&gt; 
&lt;div&gt;
  mark3labs/mcp-go 框架中创建 Tool 有两个方式： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    mcp.NewTool(name string, opts ...ToolOption) Tool 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    mcp.NewToolWithRawSchema(name, description string, schema json.RawMessage) Tool 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div&gt;
  下面通过一段代码进行对比： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;方式一：mcp.NewTool()
tool := mcp.NewTool(&quot;hello_world&quot;, // 工具名称
    mcp.WithDescription(&quot;Say hello to someone&quot;), // 工具描述
    mcp.WithString(&quot;name&quot;, // 参数名称
       mcp.Required(), // 参数是必需的
       mcp.Description(&quot;Name of the person to greet&quot;), // 参数描述
    ),
)

方式二：mcp.NewToolWithRawSchema()
rawSchema := json.RawMessage(`{
    &quot;type&quot;: &quot;object&quot;,
    &quot;properties&quot;: {
       &quot;name&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;Name of the person to greet&quot;}
    },
    &quot;required&quot;: [&quot;name&quot;]
}`)

// Create a tool with raw schema
toolRS := mcp.NewToolWithRawSchema(&quot;hello_world_1&quot;, &quot;Say hello to someone&quot;, rawSchema)&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;其中 rawSchema 的结构需要符合 ToolInputSchema 结构体：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type ToolInputSchema struct {
    Type       string                 `json:&quot;type&quot;`
    Properties map[string]interface{} `json:&quot;properties,omitempty&quot;`
    Required   []string               `json:&quot;required,omitempty&quot;`
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;需要注意的是 Properties 来源于 jsonSchema，所以具备的需要校验属性，比如 default、maximum、minimum、maxLength、minLength、enum 等等。其中 key 为请求传入的参数字段，interface{}为对 key 的各种属性校验。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;更建议使用方式一：mcp.NewTool() 更加符合编码方式，也更好控制器生成的&lt;/strong&gt; 
 &lt;strong&gt;jsonSchema&lt;/strong&gt; 
 &lt;strong&gt;。&lt;/strong&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h3_15&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.3.2 存放 Tool&lt;/h3&gt; 
&lt;div&gt;
  创建好 Tool 值之后，调用 server 的方法 AddTool() 将 Tool 添加进入，相当于 web 框架中的添加路由与相关 handle 的关系。相关代码如下： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// AddTool registers a new tool and its handler
func (s *MCPServer) AddTool(tool mcp.Tool, handler ToolHandlerFunc) {
    s.AddTools(ServerTool{Tool: tool, Handler: handler})
}

// AddTools registers multiple tools at once
func (s *MCPServer) AddTools(tools ...ServerTool) {
    // 检查工具
    if s.capabilities.tools == nil {
       s.capabilities.tools = &amp;amp;toolCapabilities{}
    }

    // 加锁
    s.mu.Lock()
    // 遍历工具
    for _, entry := range tools {
       s.tools[entry.Tool.Name] = entry
    }
    // 获取初始化状态
    initialized := s.initialized.Load()
    s.mu.Unlock()

    // 发送通知
    if initialized {
       s.sendNotificationToAllClients(&quot;notifications/tools/list_changed&quot;, nil)
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;可以看出 Tool 是放入到 MCPServer 的 tools 字段中，使用 name 作为 key，ServerTool 作为 value，其中 ServerTool 结构如下：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type ServerTool struct {
    Tool    mcp.Tool
    Handler ToolHandlerFunc
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;框架还提供了：&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    DeleteTools(names... string) 作为删除 Tool 关联的方法。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    SetTools(tools ...ServerTool) 可以设置当前所有的 Tool 列表。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_16&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.4 Resource 模块&lt;/h2&gt; 
&lt;div&gt;
  老规矩先来一个 demo，再看器源码实现： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Static resource example - exposing a README file
resource := mcp.NewResource(
    &quot;docs://readme&quot;,
    &quot;Project README&quot;,
    mcp.WithResourceDescription(&quot;The project&#39;s README file&quot;),
    mcp.WithMIMEType(&quot;text/markdown&quot;),
)

// Add resource with its handler
s.AddResource(resource, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    content, err := os.ReadFile(&quot;main.go&quot;)
    if err != nil {
       return nil, err
    }

    return []mcp.ResourceContents{
       mcp.TextResourceContents{
          URI:      &quot;docs://readme&quot;,
          MIMEType: &quot;text/markdown&quot;,
          Text:     string(content),
       },
    }, nil
})&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt;
  在 MCP 中 Resource 是指允许 Server 公开可供客户端读取并用作交互上下文的数据和内容。有很多类型的 Resource： 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    File contents 文件内容 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    Database records 数据库记录 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    API responses API 响应 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    Live system data 实时系统数据 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    images 图像 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    Log files 日志文件 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    等等... ... 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
  框架中 Resource 的结构体如下： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;
type Resource struct {
    Annotated // 包含可选注解，用于告知客户端如何使用或显示对象

    // 资源的 URI
    URI string `json:&quot;uri&quot;` // 资源的唯一标识符，用于定位和访问资源

    // 资源的可读名称
    //
    // 客户端可以使用此名称来填充 UI 元素
    Name string `json:&quot;name&quot;` // 资源的显示名称，便于用户理解和界面展示

    // 对此资源所代表内容的描述
    //
    // 客户端可以使用此描述来帮助大型语言模型（LLM）理解可用资源
    // 这可以看作是对模型的「提示」
    Description string `json:&quot;description,omitempty&quot;` // 资源的详细描述，为模型提供上下文信息

    // 如果已知，此资源的 MIME 类型
    MIMEType string `json:&quot;mimeType,omitempty&quot;` // 资源的媒体类型，如 text/plain、image/jpeg 等，用于指示资源的内容格式
}

type Annotated struct {
    Annotations *struct {
       // 描述此对象或数据的预期客户是谁
       //
       // 它可以包含多个条目，以指示对多个受众有用的内容（例如，`[&quot;user&quot;, &quot;assistant&quot;]`）
       Audience []Role `json:&quot;audience,omitempty&quot;` // 受众群体，指示数据对哪些角色或用户群体有用

       // 描述此数据对服务器操作的重要性
       //
       // 值为 1 表示「最重要」，并指示数据实际上是必需的，而 0 表示「最不重要」，并指示数据完全是可选的
       Priority float64 `json:&quot;priority,omitempty&quot;` // 优先级，表示数据对服务器操作的重要程度，范围从 0（最不重要）到 1（最重要）
    } `json:&quot;annotations,omitempty&quot;`
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;其中：&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    URI 用于定位一个具体资源的标识，场景的有 http://、file://、postgres://等等还可以去 https://www.iana.org/assignments/uri-schemes/uri-schemes.xhtml 看看。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    MIMEType 表示文件的类型，常见的有 text/html、image/png，这里也可以查看到更多：https://www.iana.org/assignments/media-types/media-types.xhtml。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func (s *MCPServer) AddResource(
    resource mcp.Resource,
    handler ResourceHandlerFunc,
) {
    // 检查资源
    if s.capabilities.resources == nil {
       s.capabilities.resources = &amp;amp;resourceCapabilities{}
    }

    // 加锁
    s.mu.Lock()
    // 解锁（defer）
    defer s.mu.Unlock()

    // 存储资源
    s.resources[resource.URI] = resourceEntry{
       resource: resource,
       handler:  handler,
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;resource 是放入到 MCPServer 的 resources 字段中，使用 URI 作为 key，resourceEntry 作为 value，其中 resourceEntry 结构如下：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type resourceEntry struct {
    resource mcp.Resource
    handler  ResourceHandlerFunc
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;框架还提供了添加 Resource templates 的功能，主要是针对动态资源，服务器可以公开 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Frfc6570&quot; target=&quot;_blank&quot;&gt;URI 模板 &lt;/a&gt;，客户端可以使用它来构建有效的资源 URI。&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Dynamic resource example - user profiles by ID
template := mcp.NewResourceTemplate(
    &quot;users://{id}/profile&quot;,
    &quot;User Profile&quot;,
    mcp.WithTemplateDescription(&quot;Returns user profile information&quot;),
    mcp.WithTemplateMIMEType(&quot;application/json&quot;),
)

// Add template with its handler
s.AddResourceTemplate(template, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    // Extract ID from the URI using regex matching
    // The server automatically matches URIs to templates
    userID := extractIDFromURI(request.Params.URI)

    profile := fmt.Sprintf(&quot;Hello %s&quot;, userID) // Your DB/API call here

    return []mcp.ResourceContents{
       mcp.TextResourceContents{
          URI:      request.Params.URI,
          MIMEType: &quot;application/json&quot;,
          Text:     profile,
       },
    }, nil
})

// extractIDFromURI 从给定的 URI 中提取用户 ID。
// 假设 URI 的格式为 &quot;users://{id}/profile&quot;。
func extractIDFromURI(uri string) string {
    // 定义正则表达式来匹配 URI 中的 ID
    re := regexp.MustCompile(`users://([^/]+)/profile`)

    // 使用正则表达式查找匹配项
    matches := re.FindStringSubmatch(uri)

    // 如果找到了匹配项，并且匹配项的数量正确，则返回 ID
    if len(matches) == 2 {
       return matches[1]
    }

    // 如果没有找到匹配项，或者匹配项的数量不正确，则返回空字符串
    return &quot;&quot;
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_17&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.5 Prompts 添加&lt;/h2&gt; 
&lt;div&gt;
  Prompts 创建可重复使用的提示模板和工作流程，提示使服务器能够定义可重复使用的提示模板和工作流程。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Simple greeting prompt
s.AddPrompt(mcp.NewPrompt(&quot;greeting&quot;,
    mcp.WithPromptDescription(&quot;A friendly greeting prompt&quot;),
    mcp.WithArgument(&quot;name&quot;,
       mcp.ArgumentDescription(&quot;Name of the person to greet&quot;),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    name := request.Params.Arguments[&quot;name&quot;]
    if name == &quot;&quot; {
       name = &quot;friend&quot;
    }

    return mcp.NewGetPromptResult(
       &quot;A friendly greeting&quot;,
       []mcp.PromptMessage{
          mcp.NewPromptMessage(
             mcp.RoleAssistant,
             mcp.NewTextContent(fmt.Sprintf(&quot;Hello, %s! How can I help you today?&quot;, name)),
          ),
       },
    ), nil
})&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt;
  Prompt 的结构体如下： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Prompt 表示服务器提供的提示或提示模板。
// 如果 Arguments 非空且包含元素，则表示该提示是一个模板，
// 在调用 prompts/get 时需要提供参数值。
// 如果 Arguments 为空或为 nil，则这是一个不需要参数的静态提示。
type Prompt struct {
    // 提示或提示模板的名称。
    Name string `json:&quot;name&quot;`
    // 提示提供内容的可选描述。
    Description string `json:&quot;description,omitempty&quot;`
    // 用于模板化提示的参数列表。
    // 参数的存在表明这是一个模板提示。
    Arguments []PromptArgument `json:&quot;arguments,omitempty&quot;`
}

// PromptArgument 描述提示模板可以接受的参数。
// 当提示包含参数时，客户端在发出 prompts/get 请求时
// 必须为所有必需参数提供值。
type PromptArgument struct {
    // 参数的名称。
    Name string `json:&quot;name&quot;`
    // 参数的可读描述。
    Description string `json:&quot;description,omitempty&quot;`
    // 此参数是否必须提供。
    // 如果为 true，则客户端在调用 prompts/get 时必须包含此参数。
    Required bool `json:&quot;required,omitempty&quot;`
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;可以通过 mcp.NewPrompt 方法来生成 Prompt 对象：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func NewPrompt(name string, opts ...PromptOption) Prompt {
    prompt := Prompt{
       Name: name,
    }

    for _, opt := range opts {
       opt(&amp;amp;prompt)
    }

    return prompt
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;又见到了 opts ...PromptOption，看看有哪些选项：&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    WithPromptDescription 用于设置 description； 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    WithArgument 用于设置 arguments； 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.6 选择传输方式&lt;/h2&gt; 
&lt;div&gt;
  现在代码已经来到了： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// 启动标准输入输出服务器
if err := server.ServeStdio(s); err != nil {
    fmt.Printf(&quot;Server error: %v\n&quot;, err) // 打印服务器错误
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;MCP 当前主要提供两类 Stdio transport 和 HTTP with SSE transport 。&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.6.1 Stdio&lt;/h3&gt; 
&lt;span id=&quot;OSC_h4_20&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;创建 StdioServer&lt;/h4&gt; 
&lt;div&gt;
  StdioServer 的结构体： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type StdioServer struct {
    server      *MCPServer
    errLogger   *log.Logger
    contextFunc StdioContextFunc
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;其中在，重要的字段有 server 和 contextFunc，给 MCPServer 进来就是为了具备 MCP 的能力，只是使用 stdio 的传输方式。contextFunc 是为了让外部自定义的 context 可以进入到 StdioServer，可以用于结束服务和控制超时.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;
// 为 MCP Server 启用 stdio
func ServeStdio(server *MCPServer, opts ...StdioOption) error {
    // 创建 Stdio 服务器
    s := NewStdioServer(server)
    // 设置错误日志
    s.SetErrorLogger(log.New(os.Stderr, &quot;&quot;, log.LstdFlags))

    // 应用选项
    for _, opt := range opts {
       opt(s)
    }

    // 创建上下文
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // 设置信号通道
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGTERM, syscall.SIGINT)

    // 监听信号
    go func() {
       &amp;lt;-sigChan
       cancel()
    }()

    // 开始监听
    return s.Listen(ctx, os.Stdin, os.Stdout)
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;其中最关键的是 Listen 方法，它是 StdioServer 类型的一个关键方法，用于监听标准输入输出的 JSON-RPC 消息。&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Listen 启动监听，从提供的输入读取 JSON-RPC 消息，并将响应写入提供的输出。
// 它将持续运行，直到上下文被取消或发生错误。
// 如果在读取输入或写入输出时遇到问题，将返回错误。
func (s *StdioServer) Listen(
    ctx context.Context, // 监听过程的上下文，用于控制生命周期和传递请求范围的信息
    stdin io.Reader, // 标准输入流，用于读取客户端发送的 JSON-RPC 消息
    stdout io.Writer, // 标准输出流，用于将响应写回客户端
) error {
    // 由于标准输入输出只有一个客户端，因此设置一个静态客户端上下文，SessionId 为 stdio
    if err := s.server.RegisterSession(&amp;amp;stdioSessionInstance); err != nil {
       // 如果会话注册失败，返回错误
       return fmt.Errorf(&quot;register session: %w&quot;, err)
    }
    // 确保在函数结束时注销会话
    defer s.server.UnregisterSession(stdioSessionInstance.SessionID())
    // 更新上下文，将会话信息加入
    ctx = s.server.WithContext(ctx, &amp;amp;stdioSessionInstance)

    // 如果存在自定义上下文函数，则应用该函数修改上下文
    if s.contextFunc != nil {
       ctx = s.contextFunc(ctx)
    }

    // 创建一个带缓冲的读取器，用于从标准输入流高效读取数据
    reader := bufio.NewReader(stdin)

    // 启动一个协程专门处理通知
    go func() {
       for {
          select {
          case notification := &amp;lt;-stdioSessionInstance.notifications:
             // 收到通知时，调用 writeResponse 方法将通知写入标准输出
             err := s.writeResponse(notification, stdout)
             if err != nil {
                // 如果写入通知时出错，记录错误日志
                s.errLogger.Printf(&quot;Error writing notification: %v&quot;, err)
             }
          case &amp;lt;-ctx.Done():
             // 如果上下文完成，退出协程
             return
          }
       }
    }()

    // 主循环，用于处理输入消息
    for {
       select {
       case &amp;lt;-ctx.Done():
          // 如果上下文完成，返回上下文错误
          return ctx.Err()
       default:
          // 使用协程使读取操作可取消
          readChan := make(chan string, 1) // 用于接收读取到的行
          errChan := make(chan error, 1)   // 用于接收读取错误

          go func() {
             line, err := reader.ReadString(&#39;\n&#39;) // 读取一行输入
             if err != nil {
                errChan &amp;lt;- err // 发送读取错误
                return
             }
             readChan &amp;lt;- line // 发送读取到的行
          }()

          select {
          case &amp;lt;-ctx.Done():
             // 如果上下文完成，返回上下文错误
             return ctx.Err()
          case err := &amp;lt;-errChan:
             // 处理读取错误
             if err == io.EOF {
                // 如果是文件结束符，表示输入结束，返回 nil
                return nil
             }
             // 其他错误则记录日志并返回
             s.errLogger.Printf(&quot;Error reading input: %v&quot;, err)
             return err
          case line := &amp;lt;-readChan:
             // 处理读取到的行
             if err := s.processMessage(ctx, line, stdout); err != nil {
                // 如果处理消息时出错
                if err == io.EOF {
                   // 如果是文件结束符，返回 nil
                   return nil
                }
                // 其他错误则记录日志并返回
                s.errLogger.Printf(&quot;Error handling message: %v&quot;, err)
                return err
             }
          }
       }
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h3_21&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.6.2 SSE&lt;/h3&gt; 
&lt;div&gt;
  SSE 模式凭借其分布式能力、实时性和架构灵活性，成为 MCP 在 
 &lt;strong&gt;企业级应用、云端协作、动态数据流处理&lt;/strong&gt;等场景的首选。所以对 SSE 的支持程度和易用程度，对于一个 MCP 框架而言是非常重要的。 
&lt;/div&gt; 
&lt;div&gt;
  mark3labs/mcp-go 如何支持 SSE 呢？看看如下代码： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;mcpServer := NewMCPServer()
sseServer := server.NewSSEServer(mcpServer, server.WithBaseURL(&quot;http://localhost:8080&quot;))
log.Printf(&quot;SSE server listening on :8080&quot;)
if err := sseServer.Start(&quot;:8080&quot;); err != nil {
    log.Fatalf(&quot;Server error: %v&quot;, err)
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;现在已经知道如何在 mark3labs/mcp-go 中启用 SSE 了，现在来分析一下，它是如何实现的。&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h4_22&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;创建 SSEServer&lt;/h4&gt; 
&lt;div&gt;
  SSEServer 的结构体如下： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// SSEServer implements a Server-Sent Events (SSE) based MCP server.
// It provides real-time communication capabilities over HTTP using the SSE protocol.
type SSEServer struct {
    server          *MCPServer       // MCPServer 实例，用于处理实际的消息传递和通信逻辑
    baseURL         string           // SSE 服务器的基础 URL，用于构建完整的端点路径
    basePath        string           // SSE 服务器的基础路径，通常用于区分不同的服务或版本
    messageEndpoint string           // 消息端点的路径，客户端通过此端点发送 JSON-RPC 消息
    sseEndpoint     string           // SSE 端点的路径，客户端通过此端点建立 SSE 连接
    sessions        sync.Map         // 存储活动 SSE 会话的同步映射，用于跟踪和管理客户端连接
    srv             *http.Server     // 内部的 HTTP 服务器实例，用于处理 HTTP 请求和响应
    contextFunc     SSEContextFunc   // 可选的上下文函数，用于根据请求内容自定义上下文
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;与之前的 StdioServer 相比，SSEServer 多了用于 http 中使用的 URI、path，还有 srv 这是一个 httpServer 的类型，用于支持 HTTP 请求和响应。继续查看如何构建 SSEServer：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// NewSSEServer creates a new SSE server instance with the given MCP server and options.
func NewSSEServer(server *MCPServer, opts ...SSEOption) *SSEServer {
    s := &amp;amp;SSEServer{
       server:          server,
       sseEndpoint:     &quot;/sse&quot;,
       messageEndpoint: &quot;/message&quot;,
    }

    // Apply all options
    for _, opt := range opts {
       opt(s)
    }

    return s
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;还是采用的才是经典 Option 模式，继续看看 SSEOption 有哪些选项：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;table cellspacing=&quot;0&quot; style=&quot;border-collapse:collapse&quot;&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;名称&lt;/td&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;功能&lt;/td&gt; 
    &lt;td style=&quot;text-align:center; white-space:pre-wrap&quot;&gt;使用方式&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithBaseURL&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置 SSE 服务器的基础 URL&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithBaseURL(&quot;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fexample.com&quot; target=&quot;_blank&quot;&gt;https://example.com&lt;/a&gt;&quot;)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithBasePath&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置 SSE 服务器的基础路径&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithBasePath(&quot;/v1&quot;)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithMessageEndpoint&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置消息端点的路径&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithMessageEndpoint(&quot;/custom-message&quot;)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithSSEEndpoint&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置 SSE 端点的路径&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithSSEEndpoint(&quot;/custom-sse&quot;)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithHTTPServer&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置 HTTP 服务器实例（通常用于测试或自定义服务器配置）&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithHTTPServer(customHttpServer)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithContextFunc&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;设置一个函数，用于根据请求内容自定义上下文&lt;/td&gt; 
    &lt;td style=&quot;white-space:pre-wrap&quot;&gt;WithContextFunc(func(ctx context.Context, r *http.Request) context.Context { ... })&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div&gt;
  WithHTTPServer 适用于需要自定义服务器配置的场景，为后续替换更好性能的 http 服务实例打下基础，也体现了 mark3labs/mcp-go 扩展性。 
&lt;/div&gt; 
&lt;div&gt;
  剩下的 Start() 就是常见的启动 http 服务实例的功能了。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func (s *SSEServer) Start(addr string) error {
    s.srv = &amp;amp;http.Server{
       Addr:    addr,
       Handler: s,
    }

    return s.srv.ListenAndServe()
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;还可以调用 Shutdown() 实现对服务器的关闭。&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h3_23&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.6.3 集成到 gin 框架&lt;/h3&gt; 
&lt;div&gt;
  在实际开发中，很多公司内部的业务有自己的框架，集成了许许多多的独特功能。总不能为了使用 MCP 重写一套 Web 框架，此时就需要使用到 mark3labs/mcp-go 集成到 Web 框架的能力了。下面以 gin 框架为例： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// 创建一个新的 Gin 引擎
r := gin.Default()

// 创建一个新的 MCPServer 实例（假设这是 SSEServer 所需的）
mcpServer := server.NewMCPServer(&quot;gin-mcp-server&quot;, &quot;1.0.0&quot;) // 根据你的实际代码调整
// mcpServer 新加 Tool、Resource、Prompt
// ... ...
// 创建一个新的 SSEServer 实例，并传入 MCPServer
sseServer := server.NewSSEServer(mcpServer)

// 将 SSEServer 的 SSE 端点和处理函数集成到 Gin 路由中
r.GET(sseServer.CompleteSsePath(), func(c *gin.Context) {
    sseServer.ServeHTTP(c.Writer, c.Request)
})

// 将 SSEServer 的消息端点和处理函数集成到 Gin 路由中
r.POST(sseServer.CompleteMessagePath(), func(c *gin.Context) {
    sseServer.ServeHTTP(c.Writer, c.Request)
})

// 启动 Gin 服务器
if err := r.Run(&quot;localhost:8081&quot;); err != nil {
    log.Fatalf(&quot;Gin server startup failed: %v&quot;, err)
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;上述的代码会生成两个路由：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;table cellspacing=&quot;0&quot; style=&quot;border-collapse:collapse; border:none; table-layout:fixed; width:500px&quot;&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       路由 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       方法 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       作用 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       实例 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       /sse 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       GET 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;ul&gt; 
      &lt;li&gt; 
       &lt;div&gt;
         获取 SessionID 
       &lt;/div&gt; &lt;/li&gt; 
      &lt;li&gt; 
       &lt;div&gt;
         接受 Server 响应 
       &lt;/div&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; &lt;pre&gt;&lt;code&gt;请求：
curl &#39;http://localhost:3000/sse?transportType=sse&amp;amp;url=http%3A%2F%2Flocalhost%3A8081%2Fsse&#39; \
  -H &#39;Accept: */*&#39; \
  -H &#39;Accept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7&#39; \
  -H &#39;Cache-Control: no-cache&#39; \
  -H &#39;Connection: keep-alive&#39; \
  -H &#39;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36&#39; 
  
  响应：
  event: endpoint
data: /message?sessionId=fee6d6df-d394-4b4d-a748-fddcc73fb766&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       /message 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;div&gt;
       POST 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; 
     &lt;ul&gt; 
      &lt;li&gt; 
       &lt;div&gt;
         使用 SessionID 保持会话 
       &lt;/div&gt; &lt;/li&gt; 
      &lt;li&gt; 
       &lt;div&gt;
         发起功能请求 
       &lt;/div&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
    &lt;td style=&quot;border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top&quot;&gt; &lt;pre&gt;&lt;code&gt;请求：
curl &#39;http://localhost:3000/message?sessionId=fee6d6df-d394-4b4d-a748-fddcc73fb766&#39; \
  -H &#39;Accept: */*&#39; \
  -H &#39;Cache-Control: no-cache&#39; \
  -H &#39;Connection: keep-alive&#39; \
  -H &#39;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36&#39; \
  -H &#39;content-type: application/json&#39; 
  --data-raw &#39;{&quot;method&quot;:&quot;initialize&quot;,&quot;params&quot;:{&quot;protocolVersion&quot;:&quot;2024-11-05&quot;,&quot;capabilities&quot;:{&quot;sampling&quot;:{},&quot;roots&quot;:{&quot;listChanged&quot;:true}},&quot;clientInfo&quot;:{&quot;name&quot;:&quot;mcp-inspector&quot;,&quot;version&quot;:&quot;0.7.0&quot;}},&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0}&#39;
 
/message 的响应：
{&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0,&quot;result&quot;:{&quot;protocolVersion&quot;:&quot;2024-11-05&quot;,&quot;capabilities&quot;:{&quot;logging&quot;:{},&quot;prompts&quot;:{&quot;listChanged&quot;:true},&quot;resources&quot;:{&quot;subscribe&quot;:true,&quot;listChanged&quot;:true},&quot;tools&quot;:{}},&quot;serverInfo&quot;:{&quot;name&quot;:&quot;example-servers/everything&quot;,&quot;version&quot;:&quot;1.0.0&quot;}}}

/sse 收到的响应：
event: message
data: {&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0,&quot;result&quot;:{&quot;protocolVersion&quot;:&quot;2024-11-05&quot;,&quot;capabilities&quot;:{&quot;logging&quot;:{},&quot;prompts&quot;:{&quot;listChanged&quot;:true},&quot;resources&quot;:{&quot;subscribe&quot;:true,&quot;listChanged&quot;:true},&quot;tools&quot;:{}},&quot;serverInfo&quot;:{&quot;name&quot;:&quot;example-servers/everything&quot;,&quot;version&quot;:&quot;1.0.0&quot;}}}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_24&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.7 处理请求&lt;/h2&gt; 
&lt;div&gt;
  之前的内容，解析了如何构建 MCP Server 的实践和背后的实现。下面我们还需要了解 mark3labs/mcp-go 如何接受请求并进行响应的。 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h3_25&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.7.1 路由入口&lt;/h3&gt; 
&lt;div&gt;
  从 SSEServer 结构体中已经知道使用的 http.Server，所以其接受请求的入口为 ServeHTTP 方法，实现了 http.Handler 接口，用于处理 HTTP 请求。根据请求的路径，它会将请求分发到不同的处理方法（handleSSE 或 handleMessage），或者返回 404 未找到。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func (s *SSEServer) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // 获取请求的路径
    path := r.URL.Path

    // 使用精确路径匹配，而不是模糊包含
    ssePath := s.CompleteSsePath() // 获取完整的 SSE 路径
    if ssePath != &quot;&quot; &amp;amp;&amp;amp; path == ssePath {
       // 如果请求路径与 SSE 路径匹配，则处理 SSE 请求
       s.handleSSE(w, r)
       return // 处理完成后直接返回，不再继续后续逻辑
    }

    // 获取消息处理的完整路径
    messagePath := s.CompleteMessagePath()
    if messagePath != &quot;&quot; &amp;amp;&amp;amp; path == messagePath {
       // 如果请求路径与消息处理路径匹配，则处理消息请求
       s.handleMessage(w, r)
       return // 处理完成后直接返回，不再继续后续逻辑
    }

    // 如果请求路径不匹配任何已知路径，则返回 404 未找到
    http.NotFound(w, r)
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;其中：&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    SSE 路径为：s.baseURL + s.basePath + s.sseEndpoint 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    Message 路径为：s.baseURL + s.basePath + s.messageEndpoint 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
  这些信息都是可以在 NewSSEServer() 方法中设置。 
&lt;/div&gt; 
&lt;div&gt;
  需要详细查看的是 s.handleSSE(w, r) 和 s.handleMessage(w, r) 方法，他们分别处理/see 和/message 的请求。 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h3_26&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.7.2 handleSSE&lt;/h3&gt; 
&lt;div&gt;
  handleSSE 实现了一个处理服务器发送事件（SSE）的 HTTP 处理器。SSE 是一种允许服务器向客户端发送自动更新的技术。主要流程： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;请求方法检查&lt;/strong&gt;：只允许 GET 请求。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;设置响应头&lt;/strong&gt;：设置适当的 SSE 响应头。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;创建会话&lt;/strong&gt;：为每个客户端创建一个新的 SSE 会话。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;注册和注销会话&lt;/strong&gt;：在服务器中注册会话，并在处理完成后注销。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;通知处理器&lt;/strong&gt;：启动一个 goroutine 处理来自通知通道的事件，并将其发送到客户端。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;主事件循环&lt;/strong&gt;：处理来自事件队列的事件，并将其发送到客户端。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// 它设置适当的头信息并为客户端创建一个新的会话。
func (s *SSEServer) handleSSE(w http.ResponseWriter, r *http.Request) {
    // 1. 检查请求方法是否为 GET，如果不是，返回 405 Method Not Allowed 错误
    if r.Method != http.MethodGet {
       http.Error(w, &quot;Method not allowed&quot;, http.StatusMethodNotAllowed)
       return
    }

    // 2. 设置 SSE 相关的响应头
    w.Header().Set(&quot;Content-Type&quot;, &quot;text/event-stream&quot;) // 设置内容类型为 text/event-stream
    w.Header().Set(&quot;Cache-Control&quot;, &quot;no-cache&quot;)         // 禁用缓存
    w.Header().Set(&quot;Connection&quot;, &quot;keep-alive&quot;)          // 保持连接活跃
    w.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)  // 允许所有域跨域请求

    // 检查 ResponseWriter 是否支持 Flush，如果不支持，返回 500 Internal Server Error 错误
    flusher, ok := w.(http.Flusher)
    if !ok {
       http.Error(w, &quot;Streaming unsupported&quot;, http.StatusInternalServerError)
       return
    }

    // 3. 创建一个新的会话 ID 和会话对象
    sessionID := uuid.New().String() // 生成唯一的会话 ID
    session := &amp;amp;sseSession{
       writer:              w,                          // 响应写入器
       flusher:             flusher,                    // 刷新器
       done:                make(chan struct{}),        // 用于通知会话结束的通道
       eventQueue:          make(chan string, 100),     // 事件队列，缓冲区大小为 100
       sessionID:           sessionID,                  // 会话 ID
       notificationChannel: make(chan mcp.JSONRPCNotification, 100), // 通知通道，缓冲区大小为 100
    }

    // 4. 将会话存储到会话存储中，并在处理完成后删除
    s.sessions.Store(sessionID, session)
    defer s.sessions.Delete(sessionID)

    // 在服务器中注册会话，如果注册失败，返回 500 Internal Server Error 错误
    if err := s.server.RegisterSession(session); err != nil {
       http.Error(w, fmt.Sprintf(&quot;Session registration failed: %v&quot;, err), http.StatusInternalServerError)
       return
    }
    // 在处理完成后注销会话
    defer s.server.UnregisterSession(sessionID)

    // 5. 启动一个 goroutine 处理通知通道中的事件
    go func() {
       for {
          select {
          case notification := &amp;lt;-session.notificationChannel: // 从通知通道接收通知
             eventData, err := json.Marshal(notification) // 将通知序列化为 JSON
             if err == nil {
                select {
                case session.eventQueue &amp;lt;- fmt.Sprintf(&quot;event: message\ndata: %s\n\n&quot;, eventData): // 将事件发送到事件队列
                   // 事件成功入队
                case &amp;lt;-session.done: // 如果会话结束，退出 goroutine
                   return
                }
             }
          case &amp;lt;-session.done: // 如果会话结束，退出 goroutine
             return
          case &amp;lt;-r.Context().Done(): // 如果请求上下文被取消，退出 goroutine
             return
          }
       }
    }()

    // 生成消息端点 URL 并发送初始的 endpoint 事件
    messageEndpoint := fmt.Sprintf(&quot;%s?sessionId=%s&quot;, s.CompleteMessageEndpoint(), sessionID)
    fmt.Fprintf(w, &quot;event: endpoint\ndata: %s\r\n\r\n&quot;, messageEndpoint) // 发送 endpoint 事件
    flusher.Flush() // 刷新响应，确保事件立即发送到客户端

    // 6. 主事件循环，运行在 HTTP 处理器 goroutine 中
    for {
       select {
       case event := &amp;lt;-session.eventQueue: // 从事件队列接收事件
          fmt.Fprint(w, event) // 将事件写入响应
          flusher.Flush()      // 刷新响应，确保事件立即发送到客户端
       case &amp;lt;-r.Context().Done(): // 如果请求上下文被取消，关闭会话并退出
          close(session.done)
          return
       }
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;第三阶段又看到 Session 了，与之前的 stdioSession 相比，sseSession 明显复杂多了，它们都实现接口 ClientSession：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type ClientSession interface {
    // NotificationChannel provides a channel suitable for sending notifications to client.
    NotificationChannel() chan&amp;lt;- mcp.JSONRPCNotification
    // SessionID is a unique identifier used to track user session.
    SessionID() string
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;sseSession 是专门用于表示一个基于服务器发送事件（Server-Sent Events, SSE）协议的活跃连接。sseSession 负责管理客户端与服务器之间的单向实时数据推送，并保持会话。其结构体如下：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type sseSession struct {
    writer              http.ResponseWriter // HTTP 响应写入器，用于向客户端发送数据
    flusher             http.Flusher       // HTTP 刷新器，用于刷新响应缓冲区，确保数据立即发送给客户端
    done                chan struct{}      // 用于通知会话结束的通道
    eventQueue          chan string        // 用于排队事件的通道，存储待发送给客户端的事件
    sessionID           string             // 会话的唯一标识符
    notificationChannel chan mcp.JSONRPCNotification // 用于接收 JSON-RPC 通知的通道
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;span id=&quot;OSC_h3_27&quot;&gt;&lt;/span&gt; 
 &lt;h3&gt;4.7.3 handleMessage&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div&gt;
  handleMessage 方法是 SSEServer 类型的一个方法，用于处理传入的 JSON-RPC 消息，并通过 SSE 连接和 HTTP 响应返回结果。其主要流程： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    请求验证：检查请求方法 
  &lt;/div&gt; 
  &lt;ol&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      检查请求方法：方法首先检查请求方法是否为 HTTP POST。如果不是，返回 &quot;Method not allowed&quot; 错误，并终止处理。 
    &lt;/div&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      验证 sessionId 参数：从请求的 URL 查询参数中获取 sessionId。如果缺失，返回 &quot;Missing sessionId&quot; 错误。 
    &lt;/div&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      加载会话：使用 sessionId 从会话存储中加载会话。如果会话不存在，返回 &quot;Invalid session ID&quot; 错误。 
    &lt;/div&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    设置上下文 
  &lt;/div&gt; 
  &lt;ol&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      调用 s.server.WithContext 方法，将请求上下文和会话信息合并，生成新的上下文。如果提供了 contextFunc，则进一步处理上下文。 
    &lt;/div&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    解析 JSON-RPC 消息 
  &lt;/div&gt; 
  &lt;ol&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      使用 json.NewDecoder 解析请求体中的原始 JSON 消息。如果解析失败，返回 &quot;Parse error&quot; 错误。 
    &lt;/div&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    处理消息 
  &lt;/div&gt; 
  &lt;ol&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      将解析后的消息传递给 s.server.HandleMessage 方法进行处理，并获取响应结果。 
    &lt;/div&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    发送响应 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp;&amp;nbsp;如果 HandleMessage 返回了响应（非通知），则： 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp;&amp;nbsp;如果 HandleMessage 没有返回响应（通知），则仅设置 HTTP 响应状态码为 202 Accepted，不发送响应体。 
  &lt;/div&gt; 
  &lt;ol&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      将响应编码为 JSON 格式。 
    &lt;/div&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      将响应事件加入会话的事件队列，供 SSE 连接发送。 
    &lt;/div&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;div&gt;
      设置 HTTP 响应头为 application/json，状态码为 202 Accepted，并发送响应体。 
    &lt;/div&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    事件队列处理 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div&gt;
  尝试将事件加入会话的事件队列。如果队列已满或会话已关闭，则丢弃事件。 
&lt;/div&gt; 
&lt;div&gt;
  那么 handleSSE 和 handleMessage 的关系是怎样的呢？使用一张图来说明： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height=&quot;729&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7cab372d06266dac5b06a8959d2df0382ea.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// handleMessage 处理来自客户端的 JSON-RPC 消息，并通过 SSE 连接和 HTTP 响应返回结果
func (s *SSEServer) handleMessage(w http.ResponseWriter, r *http.Request) {
    // 1. 如果请求方法不是 POST，则返回 JSON-RPC 错误响应，表示方法不允许
    if r.Method != http.MethodPost {
       s.writeJSONRPCError(w, nil, mcp.INVALID_REQUEST, &quot;Method not allowed&quot;)
       return
    }

    // 从请求的 URL 查询参数中获取 sessionId
    sessionID := r.URL.Query().Get(&quot;sessionId&quot;)
    // 如果 sessionId 为空，则返回 JSON-RPC 错误响应，表示缺少 sessionId 参数
    if sessionID == &quot;&quot; {
       s.writeJSONRPCError(w, nil, mcp.INVALID_PARAMS, &quot;Missing sessionId&quot;)
       return
    }

    // 从 session 存储中加载与 sessionId 对应的 session
    sessionI, ok := s.sessions.Load(sessionID)
    // 如果 session 不存在，则返回 JSON-RPC 错误响应，表示无效的 session ID
    if !ok {
       s.writeJSONRPCError(w, nil, mcp.INVALID_PARAMS, &quot;Invalid session ID&quot;)
       return
    }
    session := sessionI.(*sseSession)

    // 在处理消息之前设置客户端上下文
    ctx := s.server.WithContext(r.Context(), session)
    // 如果提供了自定义的上下文函数，则应用它
    if s.contextFunc != nil {
       ctx = s.contextFunc(ctx, r)
    }

    // 将请求体解析为原始 JSON 消息
    var rawMessage json.RawMessage
    if err := json.NewDecoder(r.Body).Decode(&amp;amp;rawMessage); err != nil {
       // 如果解析失败，则返回 JSON-RPC 错误响应，表示解析错误
       s.writeJSONRPCError(w, nil, mcp.PARSE_ERROR, &quot;Parse error&quot;)
       return
    }

    // 通过 MCPServer 处理消息
    response := s.server.HandleMessage(ctx, rawMessage)

    // 如果存在响应（非通知），则发送响应
    if response != nil {
       // 将响应编码为 JSON 格式
       eventData, _ := json.Marshal(response)

       // 将事件排队以通过 SSE 发送
       select {
       case session.eventQueue &amp;lt;- fmt.Sprintf(&quot;event: message\ndata: %s\n\n&quot;, eventData):
          // 事件成功排队
       case &amp;lt;-session.done:
          // 会话已关闭，不尝试排队
       default:
          // 队列已满，可以记录此情况
       }

       // 发送 HTTP 响应
       w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
       w.WriteHeader(http.StatusAccepted)
       json.NewEncoder(w).Encode(response)
    } else {
       // 对于通知，只发送 202 Accepted 状态码，无响应体
       w.WriteHeader(http.StatusAccepted)
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt;
  需要注意的是 HandleMessage 方法，这是通过 server/internal/gen/request_handler.go.tmpl 生成的，也根据 MCP 协议实现的模版，其流程如下： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    尝试将原始消息解析为对应请求类型。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    如果解析失败，记录错误信息。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    执行请求前的钩子函数。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    调用对应的处理函数处理请求。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    如果处理过程中发生错误，执行错误钩子函数并返回错误响应。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    执行请求后的钩子函数。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    返回成功响应。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div&gt;
  以 initialize 请求为例： 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// 根据消息方法进行分情况处理
switch baseMessage.Method {
// 初始化请求处理
case mcp.MethodInitialize:
    var request mcp.InitializeRequest
    var result *mcp.InitializeResult
    // 尝试将原始消息解析为初始化请求类型
    if unmarshalErr := json.Unmarshal(message, &amp;amp;request); unmarshalErr != nil {
       // 如果解析失败，记录错误信息
       err = &amp;amp;requestError{
          id:   baseMessage.ID,
          code: mcp.INVALID_REQUEST,
          err:  &amp;amp;UnparseableMessageError{message: message, err: unmarshalErr, method: baseMessage.Method},
       }
    } else {
       // 执行初始化请求前的钩子函数
       s.hooks.beforeInitialize(baseMessage.ID, &amp;amp;request)
       // 处理初始化请求
       result, err = s.handleInitialize(ctx, baseMessage.ID, request)
    }
    // 如果处理过程中发生错误
    if err != nil {
       // 执行错误钩子函数
       s.hooks.onError(baseMessage.ID, baseMessage.Method, &amp;amp;request, err)
       // 返回错误响应
       return err.ToJSONRPCError()
    }
    // 执行初始化请求后的钩子函数
    s.hooks.afterInitialize(baseMessage.ID, &amp;amp;request, result)
    // 返回成功响应
    return createResponse(baseMessage.ID, *result)

// 其他方法处理逻辑类似，省略...

// 如果方法不匹配任何已知方法，返回方法未找到错误响应
default:
    return createErrorResponse(
       baseMessage.ID,
       mcp.METHOD_NOT_FOUND,
       fmt.Sprintf(&quot;Method %s not found&quot;, baseMessage.Method),
    )
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;代码比较多，可以自行查看：https://github.com/mark3labs/mcp-go/blob/e183dd17cfec07072a188f6169033bf61f7bf37d/server/request_handler.go#L12&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h1_28&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、总结&lt;/h1&gt; 
&lt;div&gt;
  mark3labs/mcp-go 框架是一个简单易用的 MCP 框架，基本上实现了 MCP 协议，提供对 MCP 核心规范的完整支持，包括资源（Resources）、工具（Tools）、提示（Prompts）等核心组件，确保与主流 LLM 客户端（如 Claude、Cline）的兼容性。尤其是 mark3labs/mcp-go 提供的 hooks 机制，可以让开发者更好的使用类似 gin 空间一样的中间件能力，比如实现统一鉴权等能力。除此之外，还可以与主流的 Web 框架，如 gin 框架进行集成，进一步扩展了 mark3labs/mcp-go 的适用性。 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/qiangmzsx/blog/18014540</link>
            <guid isPermaLink="false">https://my.oschina.net/qiangmzsx/blog/18014540</guid>
            <pubDate>Thu, 27 Mar 2025 02:15:25 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>阿里通义千问开源端到端多模态模型 Qwen2.5-Omni</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;3 月 27 日，通义千问&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fzh%2Fblog%2Fqwen2.5-omni%2F&quot; target=&quot;_blank&quot;&gt;宣布推出&lt;/a&gt;&lt;/u&gt;新一代端到端多模态旗舰模型 Qwen2.5-Omni。该模型现已在 Hugging Face、ModelScope、DashScope 和 GitHub 上开源开放。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e620efb7beda14c716812fb6f4a8ed2f17f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Qwen2.5-Omni 是一种端到端多模态模型，旨在感知各种模态，包括文本，图像，音频和视频，同时以流式方式生成文本和自然语音响应。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;关键特点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Omni 和新颖的架构：我们提出 Thinker-Talker 架构，这是一种端到端多模态模型，旨在感知各种模式，包括文本，图像，音频和视频，同时以流式方式生成文本和自然语音响应。 我们提出了一种新的位置嵌入，称为 TMRoPE (时间对齐多模态 RoPE), 以将视频输入的时间戳与音频同步。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;实时语音和视频聊天：专为完全实时交互而设计的架构，支持分块输入和即时输出。&lt;/li&gt; 
 &lt;li&gt;自然和强大的语音生成：超越许多现有的流媒体和非流媒体替代方案，在语音生成中表现出卓越的鲁棒性和自然性。&lt;/li&gt; 
 &lt;li&gt;跨模式的强大性能：在与类似规模的单模式模型进行基准测试时，在所有模式中表现出卓越的性能。 Qwen2.5-Omni 在音频功能方面优于类似尺寸的 Qwen2-Audio, 并实现与 Qwen2.5-VL-7B 相当的性能。&lt;/li&gt; 
 &lt;li&gt;优秀的端到端语音指令：Qwen2.5-Omni 在端到端语音指令中表现出性能，这与文本输入的有效性相媲美，MMLU 和 GSM8K 等基准测试就证明了这一点。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;模型架构&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8eac4f9ca743454cd238cfa11a6319f1710.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ac3ad0960351e7733a1cfb5cabf05690d01.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型下载&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目前只开源了 7B 尺寸的模型&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen2.5-Omni-7B&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/Qwen/Qwen2.5-Omni-7B&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341243/qwen2-5-omni-7b</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341243/qwen2-5-omni-7b</guid>
            <pubDate>Thu, 27 Mar 2025 02:12:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI Agents SDK 已支持大模型上下文协议 MCP</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAIDevs%2Fstatus%2F1904957755829481737&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;其智能体——OpenAI Agents SDK 已支持大模型上下文协议 MCP，并表示称&lt;strong&gt;正在为 OpenAI API 和 ChatGPT 桌面应用程序开发 MCP 支持&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1052&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0327/095628_d79a_2720166.png&quot; width=&quot;1278&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/100304_ckel_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;OpenAI Agents SDK 支持 MCP 对于开发复杂的智能体具有巨大帮助。例如，在开发一个需要同时进行文件处理、数据查询和网络信息收集的智能体时，开发者可以通过 MCP 服务器分别集成文件系统工具、数据库查询工具和网络爬虫工具，更高效地完成任务。&lt;/p&gt; 
&lt;p&gt;参考文档&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.github.io%2Fopenai-agents-python%2Fmcp%2F&quot; target=&quot;_blank&quot;&gt;https://openai.github.io/openai-agents-python/mcp/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Fopenai-agents-python&quot; target=&quot;_blank&quot;&gt;https://github.com/openai/openai-agents-python&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341240/openai-agents-sdk-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341240/openai-agents-sdk-mcp</guid>
            <pubDate>Thu, 27 Mar 2025 02:04:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>张一鸣登顶中国首富</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3 月 27 日，彭博亿万富豪指数及福布斯富豪榜均显示，字节跳动创始人张一鸣登顶中国富豪榜榜首，成为中国首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;福布斯预估张一鸣身家为 655 亿美元（约合 4760.67 亿元人民币），在全球富豪榜位列第 23 位，马化腾与钟睒睒分别以 535 亿美元、531 亿美元的身家分列富豪榜第 27 和 28 位。彭博亿万富豪指数预估张一鸣身家为 575 亿美元，位居全球富豪榜第 24 位，马化腾和钟睒睒分列第 25 和 26 位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另外根据彭博亿万富豪指数，张一鸣目前是亚洲第三大富豪，仅次于印度的 Mukesh Ambani 和 Gautam Adani。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;309&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-63eb3fc9dc2e64506bf7afcc27af90e9d51.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341239</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341239</guid>
            <pubDate>Thu, 27 Mar 2025 02:00:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>商汤科技：2024 年生成式 AI 收入占比达 63.7%</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;商汤集团&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPBkhEy84piWtkBHwY8nDYA&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;截至 2024 年 12 月 31 日经审核全年业绩。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年，商汤集团总体收入同比增长 10.8%，达到 37.7 亿元人民币；其中，生成式 AI 业务收入突破 24 亿元，同比大幅增长 103.1%，这是生成式 AI 连续两年保持三位数增速，占总收入比例进一步提升至 63.7%，已成为集团最大业务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年集团毛利为 16.2 亿元人民币，毛利率为 42.9%，亏损同比收窄 33.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;商汤集团董事会执行主席兼首席执行官徐立博士表示：「大模型算法与基础设施软件系统的联合优化已成为生成式 AI 飞速发展的核心驱动力。商汤秉承的‘大装置-大模型-应用’三位一体、联合优化的战略与此趋势契合，正在迎来高速发展阶段。商汤以‘1+X’组织架构重组推动资源的战略聚焦，以可持续增长与盈利能力为核心，增强商汤作为行业标杆的竞争力。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;3808&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60709661fa23c67ebe39f9c529b30ba38ec.webp&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341237</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341237</guid>
            <pubDate>Thu, 27 Mar 2025 01:56:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英伟达正在洽谈收购贾扬清创业公司 Lepton AI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fnvidia-nears-deal-buy-gpu-reseller-several-hundred-million-dollars&quot; target=&quot;_blank&quot;&gt;根据 The Information 的报道&lt;/a&gt;&lt;/u&gt;，英伟达即将收购成立两年的 AI 创业公司 Lepton AI。据称这笔交易的金额达数亿美元。&lt;/p&gt; 
&lt;p&gt;Lepton AI 创始人贾扬清是开源深度学习框架 Caffe 创始人、TensorFlow 作者之一、也是 PyTorch 1.0 的共同创始人。他在创立 Lepton AI 之前在阿里巴巴担任技术副总裁。&lt;/p&gt; 
&lt;p&gt;2023 年 3 月，贾扬清离职创立了 Lepton AI，主做 AI 底层架构方向的事情，希望通过产品的方式来降低 AI 应用开发的门槛，帮助开发者更容易地完成创建、部署和扩展任务。&lt;/p&gt; 
&lt;p&gt;2023 年 5 月，Lepton AI 完成了首轮天使轮融资，由 Fusion Fund 基金和 CRV 风投两家机构投资。创始团队成员还包括 ONNX 的联合创始人以及 etcd 的创始人。&lt;/p&gt; 
&lt;p&gt;成立至今，Lepton AI 主要发布了两款产品：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;FastGPU：2024 年 6 月上线的云 GPU 解决方案，主打经济高效和可靠。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Lepton Search：2023 年 12 月推出的对话式搜索引擎，基于 Lepton AI 平台实现，代码量不到 500 行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Lepton AI 的基本思路是提供大模型训练、部署和应用时所需的基础设施，诸如提供 Python SDK 和云计算平台，支持 HuggingFace 模型集成和从 GitHub 仓库创建 AI 模型，以降低了 AI 应用开发的门槛。&lt;/p&gt; 
&lt;p&gt;而 NVIDIA 目前也正致力于扩展其 AI 能力和基础设施，为其客户更全面的解决方案。这是促成此次收购的核心战略逻辑。&lt;/p&gt; 
&lt;p&gt;英伟达正感受到来自其最大客户——主要云服务提供商，如亚马逊和谷歌的压力，这些客户试图通过开发和低价租赁替代芯片来削弱英伟达的市场地位，因此英伟达考虑进行多元化发展，直接下场做 Lepton AI 做的事情。&lt;/p&gt; 
&lt;p&gt;Lepton AI 的一个主要竞争对手是 Together AI，这同样是一家初创公司，尽管仅比 Lepton AI 早成立一年左右，但已筹集了超过 5 亿美元的风险投资。另外还有一个竞争对手是 Fireworks，由前 Meta PyTorch 团队成员创立，去年完成了 B 轮融资，英伟达也有参与跟投。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/340005/nvidia-gretel-acquisition-synthetic-training-data&quot; target=&quot;news&quot;&gt;英伟达收购合成数据初创公司 Gretel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/287935&quot; target=&quot;news&quot;&gt;贾扬清评价李彦宏对大模型行业趋势的预测：非常对&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/276738/search-with-lepton-opensource&quot; target=&quot;news&quot;&gt;贾扬清最新开源项目 —— 500 行代码构建的 AI 搜索工具&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341235</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341235</guid>
            <pubDate>Thu, 27 Mar 2025 01:47:25 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国 AIGC APP 月活 TOP10 出炉：DeepSeek 第一、豆包第二</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fl4_g0dgHMu0g9E2AEbRLfw&quot; target=&quot;_blank&quot;&gt;QuestMobile 数据显示&lt;/a&gt;&lt;/u&gt;，截止 2025 年 1 月，全网用户月人均使用时长提升至 171.4 小时，增速放缓，人均使用次数及 APP 个数分别达到 2487.9 次和 28.7 个，趋于稳定。其中，数量、时长同比均微增，但是次数同比出现了罕见的下降。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;582&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/192553_3GKs_2720166.png&quot; width=&quot;960&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，月活跃用户增长榜单中，AIGC、智能家居、用车服务等领域同比分别增长了 244.7%、16.7%、20.8%；相比之下，两年前的 2023 年 1 月，月活跃用户增长较快的领域分别为综合电商、手机银行、效率办公、益智休闲游戏等领域，增速分别为 12.1%、18.4%、22.9%、57.5%。&lt;/p&gt; 
&lt;p&gt;QuestMobile 数据显示，2025 年 1 月，AIGC APP 行业月活跃用户规模同比增长率高达 244.7%，净增量超 9200 万，领跑移动互联网行业。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/192740_XN38_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;随着 AI 大模型的不断升级，深度思考和推理能力显著提升，AIGC 已成为全网增速最快赛道，&lt;strong&gt;DeepSeek APP 上线次月活跃用户规模突破 1.8 亿，豆包 APP 破亿，腾讯元宝、纳米 AI 搜索在 DeepSeek 大模型加持下，跻身 TOP5&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/192702_SJHe_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/192719_cAAX_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;QuestMobile 数据显示，纳米 AI 搜索、腾讯元宝 APP 在接入 DeepSeek 大模型后日活跃用户规模提升显著，其中，腾讯元宝 APP 在接入大模型 11 天后日活跃用户规模突破 500 万，纳米 AI 搜索 2 月日活峰值达 384.8 万。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341168</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341168</guid>
            <pubDate>Sat, 22 Mar 2025 11:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>worth-calculator —— 计算「这班上得值不值」的开源项目</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;worth-calculator 是一个工作性价比计算器，通过一系列计算公式，计算出我们当前工作的性价比分数，看到底 「值不值得」 上这个（B）班。&lt;/p&gt;

&lt;p&gt;具体能算以下几项信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;nbsp;到手工资: 基于年薪和实际工作天数算出真实日薪。&lt;/li&gt;
&lt;li&gt;时间成本: 上班时长、通勤时间、各种假期都考虑进去了。&lt;/li&gt;
&lt;li&gt;&amp;nbsp;工作环境: 从工位到同事，全方位评估。&lt;/li&gt;
&lt;li&gt;最终结果: 给你一个直观的参考指标。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;结果评判标准：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;😱 低于 1.0：很惨&lt;/li&gt;
&lt;li&gt;😐 1.0-1.8：一般&lt;/li&gt;
&lt;li&gt;😎 1.8-2.5：很爽&lt;/li&gt;
&lt;li&gt;🤩 高于 2.5：爽到爆炸&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;运行效果&lt;/p&gt;

&lt;p&gt;&lt;img height=&quot;3494&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/185439_kGZz_2720166.png&quot; width=&quot;1862&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/185507_bxX6_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/worth-calculator</link>
            <guid isPermaLink="false">https://www.oschina.net/p/worth-calculator</guid>
            <pubDate>Sat, 22 Mar 2025 11:07:00 GMT</pubDate>
        </item>
        <item>
            <title>让 AI 评审代码！Gitee Code MCP 帮你高效完成 PR Review</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;还在为开发写的「屎山」代码发愁？&lt;/p&gt; 
&lt;p&gt;还在为每天 Review 不完的代码苦恼？&lt;/p&gt; 
&lt;p&gt;每次看完代码却不知道怎么评论合适？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;今天马建仓继续带着 Gitee Code MCP 走来了！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;马建仓今天将带你体验 Gitee Code MCP + Cursor 的完整实践流程，并展示 AI 在&lt;code&gt;代码审核&lt;/code&gt;、&lt;code&gt;优化建议&lt;/code&gt;、&lt;code&gt;自动合并&lt;/code&gt;环节的强大能力。&lt;/p&gt; 
&lt;p&gt;把代码托管简单化，把 PR Review 敏捷化，用 Gitee Code MCP 把 PR Review 的烦恼统统搞定！&lt;/p&gt; 
&lt;h1&gt;01 快速上手：配置 Gitee Code MCP&lt;/h1&gt; 
&lt;p&gt;在开始之前，要先拥有属于自己的 Gitee DevOps 旗舰版账号，并创建私人令牌（仅需&lt;code&gt;接口操作&lt;/code&gt;和&lt;code&gt;代码库&lt;/code&gt;、&lt;code&gt;代码组&lt;/code&gt;权限）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182107_e4mQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下载并编译 Gitee Code MCP Server，可选择&lt;code&gt;Docker&lt;/code&gt;或&amp;nbsp;&lt;code&gt;Node&lt;/code&gt;方式运行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker build 编译：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t gitee-mcp:latest -f Dockerfile .&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Npm 安装依赖，使用 node 运行：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;npm install&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 Cursor 中安装使用 MCP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182139_sUUi_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;配置 MCP Server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以 Docker 方式运行 MCP Server：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;mcp_server_gitee&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;docker&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;run&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;--rm&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-i&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-e&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_PERSONAL_ACCESS_TOKEN&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-e&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_API_URL&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;gitee-mcp:latest&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;env&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_PERSONAL_ACCESS_TOKEN&quot;:&amp;nbsp;&quot;个人令牌&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_API_URL&quot;:&amp;nbsp;&quot;http://xxx.gitee.work/api/v8&quot;&amp;nbsp;// V8 接口
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;disabled&quot;:&amp;nbsp;false,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;autoApprove&quot;: []
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以 Node 方式运行 MCP Server：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;gitee_mcp&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;node&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;mcp 代码目录/build/index.js&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;env&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_PERSONAL_ACCESS_TOKEN&quot;:&amp;nbsp;&quot;个人令牌&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_API_URL&quot;:&amp;nbsp;&quot;http://xxx.gitee.work/api/v8&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;出现弹窗后，无需关闭，查看 MCP Server 显示为绿色即为成功运行。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182208_c2r1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;打开新的聊天窗口，设置为 Agent 聊天。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182219_BpD2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;至此环境配置完成，接下来让我们看看 Gitee Code MCP 如何，智能化提升 PR Review 体验。&lt;/p&gt; 
&lt;h1&gt;02 AI 赋能 PR Review：高效应对三大评审场景&lt;/h1&gt; 
&lt;h2&gt;「屎山」代码？快速驳回！&lt;/h2&gt; 
&lt;p&gt;面对团队中堆积如山的 PR，逐个手动检查不仅低效，还可能遗漏关键问题。Gitee Code MCP 可以直接获取代码仓库中的所有待审 PR，快速呈现变更内容，并智能分析代码质量，帮助开发者精准识别可能存在的问题。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;获取代码仓库&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182245_vg10_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这时 Gitee Code MCP 会把想要查的仓库展示出来。如果想知道这个仓库里当前有哪些 PR 没处理的，同样可以让 Gitee Code MCP 列出来：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182259_ahK3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;分析 PR 很累？不用担心，Gitee Code MCP 可以帮你一键 Review：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182317_cprc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;让我们再回到 Gitee Code 上看一看：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182334_8utO_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;神级代码？照样锐评！&lt;/h2&gt; 
&lt;p&gt;即便是经验丰富的开发者，写出了看起来十分完美的代码，也难免在代码优化上有所疏漏。&lt;/p&gt; 
&lt;p&gt;Gitee Code MCP 不仅能识别问题代码，还能提供优化建议，帮助团队提升整体代码质量：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182349_ch25_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们可以在 Gitee Code 的 PR 详情中看到 AI 具体说了什么。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182402_676Y_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;无可挑剔，轻松合并！&lt;/h2&gt; 
&lt;p&gt;当代码通过审核后，Gitee Code MCP 还能，自动执行 PR 合并操作，避免繁琐的人工点击流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182422_7myc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再返回 Gitee Code 查看合并结果：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182435_wt9o_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;至此，我们在 PR Review 时不再需要任何人工的操作，对代码的评审也完全可以交给 Cursor 和 Gitee MCP Server 去做，从此不再需要为代码评审苦恼。&lt;/p&gt; 
&lt;p&gt;除了 PR Review，Gitee Code MCP 还支持 Issue 处理、Commit 追踪、代码仓库管理等完整代码仓库相关 DevOps 流程。现在就去试试，探索 AI 赋能开发的新方式吧！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/340077&quot; target=&quot;news&quot;&gt;写一行代码，用 Cursor + Gitee MCP 实现贪吃蛇游戏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/339785&quot; target=&quot;news&quot;&gt;Gitee MCP Server：让 AI 助手接管繁琐事务，助力 Gitee 专业版研发提效&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338794/gitee-mcp-server&quot; target=&quot;news&quot;&gt;Gitee MCP Server 正式开源：让 AI 助手直连你的代码仓库&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341154</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341154</guid>
            <pubDate>Sat, 22 Mar 2025 10:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 官方详解 V3 模型「小版本」升级，各项能力全面进阶</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;DeepSeek-V3 模型&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/340789/deepseek-v3-0324&quot;&gt;近日进行了更新&lt;/a&gt;&lt;/u&gt;，虽然大家都说更新后的 DeepSeek-V3-0324 强到没边——哪怕叫 DeepSeek V3.5 也不为过，但官方仍低调地称其是「小版本升级」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;486&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/172423_W9Lc_2720166.png&quot; width=&quot;1402&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面是官方针对 DeepSeek-V3-0324 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FXK6ymJL7y0vo_GQXxmpuBA&quot; target=&quot;_blank&quot;&gt;发布的更新说明&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;DeepSeek V3 模型已完成小版本升级，目前版本号 DeepSeek-V3-0324，用户登录官方网页、APP、小程序进入对话界面后，&lt;strong&gt;关闭深度思考&lt;/strong&gt;即可体验。API 接口和使用方式保持不变。&lt;/p&gt; 
&lt;p&gt;如非复杂推理任务，建议使用新版本 V3 模型，即刻享受速度更加流畅、效果全面提升的对话体验。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;模型能力提升一览&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;推理任务表现提高&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;新版 V3 模型借鉴 DeepSeek-R1 模型训练过程中所使用的强化学习技术，大幅提高了在推理类任务上的表现水平，在数学、代码类相关评测集上取得了超过 GPT-4.5 的得分成绩。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;799&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/173130_fEuG_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;新版 V3 模型的百科知识（MMLU-Pro, GPQA）、数学（MATH-500, AIME 2024）和代码任务（LiveCodeBench）表现均有提升&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;前端开发能力增强&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 HTML 等代码前端任务上，新版 V3 模型生成的代码可用性更高，视觉效果也更加美观、富有设计感。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8c268dc1982a47b1d5c1d3960317fb4b7c2.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;动图展示了一个由模型生成的演示多个小球在指定空间范围内运动的 p5.js 程序，包含若干可以调整重力、摩擦力等参数的滑动按钮，并以赛博朋克风格的 HTML 呈现&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;中文写作升级&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在中文写作任务方面，新版 V3 模型基于 R1 的写作水平进行了进一步优化，同时特别提升了中长篇文本创作的内容质量。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1761&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/173210_hnNh_2720166.png&quot; width=&quot;1252&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;中文搜索能力优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;新版 V3 模型可以在联网搜索场景下，对于报告生成类指令输出内容更为详实准确、排版更加清晰美观的结果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ceb41b23b1984968d9c56909a7beb38153.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，新版 V3 模型在&lt;strong&gt;工具调用、角色扮演、&lt;strong&gt;&lt;strong&gt;问答&lt;/strong&gt;&lt;/strong&gt;闲聊&lt;/strong&gt;等方面也得到了一定幅度的能力提升。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;模型开源&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeek-V3-0324 与之前的 DeepSeek-V3 使用同样的 base 模型，仅改进了后训练方法。私有化部署时只需要更新 checkpoint 和 tokenizer_config.json（tool calls 相关变动）。模型参数约 660B，开源版本上下文长度为 128K（网页端、App 和 API 提供 64K 上下文）。&lt;/p&gt; 
&lt;p&gt;V3-0324 模型权重下载请参考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Model Scope:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fdeepseek-ai%2FDeepSeek-V3-0324&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/deepseek-ai/DeepSeek-V3-0324&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Huggingface:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3-0324&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3-0324&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;与 DeepSeek-R1 保持一致，此次我们的开源仓库（包括模型权重）&lt;strong&gt;统一采用 MIT License&lt;/strong&gt;，并允许用户利用模型输出、通过模型蒸馏等方式训练其他模型。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#d35400&quot;&gt;&lt;strong&gt;最后，奉上 DeepSeek V3 最新版的免费体验地址，由模力方舟提供：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;u&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api/packages/1917?model=DeepSeek-V3&amp;amp;package=1917&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api/packages/1917?model=DeepSeek-V3&amp;amp;package=1917&lt;/a&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/103438_ukgv_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;模力方舟的 Serverless API 提供了视频生成、文本生成、视觉模型、图像生成与处理、文档处理 / OCR、自动语音识别、语音合成、特征抽取、代码生成、风控识别十大类共 58 款各领域的顶尖开源模型的在线体验和 API 使用。通过购买模型资源包，即可通过极低的价格即可尽享众多主流模型。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;683&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/103139_wjCp_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341137/deepseek-v3-0324-detail</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341137/deepseek-v3-0324-detail</guid>
            <pubDate>Sat, 22 Mar 2025 09:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>高通在全球三大洲指控 ARM 垄断，芯片架构授权模式面临重构</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;英国芯片设计公司 Arm&amp;nbsp;自被软银收购后，业务模式已经逐渐从基础架构提供商转向完整芯片设计商。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-25%2Fqualcomm-takes-legal-fight-with-arm-to-global-antitrust-agencies&quot; target=&quot;_blank&quot;&gt;彭博社今天援引知情人士的话透露&lt;/a&gt;&lt;/u&gt;，高通已向欧盟委员会、美国联邦贸易委员会（FTC）及韩国公平交易委员会提交机密文件，指控 Arm&amp;nbsp;涉嫌滥用市场支配地位实施反竞争行为。&lt;/p&gt; 
&lt;p&gt;高通是全球最大手机芯片制造商。该公司认为，Arm 通过开放授权模式使业界对其技术形成高度依赖，同时也促成了芯片产业的蓬勃发展。但是，这一充满活力的市场如今正受到威胁，因为 Arm 正通过限制技术访问来推动自身的芯片制造野心，以提高利润。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-378959a9f2407fecd1acaf54103c1824963.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在与监管机构的私下会议和保密文件中，高通指控 Arm 在运营开放授权模式 20 余年后，突然限制技术访问权限，试图通过自研芯片业务提升利润。具体表现为：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;拒绝提供协议范围内的关键技术&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;修改授权条款阻碍客户产品开发&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;利用指令集架构垄断地位挤压下游厂商&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;高通表示，Arm 正「不择手段」提升财务表现，包括终止与部分客户的授权协议、要求芯片厂商签订捆绑协议、强制收取更高专利费。&lt;/p&gt; 
&lt;p&gt;高通认为，Arm 通过开放的许可模式建立了对其技术的严重依赖，这也促进了一个蓬勃发展的芯片产业。高通向全球竞争管理机构表示，由于 Arm 种种限制行为，目前市场正在受到威胁。&lt;/p&gt; 
&lt;p&gt;高通发言人拒绝置评。欧盟委员会、美国 FTC 和韩国公平贸易委员会的发言人也拒绝置评。&lt;/p&gt; 
&lt;p&gt;Arm 方面则表示对胜诉充满信心：「Arm 仍然专注于加强创新，促进竞争，并尊重合同权利和义务。任何关于反竞争行为的指控都不过是高通为了自身竞争利益，不择手段地转移人们对其与我方持续商业纠纷实质的注意力并扩大争端范围的绝望尝试。」&lt;/p&gt; 
&lt;p&gt;阅读更多：&lt;a href=&quot;https://www.oschina.net/news/318231&quot; target=&quot;news&quot;&gt;英伟达、高通等芯片四巨头联手，以新 CPU 架构对抗英特尔、AMD&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341129</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341129</guid>
            <pubDate>Sat, 22 Mar 2025 09:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>蚂蚁数科发布能源电力时序大模型 EnergyTS，预测精度超谷歌、亚马逊</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蚂蚁数科在苏州举办的新能源数字资产社区春季峰会上，宣布正式推出能源电力时序大模型 EnergyTS。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EnergyTS 专为新能源行业定制，在光伏场景测评中，其发电量预测准确率显著超越谷歌（TimesFM-V2.0）和亚马逊 (Chronos-Large) 等国际主流通用时序模型。在 T+1 天预测中，模型的平均绝对误差仅为 0.0233，较谷歌模型提升约 22.4%;在 T+3 天预测中，性能提升更是达到 46.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;206&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e865e9a90be3dc50aca39f98046b6a90b3a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EnergyTS 通过 AI 技术，可精准预测发电量、电力供需情况，有效缓解电价波动、储能调度收益低等关联风险，为行业提供更智能的经营决策支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该模型具备多尺度训练、多模态融合、多任务学习和零样本冷启等优势，可广泛应用于光伏发电、风力发电、储能、微电网、电力交易等多个场景，实现&quot;开箱即用&quot;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蚂蚁数科 CEO 赵闻飙表示，公司致力于解决各行业在 AI 时代的智能化转型问题，未来将在更多领域探索大模型技术与行业实际问题的结合。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341125</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341125</guid>
            <pubDate>Sat, 22 Mar 2025 09:06:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>TensorRT-LLM —— 优化大型语言模型推理的 TensorRT 工具箱</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;TensorRT-LLM 为用户提供了易于使用的 Python API，用于定义大型语言模型（LLM）和构建 TensorRT 引擎，这些引擎包含最先进的优化技术，可在英伟达（NVIDIA）图形处理器上高效执行推理。&lt;/p&gt;

&lt;p&gt;TensorRT-LLM 还包含用于创建执行这些 TensorRT 引擎的 Python 和 C++ 运行时的组件。它还包括一个用于与英伟达 Triton 推理服务器（NVIDIA Triton Inference Server）集成的后端；这是一个为 LLM 提供服务的生产质量系统。使用 TensorRT-LLM 构建的模型可以在多种配置上执行，从单个 GPU 到具有多个 GPU 的多个节点（使用张量并行和/或管道并行）。&lt;/p&gt;

&lt;p&gt;TensorRT-LLM 的 Python API 架构与 PyTorch API 相似。它为用户提供了包含 einsum、softmax、matmul 或 view 等函数的功能模块。层模块捆绑了用于组装 LLM 的有用构件，如 Attention 块、MLP 或整个 Transformer 层。GPTAttention 或 BertAttention 等特定模型组件可在模型模块中找到。&lt;/p&gt;

&lt;p&gt;TensorRT-LLM 预先定义了几种常用模型。它们可以很容易地修改和扩展，以满足客户的需求。可&lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM#Models&quot;&gt;参阅支持型号&lt;/a&gt;列表&amp;nbsp;。&lt;/p&gt;

&lt;p&gt;为了最大限度地提高性能并减少内存占用，TensorRT-LLM 允许使用不同的量化模式来执行模型（具体示例见 &lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM/blob/release/0.5.0/examples/gpt&quot;&gt;&lt;code&gt;examples/gpt&lt;/code&gt;&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;）。TensorRT-LLM 支持 INT4 或 INT8 权重（和 FP16 activations，又称 INT4/INT8 weight-only）以及 SmoothQuant 技术的完整&lt;a href=&quot;https://arxiv.org/abs/2211.10438&quot;&gt;实现&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img height=&quot;284&quot; src=&quot;https://static.oschina.net/uploads/space/2023/1116/164435_jwZL_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/tensorrt-llm</link>
            <guid isPermaLink="false">https://www.oschina.net/p/tensorrt-llm</guid>
            <pubDate>Sat, 22 Mar 2025 08:44:00 GMT</pubDate>
        </item>
        <item>
            <title>萝卜快跑在自贡成立科技公司，含 AI 相关业务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查资料显示，近日，萝卜运力（自贡）科技有限公司成立，法定代表人为毕然，注册资本 100 万人民币。公司由萝卜快跑关联公司萝卜运力（北京）科技有限公司全资持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;313&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a544cf9d0bfa2827963e1b32d87d99f4929.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;经营范围包括软件开发、计算机系统服务、互联网数据服务、数据处理和存储支持服务、人工智能应用软件开发、人工智能基础软件开发等，由萝卜快跑关联公司萝卜运力（北京）科技有限公司全资持股。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341116</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341116</guid>
            <pubDate>Sat, 22 Mar 2025 08:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>华为增资至 409.4 亿，近一年已 3 次增资</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 App 显示，华为技术有限公司近日发生工商变更，注册资本由约 408.4 亿人民币增至约 409.4 亿人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5af3d0d03a8d4183622343df88b625dd7f.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基本信息显示，华为技术有限公司 (曾用名：深圳市华为技术有限公司) ，成立于 1987 年，位于广东省深圳市，由华为投资控股有限公司全资持股。是一家以从事计算机、通信和其他电子设备制造业为主的企业。企业注册资本 4094113.182 万人民币，超过了 100% 的广东省同行，实缴资本 4054113.18 万人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;变更记录表明，该公司近一年已三次增资，前两次分别发生于 2024 年 4 月、2024 年 6 月。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341115</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341115</guid>
            <pubDate>Sat, 22 Mar 2025 08:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Cloudflare 开源 OpenPubkey SSH（OPKSSH），将单点登录集成到 SSH</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Cloudflare 近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fopen-sourcing-openpubkey-ssh-opkssh-integrating-single-sign-on-with-ssh%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;将 OPKSSH（OpenPubkey SSH）代码库捐赠给 Linux 基金会旗下的 OpenPubkey 项目，这意味着开发者现在可通过开源方式实现基於单点登录（SSO）的 SSH 密钥管理。&lt;/p&gt; 
&lt;p&gt;OPKSSH 通过将 OpenID Connect（OIDC）协议与 SSH 协议无缝结合，使企业能够利用现有身份提供商（如 Google、Azure AD）直接管理 SSH 访问权限，彻底告别手动配置 SSH 密钥的时代。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-609a9940408bc6b0fe8a976760b572a27f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OPKSSH 基于 OpenPubkey 协议，该协议通过在 OIDC 的 ID Token 中嵌入用户公钥，生成名为「PK Token」的短期证书。当用户执行&lt;code&gt;opkssh login&lt;/code&gt;时，流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;生成临时 SSH 密钥对（默认有效期 24 小时）；&lt;/li&gt; 
 &lt;li&gt;通过浏览器跳转完成 OIDC 认证，获取包含公钥的 PK Token；&lt;/li&gt; 
 &lt;li&gt;将 PK Token 写入本地 SSH 公钥文件，私钥仅存于内存。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;服务器端只需在 SSH 配置中添加两行验证逻辑（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenpubkey%2Fopenpubkey&quot; target=&quot;_blank&quot;&gt;示例代码&lt;/a&gt;），即可将传统 SSH 公钥验证替换为 PK Token 验证。该方案兼容任何 OIDC 提供商，且无需修改 SSH 协议栈。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OPKSSH&amp;nbsp;三大核心优势&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全性跃升&lt;/strong&gt;：临时密钥自动过期，消除长期密钥泄露风险。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;运维简化&lt;/strong&gt;：管理员通过邮件地址管理权限（如&lt;code&gt;authorized_emails&lt;/code&gt;文件），无需跟踪密钥指纹。用户可在任意设备通过&lt;code&gt;opkssh login&lt;/code&gt;生成密钥，彻底解决密钥分发难题。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;审计透明化&lt;/strong&gt;：所有 SSH 登录事件均关联 OIDC 身份信息，天然支持 SIEM 系统集成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;适用场景与迁移成本&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OPKSSH 适用于已部署 OIDC 的企业环境，尤其是需严格管控云服务器或 CI/CD 系统访问权限的场景。迁移仅需：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在目标服务器运行安装脚本（&lt;code&gt;curl -sSfL https://install.opkssh.dev | sh&lt;/code&gt;）；&lt;/li&gt; 
 &lt;li&gt;在身份提供商注册 OPKSSH 客户端 ID。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;OpenPubkey SSH（OPKSSH）采用 Apache 2.0 许可证，开源地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenpubkey%2Fopkssh&quot; target=&quot;_blank&quot;&gt;https://github.com/openpubkey/opkssh&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341113/cloudflare-open-sourcing-openpubkey</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341113/cloudflare-open-sourcing-openpubkey</guid>
            <pubDate>Sat, 22 Mar 2025 08:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>昆仑万维发布全球首款音乐推理大模型 Mureka O1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;昆仑万维宣布&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1JPYXUwX-1JAVpz3IgygtQ&quot; target=&quot;_blank&quot;&gt;推出&lt;/a&gt; Mureka O1 模型与 Mureka V6 模型。「Mureka O1 作为全球首款音乐推理大模型，性能超越 Suno、模型登顶 SOTA，中国科技创新再次在 AI 音乐领域领跑全球。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 4 月，昆仑万维发布了第一代音乐生成模型：Mureka V1（SkyMusic）。Mureka V6 是当前 Mureka 的基座模型，支持纯音乐生成，还支持 10 种语言的 AI 音乐创作，包括英语、中文、日语、韩语、法语、西班牙语、葡萄牙语、德语、意大利语和俄语。在 Mureka V6 中，团队引入自研 ICL（in-context learning）技术，使得声场更加开阔，人声质感和混音设计进一步强化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;270&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eb6a0135a337596b6a6a105f75b95b34fb8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mureka O1 模型是基于 Mureka V6 思维链的推理优化版本，也是全球范围内首个引入 CoT 的音乐模型，在推理过程中加入思考与自我批判，大幅提升音乐品质、音乐创作效率和灵活性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mureka V6 和 O1 模式支持多元化的音乐创作风格及情感表达。曲风涵盖爵士 (Jazz)、电子 (Electronic)、流行 (Pop)、乡村 (Country)、节奏布鲁斯 (R&amp;amp;B)、灵魂乐 (Soul)、蓝调 (Blues)、摇滚 (Rock)、舞曲 (Dance) 等；情感维度包括快乐、放纵、神秘、充满活力、悲伤等多种情绪表达。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，Mureka 还提供两个特色音乐生成功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;歌曲参考（Reference Fuction）：将音乐本身作为提示，用户可直接上传音频或 Youtube 链接作为创作提示，比文本提示更直接更高级的提示方式；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;音色克隆（Vocal Fuction）：Mureka 是全球首个可以指定演唱歌手音色的 AI 音乐生成平台，用户不仅可以选择官方提供的多种歌手音色，还可以上传自己的声音，让 AI 学习并复刻，精准模拟歌手音色，一键生成个性化专属作品。自定义歌手音色的功能宣告人人都能成为 AI 歌手的时代正式到来了。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mureka O1 中包含了 Mureka 团队最新发布的音乐生成领域的创新研究成果——MusiCoT。根据介绍，MusiCoT 利用了思维链 Chain-of-Thought （CoT）方法，不同于传统自回归模型逐步生成音频，MusiCoT 首次在细粒度音频 token 预测前预生成整体音乐结构，大幅提升生成音乐的结构连贯性与乐器编排精准度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MusiCoT 基于 CLAP 模型，无需人工标注即具备高扩展性，并显著提高了生成音乐的可解释性和质量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于首次在音乐生成领域引入 Chain-of-Thought（CoT）技术、算法框架的升级，Mureka O1 不仅保持了低延迟音乐生成，还显著提升了歌词旋律契合度、演唱准确性和艺术表现力等，多项指标领先于 Suno V4。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;294&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-503e30956b12803e771c5937b2b29cdd12d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cbf0a6f76c773afe0506002d7f11fe7135c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-82ca85f7fa60597b44ceaddec62bfe1e73c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;330&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-051e429a4d3e0dc2eb7a98978f95ef96f3c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341110</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341110</guid>
            <pubDate>Sat, 22 Mar 2025 08:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>