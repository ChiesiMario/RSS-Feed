<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 18 Sep 2025 12:43:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>法国 AI 公司 H Company 开源 Holo1.5 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;法国 AI 公司 H Company 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.hcompany.ai%2Fblog%2Fholo-1-5" target="_blank"&gt;发布并开源&lt;/a&gt;了 Holo1.5 系列视觉语言模型，该系列专为 Computer Use (CU) Agent 设计。&lt;/p&gt; 
&lt;p&gt;新系列在 UI 元素定位与界面问答任务上全面超越了前代 Holo1，平均准确率提升超过 10%，并在 Web、桌面、移动跨平台基准测试中刷新了开源模型的纪录。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-219e3deebf5dcddb8a7f01c5f6247a79289.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0fd9afd5fa18f87cdbae72ae07c86ca4b28.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Holo1.5 基于 Qwen2.5-VL 基座模型，采用高分辨率原生输入（最高支持 3840×2160），通过大规模监督微调与在线强化学习（GRPO）两阶段进行训练，融合了开源数据、合成数据与人工标注数据。&lt;/p&gt; 
&lt;p&gt;该系列提供了三种不同规模的模型，并采用不同的开源许可：&lt;/p&gt; 
&lt;p&gt;模型规模&amp;nbsp;&amp;nbsp; &amp;nbsp;开源许可&amp;nbsp;&amp;nbsp; &amp;nbsp;商业用途&lt;br&gt; 3B&amp;nbsp;&amp;nbsp; &amp;nbsp;Qwen 许可&amp;nbsp;&amp;nbsp; &amp;nbsp;遵循原许可&lt;br&gt; 7B&amp;nbsp;&amp;nbsp; &amp;nbsp;Apache 2.0&amp;nbsp;&amp;nbsp; &amp;nbsp;完全开放&lt;br&gt; 72B&amp;nbsp;&amp;nbsp; &amp;nbsp;仅限学术研究&amp;nbsp;&amp;nbsp; &amp;nbsp;需单独授权&lt;/p&gt; 
&lt;p&gt;目前，模型已上线 HuggingFace，提供了开放权重、演示空间与本地推理脚本，支持开发者构建能够操纵真实应用的 CU Agent。H Company 表示，未来数周还将发布基于 Holo 系列的新工具与完整的 Agent 方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373033</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373033</guid>
      <pubDate>Thu, 18 Sep 2025 11:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>《Anthropic 经济指数》报告发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fresearch%2Feconomic-index-geography" target="_blank"&gt;发布&lt;/a&gt;了《Anthropic Economic Index》报告，首次披露了美国及全球 AI 使用的地理图谱。该报告基于 2024 年 12 月至 2025 年 8 月期间 Claude.ai 的匿名对话与 API 调用记录，并同步上线了交互式数据网站与开放数据集。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-71f68a68f3af83a15c28e454af5f36a1ea8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;报告显示，AI 的使用在地域、行业和模式上存在明显差异。计算机与数学任务仍占据核心地位（37–40%），教育与科研类任务显著增长，而管理运营类任务则有所下降。&lt;/p&gt; 
&lt;p&gt;值得注意的是，自动化对话的占比首次超过了增强协作（49.1% vs 47%），其中企业用户更倾向于自动化（77%），而消费者则维持均衡。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-26aabfe98a2ed7cc7ad59939d8557ae367f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;研究还发现，高收入和知识密集型地区更早采用 AI。企业更看重 AI 能力带来的价值而非成本，这预示着劳动力市场可能将迎来深度调整。&lt;/p&gt; 
&lt;p&gt;报告附带的开放数据与交互网站可供公众查询使用：&lt;em&gt;https://huggingface.co/datasets/Anthropic/EconomicIndex&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373030/anthropic-economic-index-geography</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373030/anthropic-economic-index-geography</guid>
      <pubDate>Thu, 18 Sep 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>法国 AI 公司 Mistral 开源推理模型 Magistral Small 1.2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;法国 AI 公司&amp;nbsp;Mistral AI&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmistralai%2FMagistral-Small-2509" target="_blank"&gt;&amp;nbsp;推出&lt;/a&gt;了 Magistral 系列最新的开源推理模型 Magistral Small 1.2。该模型拥有 24B 参数，采用 Apache 2.0 许可，支持 128k 上下文、多语言及视觉输入，并引入了创新的 [THINK]...[/THINK] 特殊 token 以包裹推理过程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0918/191800_wOvi_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相比 1.1 版，新版本增加了视觉编码器，并引入了 [THINK]...[/THINK] 特殊 token 来包裹模型的推理过程。系统提示中内置了推理模板，支持 vLLM、Transformers、llama.cpp 等框架即开即用，同时提供了 GGUF 量化版本与 Unsloth 微调示例。&lt;/p&gt; 
&lt;p&gt;企业版 Magistral Medium 1.2 也同步升级，继续通过 Le Chat 提供对话服务，其 API 已上线 La Plateforme 平台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373029</guid>
      <pubDate>Thu, 18 Sep 2025 11:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>快手旗下可灵 AI 数字人上线公测</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手旗下可灵 AI 数字人已于近日上线公测。该功能通过多模态技术，实现了从「对口型」到「会表演」的突破，支持用户上传图片或音频，生成 1080p/48fps、最长 1 分钟的数字人视频，具备精准口型同步、情绪动作控制、多角色同屏等功能，且支持中、英、日、韩等多语种。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-07ea3d588b535e3ffb9b60946dce753e6fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可通过可灵 AI 官网（https://app.klingai.com/cn/）体验，目前处于逐步放量阶段。&lt;/p&gt; 
&lt;p&gt;据了解，可灵 AI 数字人基于多模态理解与视频生成模型的深度结合，实现了口型精准同步以及情绪动作的精细控制。其采用的基于 Transformer 的 DiT 架构，在处理时序信息和细粒度控制方面具有独特优势，能够精准解析面部特征、理解音频语义，并根据语音内容推断合适的面部表情和微动作，从而确保生成的数字人在视频全程保持角色一致性。&lt;/p&gt; 
&lt;p&gt;在角色和语言支持方面，可灵 AI 数字人功能表现出色。其支持多种角色类型，包括真人、动画角色甚至动物形象，同时涵盖中、英、日、韩等多语种，能够满足不同用户的多样化需求。在价格策略上，结合会员优惠，可灵 AI 数字人的使用成本最低为 0.12 元 / 秒。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373025</guid>
      <pubDate>Thu, 18 Sep 2025 11:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软 Visual Studio Code 引入自动 AI 模型选择功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软正在为其 Visual Studio Code 编辑器引入自动 AI 模型选择功能，将根据「最佳性能」自动挑选 AI 模型。&lt;/p&gt; 
&lt;p&gt;此功能会在 GitHub Copilot 免费用户之间切换 Claude Sonnet 4、GPT-5、GPT-5 mini 及其他模型，而付费用户则「主要依赖 Claude Sonnet 4」模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fb40cb72cb7f78b338a2a8465189b5e88b5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一变化实际上表明，微软在编程和开发领域比起 OpenAI 最新的 GPT-5 模型，更倾向于使用 Anthropic 的 AI 模型。据熟悉微软开发业务的消息人士透露，微软近几个月来也在内部要求开发人员优先使用 Claude Sonnet 4。&lt;/p&gt; 
&lt;p&gt;微软开发者事业部负责人 Julia Liuson 在今年 6 月的一封内部邮件中曾表示：「根据内部基准测试，Claude Sonnet 4 是我们为 GitHub Copilot 推荐的模型。」而这一指导意见是在 GPT-5 发布之前提出的，据悉，目前微软对此的推荐依然没有改变。&lt;/p&gt; 
&lt;p&gt;微软方面还表示，公司正对自家 AI 模型的训练进行「重大投入」。微软 AI 业务负责人 Mustafa Suleyman 在上周的一场员工专属会议上提到：「我们也将在自有集群上做重大投资。目前 MAI-1-preview 仅使用了 1.5 万张 H100 显卡进行训练，从整体规模看还非常小。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373021</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373021</guid>
      <pubDate>Thu, 18 Sep 2025 10:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>发展大模型要摒弃短视冒进</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;一段时间以来，关于 DeepSeek 的消息层出不穷，下载量大跌、用户规模缩减……引发社会上一些对其发展前景和技术路线的质疑。然而，这背后折射出的是对大模型发展规律认知的偏差。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在人工智能时代，大模型的价值绝非简单以使用率和流量来评判，而是依托于技术沉淀的厚度以及生态协作的深度，对技术的极致追求与秉持战略耐心，才是立足大模型时代的关键所在。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从「流量为王」到「技术制胜」，人工智能时代的逻辑已发生转变。互联网时代的产品竞争遵循「快鱼吃慢鱼」法则——由于技术代差较小，抢占用户注意力、积累流量池成为决胜关键，「使用率」标准应运而生。就像一款社交软件可能凭借界面优化或运营活动在短时间内吸引百万用户，即便功能尚未完善，也能通过快速迭代留住他们。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;但大模型竞争截然不同。这是硬科技的角力场，技术指标和模型性能是实打实的，即使用户数多，如果性能不过硬，也会在技术竞争浪潮中掉队。以 DeepSeek-R1 为例，其发布之初使用率的飙增，根源在于算法架构的创新与训练数据的深度优化，而非依赖用户规模。大模型的价值如同精密仪器，参数精度、响应速度、多模态能力等硬指标才是衡量其竞争力的核心要素。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从「流量垄断」到「生态赋能」，底层思维也有了变化。当人们将目光聚焦使用率时，却忽视了其作为 AI 应用底层生态的深远战略价值。如今，阿里云、腾讯云等云服务商，诸多搜索平台、智能终端以及行业应用，还有广大用户群体，都不同程度接入 DeepSeek，形成庞大生态网络。这得益于 DeepSeek 开放 API 接口与训练框架，不搞流量分成或数据垄断，让开发者能快速构建垂直领域应用，实现多方共赢，众多 AI 应用也得以大量涌现，走进各行各业。本质上，DeepSeek 打造的是人工智能时代的「高速公路」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从「单点突破」到「系统攻坚」，大模型跨越式发展的条件正日趋成熟。DeepSeek-R2 酝酿之际，其团队已在论文中阐述下一代人工智能系统的创新蓝图——「模型+硬件」的协同优化设计，意味着大模型发展不再单纯依靠算力堆砌或算法单一创新，而是软硬件并行研发的「集团军作战」。当下，像华为升腾 384 超节点、上海 AILab 系统平台的相关突破，都为大模型新发展筑牢了基础，也让我们坚信下一代人工智能系统的推出只是时间问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;互联网思维碰上人工智能时代，「流量焦虑」「爆款心态」已成创新枷锁。在这个算力成本高昂、技术迭代迅速、计算量极大的时代，急功近利的冒进易引发系统性风险。唯有摒弃短视观念，专注技术深耕与生态共建，才能在这场关乎国家竞争力的科技竞赛中取得最终胜利。（经济日报，钟梓滨）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373019</guid>
      <pubDate>Thu, 18 Sep 2025 10:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>华为公布升腾 AI 芯片三年发展路线图，明年 Q1 推出 Ascend 950PR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在华为全联接大会 2025 上，华为副董事长、轮值董事长徐直军登台发表演讲，首次对外公布了升腾 AI 芯片未来三年的产品迭代路线图，同时明确表示 2026 年一季度发布的新产品将采用华为自研 HBM（高带宽内存）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/182257_S72G_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时他还分享了升腾芯片的后续规划：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ascend 950PR：2026 年 Q1&lt;/li&gt; 
 &lt;li&gt;Ascend 950DT：2026 年 Q4&lt;/li&gt; 
 &lt;li&gt;Ascend 960：2027 年 Q4&lt;/li&gt; 
 &lt;li&gt;Ascend 970：2028 年 Q4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其中，950 芯片采用华为自研 HBM，新增支持低精度数据格式、提升向量算力、提升互联带宽 2.5 倍。&lt;/p&gt; 
&lt;p&gt;据报道，华为 Ascend 910C 在今年一季度量产，将两颗升腾 910B 芯片通过先进封装技术整合在一起，采用相对成熟的封装方案，在性能和成本间做了平衡。其 FP16 精度算力约 800 TFLOPS，内存带宽约 3.2 TB/s，性能大概能达到 NVIDIA H100 的 80%。&lt;/p&gt; 
&lt;p&gt;据悉，阿里巴巴、百度、腾讯等互联网巨头都是 Ascend 910C 的首批客户，他们过往都采购了大量的 NVIDIA GPU 加速器，华为升腾对 NVIDIA 造成了巨大冲击。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373016</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373016</guid>
      <pubDate>Thu, 18 Sep 2025 10:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Brush - 人人皆可进行 3D 重建</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 是一个使用高斯分布的 3D 重建引擎。它适用于多种系统：macOS/windows/linux、AMD/Nvidia/Intel 显卡、Android 以及浏览器。为此，它使用了 WebGPU 兼容技术和&amp;nbsp;&lt;a href="https://github.com/tracel-ai/burn"&gt;Burn&lt;/a&gt;&amp;nbsp;机器学习框架。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器学习在实时渲染方面潜力巨大，但大多数机器学习工具都无法很好地支持它：渲染需要实时交互，通常涉及动态形状和计算，无法在大多数平台上运行，而且发布包含大量 CUDA 依赖的应用程序会非常繁琐。而 Brush 则能生成简单的无依赖二进制文件，几乎可以在所有设备上运行，无需任何设置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://arthurbrussee.github.io/brush-demo"&gt;试用网页演示版&amp;nbsp;&lt;/a&gt;（注意：仅适用于 Chrome 和 Edge。）&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 接收 COLMAP 数据或 Nerfstudio 格式的数据集。训练在移动设备和浏览器中均得到原生支持。训练期间，您可以与场景互动，实时查看训练动态，并在训练过程中将当前渲染与输入视图进行比较。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;它还支持遮罩图像：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;具有透明度的图像。这将强制最终的 splat 与输入的透明度匹配。&lt;/li&gt;
&lt;li&gt;一个名为「masks」的图像文件夹。这会忽略图像中被遮罩的部分。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 也可用作 splat &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;viewer&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，包括在 Web 上。它可以加载 .ply 和 .compressed.ply 文件。您可以从 URL 中流式传输数据（对于 Web 应用，只需在 URL 后附加&lt;code&gt;?url=&lt;/code&gt;）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 还可以加载 splat 文件的 .zip 以将其显示为动画，或包含增量帧的特殊层（参见&lt;a href="https://cat-4d.github.io/"&gt;cat-4D&lt;/a&gt;和&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://felixtaubner.github.io/cap4d/"&gt;Cap4D&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;!&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 可以用作命令行界面 (CLI)。运行&lt;code&gt;brush --help&lt;/code&gt;即可查看概览。所有命令行命令均可配合&lt;code&gt;--with-viewer&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用，并可打开用户界面 (UI)，方便调试。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/brush</link>
      <guid isPermaLink="false">https://www.oschina.net/p/brush</guid>
      <pubDate>Thu, 18 Sep 2025 10:08:00 GMT</pubDate>
    </item>
    <item>
      <title>用 Python 代码给微信「去重瘦身」？工程师回应：非常粗暴，可能导致文件打不开</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日有网友分享了一段能帮助微信「去重瘦身」的 Python 代码，专门针对微信「每一次转发都会重新保存一份」的情况，删除重复的文件，称能搞定微信这个易胖体质。&lt;/p&gt; 
&lt;p&gt;微信员工 @客村小蒋，今日转发了该消息，并表示「非常不建议这么做，没用，而且可能带来不好的后果」。&lt;/p&gt; 
&lt;p&gt;1）微信并没有对多次转发的同一个文件重复存储，电脑里看到的同文件名加 (1)、(2)，是硬链接，实际只有一份真实存储；&lt;/p&gt; 
&lt;p&gt;2）这里的代码，是通过名字重复来判断，非常粗暴，删除之后，可能导致原来消息打不开，还存在误删可能性&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-19b42cb87229a8efd6ceef9f6b84997cea4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373013</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373013</guid>
      <pubDate>Thu, 18 Sep 2025 10:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度 PaddleOCR 累计下载量突破 900 万，被超 5.9k 开源项目使用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日，百度在海外官方账号介绍了最新轻量级文字识别模型 PP-OCRv5。该模型仅 0.07B 参数，以千分之一参数量实现与 700 亿参数大模型相媲美的 OCR 精度。在多项 OCR 场景测试中，PP-OCRv5 的表现超越 GPT-4o、Qwen2.5-VL-72B 等通用视觉大模型。最新信息显示，飞桨团队发布的技术 Blog 已连续一周登顶 Hugging Face 博客热度榜首，受到开发者社区的广泛关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;img height="1576" src="https://static.oschina.net/uploads/space/2025/0918/173354_EC7R_3820517.png" width="1580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;据了解，2025 年 5 月，飞桨团队推出 PaddleOCR 3.0 版本，文字识别方案 PP-OCRv5 与通用文档解析方案 PP-StructureV3，以及原生支持文心大模型 4.5 的智能文档理解方案 PP-ChatOCRv4 共同构成其三大特色能力。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;自 2020 年开源以来，PaddleOCR 累计下载量突破 900 万，被超过 5.9k 开源项目直接或间接使用，是 GitHub 社区中唯一一个 Star 数超过 50k 的中国 OCR 项目。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;img height="998" src="https://static.oschina.net/uploads/space/2025/0918/173417_2NkS_3820517.png" width="1516" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373008/paddleocr-news-59k-star</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373008/paddleocr-news-59k-star</guid>
      <pubDate>Thu, 18 Sep 2025 09:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中文互联网基础语料 3.0 发布，数据量高达 120GB</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中文互联网基础语料 3.0 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcorpus.cybersac.cn%2F%3Fhome%23%2FdataSetDetail%3FdataSetId%3D399" target="_blank"&gt;发布&lt;/a&gt;。这一新版本的数据量达到了惊人的 120GB，旨在为大模型训练和人工智能的进一步发展提供可靠的数据支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中文互联网基础语料 3.0 的发布，是在中央网信办的指导下，由中国网络空间安全协会与国家互联网应急中心等单位协同合作的成果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="217" src="https://oscimg.oschina.net/oscnet/up-54c09b578c1c75e35f0d48e63448b668c10.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此次语料的开发与构建，得益于企业、高校和科研单位之间的紧密合作，充分利用了网安协会人工智能安全治理专委会建立的语料共建共享机制。与前两版相比，3.0 版本在信源范围上进行了扩大，进一步提升了数据的质量。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在数据处理方面，语料 3.0 经过了严格的信源筛选、内容过滤和数据去重等一系列细致的加工处理措施。这些措施确保了发布的数据更加可信，有助于过滤掉违法和不良信息，为人工智能的研究和应用提供一个更为健康的环境。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;用户可以通过登录中国网络空间安全协会网站，点击 「中文互联网语料资源平台」 链接，注册并认证后下载相关语料。该负责人表示，中文互联网基础语料 3.0 的推出标志着各界对高质量中文语料的共同努力与成果，未来还将继续加强中文互联网基础语料的建设，以支撑人工智能技术的创新与产业发展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373007</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373007</guid>
      <pubDate>Thu, 18 Sep 2025 09:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>工信部通报：29 款 APP 存在侵害用户权益行为</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工信部发布「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCCItP6cdGEq05uzR4zQwsA" target="_blank"&gt;关于侵害用户权益行为的 APP 通报（2025 年第 5 批，总第 50 批）&lt;/a&gt;」指出，近期，经组织第三方检测机构进行抽查，共发现 29 款 APP 存在侵害用户权益行为，现予以通报。上述 APP 应按有关规定进行整改，整改落实不到位的，将依法依规组织开展相关处置工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;附件：工业和信息化部通报存在问题的 APP 名单&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;img alt="" height="1200" src="https://oscimg.oschina.net/oscnet/up-7ac3883f810c1bcd70bae9b44ea0e5a6a00.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372997</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372997</guid>
      <pubDate>Thu, 18 Sep 2025 09:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 数据标注团队大幅裁员，休学大学生临危接管核心业务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fafrica.businessinsider.com%2Fnews%2Felon-musks-xai-put-a-college-student-in-charge-of-the-team-training-grok-amid%2Fj80f9tm" target="_blank"&gt;根据 Business Insider 的报道&lt;/a&gt;，xAI 正在经历人事变动。9 月以来，埃隆・马斯克旗下 AI 公司 xAI 的 Grok 训练数据标注团队经历重大人事震荡：上周至少 9 名高管被停用 Slack 账号，&lt;a href="https://www.oschina.net/news/372229" target="_blank"&gt;9 月 12 日超 500 名员工遭裁员&lt;/a&gt;，团队规模从 1500 人锐减至约 900 人。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0918/170155_oEAu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;年仅 21 岁、仍处于大学休学状态的 Diego Pasini 于 1 月通过黑客马拉松加入 xAI，如今临危受命接管该团队。这位 2023 年高中毕业生在 9 月 15 日全员会议中承诺停止裁员，但随后又有超 100 人被解雇。目前其团队正开展一对一工作汇报，并通过测试重新定岗。&lt;/p&gt; 
&lt;p&gt;Pasini 的任命引发内部争议：有员工质疑其资历，相关发言在数小时内被停用账号。据悉，他曾就读于宾夕法尼亚大学计算机科学专业，在机器人领域有研究经历，9 月初获马斯克关注。此次人事调整凸显 xAI 在快速扩张中面临的管理挑战，也折射出马斯克对年轻技术人才的破格任用策略。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372995</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372995</guid>
      <pubDate>Thu, 18 Sep 2025 09:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>透视 AI「魔改」视频争议：创意还是恶搞？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;（新华社）唐僧和孙悟空争当「话事人」、《甄嬛传》变成「枪战片」、《人民的名义》中沙瑞金和高育良开展魔法攻击……近段时间，一些 AI「魔改」内容在短视频平台上引发争议。&lt;/p&gt; 
&lt;p&gt;所谓 AI「魔改」，是指利用人工智能技术对原作品进行颠覆性改编的行为，常见于短视频、视觉创作等领域。&lt;/p&gt; 
&lt;p&gt;AI「魔改」是创意还是恶搞？边界到底在哪儿？如何更好规范治理，让 AI 技术更多「赋能」而非「跑偏」？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;备受争议的「魔改」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「家人们，看着五指山压的是谁？如来老儿。当年压我 500 年，现在必须压他 1000 年。」孙悟空手举相机「现场直播」，在他身后，如来佛祖被压在山下……&lt;/p&gt; 
&lt;p&gt;看着短视频平台推送的内容，青海西宁市民李女士着实吓了一跳。「我和孩子一起刷短视频，看到这个视频画面流畅、人物说话嘴型丝毫不差，不仔细分辨，还以为是电视剧原有的画面。」&lt;/p&gt; 
&lt;p&gt;随着 AI 技术普及，一些视频博主将其变成猎取流量的工具，选取电视剧经典片段，剪辑成天马行空的剧情，以猎奇的画面、夸张的台词激发观众兴趣。&lt;/p&gt; 
&lt;p&gt;在一些短视频平台上，此类「魔改」短视频数据火爆，有的点赞量高达数万。部分账号起号半个多月，粉丝就已涨到 10 万多。不少做此类内容的账号，还会在视频里推荐 AI 网站、卖课，通过接广告商单、知识变现、创作者分成计划等方式获取收益。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI「魔改」究竟是创意还是恶搞？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;部分公众认为，一些「魔改」视频新奇好玩，是创意表达；但也有人强调，经典承载文化记忆，娱乐化改编应有底线。一些「魔改」行为未经授权，破坏了原作品的完整性和艺术价值，一代观众的集体记忆也有可能变得混沌。&lt;/p&gt; 
&lt;p&gt;「我家孩子只有 12 岁，正处于价值观建立的关键期，看太多这类视频，三观容易被带偏。」李女士说。兰州大学新闻与传播学院副教授谭泽明认为，AI「魔改」视频制造大量非真实信息，加剧了信息茧房效应。&lt;/p&gt; 
&lt;p&gt;有青年剧作家认为，影视经典既是一代人的共同记忆，也是文化传承的载体。如果《三国演义》张飞等人物形象被肆意扭曲，甚至被「魔改」成与原著精神内核相悖的形象，是对经典的亵渎。&lt;/p&gt; 
&lt;p&gt;2025 年 4 月，浙江省高级人民法院公布一起「奥特曼形象 AI 生成侵权案」。浙江省杭州市中级人民法院审理认为，AI 的发展导致可能出现针对经典 IP 进行「魔改」的不良行为，过度或不当的「魔改」可能扭曲历史记忆、文化遗产以及社会共识。&lt;/p&gt; 
&lt;p&gt;2024 年 12 月，国家广播电视总局网络视听节目管理司也发布管理提示指出，AI「魔改」视频为博流量，毫无边界亵渎经典 IP，冲击传统文化认知，与原著精神内核相悖，且涉嫌构成侵权行为。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;走热背后：门槛低、获利高&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;利用 AI 技术改编生成内容的技术门槛和经济成本并不高。记者试用多款软件发现，AI 视频剪辑可以通过文本描述内容、上传图片与视频等多种方式生成。&lt;/p&gt; 
&lt;p&gt;随机打开一款 AI 生成软件，根据提示内容输入「根据西游记形象，让孙悟空和唐僧持枪互相攻击」，在「对口型」中选择「猴哥」……数十秒后，一条视频便生成出来。内容不仅流畅生动，人物形象和声音也与电视剧版无异。&lt;/p&gt; 
&lt;p&gt;此类 AI 生成软件大多需要付费，会员费用从几十元到一两百元不等。&lt;/p&gt; 
&lt;p&gt;记者看到，一款 AI 生成软件花费 129 元就能成为永久会员，可解锁文生视频、图生视频、AI 绘画等功能。另一款应用只需 98 元就可成为永久会员，同样有口播视频、图生视频、照片跳舞等功能，已有一百余万次下载。&lt;/p&gt; 
&lt;p&gt;谭泽明认为，AI「魔改」频发背后，既有人工智能技术驱动的因素，也有平台算法的隐蔽驱动。&lt;/p&gt; 
&lt;p&gt;业内人士告诉记者，AI「魔改」视频会给发布者带来流量曝光、粉丝增长、广告收入等效益。&lt;/p&gt; 
&lt;p&gt;一名博主在短视频平台发布了一条唐僧唱歌的 AI 视频，斩获近 200 万次转赞评，粉丝量迅速突破 32 万。「相比辛辛苦苦做原创，AI 改编的视频流量会大很多，粉丝转化率也高出好几倍。」一名短视频博主透露说，一些短视频平台推出 AIGC 内容激励计划，进一步提升了博主的创作热情。&lt;/p&gt; 
&lt;p&gt;记者调查发现，短视频平台上还有不少以「投入低回报高」「低成本开副业」「不上班在家做视频就能赚钱」为噱头的博主，宣传提供 AI 生成视频、AI 短剧制作相关培训，「短时间就能上手，少则几分钟、多则三小时即可成片，月薪一万起步」。&lt;/p&gt; 
&lt;p&gt;根据著作权法规定，未经著作权人许可，以改编、翻译、注释等方式使用作品的构成侵权行为。「不少 AI‘魔改’视频的目的是为引流赚钱，已超出‘合理使用’范畴。」青海师范大学法学与社会学学院院长马旭东教授说。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何加强治理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;针对 AI「魔改」乱象，国家广播电视总局网络视听节目管理司督促短视频平台排查清理 AI「魔改」影视剧的短视频，并要求对在平台上使用、传播的各类相关技术产品严格准入和监管，对 AI 生成内容做出显著提示。&lt;/p&gt; 
&lt;p&gt;记者调查发现，相较之前，短视频平台 AI「魔改」现象有一定改善。&lt;/p&gt; 
&lt;p&gt;抖音相继发布《关于人工智能生成内容的平台规范暨行业倡议》《关于不当利用 AI 生成虚拟人物的治理公告》，明确表示不鼓励利用 AI 生成虚拟人物开展低质创作活动。在平台内相关视频下方会明确注明「作者声明：内容由 AI 生成」。&lt;/p&gt; 
&lt;p&gt;「流量思维驱动下，相关治理工作不可能一蹴而就。」谭泽明认为，针对利用 AI「魔改」博取流量现象，短视频平台应切实承担起把关责任，对于涉及侵权甚至包含暴力、低俗恶搞等元素的不良内容进行限流或下架、封号。&lt;/p&gt; 
&lt;p&gt;「既不能阻断创作内容的创新，也要对相关著作权人的权利进行保护。」马旭东建议，相关行业协会也应发挥建设性作用，加强网络公益宣传，不断提高用户的媒介素养和对 AI 相关产品使用的法律意识；同时引导短视频平台技术向善，推出更多优质、健康的内容。&lt;/p&gt; 
&lt;p&gt;清华大学新闻与传播学院教授沈阳说，鉴于 AI 技术的复杂性和应用的广泛性，AI 治理需要实现跨领域的协同。例如，AI 生成音视频内容时，可与身份验证、行为分析等技术共同协作，以增强 AI 应用的合规性。科技公司、法律监管部门和伦理委员会等共同组成「技术共治联盟」，制定更全面、细化的治理准则。&lt;/p&gt; 
&lt;p&gt;中国政法大学传播法研究中心副主任朱巍认为，在 AI 技术飞速发展的今天，更需明确创新边界，重视知识产权保护，注重审美培育和文化尊重，让 AI 技术成为推动文化发展的新动力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372991</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372991</guid>
      <pubDate>Thu, 18 Sep 2025 08:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>2024 年全社会研发投入超 3.6 万亿元，较 2020 年增长 48%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;国务院新闻办公室今天（9 月 18 日）下午举行 「高质量完成‘十四五’规划」系列主题新闻发布会，科技部负责人介绍「十四五」时期科技创新发展成就。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据介绍，「十四五」时期，我国科技投入持续增加，2024 年全社会研发投入超 3.6 万亿元，较 2020 年增长 48%；研发投入强度达到 2.68%，超过欧盟国家平均水平；研发人员总量世界第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基础研究水平进一步提升。基础研究经费达 2497 亿元，较 2020 年增长超 70%，在量子科技、生命科学、物质科学、空间科学等领域取得一批重大原创成果，高水平国际期刊论文数量和国际专利申请量连续 5 年世界第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;国家战略科技力量不断壮大。国家实验室体系建设稳步推进，国家科研机构、高水平研究型大学科研能力不断提升，科技领军企业加快培育成长。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;区域科技创新呈现良好态势。北京、上海、粤港澳大湾区国际科创中心支撑引领和辐射带动作用不断增强，深圳-香港-广州跃居全球百强创新集群榜首。成渝、武汉、西安区域科创中心建设加快推进。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;国家综合创新能力排名由 2020 年的第 14 位提升至 2024 年的第 10 位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="771" src="https://oscimg.oschina.net/oscnet/up-44f21c70fb0f720c57bbf8586c1929ed685.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372983</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372983</guid>
      <pubDate>Thu, 18 Sep 2025 08:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里云爆款云服务器 68 元/年，2 核 2G 限时秒杀，超高性价比，立即抢购！</title>
      <description>覆盖 90%+通用业务场景，组合购买「专享活动价」。</description>
      <link>https://click.aliyun.com/m/1000406832/</link>
      <guid isPermaLink="false">https://click.aliyun.com/m/1000406832/</guid>
      <pubDate>Thu, 18 Sep 2025 07:32:00 GMT</pubDate>
    </item>
    <item>
      <title>蚂蚁百灵大模型团队开源高性能推理 MoE 模型 Ring-mini-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁百灵大模型团队正式发布 Ring-mini-2.0，一款基于 Ling-mini-2.0 架构深度优化的高性能推理型 MoE 模型（Thinking model）。&lt;/p&gt; 
&lt;p&gt;它在总参数量 16B、仅激活 1.4B 参数的情况下，即可达到 10B 级别以下 dense 模型的综合推理能力，尤其在逻辑推理、代码与数学任务中表现卓越，并支持 128K 长上下文及 300+ token/s 的高速生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="550" src="https://static.oschina.net/uploads/space/2025/0918/151311_MTTi_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 以 Ling-mini-2.0-base 为基础继续训练，经过 Long-COT SFT、更稳定持续的大规模 RLVR 以及 RLHF 联合优化，显著提升了复杂推理的稳定性与泛化性。在多项高难度基准（LiveCodeBench、AIME 2025、GPQA、ARC-AGI-v1 等）中，在输出长度相当的情况下，性能显著超越 10B 以下 dense 模型，甚至媲美更大参数量的 MoE 模型（如 gpt-oss-20B-medium），在逻辑推理方面尤为突出。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/151413_jqOH_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 已全面开源，模型权重、训练策略与数据配方将全部开放。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ring-mini-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ring-mini-2.0&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372966</guid>
      <pubDate>Thu, 18 Sep 2025 07:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁百灵大模型团队开源 MoE 大模型 Ling-flash-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁百灵大模型团队正式开源其最新 MoE 大模型 ——Ling-flash-2.0。&lt;/p&gt; 
&lt;p&gt;作为 Ling 2.0 架构系列的第三款模型，Ling-flash-2.0 以总参数 100B、激活仅 6.1B（non-embedding 激活 4.8B）的轻量级配置，在多个权威评测中展现出媲美甚至超越 40B 级别 Dense 模型和更大 MoE 模型的卓越性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150130_epe3_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="634" src="https://static.oschina.net/uploads/space/2025/0918/150203_ryAo_2720166.jpg" width="1000" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Ling-flash-2.0 在仅激活 6.1B 参数的前提下，实现了对 40B Dense 模型的性能超越，&lt;strong&gt;用最小激活参数，撬动最大任务性能&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;为此，团队在多个维度上 「做减法」 也 「做加法」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;1/32 激活比例：每次推理仅激活 6.1B 参数，计算量远低于同性能 Dense 模型&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;专家粒度调优：细化专家分工，减少冗余激活&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;共享专家机制：提升通用知识复用率&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sigmoid 路由 + aux-loss free 策略：实现专家负载均衡，避免传统 MoE 的训练震荡&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MTP 层、QK-Norm、half-RoPE：在建模目标、注意力机制、位置编码等细节上实现经验最优&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150338_KdT0_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最终结果是：6.1B 激活参数，带来约 40B Dense 模型的等效性能，实现 7 倍以上的性能杠杆。&lt;/p&gt; 
&lt;p&gt;Ling-flash-2.0 基础版与对话版模型已同步上架 Hugging Face 与 ModelScope，采用 MIT 协议可商用。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ling-flash-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ling-flash-2.0&lt;br&gt; GitHub：https://github.com/inclusionAI/Ling-V2&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372964</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372964</guid>
      <pubDate>Thu, 18 Sep 2025 07:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>拥抱新一代 Web 3D 引擎，Three.js 项目快速升级 Galacean 指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互联网前端团队- Su Ning&lt;/p&gt; 
 &lt;p&gt;本文从多个维度对比 Galacean 和 Three.js 两款 Web3D 引擎的差异，并介绍拟我形象项目从 Three.js 切换到 Galacean 以后带来的提升以及项目迁移的心得，为其他 Three.js 项目升级到 Galacean 提供参考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;1 分钟看图掌握核心观点👇&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-844825cdee521dcf0dd15502276e842fe65.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;Web 3D 技术的发展日新月异，为我们带来了前所未有的沉浸式体验。从虚拟展示到游戏开发，从建筑可视化到教育模拟，Web 3D 技术的应用场景愈发广泛。而在这一领域，Three.js 作为一款广受欢迎的 JavaScript 3D 库，凭借其简洁易用的 API 和丰富的功能，帮助众多开发者实现了精彩的 3D 项目。&lt;/p&gt; 
&lt;p&gt;然而，随着项目复杂度的不断提升，以及用户对性能和体验要求的日益苛刻，Three.js 逐渐显露出一些局限性。比如在处理重负载时，很容易遇到性能瓶颈，出现卡顿、掉帧等问题。这就如同一位经验丰富的车手，驾驶着一辆曾经性能卓越的赛车，但在面对愈发复杂的赛道和激烈的竞争时，却发现车辆的动力和操控性渐渐力不从心。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、Galacean：新一代 Web 3D 引擎&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 业务简介&lt;/h2&gt; 
&lt;p&gt;拟我形象是 vivo 账号中的一个 3D 数字人功能，提供一种代表自由、个性、创新和时尚的虚拟形象，为用户提供更加生动、直观、有趣的交流方式。采用 Native+H5 混合的开发方式，其中 3D 渲染的部分基于 Three.js 进行开发。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 技术挑战与痛点&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能瓶颈：&lt;/strong&gt;人物模型包含大量形态键以实现多样化面部特征，导致模型加载解析耗时过长。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;线程阻塞：&lt;/strong&gt;受限于 JS 单线程特性，模型解析过程会造成页面短暂无响应。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模型渲染：&lt;/strong&gt;套装切换等场景下，多个模型同时渲染时性能问题尤为突出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;阴影优化：&lt;/strong&gt;Three.js 的阴影渲染性能消耗大，不得不通过局部阴影和限制捕捉范围等折中方案来平衡画质与性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Galacean 引擎核心优势&lt;/h2&gt; 
&lt;p&gt;Galacean 是一款开源的 Web 游戏引擎，致力于打造一个开放、易用、高效的游戏开发工具，可以通过在线编辑器或者纯代码的形式进行使用。&lt;/p&gt; 
&lt;p&gt;针对现存的技术挑战与痛点，Galacean 做了深度优化：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;多线程处理：&lt;/strong&gt;采用 Worker 避免主线程阻塞。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;移动端适配：&lt;/strong&gt;对大量常量进行近似取值优化，完美适配移动端。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能突破：&lt;/strong&gt;优化数据传输链路，创新缓存设计，显著降低重负载场景下的卡顿现象。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7e8fd35268a9e4e6807d7a59d98c296eab.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对比视频 1：加载速度&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-b7b3c633bc729e87048a7e7cbbd4c6374b4.gif" width="240" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对比视频 2：套装切换&lt;/p&gt; 
&lt;p&gt;此外，Galacean 基于 EC（Entity-Component）架构设计，而非 Three.js 的面向对象，大幅提升了开发的灵活性。&lt;/p&gt; 
&lt;p&gt;近期我们将渲染引擎由 Three.js 切换为 Galacean。这一举措不仅解决了页面卡顿问题，还提升了浏览器兼容性（可支持到 chrome82），帧率表现更出色，画面质感也得到显著改善。整体切换过程较为平滑，但也遇到了一些问题。接下来，将与大家分享此次整体升级的相关经验。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;三、调优过程&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;任务拆解：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;作为一个数字人项目，涉及到引擎升级的模块大致有&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;①环境初始化&lt;/strong&gt;（场景、相机、光线、引擎设置）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 模型加载&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;骨架获取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;材质获取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;动画获取&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;③妆容、穿搭还原&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;形态键修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;贴图、颜色修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型替换&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;头像（静态头像、动态头像）导出&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;壁纸（静态壁纸、动态壁纸、视差壁纸）导出&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过梳理，可以大致分为四类：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;初始化&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;模型加载&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;素材替换&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;动画状态&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;接下来我们对这几个部分进行分别的处理&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 初始化&lt;/h2&gt; 
&lt;p&gt;有别于 Three.js 的渲染器创建，Galacean 的 engine 初始化是异步方法，所以后续用到用到 engine 的地方需要考虑加载的时序，以及 engine 存在状态的判断。另外，Three.js 中 renderer 的渲染行为需要手动调用，一般是使用 requestAnimationFrame 循环调用，而 Galacean 则不需要，引擎开始渲染只需要调用一次 engine.run 即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;renderer=new&amp;nbsp;THREE.WebGLRenderer({
&amp;nbsp;&amp;nbsp;alpha:&amp;nbsp;true,
&amp;nbsp;&amp;nbsp;antialias:&amp;nbsp;true,
})
document.body.appendChild(renderer.domElement)
const&amp;nbsp;scene =&amp;nbsp;new&amp;nbsp;THREE.Scene()
const&amp;nbsp;camera =&amp;nbsp;new&amp;nbsp;THREE.PerspectiveCamera(15,&amp;nbsp;window.innerWidth/window.innerHeight,&amp;nbsp;0.1,&amp;nbsp;100)
requestAnimationFrame(function&amp;nbsp;render() {
&amp;nbsp; renderer.render(scene, camera)
&amp;nbsp;&amp;nbsp;requestAnimationFrame(render)
})&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;engine =&amp;nbsp;await&amp;nbsp;WebGLEngine.create({
&amp;nbsp; canvas,
&amp;nbsp;&amp;nbsp;physics:&amp;nbsp;new&amp;nbsp;LitePhysics()
})
engine.run()&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中，尺寸单位统一以米为基准，无需额外进行特殊处理。不过在角度单位的使用上存在差异：Three.js 里，仅相机的 fov（视场角）采用角度单位，其他涉及角度的参数均以弧度计量；而 Galacean 则采用更为统一的设定，所有角度相关单位均为角度。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
camera.fov =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&amp;nbsp;* Math.PI/180

/** Galacean */
camera.fieldOfView =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中颜色的设置更加灵活，可以使用 16 进制或者 RGB 值来进行赋值，但是在 Galacean 中只能通过 RGB 来进行赋值，且有别于 0-255 的取值范围，Galacean 中的颜色范围是 0-1。从 Galacean1.5 版本开始，默认的色彩空间改为线性，在代码中需要手动转换一下。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
directLight.color=0xffffff
directLight.intensity=0.9

/** Galacean */
const&amp;nbsp;color =&amp;nbsp;new&amp;nbsp;Color(0.9,&amp;nbsp;0.9,&amp;nbsp;0.9,&amp;nbsp;1)
color.toLinear(color)
directLight.color = color&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 模型加载&lt;/h2&gt; 
&lt;p&gt;对于包含大量形态键和动画的模型，将模型打成 zip 包可以有效的压缩模型的体积，不论是 Three.js 还是 Galacean 都不支持加载 zip 包，但是我们可以自行扩展模型加载的链路，将 zip 下载后解压出的模型获取 ObjectUrl 再放到各自的加载器中加载，这样加载进度的获取也可以进行自定义，不需要进行额外的改造。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;exportclassModelLoader {
&amp;nbsp;&amp;nbsp;engine:&amp;nbsp;WebGLEngine
&amp;nbsp;&amp;nbsp;constructor(engine: WebGLEngine){
&amp;nbsp; &amp;nbsp;&amp;nbsp;this.engine&amp;nbsp;= engine
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;async&amp;nbsp;load(src:&amp;nbsp;string) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;url =&amp;nbsp;await&amp;nbsp;fileLoader(src)
&amp;nbsp; &amp;nbsp; returnthis.engine.resourceManager.load&amp;lt;GLTFResource&amp;gt;({
&amp;nbsp; &amp;nbsp; &amp;nbsp; url,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;type:&amp;nbsp;AssetType.GLTF
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Three.js 解析 glTF 模型输出的数据结构较为简单，主要使用模型的场景和动画片段。由于后续需针对特定材质进行替换，所以要根据节点名获取特定节点，再取出节点中的材质信息，模型的骨架也通过这种方式获取。而 Galacean 输出的数据更为全面，除动画片段和实体信息外，模型中使用的材质、贴图、蒙皮和网格信息也会分门别类展示，需要对应内容时直接获取即可，相比 Three.js 更加方便。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 素材替换&lt;/h2&gt; 
&lt;p&gt;素材替换如上文总结分为四种，分别是颜色、贴图、形态键和模型的替换，颜色设置我们在初始化中已经讲解，而模型加载和展示也没有特别的内容，无非是节点/实体的添加和移除，这里我们讲下贴图和形态键修改的一些 tips。&lt;/p&gt; 
&lt;p&gt;在 Three.js 中修改材质贴图 map 可以直接直接使用 canvas 或者 image，修改后需要将材质 needsUpdate 属性设置为 true。而在 Galacean 需要先将图片加载为 texture，再进行赋值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
material.map=canvas
material.needsUpdate =&amp;nbsp;true

/** Galacean */
const&amp;nbsp;texture: Texture2D = await engine.resourceManager.load({
&amp;nbsp; url,
&amp;nbsp;&amp;nbsp;type: AssetType.Texture2D
})
material.baseTexture = texture&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中修改形态键，可以先通过网格中的 morphTargetDictionary 属性获取到需要修改的形态键的索引，然后修改 morphTargetInfluences 中对应索引的值即可。&lt;/p&gt; 
&lt;p&gt;在 Galacean 中网格渲染器中没有存储形态键的索引信息，而是存储在 MeshRenderer 下的 mesh 属性下的 blendShapes 属性中，通过获取对应名称的形态键在数组中的索引，修改网格渲染器中 blendShapeWeights 属性对应下标的值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
const&amp;nbsp;index = morphTargetDictionary[keyName]

if&amp;nbsp;(index !==&amp;nbsp;undefined) {
&amp;nbsp; mesh.morphTargetInfluences[index] = value
}

/** Galacean */
const&amp;nbsp;blendShapes = skinMeshRenderer.mesh.blendShapes
const&amp;nbsp;index = blendShapes.findIndex(i=&amp;gt;i.name===keyName)
if&amp;nbsp;(index &amp;gt; -1){
&amp;nbsp; skinMeshRenderer.blendShapeWeights[index] = value
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;3.4 动画&lt;/h2&gt; 
&lt;p&gt;相较于 Three.js 的 AnimationMixer 和 AnimationClip，Galacean 拥有更加完善的面向组件的动画系统，支持，状态机、混合动画、时长压缩等，不同动画之间的切换与播放更加简单易维护。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js 播放动画片段 */
const&amp;nbsp;mixer =&amp;nbsp;new&amp;nbsp;THREE.AnimationMixer(scene)
const&amp;nbsp;action=mixer.clipAction(avatarClip)
action.play()
ticker.addEvent(delta =&amp;gt; {
&amp;nbsp; mixer.update(delta)
})

/** Galacean 添加状态机，播放完成回到待机状态 */
const&amp;nbsp;animationState = animator.findAnimatorState('action')
const&amp;nbsp;idleStatle = animator.findAnimatorState('idle')
const&amp;nbsp;transition =&amp;nbsp;new&amp;nbsp;AnimatorStateTransition()
transition.duration =&amp;nbsp;1
transition.offset =&amp;nbsp;0
transition.exitTime =&amp;nbsp;1
transition.destinationState = idleStatle
animationState.addTransition(transition)
animator.play('action')&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_11"&gt;&lt;/span&gt; 
&lt;h1&gt;四、结语&lt;/h1&gt; 
&lt;p&gt;Galacean 的出现，无疑为 Web 3D 开发领域带来了新的活力。它不仅解决了 Three.js 等传统技术在性能和功能上的诸多痛点，还以其卓越的性能、丰富的功能和易用性，为开发者打开了一扇通往更广阔创意空间的大门。&lt;/p&gt; 
&lt;p&gt;需要注意的是，Galacean 不同版本之间的 API 差异较大，需要进行甄别，同时开发文档及相关的案例也需要进一步完善。&lt;/p&gt; 
&lt;p&gt;对于全新的项目，Galacean 提供编码或在线编辑器两种方式保障创意的高效落地，详细的文档和案例也便于接触 Web3D 开发的新人快速上手。&lt;/p&gt; 
&lt;p&gt;对于存量的项目，Galacean 的迁移成本不高，且整个过程平滑可控，能够有效提升现有项目的画面表现和性能。为未来复杂度更高的需求提供性能保障。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18692286</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18692286</guid>
      <pubDate>Thu, 18 Sep 2025 07:06:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>华为发布全球首个通算超节点</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在华为全联接大会 2025 上，华为轮值董事长徐直军正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huawei.com%2Fcn%2Fnews%2F2025%2F9%2Fhc-lingqu-ai-superpod" target="_blank"&gt;发布&lt;/a&gt;了全球首个通算超节点华为 Taishan 950 SuperPoD，计划 2026 年一季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直军称，其将能够彻底取代各种应用场景的大型机和小型机以及 Exadata 数据库一体机，将成为各类大型机、小型机的终结者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-24f09fe6e041b3140f61e7f0fa4a12dc091.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直军指出：「算力过去是，未来也将继续是人工智能的关键，更是中国人工智能的关键」。他认为，超节点在物理上由多台机器组成，但逻辑上以一台机器学习、思考、推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，华为发布的最新超节点产品 Atlas 950 SuperPoD，算力规模 8192 卡，预计于 2026 年四季度上市。Atlas 960 SuperPoD 算力规模 15488 卡，预计 2027 年四季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基于超节点，华为同时发布了全球最强超节点集群，分别是 Atlas 950 SuperCluster 和 Atlas 960 SuperCluster，算力规模分别超过 50 万卡和达到百万卡。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372960</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372960</guid>
      <pubDate>Thu, 18 Sep 2025 06:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
