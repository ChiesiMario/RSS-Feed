<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 10 Feb 2025 21:39:21 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>2024 年 AI 编程工具的进化</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，开源中国 OSCHINA、Gitee 与 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;联合发布了《2024 中国开源开发者报告》&lt;/a&gt;。报告聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中国开源开发者报告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型观点》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thoughtworks AI 辅助研发工具与开源解决方案负责人&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;黄峰达（Phodal）&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;分析了&lt;/span&gt;2024 年 AI 编程工具的进化路线&lt;span style=&quot;color:#999999&quot;&gt;。&lt;/span&gt;全文如下。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;2024 年 AI 编程工具的进化&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/黄峰达&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;与 2023 年相比，2024 年 AI 在软件工程中的应用已经变得更加广泛和深入。这一趋势体现在 AI 编程工具的进化上，主要体现在以下几个方面：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;全面探索：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 从辅助开发人员扩展到覆盖软件开发的整个生命周期，从需求分析到运维管理，每个阶段都显著提升了效率和质量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;演进路径：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 工具从个体使用扩展到团队和组织层面。个体使用的 AI 工具如 AutoDev，团队助手如 Haiven，以及组织层面的 AI 集成到内部 IM 和 Chatbot 系统中，全面增强了协作和效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;形态变化：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从本地 AI IDE 发展到领域特定的智能代码生成工具。智能云开发环境如 Google 的 Project IDX 等工具，使得未来的开发流程更加智能化和高效。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;站在全球来看，在不同的国家、区域人们的关注点是不一样的，比如在中国，人们更关注于如何提高软件工程师的工作效率，而在其它一些区域，人们更关注于如何提高软件工程的质量、如何辅助进行遗留系统的迁移。除了各自所处的数字化阶段、水平不同，还存在一些技术人才数量、质量、分布等方面的差异。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;全面探索：从辅助开发人员到全生命周期&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 技术已经从简单的辅助开发人员发展到涵盖软件开发的整个生命周期。在这一过程中，AI 工具的应用范围不断扩展，从需求分析到运维管理，每个阶段都得到了显著提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从 2022 年 GitHub Copilot 的发布，我们可以看到越来越多的 AI 工具开始涉足到软件开发的不同阶段。比如，面向需求阶段的 Jira/Atlassian Intelligence，面向原型设计的 Vercel v0，面向编码阶段的 GitHub Copilot，以及运维阶段的 Dynatrace Davis AI 等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;就 2023 年的结论而言，基于人工智能的工具与基础大语言模型可以增强软件开发在设计、需求、测试、发布和运维等各个环节中的能力，提高质量和效率。但是，这些工具往往是破碎、割裂的，还可能并不适合我们现有的研发流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在市场上，我们也可以看到市面上的主流研发工具，如 JetBrains、GitHub（网站）等，都在逐渐加入 AI 功能，使得 AI 功能逐渐融入到我们的日常工作中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;935&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-80891774a0b75d9ea03764c0cd3d38f6a0e.png&quot; width=&quot;1600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 IntelliJ IDEA 中，我们可以看到 AI 功能的加入，如：原生的向量化模型、基于语义化搜索（SearchEverywhere）、结合补全统计的机器学习补全插件 Machine Learning Code Completion、适用於单个代码行的 Full Line Code Completion 等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而除了 GitHub Copilot 工具本身，它还开放了其插件能力，使得我们可以定义自己的 AI 智能体，以适应我们自己的工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在多阶段协同方面，2024 年有了更多的变化，比如在智能运维领域，AI 可以结合判别性 AI 分析日志，生成式 AI 分析原因，再结合智能体根据运行错误，自动修代码复问题等；在测试领域，AI 除了辅助进行测试用例的生成，还可以生成对应的单元测试代码，甚至是自动化测试代码；在 UI 设计领域，AI 可以直接生成对应的代码，基于提示词来修改 UI，所生成的是最终的 UI 代码，而不是设计稿。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;诸如此类的变化，使得 AI 所能辅助的范围更加广泛，从而使得 AI 在软件工程中的应用更加全面。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;演进路径：个体、团队、组织&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从企业采用 AI 的路径来看，我们会发现：越来越多的组织开始探索在组织层面使用 AI 辅助整体软件研发。因而，AI 辅助研发组织的技术蓝图便也逐渐清晰起来。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从形态上可以分为：带扩展能力的 IDE 插件、团队 AI 助手、结合 AI 的内部 IM，以及作为基础能力的 Chatbot。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;995&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f81e8fe70439b9145dbc6c7c33d9fcb424.png&quot; width=&quot;1732&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 编程工具应该怎么设计才能提效？在当前来说，国内的环境下，由于我们的目标是实现可见的效率提升，即要通过可度量的指标。因而，可以看到一些明显的变化：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;代码补全与生成是最容易度量的指标，并且市面上也以此类为主。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在不同环节，从时间角度来计算，如代码审查、代码测试等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;结合代码的问答，以减少工具切换、复制粘贴，提高效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;过去，AI 编程工具主要针对的是个人开发者。但随着探索不断深入，我们发现，在结合团队或组织的力量后，AI 编程工具出现了以下趋势：多样的 AI 工具正在融入自己的开发流程中；AI 工具开始融入内部的一系列规范；不断结合内部知识库，提升内容生成的质量；开始构建自己的场景化能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;故而，从个体到团队，再到组织，都在思考如何扩大 AI 的应用范围。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在设计团队 AI 助手时，我们需要考虑到团队的拓扑结构，以及团队的工作流程。在一个组织中，必然会有大量不同类型的团队，每个团队受限于业务盈利模式等因素，其采用的技术、工作流程等都会有所不同。比如，核心的业务部门可以享受自己特有的开发流程，而其它非核心部门则会采用一些标准化的流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;考虑到盈利水平高的部门，通常是大型团队，他们不仅可能有自己的 AI IDE 插件，还会有自己的 AI 团队。因此，我们也建议设计一个可以让不同团队共享知识的 AI 团队助手。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;回到整体组织层面，我们也会看到内部的 IM 工具也在融合 AI 功能，比如寻找负责人/专家、运维 Chatbot 辅助分析部署失败问题、CI/CD 问题分析、AI 会议创建与管理等等，以提升协作体验。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在另外一方面，我们也会有大量的其它 Chatbot 在不同的研发团队中使用，诸如于辅助平台的使用、文档查找等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;形态变化：从本地 AI IDE 到领域特定的智能代码生成&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;与通用性的 AI 辅助相比，领域特定的 AI 辅助效果更好，因为它更了解领域的特点，更容易生成符合领域规范的代码。从智能代码生成的角度来看，由于过去包含大量的语料知识，生成的代码质量更高，更符合领域规范。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在前面，我们已经看到了 AI 辅助研发中心的概念，即在一个组织中，AI 辅助研发中心可以为不同团队提供 AI 能力，以提升整体的研发效率。需要注意的是，AI 在快速生成大量代码的同时，也会带来一些问题，如代码质量、安全性等。我们需要考虑如何在 AI 生成代码的同时，保证代码的质量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;生成式 AI 与低代码平台结合，可以在多个方面实现增强的生产力和创新。文本生成与聊天机器人、从 PDF 构建界面、工作流程自动生成、自助式分析都是经典场景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，多模态 AI 代码的生成，诸如于 Google 的 ScreenAI。它可以将图像和文本结合起来，生成对应的 DSL，进而转换成不同的代码。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在云时代，大型组织构建了大量的云 IDE 和云基础设施，以尝试卖出更多的云服务以及解决最后一公里的部署问题。尽管，受限于云 IDE 能力、网络与计算能力，云 IDE 采用并不高，但是随着 AI 的发展，我们可以看到更多的智能云开发环境的出现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们非常看好诸如 v0.dev 这一类针对于领域特定的开发工具。它可以快速帮助我们构建出一个原型，然后再结合其它 AI 工具，如代码审查、代码测试等，可以大大提高我们的开发效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;还有诸如 Google Project IDX 这一类 AI 辅助型工作区。IDX 支持众多框架、语言和服务，还与 Google 产品集成，可简化开发工作流程，让开发者可以快速、轻松、高效地跨平台构建和发布应用。尽管 IDX 还非常早期，但是我们可以看到，未来的云 IDE 将会更加智能化，更加适应我们的工作流程。在国内，我们也可以看到 Babel Cloud、MarsCode 等一系列云 IDE 工具，也在不断的发展中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3054d057b31f6423987fec6f0abd944b82d.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;黄峰达（Phodal）&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thoughtworks AI 辅助研发工具与开源解决方案负责人，开源 Unit Mesh AI 辅助研发方案的发起人，包含 AI IDE 插件 AutoDev 等工具；智能体编程语言 Shire 的创始人，架构治理平台 ArchGuard 的核心开发者。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;他在生成式 AI 辅助需求分析、开发和质量保障方面为多家金融和互联网企业提供落地支持，著有《前端架构：从入门到微前端》《自己动手设计物联网》等多本书籍。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#333333&quot;&gt;《2024 中国开源开发者报告》&lt;/span&gt;由开源中国 OSCHINA、Gitee 与 Gitee AI 联合出品，聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;报告整体分为三章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;中国开源开发者生态数据&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;TOP 101-2024 大模型观点&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;国产 GenAI 生态高亮瞬间&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告，请点击&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中国开源开发者报告.pd&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529672</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529672</guid>
            <pubDate>Sat, 08 Feb 2025 10:50:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>大模型训练中的开源数据和算法：机遇及挑战</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，开源中国 OSCHINA、Gitee 与 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot; rel=&quot;nofollow&quot;&gt;联合发布了《2024 中国开源开发者报告》&lt;/a&gt;。报告聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;2024 中国开源开发者报告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型观点》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;苏州盛派网络科技有限公司创始人兼首席架构师苏震巍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;分析了&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型训练过程中开源数据集和算法的重要性和影响，分析其在促进 AI 研究和应用中的机遇，并警示相关的风险与挑战。&lt;/span&gt;&lt;/span&gt;全文如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;大模型训练中的开源数据和算法：机遇及挑战&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/苏震巍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着人工智能（AI）技术的迅猛发展，尤其是大模型（如 GPT、OpenAI o1、Llama 等）的崛起，开源数据和算法在大模型训练中的重要性愈发显著。开源数据集和算法不仅推动了 AI 研究的进步，也在应用层面带来了深远的影响。然而，伴随这些机遇的还有诸多风险与挑战，如数据质量、版权问题和算法透明性等。本文将浅析大模型训练过程中开源数据集和算法的重要性和影响，分析其在促进 AI 研究和应用中的机遇，并警示相关的风险与挑战。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;任何方案都具有两面性和在特殊环境下的讨论的意义和前提，因此，本文不讨论开源或对立面（闭源）的绝对取舍问题，仅对开源的有利之处加以浅析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;重要的开源数据集和算法在大模型训练中的角色&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源数据集是大模型训练的基石。没有高质量的数据，大模型的性能和应用场景将受到极大限制。ImageNet、COCO、Wikipedia 和 Common Crawl 是非常重要一批高质量的开源数据集。以下是这几个数据集在大模型训练历程中的重要角色。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;ImageNet：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ImageNet 是计算机视觉领域最著名的开源数据集之一，包含数百万张带有标签的图像。它为图像分类、物体检测等任务提供了丰富的数据资源，使得模型能够在视觉理解方面取得突破。它由普林斯顿大学的计算机科学家李飞飞（Fei-Fei Li）及其团队在 2009 年创建。ImageNet 包含超过 1400 万张图像，这些图像分为超过 2 万个类别，每个类别都与 WordNet 中的一个词条对应。每个类别的图像数量从数百到数千不等。ImageNet 每年都会举办一个大型的视觉识别竞赛，即 ImageNet Large Scale Visual Recognition Challenge(ILSVRC)。该竞赛吸引了全球众多研究团队参与，并在推动深度学习和卷积神经网络（CNN）技术的发展中发挥了重要作用。今年的诺贝尔物理学奖得主之一 Geoffrey Hinton 带领的团队成员 AlexNet 在 2012 年的 ILSVRC 中取得了显著的成功，使得深度学习在计算机视觉领域迅速崛起。也为如今我们看到的种类繁多的视觉大模型（VLMs）开启了新的篇章。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;COCO（Common Objects in Context）：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COCO 数据集由微软于 2014 年发布，涵盖了数十万张日常生活中的图像，并附有详细的标注信息。虽然 COCO 对比 ImageNet 具有更少的类别,但每一个类别拥有更多的实例，假定这能帮助复杂模型提高物体定位的准确率。它的设计初衷适用于具有上下文信息的图片中的物体检测和分割，目前在目标检测、分割等任务中发挥了重要作用，推动了计算机视觉技术的进步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Wikipedia 和 Common Crawl：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Wikipedia 是一个由全球用户共同编辑和维护的高质量在线百科全书,以文字为主，知识高度结构化，Common Crawl 是一个非营利组织，定期抓取互联网公开网页，生成大量的网页数据集，可提供大量的互联网用户知识及非结构化数据。他们的共同点是为模型训练提供了充沛的文字素材。这些大型文本数据集为自然语言处理（NLP）模型的训练提供了丰富的语料库。像 GPT 这样的语言模型正是通过大规模爬取和处理这些数据集，才能在文本生成和理解方面表现出色。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;开源算法的角色&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源算法是 AI 研究和应用的核心驱动力。开源算法的共享和复用使得研究者和开发者能够在前人工作的基础上迅速迭代和创新。以下是一些在这一轮 AI 大模型浪潮中扮演重要角色的的开源算法及其在大模型训练中的角色：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;TensorFlow 和 PyTorch：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这两个深度学习框架是当前最流行的开源工具，提供了强大的计算能力和灵活的模型构建方式。它们为大模型的训练和部署提供了基础设施支持，使得复杂的 AI 模型得以实现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Transformer 架构：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Transformer 架构是一种用于处理序列数据的开源算法，广泛应用于 NLP 任务，也是作为这一轮 AI 浪潮推动者 GPT 模型的基础算法。基于 Transformer 的模型，如 BERT 和 GPT，已经成为自然语言理解和生成的事实标准。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;GAN（生成对抗网络）：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GAN 是一种用于生成数据的开源算法，广泛应用于图像生成、数据增强等领域。它通过生成器和判别器的对抗训练，能够生成高质量的图像和其他数据。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此以外，如果把 Pre-Train 之后的微调（Fine-Tuning）等环节也看做广义「训练」的一部分，还有一系列开源方法及配套的工具，例如比较常见的 LoRA（Low-Rank Adaptation of Large Language Models）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;机遇&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从上述开源数据和算法在模型训练过程中所扮演的角色可以看到，大模型训练中的开源数据和算法为 AI 研究和应用带来了诸多机遇，在加速创新、促进合作、资源共享等方便提供了广泛而可靠的基础条件和资源，围绕这些资源，技术人员得以进行更加开放的交流和合作，并展开更加深入的教育和培训，以此不断提升整个行业人才的技术水平。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;由于目前主流的模型训练算法都需要依靠对训练数据（样本）的统计（概率），因此，开放的数据和算法能够在更大程度上确保样本的质量，从而避免更多未知的风险。例如就在 2024 年 12 月 1 日，用户发现 ChatGPT 在需要输出「David Mayer」这个名字的时候会突然提示拒绝：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;614&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-54e711fc838017bab98b163b46d3a7de8d4.png&quot; width=&quot;375&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此事件一度被解读为 GPT 模型在训练过程中被植入了特定的样本或算法，以避免讨论特定的人名。虽然后续的一系列测试表明，这种限制似乎只存在于 ChatGPT 产品中，通过 OpenAI 对外提供的模型接口并不会触发这样的屏蔽机制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OpenAI 在随后周二（12 月 3 日）立即确认「David Mayer」这个名字已经被内部隐私工具标记，其在一份声明中说：「可能有些情况下，ChatGPT 不提供关于人们的某些信息，以保护他们的隐私。」公司不会提供有关工具或流程的更多细节。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;无论真实的原因是什么，这个事件是一个反例，其显示了封闭的系统以及中心化的模型提供者所具备的风险，也说明了不透明的处理环节对模型的输出结果带来更多的不确定性。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;类似的拒绝服务也是在模型服务过程中表现出来的另外一种偏见（Bias）行为，而偏见也是目前所有模型都在极力避免的情形，要进一步解决这个问题，使用更加开放的数据集和算法是一种更负责任的做法。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;种种事件的发生并不是坏事，这是所有技术在发展过程中接受实践检验的必经之路，通过种种尝试和反馈，目前对于开源数据集和算法的呼声正在越来越高涨。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了对于训练集和算法的开源之外，对于模型的「开源」定义也经受着各种议论。笔者比较认同的观点是：开源模型不应该只把模型文件公布出来，同时应该把对应的训练集和算法进行公开，并能够提供相应的训练流程，是所有人能够对结果进行重现。这好比我们讨论开源项目的时候，通常不会指我们只能够下载某个应用程序，而是我们能够查看源码，甚至通过修改源码编译出自己想要的应用程序。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在今年 10 月 29 日，开放源代码促进会（Open Source Initiative，OSI）发布了关于「开源 AI 定义（OSAID）」1.0 版本，其规定了 AI 大模型若要被视为开源必须具备三个三个：训练数据透明性、完整代码、模型参数。虽然对比目前市面上的「开源模型」，少有能力较高的模型能完全符合，但这种声明本身就是一种开源开放态度的彰显。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我相信，在更加透明的数据集和算法的支持下，模型将在可控性上获得更好的发展机遇，相关的技术社区也将迎来更大的发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然，大模型训练中的开源数据和算法也伴随着一定的风险和挑战，这些风险需要在模型开发和应用的过程中被认真对待和解决。例如前文提到的「偏见」问题，以及数据质量问题，可能是最显著的风险。由于开源数据集质量参差不齐，虽然一些广泛使用的数据集如开头介绍的 ImageNet 和 COCO 被认为是高质量的数据集，但其他开源数据集可能包含噪声、错误标签和不完整的信息。这种数据质量问题会直接影响模型的训练效果，导致模型性能的下降，甚至可能产生错误的预测结果。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此以外，在 GPT 爆火之后，由于相关法律和政策的滞后，已经有大量大模型生成的文字、图像、视频、音频内容被发布于互联网，当这些内容再次被作为开放数据被采集，并再次进行训练，可能会带来更大的数据质量问题。因此，笔者认为对 AI 生成的观点进行标注再发布是一种更加负责任的做法，当然，在实际操作过程中，要实现仍然有极大的难度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源数据集的版权问题也是一个需要重视的风险。尽管开源数据集通常是公开的，但其使用仍然受版权法的约束。未经授权使用受版权保护的数据，可能会导致法律纠纷。此外，某些数据集可能包含敏感信息，涉及个人隐私甚至危害公共安全。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在使用这些数据时，必须遵守相关的隐私保护法规，如欧盟的《通用数据保护条例》（GDPR）和美国的《健康保险可携性和责任法案》（HIPAA）。在实际操作过程中，出于成本、工艺、能力、时间的制约，数据集的筛选和正确使用仍然将会是一个持久的挑战。对于这个问题，闭源的数据集以及方法并不是不存在，只是更加隐蔽了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;也可能会有人担心，所有的数据集和算法开放后，模型是否会面临更多被操控的风险？笔者认为，这确实是一个很大的问题，例如模型可能会更容易被「越狱」，从而被操控或输出原本不应输出的内容，这是一个需要尤其重点关注的风险点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在应对策略方面，这场攻防战的「蓝方」同时也获得了更多的信息，可以再次加固相关能力，在这个过程中，模型得以进行更加充沛的发展，就如同当下的互联网一样。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;只有黑暗才能隐藏更多风险尤其中心化的控制风险，只有让核心数据和算法经受阳光的洗礼，并在所有人的监督下不断完善，才能让模型在更多场景中被更深入地使用（即便如此，训练完的模型本身对人类来说也仍然是一个「黑盒」）。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前我们已经看到的大量开源的模型在各行各业中展现出强大的生命力和生产力，相关的开源社区也正在迎来新的繁荣期，长期来看，大模型将继续在各种风险、机遇、挑战、伦理等复杂环境中不断发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源数据和算法在大模型训练中的重要性不言而喻，它们为 AI 研究和应用带来了前所未有的机遇。然而，这些机遇也伴随着一定的风险和挑战，需要在模型开发和应用的过程中被认真对待和解决。通过采取适当的应对策略，我们可以在充分利用开源数据和算法的同时，尽量减少其潜在的风险，推动 AI 技术的健康发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;相信在未来，随着技术的不断进步和相关政策的完善，开源数据和算法将在大模型训练中发挥更加重要的作用，为 AI 及大模型的研究和应用带来更多的创新和机遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d7067c07019e3e8c6de531e38dbdac9ade.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;苏震巍&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;苏州盛派网络科技有限公司创始人兼首席架构师，微软 AI 和开发方向最有价值专家（MVP）、微软 Regional Director（RD）、腾讯云最具价值专家（TVP）、微软技术俱乐部（苏州）主席，苏州市人工智能学会理事，机械工业出版社专家委员会委员，江苏省司法厅电子数据鉴定人。《网站模块化开发全程实录》《微信开发深度解析》图书作者，Senparc.Weixin SDK 等开源项目作者，盛派开发者社区发起人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#333333&quot;&gt;《2024 中国开源开发者报告》&lt;/span&gt;由开源中国 OSCHINA、Gitee 与 Gitee AI 联合出品，聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;报告整体分为三章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;中国开源开发者生态数据&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;TOP 101-2024 大模型观点&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;国产 GenAI 生态高亮瞬间&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告，请点击&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;2024 中国开源开发者报告.pd&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529581</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529581</guid>
            <pubDate>Sat, 08 Feb 2025 10:49:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>RAG 市场的 2024：随需而变，从狂热到理性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，开源中国 OSCHINA、Gitee 与 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;联合发布了《2024 中国开源开发者报告》&lt;/a&gt;。报告聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中国开源开发者报告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型观点》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;杭州萌嘉网络科技 CEO&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;卢向东&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;分享了其&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作为大模型应用创业者，所感知到的 2024 年 RAG 市场环境的变化。&lt;/span&gt;&lt;/span&gt;全文如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;RAG 市场的 2024：随需而变，从狂热到理性&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/卢向东&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;转眼到了 2024 年尾，和小伙伴一起创立 TorchV 也接近一年。虽然这一年做了很多事情，但从技术层面上来说，RAG 肯定是不得不提的，所以今天分享一下作为大模型应用创业者所感知的这一年，RAG 市场环境的变化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;RAG vs Fine-tune&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 这一年，RAG 技术对应的市场需求变化也是挺大的。在讲变化之前，我觉得有必要分享一下为什么 RAG 是目前市场上不可或缺的一种大模型应用的技术实现方式，它的优点是什么？以及它和主要竞争技术之间的现状是怎么样的？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;RAG 最开始被大家热推，更多是因为以下三个原因：可以避开大模型的上下文窗口长度的限制；可以更好地管理和利用客户专有的本地资料文件；可以更好地控制幻觉。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这三点到现在来看依然还是成立的，但上下文窗口这个优势已经慢慢淡化了，因为各大模型的上下文窗口都在暴涨，如 Baichuan2 的 192K，doubao、GLM-4 的 128K，过 10 万 tokens 的上下文窗口长度已经屡见不鲜，更别说一些特长的模型版本，以及月之暗面这样用长文本占据用户心智的模型。虽然这些模型是否内置了 RAG 技术不好说，但是 RAG 解决上下文窗口长度限制的特点已经不太能站得住脚。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是第二点管理和利用专属知识文件，以及第三点控制幻觉，现在反而是我认为 RAG 最大的杀手锏。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）专属知识文件管理&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因为 RAG 这种外挂文件的形式，我们便可以构建一个知识文件管理的系统来维护系统内的知识，包括生效和失效时间，知识的协作，以及便捷地为知识更新内容等。RAG 在知识维护上，既不需要像传统 NLP 那样由人工先理解再抽取问答对，也不需要像微调（fine-tune）那样需要非常专业的技术能力，以及微调之后的繁琐对齐（alignment）优化。所以如果客户的知识内容更新比较频繁（假设每天需要追加、替换大量实时资讯内容），特别是金融证券、企业情报等场景，RAG 知识更新便捷的特性真的非常合适。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）RAG 的幻觉控制&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 的幻觉控制是一个有争议的话题，我之前写过类似观点，也有同学斩钉截铁地认为 RAG 和幻觉控制八竿子打不着，但我现在依然坚持 RAG 可以有效控制幻觉这个观点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先我们可以来看看 LLM 幻觉产生的主要原因：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 对于用户的提问输入，LLM 内部完全没有相应的知识来做应对。比如你问大模型，上周三我在思考一件事，但是现在想不起来，你帮我想想是什么。例子虽然夸张，但显而易见，LLM 也不知道，但是它会一本正经给你一些建议，当然肯定不是你想要的；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 当我们给 LLM 原始问题，以及多个模棱两可或互相影响的参考材料，那么 LLM 给出的最终答案也会出错。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;好，那么针对以上问题，是否我们解决好对原始问题的「理解-检索-召回」，送到 LLM 的 context 足够清晰（指的是没有歧义内容、检索相关度高），结果就会非常准确？根据我们的实践结果，答案是明确的：今年 9 月份我们对一些项目进行了槽位填充（消除模糊问答）和元数据辅助之后，问答准确率可达到 98% 以上。比直接把大文本扔进同一个 LLM 测试的问答准确率几乎高出 14 个百分点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有同学会说，LLM 幻觉的深层原因是 temperature 或者说概率引起的。就我纯个人观点来看，现当下的 LLM 参数足够大、知识量足够多，temperature 引起的偏差对于最终结果的正确性影响已经微乎其微了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（三）市场表现&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你应该看出来了，在 RAG 和微调之间，我明显站队了，而且从一年前就开始站队了，我们创业的技术方向也是如此。从今天来看，我觉得 RAG 在 2024 年的表现确实要强于微调。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;499&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3a36116d31e8f9dc257f8e00f317e80a982.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图：Menlo Ventures 在 2024 年 11 月 20 日发布的市场调研报告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;来源：https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根据 Menlo Ventures 发布的市场调研报告显示，RAG 以 51% 的市场份额在企业市场份额中占据绝对优势，Fine-tune 和 Prompting 工程均下降两倍多。Agent 今年属于纯增长，目前情况还不错，但在企业应用领域，多 Agents 的编排依然存在理解能力不足和生成幻觉等问题有待提高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果去预测明年的企业级市场趋势，我觉得应用（Application）可能会是最大的关键词，甚至会超过 Agent 的热度。其实今年下半年已经能明显的看出来，越来越多传统大企业开始将大模型技术引入到业务中，而且他们的特点是要求高、需求刚、付费爽。而一旦大家开始在大模型的应用侧竞赛，RAG 在整个业务流程中白盒流程多、易控等特点愈发会受到企业客户和开发者的热捧，优势进一步拉大。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;企业 AI 应用市场在 2024 年的变化&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）上半年：AI 无所不能，大而全&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年的上半年，AI 市场充斥着激情，那种热情似乎走在街上都会扑面而来，个人感觉最主要的推动者是自媒体和模型厂商。模型厂商的出发点很容易理解，快速打开市场嘛，但考虑到他们是要最终交付的，所以相对还是比较理性。但自媒体就不一样了，整个上半年看过太多的文章，大家也都是把最好的一面呈现给了大众，所以很多人会觉得我才几个月没关注，AI 已经发展到我不认识的地步了，AI 已经无所不能了。所以，在 2024 年上半年，我们接触到的企业需求中，占主流的是那种大而全的需求，要用 AI 替代他们业务的全流程或基本流程，气味中充满了使用者的野望。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但实际情况并不理想，AI 或者大模型还真没到这个程度，而且最关键的是范式转换也还需时间。什么是范式转换？最简单的例子就是以前人们用笨重的蒸汽机推动主轴承转动，带动整车间的机器工作。但是换了电动机之后呢，工作方式变了，动力可是变得非常分散，比如你拿在手上吹头发的吹风机。带着微型电动机的吹风机和传统的蒸汽机在工作范式上就完全不同，采用 AI 大模型之后，企业的业务流程也存在范式改造的过程，并非一朝一夕可以完成的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所以，上半年我遇到的、参与的或者听说的那些大而全的 AI 项目，一半是在可行性推演中没有被验证，一半是交付之后效果很不理想，成功者寥寥。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）下半年：回归理性，小而难&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在今年 7 月份开始，陆续有一些传统大企业找上门来，包括非常知名的企业，以及世界 500 强和多家中国 500 强。如果从时间上来说，他们属于 AI 投入相对较晚的了，但他们的优势是需求非常明确，要求也极高。比如有些企业仅仅就是解决一个咨询服务的需求，在产品范围上就是一个 AI 问答，但要求准确率接近 100%，就像我们 CTO 在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《AIGC 时代的淘金者，TorchV 这一年的心路历程》&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;说到社保咨询一样。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;小而难的好处很明显，我能看到的是下面几点：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对企业现有业务流程改造相对较小，内部推动的阻力相对较小，企业客户配合度高；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;切口小，需求明确，建设成果的考核清晰可量化；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用功能较小但可用性较高的 AI 产品，可以让企业内部员工快速接受 AI，做进一步业务流程改造的前期预热；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;乐于承接大而全需求的合作厂商多半是外包性质的（这个观点有点伤人，但确实是我看到的现状），而专业的、交付成功率更高的厂商往往更喜欢需求清晰且有难度的任务。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（三）关于 2025 年的预测&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我在上文中已经有提到，2025 年会有更多企业需求方采用 AI 技术，但企业永远不会为你的技术买单，他们只会为他们自己的使用价值买单。比如可以帮助他们提升销售额、业务流转效率更高，或者和竞争对手的竞争中获得优势，还有就是降低成本等等。所以，大模型应用端多端不够，还需要生长出藤蔓围绕着企业流程开花结果，这个任务最终会落在应用（Application）——内化了企业流程、借助了大模型能力的、带有可交互界面的程序。2025 年会成为大模型应用或 AI 应用之争。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外还有一个趋势也很明显，就是知识管理和协作。我们都说这波 AI 浪潮把原来「没用」的非结构化数据给激活了，所以我们马上会看到那些原来堆在角落里面的「冷」文件和知识（类似 wiki）会被大量启用，「热」文件和知识会爆炸性增长，知识的协作和管理会成为新的问题——就像你有再多的先进坦克和战车，却因为无序的交通都堵在阿登森林了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;AI 从业者观察&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因为我看到的不代表真相，所以这一章节会很短，仅仅分享两个发现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）AI 技术的下坡&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有两个感受（非证据）可以说明这一点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 关于 AI 大模型的自媒体数量在减少，从搜索引擎趋势，加上我和几个业内朋友的 blog、公众号以及 X 的阅读量下降趋势也可以佐证这一点，下半年虽然市场理性回归，但整体热度是在下降的。OpenAI 不再持续放大招可能也是重要原因之一。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 我前期接触了很多因为 AI 热潮而在企业内部抽调精干力量组成的 AI 小组、AI 研究组和 AI 创新组等团队的成员，但下半年有不少类似团队已经解散，人员回归到原有岗位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;还有一点就是上半年加我微信好友的很多独立开发者或在职的个人，多半也已经在寻觅了半年机会之后放弃了继续探索，这一点在和他们交流，以及他们朋友圈的内容变化中可以明显感知。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;619&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e0b61fa320f93745cf792daf0e22d6fe227.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图：技术采用生命周期。现阶段的 AI 大模型市场似乎正处于过高期望之后的下坡过程中&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是这并不是坏事，上图已经告诉我们，这是必然规律。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）价值开始显现&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前还奔跑在 AI 大模型应用赛道的公司，很多已经开始创造出客户价值，有了自己的优势。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;包括在海外风生水起的 Dify，在内容提取端的合合，以及肯定会成为国内 AI 巨无霸的火山引擎。当然我们还看到了一些深耕垂直行业的优秀团队，特别是在法律、医药、教育等行业。我们也在今年 6 月份开始做了产品转身，现在已经不再烦恼人家问我们「你们和 dify、fastgpt、ragflow 有什么区别」，因为赛道已经开始慢慢不一样了，而且这个不一样依然是产品层面的，和服务什么行业无关。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;198&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e8cb1ce63e159dcd77334342f311f629de.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;卢向东&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;国内最早的 RAG 实践者之一，杭州萌嘉网络科技 CEO，公司主要研发 TorchV 品牌的大模型应用和知识库产品。公众号：土猛的员外。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#333333&quot;&gt;《2024 中国开源开发者报告》&lt;/span&gt;由开源中国 OSCHINA、Gitee 与 Gitee AI 联合出品，聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;报告整体分为三章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;中国开源开发者生态数据&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;TOP 101-2024 大模型观点&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;国产 GenAI 生态高亮瞬间&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告，请点击&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中国开源开发者报告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529520</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529520</guid>
            <pubDate>Sat, 08 Feb 2025 10:48:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>2024 年 AI 编程技术与工具发展综述</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，开源中国 OSCHINA、Gitee 与 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot; rel=&quot;nofollow&quot;&gt;联合发布了《2024 中国开源开发者报告》&lt;/a&gt;。报告聚焦 AI 大模型领域，对过去一年的技术演进动态、技术趋势、以及开源开发者生态数据进行多方位的总结和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整报告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;2024 中国开源开发者报告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型观点》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同济大学特聘教授、CCF 杰出会员&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;朱少民&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;对 2024 年 AI 编程技术与工具发展进行了总结。全文如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年 AI 编程技术与工具发展综述&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/朱少民&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年 8 月下旬，一款 AI 代码编辑器——Cursor 火爆全球，火到一位 8 岁小女孩拿着它学编程，几十分钟内搭起来一个聊天机器人，其演示吸引来 180 万人在线围观。这导致有人大胆预言，未来编程只需要狂按 Tab 就够了。Cursor 确实好用，包括新推出的「光标位置预测」功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是 AI 编程发展没有那么快，在国内生成代码采纳率还比较低，根据《2024 软件研发应用大模型国内现状调研报告》，多数团队在 10-40% 之间，如图 1 所示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;454&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce564f5bd0fc36ee2aaa7dc75de3d3e72f3.png&quot; width=&quot;1101&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;图 1 大模型（LLM）在编程上的应用及其生成代码的采纳率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 2024 年，我们还看到了「AI 程序员」Devin 的诞生，Devin 能够独立完成复杂的编码和调试任务、自主查找和修复代码库中的错误，构建和部署应用程序。在 SWE-bench 编码基准测试中，Devin 能够解决 GitHub 中 13.86% 的真实问题，有了很大提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;说起 SWE-bench 编码基准测试（https://www.swebench.com/），2024 年进步很快，以 OpenAI 建立的 verified 子集（500 个问题）为例，4 月开始时，成功率只有 2.8%，到现在已提升到 53%，这表明 AI 在编程能力方面取得了显著的进步。这一提升反映了 AI 编程几个关键因素，正好用来总结 2024 年 AI 编程的进展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;模型能力的增强：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 模型的架构和算法不断优化，如从 Claude 3 Opus、GPT-4o 到 Claude 3.5 Sonnet、Claude 3.5 Haiku，大模型自身的能力不断提升，使得模型能够更好地理解和解决复杂的编程问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;智能体（AI agent）的引进：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能体可以收集和学习与任务相关的知识，可以直接调用静态代码分析工具、直接调用搜索引擎和 API 为编程任务服务，并通过构建代码仓库知识图来帮助大模型全面理解软件仓库的结构和依赖关系，从而更好地定位问题根源并生成有效的代码补丁。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能体还可以动态获取代码片段和问题相关的信息，并分析和总结收集到的信息，以便规划出更好的解决方案。例如从 RAG+GPT 4(1106) 的 2.8% 提升到 SWE-agent+GPT 4(1106) 的 22.4%、从 RAG+Claude 3 Opus 的 7% 提升到 SWE-agent+Claude 3 Opus 的 18.2%，效果都比较显著。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;多模态能力：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多模态 LLM 使智能体能够综合利用视觉和文本信息，可以理解软件用户界面、处理的图表、可视化数据、语法高亮和交互映射等内容，更好地理解任务陈述以及获取任务相关的产品信息、开发过程信息，从而更全面地理解和解决问题。目前排在 SWE-bench verified 前 4 位都使用了 Claude-3.5-Sonnet，而它是多模态的、具备处理文本和视觉信息的能力，使其能够理解和修复包含图像或其他视觉元素的 GitHub 问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;和工具集成的框架：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以支持智能体在处理复杂任务时进行更好的任务管理和执行，并促进不同 AI 模型和工具之间的协作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如 Composio SWE-Kit 集成文件操作、代码分析、Shell 命令执行、知识库管理和数据库操作等工具或能力，优势互补，将 SWE-bench verified 大幅度提升到 48.6%。再比如 OpenHands+CodeAct v2.1 将智能体的行为整合到统一代码行动空间的框架，允许 OpenHands 在编程任务中扮演全方位的智能助手角色，目前排在 SWE-bench verified 第一位（53%）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基于代码大模型的自身进化，以及 RAG 技术、智能体的有力支持，从而 LLM 有更好的上下文感知能力。例如，在代码大模型预训练时，其训练语料中加入抽象语法树（AST）、代码依赖关系等数据，新的代码生成模型则具有更强的上下文感知能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在此基础上，基于 AI 的编程工具能够根据给定的上下文（如函数名、注释、部分代码等）检索出最相关的代码片段和文档，能够提供完整的函数或代码块建议。这也使得 LLM 能够参考海量的代码库和技术文档，这不仅能缓解大模型的幻觉问题，显著提升代码生成与理解的准确性，而且能符合上下文的代码，更能满足开发的业务需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未来，研发人员和多个智能体、工具协同工作来完成编程工作，如论文 Flows:Building Blocks of Reasoning and Collaborating AI 所描述的（图 2 所示），构成一个复合竞争性编码流程，研发人员更多是提需求，由 LLM 和智能体实现自主编程的过程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;546&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-243a86d5adf6ad21f5d418b5511f81f0f05.png&quot; width=&quot;1107&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;图 2 由 LLM 和智能体实现自主编程的过程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着大模型技术的迅速发展，在今年，我们明显能感到，AI 已从单一的辅助工具，逐渐演变为软件开发人员不可或缺的助手或伙伴。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了前面已介绍的 Cursor、Composio SWE-Kit、OpenHands CodeAct 等工具之外，国内主要使用 chatGPT、GitHub copilot、通义灵码、CodeGeeX、文心快码、蚂蚁 CodeFuse 等编程工具，国外还出现一些受欢迎的、新的编程工具，如 Codeium IDE Cascade、Solver ai、Websim ai 等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;493&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c4bc35246b3a57ea83c92f455823fb59b03.png&quot; width=&quot;796&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图 3 国内编程助手使用状况（来源同图 1）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这些工具让我们能感受到 AI 卓越的生成能力和理解能力，帮助我们更高效地完成代码生成、代码评审、代码解释到单测生成、缺陷定位、代码优化等任务。这种进步也体现在今年国内企业一些落地实践中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一些大厂，LLM 已经实际应用到代码审查或 CI/CD 流程中（如 pull request），自动识别代码质量问题并提出改进建议。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些企业结合智能体和相关工具的支持，让基于 LLM 的研发平台生成代码流程图和类图，辅助自然语言解释，使得开发者更直观地理解代码结构和执行流程，增强智能编程的可视性和交互性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些开发团队借助智能体和 RAG 技术检索历史上已知的代码缺陷模式和已知问题，从而比较准确地识别潜在的缺陷和安全漏洞，甚至能够分析代码的功能意图，全面提升代码评审的能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些团队，根据 UI 设计图，让 LLM 自动生成相应的前端代码，大大减少了手动编码的时间，加快了从设计到实现的流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从应用效果看，前面调研的数据可供参考。在国内 AI 编程开展比较好的大厂，超过 80% 的工程师在使用 AI 编程工具完成日常的编程工作，近 30% 入库的代码由 AI 生成，生成代码平均采纳率超过 40%，有些产品线达到 60%。仅仅在编程这一项工作（虽然只占开发人员 20-30% 的工作量）上，研发效率能提升 20-30%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;850&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-33b0554523cedb9d91ec30064a650d426eb.png&quot; width=&quot;1292&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图 4 大模型时代的软件研发正确方式&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然，我们不能局限于这一个编程环境，最好要从需求开始就应用大模型。ATDD（验收测试驱动开发）是大模型时代软件研发的正确打开方式，让大模型帮我们生成需求及其验收标准，业务约束更明确了，上下文更清楚了，在此基础上分别由不同的模型生成产品代码和测试代码，再让它们之间相互验证和博弈（如图 4 所示），最终交付高质量的软件。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未来，随着 AI 技术的不断成熟和创新，AI 编程工具将进一步提升智能化和可解释性，支持更多的编程语言和平台，并通过强化学习实现自适应优化。为了全面发挥 AI 编程技术的潜力，开发团队需要不断学习和适应新技术，优化开发流程，确保 AI 工具的有效应用和高质量输出。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;作者简介：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ee7692932d7b07e9b2a9ffb1562965629.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;朱少民&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同济大学特聘教授、CCF 杰出会员、CCF TF 软件质量工程 SIG 主席、CCF2023 杰出演讲者、软件绿色联盟标准评测组组长、QECon 大会和 AiDD 峰会发起人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近三十年来一直从事软件工程的教学与研究工作，先后获得多项省、部级科技进步奖，已出版了二十多部著作和 4 本译作。曾任思科（中国）软件有限公司 QA 高级总监、IEEE ICST 2019 工业论坛主席、IEEE ICST、QRS 等程序委员、《软件学报》和《计算机学报》审稿人等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529447</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529447</guid>
            <pubDate>Sat, 08 Feb 2025 10:46:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>DeepSeek 官网全球日访问量超越谷歌 Gemini</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.similarweb.com%2Fwebsite%2Fdeepseek.com%2F%23competitors&quot; target=&quot;_blank&quot;&gt;据 SimilarWeb 数据显示&lt;/a&gt;，DeepSeek.com 的日访问量已经超过了谷歌的 Gemini 和 Character.AI。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-75442688c9422272ece272970d296377818.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;报告显示 DeepSeek 的 V3 模型在第三方基准测试中表现优于 Meta 的 Llama 3.1、OpenAI 的 GPT-4o 以及阿里巴巴的 Qwen 2.5，且成本显著更低，这使得 DeepSeek 的热度急剧攀升。&lt;/p&gt; 
&lt;p&gt;SimilarWeb 的数据显示，DeepSeek.com 在上周二（1 月 27 日）创下了 4900 万次访问量的纪录，与前一周相比增长了 614%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-64acd5aa419c5232f687b45cec93c369e7a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这一数字不包括基于应用的流量，足以凸显 DeepSeek 的迅猛发展势头。一个月前，该网站的日均访问量仅为 30 万次，而到了 1 月 27 日，这一数字飙升至 3340 万次，并引发了美国科技股的波动。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332691</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332691</guid>
            <pubDate>Sat, 08 Feb 2025 08:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Linux 内核新补丁调整 AC 电源插拔行为，向 Windows 看齐以提升硬件兼容性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;AMD 工程师主导优化，解决便携设备休眠唤醒痛点。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;近日，AMD 工程师 Mario Limonciello 向 Linux 内核&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flinux-pm%2F20250208162210.3929473-1-superm1%40kernel.org%2F&quot; target=&quot;_blank&quot;&gt;提交了一系列补丁&lt;/a&gt;&lt;/u&gt;，旨在调整系统在&lt;strong&gt;s2idle（挂起到空闲）&lt;/strong&gt;状态下的 AC 电源插拔行为，使其更贴近 Windows 11 的逻辑。&lt;/p&gt; 
&lt;p&gt;这一改动主要针对笔记本电脑、手持游戏设备（如 Steam Deck 同类产品）在休眠时因电源状态切换导致的兼容性问题，尤其是此前曝光的 Legion Go S（搭载 AMD Ryzen Z2 芯片）的固件级故障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;为何需要「模仿」Windows？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当前，Linux 与 Windows 在 s2idle 状态下的电源行为存在关键差异：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;：插入或拔出 AC 电源时，系统会完全唤醒，若后续无用户操作则重新进入睡眠。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;：AC 事件仅触发短暂唤醒后立即重回休眠，可能导致硬件固件因快速状态切换出现异常（例如某些设备无法正确处理快速进入/退出低功耗模式）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Limonciello 指出，由于 OEM 厂商通常基于 Windows 进行硬件验证，Linux 的差异行为易暴露底层固件缺陷。新补丁通过记录休眠前的电池状态，并在 AC 事件后对比状态变化，决定是否彻底唤醒系统，从而减少「兼容性陷阱」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技术细节：唤醒机制与能耗监控&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;唤醒逻辑重构&lt;/strong&gt;&lt;br&gt; 补丁在 ACPI 电池驱动中新增&lt;code&gt;suspend_state&lt;/code&gt;字段，休眠时保存当前电源状态（如是否充电）。若唤醒后检测到状态变化（如从充电变为放电），则触发系统完全唤醒，而非立即休眠。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;能耗统计透明化&lt;/strong&gt;&lt;br&gt; 新增&lt;code&gt;/sys/power/suspend_stats/last_sleep_energy&lt;/code&gt;文件，以&lt;strong&gt;毫安时（mAh）&lt;/strong&gt;为单位记录上次休眠周期的电池消耗量，方便用户空间工具分析功耗问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;争议与用户控制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尽管新行为默认启用，但开发者社区对其适用场景存在分歧。例如，若笔记本合盖时连接电源，是否应强制唤醒？Limonciello 认为，这与用户外接扩展坞的场景需求一致，但用户仍可通过禁用 ACPI 电池设备的&lt;code&gt;power/wakeup&lt;/code&gt;属性恢复旧逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;影响与未来展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此次调整尤其利好搭载 AMD 芯片的设备，但惠及所有支持 s2idle 的 x86/ARM 平台。随着 Linux 在掌机市场的渗透（如 Steam OS 设备），此类优化将显著提升用户体验。此外，补丁的「Windows 兼容性驱动」思路或成为未来硬件支持的新范式，减少厂商因生态差异对 Linux 的适配成本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;br&gt; Linux 在电源管理领域的「向 Windows 学习」，并非妥协，而是以用户体验为优先的务实选择。这一补丁不仅修复了长期存在的兼容性痛点，也为开源生态与 OEM 厂商的协作提供了新思路。未来，类似「求同存异」的优化或成常态，进一步模糊两大操作系统在硬件支持上的体验边界。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</guid>
            <pubDate>Fri, 07 Feb 2025 11:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>图解系列｜DeepSeek-R1 的出众推理能力从何而来？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; DeepSeek-R1 到底有什么特别之处？它为什么能在推理任务上取得如此出色的表现？这背后的训练方法又蕴含着怎样的创新？&lt;/p&gt; 
 &lt;p&gt;当我们需要模型处理数学题、编程任务，或是进行逻辑分析时，高质量的推理能力显得尤为重要。然而，传统的训练方法往往需要耗费大量人力物力，这对许多研究团队和企业来说都是不小的负担。&lt;/p&gt; 
 &lt;p&gt;今天这篇深度解析 DeepSeek-R1 训练方法的文章，将展示一个令人耳目一新的解决方案：如何通过创新的强化学习方法，在少量高质量人工标注数据的情况下，打造出一个推理能力出众的 AI 模型。文章详细介绍了 DeepSeek 团队如何通过&quot;自动验证机制&quot;来训练模型，这种方法不仅大大降低了对人工标注数据的依赖，还能持续提升模型的推理质量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Jay Alammar&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fa463c0670c30f6fa2098b0a2cfb8cedbd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 代表了人工智能发展的又一重要里程碑。对于机器学习领域的研究人员与开发者群体而言，这次发布之所以备受关注，主要有以下两点：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;首先，这是一款开源权重的模型，并且提供了更小的、经过蒸馏的版本；&lt;/li&gt; 
 &lt;li&gt;其次，它公布并深入探讨了训练方法，该方法能够复现类似于 OpenAI O1 的推理模型。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;本文将带您了解这一模型的构建过程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;01 回顾：大语言模型（LLMs）的训练方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02 DeepSeek-R1 的训练步骤&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.1- 长推理链的 SFT 数据&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.2- 一个过渡性的、擅长推理的高质量大语言模型（但在非推理任务上表现稍逊）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3- 利用大规模强化学习（RL）构建推理模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.1- 以推理为导向的大规模强化学习（R1-Zero）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.2- 利用过渡性推理模型生成 SFT 推理数据&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.3- 常规强化学习训练阶段&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03 模型架构&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 回顾：大语言模型（LLMs）的训练方法&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;与大多数现有的大语言模型一样，DeepSeek-R1 也是逐个生成 token，但其独特之处在于擅长解决数学和推理问题。这是因为它能够通过生成一系列思考 tokens 来详细阐述其思考过程，从而更加深入地处理问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5b41809ec9dc436f27455aa39b8ef58c830.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下图摘自书籍《Hands-On Large Language Models》的第 12 章，展示了创建高质量大语言模型的三个主要步骤：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5960076009014b645e62ad11df7e601f3dd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;语言建模阶段&lt;/strong&gt;，我们利用海量的网络数据训练模型预测下一个词汇，从而得到一个基础模型。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;监督式微调阶段&lt;/strong&gt;，这一步骤让模型在执行指令和回答问题时更加得心应手，进而得到一个指令调优的模型或称为监督式微调/SFT 模型。&lt;/p&gt; 
&lt;p&gt;3）最后是&lt;strong&gt;偏好调优阶段&lt;/strong&gt;，这一步骤进一步优化模型的行为，使其更符合人类偏好，最终形成的是你在各种平台和应用中使用的偏好调优后的 LLM。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeek-R1 的训练步骤&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek-R1 遵循了这一通用框架。其第一步的具体内容源自于之前关于 DeepSeek-V3 模型的研究论文[1]。R1 使用的是该论文中的基础模型（并非最终的 DeepSeek-V3 模型），并且同样经历了 SFT（监督式微调）和偏好调优阶段，但它的独特之处在于这些阶段的具体操作方法。&lt;/p&gt; 
&lt;p&gt;在 R1 的构建过程中，有三个关键点值得特别关注。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 长推理链的 SFT 数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71048a70e57a4dd98c33f2c0fb43d5a0d16.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这些长思维链推理的实例数量庞大（总共达到 60 万个）。如此大规模的实例获取难度极高，且若要依靠人工标注，成本也将极为昂贵。&lt;/strong&gt; 因此，这些实例的创建过程是我们需要强调的第二个独特之处。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 一个过渡性的、擅长推理的高质量 LLM（但在非推理任务上表现稍逊）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;这些数据是由 R1 的前身，一个专注于推理但尚未命名的姊妹模型所生成的。这个姊妹模型受到了另一个模型 R1-Zero 的启发（我们将在稍后讨论）。它之所以意义重大，并不是因为它是一个非常好用的 LLM，而在于在它的创建过程中，几乎无需依赖标注数据，仅通过大规模的强化学习，就能培育出一个擅长处理推理问题的模型。&lt;/p&gt; 
&lt;p&gt;接着，这个未命名的推理专家模型的输出结果，可以用来训练一个更为多能的模型，它不仅能够处理推理任务，还能应对其他类型的任务，满足用户对大语言模型（LLM）的普遍期待。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4851fe74d4b6fa9ff29c1036a1790de83f4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 利用大规模强化学习（RL）构建推理模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此处分为两个步骤：&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.1- 以推理为导向的大规模强化学习（R1-Zero）&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在此过程中，我们利用强化学习（RL）来构建一个临时的推理模型。随后，这个模型被用于生成用于监督式微调（SFT）的推理示例。然而，能够创建这个模型的关键，在于之前的一项实验，该实验成功打造了一个名为 DeepSeek-R1-Zero 的早期模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fbae4d4fb50b77fa5484a9d220719bbe4d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;R1-Zero 的独特之处在于，它能够在没有经过标注的 SFT 训练集的情况下，依然在推理任务上表现卓越。它的训练过程直接从预训练的基础模型出发，通过强化学习训练（跳过了 SFT 阶段）。它的表现非常出色，能够与 O1 模型相媲美。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd68b8120aaa63d61a0ca7bb0b7333d62ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这一成就重要重大，因为数据一直是机器学习模型能力的助推器。那么，这个模型是如何打破这一传统的呢？这主要归功于以下两点：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 现代基础模型在质量和能力上已经达到了一个临界点（这个基础模型是在高达 14.8 万亿的高质量 tokens 上训练而成的）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 与通用聊天或写作请求不同，推理问题可以实现自动验证或标注。&lt;/strong&gt; 可以通过以下这个示例来说明这一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例：推理问题的自动验证&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是一个可能出现在 RL 训练步骤中的提示词/问题：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;编写一段 Python 代码，获取一个数字列表，返回排序后的列表，并在列表开头添加数字 42。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;这样的问题非常适合自动验证。假设我们将这个问题抛给正在训练的模型，它会生成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用软件语法检查器可以验证生成的代码是否为有效的 Python 代码。&lt;/li&gt; 
 &lt;li&gt;我们可以运行这段 Python 代码，以检查其是否能够成功执行。&lt;/li&gt; 
 &lt;li&gt;其他现代代码生成 LLM 可以创建单元测试来验证代码的行为是否符合预期（它们自身无需具备推理能力）。&lt;/li&gt; 
 &lt;li&gt;我们甚至可以进一步，通过测量代码的执行时间，让训练过程偏好那些性能更优的解决方案，即使其他解决方案也是正确的 Python 程序。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在训练步骤中，我们可以向模型提出这样的问题，并生成多种可能的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f83bf0627d5f3ff8f1fda69f2a0769899e6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们可以不依赖人工干预，自动进行检查，发现第一个输出根本不是代码。第二个输出是代码，但并非 Python 代码。第三个输出看似是一个解决方案，却未能通过单元测试，而第四个输出则是正确的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1c61910f7a45c46610b945fcd73cf50a89.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些反馈都是可以直接用来优化模型的信号。这一过程当然是在大量示例（以小批量形式）和连续的训练步骤中完成的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c2e60359299a142483ec274c460a0c90dc6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些奖励信号和模型更新是模型在强化学习训练过程中不断进步的关键，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ce02ceb2d7a3049768b4b796755b83f0f9f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与此能力提升相伴的是，模型生成了更长的响应，即使用了更多的思考 tokens 来处理问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4c90ef53271c751b695ad334dddfbb87f40.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;尽管这个过程很有价值，但 R1-Zero 模型在推理问题上的高分表现背后，仍存在一些问题，使其实际可用性未达理想状态。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;虽然 DeepSeek-R1-Zero 展现出了卓越的推理能力，并自主发展出了出人意料的强大推理行为，但它也遭遇了一些挑战，比如文本可读性不佳和语言混杂等问题。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;R1 模型的设计目标是提高可用性。因此，它（DeepSeek-R1-Zero）不仅仅完全依赖于强化学习过程，而是如前文所述，在以下两个方面发挥作用：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 创建一个过渡性的推理模型，用以生成监督式微调（SFT）的数据点。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 训练 R1 模型，以在推理和非推理问题上取得进步（利用其他类型的验证器）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-694a728dfc22ac72182045659f53b114a1b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.2- 利用过渡性推理模型生成 SFT 推理数据&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;为了提升过渡性推理模型的实际效用，我们对其进行了监督式微调（SFT）训练，这一步骤在数千个推理问题示例上进行（部分示例由 R1-Zero 生成并筛选）。在论文中，这些示例被称为&quot;冷启动数据&quot;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2.3.1. 冷启动阶段&lt;/p&gt; 
 &lt;p&gt;与 DeepSeek-R1-Zero 不同，为了防止基础模型在强化学习训练初期出现不稳定的冷启动问题，对于 DeepSeek-R1，我们构建并收集了少量长思维链（CoT）数据对模型进行微调，将其作为初始的强化学习策略模型。为收集这类数据，我们探索了多种方法：使用带有长 CoT 示例的小样本提示技术、直接提示模型生成带有反思和验证的详细答案、收集 DeepSeek-R1-Zero 生成的易读格式输出，并通过人工标注员对结果进行后处理细化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;但或许你会问，既然我们已经有了这些数据，为什么还需要依赖强化学习过程呢？答案在于数据的规模。我们可以获取的可能只有 5,000 个示例的数据集，而训练 R1 则需要 600,000 个示例。&lt;/strong&gt; 这个过渡性模型帮助我们缩小了这一差距，并使我们能够合成生成那些极为重要的数据。&lt;/p&gt; 
&lt;p&gt;对于监督式微调（SFT）这一概念，可能你还不太熟悉，它是一种训练过程，通过向模型展示形式为提示词和正确补全的训练示例来进行。下面这个图展示了书籍《Hands-On Large Language Models》第 12 章中的一些 SFT 训练示例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e00bd1bb414511cf4a13d9225c9ed6bb7ba.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.3- 常规强化学习训练阶段&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;这样，R1 模型不仅在推理任务上表现卓越，还能有效地应对其他非推理类任务。这一过程与我们之前提到的强化学习过程相似，但因为它涵盖了非推理领域的应用，所以它还引入了一个实用性奖励模型和安全性奖励模型（与 Llama 模型有相似之处），用于处理这些应用领域的提示词。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cd6bf829caa63d1804a38dcdf71e88e2293.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型架构&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;与 GPT2[2] 和 GPT3[3] 等同源的早期模型一样，DeepSeek-R1 也是由 Transformer[4] 解码器块堆叠而成，总共包含了 61 个这样的块。其中，前三个块是密集层，而后续的则是采用了混合专家层（MoE）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-817d8e03a6a9f616d918a3f53eb7e8bdede.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;关于模型的维度大小和其他超参数配置，具体信息如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0acee698853f2545eaf2350f4bae0ca92ea.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有关模型架构的更多详细信息，可以在他们之前发表的两篇论文中找到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V3 Technical Report[1]&lt;/li&gt; 
 &lt;li&gt;DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models[5]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 Conclusion&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;通过上述内容，相信你现在应该对 DeepSeek-R1 模型有了基本的理解。&lt;/p&gt; 
&lt;p&gt;如果你觉得需要更多基础知识来理解这篇文章，我建议你获取一本《Hands-On Large Language Models》[6]或者在线在 O&#39;Reilly[7] 上阅读，并在 Github[8] 上查看相关内容。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Jay Alammar&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Machine learning R&amp;amp;D. Builder. Writer. Visualizing artificial intelligence &amp;amp; machine learning one concept at a time. @CohereAI.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你觉得 AI 模型最难掌握的是哪种推理能力？欢迎在评论区分享你的观点👇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中链接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2412.19437v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2412.19437v1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-gpt2%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-gpt2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fhow-gpt3-works-visualizations-animations%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/how-gpt3-works-visualizations-animations/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-transformer%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-transformer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2401.06066&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llm-book.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.llm-book.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearning.oreilly.com%2Flibrary%2Fview%2Fhands-on-large-language%2F9781098150952%2F&quot; target=&quot;_blank&quot;&gt;https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FhandsOnLLM%2FHands-On-Large-Language-Models&quot; target=&quot;_blank&quot;&gt;https://github.com/handsOnLLM/Hands-On-Large-Language-Models&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsletter.languagemodels.co%2Fp%2Fthe-illustrated-deepseek-r1&quot; target=&quot;_blank&quot;&gt;https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17553692</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17553692</guid>
            <pubDate>Fri, 07 Feb 2025 10:19:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>豆包开源视频生成模型 VideoWorld</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmXaktIsD3w5BgCJQb6R7xQ&quot; target=&quot;_blank&quot;&gt;据豆包大模型团队官方公众号消息&lt;/a&gt;&lt;/u&gt;，在北京交通大学和中国科学技术大学的联合研究下，由豆包大模型团队提出的 「VideoWorld」 视频生成实验模型近日正式开源。&lt;/p&gt; 
&lt;p&gt;据介绍，不同于 Sora 、DALL-E 、Midjourney 等主流多模态模型，&lt;strong&gt;VideoWorld 在业界首次实现无需依赖语言模型，即可认知世界&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.09781&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.09781&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代码链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2FVideoWorld&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/VideoWorld&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;项目主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmaverickren.github.io%2FVideoWorld.github.io&quot; target=&quot;_blank&quot;&gt;https://maverickren.github.io/VideoWorld.github.io&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;「VideoWorld」 通过分析和处理大量视频数据，实现了复杂的推理、规划和决策能力。研究团队的实验显示，模型在仅有 300M 参数的情况下，便取得了显著的效果。与现有依赖语言或标签数据的模型不同，VideoWorld 能够独立进行知识学习，尤其在折纸、打领结等复杂任务中，能够提供更加直观的学习方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fc6aac365dbf1a8e0403b8bb24da8452019.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了验证该模型的有效性，研究团队搭建了围棋对战和机器人模拟操控两种实验环境。围棋作为一项高度策略性游戏，可以有效评估模型的规则学习和推理能力，而机器人任务则考察模型在控制和规划方面的表现。在训练阶段，模型通过观看大量视频演示数据，逐步建立起对未来画面的预测能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332996</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332996</guid>
            <pubDate>Fri, 07 Feb 2025 10:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 服务站点大全</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;中国信息通信研究院去年 7 月 11 日发布国内首个算力互联公共服务平台，并联合产业界开展算力互联网共识共创行动。&lt;/p&gt; 
&lt;p&gt;该算力互联公共服务平台是推进和管理全国算力互联互通和算力互联网体系的综合服务平台，包括算力标识管理、算力互联网业务查询、算力统一大市场、政策和研究、标准体系、开源项目和运行监测等功能。&lt;/p&gt; 
&lt;p&gt;中国信通院今日宣布，为便利国内 AI 开发者「找调用算力」需求，算力互联公共服务平台宣布增设全球云服务商 DeepSeek 服务能力汇总功能页面（截至 2 月 5 日已汇集 22 家服务商）。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstateioc.cn%2Farticle-details%2FVjX&quot; target=&quot;_blank&quot;&gt;https://stateioc.cn/article-details/VjX&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;最后欢迎各位使用 Gitee AI —— Gitee AI 的 Serverless API 为您提供开箱即用的企业级的大模型 API 服务。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/174609_Xr4I_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332995</guid>
            <pubDate>Fri, 07 Feb 2025 09:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ai.com 域名现已跳转至 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;现在在浏览器输入&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.com%2F&quot; target=&quot;_blank&quot;&gt;ai.com&lt;/a&gt;，将直接重定向至 DeepSeek 官网 (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.deepseek.com%2F&quot; target=&quot;_blank&quot;&gt;https://chat.deepseek.com/&lt;/a&gt;)。&lt;/p&gt; 
&lt;p&gt;ai.com 域名的定位被视作前沿 AI 的象征，此前这一域名曾长期跳转至 ChatGPT、谷歌 Gemini 以及马斯克的 xAI 官网。根据 Whois 数据，ai.com 域名注册于 1993 年，有效期直至 2031 年 5 月，注册联系人来自马来西亚首都吉隆坡。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;219&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ceffc7eb4acfec05d9bcabc263bf478854.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332978</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332978</guid>
            <pubDate>Fri, 07 Feb 2025 08:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>消息称软银投资 400 亿美元，取代微软成为 OpenAI 最大金主</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息人士向 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F07%2Fsoftbank-set-to-invest-40-billion-in-openai-at-260-billion-valuation-sources-say.html&quot; target=&quot;_blank&quot;&gt;CNBC &lt;/a&gt;透露，软银即将完成对 OpenAI 的 400 亿美元初始投资，投资前估值为 2600 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Faber 报道称软银将在未来 12 到 24 个月内支付这笔资金，这意味着 OpenAI 的投资后估值将达到 3000 亿美元，第一笔款项最快将于今年春季到账。软银最多可以筹集其中的 100 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;295&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-34a9ea12a4cc3504f16154eda1fdbbc331a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;部分资金预计将用于 OpenAI 对 Stargate 的承诺。Stargate 是软银、OpenAI 和甲骨文公司的合资企业，由美国现任总统唐纳德-特朗普于今年 1 月宣布成立。该计划要求向美国的人工智能基础设施投资数十亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;这一轮融资也意味着软银将超越微软，成为 OpenAI 公司的最大投资者。去年 10 月，私人投资者对 OpenAI 的估值为 1570 亿美元。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332971/softbank-40-billion-openai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332971/softbank-40-billion-openai</guid>
            <pubDate>Fri, 07 Feb 2025 08:15:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Yandex 开发并开源 Perforator，每年可为企业节省数十亿美元的服务器基础设施成本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;推出&lt;/span&gt; &lt;span&gt;Perforator&lt;/span&gt;&lt;span&gt;，这是一款可以识别和评估公司整个代码库中效率低下的代码的工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;帮助开发人员识别最占资源的代码部分，并提供详细的统计数据，以便后续优化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;该解决方案可以帮助企业每年减少 &lt;/span&gt;&lt;span&gt;20% &lt;/span&gt;&lt;span&gt;的 &lt;/span&gt;&lt;span&gt;CPU &lt;/span&gt;&lt;span&gt;资源使用量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通过利，用&lt;/span&gt;&lt;span&gt;Perforator&lt;/span&gt;&lt;span&gt;，企业可以根据公司规模节省数百万甚至数十亿美元的开支，并将资源用于进一步的创新和增长。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;可通过&lt;/span&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyandex%2Fperforator&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#1155cc&quot;&gt;GitHub&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;免费访问。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（上海，&lt;/span&gt;&lt;span&gt;2025&lt;/span&gt;&lt;span&gt;年&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;月&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;日）全球领先的科技公司 &lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;开发并开源了&lt;/span&gt;&lt;span&gt; Perforator&lt;/span&gt;&lt;span&gt;，这是一款用于对服务器和应用程序进行持续实时监控和分析的创新工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;帮助开发人员识别最占资源的代码部分，并提供详细的统计数据，以便进行后续优化。通过识别代码中的低效部分并支持基于配置文件的优化，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;提供了准确的数据，使企业能够手动优化其应用程序，根据公司规模，降低基础设施成本最多可达 &lt;/span&gt;&lt;span&gt;20%&lt;/span&gt;&lt;span&gt;。这每年可能节省数百万甚至数十亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;帮助企业在不牺牲性能的情况下最大化服务器的使用效率，&lt;/span&gt;&lt;span&gt;」 Yandex &lt;/span&gt;&lt;span&gt;的高级开发人员、&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;团队负责人&lt;/span&gt;&lt;span&gt; Sergey Skvortsov &lt;/span&gt;&lt;span&gt;表示。&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;企业使用&lt;/span&gt;&lt;span&gt; Perforator &lt;/span&gt;&lt;span&gt;可以优化代码，减少服务器负载，最终降低能源和设备成本。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么使用 &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Perforator&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;资源优化对于大型数据中心、大型科技公司以及资源有限的小型企业和初创公司至关重要。公司可以利用 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;优化现有的基础设施，而无需投资额外的设备，也不牺牲性能。该工具已经在 &lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;的许多服务中使用了超过一年，现在可以供全球的公司、开发人员和研究人员使用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;公司可以将 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;部署在自己的服务器上，减少对外部云服务提供商的依赖，同时保持对数据的完全控制。这使得 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;非常适合那些对数据安全要求严格且在封闭基础设施中运营的组织。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;可以为各种规模的公司带来益处，从拥有&lt;/span&gt;&lt;span&gt; 10 &lt;/span&gt;&lt;span&gt;至&lt;/span&gt;&lt;span&gt; 100 &lt;/span&gt;&lt;span&gt;台服务器的小型企业，每年节省数百万美元，到拥有数千台服务器甚至更多的大型企业，每年节省数亿美元甚至数十亿美元，&lt;/span&gt;&lt;span&gt;」 Sergey Skvortsov &lt;/span&gt;&lt;span&gt;指出。&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;无论公司规模如何，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;都能帮助您减少基础设施成本，为进一步的创新和增长释放更多资源。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;如何工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;提供了关于服务器资源使用的详细洞察，并分析代码对性能的影响，突出了哪些应用程序消耗了最多的系统资源。&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;使用&lt;/span&gt;&lt;span&gt; eBPF &lt;/span&gt;&lt;span&gt;技术在&lt;/span&gt;&lt;span&gt; Linux &lt;/span&gt;&lt;span&gt;内核中运行小程序，既安全又不会拖慢系统速度。&lt;/span&gt;&lt;span&gt;eBPF &lt;/span&gt;&lt;span&gt;能够在不更改源代码的情况下，改善监控、安全性和性能优化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;支持&lt;/span&gt;&lt;span&gt; C&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;C++&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Go&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Rust&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Python &lt;/span&gt;&lt;span&gt;和 &lt;/span&gt;&lt;span&gt;Java &lt;/span&gt;&lt;span&gt;等原生编程语言。该解决方案通过火焰图提供深入的分析和数据可视化，使问题诊断变得易于管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;287&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f866d0af24a5577182b973257c103fef72e.png&quot; width=&quot;602&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;生成的火焰图示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;在&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;的高需求环境中经过了超过一年的实战测试，提供了广泛的功能，使其成为一款可靠且多功能的服务器性能监控和优化解决方案，&lt;/span&gt;&lt;span&gt;」 Sergey Skvortsov&lt;/span&gt;&lt;span&gt;补充道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;的一个关键优势是支持基于配置文件的优化（&lt;/span&gt;&lt;span&gt;PGO&lt;/span&gt;&lt;span&gt;），它能够自动将&lt;/span&gt;&lt;span&gt; C++ &lt;/span&gt;&lt;span&gt;程序的速度提高多达 &lt;/span&gt;&lt;span&gt;10%&lt;/span&gt;&lt;span&gt;。此外，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;设计可以在个别计算机上无缝运行，使其不仅适合大型企业，还能为初创公司和科技爱好者提供便利。更重要的是，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;为大企业提供了包括&lt;/span&gt;&lt;span&gt; A/B &lt;/span&gt;&lt;span&gt;测试功能在内的重要特性，帮助做出更明智的决策。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为开发人员和企业提供的开源解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;将&lt;/span&gt;&lt;span&gt; Perforator &lt;/span&gt;&lt;span&gt;开源的决定体现了&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;致力于促进社区合作开发系统技术的承诺。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「我们相信，开源诸如此类基础系统的技术能够推动全球技术创新」， &lt;/span&gt;&lt;span&gt;Sergey Skvortsov&lt;/span&gt; &lt;span&gt;补充道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;我们的目标是让我们的技术造福全球，并为开发人员和企业提供价值。此外，技术的开放性使我们能够与社区共同做出有关配置文件分析基础设施开发的决策。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;接下来会发生什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;将在近期增加更多功能，包括与&lt;/span&gt;&lt;span&gt; Python &lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt; Java &lt;/span&gt;&lt;span&gt;的更好集成以及对事件的更精确分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;的源代码现已在&lt;/span&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyandex%2Fperforator&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#1155cc&quot;&gt;GitHub&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;上公开，和其他&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;开源解决方案一起提供，如&lt;/span&gt;&lt;span&gt;YaFSDP&lt;/span&gt;&lt;span&gt;，这是一个旨在加速大语言模型训练的工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;是&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;开源工具系列中的最新成员。您可以在&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.yandex%2Fen%2F&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;此页面&lt;/span&gt;&lt;/a&gt;&lt;span&gt;查看该公司所有的开源项目，包括&lt;/span&gt;&lt;span&gt; YaFSDP&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;AQLM&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Ytsaurus &lt;/span&gt;&lt;span&gt;等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332970</guid>
            <pubDate>Fri, 07 Feb 2025 08:14:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>GitHub Copilot：Agent 觉醒</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文翻译自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fnews-insights%2Fproduct-news%2Fgithub-copilot-the-agent-awakens%2F&quot; target=&quot;_blank&quot;&gt;https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ad483c840f09803ba7d525bf909fa01465.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当我们于 2021 年推出 GitHub Copilot 时，我们有一个明确的目标：通过一个帮助开发者编写更好代码的 AI 编程助手，让开发者的生活变得更轻松。这个名字反映了我们的信念，即人工智能（AI）不会取代开发者。相反，它始终站在开发者身边。而且，就像任何优秀的副驾驶一样，Copilot 也可以独立飞行：例如，在提供 PR 回复、自动修复安全漏洞或头脑风暴如何实现问题解决方案时。&lt;/p&gt; 
&lt;p&gt;今天，我们用更加强大的&lt;strong&gt;代理式人工智能 (agentic AI)&lt;/strong&gt;升级了&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffeatures%2Fcopilot%2Fwhats-new%3Futm_source%3Dagent-awakens-announcement%26utm_medium%3Dblogtop%26utm_campaign%3Dagentic-ai&quot; target=&quot;_blank&quot;&gt;GitHub Copilot&lt;/a&gt;——推出&lt;strong&gt;代理模式 (agent mode)&lt;/strong&gt;，并发布 Copilot Edits 的 GA 版本，两者均已在 VS Code 中上线。&lt;/p&gt; 
&lt;p&gt;我们在模型选择器中为所有 Copilot 用户增加了 Gemini 2.0 Flash。我们还首次展示了 Copilot 的新自主代理，代号为 Project Padawan。从代码补全、聊天、多文件编辑到工作空间和代理，Copilot 将人类置于软件开发这一创造性工作的中心。AI 帮助处理你不想做的事情，这样你就有更多时间做自己想做的事情。&lt;/p&gt; 
&lt;h2&gt;代理模式 (Agent mode) 进入预览阶段&lt;/h2&gt; 
&lt;p&gt;GitHub Copilot 的新代理模式能够迭代自己的代码，识别错误并自动修复。它可以建议终端命令并要求您执行它们。它还可以分析运行时错误并具有自我修复功能。&lt;/p&gt; 
&lt;p&gt;在代理模式下，Copilot 不仅会迭代自己的输出，还会迭代输出结果。它会一直迭代，直到完成所有必要的子任务以完成您的提示。现在，Copilot 不仅能够执行您请求的任务，还能够推断出一些未指定但也是实现主要请求所必需的额外任务。更好的是，它能够捕捉到自己的错误，让您无需从终端复制/粘贴回聊天中。&lt;/p&gt; 
&lt;p&gt;以下是一个示例，展示了 GitHub Copilot 如何构建一个用于跟踪马拉松训练的 Web 应用程序：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fof--3Fq1M3w%3Ffeature%3Doembed&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/embed/of--3Fq1M3w?feature=oembed&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要开始使用，您需要下载 VS Code Insiders，然后为 GitHub Copilot Chat 启用代理模式设置：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ba42dfaaf982a3e645b4436884e52e9dbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然后，在 Copilot 编辑面板中，从「编辑」切换到模型选择器旁边的「Agent」：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/113603_Wgac_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;代理模式将改变开发者在使用编辑器时的工作方式；因此，我们将其带给 Copilot 支持的所有 IDE。我们也知道今天的 Insiders 版本并不完美，并欢迎您在接下来的几个月里提供反馈，以便我们改进 VS Code 和底层代理技术。&lt;/p&gt; 
&lt;h2&gt;Copilot Edits 在 VS Code 中已正式 GA&lt;/h2&gt; 
&lt;p&gt;去年 10 月在 GitHub Universe 上宣布的 Copilot Edits，结合了 Chat 和 Inline Chat 的优点，具有对话流程和能够在您管理的文件集中进行行内更改的能力。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%2Fissues%2F95&quot; target=&quot;_blank&quot;&gt;您之前提供的反馈&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%2Fissues%2F1098&quot; target=&quot;_blank&quot;&gt;在 GitHub Universe 上&lt;/a&gt;对于将此功能作为 GA 版本发布到 VS Code 至关重要。感谢！&lt;/p&gt; 
&lt;p&gt;在 Copilot Edits 中，您指定要编辑的一组文件，然后使用自然语言向 GitHub Copilot 提出您所需的内容。Copilot Edits 通过为快速迭代设计的 UI，在您的代码空间中对多个文件进行行内更改。在审查建议的更改、接受可行的更改并进行后续询问时，您始终保持在代码的流程中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c40d04de582b53363ee3ddcdea11b12a89a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在这背后，Copilot Edits 利用双模型架构来提升编辑效率和准确性。首先，一个基础语言模型会考虑 Edits 会话的完整上下文来生成初始编辑建议。您可以在以下基础语言模型中选择您偏好的一个：OpenAI 的 GPT-4o、o1、o3-mini、Anthropic 的 Claude 3.5 Sonnet，以及现在新增的 Google 的 Gemini 2.0 Flash。为了获得最佳体验，我们开发了一个推测性解码端点，针对快速应用文件中的更改进行了优化。基础模型提出的编辑建议会被发送到推测性解码端点，该端点随后将在编辑器中直接提出这些更改。&lt;/p&gt; 
&lt;p&gt;Copilot Edits 之所以有效，是因为它将控制权交给了您，从设置正确上下文到接受更改。整个过程是迭代的：当模型出错时，您可以审查多个文件中的更改，接受好的更改并迭代，直到与 Copilot 一起找到正确的解决方案。接受更改后，您可以运行代码以验证更改，并在需要时在 Copilot Edits 中撤销更改，以回到先前的有效工作状态。Copilot Edits 位于次级侧边栏（默认位于右侧），这样您在审查建议的更改时可以与主侧边栏中的视图（如资源管理器、调试或源代码控制视图）进行交互。例如，您可以在左侧的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fdocs%2Feditor%2Ftesting&quot; target=&quot;_blank&quot;&gt;测试视图中&lt;/a&gt;运行单元测试，同时使用右侧的 Copilot Edits 视图，这样在每次迭代中，您都可以验证 Copilot Edits 提出的更改是否通过了您的单元测试。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fdocs%2Feditor%2Fvoice&quot; target=&quot;_blank&quot;&gt;通过语音&lt;/a&gt;在使用 Copilot 修改时是一种自然的体验。只需与 Copilot 对话，就能使互动变得顺畅且具有对话性。这几乎就像是与一位在该领域具有专业知识的同事互动，使用你在现实生活中结对编程时相同的迭代流程。&lt;/p&gt; 
&lt;p&gt;接下来在我们的路线图上，我们将改进「应用更改」的投机解码端点性能，支持从 Copilot Chat 过渡到 Copilot Edits，通过保留上下文来实现，向工作集建议文件，并允许您撤销建议的块。如果您想成为第一批体验这些改进的人，请确保使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Finsiders%2F&quot; target=&quot;_blank&quot;&gt;VS Code Insiders&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat&quot; target=&quot;_blank&quot;&gt;GitHub Copilot Chat&lt;/a&gt;扩展的预发布版本。为了帮助我们改进这个功能，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%3Futm_source%3Dagent-awakens-announcement%26utm_medium%3Dblog%26utm_campaign%3Dagentic-ai&quot; target=&quot;_blank&quot;&gt;请在我们的仓库中提交问题&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;除了 VS Code 的 GA 之外，Copilot Edits 现在也在 Visual Studio 2022 中处于预览阶段。&lt;/p&gt; 
&lt;h2&gt;Padawan 项目：GitHub 上的 SWE 代理&lt;/h2&gt; 
&lt;p&gt;我们激动地与大家分享我们自主开发的 SWE（软件工程师）智能代理，以及我们设想这类代理将如何融入 GitHub 用户体验。&lt;/p&gt; 
&lt;p&gt;当我们在代号 Project Padawan 的产品今年晚些时候发布时，您将可以直接将问题分配给 GitHub Copilot，使用任何 GitHub 客户端，并让它生成经过全面测试的拉取请求。一旦任务完成，Copilot 将指派人类审阅者对 PR 进行审核，并努力解决他们提出的反馈。从某种意义上说，这就像将 Copilot 作为贡献者引入 GitHub 上的每一个仓库。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/114025_eVHJ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fembed%2FVWvV2-XwBMM%3Ffeature%3Doembed&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/embed/VWvV2-XwBMM?feature=oembed&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;该功能背后，Copilot 会为分配给它的每个任务自动启动一个安全的云沙盒。然后它异步克隆仓库，设置环境，分析代码库，编辑必要的文件，并构建、测试和检查代码。此外，Copilot 还会考虑问题或 PR 中的任何讨论，以及仓库中的任何自定义指令，以便它理解任务的全貌意图，以及项目的指南和约定。&lt;/p&gt; 
&lt;p&gt;就像我们之前在 Copilot 扩展和 Copilot 模型选择器中做的那样，我们也将提供机会将集成到这个 AI 原生工作流程中，并与合作伙伴和客户紧密合作，形成一个紧密的反馈循环。我们相信 Project Padawan 的最终状态将改变团队管理关键但日常任务的方式，例如修复错误或创建和维护自动化测试。因为最终，一切都是关于通过让他们专注于重要的事情来赋予开发者力量，并让协作者做其余的工作。别担心，我们会保持耐心，所以代理不会「黑化」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332928/github-copilot-the-agent-awakens</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332928/github-copilot-the-agent-awakens</guid>
            <pubDate>Fri, 07 Feb 2025 03:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 社区动态 2025 年 1 月</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎大家收看《RWKV 社区最新动态》，本期内容收录了 RWKV 社区 2025 年 1 月的最新动态。&lt;/p&gt; 
&lt;p&gt;只需 3 分钟，快速了解 RWKV 社区 1 月都有哪些新鲜事！&lt;/p&gt; 
&lt;h2&gt;1 月动态省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 学术研究动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新论文： Rate-Aware Learned Speech Compression（RWKV 语音压缩）&lt;/li&gt; 
   &lt;li&gt;新论文： RWKV-UNet（RWKV 医学图像分割）&lt;/li&gt; 
   &lt;li&gt;新论文： FSSC（RWKV 触觉传感跨域适应）&lt;/li&gt; 
   &lt;li&gt;新论文： TRP（RWKV 知识图谱补全）&lt;/li&gt; 
   &lt;li&gt;新论文： TCVADS（RWKV 视频异常检测）&lt;/li&gt; 
   &lt;li&gt;新论文： RWKV Voice Dialog System（RWKV 语音对话系统）&lt;/li&gt; 
   &lt;li&gt;新论文： Visualrwkv-Hm（RWKV 视觉语言模型）&lt;/li&gt; 
   &lt;li&gt;新论文： AutoGMM-RWKV（RWKV 无线传感器网络安全）&lt;/li&gt; 
   &lt;li&gt;新论文： Revenge of the Fallen?（RWKV 语言理解对比研究）&lt;/li&gt; 
   &lt;li&gt;新论文： Enhancing Transformer RNNs（RWKV 多时间视角增强）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新闻动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新模型： RKWV-7-1.5B&lt;/li&gt; 
   &lt;li&gt;新模型： RKWV-7-0.4B&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区活动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 创始人闭门会开启报名&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区项目动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV Othello&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 学术研究动态&lt;/h2&gt; 
&lt;p&gt;RWKV 学术研究包括&lt;strong&gt;基于 RWKV 架构的新论文&lt;/strong&gt;或 &lt;strong&gt;RWKV 社区参加的学术研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Rate-Aware Learned Speech Compression&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Rate-Aware Learned Speech Compression&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.11999&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.11999&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文提出了一种基于通道感知熵模型的学习语音压缩方案，该方案通过替换传统的量化器来增强率失真性能。它利用多尺度卷积和 RWKV 混合块来提高编码器和解码器的表示能力。&lt;/p&gt; 
&lt;p&gt;实验结果表明，与现有编解码器相比，提出的方法在比特率节省和声学质量指标方面取得了显著改善。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f7caaf051f652da78952613f6f383bf0d0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-UNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：RWKV-UNet: Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 RWKV-UNet，它将 RWKV 结构融入 U-Net 用于医学图像分割。通过 IR-RWKV 模块增强长距离依赖捕获能力，结合 CCM 模块改善跳跃连接。&lt;/p&gt; 
&lt;p&gt;实验表明，RWKV-UNet 在多个数据集上取得 SOTA 性能，平衡了性能和效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ba61005fb424e4a90b230f40c5da963eedd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;FSSC&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Reducing Cross-Sensor Domain Gaps in Tactile Sensing via Few-Sample-Driven Style-to-Content Unsupervised Domain Adaptation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F1424-8220%2F25%2F1%2F256&quot; target=&quot;_blank&quot;&gt;https://www.mdpi.com/1424-8220/25/1/256&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文介绍了 FSSC，一种全新的 few-sample-driven style-to-content 无监督域适应方法。它采用基于 RWKV 架构的设计来应对跨传感器域适应中的难题，例如传感器差异导致的域差距等问题。借助 GLAB 层、FST 模块等重要组件，它达成了有效减少触觉传感跨传感器域差距的目标。&lt;/p&gt; 
&lt;p&gt;实验表明，FSSC 在跨传感器域适应任务的准确性以及对少量样本的利用效率上均超越了现有的先进方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c9929c53128b28220a6b2be13e7004e05d5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV Knowledge Graph Completion&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Efficient Relational Context Perception for Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00397&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.00397&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-31&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文提出一种用于知识图谱补全的新方法，它采用受 Rwkv 启发的 Triple Receptance Perception (TRP) 架构来解决先前知识图谱嵌入模型的缺点，如表达能力有限、计算成本高等问题。通过 TRP 中的时间混合和通道混合模块等关键要素，它实现了高效且高质量的知识图谱补全。&lt;/p&gt; 
&lt;p&gt;实验表明，该方法在链接预测和三元分类任务方面都优于最先进的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-651119224e074229f55231cb42a9b12bc21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;TCVADS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Injecting Explainability and Lightweight Design into Weakly Supervised Video Anomaly Detection Systems&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.20201&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.20201&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-28&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文介绍了一种名为 TCVADS 的视频异常检测系统。该系统采用两个阶段的运行模式。在第一阶段，系统使用增强的 RWKV 模块来进行高效的时间序列分析。通过结合知识蒸馏和跨模态学习技术，TCVADS 在性能上优于现有的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7948ea9998ad0a372ce2ede11942518b7bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV Voice Dialog System&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Voice dialog system based on RWKV model&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10762107&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10762107&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-11-28&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出开发一个面向老年人的智能语音对话系统，采用经 LoRA 微调的 RWKV 模型。实验结果表明它提高了答案的流畅性和合理性，在老年护理方面有应用潜力，未来工作会对模型进行优化。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b9cb2625db793016ac552cb831c4bb0a7a0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Visualrwkv-Hm&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Visualrwkv-Hm: Enhancing Linear Visual-Language Models Via Hybrid Mixing&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5028149&quot; target=&quot;_blank&quot;&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5028149&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-11-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 VisualRWKV-HM，这是一种线性复杂度的视觉语言模型。它基于 RWKV 整合了时间和跨状态混合。在多个基准测试上达到了 SOTA，在 24K 上下文时比 LLaVA-1.5 等模型效率更高，还展现出强大的可扩展性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d60804f11cb6f97d2d77b7d9b04c8202f47.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;AutoGMM-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：AutoGMM-RWKV: A Detecting Scheme Based on Attention Mechanisms Against Selective Forwarding Attacks in Wireless Sensor Networks&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10729884&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10729884&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-10-23&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了 AutoGMM-RWKV 用于检测无线传感器网络中的选择性转发攻击。它聚焦于节点单轮转发率时间序列，通过将自编码器、高斯混合模型和 K - 均值与 RWKV 相结合，提高了检测精度。模拟结果显示误检率和漏检率较低，提供了一个可靠的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca49954aa5387686e8d7257714795a83744.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Revenge of the Fallen?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.19178&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.19178&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-08-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出，在语言任务中，Transformer 一直占据主导地位，但近期 RWKV 等循环模型出现。本文表明像 RWKV 这样的当代循环模型在模拟人类语言理解方面能够与 Transformer 相媲美甚至超越它们，开启了新的研究方向。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-950085a35252d8db50bb7a763699263aacf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Enhancing Transformer RNNs with Multiple Temporal Perspectives&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Enhancing Transformer RNNs with Multiple Temporal Perspectives&lt;/li&gt; 
 &lt;li&gt;论文链接：https://arxiv.org/abs/2402.02625&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-07-11&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出多时间视角概念以增强循环神经网络（RNN）。将其应用于 RWKV 模型时，能以极少的参数增加丰富上下文理解。实证结果验证了其有效性，在基准测试中表现提升且保持线性推理复杂度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a57d07d01cf1ad8f5a65263282fa35c72d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型动态&lt;/h2&gt; 
&lt;h3&gt;新模型： RKWV-7-1.5B&lt;/h3&gt; 
&lt;p&gt;RWKV-7-World-1.5B-v3 模型于 2025 年 1 月 28 日正式发布！&lt;/p&gt; 
&lt;p&gt;RWKV-7-1.5B 模型基于 RWKV World v3 数据集（共 3.1T 数据）训练而来。在英文和多语言评测中，RWKV-7-1.5B 模型的评分对比其他同参数模型处于&lt;strong&gt;绝对领先&lt;/strong&gt;地位。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-56b7f8f2ab08a6d01054853563dd460ec50.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;新模型： RKWV-7-0.4B&lt;/h3&gt; 
&lt;p&gt;RWKV-7-World-0.4B-v2.9 模型于 2025 年 1 月 8 日正式发布！&lt;/p&gt; 
&lt;p&gt;RWKV-7-World-0.4B 在 world-2.9（从 world-v3 数据集中采样 2T tokens）数据集上训练。其英文和多语言能力&lt;strong&gt;显著超越其他 0.4B 模型&lt;/strong&gt;，且支持全球 100+ 种语言和代码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-88a64b43559f9bbfd783387587d05122cf5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社区活动&lt;/h2&gt; 
&lt;p&gt;此版块包含 &lt;strong&gt;RWKV 官方动态&lt;/strong&gt;，以及 &lt;strong&gt;RWKV 社区举办或参加的各类活动&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;RWKV 创始人闭门会开启报名&lt;/h3&gt; 
&lt;p&gt;2 月 21 日晚 7 点，将在上海组织 「RWKV-7 与未来趋势「 的闭门会。&lt;/p&gt; 
&lt;p&gt;RWKV 创始人彭博会线下参加，欢迎 RWKV 开发者、感兴趣的业内人士扫码报名🤝&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c23a88285bae005e1f5e9a0b05360a9ec7b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社区项目动态&lt;/h2&gt; 
&lt;h3&gt;RWKV Othello&lt;/h3&gt; 
&lt;p&gt;RWKV 社区成员 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042&quot; target=&quot;_blank&quot;&gt;@Jellyfish042&lt;/a&gt; 基于 RWKV-7 架构开发了 RWKV Othello 项目。&lt;/p&gt; 
&lt;p&gt;项目 GitHub 仓库： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042%2FRWKV_Othello&quot; target=&quot;_blank&quot;&gt;https://github.com/Jellyfish042/RWKV_Othello&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RWKV Othello 项目利用 Othello（也称为反转棋或黑白棋）的 CoT 数据训练了仅 8.8M 参数的 RWKV-7-Othello 模型。&lt;/p&gt; 
&lt;p&gt;RWKV-7-Othello 模型可以和人类或其他模型自动对战 Othello 游戏，且在与人类对战时实现了非常高的胜率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5cdd352820faef98513bceb46e59e9a65b4.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332925</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332925</guid>
            <pubDate>Fri, 07 Feb 2025 03:36:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>谙流科技完成数千万元天使轮融资，打造统一消息流 PaaS 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;开源中国获悉，上海谙流科技有限公司（http://ascentstream.com）近期完成数千万元人民币天使轮融资，本轮融资由北极光创投领投，华泰创新参与投资，将主要用于开源社区建设、产品研发以及商业化落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;谙流科技正式成立于 2024 年初，由 Apache Pulsar 和 Apache BookKeeper 的核心人员倾力打造，专注为中国市场提供云原生消息队列（MQ）和流处理（Streaming）基础软件及解决方案，打造统一消息流 PaaS 平台，助力中国数字化新质生产力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;724&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0210/102221_CPG4_4489239.png&quot; width=&quot;2752&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;消息流系统是支撑企业数据系统运转的关键基础软件之一。从上世纪 80 年代开始，IBM，甲骨文，TIBCO 等公司的消息中间件产品被广泛使用在各行业的软件系统中。在大数据时代，消息系统在实时数据领域作为数据传输的中枢管道，发挥着不可替代的作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;Apache Pulsar 是一款开源的新一代云原生消息流平台产品，凭借其卓越的架构设计和强大功能，迅速在全球范围内获得了广泛关注。目前拥有超过 670 名贡献者，被数千家头部企业应用于核心业务场景中。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;Pulsar 依托存算分离的云原生架构基础，通过特别的设计和抽象，统一地支持消息流的使用场景。在此之上，Pulsar 为消息队列（MQ）场景提供了高可靠和强一致性，同时弥补了开源 Kafka 使用中多租户、异地多备、数据再平衡带来的集群可用性问题，是企业内部降本增效、构建统一消息流 PaaS 平台的理想选择。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在国内，Apache Pulsar 已经在众多核心业务场景中得到深度应用，并经过了长期高并发、低延迟场景的严格检验。例如，腾讯计费平台、华为终端 BG、滴滴出行、小红书以及微信视频号等场景中均借助 Pulsar 实现了高效、稳定的消息流处理，充分证明了其在大规模生产环境中的卓越性能和可靠性。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;谙流科技联合创始人兼 CEO 翟佳是 Apache Pulsar 的项目管理委员会成员，是 Apache Pulsar 代码的重要贡献者和社区构建者。翟佳曾是 StreamNative 的联合创始人，过去 5 年曾担任 CTO 和中国区负责人职务。谙流科技联合创始人兼 CTO 刘德志和联合创始人兼 COO 魏祥臣曾作为腾讯专家工程师，合作领导并成功将 Pulsar 落地在腾讯计费千亿级消息总线和腾讯云金融级分布式消息服务等项目中。商业化合伙人桂佳杰拥有十多年的企业软件销售管理经验以及基础软件创业经验，在行业内有着深厚的积累和卓越的业绩。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;2024 年成立至今，在短短一年的发展过程中，谙流科技已在产品和商业化领域实现了从无到有的突破，并成功组建了一支专业且完备的产品与服务团队。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;谙流科技的企业级产品——ASP 消息流平台，是基于 Apache Pulsar 打造的新一代金融级消息平台。该平台凭借优越的性能，适用于金融级低延迟、高吞吐量的消息传输，高可靠的多地多中心部署，以及海量 Topic 的泛物联网场景。目前，该产品已完成国产化适配，并广泛应用于国产信创环境，充分契合国内市场的高标准需求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在商业化进程中，谙流科技凭借其卓越的技术实力和优质服务，赢得了众多行业头部客户的青睐，客户群体涵盖中国银联、华泰证券、中信证券、中国联通、中国地震台网中心、中国铁道科学院、吉利汽车、深南电路等知名企业。本轮融资完成后，谙流科技将通过持续投入，推动企业的持续发展与创新，为客户提供更具价值的解决方案。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;作为本轮融资的领投方，北极光创投合伙人张朋表示：「消息流产品已经是构成企业应用的基础组件。谙流科技团队已经将 Pulsar 推广落地到各行各业。我们看到了金融客户将公司产品用在核心关键业务中，也看到了超大数据规模的客户通过零改造的方式完成了 Kafka 的切换。在过去一年的整体环境下，谙流科技依然表现亮眼，这充分证明了其巨大的发展潜力和广泛的市场需求。我们也期待谙流科技能够在未来的发展中，不断创新，砥砺前行，为推动国产基础软件行业的蓬勃发展贡献更多的力量。」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;华泰创新股权投资一部负责人胡雪飞也认为：「Apache Pulsar 是优秀的开源云原生基础软件的代表，伴随和引领着云原生技术在消息流方向的发展，同时也是数据传输和流转中的重要工具，已经具备扎实的商业化基础。谙流科技聚焦在陪伴中国企业客户降本增效和敏捷创新上，目标明确。我们相信谙流科技在未来一定会取得更多更好的成绩。」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在众多企业纷纷加速布局出海的当下，谙流科技坚定地选择了扎根国内，再次启航，这一决定源自于翟佳和团队对中国市场的深刻洞察。他们认为国内庞大的市场体量和丰富的应用场景，为开源基础软件初创企业提供了得天独厚的发展机遇，是孕育技术创新的肥沃土壤。近年来国家在基础软件和开源领域的政策引导与支持成为了企业发展的强大后盾，团队将倍加珍惜这一机遇，积极响应国家号召，深度挖掘国内企业在数字化转型和智能化升级中的核心需求。同时，团队将高度重视国内企业在数据场景复杂性、数据规模庞大性以及对基础软件的高标准、严要求，致力于打造更贴合本土需求的优质产品和服务，助力中国企业在全球竞争中脱颖而出。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332915/ascentstream-angelroundfunding</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332915/ascentstream-angelroundfunding</guid>
            <pubDate>Fri, 07 Feb 2025 02:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>苹果 3 月在上海举办「Apple 智能」相关活动</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，苹果向开发者发送了关于「利用苹果智能的力量」开发者活动的相关邮件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cdd018ef12a613a98fbadee0fe4c431a02f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得关注的是，本次活动将于 3 月 25 日 10:00 至 12:00 在上海举行，活动主题将围绕苹果智能和机器学习两个方面。&lt;span style=&quot;color:#f39c12&quot;&gt;&lt;strong&gt;而这一举动，也暗示在中国大陆的苹果智能 AI 功能或将上线&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;近期，有消息透露，苹果 CEO 库克在公司的 2024 年 Q4 财报电话会上表示，公司将会在今年 4 月对 Apple Intelligence 适配更多语言，其中包括中文。而苹果也于 1 月 30 日，对 Apple 智能的官网信息进行更新，其中提到 Apple 智能将会支持中文。另外，在 2024 年 9 月秋季发布会中苹果也提到，将会在今年内支持中文等语言。&lt;/p&gt; 
&lt;p&gt;此外，1 月 10 日，据天眼查显示，苹果技术开发（上海）有限公司成立，其法定代表人为 Tejas Kirit Gala，注册资本为 3,500 万元；该公司行业归属为软件和信息技术服务业；经营范围包括软件开发、大数据服务、数据处理服务、数据处理和存储支持服务等。&lt;/p&gt; 
&lt;p&gt;此外，据彭博社记者 Mark Gurman 报道，iPhone 正在失去优势，一方面是中国市场竞争激烈，另一方面是 iPhone 缺失 AI 的领先技术，尽管如今苹果智能已经亮相，但依然不敌 Google 的 Gemini。&lt;/p&gt; 
&lt;p&gt;而本周发布的 iPhone SE 将开启苹果的产品线关键年。Gurman 指出，iPhone 硬件负责高管 John Ternus 近期表示，即将推出的 iPhone 新品将会是其最具雄心的，并且相当看好新品的销售未来。&lt;/p&gt; 
&lt;p&gt;据悉，Gurman 此前表示，新款 iPhone SE 的外观设计看起来会更像 iPhone 14，同时将搭载 A18 芯片并支持 Apple Intelligence，接口也将升级成 USB-C。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332912</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332912</guid>
            <pubDate>Fri, 07 Feb 2025 02:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>国企官网被挂上「码农的钱你也敢吞，还钱」字样，涉事公司回应</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 8 日，有网友反映，湖北武汉一国企官网挂上了「码农的钱你也敢吞，还钱」字样，引发关注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-240b17432f7906a65d06d459ce7d5ec7b92.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，涉事企业为武汉汇科智创科技有限公司，属于国有独资企业。该国企的官网为「www.focuz-in.com」，点击网页后，无法正常浏览官网主页，只能看到上述页面。&lt;/p&gt; 
&lt;p&gt;据最新测试，官网电脑版页面显示「无法访问」，但手机版仍可访问，页面显示与网传信息一致。&lt;/p&gt; 
&lt;p&gt;媒体就此事联系到武汉汇科智创科技有限公司相关负责人贾某，她表示，官网被黑系恶意行为，公司方面已经报警，网警正在核查此事，所谓「还钱「一事不属实，后续肯定要澄清。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332909</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332909</guid>
            <pubDate>Fri, 07 Feb 2025 02:47:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek-V3 API 优惠期结束，每百万输出 tokens 由 2 元提高至 8 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek-V3 的 API 服务的「价格优惠」体验期已经结束，从 2 月 9 日开始调整为新的价格，相关情况，5G 与 6G 公众号（ID：angmobile）总结并分析如下。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;1、价格对比分析&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img height=&quot;152&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf2ea7640b7494ba3edf769e2ae2e46d433.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;输入 Token 费用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;优惠期（以前）：缓存命中 0.1 元/百万，缓存未命中 1 元/百万。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;正常期（现在）：统一 2 元/百万（缓存命中涨价 2000%，未命中涨价 100%）。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;输出 Token 费用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;优惠期（以前）：2 元/百万。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;正常期（现在）：8 元/百万（涨幅 300%）。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;优惠体验期是一种常见的市场推广策略，在优惠期内吸引了大量用户尝试和使用 DeepSeek-V3 的 API 服务，积累了用户基础和市场口碑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;优惠期结束后调整价格，5G 与 6G 公众号认为一方面可以筛选出对价格不敏感、真正有需求的长期用户，另一方面也为后续可能的价格策略调整和服务升级留出空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;价格调整反映了 DeepSeek 考虑到了运营成本、服务器资源以及持续研发所需的资金投入。值得注意的是，尽管价格有所上涨，但 5G 与 6G 公众号注意到 DeepSeek-V3 与市场上其他高端 AI 模型比如 OpenAI 的 GPT-4o 相比仍然保持了较高的性价比（如下表所示）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;116&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-62d33087cc179a4147e85ae33ada2927009.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;2、成本影响测算&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;假设典型场景：&lt;/strong&gt;100 万输入（50% 缓存命中）+ 50 万输出&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;优惠期（以前）成本：（0.1×50 + 1×50）+ 2×50 = 5+50+100=155 元。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;正常期（现在）成本：（2×100）+ 8×50 = 200+400=600 元（成本增长 287%）&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;优化使用方面，用户可能会更加注重优化 token 的使用，一是缓存策略优化，比如 5G 与 6G 公众号认为通过请求模式调整提升缓存命中率可将输入成本降低 90%；此外针对对话类应用，可设计缓存+实时处理的混合架构。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;价格并不是用户选择 AI 模型服务的唯一考量因素，DeepSeek-V3 可以通过不断提升自身的性能、功能和服务质量，与竞争对手形成更大的差异化竞争。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332908</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332908</guid>
            <pubDate>Fri, 07 Feb 2025 02:44:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek4j: Java 应用一行代码集成 DeepSeek R1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;DeepSeek R1 凭借其强大的思维链能力在开发者中广受欢迎。deepseek4j 框架提供了完整的 Java 集成方案，支持多个平台包括 Gitee AI，并带来联网搜索、多渠道支持等重要特性。本文将详细介绍如何使用 deepseek4j 快速集成 DeepSeek R1。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;一、为什么需要 deepseek4j？&lt;/h2&gt; 
&lt;h3&gt;1.1 现有框架的局限性&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;框架支持不足&lt;/strong&gt;：LangChain4j/Spring AI 对 DeepSeek 支持不完善&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;思维链内容丢失&lt;/strong&gt;：R1 最核心的推理过程完全被忽略&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;流式处理不完善&lt;/strong&gt;：用户体验欠佳&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1.2 deepseek4j 的优势&lt;/h3&gt; 
&lt;p&gt;deepseek4j 是一个专为 Java 开发者打造的 DeepSeek 模型集成框架。通过优雅的 API 设计，只需一行代码，即可实现接入 DeepSeek，并获得以下核心能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✨ &lt;strong&gt;完整思维链保留&lt;/strong&gt;：完美保留 DeepSeek 模型的推理过程&lt;/li&gt; 
 &lt;li&gt;🚀 &lt;strong&gt;流式输出体验&lt;/strong&gt;：基于 Reactor 实现的流式响应&lt;/li&gt; 
 &lt;li&gt;🛠 &lt;strong&gt;简单优雅的 API 设计&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;📦 &lt;strong&gt;开箱即用的 Spring Boot 集成&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;💡 &lt;strong&gt;内置调试页面&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;详细的请求响应日志&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;灵活的代理配置&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;⚡️ &lt;strong&gt;响应式编程支持&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二、快速开始&lt;/h2&gt; 
&lt;h3&gt;2.1 添加依赖&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.github.pig-mesh.ai&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;deepseek-spring-boot-starter&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;last-version&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2 配置参数&lt;/h3&gt; 
&lt;p&gt;在 application.properties 或 application.yml 中添加以下配置：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;deepseek:
  # Gitee AI 平台配置
  base-url: https://ai.gitee.com/v1
  model: DeepSeek-R1
  api-key: your-gitee-ai-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.3 基础使用&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Autowired
private DeepSeekClient deepSeekClient;

// sse 流式返回
@GetMapping(value = &quot;/chat&quot;, produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux&amp;lt;ChatCompletionResponse&amp;gt; chat(String prompt) {
    return deepSeekClient.chatFluxCompletion(prompt);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.4 进阶配置&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public Flux&amp;lt;ChatCompletionResponse&amp;gt; chat(String prompt) {
    ChatCompletionRequest request = ChatCompletionRequest.builder()
            // 模型选择，使用 Gitee AI 的 DeepSeek-R1
            .model(ChatCompletionModel.DEEPSEEK_CHAT)
            // 添加用户消息
            .addUserMessage(prompt)
            // 添加助手消息，用于多轮对话
            .addAssistantMessage(&quot;上轮结果&quot;)
            // 添加系统消息，用于设置角色和行为
            .addSystemMessage(&quot;你是一个专业的助手&quot;)
            // 设置最大生成 token 数，默认 2048
            .maxTokens(1000)
            // 设置响应格式，支持 JSON 结构化输出
            .responseFormat()
            .tools() // function calling
            .build();

    return deepSeekClient.chatFluxCompletion(request);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;三、高级特性&lt;/h2&gt; 
&lt;h3&gt;3.1 联网搜索支持&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://minio.pigx.vip/oss/202502/1739118403.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;突破时间边界&lt;/strong&gt;：模型不再受限于预训练数据的时间范围，可以获取和处理最新信息&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;实时信息获取&lt;/strong&gt;：通过高质量信息源获取实时资讯，提供更精准的问答服务&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;差异化竞争&lt;/strong&gt;：在大模型同质化严重的当下，联网搜索成为关键的差异化竞争点&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@GetMapping(value = &quot;/chat&quot;, produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux&amp;lt;ChatCompletionResponse&amp;gt; chat(String prompt) {
    // 指定联网搜索参数
    SearchRequest searchRequest = SearchRequest.builder()
            .enable(true)
            .freshness(FreshnessEnums.ONE_DAY)// 一天内的数据
            .summary(true) // 返回摘要
            .count(10) // 返回 10 条
            .page(1) // 第一页
            .build();
    return deepSeekClient.chatSearchCompletion(prompt,searchRequest);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3.2 智能系统提示词&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://minio.pigx.vip/oss/202502/1739118117.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;系统提示词（System Prompt）是基于模型开发的应用程序内置的指令，让决定了模型在特定上下文中的表现方式、回答风格和功能范围。&lt;/p&gt; 
&lt;p&gt;为了解决部分渠道模型部署时推理能力不稳定的问题，新版本引入了与 DeepSeek R1 官方版本一致的系统提示词功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通过精心设计的提示词模板，确保模型输出的一致性和可靠性&lt;/li&gt; 
 &lt;li&gt;内置多层级的提示词优化策略，显著提升推理质量&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.3 调试支持&lt;/h3&gt; 
&lt;p&gt;双击运行根目录的 sse.html 文件，即可打开调试页面。在页面中输入后端 SSE 接口地址，点击发送后可实时查看推理过程和最终结果。&lt;/p&gt; 
&lt;p&gt;针对非标准平台，新增了智能化的调试功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动处理 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 标签内容&lt;/li&gt; 
 &lt;li&gt;智能提取 &lt;code&gt;reason_content&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;优化多轮对话的 token 占用&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://minio.pigx.vip/oss/202502/1738864340.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;四、多渠道支持&lt;/h2&gt; 
&lt;p&gt;deepseek4j 支持多个部署渠道：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3018c10690532e0e916df5a50d7dc492bf4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;详细的使用文档请参考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjavaai.pig4cloud.com%2Fdeepseek&quot; target=&quot;_blank&quot;&gt;DeepSeek4j : https://javaai.pig4cloud.com/deepseek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitee.com/log4j/deepseek4j&quot;&gt;源码地址 gitee.com/log4j/deepseek4j&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/giegie/blog/17553532</link>
            <guid isPermaLink="false">https://my.oschina.net/giegie/blog/17553532</guid>
            <pubDate>Fri, 07 Feb 2025 02:43:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>新晋 AI 开源项目 WGAI 加入 Dromara 社区，轻量级、模块化的 AI 助手框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h3&gt;🚀 新的起点&lt;/h3&gt; 
&lt;p&gt;我们非常高兴地宣布，WGAI 项目正式加入了 Dromara 开源社区！这是一个重要的里程碑，标志着 WGAI 将能够与更多的开发者和研究者分享其独特的功能，并且共同推动人工智能领域的发展。&lt;/p&gt; 
&lt;p&gt;关于 WGAI WGAI 是一个开放源码的人工智能项目，它基于 Apache License 2.0 许可证发布。这意味着您可以在满足一定条件下自由使用、复制和分发本作品。在 WGAI 中，用户不仅可以直接利用预训练的模型进行各种应用，还可以根据自己的需求对模型进行自定义训练，以适应特定场景下的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//cd9db1bee5f630a46628d6120df7d8c7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;🚀 功能设计&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;不懂 python 也可直接执行再也不用担心技术瓶颈&lt;/li&gt; 
 &lt;li&gt;在线训练、在线标注、模型列表&lt;/li&gt; 
 &lt;li&gt;包含 OCR、图文、音视频等识别&lt;/li&gt; 
 &lt;li&gt;本地化部署语音识别、热词配置&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 四大核心优势&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Java 全栈友好&lt;/strong&gt; - 深度整合 Spring 生态，提供&lt;code&gt;wgai-spring-boot-starter&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自我训练模型&lt;/strong&gt; - WGAI 的一大特色是支持用户自行训练模型。通过这种方式，无论是学术研究还是工业应用，用户都能根据自身的数据集和任务目标来优化模型性能&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;工业级部署&lt;/strong&gt; - 支持 ONNX 导出与 TensorRT 加速&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;简单易用&lt;/strong&gt; - WGAI 提供了简洁的 API 接口和详细的文档，开发者可以快速上手并集成到自己的项目中&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🛠️ 适用场景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;安防监控-人脸识别（机场、车站的身份核验）、行为检测（识别异常行为（如跌倒、斗殴），实时触发警报）。&lt;/li&gt; 
 &lt;li&gt;交通物流-自动驾驶（实时识别道路标志、行人、车辆，辅助导航决策）、车牌识别（高速公路 ETC 系统或停车场自动识别车牌号码）。&lt;/li&gt; 
 &lt;li&gt;工业制造-缺陷检测（AI 视觉检查产品表面划痕、尺寸偏差，提升质检效率）、预测性维护（通过识别设备振动或温度数据异常，预判故障）。&lt;/li&gt; 
 &lt;li&gt;金融安全-欺诈检测（分析交易模式识别异常行为如异地大额转账）、证件核验（OCR 技术自动提取身份证、银行卡信息，比对真伪）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;💻 快速入门&lt;/h1&gt; 
&lt;h3&gt;一键训练&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//7c3c9ac7eab73a95d23b5cbca535886f.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;一键识别&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//d987b0b90439aaf3a6614bb2267c4e46.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//3dbbdecda575418e251b8c24847d03e6.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;🚀开源地址&lt;/h2&gt; 
&lt;p&gt;WGAI 作为一个轻量级、模块化的 AI 助手框架，旨在为开发者提供简单易用的工具，帮助快速构建智能应用。无论你是 AI 领域的初学者，还是经验丰富的开发者，WGAI 都能为你提供强大的支持。欢迎大家试用并反馈意见，共同推动项目的进步！&lt;/p&gt; 
&lt;p&gt;如果你觉得这个项目对你有帮助，别忘了给个 Star 哦！🌟&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gitee&lt;/strong&gt;:&amp;nbsp;&lt;a href=&quot;https://gitee.com/dromara/wgai&quot;&gt;https://gitee.com/dromara/wgai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;:&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdromara%2Fwgai&quot; target=&quot;_blank&quot;&gt;https://github.com/dromara/wgai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;感谢大家的支持！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332892</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332892</guid>
            <pubDate>Fri, 07 Feb 2025 01:06:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
    </channel>
</rss>