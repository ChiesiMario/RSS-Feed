<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 06 Sep 2025 02:41:28 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>智谱推出「Claude API 用户特别搬家计划」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，美国头部大模型公司&amp;nbsp;Anthropic&amp;nbsp;&lt;a href="https://www.oschina.net/news/370416" target="_blank"&gt;宣布&lt;/a&gt;，将停止向多数股权由中国资本持有的集团出售 Claude 服务，范围涵盖中国大陆及通过海外注册或云服务间接使用的企业。&lt;/p&gt; 
&lt;p&gt;为帮助开发者平稳过渡，智谱正式推出「Claude API 用户特别搬家计划」。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;一键迁移，畅享 GLM-4.5&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;智谱已全面兼容 Claude 协议，用户&lt;strong&gt;只需&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;替换 API URL&lt;/strong&gt;&lt;/strong&gt;，即可从 Claude 无缝切换至&amp;nbsp;&lt;strong&gt;&lt;strong&gt;GLM 模型 API&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智谱将为用户提供：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;新用户&lt;/strong&gt;&lt;/strong&gt;：赠送 2000 万 Tokens 免费体验；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开发者&lt;/strong&gt;：GLM-4.5 编码专属包月套餐，价格仅为 Claude&amp;nbsp;&lt;strong&gt;1/7&lt;/strong&gt;，用量提升&amp;nbsp;&lt;strong&gt;3 倍&lt;/strong&gt;、速度更快（平均 55 Tokens/s）；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;迁移无忧&lt;/strong&gt;：从 Claude 到 GLM 的系统迁移教程，可便捷、快速地完成模型切换。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;为企业客户额外提供：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;满足业务需求的并发规模；&lt;/li&gt; 
 &lt;li&gt;更低成本的折扣优惠权益；&lt;/li&gt; 
 &lt;li&gt;1 对 1 的搬家顾问与解决方案服务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速迁移教程&lt;/h2&gt; 
&lt;p&gt;如果你在使用 Claude API，访问 bigmodel.cn，迁移到 GLM 非常简单。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;替换你访问的&amp;nbsp;base_url&amp;nbsp;为&amp;nbsp;https://open.bigmodel.cn/api/anthropic；&lt;/li&gt; 
 &lt;li&gt;在智谱开放平台申请&amp;nbsp;api_key；&lt;/li&gt; 
 &lt;li&gt;调用时使用智谱模型编码即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# 原来的 Claude 代码
import anthropic
client = anthropic.Anthropic(
    base_url="your-base-url",
    api_key="your-api-key",
)
# 迁移到智谱 AI，只需要修改三个地方
client = anthropic.Anthropic(
    api_key="your-zhipuai-api-key",  # 替换为智谱 AI API Key
    base_url="https://open.bigmodel.cn/api/anthropic"  # 配置智谱 AI base_url
)
# 模型编码使用，智谱 AI 模型，其他代码保持不变
message = client.messages.create(
    model="glm-4.5",  # 使用智谱 AI 模型
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
)&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370531</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370531</guid>
      <pubDate>Wed, 03 Sep 2025 10:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元游戏视觉生成平台正式发布 2.0 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;腾讯混元游戏视觉生成平台正式发布 2.0 版本，新增游戏图生视频、自定义模型训练、角色一键精修等能力，并大幅提升游戏 2D 生图模型能力，图生视频和文生图模型在游戏场景达到行业 SOTA 水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次升级进一步解决了游戏美术设计与宣发中的动态内容生成、风格定制化、细节优化等痛点，帮助游戏美术设计师提高效率。本次能力升级的同时，混元游戏平台宣布面向所有用户开放，用户可以通过腾讯混元官网体验，登录即可使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="274" src="https://oscimg.oschina.net/oscnet/up-881d8901997b0231d342668e831e17877df.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;新推出的游戏 AI 动画/CG 能力基于腾讯混元图生视频能力，可以让静态画面秒变动画，包括角色 360 度旋转等游戏。用户上传任意游戏图片并输入动态描述，即刻生成高质量动态视频，支持游戏角色动作、场景特效及「万物旋转」展示，适用于游戏 CG 预演、角色原画三视图创作、技能特效预览，替代传统逐帧绘制流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自定义模型训练大幅降低了生图模型精调门槛，让个人用户也可以通过少量图片微调自己专属的 LoRA 模型，解决游戏项目风格统一难题，尤其适合独立工作室打造 IP 化美术资产。混元游戏官网提供了预设风格，包括欧卡、二次元、写实 CG 等，同时支持用户使用个人数据集训练专属 LoRA 风格模型或者角色模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自定义模型训练能力基于混元生图底模，简化了 LoRA 模型的训练流程，用户只需上传数十张图片并设置触发词，系统自动打标，数小时即可完成模型训练。整个训练过程均为可视化操作，无需代码基础或复杂工具。该能力目前处于内测阶段，用户可以申请使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;角色一键精修能力主要用于对游戏角色原画的细节丰富或风格转换，提供高一致性模式和高创意性模式。高一致性模式可保留原图结构，精细化服饰纹理、光影层次，适用于角色定稿优化；高创意性模式支持将角色原画转换为国风、3D 化、二次元等风格并细化效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;混元游戏 2.0 针对平台背后的 2D 生图模型进行了升级，文生图能力达到游戏行业 SOTA 级别。混元游戏大幅提升生图模型的美学与构图，使其更能满足游戏美术创作需求，同时针对游戏独有的场景进行优化，提供游戏技能特效、环境特效与游戏交互界面等生成能力，专项优化游戏场景、游戏道具物品、游戏角色等生成效果。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370526</guid>
      <pubDate>Wed, 03 Sep 2025 10:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>联想发布全球首款垂直旋转屏 AI PC</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在德国柏林 IFA 期间举行的 2025 联想创新世界大会上，联想带来了诸多新品。其中最引人注意的就是一款 ThinkBook VertiFlex 概念机，同时这也是业界首款 14 英寸屏幕可垂直旋转笔记本电脑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="278" src="https://oscimg.oschina.net/oscnet/up-37aa8c07d9e00681e1351bdc757279581ab.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这款概念机最大特点就是配备的旋转显示系统，可以在水平和垂直方向之间双模式切换，采用 17.9 毫米和 1.39 公斤轻薄设计。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;垂直显示模式适合分屏多任务、显示代码和查看文档等场景，并且在垂直显示模式下，智能手机可以通过联想超级互联连接到 PC 上，用于传输文件和手机镜像。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="311" src="https://oscimg.oschina.net/oscnet/up-59757bf204952fc6b4dbc03f4a4839c6721.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;事实上，这并不是联想首次在笔记本电脑屏幕上的创新，此前就曾发布了透明屏、三折叠屏，以及今年即将开卖的卷轴屏 PC。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370522</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370522</guid>
      <pubDate>Wed, 03 Sep 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>全球首个「一站式」数智化生命科学研究平台 AI4S LAB 上线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;北京大学深圳研究生院与百度智能云近日联合宣布，双方携手打造的「一站式」数智化生命科学研究平台——AI4S LAB 正式上线。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该平台深度整合算力、数据、模型、实验四大要素，开发多智能体协同系统，为科研工作者带来「AI 驱动、干湿闭环、全链数智」的云端科研体验，极大提升科研效能与创新能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-4a6c75631c23cca67acff14e602a9274676.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI4S LAB 数智化支撑生态建设包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;算力：配备可伸缩的高性能计算集群，搭载面向科学智能需求的超智融合算力调度系统。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;模型：基于百度智能云千帆大模型平台开发私有化模型与数据管理能力，为 AI4S LAB 提供了 Agent 开发所需模型、Agent 编排、数据和定制化服务。匹配一站式模型效果调优工具链，为平台提供模型纳管、精调与推理支持，尤其是生物领域大语言的场景化适配与调用。具有卓越的模型推理托管能力，在配备超 10 个可直接使用的通用与生命科学垂直领域代表性模型的同时，还支持各类主流推理框架和模型的自定义导入与部署，为科研工作者提供了高度灵活的开发环境。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;数据：配备超 15 个专业数据集，提供开放共享且持续产生新数据的知识平台，提供高效数据管理功能、智能可视化数据分析工具。实验：集成超过 22 台套的先进高通量、自动化、自迭代智能实验设备，面对生命合成领域，提供工程菌株构建与优化，蛋白表达与酶工程，代谢工程与调控，非天然氨基酸整合，合成噬菌体开发等多场景提供高效科研服务。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;北京大学深圳研究生院自主研发的 AI4S 原生多智能体系统——BIOMA，是平台全链路智能化实现的核心，提供高效协同的云化研究能力，涵盖了从理论预测、实验设计、自动化执行到数据分析与迭代的各个环节，助力科研人员突破传统研究的时空限制。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;BIOMA 多智能体系统的强大能力包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;逆向智能设计： 从期望的功能或性能指标出发，智能设计全新的实验方案与材料。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能创制与表征： 自动化地执行复杂的实验流程，并对结果进行精确表征。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;科研数据智能分析与迭代： 对海量实验数据进行深度分析，并基于分析结果自主优化后续实验方案。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-42c4dd9e2e3b6665fae4d5b9511c060a767.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;BIOMA 多智能体系统由一系列功能协同的智能体构成，每个智能体在科研流程中扮演着关键角色：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#222222"&gt;理论科学家智能体（PredAgent）&lt;/strong&gt;&lt;strong style="color:#222222"&gt;，&lt;/strong&gt;在理论预测阶段，解析科研人员以自然语言输入的研究构想，并即时调用全球前沿的预测模型和工具进行模拟与计算。极大地提升了理论设计的效率，更通过算法优化增强了预测的准确性，为后续的实验研究奠定坚实理论基础。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;实验规划师智能体（ProAgent）&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;具备自主生成完整、可执行的标准化实验方案的能力。在干湿闭环&lt;strong&gt;验证&lt;/strong&gt;&lt;strong&gt;阶段&lt;/strong&gt;，通过与研究人员的多轮交互，精确提炼并完善湿实验方案的每一个细节，包括试剂选择、参数设定以及仪器调配等，从而构建出逻辑严谨、操作性强的实验流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能实验室自动化被《自然》期刊列为「2025 年值得关注的七大技术」之首。&lt;strong&gt;实验室指挥官智能体（OperAgent）&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;负责在实验执行阶段，将 ProAgent 生成的复杂实验方案转化为机器可精确执行的指令。通过对实验室超 22 台自动化设备的多线程精准调度与协同控制，成功打造 7x24 小时不间断运行的「黑灯实验室」，实现了真正意义上的无人化、自动化实验流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据分析师智能体（ComAgent），&lt;/strong&gt;致力于构建一个一体化的科研数据生态系统，提供丰富的数据分析工具与可视化图表，同时基于设定的关键性能指标，对实验数据进行深度挖掘与洞察。通过自主分析，ComAgent 生成富有洞见的优化建议，并自动规划下一轮的实验方案，从而形成可持续进化的科研闭环，加速科学发现进程。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370509</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370509</guid>
      <pubDate>Wed, 03 Sep 2025 09:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Hopp - 开源结对编程应用程序</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hopp 是一款开源结对编程应用，可让你与队友结对编程。该应用使用 Tauri 构建，WebRTC 基础架构由&lt;a href="https://livekit.io/"&gt;LiveKit&lt;/a&gt;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;img height="132" src="https://static.oschina.net/uploads/space/2025/0903/144658_hgds_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特性&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;超高品质屏幕共享&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gethopp.app/blog/latency-exploration"&gt;优化了 WebRTC&lt;/a&gt;，以获得最佳质量的屏幕共享&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.livekit.io/home/cloud/architecture/#distributed-mesh-architecture"&gt;依靠 LiveKit 网络&lt;/a&gt;实现大规模低延迟&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Mob&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;编程&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;加入房间并立即与最多 10 名队友配对&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一键配对&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;不再在聊天中与队友分享链接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开放式建造&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;希望与 OSS 社区共同打造 Hopp&lt;/li&gt;
&lt;li&gt;这带来了自托管和社区创新的好处&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/hopp</link>
      <guid isPermaLink="false">https://www.oschina.net/p/hopp</guid>
      <pubDate>Wed, 03 Sep 2025 09:24:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenDataLab 与钉钉联手推出面向企业用户的文档解析工具 DLU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;OpenDataLab 和钉钉基于 MinerU &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLg-4_0PNluM8l_pYQTjc7Q" target="_blank"&gt;推出&lt;/a&gt;了一款面向企业用户的文档解析工具——DLU&lt;/span&gt;&lt;span&gt;(Document Language Understanding)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/172338_aEbD_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MinerU 是上海人工智能实验室（上海 AI 实验室）OpenDataLab 推出的智能文档解析引擎，因精准解析能力及广泛兼容性深受用户青睐，在 GitHub 上已累计获得超 4 万星标。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/172239_vfIi_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;基于 MinerU 打造的 DLU 将于近期开源，其具备良好的文件格式兼容性，深层次的内容理解与精准的结构化输出能力，不仅支持主流的 Office 文档、PDF、Markdown 及代码文件，还涵盖钉钉自有的文档、表格与 AI 表格格式；并支持提取纯文本内容，精准解析图表、公式、插图乃至专业领域的化学分子式等复杂视觉元素，并将其有效转换为适合大模型训练的高质量语料。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370505</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370505</guid>
      <pubDate>Wed, 03 Sep 2025 09:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>拍我 AI 接入谷歌 Nano Banana，限时免费使用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;拍我 AI 已正式接入谷歌 Nano Banana（Gemini 2.5 Flash Image），并同步开启「拍我 AI 免费开放日」限时活动，从 9 月 5 日持续至 9 月 10 日，为期六天。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-31f43668eb292a7a399ef21c78092a4f3ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;在此期间，国内用户可免费体验 PixVerse Agent 创作助手，零成本生成各类创意短片。用户只需选择喜欢的模板并上传一张图片，Agent 即可自动识别图像特征，生成 5–30 秒的完整视频。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;作为国内首批接入 Nano Banana 的 AI 视频生成平台，拍我 AI 国内版同步推出更多趣味模板，包括 3D 手办制造局、和名人合照、捕获心动角色、骑龙高手等，让普通用户也能轻松上手，制作精致、有趣的短视频作品，以及更进一步制作出自己喜爱的游戏画面！目前拍我 AI 网页端和移动端 APP 均可同步体验。&lt;/p&gt; 
&lt;p&gt;今年 6 月 6 日，PixVerse 上线了中国版本拍我 AI，目前平台的全球用户规模已突破 1 亿。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370503</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370503</guid>
      <pubDate>Wed, 03 Sep 2025 09:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>VC 投资人尝试 20 天「氛围编程」，称成本高昂、易累积技术债</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Kevin Kuipers 是一名 VC 投资人，最近他&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkevinkuipers.substack.com%2Fp%2Fvc-for-vibe-coding-a-fresh-new-start" target="_blank"&gt;分享&lt;/a&gt;了「Vibe Coding」的实践经验，通过 AI 编程构建面向 VC 的全新工作平台。&lt;/p&gt; 
&lt;p&gt;Kuipers 在暑假期间尝试了沉浸式的「氛围编程（Vibe Coding）」，目标是为自己的基金打造「AI-native」（AI 原生）管理系统。他先从 Telegram 智能体起步，逐步扩展到 Web 和桌面端应用，用 AI 自动整合文章、邮件、Pitch Deck、对话等信息，构建出一个「知识云」，从非结构化数据中提炼趋势与洞见。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165630_7gXE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在技术栈上，他大量依赖 Supabase、Orq.ai、Mem0、Koyeb、Linkup、ScrapingBee 等工具，并利用 Claude 直接生成 UI/UX，大幅减少了传统 Figma 等设计流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165641_hALP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165713_UDsC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他指出，AI 编程的优势是能在几周内完成原型，显著提升迭代效率，但同时也伴随挑战：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;技术债容易累积，代码质量难控；&lt;/li&gt; 
 &lt;li&gt;成本高昂，仅 20 天就消耗约 2600 美元 Token；&lt;/li&gt; 
 &lt;li&gt;LLM 的创造力和破坏力并存，需要工程师负责架构与质量。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Kuipers 强调，「vibe coding」核心不是写代码，而是「快速建造」，让 VC 的知识管理和决策更高效。他认为，这种模式可能重塑风险投资的工作方式，也让投资人与工程师保持更深度的互动。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370500/vc-for-vibe-coding-a-fresh-new-start</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370500/vc-for-vibe-coding-a-fresh-new-start</guid>
      <pubDate>Wed, 03 Sep 2025 08:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「Nano Banana」上线不到 10 天，为谷歌 Gemini 吸引超过 1000 万名新用户</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌最新的 AI 实验项目「Nano Banana」在上周爆火，谷歌实验室副总裁 Josh Woodward 在 X 上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fjoshwoodward%2Fstatus%2F1963627742618165270" target="_blank"&gt;透露&lt;/a&gt;，自该功能上线以来，累计已完成超 2 亿次图像编辑，&lt;strong&gt;带动超 1000 万新用户尝试 Gemini 应用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;对于这款产品的受欢迎程度，他形容称导致「TPU 严重过载，SRE 警报不停。」&lt;/p&gt; 
&lt;p&gt;&lt;img height="854" src="https://static.oschina.net/uploads/space/2025/0905/164501_ZL7i_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;Gemini 2.5 Flash Image&lt;/span&gt;（内部代号 Nano Banana）是谷歌&lt;span style="background-color:#ffffff; color:#333333"&gt;最先进的图像生成与编辑模型，&lt;/span&gt;主要特点如下：&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;充分保持角色的一致性：它可以轻松地将同一个角色置于不同的环境中，或者从多个角度展示同一款产品，同时完美地保持其核心主体不变。&lt;/li&gt; 
 &lt;li&gt;基于提示的图片编辑：允许用户通过简单的自然语言指令，对图片进行精准的局部修改 。&lt;/li&gt; 
 &lt;li&gt;利用 Gemini 的现实世界知识：模型可借助 Gemini 强大的世界知识库，让图像生成变得更加「智能」。&lt;/li&gt; 
 &lt;li&gt;多幅图像融合：可以将一张图片中的物体「放」进另一张图片的场景里，整个过程只需一条提示指令就能完成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;性能表现上，Gemini 2.5 Flash Image 在多项基准测试上均为第一名，超越 OpenAI ChatGPT 4o（GPT Image 1 high）、Qwen Image Edit 等模型。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfee07407ab38e2b001fd0dbe895d36f242.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370497</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370497</guid>
      <pubDate>Wed, 03 Sep 2025 08:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>尤雨溪 VoidZero 公司 8 月成果速览</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;尤雨溪 VoidZero 公司&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fwhats-new-aug-2025" target="_blank"&gt;发布&lt;/a&gt;了 2025 年 8 月回顾，阐述了&amp;nbsp;Vite、Vitest、Oxc、Rolldown 的项目更新以及社区动态。&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-bf866c877e66b526b8d1364ddab2a5ebfa3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具体包括：&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Oxlint：类型感知 linting 和自定义 JS 插件&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Oxlint &lt;span style="color:#3d3d3d"&gt;旨在成为一款功能齐全、运行速度与原生速度一致的 Linting 替代品。本月发布了两项重大更新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;类型感知 linting&lt;/strong&gt;：基于 TypeScript 的 Go 端口和 tsgolint，支持 40 个类型感知规则，如 no-floating-promises。性能保持高效，无需牺牲速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自定义 JS 插件支持&lt;/strong&gt;：提供 ESLint 兼容 API，支持运行现有 ESLint 插件，而不牺牲性能。未来，几乎所有 ESLint 插件都能无缝兼容 Oxlint。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Vite&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vite 现已通过&lt;code&gt;@vitejs/plugin-rsc&lt;/code&gt;引入 React Server Component 支持。目标是为每个基于 Vite 的 React 框架提供统一的解决方案。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;@vitejs/plugin-react&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitejs%2Fvite-plugin-react%2Fblob%2Fmain%2Fpackages%2Fplugin-react%2FCHANGELOG.md%23500-beta0-2025-07-28" target="_blank"&gt;5.0 版本已发布&lt;/a&gt;。当检测到&lt;code&gt;rolldown-vite&lt;/code&gt;时，它会直接集成&lt;code&gt;@vitejs/plugin-react-oxc&lt;/code&gt;，因此不再需要额外安装其他插件。&lt;/li&gt; 
 &lt;li&gt;Dev server 漏洞修复，修复源代码泄露风险。详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreen.sapphi.red%2Fblog%2Faddressing-source-code-leaks-across-the-ecosystem-a-retrospective" target="_blank"&gt;阅读 Sapphi 的回顾博客文章&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvite-pwa%2Fvite-plugin-pwa%2Fpull%2F877" target="_blank"&gt;&lt;code&gt;vite-plugin-pwa&lt;/code&gt;（和其他 Vite 插件）&lt;/a&gt;的 Plugin Hooks 现已到位，使用&lt;code&gt;rolldown-vite&lt;/code&gt;时可显著提升其运行速度&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;Vitest&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vitest 在最新的 v4 测试版中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbsky.app%2Fprofile%2Ferus.dev%2Fpost%2F3luzbsen2722x" target="_blank"&gt;支持可视化回归测试&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;v4 测试版通过平均缩短 Vitest 启动时间 25%，进一步提升了测试速度。&lt;/li&gt; 
 &lt;li&gt;Vitest 的实验性&amp;nbsp;programmatic API&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitest-dev%2Fvitest%2Fpull%2F8408" target="_blank"&gt;现在可以解析测试文件，&lt;/a&gt;而不是运行它们来收集测试数据。这对于第三方服务提供商尤其有用，并且有助于未来实现更快的过滤速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Rolldown&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolldown-Vite&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitejs%2Frolldown-vite%2Fpull%2F168" target="_blank"&gt;开箱即用地支持原生插件&lt;/a&gt;。在原生标志下进行改进，并解决所有生态系统 CI 问题后，第一组插件被认为足够稳定，可以默认启用，从而提升所有构建的速度，而无需任何配置。&lt;/li&gt; 
 &lt;li&gt;消除&amp;nbsp;Dead code elimination 和 treeshaking 优化是精简 bundle 的关键。在最近的 Rolldown 版本中进行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fpull%2F5826" target="_blank"&gt;多项&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fpull%2F5829" target="_blank"&gt;改进&lt;/a&gt;，以进一步降低 bundle 大小。 
  &lt;ul&gt; 
   &lt;li&gt;新增&lt;code&gt;inlineConst&lt;/code&gt;&amp;nbsp;功能：在打包过程中内联导入的常量值（而非引用它们）。由于减少了变量查找次数，此特性可缩小打包文件体积并提升运行时性能。自 1.0.0-beta.35 版本起，此优化将默认启用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Rolldown 现在有一个&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frolldown.rs%2Freference%2Fconfig-options%23tsconfig" target="_blank"&gt;顶级&lt;code&gt;tsconfig&lt;/code&gt;选项&lt;/a&gt;。可以将其指向项目的 tsconfig 路径，从而允许解析器遵循&lt;code&gt;compilerOptions.paths&lt;/code&gt;的别名设置，并为转换配置建立默认值。此功能将取代先前引入的&lt;code&gt;resolve.tsconfigFilename&lt;/code&gt;选项。&lt;/li&gt; 
 &lt;li&gt;第一个案例研究已经发布：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fcase-study-plaid-rolldown" target="_blank"&gt;了解 PLAID Inc. 如何迁移到 Rolldown 并将其构建时间缩短 97%&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Oxc&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolldown 团队不仅致力于确保打包体积更小，Oxc 的压缩工具现在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foxc-project%2Foxc%2Fpull%2F13026" target="_blank"&gt;也会多次运行 dead code 消除&lt;/a&gt;，类似于 Rollup。这可以进一步减小打包体积，同时只增加极小的开销。&lt;/li&gt; 
 &lt;li&gt;如果你正在使用 React 和&lt;code&gt;styled-components&lt;/code&gt;，构建速度将显著提升，因为 Oxc 现在将其大部分功能作为原生转换支持。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fblob%2Fmain%2Fexamples%2Fstyled-components-native%2FREADME.md" target="_blank"&gt;如本例所示，&lt;/a&gt;它也可以在 Rolldown 中轻松启用。&lt;/li&gt; 
 &lt;li&gt;提升性能&lt;code&gt;tsgolint&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fwhats-new-aug-2025" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370495/voidzero-whats-new-aug-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370495/voidzero-whats-new-aug-2025</guid>
      <pubDate>Wed, 03 Sep 2025 08:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>这款插件让你在开源图像编辑器 GIMP 中体验谷歌 Nano Banana</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开发者 Josh Ellithorpe 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthoughts.greyh.at%2Fposts%2Fdream-prompter%2F" target="_blank"&gt;发布&lt;/a&gt;&amp;nbsp;Dream Prompter 开源插件，将谷歌最新的 Gemini 2.5 Flash Image Preview 模型（代号 「Nano Banana」）引入 GIMP。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-57d084ce880042f5d91d09d2e5a1dc48003.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该插件支持用户在 GIMP 内直接通过文字提示生成新图像，或对现有图像进行自然语言编辑，无需切换到外部工具。使用 Dream Prompter 需绑定启用计费的 Google Gemini API key，插件本身已开源并托管在 GitHub。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7dee797f30e7632220f65ce17e0f9abb13d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ellithorpe 表示，他在 Claude 模型的帮助下快速完成了插件开发。这一集成让 GIMP 用户能够在开源环境中享受与 Adobe 等商业软件类似的 AI 创作体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370492</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370492</guid>
      <pubDate>Wed, 03 Sep 2025 08:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 生成优化 Metal 内核，PyTorch 推理速度提升 87%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据 Gimlet Labs 的&lt;span&gt;最新&lt;/span&gt;研究，AI 能够自动生成优化的 Metal 内核，使得 PyTorch 推理速度提升了 87%。这一突破性成果不仅提高了性能，还在测试的 215 个 PyTorch 模块上实现了平均 1.87 倍的加速，某些工作负载的速度甚至提高了数百倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="236" src="https://oscimg.oschina.net/oscnet/up-bffbe7fb79340a185f9f81437c72a069abe.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人员选取了来自多个&lt;span&gt;顶尖&lt;/span&gt;机构的八个 AI 模型，包括 Anthropic、DeepSeek 和 OpenAI，利用这些模型为苹果设备生成优化的 GPU 内核。这一过程无需修改用户代码或使用新的框架，直接在苹果硬件上提升模型性能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在实验中，研究团队选择了 Mac Studio （搭载 Apple M4Max 芯片） 进行测试，基准设置为 PyTorch 的 eager 模式。实验采用了 KernelBench 数据集中的 215 个 PyTorch 模块，这些模块被分为三类，涵盖从简单的矩阵乘法到完整的模型架构。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;测试过程包括接收输入和 PyTorch 代码，生成 Metal 内核，并评估其正确性。数据显示，随着尝试次数的增加，AI 生成内核的正确性逐步提升。例如，在第五次尝试时，正确实现的比例达到了 94%。此外，模型们在生成内核时表现出了跨层级的能力，尽管非推理模型有时也能生成有效内核。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;实验结果表明，GPT-5 模型在某些任务上实现了 4.65 倍的速度提升。更令人惊讶的是，o3 模型在某些情况下甚至将延迟降低了 9000 倍。研究还发现，单一模型在某些任务上并不总是表现&lt;span&gt;最好&lt;/span&gt;，多个模型的结合能够生成更优的内核。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;为了进一步提升性能，研究者尝试引入额外上下文信息，如 CUDA 实现和 gputrace 的性能分析数据，结果显示这种方法在性能加速方面达到了平均 1.87 倍，相比于普通智能体的 1.31 倍提升了三倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;需要注意的是，研究人员强调，这一工作并不是为了展示最终的性能极限，而是为了验证 AI 在内核生成中的可行性，希望通过自动化减少开发人员的负担。整体而言，这项研究标志着 AI 技术在硬件优化领域的一个重要进展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370488</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370488</guid>
      <pubDate>Wed, 03 Sep 2025 08:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软积极推动 Rust 在 Windows 驱动开发中的应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软正在积极&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcommunity.microsoft.com%2Fblog%2Fwindowsdriverdev%2Ftowards-rust-in-windows-drivers%2F4449718" target="_blank"&gt;推动&lt;/a&gt; Rust 语言在 Windows 驱动开发中的应用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/162214_t114_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最新进展显示，开发者已可通过多个 Rust crate 在 Windows 11 上编写 WDM、KMDF 和 UMDF 驱动，并借助 &lt;code&gt;cargo-wdk&lt;/code&gt; 工具快速生成模板。然而，目前驱动仍需依赖大量 &lt;code&gt;unsafe&lt;/code&gt; 代码与操作系统交互，Rust 的安全优势尚未完全发挥。&lt;/p&gt; 
&lt;p&gt;微软内部团队正开发「安全 Rust 抽象层」，以减少 &lt;code&gt;unsafe&lt;/code&gt; 的使用，并计划让工具链支持 ARM64 架构、自动依赖安装及远程部署测试。Surface 团队也已贡献了基于 Rust 的驱动代码，推动生态完善。&lt;/p&gt; 
&lt;p&gt;不过，相关工具链和流程仍处早期阶段。微软明确指出，Rust 驱动暂不适合生产环境，提交 Windows 硬件兼容性计划（WHCP）认证的流程也尚未成熟。同时，尽管 GitHub 的 CodeQL 已支持 Rust，但 WHCP 仍未正式认可最新版。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370484</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370484</guid>
      <pubDate>Wed, 03 Sep 2025 08:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌加码推销自研芯片：积极接触 NVIDIA 芯片云服务供应商</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;Google 近期与一批主要采购英伟达芯片的小型云服务供应商接洽，商讨在其数据中心中同时部署谷歌自研芯片。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;据知情人士透露，谈判已取得初步进展：已与总部位於伦敦的 Fluidstack 达成协议，将在后者位于纽约的数据中心托管 Google&amp;nbsp;TPU。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-298295c91cb27c2c551ec24f520733eb813.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;除 Fluidstack 外，Google 还接触了包括被称为「英伟达亲儿子」的 CoreWeave 在内的其他云服务商。&lt;/strong&gt;这一系列举动显示，Google 正试图拉近与那些「受英伟达扶持」的新兴云服务企业之间的关系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;与 Google、亚马逊等大型云厂商不同，这类新兴企业几乎完全依赖英伟达芯片，并更积极采购多种英伟达产品。英伟达不仅向其中多家公司投资，还优先为它们供应当前最紧俏的芯片。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Google 此次与 Fluidstack 达成合作的方式尤为直接：若 Fluidstack 无法承担纽约数据中心的建设成本，Google 愿意以「后备担保」身份介入，并提供最高 32 亿美元的资金支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;目前尚不清楚 Google 为何积极向外推广其自研芯片。此前，Google 几乎从不对外出售自研 TPU。据 Capvision 数据，GoogleTPU 70%–80% 的算力用于内部业务，其余 20%–30% 以自建租赁方式对外开放。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;有分析认为，这一策略可能源于 Google 自建数据中心的进度难以匹配其芯片需求的快速增长，又或者是希望通过第三方云服务商为 TPU 争取更多客户。若属后者，则意味着 Google 正更直接地与英伟达展开竞争。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;分析进一步指出，Google 若扩大以租赁模式部署 TPU，将类似于当前云服务商采用英伟达 GPU 的做法。而随着 GoogleTPU 在这些数据中心中渗透率提升，相应场景中对英伟达 GPU 的采购需求或将减少。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370480</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370480</guid>
      <pubDate>Wed, 03 Sep 2025 08:04:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌垄断案获「阶段性胜利」，得感谢 OpenAI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;美国华盛顿特区地方法院近日就谷歌反垄断案作出裁决，&lt;strong&gt;拒绝司法部提出的 「强制拆分 Chrome 浏览器」 等激进措施&lt;/strong&gt;。这一结果被视为谷歌的 「阶段性胜利」，而幕后推手竟是 OpenAI 等生成式 AI 公司。&lt;/p&gt; 
&lt;p&gt;主审法官 Amit Mehta 在判决书中指出，&lt;strong&gt;ChatGPT 等 AI 工具正成为传统搜索引擎的替代品，对谷歌构成 「新生的竞争威胁」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;OpenAI 高管此前出庭作证，强调若能获取谷歌搜索数据，将优化 ChatGPT 搜索体验，进一步强化了 「AI 挑战搜索霸权」 的敍事。&lt;/p&gt; 
&lt;p&gt;法院认为，在 AI 技术快速演进的背景下，传统搜索引擎的垄断地位已不再牢不可破，因此无需进行结构性拆分。这一裁决不仅为谷歌赢得喘息空间，也为科技巨头在反垄断诉讼中提供了新的辩护模板 ——「AI 威胁论」 或成未来关键论据。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-df103573bde542adfd1cea79dc07f1e2be9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管免于 「拆分」，谷歌也绝非毫发无损。Mehta 法官在判决中对谷歌的行为施加了一系列限制性措施，旨在削弱其在搜索市场上的垄断地位，为竞争对手创造喘息空间。&lt;/p&gt; 
&lt;p&gt;具体而言，法院禁止谷歌与其合作伙伴签订排他性的搜索引擎分销协议，并要求谷歌向竞争对手分享部分搜索数据，以帮助它们改进自身产品。此外，判决还禁止谷歌将在 Android 系统上授权其应用商店（Google Play Store）与必须预装其他谷歌应用（如搜索、Chrome 或 Gemini）的做法捆绑在一起。&lt;/p&gt; 
&lt;p&gt;总的来说，谷歌能 「躲过一劫」，不是因为它没垄断，而是因为 OpenAI 的 AI 浪潮让法院相信：搜索市场的游戏规则，正在被重写。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/369982" target="news"&gt;美国法院裁定谷歌无需出售 Chrome 浏览器&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/366896" target="news"&gt;多家企业盯上谷歌 Chrome，奥特曼表态 OpenAI 或考虑收购&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz" target="news"&gt;谷歌认为自己是唯一能运营 Chrome 的公司，如若转手，将「万劫不复」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370477</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370477</guid>
      <pubDate>Wed, 03 Sep 2025 07:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>系统梳理 Test-Time Compute 的主要实现路径</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; AI 真的在"思考"吗？当模型面对数学推理、代码生成或复杂决策时，它是如何一步步推演出答案的？如果你曾困惑于大模型在关键任务中表现不稳定、缺乏可解释性，甚至生成结果难以验证，那么你并不孤单。这些痛点不仅影响研发效率，更直接制约了 AI 在高风险场景中的落地可靠性。&lt;/p&gt; 
 &lt;p&gt;本文系统梳理了测试时计算（test-time compute）的三大实现路径：N 选 1 采样、多数投票及相关方法、思维链（Chain-of-Thought）自我推理，到融合搜索算法与世界模型的结构化推理系统，还深入探讨了验证器设计、奖励机制、隐空间推理与智能体行为优化等关键挑战。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Davis Treybig&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当前大语言模型（LLM）最有趣的研究趋势之一，是推理模型的兴起 ------ 这类模型在给出答案前会花费时间进行思考。&lt;/p&gt; 
&lt;p&gt;这种技术通常被称为「测试时计算」（test-time compute），即在推理阶段进行深度推理。其实在模型推理过程中应用搜索或深度推理的思路早已存在（例如 AlphaZero[1]，以及 Transformer 诞生之前就尝试用类似方法解决旅行商问题的论文[2]），但 o1 的出现让这一理念重新回到了主流视野。&lt;/p&gt; 
&lt;p&gt;最令人兴奋的是，这种测试时计算可能展现出与预训练相似的扩展规律 ------ 换言之，&lt;strong&gt;就像增加训练计算量能带来模型能力的指数级提升一样，若在推理阶段分配更多计算资源（延长思考时间），模型性能理论上也会出现可预测的指数级增长。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2cd5f7b45300d59d739523bdcd8b93f024e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 发布的关于 o1 模型测试时计算扩展效果的图示表明：模型的准确率相对于对数尺度的计算量呈现可预测的增长，表明存在指数关系&lt;/p&gt; 
&lt;p&gt;但像 o1 这类模型背后的实现原理究竟是什么？测试时计算扩展（test-time compute scaling）又有哪些不同的实现机制与技术路径？目前我尚未找到关于此技术直观系统的综述，而 OpenAI 对其技术细节守口如瓶，因此本文将尝试构建一个解读框架。&lt;/p&gt; 
&lt;p&gt;本篇博客将结合近期的大量文献研究以及与多家实验室机器学习研究者的交流，系统梳理实现测试时计算扩展的主要技术路径。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 测试时计算的基本实现机制&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 N 选 1 采样、多数投票（majority voting）及相关方法&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;其核心思想是让语言模型在推理阶段生成多个可能的输出，然后通过采样、投票或其他评估/验证器方法来选出最佳答案。&lt;/strong&gt; 这种方法无需改变模型的训练方式，但确实能作为一个有效的基线方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8257e1d517a101818c839f17c356858539a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Large Language Monkeys[3]&lt;/p&gt; 
&lt;p&gt;其中的第一点细微差异在于验证器的设计。多数投票（majority voting）等简单方法通用性虽强但效果有限。代码、数学等特定领域可采用专用的验证器（如代码的单元测试与编译器、数学的符号计算引擎），但缺乏普适性。目前的主流趋势是通过微调大语言模型构建专用验证器（参见此案例[4]）。&lt;/p&gt; 
&lt;p&gt;另一个问题在于，对于许多更复杂的问题，传统的采样方法可能永远无法生成正确答案（或者需要耗费大量计算资源才能以足够高的概率生成正确答案）。后续我们将看到，解决这一问题的正确方法要么基于优质推理轨迹进行训练，要么通过奖励机制引导模型完成复杂推理。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 思维链（Chain of thought）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;第二种方法是让语言模型生成极其详细的长链思维推理轨迹，以此提升推理能力。&lt;/strong&gt; 这种方式本质上是单一模型通过自回归方式产生大量 token 的自我对话过程 ------ 并不依赖外部系统或控制流程。OpenAI 在其 o1 公告中展示了此类案例[5]。&lt;/p&gt; 
&lt;p&gt;虽然基础版本可通过提示词工程实现（例如"逐步思考"），但其进阶版本需要专门的预训练与后训练技术，以优化这类长链推理轨迹的生成效果。&lt;/p&gt; 
&lt;p&gt;这里的关键差异在于模型如何通过训练提升长链推理能力。大致有以下实现路径：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）监督学习（Supervised learning）&lt;/strong&gt; ------ 理论上可通过大量人工撰写的长链思维样本进行训练。但实践中难以获取足够的高质量数据：公开领域的高水平长篇幅推理样本稀缺，且人工制作成本极高。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2）合成推理轨迹（Synthetic reasoning traces）&lt;/strong&gt; ------ 在特定问题领域，可通过程序化方法生成复杂的推理轨迹。例如这项研究[6]利用知识图谱生成保证正确性的问题/推理/答案三元组。在数学和计算机科学领域，还可使用形式化系统（如符号计算引擎、Lean 语言[7]、编译器与构建系统）产生合成推理链，作为模型的训练样本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3）采样&amp;amp;验证&lt;/strong&gt; ------ 要求大语言模型生成多个推理输出，通过验证机制或奖励模型区分优劣推理链，进而构建用于后训练的强化学习数据集。核心区别在于使用结果奖励模型（ORM，验证最终输出的正确性）还是过程奖励模型[8]（PRM，对局部推理链进行奖励评估）。该领域存在非常多的方法：包括采样生成方式、验证器的训练或设计、以及整合奖励信号的强化学习系统架构等。&lt;/p&gt; 
&lt;p&gt;此处的考量在于：如何在 a. 数据规模 b. 计算可行性 c. 人力成本这三个维度实现高效扩展？OpenAI 强调其 o1 技术具备"数据高效特性（data-efficient）"，暗示其很可能深度融合了合成数据与基于强化学习的验证技术，而非某种依赖人工标注的推理数据集。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;合成数据技术虽有效，但通常局限于特定领域和更易量化的问题类型，因此其泛化能力仍存疑。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;采样技术面临的挑战在于，许多复杂问题的推理搜索空间过大，既无法进行穷举生成，也难以高效验证。&lt;/strong&gt; 这与机器人等强化学习领域面临的问题相似 ------ 需要巧妙地模拟或"搜索"结果空间，并设计奖励函数。&lt;/p&gt; 
&lt;p&gt;这正是过程奖励模型（PRM）的价值核心 ------ 它能提前终止错误的推理路径，聚焦于成功概率较高的中间状态进行分支（相关论述参见该论文[9]第 3.3 节）。&lt;/p&gt; 
&lt;p&gt;关于如何构建推理轨迹结构以提升训练效果，当前存在大量前沿探索：Dualformer[10] 在训练过程中有选择性地遮蔽部分推理轨迹，旨在让模型习得类似人类"系统 1"的心理启发式思维；Stream of Search[11] 研究则发现包含错误回溯、自我修正的"不完美"推理轨迹，相比完美的线性推理更具训练价值；另有论文[12]证实带回溯纠错的错误推理链对训练有益；Beyond A[13] 甚至通过 A* 等经典搜索算法构建训练样本，来教导模型如何进行搜索。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 推理时搜索（及其他辅助系统）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;实现推理阶段计算扩展的第三大路径，是在推理过程中实际采用某种搜索技术。&lt;/strong&gt; 这意味着推理不再仅仅是模型推理问题，更演变为系统工程问题 ------ 需要引入某种控制流或流程编排机制，而非单纯依赖单一模型的词元输出。&lt;/p&gt; 
&lt;p&gt;一些有趣的例子表明，这种范式不仅限于"标准"的大语言模型。例如，AlphaZero[14] 通过训练后的神经网络指导蒙特卡洛树搜索算法选择最佳落子位置；AlphaProof[15] 则结合预训练大语言模型与强化学习算法生成候选解决方案，再通过 Lean 证明辅助语言（proof assistant language）进行验证。&lt;/p&gt; 
&lt;p&gt;当前 LLM 研究中，最常见的实现形式是在推理阶段集成某种"搜索+验证"技术：模型首先生成 N 个候选的推理步骤，经验证器或奖励模型评分筛选后，然后在最优候选子集中重复此过程。值得注意的是，前文讨论的"N 选 1 采样"方法可视为该体系的子集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-58d7426c8fc0e5267ace67aa3ad9ece203b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;HuggingFace 关于通过搜索+过程奖励模型实现测试时计算的综述&lt;/p&gt; 
&lt;p&gt;该领域的优秀研究案例包括：Tree of Thoughts[16]、Self-Evaluation Guided Beam Search for Reasoning[17] 以及 Reasoning with Language Model is Planning with World Model[18]。这些方法均融合了搜索技术（广度优先搜索、深度优先搜索、波束搜索、蒙特卡洛树搜索）与验证机制来引导语言模型推理生成。LLM Reasoners[19] 论文中的可视化呈现（如下图所示）直观展示了这些技术的运作方式。这些方法在核心思路上高度一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f0095e8a0625a7ce2c03476b6113eba37dc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，这种"搜索技术+验证器+生成模型"的组合范式与前文所述的思维链技术几乎同构 ------ 唯一区别在于这些技术是离线应用于生成后训练强化学习数据集，还是在推理时在线应用。&lt;strong&gt;但两种方式都实现了测试时计算扩展：前者通过训练使模型在测试时进行更长时间的推理，而后者则在推理过程中引导模型生成更大量的输出。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;除搜索算法外，还可集成其他类型的辅助系统来增强生成模型。RAP 论文[18]便是一个典型范例：研究者使用一个辅助 LLM 作为"世界模型"来追踪环境状态。换句话说，当生成式 LLM 持续输出回溯、思考、权衡等推理动作时，世界模型会同步跟踪每个动作执行后的"世界状态"。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f2ffd7e8607c9b8103c6e8245f58d62e57.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;标准思维链动作序列与世界模型方法的可视化对比（后者在每个动作后均保留了"世界状态"）&lt;/p&gt; 
&lt;p&gt;从理论上讲，这种方式让模型能更轻松地推断后续动作产生的影响。相较於单一思维链的输出，模型必须隐式回放整个动作序列才能理解当前世界状态。&lt;/p&gt; 
&lt;p&gt;上文提到的推理研究论文[19]提出了一个有趣的形式化框架，试图将多数投票、思维链、搜索技术等不同方法统一到同一个理论体系中。&lt;/p&gt; 
&lt;p&gt;研究者认为这些技术本质上都是以下三要素的组合：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）用于确定不同推理步骤优先级的奖励函数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2）用于定义推理状态转换的世界模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3）用于探索广阔推理空间的搜索算法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在此框架下，标准的思维链推理的奖励函数等同于默认模型似然输出，其世界模型仅简单地将推理动作持续追加到完整动作历史中，并采用始终对输出概率分布进行单次采样的"贪婪"搜索算法。&lt;/p&gt; 
&lt;p&gt;笔者认为这种分析视角颇具启发性。该论文还通过基准测试发现：搜索技术持续优于思维链推理，而 RAP（世界模型+搜索技术）则始终超越纯搜索方法。&lt;/p&gt; 
&lt;p&gt;斯坦福大学近期对推理模型的元综述（meta overview）[20]也描述了类似的思维框架 ------ 认为这些方法大多都是"生成器、验证器和搜索组件的集成"，这本质上是相同的框架。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 其他考量因素&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 验证器机制&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如我们所见，这些技术的效果很大程度上取决于验证器的质量及其验证能力。启发式/自动验证器（Heuristic/automatic verifiers）虽有效但天然具有领域局限性（例如，编程题目中的测试用例）。学习型验证器（Learned verifiers）虽可行，但需要特定领域的高质量训练数据 ------ 可参考 OpenAI 这篇早期的论文[21]，他们训练了用于数学问题的学习型验证器。直接使用 LLM 用作验证器虽已取得显著进展，但该方法的可行性仍存在一定局限。基于过程的验证器（Process based verifiers）非常重要，但其实现难度远高于基于结果的验证器（outcome based verifiers）。&lt;/p&gt; 
&lt;p&gt;MuZero[22] 为此领域的发展提供了一个重要参照 ------ 这个无模型的强化学习系统能掌握多种复杂游戏并达到顶尖水平。"无模型（Model-free）"意味着其强化学习算法中并未编码任何特定游戏规则。&lt;/p&gt; 
&lt;p&gt;这种领域无关的验证器设计似乎对模型在推理能力上实现普遍提升非常重要。当然，关键问题在于，相较于围棋、国际象棋、将棋和 Atari 游戏等奖励函数明确的领域，如何在奖励机制更模糊的领域实现类似效果仍待探索。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 泛化能力存疑&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;这篇精彩的博文深入探讨了将强化学习应用于推理领域的挑战[23]，特别是在 OpenAI 的 o1 模型这个具体背景下来讨论这个问题。&lt;strong&gt;o1 采用强化学习技术，而强化学习在奖励信号清晰且频繁的领域效果最佳，但现实是大多数领域缺乏这种明确的奖励机制。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;......&lt;/p&gt; 
&lt;p&gt;OpenAI 承认 o1 是在易于验证的领域进行训练的，但希望其推理能力能泛化到所有领域。这种跨领域的泛化能力能否实现，是一个价值万亿美元的问题。我先直截了当地说出我的观点：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⚠️ o1 风格的推理模型无法实现超越训练领域的有效泛化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;从实际案例来看，当前多数测试时计算模型在特定问题领域（如数学、逻辑、计算机科学）表现突出，但在其他领域并未展现明显优势。许多体验过这类模型的研究者反馈，它们在传统生成任务上的表现反而明显下降。基于强化学习的推理技术能否有效泛化到验证难度更高的领域，仍是一个值得探索的开放性问题。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 词元空间与隐空间中的推理&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;与上述所有方法形成有趣对照的是：词元空间究竟是否为模型推理的最优方式？现有研究开始探索让模型直接在隐空间[24]中推理 ------ 即在推理过程中将隐藏状态反馈给模型，而非解码后的词元。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e997cb1967f1e2ad035093d95b7c697c221.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;从理论上讲，隐空间推理可能更具优势，因为隐藏状态（hidden state）代表了下一词元生成的概率分布，而词元本质上是该分布的"采样样本"。相较于仅选择一个状态，在所有可能状态下进行推理更接近人类的推理模式，可能有提升效果。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这种方法的潜在缺陷是，此类模型不会向用户"展示推理过程"。但考虑到 OpenAI 等公司已经开始隐藏推理步骤，这个缺点或许无关紧要。理论上仍可可视化词元输出而同时在隐空间推理，但这可能导致用户所见与模型实际推理过程出现偏差。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.4 智能体推理机制&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;我特别关注这些技术如何映射到智能体领域。优化模型的多步骤复杂推理轨迹，与优化智能体的多步骤推理轨迹存在高度相似性 ------ 唯一区别在于智能体的子步骤被拆分为不同的模型调用，且通常涉及更多动态组件（如函数调用等）。&lt;/p&gt; 
&lt;p&gt;观察到许多领先的智能体创业公司（如 Cognition、Basis 等）都将这些理念融入其智能体设计。例如，多家智能体公司会采集智能体的运行轨迹，通过搜索技术+奖励模型进行回放来推演反事实推理路径（counterfactual reasoning paths），并将这些反事实轨迹（counterfactual trajectories）作为微调样本用于提升智能体系统性能。&lt;/p&gt; 
&lt;p&gt;对于需要 50-100+ 次链式 LLM 调用来在复杂工具环境中完成任务的智能体而言，这种方法至关重要 ------ 因为单次请求下智能体可执行的动作组合复杂度极高。&lt;/p&gt; 
&lt;p&gt;特别值得关注的是，相较于在模型层通用地解决多步推理问题，设计针对特定领域的搜索算法和过程奖励模型显然更具可行性。&lt;/p&gt; 
&lt;p&gt;这恰好印证了前文提及的那篇博客文章的观点：这些技术可能难以实现泛化。&lt;strong&gt;复杂推理的强化学习技术在模型提供商层面或许难以泛化，反而会成为垂直领域智能体创业公司的核心护城河&lt;/strong&gt; ------ 尤其是在需要高度复杂推理的领域（如会计、税务、金融、建筑等）。&lt;/p&gt; 
&lt;p&gt;预计未来将出现专门支持此类任务的开发工具（类似微调领域的 MosaicML 生态），帮助智能体创业公司更便捷地构建"搜索技术+验证"层，并为特定应用场景生成训练数据集。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓文章指出，测试时计算的泛化能力是"价值万亿美元的问题"。您认为，基于强化学习的推理技术能否有效泛化到数学、代码之外，缺乏明确奖励信号的"模糊"领域（如创意写作、战略规划）？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeepmind.google%2Fdiscover%2Fblog%2Falphazero-shedding-new-light-on-chess-shogi-and-go%2F" target="_blank"&gt;https://deepmind.google/discover/blog/alphazero-shedding-new-light-on-chess-shogi-and-go/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1611.09940" target="_blank"&gt;https://arxiv.org/abs/1611.09940&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2407.21787" target="_blank"&gt;https://arxiv.org/pdf/2407.21787&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2408.15240" target="_blank"&gt;https://arxiv.org/pdf/2408.15240&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Flearning-to-reason-with-llms%2F" target="_blank"&gt;https://openai.com/index/learning-to-reason-with-llms/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fextrasensoryai.github.io%2Fenki%2Fblog%2Fsynthetic-data-cot%2F" target="_blank"&gt;https://extrasensoryai.github.io/enki/blog/synthetic-data-cot/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flean-lang.org%2Fabout%2F" target="_blank"&gt;https://lean-lang.org/about/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2410.08146" target="_blank"&gt;https://arxiv.org/pdf/2410.08146&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2501.04682" target="_blank"&gt;https://arxiv.org/pdf/2501.04682&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2410.09918" target="_blank"&gt;https://arxiv.org/pdf/2410.09918&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.03683" target="_blank"&gt;https://arxiv.org/abs/2404.03683&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2408.16293" target="_blank"&gt;https://arxiv.org/abs/2408.16293&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2402.14083" target="_blank"&gt;https://arxiv.org/pdf/2402.14083&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeepmind.google%2Fdiscover%2Fblog%2Falphazero-shedding-new-light-on-chess-shogi-and-go%2F" target="_blank"&gt;https://deepmind.google/discover/blog/alphazero-shedding-new-light-on-chess-shogi-and-go/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeepmind.google%2Fdiscover%2Fblog%2Fai-solves-imo-problems-at-silver-medal-level%2F" target="_blank"&gt;https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2305.10601" target="_blank"&gt;https://arxiv.org/pdf/2305.10601&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2305.00633" target="_blank"&gt;https://arxiv.org/pdf/2305.00633&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2305.14992" target="_blank"&gt;https://arxiv.org/pdf/2305.14992&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[19]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2404.05221" target="_blank"&gt;https://arxiv.org/pdf/2404.05221&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[20]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2501.04682" target="_blank"&gt;https://arxiv.org/pdf/2501.04682&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[21]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2110.14168" target="_blank"&gt;https://arxiv.org/pdf/2110.14168&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[22]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeepmind.google%2Fdiscover%2Fblog%2Fmuzero-mastering-go-chess-shogi-and-atari-without-rules%2F" target="_blank"&gt;https://deepmind.google/discover/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[23]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faidanmclaughlin.notion.site%2Freasoners-problem" target="_blank"&gt;https://aidanmclaughlin.notion.site/reasoners-problem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[24]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2412.06769" target="_blank"&gt;https://arxiv.org/pdf/2412.06769&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.innovationendeavors.com%2Finsights%2Fmechanisms-for-test-time-compute" target="_blank"&gt;https://www.innovationendeavors.com/insights/mechanisms-for-test-time-compute&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18690730</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18690730</guid>
      <pubDate>Wed, 03 Sep 2025 07:25:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>英伟达新款「中国特供」 AI 芯片性能强于 H20，但价格翻番</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fworld%2Fchina%2Fchinese-firms-still-want-nvidia-chips-despite-government-pressure-not-buy-2025-09-04%2F"&gt;路透社独家报道&lt;/a&gt;了英伟达新款中国特供芯片的更多细节。&lt;/p&gt; 
&lt;p&gt;据了解，该芯片暂定名为 B30A，基于英伟达 Blackwell 架构，性能更强大。&lt;/p&gt; 
&lt;p&gt;两位知情人士表示，如果美国批准英伟达对华销售 B30A，其价格很可能是 H20 的两倍左右。目前，H20 的售价介于 1 万美元至 1.2 万美元之间。&lt;/p&gt; 
&lt;p&gt;在性能方面，一位知情人士称，B30A 的性能有望高达 H20 的六倍。B30A 和 H20 均为降级版芯片，专为遵守美国对华出口管制为中国市场开发。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/367317"&gt;结合之前的报道&lt;/a&gt;，该芯片采用单芯片设计，预计其算力约为旗舰级 B300 加速卡双芯片配置的一半。此外，该芯片将配备高带宽内存（HBM）和 NVLink 技术，以提升处理器间的数据传输效率。单芯片设计指所有主要电路都制作在同一块连续的硅晶圆上，而不是分散在多个芯片上。&lt;/p&gt; 
&lt;p&gt;当被问及在中国市场与对手的竞争格局时，英伟达在一份声明中表示：「竞争无疑已经到来」。该公司拒绝进一步置评。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370467</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370467</guid>
      <pubDate>Wed, 03 Sep 2025 07:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>华为 AI 模型运行专利公布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;天眼查 App 资料显示，华为技术有限公司申请的「AI 模型的运行方法、装置、程序产品和存储介质」专利于 9 月 5 日公布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-9727352c7cbd66eb90acc6a5d3ef583d555.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;摘要显示，本公开提供了一种 AI 模型的运行方法、装置、程序产品和存储介质，属于机器学习技术领域。该方法应用于主机，主机包括处理器，并连接计算卡，该方法包括：处理器确定 AI 模型相邻的两组输入数据中在第二数据组中但不在第一数据组中的第一数据，第二数据组在第一数据组之后训练，将第一数据对应的第一嵌入向量预取至处理器的第一内存，并确定第一数据对应的第一嵌入向量信息，在第二数据组在计算卡上处理过程中，根据第一嵌入向量信息将第一嵌入向量从第一内存预取至计算卡的第二内存。采用本公开所示的方案，能够减少嵌入向量搬运带来的处理延时。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370466</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370466</guid>
      <pubDate>Wed, 03 Sep 2025 07:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DuckDuckGo 在其订阅计划中添加了对高级 AI 模型的访问权限</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;注重隐私的消费科技公司 DuckDuckGo 去年推出了一项订阅计划，该公司周四表示，现在订阅服务允许用户通过 Duck.ai 访问最新的 AI 模型，无需额外付费。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-37ceb4f3efe0160bc85873fa2aeee1e4e0c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Duck.ai 聊天机器人可以让用户免费使用，包括 Anthropic 的 Claude 3.5 Haiku、Meta 的 Llama 4 Scout、Mistral AI 的 Mistral Small 3 24B 和 OpenAI 的 GPT-4o mini 等模型。&lt;/p&gt; 
&lt;p&gt;通过 DuckDuckGo 每月 9.99 美元的计划，用户将能够访问更新的模型，包括 OpenAI 的 GPT-4o 和 GPT-5、Anthropic 的 Claude Sonnet 4 和 Meta 的 Llama Maverick。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-05a531bb9bcf7d8ae1588a8570acc2ba232.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ff24034c7a8ed96e1594e923557bcafac9d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspreadprivacy.com%2Fp%2Fab42d8ac-7e7d-4610-86a7-fbb9c36d058d%2F"&gt;该公司在一篇博文中表示&lt;/a&gt;：「这些更大的模型更擅长遵循详细的指令，在长时间的聊天中保持语境，并提供更深入、更细致的回应。DuckDuckGo 订阅提供了一种使用其中一些模型的方式，但同时又能更好地保护隐私。」&lt;/p&gt; 
&lt;p&gt;对于那些想要访问最新模型而不局限於单一供应商的人来说，这是一个绝佳的机会。此外，Quora 的 Poe 也提供一系列模型的访问权限。您可以以每月 5 美元起的价格购买 Poe 的订阅服务。&lt;/p&gt; 
&lt;p&gt;DuckDuckGo 表示，将继续在其付费产品中增加更昂贵的套餐，提供 「更大、更先进的型号」。该公司并未具体说明当前套餐是否有使用限制。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370464</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370464</guid>
      <pubDate>Wed, 03 Sep 2025 06:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>TikTok 与美摄的知识产权纠纷案将于 10 月在美国开庭审理</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fusaherald.com%2Ftiktok-chinese-company-845m-ip-fight-moves-forward-to-october-jury-trial%2F"&gt;据《美国先驱报》报道&lt;/a&gt;，北京美摄网络科技有限公司与 TikTok 的诉讼官司将于 10 月在美国开庭审理，加州一名联邦法官拒绝完全批准 TikTok 提出的简易判决或终止制裁的动议。&lt;/p&gt; 
&lt;p&gt;该案涉及商业机密盗窃和版权侵权指控，涉案金额达 8.45 亿美元，将于 10 月 27 日开始为期 12 天的陪审团审理。&lt;/p&gt; 
&lt;p&gt;在一份长达 36 页的裁决中，美国地区法官苏珊・伊尔斯顿（Susan Illston）裁定，关于美摄的版权所有权和涉嫌盗用商业机密的行为仍然存在实质性的事实争议。&lt;/p&gt; 
&lt;p&gt;法院驳回了针对 TikTok 母公司字节跳动有限公司的诉讼，但允许针对 TikTok 的核心知识产权诉讼继续进行。&lt;/p&gt; 
&lt;p&gt;该诉讼于 2021 年提起，后转至加州北区联邦地区法院，指控美摄公司一名前员工盗用了高度机密的源代码，随后 TikTok 和字节跳动的关联公司使用这些代码开发视频编辑功能。美摄公司声称，这些被盗用的代码价值约 8.45 亿美元。&lt;/p&gt; 
&lt;p&gt;字节跳动于 2023 年解雇了涉案员工，但保留了提起相关诉讼的权利。此后，双方进行了广泛的动议实践，包括针对概括对专家证词的判断和证据质疑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c9598d0dbf07971e421eff82551bfa14faf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;伊尔斯顿法官驳回了 TikTok 终止制裁的请求，认为尽管美摄公司的部分证人行为存在疑问，但不足以构成撤销制裁的理由。&lt;/p&gt; 
&lt;p&gt;法院还裁定，美摄公司与新奥特（XAT）之间相关中国诉讼及许可协议的关键文件可予采纳，从而强化了美摄公司对争议知识产权的所有权主张。&lt;/p&gt; 
&lt;p&gt;「这项裁决确保了 TikTok 这家中国公司 8.45 亿美元知识产权纠纷的核心问题将由陪审团审理并裁决，[美摄公司发言人 / 代表表示。「我们对自己的立场充满信心，并期待着陈述我们的主张。」&lt;/p&gt; 
&lt;p&gt;TikTok 及其代表尚未对该裁决发表评论。&lt;/p&gt; 
&lt;p&gt;该案是北京美摄网络科技有限公司诉 TikTok Inc. 等案，案号 3:23-cv-06012，在美国加州北区地方法院审理。&lt;/p&gt; 
&lt;p&gt;这个案件在国内已经终审完毕，上述信息是在美国的进展。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读；&lt;a href="https://www.oschina.net/news/333672" target="_blank"&gt;抖音副总裁回应字节跳动抄袭案：美摄曾要求披露 TikTok 全部源代码&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370460</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370460</guid>
      <pubDate>Wed, 03 Sep 2025 06:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
