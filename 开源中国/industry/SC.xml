<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 12 Aug 2025 12:40:28 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Fedora 43 获准支持 Hare 编程语言，默认启用硬链接</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Fedora 工程与指导委员会 (FESCo) 本周批准了即将发布的 Fedora Linux 43 版本的多项新增功能。其中包括获准发布 Hare 软件包，Hare 是一种新的系统编程语言，旨在简化、稳定和健壮。&lt;/p&gt; 
&lt;p&gt;Hare 本身仍在开发中，但 FESCo 现已批准将 Hare 工具链打包并发布到 Fedora 43 的仓库中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/191447_Wl7H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;FESCo 还批准在 Fedora 43 中发布即将发布的 PHP 8.4 版本，这并不令人意外。FESCo 还批准弃用 YASM，转而使用 NASM。YASM 汇编器目前无人维护，而 NASM 的情况也好多了。&lt;/p&gt; 
&lt;p&gt;作为英特尔 oneAPI 线程构建版本 (TBB) 的最新更新，Threaded Building Blocks 2022.2 也已获批准发布。FESCo 本周还批准了默认对 Fedora RPM 软件包中，相同的 /usr 文件进行硬链接的提案。&lt;/p&gt; 
&lt;p&gt;有关 Fedora 43 版本中这些新批准更改的更多详细信息，&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.fedoraproject.org%2Farchives%2Flist%2Fdevel%40lists.fedoraproject.org%2Fthread%2FMVPWNTBSZUUJINZX6PZQGTYE2BA7NFKL%2F" target="_blank"&gt;请通过此 FESCo 邮件列表帖子获取&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;，该版本将于今年晚些时候发布。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365798</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365798</guid>
      <pubDate>Tue, 12 Aug 2025 11:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>One Million Screenshots：收集了超过 100 万张网站截图的网站</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;「One Million Screenshots」 是一个专门收集网站截图的网站，声称截图了超过 100 万个热门 Web 主页。此外还提供了搜索相似网站的功能，以及查看网站截图的历史变化。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0812/185333_PgpB_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;https://onemillionscreenshots.com/&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;没想到 OSCHINA 也荣幸出镜了：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fonemillionscreenshots.com%2Foschina.net%2Fscreenshot" target="_blank"&gt;https://onemillionscreenshots.com/oschina.net/screenshot&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="6306" src="https://static.oschina.net/uploads/space/2025/0812/185758_Ydik_2720166.png" width="1604" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是关于该网站的常见问题：&lt;/p&gt; 
&lt;p&gt;&lt;img height="2386" src="https://static.oschina.net/uploads/space/2025/0812/185221_4Hkz_2720166.png" width="1514" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365794</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365794</guid>
      <pubDate>Tue, 12 Aug 2025 11:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>人工智能正在降低知识的价值，大学应该重新考虑所教授的内容？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;生成式人工智能，尤其是大型语言模型（LLM）的兴起，正以前所未有的速度改变知识获取的格局。奥克兰大学商学院教授帕特里克·多德在《对话》(The Conversation) 上撰文指出，随着 AI 以低成本、高效率的方式提供知识，大学作为传统知识来源的价值正在受到挑战。他认为，大学必须重新审视其核心功能，以适应这个由 AI 驱动的新时代。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多德教授分析，大学长期以来奉行「知识稀缺」的原则，通过提供独家课程和学位证书来证明学生获取知识的能力。然而，AI 技术的进步已大大降低了获取专业知识的门槛，LLM 不仅能检索事实，还能进行解释、翻译和总结，使得曾经「稀缺」的知识价值大打折扣。这种变化已经在劳动力市场显现，自 ChatGPT 问世以来，英国入门级职位空缺减少了约三分之一，美国部分州甚至取消了公共部门职位的学位要求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;然而，多德强调，并非所有知识都同等贬值。虽然基础知识的价值下降，但&lt;strong&gt;隐性知识&lt;/strong&gt;，如团队协作、伦理判断、创造力以及解决复杂问题的能力，仍是 AI 无法取代的稀缺资源。他指出，未来教育的重点应从传授信息转向培养这些关键的人类技能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;为应对这一挑战，多德教授为大学提出了四项转型建议：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;评估转型&lt;/strong&gt;：将课堂评估重点从单纯的知识记忆转向&lt;strong&gt;判断和综合能力&lt;/strong&gt;的考察。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;体验式学习&lt;/strong&gt;：投入资源开发导师指导项目、模拟现实场景，并利用 AI 作为工具进行伦理决策研究。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;技能微证书&lt;/strong&gt;：创建针对协作、自主学习和伦理判断等关键能力的微证书。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深化产学研合作&lt;/strong&gt;：大学提供专业知识，企业提供真实案例，学生则专注于验证和完善想法，共同培养适应未来市场的复合型人才。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多德总结道，如果大学想要在未来立于不败之地，就必须从一个单纯的&lt;strong&gt;信息来源&lt;/strong&gt;转变为一个&lt;strong&gt;判断力中心&lt;/strong&gt;，教会学生如何与 AI 协同思考，而非与之竞争。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365792</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365792</guid>
      <pubDate>Tue, 12 Aug 2025 10:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源编程字体「Hack」创始人 Christopher Simpkins 去世</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Christopher Eric Simpkins 是知名开源编程字体「Hack」创始人，他于 2025 年 6 月 20 日在新罕布什尔州汉诺威突然&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftypo.social%2F%40Hilary%2F114845913381245488" target="_blank"&gt;去世&lt;/a&gt;，享年 51 岁。&lt;/p&gt; 
&lt;p&gt;&lt;img height="904" src="https://static.oschina.net/uploads/space/2025/0812/175131_lS6n_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Christopher Simpkins 讣告页面&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.legacy.com%2Fus%2Fobituaries%2Fvnews%2Fname%2Fchristopher-simpkins-obituary%3Fid%3D58856786" target="_blank"&gt;显示&lt;/a&gt;，他&lt;span&gt;在佐治亚理工学院取得计算机博士学位后先在美军服役，退役又完成医学训练成为一名器官移植外科医生&lt;/span&gt;。他医术精湛、待人温和，被誉为「温柔的巨人」，拯救了许多生命并屡获教学奖。&lt;/p&gt; 
&lt;p&gt;后来他转向科技领域，&lt;span&gt;加入 Google Fonts 团队任&lt;/span&gt;高级用户体验项目经理&lt;span&gt;，&lt;/span&gt;专注字体开发&lt;span&gt;，发起 Codeface 项目为开发者整理并推荐高可读性的编程字体，持续推动开源字体生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/175331_L0CQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;2015 年，&lt;/span&gt;Christopher Simpkins 创造了&lt;span&gt;开源 Hack 字体，这款基于 DejaVu Sans Mono 重新调校的等宽字体迅速成为程序员最喜爱的编辑器字体之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;谷歌近期发布的开源字体&lt;/span&gt;&lt;a href="https://www.oschina.net/news/363609/googlesans-code" target="_blank"&gt;&amp;nbsp;Google Sans Code &lt;/a&gt;正是由&amp;nbsp;Christopher Simpkins 负责主导。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1710" src="https://static.oschina.net/uploads/space/2025/0812/180516_SXlX_2720166.png" width="1686" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365788</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365788</guid>
      <pubDate>Tue, 12 Aug 2025 10:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达推出 Cosmos 与 Nemotron 模型，推动物理 AI 与智能体发展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.nvidia.cn%2Fblog%2Fnvidia-opens-portals-to-world-of-robotics-with-new-omniverse-libraries-cosmos-physical-ai-models-and-ai-computing-infrastructure%2F" target="_blank"&gt;据英伟达官方消息&lt;/a&gt;，英伟达在技术领域再推新进展。其推出的 NVIDIA Cosmos 平台，整合前沿生成式世界基础模型（WFM）、先进分词器、护栏以及高效数据处理和管理工作流，旨在加速物理 AI 开发。该平台的世界基础模型经 2000 万小时真实世界数据训练，能预测和生成虚拟环境未来状态，助力开发者构建新一代机器人和自动驾驶汽车。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/174129_nIuV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时，英伟达宣布推出 Nemotron 模型系列。Llama Nemotron 基于热门开源模型 Llama 构建，经剪枝和训练，在指令遵循等方面表现出色，能为 AI 智能体开发提供优化基础模组。Cosmos Nemotron 视觉语言模型（VLM）则可助力开发者构建智能体，使其能分析图像和视频并做出响应。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9ddc7846bd0a958a9b0a9772dcf6c6a4e47.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，已有众多物理 AI 领域的领先者，如机器人公司，以及自动驾驶汽车开发商等开始与 Cosmos 协作，加速模型开发进程。开发者可在 NVIDIA API 目录预览相关模型，并从 NGC 目录和 Hugging Face 下载模型系列与微调框架。&lt;/p&gt; 
&lt;p&gt;https://docs.nvidia.com/cosmos/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365780</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365780</guid>
      <pubDate>Tue, 12 Aug 2025 09:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Altman：计划在未来 5 个月内将算力集群扩容一倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;OpenAI CEO 萨姆・奥尔特曼（SamAltman）在社交平台发文上表示，鉴于 GPT-5 带来的需求激增，该公司计划在未来几个月的算力优先分配如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;首先确保当前付费版 ChatGPT 用户的总可用量比 GPT-5 推出前更多。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;其次优先满足 API 需求，直至达到当前分配的产能和已对客户做出的承诺。（粗略估计，以现有产能可在当前基础上再支持约 30% 的新 API 增长。）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;提升 ChatGPT 免费版的服务质量。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;再优先满足新的 API 需求。计划在未来 5 个月内将算力集群扩容一倍，因此这一情况有望改善。&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="450" src="https://oscimg.oschina.net/oscnet/up-546ae50cc300f2af8894d1b266b905551e4.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365777</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365777</guid>
      <pubDate>Tue, 12 Aug 2025 09:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 发布面向 GPT-5 的 Prompt 指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 官方写的 GPT-5 prompt 指南来了，看看官方是怎么让 GPT-5 表现更好的。该指南融汇贯通后，还可用于其他 AI 大模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/172857_F753_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1、 明确角色和目标 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;开头就让 AI 模型知道它是谁、要做什么，比如：&lt;/p&gt; 
&lt;p&gt;你是资深前端工程师，请帮我在现有 React 项目里实现...&lt;/p&gt; 
&lt;p&gt;2、 设定工作方式 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;用分步指令，让模型按既定节奏走，而非一次性输出：&lt;/p&gt; 
&lt;p&gt;- 先分析需求和不确定点&lt;br&gt; - 再给执行计划 &amp;nbsp; &amp;nbsp;&lt;br&gt; - 按计划分步完成&lt;br&gt; - 每步结束时总结进度&lt;/p&gt; 
&lt;p&gt;3、 控制主动性 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;想要它多动脑，就加：在不确定时自行推断并执行，完成后再告知用户。 &amp;nbsp;&lt;br&gt; 想让它少跑偏，就加：仅按已知信息执行，不额外探索。&lt;/p&gt; 
&lt;p&gt;4、 给出完成标准 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;告诉模型何时算任务完成，比如： &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;当所有代码改动已在/app/theme 目录生效，并通过现有测试时，结束任务。&lt;/p&gt; 
&lt;p&gt;5、 嵌入风格与规范 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在提示里放工程或写作规范，让它自动匹配你的需求： &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;变量用驼峰命名，CSS 类名用 BEM 规范，注释保持英文简短描述。&lt;/p&gt; 
&lt;p&gt;6、 善用示例 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;给它 1-2 个高质量示例，让它照着学，比空口说效果好得多。&lt;/p&gt; 
&lt;p&gt;7、 善用「工具前言」&lt;/p&gt; 
&lt;p&gt;工具前言可以写：先复述目标，再列计划，执行时简短说明当前步骤，最后单独总结成果。&lt;/p&gt; 
&lt;p&gt;8、 清除歧义 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;检查提示里是否有前后矛盾或模糊指令，否则 GPT-5 会花大量精力试图自圆其说，反而降低效率。&lt;/p&gt; 
&lt;p&gt;记住一个公式：角色+目标+步骤+完成标准+风格+示例，如此 GPT-5 才会既有创造力又不跑偏。&lt;/p&gt; 
&lt;p&gt;这本指南还涵盖了 API 参数具体怎么调，感兴趣的开发者可以看看。&lt;/p&gt; 
&lt;p&gt;地址：cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365773/openai-gpt-5-prompting-guide</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365773/openai-gpt-5-prompting-guide</guid>
      <pubDate>Tue, 12 Aug 2025 09:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动推出视频字幕无痕擦除方案，基于 DiT 大模型打造</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;字节跳动技术团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKsl_lF8KNwM0vRtsjzWaBA" target="_blank"&gt;宣布&lt;/a&gt;推出一项创新技术，基于 DiT 大模型与字体级分割的视频字幕无痕擦除方案，旨在助力短剧等视频内容的全球化传播。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在全球化内容制作中，原始视频的中文字幕对于海外观众而言不仅是无效信息，还严重影响观看体验。传统的字幕添加或马赛克、GAN（生成对抗网络）等字幕擦除方案，往往导致画面杂乱、模糊或帧间闪烁，无法彻底解决这一问题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;火山引擎视频点播推出的这一方案，通过两大核心技术突破和强大的工程能力，重新定义了字幕擦除标准，实现了全片真实自然的「无痕擦除」，并支持多字幕框、指定时间段的精准擦除。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e6a7ee75485165b360e216e57f4f3f2e85f.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该方案的核心在于两个技术突破：一是 DiT 视频字幕擦除模型，二是字体级分割模型。DiT 模型通过强鲁棒性预训练基底、摆脱辅助先验依赖、两阶段训练策略提升鲁棒性与修复精细度，实现了像素级无痕修复。字体级分割模型则通过精准定位目标区域，实现了从「粗放擦除」到「像素级修复」的转变，有效避免了传统块填充导致的背景模糊或纹理重复问题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="143" src="https://oscimg.oschina.net/oscnet/up-dc217440e603a0e87eec97675dbaaf606fc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;火山引擎多媒体实验室联合工程团队构建了兼顾精度与效率的技术体系，经过超万集视频数据集验证，擦除任务成功率达到 100%。创新的视频分镜技术结合服务器集群分布式计算，显著提升了视频处理效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，该方案还支持多语言内容流转，突破了中英文限制，支持多个小语种字幕擦除，为全球内容流转提供了双向通道。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365771</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365771</guid>
      <pubDate>Tue, 12 Aug 2025 09:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌向发现 Chrome 高危漏洞的安全研究员奖励 25 万美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;谷歌近日依据漏洞奖励计划（VRP）向一名安全研究员&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.chromium.org%2Fissues%2F412578726" target="_blank"&gt;发放 25 万美元（约合 179.8 万元人民币）奖金&lt;/a&gt;，奖励其发现 Chrome 浏览器高危漏洞。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/170559_YQ7o_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;该研究员于 4 月 23 日报告了一个「沙盒逃逸」漏洞，编号为 CVE-2025-4609，存在于 Chrome 内核的 IPCZ 通信系统中。攻击者可通过诱导用户访问恶意网站，利用该漏洞突破浏览器沙箱限制，实现远程代码执行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;尽管研究员最初将其标记为「中等危害」，但谷歌评估其严重性为 S0/S1 级，并列为 P1 优先级修复。 谷歌已于 5 月发布的 Chrome 更新中修复该漏洞，并在 8 月 12 日公开披露细节。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;根据谷歌「漏洞猎人（&lt;/span&gt;Google Bug Hunters&lt;span&gt;）」计划，提交包含 RCE 演示的高质量非沙盒进程逃逸或内存损坏漏洞报告，可获 2.5 万至 25 万美元奖励，此次为顶格奖励。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365764</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365764</guid>
      <pubDate>Tue, 12 Aug 2025 09:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Actual - 个人理财工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Actual 是一款本地优先的个人理财工具。它 100% 免费开源，使用 NodeJS 编写，并具备同步功能，方便用户在不同设备之间轻松迁移更改。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="271" src="https://static.oschina.net/uploads/space/2025/0806/154746_TajJ_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/actual</link>
      <guid isPermaLink="false">https://www.oschina.net/p/actual</guid>
      <pubDate>Tue, 12 Aug 2025 08:53:00 GMT</pubDate>
    </item>
    <item>
      <title>360 智脑推出 Light-IF 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;360 智脑团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FnwyQDZxYGFFA5pTmkxn3JQ" target="_blank"&gt;宣布&lt;/a&gt;推出全新的 Light-IF 系列模型，这一创新框架旨在显著提升大型语言模型（LLM）在复杂指令遵循方面的能力。随着人工智能技术的不断进步，尽管 LLM 在数学、编程等领域已经展现出了卓越的推理能力，但在遵循复杂指令方面仍存在不足。为了解决这一问题，360 智脑团队提出了以预览-自检式推理和信息熵控制为核心的 Light-IF 框架。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Light-IF 框架通过五个关键环节来提升模型性能:难度感知指令生成、Zero-RL 强化学习、推理模式提取与过滤、熵保持监督冷启动、熵自适应正则强化学习。这一框架的提出，旨在破解当前推理模型中存在的「懒惰推理」现象，即模型在思考阶段仅复述指令而不主动检查约束是否被满足，导致指令执行不准确的问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="316" src="https://oscimg.oschina.net/oscnet/up-30ae24d430fc7fd7a393ecaf7c48fbadefc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在实验中，Light-IF 系列模型在 SuperCLUE、IFEval、CFBench 及 IFBench 四个中文和跨语言指令遵循基准上均取得了显著提升。特别是 32B 版本的 Light-IF-32B，其在 SuperClue 得分达到了 0.575，比下一个最佳模型高出 13.9 个百分点。此外，参数规模仅为 1.7B 的 Light-IF-1.7B 在 SuperClue 和 IFEval 上的表现甚至超过了 Qwen3-235B-A22B 等体量更大的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;360 智脑团队表示，Light-IF 系列模型的推出，不仅为开源社区提供了一套可复现的完整路线和配套的开源代码，而且全系模型将陆续开放，供社区使用、对比与复现。同时，训练中使用的冷启动数据集也将同步开放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，360 与 SuperCLUE 联合推出的中文精确指令遵循测评基准 SuperCLUE-CPIFOpen 也将在 Github 上开放，便于研究者评测模型的中文精确指令遵循能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365748</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365748</guid>
      <pubDate>Tue, 12 Aug 2025 08:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 发布全球首个可交易 Agent Remix Marketplace</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;MiniMax 稀宇科技宣布推出全球首个 Agent Remix Marketplace，并启动了一项奖金高达 15 万美金的全球挑战赛。这一创新平台旨在将个人的想法转化为商业价值，让每个人都能成为「个体 GDP 创造者」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agent Remix Marketplace 是一个允许用户一键提效的工具，用户可以通过点击「Remix」对已发布的成熟作品进行再创作，无需从零开始，从而将效率提升 10 倍。此外，用户还可以通过发布自己的 Agent 作品至 Gallery 并允许他人 Remix，每次作品被 Remix 都能获得 100 积分的收益。这不仅是一个创作和分享的平台，也是一个涨粉和建立个人品牌的利器。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-d064cf16f7166c2be8c20d9ed0ee1bc940e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;MiniMax 强调，这一平台是「Agent 全民经济」的颠覆性突破，具有四大独家优势。用户可以轻松地 Remix 各种模板，如香氛蜡烛电商模板，快速开启自己的电商创业。此外，用户还可以定制任何行业或主题的 Daily Newsletter，甚至将 Netflix 和 Bilibili、LinkedIn 和 Tinder 等不同平台的功能进行 Remix，创造出全新的用户体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技术层面，MiniMax 在研发过程中注重 Agent 的可靠性，包括上下文压缩总结、API 信息脱敏引擎以及多 Agent 任务路由等技术，以确保用户数据的安全和隐私。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;全球挑战赛面向所有人开放，鼓励参与者用自己的想法挑战 15 万美金的奖池。挑战赛分为原创和 Remix 双赛道，无论是原创作品还是基于已发布作品的二创，都有机会获奖。参与者无需代码能力，即可参与这一全球智能普惠的活动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;体验地址：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fminimax-agent-hackathon.space.minimax.io%2F" target="_blank"&gt;https://minimax-agent-hackathon.space.minimax.io/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365744</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365744</guid>
      <pubDate>Tue, 12 Aug 2025 08:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>华为发布 AI 推理创新技术 UCM：可实现高吞吐、低时延推理体验，计划 9 月开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1840229710674780713%26wfr%3Dspider%26for%3Dpc" target="_blank"&gt;根据报道&lt;/a&gt;，华为正式发布了 AI 推理创新技术 UCM（推理记忆数据管理器）。&lt;/p&gt; 
&lt;p&gt;华为推出的 UCM（推理记忆数据管理器）是一款以 KV Cache 为中心的推理加速套件，融合多类型缓存加速算法工具，通过分级管理推理过程中产生的 KV Cache 记忆数据，扩大推理上下文窗口，实现高吞吐、低时延的推理体验，，降低每 Token 推理成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0812/160552_0ocB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，华为计划于 2025 年 9 月正式开源 UCM，届时将在魔擎社区首发，后续逐步贡献给业界主流推理引擎社区，并共享给业内所有 Share Everything (共享架构) 存储厂商和生态伙伴。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365742</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365742</guid>
      <pubDate>Tue, 12 Aug 2025 08:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Claude 新增聊天记录记忆功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 为其 Claude 聊天机器人推出备受期待的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fclaudeai%2Fstatus%2F1954982275453686216" target="_blank"&gt;「记忆」功能&lt;/a&gt;，用户可让机器人检索并参考过往对话内容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/155847_bdCE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该功能支持网页、桌面及移动端，能区分不同项目和工作区。用户只需在 「个人资料」 的 「设置」 中开启 「搜索和查看聊天记录」，即可使用。&lt;/p&gt; 
&lt;p&gt;目前，Claude 的 Max、Team 和 Enterprise 订阅层级已率先上线，其他套餐将在近期开放。与 ChatGPT 的持续记忆不同，Claude 的记忆功能为被动触发模式，仅在用户明确要求时才检索过往对话，且不会构建用户画像。&lt;/p&gt; 
&lt;p&gt;作为 AI 领域的头部企业，Anthropic 与 OpenAI 竞争激烈，双方在语音模式、上下文窗口、订阅服务等方面不断角力。此次记忆功能的推出，旨在提升用户黏性和使用时长。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365741</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365741</guid>
      <pubDate>Tue, 12 Aug 2025 07:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软为 Excel 加入 AI 公式讲解，内联解释直达单元格</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;微软&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcommunity.microsoft.com%2Fblog%2Fexcelblog%2Fexplain-formulas-with-copilot%25E2%2580%2594now-on-the-grid%2F4424028" target="_blank"&gt;宣布&lt;/a&gt;，其电子表格工具 Excel 迎来一项重要更新：由 Copilot 驱动的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;「解释此公式」（Explain Formula）&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;功能正式上线，旨在帮助用户快速理解复杂公式，显著提升数据处理效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该功能的&lt;span&gt;最大&lt;/span&gt;亮点在于操作简便。用户无需单独打开聊天面板，只需点击包含有效公式的单元格，并在旁边的 Copilot 图标中选择「解释此公式」，即可在单元格内直接获得内联解释。这些解释基于当前工作表的上下文生成，比传统网络搜索更精准、更贴合实际工作场景。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="225" src="https://oscimg.oschina.net/oscnet/up-68c25bd98edf5ade9b15bb52dea74ff751f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微软表示，Copilot 能够分解并逐步讲解各种复杂程度的公式，帮助用户快速掌握其逻辑。默认情况下，解释会以内联形式显示;若 Copilot 聊天面板已开启，内容将优先在面板中呈现。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，该功能正分阶段向 Windows 版和网页版 Excel 用户推送。微软鼓励用户在每次使用后通过点赞或点踩反馈，协助优化 AI 解释效果。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365740</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365740</guid>
      <pubDate>Tue, 12 Aug 2025 07:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「字节跳动静态资源公共库」因黑产原因下线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;从 2025 年 6 月份开始，就有诸多站长发现字节跳动旗下的静态资源公共库存在调用问题，包括部分资源连接超时或者直接 HTTP 404，这导致网站无法正常加载内容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;当时测试发现诸如 jQuery 等还可以调用，其他部分资源出现错误无法调用，因此并不清楚字节跳动哪里出问题才会导致部分资源有效、部分资源无效。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/154152_ycjH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://cdn.bytedance.com/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;现在字节跳动已经明确静态资源公共库下线，当前所有静态资源已经全部处于 404 状态，字节跳动称是「黑产原因」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365736</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365736</guid>
      <pubDate>Tue, 12 Aug 2025 07:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 亮相首届世界 RISC-V 日，分享最新 RISC-V 进展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 8 日，由 RISC-V 国际基金会重磅推出的首届世界 RISC-V 日 (World RISC-V Days) 在北京开源芯片研究院举行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//3f4075ef6e79ddf2ab5c098c63d555b7.jpg" width="840" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;deepin 社区技术委员会成员、苦芽科技工程师李程&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;参加了此活动，并于会议上带大家系统回顾了 deepin-ports SIG 的发展历程，并重点分享了 deepin-ports SIG 在 RISC-V 方向上的最新进展，包括但不限于 deepin RISC-V 生态适配、社区协作模式优化等方面。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//10b8829d40f7888c675d6790b227fb75.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&lt;span&gt;&lt;span&gt;李程，deepin 社区技术委员会成员、苦芽科技工程师&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;deepin 对 RISC-V 架构的支持并非一日之功。自 2022 年 2 月起，deepin 就建立了对应 SIG，开始了 RISC-V 架构的适配工作，现已成功支持了大量主流的 RISC-V 硬件和开发板。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在软件方面，deepin 也完成了对 RISC-V 开源软件生态的适配，提供了超过 27,000 个软件包，并为 RISC-V 开发板提供了内核、GPU、VPU、NPU 等驱动解决方案，确保了这些关键组件能够长期、及时、良好地维护。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//92d10ca4ef881324c89df1a23d1a392e.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;作为中国桌面操作系统的核心力量，deepin 积极响应国家战略，深度参与「甲辰计划」，全力投入 RISC-V 开源新生态建设。迄今，deepin 操作系统已成功适配了几乎所有可公开获取的桌面级 RISC-V 设备，并提供了关键的 GPU、NPU、VPU 等硬件加速支持。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 23&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 稳定版及 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 25 预览版&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;均已为 RISC-V 平台提供官方镜像并持续更新。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;通过在硬件适配、软件生态构建、社区协作及战略规划上的不懈努力，deepin 已成为 RISC-V 生态的重要贡献者，并有力推动着 RISC-V 桌面操作系统的普及与应用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//7215a0a6d6d54c51ac5e45faa8fd4f4a.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;李程还介绍到，deepin 作为「甲辰计划」的重要参与社区之一，为给更多同学提供深入 deepin、RISC-V 等技术项目的机会，将与甲辰计划联合提供近 80 个实习 HC。李程先生将作为该实习岗位的首席导师（Principle Mentor），协调实习工作内容，并负责 mentor 的招募和岗前培训。进一步了解：&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA5NzE0Mjg4Ng%3D%3D%26mid%3D2650457142%26idx%3D2%26sn%3D4b83559f9c00f28f1df379af82b1ab5a%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;&lt;span&gt;新增实习机会！RISC-V deepin 操作系统开发实习生正在招募&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;由于时间限制未设置现场问答环节，但与会者还是对技术路线和实习计划展现出了浓厚兴趣，众多参会者主动拍摄 PPT 关键内容页，期待进一步交流探讨。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//cd1393b25b25a0f66f8bf6cc4337cb36.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;附：&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;deepin-ports SIG 主页：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://github.com/deepin-community/sig-deepin-ports&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365735</guid>
      <pubDate>Tue, 12 Aug 2025 07:39:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>马斯克：xAI 将对苹果采取法律行动</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;埃隆·马斯克当地时间 8 月 11 日在社交平台发文称，苹果公司涉嫌通过限制措施，使除美国开放人工智能研究中心（OpenAI）外的任何人工智能公司都无法在其应用商店排行榜中登顶，称此为「明确的反垄断违规行为」。马斯克表示，其旗下 xAI 公司将立即采取法律行动。&lt;/p&gt; 
&lt;p&gt;&lt;img height="272" src="https://oscimg.oschina.net/oscnet/up-77b6ba53d5b9d23dcb776934627a6b8c4cb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管马斯克的指控引发了广泛关注，但他并未提供具体证据来支持自己的说法。截至 8 月 12 日，ChatGPT 正占据美国 App Store 的榜首位置。值得一提的是，OpenAI 和苹果去年宣布了一项合作关系，将 ChatGPT 集成到苹果的智能系统中，以增强图像和文档理解等多项功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在马斯克的指控后，OpenAI 首席执行官山姆・奥特曼也在社交平台上做出了回应。他表示，「这一指控非常引人注目，尤其是在我听到的关于马斯克如何操纵 X 以便让自己及其公司获益、并损害竞争对手及不喜欢的人的情况下。」 这一争论进一步加剧了马斯克与奥特曼之间本已紧张的关系，两人曾经在 OpenAI 共事。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;奥特曼在文中提到我希望有人能进行反向取证，我们都想知道究竟发生了什么。不过，OpenAI 将继续专注于开发优秀的产品。」 与此同时，社交媒体上有许多人质疑马斯克的说法，指出除了 ChatGPT 外，许多其他人工智能应用程序 App Store 上也曾登上过榜首。例如，来自中国的 DeepSeek 应用一度成为榜首，而自称与 ChatGPT 竞争的 Perplexity 最近在印度的 App Store 中也取得了&lt;span&gt;第一&lt;/span&gt;的位置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365734</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365734</guid>
      <pubDate>Tue, 12 Aug 2025 07:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Rust 性能提升 「最后一公里」：详解 Profiling 瓶颈定位与优化</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、Profiling：揭示性能瓶颈的"照妖镜"&lt;/h1&gt; 
&lt;p&gt;在过去的一年里，我们团队完成了一项壮举：将近万核的 Java 服务成功迁移到 Rust，并收获了令人瞩目的性能提升。我们的实践经验已在《RUST 练习生如何在生产环境构建万亿流量》一文中与大家分享。然而，在这次大规模迁移中，我们观察到一个有趣的现象：大多数服务在迁移后性能都得到了显著提升，但有那么一小部分服务，性能提升却不尽如人意，仅仅在 10% 左右徘徊。&lt;/p&gt; 
&lt;p&gt;这让我们感到疑惑。明明已经用上了性能"王者"Rust，为什么还会遇到瓶颈？为了解开这个谜团，我们决定深入剖析这些"低提升"服务。今天，我就来和大家分享，我们是如何利用 &lt;strong&gt;Profiling&lt;/strong&gt; &lt;strong&gt;工具&lt;/strong&gt;，找到并解决写入过程中的性能瓶颈，最终实现更高性能飞跃的！&lt;/p&gt; 
&lt;p&gt;在性能优化领域，盲目猜测是最大的禁忌。你需要一把锋利的"手术刀"，精准地找到问题的根源。在 Rust 生态中，虽然不像 Java 社区那样拥有 VisualVM 或 JProfiler 这类功能强大的成熟工具，但我们依然可以搭建一套高效的性能分析体系。&lt;/p&gt; 
&lt;p&gt;为了在生产环境中实现高效的性能监控，我们引入了 &lt;strong&gt;Jemalloc&lt;/strong&gt; 内存分配器和 &lt;strong&gt;pprof&lt;/strong&gt; CPU 分析器。这套方案不仅支持定时自动生成 Profile 文件，还可以在运行时动态触发，极大地提升了我们定位问题的能力。&lt;/p&gt; 
&lt;h1&gt;二、配置项目：让 Profiling"武装到牙齿"&lt;/h1&gt; 
&lt;p&gt;首先，我们需要在 Cargo.toml 文件中添加必要的依赖，让我们的 Rust 服务具备 Profiling 的能力。以下是我们的配置，Rust 版本为 1.87.0。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[target.'cfg(all(not(target_env = "msvc"), not(target_os = "windows")))'.dependencies]
# 使用 tikv-jemallocator 作为内存分配器，并启用性能分析功能
tikv-jemallocator = { version = "0.6", features = ["profiling", "unprefixed_malloc_on_supported_platforms"] }
# 用于在运行时控制和获取 jemalloc 的统计信息
tikv-jemalloc-ctl = { version = "0.6", features = ["use_std", "stats"] }
# tikv-jemallocator 的底层绑定，同样启用性能分析
tikv-jemalloc-sys = { version = "0.6", features = ["profiling"] }
# 用于生成与 pprof 兼容的内存剖析数据，并支持符号化和火焰图
jemalloc_pprof = { version = "0.7", features = ["symbolize","flamegraph"] }
# 用于生成 CPU 性能剖析数据和火焰图
pprof = { version = "0.14", features = ["flamegraph", "protobuf-codec"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;简单来说，这几个依赖各司其职：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ tikv-jemallocator&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于 jemalloc 的 Rust 实现，以其高效的内存管理闻名。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ jemalloc_pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;负责将 jemalloc 的内存剖析数据转换成标准的 pprof 格式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用于 CPU 性能分析，可以生成 pprof 格式的 Profile 文件。&lt;/p&gt; 
&lt;h1&gt;三、 全局配置：启动 Profiling 开关&lt;/h1&gt; 
&lt;p&gt;接下来，在 main.rs 中进行全局配置，指定 &lt;strong&gt;Jemalloc&lt;/strong&gt; 的 &lt;strong&gt;Profiling&lt;/strong&gt; 参数，并将其设置为默认的全局内存分配器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 配置 Jemalloc 内存分析参数
#[export_name = "malloc_conf"]
pub static malloc_conf: &amp;amp;[u8] = b"prof:true,prof_active:true,lg_prof_sample:16\0";


#[cfg(not(target_env = "msvc"))]
use tikv_jemallocator::Jemalloc;


// 将 Jemalloc 设置为全局内存分配器
#[cfg(not(target_env = "msvc"))]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这段配置中的 lg_prof_sample:16 是一个关键参数。&lt;/p&gt; 
&lt;p&gt;它表示 jemalloc 会对大约每 2^16 字节（即 64KB）的内存分配进行一次采样。这个值越大，采样频率越低，内存开销越小，但精度也越低；反之则精度越高，开销越大。在生产环境中，我们需要根据实际情况进行权衡。&lt;/p&gt; 
&lt;h1&gt;四、实现 Profile 生成函数：打造你的"数据采集器"&lt;/h1&gt; 
&lt;p&gt;我们将 Profile 文件的生成逻辑封装成异步函数，这样就可以在服务的任意时刻按需调用，非常灵活。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;内存 Profile 生成函数&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_memory_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    // 获取 jemalloc 的 profiling 控制器
    let prof_ctl = jemalloc_pprof::PROF_CTL.as_ref()
        .ok_or_else(|| "Profiling controller not available".to_string())?;


    let mut prof_ctl = prof_ctl.lock().await;
    
    // 检查 profiling 是否已激活
    if !prof_ctl.activated() {
        return Err("Jemalloc profiling is not activated".to_string());
    }
   
    // 调用 dump_pprof() 方法生成 pprof 数据
    let pprof_data = prof_ctl.dump_pprof()
        .map_err(|e| format!("Failed to dump pprof: {}", e))?;


    // 使用时间戳生成唯一文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("memory_profile_{}.pb", timestamp);


    // 将 pprof 数据写入本地文件
    std::fs::write(&amp;amp;filename, pprof_data)
        .map_err(|e| format!("Failed to write profile file: {}", e))?;


    info!("Memory profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU Profile 生成函数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;类似地，我们使用 pprof 库来实现 CPU &lt;strong&gt;Profile&lt;/strong&gt; 的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_cpu_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    use pprof::ProfilerGuard;
    use pprof::protos::Message;


    info!("Starting CPU profiling for 60 seconds...");


    // 创建 CPU profiler，设置采样频率为 100 Hz
    let guard = ProfilerGuard::new(100).map_err(|e| format!("Failed to create profiler: {}", e))?;


    // 持续采样 60 秒
    tokio::time::sleep(std::time::Duration::from_secs(60)).await;


    // 生成报告
    let report = guard.report().build().map_err(|e| format!("Failed to build report: {}", e))?;


    // 使用时间戳生成文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("cpu_profile_{}.pb", timestamp);


    // 创建文件并写入 pprof 数据
    let mut file = std::fs::File::create(&amp;amp;filename)
        .map_err(|e| format!("Failed to create file: {}", e))?;


    report.pprof()
        .map_err(|e| format!("Failed to convert to pprof: {}", e))?
        .write_to_writer(&amp;amp;mut file)
        .map_err(|e| format!("Failed to write profile: {}", e))?;


    info!("CPU profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;ProfilerGuard::new() 100 Hz 意味着每秒钟会随机中断程序 &lt;strong&gt;100 次&lt;/strong&gt;，以记录当前正在执行的函数调用栈&lt;/li&gt; 
 &lt;li&gt;tokio::time::sleep(std::time::Duration::from_secs(60)).await 表示 pprof 将会持续采样 60 秒钟&lt;/li&gt; 
 &lt;li&gt;guard.report().build() 这个方法用于将收集到的所有采样数据进行处理和聚合，最终生成一个 Report 对象。这个 Report 对象包含了所有调用栈的统计信息，但还没有转换成特定的文件格式&lt;/li&gt; 
 &lt;li&gt;report.pprof() 这是 Report 对象的一个方法，用于将报告数据转换成 pprof 格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;五、 触发和使用 Profiling：随时随地捕捉性能数据&lt;/h1&gt; 
&lt;p&gt;有了上述函数，我们实现了两种灵活的触发方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 定时自动生成&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过异步定时任务，每隔一段时间自动调用 dump_memory_profile() 和 dump_cpu_profile() 。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn start_profilers() {
    // Memory profiler
    tokio::spawn(async {
        let mut interval = tokio::time::interval(std::time::Duration::from_secs(300));
        loop {
            interval.tick().await;
            #[cfg(not(target_env = "msvc"))]
            {
                info!("Starting memory profiler...");
                match dump_memory_profile().await {
                    Ok(profile_path) =&amp;gt; info!("Memory profile dumped successfully: {}", profile_path),
                    Err(e) =&amp;gt; info!("Failed to dump memory profile: {}", e),
                }
            }
        }
    });
    // 同理可以实现 CPU profiler
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 手动 HTTP 触发&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过提供 /profile/memory 和 /profile/cpu 两个 HTTP 接口，可以随时按需触发 Profile 文件的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;async fn trigger_memory_profile() -&amp;gt; Result&amp;lt;impl warp::Reply, std::convert::Infallible&amp;gt; {
    #[cfg(not(target_env = "msvc"))]
    {
        info!("HTTP triggered memory profile dump...");
        match dump_memory_profile().await {
            Ok(profile_path) =&amp;gt; Ok(warp::reply::with_status(
                format!("Memory profile dumped successfully: {}", profile_path),
                warp::http::StatusCode::OK,
            )),
            Err(e) =&amp;gt; Ok(warp::reply::with_status(
                format!("Failed to dump memory profile: {}", e),
                warp::http::StatusCode::INTERNAL_SERVER_ERROR,
            )),
        }
    }
}
//同理也可实现 trigger_cpu_profile() 函数

fn profile_routes() -&amp;gt; impl Filter&amp;lt;Extract = impl Reply, Error = warp::Rejection&amp;gt; + Clone {
    let memory_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("memory"))
        .and(warp::path::end())
        .and_then(trigger_memory_profile);
    
    
    let cpu_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("cpu"))
        .and(warp::path::end())
        .and_then(trigger_cpu_profile);
    memory_profile.or(cpu_profile)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;现在，我们就可以通过 curl 命令，随时在生产环境中采集性能数据了：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:8080/profile/memory
curl -X POST http://localhost:8080/profile/cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;生成的 .pb 文件，我们就可以通过 go tool pprof 工具，启动一个交互式 Web UI，在浏览器中直观查看调用图、火焰图等。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go tool pprof -http=localhost:8080 ./target/debug/otel-storage ./otel_storage_cpu_profile_20250806_032509.pb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;六、性能剖析：火焰图下的"真相"&lt;/h1&gt; 
&lt;p&gt;通过 go tool pprof 启动的 Web UI，我们可以看到程序的&lt;strong&gt;火焰图&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何阅读火焰图&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 顶部：&lt;/strong&gt; 代表程序的根函数。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 向下延伸；&lt;/strong&gt; 子函数调用关系。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 火焰条的宽度：&lt;/strong&gt; 代表该函数在 CPU 上消耗的时间。&lt;strong&gt;宽度越宽，消耗的时间越多，越可能存在性能瓶颈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8b814e239f61ed1c970231bc444f3896a50.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU Profile&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-55883adfb3cf12d5390b652452d3f883d17.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Memory Profile&lt;/p&gt; 
&lt;p&gt;在我们的 CPU 火焰图中，一个令人意外的瓶颈浮出水面：&lt;strong&gt;OSS::new&lt;/strong&gt; 占用了约 19.1% 的 CPU 时间。深入分析后发现， OSS::new 内部的 TlsConnector 在每次新建连接时都会进行 TLS 握手，这是导致 CPU 占用过高的根本原因。&lt;/p&gt; 
&lt;p&gt;原来，我们的代码在每次写入 OSS 时，都会新建一个 OSS 实例，随之而来的是一个全新的 HTTP 客户端和一次耗时的 TLS 握手。尽管 oss-rust-sdk 内部有连接池机制，但由于我们每次都创建了新实例，这个连接池根本无法发挥作用！&lt;/p&gt; 
&lt;h1&gt;七、优化方案：从"每次新建"到"共享复用"&lt;/h1&gt; 
&lt;p&gt;问题的核心在于重复创建 OSS 实例。我们的优化思路非常清晰：&lt;strong&gt;复用 OSS 客户端实例，避免不必要的 TLS 握手开销&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每次写入都新建 OSS 客户端。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn write_oss() {
    // 每次写入都新建一个 OSS 实例
    let oss_instance = create_oss_client(oss_config.clone());
    tokio::spawn(async move {
        // 获取写入偏移量、文件名
        // 构造 OSS 写入所需资源和头信息
        // 写入 OSS
        let result = oss_instance
            .append_object(data, file_name, headers, resources)
            .await;
}
fn create_oss_client(config: OssWriteConfig) -&amp;gt; OSS {
    OSS::new(
    ......
    )
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这种方案在流量较小时可能问题不大，但在万亿流量的生产环境中，频繁的实例创建会造成巨大的性能浪费。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 共享实例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;让每个处理任务（ DecodeTask ）持有 Arc 共享智能指针，确保所有写入操作都使用同一个 OSS 实例。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;let oss_client = Arc::new(create_oss_client(oss_config.clone()));
let oss_instance = self.oss_client.clone(); 
// ...
let result = oss_instance
    .append_object(data, file_name, headers, resources)
    .await;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 自动重建机制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了应对连接失效或网络问题，我们引入了自动重建机制。当写入次数达到阈值或发生写入失败时，我们会自动创建一个新的 OSS 实例来替换旧实例，从而保证服务的健壮性。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 使用原子操作确保多线程环境下的计数安全
let write_count = self.oss_write_count.load(std::sync::atomic::Ordering::SeqCst);
let failure_count = self.oss_failure_count.load(std::sync::atomic::Ordering::SeqCst);


// 检查是否需要重建实例...
fn recreate_oss_client(&amp;amp;mut self) {
 
    let new_oss_client = Arc::new(create_oss_client(self.oss_config.clone()));
    self.oss_client = new_oss_client;
    self.oss_write_count.store(0, std::sync::atomic::Ordering::SeqCst);
    self.oss_failure_count.store(0, std::sync::atomic::Ordering::SeqCst);
    // 记录 OSS 客户端重建次数指标
    OSS_CLIENT_RECREATE_COUNT
        .with_label_values(&amp;amp;[])
        .inc();
    info!("OSS client recreated");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;八、优化效果：性能数据"一飞冲天"&lt;/h1&gt; 
&lt;p&gt;优化后的服务上线后，我们观察到了显著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU 资源使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降约 &lt;strong&gt;20%&lt;/strong&gt; 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-68b2935d6632ee730c0dc6ac3155a4257a4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OSS 写入耗时&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降约 &lt;strong&gt;17.2%&lt;/strong&gt; ，成为集群中最短的写入耗时。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 写入耗时&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-18a1b33fff58596e3d4317f4035511a8eca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 相关资源只占千分之一&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f35812df10896bc3430f0020571b4ab2e03.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;内存使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;平均下降 &lt;strong&gt;8.77%&lt;/strong&gt; ，这部分下降可能也得益于我们将内存分配器从 &lt;strong&gt;mimalloc&lt;/strong&gt; 替换为 &lt;strong&gt;jemalloc&lt;/strong&gt; 的综合效果。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-863bda3bf8f46a11ceeffef27808d64c90d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这次优化不仅解决了特定服务的性能问题，更重要的是，它验证了在 Rust 中通过 Profiling 工具进行深度性能分析的可行性。即使在已经实现了初步性能提升的 Rust 服务中，仍然存在巨大的优化空间。&lt;/p&gt; 
&lt;p&gt;未来，我们将继续探索更高效的 Profiling 方案，并深入挖掘其他潜在的性能瓶颈，以在万亿流量的生产环境中实现极致的性能和资源利用率。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;引用&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub - tikv/jemallocator: Rust allocator using jemalloc as a backend&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrates.io%2Fcrates%2Fjemalloc_pprof" target="_blank"&gt;https://crates.io/crates/jemalloc_pprof&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub - google/pprof: pprof is a tool for visualization and analysis of profiling data&lt;/li&gt; 
 &lt;li&gt;Use Case: Heap Profiling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjemalloc.net%2Fjemalloc.3.html%23heap_profile_format" target="_blank"&gt;https://jemalloc.net/jemalloc.3.html#heap_profile_format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.brendangregg.com%2Fflamegraphs.html" target="_blank"&gt;https://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmagiroux.com%2Frust-jemalloc-profiling" target="_blank"&gt;https://magiroux.com/rust-jemalloc-profiling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.Valkey 单点性能比肩 Redis 集群了？Valkey8.0 新特性分析｜得物技术&lt;/p&gt; 
&lt;p&gt;2.Java volatile 关键字到底是什么｜得物技术&lt;/p&gt; 
&lt;p&gt;3.社区搜索离线回溯系统设计：架构、挑战与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;4.正品库拍照 PWA 应用的实现与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;5.得物社区活动：组件化的演进与实践&lt;/p&gt; 
&lt;p&gt;文 / 炯帆，南风&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18687884</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18687884</guid>
      <pubDate>Tue, 12 Aug 2025 07:22:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Linux Turbostat 工具可显示 CPU L3 缓存拓扑信息</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 6.17 内核源代码树中 Turbostat 工具的更新已完成合并&lt;/p&gt; 
&lt;p&gt;Turbostat 是一款命令行工具，用于显示 CPU 频率/空闲/功耗统计信息以及其他相关的处理器信息，主要针对 Intel 和 AMD 处理器。值得注意的是，Linux 6.17 中的 Turbostat 增加了显示 L3 缓存拓扑信息的支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cf186a887af4b06f2d0a899e1a4af7834c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Turbostat 还新增了对新增计数器（例如累计瓦特和其他计数器）进行平均的功能，修复了对即将推出的英特尔至强 Diamond Rapids 处理器的支持。&lt;/p&gt; 
&lt;p&gt;由于部分型号特定寄存器 (MSR) 的变更，Turbostat 需要进行更多调整，以便正确显示 Granite Rapids 后续的下一代至强处理器的功耗和性能相关详细信息。&lt;/p&gt; 
&lt;p&gt;此外，Turbostat 还修复了针对 musl libc 的构建问题以及其他各种修复。更多详情，请访问&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAJvTdKmaTvaQiRjgz_Pr6a%2BXEkLzEnedujV%3Dvqwv5thEE63fdg%40mail.gmail.com%2F" target="_blank"&gt;此 pull request&lt;/a&gt;，该请求已合并至 Linux Git。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365725</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365725</guid>
      <pubDate>Tue, 12 Aug 2025 07:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
