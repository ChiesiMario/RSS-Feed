<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 02 Jul 2025 16:46:13 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>DeepEval —— 开源 LLM 评估框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;DeepEval&amp;nbsp;&lt;/strong&gt;是一个简单易用的开源 LLM 评估框架，用于评估和测试大型语言模型系统。它与 Pytest 类似，但专门用于对 LLM 输出进行单元测试。DeepEval 结合了最新研究成果，基于 G-Eval、幻觉、答案相关性、RAGAS 等指标来评估 LLM 输出，它使用 LLM 和其他各种在&lt;strong&gt;本地&lt;/strong&gt;运行的 NLP 模型进行评估。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;无论你的 LLM 应用程序是 RAG &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;pipelines&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;、聊天机器人、AI 代理，还是通过 LangChain 或 LlamaIndex 实现，DeepEval 都能满足你的需求。借助它，你可以轻松确定最佳模型、提示和架构，以改进你的 RAG 管道和代理工作流，防止 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;prompt drifting&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，甚至可以自信地从 OpenAI 过渡到托管你自己的 Deepseek R1。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&amp;nbsp;&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;以类似于 Pytest 的方式轻松地「单元测试」 LLM 输出。&lt;/li&gt;
&lt;li&gt;即插即用 30 多个 LLM 评估指标，其中大多数都有研究支持。&lt;/li&gt;
&lt;li&gt;支持端到端和组件级评估。&lt;/li&gt;
&lt;li&gt;对 RAG、代理、聊天机器人以及几乎任何用例的评估。&lt;/li&gt;
&lt;li&gt;使用最先进的进化技术生成合成数据集。&lt;/li&gt;
&lt;li&gt;指标易于定制并涵盖所有用例。&lt;/li&gt;
&lt;li&gt;红队，安全扫描 LLM 应用程序是否存在安全漏洞。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1c1e21"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，DeepEval 还有一个云平台&lt;a href="https://app.confident-ai.com/" target="_blank"&gt;Confident AI&lt;/a&gt;，允许团队使用 DeepEval 在云端进行&lt;strong&gt;评估、回归测试、红队和监控 LLM 应用程序。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="282" src="https://static.oschina.net/uploads/space/2025/0617/152602_UCxK_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepeval</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepeval</guid>
      <pubDate>Sat, 10 May 2025 10:44:00 GMT</pubDate>
    </item>
    <item>
      <title>设计协作平台 Figma 递交首次公开募股（IPO）申请</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Figma 昨日正式提交了首次公开募股（IPO）申请，计划在美国纽约证券交易所（NYSE）上市，股票代码为「FIG」。&lt;/p&gt; 
&lt;p&gt;Figma 成立于 2016 年，主要在网络上提供界面设计协作服务，同时也推出了 macOS / Windows 平台桌面客户端。该公司的产品线除了最早推出的设计工具 Figma Design 外，还包括在线协作白板 FigJam、演示文稿协作工具 Figma Slides、绘图工具 Figma Draw、设计自动化软件 Dev Mode、网站设计工具 Figma Sites，以及用于构建社交平台的 Figma Buzz 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0417/183511_QrFp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Figma 公司曾计划在 2022 年以 200 亿美元&lt;a href="https://www.oschina.net/news/210475/adobe-to-acquire-figma"&gt;出售给 Adobe&lt;/a&gt;，但由于欧盟和英国监管机构担心该交易会影响市场竞争，相应计划最终被叫停，迫使 Adobe 在当年底向 Figma 支付了 10 亿美元的解约费用。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bf6c1fe7a671d0abebcca4cc84a6f1c39da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;参考 Figma 提交的 S-1 申请文件，今年第一季度，公司拥有 1300 万月活跃用户（其中三分之二用户并非专业设计师），公司已获得了 95% 的《财富》500 强企业和 78% 的《福布斯》全球 2000 强企业的青睐。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;而在营收方面，Figma 在 2024 年实现了 7.49 亿美元（现汇率约合 53.65 亿元人民币）营收，同比增长 48%，但全年仍有 7.3 亿美元（现汇率约合 52.29 亿元人民币）亏损。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358402</guid>
      <pubDate>Sat, 10 May 2025 08:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯回应微信「Al 搜索」泄露个人隐私：仅整合公开信息，不会碰用户隐私</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，网友在社交平台吐槽被微信新推出的「AI 搜索」功能强行开盒。&lt;/p&gt; 
&lt;p&gt;该网友发现，当微信推文中出现本人姓名时，名字会变成蓝色超链接，点击人名即可一键浏览公众号 A1 强制生成的「个人简历」及所有涉及该姓名的推文。不少网友在尝试了该功能后表示「确实可以根据名字查到很多个人资料」，引发隐私安全方面的担忧。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ef93511d7c54a97e53e3f1cfb985f5f4df0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对此，腾讯方面今日回应媒体称，为了丰富用户搜索体验，微信搜索此前通过接入 DeepSeek 和混元等大模型推出 AI 搜索。AI 搜索仅整合公众号及互联网其他公开信息，不会使用用户隐私信息。根据用户近期的相关反馈，微信搜索将进一步优化 AI 搜索的使用体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358391</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358391</guid>
      <pubDate>Sat, 10 May 2025 08:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>TDMQ RabbitMQ Serverless 版限流机制深度解析与实践指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h2&gt;导语&lt;/h2&gt; 
&lt;p&gt;分布式集群限流是保障云服务高可用性的核心技术手段，其意义不仅在于防止系统过载，更是构建弹性架构、优化资源效率、实现业务可持续性的关键策略。未来，随着边缘计算和 Serverless 的普及，限流技术将进一步与底层基础设施深度融合，成为构建下一代高可用架构的核心基石。&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版作为一款极致弹性、高性能且高可靠的消息中间件，通过提供稳定低延迟的消息服务，助力企业实现系统异步解耦并高效应对海量消息堆积。然而，在高并发、大流量的实际业务中，如何科学分配资源、规避系统过载风险，已成为保障服务稳定性的关键。为此，腾讯云 TDMQ RabbitMQ Serverless 版引入了集群级别的分布式限流机制，通过动态调控集群的发送与消费速率，确保集群在高负载下仍能稳定运行。&lt;/p&gt; 
&lt;p&gt;本文将深度剖析腾讯云 TDMQ RabbitMQ Serverless 版的限流机制，涵盖限流策略设计、触发机制及底层实现逻辑。通过真实场景案例解析与实践指南，系统讲解如何通过客户端优化来降低限流影响，同时帮助客户精准掌握集群限流相关服务端配置技巧，有效规避因流控策略不当引发的业务中断风险，全面提升高并发场景下的系统稳定性与可靠性。&lt;/p&gt; 
&lt;h2&gt;概要设计&lt;/h2&gt; 
&lt;h3&gt;分布式限流的必要性&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;资源瓶颈的不可预测性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在分布式系统中，单节点流量可能因负载均衡策略（如 Round-Robin）不均导致倾斜。例如，某台服务器因硬件故障触发重试风暴，流量突增 300%，若无全局视角的限流，可能引发级联雪崩。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;长尾延迟的放大效应&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当某服务节点响应延迟升高（如磁盘刷写延迟增大），后续请求堆积导致线程池耗尽，触发上游重试，形成恶性循环。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;突发流量冲击&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;秒杀活动、热点新闻等场景下，流量可能在毫秒级陡增数十倍。例如，某电商平台大促期间，订单服务 QPS 从 5k 飙升至 80k，若未通过分布式限流拦截异常流量，核心计算资源将被瞬间打满，导致服务不可用。&lt;/p&gt; 
&lt;h3&gt;TDMQ RabbitMQ Serverless 版限流规则&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版为超大规模、低时延、高可用性要求的在线业务提供专业级消息服务。客户端通过 RabbitMQ SDK 与 TDMQ RabbitMQ Serverless 版集群建立长连接，实现高效的消息收发操作，同时动态占用集群的计算、存储及网络带宽等关键资源。在此背景下，为确保消息服务的高性能与稳定性，在应对高并发、大流量场景时，必须对集群的负载水位进行精细化管理。 基于集群的资源配置上限，服务端支持动态调控客户端的每秒消息发送与消费能力（TPS），确保系统在高负载下依然保持稳定运行。&lt;/p&gt; 
&lt;p&gt;为实现资源隔离与灵活适配的双重目标，系统对发送消息与消费消息的 TPS 配额进行独立分配，并支持用户按需配置配额比例，从而实现精细化资源管理与业务场景的精准匹配（默认配额比例为 1 : 1 也即 50%）。业务可以根据实际的收发比例进行调整，可调整的收发消息比例范围在 20%-80%（服务端支持动态调整该区间）之间。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-7e99eeeb65ba2619e29a1109b273abf1cd8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TDMQ RabbitMQ Serverless 版限流行为&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版采用 Fail-Fast 限流机制，即当客户端请求速率触及预设上限时，服务端会即时返回错误响应。在响应时间敏感的在线业务场景中，该机制可使客户端实时感知限流事件并主动介入处理，从而有效避免因资源竞争导致的端到端时延长尾，保障业务连续性与系统稳定性。&lt;/p&gt; 
&lt;p&gt;以 1000TPS 规格的基础集群为例（假设收发 TPS 比例为 1:1 也即 50%），客户端视角下的限流行为：&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;说明&lt;/strong&gt; | &lt;strong&gt;发送消息限流&lt;/strong&gt; | &lt;strong&gt;消费消息限流&lt;/strong&gt; | | ------------ | ------------ | ------------ | | 触发限流情景 | 所有连接该集群的发送客户端每秒最多可发送 TPS 总和为 500 条，发送速率达到限制后，超限的发送请求会失败。 | 所有连接该集群的消费客户端每秒最多可消费 TPS 总和为 500 条，消费速率达到限制后，消息的消费延迟会增加。 | | 触发限流时 SDK 日志关键词 | com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:xxx reason:PublishMessage, class-id=60, method-id=40) | 消费超过阈值以后，客户端使用 BasicGet 拉取消息时，会出现：com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 31436823332424324] Action: BasicGet rate limited by cluster rate limiter vhost: xxx. queue: xxx.当客户端使用 BasicConsume 消费消息时，服务端会抑制向客户端 DeliverMessage 的速率，客户端不会感知到明显的 Channel 断开的错误，整体表现为类似 AMQP 协议消费者 QOS 的行为，会抑制推送到消费者消息的速率，此时消费延迟会增加，可以通过调整限流比例或者增大购买的 TPS 来解决。消费的总 TPS 主要由 BasicGet 和 DeliverMessage 的调用 TPS 次数共享。 | | 触发限流时 SDK 重试机制 | 客户端 SDK 业务侧需要处理连接断开的行为，需要对发送错误被限流的消息重新建立 Channel 连接然后进行发送重试。 | 客户端 SDK 业务消费侧会感知到延迟增加。若使用拉取 BasicGet 拉取消息，会感知到 Channel 连接断开，需要业务上主动重试。 |&lt;/p&gt; 
&lt;h2&gt;详细设计与实现&lt;/h2&gt; 
&lt;h3&gt;架构设计&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版采用双模式限流架构，兼顾节点级保护与集群级协同：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;单机限流（Node-Level Throttling）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用于节点级资源保护，通过限制 CPU、内存、线程等关键资源的使用，防止单节点因过载导致服务不可用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分布式限流（Cluster-Level Throttling）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于集群全局视角，通过多节点流量协同管理，保护共享存储资源（如 Broker）及后端系统稳定性。该模式通过使用分布式限流系统实现。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cab8876ba86ab2c10b491074cac992a20d0.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;限流实现&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版通过在计算层 （TDMQ RabbitMQ Serverless 版集群）接入分布式限流系统实现集群级读写流量控制，其核心机制是：TDMQ RabbitMQ Serverless 版集群节点在处理 BasicPublish / BasicGet / DeliverMessage 请求前，需通过集成的限流 SDK 向限流 Server 异步上报与申请 Token。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生产端限流&lt;/strong&gt; ：若 BasicPublish 申请失败，则立即拒绝生产消息请求并返回错误。 &lt;strong&gt;消费端限流&lt;/strong&gt;：若 BasicGet 申请失败，则立即拒绝拉取消息请求并返回错误。若 DeliverMessage 申请失败，则抑制推送到消费者的消息速率，实现消费端不断连接的流控，此时类似于 RabbitMQ 开源的实现，此时该消费者处于 Flow 状态。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版集群内部集成限流 SDK，该 SDK 提供 Token 申请 API，并负责与限流 Server 通信，通过这种集中式 Token 管理实现对核心存储层 (底座 Broker 集群) 的保护。&lt;/p&gt; 
&lt;h3&gt;限流实现难点一：如何平衡性能与精度&lt;/h3&gt; 
&lt;p&gt;使用 TDMQ RabbitMQ Serverless 版的各类在线业务通常对时延比较敏感，如果计算层节点处理每次读写请求都执行一次 Limiter RPC 调用（SDK -&amp;gt; Server）的话，虽然 Limiter Server 内部处理耗时几乎可以忽略，但两次 RPC 的网络 IO 耗时对消息端到端时延的影响是不能忽视的。&lt;/p&gt; 
&lt;p&gt;实际上从服务端的角度看， TDMQ RabbitMQ Serverless 版执行限流的主要目的是防止核心存储层过载，而非追求 100% 精准的流量控制，即 SDK 与 Server 之间的强同步并不是必须的。因此，为了在限流性能和限流精度之间取得平衡，Limiter 采用了一种【先消费后结算】的 Token 管理机制，Token 申请过程在限流 SDK 内部闭环，SDK 会周期性（周期大概在 50ms 以内，上报周期越短，限流越敏感）地向限流 Server 异步上报 Token 使用量并同步配额。&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版的限流机制通过以下四大核心特性，在保障系统稳定性的同时实现高性能与低时延的平衡：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;内存级处理，主链路零干扰&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;执行机制&lt;/strong&gt;：限流判断为纯内存操作，不涉及外部 RPC 调用，确保消息处理流程完全不受阻塞。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能优势&lt;/strong&gt;：主链路延迟无感知，适用于对响应时间要求严苛的在线业务场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;先消费后结算，消除误限流风险&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;设计原理&lt;/strong&gt; ：采用异步 Token 核销机制，客户端可先执行操作，限流 SDK 后续异步周期性同步配额消耗。 &lt;strong&gt;效果保障&lt;/strong&gt;：杜绝因限流判断延迟导致的正常请求被误拒，确保业务连续性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;短暂超限容忍，资源缓冲池兜底&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;场景说明&lt;/strong&gt; ：在流量毛刺等突发场景中，可能出现瞬时配额超限，由于先消费后结算的机制导致。 &lt;strong&gt;容错机制&lt;/strong&gt;：通过服务端资源预留 Buffer 吸收流量波动，避免因短暂超限触发系统风险。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;弹性容错设计，弱耦合架构保障可用性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;故障降级策略&lt;/strong&gt; ：当限流 Server 服务异常时，系统自动切换至单机 Sentinel 组件实现基础单机限流功能。 &lt;strong&gt;依赖特性&lt;/strong&gt;：对限流 Server 服务实现弱耦合架构，可以通过随时动态降级来避免限流 Server 服务异常导致的服务异常，确保分布式限流服务的高可用。&lt;/p&gt; 
&lt;h3&gt;限流实现难点二：如何平滑限流毛刺&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版采用 TPS 作为集群规格单位，用于衡量集群的吞吐能力。例如，1000TPS 表示集群每秒可处理 1000 条 TPS（即综合生产、消费等操作的加权计算）。在分布式限流系统中，这一规格对应每秒分配 1000 个 Token，其中 "一秒"即为默认的限流计数周期，用于动态控制流量配额。&lt;/p&gt; 
&lt;p&gt;在使用限流服务的实际运维中发现：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短周期（如 1 秒）&lt;/strong&gt;： 优势：对流量波动敏感，可快速响应潜在过载风险； 缺陷：易因短暂毛刺误触限流，影响正常业务波动场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;长周期（如 10 秒）&lt;/strong&gt;： 优势：容忍毛刺，降低误控率； 缺陷：服务端资源需承受更高瞬时冲击风险。&lt;/p&gt; 
&lt;p&gt;为平衡流量控制精度与用户体验，腾讯云 TDMQ RabbitMQ Serverless 版将默认限流计数周期从 1 秒调整为 10 秒。这样既降低了用户因毛刺导致的限流困扰，又通过利用少量的服务器预留资源 Buffer 来承载瞬时流量冲击，为高并发场景下的消息处理提供了可靠的支撑。&lt;/p&gt; 
&lt;h3&gt;限流实现难点三：如何实现消费端限流&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版集群使用 AMQP 协议与客户端交互，然而 AMQP 协议中并没有定义很好的处理 Fail-Fast 限流错误的帧，因此在发送消息被限流的情况下，只能通过关闭 Channel 连接来通知到客户端，此时客户端会收到相应的 AlreadyClosedException 异常，然后业务需要通过重试来解决当前时间窗口内消息发送被限流的问题。&lt;/p&gt; 
&lt;p&gt;而在消费端限流的情况下，分为两种情况，AMQP 协议中支持两种消费模式，BasicGet（拉模式) 和 BasicConsume（推模式）。 此时对消费端的限流就需要考虑消费的连续性和延迟。针对 BasicGet 模式，是客户端发起的主动同步拉取消息的命令，此时客户端每一次拉取消息是可以直接感知到是否被限流的，更好的方式是通过关闭连接来让客户端感知到限流，从而让业务上通过重试来解决拉取当前时间窗口内消息消费被限流的问题。&lt;/p&gt; 
&lt;p&gt;但是针对 BasicConsume（推模式）, 同时也是 AMQP 客户端最普遍的使用方式，考虑到客户端开启一个长连接监听相应队列上的消息，此时如果因为限流粗暴地关闭 Channel 连接, 此时的客户端往往不能实时感知到连接 Channel 断开，增加了客户端业务上处理的复杂度，同时消费侧重建 Channel 连接也会让消费流量充满毛刺和消费延迟增加。因此腾讯云 TDMQ RabbitMQ Serverless 版在推模式下使用消费抑制的方式来实现消费端限流，当消费 TPS 超过阈值时，会减少推送到客户端的频率，保证了在连接 Channel 不断开的情况下，消费流量的平稳，尽量减少因为限流导致的消费延迟。&lt;/p&gt; 
&lt;h2&gt;客户端实践教程&lt;/h2&gt; 
&lt;h3&gt;规划集群限流负载&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版的限流机制旨在保障服务稳定性与可靠性。防止在集群高负载时出现服务响应长尾毛刺，最终导致请求成功率下降，业务受损等问题。因此，在接入时建议：客户侧需要提前规划集群负载，依据当前规模和未来趋势预测来充分评估业务 TPS， 如果业务流量具有波动特性，应以峰值 TPS 为准，根据相应的评估后的 TPS 购买相应规格的实例集群。&lt;/p&gt; 
&lt;h3&gt;限流相关告警配置&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版默认接入了腾讯云监控的能力，可以利用腾讯云 TDMQ RabbitMQ Serverless 版控制枱的监控告警能力实现对集群负载的实时观测，提前发现 TPS 水位风险并及时操作升配来避免触发限流导致业务受损。告警策略建议：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;发送和消费 TPS 水位超过容量的 70% 时触发告警，提醒进行升配评估。&lt;/li&gt; 
 &lt;li&gt;出现发送限流时触发告警，警告业务发送消息可能失败风险。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;客户端限流异常处理&lt;/h3&gt; 
&lt;p&gt;业务代码通过 RabbitMQ SDK 发送消息时，需要捕获包括限流错误在内的异常，并保存必要的上下文信息，以便人工介入恢复业务。当腾讯云 TDMQ RabbitMQ Serverless 版实例的 TPS 流量峰值超过腾讯云控制枱所购买实例的 TPS 规格上限时，业务侧生产消费流量会被限流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;限流后的行为如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版服务端会返回错误码信息。&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版服务端关闭当前请求的 Channel 连接，代码中可以捕获异常并重新打开 Channel 连接，具体请参见错误码处理示例代码章节。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;错误码信息&lt;/strong&gt;： 错误码：reply-code=530&lt;/p&gt; 
&lt;p&gt;错误信息：reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:xxx reason:PublishMessage, class-id=60, method-id=40)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;错误堆栈&lt;/strong&gt;：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Suppressed: com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:amqp-autotest reason:PublishMessage, class-id=60, method-id=40)
at com.rabbitmq.client.impl.AMQChannel.processShutdownSignal(AMQChannel.java:437)
at com.rabbitmq.client.impl.ChannelN.startProcessShutdownSignal(ChannelN.java:295)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:624)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:557)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:550)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.lambda$close$0(AutorecoveringChannel.java:74)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.executeAndClean(AutorecoveringChannel.java:102)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.close(AutorecoveringChannel.java:74)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RabbitMQ AMQP Java SDK 业界使用的比较广泛，因此使用该 SDK 作为示例，RabbitMQ AMQP Java SDK 不会对限流错误进行自动重试，因此业务代码需要捕获异常并进行处理，示例代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private static final int MAX_RETRIES = 5; // 最大重试次数
private static final long WAIT_TIME_MS = 2000; // 每次重试的等待时间（以毫秒为单位）
private void doAnythingWithReopenChannels(Connection connection, Channel channel) {
    try {
        // ......
        // 在当前通道 channel 下执行的任何操作
        // 例如消息发送、消费等
        // ......
    } catch (AlreadyClosedException e) {
        String message = e.getMessage();
        if (isChannelClosed(message)) {
            // 如果通道已经关闭，关闭并重新创建通道
            channel = createChannelWithRetry(connection); 
            // 在重连后可以继续执行其它操作
            // ......
        } else {
            throw e;
        }
    }
}
private Channel createChannelWithRetry(Connection connection) {
    for (int attempt = 1; attempt &amp;lt;= MAX_RETRIES; attempt++) {
        try {
            return connection.createChannel();
        } catch (Exception e) {
            System.err.println("Failed to create channel. Attempt " + attempt + " of " + MAX_RETRIES);
            // 检查错误, 若仍是被限流导致的关闭错误，则可以等待后继续重试
            // 也可移除本部分重试逻辑
            if (attempt &amp;lt; MAX_RETRIES) {
                try {
                    Thread.sleep(WAIT_TIME_MS);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt(); // 还原中断状态
                }
            } else {
                throw new RuntimeException("Exceeded maximum retries to create channel", e);
            }
        }
    }
    throw new RuntimeException("This line should never be reached"); // 理论上不会到达这里
}
private boolean isChannelClosed(String errorMsg) {
    // 判断是否包含 channel.close 报错，该报错代表通道已关闭。
    // 可能涵盖 530，541 等错误信息。
    if (errorMsg != null &amp;amp;&amp;amp; errorMsg.contains("channel.close")) {
        System.out.println("[ChannelClosed] Error details: " + errorMsg);
        return true;
    }
    return false;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版通过分布式限流架构为在线业务提供高可用的消息服务保障。在分布式限流模式下，服务端通过集中式 Token 管理系统（限流 Limiter）动态分配资源配额，防止因突发流量冲击导致核心存储层（底座 Broker 集群）过载来提高系统稳定性，同时采用 【先消费后结算】的异步处理模式，客户端在限流 SDK 内部闭环完成 Token 申请，避免阻塞主链路，确保限流调用接口低延时，限流 SDK 周期性同步 Token 消耗数据至限流 Server，最终平衡了限流精度与调用限流服务的性能开销。同时针对消费端的限流可以实现不断 Channel 连接，实现了消费端在限流毛刺与消费延迟之间的双重保证，此外，面对限流 Server 服务不可用的情况，系统能够自动动态降级为单机限流模式，确保客户端请求的连续性，保持对限流服务的弱依赖设计来实现系统解耦。&lt;/p&gt; 
&lt;p&gt;在实际应用与运维中，同时也需要客户业务方的配合，在接入腾讯云 TDMQ RabbitMQ Serverless 版服务时，业务方客户需要根据业务规模和未来趋势合理规划集群，预留足够的 TPS 配额以应对突发流量，防患于未然。同时腾讯云 TDMQ RabbitMQ Serverless 版提供了服务端完善的监控和告警，支持客户通过监控告警能力实时订阅集群负载，提前发现 TPS 水位风险并及时进行升配等操作。在客户端业务代码层面，需要捕获限流异常并处理，保证代码的健壮性，同时保存必要的上下文信息，以便人工查看相关日志最终介入来恢复业务。&lt;/p&gt; 
&lt;p&gt;通过本文对腾讯云 TDMQ RabbitMQ Serverless 版的限流机制的介绍与实践教程，相信读者对腾讯云 TDMQ RabbitMQ Serverless 版的限流机制有了更深入的理解，并能够在实际项目中灵活应用，最终为业务的高并发、大流量场景提供稳定的支持。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4587289/blog/18638288</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4587289/blog/18638288</guid>
      <pubDate>Sat, 10 May 2025 07:34:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>百度搜索迎来十年来最大改版：AI 智能框、百看、AI 助手全面进化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在近日的百度 AI Day 开放日上，百度搜索宣布进行了其十年来最大规模的改版，此次革新涵盖了搜索框、搜索结果页以及整个搜索生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-98d15d20c6065a79b817c094d1a37c4066c.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;升级后的百度搜索框被命名为「智能框」，显著增强了其输入能力，现在可支持超过千字的文本输入。同时，拍照、语音、视频等多种输入方式也得到全面加强，并能直接调取 AI 写作、AI 作图等创作工具，极大地丰富了用户与搜索的交互方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「百看」功能也在此次改版中实现了全面升级，不仅支持图文、音视频的混合内容输出，还创新性地接入了智能体和真人服务等功能，旨在提供更丰富、多元的信息呈现形式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「AI 助手」的升级是本次改版的另一大亮点，新增了视频通话功能，并显著提升了多模态输入、富媒体输出、一站式工作台及深度搜索能力，使其成为更全面的 AI 辅助工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，智能创作能力也得到大幅提升，用户现在只需一句话即可生成三分钟的创意视频，并支持分镜编辑和自定义画面内容。截至目前，百度搜索开放平台已成功接入 1.8 万多个优质 MCP（多媒体内容提供商），使其成为国内最大的 AI 生态系统。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得一提的是，此次百度搜索还接入了商业研发团队自研的视频生成模型 MuseSteamer 及其创作平台「绘想」。据了解，MuseSteamer 是全球首个实现中文音视频一体化生成的视频模型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358379</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358379</guid>
      <pubDate>Sat, 10 May 2025 07:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>向量检索算法：从哈希、树到量化与图</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;向量检索这门技术，其发展由来已久，可以追溯到上世纪六七十年代。1975 年发表的 KD 树算法，就是早期经典的高维数据检索算法之一。&lt;strong&gt;然而，此后近四十年间，向量检索长期处于冷门状态，并没有特别多的应用需要它。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;直到 2015 年，ImageNet 图片分类数据集及何恺明教授的 ResNet 等突破性论文引爆了深度学习，使得模型在多个任务上超越人类。推荐系统和搜索引擎快速成为向量检索技术主要落地场景，向量引擎也由此开始大规模应用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;大模型爆发又掀起第二轮热潮：&lt;/strong&gt;基于向量检索的 RAG 架构，已成为解决模型幻觉、实现知识实时更新的关键技术，推动其在多模态、企业知识库等场景爆发式应用。&lt;/p&gt; 
&lt;p&gt;不久前，&lt;strong&gt;开源中国直播栏目《数智漫谈》邀请到了傅聪博士，分享了向量检索技术的发展情况。&lt;/strong&gt;傅聪于浙江大学计算机博士毕业，曾赴美国南加州大学访问研究，其主导发明的 NSG、SSG、PSP、MAG 等高性能检索算法，已落地为千亿级向量检索系统，成为工业界大规模检索的标杆方案。目前，傅聪博士在 shopee(新加坡) 担任资深算法专家，专注于 AI 大规模应用落地方面的研究。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;微信扫码，观看直播回放：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="189" src="https://oscimg.oschina.net/oscnet/up-a3d943da38c62d33dda46a1b30db2454488.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本文根据直播整理，介绍四种向量检索算法类型：哈希算法、树算法、量化算法、图算法。其中，哈希算法、树算法慢慢淡出了历史舞台，量化算法、图算法是当前主流。&lt;/p&gt; 
&lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;哈希算法：向量检索的古早形态，已逐渐被淘汰&lt;/h4&gt; 
&lt;p&gt;向量检索的最初形态——哈希算法，是一种历史悠久的向量索引方式。&lt;/p&gt; 
&lt;p&gt;从事计算机相关行业的朋友，对哈希表应该都不陌生。哈希的本质是什么？就是把数据通过一个哈希映射函数，映射到哈希桶（buckets）里。目标是让每个桶里的数据分布尽可能均匀，这样就能通过高效的二进制方式快速检索数据。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-3ebf5adc615560ea36947f573932442be26.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;向量哈希函数与我们常规理解的哈希算法，核心区别在于，哈希函数本身是专门为向量设计的。大家无需深究其具体实现，只需知道这类函数能将向量相对均匀地分散到各个哈希桶中，从而实现高效检索。&lt;/p&gt; 
&lt;p&gt;那么，为什么哈希算法没有在当下各领域大规模应用呢？主要原因有两个：一是哈希表索引结构本身非常庞大；二是其效率低且精度差。&lt;/p&gt; 
&lt;p&gt;我们可以以构建一个线上工业级并发系统为例来说明。通常来说，系统性能的核心目标通常包括 QPS（即单机处理用户请求的最大并发能力）和 recall（召回精度）。在特定的延迟要求下，评估向量检索算法的关键指标是——在此延迟约束内能达到多高的召回精度。而哈希算法最大的问题恰恰是其精度不足，因此才逐渐被淘汰。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;树算法：单棵树精度不够，昙花一现&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;历史上与哈希算法一样昙花一现的，还有树算法。它的本质就是分治思想。设想一个庞大复杂的高维向量空间，目标是通过方法将其逐层切分，最终把整个空间分割成许多小格子（也就是叶子节点），并让每个叶子节点包含的向量数量尽量接近。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="391" src="https://oscimg.oschina.net/oscnet/up-f1128fc60ac26c9adde0404801cc8352ec4.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这样就能借助树结构高效的索引逻辑进行快速查询。入门数据库时学到的那些索引，很多其实就是这种树结构，只是切分方式不同。&lt;/p&gt; 
&lt;p&gt;这种树索引有个明显特点：体积很大。 别光看它是一棵树就觉得体积小。问题在于，单棵树的检索精度通常不够好。所以实际应用中，要构建多棵树。&lt;/p&gt; 
&lt;p&gt;比如上个时代，有名的开源检索库 FLANN (Fast Library for Approximate Nearest Neighbors)，它在计算机视觉领域用得挺多，就不会只建一棵树，而是构建多棵随机树进行并行查询，以此来提升效果。代价就是索引会膨胀得厉害。&lt;/p&gt; 
&lt;p&gt;相比哈希算法，它的精度确实高一些，但通常还是达不到在线产品系统的要求。关键问题在于：即使勉强达到某个精度（可能还不达标），它的检索速度也依然非常慢。&lt;/p&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;量化算法：低损耗，空间切分类算法的性能天花板&lt;/h4&gt; 
&lt;p&gt;量化算法，和前两类算法（哈希和树算法）其实比较相似，可以把它们理解为空间切分类算法。这类算法有一个共同的缺陷，就是索引效率较低。&lt;/p&gt; 
&lt;p&gt;但量化算法另辟蹊径，它用一种低损耗的方式实现了较好的空间切分。这里有个比较经典的例子，就是 Meta 的 FAISS 库（前身由 Facebook 开发），它最早集成的核心算法 IVFPQ（Product Quantization）代表了十年前的主流方案。PQ 的核心逻辑是通过聚类来切分空间，这和前两类算法的思路不太一样。&lt;/p&gt; 
&lt;p&gt;它具体是怎么做的呢？在切分好的空间里，选取中心点（图中红点）作为区域代表点。用户的查询向量只需要和这些中心点计算距离。这个距离近似等价于查询向量与该区域内所有原始数据点（蓝点）的距离比较。这样就能快速筛选出一部分近邻候选向量，最后再用真实距离进行精确比较。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="233" src="https://oscimg.oschina.net/oscnet/up-15d3f09345246ba6a850f9370c91c0d7c3f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;br&gt; （图片来源于，知乎用户 @vegetabledog）&lt;/p&gt; 
&lt;p&gt;这种算法的优势很明显：索引结构非常小（内存占比低），检索速度足够快，而且精度也比哈希和树算法更高。量化算法发展到这里，可以说空间切分类算法的性能天花板已经显现了。&lt;/p&gt; 
&lt;p&gt;也正是在这个阶段，创新的图检索算法开始兴起。&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;图算法：精度高、速度快，当前被普遍采用&lt;/h4&gt; 
&lt;p&gt;图检索算法可以说和前面三种算法（哈希、树、量化）是完全不同的思路。&lt;/p&gt; 
&lt;p&gt;前面那些算法的核心是「分而治之」，像切割领土、筑墙建院一样去切割空间。而图算法的核心思想恰恰相反，它是要打通区块之间的壁垒——不是去切分空间，而是在空间的点与点之间构建四通八达的「高速公路」，这就是图算法的设计理念。&lt;/p&gt; 
&lt;p&gt;图算法的特点是，它的索引会比量化算法大很多。但从当前各种基准测试的表现来看，它能在保持极快速度的同时，以高精度碾压量化类算法。&lt;/p&gt; 
&lt;p&gt;那么图算法是怎么检索的呢？&lt;/p&gt; 
&lt;p&gt;假设我们已经构建好一个图结构，图中每个点只连接空间中的少量邻近点。比如起始点是黑色点 M，目标查询点是左下角的黑色点 P。从任意起点 M 逼近目标 P 的过程，本质上是一个贪婪式的图上「游走」：每一步都在当前点的邻近中寻找离 P 最近的那个点跳转过去，然后迭代重复这个过程。这样一步步跳转，最终就能逼近目标区域（红色点即为最近的候选结果）。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-bb7e20fa086e16efab68928e5adbe9301ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;想要让图算法发展得更好——精度更高、速度更快——关键在于两点：第一，路径越短越好（跳转次数少则速度快）；第二，邻近越少越好（每个点计算量小则算力需求低）。这意味着理想的图结构应该是足够稀疏，并且点与点之间的连通路径尽可能短。&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;选型：量化算法还是图算法？&lt;/h4&gt; 
&lt;p&gt;现在开源项目或 Demo 中，最常用的就是量化算法和图算法。那要怎么选型、找到适用场景？根据长期工作经验总结如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果数据总量较小，在线精度要求不高，但对内存或 GPU 显存有严格限制，就比较适合用量化算法。因为量化是用聚类中心代表其他点，这个过程必然有信息损失——数据量越小损失越小，数据量越大精度下降越明显。&lt;/li&gt; 
 &lt;li&gt;如果数据总量非常大，同时要求高精度、低延迟，并且有充足的内存资源（目前内存也相对便宜了），那么图算法是更好的选择。实际上，当前无论是开源项目还是闭源产品，主流的向量检索方案普遍都在使用图算法。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="167" src="https://oscimg.oschina.net/oscnet/up-dc8e9e8b16cadc5a2d42d658c4914e8ae48.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;量化算法有一个典型场景，就是推荐系统中的 GPU 端向量召回。&lt;/strong&gt;例如在电商平台，需要构建一个约 2000-3000 万规模的精品商品库，通过向量表征模型（如生成 64 维或 128 维向量）实时召回个性化商品作为推荐候选集。&lt;/p&gt; 
&lt;p&gt;这些向量表征模型部署在 GPU 上进行推理，因此生成的向量数据会直接驻留在 GPU 显存中。我们希望向量检索也能在显存内完成，避免向 CPU 传输数据。然而，模型本身可能已占用 10 GB 以上的显存，剩余可用显存往往仅剩 2-3GB。&lt;/p&gt; 
&lt;p&gt;在这种显存受限的场景下，量化类检索算法就显得尤为合适。类似地，如果大模型应用中的知识库规模有限，且需要端到端 GPU 处理，量化算法也是理想选择。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;至于图算法的典型场景，可以千亿级视频版权检测为例。&lt;/strong&gt;抖音、快手等短视频平台，抖音、快手这类平台每日面临海量视频上传，必须在极短时间内完成版权筛查以避免法律风险，&lt;/p&gt; 
&lt;p&gt;其核心流程可分为三步：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;特征提取：针对版权库视频，提取关键帧的画面特征并压缩为高维向量（如 CLIP 生成 1024 维向量），确保内容相似的视频片段在向量空间中距离相近；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;索引构建：将向量存入支持 ANN（近似最近邻）检索的专用数据库（如 Milvus/FAISS），构建千亿级向量索引；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实时检索：新视频上传时，实时提取其特征向量，在毫秒级延迟内从向量库中检索相似内容，返回相似度超过阈值（如 &amp;gt;95%）的潜在侵权片段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;面对这种超大规模数据+高并发+高精度的需求，图检索算法，可以说是目前最有效的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;小结：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;纵观向量检索的发展，从早期的哈希、树算法，到当前主流的量化、图算法，技术的迭代始终围绕着效率、精度与资源消耗的平衡。哈希与树算法受限于精度或效率瓶颈，逐渐淡出主流视野；量化算法凭借其低内存消耗的特性，在资源受限场景（如 GPU 显存下的中小规模召回）找到了稳固位置；而图算法则以其高精度、低延迟的优势，成为应对千亿级海量数据、高并发在线检索的首选。&lt;/p&gt; 
&lt;p&gt;技术迭代一直在进步。傅聪博士主导发明的基于图的 NSG 算法，已成为当前主流方案之一，但仍然在实践中不断演进——目前，他在 Shopee（新加坡） 带领团队已将其迭代至第三代 PSP 与第四代 MAG 算法，不断突破着大规模向量检索的性能边界。&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span style="color:#27ae60"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;【数智漫谈】&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OSCHINA 视频号直播畅聊栏目【数智漫谈】，每期一个技术话题，三五位专家围坐，各抒己见，畅聊开源。给大家带来最新的行业前沿、最热门的技术话题、最有趣的开源项目、最犀利的思想交锋。如果你手上也有新点子、好项目，想要跟同行交流分享，欢迎联系我们，讲坛随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18683168</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18683168</guid>
      <pubDate>Sat, 10 May 2025 07:17:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Anthropic 年化收入达 40 亿美元，较年初增长近 4 倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Information 援引知情人士称，「AI 独角兽」Anthropic 年化收入已达到每年 40 亿美元，即每月 3.33 亿美元，较今年年初增长了近四倍。与此同时，Anthropic 的竞争对手 Cursor 也在积极扩展业务，双方之间的竞争愈加激烈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="269" src="https://oscimg.oschina.net/oscnet/up-2307b0436f3618822c9987fadd1eedab2af.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Cursor 是一款由 Anthropic 提供人工智能技术支持的编程应用程序，旨在帮助开发者提高工作效率。然而，Cursor 的背后并不仅仅依赖于 Anthropic 的技术。近期，Cursor 公司还招募了 Anthropic 的两位高管。这两位高管曾负责 Anthropic 的编程产品 Claude Code，他们的加入可能会进一步增强 Cursor 在市场上的竞争力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Anthropic 自成立以来，凭借其先进的人工智能技术和强大的研发团队，迅速占领了市场。然而，随着 Cursor 的崛起，Anthropic 面临着新的挑战。Cursor 虽然依赖于 Anthropic 的技术，但通过引入高管和不断创新，Cursor 希望能在市场上占据一席之地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不仅如此，人工智能技术的快速发展，也使得编程工具的需求不断增加。市场对智能编程工具的热情高涨，各家公司都在努力争取更大的市场份额。面对这样的市场环境，Anthropic 和 Cursor 之间的竞争将会更加白热化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358314</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358314</guid>
      <pubDate>Sat, 10 May 2025 03:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>前 5 个月我国软件业务收入 55788 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;工业和信息化部运行监测协调局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_451a835829c54325a8316fa9dd2a9d32.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;，&lt;/span&gt;&lt;span style="color:#000000"&gt;2025 年前 5 个月，我国软件和信息技术服务业（以下简称「软件业」）运行态势良好，软件业务收入稳健增长，利润总额保持两位数增长，软件业务出口保持正增长。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="237" src="https://oscimg.oschina.net/oscnet/up-1716524be9e23b5228867787d358aa2a175.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;一、总体运行情况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;软件业务收入稳健增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，软件业务收入 55788 亿元，同比增长 11.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;利润总额增速保持两位数增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，软件业利润总额 6721 亿元，同比增长 12.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;软件业务出口保持正增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，软件业务出口 227&lt;/span&gt;&lt;span style="color:#000000"&gt;.1&lt;/span&gt;&lt;span style="color:#000000"&gt;亿美元，同比增长 3.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;二、分领域运行情况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;软件产品收入稳定增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，软件产品收入 12478 亿元，同比增长 9.8%，占全行业收入的 22.4%。其中，基础软件收入 704 亿元，同比增长 10&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%；工业软件产品收入 1138 亿元，同比增长 7&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;信息技术服务收入保持两位数增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，信息技术服务收入 38096 亿元，同比增长 12&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%，占全行业收入的 68.3%。其中，云计算、大数据服务共实现收入 5855 亿元，同比增长 11.2%，占信息技术服务收入的 15.4%；集成电路设计收入 1516 亿元，同比增长 15.2%；电子商务平台技术服务收入 4355 亿元，同比增长 7.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;信息安全收入稳定增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，信息安全产品和服务收入 787 亿元，同比增长 8.4%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;嵌入式系统软件收入稳定增长。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 个月，嵌入式系统软件收入 4428 亿元，同比增长 8.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;三、分地区运行情况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;前 5 个月，东部地区、中部地区、西部地区和东北地区分别同比增长 11.3%、11.8%、11.0% 和 9.2%。东部地区占全国软件业务总收入的 84.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;京津冀地区软件业务收入同比增长 12.3%，长三角地区软件业务收入同比增长 11.9%。北京、广东、江苏、山东、上海软件业务收入居全国前 5，同比分别增长 12.7%、8.5%、12.3%、12.1% 和 15.1%。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358308</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358308</guid>
      <pubDate>Sat, 10 May 2025 03:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>1-5 月我国互联网业务收入 7735 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工业和信息化部运行监测协调局最新&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fgxsj%2Ftjfx%2Fhlw%2Fart%2F2025%2Fart_8805da85aec14555b88e36da36ea4e27.html" target="_blank"&gt;发布&lt;/a&gt;&lt;span style="color:#000000"&gt;了 2025 年 1-5 月份互联网和相关服务业运行情况。具体如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;一、总体运行情况&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;互联网业务收入稳定增长。1－5 月份，规模以上互联网和相关服务企业（以下简称互联网企业）完成互联网业务收入 7735 亿元，同比增长 0.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;利润总额降幅持续收窄。1－5 月份，规模以上互联网企业实现利润总额 692 亿元，同比下降 2.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研发经费增势放缓。1－5 月份，规模以上互联网企业共投入研发经费 390.6 亿元，同比增长 4.1%，增速较 1－4 月份回落 0.7 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;二、分地区运行情况&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;东部地区互联网业务收入增速放缓，西部地区收入增速领先。1－5 月份，东部地区完成互联网业务收入 6943 亿元，同比增长 2.8%，高于全国增速 1.9 个百分点，占全国互联网业务收入的 89.8%。中部地区完成互联网业务收入 308.4 亿元，同比下降 30.1%，低于全国增速 31 个百分点。西部地区完成互联网业务收入 467.8 亿元，同比增长 4.3%。东北地区完成互联网业务收入 15.7 亿元，同比下降 24.1%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;京津冀地区互联网业务收入保持较快增势。1－5 月份，京津冀地区完成互联网业务收入 2666 亿元，同比增长 8.3%，占全国互联网业务收入的 34.5%。长三角地区完成互联网业务收入 2470 亿元，同比下降 2.1%，占全国互联网业务收入的 31.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;超三成地区互联网业务增速实现正增长。1－5 月份，互联网业务累计收入居前 5 名的北京、广东、上海、浙江和天津共完成业务收入 6496 亿元，同比增长 4.1%，占全国（扣除跨地区企业）互联网业务收入的 84%。全国互联网业务收入实现正增长的省（区、市）有 11 个，其中山西、内蒙古、四川、陕西增速超 10%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;附注：规模以上互联网和相关服务企业口径为上年互联网和相关服务收入 2000 万元及以上，文中所有同比增速均按可比口径计算。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358301</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358301</guid>
      <pubDate>Sat, 10 May 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>华为开源大规模 MoE 模型推理部署技术「Omni-Infer」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;华为公布了基于升腾的超大规模 MoE 模型推理加速技术「Omni-Infer」。&lt;/p&gt; 
&lt;p&gt;官方介绍，Omni-Infer 是一套专为升腾硬件平台定制的强大推理加速工具集，完全兼容业界目前主流的开源大模型推理框架（比如 vLLM 等），旨在提供高性能、企业级推理能力，具备原生支持且功能集持续扩展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ad6ff90d8d31fab0e52f1d92fd7d9bb90e3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;部分核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高级注意力机制优化：专为 LLM、MLLM 和 MoE 模型定制，增强性能与可扩展性。&lt;/li&gt; 
 &lt;li&gt;请求级负载均衡：针对所有序列长度优化预填充（prefill）和解码（decode）阶段，实现最大吞吐量与低延迟。&lt;/li&gt; 
 &lt;li&gt;优化的 MoE 专家部署：支持 EP144/EP288 配置的大规模混合专家（Mixture of Experts, MoE）模型。&lt;/li&gt; 
 &lt;li&gt;MoE 专家负载均衡：具备分层非均匀冗余和近实时动态专家放置功能，提升资源利用效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;目前，Omni-Infer 已公布技术报告及可分析代码包等内容：&lt;a href="https://gitee.com/omniai/omniinfer"&gt;https://gitee.com/omniai/omniinfer&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358292</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358292</guid>
      <pubDate>Sat, 10 May 2025 02:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Iceberg 在图灵落地应用</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;百度 MEG 上一代大数据产品存在平台分散、易用性差等问题，导致开发效率低下、学习成本高，业务需求响应迟缓。为了解决这些问题，百度 MEG 内部开发了图灵 3.0 生态系统，包括 Turing Data Engine(TDE) 计算&amp;amp;存储引擎、Turing Data Studio(TDS) 数据开发治理平台和 Turing Data Analysis(TDA) 可视化 BI 产品。依托图灵 3.0 生态，我们引入了数据湖表格式：Apache Iceberg，利用其特性并在多种业务场景下进行优化实践，解决图灵数仓业务实时数据入湖，数据表历史记录更新效率低等多个痛点问题。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 图灵 3.0 生态概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由于百度 MEG 上一代大数据产品存在平台多、易用性差及数据流转繁琐等问题。这些问题导致开发人员研发效率低及多平台间高昂的学习成本；业务部门的感知则是需求交付迟缓、数据产出延迟及数据质量低等问题。为了解决上述问题，我们构建了新一代大数据解决方案——"图灵 3.0"，旨在覆盖数据全生命周期，支持全链路数据操作，提供高效敏捷且统一的强大数据生态系统，其中包括数据计算引擎、数据开发和数据分析三个核心部分：&lt;/p&gt; 
&lt;p&gt;1. TDE（Turing Data Engine）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247581388%26idx%3D1%26sn%3De71a4f3c4ca283ac6e8fe51d0a45a02b%26scene%3D21%23wechat_redirect" target="_blank"&gt;图灵生态的计算引擎&lt;/a&gt;，包含基于 Hive、Iceberg 进行数据处理的 Spark 和&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247601378%26idx%3D1%26sn%3D9234aeef05c3813cfb34d9a064261984%26scene%3D21%23wechat_redirect" target="_blank"&gt;ClickHouse 高性能计算引擎&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;2. TDS（Turing Data Studio）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247599508%26idx%3D1%26sn%3D19094522609ca58528295a8ccbb061bd%26scene%3D21%23wechat_redirect" target="_blank"&gt;一站式数据开发治理平台&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;3. TDA（Turing Data Analysis）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247584876%26idx%3D1%26sn%3D7bf459415ef8d51685d4e1c335b0603e%26scene%3D21%23wechat_redirect" target="_blank"&gt;新一代可视化 BI 产品&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;本文主要介绍数据湖表格式 Iceberg 在图灵 3.0 生态下的应用与实践。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1764b56858226d39002905e95ec9f32e1d2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△图灵 3.0 生态产品&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 问题&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MEG 数据中台基于 Hive 构建了离线数据仓库，已支持手百，搜索，商业，贴吧，小说，用增架构，销售等多个业务需求，但随着业务的发展，业务对数据的实时性以及查询性能等有更高要求，当前主要存在以下几个问题：&lt;/p&gt; 
&lt;p&gt;1. 商业、电商、销售等业务，周期性地更新行业等信息，单次更新数据量占比小、字段少，但是基于 Hive 的数据更新（以下简称：数据回溯）只能通过全量覆盖写的方式实现，数据回溯周期长、效率低、成本高。&lt;/p&gt; 
&lt;p&gt;2. 由于 Hive 在实时数据更新以及事务支持上存在一定局限性，无法有效满足业务构建实时数仓的需求。&lt;/p&gt; 
&lt;p&gt;3. 在处理大规模数据集上，Hive 的查询性能受到如元数据的加载解析以及每次访问数据都需通过分布式文件系统 listFile 遍历文件列表等问题的影响，导致性能降低。&lt;/p&gt; 
&lt;p&gt;基于上述问题，我们通过技术调研，最终引入了开源的数据湖表格式 Iceberg，构建数据湖存储服务，并借助大数据生态的 Spark、Flink 等计算引擎来实现数据湖的分析，将其无缝集成到图灵生态中，帮助业务提效降本，构建更快速、更高效、更低成本的数据中台产品。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 Hive 和 Iceberg 对比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Hive 作为一个基于 Hadoop 生态系统的开源数据仓库工具，主要用于对大规模结构化数据进行存储、查询和分析。而 Iceberg 作为新一代数据湖表格式，提供了类似传统数据库的事务性，保证和数据一致性，并支持复杂的数据操作，如行级更新和删除等，更加适合实时更新，流批一体数据场景，下表列出 Hive 和 Iceberg 一些主要特性对比：&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Hive&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Iceberg&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;行级更新&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;不支持&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持 merge into、&lt;/span&gt; 
         &lt;span&gt;upsert&lt;/span&gt; 
         &lt;span&gt;等语法进行行级别更新能力&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;时效性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;小时级别/天级&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;分钟级&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;事务&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;非完整的 ACID 事务&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持完整的 ACID 事务，同时使用多快照提供了读写分离的特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;元数据管理方式&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;基于 Mysql 进行元数据存储&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;通过文件组织管理，直接存储数据文件元数据&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;数据版本控制&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;无&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持时间旅⾏(Time travel) 特性，可基于快照进行历史数据版本管理和访问&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 Iceberg 的组织结构&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Iceberg 文件组织分为元数据层和数据层，主要包含 version-hint，metadata file、snapshot file、manifest file 和 data file 文件类型，具体如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;metadata 元数据层&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a. version-hint：该文件作为元数据索引初始文件，记录了 Iceberg 表的版本号，通过版本号找到对应的 metadata file。&lt;/p&gt; 
&lt;p&gt;b. metadata file：记录了 Iceberg 表的 schemas、properties 以及快照等信息。&lt;/p&gt; 
&lt;p&gt;c. snapshot file（manifest-list）：每次数据 commit 会生成一个新的快照，保存了该快照下每个 manifest file 路径及对应的分区范围。&lt;/p&gt; 
&lt;p&gt;d. manifest file：记录数据文件元信息，包含每个数据文件的路径、文件的大小等一系列统计信息（如文件每列的最大最小值、空值数等），实现元数据和数据文件的关联。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;data 数据层&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;data file：实际的数据文件，以 parquet 等列存格式存储数据。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f4a0f78b290db1caccb1aa213d0eb2ebc13.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表结构&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f506fa444f1e285b84c15e9adb1fd379988.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 文件组织结构&lt;/p&gt; 
&lt;p&gt;通过上述 Iceberg 元数据文件组织结构，Iceberg 实现了文件级的元信息统计及版本化管理。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;02 Iceberg 能力建设与应用&lt;/h1&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 图灵生态能力适配&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 统一元数据服务&lt;/h3&gt; 
&lt;p&gt;由于原生 iceberg 缺少元数据的可视化管理能力，我们通过构建统一的元数据微服务，将 Iceberg 表和 Hive 表元数据进行管理，对应用层提供相关表和分区的增删改查等接口，统一数据存储的元数据操作入口。&lt;/p&gt; 
&lt;p&gt;该微服务主要包含常驻 SparkSession 模块，EngineMetaService 模块和元数据模块，通过将 SparkSession 常驻，为用户提供 Iceberg 表和 Hive 表元数据和分区数据的增删改查功能，以及可视化的元数据管理界面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-76e46b4f67c2c75cd8176866ca4893e5c2e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△统一元数据服务架构&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 打通 Iceberg 和 Hive 联邦查询&lt;/h3&gt; 
&lt;p&gt;为了兼容历史业务存量 Hive 表，同时降低用户使用 Iceberg 的成本。我们在计算引擎层面打通 Iceberg 和 Hive 联邦查询能力，并保证了 Iceberg 表与原有方式语法一致。&lt;/p&gt; 
&lt;p&gt;通常在一条 SQL 执行过程中，主要可简化以下 Parse、Analyzer、Optimizer、CBO 四个流程。通过在 Analyzer 和 Plan 阶段进行改进优化，来打通 Iceberg 和 Hive 表联邦查询。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Analyzer 阶段：该阶段主要是将 spark 未解析的逻辑计划进行解析，我们通过对 SparkSessionCatalog 加载方式改造，优先加载 iceberg 表使用的 catalog 类型，如果用户 SQL 使用的是 Iceberg 表，则对应会使用 IcebergCatalog 和 iceberg 数据源访问，否则使用 SessionCatalog 与 Hive 数据源访问。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optimizer 阶段：为加强数据安全管理，我们进一步打通 Iceberg 表鉴权能力，在基于逻辑计划生成物理计划阶段，解析注入表、字段信息以及表操作类型规则，并与公司内数管平台交互，实现对 Iceberg 表和字段的鉴权&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a5292d689d944eafa1fc34ca2637e610b9f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 和 Hive 联邦查询适配流程&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 存量 Hive 低成本迁移 Iceberg&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;现有数仓业务数据主要存储于 Hive 表，为支持业务快速切换 Iceberg 应用新技术，我们建设了存量 Hive 表低成本迁移至 Iceberg 表的能力。&lt;/p&gt; 
&lt;p&gt;以下是在实践过程中的两种迁移方案对比：&lt;/p&gt; 
&lt;p&gt;方式 1：使用 Iceberg 功能 migrate 进行原地迁移，通过社区提供的 CALL migrate 语法，直接执行如下示例的 SQL 语句，即可将 Hive 表升级为 Iceberg 表。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CALL&amp;nbsp;catalog_name.system.migrate('db.sample', map('foo',&amp;nbsp;'bar'));﻿


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该方案操作简单且可回滚，但这种方式在图灵生态落地过程中也存在一些问题：&lt;/p&gt; 
&lt;p&gt;该方式会基于原 Hive 表的数据信息构建 Iceberg 元数据信息，并将原 Hive 表名重命名为 sample_backup_，同时数据路径也进行重命名。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下游无法读：在执行迁移过程中，原 Hive 表对应的路径已经被重命名，进而导致下游业务无法正常读取正在迁移中的表。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多表挂载冲突：在业务的使用场景中，存在同一份物理数据被多个 Hive 表挂载可能，直接修改路径会导致其他表失效。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;方式 2：基于上述问题，我们进一步对现有方案进行优化，不改变 Hive 表原有的数据路径，来实现 Hive 低成本迁移 Iceberg，具体流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;构建 Iceberg 元数据：直接复用 Hive 的分区数据，新建同名的 Iceberg 表，并重建 Iceberg 元数据，最终新 Iceberg 表的元数据信息实际指向是 Hive 分区数据存储位置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据校验：当 Iceberg 元数据构建完成后，查询 Iceberg 表中字段数据，和迁移之前 Hive 表字段数据，进行一致性校验，验证迁移是否符合预期。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;读写切换：数据校验完成后，我们只需要将对应表的属性更新为 Iceberg。因为我们已经打通了 Iceberg 和 Hive 的查询，且迁移后表名未变，业务可正常使用原有表名及语法进行查询和写入，降低迁移成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eea52f5d044ee6bc0ba16749ae9f4589492.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Hive 迁移 Iceberg 整体实现流程&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 Iceberg 在图灵的应用和性能优化&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.1 图灵实时数仓应用&lt;/h3&gt; 
&lt;p&gt;在图灵数仓大部分场景中，用户主要依托天级或小时级运行的离线 Spark 任务来完成数据入仓。在这种模式下，难以满足部分对数据实时性要求较高的需求。&lt;/p&gt; 
&lt;p&gt;为解决该问题，我们基于 Iceberg+Flink 构建的图灵实时湖仓架构，整体重构流程如下图所示。该架构模式实现了数据分钟级别实时入仓，显著提升了数据入仓的时效性。进一步扩展了整个图灵的应用场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;针对数据分析和 case 排查等场景，业务可基于图灵常驻计算引擎进行实时查询，快速获取所需要的数据支持业务分析决策；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;针对策略迭代、特征生产以及机器学习等复杂计算场景，可基于 spark 例行任务进行加工生产；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;针对策略数据调研分析、科学计算等复杂场景通过数据交互计算引擎 Jupyter 进行数据计算。通过构建图灵实时湖仓架构，既保证了数据分析的时效性又兼顾了复杂计算任务的处理能力，有效提升了业务的数据处理效率和分析决策能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fabfc35e204c90fdf9ccd937438c044d8c6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△图灵实时湖仓架构演变&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.2 行级更新策略&lt;/h3&gt; 
&lt;p&gt;在图灵数仓业务场景下，商业、搜索、电商、销售等业务，周期性地更新行业等信息。而 Hive 在该场景下支持相对较弱，需通过全量覆盖写方式刷新数据，这种方式在大数据量场景下，回溯数据周期长，消耗资源大，所需要的人力时间成本也高。我们通过利用 Iceberg 行级更新的特性，基于 update、merge into 等方式回溯进行字段变更，能够很大程度的提高回溯效率，降低资源和人力成本。&lt;/p&gt; 
&lt;p&gt;针对数据行级更新，Iceberg 提供了两种策略，分别为 COW(Copy on Write： 写时复制) 或 MOR (Merge on Read：读时合并)，其中 MOR 根据其标记删除文件的区别又细分了两种方式（Equality Delete File 和 Position Delete File）。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新策略&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新后的读取效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新时写入效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;适用场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;备注&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;COW&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最慢&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;读多写少场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;﻿&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 标记条件删除（&lt;/span&gt; 
         &lt;span&gt;&lt;span style="color:#191b1f"&gt;&lt;span&gt;Equality Delete File&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
         &lt;span&gt;）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;较快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;写入多、读取少场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;读开销：每次读取数据需要额外读取标记删除列数据进行比较。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;写开销：只需要存储标记过滤数据的条件，写入成本极低。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 标记位置删除（Position Delete File）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;快（依赖更新数据量）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;较快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;少量数据更新、读取少场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;读开销：加载每个文件需过滤的数据行号。（删除行过多，影响性能）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;写开销：需要扫描一遍原数据，找出待删除数据的行号。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;关于 COW 和 MOR 更新策略的文件表现形式如下图所示，我们针对不同场景采用不同更新策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对于日常数据查询分析场景，小时级&amp;amp;天级离线例行生成加工场景，由于查询次数会远多于数据更新次数，可默认采用 COW 策略；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;针对一些业务更新少量字段进行长周期回溯场景，以及实时场景，写入频繁，通过使用 MOR 策略，来支持用户进行数据回溯变更字段信息，以提升数据更新效率并节省资源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082e448b69e5bbdb64cc8dbc417fdcbe04d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△COW 和 MOR 两种更新策略对比&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45b92197037fdcbd76356145ee09137730c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△MOR 两种删除文件类型&amp;amp;更新字段示例&lt;/p&gt; 
&lt;p&gt;在业务进行数据回溯应用过程中，我们采用 MOR(Position Delete File) 进行行级数据更新，通过原 Hive 回溯和新 Iceberg 回溯两种方式对比，在一天 24 小时不同分区上，验证了 Hive 和 Iceberg 新旧的回溯效率，如下图所示，业务回溯效率整体可平均提升 50%+；进一步地对比单次回溯一年数据消耗的计算资源量对比，平均整体降低 70%+的计算资源消耗，整体上极大提升回溯效率，并降低资源成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ec2f7bfd27359aea682e96ed16bd8438b28.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△ Hive 和 Iceberg 回溯效率对比&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.3 Iceberg 表生命周期管理和性能优化&lt;/h3&gt; 
&lt;p&gt;在 Iceberg 应用实践的过程中，针对不同业务场景遇到的问题，我们汇总如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件过多：在实时湖仓业务场景，为了要保证数据的时效性，通常是分钟级别的 commit 操作，在这种场景下，单个作业执行一天，则需要 1440 个 commit，如果执行时间更长，则会产生更多的 commit，随着时间的累积，元数据以及数据文件等都会产生大量的小文件，对于整体查询的性能会产生一定的影响。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;存储资源增加：如果 iceberg 表的快照不及时进行清理，可能会造成数据存储增加，导致存储账号资源紧张。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺乏分区数据统一管理：在一些业务场景，只需要保存一定天数的分区数据，针对无用数据需要进行删除处理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据文件组织不均衡且无序：由于表数据写入是随机无序，且针对表数据文件大小会存在不均衡的情况。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;针对上述问题，我们通过对 Iceberg 表进行全生命周期管理，并结合 Iceberg 特性优化表查询性能，保障整个数据链路的稳定性，整体框架如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6f3d4d018567c082ed09d5addc93eb145e6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表生命周期管理和性能优化流程&lt;/p&gt; 
&lt;p&gt;以上流程主要包含表数据生命周期管理和表性能优化两部分。&lt;/p&gt; 
&lt;p&gt;一方面，对于表数据生命周期管理，我们通过在线服务执行定时任务，来实现对表数据和元数据进行全生命周期监控，具体如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;数据分区过期：基于用户配置的表生命周期，进行分区数据删除，保证数据文件按期清理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元数据快照清理：为用户提供按照时间维度天级别和按照个数维度小时级别两种快照过期策略，精细化元数据快照过期处理，实现存储资源的高效利用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元数据孤儿文件清理：通过天级例行任务来触发清理由于计算引擎执行任务失败等情况产生的一些没有被引用的孤儿文件，避免元数据累积影响性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一方面，在表性能优化方面，我们结合图灵数仓表使用情况，并基于 Iceberg 原生特性，为用户在平台侧提供 Iceberg 表优化算子（如下图示例），主要包含以下两种能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件合并：通过制定合并文件大小，对表数据文件进行重写合并，避免产生大量小文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;z-order 排序优化：实现对表相关字段进行重排序，提升查询性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ba76a39d6a2f835b0d8fb1866416f21a652.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表优化算子任务创建示例&lt;/p&gt; 
&lt;p&gt;我们通过对 Iceberg 表整体的生命周期管理，实现了数据和元数据的统一治理，表元数据小文件数万个降低到数百级别，合理控制了元数据产生的数量，并解决了数据频繁回溯场景下存储快速增加的问题。而在表查询优化方面，通过在一些表的数据重分布和字段重排序应用，在部分业务表查询性能提速 50%。&lt;/p&gt; 
&lt;span id="OSC_h1_16"&gt;&lt;/span&gt; 
&lt;h1&gt;03 未来规划&lt;/h1&gt; 
&lt;p&gt;Iceberg 作为图灵 3.0 生态中的重要组成部分，基于其高时效性、行级更新能力、小文件合并以及 Z-order 等成体系的数据优化的技术解决方案，为 MEG 数据中台业务提供构建湖仓一体，解决数据回溯等痛点问题的能力。目前 Iceberg 的应用已覆盖搜索，商业，销售，用增架构等多个业务线，通过低成本助力业务将存量 Hive 迁移 Iceberg 表，为业务提供高性能数据查询，同时实现对业务的降本增效。此外，我们也在不断完善 Iceberg 数据存储引擎的各项能力，包含表数据智能治理、查询优化、智能索引以及特定场景的性能问题等，并不断扩大 Iceberg 的业务覆盖范围。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18679436</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18679436</guid>
      <pubDate>Fri, 09 May 2025 10:17:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>RWKV 社区六月动态：多次亮相高规格活动，适合混合架构的新特性发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;欢迎大家收看《RWKV 社区最新动态》，本期内容收录了 RWKV 社区 2025 年 6 月的最新动态。&lt;/p&gt; 
&lt;p&gt;只需 3 分钟，快速了解 RWKV 社区 6 月都有哪些新鲜事！&lt;/p&gt; 
&lt;h2&gt;6 月动态省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新闻动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV-8 系列之 DeepEmbedAttention 发布&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 学术研究动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新论文：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation（基于 RWKV 的医学视频生成，已被 &lt;strong&gt;MICCAI 2025 提前接收&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新论文：Pan-Sharpening via Causal-Aware Feature Distribution Calibration（基于 RWKV 的全色锐化，一区顶刊 &lt;strong&gt;TGRS&lt;/strong&gt; 接收）&lt;/li&gt; 
   &lt;li&gt;新论文：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration（基于 RWKV 的低光照图像恢复，已入选 &lt;strong&gt;CVPR 2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新论文：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing（RWKV 的视觉语言模型，发表于 JCR Q1 期刊 Information Fusion）&lt;/li&gt; 
   &lt;li&gt;新论文：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection（遥感变化检测，IEEE TAES 接收）&lt;/li&gt; 
   &lt;li&gt;新论文：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR（基于 RWKV 的语音识别，Interspeech 2025 接收）&lt;/li&gt; 
   &lt;li&gt;新论文：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV（基于 RWKV 的音乐生成）&lt;/li&gt; 
   &lt;li&gt;新论文：Out-of-Distribution Semantic Occupancy Prediction（引入 RWKV 增强特征的 3D 语义占用预测）&lt;/li&gt; 
   &lt;li&gt;新论文：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification（基于 RWKV 的量子增强图像分类）&lt;/li&gt; 
   &lt;li&gt;新论文：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation（基于 RWKV 的医学图像分割）&lt;/li&gt; 
   &lt;li&gt;新论文：Exploring Diffusion with Test-Time Training on Efficient Image Restoration（基于 RWKV 的图像修复）&lt;/li&gt; 
   &lt;li&gt;新论文：Relational Context Modeling for Improved Knowledge Graph Completion（混合 RWKV 架构的知识图谱补全）&lt;/li&gt; 
   &lt;li&gt;新论文：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation（基于 RWKV 的医学图像分割）&lt;/li&gt; 
   &lt;li&gt;新论文：RWKV-IF: Efficient and Controllable RNA Inverse Folding via Attention-Free Language Modeling（基于 RWKV 的 RNA 逆折叠）&lt;/li&gt; 
   &lt;li&gt;新论文：A Parallel Processing Architecture for Long-Term Power Load Forecasting（基于 RWKV 的长期电力负荷预测）&lt;/li&gt; 
   &lt;li&gt;新论文：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance（集体运动临界性盲识别）&lt;/li&gt; 
   &lt;li&gt;新论文：融合接收加权键值架构和球面几何特征的甲状腺结节分割方法（基于 RWKV 的医学影像分割）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区项目动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;rwkv_Ascend（RWKV 和升腾共建的算子库）&lt;/li&gt; 
   &lt;li&gt;rwkv7-g1-1.5b-instruct-preview（RWKV 的后训练模型）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区市场活动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 参加亚马逊云科技中国峰会&lt;/li&gt; 
   &lt;li&gt;RWKV 参加 RTE Open Day&lt;/li&gt; 
   &lt;li&gt;RWKV 参加魔搭开发者大会&lt;/li&gt; 
   &lt;li&gt;RWKV 参加 GAIC 全球互联网架构大会&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相上海开源创新箐英荟&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相国际技术进出口交易会&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相香港 NovaX 国际创投嘉年华&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 模型新闻动态&lt;/h2&gt; 
&lt;h3&gt;RWKV-8 系列之 DeepEmbedAttention&lt;/h3&gt; 
&lt;p&gt;5 月 27 日，我们公开了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首个新特性 DeepEmbed：对端侧友好的稀疏设计，解决 MoE 显存占用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;6 月 30 日，与其相关的另一个新特性 DeepEmbedAttention（DEA）也正式公布。这是一种基于 RWKV-8 DeepEmbed 思路的注意力变体，拥有极小的 KV 缓存，尤其适合混合模型（例如后续的 RWKV-7s 混合模型），可将它们的长上下文性能提升到 Transformer 水准。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="DeepEmbedAttention-loss" src="https://oscimg.oschina.net/oscnet/up-1df5adeb74b9c9eb0c3f35fe35e39185bf0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;详细报道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;RWKV-8 系列之 DeepEmbedAttention：精简 KV 缓存，尤其适合混合模型（RWKV-7s）&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RWKV 学术研究动态&lt;/h2&gt; 
&lt;p&gt;RWKV 学术研究包括 &lt;strong&gt;基于 RWKV 架构的新论文&lt;/strong&gt; 或 &lt;strong&gt;RWKV 社区参加的学术研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;FEAT&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.04956" target="_blank"&gt;https://arxiv.org/abs/2506.04956&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型架构中的 WKV 注意力机制，提出了 FEAT 模型，通过统一的空间-时间-通道注意力机制解决医疗视频生成中通道交互不足、计算复杂度高和去噪指导粗糙的问题。在多个数据集上实现了高效高质量的医疗视频生成。&lt;/p&gt; 
&lt;p&gt;该项工作十分新颖和出色，已经以 top9% 的评分提前入选 &lt;strong&gt;MICCAI 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250605-FEAT" src="https://oscimg.oschina.net/oscnet/up-467d7594221b6e113f5533aa24c0fe733fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11023855" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11023855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-04&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种新的全色锐化方法，通过因果推断解决网络优化中的频率不平衡问题。该方法在训练阶段利用 RWKV 架构的全局感受野，有效学习高频分量的长尾分布，并量化特征偏差的累积方向。&lt;/p&gt; 
&lt;p&gt;实验结果表明，该方法在多个基准数据集上均优于现有先进方法，展示了其在全色锐化任务中的有效性和鲁棒性。&lt;/p&gt; 
&lt;p&gt;文中方法在全色锐化任务中有出色的表现，已入选一区顶刊 &lt;strong&gt;IEEE Transactions on Geoscience and Remote Sensing&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250604-Pan-Sharpening_via_Causal-Aware_Feature_Distribution_Calibration" src="https://oscimg.oschina.net/oscnet/up-eec12432c41aab67b1095296c7aa214168b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.23068" target="_blank"&gt;https://arxiv.org/abs/2505.23068&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型，提出了一种统一的多状态视角模型 URWKV，用于低光照图像恢复。该模型通过定制化的 URWKV 块感知和分析复杂退化，利用多阶段状态实现自适应场景感知的亮度调制。显著提升了性能。&lt;/p&gt; 
&lt;p&gt;论文受到广泛认可，已入选 &lt;strong&gt;CVPR 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-URWKV" src="https://oscimg.oschina.net/oscnet/up-b0e6fa626bfa9e998ebf650bc70d4c9f7ee.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;VisualRWKV-HM&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1566253525004099" target="_blank"&gt;https://www.sciencedirect.com/science/article/pii/S1566253525004099&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="20250606-VisualRWKV-HM" src="https://oscimg.oschina.net/oscnet/up-2d4c04b5430391084f2b0de8de9a7905587.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了 VisualRWKV-HM，这是一种具有线性复杂度的视觉语言模型，在单图像、多图像和多视图基准测试中均达到了 SOTA 性能。&lt;/p&gt; 
&lt;p&gt;与基于 Transformer-Mamba 架构的混合模型 LongLLaVA 相比，它在上下文长度为 16K 时消耗的内存更少，吞吐量提高了 24%。此外，VisualRWKV-HM 具有良好的可扩展性，通过扩展状态编码器和解码器，可以进一步提高性能。&lt;/p&gt; 
&lt;h3&gt;SMNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11039697" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11039697&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型和 Mamba 架构提出了一种新的遥感变化检测模型 SMNet，该模型通过整合多层次特征表示，有效解决了当前方法在变化检测任务中性能有限和特征表达能力不足的问题。SMNet 利用 RWKV 的多方向 WKV 注意力机制和 Mamba 的空间架构，增强了模型处理语义信息的能力。&lt;/p&gt; 
&lt;p&gt;实验结果表明，SMNet 在多个遥感变化检测基准数据集上表现出色，显著优于现有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250618-SMNet_A_Semantic_Guided" src="https://oscimg.oschina.net/oscnet/up-56b21424d56741e3598d42c23708a33f28e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.19761" target="_blank"&gt;https://arxiv.org/abs/2506.19761&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文研究了将多头注意力（MHA）替换为双向循环注意力（RA）在长语音识别（ASR）中的应用，发现双向 RWKV-Conformer 模型在保持相似准确率的同时，效率更高。通过引入 Direction Dropout 方法，进一步提升了模型的灵活性和性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250624-Accurate,fast,cheap" src="https://oscimg.oschina.net/oscnet/up-9e59775226d89bf420c19693e382a38938d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MIDI-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.13001" target="_blank"&gt;https://arxiv.org/abs/2506.13001&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了 MIDI-RWKV ，一个用于个性化、多轨道、长上下文和可控符号音乐填充的新型模型。该模型采用 RWKV-7 线性架构，能够在边缘设备上实现高效且连贯的音乐协同创作。MIDI-RWKV 通过微调初始状态实现了在极小样本条件下的个性化。&lt;/p&gt; 
&lt;p&gt;实验结果表明，MIDI-RWKV 在多项定量和定性指标上均优于现有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-MIDI-RWKV" src="https://oscimg.oschina.net/oscnet/up-059e2194193005d16941dfb46b2a50126d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Out-of-Distribution Semantic Occupancy Prediction&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Out-of-Distribution Semantic Occupancy Prediction&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.21185" target="_blank"&gt;https://arxiv.org/abs/2506.21185&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文为解决自动驾驶中的"意外"物体识别难题，创新性地引入 RWKV 架构来强化模型的特征感知力，并提出了 OccOoD 框架。它巧妙融合了精细的 3D 体素和全局的鸟瞰图视角，能更准确地判断异常。为了训练和验证模型，作者还独创性地构建了合成异常数据集.&lt;/p&gt; 
&lt;p&gt;实验结果表明，在不影响常规物体识别性能的前提下，实现了对未知风险的精准捕获。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250626-Out-of-Distribution Semantic Occupancy Prediction" src="https://oscimg.oschina.net/oscnet/up-541580df9785f32fdb7111c003976df721d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Vision-QRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.06633" target="_blank"&gt;https://arxiv.org/abs/2506.06633&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-07&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种量子增强的混合架构 Vision-QRWKV，用于图像分类任务。通过将变分量子电路（VQC）集成到 RWKV 的通道混合组件中，模型提升了非线性特征转换能力。&lt;/p&gt; 
&lt;p&gt;实验表明，该模型在多个医疗和标准图像数据集上表现优于经典模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250607-Vision-QRWKV" src="https://oscimg.oschina.net/oscnet/up-669a60a01e8d0426df73da6bbf8f6477034.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Diet-Seg&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.05.31.657149v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.05.31.657149v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-03&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种新型脑肿瘤分割框架 Diet-Seg，通过将基于熵的像素级难度估计与动态学习率调节策略结合，有效提升了脑肿瘤分割的准确性。Diet-Seg 框架采用 RWKV-UNet 作为主干网络，以捕捉全局空间依赖性。&lt;/p&gt; 
&lt;p&gt;实验结果表明，Diet-Seg 在 BraTS2018--2021 数据集上表现优于现有方法，特别是在肿瘤子区域的分割上取得了显著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250603-Diet-Seg Dynamic" src="https://oscimg.oschina.net/oscnet/up-4e65bcaea7495f4a3f7ef38e13fafaed70c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DiffRWKVIR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Exploring Diffusion with Test-Time Training on Efficient Image Restoration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.14541" target="_blank"&gt;https://arxiv.org/abs/2506.14541&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-17&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了 DiffRWKVIR 框架，该框架将测试时训练（TTT）与高效扩散相结合，通过 Omni-Scale 2D 状态演化扩展 RWKV 的位置依赖参数化，实现全局上下文感知，并通过块优化闪存处理加速计算，最终在图像修复任务中超越现有方法，显著提升了效率和效果。&lt;/p&gt; 
&lt;p&gt;该论文还提出了先验引导的高效扩散方法，通过提取紧凑的图像先验表示，加速了训练和推理过程，同时解决了传统扩散模型中的计算低效问题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250617-Exploring Diffusion with Test-Time Training on Efficient Image Restoration" src="https://oscimg.oschina.net/oscnet/up-185f166afa6a20a24ff6dfbff5ca302ec83.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RCME&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Relational Context Modeling for Improved Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.engineeringletters.com%2Fissues_v33%2Fissue_6%2FEL_33_6_28.pdf" target="_blank"&gt;https://www.engineeringletters.com/issues_v33/issue_6/EL_33_6_28.pdf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型和 TuckER 模型，提出了一种名为 RCME 的混合架构，用于改进知识图谱补全。RCME 结合了 RWKV 的序列建模能力和动态嵌入生成，以及 TuckER 的关系解码鲁棒性，在链接预测和三元组分类任务中表现优于多种先进模型。&lt;/p&gt; 
&lt;p&gt;实验结果表明，该架构在多个基准数据集上均取得了显著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250601-Relational Context Modeling for Improved" src="https://oscimg.oschina.net/oscnet/up-3df836cf1461d197114ffa8bce7c49241b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Med-URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.10858" target="_blank"&gt;https://arxiv.org/abs/2506.10858&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-12&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了一种名为 Med-URWKV 的纯 RWKV 架构，该架构基于 U-Net 框架构建，并融入了基于 ImageNet 的预训练，以进一步探索 RWKV 在医学图像分割任务中的潜力。&lt;/p&gt; 
&lt;p&gt;研究通过在七个数据集上的实验，验证了 Med-URWKV 在医学图像分割任务中的有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250612-Med-URWKV" src="https://oscimg.oschina.net/oscnet/up-5b67fb50ae77f12d7a02f9c6fa831e31496.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-IF&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.06.13.659654v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.06.13.659654v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种名为 RWKV-IF 的高效可控 RNA 逆折叠框架，通过将结构到序列的生成建模为条件语言建模任务，以线性复杂度捕获长程依赖关系。研究引入了一种解码策略，结合 Top-k 采样、温度控制和 G-C 含量偏向，生成结构准确且具有生物物理意义的序列。显著优于传统搜索基线方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250614-RWKV-IF" src="https://oscimg.oschina.net/oscnet/up-a3f69a2c1c24040e3bee2df1570eebd2a19.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MP-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：A Parallel Processing Architecture for Long-Term Power Load Forecasting&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F2673-4591%2F97%2F1%2F26" target="_blank"&gt;https://www.mdpi.com/2673-4591/97/1/26&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV-TS 模型提出了 MP-RWKV，通过并行处理路径解决长期电力负荷预测中不同预测范围的挑战。MP-RWKV 通过上下文状态机制和位置感知注意力机制，在短期和长期预测场景中均表现出色。&lt;/p&gt; 
&lt;p&gt;实验结果表明，MP-RWKV 在 24 小时至 432 小时的预测范围内均优于现有基准模型，尤其在传统模型性能下降的长期预测中表现突出。显著提升了长期电力负荷预测的准确性和稳定性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-A Parallel Processing Architecture for Long-Term Power Load Forecasting" src="https://oscimg.oschina.net/oscnet/up-1cd2d5a4b1ab3666aacf1439e4e1a8c45c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Blind Identification&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5297784" target="_blank"&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5297784&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV-7 序列模型提出了一种无参数的集体运动临界性识别方法，通过分析单智能体轨迹数据来检测 Vicsek 模型中的临界区域。&lt;/p&gt; 
&lt;p&gt;该方法利用预测香农熵的方差作为指标，无需系统控制参数或全局信息，成功在 L=32 和 L=64 系统中识别出临界噪声水平，且结果符合有限尺寸缩放原理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance" src="https://oscimg.oschina.net/oscnet/up-80916e606288454a3f41baab295cf426a08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;融合接收加权键值架构和球面几何特征的甲状腺结节分割方法&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：融合接收加权键值架构和球面几何特征的甲状腺结节分割方法&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biomedeng.cn%2Farticle%2F10.7507%2F1001-5515.202412009" target="_blank"&gt;https://www.biomedeng.cn/article/10.7507/1001-5515.202412009&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了一种融合接收加权键值架构（RWKV）和球面几何特征（SGF）采样技术的甲状腺结节分割方法。该方法通过二维偏移预测和像素级采样位置调整，有效捕捉邻近区域细节，实现精确分割。同时，本研究引入了区块注意力模块（PAM），利用区域交叉注意力机制优化解码器特征图，使其更精确关注编码器的高分辨率特征。&lt;/p&gt; 
&lt;p&gt;在甲状腺结节区域分割数据集（TN3K）和甲状腺影像数字数据库（DDTI）上的实验表明，本文所提方法的戴斯相似系数（DSC）分别达到 87.24% 和 80.79%，优于现有模型，且计算复杂度较低，或可为甲状腺结节精确分割提供一种高效解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-融合接收加权键值架构和球面几何特征的甲状腺结节分割方法" src="https://oscimg.oschina.net/oscnet/up-ab6be27562fe5cd66667ddfadbe4265a5c9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社区活动&lt;/h2&gt; 
&lt;h3&gt;RWKV 参加亚马逊云科技中国峰会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 19 日，RWKV 团队受邀出席于上海举办的亚马逊云科技中国峰会，并荣膺「智创未来」领航奖。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="AMZ-1" src="https://oscimg.oschina.net/oscnet/up-f86080aa51519b5f93f947f0abf82dddc3c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 参加 RTE Open Day&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 21 日至 22 日，北京，一场属于技术人的盛会------RTE Open Day 拉开帷幕。RWKV 团队与来自全国的技术爱好者和开发者们齐聚一堂，展示前沿应用，共话 AGI 的无限可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RTE Openday AGI Playground-3" src="https://oscimg.oschina.net/oscnet/up-b3b31a96ba8288b0c7b1da1bb4fc8d1d81b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 参加魔搭开发者大会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日，在国家信息中心指导、魔搭社区主办的 2025 魔搭开发者大会上，RWKV 团队受邀出席。团队与广大开发者深入分享了 RWKV 的最新进展与架构的核心亮点，共探 AI 技术的新可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="ModelScope-2" src="https://oscimg.oschina.net/oscnet/up-c4cf19d1c15dd0f606d0a8e16b9b6a283f2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 参加 GAIC 全球互联网架构大会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 14 日，在全球互联网架构大会上，RWKV 团队深度解析了 RWKV 最新架构在精度、显存占用及运算速度等方面的核心优势，并面向公众分享了简单易用的基于 RWKV 进行微调、推理与多模态开发的最佳实践。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="GIAC-1" src="https://oscimg.oschina.net/oscnet/up-62a00f9d678a10835a9faac67b61310ad08.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相上海开源创新箐英荟&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 28 日，RWKV 团队出席由上海开源信息技术协会主办的 2025 上海开源创新箐英荟，并凭借其卓越的技术贡献和活跃的社区生态，荣获主办方颁发的"优秀开源项目奖"。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-1" src="https://oscimg.oschina.net/oscnet/up-059448850eedb205228e74d972e9cc20be4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-2" src="https://oscimg.oschina.net/oscnet/up-1dccb3bfe4475ff6bdb9e7b19d5de026d95.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相国际技术进出口交易会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 11 日至 13 日，RWKV 团队携其创新成果亮相上海世博展览馆，出席（上海）国际技术进出口交易会。会上，团队向与会者展示了 RWKV 在端侧部署、低资源消耗及可持续学习等方面的卓越优势，引发广泛关注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="CSITF-1" src="https://oscimg.oschina.net/oscnet/up-aca0e633ac77f03ce72e551535a52187854.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相香港 NovaX 国际创投嘉年华&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日至 7 月 1 日，RWKV 团队登陆香港，在 NovaX Global Investmatch Carnival 国际创投嘉年华 2025 的舞台上，与全球顶尖的创投机构和行业领袖齐聚一堂，共同探讨 AI 技术的商业前景与未来机遇。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="NovaX-1" src="https://oscimg.oschina.net/oscnet/up-e8e859c258f108b8ebb09921dd3b78b4edb.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社区项目动态&lt;/h2&gt; 
&lt;h3&gt;rwkv_Ascend&lt;/h3&gt; 
&lt;p&gt;cann-ops-rwkv 是 RWKV 与升腾共建的算子仓库，欢迎 rwkv 爱好者学习、使用和魔改的 RNN attention（rwkv、fla）系列算子代码。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;项目地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fappleinsky%2Frwkv_Ascend" target="_blank"&gt;https://github.com/appleinsky/rwkv_Ascend&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;rwkv7-g1-1.5b-instruct-preview&lt;/h3&gt; 
&lt;p&gt;此项目是 RWKV7-G1 1.5B 的后训练模型，强化了指令遵循能力和中文能力，同时拥有更高的情商。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FSeikaijyu%2Frwkv7-g1-1.5b-instruct-preview" target="_blank"&gt;https://hf-mirror.com/Seikaijyu/rwkv7-g1-1.5b-instruct-preview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="RWKV7-G1-1.5B-instruct" src="https://oscimg.oschina.net/oscnet/up-beed0d3d6a0e327fb38fe4d0b43057e9996.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入 RWKV 论坛、QQ 频道和 QQ 群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 论坛：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 频道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 视频教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358194</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358194</guid>
      <pubDate>Fri, 09 May 2025 08:39:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Ubuntu Debcrafters 团队成立，旨在维护 Ubuntu 档案库健康</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Canonical 工程副总裁 Jon Seager 发文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fintroducing-debcrafters%2F63674" target="_blank"&gt;宣布&lt;/a&gt;&amp;nbsp;Ubuntu Debcrafters 团队的成立。主要目标在于维护 Ubuntu 档案库的健康，但也旨在吸引广泛的 Linux 发行版专业人才。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 表示，其鼓励 Debian、Arch Linux、NixOS 等发行版的贡献者加入 Debcrafters&amp;nbsp;团队，贡献的同时还可以获得报酬，并促进学习和想法共享。该团队由 Debian 开发人员、稳定版本更新 (SRU) 团队成员和档案管理员组成，并于 2025 年 5 月初首次开始合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-0e0b14cf8de1e9a97b9c9dba65bf6513bb0.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 在 Debcrafters 公告中解释道：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;Debcrafters 的主要使命是维护 Ubuntu 档案的健康。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;该团队将负责同步和合并来自 Debian 的软件包、审查提议的迁移问题、上游 Ubuntu 增量，并负责重大转变，例如升级到 glibc 和过去的示例，例如 t64 和 python3 转变。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他们将管理存档测试重建的调度、触发和报告，这些重建工作在我们对关键软件包进行重大更改时进行。我们在默认启用框架指针时以及切换 coreutils 到 uutilsUbuntu 25.10 中的实现时都执行了这些操作。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他们将负责 autopkgtestUbuntu 基础架构的演变和维护，并在引入更多发行版规模的集成测试方面发挥重要作用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他们将致力于改进 Ubuntu 档案库、其贡献者和状态的报告和仪表板，并对塑造我们用于构建和塑造 Ubuntu 的工具产生更广泛的兴趣。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;这支团队与桌面、服务器和基础团队的不同之处在于，他们处理的软件包范围非常广泛。Debcrafters 团队的成员每个周期都会迁移数千个软件包——其中许多软件包他们并不十分熟悉，但他们将运用不断提升的发行版维护和打包技能，在没有其他明确或现有所有者的情况下进行维护。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358188/ubuntu-debcrafters</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358188/ubuntu-debcrafters</guid>
      <pubDate>Fri, 09 May 2025 08:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软被曝将「AI 使用量」纳入员工考核，直接挂钩绩效</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-internal-memo-using-ai-no-longer-optional-github-copilot-2025-6" target="_blank"&gt;根据《商业内幕》的报道&lt;/a&gt;，微软开发者工具部门总裁 Julia Liuson 最近发出内部邮件，要求各级主管在评估员工绩效时，将其使用 GitHub Copilot 等内部 AI 工具的情况纳入考量。&lt;/p&gt; 
&lt;p&gt;Liuson 表示，AI 已成为微软日常工作的核心，就像团队协作、数据导向思维和沟通能力一样，使用 AI 不再是选择题，而是每个岗位的基本要求。她指出，员工是否有效使用 AI，应该被纳入对其整体表现和影响力的全面评估之中。&lt;/p&gt; 
&lt;p&gt;具体执行框架如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;基础合规层&lt;/strong&gt; ：要求员工在邮件撰写、会议记录、代码开发等高频场景 100% 启用 Copilot 基础功能，系统自动记录使用时长和任务覆盖率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;效能增值层&lt;/strong&gt; ：按岗位类型设定差异化 KPI，如开发人员需实现 30% 代码由 Copilot 生成，销售部门需达成 AI 优化提案的成交率提升指标。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;创新应用层&lt;/strong&gt; ：将员工使用 Copilot 开发新工作流程或业务解决方案的实践成果，纳入晋升评估加分项。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;知情人士透露，微软各团队的绩效考核标准不尽相同，目前已有部分团队考虑在下一个财年正式将 AI 工具使用情况作为绩效指标之一。另据两位了解内情的人士称，这一改变旨在应对微软内部 Copilot 服务推广缓慢的问题。微软希望提升整体使用率，也希望产品开发人员更深入理解自家 AI 工具的运作方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</guid>
      <pubDate>Fri, 09 May 2025 08:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 将其 AI 部门重组为 「超级智能实验室」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 公司首席执行官马克-扎克伯格（Mark Zuckerberg）正在重组公司的人工智能工作，以打造人工智能 「superintelligence」为中心。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fzuckerberg-announces-meta-superintelligence-effort-more-hires%3Fsrnd%3Dundefined" target="_blank"&gt;彭博社&lt;/a&gt;报道，其从该公司于周一发出的一份内部备忘录得知，Meta 公司所有从事人工智能工作的团队今后都将隶属于一个名为 Meta 超级智能实验室（Meta Superintelligence Labs）的新团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="366" src="https://oscimg.oschina.net/oscnet/up-44145dfdb97dd1159efb1314b8297ede5e1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「超级智能实验室」 将由前 Scale AI 首席执行官亚历山大・王（Alexandr Wang）担任首席人工智能官，负责整体方向与管理。他将与 GitHub 前首席执行官纳特-弗里德曼（Nat Friedman）合作，后者将负责 Meta 的人工智能产品和应用研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格一直在努力在人工通用智能（AGI）竞赛中取得领先，主要是通过收购人工智能公司和顶级人工智能公司的员工。本月早些时候，Meta 向 Scale AI 投资了 143 亿美元，并在此过程中引入了 Wang。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers" target="news"&gt;Meta 成功挖角三名 OpenAI 研究人员&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357940" target="news"&gt;OpenAI 被曝将重新调整薪酬以应对 Meta 挖人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358181/meta-superintelligence-labs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358181/meta-superintelligence-labs</guid>
      <pubDate>Fri, 09 May 2025 07:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软开源 GitHub Copilot Chat 的 VS Code 扩展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软在 5 月举办的开发者大会上&lt;a href="https://www.oschina.net/news/350732/ms-vs-code-open-source-ai-editor"&gt;宣布&lt;/a&gt;要将 VS Code 打造成开源 AI 编辑器，近日该计划达成了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fblogs%2F2025%2F06%2F30%2FopenSourceAIEditorFirstMilestone" target="_blank"&gt;首个里程碑&lt;/a&gt;——GitHub Copilot Chat 的 VS Code 扩展采用 MIT 开源许可证正式开源。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1098" src="https://static.oschina.net/uploads/space/2025/0701/153012_qXMd_2720166.png" width="2460" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-chat" target="_blank"&gt;https://github.com/microsoft/vscode-copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;该扩展提供了类似 Cursor 的 Chat 面板，通过聊天的方式来编辑代码，它还可以根据代码提交者、变量和斜线命令等信息，给出与代码库相关的回答。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a176b7fa906f848e0f9b0982762510cc49.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-190bfc8a0cc77c524892684d44d95a0f15c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;扩展地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat" target="_blank"&gt;https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;由于 Copilot Chat 与 VS Code 深度集成，其发布与 VS Code 同步进行，因此每个新版本的 Copilot Chat 仅兼容最新版本的 VS Code。这意味着如果你使用的是旧版本的 VS Code，将无法使用最新的 Copilot Chat。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358178</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358178</guid>
      <pubDate>Fri, 09 May 2025 07:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节、腾讯、阿里等 13 家头部企业去年利润总额同比增 19.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;5 月底结束的 2024 年度企业所得税汇算清缴数据显示，字节跳动、腾讯、阿里巴巴等 13 家头部企业营业收入和利润总额同比分别增长 11.9%、19.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上述企业是数字经济领域的代表企业，汇算清缴数据显示，2024 年度，数字经济及其核心产业营业收入和利润总额同比分别增长 5.9%、2.7%。其中，信息传输、软件和信息技术服务业营业收入和利润总额同比分别增长 11.5%、13.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除数字经济外，2024 年度，医药制造、航空航天等高技术产业营业收入和利润总额同比分别增长 8.9%、7.5%。细分行业看，科学研究和技术服务业营业收入和利润总额同比分别增长 11.7%、7.5%，航空航天产业营业收入和利润总额同比分别增长 10.5%、26.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，机器人产业也步入发展快车道，近两年机器人产业营业收入平均同比增长 10.2%。其中，特殊作业机器人、服务消费机器人、工业机器人 2024 年度同比分别增长 28.4%、12.4%、7%，多场景应用加速落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;总体上看，数字经济、高技术产业、机器人产业三个领域 2024 年度共减免企业所得税 1.97 万亿元，总营业收入同比增长 7.1%，利润总额同比增长 5.2%，我国新质生产力持续发展壮大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;国家税务总局相关负责人表示，税务部门将不折不扣落实落细结构性减税降费政策，同时，依法严厉打击违规享受、恶意骗取税费优惠等违法行为，坚决防止政策「红包」落入不法分子「腰包」。（新京报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358163</guid>
      <pubDate>Fri, 09 May 2025 06:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁数科面向香港市场开放四大自研技术</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁数科面向香港市场开放四大自研技术——Layer2 网络、大模型开发工具、「区块链+IoT」可信架构、机构级 Web3 钱包技术，为香港建设全球数字资产创新中心提供全栈技术服务。&lt;/p&gt; 
&lt;p&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-e94b03fe5b81530ba178b109352a29a4037.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;资料显示，蚂蚁数科自 2016 年起投入区块链技术研发，全球区块链授权专利排名第一，核心技术如智能合约、网络传输、存储引擎、跨链技术等已取得重大突破，处于全球领先水平。此前，蚂蚁数科作为核心成员加入香港金管局 Ensemble 沙盒，并宣布将海外总部落户香港。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358160</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358160</guid>
      <pubDate>Fri, 09 May 2025 05:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>加锁失效，非锁之过，加之错也</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：京东零售，邢成&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;多个进程或线程同时 (或着说在同一段时间内) 访问同一资源会产生并发问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;银行两操作员同时操作同一账户就是典型的例子。比如 A、B 操作员同时读取一余额为 1000 元的账户，A 操作员为该账户增加 100 元，B 操作员同时为该账户减去 50 元，A 先提交，B 后提交。 最后实际账户余额为 1000-50=950 元，但本该为 1000+100-50=1050。&lt;strong&gt;这就是典型的并发问题&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;从事零售供应链库存业务，对库存数量操作增减十分频繁，同样存在类似上述银行取款遇到的问题，库存数量操作有误势必给前台销售产生损失影响，因此需要关注对库存数量并发操作下的一致性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;下面通过一个真实的案例分享在并发情况下如何保证库存数量的准确性。&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;问题是什么-加锁失效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;看看下面这段流程和代码，思考会有并发问题吗？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c52b6c3f660ed58046c9e16a5be9c444.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;加锁前&lt;/strong&gt; &lt;strong&gt;，获取箱子明细数据，此处在锁之外，存在并发脏读问题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//1036ef25fae37b26c448522f6777c80c.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;加锁后&lt;/strong&gt; &lt;strong&gt;，并进行箱子上架分批次回传业务处理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//020a84a9615ca8e8cec22118aefca76f.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;加锁后，&lt;/strong&gt; &lt;strong&gt;更新箱子明细上架数量逻辑：已上架数量 = 加锁前的明细数据（脏读） + 报文回传的明细数据，直接进行行更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//21d80ae4a594960a582dde2c19321099.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;原因是什么-加锁的位置不正确&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//20d9ce564f5386039bb12242e16ef05b.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心的问题原因&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;业务分布式锁失效：&lt;/strong&gt; 使用分布式锁加锁了，但是仍然使用加锁前查询的数据，导致出现脏读&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;Mysql 锁失效：&lt;/strong&gt; 数据库更新时，未上任何锁，导致脏读的数据直接覆盖更新当前行&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有同学这时问了，为啥防重码也没有生效呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;防重码主要是用作幂等逻辑的，同一个请求多次处理，结果仍然是相同的。&lt;/p&gt; 
&lt;p&gt;但是这是两次不同的请求，防重码是不同的，因此不能只依赖防重码保证一致性。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;解决方案有哪些&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1、代码层面：&lt;/strong&gt; 使用锁（如互斥锁、读写锁、分布式锁等）来控制资源的访问，数据获取的全部操作都需要再获取锁后才进行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;将获取箱子明细的代码移动到加锁之后，只有获取到分布式锁，才能执行分批次上架查询和更新（串行化）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5ffc0121557805521cbb33921c4be06a.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;对应改造后的代码：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//751c2001d8d70843f24dcf8b6fa5eaa6.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、数据库层面：&lt;/strong&gt; 实现事务管理，确保数据的一致性；合理设置事务隔离级别，以防止脏读、或者采用乐观锁或悲观锁来处理并发更新，合理设计查询效率，减少锁竞争。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;数据库的并发上锁处理和业务代码的上锁是互补的关系&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;因为无法保证后续业务的调整或其他业务代码的调用能始终保持获取数据的一致性，数据库的并发上锁处理更多是一种兜底保证机制。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;乐观锁更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e4262e1d681aa19763c8066296032481.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;悲观锁更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4078a93beef3c9b077595bb8968b3a5d.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;扩展方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;应用程序设计：&lt;/strong&gt; 在应用程序设计阶段，尽量避免长时间持有数据库连接或事务，减少并发操作的可能性，利用 AI 代码评审或者人工提前找出可能出现并发问题的地方；合理设置锁的粒度，避免锁失效。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;网络负载层面：&lt;/strong&gt; 采用限流控制访问频率；采用分布式数据库，进行数据分片，降低单节点并发压力；使用负载均衡，将网络请求分发到不同的服务器，提高系统处理并发的能力，防止系统过载。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;请求层面：&lt;/strong&gt; 前端点击防重、系统幂等防重、尽可能降低同一请求的多次重试访问引起的一致性问题。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;通过以上措施，可以在不同层面有效地防止并发问题，保证系统的数据的一致性。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18638221</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18638221</guid>
      <pubDate>Fri, 09 May 2025 03:26:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>通义千问 Qwen-TTS 新增支持北京话、上海话和四川话中文方言</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通义千问团队更新并&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-VDOJrDgVzC6JI4CVTHe4w" target="_blank"&gt;上线&lt;/a&gt;了 Qwen-TTS 文本转语音服务，&amp;nbsp;新增支持生成三种中文方言，包括北京话、上海话和四川话。&lt;/p&gt; 
&lt;p&gt;据介绍，Qwen-TTS 使用了超过 300 万小时的大规模语料库进行训练，合成效果达到了人类级别的自然度和表现力，旨在提供超自然、富有表现力的音频，并能智能处理韵律、语速和情感。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Qwen-TTS 能够根据输入文本自动调整韵律、节奏和情绪变化，进一步提升语音的真实感和表达力。&lt;/p&gt; 
&lt;p&gt;目前，Qwen-TTS 支持七种中英双语音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京话）、Jada（上海话） 和 Sunny（四川话）。未来，我们还将推出更多语言和语音风格，进一步丰富用户的选择体验。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fblog%2Fqwen-tts%2F" target="_blank"&gt;https://qwenlm.github.io/blog/qwen-tts/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358128/qwen-tts</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358128/qwen-tts</guid>
      <pubDate>Fri, 09 May 2025 03:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
