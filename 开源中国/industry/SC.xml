<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 21 Jun 2025 16:45:47 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>新一代小游戏图形渲染技术 WebGE 首发！助力小游戏开发更高效</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;6 月 21 日，华为开发者大会 2025（HDC 2025）游戏服务分论坛在广东东莞松山湖成功举办。众多游戏开发者、行业领军人物及生态合作伙伴齐聚一堂，聚焦「新机遇、新体验、新服务，鸿蒙创新技术赋能游戏产业」主题，展开深度交流与研讨。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;中国音像与数字出版协会常务副理事长兼秘书长敖然出席分论坛活动并表示，鸿蒙在数字化发展的浪潮中经受住了时间的挑战，逐步走向成熟。同时，他还鼓励更多的游戏开发者加入到鸿蒙生态中来，「希望有更多富有创意和品质的鸿蒙游戏创作涌现出来，为玩家带来更加丰富的游戏体验，共同推动游戏行业的创新发展和繁荣进步。」&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1.jpg" height="467" src="https://oscimg.oschina.net/oscnet//92214fd40953f6979dc76b7ad250cc21.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;华为终端云服务互动媒体 BU 总裁张思建表示，华为游戏中心将为开发者提供一站式的赋能服务，同时，面向全场景、小游戏、大联运和出海等全新的鸿蒙游戏激励计划也在持续升级，鼓励开发者结合鸿蒙系统特性进行创新，构建全媒体流量矩阵，实现全场景智慧化分发，触达亿级的游戏玩家。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="2.jpg" height="467" src="https://oscimg.oschina.net/oscnet//cd08ed7fcd687699c20e38ea386be4f1.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;新机遇：全场景机遇迸发，激活游戏用户全域价值&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;过去一年，鸿蒙游戏生态发展迅速，截至目前，已有超 4900 款鸿蒙游戏上架。这一数字不仅是量的积累，更是整个游戏产业协同共进、创新突破的生动见证。立足当下，鸿蒙为游戏产业带来的全新机遇正全面迸发。鸿蒙系统实现「一次开发、多端部署」的技术突破，让游戏开发者得以跨越手机、电脑、智能穿戴设备等全场景终端，将优质内容精准触达全域用户，带来全新的用户增长机遇。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="3.jpg" height="467" src="https://oscimg.oschina.net/oscnet//3415cf7293a5f164308d34ac246458e2.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;国产黑马刷宝爽游《英勇之地》商务负责人在本次分论坛分享了鸿蒙全场景游戏实践经验，《英勇之地》手游于 5 月首发上线鸿蒙平台，同时完成了 PC 版对鸿蒙电脑的全方位技术适配。借势鸿蒙生态丰富的分发场景与成熟的首发运营方案，《英勇之地》在首发阶段斩获亮眼成绩，首周流水 300 万+，其中鸿蒙平台占比 30%，预约转化率高达 40%。由此可见，鸿蒙全场景生态的流量红利，正在为游戏用户增长带来全新机会点。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="4.jpg" height="467" src="https://oscimg.oschina.net/oscnet//9264fede42687ab0b6c4fbdecff975c6.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;作为游戏产业重要增量的小游戏赛道，在华为小游戏焕新升级下也迎来了全新机遇。华为小游戏持续优化接入流程、强化开发套件、完善联运体系，助力开发者高效融入鸿蒙游戏生态。同时进阶小游戏产品能力，完成小游戏从即点即玩到即时转化的增长路径，助力开发者抢滩小游戏百亿市场。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;针对内容驱动型的独立游戏，华为游戏中心专业的内容阵地和全生命周期服务支持，为其创造了更广阔的发展空间和更有利的成长环境。华为游戏中心还上线独立游戏专区，构建多维游戏分发阵地，直达目标用户群体，不断推动独立游戏掌握全场景时代新的流量机遇，塑造独立游戏的流量新场域。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;如今，随着鸿蒙生态的快速壮大和用户基数的增长，越来越多的游戏厂商加速布局鸿蒙，众多新游选择首发上线鸿蒙版本，抢占用户增长新机遇。对此，华为游戏中心也推出全新的鸿蒙游戏激励政策体系，包括游戏鸿飞计划、全场景创新激励等，从技术支持到流量倾斜，全方位助力优质内容绽放光彩，助力游戏开发者加速商业成功。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;新体验：游戏体验革新，内容+玩法焕新用户感知&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;在用户感受层面，鸿蒙游戏生态致力于突破交互边界，创造极致体验。华为游戏中心精心打磨优质内容社区，承载专业游戏内容，满足玩家高效获取优质内容的需求，并为游戏开发者提供广阔展示游戏内容的生态平台和内容矩阵。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="5.jpg" height="467" src="https://oscimg.oschina.net/oscnet//19820a8e31920af7eedaf7f1409a1bea.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;「看」游戏，更专业的游戏内容，整合玩家真实测评、开发者创作心路等深度内容，让游戏故事更生动可感；「找」游戏，更智能的搜索推荐，优化搜索功能，通过标签查找、专题查找和搜索专区，让优质游戏更容易被发现；「玩」游戏，更贴心的游戏助手，完善游戏工具、我的资产和 AI 问答等功能，激发玩家主动探索的热情。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;同时，更具创新性与趣味性的鸿蒙创新特性，已被纳入多款游戏的开发规划蓝图：《英勇之地》《NBA 巅峰对决》在分论坛分享了近场快传创新实践经验，无需网络下载，借助鸿蒙分布式软总线技术，实现游戏资源包在手机之间的高速传输。玩家之间只需轻触设备，即可分享游戏资源包，相比网络下载速提升 3 倍；而经典国风手游《浮生忆玲珑》即将基于鸿蒙创新特性，推出桌面萌宝版，将创新互动卡片添加至桌面，内置多种轻互动玩法，在桌面养娃，将游戏轻量化体验融入玩家日常，让游戏与生活无缝衔接；弹幕射击类游戏《雷电：觉醒》则深度契合小游戏玩家碎片化时间娱乐需求，上线华为小游戏 App，无需下载也能体验 90 帧超流畅画质，点击秒开畅玩，以轻量化社交玩法激活玩家活跃度。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="6.jpg" height="466" src="https://oscimg.oschina.net/oscnet//4bfca420c2fe4781247df218f108e66d.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;新服务：全栈式服务调优，推动游戏创意高质量落地&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;在开发者服务领域，华为游戏中心始终以全生命周期护航者的角色，与开发者并肩前行。一站式的鸿蒙游戏开发者服务（HGS）为开发者带来了赋能套件、运营服务、技术能力、商务政策等全方位的服务，覆盖开发—分发—运营全流程，助力行业伙伴抢占鸿蒙生态发展先机。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;本次分论坛上，《QQ 飞车》手游引擎负责人分享了《QQ 飞车》与 HGS 游戏性能调优技术合作与探索的经验。通过 HiSmartPerf 调优工具，能快速定位游戏渲染问题，针对游戏运行性能数据，如 CPU、GPU、功耗等进行深度分析，打造更高性能、更稳定的游戏产品。华为游戏中心还提供多种降功耗服务，包括插帧，二进制优化，游戏场景感知，以及专家诊断服务等，通过这些优化手段，《QQ 飞车》游戏综合功耗在不同场景下最高可下降 20%。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="7.jpg" height="467" src="https://oscimg.oschina.net/oscnet//aa00e09f55170c8c36855a0e7bedca6f.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;针对开发者关注的小游戏开发领域，华为游戏中心首发新一代小游戏图形渲染技术 WebGE，WebGE 在小游戏领域实现 WebGPU 标准，为小游戏提供更优体验。基于 WebGE 的渲染性能优化，开放冒险小游戏《曙光重临》3D 实时光影渲染帧率提升 30%，场景切换更流畅；3D 弹幕射击小游戏《雷电：觉醒》以更低功耗突破 90 帧功耗降低 15%，性能更稳定，画质更流畅。WebGE 图形渲染技术的发布，助力小游戏实现更炫酷的渲染效果，从而激发小游戏设计的无限想象空间。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="8.jpg" height="466" src="https://oscimg.oschina.net/oscnet//9ac20692852f5cade6968ddffb3b34a5.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;此外，华为游戏中心还积极搭建开发者成长平台，通过行业大咖分享、实战培训、创新大赛等系列活动，为开发者提供学习交流、竞技展示的舞台。HDC 期间，鸿蒙生态最大规模开发者官方赛事 2025 HarmonyOS 创新赛正式公布赛制，最高可获百万激励。大赛设置游戏创新专项奖，从参赛作品的创新玩法、技术深度、视觉表现等多维度设置评分标准，鼓励游戏开发者基于 HarmonyOS 新技术开拓创新，孵化游戏创意。&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="9.jpg" height="467" src="https://oscimg.oschina.net/oscnet//2dd837d46d35c4fdb551bcbc5a4827f2.jpg" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;鸿蒙游戏生态的每一次突破，都凝结着开发者的智慧与汗水。无论是《NBA 巅峰对决》通过近场快传技术实现的秒级资源共享，还是《雷电：觉醒》在 WebGE 图形渲染技术的加持下无需下载也能保持 90 帧超流畅画质，都在印证：鸿蒙生态绝非孤军奋战的孤岛，而是多方共赢的命运共同体。未来，华为游戏中心将与开发者继续携手，深耕技术创新，优化用户体验，完善服务生态，培育更多兼具品质与创意的精品游戏，共同书写游戏产业高质量发展的崭新篇章。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356582</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356582</guid>
      <pubDate>Sat, 10 May 2025 06:44:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>中国软件基因库 Gitee，如何扛起民营科技企业时代使命</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;当今世界格局，全球化退火，大国博进入弈白热化，内循环成为主战场，在此百年未有之大变局下，民营企业必须「跟随国家战略」，成为国家「政府、国企、民企战略共同体」中的重要一员，才能分享新一轮政策与市场红利。&lt;/p&gt; 
&lt;p&gt;开源中国于 2013 年发布代码托管平台 Gitee，是国内领先的代码托管服务平台，并于 2020 年牵头建设工信部国家开源托管平台项目。Gitee 于 2017 年上线发布针对企业级的研发效能平台 Gitee 企业版。同时，开源中国自 2020 年起开始深耕 DevOps 全生命周期产品国产替代方案，在满足开发者需求的同时，打造出一个自主创新、安全可信的本土开源软件工具与生态，减少开发者对海外开源软件的过度依赖，构建安全可控的中国信息化体系。&lt;/p&gt; 
&lt;p&gt;Gitee 以「国家代码库备份」和「国产替代」双核驱动，扛起民营科技企业的时代使命：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span style="color:#e67e22"&gt;国家代码库备份：&lt;/span&gt;&lt;/strong&gt;构建国内最大、最安全、最全量的开源代码备份网络，承担「国家级软件基因库」职责。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span style="color:#e67e22"&gt;国产替代先锋：&lt;/span&gt;&lt;/strong&gt;深度兼容国际前沿技术生态，坚持走信创自主可控道路，实现从源码托管到 DevOps 工具链的全流程国产替代。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;以备份能力筑牢「数字长城」&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;「备份战略下的产业复制和转移」是未来民企获取红利的重要通道。Gitee 的「多中心异地容灾、多维度镜像同步」体系，正是这一战略在代码领域的具象化：&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;千万仓库一键同步：&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;与 GitHub、GitLab 等全球主流平台实时镜像，同步延迟低于数分钟，解决境外访问不稳、政策风险及突发故障带来的断链隐患。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;数据主权·安全可控：&lt;/strong&gt;&amp;nbsp;&lt;/span&gt;完全自主研发的加密存储与访问控制，从底层保障代码资产的主权与机密性。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;智能完整性检测：&lt;/strong&gt;&amp;nbsp;&lt;/span&gt;引入 AI 驱动的代码健康扫描，定期校验、自动修复，构筑「代码防火墙」，确保备份仓库的可用性与可信度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/163359_FY3B_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/163412_u877_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;深耕 DevOps 全生命周期国产替代&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;新一轮「国产替代」浪潮正加速推进，民企要「成为国家战略性新兴产业的先锋」 。Gitee 立足国产基础设施，自 2020 年以来，深耕 DevOps 全生命周期国产替代方案，在满足开发者需求的同时，打造出一个自主创新、安全可信的本土开源软件工具与生态，减少开发者对海外开源软件的过度依赖，构建安全可控的中国信息化体系。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/163442_nIuC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/163451_0aZV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;全链路国产化：&lt;/strong&gt;&lt;/span&gt;从托管、CI/CD、制品仓库到安全审计、项目管理，提供与国际同级、符合合规要求的一站式开发运营平台。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;生态互联互通：&lt;/strong&gt;&lt;/span&gt;与阿里云、华为云、腾讯云等国产云厂商深度集成，构建覆盖操作系统、数据库、网络安全等全栈国产软件图谱。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;本土化社区运营：&lt;/strong&gt;&lt;/span&gt;用中文场景深度激励高校与企业工程师参与开源，培养中国软件创新的「基因土壤」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;展望未来：让 Gitee 成为中国软件基因银行&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;作为中国开源基础设施奠基者，开源中国运营着 1800 万开发者聚集的 &lt;a href="https://oschina.net/"&gt;oschina.net&lt;/a&gt; 社区及代码托管平台 Gitee，服务 36 万企业级用户。开源中国自主研发的 DevOps 工具链已在金融、军工等关键领域实现 80% 市场渗透率，成为信创替代工程的标杆案例，验证了开源商业化的中国路径。&lt;/p&gt; 
&lt;p&gt;2024 年，开源中国推出对标 HuggingFace 的 AI 大模型平台 "模力方舟 (&lt;a href="https://ai.gitee.com/" target="_blank"&gt;moark.com&lt;/a&gt;)"，首创 "模型数据 - 算力调度 - 应用开发" 全栈服务体系。&lt;/p&gt; 
&lt;p&gt;平台已实现三大突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;生态开放化&lt;/strong&gt;：&lt;/span&gt;聚合数万开源模型，打造 AI 应用创新基座；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;服务一体化&lt;/strong&gt;：&lt;/span&gt;提供从模型体验、推理训练到应用部署的全生命周期服务；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;算力国产化&lt;/strong&gt;：&lt;/span&gt;完成多家国产 GPU 深度适配，成功运行 DeepSeek-V3 等千亿级模型。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;开源中国下一步将以模力方舟为核心，打造全方位的 AI 业务布局，助力 AI 应用创新、科技人才培养和新质生产力提升。在「十四五」「十五五」规划与「碳中和」「数字中国」等国家战略的交汇期，Gitee 将继续：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;升级备份体系&lt;/strong&gt;：&lt;/span&gt;引入更智能的灾备演练与灾后恢复机制，让「国家级代码基因库」永不缺席。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;引领国产替代&lt;/strong&gt;：&lt;/span&gt;与更多国产厂商共建联动机制，推动开发工具、语言运行时、操作系统等关键层面全面国产化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#e67e22"&gt;&lt;strong&gt;深耕社会价值&lt;/strong&gt;：&lt;/span&gt;在稳就业、促消费方面持续发力，让技术创新与社会发展形成良性循环。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;让我们携手，把握「备份与国产替代」的时代脉搏，让 Gitee 不仅是「中国版 GitHub」，更是中国软件基因库的守护者与创新引擎，共筑数字中国新未来！&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356519</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356519</guid>
      <pubDate>Fri, 09 May 2025 14:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linux libblockdev 本地提权漏洞</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;漏洞描述&lt;/h2&gt; 
&lt;p&gt;libblockdev 是 Linux 上用于块设备管理的底层库，提供统一接口支持分区、文件系统、LVM 和加密等操作。udisks 是基于 D-Bus 的服务，封装调用 libblockdev 等工具，为桌面环境和应用程序提供挂载、格式化等存储管理功能。&lt;/p&gt; 
&lt;p&gt;受影响版本中，libblockdev 在挂载磁盘分区时遗漏 nosuid 安全标志，导致可在挂载点执行具备特殊权限（如 root 权限）的文件。攻击者拥有 allow_active 权限时，可利用该缺陷挂载恶意文件并执行，进而获取 root 权限。&lt;/p&gt; 
&lt;p&gt;由于 libblockdev 默认在较多 Linux 发行版中提供，该漏洞影响 Ubuntu、Debian、Fedora、openSUSE 等主流发行版，但由于 allow_active 权限限制，通常难以单独利用，在 SUSE 系统中可结合 CVE-2025-6018 漏洞可将 ssh 远程低权限用户提升为 allow_active 用户实现远程利用。&lt;/p&gt; 
&lt;p&gt;修复版本通过弃用系统默认挂载选项，显式添加 nosuid 和 nodev，防止本地提权漏洞。&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;漏洞名称&lt;/th&gt; 
   &lt;th&gt;Linux libblockdev 本地提权漏洞&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;漏洞类型&lt;/td&gt; 
   &lt;td&gt;权限管理不当&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;发现时间&lt;/td&gt; 
   &lt;td&gt;2025-06-19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;漏洞影响广度&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MPS 编号&lt;/td&gt; 
   &lt;td&gt;MPS-mqf0-usbi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CVE 编号&lt;/td&gt; 
   &lt;td&gt;CVE-2025-6019&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CNVD 编号&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;影响范围&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;libblockdev-lvm-dbus@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-lvm-dbus@影响所有版本&lt;/li&gt; 
 &lt;li&gt;python3-blockdev@影响所有版本&lt;/li&gt; 
 &lt;li&gt;python3-blockdev@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-crypto@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-dm@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-btrfs-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-kbd@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-lvm@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mpath@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mpath-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-crypto-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-btrfs@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-kbd-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-loop@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mdraid@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mdraid-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-nvdimm-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-plugins-all@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-swap@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-dm-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-fs@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-fs-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-loop-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-nvdimm@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-lvm-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-part@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-s390@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-swap-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-part-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-utils@影响所有版本&lt;/li&gt; 
 &lt;li&gt;python2-blockdev@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-s390-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-vdo@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-utils-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-vdo-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-btrfs@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-btrfs-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-fs-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-loop-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mdraid-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-part@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-s390@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-crypto@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-crypto-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-kbd-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-loop@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mpath-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-nvdimm-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-kbd@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-lvm@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mpath@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-dm@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-dm-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-fs@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-lvm-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-mdraid@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-nvdimm@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-plugins-all@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-part-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-s390-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-utils@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-vdo-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-utils-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;python2-blockdev@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-swap-devel@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-vdo@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev-swap@影响所有版本&lt;/li&gt; 
 &lt;li&gt;libblockdev@(-∞, 2.30)&lt;/li&gt; 
 &lt;li&gt;libblockdev@[3.0, 3.2.2)&lt;/li&gt; 
 &lt;li&gt;libblockdev@[3.3.0, 3.3.1)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;修复方案&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;将组件 libblockdev 升级至 2.30 及以上版本&lt;/li&gt; 
 &lt;li&gt;将组件 libblockdev 升级至 3.2.2 及以上版本&lt;/li&gt; 
 &lt;li&gt;将组件 libblockdev 升级至 3.3.1 及以上版本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oscs1024.com%2Fhd%2FMPS-mqf0-usbi" target="_blank"&gt;https://www.oscs1024.com/hd/MPS-mqf0-usbi&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fstoraged-project%2Flibblockdev%2Fcommit%2F4e35eb93e4d2672686789b9705623cc4f9f85d02" target="_blank"&gt;Commit&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;    &lt;/p&gt; 
&lt;h2&gt;免费情报订阅&amp;amp;代码安全检测&lt;/h2&gt; 
&lt;p&gt;OSCS 是国内首个开源软件供应链安全社区，社区联合开发者帮助全球顶级开源项目解决安全问题，并提供实时的安全漏洞情报，同时提供专业的代码安全检测工具为开发者免费使用。社区开发者可以通过配置飞书、钉钉、企业微信机器人获取一手的情报。&lt;/p&gt; 
&lt;p&gt;免费代码安全检测工具： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.murphysec.com%2F%3Fsrc%3Dosc" target="_blank"&gt;https://www.murphysec.com/?src=osc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;免费情报订阅： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oscs1024.com%2Fcm%2F%3Fsrc%3Dosc" target="_blank"&gt;https://www.oscs1024.com/cm/?src=osc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;具体订阅方式详见： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oscs1024.com%2Fdocs%2Fvuln-warning%2Fintro%2F%3Fsrc%3Dosc" target="_blank"&gt;https://www.oscs1024.com/docs/vuln-warning/intro/?src=osc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4aeef4048430ca1baea7afb51fe0f5dc3dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356507</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356507</guid>
      <pubDate>Fri, 09 May 2025 12:53:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>鸿蒙正当时 | HarmonyOS 开发者实战工坊上海站圆满收官</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;2025 年 6 月 20 日，中国上海 —— HarmonyOS 开发者实战工坊·开发者系列沙龙在热烈的技术交流氛围中圆满收官。本次活动吸引了众多开发者齐聚一堂，通过主题演讲、实战经验分享与大咖深度互动，共同探讨鸿蒙生态发展的前沿趋势与核心技术，现场交流热烈，创新思维涌动，参与者纷纷表示收获颇丰。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-92573b770811fcedec1e6c65b07d5b90c99.jpg" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;「鸿蒙为开发者构建了一个天然的平台，超越单一平台限制，助力开发者构想和创造服务于多设备互联、高可靠环境的创新应用。希望通过共创协作，我们能够相互成就，共同成长！」上海对外经贸大学开源创新与数字治理研究院院长、上海开源信息技术协会创始人张国锋先生为活动致辞。&lt;/p&gt; 
&lt;p&gt;张国锋也进一步阐述时代机遇：这是一个万物互联、场景融合的时代。传统的设备界限正被打破，用户期待的是无缝流转、高度协同的智慧体验。鸿蒙操作系统，以其与生俱来的分布式基因和对全场景连接的深刻理解，正在为这场深刻的范式转变奠定基础。这样的技术趋势，为我们每一位开发者，尤其是金融、互联网等各行各业的应用开发者们，开启了前所未有的机遇之门。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-f836c5b077897b1d15ebc8cb5d23924b1b3.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在深度洞察行业趋势的开篇之后，活动话题随即转向技术实践深度分享。 三位重量级技术专家轮番登场，分别从不同维度深入剖析鸿蒙应用开发的关键领域，涵盖生态背景、发展趋势、核心技术指引及典型应用案例，为开发者提供了落地的实战参考。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#27ae60"&gt;鸿蒙应用生态发展趋势：未来已来，共筑无限可能&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#27ae60"&gt;&lt;img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-ba33e0acae2e9aada90a922fd0ec9c2fbbd.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;中国科学院软件研究所高级工程师、资深鸿蒙应用研发专家贾文洋发表《鸿蒙应用生态发展趋势：未来已来，共筑无限可能》主题演讲。贾文洋在演讲中指出，鸿蒙生态发展获得了有力的政策支持。他提到，国际形势变化凸显了构建自主技术生态的重要性，国家层面明确要求坚持技术创新、培育鸿蒙生态、倡导开源合作。2025 年 4 月 18 日，工信部通信发展司司长讲话中，明确强调推动更多 APP 上架鸿蒙应用商店的重要性，将通过推动应用上架、支持开源共建、加速场景融合三大举措，构建中国数字经济的底层基础设施。&lt;/p&gt; 
&lt;p&gt;地方层面，作为中国的金融中心，上海拥有活跃的金融产业，而金融产业的发展与科技创新密不可分，鸿蒙生态在上海已开始实现规模化发展，已有约 500 款上海鸿蒙应用实现升级上架，助力上海加速迈向万物智联时代。作为中国数字化、智能化转型的前沿阵地，上海与鸿蒙的双向奔赴，无疑将给各地拥抱鸿蒙生态形成示范效应。&lt;/p&gt; 
&lt;p&gt;在此背景下，贾文洋指出，鸿蒙开发工具正持续迭代，通过技术的不断演进给开发者带来越来越便捷的开发体验。&lt;/p&gt; 
&lt;p&gt;比如，DevEco Studio 是鸿蒙官方推荐的集成开发工具，伴随 HarmonyOS 系统的发展不断迭代更新；ArkTS 在保持 TypeScript 基本语法风格的基础上，进一步通过规范强化静态检查和分析，在程序运行之前的开发期能检测更多错误，推出状态管理 V2，进一步提升运行时性能；跨平台开发方面，鸿蒙 Next 有 musl libc，有标准 POSIX API，有 Clang/LLVM，有 GN/ninja，Flutter 的最大优势之一是其优异的性能表现，热重载 RN 的性能取决，于 JavaScript 桥接机制的实现和优化程度；此外还有 AI 技术的加持，通过控件 AI 化，可以打造智能应用……&lt;/p&gt; 
&lt;p&gt;谈及开发者生态建设，贾文洋介绍了华为构建的多层次交流与成长平台，如华为开发者组织 HDG、全球性的华为开发者大会 HDC、HarmonyOS Connect 伙伴峰会、华为校园开发者组织 HSD 等。在产业生态方面，贾文洋展示了鸿蒙终端的广泛应用前景。鸿蒙操作系统已覆盖手机、平板、手表、智慧屏、车机等多种设备，其分布式架构实现了无缝协同。&lt;/p&gt; 
&lt;p&gt;最后，贾文洋也表示，鸿蒙生态建设正迎来前所未有的发展机遇，相信鸿蒙能够成为最大的操作系统，呼吁广大开发者积极加入鸿蒙生态，共同开拓未来。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#27ae60"&gt;Flutter 与鸿蒙的高效融合——应用适配实战解析&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#27ae60"&gt;&lt;img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-cde48d7adad68a7632408bf18525650dd0c.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;锅圈食品（上海）股份有限公司开发经理、华为 HDG 核心组织者王阳科发表《Flutter 与鸿蒙的高效融合——应用适配实战解析》主题演讲，系统介绍了跨平台框架 Flutter 在鸿蒙系统的适配方案与技术路径。&lt;/p&gt; 
&lt;p&gt;王阳科指出，Flutter 与鸿蒙融合具备三大优势。首先是性能提升，Flutter 的 Skia 自绘引擎在鸿蒙设备可实现高效图形渲染，结合 JIT/AOT 编译模式保障应用流畅性；鸿蒙分布式架构更支持跨设备协同能力。第二是跨平台优势，包括单套代码可覆盖 iOS、Android 及鸿蒙多平台，在保持 UI 一致性的同时通过平台通道调用原生功能。第三是开发效率的提升，包括热重载功能缩短开发周期，现有 Flutter 代码经适配可快速生成鸿蒙版本，鸿蒙 Next 的混合开发模式进一步降低维护成本。&lt;/p&gt; 
&lt;p&gt;具体到适配流程方面，王阳科也做了关键节点的拆解。首先是 Flutter 工程：提供一个跨平台的应用基础，便于后续与鸿蒙系统的集成 。通过鸿蒙能力扫描，确定鸿蒙系统中有哪些能力可以被 Flutter 工程调用和利用，为后续的适配工作提供基础信息。然后进行缺失能力分析，明确需要额外开发或适配的部分，以便后续步骤进行补充和完善。紧接着是三方库适配层，弥补鸿蒙系统中缺失的能力，确保 Flutter 工程在鸿蒙系统上能够完整地实现其功能。再通过原生通信通道，建立一个可靠的通信桥梁，使 Flutter 工程能顺利地调用鸿蒙系统的能力，并接收返回的数据。最后进行鸿蒙组件注入，增强 Flutter 应用在鸿蒙系统上的原生体验，提升应用的性能和功能丰富度。&lt;/p&gt; 
&lt;p&gt;为了帮助开发者更好地理解适配过程，王阳科以获取设备定位为例，演示插件开发全流程：在 Flutter SDK 插件库的鸿蒙端适配案例中，获取设备定位功能的实现分为通信框架构建与定位功能开发两阶段。首先需通过 MethodChannel 建立双向通信机制：在鸿蒙端创建专属插件文件并实现定位功能逻辑，随后在 Ability 中注册该插件。当 Flutter 调用鸿蒙端功能时，通过预置通信渠道触发定位操作并接收返回数据。&lt;/p&gt; 
&lt;p&gt;通过技术讲解和多个案例演示，也证明了 Flutter 与鸿蒙融合可充分发挥跨平台开发效率与原生系统能力优势；标准化适配流程降低多平台维护成本；原生组件注入方案为生态拓展提供新路径。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#27ae60"&gt;安全与高效并存——金融领域鸿蒙开发案例浅析&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#27ae60"&gt;&lt;img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-3587d930d01133307cf1206ff8112d87891.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;资深全栈开发专家、HarmonyOS 生态践行者蒋天泓发表《安全与高效并存——金融领域鸿蒙开发案例浅析》主题演讲，向开发者展示了鸿蒙系统在金融场景的深度实践成果。&lt;/p&gt; 
&lt;p&gt;蒋天泓介绍，根据国际数据公司 (IDC)，2023 年银联报告显示移动端交易占比显著，到 2025 年银行客户超过 80% 的流量将通过手机 APP 实现，移动端交易成为主流。根据人行数据，2024 年，银行共处理电子支付 11 业务 3016.68 亿笔，其中移动支付业务 2109.80 亿笔，70% 的交易都在移动支付业务中产生。金融行业需覆盖银行、证券、保险等全场景，多终端协同需求激增，以满足客户多样化的金融服务需求。&lt;/p&gt; 
&lt;p&gt;面对如此庞大的交易规模，鸿蒙系统为金融业务构建了安全底座。鸿蒙的 TEE 安全微内核获得全球最高 CC EAL 5+认证，金融级 TEE 微内核认证为金融交易提供了强大的安全保障。HarmonyOS 系统提供「一次开发，多端部署」能力，其应用开发框架支持一次开发复盖手机、车机、穿戴设备等，满足金融行业多终端协同需求。&lt;/p&gt; 
&lt;p&gt;此外，蒋天泓还拆解了多个金融机构的鸿蒙应用开发实践案例。京东金融采用架构分层迁移策略，基于流量分析优先迁移核心功能，上线版本包含 21 个功能模块、180 余个功能和页面，覆盖线上版本 90% 的能力。交通银行借助鸿蒙意图框架，用户可通过语音助手「小艺」快速唤起 APP 完成转账操作，简化流程。中原银行深度适配折叠屏设备，利用鸿蒙 Navigation 技术实现业务在不同屏幕状态下的自动适配和流畅交互。在持仓页实现了分屏展示。发证券打造 AI 大模型矩阵驱动智能服务。其投顾驾驶舱基于 DeepSeek-R1 大模型，聚焦解决股票分析、资讯分析等投资咨询问题。&lt;/p&gt; 
&lt;p&gt;基于过往的开发经验，蒋天泓分享了一些实际的开发挑战可应对经验。比如，迁移成本控制方面，可以借鉴京东金融「核心功能优先」策略，结合 PV/UV 漏斗模型分析确定迁移重点。H5 容器兼容性保障上，ArkWeb 基于 Chrome 内核，无需重写，有效保证了 H5 容器的兼容性。全场景金融服务突破方面，可以通过发展「原子服务」，即轻量化服务，以及实现车机、穿戴设备等多终端联动，拓展服务边界。&lt;/p&gt; 
&lt;p&gt;通过详实的案例解析和技术探讨，蒋天泓的分享为金融行业开发者应用鸿蒙系统提供了有价值的参考，展示了鸿蒙在推动金融科技创新与服务升级方面的潜力。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#27ae60"&gt;技术洞见落地生根，互动交流共话未来&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;三位专家的精彩演讲，从鸿蒙生态的宏阔前景到 Flutter 融合的技术路径，再到金融场景的深度实践，为开发者铺就了清晰可见的鸿蒙开发图景。深入浅出的剖析与落地的实战案例，点燃了现场开发者的热情与思考。演讲结束，会场气氛即刻升温，众多意犹未尽的开发者争先举手，期待与台上大咖进行更深入地探讨。热烈的互动环节随即展开，演讲嘉宾们亦以饱满的热情和专业洞见，回应了大家最为关切的问题。以下撷取其中具有代表性的三个精彩问答，以飨读者：&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="259" src="https://oscimg.oschina.net/oscnet/up-ba0a4174e107a5e029e696a9850ef395339.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;问题一：开发者现在投入鸿蒙应用开发，如何平衡短期收益与长期生态红利？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;贾文洋：&lt;/strong&gt;目前来说，整个商用推广节奏是很快的，政企合作、金融银行、运行商等各大公司场景的落地。随着鸿蒙设备的普及，HarmonyOS 应用市场的用户基数快速扩大，开发者有机会接触到更广泛的用户群体，这为应用的下载量和收益提供了潜在的增长空间。例如，一些热门的鸿蒙原生应用在发布后短时间内就获得了大量的下载和使用。所以，从长远来看，鸿蒙应用市场份额是逐步提升的。&lt;/p&gt; 
&lt;p&gt;鸿蒙 Next 的分布式架构、AI 智能等特性为开发者提供了更多的创新空间。开发者可以利用这些特性开发出具有独特功能和体验的应用，满足用户在多设备互联、智能交互等方面的需求，从而提高应用的竞争力和吸引力，进而增加收益。例如，开发一款可以在手机、平板和智能电视上无缝切换和同步数据的视频播放应用，利用鸿蒙的分布式能力，用户可以在不同设备上继续观看之前的视频内容，这种创新的体验可能会吸引更多用户使用并付费。&lt;/p&gt; 
&lt;p&gt;华为推出了多项激励计划，如鸿蒙原生应用开发者激励计划、Next 变现激励等，为开发者提供了现金及流量扶持，以及额外的变现收益机会。可以参与鸿蒙开发者的比赛，探索一些创新性的应用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;问题二：鸿蒙的&lt;/strong&gt;&lt;strong&gt;分布式&lt;/strong&gt;&lt;strong&gt;能力在金融行业有哪些创新应用场景？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;蒋天泓：&lt;/strong&gt;鸿蒙的分布式能力可以实现穿戴设备与车机间自动发现、秒级连接，保障指令传输时延＜100ms。&lt;/p&gt; 
&lt;p&gt;端云协同 AI：可以通过用户行为描绘对用户画像进行匹配，保障用户信息安全，防止多设备协同下的信息泄漏。&lt;/p&gt; 
&lt;p&gt;第二是交易协同，通过鸿蒙的分布式软总线技术，金融机构可构建覆盖手机、平板、车机、穿戴设备等多终端的统一服务。例如，交通银行用户可在手机银行发起转账后，直接在车机端确认交易，或在智能手表上接收还款提醒并一键完成支付。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;问题三：新启动的项目，是选择 Flutter 还是 All in ArkUI ？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;王阳科：&lt;/strong&gt;在新项目启动时，选择 Flutter 或 All in ArkUI 不应视为非此即彼的对立。若项目关键目标是快速抢占市场，频繁更新迭代以适应初期需求变化，那么 Flutter 是更优解。它凭借出色的跨平台性能、丰富的生态，一套代码能打包多个平台应用，极大地缩短开发周期、降低多平台开发成本，使产品能迅速推向市场，在竞争中抢占先机。&lt;/p&gt; 
&lt;p&gt;而 ArkUI 则是深度挖掘鸿蒙系统潜力的不二之选，能充分发挥鸿蒙的分布式等独特特性。至于使用 Flutter，虽无法实现鸿蒙的一次开发多端部署能力，但并不影响其在鸿蒙端运用碰一碰等功能的特性，可以单独在鸿蒙项目上增加，其在跨平台领域的优势依旧能为项目提供有力支撑。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#27ae60"&gt;活动圆满落幕，期待携手前行&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;HarmonyOS 开发者实战工坊·上海站活动在热烈讨论与务实分享的氛围中成功结束。从宏观生态分析到具体技术实践，从金融安全应用到跨平台开发适配，整场活动为开发者带来了丰富的实用信息和解决方案。参会者们带着新的思路和具体的操作指南陆续离场，活动现场仍可见意犹未尽的开发者们聚在一起交流心得。&lt;/p&gt; 
&lt;p&gt;本次上海站活动，展现了鸿蒙生态在本地化发展上的活跃态势，也为开发者们搭建了宝贵的线下交流平台。我们相信，这样的连接与分享将为鸿蒙生态注入更多活力。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="534" src="https://oscimg.oschina.net/oscnet/up-5676e23d55e3cdd724e4c5ad7a6eea0228d.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;&lt;em&gt;现场，开发者们积极交流，还有美味茶歇和贴心福利，收获满满！&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;欢迎所有对鸿蒙开发感兴趣的开发者，持续关注 HarmonyOS 开发者社区动态」，获取最新技术文档、活动信息和开发资源。期待在下一次活动中与大家再会！&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="340" src="https://oscimg.oschina.net/oscnet/up-2da8d695e5675e704afb788c01a9b5878a8.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18628121</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18628121</guid>
      <pubDate>Fri, 09 May 2025 10:54:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Gitee SBOM 扫描上线，全面守护开源软件供应链安全</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在软件开发逐渐开源化和协作化的今天，软件供应链的透明性与安全性已成为开发者和企业最关注的话题之一。&lt;/p&gt; 
&lt;p&gt;尤其对于国内开发者和开源社区来说，&lt;strong&gt;随着国际合作与市场需求的日益增加，明确掌握软件供应链的信息，保障合规性和安全性至关重要&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Gitee 全新推出的 SBOM（软件物料清单）扫描功能，正是为了解决这些关键问题而生。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;SBOM 扫描是什么？&lt;/h2&gt; 
&lt;p&gt;软件物料清单（Software Bill of Materials，简称 SBOM）类似于软件的「配料表」，清晰记录了软件中包含的所有具体组件、库和依赖项。这种方式让开发者可以快速准确地了解软件的组成结构，从而及时发现可能存在的安全漏洞和隐患，防止问题扩大。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183218_t7Cp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，SBOM 还能协助中国的开发者和企业满足国内外的合规要求以及国际出口管制和知识产权保护相关的合规标准，确保软件开发与国际接轨且安全可信。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;SBOM 扫描能做什么？&lt;/h2&gt; 
&lt;h3&gt;识别开源依赖风险&lt;/h3&gt; 
&lt;p&gt;快速准确地识别项目中使用的开源组件，帮助开发者清晰了解依赖项，避免隐性风险，保护自主知识产权。&lt;/p&gt; 
&lt;h3&gt;追踪许可证合规性&lt;/h3&gt; 
&lt;p&gt;主动管理项目中组件许可证，确保合规性，避免法律纠纷，提升对开源项目的信任度。&lt;/p&gt; 
&lt;h3&gt;快速响应漏洞威胁&lt;/h3&gt; 
&lt;p&gt;一旦发现漏洞或风险，可以迅速定位问题组件，减少修复时间，提升项目整体安全性。&lt;/p&gt; 
&lt;h3&gt;多元数据来源支持&lt;/h3&gt; 
&lt;p&gt;Gitee SBOM 扫描能够灵活支持多种数据来源，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;源码文件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;包管理器配置文件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;容器镜像&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;各类二进制格式文件&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种多样性确保了从软件开发初期到发布后的各个阶段都能被有效覆盖，保障了全生命周期的安全性和合规性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;在 Gitee 上使用 SBOM 扫描&lt;/h2&gt; 
&lt;p&gt;SBOM 扫描服务现已对 Gitee 中&lt;strong&gt;所有开源仓库&lt;/strong&gt;开放使用，可在&lt;code&gt;服务&lt;/code&gt;中找到其入口。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183234_Hi5b_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;进入 SBOM 扫描功能后，可选择两种方式进行扫描，此处介绍在 Gitee Go 中使用 SBOM，选择&lt;code&gt;使用 Gitee Go 流水线进行扫描分析&lt;/code&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183247_hscT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如选择使用 SBOM 服务平台，请选择 Gitee 账号登录。若显示该网页不安全，可直接忽略，绑定 Gitee 账号操作即可。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;新建流水线，在&lt;code&gt;任务编排&lt;/code&gt;中选择&lt;code&gt;新的任务&lt;/code&gt;，添加&lt;code&gt;SBOM 扫描&lt;/code&gt;任务，保存并确认即可。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183259_qCRC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此时，扫描任务已在运行状态，等待十分钟后即可扫描完成（扫描时间由仓库大小决定）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183310_PyTu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;运行完成后，即可进入&lt;code&gt;构建历史&lt;/code&gt;，点击下图高亮处进入&lt;code&gt;构建详情&lt;/code&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183321_En7Y_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在&lt;code&gt;任务详情&lt;/code&gt;中即可看到本次 SBOM 扫描报告和提取码。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183339_ghVF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;输入提取码后即可查看本次扫描详情，报告中包含了&lt;code&gt;组件&lt;/code&gt;、&lt;code&gt;漏洞&lt;/code&gt;、&lt;code&gt;许可证&lt;/code&gt;相关风险项及依赖关系图。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183350_3TpU_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/183401_vUGn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前该服务已对 Gitee&amp;nbsp;&lt;strong&gt;所有开源仓库&lt;/strong&gt;开放使用，欢迎开发者访问体验&amp;nbsp;&lt;a href="https://gitee.com/"&gt;https://gitee.com/&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;强大底层支撑，全面追踪风险&lt;/h2&gt; 
&lt;p&gt;开源项目的安全性和透明度不容忽视，为此，Gitee SBOM 扫描采用统一的规范和严谨的评估方法，保证物料信息的准确性和质量。同时，依托于强大的数据库和先进的 NLP、机器学习技术，实时更新开源组件与漏洞数据，实现风险精准追踪与管理。&lt;/p&gt; 
&lt;p&gt;立即使用 Gitee 的 SBOM 扫描功能，让你的软件开发和管理更加安全、可靠、高效！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0411/120710_Spld_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356489</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356489</guid>
      <pubDate>Fri, 09 May 2025 10:35:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>打破 996 魔咒，重塑软件开发</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;当午夜的城市渐入梦乡，写字楼里的软件开发工位却依然灯火通明。在传统开发模式的桎梏下，程序员们被迫困在需求反复变更、设计难题频出、代码调试无尽的循环中，「996」 甚至 「007」 的工作节奏，让软件开发行业成为高压与疲惫的代名词。而如今，飞算 JavaAI 的横空出世，正以革命性的技术力量，为行业带来破局的曙光。&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;回溯传统软件开发流程，宛如一场充满荆棘的艰辛跋涉。在需求分析阶段，业务方模糊的构想与开发者严谨的技术思维难以精准对接。频繁的沟通会议、反复修改的需求文档，使得项目前期投入的大量精力，可能因需求临时变动而付诸东流。进入软件设计环节，接口设计的灵活性、数据库表结构的合理性等问题，都需要开发者耗费大量时间权衡利弊，一旦某个环节考虑不周，后续开发便会陷入被动。而到了代码编写阶段，复杂的业务逻辑如同迷宫，调试过程中不断出现的错误提示，让开发者深陷焦虑与疲惫，项目进度也随之停滞不前。&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;飞算 JavaAI 的诞生，彻底改写了软件开发的游戏规则。在需求分析层面，它化身智能需求处理专家，借助先进的大模型技术，能够精准解析用户输入的文字或语音需求。即便需求描述零散、逻辑混乱，它也能迅速梳理出清晰的脉络，快速生成完整且严谨的需求文档，将原本漫长的需求分析周期大幅压缩，从根源上减少需求变更带来的返工风险。&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="363" src="https://oscimg.oschina.net/oscnet/up-264c3950f00f8dd56f6cb80052f1822b3b3.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;在软件设计领域，飞算 JavaAI 的自动化设计引擎展现出强大的实力。基于自研的 Java 专有模型，它能依据项目需求，瞬间生成专业且适配性强的接口设计与表结构方案。这些设计不仅满足当下业务需求，更具备出色的扩展性，可从容应对未来业务的变化。同时，它还能对复杂业务逻辑进行智能拆解，搭建起科学合理的设计框架，为开发者节省大量脑力与时间。&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;飞算 JavaAI 的 「一键代码生成」 功能更是惊艳众人。它全面兼容 Maven、Gradle 等主流项目构建工具，开发者只需简单操作，便能获取包含完整功能的源码与工程文件。更为难得的是，其内置的自动代码优化机制，会对生成的代码进行严格审查，确保代码在语法、规范和逻辑上都达到高标准，生成的代码可直接投入使用，让开发者彻底告别深夜调试代码的困境。&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;实践是检验技术的最佳标准。某知名互联网企业在开发全新电商平台时，大胆引入飞算 JavaAI 技术。以往需要开发团队日夜赶工、历经三个月才能完成的项目，借助飞算 JavaAI 的助力，仅用一个月便顺利交付，且项目质量远超预期。项目上线后运行稳定，功能丰富，开发团队成员得以摆脱繁重的加班压力，有更多时间投入到技术学习与创新探索中，职业发展与个人生活实现了更好的平衡。&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;飞算 JavaAI 所引发的，不仅是软件开发效率的巨大提升，更是整个行业发展模式的深刻变革。它有效缩短项目周期、降低开发成本，让开发者从重复性的劳动中解放出来，将更多精力投入到创造性的工作中。在飞算 JavaAI 的推动下，软件开发正从高强度的苦役转变为充满乐趣与挑战的创新之旅。这场席卷软件开发行业的变革已然开启，你是否准备好拥抱这一全新趋势，开启高效开发的新篇章？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;飞算 JavaAl 由国家高新技术企业飞算科技自主研发&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;飞算数智科技（深圳）有限公司（简称 「飞算科技」）是一家自主创新型的数字科技公司，也是国家级高新技术企业。公司以互联网科技、大数据、人工智能等技术为基础，凭借团队在相关领域多年的实践经验，将技术与应用深度融合，致力于为民生产业、中小企业、金融企业等不同类型客户提供科技支持与服务，助力客户实现科技化、数字化、智能化转型升级。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;飞算科技始终专注于中国原创技术的创新研发，已成功落地多项填补行业空白的技术应用。在技术落地过程中，公司得到了倪光南院士、石勇院士等国内科技泰斗的长期关注及支持，相关产品也曾先后获得图灵奖得主、美国三院院士大衞&lt;/span&gt;&lt;span&gt;・&lt;/span&gt;&lt;span&gt;帕特森，以及沈昌祥院士、柴天佑院士、张景安院士的点评。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;经过多次演进，飞算科技不断构建核心壁垒，目前已形成产业数字科技、数智科技、数字转型科技、数字决策科技四大业务板块。旗下涵盖飞算 JavaAI、SoData 数据机器人、AI.Modeler 建模机器人、产业数智通等应用于不同业务场景的科技产品及解决方案，能充分满足客户的技术发展需要，实现全方位客户赋能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356486</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356486</guid>
      <pubDate>Fri, 09 May 2025 10:22:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>老项目改造、定制开发太难搞？那是你没用对方法</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在互联网浪潮奔涌的当下，程序员群体凭借技术专长拓展副业的热情持续高涨。然而，这条副业创收之路布满荆棘 —— 老项目代码如同 「天书」，梳理起来耗时耗力；客户个性化需求千差万别，通用工具难以满足；开发过程不透明，沟通成本居高不下。这些难题像沉重的枷锁，束缚着程序员副业发展的脚步。飞算 JavaAI 的三大能力升级，宛如三把 「金钥匙」，精准解锁困境，成为程序员副业创收的得力助手。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本地化智能分析：破解老项目 「天书」，提速副业开发&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当程序员接手副业项目，常常被陌生的老项目代码困住手脚。那些混乱的代码、晦涩的逻辑，如同迷宫般难以捉摸，传统人工逐行梳理的方式，不仅效率低下，还会大幅增加时间成本，压缩盈利空间。飞算 JavaAI 的本地化智能分析功能，为程序员点亮了一盏明灯。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;只需将老项目导入，该功能便即刻启动，基于全量代码语义索引和上下文强关联分析，对项目架构、模块交互和核心业务逻辑展开深度剖析。比如在承接小型企业老系统优化的副业项目时，无需再像过去那样耗费数天时间梳理代码，飞算 JavaAI 能迅速理清项目脉络，精准输出适配代码，有效避免开发过程中边改边错的情况。这使得程序员能将更多精力聚焦于高价值的开发任务，快速交付项目，收获客户好评，为后续副业合作积累良好口碑。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="363" src="https://oscimg.oschina.net/oscnet/up-e7c65594aedcc0910c909f785d228763210.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI &lt;/span&gt;&lt;span&gt;规则引擎：定制专属代码，满足多元需求&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在副业开发领域，客户需求的多样性如同变幻莫测的万花筒。不同客户对代码的技术栈、风格规范要求各不相同，通用的 AI 代码生成工具往往难以应对。飞算 JavaAI 的 AI 规则引擎功能，赋予程序员强大的定制化能力，让个性化开发不再是难题。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;程序员只需通过自然语言编写规则，无论是特定的 Java 技术栈，还是独特的代码规范、安全要求，AI 都能严格遵循，生成高合规、高复用的定制化代码。以电商平台插件开发副业为例，依据客户的系统架构和代码风格设定规则后，生成的代码能够完美融入现有系统，实现即插即用，极大减少了反复修改的时间，高效满足客户需求。凭借这样优质的服务，程序员能在副业市场中脱颖而出，吸引更多潜在客户。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="396" src="https://oscimg.oschina.net/oscnet/up-9b13a8641532c2caee087fa3a0e948f22bb.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模块化智能引导：透明化开发流程，降低沟通成本&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在副业开发过程中，客户对项目进展的关注与日俱增。然而，传统 「黑盒式」 全量代码生成方式，常常导致沟通不畅，引发客户信任危机。飞算 JavaAI 的模块化智能引导功能，打破了这一局面，让开发过程变得透明可控。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;源码按照接口模块顺序逐步生成，程序员可以实时预览，并向客户清晰展示每一步的代码逻辑与设计思路。在承接 APP 功能模块开发副业时，客户能够直观看到每个接口的实现过程，随时提出意见和建议，有效减少因需求理解偏差导致的返工。这种透明化的开发模式，不仅降低了沟通成本，还能根据客户反馈及时调整，确保最终交付成果完全符合需求，进一步提升客户信任度，助力程序员在副业领域树立专业可靠的形象，赢得更多合作机会。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="315" src="https://oscimg.oschina.net/oscnet/up-9df66e67de08102267b85671ce0ea71e9d3.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;飞算 JavaAI 的三大能力升级，从项目处理、需求满足到开发流程优化，全方位为程序员的副业之路保驾护航。借助这些强大功能，程序员能够高效完成副业项目，拓宽收入渠道，在副业市场中崭露头角，实现技术价值与经济收益的双重提升。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356484</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356484</guid>
      <pubDate>Fri, 09 May 2025 10:21:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Suna —— 开源通用 AI 智能体</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;Suna 是一款完全开源的 AI 助手，可帮助你轻松完成现实世界中的任务。通过自然对话，Suna 成为你研究、数据分析和应对日常挑战的数字伴侣--它将强大的功能与直观的界面相结合，能够理解你的需求并提供结果。&lt;/p&gt;

&lt;p&gt;Suna 强大的工具包包括用于浏览网页和提取数据的无缝浏览器自动化、用于创建和编辑文档的文件管理、网络爬虫和扩展搜索功能、用于系统任务的命令行执行、网站部署以及与各种 API 和服务的集成。这些功能协调工作，使 Suna 能够通过简单的对话解决你的复杂问题并实现工作流程自动化。&lt;/p&gt;

&lt;p&gt;&lt;img height="252" src="https://static.oschina.net/uploads/space/2025/0423/101622_pcw7_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/suna</link>
      <guid isPermaLink="false">https://www.oschina.net/p/suna</guid>
      <pubDate>Fri, 09 May 2025 10:16:00 GMT</pubDate>
    </item>
    <item>
      <title>《鸿蒙编程语言白皮书》发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;华为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fdoc%2Fguidebook%2Fprogramming-language-0000002323920052" target="_blank"&gt;发布&lt;/a&gt;了《鸿蒙编程语言白皮书》V1.0 版本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e73cd052dad175f797b65d026eced0dbee7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;白皮书核心内容如下：&lt;/p&gt; 
&lt;h3&gt;一、鸿蒙编程语言整体框架&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多语言生态&lt;/strong&gt;：鸿蒙支持 ArkTS、仓颉和 C/C++三种编程语言，它们相互补充，共同支撑鸿蒙应用生态构建。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;ArkTS&lt;/strong&gt;：动态类型编程语言，基于 TypeScript，具有易学易用、生态丰富等特征，适用于高效开发场景。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;仓颉&lt;/strong&gt;：静态类型编程语言，具有高性能、强安全、跨平台等特性，适用于对性能和安全要求较高的场景。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;C/C++&lt;/strong&gt;：适用于高性能计算、硬件加速等特定场景，可通过跨语言互操作封装为 ArkTS 和仓颉扩展模块。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;语言互操作&lt;/strong&gt;：ArkTS 与 C/C++通过 Node-API 实现互操作；仓颉与 C 语言实现函数互相调用及跨语言数据转换；仓颉与 ArkTS 通过互操作库实现数据转换和函数调用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/180210_mEvI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;二、鸿蒙编程语言适用场景&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;高效开发&lt;/strong&gt;：ArkTS 兼容 TS 高效语法，提供丰富的基础库和并发能力，支持声明式 UI 开发，可继承 TS/JS 语言生态。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高性能&lt;/strong&gt;：ArkTS 编译运行时支持混合执行模式，优化模块加载机制，提供高效的并发编程模型；仓颉基于静态类型和静态编译优化技术，具有卓越的性能支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全&lt;/strong&gt;：ArkTS 在语言层面引入类型系统等特性，并在编译工具链和运行时提供额外的安全机制；仓颉通过静态类型系统、自动内存管理等确保程序安全。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;跨平台&lt;/strong&gt;：仓颉支持静态编译至不同 OS 平台的机器码，实现跨 OS 平台代码共享，支持多种操作系统平台。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;技术资产保护&lt;/strong&gt;：ArkTS 提供源码混淆工具 ArkGuard；仓颉提供外形混淆、数据混淆、控制流混淆等多种混淆技术。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;三、鸿蒙编程语言演进策略&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ArkTS 演进策略&lt;/strong&gt;：将进一步定义和完善语言规范，提供基于语言规范的编译器实现，引入类型信息优化运行时性能等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;仓颉演进策略&lt;/strong&gt;：将持续提升高效开发体验，提供高性能和强安全能力，在跨平台和智能化领域持续完善和探索。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智能化演进策略&lt;/strong&gt;：仓颉通过元编程能力和 DSL 能力构建 Agent DSL 能力，未来将深化与 AI 技术的融合，推动在多领域的应用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;四、未来一年语言演进策略&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ArkTS&lt;/strong&gt;：将持续保持演进迭代，进一步丰富并发编程、完善类型系统、现代化语法等新特性，提升开发效率，丰富 SDK 功能等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;仓颉&lt;/strong&gt;：将以提升开发者体验为目标，从语言特性构建、兼容现有生态、完善工具链易用性等方面持续建设语言能力，包括 API 发展、开发工具支持、资料文档完善等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fdoc%2Fguidebook%2Fprogramming-language-0000002323920052" target="_blank"&gt;在线阅读&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356477</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356477</guid>
      <pubDate>Fri, 09 May 2025 10:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Ollama 已支持 RWKV-7 模型，可灵活开关思考模式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Ollama 最新版本已支持 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1" target="_blank"&gt;RWKV7-G1&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-7-world%2Ftree%2Fmain" target="_blank"&gt;RWKV-7-World&lt;/a&gt; 系列模型。&lt;/p&gt; 
&lt;p&gt;3 月初，随着 RWKV 社区成员 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMollySophia" target="_blank"&gt;@MollySophia&lt;/a&gt; 的 PR 被合并，llama.cpp 正式支持 RWKV-7 模型。Ollama 近期更新了最新版 llama.cpp，因此同步支持 RWKV-7 架构和对应模型。&lt;/p&gt; 
&lt;p&gt;Ollama 官方模型仓库现已包含 RWKV-7 系列模型（&lt;strong&gt;推荐使用 RWKV7-G1 系列模型&lt;/strong&gt;）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV-G1：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Fmollysama%2Frwkv-7-g1" target="_blank"&gt;https://ollama.com/mollysama/rwkv-7-g1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV-7-World：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Fmollysama%2Frwkv-7-world" target="_blank"&gt;https://ollama.com/mollysama/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="Ollama-rwkv-7-g1-model" src="https://oscimg.oschina.net/oscnet/up-fccb3d8e64926294cacbe4a11ee95d9a770.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;在 Ollama 中运行 RWKV 模型&lt;/h2&gt; 
&lt;p&gt;以下是在 Ollama 中体验 RWKV-7 G1 2.9B 模型的最简路径。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Fdownload" target="_blank"&gt;https://ollama.com/download&lt;/a&gt; 页面，根据您的系统下载 Ollama 安装包：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="Ollama-Download" src="https://oscimg.oschina.net/oscnet/up-4ea6cdae40f2b576d1013a04ce100b86e1b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;下载完毕后，双击安装包以安装 Ollama。任务栏出现 Ollama 图标时，意味着安装已完成：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="Ollama-Install" src="https://oscimg.oschina.net/oscnet/up-a3ae79f1c042ea9a6d041491c2424644352.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在终端中运行 &lt;code&gt;ollama run mollysama/rwkv-7-g1:2.9b&lt;/code&gt; 命令，Ollama 将&lt;strong&gt;自动下载并运行&lt;/strong&gt; RWKV7-G1 2.9B 模型。您可以在终端中与 RWKV 模型进行对话，如下图所示：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;若您曾经下载过 &lt;code&gt;mollysama/rwkv-7-g1:2.9b&lt;/code&gt; 模型，请运行 &lt;code&gt;ollama pull mollysama/rwkv-7-g1:2.9b&lt;/code&gt; 命令，拉取最新的变更。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="ollama-Run" src="https://oscimg.oschina.net/oscnet/up-078fd28c775018d9e1b41165e88e4daa867.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ollama 的 RWKV7 G1 模型默认开启思考模式，可以通过 &lt;code&gt;/set nothink&lt;/code&gt; 和 &lt;code&gt;/set think&lt;/code&gt; 命令灵活地开关思考模式：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="ollama-run-nothink-mode" src="https://oscimg.oschina.net/oscnet/up-47a41f6324cd656bc720b5cac3242dd846d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用 &lt;code&gt;ollama stop mollysama/rwkv-7-g1:2.9b&lt;/code&gt; 命令可以停止当前模型实例，从而&lt;strong&gt;重置对话上下文&lt;/strong&gt;，否则 Ollama 会**持续保留当前会话的上下文（历史消息）**作为后续对话的参考&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ollama 官方仓库提供 &lt;code&gt;Q6_K&lt;/code&gt; 量化的 RWKV7 G1 模型。&lt;/p&gt; 
 &lt;p&gt;如需使用其他量化类型，需手动&lt;strong&gt;创建自定义 RWKV 模型&lt;/strong&gt; ，详细教程请在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate%2FRWKV-Inference%2FOllama" target="_blank"&gt;RWKV 教程 - Ollama 推理&lt;/a&gt; 中查看。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;RWKV Chat 端侧聊天助手&lt;/h2&gt; 
&lt;p&gt;除了在 Ollama 中运行 RWKV 模型，我们也推荐使用 &lt;strong&gt;RWKV Chat 端侧聊天助手&lt;/strong&gt;体验 RWKV 模型。&lt;/p&gt; 
&lt;p&gt;RWKV Chat 是 RWKV 官方推出的离线 AI 聊天应用，针对各类端侧设备进行深度推理优化。APP 内含多种小参数模型，支持会话配置调整、灵活切换思考模式，是你的高效生产力伙伴！&lt;/p&gt; 
&lt;p&gt;在开启和关闭思考模式两种情况下，RWKV Chat 回答同一个问题：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV-chat-dual-mode" src="https://oscimg.oschina.net/oscnet/up-0da002b7cc9c0e9f745e653ce7e39cfa22a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;下载 RWKV Chat APP：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkvos.com%2Frwkv-chat" target="_blank"&gt;https://rwkvos.com/rwkv-chat&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入 RWKV 论坛、QQ 频道和 QQ 群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 论坛：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 频道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 视频教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356473</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356473</guid>
      <pubDate>Fri, 09 May 2025 09:39:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>华为自研仓颉编程语言将于 7 月 30 日开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在华为开发者大会 HDC 2025 期间，华为宣布仓颉编程语言将于 7 月 30 日开源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 6 月，华为终端 BG 软件部总裁龚体宣布，下一代编程语言仓颉今日起正式开启预览。官网介绍显示，仓颉编程语言是一款面向全场景智能的新一代编程语言，主打智能化、全场景、高性能、强安全。融入鸿蒙生态，为开发者提供良好的编程体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="263" src="https://oscimg.oschina.net/oscnet/up-c8b68adb0faebdafc65da05a7b0d291b75c.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其具体特性表现为：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;高效编程：面向应用开发，希望语言能够易学易用，降低开发者入门门槛和开发过程中的心智负担，支持各种常见的开发范式和编程模式，让开发者简洁高效地表达各种业务逻辑。仓颉是一门多范式编程语言，支持函数式、命令式和面向对象等多种范式，包括值类型、类和接口、泛型、代数数据类型、模式匹配、以及高阶函数等特性。此外，仓颉还支持类型推断，能够减轻开发者类型标注的负担；通过一系列简明高效的语法，能够减少冗余书写、提升开发效率；语言内置的各种语法糖和宏（macro）的能力，支持开发者基于仓颉快速开发领域专用语言（DSL），构建领域抽象。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;安全可靠：作为现代编程语言，仓颉追求编码即安全，通过静态类型系统和自动内存管理，确保程序的类型安全和 null safety 等内存安全；同时，仓颉还提供各种运行时检查，包括数组下标越界检查、类型转换检查、数值计算溢出检查、以及字符串编码合法性检查等，能够及时发现程序运行中的错误；此外，还通过代码扫描工具、混淆工具以及消毒器，进一步提供跨语言互操作安全和代码资产保护等支持。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;轻松并发：并发和异步编程能够有效提高处理器利用率，并在交互式应用中确保程序的响应速度，是应用开发中必不可少的能力。仓颉语言实现了轻量化用户态线程和并发对象库，让高效并发变得轻松。仓颉语言采用用户态线程模型，每个仓颉线程都是极其轻量级的执行实体，拥有独立的执行上下文但共享内存。对开发者来说，用户态线程的使用和传统的系统线程的使用方式保持一致，没有带来额外负担；而从运行态视角看，线程的管理由运行时完成，不依赖操作系统的线程管理，因此线程的创建、调度和销毁等操作更加高效，且资源占用比系统线程更少。为了避免数据竞争，仓颉语言提供了并发对象库，并发对象的方法是线程安全的，因此在多线程中调用这些方法和串行编程没有区别，应用逻辑的开发者无需额外关心并发管理。对于一些核心库，仓颉还提供了无锁或者细粒度锁的算法实现，能够进一步减少线程的阻塞，提升并发度。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;卓越性能：仓颉编译器及运行时从全栈对编译进行优化，包括编译器前端基于 CHIR（Cangjie HighLevel IR）高层编译优化（比如语义感知的循环优化、语义感知的后端协同优化等），基于后端的编译优化（比如：SLP 向量化、Intrinsic 优化、InlineCache、过程间指针优化、Barrier 优化等），基于运行时的优化（比如轻量锁、分布式标记、并发 Tracing 优化等），一系列的优化让仓颉充分发挥处理器能力，为应用提供卓越的性能支持。另外仓颉语言对运行时进行原生的轻量化设计，通过对运行时模块化分层设计，定义仓颉公共对象模型和运行时公共基础组件，基于公共对象模型，实现运行时的内存管理、回栈、异常处理、跨语言调用等基础能力，大幅减少多个能力间的冗余对象设计，精简运行时体积。同时通过包的按需加载技术，减少仓颉应用启动的冗余包内存开销，因此对于资源敏感设备，占用资源更少，支持更友好。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除此之外，仓颉还支持面向应用开发的一系列工具链，包括语言服务（高亮、联想）、调试（跨语言调试、线程级可视化调试）、静态检查、性能分析、包管理、文档生成、Mock 工具、测试框架、覆盖率工具、Fuzz 工具以及智能辅助编程工具，进一步提升软件开发体验以及效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/298396/huawei-cangjie-lang" target="_blank"&gt;华为仓颉编程语言正式亮相&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/318801" target="news"&gt;仓颉编程语言官网正式上线，首个公测版本开放下载&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356470</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356470</guid>
      <pubDate>Fri, 09 May 2025 09:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>首个 GraphRAG-Bench 如何评估九大 GraphRAG 性能？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;导读：传统 RAG 遇瓶颈，复杂推理怎么办？ GraphRAG 正成为知识管理新利器。 但关键问题来了：GraphRAG 真的超越了 RAG 吗？GraphRAG 哪家强？GraphRAG 性能评估标准有哪些？面针对不同场景需求如何选择？香港理工大学等学者在 6 月 3 日发表论文，重磅推出首个大规模、领域特定基准 GraphRAG-Bench，为技术选型提供硬核依据。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/GraphRAG-Bench-banner.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;🔍本文翻译略有删减，论文原文如下&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2506.02404" target="_blank"&gt;https://arxiv.org/pdf/2506.02404&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本文首发于&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FV4ExjKWssYdHr9i8Ww0D7Q" target="_blank"&gt;&lt;strong&gt;「NebulaGraph 技术社区」&lt;/strong&gt;&lt;/a&gt;，更多产品资讯请访问&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nebula-graph.com.cn%2Fai-application-platform" target="_blank"&gt;&lt;strong&gt;「NebulaGraph 官网」&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、摘要&lt;/h1&gt; 
&lt;p&gt;图检索增强生成（Graph Retrieval-Augmented Generation, GraphRAG）因其在结构化组织领域特定语料库并提升复杂推理能力的潜力，正日益受到认可。然而，当前 GraphRAG 模型的评估主要依赖传统的问答数据集。这些数据集在问题广度和评估指标上存在局限性，无法全面衡量 GraphRAG 模型所带来的推理能力提升。&lt;/p&gt; 
&lt;p&gt;为弥补这一不足，我们提出了 GraphRAG-Bench，这是一个为严格评估 GraphRAG 模型而设计的大规模、领域特定基准。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/overview-of-GraphRAG-Bench.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们的基准具备三大优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;挑战性问题设计&lt;/strong&gt;： 包含大学水平、领域特定的问题，要求进行多跳推理，确保仅靠简单内容检索不足以解决问题。例如，部分问题涉及数学推理或编程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多样化任务覆盖&lt;/strong&gt;： 数据集涵盖广泛的推理任务类型，包括单项选择（MC）、判断正误（TF）、多项选择（MS）、开放式问答（OE）和填空（FB）。问题来源覆盖 20 本核心教材中的 16 个学科。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;全方位评估框架&lt;/strong&gt;： GraphRAG-Bench 提供了覆盖整个 GraphRAG 流程的全面评估，包括图构建、知识检索和答案生成。除了最终答案的正确性，它还评估推理过程的逻辑连贯性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过将九种前沿 GraphRAG 方法应用于 GraphRAG-Bench，我们量化了基于图的结构化如何提升模型推理能力。我们的分析揭示了关于图架构、检索效能和推理能力的关键见解，为业界研究提供了可操作的指导。&lt;/p&gt; 
&lt;p&gt;GraphRAG-Bench 的所有相关资源均已收集在：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjeremycp3%2FGraphRAG-Bench" target="_blank"&gt;https://github.com/jeremycp3/GraphRAG-Bench&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;二、研究背景&lt;/h2&gt; 
&lt;p&gt;检索增强生成（Retrieval-Augmented Generation, RAG）已成为将大型语言模型（Large Language Models, LLMs）植根于外部知识的关键解决方案，用以缓解幻觉问题及领域知识匮乏的问题。通过从语料库中检索相关文本片段，RAG 为 LLM 注入事实性知识，以生成更可靠的输出。&lt;/p&gt; 
&lt;p&gt;然而，传统的 RAG 系统在处理复杂推理场景时仍不尽如人意。&lt;strong&gt;RAG 中的扁平检索仅基于相似度匹配直接返回零碎的文本块，这限制了其对概念间复杂关系建模的能力，难以回答需要多跳推理、全局理解问题&lt;/strong&gt;。例如：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「2008 年雷曼兄弟破产事件对埃隆·马斯克的特斯拉公司有何影响？」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「贸易政策变革事件的主要思想是什么？」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;为应对这些局限，图检索增强生成（GraphRAG）被广泛研究，旨在以图的形式捕捉概念间的结构化知识。其中节点代表概念，边代表概念间的关系。GraphRAG 的最新进展可归纳为三个主要方向。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;分层图构建方法，通过树形结构和社区检测来组织知识。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;神经图检索方法，采用图神经网络编码器并结合专门的目标函数进行多跳推理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;动态知识集成系统，开发了与 LLM 紧密耦合的自适应图构建和遍历机制。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;通过将知识结构化为图，GraphRAG 不仅使 LLM 能够沿着显式关系路径进行遍历和推理，还能基于图结构推断隐含关系，从而支持更深层次的推理。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;然而，尽管前景广阔，现有的 GraphRAG 方法基准未能充分反映其在图结构上进行推理的性能。这些基准主要利用传统的问答数据集，如 HotpotQA 、2WikiMultiHopQA 和 MuSiQue ，这些数据集仅包含复杂度有限、答案简短的显式事实性问题，例如「Dambar Shah 的孙子是谁？」。&lt;/p&gt; 
&lt;p&gt;这些数据集存在三个关键局限：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;仅包含常识性问题，这些问题可能已被 LLM 的训练语料覆盖。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通常仅需基于显式连接的单跳或浅层多跳推理，不足以探明图结构知识的独特优势。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;答案形式单一： 多数答案为简短形式（名称、日期）或选择题，难以反映基于图的推理能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，我们提出一个研究问题：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「GraphRAG 是否真正超越了传统 RAG，提升了模型的推理能力？」&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、研究方法与实验设计&lt;/h1&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;（一）研究方法&lt;/h2&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;1. 问题设计&lt;/h3&gt; 
&lt;p&gt;为了在大学水平推理上评估 GraphRAG 框架，我们首先构建了一个权威教材语料库。从涵盖计算机科学 16 个不同子领域的 100 多份出版物出发，系统性地筛选出最具代表性的 20 本教材。我们定义了五种问题类型，每种针对 GraphRAG 推理能力的不同方面。最终选取出 1018 道高质量挑战性问题，覆盖了广泛的主题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/GraphRAG-Bench-question.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;2. 语料库收集与处理&lt;/h3&gt; 
&lt;p&gt;（1）预处理阶段区分 PDF 文本页与扫描页，分别采用直接提取和 OCR，并提取教材元数据（大纲、章节页码）。&lt;/p&gt; 
&lt;p&gt;（2）内容解析阶段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;使用 LayoutLMv3 进行多模态布局分析，分割页面为标题、段落等语义块&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用 YOLO 模型检测并隔离数学公式区域避免 OCR 错误&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对扫描页指定区域应用 OCR 获取文本&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;（3）后处理阶段通过 MinerU 工具按阅读顺序重组可能混乱的解析元素（文本、公式等）。&lt;/p&gt; 
&lt;p&gt;（4） 基于元数据构建四级层级结构（书名→章→节→知识单元），形成带结构标注的教材树。&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;3. 专家撰写推理依据&lt;/h3&gt; 
&lt;p&gt;现有基准通常仅提供最终答案或显式图路径。相比之下，我们的数据集提供了专家撰写的推理依据，清晰阐述了解决每个问题所需的完整逻辑推进过程。&lt;/p&gt; 
&lt;p&gt;这些推理依据超越了简单的语料聚合，是结构化的敍述，能够：(i) 分离出前提概念，(ii) 描述这些概念间的关系，以及 (iii) 指明问题求解过程中应用的推理操作。&lt;/p&gt; 
&lt;p&gt;通过追踪逻辑推理和知识交互的每一步，我们可以评估 GraphRAG 模型是否真正生成了基于上下文的解释，还是仅仅利用了表面模式。&lt;/p&gt; 
&lt;p&gt;为实现细粒度、主题特定的评估，我们数据集中的每个问题都带有两个层级标签：一个宽泛的子领域（Level 1，例如「机器学习」）和一个更细粒度的概念（Level 2，例如「无监督学习」）。这些标注支撑了我们的后验分析。对于每个主题，我们不仅衡量模型答案的准确性，还衡量其生成的推理依据与标准依据的契合度。通过这种方式，我们将评估转化为一个多维过程，要求模型既要提供正确答案，也要生成忠实可信的推理模式。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;（二）实验设计&lt;/h2&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;1. 评估指标&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;图构建：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;效率 (Efficiency)：&lt;/strong&gt; 构建完整图所需的时间。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;成本 (Cost)：&lt;/strong&gt; 图构建过程中消耗的 token 数量。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;组织度 (Organization)：&lt;/strong&gt; 构建图中非孤立节点所占的比例（衡量图的连通性）。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知识检索：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;索引时间 (Indexing time)：&lt;/strong&gt; 构建用于检索的向量数据库所需的时间。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;平均检索时间 (Average retrieval time)：&lt;/strong&gt; 每个查询进行知识检索的平均耗时。此外，我们总结每种方法使用的检索操作对象（Retrieval operators）以评估其检索机制的复杂度。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;生成：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们认为现有的精确匹配（exact match）指标并不合适，因为正确答案无需逐词对应。因此，本文引入了一个新指标：&lt;strong&gt;准确率 (Accuracy)&lt;/strong&gt;，定义如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OE 和 FB 问题：&lt;/strong&gt; 将生成输出和标准答案通过我们设计的提示词（prompt）输入一个 LLM，该 LLM 基于语义对齐和正确性打分。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MC 和 TF 问题：&lt;/strong&gt; 答案正确得 1 分，否则 0 分。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MS 问题：&lt;/strong&gt; 完全正确得 1 分；部分正确得 0.5 分；错误得 0 分。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;推理依据：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;推理得分 (R, Reasoning Score)：&lt;/strong&gt; 我们设计了一个提示词，将 GraphRAG 方法生成的推理依据和标准依据输入一个 LLM，该 LLM 给出一个推理得分（R）以评估它们的语义对应和推理一致性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;答案相关推理得分 (AR, Answer-related Reasoning Score)：&lt;/strong&gt; 我们额外开发了 AR 指标，用于判断当模型准确回答问题时，其是否能提供正确的推理。此指标旨在区分模型是仅仅猜对了答案，还是确实通过合理的逻辑推理得出了正确答案，从而更全面地理解模型性能。&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2. 实验设置&lt;/h3&gt; 
&lt;p&gt;评估了九种前沿 GraphRAG 方法的性能，为确保所有方法公平比较，采用相同的 GPT-4o-mini 作为默认的大型语言模型。我们没有设置最大 token 长度来限制单个方法的性能。对于需要选择 top-k 的方法，我们统一设置 k=5。在文本分块方面，块大小统一设置为 1200 个 token.&lt;/p&gt; 
&lt;span id="OSC_h1_11"&gt;&lt;/span&gt; 
&lt;h1&gt;四、实验结果&lt;/h1&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;（一）图构建评估&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/graph-construction-process.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;1. Token 与时间成本&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;树结构&lt;/strong&gt;的 Token 成本最低，因为它仅调用 LLM 生成摘要，但由于迭代聚类，耗时最长。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;段落图&lt;/strong&gt;的 Token 成本次优，仅调用 LLM 总结实体或关系，时间成本第二长，归因于耗时的实体链接过程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;知识图谱&lt;/strong&gt; Token 消耗适中，需要 LLM 进行实体提取和三元组生成，但因三元组获取后知识图谱构建快速，达到最短耗时（DALK 最快）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;丰富知识图谱&lt;/strong&gt; Token 消耗最多，因为它在标准知识图谱基础上通过 LLM 为实体和关系生成额外描述，导致时间成本增加。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2. 组织度&lt;/h3&gt; 
&lt;p&gt;使用非孤立节点比例作为指标（树结构不适用此指标）。结果显示知识图谱表现最佳，其非孤立节点比例保持在约 90%。丰富知识图谱表现次优；虽然引入了额外信息，但也不可避免地引入了更多噪声。段落图的非孤立节点比例最低，表明实体链接工具未能有效建立大多数实体对之间的边。&lt;/p&gt; 
&lt;span id="OSC_h2_15"&gt;&lt;/span&gt; 
&lt;h2&gt;（二）知识检索评估&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/knowledge-retrieval-process.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;索引时间：&lt;/strong&gt; GFM-RAG 索引时间最短；它不构建传统的向量数据库存储实体，而是在图构建阶段专门存储与问题对应的实体。在使用向量数据库的方法中，KGP、RAPTOR 和 DALK 因存储信息量少而成本较低；ToG、G-Retriever 和 LightRAG 成本适中，因为存储关系本身耗时；GraphRAG 因额外存储社区报告而进一步增加索引时间。HippoRAG 索引时间最长，归因于其额外构建实体&amp;lt;-&amp;gt;关系和关系&amp;lt;-&amp;gt;文本块映射。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;平均检索时间：&lt;/strong&gt; RAPTOR 速度最快，其树结构能快速定位信息。GFM-RAG 和 HippoRAG 紧随其后，分别利用 GNN 和 PageRank 算法进行检索。G-Retriever 采用带奖励收集斯坦纳森林算法（Prize Collecting Steiner Forest），LightRAG 依赖基于关系的检索，两者都引入了额外延迟。GraphRAG 需要利用社区信息检索，导致耗时较长。KGP、ToG 和 DALK 因检索时依赖调用 LLM 而产生显著时间成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_16"&gt;&lt;/span&gt; 
&lt;h2&gt;（三）生成准确率评估&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/generation-process.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;鉴于 GPT-4o-mini 本身已具备较强的问答能力，并非所有 GraphRAG 方法都能有效提升其性能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能下降：&lt;/strong&gt; DALK 和 G-Retriever 反而降低了 LLM 性能；它们过度依赖结构信息而牺牲了语义内容，在生成过程中引入了过多噪声，损害了 LLM 的判断准确性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;小幅提升：&lt;/strong&gt; LightRAG、ToG 和 KGP 实现了小幅性能提升，表明其检索到的内容对生成任务提供了有限的帮助。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;显著提升：&lt;/strong&gt; 相比之下，GFM-RAG、GraphRAG 和 HippoRAG 通过有效整合图结构信息和文本块级语义显著提升了 LLM 性能：GFM-RAG 利用大规模预训练获得鲁棒的基础模型，GraphRAG 利用基于社区的信息优化检索，HippoRAG 通过 PageRank 算法提升检索效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;最佳方法：&lt;/strong&gt; 实验中表现最佳的方法是 RAPTOR，它通过迭代聚类构建树结构，这种设计与教材数据天然的分层组织结构高度契合，能够高效检索相关信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;超越传统 RAG：&lt;/strong&gt; 大多数 GraphRAG 方法优于 BM-25 和 TF-IDF 等传统 RAG 基线，突显了基于图的架构在提升生成准确率方面的效用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_17"&gt;&lt;/span&gt; 
&lt;h2&gt;（四）推理能力评估&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/reasoning-ability.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;与生成任务的高准确率相比，GPT-4o-mini 在推理性能（ R 和 AR 得分）上表现出显著下降。R 得分的下降表明 LLM 常常无法进行正确推理，而是在许多情况下通过猜测或模式匹配来选择答案。AR 得分的下降表明，即使 LLM 提供了正确答案，其推理过程也可能存在缺陷；或者它们可能生成了正确推理但选择了错误答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;显著提升：&lt;/strong&gt; 所有 GraphRAG 方法都显著增强了 LLM 的推理能力：通过不同的算法设计，这些方法不仅检索到与问题语义相关的语料，还识别出知识库中具有多跳依赖性的语料，为 LLM 的推理提供了证据支持。这使得 LLM 能够基于外部信息进行推理，而非仅依赖内部知识进行猜测。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;算法性能分布：&lt;/strong&gt; 在算法性能分布上，与生成任务类似：HippoRAG 和 RAPTOR 仍是表现最好的，这很直观，因为检索到有用信息本身就与实现正确推理相关。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;超越传统 RAG：&lt;/strong&gt; 大多数 GraphRAG 方法仍然优于传统 RAG 基线（TF-IDF, BM-25）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_18"&gt;&lt;/span&gt; 
&lt;h2&gt;（五）主题特定生成准确率分析&lt;/h2&gt; 
&lt;p&gt;鉴于我们的数据集跨越 16 个不同主题领域，我们对 GraphRAG 对 LLM 生成准确率的影响进行了细粒度分析。总体而言，GraphRAG 在大多数领域带来了一致的提升。然而，也发现了一些有趣的发现：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://nebula-cdn.nebula-graph.com.cn/nebula-website-5.0/share/technology-popularization/Generation-Accuracy-by-Topic..jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;数学领域：&lt;/strong&gt; 所有 GraphRAG 方法都降低了 LLM 在数学题上的生成准确率。这是因为数学问题关键依赖于严格的符号操作和精确的推理链；模型必须在内部「计算」每个演绎步骤，而非依赖外部文本的关键词匹配。通过 GraphRAG 检索到的大多数文档是解释性或概念性的，其符号表示、公式布局和上下文结构常与问题要求不符，导致信息提取和转换过程中产生歧义或关键步骤丢失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;伦理领域：&lt;/strong&gt; GraphRAG 和 LLM 本身在伦理题上的表现都平平。我们认为伦理问题从根本上涉及主观价值判断，其含义取决于道德权衡和社会规范的动态语境。LLM 通过统计学习捕捉的符号表示难以准确建模模糊的伦理概念，在推理上存在固有局限。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;稳健性：&lt;/strong&gt; 优秀的 GraphRAG 方法在大多数主题上显著提升了 LLM 的生成准确率，展现出稳健的性能，验证了其跨领域有效性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_19"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;strong&gt;五、Observation&lt;/strong&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_20"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;🙋GraphRAG 能否提升所有问题类型的性能？&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;单项选择问题准确率下降：&lt;/strong&gt; LLM 通过在大型语料库上的广泛训练内化了海量知识，使其在选择题任务中常能正确选择答案。然而，GraphRAG 基于检索的增强可能引入冗余或松散相关的信息，这些信息与问题语境并非精确匹配。此类检索噪声会干扰模型的决策能力，最终降低其在单项选择问题上的准确率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;判断正误问题性能提升：&lt;/strong&gt; TF 问题需要对事实或逻辑陈述进行二元判断。LLM 可能对某些事实存在盲点或不完整的知识，导致错误答案。通过检索相关的事实证据，GraphRAG 帮助模型在回答前验证陈述。这些补充信息提高了模型在判断正误问题上的准确率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;开放式问题性能提升：&lt;/strong&gt; 开放式问题允许广泛、详细的回答，这对于仅依赖内部知识的 LLM 来说可能具有挑战性。GraphRAG 通过提供来自外部语料库的额外上下文和事实来缓解这一挑战。检索到的信息丰富了模型的回答，提升了主题细节和表达能力，并通过将答案基于明确证据来减少幻觉。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;填空和多项选择问题的不同效果：&lt;/strong&gt; 填空问题需要精确的上下文理解以正确预测缺失词。GraphRAG 检索到的语料通常无法匹配确切的语境，引入噪声从而降低模型在填空问题上的表现。多项选择题需要从一组选项中选择多个正确答案，涉及对选项复杂组合的推理；如果 GraphRAG 的检索遗漏了相关答案选项或包含了无关细节，则可能混淆模型。因此，这些问题类型对检索精度要求很高；除非 GraphRAG 的检索非常精确，否则其收益可能有限。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_21"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;🙋GraphRAG 能否有效增强 LLM 的推理能力？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;实验表明，GraphRAG 能有效增强 LLM 在各种问题类型上的推理能力，提高了在生成答案的同时生成正确推理依据的概率。&lt;/p&gt; 
&lt;p&gt;这归功于其高效的检索机制，不仅能为问题识别高度相关的语料，还能为 LLM 的推理过程提供有力的证据支持。特别是，现有基准缺乏对 GraphRAG 推理能力的系统性评估，而这在实际应用中至关重要。例如，在本文针对的大学级教育场景中，寻求专业知识的用户不仅期望正确答案，还期望清晰的推理依据以促进理解和知识获取。同样，在医疗场景中，患者需要清晰的用药依据和治疗建议，以确保决策的透明度。因此，有效的 GraphRAG 方法不仅应追求答案生成的高准确率，还应追求强大的推理和可解释性。&lt;/p&gt; 
&lt;span id="OSC_h1_22"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;strong&gt;六、结论&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本文提出了 GraphRAG-Bench，这是首个专为 GraphRAG 设计的领域特定基准。它包含一个跨越 16 个学科的数据集，通过多跳推理、复杂算法/编程任务、数学计算和多样化问题类型挑战现有方法，覆盖图构建、知识检索、生成和推理的全方位、多维评估，量化了结构化知识增强对 LLM 推理能力的提升。在九种前沿 GraphRAG 方法上进行的广泛实验，揭示了图集成在提升推理和生成性能方面的重要作用。&lt;/p&gt; 
&lt;p&gt;‍&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4169309/blog/18627814</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4169309/blog/18627814</guid>
      <pubDate>Fri, 09 May 2025 07:45:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>AI 落地困局：中国企业在技术狂欢后的价值觉醒之战</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;当某汽车零部件工厂的 AI 质检系统以 0.1 秒 / 件的速度运行，却在三个月后因误判率超 27% 被闲置，当工程师们在服务器机房对着持续报错的国产算力平台沉默吸烟 —— 这些未被公开的行业切片，正揭示着中国企业 AI 转型进入深水区后的真实生态。企业 AI 应用早已不是技术选择题，而是一场涉及技术架构、商业逻辑、组织基因的系统性重构。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;技术金字塔的基座崩塌：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;从算力诅咒到数据&lt;/span&gt;&lt;span&gt;熵增&lt;/span&gt;&lt;span&gt;的底层困境&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;算力经济的非对称博弈：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;在东莞某 PCB 制造厂的服务器机房里，8 台 A800 服务器每月消耗的 28 万度电，相当于 300 个家庭的年用电量。更隐蔽的成本来自技术代差：英伟达 A100 的单精度算力达 19.5TFLOPS，而国产某替代芯片仅为 7.8TFLOPS，在处理复杂视觉模型时，训练时长从 36 小时延长至 127 小时。这种 "算力鸿沟" 催生出奇特的行业现象：某新能源车企为维持自动驾驶模型训练，自建了一座 2000kW 的光伏电站，能源成本占 AI 总投入的 43%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;数据治理的熵增定律：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;苏州某医疗器械企业的案例极具代表性：其积累的 15 万份超声影像中，38% 缺乏标准化标注，22% 存在设备型号与数据格式的不匹配。当 AI 团队试图用这些数据训练结节识别模型时，发现标注误差导致的模型偏差率高达 41%。这种数据熵增现象在传统行业尤为显著 —— 某钢铁集团的高炉传感器每天产生 8TB 运行数据，但因缺乏统一元数据标准，85% 的数据在存储 3 个月后便成为 "不可读黑匣子"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;算法黑箱的伦理困境：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;某&lt;/span&gt;&lt;span&gt;股份制银行&lt;/span&gt;&lt;span&gt;的智能风控系统曾创下 "一日拦截 237 笔正常跨境贸易" 的纪录，其基于深度学习的异常检测模型，将某外贸企业连续三年的端午假期结汇模式误判为 "洗钱特征"。更严峻的挑战来自医疗领域：某 AI 辅助诊断系统在肺结节良恶性判断中，准确率达 92.3%，但因无法解释 "为何将某类毛玻璃影判定为恶性"，被三家三甲医院停用。这种 "高精准低解释" 的矛盾，在《生成式 AI 服务管理暂行办法》实施后，成为医疗 AI 商业化的核心障碍。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:16px; margin-right:16px"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;商业价值座标系的迷失：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:16px; margin-right:16px"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;从规模不经济到增长范式的认知颠覆&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;定制化陷阱的死亡螺旋：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;企业在 AI 项目中常陷入定制化陷阱，过度追求个性化需求，导致开发成本失控、技术架构碎片化，最终项目亏损、难以落地。某 AI 独角兽为某物流企业开发的智能路径规划系统，项目周期 14 个月，研发投入达 2300 万元，最终因无法适应暴雨天气的动态调度需求被搁置。这种 "项目制陷阱" 在行业内普遍存在：头部 AI 企业的定制化项目平均亏损率达 28%，某智慧城市项目的单项目亏损额甚至达到营收的 3.7 倍。更致命的是，定制化开发导致技术架构碎片化 —— 某零售企业先后引入 7 套 AI 系统，形成 13 个数据孤岛，系统间集成成本占 IT 预算的 35%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;规模效应的非线性悖论：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;许多企业认为大规模投入 AI 就能带来显著效益，实则不然。AI 的规模效应存在非线性特征，若未精准匹配业务需求，即使大规模投入也难以实现预期的成本下降与效率提升。&lt;/span&gt;&lt;span&gt;麦肯锡&lt;/span&gt;&lt;span&gt;&lt;span&gt; 2025 年全球 AI 调研显示，年营收超 100 亿的企业中，仅 12% 通过 AI 实现成本下降超 8%。某乳业巨头投入 1.2 亿元建设的智能工厂，其 &lt;/span&gt;&lt;span&gt;OEE&lt;/span&gt;&lt;span&gt;（设备综合效率）提升仅 1.7%，远低于预期的 8%。这种 "规模不经济" 源于技术适配的错位：该企业的灌装线 AI 视觉检测系统，对奶渍残留的识别精度达 0.01mm，但产线实际需要的是对封盖缺陷的检测 —— 而这一功能的实现成本仅为原系统的 1/20。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;价值评估体系的范式转移：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;传统的价值评估方式已不适用于 AI 项目，企业需建立包含技术成本、业务收益、风险成本等多维度的评估体系，才能准确衡量 AI 应用的真实价值。某服装企业的案例极具启示性：其投入 800 万元的 AI 面料缺陷检测系统，虽将质检效率提升 40%，却因漏检率高于人工质检 3 个百分点被束之高阁。深层原因在于价值评估的错位 —— 企业未建立 "误检成本 - 漏检成本 - 人力替代成本" 的三维评估模型。在纺织行业，1% 的漏检率可能导致价值 300 万元的批次性退货，而 AI 系统 0.8% 的误检率则会造成 200 万元的物料浪费，这种精细的成本测算体系，恰恰是多数传统企业的认知盲区。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:16px; margin-right:16px"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;组织基因的排异反应：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:16px; margin-right:16px"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;从人才断层到权力重构的深层博弈&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;复合型人才的量子化稀缺：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;AI 项目的落地需要既懂技术又懂业务的复合型人才，但这类人才在市场上极度稀缺。企业需调整人才策略，通过内部培养、外部合作等方式，构建适配 AI 转型的人才梯队。某智能制造百强企业的招聘数据显示，其 AI 项目经理岗位的平均招聘周期达 187 天，要求 "具备工业工程 + 机器学习 + 业务场景理解" 的复合型人才，简历通过率不足 0.3%。更严峻的是能力结构失衡：某车企自动驾驶团队中，算法工程师占比达 68%，但懂车规级硬件开发的仅占 12%，导致算法模型在车规级芯片上的部署效率低下 —— 某感知模型在实验室 GPU 上的推理速度为 28fps，移植到车规级芯片后降至 7fps。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;组织惯性的文化熵增：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;企业的组织文化与惯性会成为 AI 转型的阻力，要实现顺利转型，需打破固有思维，构建开放包容、鼓励创新的组织文化。某航空发动机企业的数字化转型案例极具戏剧性：其引入的 AI 工艺优化系统，建议将某叶片加工的&lt;/span&gt;&lt;span&gt;切削参数&lt;/span&gt;&lt;span&gt;从 "转速 3000rpm、进给量 0.2mm/r" 调整为 "5000rpm、0.1mm/r"，遭到三位国家级工匠的联名抵制。在一次技术评审会上，老工匠将 AI 生成的工艺方案摔在桌上："这参数会让刀具寿命缩短 3/4，你们懂金属切削的热传导规律吗？" 这种经验权威与算法权威的冲突，在制造业智能化进程中屡见不鲜。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;权力架构的范式转移：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;AI 的引入会引发企业权力架构的变革，企业需妥善处理权力重构带来的矛盾，明确各部门与人员在新架构中的角色与职责。某电子代工厂上线 AI 工单调度系统后，原生产计划部的 28 名计划员中，17 人申请转岗。深层原因在于权力重构：系统将工单排产的决策权从人工转移至算法，计划员的角色从 "决策者" 变为 "异常处理者"。更微妙的是知识权力的转移 —— 某化工企业的 AI 工艺系统，因掌握了老技术员未记录的 "温度 - 压力 - 转化率" 隐性关联规则，导致车间老师傅在技术决策中的话语权骤降，最终引发两次小规模的罢工事件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:16px; margin-right:16px"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;价值锚点的重建工程：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:16px; margin-right:16px"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;从技术驱动到场景定义的范式革命&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;strong&gt;场景穿透的分子级解构：&lt;/strong&gt;&lt;span&gt;企业应摒弃盲目追求全流程智能化的思维，聚焦核心业务场景，对其进行深度解构，找到 AI 应用的精准切入点，以最小投入获取最大价值。某锂电池企业的破局路径极具参考价值：其没有上马全流程智能工厂，而是聚焦极片切割这一工序 —— 通过 AI 视觉检测与振动分析的融合，将极片毛刺检测精度从 0.1mm 提升至 0.03mm，仅此一项改进便使电池良品率提升 2.3%，年收益达 1.2 亿元。这种 "分子级场景解构" 思维正在成为新范式：某食品企业将 AI 应用拆解为 127 个微场景，其中仅 "巧克力涂层厚度在线检测" 一个场景的优化，就带来年节约成本 860 万元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;人机协同的共生进化：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;AI 的价值并非完全取代人类，而是与人类协同合作。企业需探索人机协同的新模式，发挥人类经验与 AI 技术的各自优势，实现共生进化。深圳某精密制造企业的 "AI 训练师" 计划颇具创新性：其将 50 名资深质检员转型为模型优化专家，这些老师傅每天花 2 小时标注 AI 漏检的瑕疵样本，系统则根据标注数据每周迭代一次模型。这种共生模式使质检准确率从 89% 提升至 98.7%，而人力成本仅增加 15%。更前沿的探索来自某飞机维修企业：其开发的 AR 辅助维修系统，将老技师的维修动作编码为 "知识图谱"，新技师通过 VR 训练可在 3 个月内掌握原本需要 5 年积累的故障排查经验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;strong&gt;数据资产的证券化探索：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;企业应将数据视为重要资产，通过标准化治理、价值挖掘与资产运营，实现数据资产的增值。某能源集团的 "数据银行" 模式正在开创先河：其将分散在各电厂的设备运行数据进行标准化治理，构建包含 238 个维度的设备健康指数，然后以 "数据资产包" 形式提供给保险公司 —— 保险公司据此开发 "设备预测性维护保险"，实现风险共担。这种数据资产化探索已见成效：该集团通过数据资产运营，年增收达 3.7 亿元，数据存储成本却下降 42%。在金融领域，某城商行将零售客户的消费行为数据构建为 "消费图谱"，通过联邦学习与电商平台共享，使消费贷款审批效率提升 60%，不良率下降 1.2 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;当某纺织企业用 8 万元的边缘计算盒子，解决了困扰十年的布匹疵点检测难题；当某县级医院通过云端 AI 辅助诊断系统，使肺癌早期检出率提升 35%—— 这些朴素的价值创造案例，正在重新定义 AI 落地的本质。这不是一场技术竞赛，而是一场关于 "如何用数字技术重构产业价值密度" 的深刻革命。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;在这个算力成本占比仍高达 38% 的转型深水区，在这个 92.9% 非结构化数据仍在沉睡的价值荒原，中国企业需要的不是更炫酷的算法，而是更锋利的场景解剖刀；不是更庞大的算力集群，而是更精密的数据治理显微镜；不是更激进的机器换人，而是更智慧的人机共生方程式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;当 AI 真正学会理解纺织女工指尖的触感，当算法开始懂得钢铁冶金中的炉温哲学，当数据中台能够解码老技师眼中的经验光芒 —— 那时，我们才能说，中国企业的 AI 价值重构之战，真正跨越了技术与商业的裂缝，抵达了价值创造的新大陆。这或许需要十年，或许更长，但那些正在车间油污中打磨 AI 应用的实践者们知道：路虽难，行则必至。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;飞算数智科技（深圳）有限公司（简称 「飞算科技」）是一家自主创新型的数字科技公司，也是国家级高新技术企业。公司以互联网科技、大数据、人工智能等技术为基础，凭借团队在相关领域多年的实践经验，将技术与应用深度融合，致力于为民生产业、中小企业、金融企业等不同类型客户提供科技支持与服务，助力客户实现科技化、数字化、智能化转型升级。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;飞算科技始终专注于中国原创技术的创新研发，已成功落地多项填补行业空白的技术应用。在技术落地过程中，公司得到了倪光南院士、石勇院士等国内科技泰斗的长期关注及支持，相关产品也曾先后获得图灵奖得主、美国三院院士大衞・&lt;/span&gt;&lt;span&gt;帕特森，以及沈昌祥院士、柴天佑院士、张景安院士的点评。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:20px; margin-right:20px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;经过多次演进，飞算科技不断构建核心壁垒，目前已形成产业数字科技、数智科技、数字转型科技、数字决策科技四大业务板块。旗下涵盖飞算 JavaAI、SoData 数据机器人、AI.Modeler 建模机器人、产业数智通等应用于不同业务场景的科技产品及解决方案，能充分满足客户的技术发展需要，实现全方位客户赋能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356438</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356438</guid>
      <pubDate>Fri, 09 May 2025 07:34:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>宇树科技确认：近期已完成 C 轮融资交割</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;市场消息称，宇树科技已完成了始于去年 9 月的 C 轮融资交割，由中国移动旗下基金、腾讯、锦秋、阿里、蚂蚁、吉利资本共同领投，绝大部分老股东跟投。对此，证券时报记者向宇树科技核实。宇树科技方面向记者表示，「我们最近确实完成了 C 轮融资，但其他信息暂时不清楚」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;天眼查显示，自 2016 年创立至今，宇树科技已完成 9 轮融资。最近的一轮为始于去年 9 月的 C 轮融资，彼时公司估值为 80 亿元。但在过去的半年中，宇树科技屡屡「出圈」，成为人形机器人领域最受关注的公司之一。据最新消息，宇树科技的投前估值目前已超过 100 亿元人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「宇树的估值，我觉得还是保守了。」前不久，在提到宇树科技的最新估值或达到百亿元级别时，一名宇树科技的早期投资人向证券时报记者表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="306" src="https://oscimg.oschina.net/oscnet/up-307142b03f6f36a82cf894dca3e3bdd0862.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;完成 C 轮融资交割后，宇树科技的下一步动作会否是上市？这一直是备受市场关注的焦点。今年 5 月 29 日，证券时报记者从知情人士处获取一份《公司名称变更函》。宇树科技向合作伙伴表示，因公司发展需要，杭州宇树科技有限公司即日起名称变更为杭州宇树科技股份有限公司。国家企业信用信息公示系统也显示，宇树科技已从有限责任公司变更为股份有限公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;有市场人士分析，这一变更可等同于完成股改，或许是为 IPO 上市铺路。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 4 月，香港特区行政长官李家超在杭州与「六小龙」企业代表进行了交流，并到访了宇树科技。彼时，宇树科技创始人王兴兴表示，宇树科技在香港有业务，各方面合作机会也很多。至于未来会否在香港上市，王兴兴称，有可能，但不确定。李家超鼓励宇树科技来港拓展业务，并表示香港特区政府亦可提供所需支援。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与此同时，近日 A 股市场释放的一系列提升制度包容性和适应性的信号也让市场振奋。6 月 18 日，中国证监会主席吴清在 2025 陆家嘴论坛上指出，重启未盈利企业适用科创板第五套标准上市。同日，中国证监会发布《关于在科创板设置科创成长层，增强制度包容性适应性的意见》，明确提出扩大第五套标准适用范围，支持人工智能、商业航天、低空经济等更多前沿科技领域企业适用。一系列利好信号，为像宇树科技一样的前沿科技企业提供了更广阔的发展空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不过，与大部分同行仍然处于亏损状态相比，宇树科技在商业化领域的进展也较快。今年 3 月，宇树科技早期投资人、SevenUp Capital 创始人赵楠在接受媒体采访时透露，自 2020 年以来，宇树科技的财务报表每年都保持盈利状态。宇树科技也证实了该消息。数据显示，宇树科技人形机器人出货量位居全球前列，四足机器狗全球市场占有率更是超过 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;近日，王兴兴还与公司的投资方之一，吉利控股集团董事长李书福进行了一场以「AI 时代的人才培养」为主题的对话。王兴兴回忆创业经历时表示，早年创业时机器人还属于相对冷门的赛道，但他选择这一行业并非因为市场规模、盈利前景或未来热度。最大的原因还是从小就喜欢动手做东西，希望能做一些改变世界的产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对于未来，王兴兴表示，希望能看到未来整个行业发展方向，做更好的机器人产品，更好推动整个机器人 AI 的技术进步。希望未来能让机器人去干活，更好地解放生产力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356437</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356437</guid>
      <pubDate>Fri, 09 May 2025 07:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Windows 11 市占率仅比 Windows 10 低 1%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软自 2021 年 10 月推出 Windows 11 以来，就一直在不断鼓励用户升级，但 Windows 10 的市场份额一直高于 Windows 11。不过随着 Windows 10 即将停止支持，Windows 11 的市场份额终于有望实现超越。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b7ef309abb2c8b41fbb02c7ac6fe93264a1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据 StatCounter 的最新数据，&lt;strong&gt;Windows 10 的市场份额为 48.92%，而 Windows 11 的市场份额已经达到了 47.73%，两者差距仅为 1.19%&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这意味着在未来几个月内，Windows 11 的市场份额有望超过 Windows 10，实现所谓的「黄金交叉」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3d78ab74367857f983b0a30f19c666044bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从数据来看，Windows 11 的市场份额在过去一个月中提升幅度创下新高，这可能与 Windows 10 即将停止支持有关。&lt;/p&gt; 
&lt;p&gt;微软近期也通过多种方式提醒用户尽快升级，以避免安全风险，许多用户可能选择购买新电脑或从 Windows 10 升级到 Windows 11。&lt;/p&gt; 
&lt;p&gt;Windows 11 市场份额增长最快的地区是亚洲，这个月差距已经缩小到不到 3%，相比之下，美国、日本、英国等国家的 Windows 11 份额早在几个月前就已经超过了 Windows 10。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f816ff7d41f357ec1431b4b54bd88f86e50.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这也显示出亚洲用户在操作系统升级方面相对保守，直到最后几个月才开始大规模升级。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356419</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356419</guid>
      <pubDate>Fri, 09 May 2025 06:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Andrej Karpathy 提出「软件 3.0 时代」，称自然语言正在取代传统代码</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;日前，OpenAI 联合创始人、特斯拉前 AI 负责人 Andrej Karpathy 在 Y Combinator 的 AI 创业学院活动上，进行了个人演讲。&lt;/p&gt; 
&lt;p&gt;&lt;img height="556" src="https://static.oschina.net/uploads/space/2025/0620/142721_2fd9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次演讲中，Karpathy 提出了「软件 3.0 时代」这一概念，&lt;strong&gt;他认为自然语言正在取代传统代码，而大型语言模型（LLM）则成为新的「万能计算机」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/142813_2Ldh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Karpathy 指出，软件 3.0 时代下，自然语言（如英语）将作为「编程接口」，直接给大语言模型下达命令，让模型自己完成剩下的所有工作。Karpathy 直言，这并非一次工具迭代，而是「根本性变革」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="2260" src="https://static.oschina.net/uploads/space/2025/0620/142754_fhxp_2720166.png" width="4090" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/142833_1Cbg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时，Karpathy 还提出：大语言模型兼具公共设施、晶圆厂、操作系统这三种行业的属性。如「晶圆厂」：训练大模型的巨额算力与研发壁垒，使得少数实验室成为新的「芯片制造商」。&lt;/p&gt; 
&lt;p&gt;另外，Karpathy 还展望了 AI Agent（智能体）的未来。他表示，Agent 既非人类也非传统程序，而是新的「数字信息消费者与操作者」。其进一步解释称，「因为 Agent 需要我们重新设计文档、接口乃至网络协议，为它们提供可读、可执行的‘原生’内容。」&lt;/p&gt; 
&lt;p&gt;原视频：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DLCEmiRjPEtQ" target="_blank"&gt;https://www.youtube.com/watch?v=LCEmiRjPEtQ&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356402</guid>
      <pubDate>Fri, 09 May 2025 06:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>张一鸣重回公司一线？知情人士：每月参与覆盘和讨论会</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息称，字节跳动创始人张一鸣目前主要办公地已从新加坡转到北京，从去年下半年开始，他每月会召集一次字节核心管理层和 AI 项目负责人的覆盘和讨论会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fm.thepaper.cn%2Fbaijiahao_31015094" target="_blank"&gt;澎湃新闻&lt;/a&gt;记者表示，张一鸣一直很关注 AI 业务。目前张一鸣经常往返北京和新加坡，从去年下半年开始，他每月会参加一次 seed 核心技术团队的覆盘和讨论会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="279" src="https://oscimg.oschina.net/oscnet/up-ed5561a0fb8783c67b902102fad0b52aeea.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官网介绍显示，字节跳动 Seed 团队成立于 2023 年，致力于寻找通用智能的新方法,追求智能上限。团队研究方向涵盖 LLM、语音、视觉、世界模型、基础架构、AI Infra、下一代 AI 交互等，在中国、新加坡、美国等地设有实验室和岗位。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356387</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356387</guid>
      <pubDate>Fri, 09 May 2025 05:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智元机器人在上海成立云程科技公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;天眼查资料显示，上海智元云程科技有限公司于近日成立，是一家以从事软件和信息技术服务业为主的企业。法定代表人为邓泰华，注册资本 100 万人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="266" src="https://oscimg.oschina.net/oscnet/up-ef9f219581dfc75802ad4f47bb51e48b5ee.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司经营范围包括信息技术咨询服务、会议及展览服务、市场营销策划、企业形象策划等。股东信息显示，该公司由上海智元新创技术有限公司全资持股。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356358</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356358</guid>
      <pubDate>Fri, 09 May 2025 03:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub Copilot Spaces 支持将 Issues 和 Pull Requests 作为上下文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;GitHub Copilot Spaces 现已支持将 issues 和 pull requests 作为上下文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fchangelog%2F2025-06-19-copilot-spaces-now-support-issues-and-pull-requests-public-preview%2F" target="_blank"&gt;目前处于公开预览阶段&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;用户在 Copilot Spaces 中创建空间时，只需粘贴 issue 或 pull request 的 URL，即可自动拉取其最新的标题、正文、评论、状态甚至标签作为上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fe648c5ab0d622f51ad0305a0bb2aecc6a2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一功能旨在帮助开发者更高效地进行工作。例如，在规划新功能时，可以添加工作项、功能规范和预期修改的代码，让 Copilot 协助规划方法、搭建初步更改或识别风险；在修复 bug 时，可以添加 issue 和可疑代码，让 Copilot 帮助查找问题行并提出修复建议；在跟踪工作和分享更新时，可以将新功能的所有工作项添加到空间，并与团队成员共享以回答进度和障碍问题。Copilot Spaces 可在 github.com/copilot/spaces 上供所有 Copilot 用户使用。&lt;/p&gt; 
&lt;p&gt;对于商业或企业客户，组织管理员需要选择启用 Copilot 预览功能才能使用此特性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356357</guid>
      <pubDate>Fri, 09 May 2025 03:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>用 AI 会让人变笨，过度依赖 AI 或导致损坏批判性思维与记忆力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;一项由麻省理工学院媒体实验室的 Nataliya Kosmyna 及其团队主导的&lt;span&gt;最新&lt;/span&gt;研究，深入探讨了在论文写作任务中，使用大型语言模型（LLM）如 OpenAI 的 ChatGPT 可能带来的认知成本。该研究发现，尽管 LLM 产品为人类和企业带来了诸多便利，但其广泛应用却可能导致大脑积累「认知负债」，长远来看甚至会削弱个体的学习技能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-9da4a2d7ee235a5a7411c434fda354048e0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该研究招募了 54 名参与者，并将其分为三组:LLM 组（仅使用 ChatGPT）、搜索引擎组 (使用传统搜索引擎，禁用 LLM) 和纯脑力组 (不使用任何工具)。研究共进行了四次会话，其中在第四次会话中，LLM 组的参与者被要求不使用任何工具 (被称为「LLM 转纯脑力组」)，而纯脑力组的参与者则开始使用 LLM(被称为「纯脑力转 LLM 组」)。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究团队通过脑电图 (EEG) 记录了参与者的大脑活动，以评估其认知投入和负荷，并深入理解论文写作任务期间的神经激活模式。此外，研究还进行了自然语言处理 (NLP) 分析，并在每次会话后对参与者进行了访谈，同时邀请人类教师和 AI 评判员对论文进行打分。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-a56dd98b0353f8374fe7d0874c8ffcf7a89.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心发现：大脑连接性减弱，记忆和所有权受损&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究结果提供了确凿证据，表明 LLM、搜索引擎和纯脑力组的神经网络连接模式存在显著差异，反映了不同的认知策略。大脑连接性与外部支持的程度呈系统性下降：纯脑力组表现出&lt;span&gt;最强&lt;/span&gt;、范围最广的连接网络，搜索引擎组居中，而 LLM 辅助则引发了最弱的整体耦合。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特别值得关注的是，在第四次会话中，「LLM 转纯脑力组」的参与者表现出较弱的神经连接性，以及阿尔法（alpha）和贝塔 (beta) 网络的投入不足。阿尔法波段连接性通常与内部注意力、语义处理和创造性构思相关。贝塔波段则与主动认知处理、专注注意力和感觉运动整合相关。这些结果表明，过去依赖 LLM 的使用者，在脱离工具后，其大脑在内容规划和生成方面的神经活动有所减少，这与认知卸载的报告相符，即依赖 AI 系统可能导致被动方法和批判性思维能力的减弱。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在记忆方面，LLM 组的参与者在引用自己刚写完的论文时表现出明显障碍，甚至无法正确引用。这直接映射到 LLM 组较低的低频连接性，特别是与情景记忆巩固和语义编码密切相关的西塔（theta）和阿尔法波段。这表明 LLM 用户可能绕过了深层记忆编码过程，被动地整合了工具生成的内容，而没有将其内化到记忆网络中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，LLM 组对自己论文的所有权感知度普遍较低，而搜索引擎组拥有较强的所有权感，但仍低于纯脑力组。这种行为上的差异与神经连接性模式的变化相吻合，凸显了 LLM 使用对认知能动性的潜在影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;认知负债的积累&lt;/strong&gt;：&lt;strong&gt;效率与深度学习的权衡&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究指出，尽管 LLM 在初期提供了显著的效率优势并降低了即时认知负荷，但随着时间的推移，这种便利可能以牺牲深度学习成果为代价。报告强调了「认知负债」的概念:重复依赖外部系统（如 LLM）取代了独立思考所需的努力认知过程，短期内延迟了脑力投入，但长期却导致批判性探究能力下降、更容易被操纵以及创造力减退。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;纯脑力组的参与者，尽管面临更高的认知负荷，却展现出更强的记忆力、更高的语义准确性和对其作品更坚定的主人翁意识。而「纯脑力转 LLM 组」在&lt;span&gt;首次&lt;/span&gt;使用 AI 辅助重写论文时，大脑连接性显著增加，这可能反映了将 AI 建议与现有知识整合时的认知整合需求，暗示了 AI 工具引入的时机可能对神经整合产生积极影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;对教育环境的深远影响与未来展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究团队认为，这些发现对教育领域具有深远意义。过度依赖 AI 工具可能无意中阻碍深层认知处理、知识保留以及对书面材料的真实投入。如果用户过度依赖 AI 工具，他们可能会获得表面的流畅度，但却无法内化知识或对其产生所有权感。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该研究建议，教育干预应考虑将 AI 工具辅助与「无工具」学习阶段相结合，以优化即时技能转移和长期神经发展。在学习的早期阶段，全面的神经参与对于发展强大的写作网络至关重要;而在后续练习阶段，有选择性的 AI 支持可以减少无关的认知负荷，从而提高效率，同时不损害已建立的网络。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人员强调，随着 AI 生成内容日益充斥数据集，以及人类思维与生成式 AI 之间的界限变得模糊，未来研究应优先收集不借助 LLM 协助的写作样本，以发展能够识别作者个人风格的「指纹」表示。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最终，这项研究呼吁在 LLM 整合到教育和信息情境中时，必须谨慎权衡其对认知发展、批判性思维和智力独立性的潜在影响。LLM 虽然能减少回答问题的摩擦，但这种便利性也带来了认知成本，削弱了用户批判性评估 LLM 输出的意愿。这预示着「回音室」效应正在演变，通过算法策划内容来塑造用户接触信息的方式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;（研究论文标题为《Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task》，主要作者为麻省理工学院媒体实验室的 Nataliya Kosmyna 等。）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356351</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356351</guid>
      <pubDate>Fri, 09 May 2025 03:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
