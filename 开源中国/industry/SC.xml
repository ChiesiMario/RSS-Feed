<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 20 Aug 2025 07:41:34 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Reddit 季度收入创历史新高，得益于人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;Reddit 依托其独特的小众社区文化和活跃的问答氛围，正在人工智能（AI）领域实现盈利增长。该平台的&lt;span&gt;最大&lt;/span&gt;资产在于其用户生成的真实内容，这一优势让 Reddit 在与大型科技公司合作时，占据了有利位置。公司通过 AI 授权，将平台上的子版块内容整合入搜索引擎结果中，显著提升了网站流量，并为广告主提供了精准的目标受众。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-4397aa3bf8abe3165b1b0cc3c7e0843e093.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近年来，Reddit 在财务业绩方面屡次超越市场预期，用户每位收入（ARPU）增长速度远远快于其他社交媒体平台。这一趋势推动了 Reddit 股票的上涨，令其市场估值达到新高。随着投资者对 Reddit 未来增长的信心增强，该公司的股票在过去三个月内上涨了 123%，年内涨幅更是超过 344%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;分析师们对 Reddit 的盈利前景持续看好。数据显示，Reddit2025 年的每股收益（EPS）预期从最初的 1.14 美元上调至 1.86 美元，增幅达 63%。此外，2026 年和 2027 年的 EPS 预期也有所上升，分别增长了 31% 和 14%。这表明市场对红迪网的长远发展充满信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的快速增长得益于其在人工智能整合和数据授权方面的成功。最近发布的 「Reddit 问答」 搜索引擎大大提高了用户互动和流量，带动了广告支出的显著增加，用户每位收入年增长率达到 47%。这一成果超出了行业内对其逐步发展的预期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的竞争优势在于其丰富的用户数据和问答文化，结合 AI 技术，使得每一条内容不仅具有高价值，还能与广告信息无缝对接。这种独特的 「防御性」 网络效应，让其他社交平台难以复制 Reddit 的成功模式，帮助其在 AI 应用上走在了行业前列。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管 Reddit 目前的市盈率较高，投资者仍然看好其市场前景。分析师们对 Reddit 的股票保持普遍乐观，虽然有少数持谨慎态度的观点，但整体市场支持度依然强劲。只要 Reddit 能够持续保持良好的增长趋势，其股票溢价便是合理的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367390</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367390</guid>
      <pubDate>Wed, 20 Aug 2025 07:25:31 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Manus 年化收入运行率突破 9000 万美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在新加坡举行的 Stripe Tour 活动上，AI Agent 初创公司 Manus 联合创始人兼首席科学家季逸超（Peak）公布了一项令业界瞩目的数据：公司当前收入运行率 (RRR) 已达到 9000 万美元，约合人民币 5400 万元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;收入运行率是高速成长型企业常用的财务指标，通过将特定时期收入推算为年化数值。虽然季逸超未透露具体计算方式，但按月度收入推算，Manus 月收入约为 750 万美元。对于一家成立不足三年的 AI Agent 公司，这一表现已远超行业平均水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-61c3893c8632aefbb4164d5eab1a71cbd70.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Manus 表示，公司收入主要依托订阅型服务模式，显示出较强的用户粘性和相对稳定的现金流结构。业内分析师认为，9000 万美元的收入运行率将为 Manus 在下轮融资中带来更强议价能力。按照当前表现，公司可能被资本市场按"年度收入过亿美元"的预期进行估值，这将显著提升其市场地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，今年 7 月 Manus 总部迁至新加坡的战略调整，结合此次公布的财务数据，显示公司正在全球市场加速布局。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;尽管数据亮眼，业内人士提醒投资者保持理性。收入运行率并非实际收入，其可持续性仍需市场长期验证。在 AI 商业化竞争日趋激烈的环境下，Manus 能否将运行率转化为稳定的年度实际收入，以及在全球市场的扩张执行力，将成为决定其未来发展的关键因素。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367382</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367382</guid>
      <pubDate>Wed, 20 Aug 2025 06:55:31 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动即将发布「世界模型」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fbytedances-upcoming-world-model-altmans-thoughts-gpt-5-fiasco-profitability-going-public" target="_blank"&gt;根据 The Information 的报道&lt;/a&gt;，字节跳动正在筹备自己的「世界模型」（world model），以追随谷歌和 Meta 的步伐。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/145228_hX8P_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该项目由字节跳动的「Seed」人工智能研发部门主导，项目负责人是前阿里通义千问（Qwen）核心高管周畅。字节跳动在视频生成领域的积累——尤其是旗下抖音和 TikTok 的海量视频数据，以及近期开源的 EX-4D 框架（可将单目视频转化为 4D 多视角场景）——为其构建世界模型提供了技术基础和训练资源。&lt;/p&gt; 
&lt;p&gt;「世界模型」旨在模拟真实环境的物理规律和人类互动方式，未来可用于训练机器人、自动驾驶系统或构建虚拟世界，被视为通向通用人工智能（AGI）的重要路径之一。&lt;/p&gt; 
&lt;p&gt;近期，谷歌和 Meta 都分别推出了自家新款世界模型——Genie 3 和 V-JEPA 2。世界模型能模拟出真实的环境，旨在获得与真实世界相似的物体运动以及人类与周围环境互动的物理方式，从而用于训练机器人和自动驾驶模型。&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/364530/genie-3" target="_blank"&gt;谷歌发布世界模型 Genie 3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/355002/meta-vjepa-2-world-model" target="_blank"&gt;Meta 发布开源世界模型 V-JEPA 2&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367380</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367380</guid>
      <pubDate>Wed, 20 Aug 2025 06:54:31 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智谱发布 AutoGLM 2.0：全球首个手机 Agent、云端自主完成任务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj6BGkYXc8sMsh-iOMYTiaw" target="_blank"&gt;智谱宣布推出 AutoGLM 2.0&lt;/a&gt;，声称将 Agent 应用提升到新的高度：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;全球首个手机 Agent，人人可用；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;开创 Agent + 云手机 / 云电脑的新技术范式，不抢占用户手机和电脑；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;突破硬件限制，在任何设备、任何场景下运行，帮助用户代理操作；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;国产模型（GLM-4.5、GLM-4.5V）驱动，具备推理、代码与多模态的全能能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="786" src="https://static.oschina.net/uploads/space/2025/0820/143328_bZzY_2720166.png" width="1800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;智谱称，即刻起，人人都可使用 AutoGLM。该公司还将快速迭代推出新功能（「定时任务」 很快上线，AI 每天主动替你干活）。&lt;/p&gt; 
&lt;p&gt;在 AutoGLM 1.0 中，智谱已探索过让 AI 代替用户完成部分手机操作，但只在有限场景下生效。&lt;/p&gt; 
&lt;p&gt;据介绍，随着 AutoGLM 2.0 的发布，它已经成长为一名执行型助手，能够在「云端」自主完成多样化的任务。在生活场景中，用户只需一句话，就能让 AutoGLM 操作美团、京东、小红书、抖音等几十个高频应用：点外卖、订机票、查房源，例如帮你买「秋天的第一杯奶茶」。在办公场景中，它同样能跨网站执行全流程工作，操作网页版的飞书、网易邮箱、知乎、微博、抖音、微头条等网站：从信息检索到内容撰写，再到生成视频、PPT 或播客，并直接完成小红书、抖音等社交媒体平台内容发布。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/143743_Rif8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;智谱称，「这意味着，AI 不再是一个 「聊天工具」，而是一个能真正替你干活的全能代理人。不仅能给出答案，还能把任务完整执行，帮助用户节省时间与精力，彻底改变人与 AI 的协作方式。」&lt;/p&gt; 
&lt;p&gt;在 AutoGLM 2.0 中，智谱为 AI 配备了专属智能体手机 / 智能体电脑，让它可以在云端自主干活、完成任务，而无需占用用户的本地设备，期间用户可以使用其他 App（如刷抖音、打游戏）。&lt;/p&gt; 
&lt;p&gt;据介绍，AutoGLM 由智谱最新开源 SOTA 语言模型 GLM-4.5 与视觉推理模型 GLM-4.5V 驱动。AutoGLM 将基座模型原生能力发挥到极致，并结合在「端到端异步强化学习」方面的多项突破成果，可以完成推理、编码、研究、Agentic 与 GUI 操作等多类任务，并可根据需求灵活调用最合适的「大脑」完成执行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ComputerRL&lt;/strong&gt;：提出 API-GUI 协同范式，提升数据多样性与计算效率；改进 GRPO 并提出 Entropulse 机制，增强探索与策略多样性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MobileRL&lt;/strong&gt;：创新难度自适应强化学习方法（推理自举预热 + 难度自适应 GRPO），显著提升移动端任务的稳定性与收敛效率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AgentRL&lt;/strong&gt;：通过交叉采样与任务优势归一化机制，解决多任务训练中的不稳定与梯度分布不均，增强整体鲁棒性与效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在&lt;strong&gt;Device Use 基准测试&lt;/strong&gt;（涵盖手机、电脑和网页操作）中，AutoGLM 表现优于&lt;strong&gt;ChatGPT Agent、UI-TARS-1.5 和 Claude Sonnet 4&lt;/strong&gt;，展现出更强的鲁棒性与通用性，处于主流 Agent 的&lt;strong&gt;SOTA&lt;/strong&gt;水平。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/143914_h7cV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;智谱称，已将 AutoGLM 的操作执行能力封装为 API，开发者只需简单接入，即可将这一能力无缝融入各类硬件设备，从 AI 眼镜等可穿戴设备到传统家电。AutoGLM 首次让硬件具备完整的手机级操作能力，无需在端侧堆叠复杂系统或大容量电池。例如，可以通过智能眼镜点一杯咖啡。&lt;/p&gt; 
&lt;p&gt;今日起，AutoGLM 移动端 API 申请通道及开发者生态共建计划正式上线。除手机与电脑外，手表、眼镜、家电等设备都能成为 Agent 驱动的智能助手。&lt;/p&gt; 
&lt;p&gt;传送门：&lt;em&gt;https://autoglm.zhipuai.cn/misc/developer-apply&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;更多技术细节，请参阅 GLM 团队的三篇最新技术论文：&lt;/p&gt; 
&lt;p&gt;ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents&lt;br&gt; &lt;em&gt;https://arxiv.org/abs/2508.14040&lt;/em&gt;&lt;br&gt; MobileRL: Advancing Mobile Use Agents With Adaptive Online Reinforcement Learning&lt;br&gt; &lt;em&gt;https://github.com/Xiao9905/AutoGLM/blob/main/static/papers/mobilerl_0820.pdf&lt;/em&gt;&lt;br&gt; AgentRL: Reinforcing Multi-task LLM Agents From Zero (Upcoming)&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367374</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367374</guid>
      <pubDate>Tue, 19 Aug 2025 06:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>金山等软件被常用工具弹窗推广，流氓行为传播数十万终端</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;火绒安全发布报告称，近日收到多位用户反馈称在安装某些工具类软件时遭遇广告弹窗及其他流氓行为。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对捕获的样本进行分析发现，该样本主要通过捆绑在 Zip 解压缩、PDF 转换器及录屏软件等常用工具的安装包中进行传播，会执行包括静默推广安装金山毒霸、WPS、CAD 看图王等软件在内的一系列流氓行为，并最终伪装成插件进行集成和大规模传播。流氓行为已传播数十万终端。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据火绒威胁情报系统监测，该样本已感染超过数万台电脑，传播范围波及数十类网站，包括 Zip 解压缩、录屏、PDF 转换器、壁纸、DLL 修复、全能格式转换、OCR 扫描等多种类型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;样本流程图如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="393" src="https://oscimg.oschina.net/oscnet/up-a8431841a25501ff7ae752027ae9d182859.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该样本采用 C# 开发，初始版本为一个简单的下载器（Loader），主要功能是从阿里云存储桶中获取安装包，并通过命令行实现静默安装压缩包的功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;样本的主要逻辑为：通过代码伪造安装界面，包括构造所需数据、下载配置文件、获取云端配置信息，并完成 UI 设置；随后，通过用户点击按钮的操作触发静默安装。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对网站 https://zip.njzhqlkj.cn 进行溯源分析发现，其 JS 脚本被多个域名引用。进一步分析表明，这些域名中有相当一部分在下载的程序中都捆绑了该恶意服务，其中还有大部分已经失效的域名。涉及的域名包括：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="224" src="https://oscimg.oschina.net/oscnet/up-793cbede66ca1a1645e4e110f2ecefeed51.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;部分失效域名如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="627" src="https://oscimg.oschina.net/oscnet/up-13f6f36640b14098198360613753d93765e.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多详情可&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcyngfrD--tEEY02_sbSiRw" target="_blank"&gt;查看官方公告&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367373</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367373</guid>
      <pubDate>Tue, 19 Aug 2025 06:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 岗位月薪最高 7.8 万，实习生日薪可达 4000 元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;职场社交招聘平台脉脉发布的岗位统计数据显示，2025 年人工智能领域人才需求呈现爆发式增长，相关岗位数量与薪资水平均大幅上涨，从业者跳槽意向也较为显著。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;数据显示，2025 年 7 月，脉脉平台上人工智能新发岗位量相较 2024 年 1 月暴涨 29 倍，同比增长 10 倍。目前已有超过 1000 家人工智能企业在平台招聘人才，相关在招岗位数量超过 7.2 万个。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得注意的是，除技术岗位外，设计、销售、人事、财务、行政、运营、市场等多个非技术岗位也在热招，显示出人工智能行业对复合型人才的广泛需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="261" src="https://oscimg.oschina.net/oscnet/up-572a37607adc58b4b4ce2afe6c1f0054471.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;薪资方面，人工智能相关岗位的薪酬水平持续走高。2025 年 7 月，人工智能相关岗位的招聘薪资下限均值为 4.7 万元/月，较 2024 年 1 月上涨 14.16%；上限均值为 7.8 万元/月，较 2024 年 1 月上涨 8.98%。即便在实习岗位中，部分人工智能实习生的日薪可达 4000 元，远超多数行业正式员工的收入水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与此同时，人工智能领域从业者的跳槽意向较为明显。脉脉商业运营总监杨滢透露，自 2025 年 2 月以来，脉脉上每月新增上万名「正在看机会」的 AI 人才。截至 2025 年 7 月，国内 AI 头部公司中有 41.07% 的员工求职状态为「正在看机会」，具有明确的跳槽意愿。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对于求职者而言，在脉脉上搜索「AI」，不仅可以发现正在热招的人工智能高薪岗位，还能与多家人工智能企业的高管、员工直接取得联系，从而获取更多人工智能领域的职场新机遇。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367372</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367372</guid>
      <pubDate>Tue, 19 Aug 2025 06:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 联合多家公司推出 AGENTS.md，开放且供应商中立的编程 Agent 指导文件标准</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;由 OpenAI Codex、Amp、Google Jules、Cursor、RooCode 和 Factory 组成的 AGENTS.md 工作组宣布，正式推出一个名为 AGENTS.md 的单一、开放且供应商中立的标准，旨在指导编码 Agent 在代码库中的工作方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a900f271b1a5c51b12eb76900d35ea72fa3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/openai/agents.md&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://agents.md/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AGENTS.md 被定位为 「&lt;strong&gt;为 Agent 设计的 README&lt;/strong&gt;」，是一个简单、开放的格式，用于向编码 Agent 提供指导。其设计初衷是为了补充专为人类开发者设计的 README.md 文件。README.md 通常包含快速入门、项目描述和贡献指南，而 AGENTS.md 则专注于提供编码 Agent 所需的额外、详细的上下文信息，例如构建步骤、测试指令、项目结构、代码约定和安全注意事项等。&lt;/p&gt; 
&lt;p&gt;AGENTS.md&amp;nbsp;作为面向 AI 编程 Agent 提供项目上下文和操作指令的开放格式，它通过结构化的方式详细指导 AI 代理如何进行开发环境设置、执行代码测试以及遵循拉取请求（PR）的提交规范，例如使用特定命令导航、安装依赖、运行各种测试以及格式化 PR 标题等。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# AGENTS.md

## Setup commands
- Install deps: `pnpm install`
- Start dev server: `pnpm dev`
- Run tests: `pnpm test`

## Code style
- TypeScript strict mode
- Single quotes, no semicolons
- Use functional patterns where possible
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这种分离设计旨在为 Agent 提供一个清晰、可预测的指令来源，同时保持 README.md 对人类贡献者的简洁性和专注度。&lt;/p&gt; 
&lt;p&gt;使用 AGENTS.md 的方法很简单：在代码仓库的根目录下创建一个 AGENTS.md 文件。对于大型的 monorepo，可以在每个子项目或包内放置一个嵌套的 AGENTS.md 文件。Agent 会自动读取目录树中最近的该文件，使其指令具有针对性，最接近的配置文件将拥有优先权。&lt;/p&gt; 
&lt;p&gt;目前，该标准已获得 Cursor、Amp、Jules、Factory、RooCode 和 Codex 等多种 AI 编码 Agent 和工具的支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367347</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367347</guid>
      <pubDate>Tue, 19 Aug 2025 04:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源剪贴板工具 Ditto 「删库」，GitHub 主页显示 404</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;知名 Windows 开源剪贴板工具 Ditto 托管在 GitHub 的源代码已经无法访问，页面显示 404。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-04239240a2badd23bca6b79fbcde83c0d9a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;而且不仅是 Ditto 项目本身，开发者整个的账号都不见了，不过 Ditto 的官方网站仍然可以正常访问，在微软 Microsoft Store 也可以下载。&lt;/p&gt; 
&lt;p&gt;Ditto 自 2004 年发布以来，一直以其开源、免费且功能强大的特点受到用户的喜爱，它能够保存用户复制的所有内容，包括文本、图片、HTML 等，并允许用户后续快速调用。&lt;/p&gt; 
&lt;p&gt;此外，Ditto 还支持网络共享剪贴板内容，提供了合并粘贴、纯文本粘贴、分组、置顶、快速搜索和热键粘贴等功能。目前，关于 Ditto 源代码库被删除的具体原因尚不清楚，也没有官方声明对此作出解释。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367341</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367341</guid>
      <pubDate>Tue, 19 Aug 2025 03:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>扎克伯格计划重组 Meta 人工智能部门</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta 首席执行官马克・扎克伯格正积极调整公司的人工智能业务。为了更好地应对市场竞争，Meta 计划将其人工智能部门 ——Meta&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;超级&lt;/span&gt;智能实验室拆分为四个小组。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据知情人士透露，其中一个小组将专注于人工智能研究，另一个小组将致力于开发名为 「&lt;span&gt;超级&lt;/span&gt;智能」 的新一代强大人工智能技术。其他两个小组则分别负责产品开发和基础设施建设，包括数据中心及相关硬件。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-753b04ace93aaef5886ed55fd23ec57f818.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这一改革的目的在于优化资源配置，提高人工智能产品的开发效率。然而，随着部门的重组，一些高管可能会离职。此外，由于人工智能部门的规模近年来已扩展至数千人，Meta 正在考虑整体精简，包括裁员或将部分员工调至其他部门。这些讨论仍在进行中，尚未做出最终决定。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta 的人工智能战略此前经历了多次动荡，扎克伯格对此表示愈发重视。他愿意投入巨资，进行彻底改革，以在快速发展的人工智能领域保持竞争力。今年 6 月，Meta 成立了&lt;span&gt;超级&lt;/span&gt;智能实验室，专注于打造超越人类大脑的人工智能。为此，Meta 向初创公司 Scale AI 投资了 143 亿美元，并聘请该公司的首席执行官亚历山大・王担任人工智能首席官。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在过去的几个月里，扎克伯格的决策引发了公司内部的紧张局势。亚历山大・王的新团队正在努力打造公司&lt;span&gt;最强&lt;/span&gt;大的人工智能模型，并讨论将新模型设为 「闭源」，这与 Meta 长期以来的 「开源」 理念形成鲜明对比。同时，部分 Meta 的老员工对新团队的引入表示不满，尤其是在 OpenAI 的研究员赵胜佳被任命为首席人工智能科学家后，老员工们的工作受到了更多审视。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;人事变动还在持续，早期参与 Meta 人工智能研究的高管们也在不断离职。Meta 的一些&lt;span&gt;顶尖&lt;/span&gt;科学家相继跳槽，导致公司内部的士气和稳定性受到影响。尽管如此，一些&lt;span&gt;资深&lt;/span&gt;的人工智能负责人依然留在公司，继续推动基础研究的进展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367332</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367332</guid>
      <pubDate>Tue, 19 Aug 2025 03:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美团智能头盔研发实践系列 01：硬件设计篇</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;本文系《美团智能头盔研发实践》系列的第一篇文章，聚焦硬件设计维度。针对外卖骑手传统头盔佩戴体验不佳等痛点，从安全保障、体验优化、效率提升三大方向切入，详细解析安全防护、多传感器预警、通风减重、长效续航、音频降噪、工艺控制等关键技术，并提炼研发过程中行之有效的设计经验。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-79872a5be02de16ae8c86ed25e8abf50075.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;前言&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;在现代城市的喧嚣中，外卖骑手穿梭于大街小巷，只为将餐食及时送达顾客手中。然而，这份看似简单的工作背后，却隐藏着诸多痛点。骑手们面临的交通环境复杂，这不仅对他们自身的安全构成严重威胁，也增加了交通事故的风险。同时，在配送过程中，骑手需要频繁操作手机接单、打电话与顾客沟通，这在骑行过程中极不方便，还容易分散注意力。此外，长时间佩戴传统头盔，闷热、不舒适以及头盔稳定性差等问题，也极大地影响了骑手的工作体验。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//19f460a4db11dda9787ef4225c0142c3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;面对这些痛点，美团推出了智能头盔，努力为骑手们提供一种全新的安全守护解决方案，展现出安全保障、体验优化以及效率提升三大核心价值。本文为美团技术团队在硬件设计层面的一些思考和探索。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;智能头盔革新：重新定义配送安全装备&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美团智能头盔作为专为外卖骑手打造的智能安全装备，在传统头盔基础上，增加了喇叭、麦克风、快捷按键、尾灯等硬件模组，具备蓝牙耳机/语音助手功能，实现智能语音交互、实时感知戴盔、碰撞和摔倒等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//dabfa05505233a93228ada853953d011.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;美团研发智能头盔已有 6 年时间，研发模式从 ODM、JDM 直至 OEM 纯自研模式，目前已覆盖全国 S/A/B 级别 28 座城市的全量专送骑手，累计出货量突破 100 万，已经成为 B 端/C 端智能头盔行业出货量最大的机构之一。这些智能头盔，针对行业痛点，为外卖骑手提供了更安全、高效、领先行业的戴盔体验，努力为外卖骑手提供了一份守护。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a69aebc2198de8ad37a204fa71fce72c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;安全防护体系：超越国标与主动预警的双重守护&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;2.1 更严苛的头盔设计标准&lt;/h3&gt; 
&lt;p&gt;头盔设计需要满足国家强制标准，在行业中，电动车头盔设计满足电动自行车乘员头盔标准就足够了（GB 811-2022 B3 电动自行车乘员头盔国家标准）。但从骑手安全角度出发，美团主动将设计标准提升至摩托车头盔级别（GB 811-2022 A3 摩托车乘员头盔国家标准）。世界衞生组织（WHO）数据显示，佩戴头盔能显著降低摩托车事故伤亡率，可减少近 40% 的死亡风险、超 70% 的严重受伤概率。美团智能头盔从基础防护层面，努力为骑手安全筑牢根基。&lt;/p&gt; 
&lt;h3&gt;2.2 智能预警系统主动防护安全&lt;/h3&gt; 
&lt;p&gt;美团智能头盔以「传感器 + 算法」构建主动安全防护网，将被动保护升级为智能预警。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;佩戴状态智能监测&lt;/strong&gt;：在实际工作中，即便配备了头盔，仍存在部分骑手有盔不戴的现象。美团智能头盔通过三轴传感器与红外传感器的联动组合，并与骑手 App 紧密联动，有效解决了这一难题。一旦检测到骑手未正确佩戴头盔，系统会及时发出提醒，确保骑手在骑行过程中时刻处于头盔的保护之下。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自适应尾灯预警&lt;/strong&gt;：夜晚或光线较暗的环境下，骑行安全面临更大挑战。美团智能头盔内置光敏传感器，当外界光线变弱时，自感应尾灯会自动亮起，而且其较高的尾灯位置，能够有效地引起大吨位货车、卡车等高驾驶位司机的注意，减少因驾驶盲区而引发的事故。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;碰撞摔倒应急响应&lt;/strong&gt;：头盔还具备碰撞摔倒检测功能，一旦检测到骑手摔倒，会在第一时间发出报警，并迅速联系骑手确认情况，为骑手的生命安全增添了一份有力的保障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.3 三重铠甲防护电池安全&lt;/h3&gt; 
&lt;p&gt;针对智能头盔复杂的工况，如不同地区环境温度的差异、对各类手机充电器和充电线的适配、长期高频次充电习惯带来电池寿命衰减、佩戴区域敏感等考虑。头盔设计了三重防护"铠甲"，守护每一次骑行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;来自底层硬件的"钢铁守衞"&lt;/strong&gt;：智能充电芯片 24 小时监控电压电流，电池过压、过流和过放时快速断电。即使芯片失效，电池自带过充、过放、短路保护提供双重保险，安全无死角。同时高精度电量计实时采集电池数据，精准监测电池健康状态。针对目前市场上由于劣质或长期破损的充电线在 TYPE_C 处出现的自发热问题，头盔在 TYPE_C 处加入 NTC 实时温度检测，该处高温时自动停止充电。避免该处发热引起的电池安全隐患，进一步提高头盔电池的安全保障。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;来自软件的"温度管家"&lt;/strong&gt;：0℃~55℃ 智能温控，电池温度超出范围立刻停止充电。同时具备高温自动紧急处理，充电时超过 75°C 语音告警。未充电时超过 75°C 自动切断电池，进入安全模式。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;来自云端的"大数据哨兵"&lt;/strong&gt;：实时分析头盔上报的数据，提前预警异常。通知官方介入，防患于未然。电池安全防护的引入是智能头盔向高可靠性、长生命周期发展的必然结果。它既是功能实现的基石，也是用户体验的核心要素。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//7bea5408d9da2db656fa4f3969851c56.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;穿戴体验革命：轻量化与功能性的极致平衡&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;3.1 从头盔到电子模组的极致结构减重技术&lt;/h3&gt; 
&lt;p&gt;对于外卖骑手而言，头盔减重技术绝非简单的数字游戏，而是关乎职业体验的关键革新。700g 左右的传统头盔如同 "铁帽" 般压在头顶，每骑行一小时就可能累积近半公斤的垂直压力，导致颈椎劳损与疲劳感加剧。美团智能头盔通过「材料基因 + 工艺重构 + 系统集成」的三重减重革命，将整机重量降至 550g，在摩托车头盔国标框架内实现「安全不减重」的技术突破。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;吸塑工艺 - 给头盔外壳"削骨减肥"&lt;/strong&gt;：摩托车头盔设计的困难点在于，头盔保护头部的要求和轻量化之间的矛盾，行业上一般使用注塑的方式生产头盔外壳，常用的工程塑料成本低，但密度较高，轻量化空间有限。而且因注塑工艺的局限性，外壳无法设计的很薄，否则将无法生产。K3SX1 智能头盔采用吸塑一体成型工艺替代传统注塑方案，吸塑工艺可以将头盔外壳设计的很薄，配合高强度 PC 材料，头盔外壳厚度可减薄一半，大幅度减轻重量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;双密度材料 - 给防护层"精准减脂"&lt;/strong&gt;：吸塑一体成型工艺解决外壳重量的问题，但为了通过穿刺测试，缓冲层的密度还是比较大，导致缓冲层重量过重。双密度减重技术通过精确控制材料密度分布（头盔对安全要求高的部分使用高密度缓冲材料，头盔主体部分使用低密度缓冲材料），在保证外壳抗冲击、穿刺强度符合 GB 811-2022 摩托车乘员头盔国家标准的前提下，实现结构轻量化。经实测，相较于前代产品，头盔盔体重量减轻 85g，降幅达 25%。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;配件系统 - 从镜片到织带的"全身协同瘦身"&lt;/strong&gt;：镜片、织带等配件通过高强度复合材料应用与薄壁化设计，在满足抗穿透性与佩戴安全性的基础上，进一步降低产品整体重量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c2edb6d8b96f33e8e1d09a85dd6afa3e.png" alt="双密度盔体：头盔测试区部分使用高密度缓冲材料（灰色），头盔主体部分使用底密度缓冲材料（黄色）" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;电子模组 - 模块化集成的"系统级轻量革命"&lt;/strong&gt;：电子系统，采用模块化设计方案，分为主控模组、喇叭模组、按键模组和麦克红外模组。采用一拖三的方式，都和主控模组用线连接，没有对接端子，可以实现防水和减重。模组采用薄壁轻量化设计，在保证模型性能不受影响的前提下，有效降低了模组的重量。主控模组集成尾灯设计，相比单独的尾灯，减少了尾灯配件，大幅降低重量。麦克红外模组，采用灌胶密封的工艺，相比常规 AB 壳方案，减少了后壳、密封圈、螺丝、线束密封等配件，有效降低了组装复杂性和重量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过盔体、镜片、织带、电子模组等多重的减重措施，最终实现整机重量仅 550g，成为当前符合摩托车头盔国标认证的智能头盔中最轻量级产品。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a14c1d21837b140f455e181aae203417.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.2 多孔道通风结构设计与安全强化&lt;/h3&gt; 
&lt;p&gt;对骑手而言，头盔通风技术是对抗酷暑的关键刚需。传统头盔在高温下如蒸笼，易致头部闷热、注意力分散，甚至引发安全隐患。为解决传统头盔通风不足问题，K3SX1 在原有 4 个通风孔基础上，新增 16 个导流式通风孔，构建 20 孔三维贯通通风系统。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多孔道通风结构设计&lt;/strong&gt;：在头盔行业里，一般只有自行车头盔顶部有开孔，且因自行车头盔标准无穿刺测试要求，开孔设计挑战较低；而摩托车头盔出于安全考量，顶部通常不设置开孔，即便少数产品开孔，也多见于注塑外壳的头盔，吸塑一体成形的摩托车头盔开孔案例极少。这一设计面临着国标穿刺测试（要求头盔抵御 3kg 钢锥从 1m 高度自由落体的冲击）的严峻挑战。研发团队通过有限元分析（FEA）技术和实际实验，对不同孔径、缓冲层密度方案进行验证，最终确定采用双密度方案与局部 PC 片加强设计，在保证通风效率提升的同时，确保穿刺测试通过率达 100%，实现通风性能与安全标准的完美平衡。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//09159c0e5e4fef53b56f425763da3bc5.png" alt="双密度方案与局部加强设计" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;空气动力学优化与热湿交换效率提升&lt;/strong&gt;：基于 CFD（计算流体动力学）仿真技术，K3SX1 的通风系统采用前侧进气口导流设计与后侧负压抽气结构，360°全方面散热，骑行风感更加强劲。搭配疏水速干三明治网布内衬，加速导湿排汗，显著改善骑手长时间作业的热舒适性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ab6491389696f42319264e9beaf29e89.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.3 硬件极致设计引领续航三倍飞跃&lt;/h3&gt; 
&lt;p&gt;传统智能头盔续航体验较差，骑手基本一天就需要充电一次，严重影响骑手的工作效率和使用体验。为了解决头盔续航时间短这个痛点，通过分析问题的根本原因，发现主控系统+蓝牙系统+通信模组的多系统工作模式，以及音频功放器件是功耗的主要消耗点。K3SX1 从这两个点进行重构和变革，大幅降低产品的能耗，提升产品的续航能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;复杂多系统到单中国"芯"的改革&lt;/strong&gt;：多系统的复杂硬件架构，硬件复杂度和功耗都居高不下，全新的硬件设计采用全自主知识产权的国产高性能蓝牙芯片，芯片采用 32 位双核 DSP 架构，系统时钟最高达 160MHz，具备更广泛的匹配兼容性与更智能的内置算法等特点。通过优化主芯片电源管理单元、采用先进制程工艺等创新，实现主芯片在高性能运行的同时将功耗控制在较低水平。芯片的静态功耗低于 100uA，工作功耗仅有 mA 级别。单芯片系统也大幅减少了外设器件，同时大幅降低整体功耗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;音频功放的换代升级&lt;/strong&gt;：音频功放是头盔的使用场景中使用频次最高的器件，传统的 AB 类音频功放，工作效率低。K3SX1 把音频功放从 AB 类升级为 D 类，工作效率由 50% 提升至 90%，大幅延长电池续航时间。在电池容量减少 40%（从 2000mAh 降至 1200mAh）的情况下，续航时间从 12 小时提升至 36 小时，达到行业领先水平，彻底消除骑手对电量不足的担忧，让其更专注于骑行工作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.4 六层堆叠助力出色音频&lt;/h3&gt; 
&lt;p&gt;在智能头盔行业，主流方案多依赖高性能算法芯片实现降风噪，虽有效但成本较高；部分产品尝试采用泡棉降噪，却因泡棉面积小导致过滤效果有限，且吸水后性能易失效。K3SX1 通过六层堆叠设计，突破传统方案局限，实现 50km/h 骑行速度下的清晰语音通话。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;下沉式拾音区域设计&lt;/strong&gt;：拾音区域低于头盔前沿，可以减弱风对拾音面的冲击，使气流绕过拾音区域，减少湍流噪声。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高强度栅格化外壳&lt;/strong&gt;：镂空栅格设计确保充足拾音面积，避免声学遮挡，高强度外壳可以物理防护内部的防风绵，防止损坏。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大面积镀疏水膜防风绵&lt;/strong&gt;：高密度大面积海绵结构，能够对骑行中产生的风噪进行均匀过滤与消解。防风泡绵采用整体真空镀疏水涂层的工艺，不仅能够做到不沾水、不吸水、不存水，有效防止雨水、汗水等对麦克风的侵蚀，还能在全生命周期内保持稳定的物理防风降噪性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;防水透声膜&lt;/strong&gt;：既能阻挡水、灰尘等杂质进入，又能保证声波高效穿透，平衡防护性与拾音灵敏度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2mm 深 36°密闭式拾音通道&lt;/strong&gt;：通过 36°倾斜角收声孔设计，使得拾音通道的深度只有 2mm，可以有效减小声波传导损耗，确保拾音清晰。拾音孔与 PCBA 通过胶水密封粘接，杜绝漏音与二次回音，保证语音信号纯净度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高性能音频处理芯片&lt;/strong&gt;：主芯片其内置的音频编解码模块性能卓越，降噪算法更加智能，24bit DAC 的 SNR 高达 104dB，换算后噪声基底仅为 4.5μV。芯片可对智能头盔接收和播放的音频信号进行高保真处理，确保骑手通话时，无论在嘈杂的城市街道，还是高速骑行的呼啸风声中，芯片也能通过智能音频算法有效过滤背景噪音，突出人声。保证骑手声音清晰、不失真，为骑手提供优质的沟通体验。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;K3SX1 通过 "硬件结构创新 + 芯片算法赋能 + 模块化工程思维"，多层结构与高性能芯片的协同设计，在强风环境降噪与成本控制间取得平衡，为智能头盔从 "功能型" 向 "普及型" 跨越提供了关键技术支撑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6105dcd962c0165c4fa1afa81a28f8c4.png" alt="36°倾斜角收声孔+栅格化外壳设计+高密度海绵物理降噪方案" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.5 极端环境适应&lt;/h3&gt; 
&lt;p&gt;在智能头盔领域，多数产品的防水标准仅设定在 IPX4 或 IPX5 等级，这意味着它们仅能抵御少量溅水或短时淋雨，一旦遭遇暴雨、强风裹挟雨水等极端天气，设备内部电子元件极易因进水短路而损坏。而美团智能头盔打破常规，以 IPX6 级防水性能脱颖而出。这一等级要求设备能承受强水流从任意方向持续喷射 15 分钟而不受损，相当于在每小时 150 毫米降水量的特大暴雨中电子模组不进水无损坏。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在设计上精益求精，提高防护级别&lt;/strong&gt;：各个模块按照 IPX7 的要求进行设计，主控模组采用硅胶密封圈叠加设计，配合对外连接线束点胶密封，TypeC 接口 IPX7 硅胶密封，按键位置大面积双面胶密封防水等方案，形成无缝防水屏障，确保各种苛刻的使用环境模组不进水。音频模块、麦克风等核心部件均配备防水透气膜，既能隔绝液态水侵入，又能平衡内部气压，防止因温差产生水雾凝结。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在生产上严格要求，全检出货&lt;/strong&gt;：模组全部通过气密检测设备进行检测，执行的测试标准是 IPX7，进行严格管控全检测试出货，确保每一个智能头盔模组都具有卓越的防水性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;正是这些精密的设计与严苛的出厂测试，这种 "设计 + 生产" 双维度防水方案，让骑手在暴雨倾盆的街道、狂风呼啸的骑行途中，都能放心使用美团智能头盔，无需担忧雨水侵袭影响设备功能，真正实现风雨无阻地安全配送，为城市配送的高效运转筑牢可靠防线。&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;配送效率重构：人机协同的智能操作升级&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;对骑手而言，配送效率直接关乎收入水平。美团智能头盔在提升配送效率方面，展现出了强大的功能。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;一体化耳机设计&lt;/strong&gt;：其一体化头盔耳机设计，极为便捷，拿起头盔自动开机，自动连接蓝牙，骑手戴上头盔后，无需再额外佩戴耳机。并且，通过先进的降噪算法，即使在高达 50km/h 的骑行速度下，也能确保语音通话清晰流畅，让骑手与顾客、商家之间的沟通毫无障碍。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;实体按键一键接单&lt;/strong&gt;：头盔上精心配备的大号实体按键，操作简便，骑手能够快速一键接单、确认到店、到客，以及接打电话。即便是在寒冷的冬天，骑手戴着手套也能轻松操作，无需拿出手机点击屏幕，大大节省了操作时间，提高了配送效率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大模型助手主动提率&lt;/strong&gt;：此外，头盔所搭载的连接骑手 App 的大模型语音助手，更是骑手的得力助手。它不仅能在工作上为骑手提供路线规划、订单信息查询等帮助，还能在骑手感到疲惫或压力大时，给予情感上的支持与鼓励，让骑手在忙碌的工作中感受到温暖与关怀，以更饱满的精神状态投入到配送工作中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;产业赋能实践：传统制造的智能化跃迁&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;5.1 传统头盔厂的技术短板&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;音频性能测试的困境&lt;/strong&gt;：智能头盔需要支持高质量的语音交互，因此必须进行精确的音频曲线测试（如频响、失真等）。传统头盔厂通常缺乏专业的声学实验室和测试设备，导致产品在音质方面表现不佳，骑手感觉声音刺耳，有杂音等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;硬件生产测试系统的缺失&lt;/strong&gt;：智能头盔涉及蓝牙模块、传感器、电池管理等复杂电子组件，需要专业的上位机测试系统来验证其稳定性。传统厂商往往依赖人工检测，效率低且难以覆盖所有故障模式。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自动化程度低&lt;/strong&gt;：智能头盔有很高的防水和性能要求，但传统头盔厂通常缺乏自动化设备，基本依赖手工操作造成组装速度慢，工艺不稳定，不同班次的产品性能差异较大。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;生产监控系统的缺失&lt;/strong&gt;：智能头盔有许多电子器件，需要监控性能指标和追溯历史测试结果，但传统盔厂缺乏相应的系统监控，无法做到实时数据监控和历史追溯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5.2 美团头盔产线的智能升级&lt;/h3&gt; 
&lt;h4&gt;5.2.1 六大核心工艺，打造极致可靠的头盔&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能自动功能测试&lt;/strong&gt;：智能系统检测按键、蓝牙、传感器等功能，不良品自动剔除，努力确保 100% 达标。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高精度自动点胶&lt;/strong&gt;：精准控制胶量与路径，提高密封性，彻底解决传统手工点胶的溢胶、漏胶问题。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无人化锁螺钉&lt;/strong&gt;：机器人精准紧固螺丝，扭矩实时监控，螺丝零松动、零滑牙。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;气密性测试&lt;/strong&gt;：5 秒快速筛查，微漏无所遁形，防水性能行业领先。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;音频调校+音频参数测试&lt;/strong&gt;：智能声学实验室模拟真实场景，优化麦克风降噪算法，产线 100% 进行喇叭和麦克频响、失真、R&amp;amp;B、平衡度等参数测试，确保通话质量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;加速老化试验体系&lt;/strong&gt;：85℃/85%RH 双 85 测试，高强度温湿度循环+跌落测试+穿刺测试，保证头盔的寿命和安全性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//28544b39db414b0b088fa18094b0f28e.png" alt="六大核心工艺，打造极致可靠的头盔" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4&gt;5.2.2 数字化转型：老产线的华丽转身&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据驱动决策&lt;/strong&gt;：MES 系统实时监控生产参数，问题提前预警，问题追溯源头。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;柔性生产&lt;/strong&gt;：同一产线可快速切换不同型号，换型时间缩短 50%。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;人机协同&lt;/strong&gt;：工人从重复劳动解放，专注工艺优化与技术创新。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;市场与行业影响：用数据树立价值新标杆&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;K3SX1 产品从骑手到业务逐步得到认可，佩戴舒适度、蓝牙语音体验和性价比等方面产品力显著提升，满意度从 3.2 提升至 4.2（5 分制），语音功能使用率从加盟 54% 提升至加盟 87%、众包 98%。&lt;/p&gt; 
&lt;p&gt;因为智能头盔功能实用性决策购买的骑手较多（79%），朋友推荐成为第二高的骑手了解智能头盔的渠道（最新占比提升至 22%）。该产品的成功推出，不仅为外卖骑手提供了更优质的防护装备解决方案，更推动行业从单纯的功能竞争转向用户体验与成本效益并重的新阶段，为智能头盔产品的发展树立了新的技术与价值标杆。&lt;/p&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;未来技术前瞻：硬件升级与智能伙伴的革新&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美团智能头盔，通过多年的经验积累和技术迭代，新一代 K3SX1 智能头盔头盔通过多方面技术改进实现有效减重，兼顾安全、舒适性与性能提升。随着美团智能头盔的 NPS 和满意度屡创新高，取得了历代智能头盔最佳表现。&lt;/p&gt; 
&lt;p&gt;在未来，美团智能头盔搭载的大模型语音助手，将进化为骑手的 "全场景认知伙伴"。它不仅能精准处理 "规划路线"、" 播报订单"等基础指令，更能通过深度学习骑手的配送习惯与行为模式，实现主动式智能辅助 ------ 比如在暴雨天气自动播报实时路况并推荐防滑路线，检测到骑手连续配送超 3 小时后主动推送附近休息站信息，甚至能根据商家出餐速度预判延误风险，提前建议骑手调整接单节奏。&lt;/p&gt; 
&lt;p&gt;在复杂场景中，语音助手可通过多轮对话理解骑手需求，例如当骑手说"找最近的修车站"，系统会同步考虑距离、口碑及维修时长，生成带语音导航的优选方案；遇到顾客改地址等突发情况，还能自动生成标准化沟通话术并同步更新配送系统。更值得期待的是，其情感交互能力将实现"温度服务"------ 在骑手遭遇差评时推送心理疏导语音，节日时送上定制化问候，甚至能根据骑手的方言习惯调整播报语气，让科技真正成为有"人情味"的工作伙伴，彻底重构即时配送行业的人机协作范式。&lt;/p&gt; 
&lt;p&gt;未来的美团智能头盔，硬件上还会搭载更加强大的传感器，帮助骑手解决更加复杂的问题。并逐步推广到全国每一个骑手，让他们都能体验到科技带来的价值和快乐，为骑手带来更安全、高效、舒适的工作体验，不断引领智能头盔行业迈向新的高度。&lt;/p&gt; 
&lt;p&gt;| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024 年货】、【2023 年货】、【2022 年货】、【2021 年货】、【2020 年货】、【2019 年货】、【2018 年货】、【2017 年货】等关键词，可查看美团技术团队历年技术文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9b6ae5ef223651e842d935a4a4533aa3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明"内容转载自美团技术团队"。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank"&gt;tech@meituan.com&lt;/a&gt; 申请授权。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/meituantech/blog/18688335</link>
      <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/18688335</guid>
      <pubDate>Tue, 19 Aug 2025 02:53:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>字节跳动即将发布开源模型 SeedOss-36B</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;根据 Hugging Face Transformers 库的信息，字节跳动即将发布一款名为 SeedOss-36B 的 360 亿参数稠密开源模型。&lt;/p&gt; 
&lt;p&gt;相关信息来源于 Hugging Face Transformers 开源仓库中的一个 Pull Request。该 Pull Request 由 GitHub 用户「Fazziekey」提交，标题为「Addiing ByteDance Seed Seed-Oss」，旨在为即将推出的 Seed Oss 模型添加代码支持。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1304" src="https://static.oschina.net/uploads/space/2025/0820/105108_ez5K_2720166.png" width="1790" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="739" src="https://static.oschina.net/uploads/space/2025/0820/104957_sQ2l_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/105135_a86e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/huggingface/transformers/pull/40272&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;从目前披露的信息来看，SeedOss-36B 很可能是一个 360 亿参数的稠密模型，而非 MoE（Mixture-of-Experts）架构。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367325</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367325</guid>
      <pubDate>Tue, 19 Aug 2025 02:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek V3.1-Base 开源发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 最新开源模型 V3.1-Base 已上架 HuggingFace，相关信息如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型参数为 685B&lt;/li&gt; 
 &lt;li&gt;基座模型（Base），用于微调和二次开发&lt;/li&gt; 
 &lt;li&gt;基于 DeepSeek V3 架构，包含自定义代码实现&lt;/li&gt; 
 &lt;li&gt;混合精度设计，支持 BF16、FP8（E4M3）、FP32 张量类型&lt;/li&gt; 
 &lt;li&gt;支持 FP8 量化，提升推理效率&lt;/li&gt; 
 &lt;li&gt;采用 Safetensors 安全张量格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1240" src="https://static.oschina.net/uploads/space/2025/0820/104516_2Mto_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104605_duz9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104713_pqfx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3.1-Base" target="_blank"&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Base&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367323</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367323</guid>
      <pubDate>Tue, 19 Aug 2025 02:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>再获国际权威机构认可｜绿盟抗 D 解决方案斩获业界首个 Frost &amp; Sullivan 竞争战略领导奖</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;近日，绿盟科技凭借在抗 DDoS 领域的深厚积累与全球战略布局，一举斩获国际权威机构 Frost &amp;amp; Sullivan 颁发的 2025 年度竞争战略领导奖（2025 Competitive Strategy Leader）。这一重磅奖项不仅彰显了权威机构的高度认可，同时也标志着绿盟抗 D 解决方案正在持续向全球安全行业展现强劲的技术创新力与市场领导力。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="图片 1.jpg" height="400" src="https://oscimg.oschina.net/oscnet//68c662dce7d7be9538563f3bd0e5ae88.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="图片 2.jpg" height="785" src="https://oscimg.oschina.net/oscnet//c77b2f3fbb86054cf4ed258924ce184a.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;Frost &amp;amp; Sullivan 分析师 Iqra Azam 表示：「在全球市场，绿盟抗 D 以智能、敏捷、以客户为核心的解决方案脱颖而出。面对愈发复杂的大规模 DDoS 威胁，绿盟科技以创新驱动战略，已经成为国际市场中不可忽视的竞争力量。更重要的是凭借抗 D 设备+平台的智能增值运营方案，不仅为客户带来了实打实的价值转化，更帮助企业释放了新的商业增长潜能。」&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;从国际竞争力的视角来看，绿盟抗 D 解决方案近年来在亚太、拉美等重点新兴市场持续深耕，成功服务于多个国家级运营商、金融机构及关键基础设施客户，其中最受海外客户关注的正是三位一体抗 D 增值运营解决方案：&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;方案组件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;绿盟抗拒绝服务攻击系统-ADS&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;ADS 融合了机器学习建模、交互式动态防护算法、行为模式分析以及动态指纹识别等先进技术，提供高效的多层（L3-L7）DDoS 攻击流量清洗能力，在高效阻断各类 DDoS 恶意报文的同时快速放行合法业务流量，同时支持基于业务特点进行策略隔离，让防护更加灵活化。ADS 防护流程全程透明可视，统计展示各防护策略结果，并支持在线抓包和在线查看报文关键特性，帮助用户快速分析攻击细节与业务特征，真正实现可视、可控、可验证的主动防护体验。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;绿盟网络流量分析系-NTA&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;NTA 专注于流量异常监测及 DDoS 攻击快速告警，提供基于 FLOW（深度流检测）或者基于 DPI（深度包检测）双模监测模型，可灵活适配不同规模网络、不同流量及重点业务精细化分析等不同业务场景。借助基于机器学习建模的动态流量基线能力，NTA 可自动生成告警阈值，有效降低漏报与误报，减轻运维负担。设备搭配云端实时检测规则，能快速识别新兴威胁，显著提升防护响应效率。此外 NTA 支持联动绿盟威胁情报，实时识别矿机、矿池、僵尸网络等威胁信息，可通过 flowspec 实现精细化阻断。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;绿盟流量清洗业务运营系统-ADBOS&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;致力于为运营商、金融、跨国企业及网络服务提供商赋能基于抗 D 云清洗、流量分析、MSS 等云上安全服务，助力客户构建多层次的运营体系。平台支持跨地域、跨厂商的态势可视化与策略管理，助力用户实现抗 D 资源的统一调度与高效运维。平台搭载抗 D 专家策略库和自适应策略调整模块，配合探针的自学习建模、基于剧本编排的自动化处置，让用户体验一站式运营管理和全托管式运维，轻松降低运营复杂度的同时还能提供增值运营的快速变现。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="图片 3.jpg" height="210" src="https://oscimg.oschina.net/oscnet//e1def71af4771d74670ec4ab7e2ce7f8.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;三位一体的抗 D 增值运营解决方案，依托 ADBOS 平台接入 ADS/NTA，构建高性能、可扩展的抗 D 清洗与检测资源池，并通过分权分域的集中管理，实现跨地域、跨厂商设备的统一资源调度与数据融合，做到最大化设备利用率与投资回报率。平台集成客户管理、售卖规格、费用套餐等一站式增值运营功能帮助用户轻松上线增值抗 D 服务，实现从防护能力到商业变现的无缝衔接。在服务体验方面，平台提供包括自助门户与移动端 APP 在内的多种自助服务方式，让最终用户可以随时随地掌握业务状态、灵活配置防护策略，并生成自定义、多维度的业务与防护报表，全面提升操作便捷性与服务可视化，显著增强用户粘性与满意度。该方案形成了从精准流量检测，智能资源调度，高效 DDoS 清洗形成完整业务闭环，全面满足服务提供商对精细化运营和差异化服务的核心诉求。结合 MSS 可管理安全服务订阅，客户可一站式享受从攻击监控、快速响应、威胁分析、事件处置到全流程报告的无感知式托管防护，真正实现高效、省心的智能化运营。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;未来，绿盟抗 D 产品将持续突破技术边界，迭代产品能力和服务质量，打造更具前瞻性、智能化的防护体系，持续为全球客户提供强有力的抗 D 支撑，护航关键业务稳健前行。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367321</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367321</guid>
      <pubDate>Tue, 19 Aug 2025 02:39:00 GMT</pubDate>
      <author>作者: 开源科技</author>
    </item>
    <item>
      <title>小米集团基于 Apache Doris + Apache Paimon 实现 6 倍性能飞跃</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;企业在数据驱动的道路上，始终面临一对核心矛盾：既需要低成本、可扩展的存储方案来承载海量结构化、半结构化乃至非结构化数据（这正是数据湖的强项），又渴望实时、低延迟的分析能力来支撑业务决策（这是分析型数据库的核心优势）。&lt;/p&gt; 
&lt;p&gt;然而现实是，单独的解决方案往往难以两全：以 Apache Paimon 为代表的数据湖技术，虽凭借开放格式、弹性扩展和低成本存储成为企业数据中台的基石，但在低延迟响应上存在天然短板；而以 Apache Doris 为代表的分析型数据库，虽能提供高效的查询性能，却缺乏数据湖的存储灵活性与开放性。&lt;/p&gt; 
&lt;p&gt;本文的核心观点是："架起数据库与数据湖的桥梁" 并非趋势，而是破局的关键。小米通过将 Apache Doris（数据库）与 Apache Paimon（数据湖）深度融合，不仅解决了数据湖分析的性能瓶颈，更实现了 "1+1&amp;gt;2" 的协同效应。&lt;/p&gt; 
&lt;h2&gt;数据库与数据湖的互补之力&lt;/h2&gt; 
&lt;p&gt;"桥接数据库与数据湖"的核心价值，在于构建"&lt;strong&gt;存储灵活、计算高效、格式协同&lt;/strong&gt; "的一体化架构------不仅是存储与计算能力的分工互补，更包含&lt;strong&gt;数据格式层面的深度协同&lt;/strong&gt;，让两者的技术特性形成叠加效应。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 数据湖仓的分工定位&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;从基础能力来看，两者的分工已形成天然互补：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Apache Paimon 作为数据湖，核心优势体现在存储层：其开放格式（兼容 Spark、Flink、Trino 等多引擎）、基于对象存储（S3、HDFS）的 PB 级弹性扩展能力，以及对事务、Schema 演进的原生支持，使其成为海量异构数据的"统一存储基座"，兼顾低成本与兼容性。&lt;/li&gt; 
 &lt;li&gt;Apache Doris 作为分析型数据库，核心优势体现在计算层：分布式并行引擎、向量化执行框架、以及针对复杂聚合场景的算子优化，使其能提供毫秒至秒级的低延迟查询响应，成为数据价值挖掘的"高效计算引擎"。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;2. 数据格式的特性互补&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;更深层的协同点，在于数据格式的特性互补：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据湖格式（如 Paimon）为适配多引擎读写与大规模存储场景，在设计上以通用性为优先，虽能满足跨引擎兼容需求，但在高频查询、复杂计算场景下，其通用格式的解析效率、IO 开销难以进一步优化；&lt;/li&gt; 
 &lt;li&gt;而数据库（如 Doris）则拥有专为查询性能设计的 &lt;strong&gt;高效内部存储格式&lt;/strong&gt;------例如基于列存的分层存储结构、自适应编码压缩算法（如字典编码、RLE 压缩）、原生索引（如前缀索引、 bloom filter）等，这些格式通过深度耦合计算引擎的执行逻辑，可最大限度减少数据扫描量与 IO 消耗，实现亚秒级查询响应。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;3. 桥接架构的双向赋能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;桥接架构下，数据湖仓可实现&lt;strong&gt;双向赋能&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;海量冷数据、全量历史数据以 Paimon 格式存储于数据湖，保持低成本与多引擎兼容性；&lt;/li&gt; 
 &lt;li&gt;高频访问的热数据、需复杂聚合的核心指标，则通过 Doris 的物化视图、本地缓存等机制，转换为 Doris 高效内部格式存储，借助其原生存储与计算的协同优化，实现极致查询性能。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;这种模式既避免了单一数据湖格式在查询性能上的瓶颈，又解决了单一数据库格式在存储成本与扩展性上的局限。唯有通过"桥接"，才能让数据湖的通用存储优势与数据库的高效格式特性形成合力，实现"存储成本可控、查询性能最优"的理想状态。&lt;/p&gt; 
&lt;h2&gt;Apache Doris &amp;amp; Paimon 在小米的实践与挑战&lt;/h2&gt; 
&lt;p&gt;Apache Paimon 是一款优秀的开放数据湖格式，其流批一体的设计很好的满足了湖上数据的实时处理需求。&lt;/p&gt; 
&lt;p&gt;Doris 在 2.1 版本开始支持 Paimon Catalog，可以直接访问 Paimon 数据并加速 Paimon 数据分析。在 Paimon TPC-DS 1TB 测试集上，Doris 的总体查询性能是 Trino 的 5 倍。&lt;/p&gt; 
&lt;p&gt;从 2.1 版本到 3.0、3.1 版本，Doris 在持续针对 Paimon 格式进行功能更新和性能增强，包括但不限于以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;通过元信息对 Paimon 数据进行分区、分桶裁剪和谓词下推，优化查询效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Deletion Vector 读取，利用向量化 C++ 引擎加速 Paimon 更新数据的读取。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 数据的本地文件缓存，充分利用本地高速磁盘提升热点数据的查询效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 时间旅行、增量数据读取、Branch/Tag 数据读取，方便用户进行 Paimon 数据的多版本管理。&lt;/li&gt; 
 &lt;li&gt;支持基于 Paimon 的物化视图，包括分区级别的增量物化视图构建，以及本文后续将要介绍的基于快照级别的增量构建，同时支持强一致的物化视图透明改写能力，将湖和仓的能力深度结合。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Rest Catalog（DLF），方便云上用户接入 Paimon 生态，实现统一元数据管理。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在本文中，我们将重点介绍小米如何基于 Doris + Paimon 构建统一湖仓平台，以及在项目开发过程中的功能贡献和优化思路。&lt;/p&gt; 
&lt;h2&gt;01 化繁为简：基于 Doris + Paimon 的统一湖仓平台建设&lt;/h2&gt; 
&lt;p&gt;作为一家业务覆盖汽车、IoT、手机、互联网服务等多个领域的大型企业，小米集团对 OLAP 系统和湖仓平台提出了如下关键需求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多维度分析&lt;/strong&gt;：支持高并发、低延迟的多维聚合分析（如用户行为、设备状态、运营监控等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多源接入&lt;/strong&gt;：需要打通 Flink、Spark、Flink CDC 等流批框架的输入，覆盖离线、实时全链路数据处理场景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;统一数据访问&lt;/strong&gt;：支持跨引擎、多格式的数据消费需求（如 Doris、Paimon、Iceberg 等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;降低平台复杂度&lt;/strong&gt;：减少技术栈分裂，统一数据建模与管控，提升数据平台运维效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;当前架构的挑战与瓶颈&lt;/h3&gt; 
&lt;p&gt;尽管已有较成熟的数据平台体系，但小米的 OLAP 湖仓架构长期存在如下"繁杂、割裂"的结构问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;存储多源异构，数据重复堆叠&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;为满足不同业务对数据的不同时效性需求，需要按照分钟、小时、天级别的时效性要求，将数据存储在不同的数据系统中（Iceberg、Paimon、Druid、Doris），导致数据冗余、不一致等问题&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;湖仓割裂，缺乏统一接口&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需要同时使用不同的引擎进行数据查询，（如 Presto、Druid、Doris、Spark 等）。各系统有独立的数据建模、运维和权限控制逻辑，平台治理成本高，入口不统一，使用方式不统一。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//54a06d5419f01bd3f147603a3e36c475.png" alt="化繁为简：基于 Doris + Paimon 的统一湖仓平台建设.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这些问题不仅增加了平台负担，也制约了 OLAP 架构在大规模实时应用场景下的稳定性和扩展性。&lt;/p&gt; 
&lt;h3&gt;统一引擎 + 统一存储&lt;/h3&gt; 
&lt;p&gt;为应对上述挑战，小米构建了基于 &lt;strong&gt;Apache Doris + Apache Paimon&lt;/strong&gt; 的统一湖仓一体化架构，作为未来 OLAP 平台的核心形态。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;统一计算引擎：Apache Doris + Spark&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;采用 Doris + Spark 的计算引擎组合。Doris 负责实时数据和交互式数据分析，以及高并发查询场景。Spark 负责离线批处理场景。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;统一数据湖存储：Apache Paimon&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;以 Apache Paimon 作为统一数据存储格式。Paimon 的设计非常适合流、批数据一体化存储。实现批流一体、湖仓一体的数据管理。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4523b53882f118d0fe114ba1b214b893.png" alt="统一引擎 + 统一存储.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过这一架构转型，极大地简化了系统架构：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;计算引擎：Presto、Druid、Doris、Spark -&amp;gt; Doris、Spark&lt;/li&gt; 
 &lt;li&gt;存储格式：Iceberg、Paimon、Doris、Druid -&amp;gt; Doris、Paimon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02 深度融合：基于 Doris + Paimon 查询加速实践&lt;/h2&gt; 
&lt;p&gt;小米在引入 Apache Paimon 构建湖仓平台后，虽解决了海量数据的存储问题，却在实际业务中遭遇了三大关键瓶颈，直接影响了数据价值的释放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聚合性能不足&lt;/strong&gt;：Doris 在读取 Paimon 的 Merge-on-Read 表时，受限于 Paimon SDK（Java）单线程处理多文件的排序与合并，在高并发场景下完全无法满足业务对 "秒级响应" 的需求。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;物化视图更新代价高昂&lt;/strong&gt;：分区级增量更新机制粒度在某些场景下可以满足用户的增量更新需求。但对于非分区表，或者单分区数据量较大的表，依然有较高的更新成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HDFS 读取延迟不稳定&lt;/strong&gt;：HDFS 多副本读取时，默认 60 秒的超时阈值和网络抖动，导致查询延迟波动极大，业务方难以依赖数据结果快速做出决策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些问题并非单纯的技术瑕疵 ------ 它们直接拖慢了业务决策速度，同时因资源浪费和低效运行增加了企业成本。&lt;/p&gt; 
&lt;p&gt;针对上述瓶颈，小米通过深度整合 Apache Doris 与 Apache Paimon 的特性，打造了&lt;strong&gt;三大 "桥接" 方案&lt;/strong&gt;，实现了从 "问题" 到 "解决方案" 的精准突破。&lt;/p&gt; 
&lt;h3&gt;方案一：用 Doris 计算引擎加速 Paimon 聚合能力&lt;/h3&gt; 
&lt;p&gt;Doris 本身拥有强大的数据聚合计算能力，同时支持 Aggregate Key 聚合表模型，该模型在应用场景上和 Paimon 聚合表非常类似，因此可以作为 Paimon 聚合表很好的补充。&lt;/p&gt; 
&lt;p&gt;针对原先 Doris 读取 Paimon 聚合表性能不足的问题，小米采用了将文件合并与排序逻辑 "上移" 至 Doris 的查询引擎的方案，利用 Doris 的分布式并行计算与向量化执行能力，替代 Paimon SDK 的单线程处理模式。具体而言：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;放弃 JNI 调用 Paimon Java SDK 的方式，改用 Doris 原生 Parquet Reader 直接读取 Paimon 数据文件；&lt;/li&gt; 
 &lt;li&gt;借助 Doris 的 Hash 算子实现分布式聚合（无需排序步骤），充分发挥 C++ 引擎的性能优势。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2e1dbabcb52805e9fb9c1bbdabf4dcec.png" alt="方案一：用 Doris 计算引擎加速 Paimon 聚合能力.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;经过此方案改造，聚合表的查询时长&lt;strong&gt;从 40 秒缩短至 8 秒，性能提升近 5 倍。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案二：快照级增量物化视图实现高效更新&lt;/h3&gt; 
&lt;p&gt;Doris 支持 Paimon、Iceberg 等数据湖表格式的异步物化视图构建，并且支持分区级别的增量物化视图刷新与查询透明改写。物化视图作为数据库与数据湖的直接桥梁，对查询加速起到了至关重要的作用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//46574d04066c2797c966cd797925a8f0.png" alt="方案二：快照级增量物化视图实现高效更新.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为了进一步提高物化视图的时效性，并降低物化视图的更新开销。小米进一步研发了基于快照级别的物化视图增量刷新能力，并且贡献到了 Apache Doris 社区。&lt;/p&gt; 
&lt;p&gt;首先，小米开发了 Paimon 表的快照级别的增量读取能力，如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;SELECT * FROM paimon_table@incr('startSnapshotId'='0', 'endSnapshotId'='5')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该功能可以仅读取指定 snapshot 区间的增量数据。&lt;/p&gt; 
&lt;p&gt;基于该功能，小米进一步开发了基于快照级别的增量物化视图功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;在 Paimon 中创建一张聚合表&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;CREATE TABLE paimon_aggregate_table (
  dt bigint,
  k1 bigint
  k2 string,
  v1 int,
  v2 double
)
USING paimon
PARTITIONED BY (dt)
TBLPROPERTIES (
  'bucket' = '2',
  'bucket-key' = 'k1,k2',
  'fields.v1.aggregate-function' = 'sum',
  'fields.v2.aggregate-function' = 'max',
  'merge-engine' = 'aggregation',
  'primary-key' = 'dt,k1,k2'
);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Doris 中创建对应的物化视图&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;  CREATE MATERIALIZED VIEW paimon_aggregate_table_mv
  BUILD DEFERRED
  REFRESH INCREMENTAL
  PARTITION BY (dt)
  DISTRIBUTED BY RANDOM BUCKETS 2
  AS 
  SELECT dt, k1, SUM(a1) AS a1
  FROM paimon_aggregate_table
  GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Doris 的异步物化视图框架会在后台定时执行如下语句：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;INSERT INTO paimon_aggregate_table_mv
SELECT dt, k1, SUM(a1) AS a1
paimon_aggregate_table@INCR('startSnapshotId'='1', 'endSnapshotId'='2')
GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;利用快照读取功能和 Doris 聚合功能，准实时的更新物化视图，避免全量计算。&lt;/p&gt; 
&lt;p&gt;通过此方案，&lt;strong&gt;更新成本显著降低，数据时效性大幅提升，且得益于 Doris 优化的 SQL 透明改写能力，用户无需修改 SQL 即可自动享受物化视图的加速效果。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案三：HDFS 读取长尾优化与缓存机制&lt;/h3&gt; 
&lt;p&gt;针对 HDFS 读取延时不稳定的问题，小米采用了如下两方面措施：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. HDFS 快速超时与重试&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;HDFS 在读取数据时，会利用多副本机制，当一个副本的读取时间超过阈值后，会切换到另一个副本尝试读取。超市阈值由参数 &lt;code&gt;dfs.client.socket-timeout&lt;/code&gt;控制，默认是 60 秒。这导致首次读取的超时时间过长，在 HDFS 抖动或负载较高的情况下，会导致查询延迟显著增加。我们通过将该阈值降低到 100 毫秒，让读取情况进行快速的超时重试，显著降低了查询长尾，&lt;strong&gt;P99 性能提升 1 倍，总体性能提升 10%。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e3d184f7c8d525920cddc271ac838bcf.png" alt="方案三：HDFS 读取长尾优化与缓存机制.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Doris 数据缓存&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;针对高并发查询场景，单纯的降低 HDFS 的重试超时时间，无法彻底的解决 HDFS 查询延迟高的问题。因此，我们利用 Doris 的数据缓存能力，将热点数据缓存在本地高速磁盘上，完美解决了高并发场景的查询延迟问题。在开启缓存的情况下，从 5 并发到 80 并发，查询延迟可以&lt;strong&gt;降低&lt;/strong&gt; &lt;strong&gt;25% 到 300%。&lt;/strong&gt; 同时，得益于数据剪枝能力、高性能的算子，&lt;strong&gt;Doris 的整体查询并发能力是 Presto 的 5 倍。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//29901c93faeb0f8dfc37da040b805da1.png" alt="2. Doris 数据缓存.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;总结与展望&lt;/h2&gt; 
&lt;p&gt;小米在 Apache Doris 和 Paimon 上的深度融合实践，是典型的数据库与数据湖的互补增效的体现。在这些实践下，小米在湖仓数据分析场景下获得了可观的业务收益：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;查询平均延迟从 60 秒降至 10 秒，性能提升 6 倍；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高并发场景下（5 并发提高至 80 并发），查询延迟降低 25% 到 300%；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;整体查询并发能力达到 Presto 的 5 倍，有效减少了计算资源。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;目前，这些能力已经全部回馈到了 Apache Doris 社区。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在未来，小米将继续探索和拓展 Apache Doris 在数据湖仓上的能力和场景，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 Doris 全流量替换 Presto 集群实现降本增效。&lt;/li&gt; 
 &lt;li&gt;进一步加强针对 Paimon、Iceberg 湖格式增量物化视图的能力。&lt;/li&gt; 
 &lt;li&gt;Doris 湖仓架构容器化以满足更灵活的部署方式。&lt;/li&gt; 
 &lt;li&gt;基于 Doris 的 Compute Group 虚拟计算组能力实现多业务间的资源隔离，提高资源利用率，降低维护成本。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/selectdb/blog/18688781</link>
      <guid isPermaLink="false">https://my.oschina.net/selectdb/blog/18688781</guid>
      <pubDate>Tue, 19 Aug 2025 02:35:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>英伟达正开发新款「中国特供」 AI 芯片，性能强于 H20</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fworld%2Fchina%2Fnvidia-working-new-ai-chip-china-that-outperforms-h20-sources-say-2025-08-19%2F" target="_blank"&gt;据路透社援引知情人士透露&lt;/a&gt;，英伟达正在研发面向中国市场的新型 AI 芯片 B30A，其性能超越当前获准销售的 H20 芯片，并计划最快于 2025 年 9 月向中国客户提供测试样品。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/103840_kcWl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据悉，该芯片采用单芯片设计，预计其算力约为旗舰级 B300 加速卡双芯片配置的一半。此外，该芯片将配备高带宽内存（HBM）和 NVLink 技术，以提升处理器间的数据传输效率。&lt;/p&gt; 
&lt;p&gt;单芯片设计指所有主要电路都制作在同一块连续的硅晶圆上，而不是分散在多个芯片上。消息人士表示，目前芯片最终规格还没完全敲定，但 NVIDIA 希望最快下个月向中国客户提供样品进行测试。&lt;/p&gt; 
&lt;p&gt;根据相关曝光的信息，B30A 很可能是基于同样单芯片设计的 Blackwell B300A 修改而来。通过单芯片集成核心电路，B30A 在保持 Blackwell 架构先进性的同时，降低了被认定为「高性能计算设备」的风险，从而规避更严格的出口审查。&lt;/p&gt; 
&lt;p&gt;该芯片基于最新 Blackwell 架构、其核心战略定位在于，在满足美国商务部出口管制条例（EAR）的前提下，提供超越上一代特供芯片 H20 的性能，以应对中国市场日益增长的 AI 算力需求和本土厂商的竞争。&lt;/p&gt; 
&lt;p&gt;此前，有消息称，美国政府与 NVIDIA、AMD 达成协议，将在中国销售芯片的 15% 营收上缴给美国政府，以取得半导体出口许可。与此同时，中国官媒指控 NVIDIA 芯片存在安全风险，并警告中国科技公司谨慎购买 H20。&lt;/p&gt; 
&lt;p&gt;此外，据知情人士透露，NVIDIA 也正准备推出另一款针对中国市场的新芯片，同样基于最新 Blackwell 架构，主要用于 AI 推理任务。该芯片暂名 RTX6000D，售价将低于 H20，其规格较弱且制造需求更简单。该芯片设计是为了落在美国政府设定的门槛之下，采用传统 GDDR 内存，内存带宽为 1398 GB/s，计划 9 月提供少量产品给中国客户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367317</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367317</guid>
      <pubDate>Tue, 19 Aug 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动否认自研 AI 手机</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;针对近日市场上有关字节跳动正在研发「豆包手机」的传言，字节跳动相关负责人明确回应称，该消息不实，豆包目前并无推出自有手机产品的计划。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据介绍，豆包始终致力于将自身 AI 能力向包括手机厂商在内的各类硬件厂商开放。在此过程中，虽会与部分合作伙伴共同开展完整解决方案的尝试，但所有合作均不涉及自有手机产品的研发与推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="339" src="https://oscimg.oschina.net/oscnet/up-70f77e4956e520cdce2146bdfaa4e1c28a6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据了解，2019 年 1 月，字节跳动收购锤子科技部分专利使用权，当时便引发市场对于字节将进入手机市场的猜测。此后，原坚果手机团队在字节跳动内部以「新石实验室」为名开展工作，定位为集团硬件中台，探索智能手机及教育硬件等智能硬件产品。不过，2021 年 1 月，「新石实验室」并入由 Musical.ly 原创始人阳陆育负责的教育硬件团队，合并后的团队专注于教育领域，不再研发坚果手机、TNT 显示器等其他无关产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年以来，类似传闻亦多次出现。1 月，有消息称字节跳动选择与努比亚合作开发 AI 手机，字节跳动回应称消息不实；2 月，关于荣耀前 CEO 赵明将加盟字节跳动并负责手机业务的传言，字节跳动同样表示信息不实。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;豆包大模型作为字节跳动旗下重要的 AI 产品，数据显示，其 2024 年累计用户规模已超 1.6 亿，11 月平均每日新增下载用户达 80 万，单日活跃用户近 900 万。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技术应用方面，2025 年 7 月 30 日，火山引擎宣布豆包·图像编辑模型 SeedEdit 3.0 正式登陆火山方舟；8 月 1 日，小米浏览器升级「AI 搜索」功能，通过接入豆包大模型及火山方舟高代码智能体产品，进一步提升了 AI 搜索的效率与服务丰富度。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367315</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367315</guid>
      <pubDate>Tue, 19 Aug 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 计划通过股权出售成为全球最有价值私营公司，估值达 5000 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 正在考虑进行一轮价值 60 亿美元的股权出售，这将使其估值达到 5000 亿美元，超越目前全球最有价值的私人公司 SpaceX（估值 3500 亿美元）。这次股权出售的股份将主要由现有和前员工出售。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-6a3f4b40ac1c67918c3c1507155d1ac2163.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;过去一年，OpenAI 经历了迅猛的增长，微软和软银等投资者已经为该公司投入了至少 400 亿美元，使其在 2023 年 3 月的估值达到了 3000 亿美元。而在 2022 年 10 月，OpenAI 的估值仅为 1570 亿美元。如果此次股权出售成功，OpenAI 将成为全球估值&lt;span&gt;最高&lt;/span&gt;的私人公司。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;当前，参与此次股权出售谈判的投资者包括已经对 OpenAI 投资的三家机构:软银、Dragoneer 投资集团和 Thrive 资本。根据彭博社的报道，相关谈判仍处于早期阶段，最终的数字可能会有所变动。OpenAI 对此未作出评论。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在人工智能领域，OpenAI 正处于激烈的竞争之中。全球多家科技巨头，包括 Meta、谷歌、亚马逊和微软，正在大力投入人工智能研发， hiring engineers and building data centers。仅在 2025 年，这四家公司在人工智能领域的投入就超过了 1550 亿美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管自 2022 年发布 ChatGPT 以来，人工智能技术有了显著提升，但 OpenAI 在本月发布的&lt;span&gt;最新&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 模型 GPT-5 的表现却并未得到热烈反响。用户反馈称，该版本的写作质量不如之前的版本，且缺乏以往的个性化特征。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 首席执行官山姆・奥特曼表示，虽然公司追求的是 「通用人工智能」，即能在大多数任务上超越人类的 AI，但他在最近的发布会上表示，GPT-5 是 「普遍智能」 的，但尚未能够 「持续学习」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367312</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367312</guid>
      <pubDate>Tue, 19 Aug 2025 02:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 刚刚更新线上模型版本至 V3.1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 在官方社群宣布，其线上模型版本已升级至 V3.1，上下文长度拓展至 128k。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0819/193913_BlOM_2720166.png" width="1196" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;欢迎前往官方网页、APP、小程序测试，API 接口调用方式保持不变。&lt;/p&gt; 
&lt;p&gt;接口信息：https://platform.deepseek.com/usage&lt;/p&gt; 
&lt;p&gt;近日市场再度传出深度求索下一代 AI 大模型 DeepSeek-R2 的发布消息，预计时间窗口为 8 月 15 日至 30 日。对此，接近 DeepSeek 人士表示，该消息不实，并确认 DeepSeek-R2 在 8 月内并无发布计划。 &lt;/p&gt; 
&lt;p&gt;DeepSeek 创始人梁文锋在内部表示，他对 R2 取得的进展并不满意，并一直在竭力投入更多的时间来研发一款能够让该公司在 AI 领域保持领先地位的先进模型。&lt;/p&gt; 
&lt;p&gt;梁文峰要求模型达到更出色的结果才批准发布，R2 的发布还因更新版模型的数据标注时间超出预期而被推迟。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367254</guid>
      <pubDate>Mon, 18 Aug 2025 11:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 总裁透露 OpenAI 的 AGI 之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在最新一期的《Latent Space》访谈中，OpenAI 总裁 Greg Brockman 深入阐述了公司迈向 AGI 的整体路线图，核心可概括为「三个转向」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技术转向：从「一次性预训练」到「强化学习推理」&lt;/li&gt; 
 &lt;li&gt;资源转向：把「算力」视为唯一稀缺资源&lt;/li&gt; 
 &lt;li&gt;落地转向：从「科研样品」到「可审计的生产 Agent」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7470bcfe83cc59abb3b2fd2b11145f80512.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Greg Brockman 透露，GPT-4 发布之后，团队内部覆盘「它为何还不是 AGI」，结论是仅靠大规模预训练无法解决可靠性不足的问题，必须让模型在与真实世界的交互中「试错—反馈—再训练」。因此 GPT-5 首次引入强化学习驱动的「动态推理」范式：模型边使用边生成数据，再用这些数据进行再训练，逼近人类「边做边学」的循环。&lt;/p&gt; 
&lt;p&gt;他将这种「推理-重训」飞轮称为「超临界学习」（supercritical learning）：当算力放大 10× 乃至 10 000× 时，模型不仅能掌握任务本身，还能推演出二阶、三阶后果，从而快速逼近 AGI。&lt;/p&gt; 
&lt;p&gt;Greg Brockman 还把「算力」视为唯一稀缺资源，他认为算法壁垒往往可通过堆算力解决；AGI 进度条几乎与可用计算量线性相关。OpenAI 已把「持续投入大规模计算」写入长期资源策略，并认为未来 AGI 的形态会是「一个模型管理器」——本地小模型按需调用云端大算力，实现自适应计算。&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;总的来说，OpenAI 的 AGI 路线图可概括为「用强化学习把模型放进真实世界，用算力把反馈循环推到极致，用安全可控的 Agent 形态把能力嵌入千行百业」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367248</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367248</guid>
      <pubDate>Mon, 18 Aug 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 143 被发现不适用于某些旧 Windows 10 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在旧版 Windows 10 上运行 Firefox 浏览器的用户即将迎来很大困扰。目前在 Nightly 频道提供的最新版本 Firefox 143 已不再适用于 1803 之前的版本。&lt;/p&gt; 
&lt;p&gt;在 Windows 10 1703、1709 或 2015 LTSB 等老版本上启动该浏览器时，用户会收到以下错误：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于未找到 api-ms-win-core-console-11-2-0.dll，代码无法继续执行。重新安装程序或许可以解决此问题。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0700df38d95ae0494d0de12f07efb1ce47d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FTheBobPony%2Fstatus%2F1955740560292999460" target="_blank"&gt;这一发现&lt;/a&gt;迅速引发了用户的讨论（他们已经对 Mozilla 向浏览器添加不必要的、耗费资源的内容&lt;a href="https://www.oschina.net/news/366029" target="_blank"&gt;感到不满&lt;/a&gt;），他们要求 Mozilla 放弃旧版 Windows 10，这并非罕见之举。尽管 Windows 10 总体上仍然受支持，但许多应用程序已无法在旧的版本上运行。&lt;/p&gt; 
&lt;p&gt;尽管如此，考虑到 Mozilla 浏览器仍然支持 Windows 7，放弃对部分 Windows 10 市场份额的支持却令人意外，不过某些旧版本（例如 2015 LTSB 和 2016 LTSC）仍然受支持。Windows&amp;nbsp;10 2015 LTSB 版本将于 2025 年 10 月停止支持，而 2016 LTSC 版本将继续获得更新，直到 2016 年 10 月。&lt;/p&gt; 
&lt;p&gt;然而事实证明，Mozilla 并没有在 1803 之前的 Windows 10 版本上淘汰 Firefox。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ffirefox%2Fcomments%2F1mph4ra%2Fstarting_with_firefox_143_it_will_now_only%2F" target="_blank"&gt;Mozilla 工程师在 Reddit 上&lt;/a&gt;迅速处理了此事，并确认 Firefox 143 Nightly 无法在旧版 Windows 10 上运行的问题只是一个 bug，而非故意为之。因此，该问题应该很快就会得到修复。您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1983020" target="_blank"&gt;在 Bugzilla 官方网站上&lt;/a&gt;跟踪发现的 bug 。&lt;/p&gt; 
&lt;p&gt;与此同时，用户创建了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faubymori%2FFirefox-OldWindows%252010-Fix" target="_blank"&gt;一个临时解决方案&lt;/a&gt;，让浏览器在 Firefox 软件工程师准备永久修复程序期间能够正常运行。这也可以提醒大家不要依赖 Nightly 版本，因为这些版本的更改有时可能会导致浏览器完全崩溃。&lt;/p&gt; 
&lt;p&gt;Mozilla 尚未宣布终止 Windows 10 支持的计划。不过，由于 Windows 7 仍受支持，因此可以预期开发人员将在相当长的一段时间内继续在 Windows 10 上更新 Firefox。另一方面，微软近日透露，Edge 浏览器在 2025 年 10 月主流支持结束后，仍将在 Windows 10 上继续支持三年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367246</guid>
      <pubDate>Mon, 18 Aug 2025 11:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
