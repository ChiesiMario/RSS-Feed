<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 25 Mar 2025 21:36:54 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>OpenAI 发布高级语音模式更新：减少打断、支持暂停思考</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F03%2F24%2Fopenai-says-its-ai-voice-assistant-is-now-better-to-chat-with%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;对高级语音模式进行更新，使人工智能助手更加人性化，减少对用户的打扰。&lt;/p&gt; 
&lt;p&gt;OpenAI 的最新更新旨在解决人工智能语音助手经常出现的一个问题，&lt;strong&gt;即当用户暂停思考或深呼吸时，语音助手会打断用户。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-247c8326d5cecf92d8c96456777486f89e3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ChatGPT 的免费用户现在可以使用新版本的高级语音模式，让用户在与 AI 语音助手对话时暂停，而不会被打断。&lt;/p&gt; 
&lt;p&gt;ChatGPT 的付费用户（包括 OpenAI 的 Plus、Teams、Edu、Business 和 Pro 层级的用户）在使用高级语音模式时也将减少被打断的频率，同时语音助手的个性也将得到改善。针对付费用户，ChatGPT 高级语音模式进一步增强语音个性，模型响应更生动、直接且简洁，提供 9 种风格化人声选项。&lt;/p&gt; 
&lt;p&gt;阅读更多：&lt;a href=&quot;https://www.oschina.net/news/335872&quot; target=&quot;news&quot;&gt;OpenAI 免费开放 ChatGPT 语音聊天功能&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340929/openai-says-its-ai-voice-assistant-is-now-better-to-chat-with</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340929/openai-says-its-ai-voice-assistant-is-now-better-to-chat-with</guid>
            <pubDate>Sat, 22 Mar 2025 11:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Cloudflare 推出「AI 迷宫」应对 AI 爬虫</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;与其阻止爬虫机器人，不如主动把它们引进一个由 AI 生成的「废话迷宫」，让它们自我迷失&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Cloudflare 近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fai-labyrinth%2F&quot; target=&quot;_blank&quot;&gt;推出名为「AI 迷宫」（AI Labyrinth）的新工具&lt;/a&gt;&lt;/u&gt;，用以对付未经授权、到处抓取网页数据的爬虫机器人。这些爬虫通常抓取免费内容，以训练 AI 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-14b28096a4ec89447ef93e70ba02693f606.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cloudflare 介绍称，&lt;strong&gt;当系统识别到异常爬虫行为时，「AI 迷宫」就会启动，将这些机器人引向由 AI 自动生成的虚假页面。这些页面毫无实际价值，仅用于消耗机器人的时间与资源，令其陷入困惑，最终无法获取有效数据&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;过去，网站管理员常用「robots.txt」文件引导机器人避开特定页面。但一些 AI 公司，例如 Anthropic、Perplexity AI 等，屡次被指控忽视这种协议，擅自抓取数据，导致网站与机器人之间形成技术上的持续对抗。&lt;/p&gt; 
&lt;p&gt;Cloudflare 表示，每日大约有 500 亿次爬虫访问请求。尽管已开发多种拦截工具，但爬虫总能迅速适应并绕过防御措施。这次 Cloudflare 转变策略，不再直接拦截，而是通过生成迷宫般的虚假页面，让机器人陷入无用信息的循环，主动消耗自身的资源。&lt;/p&gt; 
&lt;p&gt;这种方法也被称作「下一代蜜罐陷阱」（Honeypot）。人类用户可以轻松识别并避免点击这些无价值链接，而机器人则毫无辨别能力，会持续抓取陷阱页面，越陷越深。Cloudflare 由此可记录并分析机器人行为，快速识别新的爬虫模式，并不断优化防御措施。&lt;/p&gt; 
&lt;p&gt;据介绍，AI 迷宫利用 Workers AI 和开源模型生成各种主题的独特 HTML 页面。Cloudflare 并非按需生成内容，而是预先生成并筛选内容，确保其不存在 XSS 漏洞，并将其存储在 R2 中以加快检索速度。每个生成的页面都包含适当的元指令，以防止搜索引擎索引，从而保护合法的 SEO 工作。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f86c8285f7b4db7b933becb98fe6643f887.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些 Nofollow 标签确保不遵守推荐指南的 AI 爬虫将被困在迷宫中，而遵守规则的爬虫则会安全地忽略蜜罐。重要的是，这些链接通过精心实现的属性和样式对普通访客不可见。除了保护网站内容外，AI 迷宫还作为一种复杂的识别机制。当这些隐藏链接被点击时，Cloudflare 可以自信地识别出自动化爬虫活动，并将这些宝贵的数据输入机器学习模型，以增强爬虫检测能力。这形成了一个有益的反馈循环，每次爬取尝试都有助于保护所有 Cloudflare 客户。&lt;/p&gt; 
&lt;p&gt;Cloudflare 强调，为防止误导公众，这些生成的虚假内容虽基于真实科学事实，但与目标网站毫无关系，因此对爬虫训练 AI 模型毫无价值。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-278fb851b6443b99447afe21e7853ee03da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;管理员只需在 Cloudflare 后台「机器人管理」界面启用该工具，即可简单使用。未来，Cloudflare 还计划构建更加复杂庞大的虚假页面网络，使恶意爬虫彻底迷失其中，进一步加大爬虫成本与困难度。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340927/cloudflare-unveils-ai-labyrinth</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340927/cloudflare-unveils-ai-labyrinth</guid>
            <pubDate>Sat, 22 Mar 2025 11:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>揭秘谷歌被 ChatGPT 偷袭后的自我革命</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;《彭博商业周刊》近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Ffeatures%2F2025-03-24%2Fgoogle-s-ai-search-overhaul-racing-chatgpt-for-the-web-s-future&quot; target=&quot;_blank&quot;&gt;发表深度文章称&lt;/a&gt;&lt;/u&gt;，谷歌原本有机会利用人工智能 (AI) 革新谷歌搜索，但是管理层不愿改变现状，保护广告业务利润，最终被 ChatGPT 抢占先机。为了迎头赶上，谷歌搜索开始自我变革。&lt;/p&gt; 
&lt;p&gt;以下是文章主要内容：&lt;/p&gt; 
&lt;p&gt;谷歌拥有 DeepMind 和 Google Brain 两大顶尖 AI 实验室，但其管理层对 AI 技术落地的态度始终谨慎。核心矛盾在于：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;技术可靠性&lt;/strong&gt;：生成式 AI 的答案准确性尚未达到搜索引擎的要求，可能引发误导性结果（如医疗建议错误）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;商业模式冲突&lt;/strong&gt;：谷歌搜索 2024 年贡献了 1980 亿美元收入（占 Alphabet 总营收 60%），而 AI 直接提供答案可能削弱广告展示机会——当前搜索页面的广告与自然结果混合模式为其核心利润来源。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;用户对传统搜索的不满已非秘密。Semrush 数据显示，谷歌每秒处理近 20 万次查询，但搜索结果中广告和低质 SEO 内容（如冗长的食谱网站）占比上升，导致体验下降。&lt;/p&gt; 
&lt;p&gt;相比之下，ChatGPT 的简洁交互和即时答案虽存在事实性错误，却因「纯粹性」获得用户宽容。这种反差凸显了搜索产品逻辑的范式转移：从「信息索引」转向「问题解决」。&lt;/p&gt; 
&lt;p&gt;为应对挑战，谷歌正从两方面推进变革：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;技术整合&lt;/strong&gt;：将生成式 AI 能力嵌入搜索（如实验性功能「AI Overviews」），在答案中标注信息来源以提升可信度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;广告模式迭代&lt;/strong&gt;：探索 AI 答案页面的新型广告位，例如在旅游建议中推荐酒店预订服务，试图兼容用户体验与商业需求。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;阅读更多&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/337252/google-ai-mode-search&quot; target=&quot;news&quot;&gt;谷歌搜索测试「AI Mode」：整合多模态和实时信息、一键解答复杂问题&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340924</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340924</guid>
            <pubDate>Sat, 22 Mar 2025 10:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>首发！优刻得云平台上新 DeepSeek-V3-0324 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;上新！DeepSeek-V3 重磅升级&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;昨夜，DeepSeek-V3 迎来一波更新，升级至&lt;strong&gt;「DeepSeek-V3-0324」&lt;/strong&gt;版本。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;不仅将模型参数量由原版的 671B 提升至 685B，编程、数学等推理思考能力大幅提升，性能表现可以与 Claude 3.5/3.7 Sonnet 相媲美。同时，模型的开源协议升级为更宽松的 MIT 许可，进一步降低了商业应用门槛。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet//351359c2aa96d28a2eeefa2ccdcd22c8.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;60&quot; src=&quot;https://oscimg.oschina.net/oscnet//f01541323470d69a14cad2d697ac18b7.jpeg&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;优刻得云平台始终密切关注 AI 技术发展动态，在新版本发布后迅速响应，第一时间在模型服务平台 UModelVerse 上架 DeepSeek-V3 最新版本，为广大用户带来高效、便捷的模型推理体验。&lt;strong&gt;只需简单 3 步，用户便可以「API」的调用方式，轻松解锁强大的模型推理能力！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;272&quot; src=&quot;https://oscimg.oschina.net/oscnet//58e74c42f4e9f751a7078a3b2e5d6a9c.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;技术突破：三大维度重构 AI 开发范式&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;1. 极简架构，极致效率&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;6850 亿参数 MoE 架构：&lt;/strong&gt;采用动态路由优化技术，激活参数仅 370 亿，通过&quot;偏差项&quot;机制和节点受限路由策略，实现跨节点通信开销降低 37%，推理速度提升&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;128K 超长上下文：&lt;/strong&gt;可解析 50 页 PDF 文档或完整代码库，多轮对话记忆保持能力提升&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FP8 混合精度训练：&lt;/strong&gt;显存占用压缩，单卡推理成本较初代降低&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;2. 代码生成质的飞跃&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;单次生成 400+行生产级代码&lt;/strong&gt;，支持 Vue/React 等 20+编程语言&lt;/li&gt; 
 &lt;li&gt;前端开发实现&lt;strong&gt;像素级美学：&lt;/strong&gt;生成的天气卡片、粒子动画等效果与 Claude 3.7 Sonnet 差距缩至 5%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智能纠错与接口检查：&lt;/strong&gt;自动检测 API 兼容性，代码可运行率达 92%&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;3. 数学推理突破性进化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;复杂数学题正确率提升 30%，支持逐步推导与自主纠错&lt;/li&gt; 
 &lt;li&gt;经典案例：7 米甘蔗过 2 米门难题，通过&quot;对角线原理&quot;自主发现隐藏解法&lt;/li&gt; 
 &lt;li&gt;非专业模型首次实现&lt;strong&gt;类人类顿悟思维&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;231&quot; src=&quot;https://oscimg.oschina.net/oscnet//2e498785cd98e362a2066b0deb604207.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;»评测表现&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;DeepSeek-V3-0324 在 Misguided Attention 长评估表现：&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;432&quot; src=&quot;https://oscimg.oschina.net/oscnet//052aa2fe9976e88e3e7937c428b6ea08.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;DeepSeek-V3-0324 以 53.5% 平均得分领跑，领先 Claude 3.7/GPT-4o，仅次于 DeepSeek-R1。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;»实测表现&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;X 博主「@KuittinenPetri」表示，更新后的 DeepSeek-V3-0324 可以轻松免费地创建漂亮的 HTML5、CSS 和前端。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;提示词如下，大家也可以自行尝试：为 AI 公司「NexusAI」创建一个外观精美的响应式首页，将所有内容包含在一个 HTML5 文件中。结果如下图所示，所有图像，包括用户故事和他们的面孔，一切都是用这个提示完成的。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;180&quot; src=&quot;https://oscimg.oschina.net/oscnet//d227d5bf63e56143e782b4b31b2c686e.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;180&quot; src=&quot;https://oscimg.oschina.net/oscnet//f19b9185aa95622a2ad1e303207efc4b.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;他认为：DeepSeek-V3-0324 是 DeepSeek 最好的非推理模型，通常更适合创意写作任务，但现在也比 R1 更适合制作 HTML5+CSS+前端。上述提示的结果代码总共 958 行，但它实际上实现了一个交互式网站，包括所有图像。并且结果也适用于移动设备。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;在优刻得三步极简接入，开启 AI 推理之旅&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;步骤一：注册并登录 UCloud 云平台&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;46&quot; src=&quot;https://oscimg.oschina.net/oscnet//e23be454c8ad4f08055f82a7e5886b7b.jpeg&quot; width=&quot;495&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;进入控制枱，选择产品&lt;strong&gt;「模型服务平台 UMoldeVerse」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;步骤二：开通 DeepSeek 调用权限&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;进入模型广场，选择 DeepSeek 系列模型，并点击&lt;strong&gt;「API 文档」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;*注：为保证服务稳定，目前 API 服务采用申请制。如需使用，请联系在线客服进行申请。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;321&quot; src=&quot;https://oscimg.oschina.net/oscnet//1a617d28f2cbd59c1d8332b37f636739.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;步骤三：在线体验&amp;amp;通过 API 调用&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;权限开通后，可通过体验中心进行页面对话，也可通过 API 调用进行业务接入：&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;1.在线体验：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;点击「体验」即可进入「体验中心」，在线体验与 DeepSeek 进行对话；&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;若选择两个模型，则可进行多模型对比体验。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;312&quot; src=&quot;https://oscimg.oschina.net/oscnet//6c7512bd625cb000a52b0c460fcc05c2.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;2.API 调用：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;点击「API 文档」跳转文档页面，根据 API 文档说明，进行 API 的调用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;获取 API Key：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;115&quot; src=&quot;https://oscimg.oschina.net/oscnet//5b618829a1875d3f21980060b62bcf5d.jpeg&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chat API 调用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;使用工具（如 curl）发送请求，代码调用示例：&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;232&quot; src=&quot;https://oscimg.oschina.net/oscnet//66d6378821fa0345b8b3b22933b41ac9.jpeg&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;在竞争激烈的商业环境中，快速采用新技术往往是企业脱颖而出的关键。目前，优刻得模型服务平台 UModelVerse、「优云智算」算力共享平台、私有云平台 UCloudStack 均已上架 DeepSeek 系列模型。同时提供 DeepSeek 大模型一体机的本地部署方案。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;您可以根据自身业务需求选择合适的模型镜像、云端或私有化部署方式，结合优刻得丰富的算力资源和模型微调服务，快速搭建企业级 AI 应用。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;优刻得始终致力于降低模型部署及应用的技术门槛，助力企业轻松调用 DeepSeek 等热门模型，无需投入大量时间和资源进行模型搭建与优化，即可将强大的 AI 能力融入自身业务流程中，加速产品创新与服务升级。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340922</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340922</guid>
            <pubDate>Sat, 22 Mar 2025 10:46:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>中国的「工程师红利」正在产生惊人回报</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;中国科技人才崛起正悄然改变着世界科技发展格局。「中国正从‘工程师红利’中收获巨大回报。」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/184015_h4Hs_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;彭博社以此为题&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fopinion%2Farticles%2F2025-03-24%2Fchina-s-engineer-dividend-is-paying-off-big-time&quot; target=&quot;_blank&quot;&gt;发文指出&lt;/a&gt;&lt;/u&gt;，中国政府重视高等教育，推动了工程师人才的培养，过去 20 多年里工程师数量大幅增加，庞大的人才库使中国在科技创新方面有了更大的突破机会。同时，中国工程师还具有年龄结构优势，人力成本仅为美国的八分之一，美国科技行业面临着中国带来的结构性挑战。&lt;/p&gt; 
&lt;p&gt;根据中国国务院的数据，在 2000 年至 2020 年间，工程师的数量从 520 万激增至 1770 万。人们认为，这一人才储备能够助力中国提升生产可能性边界。&lt;/p&gt; 
&lt;p&gt;彭博社指出，DeepSeek 改变了世界对中国的看法。从某种程度上来说，DeepSeek 的出现本不应令人感到意外。仅庞大的人才库这一点，就使中国有更大的机会实现突破。&lt;/p&gt; 
&lt;p&gt;保尔森基金会旗下智库宏观中国的数据显示，2022 年，在全球排名前 20% 的人工智能研究人员中，有 47% 的人本科毕业于中国，这一比例远高于美国的 18%。去年，在世界知识产权组织编制的创新指标数量排名中，中国位列第三，仅次于新加坡和美国。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c31dddf4b85b19e5e780a09ede0e11e44ef.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更重要的是，中国拥有成本优势。开源证券汇编的数据显示，在工程师群体中，30 岁以下的人占 44%，而在美国这一比例仅为 20%。因此，中国研究人员的薪酬大约仅为美国的八分之一。&lt;/p&gt; 
&lt;p&gt;因此，工程师群体的发展预示着一种全新的增长模式。中国的工程师们仍然年轻、成本较低且数量众多。因此，他们为中国开辟了新的可能性，在生物技术、人形机器人和人工智能应用的开发方面与西方竞争。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339460/software-engineer-jobs-five-year-low&quot; target=&quot;news&quot;&gt;软件工程师职位需求已俯冲到五年最低点？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/337519/anthropic-mike-krieger-how-software-engineering-work-changing&quot; target=&quot;news&quot;&gt;未来三年，软件工程师或将转型为「AI 代码审核员」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340918</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340918</guid>
            <pubDate>Sat, 22 Mar 2025 10:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源模型上下文协议 MCP 已合并</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，Anthropic 工程师在 MCP 的 GitHub 仓库&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/339546/mcp-streamable-http-transport&quot;&gt;提交&lt;/a&gt;&lt;/u&gt;了一个希望采用 &quot;Streamable HTTP&quot; 传输代替「HTTP+SSE」的 PR，以解决当前远程 Model Context Protocol (MCP) 传输方式的关键限制，同时保留其优势。&lt;/p&gt; 
&lt;p&gt;根据该 PR 目前的状态，MCP 现已合并&quot;Streamable HTTP&quot; 提案。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1212&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/180941_CBPU_2720166.png&quot; width=&quot;732&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;1412&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/181326_Jlzj_2720166.png&quot; width=&quot;2080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fspecification%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/specification/pull/206&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Streamable HTTP&amp;nbsp;改变了 MCP 的数据传输方式&lt;/strong&gt;，让协议变得：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更灵活&lt;/strong&gt;（支持流式传输，但不强制）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更易用&lt;/strong&gt;（支持无状态服务器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更兼容&lt;/strong&gt;（适用于标准 HTTP 基础设施）&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;💡&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;简单比喻&lt;/strong&gt;： 原来的 MCP 传输方式就像是&lt;strong&gt;你和客服通话时必须一直保持在线&lt;/strong&gt;（SSE 需要长连接），而新的方式更像是&lt;strong&gt;你随时可以发消息，然后等回复&lt;/strong&gt;（普通 HTTP 请求，但可以流式传输）。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;主要变更&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;移除 /sse 端点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器不再单独维护 SSE（Server-Sent Events）端点。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;所有客户端 → 服务器的消息都通过 /message 端点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任何数据传输都通过&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;/message&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;进行，不再依赖 /sse。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;服务器可以选择升级请求为 SSE&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可以根据需要&lt;strong&gt;动态升级 HTTP 请求为 SSE 流&lt;/strong&gt;，用于发送通知或请求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;客户端通过 Header 提供 Mcp-Session-Id&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可选是否需要存储 Session 信息，但客户端始终发送 Mcp-Session-Id 头部信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;支持无状态（Stateless）服务器&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可选择完全无状态运行，不再需要维持长期连接。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;变更的动机&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;当前的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;HTTP+SSE 传输&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;存在以下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;不支持可恢复性&lt;/strong&gt;（Resumability）：连接断开后，客户端必须重新开始整个会话。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;服务器需要维持长期连接&lt;/strong&gt;（High Availability Requirement）：服务器必须保持高可用性，以支持持续的 SSE 连接。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;SSE 仅支持服务器 → 客户端消息&lt;/strong&gt;，无法灵活进行双向通信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;新的 「Streamable HTTP」 传输方式解决了这些问题，并增强了系统的可扩展性和灵活性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340916/mcp-streamable-http-transport-merged</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340916/mcp-streamable-http-transport-merged</guid>
            <pubDate>Sat, 22 Mar 2025 10:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Apache Flink 2.0.0: 实时数据处理的新纪元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a431578f6b05f2fb76b7cab355fbd43976e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;今天，Flink&amp;nbsp;开发团队骄傲地宣布&amp;nbsp;Apache&amp;nbsp;Flink&amp;nbsp;2.0.0&amp;nbsp;正式发布！这是&amp;nbsp;Flink&amp;nbsp;2.x&amp;nbsp;系列的首个版本，也是自九年前&amp;nbsp;Flink&amp;nbsp;1.0&amp;nbsp;发布以来的首次重大更新。这个版本凝聚了社区两年来精心筹备与协作的成果，标志着&amp;nbsp;Flink&amp;nbsp;发展开启了新篇章。&lt;/p&gt; 
&lt;p&gt;在这个版本中，165&amp;nbsp;位贡献者齐聚一堂，完成了&amp;nbsp;25&amp;nbsp;项&amp;nbsp;Flink&amp;nbsp;改进提案（FLIP），解决了&amp;nbsp;367&amp;nbsp;个问题。我们衷心感谢所有贡献者为这个里程碑版本付出的宝贵努力！&lt;/p&gt; 
&lt;p&gt;过去十年间，Apache&amp;nbsp;Flink&amp;nbsp;经历了蜕变式的发展。在&amp;nbsp;1.0&amp;nbsp;时代，Flink&amp;nbsp;开创了有状态流计算的先河，让端到端精确一致语义的有状态流处理成为现实。如今，亚秒级延迟的实时处理已成为标准能力。然而，实时计算引擎如今却面临新的挑战，阻碍了其更加广泛的应用。实时计算的成本居高不下，无论是昂贵的资源消耗，还是掌握复杂的分布式流处理概念所需的学习曲线，都限制了实时计算在更多样化应用场景中的发挥。与此同时，云原生架构、数据湖和人工智能大语言模型等现代浪潮的涌现，也为实时系统带来了新的要求。在&amp;nbsp;2.0&amp;nbsp;时代，Flink&amp;nbsp;正在直面这些挑战，致力于提供更易用、更可扩展的实时计算解决方案，使各组织能够全面拥抱大数据和人工智能应用的实时能力。这一崭新篇章体现了&amp;nbsp;Flink&amp;nbsp;致力于使实时计算比以往更加实用、高效和广泛适用的决心。&lt;/p&gt; 
&lt;p&gt;在&amp;nbsp;2.0&amp;nbsp;版本中，Flink&amp;nbsp;引入了若干创新性功能，以应对实时数据处理的关键挑战，并满足现代应用（包括人工智能驱动的工作流）不断增长的需求。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分离式状态管理&lt;/strong&gt;&amp;nbsp;架构使得&amp;nbsp;Flink&amp;nbsp;在云原生环境中更高效地利用资源，在确保高性能实时处理的同时将资源开销降至最低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;物化表&lt;/strong&gt;&amp;nbsp;的引入和改进使用户能够专注于业务逻辑，无需深入了解流处理的复杂性以及流与批处理模式之间的差异，从而简化开发流程并提高生产力。&lt;strong&gt;批处理模式&lt;/strong&gt;&amp;nbsp;的优化为近实时或非实时处理场景提供了具有成本效益的替代方案，扩展了&amp;nbsp;Flink&amp;nbsp;对多样化应用场景的适应性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;此外，与&amp;nbsp;Apache&amp;nbsp;Paimon&amp;nbsp;的深度集成强化了&amp;nbsp;&lt;strong&gt;流式湖仓&lt;/strong&gt;&amp;nbsp;架构，使&amp;nbsp;Flink&amp;nbsp;成为实时数据湖应用场景的领先解决方案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;随着人工智能和大语言模型的不断崛起，对可扩展的实时数据处理解决方案的需求也在增长。Flink&amp;nbsp;2.0&amp;nbsp;在性能、资源效率和易用性方面的进步使其成为&amp;nbsp;&lt;strong&gt;人工智能工作流&lt;/strong&gt;&amp;nbsp;的强大基础，确保&amp;nbsp;Flink&amp;nbsp;处在实时数据处理创新的前沿地位。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些改进共同展示了&amp;nbsp;Flink&amp;nbsp;致力于满足现代数据应用不断变化的需求，这其中就包括将实时处理能力与人工智能驱动的系统相结合。&lt;/p&gt; 
&lt;p&gt;除了新功能外，Flink&amp;nbsp;2.0&amp;nbsp;还对已弃用的&amp;nbsp;API&amp;nbsp;和配置进行了全面清理，这可能导致某些接口和行为出现向后不兼容的变化。升级到此版本的用户应特别注意这些变化，以确保顺利迁移。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;新功能亮点&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;分离式状态管理&lt;/h2&gt; 
&lt;p&gt;过去十年间，Flink&amp;nbsp;的部署模式、工作负载和硬件的架构都发生了很大的改变。我们已经从计算存储耦合的&amp;nbsp;map-reduce&amp;nbsp;时代，过渡到了以&amp;nbsp;Kubernetes&amp;nbsp;容器化部署为标准的云原生世界。为了全面拥抱这一转变，Flink&amp;nbsp;2.0&amp;nbsp;引入了分离式状态存储与管理，利用分布式文件系统（DFS）作为主要存储介质。这一架构上的创新解决了云原生环境带来的关键挑战，同时又具备可扩展性、灵活性和高性能。&lt;/p&gt; 
&lt;p&gt;这种新架构解决了云原生时代给&amp;nbsp;Flink&amp;nbsp;带来的以下挑战：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;容器化环境中本地磁盘的限制&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;目前的状态模型中&amp;nbsp;Compaction&amp;nbsp;导致的计算资源尖峰&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大状态（数百 TB）作业的快速重缩放&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;以原生方式实现轻量级快速检查点&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;受限于&amp;nbsp;Flink&amp;nbsp;现有的阻塞式执行模型，直接将状态存储扩展为与远程&amp;nbsp;DFS&amp;nbsp;交互是不够的。为了克服这一限制，Flink&amp;nbsp;2.0&amp;nbsp;引入了异步执行模型以及分离式状态后端，并且重新设计了能够并行和异步地进行状态访问的&amp;nbsp;SQL&amp;nbsp;算子。&lt;/p&gt; 
&lt;p&gt;Flink&amp;nbsp;2.0&amp;nbsp;为分离式状态管理提供了从运行时到&amp;nbsp;SQL&amp;nbsp;算子层的端到端体验：&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;异步执行模型&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;无序数据处理&lt;/strong&gt;：解耦状态访问和计算，以实现并行执行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;异步状态&amp;nbsp;API&lt;/strong&gt;：对检查点期间非阻塞性状态操作的完美支持，减少延迟并提高资源利用率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;语义保持&lt;/strong&gt;：保持&amp;nbsp;Flink&amp;nbsp;核心语义（例如，水位传播、定时器处理和键顺序）不变，确保用户在采用新架构时无需担心应用程序行为的变化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;更强大的&amp;nbsp;SQL&amp;nbsp;算子&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;借助新的异步状态访问&amp;nbsp;API，Flink&amp;nbsp;2.0&amp;nbsp;重新实现了七个关键的&amp;nbsp;SQL&amp;nbsp;算子，包括&amp;nbsp;Join&amp;nbsp;和&amp;nbsp;Aggregates&amp;nbsp;等有状态操作（例如，窗口聚合、分组聚合）。这些优化针对状态访问延迟比较大的场景，通过非阻塞式执行最大化吞吐量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用户可以通过设置&amp;nbsp;&lt;code&gt;table.exec.async-state.enabled&lt;/code&gt;参数来启用该功能。一经启用，作业中所有支持的&amp;nbsp;SQL&amp;nbsp;算子将自动切换到异步状态访问模式，无需更改代码。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在&amp;nbsp;Nexmark&amp;nbsp;基准测试的&amp;nbsp;14&amp;nbsp;个有状态查询中，有&amp;nbsp;11&amp;nbsp;个现已完全兼容异步执行模型，并且有显著的性能提升。我们正在努力扩展对剩余有状态算子的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;ForSt&amp;nbsp;-&amp;nbsp;分离式状态后端&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ForSt，意为&amp;nbsp;「为了流处理」，是一个专为满足云原生部署独特需求而设计的分离式状态后端。通过将状态存储与计算资源解耦，ForSt&amp;nbsp;消除了本地磁盘的限制，并支持并行多路&amp;nbsp;I/O&amp;nbsp;操作，有效降低了延迟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ForSt&amp;nbsp;与&amp;nbsp;DFS&amp;nbsp;的集成确保了数据的持久化和容灾能力，同时优化了读写操作以保持高性能。它能够以非常轻量和快速的方式执行检查点和错误恢复。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;性能评估（以&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnexmark%2Fnexmark&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Nexmark&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;为基准）&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c44e25d52b641bf238102d4b2cbd4231.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对于重&amp;nbsp;I/O&amp;nbsp;的有状态查询（q5、q7、q18、q19、q20），使用带有&amp;nbsp;1GB&amp;nbsp;缓存的分离式状态存储与传统的本地状态存储方案相比，吞吐量可达&amp;nbsp;75%&amp;nbsp;~&amp;nbsp;120%。值得注意的是，这些查询的状态大小从&amp;nbsp;1.2GB&amp;nbsp;到&amp;nbsp;4.8GB&amp;nbsp;不等，即使在缓存受限条件下，分离式架构与完全本地状态存储相比仍能表现出竞争力。即使没有缓存，异步模型也能确保达到本地状态存储大约&amp;nbsp;50%&amp;nbsp;的吞吐量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对于状态较小（10MB&amp;nbsp;到&amp;nbsp;400MB）的有状态查询（q3、q4、q5、q8、q12、q17），状态几乎完全驻留在内存块缓存中，磁盘&amp;nbsp;I/O&amp;nbsp;可以忽略不计。在这种情况下，分离式状态存储的性能比本地状态存储平均低不超过&amp;nbsp;10%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基准测试结果证实，分离式状态架构能够高效地处理大规模有状态工作负载。它可以作为传统存算耦合状态存储的无缝、高性能替代，且没有显著的性能损失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Flink&amp;nbsp;2.0&amp;nbsp;的分离式状态管理是迈向真正云原生未来的关键一步。通过解决本地磁盘限制、资源使用波动和快速重缩放等关键挑战，使用户能够构建可扩展、高性能的流处理应用程序。随着异步执行模型和&amp;nbsp;ForSt&amp;nbsp;的引入，以及能力更强大的&amp;nbsp;SQL&amp;nbsp;算子，我们预计&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;将成为云原生时代有状态流处理的新标准。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;流批统一&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;物化表&lt;/h3&gt; 
&lt;p&gt;物化表是我们统一流处理和批处理范式这一愿景的基石。它使得用户能够声明性地通过单个数据处理流程同时管理实时数据和历史数据，消除了维护多套代码或工作流的弊端。&lt;/p&gt; 
&lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，我们将重点放在生产级的可操作性上。对简化实际环境中生命周期管理和执行的关键功能进行了增强：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查询变更&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;物化表现在支持表结构和查询语句的更新，无需重新处理历史数据即可无缝迭代业务逻辑。这对于需要应对表结构演变和计算逻辑调整的生产场景至关重要。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Kubernetes/Yarn&amp;nbsp;支持&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;除了&amp;nbsp;Standalone&amp;nbsp;集群，Flink&amp;nbsp;2.0&amp;nbsp;对将物化表刷新作业提交到&amp;nbsp;YARN&amp;nbsp;和&amp;nbsp;Kubernetes&amp;nbsp;集群进行了原生支持。这使用户能够将物化表刷新工作流无缝集成到其生产架构中，从而实现标准化资源管理、容错和可扩展性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生态系统集成&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;通过与&amp;nbsp;Apache&amp;nbsp;Paimon&amp;nbsp;社区的合作，Paimon&amp;nbsp;的湖存储格式目前原生支持&amp;nbsp;Flink&amp;nbsp;物化表，将&amp;nbsp;Flink&amp;nbsp;的流批计算与&amp;nbsp;Paimon&amp;nbsp;的高性能&amp;nbsp;ACID&amp;nbsp;事务相结合，实现统一的数据服务。&lt;/p&gt; 
&lt;p&gt;物化表给开发者提供了简单，可靠的流批数据处理链路。未来将继续深化生产级支持，例如与生产可用的调度程序集成，以实现基于策略的自动化刷新。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_9&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;自适应批处理执行&lt;/h3&gt; 
&lt;p&gt;Flink&amp;nbsp;具备自适应批处理执行功能，能够根据运行时信息优化执行计划以提高性能。关键功能包括动态分区裁剪、运行时数据过滤和基于数据量的自动并行度调整。在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，我们通过以下两项新优化进一步增强了这些功能：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自适应&amp;nbsp;Broadcast&amp;nbsp;Join&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;与&amp;nbsp;Shuffle&amp;nbsp;Hash&amp;nbsp;Join&amp;nbsp;和&amp;nbsp;Sort&amp;nbsp;Merge&amp;nbsp;Join&amp;nbsp;相比，Broadcast&amp;nbsp;Join&amp;nbsp;无需大规模数据重分布和排序，执行效率更高。然而，其适用性取决于输入数据量是否足够小；否则，可能会出现性能或稳定性问题。在静态的&amp;nbsp;SQL&amp;nbsp;优化阶段，准确估算&amp;nbsp;Join&amp;nbsp;算子的输入数据量具有一定的挑战性，难以确定&amp;nbsp;Broadcast&amp;nbsp;Join&amp;nbsp;是否适用。通过启用自适应执行优化，Flink&amp;nbsp;在运行时动态捕获&amp;nbsp;Join&amp;nbsp;算子的实际输入情况，并在满足条件时自动切换到&amp;nbsp;Broadcast&amp;nbsp;Join，显著提高执行效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自动优化数据倾斜的&amp;nbsp;Join&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;在&amp;nbsp;Join&amp;nbsp;操作中，特定键的频繁出现可能导致下游任务处理的数据量差异巨大，因而出现长尾瓶颈，严重拖慢整个作业的执行。Flink&amp;nbsp;现在可以利用&amp;nbsp;Join&amp;nbsp;算子输入边的运行时统计信息，动态拆分出倾斜的数据分区，同时确保计算结果的完整性。这有效缓解了由数据倾斜引起的长尾延迟。&lt;/p&gt; 
&lt;p&gt;更多关于&amp;nbsp;Flink&amp;nbsp;自适应批处理执行的功能和用法，请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdeployment%2Fadaptive_batch%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Flink&amp;nbsp;文档&lt;/a&gt;。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;性能&lt;/h3&gt; 
&lt;p&gt;通过上述优化，Flink&amp;nbsp;2.0&amp;nbsp;的批处理性能得到了进一步提升。我们在&amp;nbsp;10TB&amp;nbsp;TPC-DS&amp;nbsp;数据集上进行了基准测试：通过&amp;nbsp;&lt;code&gt;ANALYZE&amp;nbsp;TABLE&lt;/code&gt;&amp;nbsp;语句生成额外统计信息后，Flink&amp;nbsp;2.0&amp;nbsp;相比&amp;nbsp;Flink&amp;nbsp;1.20&amp;nbsp;实现了&amp;nbsp;8%&amp;nbsp;的性能提升；在没有额外统计信息的情况下，性能提升达到了&amp;nbsp;16%。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;流式湖仓&lt;/h2&gt; 
&lt;p&gt;湖仓架构是近年来出现的一种变革性趋势。通过将&amp;nbsp;Flink&amp;nbsp;作为流批统一处理引擎和&amp;nbsp;Paimon&amp;nbsp;作为流批统一湖格式，流式湖仓架构实现了湖仓数据的实时新鲜度。在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，Flink&amp;nbsp;社区与&amp;nbsp;Paimon&amp;nbsp;社区紧密合作，充分发挥各自优势和前沿功能，带来了显著的增强和优化。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Paimon&amp;nbsp;数据源现在支持对嵌套的&amp;nbsp;projection&amp;nbsp;进行下推。在涉及复杂数据结构的场景中显著减少了&amp;nbsp;IO&amp;nbsp;开销并大幅提升性能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当使用&amp;nbsp;Paimon&amp;nbsp;作为维度表时，Lookup&amp;nbsp;Join&amp;nbsp;的性能得到了大幅提升。通过将输入数据的分布与&amp;nbsp;Paimon&amp;nbsp;表的分桶机制对齐，显著减少了每个&amp;nbsp;Lookup&amp;nbsp;join&amp;nbsp;任务需要从&amp;nbsp;Paimon&amp;nbsp;检索、缓存和处理的数据量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有&amp;nbsp;Paimon&amp;nbsp;的维护性操作（如&amp;nbsp;Compaction、管理快照/&amp;nbsp;分支/&amp;nbsp;标签等）现在都可以通过&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;的&amp;nbsp;CALL&amp;nbsp;语句轻松执行，并且支持命名参数，可以与任何可选参数的子集一起使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;之前，批模式下将数据写入&amp;nbsp;Paimon&amp;nbsp;时无法开启自动并行度推断。在新版本中，我们通过固定并行度确保分桶的正确性，同时在与分桶无关的场景中仍应用自动并行推断，从而解决了这一问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;物化表是&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;中新的流批统一表类型，Paimon&amp;nbsp;作为首个支持该功能的&amp;nbsp;Catalog&amp;nbsp;类型，提供了连贯的开发体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;人工智能&lt;/h2&gt; 
&lt;p&gt;随着大语言模型技术的快速发展，人工智能正在从以训练为核心转向以推理和实际应用为核心，推动了对大规模数据实时处理的需求。作为领先的实时大数据处理引擎，Flink&amp;nbsp;一直在积极探索和创新，以应对人工智能时代带来的机遇和挑战，更好地支持实时人工智能应用。&lt;/p&gt; 
&lt;p&gt;Flink&amp;nbsp;CDC&amp;nbsp;3.3&amp;nbsp;版本在&amp;nbsp;&lt;code&gt;Transform&lt;/code&gt;表达式中引入了动态调用人工智能模型的能力，原生支持&amp;nbsp;OpenAI&amp;nbsp;模型。在实时捕获数据库数据变化后，用户可以立即利用人工智能模型进行智能排序、语义分析或异常检测。这种集成使&amp;nbsp;Flink&amp;nbsp;CDC&amp;nbsp;能够有效结合流处理与检索增强生成（RAG）技术，在实时风险控制、个性化推荐和智能日志解析等场景中实现端到端低延迟处理，从而在数据流中释放实时人工智能的价值。&lt;/p&gt; 
&lt;p&gt;此外，Flink&amp;nbsp;SQL&amp;nbsp;还为&amp;nbsp;AI&amp;nbsp;模型引入了专门的语法，允许用户像定义&amp;nbsp;Catalog&amp;nbsp;一样轻松定义人工智能模型，并在&amp;nbsp;SQL&amp;nbsp;语句中像函数或表函数一样调用它们。与&amp;nbsp;Flink&amp;nbsp;CDC&amp;nbsp;相比，Flink&amp;nbsp;SQL&amp;nbsp;支持更复杂的关系数据处理逻辑，能够无缝将复杂数据处理工作流与人工智能模型集成，这一特性目前正处于积极开发和完善之中。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;其他&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_14&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;DataStream&amp;nbsp;V2&amp;nbsp;API&lt;/h3&gt; 
&lt;p&gt;DataStream&amp;nbsp;API&amp;nbsp;是&amp;nbsp;Flink&amp;nbsp;提供的两种主要&amp;nbsp;API&amp;nbsp;之一，用于编写灵活的数据处理程序。作为一个几乎自项目第一天起就引入并在近十年中不断演进的&amp;nbsp;API，我们也越来越意识到它存在着诸多问题。对这些问题的改进需要巨大的不兼容变更，这使得原地重构几乎不切实际。因此，Flink&amp;nbsp;社区在&amp;nbsp;2.0&amp;nbsp;版本引入了一组新的&amp;nbsp;API，即&amp;nbsp;DataStream&amp;nbsp;API&amp;nbsp;V2，以逐步取代原始的&amp;nbsp;DataStream&amp;nbsp;API。&lt;/p&gt; 
&lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，我们提供了&amp;nbsp;DataStream&amp;nbsp;V2&amp;nbsp;API&amp;nbsp;的最小可行产品 (MVP) 版本。它包含底层的基础构建部分（数据流、处理函数、分区），以及状态、时间服务、水位线处理等上下文和原语。同时，我们还提供了一些高级扩展，如窗口和&amp;nbsp;Join。它们更像是一种语法糖，没有它们，用户仍然可以通过使用基础&amp;nbsp;API&amp;nbsp;实现相同行为，但内置支持会让实现更加容易。&lt;/p&gt; 
&lt;p&gt;更多详情请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Fdatastream-v2%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&amp;nbsp;新的&amp;nbsp;DataStream&amp;nbsp;API&amp;nbsp;目前处于实验阶段，尚不稳定，因此目前不建议在生产环境中使用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_15&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;SQL&amp;nbsp;gateway&amp;nbsp;支持&amp;nbsp;Application&amp;nbsp;模式&lt;/h3&gt; 
&lt;p&gt;SQL&amp;nbsp;gateway&amp;nbsp;现在支持以&amp;nbsp;Application&amp;nbsp;模式执行&amp;nbsp;SQL&amp;nbsp;作业，取代了已移除的&amp;nbsp;Per-Job&amp;nbsp;部署模式。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;SQL&amp;nbsp;语法增强&lt;/h3&gt; 
&lt;p&gt;Flink&amp;nbsp;SQL&amp;nbsp;现在支持&amp;nbsp;C&amp;nbsp;风格的转义字符串。更多详情请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Foverview%2F%23syntax&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;新增了更简洁的&amp;nbsp;&lt;code&gt;QUALIFY&lt;/code&gt;&amp;nbsp;子句，用于过滤窗口函数的输出。有关示例，请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Ftopn%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Top-N&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fdeduplication%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;去重&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;对于表函数调用，在&amp;nbsp;&lt;code&gt;FROM&lt;/code&gt;&amp;nbsp;中不再需要使用&amp;nbsp;&lt;code&gt;TABLE()&lt;/code&gt;&amp;nbsp;包裹。更多示例请参阅更新后的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fwindow-tvf&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;窗口表值函数&lt;/a&gt;文档。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;Java&amp;nbsp;支持&lt;/h3&gt; 
&lt;p&gt;从&amp;nbsp;2.0&amp;nbsp;版本开始，Flink&amp;nbsp;正式支持&amp;nbsp;Java&amp;nbsp;21，默认和推荐的&amp;nbsp;Java&amp;nbsp;版本已更改为&amp;nbsp;Java&amp;nbsp;17（此前为&amp;nbsp;Java&amp;nbsp;11）。同时，Flink&amp;nbsp;2.0&amp;nbsp;不再支持&amp;nbsp;Java&amp;nbsp;8。这一变更主要影响&amp;nbsp;Docker&amp;nbsp;镜像和从源代码构建&amp;nbsp;Flink。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_18&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;序列化改进&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Flink&amp;nbsp;2.0&amp;nbsp;为集合类型（Map/List/Set）引入了更高效的内置序列化器，并且默认启用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kryo&amp;nbsp;依赖升级到了&amp;nbsp;5.6&amp;nbsp;版本，该版本速度更快，内存效率更高，并且对较新的&amp;nbsp;Java&amp;nbsp;版本有更好的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_19&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;非兼容性变更&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_20&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;以下几组&amp;nbsp;API&amp;nbsp;已被完全移除。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DataSet&amp;nbsp;API。&lt;/strong&gt;&amp;nbsp;请迁移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Fdatastream%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DataStream&amp;nbsp;API&lt;/a&gt;，或在适用的情况下迁移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Table&amp;nbsp;API/SQL&lt;/a&gt;。有关如何从&amp;nbsp;DataSet&amp;nbsp;迁移到&amp;nbsp;DataStream&amp;nbsp;的更多信息，请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.20%2Fdocs%2Fdev%2Fdatastream%2Fdataset_migration&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;如何从&amp;nbsp;DataSet&amp;nbsp;迁移到&amp;nbsp;DataStream&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scala&amp;nbsp;DataStream&amp;nbsp;和&amp;nbsp;DataSet&amp;nbsp;API。&lt;/strong&gt;&amp;nbsp;请迁移到&amp;nbsp;Java&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Fdatastream%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DataStream&amp;nbsp;API&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SourceFunction、SinkFunction&amp;nbsp;和&amp;nbsp;Sink&amp;nbsp;V1。&lt;/strong&gt;&amp;nbsp;请迁移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fconnector%2Fsource%2FSource.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Source&lt;/a&gt;和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fconnector%2Fsink2%2FSink.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Sink&amp;nbsp;V2&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TableSource&amp;nbsp;和&amp;nbsp;TableSink。&lt;/strong&gt;&amp;nbsp;请迁移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fconnector%2Fsource%2FDynamicTableSource.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DynamicTableSource&lt;/a&gt;和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fconnector%2Fsink%2FDynamicTableSink.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DynamicTableSink&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TableSchema、TableColumn&amp;nbsp;和&amp;nbsp;Types。&lt;/strong&gt;&amp;nbsp;请分别迁移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fapi%2FSchema.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Schema&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fcatalog%2FColumn.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Column&lt;/a&gt;和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fapi%2FDataTypes.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DataTypes&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从&amp;nbsp;&lt;strong&gt;DataStream&amp;nbsp;API&lt;/strong&gt;&amp;nbsp;中移除了部分已弃用的方法。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从&amp;nbsp;&lt;strong&gt;REST&amp;nbsp;API&lt;/strong&gt;&amp;nbsp;中移除了部分已弃用的字段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&amp;nbsp;您可能会发现某些已移除的&amp;nbsp;API&amp;nbsp;仍然存在于代码库中，通常位于不同的包路径下。它们仅用于内部用途，可能会随时被更改或移除。请&lt;strong&gt;勿使用&lt;/strong&gt;它们。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_21&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;连接器适配计划&lt;/h2&gt; 
&lt;p&gt;随着&amp;nbsp;SourceFunction、SinkFunction&amp;nbsp;和&amp;nbsp;SinkV1&amp;nbsp;的移除，依赖这些&amp;nbsp;API&amp;nbsp;的现有连接器将无法在&amp;nbsp;Flink&amp;nbsp;2.x&amp;nbsp;系列上运行。以下是&amp;nbsp;Flink&amp;nbsp;官方支持的连接器的适配计划。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0.0&amp;nbsp;发布后，将立即发布适配&amp;nbsp;API&amp;nbsp;变化的&amp;nbsp;Kafka、Paimon、JDBC&amp;nbsp;和&amp;nbsp;ElasticSearch&amp;nbsp;连接器的新版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;我们计划在接下来的&amp;nbsp;3&amp;nbsp;个次要版本（即到&amp;nbsp;Flink&amp;nbsp;2.3）内逐步支持剩余的连接器。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;配置&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;符合以下标准的配置项将被移除：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;标记为&amp;nbsp;&lt;code&gt;@Public&lt;/code&gt;&amp;nbsp;且已弃用至少&amp;nbsp;2&amp;nbsp;个次要版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;标记为&amp;nbsp;&lt;code&gt;@PublicEvolving&lt;/code&gt;&amp;nbsp;且已弃用至少&amp;nbsp;1&amp;nbsp;个次要版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持旧版配置文件&amp;nbsp;&lt;code&gt;flink-conf.yaml&lt;/code&gt;。请改用标准&amp;nbsp;YAML&amp;nbsp;格式的&amp;nbsp;&lt;code&gt;config.yaml&lt;/code&gt;。我们提供了一个迁移工具，可将旧版&amp;nbsp;&lt;code&gt;flink-conf.yaml&lt;/code&gt;&amp;nbsp;转换为新的&amp;nbsp;&lt;code&gt;config.yaml&lt;/code&gt;。有关更多详情，请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdeployment%2Fconfig%2F%23migrate-from-flink-confyaml-to-configyaml&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;从&amp;nbsp;flink-conf.yaml&amp;nbsp;迁移至&amp;nbsp;config.yaml&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从&amp;nbsp;&lt;code&gt;StreamExecutionEnvironment&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;ExecutionConfig&lt;/code&gt;&amp;nbsp;中移除了以&amp;nbsp;Java&amp;nbsp;对象为参数的配置&amp;nbsp;API。它们现在应通过&amp;nbsp;&lt;code&gt;Configuration&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;ConfigOption&lt;/code&gt;&amp;nbsp;设置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为避免暴露内部接口，用户定义函数不再完全访问&amp;nbsp;&lt;code&gt;ExecutionConfig&lt;/code&gt;。相反，必要的功能（如&amp;nbsp;&lt;code&gt;createSerializer()&lt;/code&gt;、&lt;code&gt;getGlobalJobParameters()&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;isObjectReuseEnabled()&lt;/code&gt;）现在可直接从&amp;nbsp;&lt;code&gt;RuntimeContext&lt;/code&gt;&amp;nbsp;访问。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;其他&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Flink&amp;nbsp;1.x&amp;nbsp;和&amp;nbsp;2.x&amp;nbsp;之间不保证状态兼容性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持&amp;nbsp;Java&amp;nbsp;8，Flink&amp;nbsp;现在支持的最低&amp;nbsp;Java&amp;nbsp;版本是&amp;nbsp;Java&amp;nbsp;11。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持&amp;nbsp;Per-Job&amp;nbsp;部署模式，请改用&amp;nbsp;Application&amp;nbsp;模式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hybrid&amp;nbsp;Shuffle&amp;nbsp;的旧模式已经被基于分层存储的新架构所取代并移除。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_24&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;发行说明&lt;/h1&gt; 
&lt;p&gt;有关功能、改进、错误修复的全面列表，以及升级过程中需要关注的调整和问题，请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Frelease-notes%2Fflink-2.0%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;发行说明&lt;/a&gt;。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_25&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;贡献者名单&lt;/h1&gt; 
&lt;p&gt;Apache&amp;nbsp;Flink&amp;nbsp;社区感谢对此版本做出贡献的每一位贡献者：&lt;/p&gt; 
&lt;p&gt;Alan&amp;nbsp;Sheinberg,&amp;nbsp;Aleksandr&amp;nbsp;Pilipenko,&amp;nbsp;Alex&amp;nbsp;Sorokoumov,&amp;nbsp;AlexYinHan,&amp;nbsp;Alexander&amp;nbsp;Fedulov,&amp;nbsp;Ammu,&amp;nbsp;Andrei&amp;nbsp;Kaigorodov,&amp;nbsp;Andrey&amp;nbsp;Gaskov,&amp;nbsp;Arkadiusz&amp;nbsp;Dankiewicz,&amp;nbsp;Arvid&amp;nbsp;Heise,&amp;nbsp;BoShuai&amp;nbsp;Li,&amp;nbsp;Brisk&amp;nbsp;Wong,&amp;nbsp;Cancai&amp;nbsp;Cai,&amp;nbsp;Chesnay&amp;nbsp;Schepler,&amp;nbsp;Chester,&amp;nbsp;Chris,&amp;nbsp;CuiYanxiang,&amp;nbsp;Danny&amp;nbsp;Cranmer,&amp;nbsp;David&amp;nbsp;Anderson,&amp;nbsp;David&amp;nbsp;Moravek,&amp;nbsp;David&amp;nbsp;Radley,&amp;nbsp;Dawid&amp;nbsp;Wysakowicz,&amp;nbsp;Dian&amp;nbsp;Fu,&amp;nbsp;Dmitriy&amp;nbsp;Linevich,&amp;nbsp;Eaugene&amp;nbsp;Thomas,&amp;nbsp;Fabian&amp;nbsp;Hueske,&amp;nbsp;Feng&amp;nbsp;Jin,&amp;nbsp;Ferenc&amp;nbsp;Csaky,&amp;nbsp;Francesco&amp;nbsp;Di&amp;nbsp;Chiara,&amp;nbsp;Gabor&amp;nbsp;Somogyi,&amp;nbsp;Gantigmaa&amp;nbsp;Selenge,&amp;nbsp;Grace&amp;nbsp;Grimwood,&amp;nbsp;Grzegorz&amp;nbsp;Kołakowski,&amp;nbsp;Gustavo&amp;nbsp;de&amp;nbsp;Morais,&amp;nbsp;Hanyu&amp;nbsp;Zheng,&amp;nbsp;Hao&amp;nbsp;Li,&amp;nbsp;Hong&amp;nbsp;Teoh,&amp;nbsp;Hyungstler,&amp;nbsp;Jacky&amp;nbsp;Lau,&amp;nbsp;James&amp;nbsp;Hughes,&amp;nbsp;Jeyassri&amp;nbsp;Balachandran,&amp;nbsp;Jiangjie&amp;nbsp;(Becket)&amp;nbsp;Qin,&amp;nbsp;Jim&amp;nbsp;Hughes,&amp;nbsp;Jingsong,&amp;nbsp;Joern&amp;nbsp;Kottmann,&amp;nbsp;Joery,&amp;nbsp;JunRuiLee,&amp;nbsp;Junrui&amp;nbsp;Lee,&amp;nbsp;Kaitian&amp;nbsp;Hu,&amp;nbsp;Kartikey&amp;nbsp;Pant,&amp;nbsp;Kunni,&amp;nbsp;Kurt&amp;nbsp;Ostfeld,&amp;nbsp;Lajith,&amp;nbsp;Lei&amp;nbsp;Yang,&amp;nbsp;Lorenzo&amp;nbsp;Affetti,&amp;nbsp;Luke&amp;nbsp;Chen,&amp;nbsp;Marc&amp;nbsp;Aurel&amp;nbsp;Fritz,&amp;nbsp;Martijn&amp;nbsp;Visser,&amp;nbsp;Márton&amp;nbsp;Balassi,&amp;nbsp;Mate&amp;nbsp;Czagany,&amp;nbsp;Matt&amp;nbsp;Braymer-Hayes,&amp;nbsp;Matthias&amp;nbsp;Pohl,&amp;nbsp;Mina&amp;nbsp;Asham,&amp;nbsp;Myracle,&amp;nbsp;Paul&amp;nbsp;Zhang,&amp;nbsp;Peng&amp;nbsp;Lu,&amp;nbsp;Peter&amp;nbsp;Huang,&amp;nbsp;Piotr&amp;nbsp;Nowojski,&amp;nbsp;Piotr&amp;nbsp;Przybylski,&amp;nbsp;Qingsheng&amp;nbsp;Ren,&amp;nbsp;Ran&amp;nbsp;Tao,&amp;nbsp;Robin&amp;nbsp;Moffatt,&amp;nbsp;Roc&amp;nbsp;Marshal,&amp;nbsp;Roman&amp;nbsp;Khachatryan,&amp;nbsp;Ron,&amp;nbsp;Rui&amp;nbsp;Fan,&amp;nbsp;Ryan&amp;nbsp;Skraba,&amp;nbsp;Sam&amp;nbsp;Barker,&amp;nbsp;Samrat,&amp;nbsp;Sergei&amp;nbsp;Morozov,&amp;nbsp;Sergey&amp;nbsp;Nuyanzin,&amp;nbsp;Sergio&amp;nbsp;Pena,&amp;nbsp;Sergio&amp;nbsp;Peña,&amp;nbsp;Shengkai,&amp;nbsp;Shuyi&amp;nbsp;Chen,&amp;nbsp;Stefan&amp;nbsp;Richter,&amp;nbsp;Sud0x67,&amp;nbsp;Tamas&amp;nbsp;Sule,&amp;nbsp;Thomas&amp;nbsp;Cooper,&amp;nbsp;Timo&amp;nbsp;Walther,&amp;nbsp;Vincent-Woo,&amp;nbsp;Wang&amp;nbsp;FeiFan,&amp;nbsp;Wang&amp;nbsp;Qian,&amp;nbsp;WangQian,&amp;nbsp;Weijie&amp;nbsp;Guo,&amp;nbsp;Wenchao&amp;nbsp;Wu,&amp;nbsp;Wenjun&amp;nbsp;Ruan,&amp;nbsp;Xia&amp;nbsp;Sun,&amp;nbsp;Xiangyu&amp;nbsp;Feng,&amp;nbsp;Xintong&amp;nbsp;Song,&amp;nbsp;Xu&amp;nbsp;Huang,&amp;nbsp;XuHao41,&amp;nbsp;XuShuai,&amp;nbsp;Xuannan,&amp;nbsp;Xuyang,&amp;nbsp;Yanfei&amp;nbsp;Lei,&amp;nbsp;Yi&amp;nbsp;Zhang,&amp;nbsp;Yiyu&amp;nbsp;Tian,&amp;nbsp;Yu&amp;nbsp;Chen,&amp;nbsp;Yubin&amp;nbsp;Li,&amp;nbsp;Yuxin&amp;nbsp;Tan,&amp;nbsp;Zakelly,&amp;nbsp;Zdenek&amp;nbsp;Tison,&amp;nbsp;Zhanghao&amp;nbsp;Chen,&amp;nbsp;Zhen&amp;nbsp;Wang,&amp;nbsp;anupamaggarwal,&amp;nbsp;argoyal2212,&amp;nbsp;auroflow,&amp;nbsp;candaccc,&amp;nbsp;clarax,&amp;nbsp;codenohup,&amp;nbsp;drymatini,&amp;nbsp;dylanhz,&amp;nbsp;fengli,&amp;nbsp;fredia,&amp;nbsp;gongzhongqiang,&amp;nbsp;haishui,&amp;nbsp;huyuanfeng,&amp;nbsp;jectpro7,&amp;nbsp;lexluo09,&amp;nbsp;lincoln&amp;nbsp;lee,&amp;nbsp;liuyongvs,&amp;nbsp;lvyanquan,&amp;nbsp;lz,&amp;nbsp;mayuehappy,&amp;nbsp;mehdid93,&amp;nbsp;morazow,&amp;nbsp;naferx,&amp;nbsp;nateab,&amp;nbsp;noorall,&amp;nbsp;r-sidd,&amp;nbsp;shalini,&amp;nbsp;simplejason,&amp;nbsp;slankka,&amp;nbsp;sullis,&amp;nbsp;sunxia,&amp;nbsp;sxnan,&amp;nbsp;tison,&amp;nbsp;wangfeifan,&amp;nbsp;xaniasd,&amp;nbsp;xiarui,&amp;nbsp;xincheng.ljr,&amp;nbsp;xuyang,&amp;nbsp;xuzifu666,&amp;nbsp;yinhan.yh,&amp;nbsp;yunfengzhou-hub,&amp;nbsp;zbz,&amp;nbsp;zhangmang,&amp;nbsp;zhaorongsheng,&amp;nbsp;zhengchenyu,&amp;nbsp;zhuanshenbsj1,&amp;nbsp;余良,&amp;nbsp;皆非,&amp;nbsp;马越,&amp;nbsp;林尚泉&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/2828172/blog/17996920</link>
            <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/17996920</guid>
            <pubDate>Sat, 22 Mar 2025 09:31:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>XPipe —— shell 连接中心和远程文件管理器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;XPipe 是一种新型的 shell 连接中心和远程文件管理器，可让你从本地计算机访问整个服务器基础架构。它基于你已安装的命令行程序运行，不需要在远程系统上进行任何设置。因此，如果你通常使用 CLI 工具（如&lt;code&gt;ssh&lt;/code&gt;、&lt;code&gt;docker&lt;/code&gt;、&lt;code&gt;kubectl&lt;/code&gt;等）连接到服务器，则只需在此基础上使用 XPipe 即可。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;XPipe 可与你的工具（例如你最喜欢的文本/代码编辑器、终端、shell、命令行工具等）完全集成。该平台设计为可扩展的，允许任何人轻松添加对更多工具的支持或通过模块化扩展系统实现自定义功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;它目前支持：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/ssh&quot;&gt;SSH&lt;/a&gt;连接、配置文件和隧道&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/docker&quot;&gt;Docker&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/podman&quot;&gt;Podman&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/lxc&quot;&gt;LXD&lt;/a&gt;和&lt;a href=&quot;https://docs.xpipe.io/guide/lxc&quot;&gt;incus&lt;/a&gt;容器&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/proxmox&quot;&gt;Proxmox PVE&lt;/a&gt;虚拟机和容器&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/hyperv&quot;&gt;Hyper-V&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/kvm&quot;&gt;KVM&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/vmware&quot;&gt;VMware Player/Workstation/Fusion&lt;/a&gt;虚拟机&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/kubernetes&quot;&gt;Kubernetes&lt;/a&gt;集群、Pod 和容器&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/tailscale&quot;&gt;Tailscale&lt;/a&gt;和&lt;a href=&quot;https://docs.xpipe.io/guide/teleport&quot;&gt;Teleport&lt;/a&gt;连接&lt;/li&gt;
&lt;li&gt;适用于 Linux、Cygwin 和 MSYS2 环境的 Windows 子系统&lt;/li&gt;
&lt;li&gt;Powershell 远程会话&lt;/li&gt;
&lt;li&gt;RDP 和 VNC 连接&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height=&quot;254&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/182956_MgN3_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height=&quot;301&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/183048_DlkY_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/xpipe</link>
            <guid isPermaLink="false">https://www.oschina.net/p/xpipe</guid>
            <pubDate>Sat, 22 Mar 2025 09:00:00 GMT</pubDate>
        </item>
        <item>
            <title>「赛博考古」：C 编译器的最早版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;GitHub 有个叫 legacy-cc 的项目，竟藏着上世纪 70 年代最早版本的 C 编译器源码，而且是由 C 语言之父 Dennis Ritchie（dmr）老爷子亲手写的！&lt;/p&gt; 
&lt;p&gt;这个项目堪称程序语言「考古现场」，如果你对一门语言如何从零起步演化感兴趣，或者想理解 C 语言为何能成为编程界的大师级存在，绝对值得膜拜一下。&lt;/p&gt; 
&lt;p&gt;有人一边感慨「爷青回」，一边指出这套代码像是某种 C 语言的原始形态：没有类型检查、变量默认都是 int、甚至还能在函数体里写 extern……这些今天看起来有些离谱的写法，在当年却是主流操作。&lt;/p&gt; 
&lt;p&gt;而这段代码的价值不仅仅在于「老」，它记录了 C 编译器最原始的逻辑和结构——比如如何处理语法树、内存分配、语义分析等。&lt;/p&gt; 
&lt;p&gt;你甚至能看到最初的代码优化雏形，比如简单却精妙的「表达式折叠」——这些机制，正是今天 LLVM 或 GCC 背后技术的雏形。&lt;/p&gt; 
&lt;p&gt;再说点细节：项目中包含了两个主要目录 prestruct 和 last1120c，分别对应早期和稍后的两个阶段。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1074&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/163642_49z7_2720166.png&quot; width=&quot;770&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;顺便一提，这代码的也算是开源界的「数字文物」，Caldera 当真敢开放。&lt;/p&gt; 
&lt;p&gt;可以看到，Caldera International 在 2002 年，就大方授权了源码开放，授权明确说明：可免费使用、修改、分发，甚至允许基于源码进行二创，唯一限制是不能涉及 UNIX System III / V 及之后的版本。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1678&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/163756_WvPU_2720166.png&quot; width=&quot;1414&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;就像有网友说的：「这不只是代码，而是 Dennis Ritchie 留给后人的一份手稿。」&lt;/p&gt; 
&lt;p&gt;最后，链接奉上：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmortdeus%2Flegacy-cc&quot; target=&quot;_blank&quot;&gt;https://github.com/mortdeus/legacy-cc&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340897</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340897</guid>
            <pubDate>Sat, 22 Mar 2025 08:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>前英特尔 CEO 批评英伟达 AI 芯片定价，认为推理才是未来机遇</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;前英特尔首席执行官帕特・盖尔辛格（Pat Gelsinger）近日在英伟达 2025 年 GPU 技术大会的《Acquired》播客中&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Flive%2FpgLdJq9FRBQ%3Ft%3D2291s&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，英伟达的人工智能 (AI) 图形处理器 (GPU) 定价策略过高，难以支持大规模的 AI 推理任务。盖尔辛格指出，推理是部署 AI 模型的关键环节，当前行业的发展趋势应该更关注推理，而英伟达的技术在成本效益上难以满足这一需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;227&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e16cdecc2dda96a32b455066f1a2df3b995.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他提到，英伟达用于 AI 训练的处理器价格高达现实所需的 10，000 倍之多。虽然盖尔辛格承认早期生成式 AI 的快速发展主要得益于英伟达的图形处理单元（GPU），但他认为，该公司的强项 —— 依托 CUDA 软件平台的技术 —— 在推理成为主流之后可能会面临挑战。他强调，尽管存在缺陷，但他也对英伟达首席执行官黄仁勋 (Jensen Huang) 的远见与坚韧表示赞赏，认为黄仁勋在通用图形处理器与 AI 工作负载的早期预测上取得了成功，但这一成就也部分源于良好的时机。他甚至调侃说，「黄仁勋运气不错」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在盖尔辛格的带领下，英特尔在 AI 硬件领域的竞争中面临压力。该公司推出的 Gaudi 加速器芯片在性能上未能赶上英伟达的 Hopper 和 AMD 的 Instinct 产品。英特尔目前已将 Falcon Shores 人工智能平台搁置，转而专注于下一代项目 「Jaguar Shores」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;盖尔辛格还提到，计算机架构可能会发生变化，量子计算有望在本世纪末实现商业化。然而，他未透露英特尔在这一变革中的具体计划。尽管机器学习基础设施需求激增，英特尔在 AI 收入方面仍远远落后于竞争对手，显现出公司在这一领域的整体困难。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340889</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340889</guid>
            <pubDate>Sat, 22 Mar 2025 07:53:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AMD 开源 「GAIA」：用于本地高效运行大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;AMD&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.amd.com%2Fen%2Fdeveloper%2Fresources%2Ftechnical-articles%2Fgaia-an-open-source-project-from-amd-for-running-local-llms-on-ryzen-ai.html&quot;&gt;宣布&lt;/a&gt;推出专为本地运行大语言模型（LLM）设计的开源应用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Famd%2Fgaia&quot;&gt;GAIA&lt;/a&gt;（发音 /ˈɡaɪ.ə/），目前支持 Windows 平台。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f939cebbc620ee07d4ce6b2ffb201d6d2fc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;GAIA 是一款生成式 AI 应用，&lt;strong&gt;可在 Windows PC 上实现本地化私密运行 LLM&lt;/strong&gt;，并针对锐龙 AI 300 系列处理器进行了优化。该应用通过 NPU 提升 AI 任务性能，并支持混合部署量化 LLM。&lt;/p&gt; 
&lt;p&gt;GAIA 基于 ONNX TurnkeyML 的 Lemonade SDK 开发，采用检索增强生成（RAG）技术，支持 Llama、Phi 等主流模型。其四大功能模块包括 Chaty 聊天机器人、Clip 视频搜索专家、Joker 笑话生成器和 Simple Prompt 测试工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2a29e1d73556bb5e0390921046bf1ad85e4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;AMD 提供普通版和混合版安装方案，普通版兼容任意 Windows 设备，混合版专为锐龙 AI 300 系列优化。&lt;/p&gt; 
&lt;p&gt;GAIA 的本地化处理确保数据隐私，响应延迟降低至毫秒级，并支持离线运行。该项目采用 MIT 开源协议，未来或扩展至多平台支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340886/amd-gaia-running-local-llms-on-ryzen-a</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340886/amd-gaia-running-local-llms-on-ryzen-a</guid>
            <pubDate>Sat, 22 Mar 2025 07:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里云开启近年来规模最大的 AI 人才校园招聘</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9UyL73Bk6FBWpWcnfFfq-A&quot; target=&quot;_blank&quot;&gt;根据《科创板日报》的独家报道&lt;/a&gt;&lt;/u&gt;，阿里云近日在全球顶尖高校招募 AI 技术储备人才，为近年来规模最大的 AI 人才校园招聘。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;840&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/152257_OouC_2720166.png&quot; width=&quot;844&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据了解，此次校招面向清华大学、北京大学、浙江大学、麻省理工大学、斯坦福大学等全球顶尖高校，招募大语言模型、多模态理解与生成、模型应用、AI Infra 等领域技术人才。&lt;/p&gt; 
&lt;p&gt;同时，&lt;strong&gt;项目设置 A Star 项目和 Al Clouder 项目，面向具备高水平论文、开源项目影响力等特质的顶尖人才，为这类毕业生提供更优薪酬和专业扶&lt;/strong&gt;持。&lt;/p&gt; 
&lt;p&gt;此举系之前 T 项目后，阿里巴巴推出的又一项 AI 人才战略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339514&quot; target=&quot;news&quot;&gt;阿里全面 AI 化，公司内部相信「基于 AI 的杀手级应用可能很快就出现」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339418&quot; target=&quot;news&quot;&gt;阿里云启动「T 项目」，加速 AI 研发&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338747&quot; target=&quot;news&quot;&gt;阿里巴巴董事长蔡崇信：AI 市场规模至少 10 万亿美元&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340879</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340879</guid>
            <pubDate>Sat, 22 Mar 2025 07:23:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开放，开源，全球化，国产算力展现三大演进趋势</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我国计算产业正在自主创新中快速发展，呈现出开放、开源、全球化三大趋势。专家认为，面对人工智能在各行各业加快应用带来的海量算力需求，我国计算产业亟须抓住机遇，构建算力新体系，打造世界级新产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;数字基础设施量质齐升&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;工业和信息化部 3 月 17 日公布的数据显示，2024 年我国数字基础设施量质齐升。截至 2024 年末，全国在用算力中心标准机架数超过 880 万，算力总规模较上年末增长 16.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作为数字经济时代的核心生产力，算力对经济的巨大拉动作用已经显现。中国信息通信研究院发布的《中国算力发展指数白皮书（2023 年）》显示，算力每投入 1 元钱，就将带动 3 至 4 元的 GDP 增长。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在数字经济大省浙江，去年数字经济核心产业增加值突破 1 万亿元。据介绍，在推进数字浙江建设进程中，于 2020 年投入运营的浙江省鲲鹏生态创新中心为浙江数字经济的发展提供了技术支撑和创新动力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作为国产算力的中坚力量，在硬件层面，鲲鹏 CPU 展现出强大竞争力，部件、整机实现全量自主创新，构建起坚实的自主创新产业链；在基础软件领域，以开源欧拉、开源高斯为代表的开源项目蓬勃发展，不断丰富和繁荣软件生态，为浙江数字产业发展提供了源源不断的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作报告提出，「激发数字经济创新活力」，并作出了「优化全国算力资源布局」等具体部署。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 等机构认为，2025 年中国智能算力规模将达到 1037.3EFLOPS，并在 2028 年达到 2781.9EFLOPS。当前，我国算力总规模已位居全球第二，但仍存在算力资源供给紧张和不能有效利用的矛盾情况。算力规模的高速增长和供需错配等挑战将为国产算力的未来发展提供新空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;三大产业演进趋势渐明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;专家认为，目前计算产业变革呈现出三大趋势：一是算力架构的开放特性加速了端、边、云全场景的快速协同发展；二是算力生态共建正在替代单边创新；三是计算产业的全球化趋势愈发清晰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在业界看来，当前算力领域的技术路线正向多元化、多维度演进。受限于封闭架构的短板，传统的 X86 架构难以形成生态，而 ARM 架构的开放模式，将成为未来通用算力的主流选择。数据显示，当前全球算力大约 80% 属于 ARM 架构，其中 99% 的手机采用的都是 ARM 芯片，国内的鲲鹏和飞腾以及国外都有基于 ARM 架构的产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，DeepSeek 的开源实践，推动了人工智能技术的普及和应用。在算力领域，开源同样带来了生态的繁荣。例如，鲲鹏联合超过 6000 家合作伙伴构建的「技术乐高」模式，就证明了开源协作的强大生命力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;开源、开放的生态也让计算产业打开了全球化的新格局。通过携手合作，产业各方开始充分发挥自身优势，通过资源共享与互补，联合打造更具竞争力的解决方案，共同开拓国际市场，为全球客户提供创新产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以鲲鹏生态为例，近年来，通过开源、开放，鲲鹏打造了从芯片、整机到操作系统、数据库的自主创新生态。数据显示，截至目前，鲲鹏生态已发展超过 335 万鲲鹏开发者，面向硬件、软件和应用全面创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;迎接人工智能时代新机遇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;业内人士指出，随着人工智能应用场景的爆发式增长，算力需求呈现快速攀升态势。正如当年互联网推动 PC 快速普及和升级一样，如今人工智能的大范围落地应用也将激活对算力的庞大需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作报告提出，持续推进「人工智能＋」行动，将数字技术与制造优势、市场优势更好结合起来，支持大模型广泛应用。多家机构认为，「人工智能+」行动将重塑所有产业，DeepSeek 的火爆更为大模型应用落地提供了催化剂，不仅将加速各行各业的智能化转型，更将驱动中国计算产业升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 最新数据显示，2025 年，中国人工智能市场总规模将达到 511.3 亿美元，同比增长 34.8%，预计到 2028 年市场规模将达到 1010 亿美元，年复合增长率达到 25.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;面对人工智能时代的新机遇，专家认为，我国计算产业应抓住这一历史性机遇，打造世界级新产品，构筑坚实的算力底座。一是要构建自主创新的算力新体系。IDC 发布的 2024 年中国服务器市场报告显示，自主算力鲲鹏系服务器市场份额占比已达 20% 以上，覆盖了金融、运营商、政府、互联网等核心场景。二是要打造开放开源的自主软件生态。据 IDC 报告，在中国服务器操作系统领域，2024 年开源欧拉系份额达到 50%，累计装机量突破 1000 万套；据沙利文数据，2024 年 openGauss 在关系型数据库中占比 28.5%，超过 MySQL 和 PG，成为三个主流开源数据库技术路线之首。三是要构筑根植中国、面向全球的通用计算产业。工业和信息化部数据显示，2024 年开源欧拉用户数量超过 380 万，为全球 150 余个国家和地区提供服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;专家预测，未来几年，人工智能技术普及将推动算力需求出现爆发式增长。我国计算产业将通过在根技术上的自主创新突破，实现性能提升和成本优化，助力人工智能技术的规模化商用和千行百业的智能化转型，并逐渐走向全球市场，打造面向人工智能时代的通用算力底座。（经济参考报，记者，吴蔚）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340875</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340875</guid>
            <pubDate>Sat, 22 Mar 2025 07:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>国家数据局：以高质量数据促进人工智能发展</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国家数据局局长刘烈宏 24 日在中国发展高层论坛 2025 年年会上表示，国家数据局将充分调动社会各方力量，积极推动高质量数据集建设，持续增加数据供给，推动「人工智能+」行动赋能千行百业，打造包容开放的创新环境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;302&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bfc45482de2edcfe691d1f74d79bbdf71b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;刘烈宏说，高质量数据与人工智能的结合，将会进一步发挥数据和人工智能的倍增效应。如何更好以高质量数据促进人工智能发展？刘烈宏提出重点做好四方面工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进基础制度供给——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;刘烈宏说，将统筹开展数据领域规划编制工作，加快形成数据领域的规划体系，制定印发数据产权制度和培育全国一体化数据市场的文件，加快推进数据基础制度建设，组织开展数字中国、数字经济、数据要素综合试验区的建设，因地制宜开展先行先试，为数据要素价值释放积累实践经验，健全完善数据治理、数据安全等制度，更好保障人工智能安全发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进高质量数据供给——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「‘人工智能+’行动到哪里，高质量数据集的建设和推广就要到哪里。」刘烈宏说，将强化公共数据资源登记管理，规范公共数据资源授权运营实施，建立授权运营价格形成机制，积极引导做好高质量数据集建设工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进数据基础设施建设——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;生成式人工智能的快速发展，对算力和数据流通利用提出更高更迫切的需求。刘烈宏表示，将系统推进全国一体化算力网建设，创新算力电力协同机制，推动算力设施一体化、集约化、绿色化发展。同时，加快国家数据基础设施建设，推动区域、行业数据基础设施互联互通。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持续推进数据领域国际合作深化——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国家数据局将推进数据领域高水平开放，为中外数字企业发展创造良好环境。「欢迎世界各国企业参与到中国数据要素市场化、价值化进程中，共享数据发展红利和发展机遇。同时我们也将积极参与并持续推动人工智能安全治理，加强国际合作和对话，为全球治理体系完善提供新的动力。」刘烈宏说。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340860</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340860</guid>
            <pubDate>Sat, 22 Mar 2025 06:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>高并发场景下的库存管理，理论与实战能否兼得？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本篇文章，是一篇实战后续篇，是基于之前我发了一篇关于如何构建高并发系统文章的延伸： &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F35216%3FshareId%3D8087%26isHideShareButton%3D1&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高并发系统的艺术：如何在流量洪峰中游刃有余&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而这篇文章，从实践出发，解决一个真实场景下的高并发问题：秒杀场景下的系统库存扣减问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着互联网业务的不断发展，选择在网上购物的人群不断增加，这种情况下，会衍生出一些促销活动，类似抢购场景或者热销热卖场景，在高峰时段的下单数量会非常大，也意味着对数据库中畅销商品的库存操作十分频繁，需要频繁查库存和更新库存。这属于高读写场景，比起单独的并发读和并发写来说，业务场景更复杂一些。那么这种高并发为了保证库存数据一致性，一般会在数据库更新时进行加锁操作，以保证系统不会发生超卖情况。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们应该如何应对呢？大家可以根据我之前那篇文章中的思维导图，跟随我的思路，一起来看如何解决当前场景下的高并发问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;小试牛刀&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面对库存扣减的场景，我们第一个考虑到是数据一致性问题，因为超卖会对我们的履约和客户信誉造成影响。所以一般情况下，在数据库更新时进行加锁操作，以保证系统不会发生超卖情况。所以更多方案是提高数据库性能方法，比如增加硬件性能，优化乐观锁，提升锁效率，优化 SQL 性能等。对于一些大型系统，也衍生出一些基于分片的库存方案，通过分库分表增加并发吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然那这样不够，因为 MySQL 数据库的读写的并发上线能力是有限的，我们还是需要再进一步优化我们的方案。这里就要参考之前我写的那篇文章中的思维导论了，这里常见解决方案就是，引入缓存机制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如下图所示，我们把读请求进行缓存，每次库存校验时，我们引入 redis 缓存，读请求通过缓存，增加接口性能，然后库存扣减时，在进行缓存同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c08115baf35c2454a8997ca9afa97a80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但这种方式存在很大问题： 所有请求都会在这里等待锁，获取锁有去扣减库存。在并发量不高的情况下可以使用，但是一旦并发量大了就会有大量请求阻塞在这里，导致请求超时，进而整个系统雪崩；而且会频繁的去访问数据库，大量占用数据库资源，所以在并发高的情况下这种方式不适用。同时这个方案还会存在 mysq 和 redis 的数据同步不一致的情况，导致高并发情况下，出现超卖。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;所以这种方案虽然简单，但是无法满足高并发场景，我们必须得 pass。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;循序渐进&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;为此，我们可以进行一次优化，通过架构维度进行调整。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在这个方案中，我们将库存操作封装成一个单独模块，这个方案的优化点在于，所有库存的查询和扣减都围绕 redis 进行。当发生库存扣减操作时，会直接更新 redis，同时采用异步流程，更新 MySQL 数据库。这样以来，我们的性能会比直接访问 MySQL 数据库高效不少，并发能力会有不少提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;流程如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//f6f8964c0024b3ee676272e4655ccfa7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但这个方案依然有缺陷，它的点在于 redis 的单点性能问题。该方案的最大并发性能取决于 redis 的单点处理能力。而如果想要进一步提升并发能力，该方案不具备水平扩展能力。那么，这个方案，依然不是我们最优的选择。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大显身手&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那么接下来，我们需要考虑的是如何可以实现我们业务系统并发能力的水平扩展能力。当然这里也不是凭空来想，我们可以思考一下，业内成熟的一些中间件是如何实现高并发的，这里我们可以两个我们常见的框架：kafka 和 elasticsearch。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;上述我们常见的两个中间件框架，都以可以水平能力扩展著称。那么仔细思考一下他们的技术架构不难发现，他们的核心其实都是采用了一种所谓的分片实现的。那么问题来了，我们的库存扣减，能不能实现分片呢？或者换一个思路思考这个问题：我们的库存逻辑是否可以转化为分布式库存进行存储和扩展呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有了以上的思路，我们就可以开始构建我们的架构方案了。接下来，我先把架构图贴出来：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//6542ddad18a4604d2a38c7b51195fe8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在这个架构方案中，是以 Redis 缓存为实现基础，结合 Mysql 数据存储，通过一套控制机制，保证库存的分布式管理。在该方案中，有一些特定的业务模块单元需要说明。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1. partition&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;熟悉 kafka 的人对 partition 一定不陌生。在本架构方案之中，该业务架构中的 partition 的概念是一组基于 redis 来实现的库存分片，分别存储一部分库存大小。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一个 partition 中，会存有一定量的预占库存量，当有请求服务进行库存扣减时，只需要选择其中一个 partition 即可，这样以来，就可以减轻单节点的压力，同时可以基于 redis 集群的可扩展性，实现 partition 的水平扩展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分布式系统常见的一个问题就是数据倾斜问题，因为严重的数据倾斜，会让我们分布式方案瞬间瓦解，导致单点承担高并发。那么该方案下的数据倾斜问题如何解决呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;最终，我想到的解决方案类似养宠物狗时买的那种定时投喂仪器，每天通过定时定量投喂，来保证宠物狗不会被饿到或者吃撑。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果最初把所有库存全部平均到每个 partition 中，当有多个大库存扣减打到一个 partition 上时，会造成该 partition 上出现库存被消耗光，而失去后续提供库存扣减能力。为了解决这个问题，我在 partition 中采取的是动态库存注入和子域隔离的方案。具体方案如下图：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//8c57d7654d67f6af4f23f47905ef2ce6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每个 partition 会有两个子域，调度器中会记录每个 partition 当前激活的子域，每次库存扣减，会扣减激活的子域中的库存值。而当激活的子域库存值低于设定阈值是，会切换子域，冷却当前子域，激活另一个子域。被冷却的子域会触发任务触发器，实现预占库存的数据同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;子域中会存储一定额度的库存值，不会存储很大的量，这样就可以保证动态的预占库存实现，从而解决库存倾斜的问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然为了更好的管理 partition，我们需要单独开发一个 partition 调度器模块，来负责管理管理众多 partition 资源，那么这个调度器的具体功能包括：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;1.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;调度器中有一个注册表，会记录 Partition 的 key 值，外部服务获取 partition key 是需要通过调度器获取，调度器会记录每个 partition 的库存余量和 partition 和子域信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;2.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当 partition 无法再获取预占库存，且库存耗尽时，调度器会从注册表中摘除该 partition 信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;3.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 调度器可以采用随机或者轮训的方式获取 partition，同时每次也会校验 partition 剩余库存是否满足业务扣减数量，如果剩余库存小于业务扣减数量，将会跳过该 partition 节点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2. 异步更新库存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二个核心模块就是更新库存管理了，这块你可以理解为异步流程机制，通过异步化操作，来减轻系统的高并发对数据库的冲击。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更新库存会有一个明细表，记录每个 partition 库存扣减信息，明细表会有一个同步状态，有两种情况可以出发库存同步 MQ 消息：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一． 当每个 partition 中的明细数据条数超过设定阈值，会自动触发一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二． 每间隔额定设定时间 (默认设置 1 秒)， 会触发一次当前时间段内每个 partition 产生的库存扣减明细信息，然后发送一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;两中触发方案相互独立，互不影响，通过同步状态和明细 ID 实现幂等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3. 预占库存管理和库存管理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接下来就是关于库存的底层数据结构设计了。这里会引入一个在电商行业很共识的概念：预占库存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在库存领域层中，库存分为预占库存和库存两个模块，这里面的库存关系实例如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假设当前商品的库存值为 10000 件，当前 partition 触发一次预占库存任务，领取 400 件， 然后假设此时收到 MQ 库存消费更新消息，更新 30 件。随后 partition 又触发一次预占库存任务，零陵区了 100 件。库存变化如下图所示：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c83f3fadc83623765f0e90cf251f75ad.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其中，实际库存= 预设库存池 + 预占库存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每次预占库存任务触发，会从预设库存池中扣减，如果预占库存池清空，则 partition 就无法在获取预占库存，调度器会将它从注册表中摘除。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而每次 MQ 更新库存消息，会更新实际库存量，同时对预占库存和扣减库存值进行修改，这个操作具有事务性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_8&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;通过这次的案例分析，我们其实是通过方法论结合实际业务场景的方式出发，设计了我们的系统架构。剥离业务场景，其实本质就是通过缓存和异步流程来实现系统的高并发，同时让系统具备拥有水平扩展的能力。但这个方法论在与实际业务结合时，还是会有很多很多需要思考和细化的点，比如分布式思想的使用，比如预占库存的逻辑设计等等。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4090830/blog/17989921</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/17989921</guid>
            <pubDate>Sat, 22 Mar 2025 06:36:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>树莓派开源镜像定制工具 rpi-image-gen</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;树莓派基金会近日推出开源工具 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fraspberrypi%2Frpi-image-gen&quot; target=&quot;_blank&quot;&gt;rpi-image-gen&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;rpi-image-gen 是一个根文件系统和镜像创建工具，旨在提供高度的自定义、灵活性和控制。rpi-image-gen 使用&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbdrung%2Fbdebstrap&quot; target=&quot;_blank&quot;&gt;bdebstrap&lt;/a&gt;&amp;nbsp;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.mister-muffin.de%2Fjosch%2Fmmdebstrap&quot; target=&quot;_blank&quot;&gt; mmdebstrap &lt;/a&gt;进行根文件系统的构建，并使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpengutronix%2Fgenimage&quot; target=&quot;_blank&quot;&gt;genimage&lt;/a&gt; 进行镜像创建。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是一个以 Bash 为中心的脚本引擎，能够使用元数据集合和定义的执行流程生成具有不同磁盘分区布局、文件系统和配置文件的软件镜像。它提供了为 Raspberry Pi 设备创建高度自定义软件镜像的方法。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是易于阅读、可审计且易于使用的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;技术亮点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;模块化定制&lt;/strong&gt;：通过 YAML 配置文件定义软件包列表，移除冗余服务降低资源占用&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全增强&lt;/strong&gt;：自动扫描镜像内软件组件的已知漏洞（CVE），生成 SBOM 清单满足合规需求&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;场景化模板&lt;/strong&gt;：提供 Web Kiosk 等预设配置，5 分钟快速生成专用设备系统&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1852&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/143335_AvvG_2720166.png&quot; width=&quot;2464&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9fd9d61d93288d85f72c7f103eb0e6445bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;该工具支持用户根据需求裁剪操作系统组件、管理软件供应链安全（SBOM 与 CVE），并内置轻量化「slim」镜像模板，为树莓派设备创建定制化的 Raspberry Pi OS 镜像，适用于工厂批量烧录、边缘计算设备集群管理等场景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</guid>
            <pubDate>Sat, 22 Mar 2025 06:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>华为语言模型推理专利公布，可提高对预设内容的理解能力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查资料显示，华为技术有限公司、清华大学申请的「一种语言模型推理方法以及推理装置」专利于 3 月 25 日公布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-71363ec3371e1b4ce56ef932ddc41db7554.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要信息显示，该方法包括：根据第四问题生成第五问题，所述第五问题用于提问所述第四问题、以及提示语言模型回答所述第四问题的回复中不要包括预设内容；所述语言模型根据所述第五问题输出第三回复，所述第三回复不包括所述预设内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中，所述语言模型的参数根据第一回复的评价数据更新，所述语言模型根据第一问题输出所述第一回复，所述评价数据用于指示所述第一回复是否包括所述预设内容。该方法可以提高语言模型对预设内容的理解能力，从而更准确地抑制模型输出预设内容。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340851</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340851</guid>
            <pubDate>Sat, 22 Mar 2025 06:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>人类细胞谱系大科学研究设施启动建设，打造数字细胞 AI 大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人类细胞谱系大科学研究设施 25 日在广州启动建设，将绘制人类生命过程中的细胞动态演化图谱，构建数字细胞 AI 大模型，催生生物医药研究新范式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;这一设施是国家「十四五」重大科技基础设施，由中国科学院广州生物医药与健康研究院牵头，位于广州国际生物岛，规划建设周期 4.5 年，总建筑面积超 5 万平方米。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人员介绍，细胞是生命的基本单元。从受精卵开始，到发育成组织器官，再到衰老全过程中出现的所有细胞类型进行汇总和演变关系的绘制，就构成了「细胞谱系」。解析细胞谱系被誉为揭示生命发育与演变奥秘、操纵生命活动的「钥匙」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;533&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf7c06015d01a819ca8b5ea7cfba8024211.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该设施将以样品保活存储、空间多组学、先进成像等创新技术和装置研发为核心，集成人工智能等前沿技术，绘制涵盖发育、疾病、衰老三大维度的动态细胞图谱。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「这就像为生命编写一部详尽的‘细胞家谱’，让科学家乃至公众能够清晰追踪每个细胞的‘前世今生’。」广州健康院副院长、细胞谱系设施总指挥兼总工程师孙飞表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人员介绍，当前全球创新药研发耗时长、耗资大，但临床成功率低，部分原因在于药物研发主要在动物模型中进行，不能准确模拟人类生理系统反应。未来，细胞谱系设施有望用患者细胞信息打造一个「数字患者」，预演不同治疗手段在体内的治疗效果，实现「量体裁衣」式的精准治疗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;广州健康院研究员、细胞谱系设施副总指挥兼总工艺师陈捷凯表示，这一设施的建设将在生命科学仪器、试剂、软件和数据等方面产出一批创新性科技成果和产品，并进一步强化 AI 与数据资源整合，与龙头企业开展深度合作，加速科研成果向临床应用转化。（新华社，记者马晓澄、钟焯）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340845</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340845</guid>
            <pubDate>Sat, 22 Mar 2025 06:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>小鹏汽车公布双足机器人新专利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 APP 知识产权信息显示，广州小鹏汽车科技有限公司申请的「双足机器人的控制方法及电子设备」专利于 3 月 25 日公布。解决了相关技术中无法实现双足机器人单脚点地姿态的技术问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;310&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6ad6f0bc0677b09916d95d0fcf8a8f559d.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要显示，本发明公开了一种双足机器人的控制方法及电子设备。其中，该方法包括：响应于接收到双足机器人的控制指令，采集双足机器人的当前姿态，其中，控制指令中携带有双足机器人的姿态数据，姿态数据用于确定双足机器人的期望单脚点地姿态，期望单脚点地姿态用于表示期望在双足机器人对应支撑脚的足底区域接触地面的情况下，双足机器人对应摆动脚的足尖区域接触地面；基于当前姿态和期望单脚点地姿态，确定摆动脚的摆动脚移动轨迹和双足机器人对应机身的机身移动轨迹；基于摆动脚移动轨迹和机身移动轨迹控制双足机器人运行。本发明解决了相关技术中无法实现双足机器人单脚点地姿态的技术问题。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340843</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340843</guid>
            <pubDate>Sat, 22 Mar 2025 06:01:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>工作流自动化平台 Zapier 上线 MCP 服务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;工作流自动化平台 Zapier 近日上线了 Zapier MCP 服务，允许用户通过 Zapier 将他们的 Cursor AI 代理连接到各种应用程序，而无需复杂的 API 集成。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/114131_qF9e_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzapier.com%2Fmcp&quot;&gt;https://zapier.com/mcp&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Zapier MCP 服务赋予了 AI 助手强大的实用能力，包括自动化工作流程、管理数据、发送电子邮件、创建日历事件、更新数据库以及与其他应用进行实时交互等。无论是企业用户希望优化日常运营，还是个人用户想要简化繁琐任务，这一服务都提供了前所未有的便利。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/113921_nkJu_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;例如，AI 助手可以通过简单的配置，自动将会议安排记录到日历中，或根据需求从数据库中提取并整理数据，甚至与团队协作工具实时同步信息。&lt;/p&gt; 
&lt;p&gt;更值得一提的是，Zapier MCP 在权限控制方面表现出色。用户可以精确地定义 AI 助手能够执行的操作范围，细化到具体的应用程序、功能乃至特定字段。这种设计有效防止了 AI 滥用权限的风险。例如，用户可以设置 AI 助手仅限于向某个特定的 Slack 频道发送消息，或限制其只能访问指定的 GitHub 仓库。这种细粒度的控制不仅提升了安全性，也让 MCP 服务更具灵活性和实用性。&lt;/p&gt; 
&lt;p&gt;使用 Zapier MCP 的过程也极为简便。用户只需从 Zapier 平台复制一个专属的 URL，并将其集成到 AI 助手中，即可快速启用这些功能。无需复杂的编程或 API 对接，这一 「即插即用」 的特性大大降低了技术门槛，使得非专业人士也能轻松上手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340820/zapier-mcp-beta</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340820/zapier-mcp-beta</guid>
            <pubDate>Sat, 22 Mar 2025 03:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>