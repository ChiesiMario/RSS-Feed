<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 11 Sep 2025 07:42:36 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>腾讯开源图检索增强生成框架 Youtu-GraphRAG</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;腾讯优图实验室开源了 Youtu-GraphRAG，这是一个全新的图检索增强生成框架，旨在通过大语言模型+RAG 模式，将知识组织成图谱，再交给大语言模型进行检索和推理，从而提高模型在处理复杂问答任务时的准确性和可追溯性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Youtu-GraphRAG 特别适用于企业知识库问答、科研文档解析、个人知识管理等知识密集型场景。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Youtu-GraphRAG 通过三大创新实现了从图构建到索引、再到检索的垂直统一和认知闭环。首先，它采用了四层知识树结构，将知识拆解成属性、关系、关键词和社区四个层次，使得大模型在回答问题时能够沿着知识树定位信息，推理路径清晰可见。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;其次，社区检测升级不仅关注「谁和谁有关」，还结合语义理解「为什么它们有关」，生成简明摘要，帮助用户快速抓住问题本质。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最后，智能迭代检索机制允许用户提出复杂问题时，将其拆解成多个子问题并行检索，并通过迭代反思机制对结果进行补充和修正，最终给出更完整、更可靠的回答。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="314" src="https://oscimg.oschina.net/oscnet/up-ab798039306f65590d7249203cb4394d0d9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Youtu-GraphRAG 在实践检验中表现出色。在六个&lt;span&gt;权威&lt;/span&gt;基准测试中，&lt;span&gt;最高&lt;/span&gt;可节省 90.71% 的 Token 成本，复杂推理任务的准确率&lt;span&gt;最高&lt;/span&gt;提升 16.62%。此外，该框架支持中英文双语，跨领域应用无需重构，具有很高的灵活性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;使用 Youtu-GraphRAG 非常简单，只需四步即可上手。首先，通过命令行获取项目代码。其次，进行环境配置，包括获取远程调用模型的凭证 API key 并创建配置文件。然后，一键部署项目。最后，通过 curl 命令体验交互。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371566</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371566</guid>
      <pubDate>Thu, 11 Sep 2025 07:30:33 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动发布开源多模态模型 Mini-o3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;字节跳动发布开源多模态模型 Mini-o3，通过扩展推理模式和交互轮次提升视觉搜索性能，在复杂场景中实现显著突破。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/151240_xzZ9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://mini-o3.github.io/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Mini-o3 是一个完全开源的多模态模型，专为「边看边想」的视觉搜索任务设计。它通过强化学习将工具调用次数扩展到数十轮，在 VisualProbe、V* Bench、HR-Bench、MME-Realworld 等基准上取得了 7B 量级的最佳成绩。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a111377d25b371aba3ccf675445d406ca6b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-71b6b52f2c739864eda55692e83e9bbe7ce.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;项目公开了训练代码、模型权重以及包含 4,500 条数据的 Visual Probe 数据集，允许研究者在非商业许可下复现 OpenAI o3 风格的深度推理行为。&lt;/p&gt; 
&lt;p&gt;Mini-o3 支持深度优先搜索、试错等多样化推理模式，测试时交互轮次可扩展至 32 轮以上，准确率随轮次增加显著提升（如 VisualProbe-Hard 任务准确率从 35.1% 提升至 48.0%）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心创新&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;挑战性数据集构建&lt;/strong&gt;：推出 VisualProbe 数据集，包含高分辨率图像、小目标和密集干扰物场景，强制模型进行多轮探索。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;迭代数据收集&lt;/strong&gt;：通过冷启动数据生成多样化推理轨迹，覆盖回溯、假设验证等策略，解决预训练模型缺乏多轮交互能力的问题。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Over-Turn Masking 策略&lt;/strong&gt;：在强化学习中避免对超轮次响应的惩罚，支持模型深度探索，训练时轮次上限设为 6 轮，测试时可扩展至 32 轮以上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;应用案例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-32f28f4c28db5eb7a911b5d6fe714e2b11b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371562</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371562</guid>
      <pubDate>Thu, 11 Sep 2025 07:19:33 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥智能植物收割？能割韭菜不？</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2195</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2195</guid>
      <pubDate>Thu, 11 Sep 2025 07:04:33 GMT</pubDate>
    </item>
    <item>
      <title>🔥🔥AI 能打造盲人的第三只眼？</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2194</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2194</guid>
      <pubDate>Thu, 11 Sep 2025 07:04:33 GMT</pubDate>
    </item>
    <item>
      <title>9 月线下活动汇总</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;9 月 13 日，广州，Solar 开发者咖啡&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;👨‍💻熟悉的开发者咖啡活动回归，这次搬到了广州！这也是 Solar 第一次在广州举办社区活动，尝试在大湾区布局更多站点。期待开发者们的加入！&lt;/p&gt; 
&lt;p&gt;🗓️时间：9 月 13 日，周六 14:30-18:00&lt;br&gt; 📝现在报名 https://luma.com/xhki98ic&lt;/p&gt; 
&lt;p&gt;分享主题：&lt;/p&gt; 
&lt;p&gt;- Solana 历史、POH 机制、开发差异；&lt;br&gt; - Solana 现在的开源生态、技术、项目；&lt;br&gt; - 基于 Blinks 开发所用的技术、需求分析、商业模式和收获；&lt;br&gt; - Solar.zens.one, Solar 的项目导航&lt;br&gt; - Solana DeFi 生态现状和创新&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 13–14 日，杭州，RustChinaConf 2025 x Rust Global China&lt;/h4&gt; 
&lt;p&gt;今年正值 Rust 诞生 10 周年 🎉&lt;br&gt; 👉 讲师阵容全面升级，海外讲师议题比例高达 45%！&lt;br&gt; 👉 Rust Foundation 团队将首次现场参与交流！&lt;br&gt; 👉 国内大厂创业公司纷纷加入，了解 Rust 语言的最近进展&lt;br&gt; 👉 现场设有 Rust 十周年庆典与特别大礼包&lt;/p&gt; 
&lt;p&gt;🔎 查看完整议程： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frustcc.cn%2F2025conf%2Fschedule.html" target="_blank"&gt;https://rustcc.cn/2025conf/schedule.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🎟️ 立即购票： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhangzhou2025.gosim.org%2Ftickets%2F" target="_blank"&gt;https://hangzhou2025.gosim.org/tickets/&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 14 日，成都，聚焦 Kiro：体验下一代 Agentic IDE&lt;/h4&gt; 
&lt;p&gt;生成式 AI 正在重构开发流程，AI Agent 成为人机交互新核心！亚马逊云科技成都 User Group 技术沙龙邀您共同探索最前沿的 Agentic 实践。&lt;/p&gt; 
&lt;p&gt;🔍 聚焦 Kiro：体验下一代 Agentic IDE，基于 MCP 协议重塑开发环境&lt;br&gt; 🧠 依托 Amazon Bedrock：构建与部署高效 AI Agent（如 Strands Agents）&lt;br&gt; 🛠 实战指引：掌握亚马逊云科技 Builder Cards 中文版，加速生成式 AI 应用开发&lt;/p&gt; 
&lt;p&gt;立即报名，携手迈进智能体驱动开发的新时代！&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1mqqg_M34zzVig1QZl0KCg" target="_blank"&gt;https://mp.weixin.qq.com/s/1mqqg_M34zzVig1QZl0KCg&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，成都，Gitee Talk | 模力方舟 AI 应用开发沙龙&lt;/h4&gt; 
&lt;p&gt;📅 9 月 20 日（下周六）13:30-17:00&lt;br&gt; 📍 成都春熙路 voco 酒店（3 号线春熙路 E1 口出直达）&lt;/p&gt; 
&lt;p&gt;✨ 聚焦 AI 开发全链路：从模型调用、开源实践、3D 交互到硬件选型，5 大实战议题，带你突破技术边界！&lt;br&gt; 🙌 现场和大咖交流互动、结识技术同频人，开源老传统披萨畅吃，抽模力方舟千元代金券和更多惊喜好礼～&lt;/p&gt; 
&lt;p&gt;🚀 立即报名，锁定席位：&lt;a href="https://www.oschina.net/event/8598033"&gt;https://www.oschina.net/event/8598033&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，合肥，架构师的 AI 进化论&lt;/h4&gt; 
&lt;p&gt;🚀「架构师的 AI 进化论——从架构升级到行业应用」腾讯云架构师技术沙龙 · 合肥&lt;/p&gt; 
&lt;p&gt;🤔AI 时代，架构师是被替代？被重构？还是——主动进化？&lt;/p&gt; 
&lt;p&gt;🌟下周六（9 月 20 日）14:00，相约合肥！与多位一线专家面对面，全程硬核干货，深入 AI 架构实战经验与前沿思考，千万不要错过！&lt;/p&gt; 
&lt;p&gt;🎁 现场还有鹅厂限定周边、公仔、定制好礼抽奖送不停，戳链接免费报名👇&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmc.tencent.com%2FD91JjaK9" target="_blank"&gt;https://mc.tencent.com/D91JjaK9&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_6"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，青岛，奇妙 AI 之旅&lt;/h4&gt; 
&lt;p&gt;免费参与，0 门槛入场！&lt;br&gt; 这是一个真正能带走方案、解决实际问题的 AI 实战工作坊！💡&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;聚焦真问题，挖掘问题痛点；&lt;/li&gt; 
 &lt;li&gt;一起头脑风暴，打破思维限制；&lt;/li&gt; 
 &lt;li&gt;快速搭建方案原型，让想法能实实在在被看到；&lt;/li&gt; 
 &lt;li&gt;多方面验证，直到拿出可落地的方案；&lt;/li&gt; 
 &lt;li&gt;现场路演，让 AI 创新方案被看到。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;👉🏼立即报名：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F9823342171500%3Fcoupon%3D88ab88" target="_blank"&gt;https://www.huodongxing.com/event/9823342171500?coupon=88ab88&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;全程边玩边掌握 AI 技能，更有 3000 元奖金🧧等你来拿～&lt;/p&gt; 
&lt;p&gt;外地朋友别犹豫！机票 / 车票报销名额等你来抽！&lt;/p&gt; 
&lt;span id="OSC_h4_7"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，上海，PyCon China 2025&lt;/h4&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;1 个主会场 + 4 个分会场 + 开源松 + Vibe Coding 黑客松 + 社区开源集市展&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;汇集国内外 Python 领域专家与实力开发者，立足 AI 新纪元，&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;为大家呈现一场丰富、精彩、趣味，且充满活力的 PyCon 盛会。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;开创性地带来首届 PyCon China Vibe Coding 黑客松大赛&lt;/span&gt;。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;活动详情：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FDfU9DaqCMT5nDgHufzzaNw" target="_blank"&gt;https://mp.weixin.qq.com/s/DfU9DaqCMT5nDgHufzzaNw&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18691462</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18691462</guid>
      <pubDate>Sun, 07 Sep 2025 06:37:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>网信办副主任王京涛：促进软件生态、开源代码等自主生态构建</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;中央网信办副主任、国家网信办副主任王京涛在《新安全》杂志上撰文表示，今年是「十四五」规划收官之年、「十五五」规划谋篇布局之年，也是进一步全面深化改革的重要一年。&lt;/p&gt; 
&lt;p&gt;网络安全工作机遇与挑战并存，要以更大力度、更实举措加快推进国家网络安全体系和能力现代化，推动我国网络安全事业发展迈上新台阶。进一步建立安全可信的供应链安全管理体系。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0911/143425_K3L6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://mp.weixin.qq.com/s/b-rPE4C9CD9-5IEJ7odAXA&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;围绕集成电路、基础软件、人工智能、量子信息等重点领域，加强产业链协同创新，加快推动关键核心技术研发突破。充分发挥我国超大规模市场优势，促进软件生态、开源代码等自主生态构建，推动人工智能等技术在产业应用上取得更大突破。充分发挥网络安全审查、云计算服务安全评估、新技术新应用安全评估等制度机制作用，防范网络安全风险，提高供应链安全水平。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371539</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371539</guid>
      <pubDate>Sun, 07 Sep 2025 06:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里云创始人王坚：开源不只是开放代码，开源是今天 AI 竞争的关键变量</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 11 日上午，以「重塑创新增长」为主题的「2025 Inclusion·外滩大会」在上海黄浦世博园区开幕。在大会开幕式上，中国工程院院士、之江实验室主任、阿里云创始人王坚发表主题演讲，提出了一个重要观点：在 AI 时代，开源的内涵正在发生「革命性变化」——从以往「源代码的开放」逐渐转向「资源的开放」。模型权重的开放本质上是对数据资源与计算资源的开放，这也构成了 AI 时代开源的核心特征。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ee42154cfc30f409d743f5f865919f0d777.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;王坚举例道，今年 1 月 13 日，美国公布对 AI 的出口管制，首次明确要对 AI 模型的权重进行管制；今年 1 月 30 日，OpenAI 联合创始人兼 CEO Sam Altman 说：「在（开源）这个问题上，我们站在了历史的错误一边。」2025 年神奇的一件事情是，开源变成了今天 AI 竞争的关键变量。&lt;/p&gt; 
&lt;p&gt;随后，王坚简单回顾了推动 AI 发展到当今的几大重要理论，王坚表示，开放的话题不是今天才重要，在互联网时代就是关键的变量。在互联网时代，Netscape 的开源是那个时代的分水岭。开放资源的概念不是因为有「开源」一词才出现的，在科学探索过程中，很多先驱已经这样做了。&lt;/p&gt; 
&lt;p&gt;王坚强调：「模型权重的开放，本质上是数据资源和计算资源的开放。有了模型开放以后，你不需要再花那么多计算资源去重新做，有人替你完成了。我想说一下，开放以后并不意味着计算不重要，而只是意味着个体不用花这么多资源，因为有人付了这笔钱。」&lt;/p&gt; 
&lt;p&gt;他还说，「但要做更好的模型，需要更多资源的投入。今天，仅仅开放源代码，不能解决我们过去在软件时代用开源解决的问题。开放资源，特别是数据和计算资源，才是推动行业往前走不可缺失的环境。这就是 AI 时代开源的重要特点。我更愿意把它叫作 open resource。但 open source 和 open resource 翻译成中文，都是开源。」&lt;/p&gt; 
&lt;p&gt;此外，王坚还分享了他对 AI 进入太空的愿景。据他介绍，今年 5 月 14 号，之江实验室第一次把 12 颗衞星同时送上天，在这 12 颗衞星组成的星座上，第一次把一个地面上完整的 8B AI 模型放到太空里。这 12 颗衞星到了太空以后，就可以保证在衞星到达的地方，就能完成所有数据的处理。这是第一次实现了在太空中衞星之间的互通互联，给 AI 在太空带来机会。该项目被称为「三体计算星座」。&lt;/p&gt; 
&lt;p&gt;「我们计划把每一颗衞星开放给全世界任何人。这可以解决很多问题，也可以支持我们向深空探索。科学家已经在设想，几年内把衞星送到太阳轨道的 L5 点，这个点离地球 1.5 亿公里，离太阳 1.5 亿公里。」王坚表示，「只有把 AI 和算力送入太空，人类才可能真正走出地球。下面的时代非常激动人心。人类去火星的路上不能没有计算和 AI 的陪伴。这就是未来十年甚至二十年最激动人心的地方。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371536</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371536</guid>
      <pubDate>Sun, 07 Sep 2025 06:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linyaps - Linux 跨发行版独立包管理工具集</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#7a7a7a"&gt;&lt;span style="color:#000000"&gt;如意玲珑（Linyaps）是由统信软件技术有限公司自主研发的跨发行版 Linux 软件包管理工具集，现捐赠至开放原子开源基金会并成为其孵化的重点项目。项目以独立沙盒容器技术为核心，针对传统 Linux 软件生态的依赖冲突、分发碎片化、安全风险高等痛点，创新提出非特权沙箱设计、增量更新机制及离线分发能力（uab 格式），实现「一次构建，全平台运行」。&lt;br&gt;
&lt;br&gt;
项目已适配 deepin、Debian、Ubuntu、Arch、Fedora、UOS、openEuler、openkylin 等 Linux 主流发行版，覆盖 X86、ARM64、LoongArch 等芯片架构，支持超 5000 款应用分发，通过如意玲珑应用商店实现高效交付。核心技术如 rootless 容器部署、OSTree 原子化更新等，显著降低资源占用，有效保障安全分发。独创 uab 离线包格式，支持涉密场景无网络部署，助力政务、金融等领域实现国产化替代。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="color:#000000"&gt;八宝玲珑塔，蕴含芥子乾坤般的另一个世界，状似七层实非七层，以逞道法之变化。「玲珑」二字，正好融合「隔离」与「分层」思想，寓意对应用运行时的系统环境进行分层管理，实现权限管控。&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/linyaps</link>
      <guid isPermaLink="false">https://www.oschina.net/p/linyaps</guid>
      <pubDate>Sun, 07 Sep 2025 06:23:00 GMT</pubDate>
    </item>
    <item>
      <title>强化学习之父 Richard Sutton：如今 AI 正进入「经验时代」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;2024 年图灵奖得主、「强化学习之父」理查德·萨顿（Richard Sutton）在 2025 Inclusion·外滩大会上发表主旨演讲，他认为，人类数据红利正逼近极限，人工智能正在进入以持续学习为核心的「经验时代」，潜力将远超以往。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;萨顿表示，大多数机器学习的目标，是把人类已有的知识转移到静态、缺乏自主学习能力的 AI 上。「我们逐渐达到人类数据的极限，现有的方法不能生成新的知识，不适合持续学习，而持续学习对智能的效用至关重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他认为，我们正进入「经验时代」，需要一种新的数据源，由智能体与世界直接交互中生成。这正是人类和其他动物的学习方式，是 AlphaGo 自我博弈下的「第 37 手」，也是近期 AlphaProof 在国际数学奥林匹克斩获银牌的路径。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="294" src="https://oscimg.oschina.net/oscnet/up-6ecdf369f59aeda51d53bb897d5a8cacd52.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;萨顿解释，「经验」指的是观察、行动和奖励，这三种信号在智能体与世界之间来回传递。「知识来自于经验，可以从经验中学习。一个智能体的智能程度，取决于它能预测并控制自身输入信号的程度。经验是一切智能的核心与基础。」他同时指出，强化学习带领我们进入了新的经验时代，但要释放全部潜力，还需要两项目前尚不成熟的技术——持续学习（continual learning）和元学习（meta-learning）技术。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面对外界对 AI 带来偏见、失业甚至人类灭绝的担忧，萨顿认为，这种对人工智能的恐惧被夸大了，目标不同的智能体，可以通过去中心化的协作实现双赢。「人类最卓越的超能力，就在于比其他任何动物都更擅长协作。人类最伟大的成功在协作本身——经济、市场与政府都是成功协作的产物。」萨顿表示，人工智能和人类繁荣将来自于去中心化协作，「协作并非总能实现，却是世间一切美好事物的源泉，我们必须寻求协作、支持协作，并致力将协作制度化。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他认为，在人类的发展进程中，人工智能的替代将是不可避免的。而人类至少是催化剂，是助产士，更是开启宇宙第四大时代——「设计时代」的先驱。萨顿将宇宙历史分为四个时代：粒子时代、恒星时代、复制者时代和设计时代。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「人工智能是宇宙演化的必然下一步，我们应以勇气、自豪和冒险精神来迎接它。」萨顿表示。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371531</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371531</guid>
      <pubDate>Sun, 07 Sep 2025 06:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义即将发布 Qwen3-Next 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义 Qwen 团队通过 Hugging Face transformers 库的 PR&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftransformers%2Fpull%2F40771" target="_blank"&gt;提交&lt;/a&gt;了对 Qwen3-Next 系列的支持，信息显示将有一款名为 Qwen3-Next-80B-A3B-Instruct 的模型。该系列定位为 「下一代基础模型」，主打极端上下文长度与参数效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/141001_xzxJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Qwen3-Next 系列模型在架构层面引入了三项核心创新。首先是 Hybrid Attention，它使用 Gated DeltaNet 和 Gated Attention 替代传统注意力机制，以实现高效的长文本建模。其次是 High-Sparsity MoE，将激活比例压缩至 1:50，大幅减少了单个 token 的 FLOPs 而不损失模型容量。最后是 Multi-Token Prediction，在预训练阶段同步预测多个 token，从而提升性能并加速推理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/141034_JXYV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，模型还辅以 zero-centered、weight-decayed layernorm 等多项稳定化改进，增强了训练的鲁棒性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371530</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371530</guid>
      <pubDate>Sun, 07 Sep 2025 06:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美国参议员提出「SANDBOX 法案」 允许 AI 公司设定长达 10 年自我监管规则</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;美国参议员特德・克鲁兹（Ted Cruz）提出了一项名为 「SANDBOX 法案」 的新立法。这项法案旨在为人工智能 (AI) 公司提供一个 「监管沙箱」，让它们在较少的联邦监管下进行实验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据该法案，AI 公司可以申请修改或豁免任何 「阻碍性规定」，以便更方便地测试和部署包含或使用至少一个 AI 系统的产品或服务。作为交换，公司需要向监管机构披露其减轻消费者安全和财务风险的计划。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;法案规定，豁免期限为两年，最多可延长至十年。这一提案与此前一项试图暂停十年所有州级 AI 监管的失败提案有所相似。该提案于七月份在参议院遭到否决。赋予豁免权的将是相关的联邦机构，例如负责保护儿童在线隐私的联邦贸易委员会（FTC）。如果相关机构在 90 天内未作回应，豁免将会自动被授予。如果申请被拒，企业可以向白宫科技政策办公室 (OSTP) 上诉，该办公室将监督该监管沙箱项目并有权推翻拒绝决定。每年，国会将收到关于豁免或修改联邦规则次数的报告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;技术问责组织 「科技监督项目」 对此法案表示担忧，称其可能成为 「大科技首席执行官」 的 「甜蜜交易」，而那些为唐纳德・特朗普（Donald Trump）捐款的公司可能会享有不同的规则。此外，消费者权益组织 「公民公共事务」 警告称，该法案将允许硅谷在法律和监管方面实施 「快速推进、破坏一切」 的态度。这两个组织均对该法案赋予 OSTP 推翻联邦机构决策的权力表示关切，因为许多相关机构已经因拆解而失去了效能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，特朗普在七月份发布的 AI 行动计划中曾表示支持为 AI 公司创建监管沙箱。此外，特朗普的计划还包括通过撤销对实施 AI 监管的州的资金支持，间接推动这一监管沙箱的设立。克鲁兹所在的德克萨斯州在今年六月份通过了一项类似的 AI 法律，但该法案的沙箱期限仅限于 36 个月。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371526</guid>
      <pubDate>Sun, 07 Sep 2025 05:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>月之暗面开源 Checkpoint Engine，专为 LLM 推理引擎设计的中间件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;月之暗面开源了 Checkpoint Engine，这是一个专为 LLM 推理引擎设计的中间件，用于在强化学习等场景中实现模型权重的原地热更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db10fbcc3d6c729314d03825d34c1659112.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该工具可在约 20 秒，内完成 1 万亿，参数的 Kimi-K2 模型在数千个 GPU 上的权重同步，从而显著降低强化学习训练迭代过程中的停机时间。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-68055dc37220717eaee1d87c60b9856da48.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，该实现仅与 vLLM 深度集成，但其接口设计便于扩展至 SGLang 等其他框架。&lt;/p&gt; 
&lt;p&gt;开源地址：&lt;em&gt;https://github.com/MoonshotAI/checkpoint-engine&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371502</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371502</guid>
      <pubDate>Sun, 07 Sep 2025 03:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>甲骨文埃里森总财富达 4019 亿美元，史上第二个净资产突破 4000 亿美元的人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;福布斯实时富豪榜显示，甲骨文的联合创始人拉里·埃里森总财富达 4019 亿美元，日增 1100 亿美元或 37%，成为史上第二个净资产突破 4000 亿美元大关的人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;榜单显示，特斯拉首席执行官、太空探索技术公司（SpaceX）创始人埃隆·马斯克的最新财富为 4404 亿美元，依然是全球首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不过，由于统计口径不同，也有榜单认为埃里森已经超越马斯克成全球首富，根据彭博亿万富豪指数最新数据，拉里·埃里森（Larry Ellison）的财富达到 3930 亿美元，凭借此，其超越马斯克（3850 亿美元）成为全球首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="587" src="https://oscimg.oschina.net/oscnet/up-1c2309c9f3f45c8e7522623751993556803.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，OpenAI 已签署一项协议，将在大约五年内向甲骨文购买价值 3000 亿美元的算力。这笔交易是有史以来规模最大的云服务合同之一。该合同将需要 4.5 吉瓦的电力容量。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371487</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371487</guid>
      <pubDate>Sun, 07 Sep 2025 03:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MCP 是为开发者设计的工具，而非为 LLM 而设</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 你在开发 AI 智能体时，是否也曾为这些事头疼不已：每接入一个新工具就要重写集成代码？工具一多就难以统一管理？LLM 时而"幻觉"出根本不存在的工具调用？&lt;/p&gt; 
 &lt;p&gt;这些问题不仅拖慢开发节奏，更让智能体的稳定性和扩展性大打折扣。&lt;/p&gt; 
 &lt;p&gt;今天推荐的这篇文章，正来自一线开发者对 Model Context Protocol (MCP) 的深度实践与思考。对 LLM 来说，"常规"的工具调用和使用 MCP 这样的标准没有任何区别。它只看到一组工具定义（tool definitions），它不知道也不关心幕后发生着什么 ------ 而这恰恰是件好事...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Roy Derks&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Model Context Protocol (MCP) 已成为构建智能体时使用工具调用（tool calling）的标准，但恰恰相反，你的 LLM 并不需要理解 MCP。你可能听说过"上下文工程（context engineering）"这一术语，在这项技术中，作为与 LLM 交互的人，你需要负责提供正确的上下文来帮助它回答问题。为了收集这些上下文，你可以使用工具调用，让 LLM 能够访问一组可以用于获取信息或执行操作的工具。&lt;/p&gt; 
&lt;p&gt;MCP 通过标准化 AI 智能体连接到这些工具的方式来提供帮助。&lt;strong&gt;但对你的 LLM 来说，"常规"的工具调用和使用 MCP 这样的标准没有任何区别。&lt;/strong&gt; 它只看到一组工具定义（tool definitions），它不知道也不关心幕后发生着什么 ------ 而这恰恰是件好事。&lt;/p&gt; 
&lt;p&gt;通过使用 MCP，你可以访问成千上万的工具，而无需为每个工具编写自定义的集成逻辑。它极大地简化了涉及工具调用的智能体循环（agentic loop）的设置过程，而这一过程的开发时间通常情况下几乎为零。开发者负责调用工具，LLM 只生成一个片段，说明需要调用什么工具（单个或多个）以及使用哪些输入参数。&lt;/p&gt; 
&lt;p&gt;在这篇博客文章中，我将详细解释工具调用是如何工作的、MCP 实际上做了什么，以及这两者与上下文工程的关系。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 工具调用 Tool Calling&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;LLMs 理解工具调用【有时也称为工具使用（tool use）或函数调用（function calling）】的概念。你需要在提示词中提供工具定义列表。每个工具都包含名称、功能描述和所需的输入参数。根据用户问题和现有工具，大语言模型可能会生成对应的调用指令。&lt;/p&gt; 
&lt;p&gt;但关键点在于：&lt;strong&gt;LLMs 并不懂得如何使用工具。它们没有原生的工具调用支持，它们只会生成代表函数调用的文本。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b4a5e413dea5e14905d7abfa20648388860.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;与 LLM 交互时的输入与输出&lt;/p&gt; 
&lt;p&gt;在上方的示意图中，我们可以看到 LLM 实际看到的内容：一个由指令、之前的用户消息和可用工具列表组成的提示词。基于这些信息，大语言模型会生成文本响应，其中可能包含系统应当调用的工具指令。&lt;strong&gt;它并非真正理解工具的实际意义，只是在基于概率生成预测性响应。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;让我们来看一个更实际的应用场景。例如，如果你提供一个名为 get_weather 的工具，它接受一个地理位置作为输入，然后问模型："加利福尼亚州圣何塞的天气怎么样？" 它可能会回应：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
"name":"get_weather",
"input":{
"location":"San Jose, CA"
}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;LLM 能够根据所提供的上下文生成这个代码片段，如下方示意图所示。LLM 并不了解如何调用 get_weather 工具，它也无需知道。你的智能体循环（agentic loop）或智能体应用（agentic application）负责获取该输出，并将其转换为实际的 API 调用或函数调用。系统会解析模型生成的工具名称及输入参数，执行对应工具，并将执行结果作为新消息反馈给大语言模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bd5d7ee2fa32032370de356467715267894.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;工具调用流（Tool Calling flow）与 LLM 的交互&lt;/p&gt; 
&lt;p&gt;这种职责分离很重要。大语言模型仅负责生成预测结果，而执行环节交由您的系统处理。这正是 MCP（模型上下文协议）发挥作用的关键所在。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 模型上下文协议 (MCP)&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Model Context Protocol（简称 MCP）是一种标准化智能体与数据源（如工具、提示词、资源服务及样本示例）连接方式[1]的协议。&lt;strong&gt;现阶段，MCP 最显著的价值在于简化了工具集成这一关键环节。&lt;/strong&gt; MCP 通过定义统一的接口规范和通信协议，取代了为每个工具手动编写定制化代码的方式。您可以将其理解为工具领域的通用适配器（如同 USB-C 接口）。&lt;/p&gt; 
&lt;p&gt;MCP 通常包含三个核心组件：宿主应用 (host application)、MCP 客户端 (MCP client) 和若干 MCP 服务器 (MCP servers)。宿主应用可能是聊天软件或 IDE（例如 Cursor），其中内置了能连接不同 MCP 服务器的 MCP 客户端。这些 MCP 服务器则对外提供工具、提示词、样本示例或资源服务。&lt;/p&gt; 
&lt;p&gt;与 LLM 的交互方式并未改变，改变的是工具数据的接入方式：智能体应用与 MCP 客户端通信，再由客户端对接目标服务器。所有工具均以 LLM 可识别的格式进行描述。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d80215e3d29caf348271fee246fff36968e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;工具调用流与 LLM 及 MCP 的交互&lt;/p&gt; 
&lt;p&gt;当面对同样的问题"加利福尼亚州圣何塞的天气怎么样？"时，LLM 接收到的仍是相同的工具列表。根据该列表，它将告诉你需调用的工具，而具体的执行策略仍由开发者掌控。当采用 MCP 时，该工具将通过 MCP 协议执行。&lt;/p&gt; 
&lt;p&gt;该机制的核心受益方并非大语言模型，而是作为开发者的你。随着智能体系统的扩展，MCP 能有效管理复杂的多工具协作：实现跨项目的工具复用，统一数据格式规范，以及无需重构即可无缝接入新系统。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;但除非在系统提示词中明确告知，否则 LLM 永远无法感知你是否使用了 MCP。&lt;/strong&gt; 开发者始终承担工具调用的执行职责，大语言模型仅生成包含目标工具及对应输入参数的指令片段。&lt;/p&gt; 
&lt;p&gt;接下来，本文将解析该机制是如何融入上下文工程体系的，并阐释为何 MCP 这样的抽象层本质是为人类而非模型服务。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 上下文工程 Context Engineering&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Context engineering（上下文工程）的核心在于为 LLM 提供精准恰当的输入，使其生成有效的输出。这看似简单，却是构建高效 AI 系统最关键的环节之一。&lt;/p&gt; 
&lt;p&gt;当我们向模型提问时，本质上是在向其提供提示词（prompt） ------ 即模型用于预测后续文本的文本块。该提示词的质量直接影响响应质量。&lt;/p&gt; 
&lt;p&gt;这正是工具调用的价值所在。当模型缺乏足够上下文时（如需实时数据、用户画像或代用户执行操作的能力），通过工具调用可使其接入外部系统 ------ 正如本文所述。&lt;/p&gt; 
&lt;p&gt;但在此再次强调，模型无需理解这些工具的实现逻辑。它只需知晓三点：工具的存在性、功能定位及调用方式。这正是上下文工程（context engineering）与工具设计（tool design）的交汇点 ------ 我们所设计的工具定义集本质上是提示词的组成部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-70d75852edc894f635b93c2125ec512de9d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;LLM 视角下的工具调用&lt;/p&gt; 
&lt;p&gt;MCP 使该过程更简洁规范且可复用。通过 MCP 协议，开发者只需一次性定义结构化接口并对外发布，即可避免硬编码工具（hardcoding tools）或编写临时封装器（writing ad hoc wrappers）。LLM 接收到的工具定义格式保持不变，但现在它们更容易维护和扩展。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;综上所述，MCP 本质上是一个为开发者设计的工具，而非为 LLM 而设。&lt;/strong&gt; 它可以帮助我们构建更可靠的、更模块化的系统，使工程师能专注于上下文工程，而无需每次都重复搭建基础架构。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓文中的核心观点是："MCP 是为开发者，而非为 LLM 服务的"。你是否认同？有没有反例或不同的角度？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F4029634%2Fwhat-is-model-context-protocol-how-mcp-bridges-ai-and-external-services.html" target="_blank"&gt;https://www.infoworld.com/article/4029634/what-is-model-context-protocol-how-mcp-bridges-ai-and-external-services.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhackteam.io%2Fblog%2Fyour-llm-does-not-care-about-mcp%2F" target="_blank"&gt;https://hackteam.io/blog/your-llm-does-not-care-about-mcp/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18691378</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18691378</guid>
      <pubDate>Sun, 07 Sep 2025 03:12:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>腾讯优图公布今年整体开源计划</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯向《科创板日报》透露，围绕 Youtu-RAG 和 Youtu-Agent 两大系列，从 9 月到 12 月将陆续开源 RAG 所需的 Youtu-Embedding/Youtu-GraphRAG/Youtu-Parsing/Youtu-Reranker 等系列模型，并提供基于 MCP 的 Youtu-RAG 框架；以及 Agent 训练改进算法 SAL/Agent 数据引擎 AgentVR。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;具体来说，Youtu-Embedding、Video-MME V2、Youtu-Parsing 预计将分别于 9 月、10 月、11 月开源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;腾讯优图实验室于日前宣布开源了智能体框架 Youtu-Agent。该框架以极简设计和高性能表现为核心，旨在为研究人员和开发者提供高效、易用、可复现的智能体开发工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="347" src="https://oscimg.oschina.net/oscnet/up-64fd8e3e9b8e3d8fd3e9f449c2f233b39c8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-6811930e47590e421a4609fdf9f21724e09.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在性能表现上，Youtu-Agent 在多个智能体挑战性基准测试中取得领先成绩。例如，在 WebWalkerQA 基准中，基于 DeepSeek-V3.1 的运行结果达到了 71.47% 的准确率，刷新了开源模型的最新纪录。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371482</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371482</guid>
      <pubDate>Sun, 07 Sep 2025 03:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>deepchat 企业 AI 应用平台增加智能体发布嵌入网站功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//de83a8e2d16232270d87894690136c66.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;经过一些日子的开发，一个人加 AI，deepchat 终于有了点模样。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#40485b"&gt;项目地址：&lt;/span&gt;https://gitee.com/noday/deepchat&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;官网：http://deepchat.6661943.xyz/&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#40485b"&gt;deepchat 探索大模型企业应用落地场景。包括但不限于知识库、问数、ChatBI、Office 助手、智能客服、资料分类于分析等等，对接了国内外厂家的大模型提供商。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本次更新：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;智能体发布功能，发布到对话广场和嵌入网站&lt;/p&gt; 
&lt;p&gt;&lt;img height="945" src="https://oscimg.oschina.net/oscnet/up-9f8aaed339c03f51e2f4085edd50e700f39.png" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="945" src="https://oscimg.oschina.net/oscnet/up-15dfdd00de87fd29822b57f37c412758d46.png" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371479</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371479</guid>
      <pubDate>Sun, 07 Sep 2025 02:59:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Thinking Machines Lab 发文，揭示 LLM 推理过程不确定性的真相</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;由 OpenAI 前 CTO Mira Murati 创办的 Thinking Machines Lab 发布了第一篇技术博客：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthinkingmachines.ai%2Fblog%2Fdefeating-nondeterminism-in-llm-inference%2F" target="_blank"&gt;《在 LLM 推理中战胜不确定性》(「Defeating Nondeterminism in LLM Inference」)&lt;/a&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/103902_WRpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为什么大语言模型推理过程是不确定性的，如何让大模型 100% 输出同样的结果？这篇文章正是讨论了这一问题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-59d0b8b8b532757c7b9865e53d7395f459d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们知道即使将大模型温度参数设为 0，使用相同的输入、相同的模型和硬件，仍可能得到不同的输出。&lt;/p&gt; 
&lt;p&gt;文中认为主要原因有两个：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 浮点数加法的非结合性（floating-point non-associativity）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;即 (a + b) + c ≠ a + (b + c)，这在并行计算中会导致不同的求和顺序产生不同的数值结果。&lt;/p&gt; 
&lt;p&gt;不过这不是主要原因。主要还是因为第二点：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 并行计算策略的变化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;不同的 batch size、序列长度、KV-cache 状态等，会导致 GPU 内核选择不同的并行策略，从而改变计算顺序和结果。&lt;/p&gt; 
&lt;p&gt;为了实现确定性推理，作者提出要让所有关键计算核（kernel）具备 batch-invariant 特性，即无论 batch 大小或序列如何切分，计算顺序和结果都保持一致。并针对 RMSNorm、矩阵乘法 (Matrix Multiplication)、注意力机制 (Attention) 给出了具体方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-35e97e53fd1856165d750d9473d2ae1e61f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作者用 Qwen3-235B-A22B-Instruct-2507 做了试验，用他的改进方法后，重复 1000 次，大模型的输出仍然是完全相同的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371472/defeating-nondeterminism-in-llm-inference</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371472/defeating-nondeterminism-in-llm-inference</guid>
      <pubDate>Sun, 07 Sep 2025 02:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>快手推出 AI 视频制作助手 Kwali</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;快手近日推出了一款名为 Kwali 的 AI 视频制作助手，旨在帮助用户快速生成高质量的短视频。只需在对话框中输入需求，Kwali 便能在几分钟内提供成片，彻底简化了以往繁琐的视频制作流程。&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="310" src="https://oscimg.oschina.net/oscnet/up-5eaeb10c1296b2e9134f6722c021fd45857.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Kwali 的工作原理是通过一个强大的云端多 Agent 框架，将多个功能整合在一起，形成一个完整的视频制作系统。用户只需清晰描述需求，Kwali 会自动拆解出视频所需的卖点、受众和情境标签等信息。随后，脚本生成 Agent 会创建分镜和台词，而镜头匹配 Agent 则负责从素材库中选择合适的画面。最后，剪辑合成 Agent 将音乐和字幕进行排版，整个过程高效且便捷。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Kwali 配备了丰富的素材库，用户可以随时使用热门视频素材和数字人模特。如果用户有自己的私有素材，也可以轻松导入，系统会自动为其贴上多维标签，以便后续快速检索。这样，用户不再需要担心没有足够的素材支持自己的创作。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在 Kwali 的操作界面上，用户可以简单地选择智能助手，输入想要制作的视频主题，比如一个烧烤店的宣传视频。Kwali 会通过解析行业内热门视频的结构，为脚本创作提供灵感。随后，它会在素材库中搜寻相关素材，并进行后期包装，最终合成成片。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;整个视频制作流程大幅度压缩，不再需要多团队的衔接。Kwali 让视频生成和发布一体化，商家和个人可以轻松、高效地发布宣传内容，降低了制作成本，也提升了内容的更新频率。商家节省下来的预算，可以用于更多的市场活动和促销策略，从而实现快速的资金回笼。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371470</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371470</guid>
      <pubDate>Sun, 07 Sep 2025 02:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 与甲骨文签署 3000 亿美元云计算大单</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F10%2Fopenai-and-oracle-reportedly-ink-historic-cloud-computing-deal%2F" target="_blank"&gt;据 TechCrunch 报道&lt;/a&gt;，当地时间 9 月 10 日消息，OpenAI 已与甲骨文签订了一份价值 3000 亿美元的算力购买订单，这是有史以来最大的云计算合同之一。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4342e98cd2b999b112280a6366b3dbfedb6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该交易将于 2027 年正式生效，为期约 5 年，平均每年金额规模达到 600 亿美元。协议涉及为 OpenAI 提供 4.5 吉瓦的数据中心容量，可支持超 200 万枚芯片运行。这一合作是 OpenAI 「星际之门」 数据中心建设计划的一部分。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cbef7bd3ffcd6148eb21a344ed8230f6989.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;受此利好消息影响，甲骨文 10 日盘中一度涨超 40%，创下 1992 年以来最大盘中涨幅，此前该公司公布了令人惊叹的云服务需求数据。这家云服务巨头市值正迅速逼近 1 万亿美元大关，目前已达 9500 亿美元。其联合创始人拉里・埃里森（Larry Ellison）的财富在一天内暴增 1010 亿美元，创下有史以来单日最大财富增长纪录，并超越马斯克，登顶世界首富。&lt;/p&gt; 
&lt;p&gt;甲骨文 CEO 表示，公司打造的千兆瓦级数据中心，在训练人工智能模型方面比全球任何其他企业都更快、更具成本效益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371464</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371464</guid>
      <pubDate>Sun, 07 Sep 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软与 OpenAI 战略转变，探索新合作伙伴关系</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期，微软与 OpenAI 的合作关系似乎正在发生变化，两者都在寻求更多的独立性。根据《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Fbusiness%2Fopenai-oracle-sign-300-billion-computing-deal-among-biggest-in-history-ff27c8fe%3Fmod%3De2twd" target="_blank"&gt;华尔街日报&lt;/a&gt;》的报道，OpenAI 已与甲骨文签署了一项计算资源的协议，交易额可能高达 3000 亿美元。这一协议与 OpenAI 在七月份宣布的 4.5 吉瓦 Stargate 数据中心容量开发协议并无直接关系。甲骨文对此交易未作评论。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-2066936395dcd6fac44bb306f67eb3fb73e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;与此同时，作为 OpenAI 的长期投资者，微软对于将 Anthropic 技术应用于 Office365 的消息并未给予明确的否认或确认。这意味着微软可能不再仅仅依赖 OpenAI 来支持其 Word、Excel、Outlook 和 PowerPoint 等应用程序。如果这一情况属实，将进一步显示出当前 AI 领域的快速变化。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在甲骨文的季度财报电话会议上，该公司透露已与 OpenAI、xAI、Meta、Nvidia 和 AMD 等多家公司签署了重要的云计算合同。分析师 Chirag Dekate 表示，OpenAI 正在加速发展，急需更强大的计算能力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，OpenAI 近期还推出了 AI 数据中心项目 Stargate Norway，并与谷歌达成了云计算资源的协议。Dekate 指出，OpenAI 似乎正在为大规模推理执行铺平道路，尤其是在消费产品和应用程序（如 ChatGPT）方面。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;关于 OpenAI 与微软的合作关系，微软发言人重申，OpenAI 仍将是其在前沿模型上的合作伙伴，双方的长期合作仍然会继续。尽管微软在过去七年内已经投入超过 130 亿美元于 OpenAI，但其也在不断多元化自身的投资组合，开始提供其他供应商的模型，如 xAI 的 Grok 和 Anthropic 的 Claude。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;分析师 David Menninger 表示，微软近期推出的 MAI-Voice1 和 MAI-1-preview 等自家模型标志着与 OpenAI 的关系正在发生变化。微软正处于与 OpenAI 的 「合作竞争」 之中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在市场竞争中，微软收购 Anthropic AI 技术的消息也表明了其在负责任 AI 和代码生成领域的快速发展。微软的目标是抓住 Anthropic 客户的云计算市场，特别是在与谷歌等竞争对手抗衡时。最近，微软还与基础设施公司 Nebius 达成协议，计划在未来五年内从 Nebius 的 GPU 中租赁计算能力，交易额高达 200 亿美元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371461</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371461</guid>
      <pubDate>Sun, 07 Sep 2025 02:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
