<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 07 Aug 2025 07:41:08 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Cursor 设计负责人分享：软件工程师（或任何人）如何提升设计水平？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;我经常被问到这个问题。作为一个从计算机科学（CS）转型做设计的人，我想分享一条切实可行的路径：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;从系统思维开始&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;工程师们对此已经很熟悉了。设计，只不过是为人类和我们的感官（而非机器）打造的系统。如果你还没读过，可以去读一读《系统之美》（Thinking in Systems）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;学习基础知识&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;人类经过几个世纪的进化，已经形成了一套用于视觉化呈现和接收信息的系统。即使是命令行界面（CLI），也无法避开这些法则：&lt;/p&gt; 
&lt;p&gt;字体排印 — 从 Jost Hochuli 的《Details in Typography》开始。 色彩基础 — 从 Josef Albers 的《色彩构成》(Interaction of Color) 开始。 网格系统 — 从 Josef Müller-Brockmann 的《平面设计中的网格系统》(Grid Systems) 开始。&lt;/p&gt; 
&lt;p&gt;视觉层次、阅读节奏、符号与概念系统、动效、无障碍设计…… — 随着实践，你会掌握更多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;敞开你的双眼和大脑&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;观察你周围的事物，无论是数字世界还是自然界。观察万物中的美与共通之处，思考它为何被设计成这样。在你的观察、思考和创造之间建立联系。打破僵化、线性的思维，释放自己。凝望天空，放空自己。洞悉万物。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然后，放手去创造&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;既然你已经开始留意，那就试着去改进事物，先用你自己的方式。重新设计你日常使用的应用。逐像素地复刻你喜爱的设计——这样一周学到的东西比你看几个月理论还多。然后，将你的作品分享给他人，获取反馈，并为更多人设计。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;关键心态转变：感受先行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;停止为计算机优化，开始为人类优化。工程师考虑的是边缘情况（edge cases）和错误状态，而设计师考虑的是理想路径（happy paths）和情感体验。对人类来说，最终的感受以及事物如何融为一体，远比边缘情况重要得多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;工具没那么重要&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Figma 是行业标准。一个周末就能学会（它基本上就是可视化的 Flexbox）。你可以用 Cursor 这类工具来拆解现有设计系统并制作原型，研究它们是如何构建的——前端技术在这里大有可为。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最重要的一点&lt;/strong&gt;：通过约束找到你自己的设计语言。 选择一款出色的字体，一套有限的调色板，然后用它们做出 10 种不同的布局。约束催生创造力。而迭代是达成目标的途径。&lt;/p&gt; 
&lt;p&gt;优秀的工程师已经理解系统、逻辑和解决问题的方法。他们只需将这些能力应用到人的概念和问题上，而不是技术问题上。&lt;/p&gt; 
&lt;p&gt;从明天开始。重新设计你的个人网站或一个简单的应用。完成它，分享它，不断重复。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：x.com/ryolu_/status/1952759102058242253&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364816</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364816</guid>
      <pubDate>Thu, 07 Aug 2025 07:35:05 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>摩尔线程 MUSA 架构成功适配开源推理框架 llama.cpp</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MUSA（Meta-computing Unified System Architecture）是摩尔线程自主研发的通用并行计算架构。官方近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1qctAz4EUq%2F"&gt;宣布&lt;/a&gt;&amp;nbsp;MUSA&amp;nbsp;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;已正式完成与开源推理框架 llama.cpp 的适配，进一步融入全球 AI 生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-21f1f791376efc2c7275c63eb22cf6de3a0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;llama.cpp 作为纯 C/C++ 实现的大语言模型推理工具，以轻量化部署和跨硬件兼容性著称，支持 LLaMA、Mistral 等主流模型及多模态应用。此次适配意味着用户可在 MTT S80/S3000/S4000 系列 GPU 上通过官方容器镜像高效运行 AI 推理。&lt;/p&gt; 
&lt;p&gt;今年 4 月，MUSA SDK 4.0.1 已扩展至 Intel 处理器与国产海光平台，此次与 llama.cpp 的联动，进一步降低了开发者部署大模型的门槛，为本土 AI 硬件生态注入新动能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364814</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364814</guid>
      <pubDate>Thu, 07 Aug 2025 07:23:05 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>小红书开源多模态大模型 dots.vlm1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;小红书 Hi Lab 开源了其首个自研多模态大模型&amp;nbsp;&lt;strong&gt;dots.vlm1&lt;/strong&gt;。该模型基于 12 亿参数的&amp;nbsp;&lt;strong&gt;NaViT 视觉编码器&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;DeepSeek V3 大语言模型&lt;/strong&gt;，从零开始完全训练，其卓越性能在多模态视觉理解与推理能力上已接近当前领先的闭源模型，如&amp;nbsp;&lt;strong&gt;Gemini2.5Pro&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;Seed-VL1.5&lt;/strong&gt;，标志着开源多模态模型的性能达到了新的高度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;dots.vlm1 的核心亮点在于其原生自研的&amp;nbsp;&lt;strong&gt;NaViT 视觉编码器&lt;/strong&gt;。与传统基于成熟模型微调的方式不同，NaViT 从零训练，并支持动态分辨率，能够更好地适应多样化的真实图像场景。该模型还通过结合纯视觉与文本视觉的双重监督，极大提升了其泛化能力，尤其是在处理表格、图表、公式、文档等非典型结构化图片时表现出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在数据方面，Hi Lab 团队构建了规模庞大且清洗精细的训练集。他们通过自主重写网页数据和自研&amp;nbsp;&lt;strong&gt;dots.ocr&lt;/strong&gt;&amp;nbsp;工具处理 PDF 文档，显著提升了图文对齐的质量，为模型的跨模态理解能力打下了坚实基础。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;评测结果表明，dots.vlm1 在&amp;nbsp;&lt;strong&gt;MMMU&lt;/strong&gt;、&lt;strong&gt;MathVision&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;OCR Reasoning&lt;/strong&gt;&amp;nbsp;等多项基准测试中，达到了与 Gemini2.5Pro 和 Seed-VL1.5 相当的水平。在复杂的图表推理、STEM 数学推理以及长尾细分场景识别等应用中，dots.vlm1 展现出卓越的逻辑推理和分析能力，完全胜任奥数等高难度任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="527" src="https://oscimg.oschina.net/oscnet/up-6e01b7f98f74ddc0a373242bba0c2e628a3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;尽管在文本推理的极复杂任务上与 SOTA 闭源模型仍有差距，但其通用数学推理和代码能力已与主流大语言模型持平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Hi Lab 团队表示，未来将继续优化模型。他们计划扩大跨模态数据规模，并引入强化学习等前沿算法，进一步提升推理泛化能力。通过开源&amp;nbsp;&lt;strong&gt;dots.vlm1&lt;/strong&gt;，小红书致力于为多模态大模型生态系统带来新的动力，推动行业发展。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364810</guid>
      <pubDate>Thu, 07 Aug 2025 07:08:05 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>日本政府禁止苹果在 iOS 平台限制第三方浏览器引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;日本政府已通过《智能手机法》（正式名称为《&lt;/span&gt;Bill on the Promotion of Competition for Specified Software Used in Smartphones&lt;span&gt;》）及其配套的《移动软件竞争法》（MSCA）指南，正式禁止苹果在 iOS 平台上限制第三方浏览器引擎，要求&lt;/span&gt;苹果 iOS 必须在今年 12 月前解除浏览器引擎禁令，必须允许第三方浏览器使用自己的引擎（如 Blink、Gecko）。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1832" src="https://static.oschina.net/uploads/space/2025/0807/145413_X9Uj_2720166.png" width="1316" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://www.jftc.go.jp/file/MSCA_Guidelines_tentative_translation.pdf&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;配套要求&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;禁止设置技术或财务上的不合理障碍；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;禁止引导用户远离非 WebKit 浏览器；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要求设备首次激活时立即弹出浏览器选择界面，确保用户能明确选择；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;浏览器开发者必须获得与 Safari 同等水平的系统 API 访问权限。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;据了解，&lt;span&gt;苹果以「安全与隐私」为由，强制所有运行在 iOS 的浏览器（比如&amp;nbsp;&lt;/span&gt;Firefox、Chrome、Edge、Opera、Brave&lt;span&gt;）必须使用 WebKit 引擎，导致这些浏览器本质上都是「Safari 换皮」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Open Web Advocacy 组织参与了法律咨询并协助制定政府最终报告，该组织昨天在其官网发布的声明称：「苹果通过强制使用 WebKit，实际上禁止了 iOS 上独立浏览器的发展。新的法律不仅禁止了明令禁止的行为，也禁止了那些让替代引擎难以运行的做法。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364809</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364809</guid>
      <pubDate>Thu, 07 Aug 2025 07:06:05 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Character.AI 发布全球首个 AI 原生社交动态功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Character. AI &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.character.ai%2Fcharacter-ai-launches-worlds-first-ai-native-social-feed%2F" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;推出全球首个 AI 原生社区动态（Community Feed） 功能，将提供个性化的角色、场景和创作者帖子，旨在激发灵感、娱乐和联系。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5457c8a14f5ed1a8c61106c1b0ad7e652b7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a44b4f56f6311445a4cc5ae981e65fc3360.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;社区动态功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聊天片段（分享展现角色个性的对话片段）&lt;/li&gt; 
 &lt;li&gt;角色卡片（生成可直接聊天的角色预览）&lt;/li&gt; 
 &lt;li&gt;直播流（为心仪角色设定主题，观看其辩论、吐槽、制作视频博客等）&lt;/li&gt; 
 &lt;li&gt;虚拟形象特效（通过自定义视频模型生成角色或任意内容的视频，只需一张图片和简短脚本，数秒即可完成）&lt;/li&gt; 
 &lt;li&gt;图像生成（基于与角色的聊天内容生成背景图）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;据介绍，社区动态功能使 Character.AI 从聊天应用升级为面向下一代的全内容社交平台，重塑人们与 AI、敍事及彼此的互动方式。其 CEO 表示：「新信息流模糊了创作者与消费者的界限，终结无意义滑动，引领 AI 娱乐未来。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364805/character-ai-launches-worlds-first-ai-native-social-feed</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364805/character-ai-launches-worlds-first-ai-native-social-feed</guid>
      <pubDate>Thu, 07 Aug 2025 06:47:05 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 在实际生成环境中的提效实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;导读&lt;/h4&gt; 
&lt;p&gt;随着 AI 时代的到来，各类 AI 工具层出不穷，业界都在探索一套完整的 AI 加成的提效方案，我们团队基于自身特色，利用起团队沉淀好的历史知识库，落地了一套深度结合 AI 的工作流，用 AI 武装研发团队，实现研发效率的提升。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;各类 AI 研发工具层出不穷，很多现成工具可使用，&lt;em&gt;&lt;strong&gt;业界都在探索一套完整的 AI 加成的提效方案&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;团队内部规范文档完备，但是没有融入开发流程中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Code review、研发自测、接口文档更新消耗大量时间&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 拥抱 AI 时代，&lt;strong&gt;让团队更先进&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;2. 用 AI 武装研发团队，通过资源的配合与协调，实现研发效率的提升。&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;思路&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 拆分研发流程，并找到 AI 结合点，并将其串联起来。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 深度探索 AI IDE，得出最佳实践。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;3. 利用起团队的知识库，为 AI 提供辅助能力。&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;定位&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 这是一个锚点，自此开始团队研发流程向 AI 化转变。&lt;/p&gt; 
&lt;p&gt;2. 这是一个开始，带动团队与其他同学 review 当前研发流程，&lt;strong&gt;共建更多研发工作流。&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;01 研发链路&lt;/h1&gt; 
&lt;p&gt;对研发链路进行拆解，得到不同阶段的 AI 工作流形态，并基于当前形态向下一形态进行推进。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b940caac96e16b2debbc458606192f14b2c.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;当前我们团队正处于阶段 1 接近完成，阶段 2 正在开始探索实践的阶段，因此下面我们会基于我们团队在这些方面的实践进行分享。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;原本研发链路：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8a46b6b27bceca968a8d8cb3f86c27b69d8.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 加持研发流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e74eb941a7e4a40ab2b07fbbe750401fff3.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;AI 工作流&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;对上面涉及到的 AI 工作流进行补充说明&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI-Cafes：AI 生成需求文档，制作产品原型图，节省产品人天。&lt;/p&gt; 
&lt;p&gt;AI-Docs：需求文档转技术文档，节省研发梳理过程，节省研发人天。&lt;/p&gt; 
&lt;p&gt;AI-DocsCoding：基于技术文档，生成基础无业务逻辑代码，节省研发人天。&lt;/p&gt; 
&lt;p&gt;AI-Coding：基于团队内部代码规范生成代码，减少返工和代码理解成本，深度提高研发效率，节省研发人天。&lt;/p&gt; 
&lt;p&gt;AI-API：基于 MCP Server 打通接口文档，避免 api 文档/技术文档更新不及时，节省研发人天。&lt;/p&gt; 
&lt;p&gt;AI-CR：基于 Rules，进行 AI Code Review，节省研发人天。&lt;/p&gt; 
&lt;p&gt;AI-Develops：AI 赋能测试、验证、监控环节，节省测试人天。&lt;/p&gt; 
&lt;span id="OSC_h1_8"&gt;&lt;/span&gt; 
&lt;h1&gt;02 需求阶段&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;AI-CafeDocs&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在原本的工作流中，在需求评审过后，研发同学通常需要至少 0.5d 的人力进行技术文档的落地，以及 api 接口的准备。&lt;/p&gt; 
&lt;p&gt;但是这一步中的大部分工作是&lt;strong&gt;&lt;strong&gt;重复的，可替代的，可节省&lt;/strong&gt;&lt;/strong&gt;的。&lt;/p&gt; 
&lt;p&gt;因此我们实现了了_&lt;strong&gt;&lt;em&gt;&lt;strong&gt;需求文档 -&amp;gt; aisuda（百度的低代码平台）-&amp;gt; 大模型 -&amp;gt; 技术文档（markdown）&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;_的工作流。&lt;/p&gt; 
&lt;p&gt;在微调好大模型之后，我们只需要以下两步就能完成技术文档+api 接口准备的工作：&lt;/p&gt; 
&lt;p&gt;1. 投喂需求文档给大模型，得到初版技术文档。&lt;/p&gt; 
&lt;p&gt;2. 人工 check 技术文档。&lt;/p&gt; 
&lt;p&gt;在快速生成了技术文档后，后端再和前端进行沟通，根据细节进行修改具体实现。&lt;/p&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-DocsCoding&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在得到技术文档之后，我们下一步要做的则是落地。不得不承认，我们的工作中无可避免的会存在一些基础的 CRUD 环节，这是正常的，也是&lt;strong&gt;&lt;strong&gt;重复的，可替代的，可节省&lt;/strong&gt;&lt;/strong&gt;的。&lt;/p&gt; 
&lt;p&gt;因此，基于以上的 AI-CafeDocs 环节，我们进行了进一步的延伸，实现了_&lt;strong&gt;&lt;em&gt;&lt;strong&gt;技术文档 -&amp;gt; MCP Server -&amp;gt; AI IDE&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;_ 的工作流&lt;/p&gt; 
&lt;p&gt;我们通过 MCP 打通了内部的知识库，使得 AI 能够阅读到需求文档和技术文档，了解上下文，并进行对应的开发工作。&lt;/p&gt; 
&lt;p&gt;当然，AI 全流程开发只是一种理想的状态，就当前而言，AI-DocsCoding 写出来的代码并不是完全可用的，在涉及到的业务逻辑越复杂时，代码的正确性就越低。&lt;/p&gt; 
&lt;p&gt;但是不要紧，我们在设计这个流程的时候，就早有准备。&lt;/p&gt; 
&lt;p&gt;还记得我们强调的一点：让 AI 取代&lt;strong&gt;&lt;strong&gt;重复的，可替代的，可节省&lt;/strong&gt;&lt;/strong&gt;的工作，那么正确的流程为：&lt;/p&gt; 
&lt;p&gt;1. AI 通过 MCP 阅读需求文档、技术文档，生成本次功能的基础代码——除却业务逻辑之外的参数处理、数据处理的 CRUD 代码。&lt;/p&gt; 
&lt;p&gt;2. 人工补全核心的业务逻辑处理，人也只需要关心真正的业务逻辑，这些事 AI 无法替代的。&lt;/p&gt; 
&lt;p&gt;可以看到，在以上的两个工作流里，人的角色从执行者，变成了驱动者/观察者，或者说产品经理。&lt;/p&gt; 
&lt;p&gt;我们通过**&lt;em&gt;&lt;strong&gt;向 AI 提出需求，监督 AI 工作，验收 AI 工作结果&lt;/strong&gt;&lt;/em&gt;**的方式进行工作。&lt;/p&gt; 
&lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
&lt;h1&gt;03 开发阶段&lt;/h1&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-Coding&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;AI-Coding 这一块主要围绕 AI IDE 的使用，现在市面上有很多的产品，比如 Cursor、Comate、Trae 等。其实在许多人看来，AI IDE 的核心在于底层能够接入的模型，但是我觉得这不尽然，大模型的边界效应很强。&lt;/p&gt; 
&lt;p&gt;有些时候，我们对 AI IDE 的使用，还没有达到需要区分模型效果的地步。&lt;strong&gt;&lt;strong&gt;或者说，如果我们使用了世界上最好的模型，那我们是否就高枕无忧了，可以让 AI 全程进行 Coding 而不需要人为 Review 了&lt;/strong&gt;&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;至少使用到今天为止，我们认为 AI-Coding，还离不开人的关注，因此如何更好地使用 AI 进行 Coding，是 AI 提效的必经之路。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;合理使用 Rule&lt;/h3&gt; 
&lt;p&gt;在&lt;strong&gt;&lt;strong&gt;AI IDE&lt;/strong&gt;&lt;/strong&gt;内，Rule 是一个非常重要的环节，&lt;strong&gt;它是连接开发者意图与 AI 代码生成行为之间的关键桥梁&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;定义：Rule 的，核心目的是指导 AI 更准确地理解当前代码库的上下文、遵循特定的项目规范与编码标准、生成符合预期的代码，或辅助完成复杂的工作流程。Cursor 官方文档将其描述为「控制 Agent 模型行为的可复用、有作用域的指令」。&lt;/p&gt; 
&lt;p&gt;作用：大型语言模型（LLMs）本身在多次交互之间通常不具备持久记忆。Rule 通过在每次 AI 请求的提示词（prompt）层面提供持久化、可复用的上下文信息，有效解决了这一问题。&lt;strong&gt;当一个规则被应用时，其内容会被包含在模型上下文的起始部分&lt;/strong&gt;，从而为 AI 的代码生成、编辑解释或工作流辅助提供稳定且一致的指导。&lt;/p&gt; 
&lt;p&gt;上面有一个非常重要的点，那就是所有的 rule 在使用的过程中，都会占用我们上下文的 token，因此如何更好的使用 Rule，是提升 AICoding 能力的关键。&lt;/p&gt; 
&lt;p&gt;基于我们的实践，我们建议将 AI IDE 的 rule 进行层级划分：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第一层：IDE 全局层 (User Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：User Rules&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;范围：所有项目通用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内容：个人编码风格偏好&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：50 行以内&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第二层：项目基础层 (Always Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/always/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;范围：整个项目强制遵循&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内容：技术栈、核心原则、基础规范&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：100 行以内&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第三层：自动匹配层 (Auto Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/auto/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;范围：特定文件类型或目录&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内容：模块专门的开发规范&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每个规则 200 行以内&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第四层：智能推荐层 (Agent Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/agent/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;范围：AI 根据对话内容智能判断&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内容：优化建议和最佳实践&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每个规则 150 行以内&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第五层：手动调用层 (Manual Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/manual/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;范围：手动调用的代码模板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内容：完整的项目或模块模板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每个规则 300 行以内&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上的划分，我们再给出对 &lt;strong&gt;&lt;strong&gt;已有/未有 Rule 规范&lt;/strong&gt;&lt;/strong&gt;的代码库的 Rule 创建规则（语言不重要，以 Go 为例）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;内容优化原则&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;详细代码示例（每个 100+行）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;重复的概念解释&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推荐：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;简洁要点列表（每个 20-30 行）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;具体的操作指令&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;globs 精确匹配&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;过于宽泛：&lt;code&gt;"**/*.go"&lt;/code&gt;（匹配所有 Go 文件）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推荐&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精确匹配：&lt;/p&gt; &lt;p&gt;&lt;code&gt;"internal/handler/**/*.go"&lt;/code&gt;（只匹配处理器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精确匹配：&lt;/p&gt; &lt;p&gt;&lt;code&gt;"internal/repository/**/*.go"&lt;/code&gt;（只匹配仓储层）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精确匹配：&lt;code&gt;"**/*_test.go"&lt;/code&gt;（只匹配测试文件）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;优先级设置详解&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;优先级数值范围：1-10，数值越高优先级越高&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f56ca8d226b9275006442e4b467dc204f2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;优先级使用策略&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 基础规范用 10&lt;/strong&gt;&lt;/strong&gt;：项目必须遵循的核心规范&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 核心模块用 8-9&lt;/strong&gt;&lt;/strong&gt;：handler、service、repository 等主要模块&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 辅助模块用 6-7&lt;/strong&gt;&lt;/strong&gt;：middleware、config、utils 等辅助模块&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;4. 优化建议用 5&lt;/strong&gt;&lt;/strong&gt;：性能优化、最佳实践等智能建议&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;5. 模板参考用 3-4&lt;/strong&gt;&lt;/strong&gt;：代码模板、脚手架等参考资料&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;6. 实验功能用 1-2&lt;/strong&gt;&lt;/strong&gt;：测试中的新规范，避免影响稳定功能&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;冲突解决机制&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;当多个规则应用于同一文件时，高优先级规则会覆盖低优先级规则的冲突部分&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;相同优先级规则按文件名字母顺序加载&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Always 规则始终优先于所有其他类型规则&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Rule 的核心价值在于它&amp;nbsp;**&lt;em&gt;**为开发者提供了一种机制，用以精细化控制 AI 在代码理解、生成、重构等环节&amp;nbsp;**&lt;/em&gt;**的行为。&lt;/p&gt; 
&lt;p&gt;通过预设规则，开发者可以将项目规范、编码标准、技术选型乃至特定业务逻辑「教授」给 AI，从而显著提升 AI 辅助编程的效率、保证代码质量的均一性，并确保项目整体的规范性。&lt;/p&gt; 
&lt;p&gt;它使得 AI 从一个泛用的助手，转变为一个深度理解特定项目需求的「领域专家」。&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;记忆库&lt;/h3&gt; 
&lt;p&gt;基于 Rule 的运用，我们通过&lt;strong&gt;&lt;strong&gt;memory bank + rule&lt;/strong&gt;&lt;/strong&gt;生成专属业务研发助手&lt;/p&gt; 
&lt;p&gt;在 AICoding 的使用中，有一种常见的痛点场景，&lt;strong&gt;&lt;strong&gt;就是在复杂的项目中，AI 无法感知到整个项目的历史上下文，即便是有 Codebase 的存在，也对业务逻辑是一知半解&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在我们实践的过程中，引入了记忆库的模式，深化 AI 对项目的理解和记忆，使得每一次需求迭代的上下文都被记录下来。&lt;/p&gt; 
&lt;p&gt;生成了 memorybank 后，我们可以随时通过对话查看项目大纲和内容，并且每一次重新进入开发，不会丢失之前的记忆。&lt;/p&gt; 
&lt;p&gt;这种模式，其实就是 Rules 的一种应用，它把上下文总结在代码库的制定位置，强制 AI 在每次进入时会阅读上下文，回到上一次 Coding 的状态，对于解决上下文丢失的问题有非常大的帮助。&lt;/p&gt; 
&lt;p&gt;这里可能有人会问，记忆库和 IDE 本身的长期记忆功能有什么区别？&lt;/p&gt; 
&lt;p&gt;答：&lt;strong&gt;记忆库是公共的项目记忆库，IDE 长期记忆是私人的 IDE 使用记忆&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;而记忆库的详细内容，这里不作详细分享，它只是一份提示词，感兴趣的同学只要简单搜索一下就能找到很多的资源。&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;MCP Server（重点）&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;MCP（Model Context Protocol），模型上下文协议&lt;/strong&gt;&lt;/strong&gt;，由 Anthropic 于 24 年 11 月提出，旨在为大语言模型和外部数据源、工具、服务提供统一的通信框架，&lt;strong&gt;&lt;strong&gt;标准化 AI 与真实世界的交互方式&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5bd218b1f85d823bffcb86015c0c545c99e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;MCP 的核心架构包括三环：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Host 主机：用户与 AI 互动的应用环境，如 Claude Desktop、Cursor；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Client 客户端：充当 LLM 和 MCP server 之间的桥梁，将用户查询指令、可用工具列表、工具调用结果发给 LLM，将 LLM 需要使用的工具通过 server 执行调用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server 服务器：轻量级服务节点，给予 AI 访问特定资源、调用工具能力的权限&lt;/strong&gt;；目前已有数据库类（如 SQLite、supabase）、工具类（如飞书多维表格）、应用类（如高德地图）服务器。是 MCP 架构中最为关键的组件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-61c480bfeeaca3a1ea58453b8acc6a3cb64.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在开发中，我们可以接入以下几种 MCPServer&lt;/p&gt; 
&lt;p&gt;1. 实时搜索，baidu/google/github/微博等&lt;/p&gt; 
&lt;p&gt;2. 存储，mysql/redis 等&lt;/p&gt; 
&lt;p&gt;3. 工具，kubectl/yapi 等&lt;/p&gt; 
&lt;p&gt;用法一：我们接入百度搜索的 MCP&lt;/p&gt; 
&lt;p&gt;1. 搜索问题：在开发之余搜索一下，夜的命名术，是否完结。&lt;/p&gt; 
&lt;p&gt;2. 搜索知识点：在想知道 Go1.24 新特性时，通过 MCP 进行搜索，让 AI 进行总结。&lt;/p&gt; 
&lt;p&gt;3. 搜索用法：在想了解 Linux 的快捷命令时进行搜索。&lt;/p&gt; 
&lt;p&gt;以上这些场景，并非非 MCP 不可，非 AI IDE 不可，但是通过这样的方式，我们至少节省了切换到浏览器，搜索，自己总结结论，返回继续 Coding 这些步骤。&lt;/p&gt; 
&lt;p&gt;用法二：client 里直接进行多 client 操作&lt;/p&gt; 
&lt;p&gt;1. Redis 自然语言查询：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9b021b5b54f9cb7063c72f8966cb7960f0a.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2. MySQL 自然语言查询：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6a02d721c76876fa171df81368ea9c7bf0.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;3. GCP 自然语言查询：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9d3eb554b2f75250662d10f7287f5b516ec.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其他的 client（kubectl 等）我就不一一列举了，但是可以看到，当我们在我们的 IDE 内集成了各种各样的 client 后，开发效率能极大地提升。&lt;/p&gt; 
&lt;p&gt;当然，这里有两个关键点：&lt;/p&gt; 
&lt;p&gt;1. 接入 mcpserver 并不需要我们研究，&lt;em&gt;&lt;strong&gt;我们只要把 mcp server 的链接丢给 AI&lt;/strong&gt;&lt;/em&gt;，它自己就能开始接入&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 禁止在开发环境使用线上 client 账号密码&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-API&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;相信无论是前端还是后端开发，都或多或少地被接口文档折磨过。前端经常抱怨后端给的接口文档与实际情况不一致。后端又觉得编写及维护接口文档会耗费不少精力，经常来不及更新。&lt;/p&gt; 
&lt;p&gt;其实无论是前端调用后端，还是后端调用后端，都期望有一个好的接口文档。但是随着时间推移，版本迭代，接口文档往往很容易就跟不上代码了,更会出现之前的同学没有把接口文档交接清楚就离职，留下一个繁重复杂的项目，重新啃起来异常艰难，不亚于自己从头写一遍。&lt;/p&gt; 
&lt;span id="OSC_h4_16"&gt;&lt;/span&gt; 
&lt;h4&gt;痛点&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 重复劳动&lt;/strong&gt;&lt;/strong&gt;：每一个涉及到前后端的功能，研发都需要手动进行维护接口文档，在一些时候，接口最后和最开始的设定有可能大相径庭，每一次改动都是非常令人头疼的工作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 低效沟通&lt;/strong&gt;&lt;/strong&gt;：前后端在沟通接口后，再进行对应的代码开发，其实是一件&lt;strong&gt;&lt;strong&gt;重复的，可替代的，可节省&lt;/strong&gt;&lt;/strong&gt;的工作。&lt;/p&gt; 
&lt;p&gt;为了解决这些痛点，通过引入 AI 自动化功能，搭建&lt;strong&gt;&lt;strong&gt;API MCP Server&lt;/strong&gt;&lt;/strong&gt;，帮我们解决这些冗杂的工作，&lt;strong&gt;让研发人力更多的集中在核心业务代码的开发上&lt;/strong&gt;，提升代码开发效率、降低沟通成本。&lt;/p&gt; 
&lt;p&gt;这是我们一直畅想的场景，&lt;strong&gt;&lt;strong&gt;后端开发完代码 -&amp;gt; AI 推送接口文档 -&amp;gt; API 文档自动更新 -&amp;gt; AI 拉取接口文档 -&amp;gt; 前端生成代码&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;也就是前后端的研发同学，只关注业务功能的实现，而不需要关注这些接口对接的繁琐工作。&lt;/p&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;Better Thinking&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;这是我想补充的两个使用 AICoding 的思想，也是我使用下来的一个感悟。&lt;/p&gt; 
&lt;p&gt;一：&lt;em&gt;&lt;strong&gt;学会递归使用 AI&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;场景：在 IDE 内布置 MCP Server&lt;/p&gt; 
&lt;p&gt;通常的做法是：&lt;/p&gt; 
&lt;p&gt;1. 在 MCP Server 市场找到想用的 MCP Server&lt;/p&gt; 
&lt;p&gt;2. 把配置部署好&lt;/p&gt; 
&lt;p&gt;3. 开始调试，完成后投入使用&lt;/p&gt; 
&lt;p&gt;递归式使用做法：&lt;/p&gt; 
&lt;p&gt;1. 在 MCP Server 市场找到想用的 MCP Server&lt;/p&gt; 
&lt;p&gt;2. 把链接丢给 AI，让它自己安装（递归）&lt;/p&gt; 
&lt;p&gt;3. 安装完后让它自己修改 mcp.json 的配置（递归）&lt;/p&gt; 
&lt;p&gt;4. 修改完成后让它自己调通（递归）&lt;/p&gt; 
&lt;p&gt;更进一步我们还可以：&lt;/p&gt; 
&lt;p&gt;1. @Web 让 AI 找一个可用的 McpServer（递归）&lt;/p&gt; 
&lt;p&gt;2. ...（递归）&lt;/p&gt; 
&lt;p&gt;3. ...（递归）&lt;/p&gt; 
&lt;p&gt;4. ...（递归）&lt;/p&gt; 
&lt;p&gt;二：&lt;em&gt;&lt;strong&gt;把 AI 当成一个真正的工具&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;场景：写某篇文档的时候，我突然想要做一个 Gif 格式的图片示例。&lt;/p&gt; 
&lt;p&gt;已知：电脑支持录屏，但是我缺少视频转 Gif 格式的工具。&lt;/p&gt; 
&lt;p&gt;麻烦点：&lt;/p&gt; 
&lt;p&gt;1. 如果通过百度/Google 搜索网页在线工具，非常麻烦，还要付费。&lt;/p&gt; 
&lt;p&gt;2. 如果通过内部的视频裁剪服务，还需要起服务来处理。&lt;/p&gt; 
&lt;p&gt;3. 如果通过剪映这样的工具，那还要下载一个软件。&lt;/p&gt; 
&lt;p&gt;以上这些点，都不算困难，但都相对麻烦，&lt;strong&gt;&lt;em&gt;属于能做但是又要浪费一点精力&lt;/em&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;解决方案：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-243c673fa2ab4faf47acc4027d61529933e.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;理论上让 AI 写和让 GPT/Deepseek 写没什么区别，但是我们的操作步骤得到了以下简化：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6c74d08c893d911217d31f3e6c1e92711aa.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;也就是说，我们在遇到很多**&lt;em&gt;&lt;strong&gt;自己能做，但是又觉得麻烦，浪费精力的场景&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;以及&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;strong&gt;大部分的杂活&lt;/strong&gt;&lt;/em&gt;**，都可以第一时间 Ask Ourself，Can AI Do it？&lt;/p&gt; 
&lt;p&gt;包括但不限于：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;捞数据&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;写文档&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;找 bug&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;...&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;AI-Coding VS Original-Coding&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ebea7546f0be5316db168e3e362a4cd52a4.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_18"&gt;&lt;/span&gt; 
&lt;h1&gt;04 集成阶段&lt;/h1&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-CR&lt;/strong&gt;&lt;/h3&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;问题&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 时间压力&lt;/strong&gt;&lt;/strong&gt;：团队每周可能需要审查数十个 CR，高 T 同学需要审查的居多，每个 CR 的细节往往耗费大量时间。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 沟通低效&lt;/strong&gt;&lt;/strong&gt;：CR 评论描述不清晰，开发者需要来回沟通确认修改点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 重复劳动&lt;/strong&gt;&lt;/strong&gt;：相似的代码改动需要重复审查，难以专注关键问题。&lt;/p&gt; 
&lt;p&gt;为了解决这些痛点，通过引入 AI 自动化功能，提前规避一些基础问题，&lt;em&gt;&lt;strong&gt;让 CR 人力更多的集中在关键问题上&lt;/strong&gt;&lt;/em&gt;，提升代码审查效率、降低沟通成本。&lt;/p&gt; 
&lt;span id="OSC_h3_21"&gt;&lt;/span&gt; 
&lt;h3&gt;解决方案&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;工作流&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9dc56fede6b3b23156212ab86640c5460fc.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_22"&gt;&lt;/span&gt; 
&lt;h1&gt;05 运维阶段&lt;/h1&gt; 
&lt;span id="OSC_h4_23"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;AI-Develops&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;随着业务系统的复杂度不断增加，运维过程中产生的告警数量急剧增长，传统的人工处理方式已经无法满足快速响应的需求。&lt;/p&gt; 
&lt;p&gt;目前在我们来看，现有的运维体系存在了以下的弊端：&lt;/p&gt; 
&lt;p&gt;1. 告警存在非常厚的方向壁垒，不同方向的同学遇到另一个方向的告警时大都只能进行 Case 路由。&lt;/p&gt; 
&lt;p&gt;2. 告警存在非常厚的年限壁垒，团队不同年限的同学遇到 Case 的应对时间有可能天差地别。&lt;/p&gt; 
&lt;p&gt;一个点是否足够痛，决定了我们是都要优化。&lt;/p&gt; 
&lt;p&gt;在我们团队内，有丰富的 case 处理文档和记录，也有着应对问题经验非常丰富的同学，但是在值班同学遇到告警轰炸的时候，同样会焦头烂额。&lt;/p&gt; 
&lt;p&gt;回顾起告警处理的过程，其实大部分都是&lt;strong&gt;&lt;strong&gt;重复的，可替代的，可节省&lt;/strong&gt;&lt;/strong&gt;的工作，它们是有方法论的，并非遇到之后就手足无措。因此我们构建一个智能化的应急诊断系统，通过 AI 技术提升故障处理效率，减少平均故障修复时间 (MTTR)。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-abefe62efa9d85ddcf75055afebb1ab4847.jpg" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;在这种模式下，AI 可以自动捕捉消息，在遇到告警信息的时候自动分析给出结论，如果有 AI 无法解决的问题，才会轮到人工进行介入。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这种模式最大的优点在于：&lt;strong&gt;&lt;strong&gt;所有出现过的 Case/已有的文档&lt;/strong&gt;&lt;/strong&gt;都会沉淀为 AI 的记忆和知识库，从今往后只会有新增的 Case 需要人来解决，存量全都会被 AI 拦截，换而言之，&lt;em&gt;&lt;strong&gt;团队内多出了一个永远不会离开，且能够同时接受所有方向培养的 AI 运维人员&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;span id="OSC_h1_24"&gt;&lt;/span&gt; 
&lt;h1&gt;06 总结&lt;/h1&gt; 
&lt;p&gt;以上就是我们百度国际化广告团队的 AI 提效实践，也希望这篇文章能作为一个锚点，带动所有看到这篇文章的同学 review 自己所在团队的工作流程，共建更多的 AI 加持工作流。&lt;/p&gt; 
&lt;p&gt;就如我上面说的，其实 AI 的用法很简单，它就是我们的助手，假如我们的工作中真的存在一些&lt;strong&gt;&lt;strong&gt;重复的，可替代的，可节省工作&lt;/strong&gt;&lt;/strong&gt;，那不妨把这些工作交给 AI 试试。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18687336</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18687336</guid>
      <pubDate>Sun, 03 Aug 2025 06:34:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>腾讯 AI Lab 开源智能体框架 Cognitive Kernel-Pro</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;腾讯 AI Lab 推出了全新开源的智能体框架 ——Cognitive Kernel-Pro，旨在&lt;span&gt;最大&lt;/span&gt;限度地降低外部依赖，使更多研究人员和开发者能够轻松参与智能体的开发和训练。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-e9c42dbf8c0a6016e86a9cebb846fb609e5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cognitive Kernel-Pro 采用了多模块、层次化的设计，主要由主智能体和多个子智能体组成。主智能体负责任务分解和信息整合，而子智能体则专注于特定任务，如网页浏览和文件处理。这种模块化结构确保了各部分的独立性和扩展性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;为了提升复杂任务的处理效率，Cognitive Kernel-Pro 引入了 「进度状态」 机制，智能体可以记录已完成的步骤和待办任务。此外，框架通过简单的文本接口实现主智能体和子智能体之间的高效通信，便于协作与调试。同时，反思和投票机制的引入，进一步优化了智能体的任务完成质量，特别是在网页浏览等高随机性的任务中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在性能方面，Cognitive Kernel-Pro 在 GAIA 基准测试中表现出色，超越了其他开源框架 SmolAgents，接近那些依赖付费工具的智能体。这一成果得益于其创新的训练方法，涵盖网页导航、文件处理和推理等多个领域。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;除了强大的框架设计，腾讯 AI Lab 还提供了 Agent Foundation Model 的训练配方。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364792</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364792</guid>
      <pubDate>Sun, 03 Aug 2025 06:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软宣布 Windows 11 本地支持 OpenAI 开源模型 gpt-oss-20b</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微软宣布通过其&amp;nbsp;Windows AI Foundry&amp;nbsp;平台，正式向 Windows11 用户提供 OpenAI&amp;nbsp;最新发布的免费开源大模型&amp;nbsp;gpt-oss-20b。这意味着用户无需依赖云端，即可直接在本地电脑上调用强大的 AI 功能和各类热门开源模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="212" src="https://oscimg.oschina.net/oscnet/up-98dfb3a29f2c9673ea430dd0dfd9cc33c9d.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微软在博客中指出，gpt-oss-20b 是一款轻量且高效的模型，尤其擅长执行代码、调用外部工具等任务。它能在多种 Windows 硬件上高效运行，未来还将支持更多设备。即便在网络带宽受限的环境下，该模型也适合构建自主 AI 助手或将 AI 集成到日常工作流中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这款模型能在配备至少&amp;nbsp;16GB 显存的主流消费级 PC 或笔记本上运行。OpenAI 表示，gpt-oss-20b 经过高强度计算资源的强化学习训练，特别擅长处理「思维链式」任务，如调用工具进行网页搜索或执行代码。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;不过，作为 OpenAI 的「最小」开源模型，gpt-oss-20b 仅支持文本处理，无法生成图像或音频。OpenAI 同时也提醒，该模型的「幻觉」比例较高，在内部测试中，其回答中约有&amp;nbsp;53%&amp;nbsp;存在事实错误。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了 Windows11，微软表示未来计划将该模型引入&amp;nbsp;macOS&amp;nbsp;等更多平台。目前，gpt-oss-20b 已在微软的&amp;nbsp;Azure AI Foundry&amp;nbsp;和亚马逊的&amp;nbsp;AWS&amp;nbsp;平台上线，为云端开发者提供了更多选择。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364789</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364789</guid>
      <pubDate>Sun, 03 Aug 2025 05:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>又跑出一匹黑马！超级麦吉，一个开源的超级 AI Agent！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;最近，Agent 领域又跑出了一匹黑马！超级麦吉——一个开源的超级 AI Agent。&lt;/p&gt; 
&lt;p&gt;与市面上那些硬编码、预设流程、通过一次性附件交付产物的 AI 工具不同，超级麦吉具有突破性优势：实时文件管理、在线人机协同编辑、任务完全可控。&lt;/p&gt; 
&lt;p&gt;超级麦吉采用工作区 &amp;gt; 项目 &amp;gt; 话题的三层结构，每个话题都是一个独立的 AI 执行单元，可以并行运转。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;所以，你可以同时让&lt;span style="color:#3498db"&gt;超级麦吉&lt;/span&gt;帮你写 100 份报告、做 50 个方案、分析 20 个市场，&lt;span&gt;甚至一次性处理&amp;nbsp;1000&amp;nbsp;份简历筛选。也&lt;/span&gt;&lt;span&gt;可以随时调整、修改、回滚任何环节，通过持续与超级麦吉对话的方式，直至完成最终目标。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我浅浅试用了一下，让它帮我做一个网站，两三轮对话，前端页面完成度就很高了，设计审美也很在线。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1248" src="https://oscimg.oschina.net/oscnet/up-915531dcaf528a9c1bc111b9a4aee7094a9.png" width="900" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 生成的技术报告结构清晰，逻辑完整，还有丰富的图、表。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1782" src="https://oscimg.oschina.net/oscnet/up-82833df77f3d079522eef438e049462e334.png" width="1307" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;超级麦吉有网页版，也可以下载 Windows 版、maciOS 版、iOS 版、Android 版本。&lt;/p&gt; 
&lt;p&gt;这个超级 Agent 已经开源，GitHub star 数已经有 1.4K。 开源版本跟当前最新的产品还是有一些不同。不过超级麦吉的联创——陈曹奇昊公开解释过，超级麦吉的所有核心功能都是开源的，如果有差异也只是暂时的。因为目前工作量比较大，团队规模比较小，未能及时同步到开源版本。&lt;/p&gt; 
&lt;p&gt;8 月 12 日晚，我们开源中国（OSCHINA ）邀请到&lt;strong&gt;&lt;span style="color:#3498db"&gt;灯塔引擎 CTO、超级麦吉联创陈曹奇昊&lt;/span&gt;&lt;/strong&gt;做客《技术领航》直播栏目，跟&lt;strong&gt;大家分享：&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     超级麦吉和主流通用 Agent 产品有什么区别？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     项目模式设计详解，如何做到多任务并跑、产物无限迭代？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     揭秘主流 AI PPT 制作原理，超级麦吉助你职场汇报好看又有料 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     职场办公、个人生活、副业探索、知识积累，超级麦吉如何能够无所不能？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     演示：小工具开发、一口气做一百份调研报告 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     中国式 MCP 有趣玩法分享 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     超级麦吉未来还有哪些「大招」？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Q&amp;amp;A：直播答疑 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;微信扫码，预约直播：&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height="660" src="https://oscimg.oschina.net/oscnet/up-e9096d1fdeb8b839be2c4cdc92eb9a7726a.png" width="400" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;p&gt;对超级麦吉刚兴趣的朋友，可以访问以下地址：&lt;/p&gt; 
 &lt;p&gt;中国站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.letsmagic.cn" target="_blank"&gt;https://www.letsmagic.cn&lt;/a&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p style="color:#2a2d3e; margin-left:0px; margin-right:0px; text-align:start"&gt;国际站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.letsmagic.cn" target="_blank"&gt;https://www.letsmagic.ai&lt;/a&gt;&lt;/p&gt; 
  &lt;p style="color:#2a2d3e; margin-left:0px; margin-right:0px; text-align:start"&gt;GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdtyq%2Fmagic" target="_blank"&gt;https://github.com/dtyq/magic&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;还可以加入超级麦吉的交流群，一起聊聊用它做些什么有意思的事~&lt;/p&gt; 
  &lt;p&gt;&lt;img height="191" src="https://oscimg.oschina.net/oscnet/up-46c10a258bc90ff73c81ea07baf50c9248d.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   或者 OSC 直播交流群，可以经进来唠唠嗑，或者你有好的产品 / 项目，也欢迎推荐过来呀～ 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div style="text-align:center"&gt; 
    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-f4e3f0507c7b79ba06185e2b2d6da4cd412.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;陈曹奇昊是&amp;nbsp;PHP 语言官方团队成员、Swoole 协程网络引擎核心开发者、Swow 项目发起者，协程和异步网络编程领域专家，是多个知名开源项目的核心贡献者，有丰富的开源项目经验。此前，他在某大型零售企业担任技术负责人，具备大型企业技术实践经验。&lt;/p&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;&lt;img height="395" src="https://oscimg.oschina.net/oscnet/up-441276df82e6d018accbc3c8b47a5edb643.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;本次直播中，我们将有 5 轮抽奖，参与就有机会获得 OSC T 恤、马建仓蛇年公仔（限量版）、代码圣杯、马克杯、冰箱贴、前沿技术书籍等。立即扫码预约直播吧！&lt;/p&gt; 
  &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;hr&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技术领航》是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，基本上每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18687305</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18687305</guid>
      <pubDate>Sun, 03 Aug 2025 04:40:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Steam 7 月份调查显示 Linux 使用率接近 3%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;今年 2-6 月，Steam 在 Linux 上的市场份额分别为 1.45%、2.33%、2.27%、2.69% 以及 2.57%。目前，7 月份的数据也已发布，显示 Linux 游戏玩家数量创近期新高。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;调查结果显示，Linux 游戏市场份额健康增长 0.32%，达到 2.89%，这个百分比是近期的新高。虽然十年前 Steam 在 Linux 上推出初期的份额约为 3%，但从绝对值来看，这可能是调查以来 Linux 游戏人口数的最大值。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="163" src="https://oscimg.oschina.net/oscnet/up-fd2ea1a25e40200cd90e1245e40251b1bd8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，7 月份 macOS 的市场份额为 1.88%，Windows 的市场份额为 95.23%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-74ddf525ff9c96f683453cff5fe0b21aa8d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;总体而言，SteamOS Holo 作为 Steam Deck 的基础（Arch Linux 衍生）操作系统继续名列前茅。这在很大程度上要归功于 Steam Deck 采用了定制的 AMD APU，以及许多 Linux 游戏玩家和发烧友偏爱 AMD 的开源特性，AMD CPU 在 Linux 游戏玩家中的使用率一直徘徊在 68% 左右。在 Windows 下，AMD CPU 在 Steam 上的使用率约为 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="144" src="https://oscimg.oschina.net/oscnet/up-562e67f58ff3c652709be1cd3bda219182c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多详情可查看&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstore.steampowered.com%2Fhwsurvey%2FSteam-Hardware-Software-Survey-Welcome-to-Steam" target="_blank"&gt;SteamPowered.com&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364763/steam-survey-july-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364763/steam-survey-july-2025</guid>
      <pubDate>Sun, 03 Aug 2025 03:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元正式发布「AI 播客」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯混元正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fptzp9RC391boFvOVm6dpyw" target="_blank"&gt;发布 AI 播客功能&lt;/a&gt;，支持将文本、网页、文档一键转化为自然流畅的双人对谈式音频，它能把原本晦涩难啃的内容，变成一场有逻辑、有节奏的对话。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/110856_9lik_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;体验入口：使用电脑访问腾讯混元官网（https://hunyuan.tencent.com），点击首页对话框下方「AI 播客」 即可尝试。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据介绍，腾讯混元「AI 播客」支持将文本、网页链接或本地文档（涵盖 .pdf、.txt、.docx、.md 格式）一键转换为双人对话式的音频播客，旨在将静态文字内容转化为动态、自然的对话，采用一男一女双角色对谈模式，音色和语调接近真人。&lt;/p&gt; 
&lt;p&gt;目前，该功能已应用于腾讯旗下的知识库应用 ima 中。「腾讯新闻 AI 播客」也计划于 8 月底上线。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364759</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364759</guid>
      <pubDate>Sun, 03 Aug 2025 03:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>慢 SQL 优化实战：从一例线上慢 SQL 探究执行引擎工作过程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互联网服务器团队- Li Xin&lt;/p&gt; 
 &lt;p&gt;本文通过一个线上慢 SQL 案例，介绍了 Join 的两种算法和 Order by 的工作原理，并通过 Explain 和 Optimizer_trace 工具完整推演了慢 SQL 的执行过程。基于对原理和执行过程的分析，本文给出一种「引导执行引擎选择效率更高的算法」的方案，从而使查询性能得到大幅提升。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;1、线上慢 SQL 背景&lt;/h1&gt; 
&lt;p&gt;慢 SQL 会影响用户使用体验，降低数据库的整体性能，严重的甚至会导致服务器挂掉、整个系统瘫痪。笔者通过监控平台发现线上存在这样一条慢 SQL（原始 SQL 已脱敏，表结构出于简化的目的做了一定删减，实际执行耗时以文中提供数据为准），其执行耗时在分钟级。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;select&amp;nbsp;t1.*,t2.x&amp;nbsp;from&amp;nbsp;t_table1 t1 leftjoin t_table2 t2&amp;nbsp;on&amp;nbsp;t1.a = t2.a&amp;nbsp;orderby&amp;nbsp;t1.c desc;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;表结构如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CREATETABLE&amp;nbsp;`t_table1`&amp;nbsp;(
&amp;nbsp;&amp;nbsp;`id`&amp;nbsp;bigint(20) unsigned&amp;nbsp;NOTNULL&amp;nbsp;AUTO_INCREMENT&amp;nbsp;COMMENT&amp;nbsp;'主键',
&amp;nbsp;&amp;nbsp;`a`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`b`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`c`&amp;nbsp;varchar(20)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;PRIMARYKEY&amp;nbsp;(`id`),
&amp;nbsp;&amp;nbsp;KEY&amp;nbsp;`idx_a`&amp;nbsp;(`a`)
)&amp;nbsp;ENGINE=InnoDB&amp;nbsp;AUTO_INCREMENT=0DEFAULT&amp;nbsp;CHARSET=utf8mb4;

CREATETABLE&amp;nbsp;`t_table2`&amp;nbsp;(
&amp;nbsp;&amp;nbsp;`id`&amp;nbsp;bigint(20) unsigned&amp;nbsp;NOTNULL&amp;nbsp;AUTO_INCREMENT&amp;nbsp;COMMENT&amp;nbsp;'主键',
&amp;nbsp;&amp;nbsp;`a`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`x`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`y`&amp;nbsp;varchar(20)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;PRIMARYKEY&amp;nbsp;(`id`)
)&amp;nbsp;ENGINE=InnoDB&amp;nbsp;AUTO_INCREMENT=0DEFAULT&amp;nbsp;CHARSET=utf8mb4;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其他信息：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/b6/b6d3dd02b7c1dde85561715f07cbc8e5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;当发现慢 SQL 时，笔者的第一反应是使用 Explain 查看 SQL 的执行计划，结果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/d8/d80e469be4c5bf6a591e0f15e9ce7329.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过 Explain 初步分析：两张表均执行了全表扫描，结合两张表的数据规模分析全表扫描并非耗时达到分钟级的主要原因。另外执行计划 extra 种提示的 Using temporary; Using filesort; Using join buffer (Block Nested Loop) 又分别代表什么含义呢？&lt;/p&gt; 
&lt;h1&gt;2、原理探究&lt;/h1&gt; 
&lt;h2&gt;2.1 Join 算法原理&lt;/h2&gt; 
&lt;h3&gt;2.1.1 驱动表和被驱动表&lt;/h3&gt; 
&lt;p&gt;在 Join 语句中，执行引擎优先扫描的表被称为驱动表，另一张表被称为被驱动表。执行引擎在选择驱动表时，除了必须要遵守的特定语义外，最重要的考虑便是执行效率。&lt;/p&gt; 
&lt;p&gt;首先列举两种特定语义约束驱动表选取的&lt;strong&gt;场景&lt;/strong&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;**场景一：**Straight join 指定连接顺序，强制要求执行引擎优先扫描左侧的表。&lt;/p&gt; 
 &lt;p&gt;**场景二：**Left/Right [outer] join，方向连接的特点是反方向表中如果不存在关联的数据则填充 NULL 值，这一特性要求方向查询时优先扫描相同方向的表。倘若 where 条件中明确指明反方向表中的部分列非空，则驱动表的选择就不受此语义的限制，执行引擎会依据效率选取驱动表。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;当没有特定语义的约束时，执行引擎便会依据执行效率选取驱动表，如何判断哪张表作为驱动表的效率更高呢？下文会结合 Join 的两种算法更深入地探讨这个问题。&lt;/p&gt; 
&lt;h3&gt;2.1.2 Block Nested-Loop Join&lt;/h3&gt; 
&lt;p&gt;假设一个数据量为 m 行的驱动表与一个数据量为 n 行的被驱动表进行 join 查询。&lt;/p&gt; 
&lt;p&gt;最简单的一种算法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;从驱动表扫描一行数据；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;对被驱动表进行全表扫描，得到的结果依次与驱动表的数据进行 join 并把满足条件的数据加入结果集；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着扫描驱动表，每扫描一行数据，均重复执行一次步骤 2，直至驱动表的全部数据被扫描完毕。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;这种算法的磁盘扫描开销为 m*n，非常低效，MySQL 在实际中并未直接使用该算法，而是采用缓存的思想（分配一块 Join buffer）对该算法进行改进，并命名为 Block Nested-Loop join(BNL)。&lt;/p&gt; 
&lt;p&gt;BNL 的算法&lt;strong&gt;步骤&lt;/strong&gt;为：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;从驱动表一次扫描 K 条数据，并把数据缓存在 Join buffer；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;对被驱动表进行全表扫描，得到的结果依次与驱动表的 K 条数据进行 join 并把满足条件的数据加入结果集；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;清空 join_buffer；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着从驱动表再取出 K 条数据，重复步骤 2、3，直至扫描完驱动表的全部数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;上述算法中，驱动表分段取数的次数记为 l，整个算法的磁盘扫描开销为 m+ln。由于分段的次数与驱动表的数据成正相关，所以公式可以记为 m+λmn，λ的取值范围为 (0,1)。&lt;/p&gt; 
&lt;p&gt;当两张表的行数（m、n 大小）固定的情况下，m 对结果的影响更大，m 越小整体扫描的代价越小，所以执行引擎优先选择数据量更小的表作为驱动表 (符合「小表驱动大表」的说法)。&lt;/p&gt; 
&lt;h3&gt;2.1.3 Index Nested-Loop Join&lt;/h3&gt; 
&lt;p&gt;BNL 算法使用了 Join buffer 结构，虽然有可能通过减少重复扫描来降低磁盘扫描开销，然而驱动表分段扫描的次数过多依然可能会导致查询的低效。索引是 MySQL 查询提效的重要结构，当被驱动表的关联键存在索引时，MySQL 会使用 Index Nested-Loop Join（NLJ）算法。&lt;/p&gt; 
&lt;p&gt;该算法的步骤为：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;从驱动表扫描一行数据；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;使用驱动表的关联键搜索被驱动表的索引树，通过被驱动表的索引结构找到被驱动表的主键，再通过主键回表查询出被驱动表的关联数据（暂不考虑覆盖索引的情况）；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着扫描驱动表，每扫描一行数据，均重复执行一次步骤 2，直至驱动表的全部数据被扫描完毕。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;每次搜索一棵树的复杂度近似为 log2 n，上述过程在被驱动表扫描一行数据的时间复杂度是 2log2 n，算法的整体复杂度为 m+2mlog2 n，在该算法中，依旧是 m 对结果的影响更大，m 越小整体扫描的代价越小，所以执行引擎总是选择数据量更小的表作为驱动表 (符合「小表驱动大表」的说法)。&lt;/p&gt; 
&lt;h2&gt;2.2 Order by 算法原理&lt;/h2&gt; 
&lt;h4&gt;2.2.1 全字段排序&lt;/h4&gt; 
&lt;p&gt;MySQL 会为每个线程分配一块内存（Sort buffer）用于排序，当 Sort buffer 的空间不足时（通过系统参数 sort_buffer_size 设置 Sort buffer 的大小），执行引擎不得不开辟磁盘临时文件用于排序，此时排序的性能也会大幅降低。&lt;/p&gt; 
&lt;p&gt;全字段排序是将查询需要的所有字段进行暂存，并按照排序字段进行排序，并将排序后的结果集直接返回。&lt;/p&gt; 
&lt;h3&gt;2.2.2 Rowid 排序&lt;/h3&gt; 
&lt;p&gt;若要查询的数据单行占用空间较大，Sort buffer 中可以容纳的排序行数将会减少，此时使用磁盘临时文件进行排序的概率将会增大。为了提高排序性能，执行引擎提供一种只存储排序字段的算法，称为 Rowid 排序算法。&lt;/p&gt; 
&lt;p&gt;该算法的&lt;strong&gt;步骤&lt;/strong&gt;为：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;将参与排序的字段和主键进行临时存储；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;按照排序字段进行排序，得到有序的主键；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;根据有序的主键进行回表，按顺序将所有要查询的数据返回。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Rowid 排序在单行查询数据较大时可以通过节省临时排序空间从而达到降低排序开销的目的，然而该算法的代价是会增加磁盘扫描的次数（主键回表），所以是否选择使用该算法需要根据实际情况进行取舍（通过系统参数 max_length_for_sort_data 设置）。&lt;/p&gt; 
&lt;h1&gt;3、调优过程&lt;/h1&gt; 
&lt;h2&gt;3.1 执行过程分析&lt;/h2&gt; 
&lt;p&gt;了解了 Join 和 Order by 的工作原理，我们推测执行计划的大致&lt;strong&gt;过程&lt;/strong&gt;为：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;t_table_1 与 t_table_2 进行 Join 查询，使用了 BNL 算法（Using join buffer (Block Nested Loop)）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;将 Join 的结果暂存临时表（Using temporary）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;对临时表中的数据进行排序后返回（Using filesort）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;为了佐证笔者的推测以及了解每一步的开销情况，Optimizer_trace 命令可以提供更多执行过程细节。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_execution_plans":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"`t_table1` `t1`",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"best_access_path":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_access_paths":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_to_scan":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"access_type":&amp;nbsp;"scan",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"resulting_rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost":&amp;nbsp;615,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"use_tmp_table":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_access_paths */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* best_access_path */,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rest_of_plan":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"`t_table2` `t2`",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"best_access_path":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_access_paths":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_to_scan":&amp;nbsp;69882,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"access_type":&amp;nbsp;"scan",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"using_join_cache":&amp;nbsp;true,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"buffers_needed":&amp;nbsp;5,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"resulting_rows":&amp;nbsp;69882,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost":&amp;nbsp;4.19e7,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_access_paths */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* best_access_path */,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_for_plan":&amp;nbsp;2.1e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost_for_plan":&amp;nbsp;4.19e7,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_cost":&amp;nbsp;2.1e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"new_cost_for_plan":&amp;nbsp;2.52e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* rest_of_plan */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_execution_plans */
&amp;nbsp; &amp;nbsp;}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上图展示的即为执行引擎预估的执行计划，从 Optimizer_trace 的输出结果中可以佐证上述对于执行过程的推测。另外我们可以得到执行代价的结果为：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;t_table1 的扫描行数为 3000，代价为 615;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;t_table2 的扫描行数为 69882，由于 BNL 算法 t_table2 会被多次全表扫描，整体代价为 4.19e7;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;对 Join 结果进行排序的开销为 2.1e8。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;从执行引擎预估的执行计划可以看出执行引擎认为排序的开销最大，另外由于使用 BNL 算法会导致被驱动表执行多次全表扫描，其执行代价仅次于排序。然而预估的执行计划并不代表真正的执行结果，下面展示 Optimizer_trace 命令对于真实执行结果部分参数：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"join_execution":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"select#":&amp;nbsp;1,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"steps":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"creating_tmp_table":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"tmp_table_info":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"intermediate_tmp_table",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"row_length":&amp;nbsp;655,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"key_length":&amp;nbsp;0,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"unique_constraint":&amp;nbsp;false,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"location":&amp;nbsp;"memory (heap)",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"row_limit_estimate":&amp;nbsp;25614
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* tmp_table_info */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* creating_tmp_table */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;},
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"filesort_summary":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"examined_rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"number_of_tmp_files":&amp;nbsp;0,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_buffer_size":&amp;nbsp;60200,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_mode":&amp;nbsp;"&amp;lt;sort_key, rowid&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* filesort_summary */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* steps */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* join_execution */
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;从执行结果参数来看：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;执行引擎使用临时表保存 Join 的结果，且临时表是一张内存表。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;参与排序的数据行数为 3000 行，没有使用磁盘临时文件进行排序，排序算法选择的是 Rowid 排序。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;综合执行引擎的预估的执行计划和真实的执行结果参数可以得出，执行引擎预估最大的执行开销为排序，但实际上排序并未使用到磁盘临时文件，且 Rowid 排序的回表操作是在内存中进行的（在内存临时表中进行回表），3000 条数据的内存排序开销是极快的，所以真实的最大开销是 BNL 算法导致的对被驱动表多次进行全表扫描的开销。&lt;/p&gt; 
&lt;h2&gt;3.2 最终的优化&lt;/h2&gt; 
&lt;p&gt;对于 BNL 算法，可以通过在被驱动表添加索引使其转化为 NLJ 算法来进行优化（此处注意一些索引失效的场景，笔者在实际调优中遇到了字符集不同导致的索引失效场景）。在 t_table2 表添加索引后，观察一周内的 SQL 监控如下，可以看到 SQL 最大响应时间不超过 20ms，执行效率得到了大幅提升。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/47/475398e816de211f42468bc73336a5fa.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;4、总结&lt;/h1&gt; 
&lt;p&gt;本文完整的介绍了一个 SQL 调优案例，通过这个案例可以归纳出 SQL 调优的基本思想。首先，需要了解 SQL 语句中的关键字（Join、Order by...）的基本工作原理，并辅助一些执行过程数据（Explain、Optimizer_trace），通过实验验证猜想，最终达成调优的目的。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18687291</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18687291</guid>
      <pubDate>Sun, 03 Aug 2025 02:46:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>阿里通义上架 Qwen-Flash API，1M 超长上下文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义千问团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVSQEC5IANVzlef9FiaiaUw" target="_blank"&gt;宣布&lt;/a&gt;其 Qwen 家族多款模型 API 上架，分别为 Qwen-Flash、Qwen3-Coder-Flash、Qwen-Plus，并且全部支持 1M 超长上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103102_OBd5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103109_o4F8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103133_eSWW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1438" src="https://static.oschina.net/uploads/space/2025/0807/103203_busb_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103225_G56r_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方表示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen-Flash(qwen-flash-2025-07-28)：相较于 qwen-turbo-2025-04-28，Qwen-Flash「通用能力」大幅度提升；同时「推理能力」「中英文长尾知识能力」「Agent 能力」均获得提升。&lt;/li&gt; 
 &lt;li&gt;Qwen3-Coder-Flash(qwen3-coder-flash-2025-07-28)：继承 Qwen3-Coder-Plus 的 coding agent 能力，支持多轮工具交互；Agent 能力增强，工具调用更稳定。&lt;/li&gt; 
 &lt;li&gt;Qwen-Plus(qwen-plus-2025-07-28(qwen-plus-latest))：中英文的「通用能力」大幅提升；「逻辑能力」更强了；RAG、工具调用等 Agent 能力更强。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;三款模型 API 均已上线阿里云百炼平台，并为每位开发者提供每款模型 100w 免费 tokens。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364747</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364747</guid>
      <pubDate>Sun, 03 Aug 2025 02:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：赛博占卜</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2118</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2118</guid>
      <pubDate>Sun, 03 Aug 2025 02:26:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 将于 8 月 7 日举行直播活动，有望发布 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1953139020231569685" target="_blank"&gt;发布预告信息&lt;/a&gt;，将于太平洋时间周四上午 10 点举行网络直播，届时将有望发布传闻已久的 GPT-5 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="354" src="https://static.oschina.net/uploads/space/2025/0807/101913_nIwa_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;公告内容仅为「&lt;em&gt;LIVE5TREAM THURSDAY 10AM PT&lt;/em&gt;」，其简洁和神秘的风格引发了业界的广泛关注和猜测。许多分析人士和社区成员推测，此次活动可能会发布备受期待的 GPT-5 模型。&lt;/p&gt; 
&lt;p&gt;在几乎同一时间，网络上突然爆出了 GPT-5 的三个版本型号以及图表信息：共拥有 GPT-5、GPT-5 mini、GPT-5 nano。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/102026_2Z7k_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据目前消息来看，GPT-5 的最大亮点并非空泛的跑分提升，而是在多模态、软件工程和 AI 智能体（Agent）这三个极具实用价值的领域，展现了相当大的性能提升。&lt;/p&gt; 
&lt;p&gt;对于 GPT-5 的表现，OpenAI CEO Sam Altman 也曾多次公开表示「十分强大」，甚至形容自己在面对新模型时，有一种「自己相对 AI 毫无用处」的感觉。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364739</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364739</guid>
      <pubDate>Sun, 03 Aug 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AMD、高通宣布旗下硬件支持 gpt-oss 系列开放模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AMD 与高通近日联合宣布，旗下硬件正式支持 OpenAI 推出的 gpt-oss 系列开放推理模型。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 新发布的 gpt-oss 系列包括两个模型：gpt-oss-20b 和 gpt-oss-120b。前者可以在配备 16GB 内存的设备上流畅运行，而后者则能在单个 80GB 显卡上高效执行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AMD 表示，锐龙 AI Max+395 处理器成为全球&lt;span&gt;首款&lt;/span&gt;能够运行 gpt-oss-120b 模型的消费级 AI PC 处理器。为了适应这一模型，AMD 采用了 GGML 框架和 MXFP4 格式，使得 gpt-oss-120b 在使用大约 61GB 显存时得以顺畅运行。此外，"Strix Halo" 平台通过 128GB 的统一内存，能够将 96GB 分配给 GPU，从而满足运行需求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="284" src="https://oscimg.oschina.net/oscnet/up-e6d0339194cefafe23caeacc321abc53252.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在性能方面，锐龙 AI Max+395 在运行 gpt-oss-120b 时可以实现每秒 30 个 Token 的输出速度，并且支持 MCP 模型上下文协议。这意味着用户在处理复杂任务时可以享受到更快的响应速度和更高的效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;高通则表示，经过早期测试，gpt-oss-20b 模型在其骁龙平台上展现出色的思维链推理能力。开发者可以通过 Hugging Face 和 Ollama 等平台，在搭载骁龙芯片的设备上轻松访问这一模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364737</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364737</guid>
      <pubDate>Sun, 03 Aug 2025 02:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义超顶小模型「Qwen3-4B」发布更新，手机也能轻松跑</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义千问团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcXAWq0Qkrdh2ag9BcnACPQ" target="_blank"&gt;发布&lt;/a&gt;了更小尺寸新模型——Qwen3-4B-Instruct-2507 和 Qwen3-4B-Thinking-2507 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101110_FtLJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新模型性能有了大幅提升。在非推理领域，Qwen3-4B-Instruct-2507 全面超越了闭源的 GPT4.1-Nano；在推理领域，Qwen3-4B-Thinking-2507 甚至可以媲美中等规模的 Qwen3-30B-A3B（thinking）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101118_RpzT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101129_LX7V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101151_mrbH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;「2507」版本的 Qwen3-4B 模型，体积小，性能强，对手机等端侧硬件部署尤为友好，目前新模型已在魔搭社区、Hugging Face 正式开源。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;以下为模型核心亮点：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、Qwen3-4B-Instruct-2507&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🌟通用能力显著提升，更全能的端侧利器&lt;br&gt; Qwen3-4B-Instruct-2507 的通用能力均大幅提升，超越了商业闭源的小尺寸模型 GPT-4.1-nano，与中等规模的 Qwen3-30B-A3B（non-thinking）性能接近。&lt;/p&gt; 
&lt;p&gt;🌟掌握更多语言和长尾知识，回答更合你意&lt;br&gt; 新模型覆盖了更多语言的长尾知识，在主观和开放性任务中增强了人类偏好对齐，可提供更符合人们需求的答复。&lt;/p&gt; 
&lt;p&gt;🌟上下文理解扩展至 256K，小模型也能处理长文本&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、 Qwen3-4B-Thinking-2507&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🌟推理能力大幅增强，AIME25 高达 81.3 分&lt;br&gt; Qwen3-4B-Thinking-2507 的推理表现可媲美中等模型 Qwen3-30B-Thinking，特别是在聚焦数学能力的&amp;nbsp;AIME25 测评中，以 4B 参数量斩获惊人的 81.3 分的好成绩！&lt;/p&gt; 
&lt;p&gt;🌟通用能力显著提升，Agent 分数爆表，相关评测均超越了更大尺寸的 Qwen3-30B-Thinking 模型。&lt;/p&gt; 
&lt;p&gt;🌟 256K tokens 上下文的理解能力，支持更复杂的文档分析、长篇内容生成、跨段落推理等场景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364735</guid>
      <pubDate>Sun, 03 Aug 2025 02:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌推出新编程工具 Jules</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;谷歌宣布正式推出一款名为 Jules 的全新编程工具。该工具支持与 GitHub 深度集成，具备异步处理代码修复与更新任务的能力，有助于开发者提升编程效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据介绍，Jules 可直接将代码库克隆至云端虚拟机运行环境中，实现对 GitHub 仓库中的任务进行自动化处理。开发者无需手动干预，即可在后台完成大量重复性编程操作，从而节省时间、提高工作产出。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="238" src="https://oscimg.oschina.net/oscnet/up-cc1e37ad346861f92473d5cf76ccb3c474c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该工具于今年 5 月开启公开测试，期间吸引了大批开发者参与。据谷歌披露，在测试阶段，全球已有成千上万名开发者使用 Jules 处理了数以万计的编程任务，并累计提交超过 14 万项代码改进建议，显示出该工具在实际应用中的广泛认可度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据用户反馈，谷歌近期为 Jules 增加了多项实用功能，包括复用既有设置以加快任务执行速度、整合 GitHub 问题管理系统、以及支持图文等多种形式的输入内容。目前，该工具的用户群体主要包括专业开发者和技术爱好者。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-36839410d19ac85f97ffb0c2507b041ea6e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在定价方面，谷歌为 Jules 提供结构化的服务方案。免费用户每日最多可执行 15 项任务，同时最多可并发运行 3 个任务。付费方案则包含在 Google Pro 和 Ultra 套餐中，分别定价为每月 19.99 美元和 124.99 美元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364729</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364729</guid>
      <pubDate>Sun, 03 Aug 2025 02:04:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>预装开源操作系统 openFyde 的 XpressReal T3 开发板上市，售价 458 元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Fyde 与 Radxa、Realtek 合作推出的 XpressReal T3 开发板现已在国内上市，该板预装 openFyde 系统，同时也原生支持 Debian Linux、安卓等，定价为 458 元。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1200" src="https://static.oschina.net/uploads/space/2025/0806/191846_lEaM_2720166.png" width="2070" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://madeforfydeos.cn/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，该开发板整体尺寸 96mm x 40mm，匹配 4GB LPDDR4 RAM 和 32GB eMMC，搭载 Realtek RTD1619B 芯片，该芯片具体规格如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU：四核 ARM Cortex-A55，主频高达 2.0GHz。&lt;/li&gt; 
 &lt;li&gt;GPU：ARM Mali-G57 MP1，支持 Vulkan 1.1、OpenGL ES 3.2 和 OpenCL 2.0。&lt;/li&gt; 
 &lt;li&gt;NPU：具备 1.6 TOPs 的算力，并支持 INT4 / INT8 / INT16、FP16 / BF16、TF32 等多种精度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;扩展方面，这款开发板提供 1 个 M.2 NVMe SSD 插槽（支持 PCIe Gen2 x1 通道和 2280 规格）、1 个全尺寸 SD 卡槽（符合 SD 3.0 标准）、1 个 HDMI 2.1a 接口、1 个 USB-C 3.2 Gen 1 接口、1 个 USB-A 2.0 接口、1 个千兆 RJ45 网口，同时板载 40-Pin GPIO 扩展接口。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0806/192329_3LuD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多介绍查看：&lt;em&gt;https://mp.weixin.qq.com/s/hS-GRO9-y_KFvZjeBWzfIQ&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364658</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364658</guid>
      <pubDate>Sat, 02 Aug 2025 11:24:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>JetBrains 推出基于 AI 的无代码平台 Kineto</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;JetBrains 推出基于 AI 的无代码平台 Kineto，旨在帮助用户快速进行 Web 开发，无需编写任何代码即可创建 Web 应用程序和网站。&lt;/p&gt; 
&lt;p&gt;该平台旨在帮助用户快速构建小型的、单一用途的应用程序，例如植物追踪器、健身应用或博客等。Kineto 的目标是让有创意的用户能够专注于想法本身，而非编码实现。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0806/190713_SJog_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据 JetBrains 的说法，用户不需要解释每个按钮或者提供广泛的说明，因为 Kineto 会直观地为用户提供必要的组件，它只要求一些基本的设计选择，例如模板、字体和配色方案，以便在符合用户偏好的基础上开始构建。&lt;/p&gt; 
&lt;p&gt;提交选择后平台就可以制作功能齐全的原型，整个过程需要 20 分钟左右，然后用户就可以调整结果以添加新功能、更改设计或者直接通过自然语言对话生成插图，最后可以直接通过 Kineto 进行在线部署。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0806/190800_uVV9_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，该平台的早期访问计划（EAP）已开放候补名单注册：&lt;em&gt;https://kineto.dev/&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364654</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364654</guid>
      <pubDate>Sat, 02 Aug 2025 11:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
