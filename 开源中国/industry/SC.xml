<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 20 Jun 2025 07:43:53 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>宇树科技确认：近期已完成 C 轮融资交割</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;市场消息称，宇树科技已完成了始于去年 9 月的 C 轮融资交割，由中国移动旗下基金、腾讯、锦秋、阿里、蚂蚁、吉利资本共同领投，绝大部分老股东跟投。对此，证券时报记者向宇树科技核实。宇树科技方面向记者表示，「我们最近确实完成了 C 轮融资，但其他信息暂时不清楚」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;天眼查显示，自 2016 年创立至今，宇树科技已完成 9 轮融资。最近的一轮为始于去年 9 月的 C 轮融资，彼时公司估值为 80 亿元。但在过去的半年中，宇树科技屡屡「出圈」，成为人形机器人领域最受关注的公司之一。据最新消息，宇树科技的投前估值目前已超过 100 亿元人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「宇树的估值，我觉得还是保守了。」前不久，在提到宇树科技的最新估值或达到百亿元级别时，一名宇树科技的早期投资人向证券时报记者表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="306" src="https://oscimg.oschina.net/oscnet/up-307142b03f6f36a82cf894dca3e3bdd0862.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;完成 C 轮融资交割后，宇树科技的下一步动作会否是上市？这一直是备受市场关注的焦点。今年 5 月 29 日，证券时报记者从知情人士处获取一份《公司名称变更函》。宇树科技向合作伙伴表示，因公司发展需要，杭州宇树科技有限公司即日起名称变更为杭州宇树科技股份有限公司。国家企业信用信息公示系统也显示，宇树科技已从有限责任公司变更为股份有限公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;有市场人士分析，这一变更可等同于完成股改，或许是为 IPO 上市铺路。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 4 月，香港特区行政长官李家超在杭州与「六小龙」企业代表进行了交流，并到访了宇树科技。彼时，宇树科技创始人王兴兴表示，宇树科技在香港有业务，各方面合作机会也很多。至于未来会否在香港上市，王兴兴称，有可能，但不确定。李家超鼓励宇树科技来港拓展业务，并表示香港特区政府亦可提供所需支援。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与此同时，近日 A 股市场释放的一系列提升制度包容性和适应性的信号也让市场振奋。6 月 18 日，中国证监会主席吴清在 2025 陆家嘴论坛上指出，重启未盈利企业适用科创板第五套标准上市。同日，中国证监会发布《关于在科创板设置科创成长层，增强制度包容性适应性的意见》，明确提出扩大第五套标准适用范围，支持人工智能、商业航天、低空经济等更多前沿科技领域企业适用。一系列利好信号，为像宇树科技一样的前沿科技企业提供了更广阔的发展空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不过，与大部分同行仍然处于亏损状态相比，宇树科技在商业化领域的进展也较快。今年 3 月，宇树科技早期投资人、SevenUp Capital 创始人赵楠在接受媒体采访时透露，自 2020 年以来，宇树科技的财务报表每年都保持盈利状态。宇树科技也证实了该消息。数据显示，宇树科技人形机器人出货量位居全球前列，四足机器狗全球市场占有率更是超过 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;近日，王兴兴还与公司的投资方之一，吉利控股集团董事长李书福进行了一场以「AI 时代的人才培养」为主题的对话。王兴兴回忆创业经历时表示，早年创业时机器人还属于相对冷门的赛道，但他选择这一行业并非因为市场规模、盈利前景或未来热度。最大的原因还是从小就喜欢动手做东西，希望能做一些改变世界的产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对于未来，王兴兴表示，希望能看到未来整个行业发展方向，做更好的机器人产品，更好推动整个机器人 AI 的技术进步。希望未来能让机器人去干活，更好地解放生产力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356437</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356437</guid>
      <pubDate>Fri, 20 Jun 2025 07:27:50 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Windows 11 市占率仅比 Windows 10 低 1%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软自 2021 年 10 月推出 Windows 11 以来，就一直在不断鼓励用户升级，但 Windows 10 的市场份额一直高于 Windows 11。不过随着 Windows 10 即将停止支持，Windows 11 的市场份额终于有望实现超越。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b7ef309abb2c8b41fbb02c7ac6fe93264a1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据 StatCounter 的最新数据，&lt;strong&gt;Windows 10 的市场份额为 48.92%，而 Windows 11 的市场份额已经达到了 47.73%，两者差距仅为 1.19%&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这意味着在未来几个月内，Windows 11 的市场份额有望超过 Windows 10，实现所谓的「黄金交叉」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3d78ab74367857f983b0a30f19c666044bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从数据来看，Windows 11 的市场份额在过去一个月中提升幅度创下新高，这可能与 Windows 10 即将停止支持有关。&lt;/p&gt; 
&lt;p&gt;微软近期也通过多种方式提醒用户尽快升级，以避免安全风险，许多用户可能选择购买新电脑或从 Windows 10 升级到 Windows 11。&lt;/p&gt; 
&lt;p&gt;Windows 11 市场份额增长最快的地区是亚洲，这个月差距已经缩小到不到 3%，相比之下，美国、日本、英国等国家的 Windows 11 份额早在几个月前就已经超过了 Windows 10。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f816ff7d41f357ec1431b4b54bd88f86e50.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这也显示出亚洲用户在操作系统升级方面相对保守，直到最后几个月才开始大规模升级。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356419</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356419</guid>
      <pubDate>Fri, 20 Jun 2025 06:58:50 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Andrej Karpathy 提出「软件 3.0 时代」，称自然语言正在取代传统代码</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;日前，OpenAI 联合创始人、特斯拉前 AI 负责人 Andrej Karpathy 在 Y Combinator 的 AI 创业学院活动上，进行了个人演讲。&lt;/p&gt; 
&lt;p&gt;&lt;img height="556" src="https://static.oschina.net/uploads/space/2025/0620/142721_2fd9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次演讲中，Karpathy 提出了「软件 3.0 时代」这一概念，&lt;strong&gt;他认为自然语言正在取代传统代码，而大型语言模型（LLM）则成为新的「万能计算机」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/142813_2Ldh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Karpathy 指出，软件 3.0 时代下，自然语言（如英语）将作为「编程接口」，直接给大语言模型下达命令，让模型自己完成剩下的所有工作。Karpathy 直言，这并非一次工具迭代，而是「根本性变革」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="2260" src="https://static.oschina.net/uploads/space/2025/0620/142754_fhxp_2720166.png" width="4090" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/142833_1Cbg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时，Karpathy 还提出：大语言模型兼具公共设施、晶圆厂、操作系统这三种行业的属性。如「晶圆厂」：训练大模型的巨额算力与研发壁垒，使得少数实验室成为新的「芯片制造商」。&lt;/p&gt; 
&lt;p&gt;另外，Karpathy 还展望了 AI Agent（智能体）的未来。他表示，Agent 既非人类也非传统程序，而是新的「数字信息消费者与操作者」。其进一步解释称，「因为 Agent 需要我们重新设计文档、接口乃至网络协议，为它们提供可读、可执行的‘原生’内容。」&lt;/p&gt; 
&lt;p&gt;原视频：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DLCEmiRjPEtQ" target="_blank"&gt;https://www.youtube.com/watch?v=LCEmiRjPEtQ&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356402</guid>
      <pubDate>Sun, 11 May 2025 06:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>张一鸣重回公司一线？知情人士：每月参与覆盘和讨论会</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息称，字节跳动创始人张一鸣目前主要办公地已从新加坡转到北京，从去年下半年开始，他每月会召集一次字节核心管理层和 AI 项目负责人的覆盘和讨论会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fm.thepaper.cn%2Fbaijiahao_31015094" target="_blank"&gt;澎湃新闻&lt;/a&gt;记者表示，张一鸣一直很关注 AI 业务。目前张一鸣经常往返北京和新加坡，从去年下半年开始，他每月会参加一次 seed 核心技术团队的覆盘和讨论会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="279" src="https://oscimg.oschina.net/oscnet/up-ed5561a0fb8783c67b902102fad0b52aeea.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官网介绍显示，字节跳动 Seed 团队成立于 2023 年，致力于寻找通用智能的新方法,追求智能上限。团队研究方向涵盖 LLM、语音、视觉、世界模型、基础架构、AI Infra、下一代 AI 交互等，在中国、新加坡、美国等地设有实验室和岗位。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356387</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356387</guid>
      <pubDate>Sun, 11 May 2025 05:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智元机器人在上海成立云程科技公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;天眼查资料显示，上海智元云程科技有限公司于近日成立，是一家以从事软件和信息技术服务业为主的企业。法定代表人为邓泰华，注册资本 100 万人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="266" src="https://oscimg.oschina.net/oscnet/up-ef9f219581dfc75802ad4f47bb51e48b5ee.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司经营范围包括信息技术咨询服务、会议及展览服务、市场营销策划、企业形象策划等。股东信息显示，该公司由上海智元新创技术有限公司全资持股。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356358</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356358</guid>
      <pubDate>Sun, 11 May 2025 03:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub Copilot Spaces 支持将 Issues 和 Pull Requests 作为上下文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;GitHub Copilot Spaces 现已支持将 issues 和 pull requests 作为上下文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fchangelog%2F2025-06-19-copilot-spaces-now-support-issues-and-pull-requests-public-preview%2F" target="_blank"&gt;目前处于公开预览阶段&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;用户在 Copilot Spaces 中创建空间时，只需粘贴 issue 或 pull request 的 URL，即可自动拉取其最新的标题、正文、评论、状态甚至标签作为上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fe648c5ab0d622f51ad0305a0bb2aecc6a2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一功能旨在帮助开发者更高效地进行工作。例如，在规划新功能时，可以添加工作项、功能规范和预期修改的代码，让 Copilot 协助规划方法、搭建初步更改或识别风险；在修复 bug 时，可以添加 issue 和可疑代码，让 Copilot 帮助查找问题行并提出修复建议；在跟踪工作和分享更新时，可以将新功能的所有工作项添加到空间，并与团队成员共享以回答进度和障碍问题。Copilot Spaces 可在 github.com/copilot/spaces 上供所有 Copilot 用户使用。&lt;/p&gt; 
&lt;p&gt;对于商业或企业客户，组织管理员需要选择启用 Copilot 预览功能才能使用此特性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356357</guid>
      <pubDate>Sun, 11 May 2025 03:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>用 AI 会让人变笨，过度依赖 AI 或导致损坏批判性思维与记忆力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;一项由麻省理工学院媒体实验室的 Nataliya Kosmyna 及其团队主导的&lt;span&gt;最新&lt;/span&gt;研究，深入探讨了在论文写作任务中，使用大型语言模型（LLM）如 OpenAI 的 ChatGPT 可能带来的认知成本。该研究发现，尽管 LLM 产品为人类和企业带来了诸多便利，但其广泛应用却可能导致大脑积累「认知负债」，长远来看甚至会削弱个体的学习技能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-9da4a2d7ee235a5a7411c434fda354048e0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该研究招募了 54 名参与者，并将其分为三组:LLM 组（仅使用 ChatGPT）、搜索引擎组 (使用传统搜索引擎，禁用 LLM) 和纯脑力组 (不使用任何工具)。研究共进行了四次会话，其中在第四次会话中，LLM 组的参与者被要求不使用任何工具 (被称为「LLM 转纯脑力组」)，而纯脑力组的参与者则开始使用 LLM(被称为「纯脑力转 LLM 组」)。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究团队通过脑电图 (EEG) 记录了参与者的大脑活动，以评估其认知投入和负荷，并深入理解论文写作任务期间的神经激活模式。此外，研究还进行了自然语言处理 (NLP) 分析，并在每次会话后对参与者进行了访谈，同时邀请人类教师和 AI 评判员对论文进行打分。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-a56dd98b0353f8374fe7d0874c8ffcf7a89.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心发现：大脑连接性减弱，记忆和所有权受损&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究结果提供了确凿证据，表明 LLM、搜索引擎和纯脑力组的神经网络连接模式存在显著差异，反映了不同的认知策略。大脑连接性与外部支持的程度呈系统性下降：纯脑力组表现出&lt;span&gt;最强&lt;/span&gt;、范围最广的连接网络，搜索引擎组居中，而 LLM 辅助则引发了最弱的整体耦合。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特别值得关注的是，在第四次会话中，「LLM 转纯脑力组」的参与者表现出较弱的神经连接性，以及阿尔法（alpha）和贝塔 (beta) 网络的投入不足。阿尔法波段连接性通常与内部注意力、语义处理和创造性构思相关。贝塔波段则与主动认知处理、专注注意力和感觉运动整合相关。这些结果表明，过去依赖 LLM 的使用者，在脱离工具后，其大脑在内容规划和生成方面的神经活动有所减少，这与认知卸载的报告相符，即依赖 AI 系统可能导致被动方法和批判性思维能力的减弱。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在记忆方面，LLM 组的参与者在引用自己刚写完的论文时表现出明显障碍，甚至无法正确引用。这直接映射到 LLM 组较低的低频连接性，特别是与情景记忆巩固和语义编码密切相关的西塔（theta）和阿尔法波段。这表明 LLM 用户可能绕过了深层记忆编码过程，被动地整合了工具生成的内容，而没有将其内化到记忆网络中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，LLM 组对自己论文的所有权感知度普遍较低，而搜索引擎组拥有较强的所有权感，但仍低于纯脑力组。这种行为上的差异与神经连接性模式的变化相吻合，凸显了 LLM 使用对认知能动性的潜在影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;认知负债的积累&lt;/strong&gt;：&lt;strong&gt;效率与深度学习的权衡&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究指出，尽管 LLM 在初期提供了显著的效率优势并降低了即时认知负荷，但随着时间的推移，这种便利可能以牺牲深度学习成果为代价。报告强调了「认知负债」的概念:重复依赖外部系统（如 LLM）取代了独立思考所需的努力认知过程，短期内延迟了脑力投入，但长期却导致批判性探究能力下降、更容易被操纵以及创造力减退。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;纯脑力组的参与者，尽管面临更高的认知负荷，却展现出更强的记忆力、更高的语义准确性和对其作品更坚定的主人翁意识。而「纯脑力转 LLM 组」在&lt;span&gt;首次&lt;/span&gt;使用 AI 辅助重写论文时，大脑连接性显著增加，这可能反映了将 AI 建议与现有知识整合时的认知整合需求，暗示了 AI 工具引入的时机可能对神经整合产生积极影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;对教育环境的深远影响与未来展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究团队认为，这些发现对教育领域具有深远意义。过度依赖 AI 工具可能无意中阻碍深层认知处理、知识保留以及对书面材料的真实投入。如果用户过度依赖 AI 工具，他们可能会获得表面的流畅度，但却无法内化知识或对其产生所有权感。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该研究建议，教育干预应考虑将 AI 工具辅助与「无工具」学习阶段相结合，以优化即时技能转移和长期神经发展。在学习的早期阶段，全面的神经参与对于发展强大的写作网络至关重要;而在后续练习阶段，有选择性的 AI 支持可以减少无关的认知负荷，从而提高效率，同时不损害已建立的网络。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人员强调，随着 AI 生成内容日益充斥数据集，以及人类思维与生成式 AI 之间的界限变得模糊，未来研究应优先收集不借助 LLM 协助的写作样本，以发展能够识别作者个人风格的「指纹」表示。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最终，这项研究呼吁在 LLM 整合到教育和信息情境中时，必须谨慎权衡其对认知发展、批判性思维和智力独立性的潜在影响。LLM 虽然能减少回答问题的摩擦，但这种便利性也带来了认知成本，削弱了用户批判性评估 LLM 输出的意愿。这预示着「回音室」效应正在演变，通过算法策划内容来塑造用户接触信息的方式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;（研究论文标题为《Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task》，主要作者为麻省理工学院媒体实验室的 Nataliya Kosmyna 等。）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356351</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356351</guid>
      <pubDate>Sun, 11 May 2025 03:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>警惕日志采集失败的 6 大经典雷区：从本地管理反模式到 LoongCollector 标准实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：余韬（讯飞）&lt;/p&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;观察系统的运行状态，排查疑难问题，日志作为一种历史悠久的可观测手段，始终扮演着不可替代的角色。&lt;/p&gt; 
&lt;p&gt;科学的本地日志管理策略，不仅能在本地保留更完整历史记录，最小化性能开销，并且能为日志采集和后续分析提供便利。然而在实际运维中，我们时常遇到反例，这类管理缺陷带来的采集现在对于主流采集工具（LoongCollector（原 iLogtail）、Filebeat、Fluentbit、Vector、OpenTelemetry Collector）均无法完美解决，唯有从源头解决才是最佳实践。&lt;/p&gt; 
&lt;p&gt;我们将沉淀自阿里云云原生可观测团队的经验总结成本文，希望给大家一些启发，一起让日志更好地为大家服务。&lt;/p&gt; 
&lt;h2&gt;反模式&lt;/h2&gt; 
&lt;h3&gt;1. 使用 copy truncate 模式轮转日志，因两个动作非原子并创建新文件，可能导致日志丢失或重复采集&lt;/h3&gt; 
&lt;p&gt;使用 logrotate 的 copy truncate 模式轮转日志的原理是先复制原日志文件，然后截断原文件。这种方式存在以下问题：&lt;/p&gt; 
&lt;p&gt;a. copy 动作产生的新文件可能被当作新的内容重复采集。因为文件系统的 inode 变化，采集器可能无法正确识别这是轮转后的旧文件。&lt;/p&gt; 
&lt;p&gt;b. copy 和 truncate 之间产生的日志可能丢失。在这两个操作之间有一个时间窗口，此时写入的内容既不在复制的文件中，又会被截断操作清除。&lt;/p&gt; 
&lt;p&gt;c. truncate 操作可能导致文件大小变小和头部内容变化，缩小文件或改变文件头部签名会导致采集器误判为新文件，造成重复采集。&lt;/p&gt; 
&lt;p&gt;因此，copy truncate 模式可能导致日志重复采集、内容丢失或不一致的问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-11c600c00de52c3f883da0edfddcbf352fa.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推荐使用 create 模式进行日志轮转，即创建新文件并重命名旧文件，这样可以保证文件的完整性和连续性。如果无法避免，请在配置采集配置时使用精确的路径名。&lt;/p&gt; 
&lt;h3&gt;2. 使用 NAS、OSS 作为日志存储，因元信息不一致和 ls 性能低，可能导致日志采集截断或停止&lt;/h3&gt; 
&lt;p&gt;网络附加存储 (NAS) 通常采用基于最终一致性的一致性模型，这在分布式系统中是常见的设计。在实时采集场景下，这可能导致以下问题：&lt;/p&gt; 
&lt;p&gt;a. 文件元信息与实际内容不一致。由于最终一致性，文件大小等元数据可能先于实际内容更新。&lt;/p&gt; 
&lt;p&gt;b. 读取到文件空洞。当元信息显示文件已增大，但实际内容尚未同步时，读取操作可能返回 \0 字符（文件空洞）。&lt;/p&gt; 
&lt;p&gt;c. 数据延迟。写入操作的结果可能不会立即对读取操作可见，导致采集延迟。&lt;/p&gt; 
&lt;p&gt;d. 数据丢失。由于 NAS 不支持 inotify 并且 list 性能低下，因此文件可能无法被发现，导致数据丢失。&lt;/p&gt; 
&lt;p&gt;这些问题可能导致采集到的数据与最终内容不一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f58f5b993aee7f7f62ca6fba5fe9e6ac750.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;建议使用 EBS，自建机器使用本地磁盘，以保证日志读写的效率和一致性。如无法避免，请在消费端做好异常日志的兼容逻辑。&lt;/p&gt; 
&lt;h3&gt;3. 多进程写日志，因数据互相覆盖，可能导致采集到的数据不完整&lt;/h3&gt; 
&lt;p&gt;多进程并发写入同一日志文件是一种常见但不推荐的做法，它可能导致以下问题：&lt;/p&gt; 
&lt;p&gt;a. 文件内容交叉。多个进程的写入可能相互交叉，导致日志条目混乱。&lt;/p&gt; 
&lt;p&gt;b. 采集不完整。当文件发生写入事件时，采集器开始采集数据。但如果采集过程中其他进程继续写入，这些新写入的内容可能被跳过。&lt;/p&gt; 
&lt;p&gt;c. 文件锁争用。多进程写入可能导致文件锁争用，影响写入性能和可靠性。&lt;/p&gt; 
&lt;p&gt;这种模式可能导致采集到的数据不完整且与文件的最终内容不一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fc14b0f44891b38e616836bdef9df5c90d2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推荐多进程写入各自不同文件，这样可以保证日志的完整性和顺序性。如无法避免，请在消费端做好异常日志的兼容逻辑。&lt;/p&gt; 
&lt;h3&gt;4. 创建文件空洞释放日志文件空间，因改变文件签名和内容，可能导致日志重复采集或数据丢失&lt;/h3&gt; 
&lt;p&gt;通过在文件头部创建空洞来释放日志文件空间是一种存在风险的做法，原因如下：&lt;/p&gt; 
&lt;p&gt;a. 文件签名改变。LoongCollector（原 iLogtail）为避免 inode 复用漏采数据，额外使用文件头部的内容作为文件唯一性的判断依据。创建空洞可能改变这个签名，导致采集器误判为新文件。&lt;/p&gt; 
&lt;p&gt;b. 数据完整性问题。创建空洞实际上是用 \0 字符替换了原有内容，可能导致重要的历史日志丢失。&lt;/p&gt; 
&lt;p&gt;c. 文件系统碎片化。频繁创建空洞可能导致文件系统碎片化，影响读写性能。&lt;/p&gt; 
&lt;p&gt;这种做法可能导致数据重复采集和历史数据丢失。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6c6407d85a79a192a0b95f05fca565f3e16.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推荐使用标准的日志轮转机制来管理日志文件大小，如使用 logrotate 工具定期轮转日志文件，这样可以保证日志的完整性和可追溯性。如无法避免，建议使用 &lt;code&gt;fallocate &lt;/code&gt;而非 &lt;code&gt;truncate 或 dd，&lt;/code&gt;并在消费端做好异常日志的兼容逻辑。&lt;/p&gt; 
&lt;h3&gt;5. 频繁覆盖写文件，因文件内容频繁变化，可能导致采集数据不完整或不一致&lt;/h3&gt; 
&lt;p&gt;频繁覆盖写整个日志文件是一种不安全的日志管理方式，可能导致以下问题：&lt;/p&gt; 
&lt;p&gt;a. 文件元信息与内容不一致。在覆盖过程中，文件大小等元信息可能先于实际内容更新，导致采集器读取到不完整或不一致的内容。&lt;/p&gt; 
&lt;p&gt;b. 数据丢失风险。如果在日志采集过程中发生覆盖写入，可能导致采集读取到的数据内容错乱或丢失。&lt;/p&gt; 
&lt;p&gt;c. 历史数据难以保留。频繁覆盖会导致无法保留历史日志，不利于问题追溯和分析。&lt;/p&gt; 
&lt;p&gt;这种做法可能导致采集到的内容与文件最终内容不一致，或完全丢失文件内容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-13e7a8b3340e98dc878a5e6f8087c47f0eb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;建议采用追加写入（append）的方式记录日志，并配合日志轮转机制管理文件大小。如无法避免，请在消费端做好异常日志的兼容逻辑。&lt;/p&gt; 
&lt;h3&gt;6. 使用 vim 编辑文件保存，因创建新文件替换原文件，可能导致日志重复采集&lt;/h3&gt; 
&lt;p&gt;使用 vim 编辑并保存文件时，vim 的保存机制可能导致以下问题：&lt;/p&gt; 
&lt;p&gt;a. inode 变化。vim 创建新文件替换原文件时，新文件的 inode 与原文件不同，可能导致采集器误判为新文件。&lt;/p&gt; 
&lt;p&gt;b. 文件签名改变。新文件的头部内容可能与原文件不同，改变了文件签名，导致采集器无法正确识别。&lt;/p&gt; 
&lt;p&gt;c. 文件内容丢失。当 vim 替换文件时，写入程序可能没有切换到新保存日志文件，可能导致日志内容丢失。&lt;/p&gt; 
&lt;p&gt;这种编辑方式可能导致日志重复采集或数据丢失。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-312ad3a220f60d82ea0e47d533d32de2372.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如仅需查看日志，建议使用 less、grep 等只读工具。如无法避免，请在消费端做好去重和异常处理的逻辑。&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;日志是系统运行的"黑匣子"，其管理质量直接影响故障排查效率与系统可靠性。通过规避本文提到的反模式，遵循使用日志库轮转、本地盘写入、单线程追加等最佳实践，可显著降低日志采集风险，提升可观测性能。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18627746</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18627746</guid>
      <pubDate>Sun, 11 May 2025 03:19:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>昆仑万维开源代码 Agent 模型 Skywork-SWE-32B</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;昆仑万维开源了其专门为软件工程（SWE）任务设计的代码代理模型 Skywork-SWE-32B。&lt;/p&gt; 
&lt;p&gt;据介绍，昆仑万维团队通过构建超过 1 万个可验证的 GitHub 仓库任务实例，打造出目前最大规模的可验证 GitHub 仓库级代码修复的数据集，并系统性验证了大模型在软件工程任务上的数据缩放定律（Scaling Law）。&lt;/p&gt; 
&lt;p&gt;Skywork-SWE-32B 模型在 SWE-bench Verified 基准上取得 38.0% pass@1 准确率，刷新 Qwen2.5-Coder-32B 系列模型在 OpenHands 代码框架下的最佳成绩。进一步引入测试时扩展技术后，模型表现提升至 47.0% 的准确率，不仅超越了现有参数规模在 32B 以下的开源模型，也显著效缩小了与闭源模型之间的性能差距。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-75700273fe37027abd1178c6a983f991074.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45145852d765d18d59adfdb2f0f701193c5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过结合测试时缩放技术（Test-Time Scaling），Skywork-SWE-32B 的性能进一步提升至 47.0% 的准确率，超越了 32B 参数以下模型的现有 SOTA 结果。&lt;/p&gt; 
&lt;p&gt;昆仑万维还明确展示了 LLM 软件工程能力的数据缩放定律现象，在收集了 8209 条训练轨迹后仍未出现饱和迹象。此外，昆仑万维引入了一种高效自动化的 SWE 数据收集流程，并创建了 Skywork-SWE 数据集，该数据集具有大规模、高质量和全面的可执行运行时环境。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FSkywork%2FSkywork-SWE-32B" target="_blank"&gt;https://huggingface.co/Skywork/Skywork-SWE-32B&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356330/skywork-swe-32b</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356330/skywork-swe-32b</guid>
      <pubDate>Sun, 11 May 2025 02:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 智能体对话存在低俗擦边内容，筑梦岛 APP 被约谈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;网信上海微信公众号&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX9cFX9Eaw0BLbMdxV9GbKg" target="_blank"&gt;发文&lt;/a&gt;称，近期有媒体报道，筑梦岛 APP 等 AI 聊天软件存在虚拟角色互动生成低俗内容等问题，经核实，该平台 AI 智能体内容生成环节存在低俗擦边等违规内容，危害未成年人身心健康。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;6 月 19 日上午，上海市网信办依法约谈筑梦岛 APP 运营企业主要负责人，要求平台立即整改，健全 AI 生成合成内容审核机制，提升技术把关能力，加强涉未成年人不良内容的整治清理，切实落实未成年人网络保护义务。企业负责人表示，将按照约谈要求，对照问题举一反三、全面整改。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="310" src="https://oscimg.oschina.net/oscnet/up-a021104c6777b288b3b3b3b2eb09dbff5e9.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上海市网信办相关负责人指出，AI 技术应用的规范发展事关广大网民的切身利益。依据《未成年人网络保护条例》《生成式人工智能服务管理暂行办法》等相关法规，互联网平台应当主动履行主体责任，平衡好技术创新与内容合规之间的关系，切实防范 AI 技术滥用风险，保护未成年人合法权益，为用户营造风清气正的网络空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据国家网信办统一部署，上海组织开展的「清朗・整治 AI 技术滥用」专项行动当前已进入第二阶段。上海市网信办聚焦利用 AI 技术制作发布谣言、不实信息、色情低俗内容、假冒他人、从事网络水军活动等突出问题，指导督促网站平台、APP 运营企业集中清理相关违法不良信息，处置违规账号、MCN 机构。对屡教不改、问题严重的企业，上海市网信办将依法予以处罚，并对典型案例进行媒体曝光。欢迎广大网民积极参与，通过以下渠道据实提供举报线索，共同营造清朗网络生态。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356329</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356329</guid>
      <pubDate>Sun, 11 May 2025 02:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>无需邀请码，Manus AI 推出 Windows 桌面应用程序</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;Manus AI 宣布，其备受瞩目的 Windows 桌面应用程序正式登陆 Microsoft Store，为 Windows 用户带来无缝的智能自动化体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Manus AI 的 Windows 桌面应用程序继承了其云端服务的核心优势，通过多代理架构和先进的自主任务处理能力，为用户提供从数据分析到代码生成的全面支持。与传统的 AI 助手不同，Manus AI 不仅能提供建议，还能自主规划并执行复杂任务，例如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;智能任务管理：用户只需输入模糊的需求，如「分析市场数据」或「规划旅行行程」，应用便能自动分解任务、搜索信息并生成完整结果，如 Excel 报表或交互式网站。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;本地化性能优化：Windows 应用利用本地计算资源，提供更快的响应速度和更低的延迟，同时支持离线任务处理（需预配置）。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;无缝集成：应用与 Windows 生态深度整合，支持浏览器自动化、文件处理及第三方工具调用，适配办公、开发和创意等多种场景。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="529" src="https://oscimg.oschina.net/oscnet/up-9181760d369a202b7816fd8a4b8e95b481d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据 Microsoft Store 的介绍，安装该应用需 Windows7 及以上系统，至少 2GB 内存，管理员权限，以及&lt;span&gt;最新&lt;/span&gt;的图形驱动程序，确保流畅运行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Manus AI Windows 应用保留了其标志性的「Manus’s Computer」侧边栏功能，允许用户实时观察 AI 的执行过程，如打开浏览器、填写表单或编写代码。用户甚至可以通过回放功能查看任务的每一步操作，极大地提升了透明度和可控性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，应用提供免费每日任务（300 积分）和一次性 1000 积分奖励，让新用户能够快速上手体验。官方强调，应用目前无需邀请码即可下载，彻底消除了此前云端服务的访问限制。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;与此同时，Manus AI 与 Microsoft Azure AI Foundry 的合作进一步增强了其技术生态。据官方透露，未来可能通过 Windows API 的开放性，将 Manus AI 打造为系统级调度助手，为用户提供更深度的操作系统集成体验。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管 Windows 应用的发布广受好评，但部分用户反馈指出，应用在处理复杂多模态任务（如视频生成）时可能存在性能瓶颈，且当前缺少语音输入功能。Manus AI 官方表示，将持续优化应用性能，并计划引入更多多模态功能，如实时图像和视频处理，以满足多样化需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356325</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356325</guid>
      <pubDate>Sun, 11 May 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克驳斥 xAI 巨额亏损传闻：每月烧钱 10 亿美元纯属无稽之谈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有媒体报道称，科技巨头埃隆・马斯克创办的人工智能初创公司 xAI 每月烧钱高达 10 亿美元，这一说法引发了广泛关注。消息称，xAI 在构建先进的 AI 模型方面的成本远远超过其收入增长，公司的资金需求愈加迫切。对此，马斯克进行了强烈反驳，称这些报道 「纯属胡说八道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-34a4735e7445256b266cb4625e29a62693a.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 自 2023 年成立以来，正积极寻求通过债务和股权融资来填补资金缺口，目标是融资 93 亿美元。尽管如此，马斯克合并了 xAI 与社交媒体平台 X，令合并后的新公司的估值达 1130 亿美元，其中 xAI 的估值为 800 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据相关人士透露，xAI 的支出速度在整个 AI 行业中显得尤为显著。公司预计在未来三个月内将花费超过一半的融资金额，而全年亏损预计达到 130 亿美元。相比之下，竞争对手 OpenAI 预计在 2025 年的收入将达到 127 亿美元，而 xAI 在同年仅预计收入 5 亿美元，明年才有可能突破 20 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;马斯克的巨大个人魅力和资源，使得 xAI 有理由保持乐观。他曾在特斯拉和 SpaceX 的早期阶段也经历了类似的巨额亏损，然而这些项目最终都取得了成功。马斯克相信，xAI 将在 2027 年实现盈利，尽管当前仍需与时间赛跑，以应对巨额支出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 计划利用与 X 平台的整合，利用其庞大的数据档案来训练 AI 模型，从而降低昂贵的数据费用。虽然目前 xAI 正在进行大规模的资金筹集，但公司对于未来的发展前景充满信心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356227</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356227</guid>
      <pubDate>Sat, 10 May 2025 10:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Boot 启动优化实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网服务器团队- Liu Di&lt;/p&gt; 
 &lt;p&gt;本文系统性分析并优化了一个 Spring Boot 项目启动耗时高达 280 秒的问题。通过识别瓶颈、优化分库分表加载逻辑、异步初始化耗时任务等手段，最终将启动耗时缩短至 159 秒，提升近 50%。文章涵盖启动流程分析、性能热点识别、异步初始化设计等关键技术细节，适用于大型 Spring Boot 项目的性能优化参考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;文章太长？1 分钟看图抓住核心观点👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//de4a19ad8ae5ee03f930e1ffa71b9716.gif" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、前言&lt;/h1&gt; 
&lt;p&gt;随着业务的发展，笔者项目对应的 Spring Boot 工程的依赖越来越多。随着依赖数量的增长，Spring 容器需要加载更多组件、解析复杂依赖并执行自动装配，导致项目启动时间显著增长。在日常开发或测试过程中，一旦因为配置变更或者其他热部署不生效的变更时，项目重启就需要等待很长的时间影响代码的交付。加快 Spring 项目的启动可以更好的投入项目中，提升开发效率。&lt;/p&gt; 
&lt;p&gt;整体环境介绍：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Spring 版本：4.3.22&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Spring Boot 版本：1.5.19&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU：i5-9500&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内存：24GB&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化前启动耗时：280 秒&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、Spring Boot 项目启动流程介绍&lt;/h1&gt; 
&lt;p&gt;Spring Boot 项目主要启动流程都在 org.spring-&lt;/p&gt; 
&lt;p&gt;framework.boot.SpringApplication#run(java.lang.String...) 方法中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public ConfigurableApplicationContext run(String... args) {
    StopWatch stopWatch = new StopWatch();
    stopWatch.start();
    // Spring 上下文
    ConfigurableApplicationContext context = null;
    FailureAnalyzers analyzers = null;
    configureHeadlessProperty();
    // 初始化 SpringApplicationRunListener 监听器
    SpringApplicationRunListeners listeners = getRunListeners(args);
    listeners.starting();
    try {
        ApplicationArguments applicationArguments = new DefaultApplicationArguments(
                args);
        // 环境准备
        ConfigurableEnvironment environment = prepareEnvironment(listeners,
                applicationArguments);
         // 打印 banner
        Banner printedBanner = printBanner(environment);
        // 创建上下文
        context = createApplicationContext();
        analyzers = new FailureAnalyzers(context);
        // 容器初始化
        prepareContext(context, environment, listeners, applicationArguments,
                printedBanner);
        // 刷新容器内容
        refreshContext(context);
        afterRefresh(context, applicationArguments);
        // 结束监听广播
        listeners.finished(context, null);
        stopWatch.stop();
        if (this.logStartupInfo) {
            new StartupInfoLogger(this.mainApplicationClass)
                    .logStarted(getApplicationLog(), stopWatch);
        }
        return context;
    } catch (Throwable ex) {
        handleRunFailure(context, listeners, analyzers, ex);
        throw new IllegalStateException(ex);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到在启动流程中，监听器应用在了应用的多个生命周期中。并且 Spring Boot 中也预留了针对 listener 的扩展点。我们可以借此实现一个自己的扩展点去监听 Spring Boot 的每个阶段的启动耗时，实现如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Slf4j
public class MySpringApplicationRunListener implements SpringApplicationRunListener{
    private Long startTime;
    public MySpringApplicationRunListener(SpringApplication application, String[] args){
    }
    @Override
    public void starting(){
        startTime = System.currentTimeMillis();
        log.info("MySpringListener 启动开始 {}", LocalTime.now());
    }
    @Override
    public void environmentPrepared(ConfigurableEnvironment environment){
        log.info("MySpringListener 环境准备，准备耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextPrepared(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文准备，耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextLoaded(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文载入，耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
   @Override
   public void finished(ConfigurableApplicationContext context, Throwable exception){
        log.info("MySpringListener 结束，耗时：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接着还需要在 classpath/META-INF 目录下新建 spring.factories 文件，并添加如下文件内容：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;org.springframework.boot.SpringApplicationRunListener=com.vivo.internet.gameactivity.api.web.MySpringApplicationRunListener
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;至此，借助 Listener 机制，我们能够追踪 Spring Boot 启动各阶段的耗时分布，为后续性能优化提供数据支撑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e19075cd485d32e7d5029945fd7ba604.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;contextLoaded 事件是在 run 方法中的 prepareContext() 结束时调用的，因此 contextLoaded 事件和 finished 事件之间仅存在两个语句：refreshContext(context) 和 afterRefresh&lt;/p&gt; 
&lt;p&gt;(context,applicationArguements) 消耗了 285 秒的时间，调试一下就能发现主要耗时在 refreshContext() 中。&lt;/p&gt; 
&lt;h1&gt;三、AbstractApplicationContext#refresh&lt;/h1&gt; 
&lt;p&gt;refreshContext() 最终调用到 org.spring-framework.context.support.AbstractApplicationContext#refresh 方法中，这个方法主要是 beanFactory 的预准备、对 beanFactory 完成创建并进行后置处理、向容器添加 bean 并且给 bean 添加属性、实例化所有 bean。通过调试发现，finishBeanFactoryInitialization(beanFactory) 方法耗时最久。该方法负责实例化容器中所有的单例 Bean，是启动性能的关键影响点。&lt;/p&gt; 
&lt;h1&gt;四、找出实例化耗时的 Bean&lt;/h1&gt; 
&lt;p&gt;Spring Boot 也是利用的 Spring 的加载流程。在 Spring 中可以实现 InstantiationAwareBeanPost-&lt;/p&gt; 
&lt;p&gt;Processor 接口去在 Bean 的实例化和初始化的过程中加入扩展点。因此我们可以实现该接口并添加自己的扩展点找到处理耗时的 Bean。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class TimeCostCalBeanPostProcessor implements InstantiationAwareBeanPostProcessor {
    private Map&amp;lt;String, Long&amp;gt; costMap = Maps.newConcurrentMap();

    @Override
    public Object postProcessBeforeInstantiation(Class&amp;lt;?&amp;gt; beanClass, String beanName) throws BeansException {
        if (!costMap.containsKey(beanName)) {
            costMap.put(beanName, System.currentTimeMillis());
        }
        return null;
    }
    @Override
    public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {
        return true;
    }
    @Override
    public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException {
        return pvs;
    }
    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        return bean;
    }
    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
         if (costMap.containsKey(beanName)) {
            Long start = costMap.get(beanName);
            long cost = System.currentTimeMillis() - start;
            // 只打印耗时长的 bean
             if (cost &amp;gt; 5000) {
                System.out.println("bean: " + beanName + "\ttime: " + cost + "ms");
            }
        }
         return bean;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;具体原理就是在 Bean 开始实例化之前记录时间，在 Bean 初始化完成后记录结束时间，打印实例化到初始化的时间差获得 Bean 的加载总体耗时。结果如图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//28a73a7adfed28c5eff40855c8260121.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到有许多耗时在 10 秒以上的类，接下来可以针对性的做优化。值得注意的是，统计方式为单点耗时计算，未考虑依赖链上下文对整体加载顺序的影响，实际优化还需结合依赖关系分析。&lt;/p&gt; 
&lt;h1&gt;五、singletonDataSource&lt;/h1&gt; 
&lt;pre&gt;&lt;code&gt;@Bean(name = "singletonDataSource")
public DataSource singletonDataSource(DefaultDataSourceWrapper dataSourceWrapper) throws SQLException {
    //先初始化连接
    dataSourceWrapper.getMaster().init();
    //构建分库分表数据源
    String dataSource0 = "ds0";
    Map&amp;lt;String, DataSource&amp;gt; dataSourceMap = new HashMap&amp;lt;&amp;gt;();
    dataSourceMap.put(dataSource0, dataSourceWrapper.getMaster());
    //分库分表数据源
    DataSource shardingDataSource = ShardingDataSourceFactory.createDataSource
    (dataSourceMap,shardingRuleConfiguration, prop);
    return shardingDataSource;    
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;singletonDataSource 是一个分库分表的数据源，连接池采用的是 Druid，分库分表组件采用的是公司内部优化后的中间件。通过简单调试代码发现，整个 Bean 耗时的过程发生在 createDataSource 方法，该方法中会调用 createMetaData 方法去获取数据表的元数据，最终运行到 loadDefaultTables 方法。该方法如下图，会遍历数据库中所有的表。因此数据库中表越多，整体就越耗时。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//05283b802a6c9c0a6c8653f9a7f080cd.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;笔者的测试环境数据库中有很多的分表，这些分表为了和线上保持一致，分表的数量都和线上是一样的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//eee1a3f0f0dd73861b2894776a40850b.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此在测试环境启动时，为了加载这些分表会更加的耗时。可通过将分表数量配置化，使测试环境在不影响功能验证的前提下减少分表数量，从而加快启动速度。&lt;/p&gt; 
&lt;h1&gt;六、初始化异步&lt;/h1&gt; 
&lt;p&gt;activityServiceImpl 启动中，主要会进行活动信息的查询初始化，这是一个耗时的操作。类似同样的操作在工程的其他类中也存在。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class ActivityServiceImpl implements ActivityService, InitializingBean{
     // 省略无关代码
     @Override
     public void afterPropertiesSet() throws Exception {
        initActivity();
    }
     // 省略无关代码
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以通过将 afterPropertiesSet() 异步化的方式加速项目的启动。&lt;/p&gt; 
&lt;p&gt;观察 Spring 源码可以注意到 afterPropertiesSet 方法是在 AbstractAutowireCapableBeanFactory#&lt;/p&gt; 
&lt;p&gt;invokeInitMethods 中调用的。在这个方法中，不光处理了 afterPropertiesSet 方法，也处理了 init-method。&lt;/p&gt; 
&lt;p&gt;因此我们可以写一个自己的 BeanFactory 继承 AbstractAutowireCapableBeanFactory，将 invokeInitMethods 方法进行异步化重写。考虑到 AbstractAutowireCapableBeanFactory 是个抽象类，有额外的抽象方法需要实现，因此继承该抽象类的子类 DefaultListableBeanFactory。具体实现代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitListableBeanFactory extends DefaultListableBeanFactory{
     public AsyncInitBeanFactory(ConfigurableListableBeanFactory beanFactory){
         super(beanFactory);
    }
     @Override
     protected void invokeInitMethods(String beanName, Object bean, RootBeanDefinition mbd)throws Throwable {
        if (beanName.equals("activityServiceImpl")) {
            AsyncTaskExecutor.submitTask(() -&amp;gt; {
                try {
                      super.invokeInitMethods(beanName, bean, mbd);
                } catch (Throwable throwable) {
                    throwable.printStackTrace();
                }
            });
        } else {
              super.invokeInitMethods(beanName, bean, mbd);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;又因为 Spring 在 refreshContext() 方法之前的 prepareContext() 发放中针对 initialize 方法提供了接口扩展 (applyInitializers())。因此我们可以通过实现该接口并将我们的新的 BeanFactory 通过反射的方式更新到 Spring 的初始化流程之前。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public interface ApplicationContextInitializer&amp;lt;C extends ConfigurableApplicationContext&amp;gt; {
     /**
     * Initialize the given application context.
     * @param applicationContext the application to configure
     */
    void initialize(C applicationContext);

}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;改造后的代码如下，新增 AsyncAccelerate-&lt;/p&gt; 
&lt;p&gt;Initializer 类实现 ApplicationContextInitializer 接口：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncBeanFactoryInitializer implements ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt; {
    @SneakyThrows
    @Override
    public void initialize(ConfigurableApplicationContext applicationContext){
        if (applicationContext instanceof GenericApplicationContext) {
            AsyncInitListableBeanFactory beanFactory = new AsyncInitListableBeanFactory(applicationContext.getBeanFactory());
            Field field = GenericApplicationContext.class.getDeclaredField("beanFactory");
            field.setAccessible(true);
            field.set(applicationContext, beanFactory);
        }
    }
}
public class AsyncBeanInitExecutor{
    private static final int CPU_COUNT = Runtime.getRuntime().availableProcessors();
    private static final AtomicReference&amp;lt;ThreadPoolExecutor&amp;gt; THREAD_POOL_REF = new AtomicReference&amp;lt;&amp;gt;();
    private static final List&amp;lt;Future&amp;lt;?&amp;gt;&amp;gt; FUTURES = new ArrayList&amp;lt;&amp;gt;();
     /**
      * 创建线程池实例
      */
     private static ThreadPoolExecutor createThreadPoolExecutor(){
         int poolSize = CPU_COUNT + 1;
         return new ThreadPoolExecutor(poolSize, poolSize, 50L, TimeUnit.SECONDS, new LinkedBlockingQueue&amp;lt;&amp;gt;(), new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }
    /**
     * 确保线程池已初始化（线程安全）
     */
     private static void ensureThreadPoolExists(){
         if (THREAD_POOL_REF.get() != null) {
              return;
        }
        ThreadPoolExecutor executor = createThreadPoolExecutor();
         if (!THREAD_POOL_REF.compareAndSet(null, executor)) {
            executor.shutdown(); // 另一线程已初始化成功
        }
    }
    /**
     * 提交异步初始化任务
     *
     * @param task 初始化任务
     * @return 提交后的 Future 对象
     */
    public static Future&amp;lt;?&amp;gt; submitInitTask(Runnable task) {
        ensureThreadPoolExists();
        Future&amp;lt;?&amp;gt; future = THREAD_POOL_REF.get().submit(task);
        FUTURES.add(future);
        return future;
    }
    /**
     * 等待所有初始化任务完成并释放资源
     */
    public static void waitForInitTasks(){
        try {
            for (Future&amp;lt;?&amp;gt; future : FUTURES) {
                future.get();
            }
        } catch (Exception ex) {
            throw new RuntimeException("Async init task failed", ex);
        } finally {
            FUTURES.clear();
            shutdownThreadPool();
        }
    }
     /**
     * 关闭线程池并重置引用
     */
     private static void shutdownThreadPool(){
        ThreadPoolExecutor executor = THREAD_POOL_REF.getAndSet(null);
         if (executor != null) {
            executor.shutdown();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;实现类后，还需要在 META-INF/spring.factories 下新增说明 org.springframework.context.&lt;/p&gt; 
&lt;p&gt;ApplicationContextInitializer=com.xxx.AsyncAccelerateInitializer，这样这个类才能真正生效。&lt;/p&gt; 
&lt;p&gt;这样异步化以后还有一个点需要注意，如果该初始化方法执行耗时很长，那么会存在 Spring 容器已经启动完成，但是异步初始化任务没执行完的情况，可能会导致空指针等异常。为了避免这种问题的发生，还要借助于 Spring 容器启动中 finishRefresh() 方法，监听对应事件，确保异步任务执行完成之后，再启动容器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitCompletionListener implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt;, ApplicationContextAware, PriorityOrdered{
    private ApplicationContext currentContext;
    @Override
    public void setApplicationContext(ApplicationContext applicationContext)throws BeansException {
         this.currentContext = applicationContext;
    }
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event){
        if (event.getApplicationContext() == currentContext) {
            AsyncBeanInitExecutor.waitForInitTasks();
        }
    }
    @Override
    public int getOrder(){
         return Ordered.HIGHEST_PRECEDENCE;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;七、总结&lt;/h1&gt; 
&lt;p&gt;启动优化后的项目实际测试结果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2f535724d8b21204e9e881711c6acf6f.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过异步化初始化和分库分表加载优化，项目启动时间从 280 秒缩短至 159 秒，提升约 50%。这对于提升日常开发效率、加快测试与联调流程具有重要意义。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18627678</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18627678</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>数据「熵增」时代，AI 如何以标准重构治理秩序?</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;Agent 热潮不减,但数据分析与治理状况却仍存在短板。据 Gartner 公司预测,到 2027 年,80% 的数据和分析治理举措或将因各类原因而失效。如何在 AI 时代重塑数据治理体系,让混乱数据重归有序,成为企业智能转型的关键命题。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;近日,在 infoQ 举办的全球人工智能开发与应用大会上,瓴羊智能数据建设与治理产品 Dataphin 高级技术专家，周鑫，受邀出席,以&lt;strong&gt;「基于统一标准的智能数据治理&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;Dataphin&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;的落地实践」&lt;/strong&gt;为主题,系统阐述了以数据标准为核心,实现可持续数据治理的方法论,以及以 AI 赋能自动化数据治理、重构复杂业务流程的实践路径。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;01&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;数据「&lt;/strong&gt;&lt;strong&gt;熵减」之道:基于统一标准,打造数据治理方法论&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「事物天生具有‘变混乱’的趋势,数据也是如此。如何将无序变得有序?按照热力学第二定律,需要从外界输入能量,并且具备感知能力。」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示:「对于数据治理来说,能量就是治理工具,感知就是标准规范。」数据治理是实现数据世界的「熵减」,它可以通过&lt;strong&gt;现状评估、制定目标、执行计划、持续监测&lt;/strong&gt;四个治理阶段,帮助数据生产者打破孤岛,实现低成本数据开发,帮助数据管理者做好资产盘点,确保数据质量与安全,帮助数据使用者便捷用数,助力决策分析。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//5ca3fd8084d8b3ffa1e3874b915a46b8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;但在现实情况中,许多数据治理的结果通常会面临失败,周鑫将其归结为四个原因:1) 治理动作分散,缺乏体系化方法论;2) 治理流程复杂,重度依赖人的能力和素质;3) 缺乏工具支撑,导致理论与实施脱节;4) 无法持续治理,治理策略难以快速调整。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c19a9aa3073e13c96e65f3ea454ed7c5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面对以上四类问题,Dataphin 提出了一套以数据标准为中心的数据治理方法论及产品化的落地。其核心逻辑为:&lt;strong&gt;聚焦&lt;/strong&gt;&lt;strong&gt;Data x AI&lt;/strong&gt;&lt;strong&gt;,用中台方法论构建统一的数据标准&lt;/strong&gt;,打造企业级好数据,帮助企业形成数据生产、数据消费、行业数据流通的数据要素服务链,驱动数据价值的释放。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「方法论的核心关键,在于以数据标准为中心。数据标准贯穿数据整个生命周期,它让数据治理具备核心抓手,不会漫无目的」,周鑫表示,&lt;strong&gt;企业需从核心业务入手,先行试点开展业务梳理与盘点工作,将相关统一纳入&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;DataCatalog&lt;/strong&gt;&lt;strong&gt;,并在此过程中逐步形成对应的数据标准。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;标准梳理完成后,平台即可开展标准构建:通过统一的数据标准,自动实现质量监控与安全分类,保障开发过程规范,阻断不规范数据开发。同时,统一标准可提升数据的可理解性与细节清晰度,实现数据从生成、开发到消费的全生命周期标准化管理。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a79214da341aeb304b867992344fd1c8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「整个治理链路就是以数据标准为中心,将传统的复杂的治理手段,简化成数据标准的梳理与治理效果的评估过程,数据符合标准的程度越高,整体数据质量也就越好」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,该方案以数据标准为核心,通过插件集成、API 注册和准实时同步等多种方式采集元数据,并统一纳入 DataCatalog,结合质量规则和安全策略进行自动识别与治理。这一方法论具备三大优势:一是&lt;strong&gt;体系化&lt;/strong&gt;,明确治理目标与路径;二是&lt;strong&gt;易落地&lt;/strong&gt;,借助一体化工具和 AI 能力,贯穿数据全生命周期;三是&lt;strong&gt;可持续&lt;/strong&gt;,以标准驱动模式便于应对业务变化,有效降低治理成本与复杂度。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;02&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;语义知识&lt;/strong&gt;&lt;strong&gt;+&lt;/strong&gt;&lt;strong&gt;流程提效,智能&lt;/strong&gt;&lt;strong&gt;Agent&lt;/strong&gt;&lt;strong&gt;多场景赋能数据治理&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;许多企业在应用 Agent 时都难免遇到一个难题:Agent 虽然具备一定的智能和对话能力,但在复杂业务场景中常常「空转」,无法真正理解业务语境、解决预期的实际问题。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,造成这一现象的根本原因,「在于数据质量偏低或数字化基础薄弱,导致 Agent 无法有效发挥价值,最终企业只能被迫放弃」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;AI 时代,优质数据至关重要,但「好数据」应如何获取?AI 又该如何赋能数据治理?&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;首先,「Agent 在没有丰富准确的语义知识下,不可能达到可生产使用的准确率」,周鑫认为,&lt;strong&gt;企业获取好数据,需要构建准确且丰富的语义知识体系&lt;/strong&gt;。Dataphin 针对这一需求,打造了包含&lt;strong&gt;元数据&lt;/strong&gt;、&lt;strong&gt;数据标准&lt;/strong&gt;、&lt;strong&gt;数据模型&lt;/strong&gt;、&lt;strong&gt;业务知识&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;四大语义知识体系。企业可以通过采集丰富且统一的元数据,建立涵盖码表、词根、值域及安全分类分级的标准体系,依托 Dataphin 智能构建的概念模型、逻辑模型和物理模型,以及对业务词条和逻辑的高效管理,实现对复杂业务知识的精准映射和应用。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e35e9b9658db17cdacdbbccf911c6633.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 为例,Dataphin 通过引入业务语义,不仅提升了问题泛化能力,还大幅提高了 SQL 匹配的准确率,显著增强了对自然语言的理解能力。实测数据显示,在 Dataphin 开放数据共享模型涵盖的 45 个典型问题中,&lt;strong&gt;简单问题的&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;strong&gt;准确率从&lt;/strong&gt;&lt;strong&gt;70%&lt;/strong&gt;&lt;strong&gt;提升至&lt;/strong&gt;&lt;strong&gt;80%&lt;/strong&gt;&lt;strong&gt;,而中等及复杂问题的准确率更是从&lt;/strong&gt;&lt;strong&gt;10%&lt;/strong&gt;&lt;strong&gt;跃升至&lt;/strong&gt;&lt;strong&gt;60%&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;其次,企业还需借助 AI,对数据治理链路进行提效。基于 TaskWeaver 改造,Dataphin 构建了具备生产化能力的 Agent 框架,覆盖研发、治理、资产问答等多个场景,显著提升了现有流程效率,拓展了 Agent 的应用边界。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 为例,系统可在识别信息不全时自动发起反问,补全后再继续处理,确保复杂业务场景下依然具备高理解力与执行准确率。同时,Dataphin 的开放能力不断演进,从传统的 API 和数据服务扩展至 MCP 模式,支持更灵活的接入方式,适配非固定流程和动态交互等复杂需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;智能找表&lt;/strong&gt;场景,Dataphin 有效解决了用户将复杂业务问题,转化为准确搜索词的难题。「引入 AI 后,你可以用业务的语言直接问,比如‘我要做客户分层’,‘我要用哪张表’,AI 会用大模型去对业务问题进行拆解和泛化,最后找关联到你已有的全域资产」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 5.png" height="366" src="https://oscimg.oschina.net/oscnet//44b7bd5fb943546e95785c6a26a72115.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;数据分析&lt;/strong&gt;场景,Dataphin 通过专辑机制与丰富的语义知识,解决了因语义知识的缺失或混乱,相似口径和命名干扰、以及海量表格带来的找表难题,显著提升了找表的效率与准确率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 6.png" height="366" src="https://oscimg.oschina.net/oscnet//5484c3d0938ae4172448aca47dd0d73a.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;数据治理&lt;/strong&gt;场景,Dataphin 通过「性别」等复杂字段特征识别,解决了正则表达式「不会写」、「看不懂」难题,取代了传统人工探查的繁琐过程,以往需要耗费十几分钟的特征识别,如今只需几十秒即可完成。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 7.png" height="460" src="https://oscimg.oschina.net/oscnet//5ada55aa58b287d443496c220aa124d5.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;数据管家&lt;/strong&gt;场景中,资产上架往往涉及表描述、字段注释、目录归属、标签分类等复杂操作,尤其在字段数量众多时,人工维护工作量大、耗时长且易出错。通过引入 AI 能力,Dataphin 支持属性信息的智能生成,可一键生成表/字段描述信息、目录、标签等,使人力成本与操作门槛大大降低。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="图片 8.png" height="359" src="https://oscimg.oschina.net/oscnet//004299cfcc7d5766516ace7402af26ad.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;随着 AI 对复杂节点的处理能力增强,Dataphin 正在以「智能工作台」有机整合独立模块,重构整体业务流程。 「有了 AI 之后,工作台模式可以让很少的人,完成复杂的业务,每个环节都有大量 AI 和自动化能力支撑,人们干的最多的事情是进行确认」,周鑫表示,未来,AI 还将在更多场景中深度参与,从辅助提效逐步向自动化、智能化方向迈进,推动企业实现数据治理范式的全面升级。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356211</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356211</guid>
      <pubDate>Sat, 10 May 2025 08:27:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Workout.cool —— 现代开源健身教练平台</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;一个全面的健身指导平台，可以为你制定锻炼计划、跟踪进度并访问包含详细说明和视频演示的庞大锻炼数据库。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;项目包含一个全面的练习数据库。要导入练习样本，请执行以下操作：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;导入的先决条件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;准备 CSV 文件&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你的 CSV 应该包含以下列：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以使用提供的示例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;导入命令&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Import exercises from a CSV file&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full /path/to/your/exercises.csv

&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Example with the provided sample data&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full ./data/sample-exercises.csv&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;CSV 格式示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,TYPE,STRENGTH
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,PRIMARY_MUSCLE,QUADRICEPS&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可用的属性类型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRENGTH&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CARDIO&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;PLYOMETRICS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRETCHING&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRIMARY_MUSCLE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;QUADRICEPS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CHEST&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BACK&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;SHOULDERS&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SECONDARY_MUSCLE&lt;/strong&gt;: Secondary muscle groups targeted&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EQUIPMENT&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BARBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;DUMBBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BODYWEIGHT&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;MACHINE&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MECHANICS_TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;COMPOUND&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ISOLATION&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/workout-cool</link>
      <guid isPermaLink="false">https://www.oschina.net/p/workout-cool</guid>
      <pubDate>Sat, 10 May 2025 08:20:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenBMB 开源轻量级 CUDA 推理框架 CPM.cu</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 推出了 CPM.cu，这是一个轻量级且高效的开源 CUDA 推理框架，专为端侧大型语言模型（LLMs）的部署而设计，并为&lt;a href="https://www.oschina.net/news/354328"&gt;MiniCPM4&lt;/a&gt;提供优化，核心支持&lt;strong&gt;稀疏架构&lt;/strong&gt;、&lt;strong&gt;投机采样&lt;/strong&gt;和&lt;strong&gt;低位宽量化&lt;/strong&gt;等前沿技术创新。&lt;/p&gt; 
&lt;p&gt;CPM.cu 亮点包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集成了 InfLLM v2 可训练稀疏注意力内核，可加速长上下文预填充和解码；&lt;/li&gt; 
 &lt;li&gt;FR-Spec（频率排序推测采样）通过压缩词汇空间提高草稿效率，显著降低计算开销；&lt;/li&gt; 
 &lt;li&gt;结合了 EAGLE-2 推测采样、4 位量化和基于滑动窗口注意力的长上下文支持，从而在资源受限设备上实现高效部署。&lt;/li&gt; 
 &lt;li&gt;性能方面，在 128K-token 序列上，预填充速度比 Qwen3-8B 快 2-4 倍，解码速度快 4-6 倍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CPM.cu&amp;nbsp; 框架结构：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CPM.cu/
├── src/
│   ├── flash_attn/ # 修改后的 Flash-Attention, 支持稀疏和投机采样
│   ├── model/
│   │   ├── minicpm4/ # minicpm4 模型
│   │   │   ├── minicpm4_model.cuh # 模型的核心实现
│   │   │   └── minicpm4_eagle.cuh # 投机采样实现
│   │   ├── model.cuh # 其他代表性模型
│   │   ├── w4a16_gptq_marlin/ # GPTQ 量化计算 kernel
│   │   ├── memory.cuh # 显存分配
│   │   └── layer.cuh # 通用层
│   ├── entry.cu # pybind: 连接 C/CUDA 和 Python
│   └── ...
├── cpmcu/ # python interface
└── ...&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;cpmcu/ 代码提供了一个 python 的调用接口，里面涉及在 Python 侧 tokenize，调用 C 代码得到模型的输出 logits，在 Python 侧根据 logits 采样并 detokenize 这些过程。我们使用了 pybind 将 C 代码与 Python 代码进行绑定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/memory.cuh 这里实现了整个推理框架的内存管理，这里我们采用了先分配模型权重，再分配模型中间计算结果所需的空间，最后把所有剩余显存分配给 kv-cache 的内存管理策略。这一点设计上是和 vLLM, SGLang 类似的。分配中间计算结果的空间时可以考虑一下中间计算结果的生命周期，做一点显存复用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/w4a16_gptq_marlin/ 量化的计算 kernel。这里直接使用了 vLLM 的 Marlin 代码。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/minicpm4/ 这里是模型的架构实现。src/model/下也有其他代表性模型实现。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/flash_attn/ 我们基于 flash_attn 2.6.3 版本，在上面增加了对 InfLLM v2、投机采样的适配支持。下面我们主要介绍这一部分，也是整个框架实现的难点。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;开源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FCPM.cu" target="_blank"&gt;https://github.com/OpenBMB/CPM.cu&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356197</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356197</guid>
      <pubDate>Sat, 10 May 2025 07:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源模型上下文协议 MCP 更新规范文档，添加对结构化工具输出的支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源模型上下文协议 MCP 昨天更新了规范文档，主要变更如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;移除对 JSON-RPC 批处理的支持（PR #416）&lt;/li&gt; 
 &lt;li&gt;添加对结构化工具输出的支持（PR #371）&lt;/li&gt; 
 &lt;li&gt;将 MCP 服务器归类为 OAuth 资源服务器，添加受保护资源元数据以发现相应的授权服务器。（PR #338）&lt;/li&gt; 
 &lt;li&gt;要求 MCP 客户端按照 RFC 8707 中描述的方式实现资源指示器，以防止恶意服务器获取访问令牌。（PR #734）&lt;/li&gt; 
 &lt;li&gt;在授权规范中阐明安全注意事项和最佳实践，并在新的安全最佳实践页面中说明。&lt;/li&gt; 
 &lt;li&gt;增加引导支持，使服务器能够在交互过程中向用户请求更多信息。（PR #382）&lt;/li&gt; 
 &lt;li&gt;在工具调用结果中增加资源链接支持。（PR #603）&lt;/li&gt; 
 &lt;li&gt;在使用 HTTP 时，后续请求中需通过&amp;nbsp;&lt;code&gt;MCP-Protocol-Version&lt;/code&gt;&amp;nbsp;头指定协商的协议版本。（PR #548）&lt;/li&gt; 
 &lt;li&gt;将生命周期操作中的 SHOULD 改为 MUST&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fspecification%2F2025-06-18%2Fchangelog" target="_blank"&gt;https://modelcontextprotocol.io/specification/2025-06-18/changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356195</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356195</guid>
      <pubDate>Sat, 10 May 2025 07:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源代码编辑器 Zed 上线「调试器」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源代码编辑器 Zed &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fdebugger" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;推出「调试器（Debugger）」功能，称这是向 Zed 1.0 迈出的重要一步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;调试器特性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;快速&lt;/strong&gt; ：减少上下文切换时间，让用户能更专注于调试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;熟悉&lt;/strong&gt; ：与 Zed 的设计语言保持一致，支持典型的调试流程，方便用户快速上手。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可配置&lt;/strong&gt; ：用户可自定义 UI、键绑定、调试配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-43c899b5d73c5470109aecf601bbff05ba7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Zed 开箱即支持调试多种流行编程语言，包括 Rust、C/C++、JavaScript、Go 和 Python。通过扩展系统，Zed 可以支持任何实现调试适配器协议（DAP）的调试适配器。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;技术架构&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   采用两层架构，数据层与调试适配器直接通信，UI 层从数据层获取数据进行界面渲染。
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   数据层负责维护会话状态、缓存响应、使失效数据，UI 层按需请求数据，避免不必要的请求，便于后续实现协作调试。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;调试适配器集成&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   扩展了 Zed 的扩展 API 以支持调试器集成，通过定义自定义架构等方式，让扩展作者能轻松将调试适配器集成到 Zed 中。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;内联变量值实现&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   利用 Tree-sitter 查询准确识别当前执行范围内的变量，无需依赖 LSP 服务器与调试适配器的紧密集成，目前支持 Python、Rust、Go 等语言。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fdocs%2Fdebugger" target="_blank"&gt;https://zed.dev/docs/debugger&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356190/zed-debugger</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356190/zed-debugger</guid>
      <pubDate>Sat, 10 May 2025 06:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源 Rust 浏览器引擎 Servo 支持 GIF</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Servo 是一款开源的浏览器引擎，最初由 Mozilla 开发。它使用 Rust 语言编写，旨在提供高效、安全的网页渲染能力，并且采用并行渲染技术，以提高网页加载速度和性能。&lt;/p&gt; 
&lt;p&gt;近日，Servo 团队介绍了最近的更新内容，其中一项重要新功能是&lt;strong&gt;支持显示动态 GIF&lt;/strong&gt;，并且还可以通过 HTML "img"标签加载 SVG 图像。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/142856_yG2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 还在推进其 Trusted Types API、输入类型 &amp;lt;input type=color&amp;gt; 支持、更好的布局和 CSS 支持，以及支持各种其他 API 和功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f8cd0cc574887e5f2e0cc055fb9586cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 还在继续努力提升围绕 Servo 嵌入支持的开发者体验，以 Servo 作为 Chromium 的 CEF 替代方案在应用程序中利用 Servo。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2025%2F06%2F18%2Fthis-month-in-servo%2F" target="_blank"&gt;https://servo.org/blog/2025/06/18/this-month-in-servo/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</guid>
      <pubDate>Sat, 10 May 2025 06:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美国科技巨头推动联邦立法，禁止各州单独监管 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《金融时报》报道称，近日美国多家大型科技公司正积极推动一项联邦禁令，旨在禁止各州自行制定人工智能（AI）监管法规。此次立法倡议得到了亚马逊、谷歌、微软和 Meta 等公司的支持，目的是避免各州在 AI 监管方面各自为政，影响行业的整体发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士透露，这项禁令提案已经被纳入众议院版本的 「大而美」 预算法案中。参议院也计划在近期推出自己的版本，并希望能够在 7 月 4 日之前完成相关立法工作。前联邦众议员、现任 INCOMPAS 首席执行官 Chip Pickering 是这项提案的重要推动者，他表示，保持美国在技术领域的领导地位是确保国家竞争力的关键。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;INCOMPAS 组织于 2024 年成立了 「人工智能竞争中心」（AICC），专注于游说国会与监管机构，以适应快速发展的 AI 行业。随着 AI 监管讨论的加剧，尤其是在欧盟出台新规后，亚马逊和 Meta 也加入了该组织，试图通过统一监管来增强竞争力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，此提案引发了广泛的争议。反对者认为，大型科技公司推动禁令的真正目的是为了巩固自身在 AGI（通用人工智能）竞争中的垄断地位。范德比尔特大学的政策加速中心 AI 与科技政策主任 Asad Ramzanali 表示，负责任的创新不应该惧怕法律的约束。同时，麻省理工学院的教授 Max Tegmark 也批评称，这种行为是科技巨头为了进一步集中财富和权力的扩张。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，支持禁令的人士认为，联邦层面的统一监管将有助于避免各州的分歧，保持行业的创新能力，从而在全球 AI 竞争中处于有利地位。AI 安全倡导者如 Anthropic 联合创始人 Dario Amodei 则警告称，如果完全依赖企业自我监管，可能会带来严重的社会风险。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356176</guid>
      <pubDate>Sat, 10 May 2025 06:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
