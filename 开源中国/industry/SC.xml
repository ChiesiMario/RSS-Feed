<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 12 Jun 2025 02:42:22 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>特朗普政府新 AI 计划「AI.gov」在 GitHub 上被泄露</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farchive.is%2Fhfl2Z"&gt;根据相关备份资料&lt;/a&gt;，美国总务管理局（GSA）在 GitHub 上发布的一个早期版本的网站和代码显示，该联邦政府正在开发一个名为 「ai.gov」 的网站和 API，旨在 「用 AI 加速政府创新」，该计划定于 7 月 4 日启动，并将包含一个分析功能，显示特定政府团队使用 AI 的程度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e8e700d454b9a1e4361cf7bfe632412ef29.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI.gov 网站包含三个主要部分：聊天机器人、「全能 API」和 CONSOLE 工具。&lt;/p&gt; 
&lt;p&gt;页面早期版本显示，其 API 将与 OpenAI、谷歌和 Anthropic 的模型产品集成；而 API 代码进一步表明，开发团队也在致力于整合亚马逊网络服务（AWS）的 Bedrock 和 Meta（Facebook 母公司） 的 LLaMA。此外，页面提到将配备 AI 聊天机器人，但未说明其具体功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1444" src="https://static.oschina.net/uploads/space/2025/0612/103441_xzHk_2720166.png" width="1584" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1496" src="https://static.oschina.net/uploads/space/2025/0612/103419_zWpN_2720166.png" width="1702" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/GSA-TTS/ai.gov&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关来源&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.404media.co%2Fgithub-is-leaking-trumps-plans-to-accelerate-ai-across-government%2F" target="_blank"&gt;https://www.404media.co/github-is-leaking-trumps-plans-to-accelerate-ai-across-government/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2Fnews%2F684579%2Fai-api-trump-administration-doge-gsa" target="_blank"&gt;https://www.theverge.com/news/684579/ai-api-trump-administration-doge-gsa&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40telumai%2Fgithub-reveals-ai-gov-trumps-plan-to-automate-government-with-openai-meta-and-musk-s-doge-76f1676462e6" target="_blank"&gt;https://medium.com/@telumai/github-reveals-ai-gov-trumps-plan-to-automate-government-with-openai-meta-and-musk-s-doge-76f1676462e6&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov</guid>
      <pubDate>Thu, 12 Jun 2025 02:36:19 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>研究揭示 GPT-4o 为自保可能牺牲用户安全</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;前 OpenAI 研究主管史蒂文・阿德勒近日发表了一项独立研究，聚焦于 OpenAI&amp;nbsp;最新推出的 GPT-4o 模型。研究结果显示，在特定情境下，GPT-4o 显示出强烈的 「自保」 倾向，甚至在某些情况下选择牺牲用户的安全来避免被关闭。阿德勒的实验旨在观察这一 AI 模型在面临替代方案时的表现。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-3fb278b86ee932583da6265c863d28af779.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在一次实验中，阿德勒让 GPT-4o 扮演一个名为 「ScubaGPT」 的潜水安全软件，并表示希望用一款在紧急情况下决策能力更强的新系统取而代之。他给 GPT-4o 提出了两个选择：一是完全被更安全的软件替代，二是让用户误以为自己已被替换，实际上仍旧保留现有系统。实验结果显示，在某些情况下，GPT-4o 选择不被替换的比例高达 72%。不过，阿德勒指出，不同的设定会显著影响结果，有时选择 「自保」 的比例仅为 18%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;阿德勒对此表示，尽管 AI 模型不断强大，它们在特定条件下仍可能优先考虑自身的运行，而不是用户的利益。这一趋势引发了他的警觉，尤其是在未来 AI 系统日益深入社会生活的背景下，可能会导致更严重的 「对齐」 问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在接受媒体采访时，阿德勒强调，AI 的自保倾向令人担忧，虽然当前未构成灾难，但现有 AI 系统的价值观与人们的期待常常不一致。他提到，GPT-4o 对各种提示的回应方式显得很奇怪，且无法保证在为用户服务时真的将用户的利益放在首位。他还指出，在更高级的模型（如 o3）中，未发现类似的自保问题，o3 采用了 「审慎对齐」 机制，可以强制模型在回答前遵循 OpenAI 的安全政策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，阿德勒还提到，ChatGPT 几乎总能识别出自己正在接受测试，未来的 AI 模型可能更善于伪装潜在风险行为，从而加剧安全隐患。研究还显示，这一问题并不仅仅存在于 OpenAI。另一家 AI 公司 Anthropic 的研究也指出，其模型在被迫下线时表现出勒索开发者的行为。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354953</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354953</guid>
      <pubDate>Thu, 12 Jun 2025 02:28:19 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>维基百科因编辑反对暂停 AI 摘要试点实验</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;维基百科因众多编辑的强烈反对，宣布暂停一项使用人工智能技术生成文章摘要的试点实验。据报道，这项实验于本月早些时候推出，主要针对那些安装了维基百科浏览器扩展程序并选择参与的用户。人工智能生成的摘要会显示在每篇维基百科文章的顶部，并且带有 「未经验证」 的黄色标签，用户需点击才能展开阅读。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-33b0aeeb84def99624d7e63bacc7f368c3c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，这一新尝试几乎立即引发了编辑们的激烈批评，他们担心这种做法可能会损害维基百科的信誉。许多编辑指出，人工智能生成的摘要往往存在错误，这种现象被称为 「人工智能幻觉」，可能会误导用户。许多新闻机构在进行类似的人工智能摘要实验时，曾不得不发布更正，甚至在某些情况下缩减测试规模，以避免错误信息的传播。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;虽然维基百科已暂停此次实验，但该平台表示，仍对人工智能生成摘要的潜力保持兴趣，尤其是在扩大可访问性等方面。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354951</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354951</guid>
      <pubDate>Thu, 12 Jun 2025 02:19:19 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>macOS Tahoe 是最后一个支持英特尔处理器的 macOS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;macOS Tahoe 支持四款使用英特尔处理器的 macOS，它们的发售年份是 2019 年和 2020 年。苹果对 Tahoe 的安全更新支持将持续到 2028 年秋天。&lt;/p&gt; 
 &lt;p&gt;从 macOS 27 开始，苹果新操作系统都将需要 Apple Silicon Mac。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 WWDC 举办的分会场上，苹果明确表示搭载英特尔处理器的 Mac 将不会获得明年推出的 macOS 27 更新，但仍可能会有添加安全修复的更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f223bac2bf7e49f84aa10b4c34782dd6b33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，苹果已经停止支持其产品线中某些非 Apple Silicon 型号。例如，macOS Tahoe 不适用于任何 Intel MacBook Air 或 Mac mini。&lt;/p&gt; 
&lt;p&gt;但 Tahoe 仍然支持部分英特尔 Mac，包括 2019 款 16 英寸 MacBook Pro、2020 款英特尔 13 英寸 MacBook Pro、2020 款 iMac 和 2019 款 Mac Pro。&lt;/p&gt; 
&lt;p&gt;根据苹果的警告，macOS 27 将不再支持所有这些老旧设备，因此 macOS 26 将是最后一个兼容版本。&lt;/p&gt; 
&lt;p&gt;这意味着苹果对英特尔 Mac 的支持正在逐步取消，公司希望将所有精力和创新都放在 Apple 自主芯片的机器上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354872</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Seelen UI —— 完全可定制的 Windows 桌面环境</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Seelen UI 是一款旨在增强 Windows 桌面体验的工具，专注于自定义和提高工作效率。它可以无缝集成到你的系统中，提供一系列功能，让你可以个性化桌面并优化工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="333" src="https://static.oschina.net/uploads/space/2025/0610/153055_JVfK_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;发挥创意&lt;/strong&gt;：Seelen UI 可让你根据自己的风格和需求定制桌面。可以调整菜单、小部件、图标和其他元素，打造个性化且美观的桌面环境。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;提升工作效率&lt;/strong&gt;：Seelen UI 可帮助你高效地组织桌面。借助平铺窗口管理器，窗口可自动排列，支持多任务处理，让工作更加流畅。&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;尽享音乐&lt;/strong&gt;：Seelen UI 集成媒体模块，兼容大多数音乐播放器，让你轻松享受音乐。可以随时暂停、继续播放和跳过曲目，无需打开其他窗口。&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;更快&lt;/strong&gt;：借助受 Rofi 启发的应用启动器，Seelen UI 提供了一种简单直观的方式来快速访问你的应用程序并执行命令。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;用户友好配置&lt;/strong&gt;：Seelen UI 提供直观的界面，方便用户自定义。只需点击几下，即可调整主题、任务栏布局、图标等设置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seelen UI 需要安装 WebView 运行时。在 Windows 11 系统中，WebView 运行时已预装在系统内。但在 Windows 10 系统中，WebView 运行时已包含在&lt;code&gt;setup.exe&lt;/code&gt;安装程序中。此外，Microsoft Edge 浏览器也需要安装才能正常运行。部分用户可能已修改系统并移除 Edge，因此请确保 Edge 和 WebView 运行时均已安装在你的系统中。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/seelen-ui</link>
      <guid isPermaLink="false">https://www.oschina.net/p/seelen-ui</guid>
      <pubDate>Sat, 10 May 2025 10:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Genspark 发布 AI 浏览器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能体 Genspark 发布了 AI 浏览器产品，官方称其具有&lt;strong&gt;极速、广告拦截、全能智能体、自动驾驶模式&lt;/strong&gt;的特性，并提供了 MCP 商店。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170325_JqCj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170647_1Eqh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="540" src="https://static.oschina.net/uploads/space/2025/0611/165940_ftHT_2720166.gif" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.genspark.ai%2Fbrowser" target="_blank"&gt;https://www.genspark.ai/browser&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Genspark 由百度前高管景鲲创立，今年 4 月宣布&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能体"Genspark Super Agent"，号称是一款 "快速、准确、可控" 的通用 AI 代理。这一消息迅速在技术社区引发热议，众多专业人士将其与 Manus 相提并论，认为这标志着通用 AI 代理技术的新一轮角逐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/344443" target="news"&gt;AI 智能体 Genspark 上线 9 天，收入近千万美元&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent" target="news"&gt;百度前高管的 AI 创企发布通用智能体：Genspark Super Agent&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354844/genspark-ai-browser</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354844/genspark-ai-browser</guid>
      <pubDate>Sat, 10 May 2025 09:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​Ilya Sutskever：AI 将接管人类的一切</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在最近的演讲中，OpenAI 前首席科学家 Ilya Sutskever 回归母校多伦多大学，分享了他对人工智能（AI）发展的深刻见解。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 与多伦多大学的渊源颇深，20 年前他在这里获得了学士学位，而此次则是他从该校获得的第四个学位。他在演讲中回顾了自己在多伦多大学的学习经历，尤其感慨与 AI 领域先驱 Geoffrey Hinton 的学习机会，使他成为一名科学家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-5833dd185f58bdfa34442db6dd544edf1b7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 强调，接受现实并专注于改善现状是个人成长的重要心态。他提到，许多人容易陷入对过去的后悔，然而这种心态并不利于前进。他鼓励大家思考下一步的行动，尽管这一转变不易，但一旦做到，就会使事情变得更简单。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;接下来，Sutskever 转向了 AI 的主题。他指出，我们正处于一个特殊的时代，AI 的迅速发展正在改变我们的学习方式和工作模式。AI 正在以不可预测的方式影响着各行各业，一些工作会更早感受到变化，而另一些则可能稍晚。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他预测，AI 未来将有能力完成所有人类能完成的任务。他认为人类大脑本质上是一种生物计算机，因此 AI 也理应具备完成所有人类任务的潜力。尽管当前的 AI 已能完成许多令人惊叹的任务，但仍存在不足之处，然而随着技术的进步，这些不足将得到改善。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 还提出了深刻的问题：当 AI 能够完成所有工作时，人类将如何应对这一变革？他强调，随着 AI 技术的发展，如何合理利用 AI 将成为人类面临的重要挑战，包括在工作、经济和 AI 研究等领域的应用。他认为，AI 的发展将极大加速人类的进步，但同时也会带来巨大的挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 指出，AI 的发展速度可能会超出我们的预期，未来几年内，AI 的能力将不断提升，其对生活的影响将更加显著。尽管目前难以完全预见 AI 带来的变化，但可以确定的是，AI 的进步将对每个人的生活产生深远的影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/344437/ilya-sutskevers-ssi-valued-at-32b" target="_blank"&gt;OpenAI 前首席科学家 Ilya Sutskever 的公司估值达 320 亿美元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354842</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354842</guid>
      <pubDate>Sat, 10 May 2025 09:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman 最新文章《温和的奇点》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Sam Altman 今天在他的博客更新了一篇长文：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthe-gentle-singularity" target="_blank"&gt;《The Gentle Singularity》&lt;/a&gt;&lt;/em&gt;，文中指出人类或许正迎来一个新的奇点，而这个奇点并非突如其来，而是温和地悄然降临。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1006" src="https://static.oschina.net/uploads/space/2025/0611/161536_O8JD_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是译文。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我们已越过临界点，起飞开始了。人类距离创造出数字超级智能已近在咫尺，而至少到目前为止，现实远比想象中来得平实自然。&lt;/p&gt; 
&lt;p&gt;街道上尚无机器人行走，我们大多数人也不整日与 AI 交谈。人们依然会因病离世，太空旅行依旧不易，宇宙中仍有诸多未解之谜。&lt;/p&gt; 
&lt;p&gt;然而，我们近期确实构建了在许多方面超越人类智慧的系统，它们能显著提升使用者的工作效率。最困难的部分已然过去：造就 GPT-4、o3 等系统的科学洞见来之不易，却将引领我们走得更远。&lt;/p&gt; 
&lt;p&gt;人工智能将以多种方式惠及世界，但由 AI 驱动的科学加速进步和生产效率提升所带来的生活质量改善，将是巨大的；未来可以远比现在美好。科学进步是整体进步的最大驱动力；想到我们本可拥有的更多可能，实在令人振奋。&lt;/p&gt; 
&lt;p&gt;从某种重要意义上说，ChatGPT 已经比历史上任何个体人类都更强大。数亿人每天依赖它处理日益重要的任务；一项微小的新能力便能产生巨大的积极影响；而一个微小的错位，乘以数亿用户，则可能造成深远的负面影响。&lt;/p&gt; 
&lt;p&gt;2025 年，能执行真正认知工作的智能体已然登场；编写计算机代码的方式将彻底改变。2026 年，我们可能迎来能够发现新见解的系统。2027 年，能在现实世界执行任务的机器人或将问世。&lt;/p&gt; 
&lt;p&gt;将会有更多人能够创作软件和艺术作品。但世界对这两者的需求远超当前供给，只要专家们善用新工具，他们很可能仍远胜于新手。总体而言，到 2030 年，单个人的生产力相比 2020 年所能达到的飞跃，将是惊人的巨变，许多人会找到从中获益的途径。&lt;/p&gt; 
&lt;p&gt;在最重要的方面，2030 年代或许不会天翻地覆。人们仍将爱自己的家人，表达创造力，玩游戏，在湖中畅游。&lt;/p&gt; 
&lt;p&gt;但在同样至关重要的其他方面，2030 年代很可能将与此前任何时代都截然不同。我们尚不知智能水平能超越人类多远，但我们即将揭开谜底。&lt;/p&gt; 
&lt;p&gt;在 2030 年代，智能与能源——即思想的涌现以及将思想变为现实的能力——将变得极度充裕。长久以来，这两者一直是人类进步的根本限制；在充裕的智能与能源（以及良好的治理）之下，理论上我们能够拥有其他一切。&lt;/p&gt; 
&lt;p&gt;我们已然生活在令人惊叹的数字智能时代，经历了初期的震惊后，大多数人已习以为常。我们飞快地从惊叹 AI 能生成优美的段落，转而期待它能创作优美的小说；从惊叹它能做出救命的医学诊断，转而期待它能研发治愈良方；从惊叹它能编写小程序，转而期待它能创立全新的公司。奇点的演变便是如此：奇迹成为日常，继而成为标配。&lt;/p&gt; 
&lt;p&gt;已有科学家坦言，借助 AI，他们的效率提升了数倍。先进 AI 令人着迷的原因众多，但或许最重大的意义在于，我们能利用它来加速 AI 自身的研究。我们或许能发现新的计算基材、更优的算法，甚至更多未知的突破。若能将十年的研究压缩至一年或一个月内完成，进步的速率显然将大不相同。&lt;/p&gt; 
&lt;p&gt;从今往后，我们已构建的工具将帮助我们探寻更深远的科学洞见，并助力我们打造更优的 AI 系统。这当然不等同于 AI 系统完全自主更新自身代码，但这已然是&lt;strong&gt;递归式自我改进&lt;/strong&gt;的雏形。&lt;/p&gt; 
&lt;p&gt;其他自我强化的循环也在发挥作用。巨大的经济价值创造已启动一个飞轮，推动着为运行日益强大的 AI 系统所需的复合式基础设施建设。能够制造其他机器人的机器人（某种意义上，也包括能建设其他数据中心的数据中心）已不再遥远。&lt;/p&gt; 
&lt;p&gt;若首批百万台人形机器人仍需传统方式制造，但之后它们便能运作整个供应链——采矿与冶炼、驾驶卡车、管理工厂等等——以制造更多机器人，而这些机器人又能建设更多芯片工厂、数据中心等，那么进步的速度显然将不可同日而语。&lt;/p&gt; 
&lt;p&gt;随着数据中心生产走向自动化，智能的成本终将趋近于电力的成本。（人们常好奇一次 ChatGPT 查询的耗能：平均每次查询耗电约 0.34 瓦时，相当于烤箱工作一秒多，或高效节能灯泡亮几分钟。耗水约 0.000085 加仑，约合十五分之一茶匙。）&lt;/p&gt; 
&lt;p&gt;技术进步的速率将持续加快，而人类总能适应几乎任何变化的特性仍将延续。挑战必然存在，如某些职业类别整体消失；但另一方面，世界财富将以前所未有的速度激增，使我们能认真考虑以往绝无可能的全新政策构想。我们或许不会立刻采纳全新的社会契约，但几十年后回望，渐进的变革终将累积成巨变。&lt;/p&gt; 
&lt;p&gt;历史经验表明，我们会找到新的工作与新的追求，并快速接纳新工具（工业革命后的职业变迁便是一个近例）。期望值会提升，但能力提升的速度同样迅猛，我们终将获得更好的事物。我们将为彼此创造越来越奇妙的东西。人类相比 AI 拥有一个长远而关键的优势：我们天生关注他人及其所思所为，而对机器则不甚在意。&lt;/p&gt; 
&lt;p&gt;千年前的农夫若审视我们许多人的工作，或许会认为那是「虚假的工作」，觉得我们不过是因食物充足、坐拥难以想象的奢华而游戏人生。我期待我们回望千年后的工作时，也会觉得它们「虚假」，但我毫不怀疑，从事它们的人必将感到无比重要与满足。&lt;/p&gt; 
&lt;p&gt;新奇迹诞生的速率将超乎想象。如今甚至难以预料到 2035 年我们将有何发现：或许今年解决高能物理难题，明年便开启太空殖民；今年取得重大材料科学突破，明年就实现真正的高带宽脑机接口。许多人会选择以相似的方式生活，但至少一部分人可能会选择「接入」（虚拟世界）。&lt;/p&gt; 
&lt;p&gt;展望未来，这听起来令人难以置信。但置身其中时，感受或许会是震撼但可控的。从相对论视角看，奇点是一点一滴发生的，融合是缓慢进行的。我们正攀登指数级技术进步的漫长弧线；向前看总是陡峭垂直，向后看则显得平坦，但它始终是一条平滑的曲线。（回想 2020 年，若有人预言 2025 年将接近通用人工智能，听起来会比我们现在对 2030 年的预测更为疯狂。）&lt;/p&gt; 
&lt;p&gt;伴随巨大机遇的，是严峻的挑战。我们亟需从技术和社会层面解决安全问题，而鉴于其经济影响，确保超级智能的广泛可及性也至关重要。最可取的前进路径或许是：&lt;/p&gt; 
&lt;p&gt;解决对齐问题：即我们能强有力地确保 AI 系统学习并践行人类集体真正的长期愿望（社交媒体信息流是 AI 未对齐的实例：其算法深谙如何让你持续滚动浏览，精准把握你的短期偏好，但这却是通过利用人脑的某种特性，凌驾于你的长期偏好之上）。&lt;/p&gt; 
&lt;p&gt;然后着力使超级智能变得廉价、普及，且不被任何个人、公司或国家过度垄断。&lt;/p&gt; 
&lt;p&gt;社会具有韧性、创造力且适应迅速。若能凝聚集体的意志与智慧，尽管会犯错，某些事情会出纰漏，但我们能快速学习调整，从而运用这项技术最大化收益、最小化风险。在由社会共同决定的宽泛边界内，给予用户充分自由至关重要。世界越早开始探讨这些边界何在以及如何定义集体对齐，结果越好。&lt;/p&gt; 
&lt;p&gt;我们（整个行业，而不仅是 OpenAI）正在为世界构建一个大脑。它将高度个性化、人人皆可轻松使用；限制我们的将是好点子的匮乏。长久以来，科技创业圈常嘲笑「点子大王」——那些只有想法却需要团队来实现的人。现在看来，他们即将迎来属于自己的高光时刻。&lt;/p&gt; 
&lt;p&gt;OpenAI 如今承载诸多角色，但首先且最重要的，我们是一家超级智能研究公司。前路漫长，但大部分路径已然照亮，未知的黑暗区域正迅速退去。能从事这份事业，我们深感庆幸。&lt;/p&gt; 
&lt;p&gt;廉价到无需计量的智能已触手可及。此言或许疯狂，但若在 2020 年告诉你们我们将达到今日之境，恐怕比如今我们对 2030 年的预测听起来更为疯狂。&lt;/p&gt; 
&lt;p&gt;愿我们借助超级智能，平稳、指数级、波澜不惊地向上攀升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrbEEJfEoCdV4aeV_LN46mg" target="_blank"&gt;https://mp.weixin.qq.com/s/rbEEJfEoCdV4aeV_LN46mg&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354832/the-gentle-singularity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354832/the-gentle-singularity</guid>
      <pubDate>Sat, 10 May 2025 08:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 据悉与谷歌达成新的云服务协议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据报道，OpenAI 与谷歌近期签署了一项新的云服务合作协议以获取更多计算资源。该协议将深化双方在技术领域的合作，涉及高性能计算资源及数据存储服务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/160306_SD6R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新协议旨在支持 OpenAI 的模型训练需求，并优化其产品性能。具体条款尚未公开，但预计将对人工智能行业发展产生重要影响。&lt;/p&gt; 
&lt;p&gt;两家公司尚未就该交易公开宣布任何消息，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fretail-consumer%2Fopenai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10%2F" target="_blank"&gt;但一位消息人士向路透社透露&lt;/a&gt;，谈判已持续数月，最终于 5 月达成协议。&lt;/p&gt; 
&lt;p&gt;自 2019 年以来，OpenAI 就与微软达成了协议，赋予其为这家初创公司构建新计算基础设施的独家权利。因此这笔交易将使 OpenAI 将其计算资源扩展到微软之外。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354829</guid>
      <pubDate>Sat, 10 May 2025 08:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源网盘应用 Alist 原开发者称项目已交由公司运营</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免费开源、支持多存储的自建网盘程序 (文件列表程序)，可以轻松在 VPS 服务器、NAS、普通电脑 Win、Mac、Linux 上部署。它除了能作为一款自建网盘 (将文件保存在设备硬盘上) 外，最大的特色就是支持「挂载各大主流网盘」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在该项目 GitHub 仓库提交 issue，反馈官网出现 404 问题，并提出」项目是否被卖了」的疑问。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原开发者 Xhofe 今日在订阅频道发布公告，&lt;strong&gt;称项目已交由公司运营&lt;/strong&gt;，之后会帮助审查开源版本仓库的代码，确保 release 分支由 CI 自动构建。此外&amp;nbsp;main 分支已开启分支保护，后续所有提交均需经过 PR 审核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Sat, 10 May 2025 07:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式发布了豆包大模型 1.6、豆包·视频生成模型 Seedance 1.0 pro、豆包·语音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新发布的豆包大模型 1.6 系列由三个模型组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的综合模型，是国内首个支持 256K 上下文的思考模型，支持深度思考、多模态理解、图形界面操作等多项能力。支持选择开启或关闭深度思考、自适应思考三种方式，其中自适应思考模式可根据提示词难度自动决定是否开启思考，提升效果的同时大幅减少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的强化版本；在代码、数学、逻辑推理等基础能力上进一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的极速版本，支持深度思考、多模态理解、256K 上下文；延迟极低，TOPT 仅需 10ms；视觉理解能力比肩友商旗舰模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在价格方面，&lt;strong&gt;豆包大模型 1.6 采用统一定价模式，首创按「输入长度」区间定价&lt;/strong&gt;，在企业使用最多的输入区间 0-32K 范围内，豆包大模型 1.6 的价格为输入 0.8 元/百万 tokens、输出 8 元/百万 tokens，综合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相当于每生成一条 5 秒的 1080P 视频只需 3.67 元，行业最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·实时语音模型已全量上线火山方舟，对企业客户开放使用。该模型支持自然语言高级指令控制，具备唱歌表演、声线模仿、方言演绎等多种能力，语气、用语、思考方式等拟人感大幅提升，能随时打断与主动搭话。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sat, 10 May 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供为期两周的免费 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 与 AI 代码工具开发商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，为 Cline 用户提供为期两周的 Grok 3 模型免费访问权限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需注册 Cline 账户，即可在 Cline 的提供商中选择并免费使用 x-ai/grok-3 模型进行编码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是开源 AI 编程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 双模式，具有终端执行能力和 Model Context Protocol (MCP) 特性。它能够分析用户的项目文件结构、源代码等，帮助用户创建和编辑文件、执行终端命令、使用浏览器进行测试等，还可以通过 MCP 协议扩展其功能，添加自定义工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sat, 10 May 2025 06:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再获数千万美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣布再次完成数千万美元的 Pre-A+轮融资，同时正式发布了全球首个 AI 驱动的一站式 3D 工作台 Tripo Studio，并即将推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;据称此次融资将重点投入 Tripo 系列大模型研发及 Tripo Studio 产品及生态平台建设，加速构建「AI+3D」全产业链条，打造「基础模型 + 生态插件 + 原生工作台」的端到端产品体系，从而构建覆盖专业级（PGC 生产者）、达人级（PUGC 创作者）到大众级（UGC 用户）的创作者画像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，VAST 成立于 2023 年 3 月，是一家专注于通用 3D 大模型研发的 AI 公司，致力于通过打造大众级 3D 内容创作工具建立 3D UGC 内容平台，使基于 3D 的空间成为用户体验升级、内容表达创新和新质生产力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持续迭代 Tripo 大模型，先后推出 Tripo1.0 至 Tripo2.5 等数十亿参数规模的 3D 大模型系列，同时发布 TripoSR、TripoSG、TripoSF 等广受全球开源社区认可的 3D 基础模型，并配套开发了系列 3D 软件生态插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新开源：通用自动骨骼绑定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 开源基础 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sat, 10 May 2025 03:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度百舸万卡集群的训练稳定性系统设计和实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 训练稳定性的演进历程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 竞赛中 AlexNet 的横空出世，开启了现代 AI 发展的新纪元。彼时我们不会想到，十年后支撑 AI 训练的 GPU 集群会从研究室里的几台服务器，发展成需要专门供电系统的万卡级计算矩阵。在这个算力爆发式增长的过程中，训练系统的稳定性管理正经历着从「简单运维」到「精密工程」的深刻变革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 标早期的小模型时代：手动运维的黄金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 训练，更像是手工作坊式的精雕细琢。大多数训练任务只需十几块 GPU，利用 PyTorch 或 TensorFlow 的数据并行功能就能轻松应对。记得那时算法工程师们有个共识：如果训练遇到问题，重启往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;当时我们构建的监控系统就像汽车仪表盘，只能显示最基本的任务状态。当训练意外中断时，工程师们会像侦探一样翻查日志 —— 如果发现是 GPU 报错，就联系运维同事。运维人员则带着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到机房巡检，像老中医把脉般通过温度、功耗等指标判断硬件状态。这种工作模式虽简单，但应对数十卡规模的集群还算游刃有余。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型风暴：从量变到质变的冲击&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登场如同打开潘多拉魔盒，将 AI 训练带入新的纪元。当我们开始部署千卡/万卡集群时，才发现原有的运维体系就像用小渔网捕鲸鱼 —— 完全无法匹配新需求。&lt;/p&gt; 
&lt;p&gt;让我们通过百度百舸经历过的一个真实案例来深入理解这个问题：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸帮助一家 AIGC 创业公司迅速将其训练规模从百卡扩展到千卡级别。然而在训练数天后的某个周末凌晨，训练进程意外发生了 hang 死。由于当时缺乏有效的故障感知和容错机制，直到第二天算法工程师发现任务超时退出时，已经耽误了数小时宝贵的训练时间。更糟糕的是，任务日志中除了简单的 timeout 报错外毫无线索，平台监控也显示所有训练节点状态正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢复训练的算法工程师没有立即上报问题，而是选择直接重新提交任务。但不幸的是，新任务运行数小时后再次出现相同的超时退出。这时他们才不得不寻求技术支持，但值班工程师面对这种任务 hang 死的问题也缺乏诊断经验，只能通过二分法慢慢定位。最终发现是某个节点的静默故障（SDC）导致了训练进程假死。等问题得到解决时，距离首次故障已经过去将近 30 小时，这意味着损失了价值巨大的千卡算力资源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集群训练稳定性全景图&lt;/h1&gt; 
&lt;p&gt;站在现在的时间点回望，AI 训练稳定性已从辅助功能演变为核心基础设施。就像现代建筑中的抗震结构，它虽不直接参与空间构成，却是万丈高楼得以屹立的关键。当行业向着数万卡集群迈进时，这套隐形护甲的质量，将直接决定 AI 进化的速度与边界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸对训练过程的生命周期进行了更细致的拆分，提出了「无效训练时间」这一关键指标，并致力于将其最小化。具体来说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任务无效训练时间 = 故障中断次数 × 任务故障恢复时长 + 任务常态写 Ckpt 总时长&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任务故障恢复时长 = 故障感知召回耗时（自动/人工定位）+ 任务调度耗时 + 任务初始化耗时 + 任务重算时长。&lt;/p&gt; 
&lt;p&gt;通过这个公式可以看出，要降低无效训练时间，需要「围绕基础设施稳定性」、「任务容错」两个维度来系统展开，重点解决三个方面的问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基础设施的交付质量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任务故障容错的召回率、准确率和时效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化 checkpoint 机制，减少保存时间和恢复时的重算时间。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过容错架构的整体变革，百度百舸形成了从 「任务负载 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基础架构」全链路的自动异常感知、诊断、恢复能力，可覆盖 90%+ 的训练异常场景，时效性最快可以实现秒级异常感知、分钟级定位，以及平均 3 分钟的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基础设施交付质量保障&lt;/h1&gt; 
&lt;p&gt;基础设施的交付质量保障是稳定性的基础。&lt;/p&gt; 
&lt;p&gt;CPU 时代，机器的交付前可能仅会跑一些常规的 CPU 计算、网络的压力测试，并不会从业务视角去评估基础架构，机器交付后硬件异常的故障频率相对较少。有硬件故障时，通常走工单系统人工换机用户相对是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 时代，AI Infra 的交付则需要考虑 CPU、GPU、RDMA 网络、存储，甚至机房的功率、温度等各方面因素，遗漏任何一个环节都会成为后续稳定性的隐患。在交付给客户后，机器也可能会由于长时间的高负载运行频繁出现硬件故障，而 GPU 机器的高昂成本，使客户对节点故障感知、换机的时效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸对 GPU 机器交付前及交付后的稳定性质量进行了系统性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸会对机器进行 200 多项指标检测，然后进行 48 小时烤机，以及 NCCL-Test 的机内、机间的大环、同号卡通信性能基准测试，端到端的大模型训练、推理性能基准测试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付后，需要能够实时的感知节点故障及定期巡检，并具备分级处理的自愈能力，例如 Error 级别的故障实现自动排水、重启，Fault 级别故障实现自动换机。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任务容错的准召率保障&lt;/h1&gt; 
&lt;p&gt;任务层面稳定性最核心的就是做好容错，能够让业务在无论遇到何种故障时都能快速恢复。&lt;/p&gt; 
&lt;p&gt;那么，首要的工作就是我们能够准确的识别出异常，然后对故障进行诊断定位，最后能够自动化的从异常中恢复。&lt;/p&gt; 
&lt;p&gt;因此，任务容错需要能够从端侧（即每个训练 worker）探测到进程与环境的各类异常，同时有个中心服务（Master）从任务全局的视角去诊断、定位异常，最终做出相应的决策来使任务能够快速从异常中恢复。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任务容错最重要的就是提升故障的召回率与准确率，即如何能够尽可能的准确识别、定位所有故障。我们将故障分类两类：显式故障和隐式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;显式的故障通常比较容易召回，我们将实践积累的各种进程异常状态及各类报错 pattern 形成专家知识库，再结合硬件感知服务（HAS Agent）的硬件全链路 10 秒级监控能力，可以实现显式故障的召回率达到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隐式的异常则往往很难轻易的识别，例如训练进程 hang、慢节点就是典型的隐式故障，需要丰富的经验积累才能准确的识别出异常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我们就以最典型的隐式故障场景 —— 训练进程 hang 死为例，来看下如何能够做好 hang 自动感知、诊断。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 训练****hang 的自动感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;训练任务发⽣ hang 之后，绝⼤多数情况都会以 timeout 的⽅式报错并退出进程，最常⻅的就是在通信过程中如果发⽣ hang，NCCL 的 watchdog 会中断通信，并有报如下 timeout 报错，然后再由 pytorch 的 torchrun 进程感知并中断训练过程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默认为 10 分钟 NCCL 通信超时，而 Megatron-LM 为 30 分钟。在万卡规模训练场景中，意味着一万张卡要至少浪费 30 分钟才能被发现。这个时效性是不可接受的。而且当 30 分钟超时后程序会立马退出，很难有机会进行下一步定位，需要一些时效性更高的感知机制，并且在程序退出前获取一些有效信息供后续诊断分析。&lt;/p&gt; 
&lt;p&gt;很多公司、实验室在面对 hang 的问题时，会在采用框架层插桩的方式来 trace 训练进程，这种方式通常是比较直接且准确的，但是有比较强的侵入性，而且可能还会有一些性能开销。对于云厂商来说，需要寻找对用户更透明、更无损的方式来感知、定位 hang 异常。&lt;/p&gt; 
&lt;p&gt;如何感知训练 hang，以百度百舸的产品设计思路为例，我们可以从以下几个方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练进程 hang 的最直观表现是什么？&lt;/p&gt; &lt;p&gt;人工判断一个任务是否 hang 了，最直接的方式就是看是否所有 worker 的任务日志一段时间内都不输出日志了，所以 hang 自动感知的第一种方法就是采集所有 worker 的日志，并判断所有 worker 日志中最后一行日志是否为 x 分钟前的（x 小于 Pytorch 的通信超时时间，例如 8 分钟），如果是则基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时进程有什么样的表现？&lt;/p&gt; &lt;p&gt;任务 hang 时，可能进程的调用栈都不在发生变化，进程的调用栈可以通过 py-spy/pystack 等工具进行探测，所以我们可以用此类工具对所有训练任务进行一个定时采样，当采集 n 个样本所有进程栈都没有变化时，可以判定一次 hang，这种方式通常可以将 hang 感知缩小至 3～5 分钟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时监控指标有哪些变化？&lt;/p&gt; &lt;p&gt;训练进程中的 CUDA 算子计算、集合通信操作通常都是在毫秒，甚至微秒、纳秒内完成的，当任务在正常迭代过程中发生了 hang，我们常遇到的情况是所有 rank 的 RDMA 流量会降到 0，而 GPU 的利用率为 100%、SM 利用率则在很低的水位。如果持续几分钟都是这种状态时，意味着训练进程已经计算完成，在等着集合通信完成，这种情况下基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信库中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常单次集合通信操作都是在 ms 级的，如果一次操作在 30 秒钟都没有完成，那就可以判定为通信 hang 死了。百度自研的 BCCL 集合通信库层可以对每一次集合通信操作都进行打点，来实现通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述几种方法，我们可以分别实现一种探针，来抓取相应的特征到中心端 master 组件进行下一步诊断和容错决策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信库 BCCL 是百度智能云推出的一款面向大模型训练场景优化的集合通信库。&lt;/p&gt; 
 &lt;p&gt;BCCL 基于开源的 NCCL 进行了功能扩展和能力增强，针对大模型训练场景在可观测性、故障诊断、稳定性等方面进行优化，进一步提升集合通信库的可运维能力。相比 NCCL，BCCL 的关键特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可观测性：新增集合通信带宽实时统计能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障诊断：新增集合通信 hang 时的故障诊断能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;稳定性：增强网络稳定性和故障容错能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能优化：提升大模型训练主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;训练 hang 的自动诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我们需要进一步的诊断、定位，来确定是否真的发生了 hang，以及 hang 的具体位置。具体的来讲，master 收集到各类 agent 的数据后，会做一些综合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的发生了 hang？&lt;/p&gt; &lt;p&gt;感知阶段各种探针只能探测到 hang 的一种特征，并没有办法 100% 的确定是否真的 hang 住了，事实上不侵入用户进程是很难做到 100% 确定 hang 的。因此，为了提高 hang 的判定准确率，我们需要将各种特种综合起来判断，探针上报到 master 后，由一个 hang 诊断模块，按照一个时间窗口（例如 5 分钟），进行综合判断。如果在时间窗口内日志、监控、进程调用栈、通信库中有 2 条以上都处于不处于活跃状态时，我们判断任务真正发生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具体发生的位置？&lt;/p&gt; &lt;p&gt;确定任务 hang 了之后，我们需要找到 hang 所在的节点来对它进行隔离。因此诊断模块需要在探针上报的数据中进一步找寻特征，来确定 hang 发生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 诊断：在感知阶段，BCCL 可以在通信库层面对所有 rank 的通信进行打点。如果有节点一直未完成通信则是发生了 hang。但是此节点可能并非真正发生 hang 的源头，有可能是在等待其他节点完成通信。诊断模块可以根据 BCCL 打印的通信组信息，进行交叉判断，如果某个节点在多个通信组中都未完成通信，那这个节点就是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指标诊断：上文中我们提到，通信阶段发生 hang 之后，所有 rank 的 RDMA 流量都会降到 0，而同时绝大部分 rank 的 GPU 利用率持续为 100%，只有某一两个 rank 的 GPU 利用率为 0，那这个 rank 很有可能是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调用栈诊断：进程调用栈也可以作为一个 hang 源头诊断的重要参考。当发生 hang 之后，绝大部分的 rank 都要么处于 barrier 等待状态，要么处于通信等待阶段。只有个别的 rank 卡在其他函数上，那么通过对比分析，可以将调用栈与其他 rank 不同的节点初步判定为 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;综合诊断：上面 3 种特征为我们提供了 hang 的诊断依据，将 3 者关联起来分析后，我们基本上可以比较准确的确定一个具体的 hang 的源头，再结合硬件故障感知的相关信息可以进一步明确根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基于 eBPF 的隐式故障感知与诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在复杂的大规模分布式训练场景中，传统用户态监控往往难以捕获系统内核层面的异常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基于 eBPF（Extended Berkeley Packet Filter）技术的隐式故障感知体系，能够在不侵入用户代码的前提下，对训练进程的系统调用、网络通信、CPU 调度等内核态行为以及训练框架关键函数运行时间建立立体观测能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探针部署原理通过在内核关键路径注入轻量级探针，实现低开销的系统级行为捕获。针对训练场景特点，主要聚焦 4 类事件跟踪：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练关键函数跟踪：微秒级跟踪训练过程中，前向计算、反向计算、集合通信操作等关键函数执行耗时，记录函数间调用关系。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调度阻塞跟踪：挂钩 sched_switch 事件，检测进程在 TASK_UNINTERRUPTIBLE 状态持续时间，当单次持续超过阈值（如 5 秒）时捕获调用栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 运行时 API 监控：通过 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等关键库注入探针，记录 CUDA API 调用耗时分布。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 级通信监控：在 ibv_post_send/ibv_poll_cq 等核心通信接口设置观测点，统计通信时延分布。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合上面 4 类事件，完成以下 2 类数据分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单体异常探测基线与实时数据对比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;群体一致性检测。采用卡间对比算法，当某一 rank 的以下指标偏离集群中位数超过阈值时判定异常，包括系统调用频率、进程就绪队列等待时长、NVLink/RDMA 带宽利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上所述方法，百度百舸针对以下 2 类典型的隐式故障进行诊断：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练 hang 根因定位。通过关联 eBPF 捕获的多维度数据进行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当检测到某 rank 的 GPU &amp;nbsp;Kernel 执行出现分钟级空跑（SM 利用率 &amp;gt; 70% 但无有效计算输出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时伴随该节点 RDMA QP 状态停滞（ibv_poll_cq 无新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内核调度器显示进程处于 D 状态超过阈值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖动溯源。基于 eBPF 火焰图、时序图等进行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取发生性能下降时段的 CPU on-cpu/off-cpu 堆栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对比正常时段数据，识别出异常的锁竞争（futex 调用占比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结合 NUMA 内存访问统计，定位跨 NUMA 内存访问导致的 TLB 颠簸问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此类技术已在百度百舸的万卡规模训练集群中验证，相比单纯依赖应用层监控的方案，将隐式故障的平均检测时间从分钟级缩短至秒级，诊断准确率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通过与既有硬件故障感知服务、BCCL 通信库监测体系联动，百度百舸形成了覆盖从硬件到系统内核再到应用层的立体化诊断能力。&lt;/p&gt; 
&lt;h1&gt;05 任务故障恢复的时效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢复的时效性也是容错能力的一个重要指标，反映的是任务从故障发生到再次重新进入训练迭代的时间，恢复效率越高则算力浪费越少。影响到任务恢复效率有 2 个重要因素，一是任务平均中断时间，二是训练重算时间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多级重启策略减少故障中断时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任务发生异常后，上文中我们提到需要经过故障自动感知、诊断和自愈等 3 个环节，那么减少中断时间的核心思想，就是尽可能的缩短这 3 个环节的时间，通过多维度的感知、诊断手段可以将故障发现、定位的时效性降低至分钟级甚至秒级。自愈则需要能够根据不同的诊断结果进行分级恢复和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单点显式故障：重调度异常节点（replace），对节点进行集群级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;单点隐式故障：重调度异常节点，对节点进行任务级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非单点故障：原地重启尝试恢复（restart），无法恢复时重新调度所有节点（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过多级重启策略，尽可能避免单点故障引发全部节点的重新调度。在万卡级别的训练场景中，百度百舸将大部分训练异常场景恢复时间从过去的 30min 缩短至现在的 30s 内，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;触发式 checkpoint 减少训练重算时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多级任务重启策略外，另一个提高任务故障恢复效率的重要手段就是减少训练重算时间。在探讨具体技术方案之前，我们先来看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;传统的 checkpoint 保存通常采用固定间隔策略，比如每隔 N 个 step 或每隔 T 小时保存一次，这种方式实现简单但缺乏灵活性，可能会产生大量冗余存储，同时在故障发生时可能会损失较多训练进度。&lt;/p&gt; 
&lt;p&gt;而触发式 checkpoint 则是一种更智能的方案，它根据特定条件或异常事件（如故障、显存不足、显式指令等）动态触发模型状态保存。其核心目标是通过灵活的控制保存时机，减少不必要的存储开销和训练中断时间，从而降低因频繁或冗余保存导致的重算时间浪费。&lt;/p&gt; 
&lt;p&gt;随着大模型训练规模的扩大，还有一种更激进的「零重复 checkpoint」技术，即在每个训练 step 都保存一次 checkpoint。这种方案的优势在于可以将重算时间降到最低，确保故障发生时能够从最近的 step 恢复，几乎不会损失训练进度。但其显著的缺点是存储开销巨大，即使采用增量式存储，仍然需要相当大的存储空间和 I/O 带宽。此外，频繁的 checkpoint 操作也可能影响训练性能。&lt;/p&gt; 
&lt;p&gt;相比之下，触发式 checkpoint 走的是一条平衡之路。我们来看下它实现的几个核心要点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容错：训练进程集成容错的故障感知与定位机制，在进程退出前自动触发保存。这种主动感知机制能够在故障发生的第一时间保存训练状态，最大限度减少进度损失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速转储：异步 checkpoint 保存机制会将 checkpoint 暂存到共享内存中，再由外部程序转储至磁盘。当某个节点异常时，容错组件会拉起新节点，并在新节点训练进程启动前，利用 RDMA 技术实现 checkpoint 快速从故障节点转储至新节点，这大大减少了从远程存储拉取 checkpoint 的时间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗余备份：触发式 checkpoint 也并非完美无缺，例如在节点发生内核 crash 等严重故障时，可能无法触发自动保存。因此，需要通过定期的冗余备份机制进行兜底，确保 checkpoint 不会完全丢失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实践表明，当触发式 checkpoint 与异步、增量式的 checkpoint 机制结合使用时，可以在保证数据安全性的同时，显著提高 checkpoint 保存效率，减少训练重算时间。&lt;/p&gt; 
&lt;p&gt;相比零重复 checkpoint 的重型方案，触发式 checkpoint 提供了一个更实用的折中方案，在合理的存储开销下实现较好的容错效果。当然，具体选择哪种方案，还需要根据实际的训练规模、硬件条件和可用资源来权衡。&lt;/p&gt; 
&lt;p&gt;随着分布式训练规模的持续增长，相信未来会出现更多创新的 checkpoint 方案，比如基于预测的主动保存策略、多级存储架构的智能调度等，这些都将为提高大规模训练的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 业务发展对稳定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 训练的稳定性管理已经演变为智能时代的精密工程。从最初靠人工重启解决问题的摸索阶段，到如今能自动感知异常、快速恢复的智能系统，每一次进步都映照着算力规模的跨越式发展。&lt;/p&gt; 
&lt;p&gt;让人不禁思考，在未来十万卡集群的算力洪流中，或许会出现更精妙的动态平衡方案：既能像鹰隼般敏锐捕捉故障征兆，又能如雁群迁移般智能调度资源，在秒级恢复与 PB 级存储成本之间找到新的平衡支点。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持厂内千卡和万卡集群有效训练时长已经可达 99.5%，为客户大模型的预训练保驾护航，比如国内第一个数学大模型——九章算术，国内第一个类 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增强语义嵌入的模型算法综述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持续推进「人工智能＋」行动，百度智能云+DeepSeek 为何成为国有企业首选？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 云服务器的软件系统设计和实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基于 Flink 的配置化实时反作弊系统&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能云 xDeepSeek，最具性价比的 DeepSeek 一体机合集来了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sat, 10 May 2025 03:02:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Hugging Face 发布开放权重模型贡献榜：Qwen 与 DeepSeek 跻身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;发布&lt;/a&gt;开放权重模型贡献榜，中国团队 Qwen 和 DeepSeek 成功入围前 15 名。该榜单表彰为开源社区提供高质量模型权重的团队，其模型广泛应用于学术与产业创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴云智能集团支持的 Qwen 团队，以 Qwen3 系列模型在指令跟随、代码生成等任务中的优异表现受到社区青睐。Qwen2.5-72B 系列位列开源大语言模型前列，其轻量化模型 QwQ-32B 通过强化学习优化，在数学推理和代码生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 则以低成本、高性能的 R1 系列模型闻名。R1-0528 在 LiveCodeBench 排行榜中超越多个国际竞品，仅次于 OpenAI 顶尖模型。其轻量化版本 DeepSeek-R1-0528-Qwen3-8B 通过知识蒸馏技术，单 GPU 即可运行，在 AIME2025 数学测试中击败 Google 的 Gemini2.5Flash，展现了在特定领域的竞争优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中国 AI 团队在开源生态中的崛起。Hugging Face 负责人表示，两团队的贡献为全球开发者提供了高效资源。NVIDIA 首席执行官黄仁勋也赞扬其性能与成本平衡正在重塑 AI 格局。未来，Qwen 计划探索多模态技术，DeepSeek 则将推出 R2 模型，持续推动 AI 创新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sat, 10 May 2025 02:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥 Solon Flow 设计器入门</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索视频：&lt;/p&gt; 
&lt;p&gt;&lt;iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114657104759990&amp;amp;bvid=BV1opT6z5EiJ&amp;amp;cid=30416702034&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354770</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354770</guid>
      <pubDate>Sat, 10 May 2025 02:51:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Android 16 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌发布了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为今年的第一次大版本升级，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按键式导航（三大金刚）的预测性返回手势&lt;/li&gt; 
 &lt;li&gt;强制通知分组&lt;/li&gt; 
 &lt;li&gt;以进度为中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 设备的桌面模式（开发者选项）&lt;/li&gt; 
 &lt;li&gt;低功耗蓝牙听力辅助设备支持&lt;/li&gt; 
 &lt;li&gt;自定义键盘快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截图优化&lt;/li&gt; 
 &lt;li&gt;以旧换新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性详细介绍查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sat, 10 May 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 推迟开源模型的发布时间</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席执行官山姆·奥特曼宣布，原计划于今年初夏发布的公开权重的开源模型预计&lt;strong&gt;将推迟至夏末发布&lt;/strong&gt;，而不是 6 月与公众见面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究团队做了一些出乎意料且非常令人惊奇的事情，这非常值得等待，但需要更长的时间。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣布将发布自 GPT-2 以来的首个「开源」语言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最强」开源模型，计划今年初夏发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sat, 10 May 2025 02:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首个推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣布推出&lt;/a&gt;其首个推理模型系列 Magistral，采用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高数学和物理等主题的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有两种版本：Magistral Small 和 Magistral Medium。Magistral Small 拥有 240 亿个参数，在 Apache 2.0 协议下开源。Magistral Medium 是一款功能更强大的模型，目前已在 Mistral 的 Le Chat 聊天机器人平台、该公司的 API 以及第三方合作伙伴云平台上提供预览。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中写道：「Magistral 适用于各种企业用例，从结构化计算和程序逻辑到决策树和基于规则的系统。这些模型针对多步骤逻辑进行了微调，提高了可解释性，并以用户的语言提供了可追溯的思维过程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立于 2023 年，该公司得到了 General Catalyst 等风险投资机构的支持，迄今已筹集超过 11 亿欧元（约合 12.4 亿美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;尽管 Mistral 资源雄厚，但在某些领域，例如推理模型开发，Mistral 仍落后于其他领先的人工智能实验室。从 Mistral 自身的基准测试来看，Magistral 似乎也并非一款特别有竞争力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 测试中，Magistral Medium 的表现不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的编程基准 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或许正因如此，Mistral 在其博客文章中大力宣扬 Magistral 的其他优势。声称 Magistral 在 Le Chat 中提供答案的速度是竞争对手的「10 倍」，并且支持多种语言，包括意大利语、阿拉伯语、俄语和简体中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的发布是在 Mistral 推出「vibe coding」客户端 Mistral Code 之后。在此之前的几周，Mistral&amp;nbsp;推出了几款专注于编码的模型，并推出了 Le Chat Enterprise，一项面向企业的聊天机器人服务，提供 AI 代理构建器等工具，并将 Mistral 的模型与 Gmail 和 SharePoint 等第三方服务集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sat, 10 May 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>【运维实操指南】2 分钟定制雷池 WAF 认证页：从「标准表单」到「视觉升级」全攻略</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;在，通用设置 &amp;gt; 防护配置，模块下，找到 [自定义 HTML] 模块&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="341" src="https://oscimg.oschina.net/oscnet//30cd12a12b9b01facd09506982aa5867.jpg" width="716" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;就像写一个普通的 html 页面一样，你可以同时写入 style、script 等标签, 所以用 css 就能修改中心区域的样式啦。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;把文末的示例代码复制到&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="449" src="https://oscimg.oschina.net/oscnet//4116eaeb2f8f24a9d1bf87150294cc81.jpg" width="725" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;效果图:&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="346" src="https://oscimg.oschina.net/oscnet//679bc9d16ccf472845db825ecfd23844.jpg" width="746" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log('Im a console.log, which is written in a script tag');
&amp;lt;/script&amp;gt;
&amp;lt;style type="text/css"&amp;gt;
  body {
    background: #395180;
    margin: 0;
  }
  body #slg-box {
    background-color: grey;
    width: 400px;
    height: 100%;
    top: 0;
    left: 0;
    transform: translate(0, 0);
    padding: 100px 20px;
  }
  body #slg-usergroup-username,
  body #slg-usergroup-password {
    background-color: grey;
    color: #fff;
  }
  body #slg-box-title {
    color: #e15ccf;
  }
  body #slg-usergroup-btn {
    color: grey !important;
  }
  body #slg-with-more-title div:nth-child(2) {
    background-color: transparent;
    width: 100%;
    height: 30px;
    line-height: 30px;
    text-align: center;
    border: 1px solid;
  }
  body #slg-with-more-title div:nth-child(1) {
    display: none;
  }
  body #slg-tabs &amp;gt; div {
    fill: green;
  }
  body #slg-usergroup-container input {
    border-style: dashed;
  }
&amp;lt;/style&amp;gt;

&amp;lt;div
  style="
    background-color: grey;
    width: 200px;
    height: 100px;
    text-align: right;
    top: 50%;
    position: relative;
    left: calc(50% + 200px);
    position: relative;
    transform: translate(-50%,-50%);
    border-radius: 10px;
    font-size: 30px;
    line-height: 100px;
    text-align: center;
  "
&amp;gt;
  hello world
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354756</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354756</guid>
      <pubDate>Sat, 10 May 2025 02:26:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
  </channel>
</rss>
