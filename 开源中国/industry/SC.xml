<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 11 Mar 2025 12:39:01 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>梁文锋拒绝用 DeepSeek 赚快钱，腾讯、阿里近期都曾与其接触</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.wsj.com%2Farticles%2Finvestors-want-a-piece-of-deepseek-its-founder-says-not-now-724386a5%3Fmod%3Dcn_hp_lead_pos2&quot; target=&quot;_blank&quot;&gt;据《华尔街日报》报道&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;DeepSeek 创始人梁文锋已经拒绝了通过其大模型赚快钱的投资提议。他告诉潜在投资者，自己希望保持那种致力于科学项目研究的精神&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;702&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0311/184106_oQoG_2720166.png&quot; width=&quot;1800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据知情人士透露，梁文锋告诉身边的人，他并不急于获得投资，因为担心外部投资者会干预 DeepSeek 的决策。最近几周，包括腾讯和阿里巴巴在内的中国科技公司高管曾与梁文锋会面，讨论潜在合作机会。&lt;/p&gt; 
&lt;p&gt;知情人士称，自 2023 年底以来，DeepSeek 曾向多个风险投资基金进行推介，包括一些外国公司，但是这些公司拒绝投资，因为他们看不到明确的资金回报途径。&lt;/p&gt; 
&lt;p&gt;尽管对 DeepSeek 缺乏明确创收计划表示担忧，但最近更多潜在投资者表达了对投资 DeepSeek 的兴趣。然而，梁文锋着眼于公司的长期战略，拒绝了他们的投资提议。DeepSeek 正在研究如何帮助科技巨头利用 AI 开发商业应用并分享其中的收益。&lt;/p&gt; 
&lt;p&gt;目前，梁文锋似乎在坚持他在 2023 年一次罕见采访中表达的理念。他当时说：「我们不做应用，我们只做研究和探索。」记者问他为什么这样做，梁文锋回答说，原因是好奇心驱动。&lt;/p&gt; 
&lt;p&gt;知情人士还透露，梁文锋不想对 DeepSeek 的核心 AI 模型收费。这些模型目前是免费的。该公司计划最早在 4 月发布其下一个推理模型，旨在解决复杂问题。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338220</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338220</guid>
            <pubDate>Thu, 06 Mar 2025 10:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微信小程序「聊天工具」模式开始内测</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微信团队今日发布公告称，为更好地支持开发者在微信群聊场景内服务用户&lt;strong&gt;，小程序「聊天工具」模式开始内测&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;功能介绍&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;聊天工具模式是为了帮助小程序更好与微信聊天结合而推出的模式，可用于实现群问卷、群拼单、群任务等功能。其与小程序普通模式相比开放更多与聊天紧密结合的能力：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;聊天成员相关能力：开发者可调用聊天成员选择器并获取成员相关 id，通过开放数据域渲染聊天成员的头像暱称&lt;/li&gt; 
  &lt;li&gt;发送内容到聊天能力：开发者可发送文本、提醒、图片、表情、视频等内容类型到聊天中&lt;/li&gt; 
  &lt;li&gt;动态消息能力：小程序卡片上的辅标题可以动态更新，在用户完成/参与了活动后下发系统消息&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;同时，聊天工具模式需要使用独立分包基于 skyline 开发，该分包也可被普通模式打开。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;小程序「聊天工具」模式的能力介绍如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聊天成员相关能力&lt;/strong&gt;：开发者可调用聊天成员选择器并获取成员相关 id，通过开放数据域渲染聊天成员的头像暱称&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/70dbe39d-824d-4504-9929-aca7c109a807.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-681fa9ded30fbe32ccdcc7d158863ac4818.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;发送内容到聊天能力&lt;/strong&gt;：开发者可发送文本、提醒、图片、表情、视频等内容类型到聊天中，用户通过内容可进入小程序&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-59fa2aecb7ab97672121ab713e31a28004e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/b38d2ebf-68ab-4a08-ac94-60d09d79681d.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;动态消息能力&lt;/strong&gt;：小程序卡片上的辅标题可以动态更新，在用户完成 / 参与了活动后下发系统消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-03294ca6c0c39d56a7d7127e664c8534b88.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;详情查看文档：&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/3e6a2e0e-35a8-48c6-bb62-6be791f89764.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.weixin.qq.com%2Fminiprogram%2Fdev%2Fframework%2Fopen-ability%2FchatTool.html&quot; target=&quot;_blank&quot;&gt;https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/chatTool.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338202</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338202</guid>
            <pubDate>Thu, 06 Mar 2025 09:04:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 的「脸」该怎么管？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;em&gt;人民网记者，赵竹青&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「靳东两会建议 AI 换脸立法」「雷军回应国庆 7 天被 AI 雷军骂了 8 天」……今年两会期间，AI 话题频频登上热搜，「AI 换脸」引发的风险问题更是受到代表委员的热议。 事实上，苦于被 AI 偷走面孔和声音的，远不止靳东与雷军。前有「假张文宏」深夜直播带货，后有「假刘晓庆」分享人生鸡汤，以及「假古天乐」代言游戏平台，深度伪造 (Deepfake) 技术自 2017 年问世以来，正以指数级速度渗透日常生活。随着技术持续进化、门槛不断降低，「AI 换脸」的不当滥用已成为违法侵权重灾区，并有愈演愈烈之势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;面对新型侵权形态，现行法律体系正面临现实挑战。全国人大代表、小米集团创始人雷军坦言，现有法律体系仍将 AI 侵权嵌套在隐私权、肖像权、名誉权等传统框架中，而「被骂 8 天」「因 AI 谣言导致股价下跌」等损失，却因无法量化举证而难以维权。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「这些损害涉及众多不特定个体，仅靠私益诉讼难以实现有效治理。」最高人民检察院公益诉讼检察厅厅长徐向春的观察一针见血。显然，面对新技术引发的新问题，仍沿用传统追责机制，就好比用渔网去拦截数据洪流，是力所不逮的。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近年来，我国《互联网信息服务深度合成管理规定》《生成式人工智能服务管理暂行办法》等法律法规已颁布实施，《人工智能生成合成内容标识办法 (征求意见稿)》完成社会意见征集，对人工智能治理进行了有益探索。然而，鉴于技术的迅猛发展，治理的「工具箱」仍需不断扩容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;如何管好 AI 这张「脸」？全国两会上，代表委员们围绕如何更好把握人工智能发展机遇、更好应对新技术带来的风险挑战，积极建言献策。 雷军建议，加快单行法立法进程，提升立法位阶；强化行业自律共治，压实平台企业等各方的责任和义务；加大普法宣传的广度力度，增强民众的警惕性和鉴别力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;全国人大代表、TCL 创始人李东生建议，加快人工智能深度合成内容标识管理规章制度的出台，明确惩罚制度，同时还需加强国际合作，形成人工智能生成合成内容的有效监管。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;全国政协委员、中华全国律师协会监事长吕红兵认为，应当加快推进「小、快、灵」立法，尽早出台行政法规，规范相关领域发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在全国人大代表、四川省律师协会会长李世亮看来，随着 DeepSeek 在全世界范围内引发轰动，「AI+」快速融入各行各业，AI 立法「条件已经成熟」。他期待 AI 全面系统性法案的出台，填补我国 AI 法律空白。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;记者注意到，8 日提请审议的全国人大常委会工作报告明确，今年将围绕人工智能、数字经济、大数据等新兴领域加强立法研究。这也意味着，我国 AI 治理正逐步从「补丁式规范」向「体系化建构」转型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;技术狂飙的时代，规则不能只是追赶者。今年全国两会关于 AI 治理的讨论中，一个共识逐渐清晰：唯有构建起「法律划界、技术鉴伪、平台担责、全民共治」的多维防护网，才能让 AI 的「脸」既绽放科技之美，又不失人性之真与善。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338192</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338192</guid>
            <pubDate>Thu, 06 Mar 2025 08:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度上线 AI 陪伴产品「月匣」App</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;百度近期低调推出情感陪伴类 App「月匣」，主打高自由度 AI 对话与沉浸式剧本互动两大核心功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;544&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2b1b8422cc0ee7f9d5a53332bf2f668b7d0.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，这款产品通过构建虚拟角色生态，试图在泛娱乐社交领域开辟新赛道。与以往百度推出的 AI 社交产品不同的是，百度的这款全新 AI 社交产品，不仅搭载自研的文心一言大模型，还整合了 DeepSeek、豆包、MiniMax abab 三大外部的大模型，构建起「四核驱动」的 AI 社交引擎。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338176</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338176</guid>
            <pubDate>Thu, 06 Mar 2025 07:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>TIOBE 3 月榜单：Fortran 和 Delphi 争夺前十</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE 公布了 2025&amp;nbsp;年 3 月的&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F&quot; target=&quot;_blank&quot;&gt;编程语言排行榜&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;66&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-538dc8bd513430c8df55d4d61c23929ab13.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本月榜单中，一些古老的语言正在悄然上升。其中，Fortran 和 Delphi 正在争夺前十名的位置，COBOL 和本月新加入的 Ada 则稍稍靠后，但也均成功挤入了 Top 20。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE CEO&amp;nbsp;Paul Jansen 认为，这一趋势与维持世界运转的许多重要遗留系统有关。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;它们中的大多数都是借助这些「dinosaur languages」开发出来的。现在，这些系统的最后一批核心开发人员即将退休，公司为了避免任何风险，选择保留现有系统，甚至对其进行扩展，而不是用基于更现代语言的更新系统来取代它们。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;请注意，我们把这些语言称为「dinosaurs」，但它们已经随着时间的推移而不断发展，而且已经相当先进。它们都有新的语言定义。譬如 Fortran 2023、Delphi 12（2024 年发布）、Ada 2023 和 COBOL 2023。我们可能会对这些语言进入 TIOBE 指数前 20 名感到惊讶，但它们绝对是有作用的，值得称赞。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#333333&quot;&gt;TIOBE 3 月 TOP 20 编程语言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;400&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-204e07ccd60ab4b3c568070f91028f34963.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#333333&quot;&gt;TOP 10 编程语言 TIOBE 指数走势（2002-2024）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;221&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-33bfc79079a90aaf3dd4ea7c65b16937581.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#333333&quot;&gt;第 21-50 名编程语言排行&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;413&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-270d625073c800a18b1102408d7f43cbb57.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;第 51-100 名如下，由于它们之间的数值差异较小，仅以文本形式列出（按字母排序）：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;ActionScript, Algol, Alice, Apex, APL, CFML, CHILL, Clipper, CLIPS, Clojure, Curl, Eiffel, Elm, Erlang, F#, Forth, Groovy, Hack, Icon, Inform, Io, J, JScript, LabVIEW, Ladder Logic, Logo, Maple, Modula-2, Mojo, MQL5, NATURAL, Nim, OCaml, Occam, OpenCL, OpenEdge ABL, PL/I, Q, Raku, Ring, S, Scheme, Simulink, Smalltalk, SPARK, Tcl, Vala/Genie, VHDL, Wolfram, Xojo&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE 编程社区指数（The TIOBE Programming Community index）是一个衡量编程语言受欢迎程度的指标，该指数每月更新一次。评判的依据来自世界范围内的工程师、课程和第三方供应商，包括流行的搜索引擎，如 Google、必应、雅虎、维基百科、亚马逊、YouTube 和百度都被用于指数计算。值得注意的是，TIOBE 指数并不代表编程语言的好坏或编写代码的多少。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;该指数可以用来检查你的编程技能是否还能跟上时代的步伐，或者在开始建立一个新的软件系统时，基于指数对采用何种编程语言做出决策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F&quot; target=&quot;_blank&quot;&gt;TIOBE 指数&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;的定义方式，以及详细榜单信息&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F&quot; target=&quot;_blank&quot;&gt;均可查看官网&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338172/tiobe-index-202503</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338172/tiobe-index-202503</guid>
            <pubDate>Thu, 06 Mar 2025 07:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>最新消息：DeepSeek-R2 AI 模型将于 3 月 17 日发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;据智通财经援引消息人士透露，&lt;strong&gt;DeepSeek 下一代 AI 模型 DeepSeek-R2 或提前于下周一 (3 月 17 日) 正式发布&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;948&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0311/153001_YozB_2720166.png&quot; width=&quot;1220&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;DeepSeek-R2 在多个关键领域实现突破，包括更出色的编程能力、多语言推理能力，以及以更低的成本提供更高的准确性。专业人士认为，这些特性若得以兑现，可能使其在全球 AI 竞赛中占据显著优势。这对于资产价格而言，可能又是一次重估机会。&lt;/p&gt; 
&lt;p&gt;据悉，截至目前，DeepSeek 官方尚未正式公布 R2 的具体日期及技术细节等。早前市场预期 DeepSeek-R2 模型于 5 月发布。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/335778/deepseek-rushes-launch-new-ai-model&quot; target=&quot;news&quot;&gt;DeepSeek R2 将提前推出&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338171</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338171</guid>
            <pubDate>Thu, 06 Mar 2025 07:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>基于 Megatron 的多模态大模型训练加速技术解析</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：胡凯文，李鹏，黄俊&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;单位：阿里云智能集团人工智能平台 PAI 算法团队&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;多模态大模型是近期业界关注的热点，OpenAI 的 GPT4O 以及谷歌 Gemini 等多模态大模型的出现让人机交互变得更加简单和自然。这种模型在多种下游任务上表现优异，比如图文检索、视觉问答等。通过结合语言理解和视觉感知能力，它能为用户提供更加丰富和自然的人机交互体验。Pai-Megatron-Patch 是一款由阿里云人工智能平台 PAI 研发的围绕英伟达 Megatron 的大模型训练配套工具，旨在帮助开发者快速上手大模型，打通大模型相关的高效分布式训练、有监督指令微调、下游任务评估等大模型开发链路。在 Megatron 的基础之上，Pai-Megatron-Patch 及时追踪社区最新需求，搭建了包括 LLaMA3、Qwen2 等在内的多种热门大语言模型，并在此基础上持续拓展新特性，如支持 Optimizer Offloading 功能的 Distributed Optimizer， 可与 Transformer Engine、MoE 以及流水并行等模块协同使用，以适应更多场景需求。Pai-Megatron-Patch 的整体技术栈如下图所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0965cecdadad37ae040df3b73c232297.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;本文以 Qwen2-VL 为例，从易用性和训练性能优化两个方面介绍基于 Megatron 构建的 Pai-Megatron-Patch 多模态大模型训练的关键技术。在易用性方面，最新的 Pai-Megatron-Patch 实现了基于 Mcore 的多模态编码器和 LLM 解码器，同时实现了支持高精度低损耗的 Huggingface 和 MCore 多模态模型权重互转转换以及并行加载，极大简化了不同框架间迁移的学习成本和技术障碍。在性能方面，实现了支持高性能的文本/图像/视频数据统一加载，实现了高性能的流水并行切分，另外通过引入 CPU 卸载技术以及 Sequence Packing 技术，进一步支持多模态长序列训练的显存优化，有效缓解了 GPU 的显存压力，提升了大模型训练的效率与稳定性。这些改进共同作用，为用户提供更加流畅且高效的多模态大模型开发体验。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;支持模型并行的权重转换&lt;/h1&gt; 
&lt;p&gt;作为开源主流高效大模型训练工具，用户在尝试使用 Megatron 训练开源模型时首先遇到的障碍是 Huggingface 与 Megatron 模型权重格式的差异。下面将以 Qwen2-VL 为例，详解从 Huggingface 到 Megatron 的模型权重转换技术。如下图所示，Qwen2-VL[2] 主要由多模态编码器和 LLM 解码器两个模块组成。Qwen2-VL 采用了专门设计的多模态编码器架构，可以同时接受文本/图像/视频作为输入，并将它们转换成统一形式的表示向量后送入 LLM 解码器。这种设计使得模型能够在同一个空间内有效地捕捉到跨模态的信息关联。与 LLaVA 等多模态模型不同，Qwen2-VL 的视觉输入不需要缩放到固定分辨率大小，而是根据图像/视频数据的原始分辨率，动态生成不同长度的视觉表示向量，这一特性被称为动态分辨率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1eb93737ae6dbd05ddba2e152c5a393b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;通过将 Huggingface 模型转换到 Megatron 格式，用户可在已经充分训练好的 Qwen2-VL 基础大模型或者微调大模型上进行二次训练。所谓支持模型并行的权重转换，其核心原理是在转换时将大型模型权重分割成多个部分，并分配给不同的 GPU 进行并行加载。通过这种方式可以显著减少单个设备上的显存占用量，加快训练速度。然而，在实际应用中这一技术面临着若干挑战。在开发过程中，我们遇到的最常见问题之一是在完成权重转换后重新加载进行训练时，step 0 loss 比预期高。造成这种情况的原因主要有两个方面：一方面是模型实现风格不一致，结构映射关系十分复杂；另一方面是模型权重并行切分算法实现容易出错。因此，针对上述两种原因，Pai-Megatron-Patch 分别进行了优化。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在 Pai-Megatron-Patch 的模型转换中，针对模型结构映射关系十分复杂的问题，建模分析并构建映射表能有效对比 Huggingface 模型与 Megatron 实现的联系。下表总结了两者分别在各个算子类型上的命名对应关系。在支持模型并行的权重转换实现过程中，我们首先将 Huggingface 模型的 ckpt 赋值给 Megatron 模型，然后再在 Megatron 模型上进行 TP/PP 切分。这种先转换再切分的好处是可以提升代码的可维护性，减少转换出错的概率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ef715495d37cfd035b51f1b0d64e4bbb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;除了模块层面的实现差异，在算子层，由于 3D 并行的存在，Megatron 与 Huggingface 的权重及计算方式也存在很大区别，需要根据实际情况进行转换。针对模型权重并行切分算法实现容易出错的问题，逐算子精细化切分保证了自底向上的准确转换。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0a7d46cfbd1f0e2bdb39037f639960a9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;上图表示了一个 Huggingface 实现的 GQA 权重转换到 Megatron 的正确/错误流程，其中每个块表示一个 head 的权重，边框和内部的颜色分别代表这个 head 对应的类型及被理解成的类型。在 transformers 库中，Huggingface 采用 q_proj, k_proj, v_proj 这三个算子来计算 QKV status, 随后再调用&lt;code&gt;repeat_kv()&lt;/code&gt;函数将同一个 Query Group 内的 KV status 数量与 Query 对齐，进而调用 attention 函数。在 Megatron 中，由于张量并行的存在，Attention Module 采用了 ColumnLinear(linear_qkv) 对 QKV 统一计算，为了降低节点间通信量，这个并行 Linear 将 Query Group 均匀切分到各个 Node 上，使每个节点内就能计算一部分 attention 结果，不需要对 QKV status 进行同步。在这个 case 下，如果直接拼接 QKV 的权重张量（如图上半部分）再进行 TP 切分，可以明显看到大部分 head 位置出现问题，因此，我们需要将 QKV 权重进行一定转换，按 Query Group 的顺序进行拼接（如图下半部分）后再切分才能保证 Attention 的正确性。具体地说，在进行 TP=2 切分时，Pai-Megatron-Patch 先将 query，key 和 value 这三个 tensor 分别 reshape 成一个 4D 的 tensor，reshape 后的 shape 是&amp;lt;num_query_groups, -1, head_dim, hidden_dim&amp;gt;。接着沿着第二个维度拼接在一起，然后沿着 num_query_groups 维度进行算子拆分。才能确保并行加载 ckpt 后的起步 loss 值误差偏移在合理范围内。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//13b6f29e544514a59b0fa5f932487c7e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;用户友好的多模态数据加载&lt;/h1&gt; 
&lt;p&gt;相对于 LLM 预训练，在数据加载方面，由于引入了多个类型的数据，多模态模型的 DataLoader 尤其复杂。为了支持 LLaVA 等模型，英伟达的 Megatron 进一步推出了 Energon 来实现多模态数据的加载逻辑。尽管如此，由于目前多模态输入并无统一的格式，在目前的 Megatron 中，对于多模态数据的支持仍比较有限，具体表现在 (1) 仅支持部分格式简单的数据加载，例如每个样本至多包含一张图像或一个视频，应用场景有限;(2) 现有 TaskEncoder 输出格式固定，灵活性不大，难以高效支持模型训练。在实际开发中，Qwen2-VL 同时遇到了上述两类障碍:与已有的 LLaVA 相比，Qwen2-VL 基于 ChatML 格式设计输入，应当支持单个样本中多张图片视频、多轮对话等复杂功能，但这类数据无法使用当前 energon 的代码进行读取;此外，现有 TaskEncoder 仅支持将图片缩放到固定大小，再传入模型训练，因此难以支持 Qwen2-VL 独有的动态分辨率特性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;为了解决上述功能性问题，我们首先对内置的 DataLoader 代码做了大量扩展，使其能基于输入的原始多模态数据构造用于动态分辨率训练的图像切片序列以及位置信息，同时支持可自定义 prompt、多轮、包含任意数量图像或视频的对话样本的数据处理。在此基础上，我们设计了一套自动化脚本，能基于用户给定的 sharegpt 格式数据集路径自动转换成 energon 可读取的 webdataset 数据集，绕过当前 energon 数据集准备的交互流程，加快数据转换效率，同时降低用户学习成本。此外，对于数量不定的图像，为了能在 energon 侧自动解码，webdataset 支持将其以 numpy array 的形式保存，然而，由于 jpg 到 ndarray 间的数据格式差异，在实际测试中，我们发现这将造成最终数据集文件体积出现几倍到几十倍的增加。为了解决这个问题，我们在运行时向 webdataset 的编解码模块增加钩子函数，使其支持图像文件列表的自动编解码，实现在按原始二进制数据保存的同时能被 energon 自动转换为图像张量的需求。通过上述优化，在 Pai-Megatron-Patch 中，经过转换的 sharegpt 格式数据相对于其原始总大小几乎没有变化。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6d2c8ff40024e1e3d09c02ef056fc475.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;视觉特征处理流程优化&lt;/h1&gt; 
&lt;p&gt;与 LLM 相比，多模态模型先对视觉数据进行编码，再与文本特征拼接后送入 LLM 进行推理。与基于静态分辨率的多模态大模型不同，复杂的多模态数据格式以及动态分辨率共同使得 Qwen2-VL 的这一过程更加复杂，不仅显著影响训练效率，也与能否应用 TP Comm Overlap 等技术相关。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;与静态分辨率使用固定数量视觉 token 不同，动态分辨率技术允许模型依据输入图像大小，将其编码成不定数量的视觉特征。这一改进使模型对于高分辨率图像的细节捕捉能力获得显著提升，同时也优化了低分辨率图像的推理性能。下图是 Qwen2-VL 的训练数据的简单示例，针对不同长度的视觉 token，最终它们会被嵌入到文本序列中，与同一个 batch 的数据拼合后送入到 LLM 解码器。在这个过程中主要存在两个难点:(1) 如何对同一批次内的多个视觉输入高效获得特征表示;(2) 如何拼合数据以支持原生性能优化开关。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//739d529e86745f50251962405174bef3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;由于视觉输入的分辨率具有很大不确定性，为了将同一 batch 内的不同长度视觉数据转换成推理所需的特征表示，常见的做法是将每个视觉数据填充到相同长度后统一送入视觉模型。尽管这一方式实现简洁，但填充的 token 不仅造成了显存的浪费，同时也影响了视觉编码器的吞吐，当同一批次数据中同时包含高分辨率视频及低分辨率图像，由于视觉 token 数量的显著差异，将造成极为显著的性能浪费。对此，Pai-Megatron-Patch 借鉴了 Sequence Packing 的做法，将同一批次内的所有视觉输入打包后调用 varlen attention，来避免填充操作带来的显存/性能损耗。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//939334d510ecedf2be878901ae2b15b7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在生成视觉特征表示后，基于预先构造好的掩膜张量，视觉编码器的输出会被依次填入文本表示的对应位置，替换掉默认的占位符。在不使用任何性能优化技术的情况下，这一实现并不会带来什么问题。然而，当开启序列并行后，LanguageEmbedding 模块的输出会自动 reduce scatter 到各个 TP rank，导致基于原始输入构造的完整掩膜张量无法使用。为了解决这一问题，同时避免冗余通信，Pai-Megatron-Patch 针对性修改了 MCore 中实现的 LanguageEmbedding 模块，在输入序列拆分前增加利用掩膜张量替换文本表示的操作 ，不干扰序列并行特性的正常运行。&lt;strong&gt;在实现序列并行机制的基础上，通过进一步应用 TP Communication Overlap 特性，对于 Qwen2-VL-70B 我们在 4 机 32 卡 a100 上观察到了 6% 性能提升。（详见实验部分）&lt;/strong&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;基于优化器卸载的多模态长序列显存优化&lt;/h1&gt; 
&lt;p&gt;相对于大语言模型训练微调，由于视频、音频等模态存在，多模态大模型的输入序列长度将远远大于纯的语言模型。因此，在通常情况下，为了完成这类模型的训练微调，往往需要更多的计算资源。而当获取更多资源这条路径不可行时，在资源受限的情况下拉起任务成为这一场景下的首要挑战。在之前 Pai-Megatron-Patch 实现的优化器卸载特性基础上，最近，PAI 团队与英伟达 Megatron 团队深度合作，共建了一套原生基于 Megatron 的权重卸载优化器。在此基础上，通过与多种正交的卸载技术结合，Pai-Megatron-Patch 将四机 32 卡 A100 上的 Qwen2-VL 的最长上下文从 4K 提升至 32K。在本章节中，我们将以 BF16 训练为例，详细描述最新版权重卸载优化器的原理、实现及我们引入的最新性能优化特性--Optimizer Overlapping。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如下图，与激活重计算或激活卸载等显存优化技术不同，优化器卸载的目的在于将参数更新这一计算负载较低但显存占用相对高的步骤全部或部分放置到 CPU 上进行，以达到降低显存占用的目的。对于一个参数量为 M 的模型，Adam 会默认分配大小为 12M 字节的显存以保存全精度的参数 (4M) 及优化器状态 (8M)，当使用优化器卸载时，优化器则会将这 12M 大小的张量全部分配到内存上，同时额外分配 4M 的内存用于拷贝 GPU 上的全精度梯度数据。因此，当打开 Megatron 的分布式优化器时，以 4 机 32 卡训练 70B 为例，每张卡的显存能进一步减少约 26GB。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d9895494e5ede2ef2bfd1f6e0b119cdc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如下图所示，在最新的原生优化器卸载特性实现中，我们设计了一个混合设备优化器类 (Hybrid Device Optimizer, HDO) 来支持静态优化器卸载功能。与先前的深度修改 DistributedOptimizer，难以快速迁移到其他训练代码不同，通过在顶层沿用 PyTorch 优化器的 API，HDO 能无缝替换 TorchAdam，同时仍保留一定的优化器卸载能力。我们希望这一设计能使用户在更多场景下体验到优化器卸载带来的资源需求下降*注。整个 HDO 大致分为两部分，包括针对单个参数张量更新的底层优化器集合，以及用于管理优化器参数映射关系、优化器保存/读取、以及更新过程中子优化器间同步的 HDO 类。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f44b34f0fc6d5d9c7efc682cbcd49061.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;由于在先前版本的 Megatron-Core 中，优化器内全精度参数创建部分由 DistributedOptimizer 默认分配到 GPU 上，并不能进行卸载，导致最初 HDO 的实际显存优化仅有 8M 而非旧版深度定制 DO 的 12M。为了解决这一问题，我们修改了 DO 的参数创建逻辑，当识别到用户启用优化器卸载特性时，DO 自动将全精度参数创建这一步骤交由 HDO 进行，避免了冗余显存分配。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;注: 由于参数已经被外部创建，为了不对这些参数进行修改，这一场景下仅能将 8M 的 Adam/AdamW 优化器状态分配及参数更新移动到 CPU 上进行，对于 SGD 优化器，由于无额外的固定显存分配，HDO 没有卸载效果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;优化器初始化&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;与支持单一设备张量的优化器不同，为了实现位于不同设备上的多个张量的参数更新及性能优化，HDO 被实现为多个子优化器的集合，每个子优化器负责单一设备上的数个张量的参数更新，而 HDO 用于实现主优化器与子优化器间的优化状态同步、Device/Host 间的参数/梯度传递以及由此引发的 CUDA 同步问题。在优化器初始化阶段，相对于普通的 Adam，HDO 额外要求用户指定 CPU/CUDA 上的子优化器类型以及相应的卸载比例，随后基于这一比例对 param_groups 进行拆分，再重新构造对应设备上的子优化器。在训练阶段，由于 lr_scheduler 等外部因素可能会对优化器参数产生影响，在子优化器参数更新前，HDO 会将所有状态同步到子优化器，如果子优化器在 CPU 上更新，也会将 GPU 梯度复制到 CPU 上。由于子优化器也可能修改参数组的状态，在更新结束后，每个子优化器也会将这些状态同步到主优化器，从而保证与非优化器卸载训练的收敛一致性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;优化器保存/读取，及 卸载比例变换&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相对于 Pai-Megatron-Patch 内的优化器卸载模块，HDO 支持完整的优化器保存/读取特性，同时也支持加载优化器时切换优化器卸载比例，具有更大的灵活性。如前文所述，HDO 内部由多个子优化器负责实际参数更新，在每个参数更新阶段开始前/结束后分别进行 HDO 及子优化器间参数的同步。在保存优化器状态时，由于 HDO 内数据与子优化器一致，HDO 的 state_dict 即包含恢复优化器所需的全部信息。在加载权重时，由于子优化器需要基于 fp32 参数进行更新，我们引入了 pre_load_state_dict_hook 以及 post_load_state_dict_hook，将 HDO 的 state 中的半精度参数数据临时用保存的 fp32 替换后同步到子优化器，再替换回来，随后调用&lt;code&gt;_move_new_state_to_right_device&lt;/code&gt;，将每个子优化器的状态移动到其对应的设备。通过在运行时更新子优化器的对应设备，我们能将在一个卸载比例下保存的模型在另一个优化器卸载配置上拉起训练。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Naive Optimizer Overlapping 技术&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;与 CUDA 上的参数更新相比，基于 CPU 的参数更新性能成为优化器卸载技术是否可用的关键因素。通常，优化器卸载的时间包含三个部分：将 CUDA 梯度同步到 CPU(D2H)、在 CPU 上进行参数更新 (C)、将更新后的 CPU 参数同步到 CUDA(H2D)。为了尽可能提升性能，我们提出了一项 Naive optimizer Overlapping 技术，通过 PyTorch 的 CUDA Stream 机制，实现通信与计算重叠，将 CPU-CUDA 间数据拷贝的时间尽可能掩盖在 CPU 计算下。在 Naive optimizer Overlapping 中，我们的一个主要改进是将 CPU 子优化器进一步打散，使一个 CPU 参数对应一个 CPU 优化器，同时令所有拷贝非阻塞化。这一改进允许 HDO 在单个梯度张量同步完成后立即调用 CPU 参数更新，无需等待所有梯度完成拷贝，也允许 CPU 参数更新完成后立刻非阻塞拷贝到 GPU，从而实现重叠。为了保证多个 CUDA Stream 以及 CPU 之间正确的数据同步关系，同时尽可能避免影响性能，我们仅在关键位置引入 CUDAEvent，来避免额外流同步带来的开销。下图表示了一个理想的优化器重叠场景，其中每个参数张量的更新时间与两次数据传输接近。当流水线热身结束后（time step 2），可以看到 HDO 在两个 CUDA Stream 上进行双向的数据拷贝同时，CPU 也在同时进行参数更新。这一方式最大化掩盖了冗长的数据传输时间，&lt;strong&gt;在我们测试的 LLaMA2-70B 训练中，我们观察到该优化能减少约 1s 的端到端时间。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5ca7cdd30c2c3af2cf816eeb23f0e253.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_6&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;多模态流水并行性能优化&lt;/h1&gt; 
&lt;p&gt;多模态大模型训练微调作为英伟达 Megatron 的新特性，目前仍在持续开发中。在 3D 并行方面，目前以 LLaVA 为代表的多模态模型的类型均为 ModelType.encoder_and_decoder，它对 encoder（视觉编码器）与 decoder（LLM 解码器）分别引入了一套 TP/PP 参数，同时支持特殊的 Encoder PP 配置：当 Encoder PP&amp;gt;0 时，Megatron 会将 Encoder 放在独立的 GPU 上，允许两部分模型使用不同的 TP/PP 参数初始化；当 Encoder PP=0 时，Megatron 将 Encoder 部分按照 Decoder 的 TP 切分后，与 Decoder 的第一个 PP Stage 合并，放置在同一组 GPU 上。其中，前种切分方式一般适用于编码器/解码器结构类似、参数量接近的情况；后者则适用于视觉编码器参数量较少，计算量不大的场景。考虑到 Qwen2-VL 的视觉编码器大小以及用户体验，我们最初采用了编码器与解码器部分合并的切分方式，来保持和其他 LLM 相似的切分参数配置，减少学习成本。但在实际测试中，通过与基模型 Qwen2 对比，我们观察到这一合并显著降低了 Qwen2-VL 的训练吞吐。这主要由两方面因素导致：(1) 由于模型结构不一致，视觉编码器与 LLM 解码器的前向速度有差异，导致 micro batch 内哥 GPU 间存在负载不均衡;(2) 由于视觉编码器支持动态分辨率特性，对于每个 micro batch，实际前向的 token 数并不一致，使得每个 mciro batch 计算量略有差异，出现各 GPU 间存在负载不均衡的情况。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;为了解决上述负载不均衡的问题，进一步提升训练吞吐，在原生 Megatron 的基础上，我们从两个方向对现有框架进行改进尝试：(1) 基于非均匀切分策略间的负载均衡;(2) 拓展模型实现以支持虚拟流水线并行特性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;基于非均匀切分策略间的负载均衡：在模型总参数量较小或 PP 较大的并行配置下，pp rank 0 包含的视觉编码器带来的额外计算量相对于原有的 LLM 解码器的计算量比例有显著提升。由于在流水线中，最慢的步骤决定了整体的性能，应用 megatron 内的非均匀切分特性，将部分计算量转移到其他 pp rank 上，能有效提升整体的训练性能。为了支持基于非均匀切分的继续预训练或微调功能，我们同步更新了 Qwen2-VL 的转换模型，用户可以通过控制 MP_PP0_LAYERS 环境变量，获得非均匀切分的模型权重文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//32be076a3fe4ab8d995a8aa30ddcf555.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;虚拟流水线并行特性：虚拟流水线并行，或 interleaved 1F1B PP 是 Megatron-LM 在 1F1B 的流水线并行实现上的重要改进。它通过将同一个 pp stage 内的 transformer 层分配到多个 GPU，进一步打碎计算，通过增大通信量的方式使负载更加均衡，降低 Global Batch 内的 bubble 比例。然而， 对于 encoder_and_decoder 类型的模型（即英伟达内置的所有多模态模型），MCore 不支持启用 VPP。考虑到视觉编码器的整体计算量不需要独立 GPU，我们进一步改进了 Qwen2-VL 实现，移除了 Encoder PP 的支持，并将 Qwen2-VL 的模型类型设置为 LLM 的 encoder_or_decoder 来启用 VPP 选项。&lt;strong&gt;与官方论文的结果不同，我们观察到虚拟流水线并行也能起到训练加速效果，甚至在 H20 上，我们观察到相对于非均匀切分，虚拟流水线并行的加速效果更加明显。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_7&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;实验分析&lt;/h1&gt; 
&lt;p&gt;在本节中，我们对上述提到的技术对 Qwen2-VL 模型的性能及收敛情况展开了全面的分析，主要包括三方面：1. 权重转换精度分析：通过对比转换前后的模型测试集表现，我们验证了权重转换模块的正确性；2.多模态长序列显存优化分析：通过引入 HDO 对优化器进行卸载，在相同 GPU 数量的情形下，Pai-Megatron-Patch 大大提升了长序列训练的可用性；3.多模态模型训练性能优化：全面测试了各训练加速技术对于不同设备/模型大小的影响，论证了技术的有效性，同时为用户提供开关设置的指引。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;权重转换精度分析&lt;/h3&gt; 
&lt;p&gt;为了验证 PAI-Megatron-Patch 内多模态模型转换的正确性，我们采用 VLMEvalKit 对转换前后的 Qwen2-VL-7B 模型在多个数据集上的表现进行评估。结果如下图，其中 Ref 是 VLMEvalKit 提供的在 SEEDBench 及 MMBench 上的评估分数，Official 是官方权重在测试环境内的实测分数，Convert 为将官方原始权重进行两次转换得到的新 Huggingface 权重的分数。可以看到，转换前后的模型评估分数完全一致，且均与开源 leaderboard 指标接近，有效说明了转换代码的正确性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//03efee772c4e46b60b013c2d364ef1c2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_9&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;基于优化器卸载的多模态长序列显存优化&lt;/h3&gt; 
&lt;p&gt;在本节中，我们探索了通过 HDO 与其他显存优化技术复合，进一步提升有限机器场景下可训练上下文长度上限的可能性。我们分别测试了 Qwen2-VL 7B/72B 在单机 8 卡、四机 32 卡的无 offload 情况下的最长上下文，以及打开所有优化后的上下文长度，结果如下表。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1dc0526f3b5d0fc7ccb86254065117d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;可以看到，对于 Qwen2-VL 7B 模型，通过结合激活重计算技术及优化器卸载技术，我们将原本 64K 上下文长度的训练上限进一步拓展到 128K，且没有 OOM 风险。*对于 72B 模型，结论类似，通过结合多种正交的显存优化技术，我们也将四机 32 卡 A100 的可训练上下文长度从 16K 提升到 128K。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;*注：在单独开启重计算的情况下我们也成功在 demo 数据集上实现了 128K 上下文长度的训练，此时显存空闲不到 1G，考虑到实际场景下视觉模型占用的显存会随数据变化等原因，不推荐使用这一配置训练。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;多模态模型训练性能优化&lt;/h3&gt; 
&lt;p&gt;在本节中，我们针对两种大小的 Qwen2-VL 模型的训练场景，测试了 PAI-Megatron-Patch 当前支持的训练优化技术对吞吐的影响，来说明其在不同场景下的优势。具体地，我们采用预处理的 LLaVA-Pretrain 数据集 (参见 Qwen2-VL 的最佳实践文档) 在 4K 上下文长度下对 Qwen2-VL-7B/70B 进行训练，在最佳并行配置的基础上，进一步打开各类优化技术以比较模型性能的变化。其中，&lt;code&gt;PP0_layers&lt;/code&gt;表示开启非均匀切分时，PP Rank0 上的 LLM Decode r 层数，&lt;code&gt;TGP&lt;/code&gt;内的三个字母依次表示&lt;code&gt;tp-comm-overlap&lt;/code&gt;、&lt;code&gt;overlap-grad-reduce&lt;/code&gt;、&lt;code&gt;overlap-param-gather&lt;/code&gt;三个优化开关的启用状态。对于每个实验，我们记录了其训练时的每秒 token 数 (TGS) 及 MFU。需要注意的是，由于 megatron-core 暂不支持估计视觉编码器的 TFLOPs，记录的 MFU 仅基于 LLM 的运算量计算得到，因此略低于实际值。&lt;/p&gt; 
&lt;span id=&quot;OSC_h4_11&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;overlap 开关对训练吞吐的影响&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8ccde1833962a155ee78229e63d7572e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相对于 LLM，由于存在多个不同结构的 transformer，多模态模型并不原生支持 megatron-core 的某些 overlap 技术，同时差异化的结构也可能导致 overlap 的收益与 LLM 不同。在本节中，我们在 A100 上测试了&lt;code&gt;tp-comm-overlap&lt;/code&gt;、&lt;code&gt;overlap-grad-reduce&lt;/code&gt;、&lt;code&gt;overlap-param-gather&lt;/code&gt;三个优化开关对 Qwen2-VL 7B/72B 训练吞吐的影响，结果如上表所示。主要结论如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;对于 Qwen2-VL，可以观察到&lt;code&gt;overlap-grad-reduce&lt;/code&gt;及&lt;code&gt;overlap-param-gather&lt;/code&gt;无论在 7B/72B 模型规模上均导致了性能出现略微下降。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;相对于 72B 模型 (~8%),7B 模型开启&lt;code&gt;tp-comm-overlap&lt;/code&gt;的直接收益可以忽略不计。这主要是因为 7B 模型实际运行时的低 TP 数以及未开启 overlap 的 vision model 计算量占比相对较高。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h4_12&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;虚拟流水并行及非均匀切分对训练吞吐的影响&lt;/h4&gt; 
&lt;p&gt;基于 megatron-core 的核心能力，Pai-Megatron-Patch 为 Qwen2-VL 提供了两种性能优化方式：多模态大模型的虚拟流水并行及解码器非均匀切分技术。为了比较这两者对训练吞吐的影响差异，我们在最佳并行配置的基础上，比较了两种技术的性能上限，结果如下表。其中，VP 表示每个虚拟并行块中的解码器 Transformer 层数（区别于通常意义的 VPP Size）。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e941277896d9cc4003214357264a1e77.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;从表中我们能得出的主要结论如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;尽管&lt;code&gt;tp-comm-overlap&lt;/code&gt;仅能为 Qwen2-VL 72B 模型直接带来约 8% 的性能提升，然而，通过序列并行带来的显存优化，模型有进一步降低并行数来提升吞吐的潜力。例如在 H20 上，我们观察到，通过打开 SP 及 TP Comm overlap 开关，模型可以采用 TP4PP4 的配置进行训练，通过调整虚拟流水并行，相对于 TP8PP4 的最佳性能有额外 15% 的性能提升。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;由于各 GPU 的机内、机间带宽差异，在不同的 GPU 上，最佳优化技术有所不同。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;与 Qwen2-VL 论文的结果不同，我们的 VPP（或 1F1B interleaved）实现在 A100/H20 机器上均有一定的性能提升。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h1_13&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;总结&lt;/h1&gt; 
&lt;p&gt;在基于 Megatron 的 Qwen2-VL 多模态大模型最佳实践开发过程中，我们围绕大模型训练测试了以下核心技术的性能：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持模型并行的权重转换。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于 CPU 卸载的多模态长序列显存优化的鲁棒性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于 Megatron 的多重训练加速技术的稳定性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;运用综合加速技术来训练 Qwen2-VL 过程中的易用性和稳定性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;后续在 Pai-Megatron-Patch 中还会陆续放出更多高质量的大模型最佳实践以及最新的训练加速技术应用示例，敬请期待。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;参考文献&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen2-VL: Enhancing Vision-Language Model&#39;s Perception of the World at Any Resolution&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MMBench: Is Your Multi-modal Model an All-around Player?&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopen-compass%2FVLMEvalKit&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://github.com/open-compass/VLMEvalKit&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/17876695</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/17876695</guid>
            <pubDate>Thu, 06 Mar 2025 07:09:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>奇安信：攻击 X 平台的僵尸网络与春节攻击 DeepSeek 的为同一组织</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;美国东部时间 3 月 10 日，埃隆·马斯克一天内遭遇了双重打击：除了特斯拉股价下跌 15%、自高点几乎腰斩之外，其旗下的社交媒体 X 平台（原 Twitter）还遭遇了大规模网络攻击，导致全球范围内多次宕机，许多用户无法正常使用该应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d867334583b4a067b5d5ac7e28903e2b6f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c22e078be8628892b35aceafc606813c59c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FBSbnMTxG_piE0Mi_bH4v0A&quot; target=&quot;_blank&quot;&gt;奇安信 Xlab 实验室监测发现&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;此次攻击所使用的僵尸网络为 Mirai 变种僵尸网络 RapperBot，&lt;/strong&gt;攻击时间与 X 平台宕机时间完全吻合，主要集中在北京时间 3 月 10 日晚 10 点至 11 日凌晨 2 点。&lt;strong&gt;与 2025 年春节期间攻击 DeepSeek 的属于同一组僵尸网络&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;据称该僵尸网络常年活跃，以高强度的流量攻击闻名，平均每天攻击上百个目标，高峰时期指令上千条，能够迅速瘫痪目标服务器。攻击目标分布在巴西、白俄罗斯、俄罗斯、中国、瑞典等地区。此次攻击规模之大、烈度之猛，直接导致 X 平台在美国东部时间 3 月 10 日遭遇三次明显服务中断，最高时有 20538 名用户报告故障。&lt;/p&gt; 
&lt;p&gt;RapperBot 僵尸网络并非普通黑客组织，而是对外提供有偿攻击服务的「职业打手」。其攻击规模和资源投入远超普通网络攻击，可能涉及大型组织甚至国家层面的支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338164</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338164</guid>
            <pubDate>Thu, 06 Mar 2025 07:04:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV7-G1 0.1B 推理模型发布，最适合嵌入式的纯血 RNN 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 3 月 10 日，RWKV 基金会发布第一个 &lt;strong&gt;RWKV-7 推理模型&lt;/strong&gt;（Reasoning Model）： &lt;strong&gt;RWKV7-G1&lt;/strong&gt; 0.1B。&lt;/p&gt; 
&lt;p&gt;RWKV7-G1 系列模型拥有&lt;strong&gt;杰出的推理能力&lt;/strong&gt;，且原生支持世界 100+ 种语言和代码。即使是最小的 0.1B 也能回答&lt;strong&gt;开放性和创造性问题&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV7-G1（&quot;GooseOne&quot;）系列推理模型是基于 World v3.5 数据集&lt;strong&gt;继续训练&lt;/strong&gt; RWKV-7 &quot;Goose&quot; World 系列模型。&lt;/p&gt; 
 &lt;p&gt;World v3.5 数据集包含更多小说、网页、数学、代码和 reasoning 数据，总数据为 5.16T tokens。对于 0.1B 模型，我们会随机采样其中的 1T tokens 训练。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;目前我们已能在手机高通 8gen3 以 62 token/s 推理 RWKV-7 1.5B 模型，而 0.1B 模型在树莓派也能跑得挺快，欢迎做嵌入式的朋友加入 RWKV 技术群讨论。&lt;/p&gt; 
&lt;h2&gt;模型表现&lt;/h2&gt; 
&lt;p&gt;RWKV7-G1 0.1B 模型回答 &lt;code&gt;simulate SpaceX mars landing using python&lt;/code&gt;（使用 python 模拟 SpaceX 火星着陆）」：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV G1 0.1B simulate SpaceX mars landing using python&quot; height=&quot;2276&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a90a626d3589d084f50ce2836131854b642.jpg&quot; width=&quot;650&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;日本开发者测试 RWKV7-G1 0.1B 的多语言能力：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV7-G1-0.1B-jpn&quot; height=&quot;480&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-30c2c03d927be963bcead808ee26ffd2196.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如此小的 0.1B 模型，也能同时支持世界 100+ 种语言和代码。更大参数的 RWKV7-G1 0.4B/1.5B/2.9B &lt;strong&gt;正在同时训练中&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;英文和多语言测评&lt;/h2&gt; 
&lt;p&gt;RWKV7-G1 0.1B 的英文和多语言能力相比 RWKV-7-World 0.1B 继续提升：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;141&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c2badec5fa9dba560aa79f167930e033418.png&quot; width=&quot;1441&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们也对 RWKV7-G1 0.1B 进行了 「无法作弊的模型评测」 Uncheatable Eval，可见 RWKV7-G1 0.1B 对于多种新数据的压缩率，显著超越所有其它同尺寸的开源模型：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;154&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d64cc13d9c6b94f4752c404005bbf9b83bb.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Uncheatable Eval：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/Jellyfish042/UncheatableEval&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;训练中的 RWKV7-G1 1.5B 模型&lt;/h2&gt; 
&lt;p&gt;以下示例基于 &lt;code&gt;RWKV7-G1-1.5B-16%trained&lt;/code&gt;模型，注意这个模型目前只训练了 16%。后续 100% 训练完成的 RWKV7-G1 1.5B 会显著更强：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1556&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4b81465fc759bfe4e90f4c9969ce95b71d2.png&quot; width=&quot;812&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV7-G1-1.5B-16%trained 的示例二：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;541&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a300e868682a29ea61efa75a25523cee5fd.png&quot; width=&quot;660&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;训练中的 RWKV 模型可在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Ftemp-latest-training-models%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/temp-latest-training-models/tree/main&lt;/a&gt; 下载。&lt;/p&gt; 
&lt;h2&gt;模型试用&lt;/h2&gt; 
&lt;p&gt;可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;Hugging Face Gradio Demo&lt;/a&gt; 试用 RWKV7-G1 0.1B 模型。&lt;/p&gt; 
&lt;p&gt;G1 的整体 prompt 格式与 RWKV-7 模型类似，可选使用 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 标签开启 reasoning 功能：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 你不许参加学术派对！

Assistant: &amp;lt;think&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RWKV Runner 和 Ai00 等 RWKV 推理工具&lt;strong&gt;正在适配 reasoning 聊天模式&lt;/strong&gt;，因此目前只能在&lt;strong&gt;续写模式中&lt;/strong&gt;体验 reasoning 功能。&lt;/p&gt; 
&lt;h2&gt;模型下载&lt;/h2&gt; 
&lt;p&gt;下载已完成训练的 RWKV7-G1 0.1B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社区：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载其他训练中的 RWKV7-G1 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Ftemp-latest-training-models%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/temp-latest-training-models/tree/main &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社区：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Ftemp-latest-training-models%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/temp-latest-training-models/files&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;G1 模型发布计划&lt;/h2&gt; 
&lt;p&gt;当前已发布 G1 0.1B 模型，正在训练 G1 0.4B/1.5B/2.9B，具体发布计划如下：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;发布计划&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 0.1B&lt;/td&gt; 
   &lt;td&gt;3 月 8 日（已发布）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 0.4B&lt;/td&gt; 
   &lt;td&gt;3 月下旬&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 1.6B&lt;/td&gt; 
   &lt;td&gt;4 月&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 2.9B&lt;/td&gt; 
   &lt;td&gt;5 月&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;我们也在同时准备更大更优的数据集 &lt;strong&gt;World v3.7&lt;/strong&gt;，用于 G1 7B 训练。&lt;/p&gt; 
&lt;h2&gt;RWKV-7 学术支持&lt;/h2&gt; 
&lt;p&gt;RWKV 社区近期新增了大量 RWKV 学术研究论文，以下是截至 2025 年 2 月的 RWKV 论文数量统计表格：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;546&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ad88e36470c390ace32e587452140fa813c.png&quot; width=&quot;650&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;欢迎大家基于 RWKV-7 进行创业、科研，我们也会为基于 RWKV 的项目提供技术支持。&lt;/p&gt; 
&lt;p&gt;如果您的团队正在基于 RWKV 创业或开展研究，请联系我们！（在「RWKV 元始智能」微信公众号留言您的联系方式，或发送邮件到「contact@rwkvos.com」。）&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入 RWKV 论坛、QQ 频道和 QQ 群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn&quot; target=&quot;_blank&quot;&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 论坛：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 频道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 视频教程：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933&quot; target=&quot;_blank&quot;&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338160</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338160</guid>
            <pubDate>Thu, 06 Mar 2025 06:53:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>李想：AGI 投资远超互联网、一两年内还不具备更好的商业模式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;理想汽车 CEO 李想近日在朋友圈分享了对 AGI 的一些观点，他表示，AGI 所需的投资远超互联网，一两年内还不具备好的商业模式。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1612&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0311/144714_pwWM_2720166.png&quot; width=&quot;1002&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李想还说道，&lt;strong&gt;AGI 早期虽然自己不赚钱，但会破坏传统商业模式赚钱&lt;/strong&gt;。他还提到，新技术往往从通缩开始，AGI 的发展趋势不可阻挡。&lt;/p&gt; 
&lt;p&gt;理想汽车在 2024 年底举行 2024 理想 AI Talk ，李想当时曾就 AI 等话题展开对话。&lt;/p&gt; 
&lt;p&gt;他表示，理想汽车一年一百亿的研发，一半投在了人工智能上。大模型出现以后，人类会发生根本性的改变。互联网让信息平权，人工智能帮助实现认知和知识的平权。&lt;/p&gt; 
&lt;p&gt;李想还谈到了人工智能的三个阶段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;第一阶段，「增强能力」，主要起辅助作用，决策权在用户。例如 L3 自动驾驶，需要用户监督，并且负责任。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第二阶段，「我的助手」，助手角色，布置给它任务，它就可以独立完成，并对结果承担责任。例如 L4 自动驾驶，可以让它到学校帮忙接孩子等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第三阶段，终极阶段，「硅基家人」，不需要指示、分配任务，它就是我们的家庭成员，甚至是家庭重要的组织者。它不但了解我，它还了解我的孩子，了解我身边的朋友，甚至比我还了解。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/285159&quot; target=&quot;news&quot;&gt;理想汽车多模态认知大模型 Mind GPT 正式上线&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/270426&quot; target=&quot;news&quot;&gt;理想汽车全自研多模态认知大模型 —— Mind GPT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338155</guid>
            <pubDate>Thu, 06 Mar 2025 06:49:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>iPhone 17 系列机模曝光</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;博主 MajinBuOfficial 根据供应链获得的 CAD 数据，以 3D 打印的方式获得了 iPhone 17 全系列的机模。这批机模包括了 iPhone 17、iPhone 17 Air、iPhone 17 Pro、iPhone 17 Pro Max 四款机型，而外观信息与此前透露的谍照基本一致。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2fecc3d4611b83757346306026632dfd575.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;除了 iPhone 17 的后置摄像头排列没有太大变化之外，新的 iPhone 17 Air 采用了后置单摄的配置，并将它放置于一个长条形的横向模块当中，整机的厚度也有了明显缩小。&lt;/p&gt; 
&lt;p&gt;Pro 版本的摄像头同样变化较大，采用横向的大尺寸模组，将后置三摄、LiDAR 传感器、闪光灯、后置麦克风等元器件都收纳于其中。至于为什么苹果要预留如此巨大的模组位置，还有待观察。&lt;/p&gt; 
&lt;p&gt;此前，分析师郭明𫓹透露，新的 iPhone 17 Air 或将采用高密度电池，使其可以在紧凑尺寸之中获得更胜于以往的电池续航表现。&lt;/p&gt; 
&lt;p&gt;此外，彭博社记者 Mark Gurman 今日发文&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/338104/apple-ios-ipados-macos-design-overhaul&quot;&gt;透露&lt;/a&gt;&lt;/u&gt;，苹果将会统一 iPhone、iPad 以及 Mac 三个设备的系统界面。据 Gurman 预测，本次系统界面统一将涉及图标、菜单、界面窗口样式等内容。值得关注的是，统一后的系统界面设计将会与 visionOS 的风格保持一致，同时简化用户使用的操作步骤、方式。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0311/103415_RHy0_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，本次改动将会在 iOS19、iPadOS19 和 MacOS16 中出现。报道指出，这也是自 iOS7 后，时隔十年，苹果再一次为 iPhone 进行 UI 大改变；而 Mac 方面，MacOS16 将是自 2020 年 MacOS Big Sur 发布以来，苹果对 MacOS 最大的一次升级。&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335621&quot; target=&quot;news&quot;&gt;iPhone 17 系列 CAD 图曝光&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338104/apple-ios-ipados-macos-design-overhaul&quot; target=&quot;news&quot;&gt;苹果计划对 iOS、iPadOS 和 macOS 系统外观进行大幅重新设计&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338152</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338152</guid>
            <pubDate>Thu, 06 Mar 2025 06:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>越疆发布 Dobot Atom：全球首款「灵巧操作+直膝行走」具身智能人形机器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;深圳越疆科技今日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1EkREYbEsg%2F&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;&lt;/u&gt;了全球首款「灵巧操作 + 直膝行走」具身智能人形机器人 Dobot Atom，可实现跨场景、多台协同胜任复杂操作泛化任务。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1502&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0311/143353_pHFB_2720166.png&quot; width=&quot;2430&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，该款机器人是面向工业级精细操作全尺寸仿生人形机器人，搭载自研操作技能模型 ROM-1，具有神经驱动灵巧操作和仿人直膝步态行走两大特征。&lt;/p&gt; 
&lt;p&gt;区别于传统机器人，该产品通过「脑-手协同」技术突破，结合视觉感知与五指灵巧手闭环操作，无需预编程即可自主完成上百种复杂任务。&lt;/p&gt; 
&lt;p&gt;官方介绍称，这台为「打工」而生的工业级操作类人形机器人，身高 1.53 米，体重 62 公斤，采用 1:1 仿人手臂构型设计，全身配置 41 个自由度，搭载重复定位精度 ±0.05mm 的 7 自由度工业级仿生协作臂，适应常见 700-1000mm 工作台高度灵巧作业，并具有工业现场稳定通过能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fbf5c225d2fa360687b55084e48cf17f3d8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;作为中国首款具备工业级双臂操作与仿人直膝行走能力的人形机器人，其核心搭载越疆自研的神经驱动灵巧操作系统（NDS）与仿人直膝行走系统（AWS），双臂协同灵巧操作，高还原度仿人直膝行走，这种同时拥有上下肢体高水平运动和控制表现的能力，标志着人形机器人操作领域取得重要进展。&lt;/p&gt; 
&lt;p&gt;NDS 系统通过端到端自主推理，赋予机器人 28 个上肢自由度及伺服级抖动抑制能力，可完成工具制造、脆弱物料无损抓取（如车厘子）等复杂任务，操作精度高达 ±0.05mm。&lt;/p&gt; 
&lt;p&gt;AWS 系统则基于类人生物力学与强化学习技术，实现高度拟人的直膝行走和灵活转身，适配短程狭小空间作业需求。其自适应泛化能力尤为突出，仅需 2 小时采集少量数据即可掌握新技能，显著提升非结构化场景下的操作效率。&lt;/p&gt; 
&lt;p&gt;据官方介绍，这台人形机器人的核心零部件、软硬件系统采用了自主研发的工业级方案，主要面向数以千计用工的车厂组装备料环节、咖啡店制饮多台设备的流程操作、连锁药店夜间取药等场景，即设备位置不固定、产品多规格、操作相似度高，并有短程狭小空间通过、灵活转身操作需求的工业商业连续重复工作场景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338149</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338149</guid>
            <pubDate>Thu, 06 Mar 2025 06:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马斯克尝试用 AI 取代美国公务员</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theatlantic.com%2Ftechnology%2Farchive%2F2025%2F03%2Fgsa-chat-doge-ai%2F681987%2F&quot; target=&quot;_blank&quot;&gt;大西洋月刊报道称&lt;/a&gt;&lt;/u&gt;，马斯克领导的政府效率部（DOGE）正在努力缩减和重组美国公务员队伍，这一努力已进入新阶段。其理念很简单：&lt;strong&gt;利用生成式人工智能来自动化以前由人完成的工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0311/142816_kg1u_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;美国政府正在与美国总务管理局（GSA）的 1,500 名联邦雇员一起测试一款新型聊天机器人 「GSA Chat」&amp;nbsp;，并可能最早于本周五向整个机构发布，这意味着超过 10,000 名负责超过 1,000 亿美元合同和服务的工作人员可以使用这款机器人。&lt;/p&gt; 
&lt;p&gt;这款聊天机器人被 GSA 领导层视为提升联邦工作人员生产力的工具，是政府效率部及其盟友更大行动方案的一部分。谈到 GSA 的整体计划时，最近被任命为 GSA 信息技术部门 —— 技术转型服务局局长的前特斯拉工程师托马斯・谢德上个月在全体员工会议上表示，&lt;strong&gt;该机构正在推进「人工智能优先战略」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;谢德称，「正如大家所知，随着我们缩减联邦政府的整体规模，仍有大量项目需要保留，这为技术和自动化全面发挥作用提供了巨大机遇」。他提出，可以在政府范围内提供「编码代理」—— 指的是能够代替人类编写并可能部署代码的 AI 程序。此外，谢德还表示，AI 可以「对合同进行分析」，软件可用于「自动化」GSA 的「财务职能」。&lt;/p&gt; 
&lt;p&gt;目前，在工作中使用人工智能很常见，GSA 的聊天机器人可能不会对政府运作产生巨大影响。但这只是政府效率部继续大幅削减公务员体系的一个小例子。据报道，在教育部，政府效率部顾问将有关机构支出的敏感数据输入 AI 程序，以确定削减开支的方向。据说政府效率部打算利用 AI 来帮助决定政府各部门的员工是否应保住工作。&lt;/p&gt; 
&lt;p&gt;在上周晚些时候的另一场 TTS 会议上，谢德表示，他预计该部门在几周内规模将「至少缩小 50%」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338147/musk-replacing-workers-with-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338147/musk-replacing-workers-with-ai</guid>
            <pubDate>Thu, 06 Mar 2025 06:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RISC-V 工委会：征集《RISC-V 指令集架构矩阵扩展（ME）指令集》等三项团体标准参编单位</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国电子工业标准化技术协会 RISC-V 工委会发布「关于公开征集《RISC-V 指令集架构矩阵扩展（ME）指令集》等三项团体标准参编单位的通知」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通知内容指出，由阿里巴巴达摩院（杭州）科技发起制定的《RISC-V 指令集架构矩阵扩展（ME）指令集》、进迭时空（杭州）科技发起制定的《开放精简指令集（RISC-V）配置文件》，以及由芯升科技发起制定的《RISC-V 指令集架构无线矢量扩展（Zvw）指令集》三项团体标准已获批立项。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为更高质量地完成标准编制工作，保障标准的广泛性、科学性和实用性，现向全行业及 RISC-V 工委会成员征集上述三项团体标准参编单位，共同完成标准的制定工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;383&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0311/142732_nWVQ_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;报名条件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1、参编单位具备相关领域工作基础，具有较高的社会影响力，重视标准化工作，能够提供技术专家作为参编人员参与标准编制。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2、参编单位应指定固定的起草人员，能够确保参与标准制修订过程中的各项会议，按时完成标准编制组分配的工作任务。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3、起草人应具备相应的专业知识、经验和能力，了解产业现状和技术发展水平。同时较熟悉标准化工作流程，具有标准制修订相关工作经验的优先。起草人应及时对标准提出建设性意见建议。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4、在可以公开的前提下，参编单位向标准编制工作组提供相关研究成果、经典案例和数据，供编制标准组参考。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjAQEyU7kzEWgp9HefHji_g&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338146</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338146</guid>
            <pubDate>Thu, 06 Mar 2025 06:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Composio —— 适用于 AI 代理的生产就绪工具集</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p style=&quot;color:#1f2328; text-align:start&quot;&gt;&lt;strong&gt;Composio 为 AI 代理提供可用于生产的工具集&lt;/strong&gt;，提供：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;支持多个类别的 250 多种工具：
&lt;ul&gt;
&lt;li&gt;GitHub、Notion、Linear、Gmail、Slack、Hubspot、Salesforce 等软件工具 &amp;amp;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://app.composio.dev/apps&quot;&gt;更多&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;操作系统操作, 包括文件工具、shell 工具、代码分析工具 &amp;amp;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://app.composio.dev/apps&quot;&gt;更多&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;通过 Google、Perplexity、Tavily 和 Exa 实现搜索功能 &amp;amp;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://app.composio.dev/apps&quot;&gt;更多&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;全面的框架支持，包括 OpenAI、 Groq、Claude、LlamaIndex、Langchain、CrewAI、Autogen、Gemini 以及&lt;a href=&quot;https://docs.composio.dev/framework&quot;&gt;更多&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;支持多种协议 (OAuth、API 密钥、Basic JWT) 的托管身份验证&lt;/li&gt;
&lt;li&gt;通过优化设计将工具调用准确率提高高达 40%&lt;/li&gt;
&lt;li&gt;用于后端集成的白标解决方案&lt;/li&gt;
&lt;li&gt;支持自定义工具和扩展的可插拔架构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;500&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/163052_S7VK_4252687.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/composio</link>
            <guid isPermaLink="false">https://www.oschina.net/p/composio</guid>
            <pubDate>Thu, 06 Mar 2025 06:15:00 GMT</pubDate>
        </item>
        <item>
            <title>稚晖君发布灵犀 X2，具备复杂交互能力的「灵动机器人」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元机器人宣布其新款人形机器人灵犀 X2 正式上线，具备完善的运动、交互及作业能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;灵犀 X2&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;由智元旗下的机器人实验室 X-Lab 开发，全身共 28 个自由度、体重 33.8 千克，小脑控制器、域控制器、智能电源管理系统、核心关节模组全线自研。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;iframe frameborder=&quot;0&quot; height=&quot;350&quot; scrolling=&quot;no&quot; src=&quot;https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114138890110697&amp;amp;bvid=BV1JYRjYoEzE&amp;amp;cid=28800323370&amp;amp;p=1&quot; style=&quot;box-sizing: inherit; font-family: -apple-system, BlinkMacSystemFont, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;, &amp;quot;Segoe UI&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(0, 0, 0); background-color: rgb(255, 255, 255);&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元机器人创始人彭志辉（稚晖君）在视频中，着重介绍了这款机器人的关节、仿生足弓、灵巧手，以及散热、续航能力，该机器人采用柔性材料，可与手机联动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;灵犀 X2 不仅可以像人一样自然走路，也能跑、能转、能跳点小舞，会滑板车、玩平衡车、骑自行车。该机器人搭载情感计算引擎。彭志辉称，灵犀 X2 搭载了多模态交互大模型「硅光动语」，因此它是第一台真正具备复杂交互能力的「灵动机器人」，具备毫秒级交互反应，以及通过视觉理解和认知世界的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;灵犀 X2 可进行远程裸眼 3D 交流。还可模仿人类呼吸韵律、具备人类好奇心和注意力机制、会一些小动作等肢体语言。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338139</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338139</guid>
            <pubDate>Thu, 06 Mar 2025 05:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国信通院启动大模型应用交付生态图谱编制</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国信息通信研究院（简称 「中国信通院」）现已正式开展大模型应用交付生态图谱编制工作，面向产业各界开放报名渠道。该图谱旨在深入洞察大模型应用生态发展趋势，全面梳理大模型交付供应商、需求方等产业主体的情况，把握当下大模型实际落地进展，持续推动大模型应用生态的高质量发展，促进产业链各环节的深度合作与交流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本图谱从产业供需出发，设定了需求方、供应商两大视角。一方面需求方可通过图谱关注供应商可支持的能力，包括交付大模型应用、模型服务、大模型相关平台或私域模型部署、全栈能力交付等多种内容，以及提供项目前期的咨询服务以及项目上线后的运营管理等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面供应商可通过图谱了解需求方市场所倾向的行业场景，把握当下需求热点，反哺产品迭代更新。本图谱内容将不断更新完善，为行动计划后续工作做好铺垫，在大模型产业分析研究报告、大模型项目供需对接会等活动中发挥作用，并作为大模型应用交付供应商名录的重要参考依据。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;现面向产业各界开放大模型应用交付生态图谱参与渠道，有意参与的企业可于 2025 年 3 月 22 日前完成填写。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMzspp_8L1Bze7DbGiirONA&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338137</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338137</guid>
            <pubDate>Thu, 06 Mar 2025 05:47:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>网易有道完成翻译底层技术迭代，宣称「翻译质量全球第一」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 11 日，网易有道&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fg4SqrMDbb9C41pChnjWGeQ&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;完成翻译底层技术迭代，基于自主研发的&lt;strong&gt;子曰翻译大模型 2.0&lt;/strong&gt;，在测试中实现翻译质量超越国内外主流通用大模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0311/114216_wW5E_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此次突破，也标志着国产大模型在专业领域取得实质性进展，通过数据、算法等技术创新，使得小参数垂类模型实现性能大幅提升。&lt;/p&gt; 
&lt;p&gt;据了解，搭载全新大模型的翻译已在有道词典、有道翻译及有道翻译官内上线，提供标准模型、高级模型两种不同参数选择。另外，有道词典笔 X7 系列也已升级为最新翻译大模型，其余型号将陆续更新。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338122</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338122</guid>
            <pubDate>Thu, 06 Mar 2025 03:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Spring Boot 的 20 个实用技巧</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&amp;gt; &lt;strong&gt;文章首发公众号『风象南』&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Java 开发领域，Spring Boot 以简化配置、快速开发等特性，目前成为必不可少的开发框架。但在日常开发中，还有许多实用技巧能让我们更高效地使用 Spring Boot。今天分享工作中常用的 20 个实用技巧。&lt;/p&gt; 
&lt;h3&gt;1. @ConfigurationProperties 管理复杂配置&lt;/h3&gt; 
&lt;p&gt;在复杂项目中，配置项众多，分散在各处的配置不利于管理。这时，&lt;code&gt;@ConfigurationProperties&lt;/code&gt;注解就能派上用场。它能将多个相关配置映射到一个类中，使代码更简洁。&lt;/p&gt; 
&lt;p&gt;定义一个配置类：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.context.properties.ConfigurationProperties;

@ConfigurationProperties(prefix = &quot;app&quot;)
public class AppProperties {
    private String name;
    private int version;

    // getters and setters
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;配置文件中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;app:
  name: mySpringApp
  version: 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在其他组件中，通过&lt;code&gt;@Autowired&lt;/code&gt;注入&lt;code&gt;AppProperties&lt;/code&gt;，就可以方便地获取配置信息：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Component
public class MyComponent {
    @Autowired
    private AppProperties appProperties;

    public void doSomething() {
        String appName = appProperties.getName();
        int appVersion = appProperties.getVersion();
        // 使用配置信息进行业务逻辑处理
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 自定义启动 Banner&lt;/h3&gt; 
&lt;p&gt;每次启动 Spring Boot 应用，看到默认的启动 Banner 是不是觉得有点单调？其实，我们可以自定义这个 Banner，让启动界面充满个性。只需在&lt;code&gt;src/main/resources&lt;/code&gt;目录下创建一个&lt;code&gt;banner.txt&lt;/code&gt;文件，在里面写入你想要展示的内容，比如公司 logo、项目名称、版本号等。&lt;/p&gt; 
&lt;p&gt;例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; ____ _ _ _
| _ \| | (_) | | |
| |_) | __ _ ___| |__ _ _ __ ___  __ _| |_
| _ &amp;amp;lt; / _` |/ __| &#39;_ \| | &#39;_ ` _ \ / _` | __|
| |_) | (_| | (__| | | | | | | | | | (_| | |_
|____/ \__,_|\___|_| |_|_|_| |_| |_|\__,_|\__|
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这样，下次启动应用时，就能看到自定义的 Banner 。&lt;/p&gt; 
&lt;h3&gt;3. 排除不必要的自动配置&lt;/h3&gt; 
&lt;p&gt;Spring Boot 的自动配置功能十分强大，但有时我们并不需要加载所有的自动配置组件，这时候可以使用&lt;code&gt;@SpringBootApplication&lt;/code&gt;的&lt;code&gt;exclude&lt;/code&gt;属性来排除不需要的模块，从而加快启动速度，减少内存占用。&lt;/p&gt; 
&lt;p&gt;比如，若项目中不使用数据库相关的自动配置，可以这样写：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;

@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})
public class MyApplication {
    public static void main(String[] args) {
        SpringApplication.run(MyApplication.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通过排除&lt;code&gt;DataSourceAutoConfiguration&lt;/code&gt;，Spring Boot 在启动时就不会尝试加载数据库相关的配置和组件，启动过程更加轻量化。&lt;/p&gt; 
&lt;h3&gt;4. CommandLineRunner 执行启动任务&lt;/h3&gt; 
&lt;p&gt;当 Spring Boot 应用启动完成后，有时我们需要执行一些初始化任务，比如初始化数据库、加载默认数据等。这时，&lt;code&gt;CommandLineRunner&lt;/code&gt;接口就能派上用场。&lt;/p&gt; 
&lt;p&gt;创建一个实现&lt;code&gt;CommandLineRunner&lt;/code&gt;接口的组件：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.CommandLineRunner;
import org.springframework.stereotype.Component;

@Component
public class StartupRunner implements CommandLineRunner {
    @Override
    public void run(String... args) throws Exception {
        System.out.println(&quot;Application started, running initial tasks...&quot;);
        // 在这里编写具体的初始化任务逻辑，比如数据库初始化操作
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Spring Boot 在启动过程中，会检测到实现了&lt;code&gt;CommandLineRunner&lt;/code&gt;接口的组件，并在应用启动完成后，按顺序执行它们的&lt;code&gt;run&lt;/code&gt;方法。如果有多个&lt;code&gt;CommandLineRunner&lt;/code&gt;实现类，可以通过实现&lt;code&gt;org.springframework.core.Ordered&lt;/code&gt;接口或使用&lt;code&gt;@Order&lt;/code&gt;注解来指定执行顺序。&lt;/p&gt; 
&lt;h3&gt;5. SpringApplicationBuilder 自定义启动方式&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;SpringApplicationBuilder&lt;/code&gt;为我们提供了更多灵活的启动配置方式，通过链式调用，可以在代码层面方便地设置应用的各种属性。&lt;/p&gt; 
&lt;p&gt;例如，设置应用的运行环境为开发环境，并指定服务器端口为 8081：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.SpringApplication;
import org.springframework.boot.builder.SpringApplicationBuilder;

public class MyApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(MyApplication.class)
               .profiles(&quot;dev&quot;)
               .properties(&quot;server.port=8081&quot;)
               .run(args);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这种方式特别适合一些需要根据不同条件灵活配置启动参数的场景，相比在配置文件中设置，在代码中控制更加直观和便捷。&lt;/p&gt; 
&lt;h3&gt;6. &lt;a href=&quot;https://my.oschina.net/u/3524728&quot;&gt;@Profile&lt;/a&gt; 切换不同环境配置&lt;/h3&gt; 
&lt;p&gt;在开发、测试、生产等不同环境中，应用的配置往往有所不同，比如数据库连接信息、日志级别等。Spring Boot 的&lt;code&gt;@Profile&lt;/code&gt;注解可以轻松实现不同环境配置的切换。&lt;/p&gt; 
&lt;p&gt;首先，定义不同环境的配置类：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Profile;
import javax.sql.DataSource;
import org.apache.commons.dbcp2.BasicDataSource;

@Configuration
public class DataSourceConfig {

    @Bean
    @Profile(&quot;dev&quot;)
    public DataSource devDataSource() {
        BasicDataSource dataSource = new BasicDataSource();
        dataSource.setUrl(&quot;jdbc:mysql://localhost:3306/devdb&quot;);
        dataSource.setUsername(&quot;devuser&quot;);
        dataSource.setPassword(&quot;devpassword&quot;);
        return dataSource;
    }

    @Bean
    @Profile(&quot;prod&quot;)
    public DataSource prodDataSource() {
        BasicDataSource dataSource = new BasicDataSource();
        dataSource.setUrl(&quot;jdbc:mysql://localhost:3306/proddb&quot;);
        dataSource.setUsername(&quot;produser&quot;);
        dataSource.setPassword(&quot;prodpassword&quot;);
        return dataSource;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后，在&lt;code&gt;application.yaml&lt;/code&gt;中指定当前激活的环境：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;spring:
  profiles:
    active: dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这样，Spring Boot 会根据&lt;code&gt;spring.profiles.active&lt;/code&gt;的值，自动加载对应的环境配置类，方便我们在不同环境下快速切换配置。&lt;/p&gt; 
&lt;h3&gt;7. @ConditionalOnProperty 控制 Bean 加载&lt;/h3&gt; 
&lt;p&gt;有时，我们希望根据配置文件中的某个属性值来决定是否加载某个 Bean，&lt;code&gt;@ConditionalOnProperty&lt;/code&gt;注解就可以满足这个需求，实现按需加载 Bean。&lt;/p&gt; 
&lt;p&gt;例如，假设有一个功能开关&lt;code&gt;featureX.enabled&lt;/code&gt;，只有当该开关为&lt;code&gt;true&lt;/code&gt;时，才加载&lt;code&gt;FeatureX&lt;/code&gt;这个 Bean：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class FeatureConfig {

    @Bean
    @ConditionalOnProperty(name = &quot;featureX.enabled&quot;, havingValue = &quot;true&quot;)
    public FeatureX featureX() {
        return new FeatureX();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在&lt;code&gt;application.properties&lt;/code&gt;中配置：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;featureX.enabled=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;当&lt;code&gt;featureX.enabled&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;时，Spring Boot 会创建&lt;code&gt;FeatureX&lt;/code&gt;的 Bean；若为&lt;code&gt;false&lt;/code&gt;，则不会创建，可以根据条件动态控制 Bean 的加载。&lt;/p&gt; 
&lt;h3&gt;8. 使用 DevTools 加快开发效率&lt;/h3&gt; 
&lt;p&gt;Spring Boot DevTools 是一个专门为开发过程提供便利的工具，它包含了代码热重载、缓存禁用等功能，能大大加快开发调试的速度。&lt;/p&gt; 
&lt;p&gt;只需要在&lt;code&gt;pom.xml&lt;/code&gt;文件中引入 DevTools 依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupid&amp;gt;org.springframework.boot&amp;lt;/groupid&amp;gt;
    &amp;lt;artifactid&amp;gt;spring-boot-devtools&amp;lt;/artifactid&amp;gt;
    &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;引入后，当我们修改代码保存时，应用会自动重启，无需手动重启，节省了大量开发时间。&lt;/p&gt; 
&lt;h3&gt;9. 整合 Actuator 监控应用&lt;/h3&gt; 
&lt;p&gt;Spring Boot Actuator 是一个强大的监控和管理工具，通过它，我们可以轻松了解应用的运行状态、性能指标等信息。&lt;/p&gt; 
&lt;p&gt;首先，在&lt;code&gt;pom.xml&lt;/code&gt;中引入 Actuator 依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupid&amp;gt;org.springframework.boot&amp;lt;/groupid&amp;gt;
    &amp;lt;artifactid&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactid&amp;gt;
&amp;lt;/dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;引入后，应用会自动暴露一些内置的端点，比如：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;/health&lt;/code&gt;：用于查看应用的健康状况，返回&lt;code&gt;UP&lt;/code&gt;表示应用正常运行。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;/metrics&lt;/code&gt;：可以获取应用的各种指标数据，如内存使用情况、HTTP 请求数、CPU 使用率等。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;/info&lt;/code&gt;：可以展示应用的一些自定义信息，比如版本号、构建时间等，需要在&lt;code&gt;application.yaml&lt;/code&gt;中配置相关信息：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;info:
  app:
    name: MySpringApp
    version: 1.0.0
  build:
     time: 2024-10-01T12:00:00Z
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通过这些端点，我们能更好地监控和管理 Spring Boot 应用，及时发现和解决潜在问题。&lt;/p&gt; 
&lt;h3&gt;10. 数据校验 @Validated&lt;/h3&gt; 
&lt;p&gt;在接收用户输入或处理业务数据时，数据校验不可或缺。Spring Boot 整合了 Java Validation API，借助&lt;code&gt;@Validated&lt;/code&gt;注解，我们能轻松实现数据校验功能。通过在方法参数前添加&lt;code&gt;@Validated&lt;/code&gt;，并结合各种校验注解（如&lt;code&gt;@NotNull&lt;/code&gt;、&lt;code&gt;@Size&lt;/code&gt;、&lt;code&gt;@Pattern&lt;/code&gt;等），Spring Boot 会自动对输入数据进行校验，校验不通过时会抛出异常，便于我们统一处理。&lt;/p&gt; 
&lt;p&gt;比如，我们有一个用户注册的 DTO 类：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import javax.validation.constraints.NotBlank;
import javax.validation.constraints.Pattern;

public class UserRegistrationDTO {
    @NotBlank(message = &quot;Username cannot be blank&quot;)
    private String username;

    @Pattern(regexp = &quot;^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$&quot;, message = &quot;Invalid email format&quot;)
    private String email;

    // getters and setters
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在控制器方法中使用&lt;code&gt;@Validated&lt;/code&gt;进行校验：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class UserController {

    @PostMapping(&quot;/register&quot;)
    public String registerUser(@Validated @RequestBody UserRegistrationDTO userDTO) {
        // 业务逻辑，处理注册
        return &quot;User registered successfully&quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;11. 优雅处理异常&lt;/h3&gt; 
&lt;p&gt;在 Spring Boot 应用中，统一处理异常是非常重要的，它可以提高应用的健壮性和用户体验。我们可以通过创建一个全局异常处理器来捕获并处理应用中抛出的各种异常。&lt;/p&gt; 
&lt;p&gt;创建一个全局异常处理类，使用&lt;code&gt;@ControllerAdvice&lt;/code&gt;注解：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;

@ControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(Exception.class)
    public ResponseEntity&amp;lt;string&amp;gt; handleGeneralException(Exception ex) {
        return new ResponseEntity&amp;amp;lt;&amp;amp;gt;(&quot;An error occurred: &quot; + ex.getMessage(), HttpStatus.INTERNAL_SERVER_ERROR);
    }

    @ExceptionHandler(NullPointerException.class)
    public ResponseEntity&amp;lt;string&amp;gt; handleNullPointerException(NullPointerException ex) {
        return new ResponseEntity&amp;amp;lt;&amp;amp;gt;(&quot;A null pointer exception occurred: &quot; + ex.getMessage(), HttpStatus.BAD_REQUEST);
    }
    // 可以继续添加其他类型异常的处理方法
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通过这种方式，当应用中抛出异常时，会被全局异常处理器捕获，并根据异常类型返回相应的 HTTP 状态码和错误信息，使前端能更好地处理异常情况，同时也方便开发人员定位问题。&lt;/p&gt; 
&lt;h3&gt;12. 利用 AOP 进行日志记录和性能监控&lt;/h3&gt; 
&lt;p&gt;AOP（面向切面编程）在 Spring Boot 中是一个非常强大的功能，我们可以利用它来进行日志记录、性能监控等横切关注点的处理，避免在业务代码中大量重复编写相关逻辑。&lt;/p&gt; 
&lt;p&gt;首先，在&lt;code&gt;pom.xml&lt;/code&gt;中引入 AOP 依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupid&amp;gt;org.springframework.boot&amp;lt;/groupid&amp;gt;
    &amp;lt;artifactid&amp;gt;spring-boot-starter-aop&amp;lt;/artifactid&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后，创建一个切面类：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;

@Aspect
@Component
public class LoggingAndPerformanceAspect {
    private static final Logger logger = LoggerFactory.getLogger(LoggingAndPerformanceAspect.class);

    @Around(&quot;@annotation(org.springframework.web.bind.annotation.RequestMapping)&quot;)
    public Object logAndMeasurePerformance(ProceedingJoinPoint joinPoint) throws Throwable {
        long startTime = System.currentTimeMillis();
        logger.info(&quot;Start executing method: {}&quot;, joinPoint.getSignature().getName());
        try {
            return joinPoint.proceed();
        } finally {
            long endTime = System.currentTimeMillis();
            logger.info(&quot;Method {} executed in {} ms&quot;, joinPoint.getSignature().getName(), endTime - startTime);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述切面类通过&lt;code&gt;@Around&lt;/code&gt;注解，对所有被&lt;code&gt;@RequestMapping&lt;/code&gt;注解标记的方法进行环绕增强，在方法执行前后记录日志，并统计方法执行的时间，方便我们对应用的性能进行监控和分析，同时也能更好地了解方法的调用情况。&lt;/p&gt; 
&lt;h3&gt;13. 配置嵌入式 Servlet 容器&lt;/h3&gt; 
&lt;p&gt;Spring Boot 默认使用嵌入式 Servlet 容器（如 Tomcat）来运行应用，我们可以通过配置文件或编程方式对其进行自定义配置，以优化性能或满足特定需求。&lt;/p&gt; 
&lt;p&gt;在&lt;code&gt;application.yaml&lt;/code&gt;中配置 Tomcat 的最大线程数和连接数：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;server:
  tomcat:
    max-threads: 200
    max-connections: 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果需要更复杂的配置，也可以通过编程方式来实现&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.apache.catalina.connector.Connector;
import org.apache.coyote.http11.Http11NioProtocol;
import org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class TomcatConfig {

    @Bean
    public TomcatServletWebServerFactory tomcatServletWebServerFactory() {
        TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory();
        Connector connector = new Connector(Http11NioProtocol.class.getName());
        connector.setPort(8080);
        Http11NioProtocol protocol = (Http11NioProtocol) connector.getProtocolHandler();
        protocol.setMaxThreads(200);
        protocol.setMaxConnections(1000);
        factory.addAdditionalTomcatConnectors(connector);
        return factory;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通过这种方式，可以根据项目的实际情况，灵活调整 Servlet 容器的参数。&lt;/p&gt; 
&lt;h3&gt;14. 缓存数据提升性能&lt;/h3&gt; 
&lt;p&gt;在 Spring Boot 应用中，合理使用缓存可以显著提升应用的性能，减少数据库查询次数，提高响应速度。Spring Boot 提供了强大的缓存支持，通过&lt;code&gt;@EnableCaching&lt;/code&gt;注解开启缓存功能，并使用&lt;code&gt;@Cacheable&lt;/code&gt;等注解来标记需要缓存的方法。&lt;/p&gt; 
&lt;p&gt;首先，在启动类或配置类上添加&lt;code&gt;@EnableCaching&lt;/code&gt;注解：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cache.annotation.EnableCaching;

@SpringBootApplication
@EnableCaching
public class MyApplication {
    public static void main(String[] args) {
        SpringApplication.run(MyApplication.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后，在需要缓存结果的方法上使用&lt;code&gt;@Cacheable&lt;/code&gt;注解：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.cache.annotation.Cacheable;
import org.springframework.stereotype.Service;

@Service
public class UserService {

    @Cacheable(value = &quot;users&quot;, key = &quot;#id&quot;)
    public User getUserById(Long id) {
        // 这里执行查询数据库等操作获取用户信息
        User user = new User();
        user.setId(id);
        user.setName(&quot;John Doe&quot;);
        return user;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述代码中，&lt;code&gt;@Cacheable&lt;/code&gt;注解表示当&lt;code&gt;getUserById&lt;/code&gt;方法被调用时，如果缓存中已经存在对应&lt;code&gt;id&lt;/code&gt;的用户信息，则直接从缓存中返回，不再执行方法内部的数据库查询操作。&lt;code&gt;value&lt;/code&gt;属性指定缓存的名称，&lt;code&gt;key&lt;/code&gt;属性指定缓存的键。&lt;/p&gt; 
&lt;h3&gt;15. 异步任务处理&lt;/h3&gt; 
&lt;p&gt;在 Spring Boot 应用中，有些任务可能比较耗时，如果在主线程中执行，会影响应用的响应速度。通过&lt;code&gt;@Async&lt;/code&gt;注解，我们可以将这些任务异步执行，使主线程能够迅速返回，提升用户体验。&lt;/p&gt; 
&lt;p&gt;首先，在启动类或配置类上添加&lt;code&gt;@EnableAsync&lt;/code&gt;注解，开启异步任务支持：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.scheduling.annotation.EnableAsync;

@SpringBootApplication
@EnableAsync
public class MyApplication {
    public static void main(String[] args) {
        SpringApplication.run(MyApplication.class, args);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后，在需要异步执行的方法上使用&lt;code&gt;@Async&lt;/code&gt;注解：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

@Service
public class TaskService {

    @Async
    public void processLongTask() {
        // 模拟一个耗时任务，比如复杂的数据处理、远程调用等
        try {
            Thread.sleep(5000);
            System.out.println(&quot;Long task completed.&quot;);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;当调用&lt;code&gt;processLongTask&lt;/code&gt;方法时，它会在一个新的线程中执行，不会阻塞主线程，应用可以继续处理其他请求。&lt;/p&gt; 
&lt;h3&gt;16. 配置文件外部化&lt;/h3&gt; 
&lt;p&gt;在生产环境中，我们常常需要在不重新打包应用的情况下修改配置。Spring Boot 支持将配置文件外部化，这样可以方便地在不同环境中调整配置。常见的方式是将配置文件放置在应用运行目录的&lt;code&gt;config&lt;/code&gt;文件夹下，或者通过命令行参数指定配置文件路径。&lt;/p&gt; 
&lt;p&gt;假设我们有一个&lt;code&gt;application.yaml&lt;/code&gt;文件，内容如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;app:
  message: Hello, World!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在应用启动时，可以通过以下命令指定外部配置文件路径：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;java -jar your-application.jar --spring.config.location=file:/path/to/your/config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这样，即使应用已经打包成&lt;code&gt;jar&lt;/code&gt;文件，也能轻松修改配置，无需重新构建和部署应用。另外，还可以使用 Spring Cloud Config 实现集中化的配置管理，在分布式系统中更方便地管理各个服务的配置。&lt;/p&gt; 
&lt;h3&gt;17. 动态数据源切换&lt;/h3&gt; 
&lt;p&gt;在某些业务场景下，一个应用可能需要连接多个数据源，根据不同的业务需求动态切换数据源。Spring Boot 提供了灵活的机制来实现这一点。首先，配置多个数据源：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.boot.jdbc.DataSourceBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.jdbc.core.JdbcTemplate;

import javax.sql.DataSource;

@Configuration
public class DataSourceConfig {

    @Bean
    @ConfigurationProperties(prefix = &quot;spring.datasource.first&quot;)
    public DataSource firstDataSource() {
        return DataSourceBuilder.create().build();
    }

    @Bean
    @ConfigurationProperties(prefix = &quot;spring.datasource.second&quot;)
    public DataSource secondDataSource() {
        return DataSourceBuilder.create().build();
    }

    @Bean
    public JdbcTemplate firstJdbcTemplate(@Qualifier(&quot;firstDataSource&quot;) DataSource dataSource) {
        return new JdbcTemplate(dataSource);
    }

    @Bean
    public JdbcTemplate secondJdbcTemplate(@Qualifier(&quot;secondDataSource&quot;) DataSource dataSource) {
        return new JdbcTemplate(dataSource);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后，通过 AOP（面向切面编程）实现动态数据源切换。创建一个切面类，根据方法上的自定义注解决定使用哪个数据源：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;
import org.springframework.stereotype.Component;

@Aspect
@Component
public class DataSourceAspect {

    @Around(&quot;@annotation(com.example.DataSourceAnnotation)&quot;)
    public Object switchDataSource(ProceedingJoinPoint joinPoint) throws Throwable {
        DataSourceAnnotation annotation = joinPoint.getSignature().getDeclaringType().getAnnotation(DataSourceAnnotation.class);
        if (annotation != null) {
            String dataSourceName = annotation.value();
            AbstractRoutingDataSource dataSource = (AbstractRoutingDataSource) dataSourceResolver.resolveDataSource();
            dataSource.setCurrentLookupKey(dataSourceName);
        }
        try {
            return joinPoint.proceed();
        } finally {
            // 清除数据源标识，恢复默认数据源
            AbstractRoutingDataSource dataSource = (AbstractRoutingDataSource) dataSourceResolver.resolveDataSource();
            dataSource.setCurrentLookupKey(null);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通过这种方式，应用可以在运行时根据业务需求灵活切换数据源，满足复杂业务场景下的数据访问需求。&lt;/p&gt; 
&lt;h3&gt;18. 使用 Testcontainers 进行测试&lt;/h3&gt; 
&lt;p&gt;在编写单元测试和集成测试时，模拟真实的数据库、消息队列等环境是很有必要的。Testcontainers 是一个开源库，它允许我们在测试中轻松创建和管理容器化的测试环境，如 MySQL、Redis、Kafka 等。&lt;/p&gt; 
&lt;p&gt;以测试一个使用 MySQL 数据库的 Spring Boot 应用为例，先在&lt;code&gt;pom.xml&lt;/code&gt;中添加 Testcontainers 和相关数据库驱动依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupid&amp;gt;org.testcontainers&amp;lt;/groupid&amp;gt;
    &amp;lt;artifactid&amp;gt;testcontainers&amp;lt;/artifactid&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupid&amp;gt;org.testcontainers&amp;lt;/groupid&amp;gt;
    &amp;lt;artifactid&amp;gt;mysql&amp;lt;/artifactid&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后编写测试类：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.jdbc.core.JdbcTemplate;
import org.testcontainers.containers.MySQLContainer;
import org.testcontainers.junit.jupiter.Container;
import org.testcontainers.junit.jupiter.Testcontainers;

import static org.junit.jupiter.api.Assertions.assertEquals;

@Testcontainers
@SpringBootTest
public class DatabaseTest {

    @Container
    public static MySQLContainer&amp;lt;!--?--&amp;gt; mysql = new MySQLContainer&amp;amp;lt;&amp;amp;gt;(&quot;mysql:8.0.26&quot;)
           .withDatabaseName(&quot;testdb&quot;)
           .withUsername(&quot;testuser&quot;)
           .withPassword(&quot;testpassword&quot;);

    @Autowired
    private JdbcTemplate jdbcTemplate;

    @Test
    public void testDatabaseInsert() {
        jdbcTemplate.execute(&quot;INSERT INTO users (name, age) VALUES (&#39;John&#39;, 30)&quot;);
        int count = jdbcTemplate.queryForObject(&quot;SELECT COUNT(*) FROM users&quot;, Integer.class);
        assertEquals(1, count);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述测试类中，&lt;code&gt;MySQLContainer&lt;/code&gt;会在测试启动时创建一个 MySQL 容器实例，并且自动配置好数据源连接信息供 Spring Boot 应用使用。测试完成后，容器会自动销毁，保证每次测试环境的一致性和独立性，极大提升了测试的可靠性和可重复性。&lt;/p&gt; 
&lt;h3&gt;19. 定制 Jackson 数据格式&lt;/h3&gt; 
&lt;p&gt;Spring Boot 默认使用 Jackson 库来处理 JSON 数据的序列化和反序列化。在实际开发中，我们可能需要根据业务需求定制 Jackson 的行为，比如修改日期格式、忽略某些属性等。&lt;/p&gt; 
&lt;p&gt;要定制日期格式，可以创建一个&lt;code&gt;Jackson2ObjectMapperBuilderCustomizer&lt;/code&gt;的 Bean：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.SerializationFeature;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;

@Configuration
public class JacksonConfig {

    @Bean
    public Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() {
        return builder -&amp;amp;gt; {
            JavaTimeModule module = new JavaTimeModule();
            module.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)));
            builder.featuresToDisable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS).modules(module);
        };
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述代码中，我们创建了一个&lt;code&gt;JavaTimeModule&lt;/code&gt;，并为&lt;code&gt;LocalDateTime&lt;/code&gt;类型定制了序列化格式，然后将其添加到&lt;code&gt;Jackson2ObjectMapperBuilder&lt;/code&gt;中。这样，在将&lt;code&gt;LocalDateTime&lt;/code&gt;类型的数据序列化为 JSON 时，就会按照指定的格式输出。此外，还可以通过&lt;code&gt;@JsonIgnore&lt;/code&gt;注解忽略某些属性，通过&lt;code&gt;@JsonProperty&lt;/code&gt;注解重命名属性等，灵活定制 JSON 数据的处理方式，满足各种复杂的业务需求。&lt;/p&gt; 
&lt;h3&gt;20. 任务调度 @Scheduled&lt;/h3&gt; 
&lt;p&gt;在 Spring Boot 应用里，我们常常会遇到定时任务的需求，像是定时清理过期数据、定时发送提醒邮件等。Spring Boot 借助&lt;code&gt;@Scheduled&lt;/code&gt;注解，能轻松实现任务调度功能。只要在方法上添加该注解，并设置好调度规则，Spring Boot 就会按设定的时间间隔或具体时间点执行任务。&lt;/p&gt; 
&lt;p&gt;例如，我们要实现一个每天凌晨 1 点执行的任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

@Component
public class ScheduledTask {

    @Scheduled(cron = &quot;0 0 1 * * ?&quot;)
    public void cleanExpiredData() {
        // 执行清理过期数据的业务逻辑
        System.out.println(&quot;Executing clean expired data task at &quot; + System.currentTimeMillis());
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述代码里，&lt;code&gt;cron&lt;/code&gt;表达式&lt;code&gt;&quot;0 0 1 * * ?&quot;&lt;/code&gt;代表每天凌晨 1 点触发任务。当然，&lt;code&gt;@Scheduled&lt;/code&gt;注解还支持&lt;code&gt;fixedRate&lt;/code&gt;、&lt;code&gt;fixedDelay&lt;/code&gt;等属性，能满足不同场景下的任务调度需求。 &amp;lt;/string&amp;gt;&amp;lt;/string&amp;gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/cccyb/blog/17875469</link>
            <guid isPermaLink="false">https://my.oschina.net/cccyb/blog/17875469</guid>
            <pubDate>Thu, 06 Mar 2025 03:38:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>【送书活动】金融数据库转型实战宝典</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;赠书啦，欢迎大家在评论区聊聊「&lt;span style=&quot;color:#3b3b3b&quot;&gt;数据库转型那些事&lt;/span&gt;」，畅所欲言&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;我们将在评论区随机选出 3 名 OSCer，赠送&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;《金融数据库转型实战：基于 OceanBase》&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#2c3e50&quot;&gt;一本&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#2c3e50&quot;&gt;活动截止时间：3 月 17 日 18:00&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;目前，金融数据库的数字化转型方兴未艾。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;以 OceanBase 为代表的新型分布式数据库凭借其高可用性、水平扩展能力和成本优势，正在成为金融数据库数字化转型的重要解决方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;然而，相较于 Oracle 等成熟的商业数据库，市场上关于 OceanBase 的应用实践和深度使用的图书较少。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;许多金融机构在开展数据库数字化转型工作时往往感到无从下手，缺乏有效的指导。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;近 3 年来，&lt;/span&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;《金融数据库转型实战：基于 OceanBase》&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;一&lt;span&gt;书的主笔人&lt;/span&gt;有幸参与到中国太平洋保险集团（简称「太保」）的数据库数字化转型工作中，在这个过程中，其所在的团队经历了无数个日夜的努力和奋斗，在公司领导及数智研究院院长的悉心指导下，与数据库团队、研发侧各项目组以及厂商专家紧密合作，共同面对困难和挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;800&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-42531ce5940227085e5c7ba37740da748f6.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;通过不懈的努力，最终实现了&lt;span&gt;大量复杂系统的成功上线，并保证了其稳定运行。&lt;/span&gt;这一成果不仅是一个重要里程碑，也为整个金融行业树立了标杆。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;鉴于此，作者深感有必要将这些宝贵的实战经验和方法论整理成书，以供那些正处在或即将步入金融数据库转型过程中的同行借鉴。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;《金融数据库转型实战：基于 OceanBase》&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;一&lt;/span&gt;书旨在填补市场上关于 OceanBase 应用和实践的空白，为更多希望使用 OceanBase 产品的企业及用户提供有力的支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本书特色&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;数据库知识体系庞杂，将其精华浓缩在一本书中实非易事。我对本书中的内容进行了精心安排，每章都从实战出发进行讲解。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;本书的特色如下。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;u&gt;&lt;strong&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;（1）内容来自金融数据库转型实战，&lt;/span&gt;&lt;/strong&gt;&lt;/u&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;包括选型、降本、最佳配置、最佳管理、核心攻坚、最佳优化、最佳备份等案例，实战性强，有的放矢，具有很好的指导意义。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;u&gt;&lt;strong&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;（2）原理和实战结合，图文并茂、内容翔实，&lt;/span&gt;&lt;/strong&gt;&lt;/u&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;将 Oracle 与 OceanBase 从存储架构、内存架构、术语等方面进行对比，帮助广大技术人员快速完成已有知识的升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;strong&gt;&lt;u&gt;（3）介绍了 OceanBase 4.2 版本新特性，&lt;/u&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;为广大 OceanBase 用户补充必要的知识。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;u&gt;&lt;strong&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;（4）包含大量实战技巧及案例，&lt;/span&gt;&lt;/strong&gt;&lt;/u&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;为金融数据库转型提供了避「坑」指南。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;u&gt;&lt;strong&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;（5）深入剖析金融数据库转型痛点，&lt;/span&gt;&lt;/strong&gt;&lt;/u&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;提供大量原创解决方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;800&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ca720f0971109254f8b151f9144f96bcb1.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本书内容&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;本书共分为 10 个章节。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;第 1 章&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;介绍金融业务系统架构、数据库使用现状及太保的数据库转型历程；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;第 2 章&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;介绍金融行业分布式数据库选型标准以及数据库选型考察要点；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;第 3 章&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;重点介绍金融数据库转型降本策略，包括应用改造、测试成本、迁移成本、硬件成本、架构设计等环节，具有指导意义；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;第 4~7 章&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;结合数据库转型实战经验以及 OceanBase 4.2 版本新特性，从数据库配置基线、开发规范、性能调优、管理转型等方面介绍 OceanBase 的最佳实践；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;第&amp;nbsp;8~9&amp;nbsp;章&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;介绍数据库改造及迁移案例，内容翔实；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#c00000&quot;&gt;&lt;strong&gt;&lt;span&gt;第&amp;nbsp;10&amp;nbsp;章&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;介绍 OceanBase 备份与恢复的最佳实践。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;对于金融&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;IT&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;从业人员和&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;OceanBase&lt;/span&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;使用者等不同需求层次的人群，本书都堪称&lt;span&gt;「一桌色香味俱全的饕餮盛宴」&lt;/span&gt;，欢迎热爱技术的您「享用」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#3b3b3b&quot;&gt;好书趁手，只争朝夕，不负韶华！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;图书下单链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fu.jd.com%2F6rajOiM&quot; target=&quot;_blank&quot;&gt;https://u.jd.com/6rajOiM&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#ab1942&quot;&gt;&lt;strong&gt;&lt;span&gt;↑限时优惠，快快抢购吧↑&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;div&gt; 
 &lt;strong&gt;当然你也有机会免费获得此书&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  【活动时间】 
 &lt;br&gt; 2025 年 3 月 11 日 - 3 月 17 日（7 天） 
&lt;/div&gt; 
&lt;div&gt;
  【活动方式】 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.85)&quot;&gt;在活动帖评论区发表评论，内容不局限于以下内容大家都可以探讨。&lt;/span&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.85)&quot;&gt;您所在机构的数据库转型阶段&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.85)&quot;&gt;遇到的核心挑战及解决方案&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.85)&quot;&gt;对本书某一章节的期待与应用场景&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.85)&quot;&gt;你想阅读这本书的理由&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.85)&quot;&gt;优质评论奖：小编会选 3 条优质留言免费赠送《金融数据库转型实战：基于 OceanBase》一本。&lt;/span&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&amp;nbsp;&lt;/pre&gt; 
&lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/broadviewbj/blog/17875926</link>
            <guid isPermaLink="false">https://my.oschina.net/broadviewbj/blog/17875926</guid>
            <pubDate>Thu, 06 Mar 2025 03:24:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>