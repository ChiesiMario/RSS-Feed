<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 19 Jun 2025 02:42:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>​OpenAI 终止与 Scale AI 合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 发言人当地时间周三向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-18%2Fopenai-is-phasing-out-its-work-with-scale-ai-after-meta-deal" target="_blank"&gt;彭博社&lt;/a&gt;透露，在 Meta 与 Scale AI 达成交易后，OpenAI 将逐步停止与 Scale AI 的合作，并切断与该数据供应商的联系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 表示，早在 Meta 上周宣布向这家初创公司投资数十亿美元并任命 Alexandr Wang 担任首席执行官之前，该公司就已开始逐步结束与 Scale AI 的合作。OpenAI 一直在寻找其他供应商来获取更专业的数据，以开发日益先进的 AI 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="336" src="https://oscimg.oschina.net/oscnet/up-77faf9c892257b37289b5ccb5a6d4304d54.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 断绝关系的决定引发了人们对 Scale AI 核心数据标签业务的质疑。上周，路透社报道称，谷歌也在讨论放弃 Scale AI 作为数据提供商的计划。随着 Meta 与 Scale AI 达成合作，Scale AI 的一些竞争对手表示，他们收到了大量寻求「中立」合作伙伴的 AI 模型供应商的兴趣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在周三发布的一篇博客文章中，Scale AI 的总法律顾问试图驳斥 Meta 将在此次交易后获得优待的说法。Scale AI 的高管表示，公司不会与 Meta 分享其他客户的机密信息，并且新任首席执行官 Wang 不会直接参与公司的日常运营。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在周三发布的另一篇博客文章中，Scale AI 的临时首席执行官 Jason Droege 则表示，公司将「加倍投入」其应用程序业务，其中包括为政府和企业构建定制的 AI 应用程序。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</guid>
      <pubDate>Thu, 19 Jun 2025 02:30:15 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Midjourney 发布首个 AI 视频生成模型 V1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 初创公司 Midjourney &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1935377193733079452" target="_blank"&gt;宣布&lt;/a&gt;推出其备受期待的首款 AI 视频生成模型 V1，支持图像到视频的生成，并可实现从文本直接生成视频。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1216" src="https://static.oschina.net/uploads/space/2025/0619/102551_SwUy_2720166.png" width="1286" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;V1 目前仅通过 Discord 平台的网页端提供服务，基础订阅费为每月 10 美元。&lt;/p&gt; 
&lt;p&gt;根据 Midjourney 的官方介绍，V1 基于此前的图像模型生态进行打造。&lt;/p&gt; 
&lt;p&gt;Midjourney V1 操作分为自动和手动两种模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动模式下，平台会根据用户生成的图片，自动创建「动作提示词」并让画面运动起来；&lt;/li&gt; 
 &lt;li&gt;手动模式则是由用户提供提示词。同时，Midjourney V1 也分为「低动态」和「高动态」两种运动模式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;V1 的发布让 Midjourney 加入与 OpenAI 的 Sora、Runway 的 Gen 4 等 AI 视频模型的竞争。其目标不止于为好莱坞或广告业生成素材，公司 CEO David Holz 称这是迈向 「实时开放世界模拟」 AI 模型的一步，后续还计划开发 3D 渲染和实时 AI 模型。 &amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</guid>
      <pubDate>Thu, 19 Jun 2025 02:27:15 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 考虑赴港 IPO？知情人士：属实，仍处于初步筹备阶段</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息称，AI 独角兽稀宇科技 (MiniMax) 正考虑在香港进行首次公开募股（IPO）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对此，有接近 MiniMax 的知情人士向澎湃新闻记者表示，MiniMax 内部确实有类似想法，但目前仍处于初步筹备阶段。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-1c8fdc630a51d77c2dbbdb3ff2131f20e68.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官网介绍显示，MiniMax 是全球领先的通用人工智能科技公司。自 2022 年初成立以来，以「与所有人共创智能」为使命，致力于推动人工智能科技前沿发展，实现通用人工智能 (AGI）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，MiniMax 已自主研发了一系列多模态通用大模型，包括 MiniMax M1、Hailuo-02、Speech-02 和 Music-01，具备超长上下文处理能力，能够理解、生成并整合包括文本、音频、图像、视频和音乐在内的多种模态。并基于这些自研模型推出一系列 AI 原生产品，包括 MiniMax、海螺 AI、MiniMax Audio、星野等，以及面向企业和开发者的开放平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 3 月，MiniMax 获 6 亿美元 A 轮融资，投后估值 25 亿美元，由阿里巴巴领投，此前融资的投资方也包括腾讯等。据媒体报道称，MiniMax 的实际估值目前已经超过 2024 年所报道过的「25 亿美元」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356108</guid>
      <pubDate>Thu, 19 Jun 2025 02:10:15 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>融云 AI 机器人上线，独家直连 AI 平台，加速落地创新探索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 技术的爆发为各行各业带来了前所未有的机遇，各类创新应用如雨后春笋般涌现——从图像生成、视频创作，到智能搜索引擎、代码助手，AI 正在重塑人们的工作与生活方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;而在这一波浪潮中，ChatBot 类产品及其衍生形态——如虚拟角色、智能客服和 AI 助理——作为 AI 普及的「OG」，始终占据着核心地位。无论是全球科技巨头的布局，还是创业团队的创新尝试，这一领域依然活力十足，不断有优秀的新产品崭露头角。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;深度整合 IM 对话与 AI 能力，融云 AI 机器人正式上线。&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;独立的机器人用户类型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，拥有&lt;/span&gt;&lt;strong&gt;&lt;span&gt;详细的事件回调能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，&lt;strong&gt;独家直连 AI 平台&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，大幅降低开发者落地 AI 社交、智能回复等业务的成本，给开发者的创新探索加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;无论是以全新产品角逐市场，还是在现有产品中增加附加玩法。融云 AI 机器人都可以&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效缩短业务上线周期，助力开发者快速探索充满潜力的 AI 赛道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;无论是以全新产品角逐市场，还是在现有产品中增加附加玩法。融云 AI 机器人都可以&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效缩短业务上线周期，助力开发者快速探索充满潜力的 AI 赛道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;场景丰富，响应稳定&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融云 AI 机器人支持基于指定机器人的详细事件回调，方便开发者精准掌握用户与机器人的互动，如单聊消息、群聊@指令等，并基于不同事件进行定制化处理，灵活响应各类业务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;无论是自动回复、任务触发，还是群聊助手，都可以借助融云 AI 机器人轻松实现更智能、更丰富的交互，&lt;/span&gt;&lt;span&gt;&lt;span&gt;提升产品的用户体验及业务运营效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;以单聊和群聊两种主要对话场景来看：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在单聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过与机器人对话，可触发多轮智能对话、内容生成等功能，支持流式或非流式输出，适用于&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 陪伴、角色扮演&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等社交场景&lt;/span&gt;&lt;span&gt;&lt;span&gt;及&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 知识问答、智能客服&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等商务社交场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="636" src="https://oscimg.oschina.net/oscnet/up-faa3c43ddca6e7fdc989dafeddb8f0d1286.png" width="585" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;除了稳定高效的多轮对话支持外，还可以实现智能任务执行功能，响应用户发起的智能操作请求，如「生成北京出行计划」、&lt;span&gt;「写一封邮件」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;等；或&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;查询个人事务，如「我今天还有哪些未完成的任务」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在群聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过 @ 机器人，触发与 AI 机器人的沟通或智能业务处理流程，如：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;FAQ 问答：解析用户意图并自动回复；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;工单创建：识别需求并提交至工单系统；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;日程提醒：识别时间表达并添加到日历服务。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;快速上线，降本增效&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;提供独立的机器人类型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;融云 IM 提供独立的机器人服务，自带区别于真实用户类型的业务逻辑，大幅降低开发者在 AI 对话类业务实现时针对机器人的特殊处理逻辑，从底层能力上满足开发者灵活创新的 AI 对话需求，极具拓展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;独家直连&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;&amp;nbsp;AI 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;融云 AI 机器人业内独家实现了与第三方 AI 平台的对接，开发者无需进行繁琐的中间处理，即可快速接入 AI Agent 创建调试及大模型推理服务，显著降低开发难度，为开发者的 AI 社交、智能客服等业务落地打开了一个「绿色极速通道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;此前，开发者若想借助 AI 平台赋能自身的 AI 对话类业务，需要自行实现中间的需求中转和消息流转，链路长、问题多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通过融云 AI 机器人，开发者可在简单调用接口后实现对 AI 平台能力的关联，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;链路稳定、响应高效&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并可以在融云&lt;/span&gt;&lt;strong&gt;&lt;span&gt;流式消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等底层能力和&lt;/span&gt;&lt;strong&gt;&lt;span&gt;内容审核&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等周边服务的配套支持下实现灵活的业务需求。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;接入便捷，灵活搭建&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融云 AI 机器人支持 Webhook 回调、Dify 平台对接，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方便开发者根据自身的业务情况选择对接方式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;设置 Webhook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可通过 Webhook 回调，将用户向机器人发送的消息同步到自己的业务服务器，由业务服务器自由对接自研或私有大模型自建服务（&lt;em&gt;如私有部署的 LLM、LangChain、RAG 检索系统等&lt;/em&gt;）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通过这一方式可以实现灵活的消息接入、参数定制、响应策略，&lt;/span&gt;&lt;span&gt;&lt;span&gt;适合有高度定制化、私有化部署、安全隔离等要求的业务场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;对接 AI Agent 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;支持对接已&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;接入 OpenAI、Claude、Gemini 等多种大模型的 Dify 平台。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可在 Dify 平台上创建一个自己的 AI Agent（&lt;/span&gt;&lt;em&gt;&lt;span&gt;如：聊天机器人&lt;/span&gt;&lt;/em&gt;&lt;span&gt;），同时在融云服务端创建一个机器人，并将该机器人通过配置直接与 Dify 平台创建的 AI Agent 进行对接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;这样，&lt;/span&gt;&lt;span&gt;&lt;span&gt;无需自行搭建模型服务，就可以实现多轮 AI 对话、知识库问答、RPA 流程（&lt;em&gt;机器人流程自动化&lt;/em&gt;）等&lt;/span&gt;&lt;span&gt;&lt;span&gt;高级功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="148" src="https://oscimg.oschina.net/oscnet/up-7518cc39e9922c3ad838434add534928cc3.png" width="580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;快速搭建 AI 陪伴应用示例&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;以 AI 陪伴应用为例，融云提供从 AI 角色配置、Prompt 预设到 IM 对接的全链路服务，&lt;/span&gt;&lt;span&gt;&lt;span&gt;快速搭建 AI 陪伴应用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在 Dify 中创建和调试 AI Agent&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪创建聊天助手&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪填写人设&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪设置 LLM 和参数&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪配置开场白&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在融云服务端创建机器人并完成关联&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通过 Server API 创建机器人&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通过&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;Agent 地址&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;设置机器人的回调配置信息，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;关联 AI Agent&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑在客户端集成 IM SDK， AI 角色便可出现在 App 中，提供&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能破冰、AI 陪伴等能力，助力应用提升用户粘性和商业价值。&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;详细接入流程可见本期推文次条&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;更多详情见&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;em&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.rongcloud.cn%2Fplatform-chat-api%2Fbot%2Foverview" target="_blank"&gt;开发者文档&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356103</guid>
      <pubDate>Thu, 19 Jun 2025 02:02:15 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Firefox 139 测试内置 Perplexity AI 搜索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;负责 Firefox 搜索的产品经理&amp;nbsp;Gayatri &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconnect.mozilla.org%2Ft5%2Fdiscussions%2Ftry-out-perplexity-ai-search-in-firefox-139%2Ftd-p%2F98352" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;团队正在与 Perplexity 合作，将&amp;nbsp;Perplexity AI 搜索内置到 Firefox 139 中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db094748597759caee52fd4a82e08cdcb33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0618/191849_B1yu_2720166.png" width="1390" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Perplexity 是一个 AI 驱动的搜索引擎，能直接以对话形式回答你的问题——无需翻阅大量搜索结果。它特别适用于以下情况：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅&amp;nbsp;需要快速简洁的答案，避免在多个信息源中迷失&lt;/li&gt; 
 &lt;li&gt;📚&amp;nbsp;在研究或学习时需要准确且引用充分的资料&lt;/li&gt; 
 &lt;li&gt;✍️&amp;nbsp;在创作或处理技术内容，如博客文章或代码片段&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Firefox 团队表示，这是他们更广泛目标的组成部分，即在使用搜索方式以及信任哪些工具来帮助他们完成任务方面为用户提供更多选择。如果体验良好，可能会考虑在未来支持更多 AI 回答或搜索选项。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepEP —— 开源 EP 通信库</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;DeepEP 是专为&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Mixture-of-Experts (MoE)&lt;/span&gt;&amp;nbsp;和 &lt;span style="background-color:#ffffff; color:#1f2328"&gt;expert parallelism (EP)&lt;/span&gt;&amp;nbsp;定制的通信库。它提供高吞吐量和低延迟的&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;all-to-all&lt;/span&gt;&amp;nbsp;GPU 内核，也就是所谓的 MoE 调度和组合。该库还支持低精度操作，包括 FP8。&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;为了与 DeepSeek-V3&amp;nbsp;论文中提出的 group-limited gating algorithm 保持一致，DeepEP 提供了一组针对非对称域带宽转发（例如将数据从 NVLink 域转发到 RDMA 域）进行优化的内核。这些内核提供高吞吐量，使其适合训练和推理预填充任务。此外，它们还支持 SM (Streaming Multiprocessors)&amp;nbsp;数量控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对于延迟敏感的推理解码，DeepEP 包含一组具有纯 RDMA 的低延迟内核，以最大限度地减少延迟。该库还引入了一种 hook-based 通信计算重叠方法，该方法不占用任何 SM 资源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;要求&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;Hopper GPU（以后可能支持更多架构或设备）&lt;/li&gt;
&lt;li style="text-align:start"&gt;Python 3.8 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;CUDA 12.3 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;PyTorch 2.1 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;用于节点内通信的 NVLink&lt;/li&gt;
&lt;li style="text-align:start"&gt;用于节点内通信的 RDMA 网络&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepep</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepep</guid>
      <pubDate>Sat, 10 May 2025 10:35:00 GMT</pubDate>
    </item>
    <item>
      <title>Gitee MCP 现已支持远程访问：无需本地部署，AI 助手即插即用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今年三月，&lt;a href="https://www.oschina.net/news/338794/gitee-mcp-server"&gt;Gitee 正式发布了官方 MCP Server&lt;/a&gt;，让 AI 助手深度参与代码仓库的管理，助力开发者更高效地工作。&lt;/p&gt; 
&lt;p&gt;今天，Gitee MCP 正式支持远程访问，上线了&lt;code&gt;Remote mcp-gitee&lt;/code&gt;：无需安装、即开即用，让 AI 助手可以远程、安全地与 Gitee 交互，真正做到「即连即用」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源地址：&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;什么是 Remote mcp-gitee？&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;是 Gitee 推出的远程版 MCP Server，无需本地部署，默认运行在云端，同时也拥有全面的接口能力，支持仓库、文件、Issue、PR、用户信息获取、评论等众多操作，满足常见开发协作需求。&lt;/p&gt; 
&lt;p&gt;你可以通过简单配置直接将其接入任意支持 MCP Streamable HTTP 协议的客户端，&lt;strong&gt;无需安装依赖、编译构建，也无需配置本地环境&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;与此前的本地部署方式不同，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;将服务完全托管在云端，为用户提供了开箱即用、跨平台、跨设备的一致使用体验。&lt;/p&gt; 
&lt;h2&gt;远程 MCP 有哪些使用场景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI 驱动的协作&lt;/strong&gt;：通过&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手能够自动创建 Issue、提取任务、拆解子任务、发起/合并 PR，减轻日常操作负担。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;低门槛接入&lt;/strong&gt;：无需本地搭建或安装依赖，企业或个人团队只需配置一次，即可将 MCP 能力集成至工作流中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨团队标准化流程&lt;/strong&gt;：所有操作通过远端 MCP 接入，统一管理权限、审计、日志，便于追踪和审查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;无需部署即可读写代码仓库&lt;/h2&gt; 
&lt;p&gt;借助&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手将具备完整的上下文访问能力，能够直接调用 Gitee 接口，获取仓库结构、读取文件内容、创建 Issue、生成 PR，甚至合并代码、发布版本。&lt;/p&gt; 
&lt;p&gt;你只需要准备一个 Gitee 访问令牌，并将其配置在客户端中，即可激活整个智能协作流程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"gitee": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"https://api.gitee.com/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"headers": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Authorization":&amp;nbsp;"Bearer &amp;lt;YOUR PERSONAL ACCESS TOKEN&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;本方法适用于 Cursor、Trae 等多种主流客户端，配置完毕后，即可直接连接 Remote mcp-gitee。&lt;/p&gt; 
&lt;h3&gt;在 Cursor 中连接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;进入 Cursor 设置页面，选择&lt;code&gt;Tools &amp;amp; Integrations&lt;/code&gt;，新建一个 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182420_lanO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将配置信息复制到文件中，填入 Gitee 账号的私人令牌，保存即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182431_KJ6X_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;返回设置页面，可以看到 mcp-gitee server 已正常连接。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182440_lOSn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;在 Trae 中连接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择任意一种方式进入 MCP 设置页面。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182451_sEtI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;搜索 Gitee 并添加。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182501_L5XD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将配置信息复制到文件中，填入 Gitee 账号的私人令牌（Trae 暂时未支持远程连接，需手动复制远程连接的配置信息）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182511_Y51c_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;确认后，mcp-gitee server 已成功连接至 Trae。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="360" src="https://static.oschina.net/uploads/space/2025/0618/182521_D6Qz_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182549_TvrI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;同时，开发者也可选择自行部署 Remote mcp-gitee 至本地，具体流程可访问项目仓库查看：&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;即插即用的智能协作，就在 Gitee&lt;/h2&gt; 
&lt;p&gt;Gitee 始终致力于在 AI 时代持续探索智能开发的边界。无论是底层协议支持，还是工具链能力拓展，我们都希望为开发者&lt;strong&gt;提供更开放、更易用、更高效、更先进的基础设施&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;让 Gitee MCP 能力以即插即用的方式走进开发者日常。无需安装、无需配置环境，只需一段 JSON 与私人令牌，就能让 AI 真正参与项目开发的各个环节。&lt;/p&gt; 
&lt;p&gt;现在，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;已全面开放使用，欢迎体验轻量、流畅的智能协作能力，欢迎访问项目仓库了解更多信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee" target="_blank"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356026</guid>
      <pubDate>Sat, 10 May 2025 10:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国家互联网信息办公室：中国已有 433 款大模型完成备案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 上海世界移动通信大会（MWC 上海 2025）开幕式上，国家互联网信息办公室副主任王京涛在致辞中指出，截至目前，中国已经有 433 款大模型完成备案，上线提供服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京涛表示，目前中国已成为全球最大的互联网市场，拥有全球最多的网民和移动互联网的用户，以及最活跃的数字技术和应用创新生态，建成了全球规模最大、技术领先、性能优越的网络基础设施。在追求自身发展的同时，中国也积极地推进各国共享互联网发展机遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向未来，中国要坚持发展与安全并重研究，加强发展战略、治理规则和技术标准的对接协调，推动人工智能朝着有益、安全、公平的方向健康、有序发展。要尊重各国网络主权，尊重各国的互联网发展道路和治理模式，共同构筑和平、开放、安全、合作、有序的网络空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京涛还表示，以人工智能为代表的新的数字技术，给人类生产生活带来前所未有的机遇的同时，不同地区、国家、群体间享受数字红利的差距依然较大。对此，他建议，秉持人类共同体理念，广泛开展人工智能国际合作，帮助发展中国家加强能力建设，提高人工智能的技术的可及性，弥合全球智能鸿沟，释放更多的智能红利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356024</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356024</guid>
      <pubDate>Sat, 10 May 2025 10:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「最火 AI 编程软件」 Cursor 备受风投公司青睐，公司估值超过 180 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-17%2Fai-startup-anysphere-fields-vc-offers-at-over-18-billion-valuation"&gt;据彭博援引知情人士报道&lt;/a&gt;，近几周来，投资者已与 Cursor 开发商 Anysphere 接洽，商讨一项融资协议，该协议将使这家初创公司的估值达到 180 至 200 亿美元。该提议是在这家 AI 初创公司年收入超过 5 亿美元后不久提出的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/180654_RHv6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;知情人士透露，该公司并未主动寻求新一轮融资，而是投资者主动接洽。&lt;/p&gt; 
&lt;p&gt;Anysphere 首席执行官 Michael Truell 此前透露，超过半数财富 500 强企业使用 Cursor，日活用户超过 100 万人。OpenAI、Spotify、美国职业棒球大联盟和 Instacart 等知名公司均为其用户。&lt;/p&gt; 
&lt;p&gt;这家成立于 2023 年的公司年化收入已突破 5 亿美元，被硅谷投资者誉为 「史上收入增长最快的初创公司」。虽然公司目前并不缺乏现金，但考虑到有利的融资条件，Anysphere 可能会选择增加更多资本储备。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356022</guid>
      <pubDate>Sat, 10 May 2025 10:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>bzip2 的 crate 包已完全从 C 迁移到 Rust</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;bzip2 0.6.0&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrifectatech.org%2Fblog%2Fbzip2-crate-switches-from-c-to-rust%2F" target="_blank"&gt; 已发布&lt;/a&gt;，团队称新版本默认采用他们实现的 bzip2 算法 libbz2-rs-sys，bzip2 的 crate 包也已完全从 C 迁移到 Rust，bzip2&amp;nbsp;库现在编译更快、跨编译更简单。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/173858_3xAW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管现在 bzip2 的使用不如以前广泛，但许多协议和库仍需支持它以满足规范要求。团队借鉴了在 zlib-rs 项目中的经验，对 bzip2 的实现进行了更新。&lt;/p&gt; 
&lt;p&gt;在性能方面，Rust 实现通常优于 C 实现，尽管在某些情况下两者性能相当。压缩性能测试显示，Rust 实现的压缩速度比 C 实现快 14% 左右。在解压缩方面，Rust 实现也带来了显著的速度提升，测试结果显示平均速度快了 5%-10%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/173936_x7TO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;移除 C 语言依赖后，Rust 项目在交叉编译时的复杂性大大降低，编译为 WebAssembly 等平台的问题也得到了解决。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/256102/sudo-rs-0-2-0-first-stable" target="news"&gt;sudo-rs 发布首个稳定版 0.2.0：内存安全、用 Rust 重写的 sudo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356012/bzip2-crate-switches-from-c-to-rust</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356012/bzip2-crate-switches-from-c-to-rust</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​字节跳动 Seedance 1.0 模型评测结果超越谷歌 Veo 3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在近期的人工智能视频生成领域，字节跳动悄然发布了一款名为 Seedance1.0 的新模型，该模型在独立的评测中已经超越了谷歌最新推出的 Veo3。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Seedance1.0 的研究论文中详细介绍了该模型的创新之处。字节跳动的团队通过对空间和时间层的解耦，结合了多模态位置编码，从而使得该模型能够同时处理文本到视频和图像到视频的生成任务。这样的方法支持复杂的场景切换和多镜头敍事，保持了一致的主题表现。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="185" src="https://oscimg.oschina.net/oscnet/up-cdfc14b924c4930f690c558ca675747c61e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Seedance1.0 的性能离不开字节跳动强大的数据管道。团队精心构建了一个大规模、多来源的数据集，配有详细的双语注释和丰富的动作与静态特征标注，确保生成内容的准确性。同时，采用了一种新颖的强化学习设置，结合了三个奖励模型，重点关注基础对齐、动作质量和美观度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-3b8266677daa9731bb02990119d48c53102.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在评测中，Seedance1.0 在多个维度上超过了 Veo3。在与电影导演合作开发的 SeedVideoBench 基准测试中，该模型在遵循提示和动作真实感方面取得了更高的分数。在图像到视频的任务中，Seedance 保持了输入帧的视觉一致性，而 Veo3 则在某些情况下出现了光照和纹理的变化。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="293" src="https://oscimg.oschina.net/oscnet/up-47383f948234dcb7e6170c1e5457953697d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在推理性能方面，Seedance1.0 也表现出色。该模型能够在 41.4 秒内生成一段 1080p 的五秒视频，这一速度远超其他竞争对手，如 Sora、Runway Gen-4 和 Veo3。字节跳动还表示，他们在降低成本和延迟方面取得了重大进展，使得视频生成向实时应用的目标迈进了一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Seedance1.0 计划于 2025 年 6 月集成到 Doubao 和 Jimeng 等平台，旨在显著改善专业工作流程和常规创作任务。虽然 Veo3 因首次结合了真实视频与环境音效和对话而备受瞩目，但 Seedance1.0 在视觉保真度、运动稳定性和敍事连贯性方面表现更为出色，虽然在音频能力上有所欠缺。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356005</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356005</guid>
      <pubDate>Sat, 10 May 2025 09:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>通过 AIOps、生成式 AI 和机器学习，实现更智能的可观测性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;云与 AI 成为基础设施与平台的当下，运维团队正面临多重挑战：指标、日志、跟踪数据割裂形成的「数据孤岛」，被动响应机制导致的平均修复时间攀升，传统监控在动态微服务架构中的失效等等。&lt;/p&gt; 
 &lt;p&gt;而在现代应用开发的背景下，可观测性可以从各种来源收集和分析数据：日志、指标和追踪 —— 以深入了解在你环境中运行的应用程序的行为。而通过可观测性方案 + AI，也能为现代 IT 系统实现更加智能的可观测性。&lt;/p&gt; 
 &lt;p&gt;本周六，第 114 期 OSC 源创会将在北京举办，以「AI 运维「开挂」指南」为主题。Elastic 社区首席布道师刘晓国将出席活动，并发表《通过 AIOps、生成式 AI 和机器学习，实现更智能的可观测性》主题演讲。在活动正式开始前，先来简单了解下可观测方案。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="1440" src="https://oscimg.oschina.net/oscnet/up-499956c715242acc73d6281d0bffbe0ce6b.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：您提到现代系统需从「被动响应转向主动防御」，当前企业在可观测性实践中面临的最大痛点是什么？传统监控方案为何难以应对云原生环境下的复杂性？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;数据量大，存储成本高、海量数据处理压力大，很多企业的可观测性数据（指标，日志及跟踪）存在于不同的数据库中，从而造成数据孤岛，手动关连它们或通过一些工具进行转化比较困难。当真正的事件发生后，很难找到真正的原因。另外人工分析这些数据几乎是不可能的，特别是想从被动响应转向主动防御。 &lt;strong&gt;Elastic 的全面可观测性方案&lt;/strong&gt;可以采用机器学习的方法来对实时数据进行分析，并查看异常事件，从而完成从被动响应转向主动防御的需求。这些异常的事件可以结合通知/告警的方式以不同的形式发送给运维人员。云原生环境中的服务频繁启动，停止和扩展，传统的监控很难实时地跟踪这些变化。另外，传统监控难以在云环境中捕获服务的调用链和依赖关系。Elastic 的服务图可以很方便地显示各个服务之间的调用关系，并在图上以不同的颜色显示该服务的健康状态。我们可以结合机器学习及大模型来进一步解释及提供修正的方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：Elastic 可观测性方案的优势是什么？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Elastic 可观测性方案把指标，日志，跟踪及通用分析数据保存于同一个数据库中，尽管存在于同一个平台的不同索引里。Elastic 使用 ECS (Elastic Common Schema) 语义语法来定义统一的字段名称。这样不同的索引还是可以通过一些字段进行关联。当一个事件发生时（比如响应缓慢可以在跟踪视图可见），我们可以同时同时在一个平台查看日志，指标，从而找出真正的事件原因。Elastic 全观测性方案可以更快地位 IT 团队找出根因，而不用在各个不同的平台里进行手动关联，或通过一种转换的方式来进行操作。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：在您遇到的案例中，是否有某个问题通过传统监控完全无法捕捉，却因 Universal Profiling 的‘全栈可见性’意外暴露？当时团队如何反应？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Elastic Universal Profiling™ 是一种全系统、始终在线、连续的分析解决方案，无需代码检测、重新编译、主机上调试符号或服务重新启动。 通用分析利用 &lt;span style="color:#6425d0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Febpf.io%2F" target="_blank"&gt;eBPF&lt;/a&gt;&lt;/span&gt; 在 Linux 内核空间内运行，以不引人注目的方式以最小的开销仅捕获所需的数据。它可以帮我们定位消耗时间最多的函数以及这些函数的调用情况，并以火焰图的形式表达出来。它可以帮我们了解整个基础架构中哪些代码行始终消耗 CPU 资·源。我们可以通过 Universal Profiling 工具来优化我们的代码设计。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; Assistant 生成的操作建议需要人工复核吗？在您经历的案例中，运维团队对 AI 建议的信任度如何建立？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;我们的 AI Assistant 是基于 LLM RAG 基础之上的智能助手。我们可以建立自己的知识库，从而消除人工智能在推理时产生的幻觉。这些知识库存在于 Elastic 自己的索引里，是可以由运维人员自己创建的，或者直接有运营手册直接导入的。这些知识库可以来自 github，runbook， playbook 等。另外 Elasticsearch 的文档非常全面，很多大模型对 Elasticsearch 的文档进行了充分的训练。通常来说，产生幻觉的机会还是蛮少的。我们将来甚至可以推出自己的大模型。针对有些敏感的操作，我们可以在助手里做出相应的选择。在 AI 进行回答问题之前，通常会查看自己的知识库得到最相近的答案。如果 AI 提供的推理是建立在自己的知识库之上，或者我们在自己平时积累的解决方案之上，那么 AI 推理提出的解决方案还是相当可以接受的。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：您认为 &lt;/strong&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;strong&gt;+Observability 的结合会催生哪些新&lt;/strong&gt;&lt;strong&gt;范式&lt;/strong&gt;&lt;strong&gt;？未来是否可能出现「自主修复系统」？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;是的，这种完全可能。目前在 Elastic 的可观测性方案中，我们使用 AIOps 来针对可观测性提供解决方案。由于 LLM 具有良好的推理及总结功能，甚至它还可以帮我们关联不同索引里的数据。结合私有知识库，LLM+Observability 为我们的可观测性提供良好的解决方案。Elastic 的可观测性其实还有一个叫做 AutoOps 的解决方案。其实主要是针对集群的运行及查询，摄入的监控，并提出相应的解决方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：对于资源有限的中小团队，部署智能可观测性最应规避的‘过度设计’陷阱是什么？能否分享一个最小可行方案的搭建路径？」&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;我觉得尽量采用通用标准，比如 OpenTelemetry 从而规避锁定厂商。另外，尽量避免工具泛滥，膨胀。工具多了，维护的成本也会增加，带来的问题也会很多。如把需要的数据采集到一个数据库中，而不是分散到不同的平台中。还有最好采用一下比较成熟的解决方案，而不是一些未经得到证实的方案。Elastic 其实已经提供了一个比较简介的部署方案，从数据摄取，处理，展示，搜索，及到事件的捕获，通知/告警。在同一个平台即可搞定所有的事。我们还可以结合人工智能来帮助我们摄取，优化，推理，并提供解决方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：开发者需掌握哪些新技能来驾驭智能运维时代？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;日志，指标及跟踪的数据采集，处理及分析技能（Elastic Stack, OpenTelemetry 等）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;数据整合的能力，比如数据采集，清洗，丰富等&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;熟悉 Kafka, Spark, Flink, Logstash, Beats, Elastic Agents 等数据处理框架。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AI/ML 能力。Elastic 中使用 ML 来监测异常事件。虽然开发者不需要掌握很深的 ML 能力，但是知道其作用并如何使用即可。。如果使用 LLMs 来帮助我们分析文件，解决问题。在海量的数据里找到洞察。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;具有使用一些构建易用，直观的运维可视化界面能力（比如 Kibana, Grafana 等）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;通知及告警&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AI agents&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：Elastic 近年从&lt;/strong&gt;&lt;strong&gt;搜索引擎&lt;/strong&gt;&lt;strong&gt;扩展到可观测性、安全甚至&lt;/strong&gt;&lt;strong&gt;生成式 AI&lt;/strong&gt;&lt;strong&gt;领域，这种跨界拓展背后的核心逻辑是什么？在您看来，未来 3 年 Elastic 最可能颠覆的 「下一个生态位」 会是什么？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;其实 Elastic 在很多年前已经进入到可观测性及安全领域。早期我们还有企业搜索。这些构成了 Elastic 的三大技术方案。目前企业搜索已经退出，更多地集成到我们的 Search 解决方案里。Elastic 在过去的三年里大量投入到 AI 领域。我们的向量搜索库 Elasticsearch 是世界上下载最多的数据库。在未来，我们将围绕 AI 打造智能解决方案。LLMs 为这些提供了良好的基础。我们结合 MCP 这种 AI agents 通过自然语言的方式对我们的数据进行查询，分析，并提出解决方案。AI 智能体在未来肯定会越来越聪明，并为我们的可观测性带来自动处理的能力！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="10252" src="https://oscimg.oschina.net/oscnet/up-c40d45614995bacbd788286afa1eafa1aa4.png" width="3125" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18627539</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18627539</guid>
      <pubDate>Sat, 10 May 2025 08:48:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Docker Desktop 4.42 发布，集成 MCP 工具包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Docker Desktop&amp;nbsp;4.42 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-desktop-4-42-native-ipv6-built-in-mcp-and-better-model-packaging%2F" target="_blank"&gt;已发布&lt;/a&gt;&lt;/u&gt;，新增原生支持 IPv6 网络，智能 DNS 解析、集成 Docker MCP Toolkit、增强 AI 相关功能等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b35f142c42d62e4321cd5c076947810288e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在网络功能方面，Docker Desktop 4.42 为满足多样化的企业网络需求，引入了原生 IPv6 网络支持，开发者可灵活选择 IPv4 / IPv6 双栈（默认）、IPv4 专用或 IPv6 专用模式。&lt;/p&gt; 
&lt;p&gt;新版本还新增智能 DNS 解析功能，能够检测主机的网络堆栈，并过滤不支持的 DNS 记录类型，有效减少 IPv4 或 IPv6 限制环境下的连接问题。&lt;/p&gt; 
&lt;p&gt;这些网络设置可在 Docker Desktop 的「Settings」 &amp;gt; 「Resources」 &amp;gt; 「Network」中调整，并支持团队集中管理和强制执行，从而提升复杂网络配置的可靠性。&lt;/p&gt; 
&lt;p&gt;在工具方面，Docker Desktop 4.42 集成 Docker MCP Toolkit，开发者无需额外安装，可以直接使用 GitHub、MongoDB 和 HashiCorp 等热门 MCP 服务器，并可将其连接至 Claude Desktop、Cursor 等客户端或 Docker 自家 AI 代理 Gordon。此外还新增 docker mcp 命令，支持通过命令行管理服务器、客户端及配置。&lt;/p&gt; 
&lt;p&gt;Docker 正致力于成为一个全面的 AI 解决方案，&lt;a href="https://www.oschina.net/news/340579/docker-model-runner-run-llms-natively"&gt;此前已内置 LLM 模型运行器&lt;/a&gt;，使得基于 llama.cpp 的服务器模型部署更加便捷。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-desktop-4-42-native-ipv6-built-in-mcp-and-better-model-packaging%2F" target="_blank"&gt;详情查看发布公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355998/docker-desktop-4-42-native-ipv6-built-in-mcp</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355998/docker-desktop-4-42-native-ipv6-built-in-mcp</guid>
      <pubDate>Sat, 10 May 2025 08:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>【视频】Solon Flow vs Drools - 业务规则应用对比</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索视频：&lt;/p&gt; 
&lt;p&gt;&lt;iframe height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114703174993573&amp;amp;bvid=BV1FfNjz1EzQ&amp;amp;cid=30560947818&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355985</guid>
      <pubDate>Sat, 10 May 2025 07:53:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>深度解析 Cursor</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 我们今天为大家带来的这篇文章，作者的观点是：只有深入理解 AI 编程工具的底层原理和能力边界，才能真正驾驭这些工具，让它们成为提升开发效率的"外挂神器"。&lt;/p&gt; 
 &lt;p&gt;本文从 LLM 的基础工作机制出发，解释了 Cursor 等工具本质上是 VSCode 的复杂封装，通过聊天界面、工具集（如 read_file、write_file 等）和精心设计的提示词来实现智能编程辅助。作者还逐行解析了 Cursor 的系统提示词，分析了其中的工程设计细节。此外，作者还提供了制定高效 Cursor Rules 的具体指导，强调 Cursor Rules 应该像百科词条般详实，而非简单的命令列表。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shrivu Shankar&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;透彻了解 Cursor[1]、Windsurf[2] 和 Copilot[3] 这类 AI 编程工具的运作原理细节，能大大提升你的开发效率，并让这些工具在不同场景下都更加稳定地工作 ------ 尤其在庞大、复杂的代码库中。当人们难以让 AI 编程工具高效工作时，往往是把它们当成了传统工具来使用，却忽略了一个关键：只有清楚这些工具的先天不足和最佳应对策略，才能真正驾驭它们。一旦摸透这些工具的运作逻辑和能力边界，它们就会化身成为提升开发效率的"外挂神器"。在我写作此文时，我约 70% 的代码 1 都由 Cursor 产出。&lt;/p&gt; 
&lt;p&gt;在本文，我将深入解析这些 AI 编程工具的实际运行原理、Cursor 的系统提示词，以及如何优化你的编码方式与 Cursor rules。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 从 LLM 到代码编写智能体&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 LLM&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;LLMs 的核心工作方式是不断重复预测下一个词，正是基于这个简单的原理，我们得以构建出各种复杂的应用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e7cd63f365717b2dd8cdd7ea2ebb3cf3e0c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从基础的编程 LLM 到智能体主要经历三个阶段：蓝色部分表示我们设定的前缀（即 prompts），橙色部分则为 LLM 自动补全的内容。在智能体中会反复运行 LLM，直到它生成面向用户的输出（response）。每次运行时，由客户端代码（而非 LLM）负责计算工具（tool）运行结果并将其反馈回智能体（agent）。&lt;/p&gt; 
&lt;p&gt;在早期解码器 LLM（如 GPT-2[4]）的提示词实践中，需要精心构造一个前缀字符串（prefix） ------ 当其被补全时，便能得到想要的结果。相比于直接的指令"Write a poem about whales"，不如说 "Topic: Whales\nPoem: "，甚至是"Topic: Trees\nPoem: ... actual tree poem ...\nTopic: Whales\nPoem: "。在编程场景下，需要构造类似"PR Title: Refactor Foo Method\nDescription: ...\nFull Diff: "这样的前缀。所谓的"Prompt engineering"，其核心就是巧妙地构建理想前缀，从而引导模型自动补全出所需答案。&lt;/p&gt; 
&lt;p&gt;随后引入了指令微调[5]（例如 ChatGPT），大幅降低了大语言模型的使用门槛。现在你如果输入"Write a PR to refactor Foo"，它就会直接返回代码。其内在机制几乎完全等同于上述的自动补全过程，只是前缀变成了"&amp;lt;user&amp;gt;Write a PR to refactor Foo&amp;lt;/user&amp;gt;&amp;lt;assistant&amp;gt;"，此时大语言模型正扮演着聊天中的助手角色。即使在今天，你仍会看到一些奇怪的情况 ------ 模型有时会越过"&amp;lt;/assistant&amp;gt;"标签继续自动补全生成内容，开始给自己写提问。&lt;/p&gt; 
&lt;p&gt;当模型规模达到一定程度时，我们更进一步，加入了"工具调用（tool calling）[6]"功能。不再局限于填充 assistant 文本，我们可以在前缀中输入"Say \read_file(path: str)` instead of responding if you need to read a file"。当遇到编码任务时，模型现在会补全出"read_file('index.py')&amp;lt;/assistant&amp;gt;"，我们（客户端）则会再次输入提示词"&amp;lt;tool&amp;gt;... full contents of index.py ...&amp;lt;/tool&amp;gt;&amp;lt;assistant&amp;gt;`"并要求其继续补全文本。虽然本质上仍是自动补全，但大语言模型已能借此与外界及外部系统互动了。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 Agentic Coding&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;像 Cursor 这样的 AI 编程工具，其本质就是这个简单概念的复杂封装。&lt;/p&gt; 
&lt;p&gt;要构建一个 AI 编程工具，你需要：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Fork VSCode[7]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;添加聊天界面，并选择一个强大的大语言模型（例如 Sonnet 3.7）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为编码智能体实现一套工具集&lt;/p&gt; &lt;p&gt;a. read_file(full_path: str)&lt;/p&gt; &lt;p&gt;b. write_file(full_path: str, content: str)&lt;/p&gt; &lt;p&gt;c. run_command(command: str)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化内部提示词（Prompts）：例如"你是一位编码专家"、"不要假设，请使用工具"等&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;总的来看，核心流程基本就是这些了。&lt;strong&gt;真正的难点在于设计提示词和工具链，确保它们能稳定可靠地工作。&lt;/strong&gt; 如果完全按照上述描述来构建，系统虽能勉强运行，但会频繁出现语法错误、幻觉问题（hallucinations）且相当不稳定。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 优化 Agentic Coding&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;打造优秀 AI 编程工具的诀窍，在于找出大语言模型擅长的领域，并围绕其局限性精心设计提示词和工具。这通常意味着需要减轻主智能体的任务负担 ------ 通过使用更小的模型来完成子任务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e7e56113a8ef764b999eca561a12d609740.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图表说明：当你使用 AI 编程工具时，其底层发生了什么？我们简化了主智能体的工具集，将"认知负担"转移到其他大语言模型上。AI 编程工具会将你的 @标签注入上下文，调用多个工具来收集更多信息，使用专用的代码变更标记规则（diff syntax）编辑文件，最后向用户返回摘要响应。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 优化措施与面向终端用户的操作建议（Optimizations &amp;amp; User Tips）&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;通常情况下，用户自己知道需要哪些具体文件或上下文。因此，我们在聊天界面（Chat UI）中添加了"@file"语法。当调用大语言模型时，我们会将所有附加文件的内容整体打包放入一个"&amp;lt;attached-files&amp;gt;"区块中传递。这本质上是为用户提供语法糖（syntactic sugar），免去了手动复制粘贴整个文件或文件夹的麻烦。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;操作建议 (Tip)：&lt;strong&gt;在这些编程工具中建议积极使用 @folder/@file（优先提供更明确的上下文，以获取更快更准确的响应）。&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;搜索代码可能很复杂，尤其对于"我们在哪里实现了认证功能相关的代码？"这类语义查询。我们没有让智能体精通编写搜索正则表达式（regexes），而是选择在索引阶段使用一个编码器大模型（encoder LLM）将整个代码库索引到向量数据库（vectorstore）中，从而将文件内容及其功能嵌入到向量中。在查询时，另一个大语言模型会根据相关性对文件进行重排序和过滤。这确保了主智能体在询问认证功能代码相关问题时能获得"完美"的结果。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;操作建议 (Tip)：&lt;strong&gt;代码注释（Code comments）和文档字符串（doc-strings）能引导嵌入模型（embedding model）理解代码，这使得它们的重要性甚至超过了仅写给人类同事看的情况。&lt;/strong&gt; 务必在文件顶部用一段文字说明：该文件的作用、实现的语义功能以及应何时更新。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要生成字符层级上零缺陷（character-perfect）的代码既困难又昂贵，因此优化 write_file(...) 工具成为众多此类 AI 编程工具的核心。大语言模型通常不会输出完整的文件内容，而是生成一个 "semantic diff" ------ 仅提供已更改的内容，并附带代码注释，以指导在何处插入更改的文件内容。随后，另一个更轻量、更快的代码应用大模型（code-apply LLM） 会将该 "semantic diff" 作为输入提示词，并在修复那些微小语法问题的同时写入实际文件内容。新文件经过 linter 校验器处理后，工具返回主智能体的结果时会包含实际文件差异（actual diff）和 lint 校验结果，可用于自我修正文件的错误改动。我将此机制类比为：与一位懒散的资深工程师协作，他只需写出核心片段，后续细节交由实习生完成。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;操作建议 (Tip)：你无法直接将提示词发送给应用模型（apply-model）。&lt;strong&gt;类似"别乱删代码"或"别随意增删注释"的建议完全无效，因为这些问题本质上是应用模型（apply-model）工作机制的固有产物。&lt;/strong&gt; 应该让主智能体获得更多控制权，例如在指令中明确要求："在 edit_file 指令中提供完整的文件内容"&lt;/li&gt; 
   &lt;li&gt;操作建议 (Tip)：应用模型处理超大文件时缓慢且易错，&lt;strong&gt;务必将文件拆分至每部分小于 500 行代码&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;操作建议 (Tip)：lint 反馈对智能体具有极高价值&lt;/strong&gt;，应投资构建能提供高质量建议的增强型 linter2。使用编译型语言和静态类型语言能提供更丰富的 lint 时反馈（lint-time feedback）&lt;/li&gt; 
   &lt;li&gt;操作建议 (Tip)：&lt;strong&gt;使用唯一的文件名&lt;/strong&gt; （不要在代码库中使用多个不同的 page.js 文件，最好改用 foo-page.js、bar-page.js 等），&lt;strong&gt;在文档中应使用完整的文件路径&lt;/strong&gt;，并将高频修改的代码段（hot-paths）集中到同一文件或文件夹中，以降低编辑工具的操作歧义&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;选用擅长在此类智能体（Agent）工作流中编写代码的模型（而非仅具备通用编码能力）。这就是 Anthropic 模型在 Cursor 等 AI 编程工具中表现出色的原因 ------ 它们不仅代码质量高，更擅长将编程任务拆解为这种类型的工具调用（tool calls）。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;操作建议 (Tip)：&lt;strong&gt;选用模型时，不应仅关注"编码能力"，应优先选择专门为智能体驱动型编程工具（agentic IDEs）优化的模型。&lt;/strong&gt; 目前（据我所知）能有效评估此能力的唯一排行榜是 WebDev Arena[8] 3。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我在自研 AI 编程工具 sparkstack.app 中采用过一个（极其昂贵的）技巧，大幅提升了系统的自我修正能力：为其配备 apply_and_check_tool。该工具会执行更严苛的 linting，并启动无头浏览器（headless browser），沿应用的用户流程（user-flows）获取控制枱日志和截图，为智能体提供反馈。正是在此类场景中，MCP（Model Context Protocol）[9]协议将大放异彩 ------ 它能赋予智能体更强的自主权和上下文理解能力。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 逐行解析 Cursor 的系统提示词&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;通过基于 MCP 协议的提示词注入技术，我提取了 Cursor 智能体模式（agent mode）最新（2025 年 3 月）的提示词内容。作为一名长期深耕大语言模型领域的开发者，我必须表达对 Cursor "提示词工程师（prompt engineers）"的高度敬意 ------ 相比其他 AI 编程工具的提示词设计，他们的专业水准令人赞叹（个人观点）。我认为这正是 Cursor 能成为领先编程工具的核心因素。剖析此类提示词也是提升自身提示词编写能力与智能体架构能力的绝佳途径 ------ 从某种意义上看，大多数基于 GPT 的封装工具采用"开放提示词（open-prompt）"实现方案，这种特性极具价值。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8e349136713631673bc71fb2c250460d94f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cursor Agent 系统提示词片段。完整提示词及工具定义（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fsshh12%2F25ad2e40529b269a88b80e7cf1c38084%EF%BC%89" target="_blank"&gt;https://gist.github.com/sshh12/25ad2e40529b269a88b80e7cf1c38084）&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"&amp;lt;communication&amp;gt;"、"&amp;lt;tool_calling&amp;gt;"等标签&lt;/strong&gt; → 混合使用 Markdown 和 XML 标签能大大降低人类和模型对提示词的阅读难度 4。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"由 Claude 3.5 Sonnet 驱动（powered by Claude 3.5 Sonnet）"&lt;/strong&gt; → 大模型通常不会主动声明自身模型版本。显式标注此信息可减少用户对计费模型与实际运行模型不一致的抱怨 5。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"全球最佳 IDE（the world's best IDE）"&lt;/strong&gt; → 该表述简洁地禁止模型在故障时推荐竞品，这对那些代表品牌形象的智能体来说至关重要 6。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"我们会自动附上某些信息...遵循 &amp;lt;user_query&amp;gt; 标签内的用户指令（we may automatically attach some information...follow the USER's instructions...by the &amp;lt;user_query&amp;gt; tag）"&lt;/strong&gt; → Cursor 并未直接将用户提示词传递给模型，而是将其置于专用标签中。这使得系统能在 &amp;lt;user&amp;gt; 消息中传递更多与用户相关的文本，既不会让大语言模型（LLM）混淆，也不会让用户感到困惑。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"避免道歉（Refrain from apologizing）"&lt;/strong&gt; → 这显然是为抑制 Sonnet 模型的致歉倾向而添加的规则。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"绝对不要提及工具名称（NEVER refer to tool names when speaking）"&lt;/strong&gt; → Cursor 特别以加粗格式添加此指令。但讽刺的是，我仍常见到类似"使用 edit_tool"的违规输出 ------ 近期 Sonnet 模型在此方面的表现确实恼人。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"调用每个工具前需先解释（Before calling each tool, first explain）"&lt;/strong&gt; → 当大模型在流式传输（streaming）工具调用时，用户界面会出现短暂卡顿。此指令能帮助用户确信系统正在处理他们的请求，避免因界面停滞而产生不安。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"若部分满足了用户查询，但你还不确定，则请收集更多信息（partially satiate the USER's query, but you're not confident, gather more information）"&lt;/strong&gt; → 大模型智能体常因过度自信而过早终止任务。此指令为其提供"退路"，促使其深度探索后再响应。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"禁止直接向用户输出代码（NEVER output code to the USER）"&lt;/strong&gt; → 默认情况下，大模型倾向以内联代码块（inline markdown codeblocks）形式输出代码。此规则强制其仅通过工具操作代码，并依赖 UI 间接向用户展示变更结果。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"若从零构建 Web 应用，必须设计精美的、现代感的 UI（If you're building a web app from scratch, give it a beautiful and modern UI）"&lt;/strong&gt; → 此为针对演示场景的优化（demo-hacking），确保单提示词（single-prompt）即可生成华丽的应用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"在编辑之前，你必须读取你要编辑的内容 7（you MUST read the contents or section of what you're editing before editing it）"&lt;/strong&gt; → 编码智能体常急于写代码而忽略收集上下文。此类直接的、显式的指令用于校正该行为。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"修复 linter 错误时循环次数不得超过 3 次（DO NOT loop more than 3 times on fixing linter errors）"&lt;/strong&gt; → 旨在防止 Cursor 陷入代码编辑的死循环。此措施虽有帮助，但 Cursor 的深度用户都知道，系统仍易因此卡顿。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"解决根本原因而非仅处理表象（Address the root cause instead of the symptoms）"&lt;/strong&gt; → 这一点是针对大模型常见的对齐问题（alignment issues）：模型常倾向于直接删除报错代码而非修复问题本身。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"禁止硬编码 API 密钥（DO NOT hardcode an API key）"&lt;/strong&gt; → 众多安全方面的最佳实践之一，至少可以防止一些明显的安全问题。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;工具 codebase_search/read_file/grep_search/file_search/web_search&lt;/strong&gt; → 鉴于编码前获取正确上下文是非常重要的，Cursor 提供多种形态的搜索工具，确保智能体能够轻松定位要做的修改。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;一些工具中的"单句解释...说明为何需要运行此命令..."（"One sentence explanation...why this command needs to be run..."）&lt;/strong&gt; → 大多数工具都包含这个非功能性参数，它迫使大模型推理论证它将传递哪些参数，此为提升工具调用准确性的常规技巧。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;reapply 工具"调用更强大模型执行上次编辑的内容（Calls a smarter model to apply the last edit）"&lt;/strong&gt; → 允许主智能体动态升级应用模型（即使用更高成本模型），自主解决低级应用错误。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;edit_file 工具要求"用对应语言的注释表示未修改代码（represent all unchanged code using the comment of the language you're editing）"&lt;/strong&gt; → 此规则解释了自动生成的随机注释的来源，也是应用模型正常工作的必要前提。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;您会注意到整个系统提示词和工具描述均为静态内容（未注入用户或代码库个性化文本）。&lt;/strong&gt; 该设计使 Cursor 能充分利用提示词缓存（prompt caching） 优势[10]，大幅降低推理成本并减少输出首个 token 的延迟时间（time-to-first-token latency） ------ 这对每次使用工具都需调用大模型的智能体架构至关重要。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;03 如何高效制定 Cursor Rules&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;现在最大的问题是，编写 Cursor rules 的"正确方式"是什么？虽然我的整体答案是"以实际效果为准，适合你的才是最好的"（whatever works for you），但基于提示词工程经验和对 Cursor 内部原理的认知，我确实有大量具体建议。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-de0947ac445dd1c5a3c2a12d4151efe865a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;大语言模型如何看待你的 Cursor 项目规则？模型会看到规则的名称和简介列表，然后根据需要调用 fetch_rules(...) 函数来获取和查看具体的规则内容&lt;/p&gt; 
&lt;p&gt;关键是要明白，这些规则并非是附加到系统提示词中的，而是作为具名指令集（named sets of instructions）被引用。因此，建议采用编写百科词条（encyclopedia articles）而非命令（commands）的思维方式设计 Cursor rules。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;切勿在 Cursor rules 中声明身份（例如"您是精通 TypeScript 的资深前端工程师"）。&lt;/strong&gt; 此类规则虽见于 cursor.directory 且看似有效，但会与内置提示词赋予的身份产生冲突，导致智能体行为异常。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;避免尝试覆盖系统提示词指令，或通过特定提示词（prompt）引导应用模型（apply model）的行为。&lt;/strong&gt; 类似"别添加注释"、"编码前先提问"、"勿删除未提及代码"的指令会直接破坏工具使用机制并干扰智能体运作。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;减少使用否定性指令。&lt;/strong&gt; 大模型更擅长遵循正向指令（"若遇&amp;lt;此情况&amp;gt;，则&amp;lt;执行此操作&amp;gt;"），而非单纯列出限制条件。此原则亦体现在 Cursor 的官方提示词中。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;请务必花时间编写高度明显的规则名称和描述。&lt;/strong&gt; 关键在于，即使智能体（Agent）对您的代码库所知甚少，也能凭直觉知道何时适合应用某条 Cursor rules 来使用其 fetch_rules(...) 工具。类似于手动建立文档索引的做法，你应该适当地创建一些内容相同但名称和描述不同的规则副本，这样可以提高 AI 找到相关规则的概率。规则描述应当力求信息密集，避免过度冗长。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;把你的模块规则和常见代码修改规则写得像百科词条一样详细和完整。&lt;/strong&gt; 如同维基百科那样，将关键术语（使用 mdc 链接语法）链接到代码文件，这在智能体确定代码变更所需的关键上下文时能提供巨大助力。有时，这也意味着，要避免按部就班地进行说明（专注于"做什么"而非"怎么做"），除非真的没办法，否则不要让智能体过度专门化，只会处理某一种特定的代码修改模式。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;请务必使用 Cursor 本身来起草您的 Cursor rules 。&lt;/strong&gt; 大语言模型（LLMs）非常擅长为其他大语言模型撰写内容。如果您不确定如何组织文档格式或编码上下文，请执行 "@folder/ generate a markdown file that describes the key file paths and definitions for commonly expected changes"。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;要意识到制定太多规则其实是个不好的做法。&lt;/strong&gt; 这一点看似违反直觉 ------ 虽然规则确实是让 AI 开发工具处理大型项目的关键，但需要很多规则本身就暴露了一个问题：你的代码库对 AI 来说不够友好。我在《AI-powered Software Engineering》[11]一书中深入探讨了这个话题。未来理想的代码库应该设计得足够清晰直观，AI 编程工具光靠基础功能就能完美胜任所有工作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;请参考我生成的一些示例[12]。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Conclusions&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;一个基于近乎开源的智能体提示词和公开模型 API 构建的 VSCode 分支，其估值竟能接近 100 亿美元 ------ 带着 68 倍的"wrapper multiple"8 ------ 这着实令人惊叹。我们将拭目以待 Cursor 最终是否会开发自己的智能体模型（感觉可能性不大），或是 Anthropic 是否会带着 Claude Code + 下一代 Sonnet 强势介入成为竞争对手。&lt;/p&gt; 
&lt;p&gt;无论最终结果如何，学会如何优化你的代码库、文档和规则配置仍然是一项有用的技能。我希望这次深入探讨能让你对 Cursor 的工作原理以及优化之道有更具体、更实用的理解。&lt;/p&gt; 
&lt;p&gt;我经常说这句话，现在再说一遍：&lt;strong&gt;如果你觉得 Cursor 不好用，那一定是你用错了方法。&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;1.这是一个基于直觉的统计数据，但我认为相差不远。一旦你熟练掌握了 Cursor rules，相当数量的 PR 实际上就变成了单次发送提示词（one-shot prompts）的事。我原本以为要到 2027 年才能达到这个水平，但随着 Anthropic、Cursor 和我自己的提示词水平同时提升，进展比我预想的要快。&lt;/p&gt; 
&lt;p&gt;2.到目前为止，我对 CodeRabbit 的代码检查功能印象非常深刻，计划使用 MCP 将其集成到 Cursor 中。如果 Cursor 的默认代码检查器能更好一些，在其他条件不变的情况下，使用体验会像用 Sonnet 3.8 一样。&lt;/p&gt; 
&lt;p&gt;3.（大多数）LLM 的美妙之处在于，虽然这是一个 Web 开发基准测试，但根据我的经验，其性能与各种类型的编程和框架都有很强的相关性。&lt;/p&gt; 
&lt;p&gt;4.我没能找到相关的科学研究，但基于个人经验，这种方法效果很好，如果 Anthropic 的模型专门针对伪 XML 语法进行训练，我也丝毫不会感到惊讶。&lt;/p&gt; 
&lt;p&gt;5.这确实会产生一些意想不到的副作用，编程模型会将你代码库中引用的模型名称更改为它自己（引用的模型）的名称。&lt;/p&gt; 
&lt;p&gt;6.这里存在一个有趣的法律灰色地带。Cursor 将此内容放在他们的网站上实际上是违法的（见《联邦贸易委员会法》、《兰哈姆法》），但（至少目前）他们将内容放进提示词（prompt）中，并由 LLM 代其表述出来，却是被允许的。&lt;/p&gt; 
&lt;p&gt;7.顺便说一句："Cursor 团队，我发现了一个错别字 (:"&lt;/p&gt; 
&lt;p&gt;8.这是我创造的一个术语，用来表示基于 GPT 封装的工具的估值与模型提供商估值之间的比率。在这种情况下，Anthropic : Cursor = 600 亿美元 : 100 亿美元 = 6。我的直觉告诉我"6"不是一个合理的比率。戴上我那业余投资者的帽子，我推测 Anthropic 应该接近 1000 亿美元，而 Cursor 则最高达 10 亿美元（wrapper multiple 为 100）。我实在看不出他们其中任何一方真的拥有持久的"护城河"（long term moat），Anthropic 构建自己的下一代 AI 编程工具似乎也是轻而易举的事。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓文中说『未来理想的代码库应该对 AI 足够友好』，你眼中的『AI 友好型代码库』有哪些具体特征？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2F" target="_blank"&gt;https://www.cursor.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodeium.com%2Fwindsurf" target="_blank"&gt;https://codeium.com/windsurf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffeatures%2Fcopilot" target="_blank"&gt;https://github.com/features/copilot&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcdn.openai.com%2Fbetter-language-models%2Flanguage_models_are_unsupervised_multitask_learners.pdf" target="_blank"&gt;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2203.02155" target="_blank"&gt;https://arxiv.org/abs/2203.02155&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fconcepts%2Ftool_calling%2F" target="_blank"&gt;https://python.langchain.com/docs/concepts/tool_calling/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fcursor%2Fcomments%2F1h9d763%2Fdid_cursor_really_need_to_fork_vscode_rather_than%2F" target="_blank"&gt;https://www.reddit.com/r/cursor/comments/1h9d763/did_cursor_really_need_to_fork_vscode_rather_than/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.lmarena.ai%2Fleaderboard" target="_blank"&gt;https://web.lmarena.ai/leaderboard&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fintroduction" target="_blank"&gt;https://modelcontextprotocol.io/introduction&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fprompt-caching" target="_blank"&gt;https://www.anthropic.com/news/prompt-caching&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sshh.io%2Fp%2Fai-powered-software-engineering" target="_blank"&gt;https://blog.sshh.io/p/ai-powered-software-engineering&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.sshh.io%2Fshare%2FpWMGGDyPTok05mxOq17p-" target="_blank"&gt;https://chat.sshh.io/share/pWMGGDyPTok05mxOq17p-&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sshh.io%2Fp%2Fhow-cursor-ai-ide-works" target="_blank"&gt;https://blog.sshh.io/p/how-cursor-ai-ide-works&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18627427</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18627427</guid>
      <pubDate>Sat, 10 May 2025 07:43:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Cursor 推出月费 200 美元的 Ultra 计划，Pro 计划将更新为「不限量但有速率限制」的模式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cursor 推出了每月 200 美元的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fcn%2Fblog%2Fnew-tier" target="_blank"&gt;Ultra 计划&lt;/a&gt;。官方称这个变化来自高级用户的需求，他们希望获得&lt;strong&gt;比按使用量计价更有可预测性的&lt;/strong&gt;订阅计划。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/151550_1QMH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;新的 Ultra 计划&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;每月费用为 200 美元&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用量是 Pro 计划的 20 倍&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;专为追求比按使用量计价更稳定价格的高级用户设计&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Pro 计划的变更&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pro 计划将更新为「不限量但有速率限制」的模式&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将取消对工具调用的所有限制&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;现有用户如果愿意，可以选择继续使用之前的「500 次请求限制」方法（通过仪表板 &amp;gt; 设置 &amp;gt; 高级选项）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;详情：https://www.cursor.com/blog/new-tier&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355977</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355977</guid>
      <pubDate>Sat, 10 May 2025 07:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>通用智能体 Genspark 免费提供 OpenAI o3-pro 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能体 Genspark&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgenspark_ai%2Fstatus%2F1934633273940115571" target="_blank"&gt; 宣布&lt;/a&gt;其 AI Chat 功能现已免费提供 &lt;a href="https://www.oschina.net/news/354753/openai-o3-pro" target="news"&gt;OpenAI o3-pro&lt;/a&gt;&amp;nbsp;模型。免费用户每天可获得 200 积分，Plus 用户则可无限量使用。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1090" src="https://static.oschina.net/uploads/space/2025/0618/150220_b7UB_2720166.png" width="1278" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;o3-pro 是 OpenAI 最新发布的推理模型，基于 o3 所打造，拥有更强的数学、科学、编程等领域的表现。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;o3-Pro 可，自动调用多种工具，包括可以搜索网页、分析文件、推理视觉输入、使用 Python、通过记忆功能个性化回复等。&lt;strong&gt;由于调用的工具较多，所以，思考的时间比 o1 Pro、o3 更长。&lt;/strong&gt;o3-pro 与 o3 系列一样拥有 200K 的上下文窗口和 100K 的输出，但价格却比它们暴降 80%。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;价格方面，o3-pro 输入为 20 美元 / 百万 token，输出 80 美元 / 百万 token。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Genspark 由百度前高管景鲲创立，今年 4 月宣布&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能体 "Genspark Super Agent"，号称是一款 "快速、准确、可控" 的通用 AI 代理。这一消息迅速在技术社区引发热议，众多专业人士将其与 Manus 相提并论，认为这标志着通用 AI 代理技术的新一轮角逐。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355972</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355972</guid>
      <pubDate>Sat, 10 May 2025 07:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>韩国计划未来 5 年在 AI 领域投入 16 万亿韩元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;外媒援引业内消息人士&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.yna.co.kr%2Fview%2FAEN20250618008500320%23%3A%7E%3Atext%3DSEOUL%252C%2520June%252018%2520%2528Yonhap%2529%2520--%2520South%2520Korea%2527s%2520science%2Cand%2520development%2520%2528R%2526D%2529%2520activities%252C%2520industry%2520sources%2520said%2520Wednesday." target="_blank"&gt;透露&lt;/a&gt;，韩国科技部已申请在未来五年内拨付超过 16 万亿韩元（约合 117 亿美元）的预算，用于建设国家人工智能（AI）基础设施和支持与 AI 相关的研发活动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="298" src="https://oscimg.oschina.net/oscnet/up-ff88a8c741069c76b9c2d612b6c7bb3fc53.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据知情人士称，韩国科技部以到 2030 年使韩国成为世界三大 AI 强国之一为目标，提交了一份要求拨款总额为 16.08 万亿韩元的提案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韩国科技部拒绝证实这一消息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息人士称，在这笔 16 万亿韩元的预算中，其中 12.3 万亿将将专门用于建立「AI 高速公路」，其中包括建设配备 5 万个 GPU 的 AI 数据中心。其他资金将用于支持 AI 相关的研发、AI 专业产业园区的发展和政策贷款项目。预算还将用于培养专业技能人才，以引领 AI 领域的创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另外，韩国科技部还要求在 5 年内投入 3.09 万亿韩元，用于加强韩国的数字基础设施，提高用户的便利性。其中，2.34 万亿韩元将用于加强网络安全和构筑更安全的数字环境。该部还建议减轻公众的电信负担，允许手机话费减税。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355971</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355971</guid>
      <pubDate>Sat, 10 May 2025 07:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OSC 社区 2.1 发布：私有化 + AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;内容社区拒绝一切广告，是逃避；把广告做到让人反感，是失衡。&lt;/p&gt; 
&lt;p&gt;社区的生命力，从来不在于「免费」与「流量」的幻象，而是在于自我造血，持续成长。那些只依赖低价 CPM 和人海运营的社区，终将如天涯、猫扑那样被时代抛弃 —— 它们活得像一条奄奄一息的巨鱼，体型庞大却无力回天。&lt;/p&gt; 
&lt;p&gt;早年，「社区＝广告」几乎是唯一选项。国内大多数社区依靠信息流广告，CPM（每千次曝光收入）往往在 6 元人民币左右；而 YouTube 同期的 CPM 高达 18 美元（约合 129 元人民币），两者相差 21 倍。当广告收益的天花板被牢牢掐住，内容与运营的成本却从未松动，社区便陷入了必然的人力成本漩涡。&lt;/p&gt; 
&lt;p&gt;我们曾见证，一家拥有百万级日活的社区，为了承载社区安全审核和运营，仅内容审核团队就 200 人，支撑起从人工审核到紧急拦截的全流程；运营团队更是分区、分板块、分专题地轮番维护，人工成本与日俱增。即使人海战术能暂时撑起「多板块分流」的表面繁荣，可背后累积的工资支出，却如同吞噬社区未来的黑洞。&lt;/p&gt; 
&lt;p&gt;有人说，「社区的灵魂在于共创与分享」，这没错；但我更认同，「社区的命脉在于变现与可持续」。那些传统的广告商业化模式，虽显其短期效益，却无法带来长久的繁荣。只有找到既能坚守社区初心，又能持续自我造血的创新路径，才能真正让分享在实践中扎根，交流在未来中生长。&lt;/p&gt; 
&lt;p&gt;答案在于通过 AI 赋能，实现社区的智能化升级，并构建可私有化部署的智能知识库，为企业提供持续创新和高效协作的解决方案。&lt;/p&gt; 
&lt;p&gt;今天，开源中国技术社区（&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FOSCHINA.NET" target="_blank"&gt;OSCHINA.NET&lt;/a&gt;）推出&lt;strong&gt;「数字化企业知识管理 AI 平台」&lt;/strong&gt;，以突破性思路重塑社区商业模式：将社区沉淀的技术力与 AI 深度融合，打造可私有化部署的「企业知识中枢」，从 C 端流量生意转向 B 端价值创造。实现社区从「免费流量」到「付费解决方案」的全面跃迁。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/141154_0IaF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;从「模型」到「场景」，构建真正的 AI 全栈社区&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;GiEngine 高速推理引擎 - 私有化 AI 智能响应&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在需要对内部海量知识进行实时检索与推理的场景，OSC 通过 GiEngine 多模型推理能力，实现在本地环境中对 DeepSeek、Qwen3、GLM4 等模型的百毫秒级响应。用户可即时获得精准答案，显著提升内部协作效率并降低运维压力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OSC × AI 内容工厂 - 高效闭环的知识生成&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在跨部门内容策划、审批与发布流程复杂、效率低下的场景，&lt;span style="color:#27ae60"&gt;OSC 将社区沉淀的 2000 万篇开源技术方案与 AI 创作引擎深度融合，自动完成「策划→采集→翻译→撰写→审核→发布」闭环。&lt;/span&gt;部门间协同成本下降 60%，知识沉淀速度提升 3 倍，实现持续可复用的企业级知识库。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI 智能推荐系统 - 精准匹配客户需求&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在面临海量信息难以快速定位高价值内容的场景，OSC 引入原创度、全网热度、社交反馈、用户画像匹配度等多维打分，并结合实时热榜与行业标签精准推送，解决信息茧房与同质化问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;人格化 AI 问答机器人 – 7×24 小时无感问题解决&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI 问答机器人专注于技术问答场景，系统结合全文检索与大模型生成，以「无感」方式自动理解用户需求，快速给出精准解答。用户平均从提问到获得完整解答的时间可从 10 分钟缩短至 1 分钟，节省约 90% 的时间成本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI 态势大屏&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在需要宏观监控社区健康与风险预警的场景，OSC 利用 RAG 检索增强与大模型趋势预测，打造「运营指挥中心」可视化平台，一屏呈现访问热力、留存、算力消耗、安全拦截等核心指标。管理者可实现宏观与微观的无缝切换，决策效率提升 20%，风险响应时间缩短 50%。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;私有化部署的五大价值&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;安全合规与自主可控&lt;/strong&gt;&lt;/span&gt;：私有化部署在客户内网完成，全链路数据不出域，兼容国产操作系统、中间件与数据库；同时提供细粒度权限管控与操作审计，确保社区运行合规、可控、可信。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;知识共创与沉淀&lt;/strong&gt;&lt;/span&gt;：员工可跨部门在同一平台发起话题、撰写文档、沉淀 FAQ，AI 与人协作的内容自动归档入库，打破知识孤岛，形成可检索、可复用的组织级知识资产。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;跨部门协作与创新&lt;/strong&gt;&lt;/span&gt;：内置在线讨论、活动中心与智能推荐模块，线上线下无缝衔接，激发创新灵感，促进多团队协同和技术孵化。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;智能运营降本增效&lt;/strong&gt;&lt;/span&gt;：AI 自动化覆盖采集、翻译、编辑、审核与发布全流程，7×24h 不间断运营，内容更新频率提升 3 倍以上，人力成本减少 60%，并通过预测预警保障运营质量与安全。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;数字化转型赋能&lt;/strong&gt;&lt;/span&gt;：整合海量开源技术内容与文档资源，提供从知识获取、技能提升到实践落地的端到端数字化支持；依托模型微调与数据反馈，平台持续进化，助力组织加速数字化升级。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;商业不是污染源，是让技术流动的河&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;社区的灵魂在于共创与分享。没错，但真正的价值释放，必须伴随可持续的商业闭环。AI 与社区的融合只是开始，我们将继续突破边界，推出更多 AI 项目 - 从直播驱动硬件 prototyping，到 AI 培训教育孵化新一代开发者；从行业专属知识库，到全链路智能运营。&lt;/p&gt; 
&lt;p&gt;过去两年，开源中国社区通过 AI 能力驱动内容增长，内容运营成本降低 30%、商业化营收提升 200%，同时也吸引了多家客户定制化部署合作的需求，更有外资企业前来考察，意欲引入我们的「数字化企业知识管理 AI 平台」。下一步，我们的目标是再翻一番 —— 向政采商机、行业大厂以及全球化市场持续扩张。&lt;/p&gt; 
&lt;p&gt;在「数字中国」「网络强国」战略的双轮驱动下，企业级社区已成为国家数字基础设施的重要组成部分。&lt;span style="color:#27ae60"&gt;开源中国社区的「数字化企业知识管理 AI 平台」不仅为企业提供「知识管理＋智能创作＋可视化决策」的一站式解决方案，也正承载着国家「自主可控」「高质量发展」的时代使命&lt;/span&gt;。AI 与社区的深度融合，将助力中国企业在未来十年实现真正的科技突围与产业升级。&lt;/p&gt; 
&lt;p&gt;真正的商业化成功，从不是孤军奋战，而是与时代共潮生。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;数字化企业知识管理 AI 平台：&lt;/strong&gt;&lt;em&gt;&lt;a href="http://next.oschina.net/"&gt;next.oschina.net&lt;/a&gt;&lt;/em&gt;&lt;/h4&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355961</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355961</guid>
      <pubDate>Sat, 10 May 2025 06:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman：Meta 曾试图以 1 亿美元挖走 OpenAI 人才，但未能成功</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 首席执行官马克·扎克伯格 (Mark Zuckerberg ) 最近大举招聘，试图从竞争对手的实验室挖角顶尖 AI 研究人员，以充实 Meta 新的超级智能团队。据报道，为了在由 Scale AI 前首席执行官 Alexandr Wang 领导的团队中工作，并在扎克伯格附近办公，Meta 向 OpenAI 和谷歌 DeepMind 的员工提供了高达 1 亿美元的薪酬待遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 首席执行官萨姆·奥尔特曼 (Sam Altman) 在周二与其兄弟 Jack Altman 共同发布的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fjaltma%2Fstatus%2F1935063796802011164" target="_blank"&gt;播客&lt;/a&gt;中证实了这些报道。但他指出，扎克伯格的招募工作基本上没有成功，并在过程中多次挖苦 Meta。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「[Meta] 开始给我们队里的很多人开出巨额合同。你知道，比如每年 1 亿美元的签约奖金，比这还多的薪水……我很高兴，至少到目前为止，我们最优秀的员工中还没有人决定接受他的条件。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="416" src="https://oscimg.oschina.net/oscnet/up-bc17827506816afff89a78697159baba20a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Altman 称，他相信员工们的评估是，OpenAI 更有可能实现 AGI，并且有朝一日可能成为更有价值的公司。他认为 Meta 公司只关注员工的高额薪酬，而不是实现 AGI 的使命，这很可能不会创造出优秀的企业文化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息称，Meta 曾试图挖走 OpenAI 的首席研究员之一 Noam Brown 以及谷歌的 AI 架构师 Koray Kavukcuoglu。然而，这两次尝试都未能成功。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Altman 认为，OpenAI 的创新文化是其成功的关键，而 Meta 的「当前 AI 努力并未取得预期的效果」。并表示，他尊重 Meta 的很多方面，但也指出他「并不认为他们是一家擅长创新的公司」。在播客的后半部分，Altman 表示，他认为企业仅仅在 AI 领域迎头赶上是不够的——他们必须真正创新才能保持领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，Sam Altman 还描述了一款可能会蚕食 Meta 应用市场的由 AI 驱动的社交媒体信息流。他表示，自己很有兴趣探索一款利用 AI 根据用户需求提供定制信息流的社交媒体应用，而不是传统社交媒体应用中默认的算法信息流。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355944/sam-altman-meta-tried-100m-offers</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355944/sam-altman-meta-tried-100m-offers</guid>
      <pubDate>Sat, 10 May 2025 03:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
