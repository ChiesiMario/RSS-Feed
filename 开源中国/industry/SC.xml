<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 29 Jul 2025 12:44:03 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>马斯克宣布 Grok 推出新 UI，引入「Auto 模式」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;马斯克&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1948992239071326244" target="_blank"&gt;宣布&lt;/a&gt;，Grok&amp;nbsp;已推出新的用户界面。该更新目前已在网页端上线，并将很快推广至移动端 APP。&lt;/p&gt; 
&lt;p&gt;新界面增加了一个新的模型选择器功能。该功能引入了 Auto 模式，允许应用自动选择合适的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1613" src="https://static.oschina.net/uploads/space/2025/0729/192206_0PZn_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前已经用户体验到了新版的移动端 APP，并表示有「两个版本」：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-87130b778bb6fac752a16c5287206709ff7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b88733bc4bda21493906af15dda98f02539.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363022</guid>
      <pubDate>Thu, 17 Jul 2025 11:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源项目 Kapitano 作者无端遭遇人身攻击，心灰意冷之下宣布停止维护</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，Linux 开源社区发生了一起令人遗憾的事件，开发者 zynequ 宣布，由于遭遇无端的人身攻击，他决定停止维护其开源项目 Kapitano。&lt;/p&gt; 
&lt;p&gt;Kapitano 是一个为命令行杀毒工具 ClamAV 提供图形界面的应用程序，可帮助 Linux 用户更方便地使用 ClamAV 进行病毒扫描。&lt;/p&gt; 
&lt;p&gt;起因是一位用户在 Kapitano 的 Codeberg 页面上创建了一个问题，声称该软件在其 Linux Mint 系统上产生了误报，检测到 24 个与 Windows 漏洞和木马相关的阳性结果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-da7edb2fb2aa6ca9655d630c2e2b8a6933a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该用户声称所有被标记的文件都与 Kapitano Flatpak 本身有关，并且以一种较为激进的方式警告其他用户不要下载该程序。&lt;/p&gt; 
&lt;p&gt;该用户甚至表示：「程序没有任何评论，应该保持这种状态，直到源代码被独立来源验证。」&lt;/p&gt; 
&lt;p&gt;zynequ 在回应中冷静地指出，问题并不是他的应用程序，Kapitano 并不参与具体的病毒判断逻辑。&lt;/p&gt; 
&lt;p&gt;他还提供了相关代码的链接，证明 Kapitano 只是调用了 ClamAV 的 clamscan 和 freshclam 命令。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ada62c2d3c6bf63d9f8dd27f293bb5a7110.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;然而事情并没有就此结束，用户随后创建了重复的问题，并声称 zynequ 是恶意行为者，要求将他这个「恶意软件传播者」封锁。&lt;/p&gt; 
&lt;p&gt;经过激烈的争论后，用户表示：「你的项目已经从我的笔记本硬盘中删除了。让它安息吧。再见。」&lt;/p&gt; 
&lt;p&gt;最终 zynequ 发布终止维护声明，他指出，Kapitano 是一个纯粹的爱好项目，没有得到任何经济支持，而这种无端的人身攻击让他很难保持开发的动力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-011febf1266dc370c06a3c74915c45686a5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;zynequ 宣布，Kapitano 的代码现在已发布到公共领域，采用无许可证（The Unlicense），这意味着任何人都可以分叉并随意使用它。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363019</guid>
      <pubDate>Thu, 17 Jul 2025 11:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>新研究提出 AI 自主架构发现系统 ASI-Arch</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;上海创智学院领衔的团队发布了 AI&amp;nbsp;超智能系统：ASI-Arch，其成功设计彻底颠覆了这一认知。该系统基于先进的大模型技术，构建了高度自主的多智能体研究框架，能够完全独立地进行从问题识别、假设生成、实验设计到结果验证的完整科学研究流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/184132_dCXe_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文标题: AlphaGo Moment for Model Architecture Discovery&lt;/li&gt; 
 &lt;li&gt;系统开源: https://github.com/GAIR-NLP/&lt;/li&gt; 
 &lt;li&gt;ASI-Arch 网站地址: https://gair-nlp.github.io/ASI-Arch/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;据介绍，在长达数月的自主研究过程中，ASI-Arch 系统展现出了令人震撼的研究能力。系统共进行了 1,773 次独立实验，累计消耗超过 20,000 GPU 小时的计算资源，在无人干预的情况下，ASI-ARCH 自主发现了 106 个新颖且性能卓越的线性注意力架构，这些架构在多个基准测试中超越了如 Mamba2 和 Gated DeltaNet 等强大的基线模型。&lt;/p&gt; 
&lt;p&gt;这一研究规模和效率远超传统人类研究团队的能力范围。&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0729/184123_2g16_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图：AI 自主进行了 1,773 次科研探索&lt;/p&gt; 
&lt;p&gt;ASI-ARCH 系统成功发现了 106 个全新的线性注意力机制架构，每一个在性能指标上都显著超越了现有的人类设计方案。这些发现的重要性不仅在于性能提升，更在于设计理念的创新。系统提出的许多架构设计原理和优化策略，即使是该领域的顶级专家也承认此前从未考虑过。这表明 AI 系统已经具备了超越人类认知边界的创新能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363014</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363014</guid>
      <pubDate>Thu, 17 Jul 2025 10:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 AI 编程工具 Gemini CLI 定为每周三发布更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;为提高更新流程的有序性，Gemini CLI 的发布周期将调整为每周三定期更新。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1404" src="https://static.oschina.net/uploads/space/2025/0729/182925_0lMy_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini CLI 维护团队成员宣布将对其 Gemini CLI 的更新发布计划进行调整。从现在开始，Gemini CLI 的更新将在每周三定期发布，以使更新流程更有序、更有计划性。&lt;/p&gt; 
&lt;p&gt;Gemini CLI 是谷歌开源的免费 AI 编程工具，该工具将 Gemini 的能力带到了开发者最常用的终端，能够提供轻量化的 Gemini 访问通道。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363011</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363011</guid>
      <pubDate>Thu, 17 Jul 2025 10:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 首席科学家杨立昆回应另一位首席科学家的加入</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 近日宣布清华校友赵晟佳（Shengjia Zhao）将&lt;a href="https://www.oschina.net/news/362754"&gt;正式&lt;/a&gt;担任其超级智能实验室（ MSL）首席科学家。&lt;/p&gt; 
&lt;p&gt;而 Meta 中的另一个 AI 团队部门——FAIR 团队，虽然在 Meta 的整体战略中逐渐边缘化，但 65 岁的图灵奖得主 Yann LeCun（杨立昆）的职位未发生变化。扎克伯格也特别强调，&lt;strong&gt;杨立昆将继续担任 FAIR 的首席科学家&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-10f48ab6c9358abcb6969b367b7a7b9619d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;与 MSL 不同，FAIR 专注于长期 AI 研究——即可能在五到十年后使用的技术。而对于扎克伯格的任命宣布，Yann Lecun 也回应表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我作为 FAIR 首席科学家的角色一直专注于长期的人工智能研究和构建下一代人工智能范式。我期待与赵晟佳合作，加速将新研究成果整合到我们最先进的模型中。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363007</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363007</guid>
      <pubDate>Thu, 17 Jul 2025 10:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 招聘硬件系统产品设计师，打造「下一代全球最具创新移动设备」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正在招聘多个消费硬件相关职位，引发外界对其布局新品的猜测。其中，硬件系统产品设计师岗位旨在打造「下一代全球最具创新的移动设备」。&lt;/p&gt; 
&lt;p&gt;在硬件系统产品设计师的&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fjobs%2Fview%2Fhardware-systems-product-designer-at-openai-4263584294%2F" target="_blank"&gt;职位描述中&lt;/a&gt;&lt;/u&gt;，OpenAI 表示该职位要求应聘者具备强大的机械设计技能，以及制造性设计（DFM）、装配性设计（DFA）、公差与尺寸设计等领域的专业知识。此外，还需要具备组件模块的经验，包括 OLED / LCD 显示屏、电池、声学、摄像头模块，以及蜂窝和 GPS 系统等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1650" src="https://static.oschina.net/uploads/space/2025/0729/180234_vwbc_2720166.png" width="1410" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，OpenAI 也在招募电气工程师，以「设计和优化高性能硬件产品的下一代充电技术」，涉及电路设计与充电技术优化，可能为未来设备构建无线充电平台。有用户推测，该设备或类似智能手表或 Humane AI 别针，具备摄像头、屏幕和麦克风等功能。&lt;/p&gt; 
&lt;p&gt;一位用户在 X 社交平台上&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fliminalsunset_%2Fstatus%2F1949642969914778016" target="_blank"&gt;猜测&lt;/a&gt;&lt;/u&gt;：「这看起来像是他们正在为 io 设备招聘，可能包含摄像头、小屏幕和麦克风。」这位用户推测这可能是智能手表或类似 Humane AI 别针的设备。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363005/hardware-systems-product-designer-at-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363005/hardware-systems-product-designer-at-openai</guid>
      <pubDate>Thu, 17 Jul 2025 09:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>全新高效模型架构！RWKV-7s 闪耀 WAIC</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 26-29 日，&lt;strong&gt;RWKV 团队受邀参加 2025 世界人工智能大会（WAIC 2025）&lt;/strong&gt;, 并在大会公开了 RWKV 最新的高效大模型架构：RWKV-7s，吸引了来自产业界、学术界及媒体的广泛关注与讨论。&lt;/p&gt; 
&lt;h2&gt;战略合作，广泛落地&lt;/h2&gt; 
&lt;p&gt;7 月 26 日，&lt;strong&gt;移远通信宣布与 RWKV 公司建立全面合作关系&lt;/strong&gt;，双方将依托移远的算力平台，优化并支持 RWKV 最新模型架构，共同推动大模型在端侧设备的低资源占用部署。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV x 移远通信" src="https://oscimg.oschina.net/oscnet/up-ec04d5001a459b4a33964c1c2478645def2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUk6xlo-MQ09vS9JFwf35NA" target="_blank"&gt;端侧大模型迎来「轻」革命！移远通信 × RWKV 打造「轻量 AI 大脑」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;凭借 RWKV 架构「资源占用和推理速度恒定」的特性，RWKV 系列模型在端侧部署具有天然优势。&lt;strong&gt;现在，RWKV 已与多家芯片厂商、具身智能厂商合作将 RWKV 模型部署在芯片及机器人上&lt;/strong&gt;，如：高通、联发科、Intel、AMD、英伟达、地平线机器人、有鹿机器人等等。&lt;/p&gt; 
&lt;h2&gt;全新技术，全面领先&lt;/h2&gt; 
&lt;p&gt;WAIC 大会首日，承接 RWKV-7 优势的 RWKV-7s 新型高效大模型架构正式发布。凭借其原创的 DeepEmbed 和 DeepEmbedAttention 技术，成为现场焦点并 &lt;strong&gt;荣获 WAIC「镇馆之宝-未来之星」称号&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="WAIC-Award" src="https://oscimg.oschina.net/oscnet/up-e03b0a22f02ad601b832cf7790bf0bd78e8.jpg" referrerpolicy="no-referrer"&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhH7y37AcYP4GWOIjhNHz7g" target="_blank"&gt;镇馆之宝｜WAIC 2025 镇馆之宝及系列奖项名单公布&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-7s 是 RNN+DeepEmbedAttention 混合架构，兼具高效计算与强长文本性能，其设计创新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;原创 DeepEmbed 技术，大稀疏模型只需小显存，比 MoE 显著更适合端侧！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;原创 DeepEmbedAttention (DEA) 技术，长文本性能看齐 Attention，而 KV cache 仅为 MLA 的 1/9，更快更省！&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="DeepEmbed" src="https://oscimg.oschina.net/oscnet/up-78a8be5b2720c3b1b8ac934f907d2e6d5cf.png" referrerpolicy="no-referrer"&gt; &lt;img alt="DeepEmbedAttention" src="https://oscimg.oschina.net/oscnet/up-8c057eabf3fdcda0299f303d25e8433b8a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-7s 架构支持适配大语言模型、多模态、智能体等多种应用场景，凭借广泛的适配性吸引了现场各领域有智能化发展需求的企业关注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eb5cd7552cfc42ce0e5ca61d787880e5ceb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;多场深度分享&lt;/h2&gt; 
&lt;p&gt;大会期间，&lt;strong&gt;RWKV 联合创始人 &amp;amp; COO 罗璇及 RWKV-PEFT 与 WorldRWKV 作者康嘉乐受邀参与多场技术论坛与专题活动&lt;/strong&gt;，围绕 RWKV-7s 混合架构、AGI 演进路径及端侧部署趋势等话题展开深度分享。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="mohe" src="https://oscimg.oschina.net/oscnet/up-9bcdda5f376377dfa999b9685d793452f65.png" referrerpolicy="no-referrer"&gt; &lt;img alt="open_talk" src="https://oscimg.oschina.net/oscnet/up-3a8aebd93474fb31316773da624d59feaa3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;端侧 Demo&lt;/h2&gt; 
&lt;p&gt;展会现场，&lt;strong&gt;RWKV 展台同步展出了五款 RWKV 自研的端侧离线应用&lt;/strong&gt;。凭借对多模态场景的广泛覆盖，收获了现场观众的热烈反响。&lt;/p&gt; 
&lt;p&gt;其中，&lt;strong&gt;RWKV 作曲家&lt;/strong&gt;升级全新输入方式。除原有的虚拟键盘和蓝牙 MIDI 键盘输入以外，&lt;strong&gt;新增哼唱识别乐谱输入功能，大幅降低使用门槛，便捷不同用户使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV 作曲家" src="https://oscimg.oschina.net/oscnet/up-7d3a18337b7b4cc8bab88df444b0e5fafd3.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV Chat 内置 RWKV7-G1 推理模型，&lt;strong&gt;无需联网即可实现推理、深度对话与文本续写。其中的 RWKV7-G1 2.9B 模型在高通手机平台的速度可达 30 token/s&lt;/strong&gt;，且由于 RWKV 架构无需 KV cache，在超长推理后仍然可以速度恒定，内存占用恒定。&lt;/p&gt; 
&lt;p&gt;本次展示，RWKV Chat 全面优化 UI 界面，&lt;strong&gt;新增 Agent 陪聊与文本续写功能，开发团队还同步推出新手、高级、专家三种应用模式&lt;/strong&gt;，以满足不同技术背景用户的需求为核心，为用户带来更个性化的体验。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV Chat" src="https://oscimg.oschina.net/oscnet/up-4953f6c241e03a59b465a5b2bfbda1ba2af.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，RWKV 展位还演示了端侧离线部署的图像多模态应用 &lt;strong&gt;RWKV See&lt;/strong&gt;；超长 CoT 解决复杂数独的 &lt;strong&gt;RWKV 数独&lt;/strong&gt;；以及语音多模态应用 &lt;strong&gt;RWKV Talk&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV 数独" src="https://oscimg.oschina.net/oscnet/up-7403589cfd4c77f004366bd59184897e350.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV See" src="https://oscimg.oschina.net/oscnet/up-7164d710aae30a7840955bd661f1b2001d2.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV Talk" src="https://oscimg.oschina.net/oscnet/up-99d0220761f728cfb0db51908d13a2fd81a.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV— 面向未来的高效 AI 大模型架构&lt;/h2&gt; 
&lt;p&gt;感谢每一位在 WAIC 2025 与 RWKV 相遇的朋友。未来，RWKV 期待深度参与社区技术交流与资源整合，携手伙伴共同推动普惠开放的 AI 未来。目前，下一代核心架构 RWKV-8 的研发已在加速筹备中，预计于今年内发布。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8409a5f7ed66ea3012c851458bdf076b2de.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多 RWKV 技术动态、产品进展及社区合作信息，敬请持续关注 RWKV 官方公众号。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363004</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363004</guid>
      <pubDate>Thu, 17 Jul 2025 09:53:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>​Mistral AI 发布人工智能模型环境影响分析</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Mistral AI 对其一款大型语言模型进行了全面的生命周期分析，旨在评估人工智能技术的环境影响。这项研究由 Mistral 与可持续发展咨询公司 Carbone4 及法国生态转型机构共同开展，分析结果还经过了环境咨询公司 Resilio 和 Hubblo 的同行评审。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#000000"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-9d2866802c4667241df914db00df7739dfa.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;该分析主要聚焦于 Mistral AI Large2 模型的整个生命周期，评估了其在温室气体排放、水资源使用和材料消耗等三个关键领域的影响。研究发现，人工智能模型的训练和推理阶段是环境影响最大的环节，Mistral 表示，该模型 85.5% 的温室气体排放和 91% 的水消耗都发生在模型的开发和用户交互过程中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;截至 2025 年 1 月，Mistral 的 Large2 模型在运行 18 个月后已产生 20.4 千吨的二氧化碳排放量，并消耗了 28.1 万立方米的水资源。研究还估算了推理的边际影响，通过用户与 「Le Chat」 聊天机器人进行 400 个令牌的交互，预计每次交互会产生约 1.14 克的二氧化碳排放和 45 毫升的水消耗。这些数据表明，单次查询的环境影响虽然微小，但在数百万乃至数十亿用户长期交互下，整体的环境挑战是不可忽视的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Mistral 也承认其研究存在一些局限性，特别是在准确量化大型语言模型工作负载对 GPU 和数据中心基础设施造成的硬件性能下降方面。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;尽管如此，该报告中的数据与其他机构对人工智能环境影响的评估基本一致。Mistral 表示，未来将更新环境报告，呼吁整个人工智能行业提升透明度，致力于实现全球气候目标。公司指出，目前的一些政策与这些目标存在背道而驰的现象。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362993</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362993</guid>
      <pubDate>Thu, 17 Jul 2025 09:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>opencode —— 为终端打造的 AI 编码代理</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;a href="https://opencode.ai/"&gt;opencode&lt;/a&gt;&amp;nbsp;是为终端打造的 AI 编码代理。&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;&lt;strong&gt;原生 TUI&lt;/strong&gt;：响应迅速、原生、可主题化的终端 UI。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSP 已启用&lt;/strong&gt;：自动为 LLM 加载正确的 LSP。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多会话&lt;/strong&gt;：在同一个项目上并行启动多个代理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可共享链接&lt;/strong&gt;：共享任何会话的链接以供参考或调试。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Claude Pro&lt;/strong&gt;：通过 Anthropic 登录以使用你的 Claude Pro 或 Max 帐户。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用任何模型：通过&lt;/strong&gt;&lt;a href="https://models.dev/"&gt;Models.dev&lt;/a&gt;支持 75 多个 LLM 提供商，包括本地模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="366" src="https://static.oschina.net/uploads/space/2025/0725/145221_a1Fv_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/opencode</link>
      <guid isPermaLink="false">https://www.oschina.net/p/opencode</guid>
      <pubDate>Thu, 17 Jul 2025 08:59:00 GMT</pubDate>
    </item>
    <item>
      <title>统信 Windows 应用兼容引擎官网上线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;统信 Windows 应用兼容引擎官网已于近日正式上线，「&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#3f3f3f"&gt;标志着兼容技术从工具迭代迈向生态共建的新阶段&lt;/span&gt;&lt;span style="color:#000000"&gt;」。官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLicvwV1XgGFgG_GKdHzImw" target="_blank"&gt;发文&lt;/a&gt;详细介绍了统信 Windows 应用兼容引擎的演进历程、核心功能与生态共建新起点。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;前期探索&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;wine 助手与 UOS 应用迁移助手&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2014 年，deepin-wine 团队以「让 Linux 系统流畅运行 Windows 应用」为目标，持续向 wine 上游社区提交 200 余个补丁，十余年间团队从技术验证走向产品化，产品也在不断升级演进。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;2021 年：首次尝试 wine 技术应用化&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2021 年，团队首次尝试将 wine 技术应用化，推出了「wine 助手」，实现了在 deepin 上双击直接安装运行 Windows exe 程序，让普通用户无需复杂操作即可使用 Windows 应用，大幅降低了 wine 技术的使用门槛。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="248" src="https://oscimg.oschina.net/oscnet/up-29ad2fa7bd2709449d99883d318532ea5b0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;2024 年：UOS 应用迁移助手聚焦专业场景&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年，推出与 wine 助手定位差异化的「UOS 应用迁移助手」，聚焦更多专业场景，主打将 exe 程序打包为 deb 包，支持绿色软件打包、ARM 架构运行等特性，满足运维人员、技术工程师及应用开发者的专业需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-59821dc6d3b3bc43207d6072947b4234f52.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;统信 Windows 应用兼容引擎&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;功能升级与定位革新&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 11 月，UOS 应用迁移助手正式更名为「统信 Windows 应用兼容引擎」，并于 12 月迭代至 V3.0.4 版本，实现功能与定位的双重升级：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;软件功能重构&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从「打包工具」转向「全场景兼容引擎」，支持直接双击运行 Windows exe 程序；打包功能整合至应用管理菜单，成为兼容成功后的延伸能力，优先保障 wine 应用的运行成功率。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;覆盖多元用户需求&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向普通用户提供「一键运行」便利，为技术发烧友、软件厂商提供图形化迁移工具，助力 Windows 程序快速适配 deepin 与统信 UOS，满足多架构、多场景的生态需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="335" src="https://oscimg.oschina.net/oscnet/up-c8e50fba3fe4eed53c9ee23e7fae68c4f86.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年，统信 Windows 应用兼容引擎持续迭代，现已更新至 V3.3.1 版本，进一步提升技术实力与生态覆盖。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Proton 支持与架构适配&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;3&amp;nbsp;月成功适配 Proton 技术，支持在 deepin 25 中选择「ge-proton」版本运行游戏，大幅提升游戏运行成功率与性能；新增与 Steam 版本对齐的稳定版 Proton，增加对 wow64 的支持，实现纯 64 位系统运行多数 32 位游戏。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="269" src="https://oscimg.oschina.net/oscnet/up-93effbf36f9e47fd70fbe255d4b322344ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;应用清单与版本标准化&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;5 月 V3.3.0 版本新增 「全部应用」 模块，整合 deepin-wine 团队验证通过的可兼容应用清单，为用户提供清晰的适配参考；默认 wine 版本升级为 deepin-wine10-stable，统一容器运行标准，减少适配冲突。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="382" src="https://oscimg.oschina.net/oscnet/up-6024ea1bea8099cb9b6ab2da98e7a666c43.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;wine 应用内存占用下降 90%&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;6 月 V3.3.1 版本&lt;/strong&gt;解决了 wine 应用在 Linux 下的内存开销过大问题，针对 64 位 Electron 框架的应用优化最为明显，实测可以减少 90% 内存开销，趋近于其在原生 Windows 平台上的实际使用量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-b95aae66980222fd322f3775f265b8b3b1a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;官网上线&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;打造协同共建新平台&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;统信 Windows 应用兼容引擎官网地址：&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#3f3f3f"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwine.deepin.org%2F" target="_blank"&gt;https://wine.deepin.org/&lt;/a&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;提供详细使用教程、开发文档与论坛交流入口等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-030f9331200776bda96ead8151501f87a9d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362978</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362978</guid>
      <pubDate>Thu, 17 Jul 2025 08:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包 App 视觉推理能力升级，图片分析支持深度思考</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;豆包 App 在视觉推理领域迎来重大升级，其图片分析功能现已支持深度思考模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;用户只需在深度思考模式下拍摄或上传一张图片，豆包便能迅速对图片进行放大、裁剪等精细处理，并支持图片搜索功能，实现边想边搜，从而进一步提升搜索结果的准确性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-0abd984fd925aba9f9e2f8f34b62cce318d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在图片分析过程中，豆包展现出强大的信息处理能力。它能够根据图片中的细节信息，对比历史档案，检索出相似图片，并梳理出图片的演变脉络。通过这一系列操作，豆包能够最终确定图片的年代范围，为用户提供更为精准的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，豆包还能对图片进行深入分析，根据地形景观、建筑风格以及窗户细节等特征，对照地理和人文特征进行综合判断。经过这一系列复杂的分析过程，豆包能够准确确定图片所展示的具体方位，甚至最终确定城市名称，为用户提供更加全面、准确的图片解读服务。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362977</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362977</guid>
      <pubDate>Thu, 17 Jul 2025 07:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁 inclusionAI 团队发布 Ming-lite-omni v1.5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁集团 inclusionAI 团队发布了全面升级版的全模态模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finclusionai.github.io%2Fzh%2Fblog%2Fming-lite-omni-1_5%2F" target="_blank"&gt;&lt;strong&gt;Ming-Lite-Omni v1.5&lt;/strong&gt;&lt;/a&gt;，基于 &lt;strong&gt;Ling-lite-1.5&lt;/strong&gt; 构建，总参数量为 &lt;strong&gt;203 亿&lt;/strong&gt;（其中 MoE 部分活跃参数为 &lt;strong&gt;30 亿&lt;/strong&gt;），在图像-文本理解、文档理解、视频理解、语音理解与合成、图像生成与编辑等全模态能力上显著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95012b461af8180f5480bac2f4c85b95949.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ming-lite-omni v1.5 模型架构如下，主题参考了 Ming-lite-omni v1 版本的结构，区别在于为了增强图像编辑人物和场景一致性，升级 Vision head 支持参考图特征输入。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6c48bdf68ea2bcdfc0e8deb440f605297fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;关键优化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;增强视频理解&lt;/strong&gt;：通过 &lt;strong&gt;MRoPE 3D 时空编码&lt;/strong&gt; 和针对长视频的 &lt;strong&gt;课程学习策略&lt;/strong&gt;，显著提升对复杂视觉序列的理解能力 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优化多模态生成&lt;/strong&gt;：采用双分支图像生成（ID 与场景一致性损失）和新的音频解码器及 BPE 编码，提升生成一致性与感知控制，实现高质量实时语音合成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据全面升级&lt;/strong&gt;：新增结构化文本数据、高质量产品信息及包括方言（如普通话、粤语、四川话等）在内的精细化视觉与语音感知数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;性能表现&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 &lt;strong&gt;MMVet&lt;/strong&gt;、&lt;strong&gt;MathVista&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt; 等数据集上表现突出，文档理解任务（如 &lt;strong&gt;ChartQA&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt;）取得 10B 以下参数模型中的 &lt;strong&gt;SOTA&lt;/strong&gt; 成绩。&lt;/li&gt; 
 &lt;li&gt;视频理解、语音理解与生成（支持多种方言）及图像生成（保持人物 ID 一致性编辑）均处于行业领先地位。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该模型已在 &lt;strong&gt;Hugging Face&lt;/strong&gt; 和 &lt;strong&gt;ModelScope&lt;/strong&gt; 上开放下载，并提供详细安装指南、代码示例和 &lt;strong&gt;Gradio&lt;/strong&gt; 演示。&lt;/p&gt; 
&lt;p&gt;Hugging Face: https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5&lt;br&gt; ModelScope: https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362971</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362971</guid>
      <pubDate>Thu, 17 Jul 2025 07:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>eBPF 助力 NAS 分钟级别 Pod 实例溯源</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;云存储 NAS 产品是一个可共享访问、弹性扩展、高可靠、高性能的分布式文件系统。 NAS 兼容了 POSIX 文件接口，可支持数千台计算节点共享访问，可挂载到弹性计算 ECS、容器实例等计算业务上，提供高性能的共享存储服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;鉴于多主机间共享的便利性和高性能， NAS 在得物的算法训练、应用构建等场景中均成为了基础支撑。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/36/36274710c18533ce5fc246ee82e640c2.jpeg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在多业务共享的场景中，单个业务流量异常容易引发全局故障。目前，异常发生后需依赖&lt;strong&gt;云服务厂商 NAS &lt;/strong&gt;的溯源能力，&lt;strong&gt;但只能定位到主机级别，无法识别具体异常服务&lt;/strong&gt;。要定位到服务级别，仍需依赖所有使用方协同排查，并由 SRE 多轮统计分析，&lt;strong&gt;效率低下&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6a6a6a"&gt;（若服务实例发生迁移或重建，排查难度进一步增加）&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;为避免因 NAS 异常或带宽占满导致模型训练任务受阻&lt;/strong&gt;，因此需构建支持服务级流量监控、快速溯源及 NAS 异常实时感知的能力，以提升问题定位效率并减少业务中断。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、流量溯源方案调研和验证&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;NAS 工作原理&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 本地挂载原理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux 平台上，NAS 的产品底层是基于标准网络文件系统 NFS（Network File System），通过将远端文件系统挂载到本地，实现用户对远端文件的透明访问。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NFS 协议（主要支持 NFS v3 和 v4，通常以 v3 为主）允许将远端服务挂载到本地，使用户能够像访问本地文件目录一样操作远端文件。文件访问请求通过 RPC 协议发送到远端进行处理，其整体流程如下：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="465" src="https://oscimg.oschina.net/oscnet/up-3f3abf4fce2a08639688cf370284cf62cdd.png" width="620" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;文件系统访问时的数据流向示意&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="552" src="https://oscimg.oschina.net/oscnet/up-a5b7a533fbca51c726053b4598e79c9786f.jpg" width="507" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;Linux 内核中 NFS 文件系统&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NFS 文件系统读/写流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux NFS 文件系统的实现中，文件操作接口由 nfs_file_operations 结构体定义，其读取操作对应的函数为:&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;//NFS 文件系统的 VFS 层实现的函数如下所示：
const&amp;nbsp;struct&amp;nbsp;file_operations nfs_file_operations = {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .llseek &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_llseek,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .read_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;= nfs_file_read,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .write_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_write,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
};&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;针对 NFS 文件系统的读操作涉及到 2 个阶段（写流程类似，只是函数名字有所差异，本文仅以读取为例介绍）。由于文件读取涉及到网络操作因此这两个阶段涉及为异步操作：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 两个阶段&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;读取请求阶段：&lt;/strong&gt;当应用程序针对 NFS 文件系统发起 read() 读操作时，内核会在 VFS 层调用 nfs_file_read 函数，然后调用 NFS 层的 nfs_initiate_read 函数，通过 RPC 的 rpc_task_begin 函数将读请求发送到 NFS Server，至此向 NFS Server 发起的请求工作完成。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;读响应阶段：&lt;/strong&gt;在 NFS Server 返回消息后，会调用 rpc_task_end 和 nfs_page_read_done 等函数，将数据返回到用户空间的应用程序。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="415" src="https://oscimg.oschina.net/oscnet/up-fd2c800299c65096f8d6eba7de108c0581f.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在了解 NFS 文件系统的读流程后，我们回顾一下 NFS Server 为什么无法区分单机访问的容器实例或进程实例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;这是因为 NFS 文件系统的读写操作是在内核空间实现的。当容器 A/B 和主机上的进程 C 发起读请求时，这些请求在进入内核空间后，统一使用主机 IP（如 192.168.1.2）作为客户端 IP 地址。因此，NFS Server 端的统计信息只能定位到主机维度，无法进一步区分主机内具体的容器或进程。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-91366119d285327518f226735b34227dddd.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;内核空间实现示意&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;方案调研和验证&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;进程对应容器上下文信息关联&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;内核中进程以 PID 作为唯一编号，与此同时，内核会建立一个 struct task_struct 对象与之关联，在 struct task_struct 结构会保存进程对应的上下文信息。如实现 PID 信息与用户空间容器上下文的对应（进程 PID 1000 的进程属于哪个 Pod 哪个 Container 容器实例），我们需基于内核 task_struct 结构获取到容器相关的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过分析内核代码和资料确认，发现可以通过 task_struct 结构中对应的 cgroup 信息获取到进程对应的 cgroup_name 的信息，而该信息中包含了容器 ID 信息，例如&lt;strong&gt; docker-2b3b0ba12e92...983.scope &lt;/strong&gt;，完整路径较长，使用 .... 省略。基于容器 ID 信息，我们可进一步管理到进程所归属的 Pod 信息，如 Pod NameSpace 、 Pod Name 、 Container Name 等元信息，最终完成进程 PID 与容器上下文信息元数据关联。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;struct&amp;nbsp;task_struct&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;css_set&amp;nbsp;__rcu &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;*cgroups;
}


struct&amp;nbsp;css_set&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;*subsys[CGROUP_SUBSYS_COUNT];
}


struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup&amp;nbsp;*cgroup;
}


struct&amp;nbsp;cgroup&amp;nbsp;{
&amp;nbsp;&amp;nbsp;struct&amp;nbsp;kernfs_node&amp;nbsp;*kn; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;/* cgroup kernfs entry */
}


struct&amp;nbsp;kernfs_node&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; *name; &amp;nbsp;// docker-2b3b0ba12e92...983.scope
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以某容器进程为例，该进程在 Docker 容器环境中的 cgroup 路径完整为 /sys/fs/cgroup/cpu/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podefeb3229_4ecb_413a_8715_5300a427db26.slice/docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;经验证，我们在内核中读取 task-&amp;gt;cgroups-&amp;gt;subsys[0]-&amp;gt;kn-&amp;gt;name 的值为 docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/92/92735ea140e6e0021584e2c7cc21b0b4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;其中容器 ID 字段为 docker- 与 .scope 间的字段信息，在 Docker 环境中一般取前 12 个字符作为短 ID，如 2b3b0ba12e92 ，可通过 docker 命令进行验证，结果如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;docker&amp;nbsp;ps -a|grep&amp;nbsp;2b3b0ba
2b3b0ba12e92&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; registry-cn-hangzhou-vpc.ack.aliyuncs.com/acs/pause:3.5&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 上下文信息关联&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NAS 产品的访问通过挂载命令完成本地文件路径的挂载。我们可以通过 mount 命令将 NAS 手工挂载到本地文件系统中。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;mount&amp;nbsp;-t nfs -o vers=3,nolock,proto=tcp,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport \
&amp;nbsp;&amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test /mnt/nas&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;执行上述挂载命令成功后，通过 mount 命令则可查询到类似的挂载记录：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;5368 47 0:660 / /mnt/nas rw,relatime shared:1175 \
&amp;nbsp; &amp;nbsp; &amp;nbsp;- nfs 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test \ &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp;rw,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,nolock,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;noresvport,proto=tcp,timeo=600,retrans=2,sec=sys, \
&amp;nbsp; &amp;nbsp; &amp;nbsp;mountaddr=192.168.0.91,mountvers=3,mountport=2049,mountproto=tcp,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;local_lock=all,addr=192.168.0.92&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;核心信息分析如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# 挂载点，父挂载点，挂载设备号 &amp;nbsp; 目录 &amp;nbsp; &amp;nbsp; 挂载到本机目录 &amp;nbsp;协议 &amp;nbsp; NAS 地址
5368&amp;nbsp; &amp;nbsp; &amp;nbsp;47&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0:660&amp;nbsp; &amp;nbsp; &amp;nbsp;/ &amp;nbsp; &amp;nbsp; &amp;nbsp; /mnt/nas &amp;nbsp; &amp;nbsp; nfs &amp;nbsp; &amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;maror:minor&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;挂载记录中的&lt;/span&gt;&lt;span style="color:#d92142"&gt;&lt;strong&gt; 0:660 &lt;/strong&gt;&lt;/span&gt;为本地设备编号，格式为 major:minor ， 0 为 major 编号， 660 为 minor 编号，系统主要以 minor 为主。在系统的 NFS 跟踪点 nfs_initiate_read 的信息中的 dev 字段则为在挂载记录中的 minor 编号。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;cat /sys/kernel/debug/tracing/events/nfs/nfs_initiate_read/format
format:
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:dev_t dev; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:8; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:u32 count; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:32; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过用户空间 mount 信息和跟踪点中 dev_id 信息，则可实现内核空间设备编号与 NAS 详情的关联。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;内核空间信息获取&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如容器中进程针对挂载到本地的目录 /mnt/nas 下的文件读取时，会调用到 nfs_file_read() 和 nfs_initiate_read 函数。通过 nfs_initiate_read 跟踪点我们可以实现进程容器信息和访问 NFS 服务器的信息关联。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过编写 eBPF 程序针对跟踪点 tracepoint/nfs/nfs_initiate_read 触发事件进行数据获取，我们可获取到访问进程所对应的 cgroup_name 信息和访问 NFS Server 在本机的设备 dev_id 编号。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="673" src="https://oscimg.oschina.net/oscnet/up-b7e2eac3eeba85b51ed94f7a84d28a096ea.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;获取 cgroup_name 信息&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;进程容器上下文获取：&lt;/strong&gt; 通过 cgroup_name 信息，如样例中的 docker-2b3b0ba12e92...983.scope ，后续可以基于 container_id 查询到容器对应的 Pod NameSpace 、 Pod Name 和 Container Name 等信息，从而定位到访问进程关联的 Pod 信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;NAS 上下文信息获取：&lt;/strong&gt; 通过 dev 信息，样例中的 660 ，通过挂载到本地的记录，可以通过 660 查询到对应的 NAS 产品的地址，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com 。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;用户空间元信息缓存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/aa/aa252b079e6ce3cb1e52e02ab5b4052a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在用户空间中，可以通过解析挂载记录来获取 DEV 信息，并将其与 NAS 信息关联，从而建立以 DevID 为索引的查询缓存。如此，后续便可以基于内核获取到 dev_id 进行关联，进一步补全 NAS 地址及相关详细信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;对于本地容器上下文的信息获取，最直接的方式是通过 K8s kube-apiserver 通过 list-watch 方法进行访问。然而，这种方式会在每个节点上启动一个客户端与 kube-apiserver 通信，显著增加 K8s 管控面的负担。因此，我们选择通过本地容器引擎进行访问，直接在本地获取主机的容器详情。通过解析容器注解中的 Pod 信息，可以建立容器实例缓存。后续在处理指标数据时，则可以通过 container-id 实现信息的关联与补全。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;三、架构设计和实现&lt;/h1&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;整体架构设计&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;内核空间的信息采集采用 Linux eBPF 技术实现，这是一种安全且高效的内核数据采集方式。简单来说，eBPF 的原理是在内核中基于事件运行用户自定义程序，并通过内置的 map 和 perf 等机制实现用户空间与内核空间之间的双向数据交换。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NFS 和 RPC 调用事件触发的基础上，可以通过编写内核空间的 eBPF 程序来获取必要的原始信息。当用户空间程序搜集到内核指标数据后，会对这些原始信息进行二次处理，并在用户空间的采集程序中补充容器进程信息（如 NameSpace、Pod 和 Container 名称）以及 NFS 地址信息（包括 NFS 远端地址）。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/c6/c687b3f4df8a2ce5d0ab5cd9f287dfd4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;内核 eBPF 程序流程&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 NFS 文件读为例，通过编写 eBPF 程序跟踪 nfs_initiate_read / rpc_task_begin / rpc_task_end / nfs_page_read_done 等关键链路上的函数，用于获取到 NFS 读取的数据量和延时数据，并将访问链路中的进程上下文等信息保存到内核中的指标缓存中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="471" src="https://oscimg.oschina.net/oscnet/up-f854a1a8cdf429eff044e715772dc96dfb6.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如上图所示， nfs_initate_read 和 rpc_task_begin 发生在同一进程上下文中，而 rpc_task_begin 与 rpc_task_end 是异步操作，尽管两者不处于同一进程上下文，但可以通过 task_id 进行关联。同时， page_read_done 和 rpc_task_end 则发生在同一进程上下文中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="627" src="https://oscimg.oschina.net/oscnet/up-70f989400d6710f021cfa7577375a709030.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;nfs_initiate_read 函数调用触发的 eBPF 代码示例如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;

SEC("tracepoint/nfs/nfs_initiate_read")
int&amp;nbsp;tp_nfs_init_read(struct&amp;nbsp;trace_event_raw_nfs_initiate_read *ctx)
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步骤 1 获取到 nfs 访问的设备号信息，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com
&amp;nbsp; &amp;nbsp;&amp;nbsp;// dev_id 则为： 660&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;dev_t&amp;nbsp;dev_id =&amp;nbsp;BPF_CORE_READ(ctx, dev);
&amp;nbsp; &amp;nbsp; u64 file_id =&amp;nbsp;BPF_CORE_READ(ctx, fileid);
&amp;nbsp; &amp;nbsp; u32 count =&amp;nbsp;BPF_CORE_READ(ctx, count);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;task_struct&amp;nbsp;*task = (struct&amp;nbsp;task_struct *)bpf_get_current_task();


&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步骤 2 获取进程上下文所在的容器 cgroup_name 信息
&amp;nbsp; &amp;nbsp;&amp;nbsp;// docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp;*cname =&amp;nbsp;BPF_CORE_READ(task, cgroups, subsys[0], cgroup, kn, name);
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(cname)
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_core_read_str(&amp;amp;info.container, MAX_PATH_LEN, cname);
&amp;nbsp; &amp;nbsp; }


&amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_map_update_elem(&amp;amp;link_begin, &amp;amp;tid, &amp;amp;info, BPF_ANY);
}


SEC("tracepoint/nfs/nfs_readpage_done")
int&amp;nbsp;tp_nfs_read_done(struct&amp;nbsp;trace_event_raw_nfs_readpage_done *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_begin")
int&amp;nbsp;tp_rpc_task_begin(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;&amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_end")
int&amp;nbsp;tp_rpc_task_done(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;用户空间程序架构&lt;/span&gt;&lt;/h2&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b9cf6d19b68dcceaa9f6f459645264baaa8.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;元数据缓存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ NAS 挂载信息缓存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过解析挂载记录，可以获取 DEV 信息与 NAS 信息的关联关系。以下是实现该功能的关键代码详情：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;scanner := bufio.NewScanner(mountInfoFile)
count :=&amp;nbsp;0
for&amp;nbsp;scanner.Scan() {
&amp;nbsp; &amp;nbsp; line := scanner.Text()
&amp;nbsp; &amp;nbsp; devID,remoteDir, localDir, NASAddr = parseMountInfo(line)


&amp;nbsp; &amp;nbsp; mountInfo := MountInfo{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;DevID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; devID,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;RemoteDir: &amp;nbsp; &amp;nbsp; remoteDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;LocalMountDir: localDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NASAddr： NASAddr,
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; mountInfos =&amp;nbsp;append(mountInfos, mountInfo)

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 容器元信息缓存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过 Docker 或 Containerd 客户端，从本地读取单机的容器实例信息，并将容器的上下文数据保存到本地缓存中，以便后续查询使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;podInfo := PodInfo{
&amp;nbsp; &amp;nbsp; NameSpace: &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.namespace"],
&amp;nbsp; &amp;nbsp; PodName: &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.name"],
&amp;nbsp; &amp;nbsp; ContainerName: labels["io.kubernetes.container.name"],
&amp;nbsp; &amp;nbsp; UID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.uid"],
&amp;nbsp; &amp;nbsp; ContainerID: &amp;nbsp; conShortID,
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据处置流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;用户空间程序的主要任务是持续读取内核 eBPF 程序生成的指标数据，并对读取到的原始数据进行处理，提取访问设备的 dev_id 和 container_id 。随后，通过查询已建立的元数据缓存，分别获取 NAS 信息和容器 Pod 的上下文数据。最终，经过数据合并与处理，生成指标数据缓存供后续使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;func&amp;nbsp;(m *BPFEventMgr)&amp;nbsp;ProcessIOMetric() {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; events := m.ioMetricMap
&amp;nbsp; &amp;nbsp; iter := events.Iterate()


&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;iter.Next(&amp;amp;nextKey, &amp;amp;event) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ① 读取到的 dev_id 转化为对应的完整 NAS 信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;devId := nextKey.DevId
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;mountInfo, ok := m.mountMgr.Find(int(devId))


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ② 读取 containerID 格式化并查询对应的 Pod 上下文信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;containerId := getContainerID(nextKey.Container)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;podInfo, ok = m.criMgr.Find(containerId)
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ③ 基于事件信息、NAS 挂载信息和 Pod 上下文信息，生成指标数据缓存&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;metricKey, metricValue := formatMetricData(nextKey， mountInfo, podInfo)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;value, loaded := metricCache.LoadOrStore(metricKey, metricValue)
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ④ 指标数据缓存，生成最终的 Metrics 指标并更新&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;var&amp;nbsp;ioMetrics []metric.Counter
&amp;nbsp; &amp;nbsp; metricCache.Range(func(key, value&amp;nbsp;interface{})&amp;nbsp;bool&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;k := key.(metric.IOKey)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;v := value.(metric.IOValue)


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ioMetrics =&amp;nbsp;append(ioMetrics, metric.Counter{"read_count",&amp;nbsp;float64(v.ReadCount),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[]string{k.NfsServer, v.NameSpace, v.Pod, v.Container})
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&amp;nbsp;true
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; m.metricMgr.UpdateIOStat(ioMetrics)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;启动 Goroutine 处理指标数据：通过启动一个 Goroutine，循环读取内核存储的指标数据，并对数据进行处理和信息补齐，最终生成符合导出格式的 Metrics 指标。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 具体步骤&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;获取 NAS 信息：&lt;/strong&gt;从读取的原始数据中提取 dev_id ，并通过 dev_id 查询挂载的 NAS 信息，例如远端访问地址等相关数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;查询 Pod 上下文：&lt;/strong&gt;对 containerID 进行格式化处理，并查询对应的容器 Pod 上下文信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成指标数据缓存：&lt;/strong&gt;基于事件数据、NAS 挂载信息和 Pod 上下文信息，生成指标数据缓存。此过程主要包括对相同容器上下文的数据进行合并和累加。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;导出 Metrics 指标：&lt;/strong&gt;根据指标数据缓存，生成最终的 Metrics 指标，并更新到指标管理器。随后，通过自定义的 Collector 接口对外导出数据。当 Prometheus 拉取数据时，指标会被转换为最终的 Metrics 格式。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过上述步骤，用户空间能够高效地处理内核 eBPF 程序生成的原始数据，并结合 NAS 挂载信息和容器上下文信息，生成符合 Prometheus 标准的 Metrics 指标，为后续的监控和分析提供了可靠的数据基础。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自定义指标导出器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在导出指标的场景中，我们需要基于保存在 Go 语言中的 map 结构中的动态数据实时生成，因此需要实现自定义的 Collector 接口。自定义 Collector 接口需要实现元数据描述函数 Describe() 和指标搜集的函数 Collect() ，其中 Collect() 函数可以并发拉取，因此需要通过加锁实现线程安全。该接口需要实现以下两个核心函数：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Describe() ：用于定义指标的元数据描述，向 Prometheus 注册指标的基本信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Collect() ：用于搜集指标数据，该函数支持并发拉取，因此需要通过加锁机制确保线程安全。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;type&amp;nbsp;Collector&amp;nbsp;interface&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 指标的定义描述符
&amp;nbsp; &amp;nbsp; Describe(chan&amp;lt;- *Desc)
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 并将收集的数据传递到 Channel 中返回
&amp;nbsp; &amp;nbsp; Collect(chan&amp;lt;- Metric)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;我们在指标管理器中实现 Collector 接口， 部分实现代码，如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;nfsIOMetric := prometheus.NewDesc(
&amp;nbsp; &amp;nbsp; prometheus.BuildFQName(prometheusNamespace,&amp;nbsp;"",&amp;nbsp;"io_metric"),
&amp;nbsp; &amp;nbsp;&amp;nbsp;"nfs io metrics by cgroup",
&amp;nbsp; &amp;nbsp; []string{"nfs_server",&amp;nbsp;"ns",&amp;nbsp;"pod",&amp;nbsp;"container",&amp;nbsp;"op",&amp;nbsp;"type"},
&amp;nbsp; &amp;nbsp;&amp;nbsp;nil,
)


// Describe and Collect implement prometheus collect interface
func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Describe(ch&amp;nbsp;chan&amp;lt;- *prometheus.Desc) {
&amp;nbsp; &amp;nbsp; ch &amp;lt;- m.nfsIOMetric
}


func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Collect(ch&amp;nbsp;chan&amp;lt;- prometheus.Metric) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// Note：加锁保障线程并发安全
&amp;nbsp; &amp;nbsp; m.activeMutex.Lock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;defer&amp;nbsp;m.activeMutex.Unlock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;_, v :=&amp;nbsp;range&amp;nbsp;m.ioMetricCounters {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ch &amp;lt;- prometheus.MustNewConstMetric(m.nfsIOMetric, prometheus.GaugeValue, v.Count, v.Labels...)
&amp;nbsp; &amp;nbsp; }

&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;四、总结&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;当前 NAS 溯源能力已正式上线，以下是主要功能和视图介绍：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 单 NAS 实例整体趋势&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;支持基于环境和 NAS 访问地址过滤，展示 NAS 产品的读写 IOPS 和吞吐趋势图。同时，基于内核空间统计的延时数据，提供 P95 读写延时指标，用于判断读写延时情况，辅助问题分析和定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/14/14577d6fe8b2876ca7f5138680fc3667.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/9c/9c091aeaecc284956b851416de5d313a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NAS 流量溯源方面，我们结合业务场景设计了基于任务和 Pod 实例维度的流量分析视图：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 任务维度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过聚合具有共同属性的一组 Pod 实例，展示任务级别的整体流量情况。该视图支持快速定位任务级别的流量分布，帮助用户进行流量溯源和多任务错峰使用的依据。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/0a/0a504606b05345b52061d2f754c15b51.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Pod 实例维度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 Pod 为单位进行流量分析和汇总，提供 Pod NameSpace 和 Name 信息，支持快速定位和分析实例级别的流量趋势，帮助细粒度监控和异常流量的精准定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/90/90765c51493906beaf530c64494abc6a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在整体能力建设完成后，我们成功构建了 NAS 实例级别的 IOPS、吞吐和读写延时数据监控大盘。通过该能力，进一步实现了 NAS 实例的 IOPS 和吞吐可以快速溯源到任务级别和 Pod 实例级别，流量溯源时效从小时级别缩短至分钟级别，有效提升了异常问题定位与解决的效率。同时，基于任务流量视图，我们为后续带宽错峰复用提供了直观的数据支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;1.&lt;/span&gt;正品库拍照 PWA 应用的实现与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;2.&lt;/span&gt;汇金资损防控体系建设及实践 | 得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;3.&lt;/span&gt;一致性框架：供应链分布式事务问题解决方案｜得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;4.&lt;/span&gt;得物社区活动：组件化的演进与实践&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;5.&lt;/span&gt;从 CPU 冒烟到丝滑体验：算法 SRE 性能优化实战全揭秘｜得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;文 / 泊明&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;关注得物技术，每周更新技术干货&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18683994</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18683994</guid>
      <pubDate>Thu, 17 Jul 2025 07:35:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>英伟达开源 Llama-3.3-Nemotron-Super-49B-v1.5 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;英伟达发布了 Llama-3.3-Nemotron-Super-49B-v1.5，这是一款专为推理和 Agentic 任务优化的开源模型，在单个 H100 GPU 上实现高吞吐量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1eb8efcbf4188aaa81c53fbda0c23259d86.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型介绍&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Llama Nemotron Super v1.5 是 Llama-3.3-Nemotron-Super-49B-V1.5 的简称。它是 Llama-3.3-Nemotron-Super-49B-V1 的升级版本（该模型是 Meta 的 Llama-3.3-70B-Instruct 的衍生模型），专为复杂推理和智能体任务设计，支持 128K tokens 的上下文长度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型架构&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Llama Nemotron Super v1.5 采用神经架构搜索（Neural Architecture Search，NAS），使该模型在准确率和效率之间实现了良好的平衡，将吞吐量的提升有效转化为更低的运行成本。&lt;/p&gt; 
&lt;p&gt;（注：NAS 的目标是通过搜索算法从大量的可能架构中找到最优的神经网络结构，利用自动化方法替代人工设计神经网络架构，从而提高模型的性能和效率。）&lt;/p&gt; 
&lt;p&gt;模型经过了多阶段后训练，包括针对数学、代码、科学和工具调用的监督微调 (SFT)，以及用于聊天对齐的奖励感知偏好优化 (RPO)、用于推理的带可验证奖励的强化学习 (RLVR) 和用于工具调用能力增强的迭代直接偏好优化 (DPO)。&lt;/p&gt; 
&lt;p&gt;在多个基准测试中，该模型表现出色。例如，在 MATH500 上 pass@1 达到 97.4，在 AIME 2024 上达到 87.5，在 GPQA 上达到 71.97。模型支持 Reasoning On/Off 模式，用户可通过在系统提示中设置 /no_think 来关闭推理模式。官方推荐在推理开启时使用 temperature=0.6 和 Top P=0.95，在关闭时使用贪心解码。&lt;/p&gt; 
&lt;p&gt;该模型已准备好用于商业用途，遵循 NVIDIA Open Model License 和 Llama 3.3 社区许可协议。开发者可以通过 NVIDIA build.nvidia.com 或 Hugging Face 下载和试用该模型，并可使用 vLLM（推荐 v0.9.2）进行部署，官方仓库中提供了支持工具调用的解析器插件。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362966</guid>
      <pubDate>Thu, 17 Jul 2025 07:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Julius AI 完成 1000 万美元种子轮融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自称为「AI 数据分析师」的初创公司 Julius AI 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjulius.ai%2Farticles%2Ffunding-announcement" target="_blank"&gt;宣布&lt;/a&gt;，已成功完成 1000 万美元种子轮融资，本轮融资由知名风投机构 Bessemer Venture Partners 领投。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此轮融资吸引了众多知名投资者参与，包括 Horizon VC、8VC、Y Combinator、AI Grant 加速器，以及 Perplexity 首席执行官 Aravind Srinivas、Vercel 首席执行官 Guillermo Rauch 和 Twilio 联合创始人 Jeff Lawson 等多位知名天使投资人。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="265" src="https://oscimg.oschina.net/oscnet/up-fa76ef8ea19caf7593f5d21fe0c268005aa.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Julius AI 由创始人 Rahul Sonwalkar 于 2022 年从 Y Combinator 毕业后创立。Sonwalkar 在加速器期间曾创立一家物流初创公司，但最终选择放弃并全身心投入到 Julius AI 的开发中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Julius AI 旨在像数据科学家一样，通过分析和可视化海量数据集，并根据自然语言提示进行预测建模。尽管其功能与 ChatGPT、Anthropic 的 Claude 和谷歌的 Gemini 等基础模型公司有所类似，但 Julius AI 成功开辟了自己的市场。公司透露，目前已拥有超过 200 万用户，并生成了超过 1000 万份可视化作品。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Rahul Sonwalkar 在接受 TechCrunch 采访时表示：「使用 Julius 最简单的方法就是跟它对话。你可以像跟团队分析师对话一样跟 AI 对话，然后 AI 会像人类一样，为你运行代码并进行分析。」&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;去年，Julius 在数据科学领域的专业能力甚至引起了哈佛商学院 （HBS） 教授 Iavor Bojinov 的关注。Bojinov 对 Julius 印象深刻，并邀请 Sonwalkar 专门修改其设计，以适应哈佛商学院的新必修课程——「领导者的数据科学与人工智能」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362957</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362957</guid>
      <pubDate>Thu, 17 Jul 2025 07:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 出现大范围服务中断：目前已全部恢复，影响超 8 小时</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;代码托管平台 GitHub 从 2025 年 7 月 28 日 16:50 UTC（北京时间 7 月 29 日 00:50）起突发&lt;strong&gt;大规模服务中断&lt;/strong&gt;，受影响服务包括 Git 操作、API 请求、Pull 请求和 Issues 跟踪等核心功能 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/150643_ZtSu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管 GitHub 工程团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.githubstatus.com%2Fincidents%2Fs6d4x8c6cvv5" target="_blank"&gt;尝试了多种修复措施&lt;/a&gt;（如增设服务器容量、调整限流措施），初期效果不佳，直到北京时间 &lt;strong&gt;7 月 29 日 9:23 左右&lt;/strong&gt; 才取得实质性进展。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1416" src="https://static.oschina.net/uploads/space/2025/0729/150606_wHAe_2720166.png" width="1890" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最终，相关问题已逐步解决，截至目前，API 请求、Pull 请求等服务已全面恢复，整体中断时间超过 &lt;strong&gt;8 小时&lt;/strong&gt;。GitHub 官方表示正在深入调查具体原因，后续将发布详细技术分析报告。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.githubstatus.com/history&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362956</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362956</guid>
      <pubDate>Thu, 17 Jul 2025 07:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中国移动「九天」3.0 发布，多项核心技术同步开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;中国移动发布了其自主研发的 「九天」基础大模型 3.0。根据介绍，「九天众擎语言大模型」实现了架构上的突破性创新，采用可扩展至万亿级的&amp;nbsp;&lt;strong&gt;MoE 架构&lt;/strong&gt;。通过 15T token 的多阶段配比预训练数据与全流程治理体系，其推理能力得到显著强化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该模型还创新构建了 113 域 ×53 能力的二维分级后训练框架，结合动态强化学习策略，使复杂推理能力提升了&amp;nbsp;&lt;strong&gt;35%&lt;/strong&gt;。测评结果显示，「九天」语言大模型：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;GPQA-Diamond&lt;/strong&gt;&amp;nbsp;评测中，以&amp;nbsp;&lt;strong&gt;77.67 分&lt;/strong&gt;斩获全球第二，超越 DeepSeekR1 和 Qwen3。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;ArenaHard V1.0&lt;/strong&gt;&amp;nbsp;中，以&amp;nbsp;&lt;strong&gt;67.2 分&lt;/strong&gt;位居全球第一。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;BFCL V3&lt;/strong&gt;&amp;nbsp;评测中，达到&amp;nbsp;&lt;strong&gt;68 分&lt;/strong&gt;。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在性能大幅跃升的同时，模型进一步强化了可控生成能力，通过精确流程内置等技术细节，实现了专业场景下的&lt;strong&gt;零幻觉&lt;/strong&gt;，破解了沉浸式角色演绎难题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基于最新的语言大模型，中国移动还同步推出了多个专项模型:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;九天代码大模型：&lt;/strong&gt;采用两阶段持续训练技术，支持代码生成、注释生成、单元测试生成、代码智能问答等任务，覆盖 Python、Java、JS、TS、Go、C++ 等 10 余种主流编程语言。在 EvalPlus、MHPP、LivecodeBenchv6 等多个代码生成榜单上表现领先。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;九天数学大模型：&lt;/strong&gt;在短思考、长思考模式下均达到业界 SOTA 水平，多项指标超越 Qwen2.5Math、Qwen3、DeepSeek Math、DeepSeek R1-Distill 等同参数量级模型。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「九天善智多模态大模型」引入复杂时空建模、流匹配图片视频渐进式联合训练、端到端局部可控注意力机制等创新技术。同时，通过融合多模态理解信息和联合图文交织数据训练，显著提升了模型对文本指令和输入条件图像视频的感知能力。这意味着模型不仅能生成高质量的图像视频，还能进行多轮对话式高可控精确编辑操作，大幅提升了视觉生成的灵活便利性。例如，在图片生成方面可支持多轮精准局部修改，如修改文字、修改背景、增加元素等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;模型的图理解和视频理解性能也得到了全面提升：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;图理解方面：&lt;/strong&gt;在 MMStar、HallusionBench 和 OCRBench 等图理解任务中，九天模型分别获得了&amp;nbsp;&lt;strong&gt;82.2、64.3 和 94.9 的高分&lt;/strong&gt;，处于业界领先水平。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;视频理解方面：&lt;/strong&gt;在 Videomme 和 MVbench 两个任务中均表现领先，超越 Qwen2-VL 和 InternVideo2。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;目前，中国移动已将多项模型及核心技术进行开源：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源九天数童结构化数据大模型&lt;/strong&gt;：包括 JT-DA-8B 模型及后续演进版本，支持下载模型权重、微调代码、推理代码等。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源九天数学大模型&lt;/strong&gt;：包括 JT-Math-8B 系列模型，支持下载模型权重、推理代码、技术报告。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源九天代码大模型&lt;/strong&gt;：包括 JT-Coder-8B 系列模型，支持下载模型权重、推理代码、技术报告。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源业界首创的结构化数据模型评测数据及 TReB 评测体系&lt;/strong&gt;：涵盖 6 大任务、34 个能力，包括高质量、全面的数据、推理模式及评价指标，支持下载评测数据集、测试代码。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源 CCR-Bench 行业场景复杂指令遵循评测数据集&lt;/strong&gt;：包含 174 条高质量、多样化、高难度复杂指令数据，高度模拟健康专家、智能客服、医疗助手等典型工业场景，支持下载数据集。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362949</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362949</guid>
      <pubDate>Thu, 17 Jul 2025 06:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>特斯拉与三星签订 165 亿美元 AI 芯片制造协议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 28 日，三星电子在提交给监管机构的文件中表示，三星电子与一家全球大型公司签署了价值 22.8 万亿韩元（注：现汇率约合 1181.72 亿元人民币，约合 165 亿美元）的芯片制造协议，但未透露具体客户名称。&lt;/p&gt; 
&lt;p&gt;据消息人士透露，特斯拉正是这家客户，该公司目前与三星的合同芯片制造部门已有业务往来。&lt;/p&gt; 
&lt;p&gt;有外媒表示，三星电子公司将就新达成的 165 亿美元协议，为特斯拉公司生产半导体，这将为其表现不佳的晶圆代工部门提供助力。该合作的合同期 2025 年 7 月 24 日-2033 年 12 月 31 日。&lt;/p&gt; 
&lt;p&gt;对此，特斯拉 CEO 埃隆・马斯克确认了合作爆料，三星在美国得克萨斯州新建的巨型工厂将专门用于生产特斯拉的下一代 AI6 芯片（注：特斯拉汽车智驾芯片），并称「其战略重要性毋庸置疑」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99e430011e2ff79c31d84adca382c598c73.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;马斯克还称，三星目前正在生产 AI4 芯片。台积电将首先在中国台湾地区生产刚刚完成设计的 AI5 芯片，然后在美国亚利桑那州生产。&lt;/p&gt; 
&lt;p&gt;根据外媒今年 6 月报道，台积电在全球第三方晶圆代工市场的市占比为 67%，而排名第二的三星则仅占 11%。另外，有消息人士称，三星电子 2025 上半年晶圆代工部门获零奖金。此前，外媒援引供应链消息称，三星已启动「精选和聚焦」战略，集中资源提升 2nm 工艺良率，希望通过产量和成本优势来挑战台积电。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362947</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362947</guid>
      <pubDate>Thu, 17 Jul 2025 06:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>端侧原生大模型 SmallThinker 正式开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;上海交通大学 IPADS 研究所、上海交通大学人工智能学院联合初创公司本智激活（Zenergize AI），发布了开源端侧原生大模型 SmallThinker。&lt;/p&gt; 
&lt;p&gt;该系列模型采用为端侧算力、内存、存储特性而原生设计的模型架构，并从零开始预训练，具体包含两个尺寸的稀疏模型，分别是 SmallThinker-4B-A0.6B 和 SmallThinker-21B-A3B。&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt; 
&lt;p&gt;SmallThinker 专为低成本硬件设计，可在百元级国产开发板（如瑞芯微 RK3588）上流畅运行百亿参数模型，旨在为资源受限的个人设备带来强大、私密且低延迟的 AI 能力，无需依赖云端。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1578" src="https://static.oschina.net/uploads/space/2025/0729/143436_ewWq_2720166.png" width="2044" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以通过 Transformers（版本需 &amp;gt;= 4.53.3）或 ModelScope 来运行该模型。官方 GitHub 仓库提供了详细的设置、模型转换和运行指南。官方提示，模型使用了稀疏的 lm_head，可能会导致一定的精度损失，但用户可以手动修改代码禁用此特性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct&lt;/li&gt; 
 &lt;li&gt;https://github.com/SJTU-IPADS/PowerInfer/tree/main/smallthinker&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362945</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362945</guid>
      <pubDate>Thu, 17 Jul 2025 06:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：AnyShake Project 开源地震监测系统</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2112</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2112</guid>
      <pubDate>Thu, 17 Jul 2025 06:18:00 GMT</pubDate>
    </item>
  </channel>
</rss>
