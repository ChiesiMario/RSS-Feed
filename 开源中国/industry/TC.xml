<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 03 Mar 2025 21:43:24 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>IBM 完成 64 億美元收購 HashiCorp 交易</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;IBM 公司近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsroom.ibm.com%2F2025-02-27-ibm-completes-acquisition-of-hashicorp%2C-creates-comprehensive%2C-end-to-end-hybrid-cloud-platform&quot; target=&quot;_blank&quot;&gt;完成&lt;/a&gt;&lt;/u&gt;了對基礎設施自動化供應商 HashiCorp 公司 64 億美元的收購。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e58fe5ac5bcf71a8ae80e6570c9c668996d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;兩家公司最初預計將在 2024 年底前完成交易。延遲可能與反壟斷監管機構對該交易的審查有關。去年，美國聯邦貿易委員會 (FTC) 和英國競爭和市場管理局 (CMA) 都對這項收購進行了審查。&lt;/p&gt; 
&lt;p&gt;CMA 在週二批准了 IBM 收購 HashiCorp。據 TechCrunch 報道，FTC 在 CMA 之前已經悄然批准了這項交易。&lt;/p&gt; 
&lt;p&gt;HashiCorp 提供免費的 IT 基礎設施管理軟件工具。企業使用這些工具來配置雲實例、保護網絡連接並執行相關任務。該軟件套件被數十萬家組織使用，其中超過 5,000 家付費使用具有更多功能的商業版本。&lt;/p&gt; 
&lt;p&gt;在一篇博客文章中，HashiCorp 首席技術官 Armon Dadgar 表示，公司看到了將其工具與 IBM 產品組合更緊密集成的機會。&lt;/p&gt; 
&lt;p&gt;這項工作將特別強調 Terraform 和 Ansible。這兩個分別由 HashiCorp 和 IBM 開發的自動化工具可以減少配置 IT 基礎設施所需的工作量。Terraform 特別適合配置雲資源和其他硬件資源，而 Ansible 可用於設置在這些資源之上運行的軟件。&lt;/p&gt; 
&lt;p&gt;&quot;將用於資源配置的 Terraform 與用於配置管理的 Ansible 集成，將實現端到端的基礎設施自動化即代碼方案，&quot;Dadgar 寫道。&lt;/p&gt; 
&lt;p&gt;產品集成工作的另一個重點是 HashiCorp 的 Vault 工具。它提供了一個加密環境來存儲機密信息，如在公司網絡安全工作中發揮重要作用的密碼等數據。該軟件可以定期輪換或替換機密信息，以降低網絡攻擊的風險。&lt;/p&gt; 
&lt;p&gt;HashiCorp 看到了將 Vault 與 Ansible 以及 IBM 的另外兩款產品：OpenShift 和 Guardium 進行集成的機會。前者是用於支持容器應用程序的 Kubernetes 發行版，後者是幫助公司保護其業務數據的工具。&lt;/p&gt; 
&lt;p&gt;HashiCorp 還計劃將 Terraform 與 Cloudability 集成。後者是 IBM 通過早期收購獲得的工具，可幫助公司追蹤其雲支出。Terraform 持有的關於雲環境的技術數據可以幫助用戶更輕鬆地識別節省成本的機會。&lt;/p&gt; 
&lt;p&gt;IBM 和 HashiCorp 已經開始產品集成過程。週三，HashiCorp 認證其 HCP Terraform Operator for Kubernetes 可在 OpenShift 上運行。HCP Terraform Operator 允許開發人員通過 Kubernetes 的應用程序編程接口管理 Terraform。&lt;/p&gt; 
&lt;p&gt;&quot;通過聯手，我們獲得了他們的全球規模和增加的研發資源，&quot;Dadgar 在今天的博客文章中寫道。&quot;這使我們能夠接觸更多客戶，並繼續投資解決基礎設施和安全挑戰。&quot;&lt;/p&gt; 
&lt;p&gt;當 IBM 去年 4 月首次宣佈收購 HashiCorp 的計劃時，表示該收購將在交易完成後一年內對其調整後的息稅折舊及攤銷前利潤產生積極影響。該公司預計從第二年開始，這筆交易將提升其自由現金流。HashiCorp 上季度實現調整後營業收入 1,100 萬美元，收入為 1.734 億美元。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/327615/ibms-acquire-hashicorp-takeover-faces-uk-antitrust-scrutiny&quot; target=&quot;news&quot;&gt;IBM 收購 HashiCorp 交易面臨英國反壟斷審查&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/314704/mitchellh-zig-donation-300k&quot; target=&quot;news&quot;&gt;HashiCorp 創始人向 Zig 軟件基金會捐贈 30 萬美元&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289379/ibm-acquire-hashicorp-6-4-billion&quot; target=&quot;news&quot;&gt;IBM 以 64 億美元收購 HashiCorp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289203/ibm-nearing-buyout-deal-hashicorp&quot; target=&quot;news&quot;&gt;IBM 正在洽談收購雲基礎設施公司 HashiCorp&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336678/ibm-completes-acquisition-of-hashicorp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336678/ibm-completes-acquisition-of-hashicorp</guid>
            <pubDate>Thu, 27 Feb 2025 10:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌聯合創始人督促員工一週工作 60 小時</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌聯合創始人 Sergey Brin 在一份內部備忘錄中&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2Fcommand-line-newsletter%2F622045%2Fgoogle-ai-nanny-products&quot; target=&quot;_blank&quot;&gt;督促&lt;/a&gt;從事 Gemini AI 產品相關工作的員工至少每個工作日都去辦公室工作，&lt;strong&gt;並建議每週工作 60 小時，稱這是生產力的最佳時間點&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Brin 警告，AI 的競爭在加速，而 AGI 的終賽即將到來。AGI 指 AI 將達到或超越人類智能。Brin 在備忘錄中説，谷歌擁有贏得這場競賽的所有要素，但必須加大努力。這份備忘錄沒有改變谷歌要求員工每週至少去辦公室工作三天的政策。Brin 還在備忘錄中批評沒有付出更多努力的員工，稱他們挫傷了所有人的士氣。&lt;/p&gt; 
&lt;p&gt;Brin 要求 AI 團隊優先採用「簡單的解決方案」，並提高工作效率（&lt;strong&gt;「不能為了運行一小段 Python 代碼等待 20 分鐘」&lt;/strong&gt;）。&lt;/p&gt; 
&lt;p&gt;但最引人關注的是他對谷歌 AI 產品的批評：目前產品過度依賴過濾和限制措施。Brin 認為，谷歌應該「信任用戶」，而不是繼續推出「保姆式」產品。&lt;/p&gt; 
&lt;p&gt;Brin 內部備忘錄大意如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Gemini 計劃和 GDM 已經走過了兩年。這段時間裏，我們取得了顯著進展，也完成了許多值得驕傲的工作。然而，競爭日益激烈，AGI 競賽已進入關鍵階段。我相信我們具備勝出的所有條件，但必須加快步伐。&lt;/p&gt; 
 &lt;p&gt;代碼決定一切 ——AGI 的突破點在於&lt;strong&gt;AI 的自我優化&lt;/strong&gt;，儘管初期可能仍需大量人工幹預，因此代碼性能至關重要。此外，這必須建立在我們的 1p 代碼基礎上。我們要藉助自身 AI，成為全球最高效的開發者和 AI 科學家。&lt;/p&gt; 
 &lt;p&gt;高效工作 —— 根據我的經驗，&lt;strong&gt;每週 60 小時的工作量最有助於保持效率&lt;/strong&gt;。有人工作時間更長，但可能會&lt;strong&gt;精疲力竭、影響創造力&lt;/strong&gt;；也有人低於 60 小時，甚至有些人僅滿足最低要求。這不僅&lt;strong&gt;效率低下，&lt;strong&gt;還會&lt;/strong&gt;影響團隊士氣&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;線下協作 —— 面對面溝通遠比遠程會議等方式高效，因此必須與團隊成員在同一地點辦公。我們應儘量減少跨國、跨城市、跨大樓的彙報關係，建議每個工作日都到辦公室。&lt;/p&gt; 
 &lt;p&gt;組織優化 —— 團隊需要明確職責分工，保持高效協作，並由統一的管理和技術領導進行協調。&lt;/p&gt; 
 &lt;p&gt;簡化方案 —— 儘可能選擇簡單高效的解決方案。例如，如果提示詞（prompting）能滿足需求，就直接使用，而不是額外訓練單獨的模型。避免不必要的複雜技術（如 LoRA）。理想狀態是採用一個通用模型，只需調整提示即可滿足不同用途。&lt;/p&gt; 
 &lt;p&gt;追求卓越 —— 無論是評估指標、數據來源、儀表盤，還是內部 UI 消息，都要確保運行穩定、質量過硬。&lt;/p&gt; 
 &lt;p&gt;追求速度 —— 產品、模型和內部工具都要儘可能提高運行速度。&lt;strong&gt;不能為了運行一小段 Python 代碼等待 20 分鐘&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;快速迭代 —— 我們需要快速驗證大量想法，最好的方法是小規模試驗，逐步擴展並觀察是否能帶來更大優勢。過度依賴大規模開發，容易陷入微調、過擬合評估指標等問題。我們要追求真正可擴展的成果。&lt;/p&gt; 
 &lt;p&gt;避免過度限制 —— 不能繼續開發「保姆式」產品。當前產品已經充斥了過多的限制和篩選，我們需要打造&lt;strong&gt;真正有能力的產品&lt;/strong&gt;，並相信用戶的判斷。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336673/google-ai-nanny-products</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336673/google-ai-nanny-products</guid>
            <pubDate>Thu, 27 Feb 2025 10:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>軟件供應鏈安全的研究方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h3&gt;&lt;strong&gt;01 摘要&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;可複用的軟件庫、框架和組件（如開源生態系統和第三方供應商提供的）加速了數字創新。但近年來，攻擊者利用這些軟件製品發起軟件供應鏈攻擊的數量呈指數增長，比如&amp;nbsp;**SolarWinds、log4j 和 xz utils&amp;nbsp;**等知名攻擊事件。&lt;/p&gt; 
&lt;p&gt;軟件供應鏈攻擊主要有三個途徑：利用開源和第三方依賴組件漏洞注入惡意內容；在構建和部署過程中滲透構建基礎架構；通過社會工程學等手段針對軟件開發人員。若軟件行業減少對開源和第三方組件的使用來降低風險，會減緩數字創新，損害軟件供應鏈的信任。本文從研究者與從業者交流了解到的實際挑戰，以及大量研究成果出發，概述了當前保障軟件供應鏈安全的研究工作，並提出未來研究方向以應對軟件供應鏈攻擊。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;02 研究背景&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;軟件供應鏈的重要性與安全隱患&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現代社會高度依賴數字創新，可複用軟件製品加速了這一進程，但軟件供應鏈卻成為攻擊目標。軟件開發行業未料到其會被蓄意攻擊，近年攻擊事件頻發，如 SolarWinds 等，造成了巨大影響。美國和歐洲也出台相關法規，強調提升開源製品&lt;strong&gt;透明度和完整性&lt;/strong&gt;的緊迫性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;軟件供應鏈的攻擊向量&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;存在三個主要攻擊途徑：一是&lt;strong&gt;利用開源和第三方代碼&lt;/strong&gt;依賴中的漏洞或惡意注入，攻擊者可藉此執行任意代碼、竊取數據；二是&lt;strong&gt;滲透構建基礎架構&lt;/strong&gt;，在軟件構建和部署過程中注入惡意代碼；三是通過&lt;strong&gt;社會工程學手段&lt;/strong&gt;針對軟件開發人員，利用人的因素髮起攻擊。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;安全問題的影響&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;軟件供應鏈信任度降低，若企業減少對開源和第三方製品的使用，會阻礙數字創新。本文旨在闡述研究方法，概述針對三大攻擊向量的研究挑戰和成果，提出未來研究方向以增強軟件供應鏈安全，後續內容依次介紹研究方法、各攻擊向量的挑戰與研究、其他方向的研究成果，總結對軟件供應鏈安全研究方向的看法。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;03 行業和政府對挑戰的投入&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;S3C2 通過舉辦年度安全軟件供應鏈峯會、社區日活動，以及安排研究人員和學生到工業與政府機構演講交流，收集軟件供應鏈安全的實踐問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;挑戰反饋&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;行業和政府從業者反饋，軟件供應鏈安全是亟待解決的實際問題。在依賴選擇上，缺乏有效指標輔助決策，政府從業者還關注國外開發的軟件依賴風險。依賴更新時，漏洞數量多且工具無法提供足夠信息，更新可能帶來兼容性問題。惡意提交檢測困難，缺乏可靠方法。在構建基礎架構方面，企業尋求安全構建和部署指導，認為可重複性構建不實用。此外，軟件供應鏈安全框架的廣泛實施面臨挑戰，需行業共同努力，且自動化漏洞修復和構建安全文化至關重要。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;04 攻擊向量：代碼依賴&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;開發者在代碼依賴方面面臨的實際挑戰&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;依賴項選擇困難&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開發者在挑選開源和第三方代碼依賴項時，難以在安全性和功能性之間找到平衡。他們缺乏全面且實用的指標，來幫助判斷依賴項是否存在安全漏洞或潛在風險，也難以確定依賴項是否符合項目的功能需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;依賴更新困難&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;保持依賴項更新對修復安全漏洞至關重要，開發者更新時會遇到麻煩。他們擔心新版本依賴會引入與現有代碼的兼容性問題，進而破壞軟件的正常功能。而且，在更新過程中，開發者難以預估可能出現的新安全漏洞，這使得依賴更新的決策變得異常複雜。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;惡意提交難以及時發現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源生態系統中，代碼依賴項的維護者提交惡意代碼的情況時有發生，開發者卻很難快速察覺。因為他們缺乏有效的監測機制和工具，無法及時識別這些惡意提交，從而使軟件面臨安全風險。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;針對代碼依賴安全的現有研究成果&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;依賴選擇工具與指標&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為輔助開發者進行依賴項選擇，研究人員開發瞭如 OpenSSF Scorecard 等工具，通過評估開源項目的安全性指標，為開發者提供參考。但目前依賴選擇指標體系仍不完善，無法全面覆蓋所有與安全和功能相關的因素，難以滿足開發者多樣化的需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;依賴更新策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;研究提出了基於風險的依賴更新策略，旨在綜合考慮依賴項的安全風險、更新的影響範圍等因素，制定更合理的更新計劃。然而，這些策略在實際應用中缺乏足夠的自動化支持，需要開發者手動進行大量的分析和決策，增加了操作成本和複雜性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;惡意提交檢測方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在檢測開源依賴項中的惡意提交方面，研究採用機器學習技術，對代碼的歷史提交記錄、開發者行為模式等數據進行分析建模。但該方法面臨訓練數據庫信息不完整的問題，難以涵蓋所有類型的惡意行為模式，導致檢測的準確性和全面性受到限制。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;代碼依賴安全研究面臨的挑戰&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;依賴選擇指標與數據問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當前依賴選擇指標不夠全面和精準，無法充分反映依賴項的真實安全狀況。同時，用於評估依賴項的數據庫存在信息缺失、更新不及時等問題，難以提供完整可靠的參考依據。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;理論與實踐脫節&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;雖然在依賴管理的理論研究上取得了一定進展，但在將這些理論轉化為實際可用的工具和方法時，存在較大差距。開發出的工具往往難以集成到現有的軟件開發流程中，導致開發者在實際應用中面臨諸多困難。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨平台研究不足&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨着軟件開發環境的日益複雜，跨平台的代碼依賴越來越常見。然而，目前針對跨平台依賴安全的研究相對較少，缺乏有效的方法和工具來保障不同平台間依賴項的安全性和兼容性 。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;05 攻擊向量：構建基礎架構&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;從業者對構建基礎架構安全的認知&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全擔憂傾向&lt;/strong&gt;：相較於軟件部署過程，從業者更擔憂構建過程中的安全問題，認為構建環境存在更多潛在風險，容易被攻擊者利用來篡改軟件。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可重複性構建的看法&lt;/strong&gt;：儘管可重複性構建有助於確保軟件在不同環境下的一致性，但從業者對其實際效用存在疑慮。他們覺得在實際操作中，實現可重複性構建面臨諸多困難，並且其對保障軟件安全的直接價值不明確。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;構建基礎架構安全的現有研究成果&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;透明度研究進展&lt;/strong&gt;：研究致力於提高構建過程的透明度，通過記錄和審計構建過程中的每一個步驟和操作，使得開發者和安全人員能夠追溯和驗證軟件的構建歷史，及時發現潛在的篡改行為。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完整性保障措施&lt;/strong&gt;：為確保構建輸出的完整性，研究引入瞭如軟件物料清單（SBOM）、代碼簽名等技術和方法，以驗證軟件在構建和分發過程中未被篡改。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;信任模型探索&lt;/strong&gt;：構建了信任模型來評估構建基礎架構中各個組件和參與者的可信度，幫助識別潛在的不可信來源，從而降低安全風險。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD 漏洞檢測&lt;/strong&gt;：針對持續集成 / 持續交付（CI/CD）流程中的漏洞，開發了相應的檢測工具和技術，能夠及時發現並修復流程中可能存在的安全隱患。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;構建基礎架構安全研究面臨的未來挑戰&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;透明度實現難題&lt;/strong&gt;：雖然提高構建透明度是目標，但在實際應用中，如何在不增加過多成本和複雜性的前提下，實現全面、實時的構建過程透明化，仍是亟待解決的問題。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;代碼簽名推廣困境&lt;/strong&gt;：儘管代碼簽名技術有助於保障軟件完整性，但目前在行業內的廣泛應用和接受度仍不理想，需要解決技術標準統一、證書管理等一系列問題，以推動其普及。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可重複性構建普及問題&lt;/strong&gt;：要使可重複性構建在實際項目中得到廣泛應用，需要克服技術、流程和人員等多方面的障礙，建立更加完善的支持體系和最佳實踐指南。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD 漏洞評估挑戰&lt;/strong&gt;：隨着 CI/CD 技術的不斷發展和應用場景的日益複雜，如何持續有效地評估和應對其中的安全漏洞，需要進一步研究和探索新的方法和工具 。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;06&amp;nbsp;&lt;strong&gt;攻擊向量：人為因素&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;實際挑戰&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;軟件供應鏈安全依賴行業集體行動與人員參與，相關框架需廣泛採用和信息共享才有效。企業雖有安全措施，但面臨文化適應問題，如 SolarWinds 事件後需調整安全文化。「guardrails, not gates」 方式平衡開發速度與安全，但仍有風險。此外，自動化漏洞修復可減輕開發者負擔，構建安全文化需全員參與。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;研究成果&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;支持開發者&lt;/strong&gt;：實施軟件供應鏈安全複雜，開發者需應對第三方組件信任、代碼漏洞等問題。研究發現多數公司有外部代碼管理政策，但開發者需更多資源審計和保障組件安全。同時，研究建議開發者主動預見工具的負面影響。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;開源生態系統&lt;/strong&gt;：開源軟件在軟件供應鏈佔比大，但面臨開發分散、資源有限等問題。研究表明開源項目安全措施差異大，小項目資源不足，且存在祕密管理難題，如 API 密鑰易泄露。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;學術界&lt;/strong&gt;：軟件供應鏈安全研究人員面臨倫理困境，如披露漏洞可能幫助或傷害用戶，研究數據涉及隱私保護和使用許可問題。相關工作影響了計算機安全領域的倫理準則，促使研究人員討論決策的倫理維度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;未來挑戰&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;軟件供應鏈安全方法的廣泛採用至關重要，需確保其用戶友好以推動行業接受。未來，高級網絡釣魚攻擊將構成更大威脅，需通過改進培訓、限制環境或利用 LLMs 防禦等措施應對。此外，隨着技術防禦加強，內部威脅可能持續存在，需要更先進的行為監測和自適應安全協議。&lt;/p&gt; 
&lt;h3&gt;07&amp;nbsp;&lt;strong&gt;軟件供應鏈安全的其他研究方向&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;軟件物料清單（SBOM）&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;概述與作用：SBOM 用於識別和跟蹤軟件系統中的第三方組件，能提高透明度、助力企業掌握軟件風險，美國政府要求關鍵軟件提供 SBOM。&lt;/li&gt; 
 &lt;li&gt;面臨的挑戰：從業者雖認可其安全價值，但在實施中面臨諸多問題。生成方面，工具生成的 SBOM 質量參差不齊，缺乏通用性，標準不統一且存在隱私問題。應用環節，當前流程混亂易錯，SBOM 質量低且數據缺失，動態組件缺失和安全流程集成不足限制其應用。共享時，企業擔心隱私泄露，且格式轉換操作複雜。VEX 雖能提升 SBOM 安全性，但手動創建限制其價值，自動化生產 VEX 需解決信息識別等問題。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;從業者挑戰：自我認證和出處&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;美國行政命令要求政府承包商 CEO 對軟件符合開發實踐、開源軟件完整性和出處進行自我認證。工業參與者擔心要求不明確，部分企業因負擔問題將產品開源以豁免認證，但多數人認為相關認證對安全更具基礎性作用。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;LLM 與軟件供應鏈&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM 在軟件供應鏈中的應用與風險：LLMs 在軟件開發各階段廣泛應用，成為軟件供應鏈一部分，但帶來信任問題，如幻覺現象和不安全編碼影響。在代碼生成方面，能提高效率但可能生成不安全代碼，且其供應鏈存在組件漏洞風險。&lt;/li&gt; 
 &lt;li&gt;LLM 在漏洞檢測中的表現與問題：LLMs 在漏洞檢測上比部分傳統方法更有效，但存在誤報、幻覺等問題。研究通過改進方法和框架提升其檢測能力，但仍需克服性能和可靠性挑戰。&lt;/li&gt; 
 &lt;li&gt;LLM 作為攻擊向量的威脅：LLMs 可被用作攻擊向量，如通過提示注入和第三方 API 集成引入新漏洞，研究展示了其被攻擊的方式及潛在風險。&lt;/li&gt; 
 &lt;li&gt;LLM 性能與可擴展性研究方向：未來研究需全面提升 LLM 性能，降低成本，解決處理大文件時的侷限性，提高效率和可擴展性，減少模型崩潰和幻覺現象。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;從業者挑戰：供應鏈標準、指南和框架&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;眾多軟件安全標準、指南和框架湧現，如 SSDF、SLSA 等，旨在降低供應鏈風險。但從業者在眾多標準中難以抉擇，Proactive Software Supply Chain Risk Management（PSSCRM）試圖整合多個框架來提供統一指導。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;軟件供應鏈安全度量&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;美國將軟件安全度量列為研究重點，但軟件系統的特性使有效度量困難重重。提供支持需進行指標策劃、數據發佈和定期審查，以幫助開發者在複雜情況下做出決策，研究正朝着更實用的方向努力，如提供單個依賴及其生態系統的實時數據和指標。&lt;/p&gt; 
&lt;h3&gt;08&amp;nbsp;&lt;strong&gt;結論&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;研究總結&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;軟件供應鏈安全至關重要，近年來受 SolarWinds、log4j 等事件影響備受關注。行業和學術界針對代碼依賴、構建基礎架構、人員這三個主要攻擊向量展開了大量研究。例如，行業中採用 SCA 工具、SBOMs 和 OpenSSF Scorecard 應對代碼依賴問題，利用 SLSA、in - toto 和 TUF 保障構建過程安全；學術界則開發了新分析工具，對現有工具和生態系統進行實證研究，並與從業者溝通以瞭解實際挑戰。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;現存挑戰&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;儘管取得了一定進展，但軟件供應鏈安全仍面臨諸多難題。在代碼依賴方面，管理漏洞困難，開發者難以選擇安全可靠的依賴項；構建基礎架構方面，遺留環境難以改變，缺乏有效的分析工具，構建過程的可重複性難以實現；人員因素方面，需持續關注人為因素帶來的風險；同時，LLMs 在軟件供應鏈中的應用也帶來了新的安全風險。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;未來展望&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;未來需要持續深入研究軟件供應鏈安全，具體包括改進依賴管理，加強構建環境安全，關注人員因素對軟件供應鏈安全的影響，以及應對 LLMs 帶來的新風險等。還計劃開發 「軟件供應鏈安全儀錶板」 併發布年度報告，以滿足從業者的數據需求並進行定期審查，從而更好地推動軟件供應鏈安全的發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336669</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336669</guid>
            <pubDate>Thu, 27 Feb 2025 10:20:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>百川智能在深圳以 3000 萬元成立科技公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，深圳百方智能科技有限公司於近日成立，法定代表人為謝劍；註冊資本 3000 萬人民幣，超過了 98% 的廣東省同行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;企業經營範圍含計算機系統服務、人工智能應用軟件開發、人工智能雙創服務平台、人工智能理論與算法軟件開發、人工智能基礎軟件開發、人工智能通用應用系統等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;股東信息顯示，該公司由北京百川智能科技有限公司全資持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;239&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9257b9ebf40f2dbbbf72331a47f47e644aa.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336663</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336663</guid>
            <pubDate>Thu, 27 Feb 2025 09:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>verl —— HybridFlow 論文的開源實現</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;verl 是一個靈活、高效且可用於生產的 RL 訓練庫，適用於大型語言模型 (LLM)。&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;verl 是&lt;strong&gt;&amp;nbsp;&lt;a href=&quot;https://arxiv.org/abs/2409.19256v2&quot;&gt;HybridFlow：一種靈活高效的 RLHF 框架&lt;/a&gt;&amp;nbsp;&lt;/strong&gt;論文的開源實現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;verl 靈活且易於使用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;輕鬆擴展各種 RL 算法&lt;/strong&gt;：混合編程模型結合了單控制器和多控制器範式的優勢，能夠靈活地表示和高效執行復雜的訓練後數據流。允許用戶用幾行代碼構建 RL 數據流。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;現有 LLM 基礎架構與模塊化 API 無縫集成&lt;/strong&gt;：解耦計算和數據依賴關係，實現與現有 LLM 框架（如 PyTorch FSDP、Megatron-LM 和 vLLM）無縫集成。此外，用戶可以輕鬆擴展到其他 LLM 訓練和推理框架。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;靈活的設備映射&lt;/strong&gt;：支持將模型放置到不同的 GPU 組上，以實現高效的資源利用率和跨不同集羣規模的可擴展性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;輕鬆與流行的 HuggingFace 模型集成&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;verl 速度很快：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;最先進的吞吐量&lt;/strong&gt;：通過無縫集成現有的 SOTA LLM 訓練和推理框架，verl 實現了高生成和訓練吞吐量。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用 3D-HybridEngine 進行高效的演員模型重新分片&lt;/strong&gt;：消除內存冗餘並顯著減少訓練和生成階段之間轉換期間的通信開銷&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FSDP&lt;/strong&gt;和&lt;strong&gt;Megatron-LM&lt;/strong&gt;用於訓練。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vLLM&lt;/strong&gt;和&lt;strong&gt;TGI&lt;/strong&gt;用於推出生成，&lt;strong&gt;SGLang&lt;/strong&gt;支持即將推出。&lt;/li&gt;
&lt;li&gt;huggingface 模型支持&lt;/li&gt;
&lt;li&gt;監督微調&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/ppo_trainer&quot;&gt;使用 PPO&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/grpo_trainer&quot;&gt;GRPO&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/remax_trainer&quot;&gt;ReMax&lt;/a&gt;、&lt;a href=&quot;https://verl.readthedocs.io/en/latest/examples/config.html#algorithm&quot;&gt;Reinforce++&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/tree/main/examples/rloo_trainer/run_qwen2-7b.sh&quot;&gt;RLOO&lt;/a&gt;等&amp;nbsp;從人類反饋中進行強化學習
&lt;ul&gt;
&lt;li&gt;支持基於模型的獎勵和基於函數的獎勵（可驗證的獎勵）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;flash-attention、&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh&quot;&gt;序列打包&lt;/a&gt;、通過 DeepSpeed Ulysses、&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/sft/gsm8k/run_qwen_05_peft.sh&quot;&gt;LoRA&lt;/a&gt;、&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh&quot;&gt;Liger-kernel 提供&lt;/a&gt;&lt;a href=&quot;https://github.com/volcengine/verl/blob/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh&quot;&gt;長上下文支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;可擴展至 70B 模型和數百個 GPU&lt;/li&gt;
&lt;li&gt;使用 wandb、swanlab 和 mlflow 進行實驗跟蹤&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/verl</link>
            <guid isPermaLink="false">https://www.oschina.net/p/verl</guid>
            <pubDate>Thu, 27 Feb 2025 08:42:00 GMT</pubDate>
        </item>
        <item>
            <title>RWKV 社區 2 月動態：10 篇新學術論文！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎大家收看《RWKV 社區最新動態》，本期內容收錄了 RWKV 社區 2025 年 2 月的最新動態。&lt;/p&gt; 
&lt;p&gt;只需 3 分鐘，快速瞭解 RWKV 社區 2 月都有哪些新鮮事！&lt;/p&gt; 
&lt;h2&gt;2 月動態省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 學術研究動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新論文：Activation Sparsity in Recurrent LLMs（RWKV 能效神經形態計算）&lt;/li&gt; 
   &lt;li&gt;新論文：SNAP（RWKV 混合神經網絡架構）&lt;/li&gt; 
   &lt;li&gt;新論文：ARWKV（從 DeepSeek 快速遷移到 RWKV 架構）&lt;/li&gt; 
   &lt;li&gt;新論文：OmniRWKVSR（RWKV 圖像超分辨率）&lt;/li&gt; 
   &lt;li&gt;新論文：ET_MGNN（RWKV 腦部疾病診斷）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKV-UI（RWKV 高分辨率用戶界面理解）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKV-Among-Us（RWKV 多智能體強化學習）&lt;/li&gt; 
   &lt;li&gt;新論文：LALIC（RWKV 圖像壓縮）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKV 工業缺陷檢測&lt;/li&gt; 
   &lt;li&gt;新論文：Rwkv-vg（RWKV 視覺定位）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新聞動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新模型： RKWV-7-2.9B&lt;/li&gt; 
   &lt;li&gt;新模型： 新模型：Qwerky-72B&lt;/li&gt; 
   &lt;li&gt;推理模型 G1 系列訓練中&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區活動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 開發者大會 2025&lt;/li&gt; 
   &lt;li&gt;RWKV 2025 生態內容徵集大賽 | 1 月投稿作品及評審結果&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 學術研究動態&lt;/h2&gt; 
&lt;p&gt;RWKV 學術研究包括&lt;strong&gt;基於 RWKV 架構的新論文&lt;/strong&gt;或&lt;strong&gt;RWKV 社區參加的學術研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Activation Sparsity in Recurrent LLMs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Explore Activation Sparsity in Recurrent LLMs for Energy-Efficient Neuromorphic Computing&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.16337&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.16337&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-01-09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種低成本、無需訓練的算法，用於稀疏循環大語言模型（R-LLMs）的激活，以實現高效能的神經形態計算。論文以 RWKV 為例展示了該方法的有效性。通過在 RWKV 中添加閾值函數，平均激活稀疏度得以提升。硬件模擬顯示出顯著的節能和延遲改善，並且該方法還可以擴展到其他模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-236dccf9bebcc12e643b9a73457982c5569.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;SNAP&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Learnable Sparsification of Die-to-Die Communication via Spike-Based Encoding&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08645&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08645&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-01-15&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 SNAP，一種結合了脈衝神經網絡（SNNs）和人工神經網絡（ANNs）的混合神經網絡架構。為了評估 SNAP，論文將 RWKV 作為代表性的語言模型架構進行集成。&lt;/p&gt; 
&lt;p&gt;實驗表明，SNAP 優於傳統的 SNN 和非脈衝模型，實現了高達 5.3 倍的能源效率提升和 15.2 倍的推理延遲降低，凸顯了其在大規模人工智能系統中的潛力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5300cb672c916fedd3bf729a745b2df0d5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;ARWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.15570&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.15570&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face 倉庫鏈接: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FRWKV-Red-Team%2FARWKV_7B_R1_16K&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/RWKV-Red-Team/ARWKV_7B_R1_16K&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-01-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 ARWKV：一種基於 RWKV 架構的語言模型，ARWKV 引入 RWKV 的時間混合模塊來替代傳統 Transformer 中的自注意力機制。該方法旨在提升 RNN 的表達能力和狀態跟蹤能力，從而超越 Transformer 模型。ARWKV 通過從 Qwen2.5 等 Transformer 模型蒸餾知識到 RNN 中，實現了在有限資源（如單塊 A100 GPU 上訓練 7B 模型）下的高效訓練。&lt;/p&gt; 
&lt;p&gt;ARWKV 的方法包含三個階段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一階段：用 RWKV-7 時間混合模塊替代自注意力機制，保持了模型的表達能力，同時將架構從 Transformer 轉向 RNN。&lt;/li&gt; 
 &lt;li&gt;第二階段：進行知識蒸餾，將較大的 Transformer 模型（如 Qwen2.5）中的知識轉移到基於 RNN 的 ARWKV 模型中。&lt;/li&gt; 
 &lt;li&gt;第三階段：使用監督微調（SFT）和直接偏好優化（DPO）進一步優化模型，並對用戶偏好進行對齊。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該方法融合了 Transformer 和 RNN 架構的優勢，展示了 RWKV 在混合架構中的潛力。評估結果顯示，ARWKV 在多個基準任務中表現良好。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca53111a4ad9e78a1c31bbfe9fee6e870dc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;OmniRWKVSR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Exploring Linear Attention Alternative for Single Image Super-Resolution&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.00404&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.00404&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 OmniRWKVSR 模型用於單圖像超分辨率，結合 RWKV 架構與新型特徵提取技術（VRSM 和 VRCM），以解決計算複雜性和重建質量問題。通過利用 RWKV 的線性計算效率及 RNN-Transformer 混合優勢，該模型避免了二次注意力計算成本，同時增強多尺度特徵捕捉。&lt;/p&gt; 
&lt;p&gt;實驗結果表明其性能優於 MambaIR 和 SwinIR，在 4 倍超分辨率任務中 PSNR 提升 0.26%、SSIM 提升 0.16%，且訓練速度加快 15%。研究突顯了 RWKV 在平衡效率與圖像恢復質量（尤其在遙感應用）中的有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eb1030d144498811dc7089ee27fcd0f4ad1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;ET_MGNN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Multi-Modal Dynamic Brain Graph Representation Learning for Brain Disorder Diagnosis Via Temporal Sequence Model&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5114041&quot; target=&quot;_blank&quot;&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5114041&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了用於腦部疾病診斷的 ET_MGNN 模型。該模型整合了多模態腦網絡信息，並使用 RWKV 進行動態序列建模。通過融合結構和功能連接性，該模型能夠捕捉複雜的腦網絡特徵。&lt;/p&gt; 
&lt;p&gt;在 ABIDE II 和 ADNI 等數據集上的實驗表明，ET_MGNN 優於其他方法，且 RWKV 在性能提升中發揮了關鍵作用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aff6c004a3bc9826d8d334c84beef900c80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-UI&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：RWKV-UI: UI Understanding with Enhanced Perception and Reasoning&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03971&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.03971&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 RWKV-UI，一種基於 RWKV 架構的視覺語言模型，專為高分辨率用戶界面（UI）理解設計。針對現有視覺語言模型在高分辨率 UI 圖像處理中的信息丟失和推理能力不足，該模型集成三種視覺編碼器（SIGLIP、DINO、SAM），採用分塊編碼策略處理 4096×4096 圖像並保留細節。結合 RWKV 高效的 RNN 結構，模型引入佈局檢測和思維鏈（CoT）視覺提示，增強空間推理和多步交互預測能力。&lt;/p&gt; 
&lt;p&gt;實驗表明其在 UI 理解任務中表現卓越，在動作定位和元素識別等任務上優於更大規模模型，凸顯了 RWKV 在多模態場景中的適應性和高效性。 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c4074f12f1fe4b80835bf9f29a82accd791.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-Among-Us&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.06060&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.06060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出利用多智能體強化學習訓練語言模型，使其在無需人類示範的社交推理遊戲中實現自然語言溝通。通過結合 「聽」（從討論中推理內鬼身份）和 「説」（獎勵能改變他人觀點的信息），該方法採用 RWKV 模型 —— 一種基於線性注意力的循環架構，以高效處理長遊戲序列並降低計算負擔。&lt;/p&gt; 
&lt;p&gt;實驗表明，基於 RWKV 的智能體勝率是標準強化學習方法的兩倍，並展現出基於證據指控等類人策略。RWKV 的選擇解決了擴展性和長上下文處理的挑戰，對實時多智能體交互至關重要。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a703109ab6ab803b7e25a59685ccfa7801.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;LALIC 圖像壓縮方法&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Linear Attention Modeling for Learned Image Compressionc&lt;/li&gt; 
 &lt;li&gt;論文鏈接：https://arxiv.org/abs/2502.05741&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 LALIC 框架，一種基於 RWKV 的學習型圖像壓縮方法。通過雙向 RWKV（BiWKV）注意力模塊和 Omni-Shift 模塊，LALIC 以線性複雜度捕捉二維潛在特徵的全局依賴與局部上下文。結合 RWKV 空間 - 通道上下文模型（RWKV-SCCTX），該方法進一步利用空間和通道冗餘優化熵建模。&lt;/p&gt; 
&lt;p&gt;實驗表明，LALIC 在 Kodak、Tecnick 和 CLIC 數據集上的 BD-rate 性能超越 VTM-9.1 達 17.32%，且計算複雜度低於傳統 Transformer 方法。該工作驗證了 RWKV 在高分辨率圖像壓縮中兼顧效率與性能的優勢。 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b9a74473fe332427353c4384942b0fdb52d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 工業缺陷檢測&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Substation equipment non-rigid defect detection via receptance weighted key value-based causality-aware networks&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs11760-025-03852-y&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/article/10.1007/s11760-025-03852-y&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種基於 RWKV 架構的因果感知設備缺陷檢測框架，以解決變電站設備中的非剛性缺陷檢測和長尾分佈問題。RWKV 架構具有全局感受野，可增強缺陷特徵提取能力。它與框架中的其他模塊相結合。&lt;/p&gt; 
&lt;p&gt;實驗表明，該框架優於基線方法，驗證了其有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5ce4856d0d0280b88440b26b881aa700d17.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Rwkv-vg&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Rwkv-vg: visual grounding with RWKV-driven encoder-decoder framework&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs00530-025-01720-w&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/article/10.1007/s00530-025-01720-w&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-02-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 RWKV-VG，一種完全基於 RWKV 架構的視覺定位框架。不同於傳統的 CNN 或 Transformer 方法，RWKV-VG 利用 RWKV 結合 RNN 的順序建模與 Transformer 注意力的混合設計，高效建模模態內和跨模態交互。該框架包含 RWKV 驅動的視覺 / 語言編碼器、跨模態解碼器及可學習的 [REG] 令牌用於邊界框迴歸。&lt;/p&gt; 
&lt;p&gt;在 ReferItGame 和 RefCOCO 等基準測試中，其性能超越 TransVG 等 Transformer 方法，精度更高且收斂更快。消融實驗驗證了 RWKV 模塊和 [REG] 令牌位置的關鍵作用。該工作證實了 RWKV 在視覺 - 語言任務中的競爭力，兼具高效計算與高精度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c6124a9db6e9eccb7d8157ca977f713f8ee.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型動態&lt;/h2&gt; 
&lt;h3&gt;新模型：RKWV-7-2.9B&lt;/h3&gt; 
&lt;p&gt;2025 年 2 月 11 日，RWKV 基金會正式發佈 RWKV-7-World-2.9B-V3 模型（以下簡稱 RWKV-7-2.9B）。&lt;/p&gt; 
&lt;p&gt;RWKV-7-2.9B 模型基於 RWKV World V3 數據集訓練，英文和多語言能力均&lt;strong&gt;顯著超越&lt;/strong&gt;所有同尺寸模型，包括 Llama 3.2 3B、Qwen2.5 3B 等知名優秀開源模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d16b73a1fdbd217b46c921f5c7643eb0845.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可在 Hugging Face Demo 在線體驗 RWKV-7-2.9B 模型：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;新模型：Qwerky-72B&lt;/h3&gt; 
&lt;p&gt;從 Qwen 2.5 遷移到 RWKV-7 的 Qwerky-72B 現已由海外 RWKV 社區開源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Ffeatherless-ai%2FQwerky-72B-Preview&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/featherless-ai/Qwerky-72B-Preview&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Qwerky-72B 基於海外 RWKV 社區提出的新穎模型遷移方法，可將使用 softmax attention （如 Qwen 和 LLaMA）的大模型用極低的成本（例如在單台 H800 訓練幾天）快速微調為 RWKV 模型，而無需從頭開始預訓練。&lt;/p&gt; 
&lt;h3&gt;推理模型 G1 系列訓練中&lt;/h3&gt; 
&lt;p&gt;我們正在基於 World v3.5 數據集繼續訓練 RWKV-7 &quot;Goose&quot; 系列模型（0.1B/0.4B/1.6B/2.9B），並命名為 &lt;strong&gt;RWKV7-G1&lt;/strong&gt; （&quot;GooseOne&quot;）系列推理模型。據測試，最小的 G1 0.1B 就已能實現推理過程。&lt;/p&gt; 
&lt;p&gt;G1 系列模型的發佈計劃：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;發佈計劃&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 0.1B&lt;/td&gt; 
   &lt;td&gt;3 月 8 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 0.4B&lt;/td&gt; 
   &lt;td&gt;3 月下旬&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 1.6B&lt;/td&gt; 
   &lt;td&gt;4 月&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;G1 2.9B&lt;/td&gt; 
   &lt;td&gt;5 月&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;RWKV 社區活動&lt;/h2&gt; 
&lt;p&gt;此版塊包含&lt;strong&gt;RWKV 官方動態&lt;/strong&gt;，以及&lt;strong&gt;RWKV 社區舉辦或參加的各類活動&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;RWKV 開發者大會 2025 圓滿舉辦&lt;/h3&gt; 
&lt;p&gt;2025 年 2 月 22 日，RWKV 在上海漕河涇舉辦了主題為《RWKV-7 與未來趨勢》的開發者大會。&lt;/p&gt; 
&lt;p&gt;來自全國各地的開發者、行業專家和技術創新者齊聚一堂——從知名高校實驗室到前沿創業團隊，現場湧動的創新能量印證了 RWKV-7 的優秀性能和深遠意義。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0009b032f793e66e731fcfb92175fcbbf19.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有關 RWKV 2025 開發者大會的更多信息，可以查看此文章：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fr7eUhh7BJEDLFq_Iy4XWgA&quot; target=&quot;_blank&quot;&gt;RWKV 開發者大會 2025：全球數萬開發者探討 RWKV-7 超越 Transformer&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 2025 生態內容徵集大賽 | 1 月投稿作品及評審結果&lt;/h3&gt; 
&lt;p&gt;2025 年 1 月，活動共收到 RWKV 生態作品投稿 11 份，包括 3 篇論文、7 款應用和 1 篇教程 / 動畫。&lt;/p&gt; 
&lt;p&gt;評審後，共選出&lt;strong&gt;金獎 1 項、銀獎 4 項、鐵獎 2 項&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;更多信息可參考：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqqGF05Sot1seCCRg1N9Bhg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生態內容徵集大賽 | 1 月投稿作品及評審結果&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336650</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336650</guid>
            <pubDate>Thu, 27 Feb 2025 08:26:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>北京人工智能公共算力平台擴容，智算規模突破 10000P</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「北京發佈」公眾號發文稱，北京人工智能公共算力平台近日再次實現擴容，智算規模突破 10000P，成為北京最大、國內領先的超大規模高性能單體智算集羣，將有力支撐各類創新主體萬億參數級通用基礎大模型一體化訓練和推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;430&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-73fb2db20ce7d8ffa92917b1d678f17f7fe.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336647</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336647</guid>
            <pubDate>Thu, 27 Feb 2025 08:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 公佈利潤率——引發兩家國產 AI Infra 公司創始人隔空互嗆</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 1 日，在「開源五連發」後，DeepSeek 又來了一個「One More Thing」為開源周收官——首次&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27181462601&quot; target=&quot;_blank&quot;&gt;披露&lt;/a&gt;&lt;/u&gt;了其模型推理系統 DeepSeek-V3 / R1 的技術細節及成本利潤率。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/143406_aFcS_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根據 DeepSeek 公開的信息計算，&lt;strong&gt;它理論上一天的總收入為 562027 美元，成本利潤率高達 545%&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此次 DeepSeek 盈利數據公佈後瞬間成為行業焦點，引發廣泛討論，尤其是引發了兩家國產 AI Infra 公司創始人——尤洋與袁進輝的爭論。&lt;/p&gt; 
&lt;p&gt;事件的兩個主角，一方是尤洋及其創辦的潞晨科技，另一方是袁進輝及其創立的硅基流動。&lt;/p&gt; 
&lt;p&gt;先是 DeepSeek 的這篇技術分享在知乎發佈後，不少用戶開始@尤洋，讓他點評。這是因為此前在 DeepSeek 被各家服務商爭相部署的熱潮裏，他是最積極的反對聲音之一。&lt;/p&gt; 
&lt;p&gt;此前尤洋曾在社交平台上計算過部署 DeepSeek 的成本和收益，並得出結論，&lt;strong&gt;部署 DeepSeek 並提供服務的 AI Infra 公司，都是在虧錢，並且是「月虧四億」&lt;/strong&gt;。他提到：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;短期內，中國的 MaaS（模型即服務）模式可能是最差的商業模式，大廠相互卷低價和免費，滿血版 DeepSeek R1 每百萬 token（輸出）只收 16 元。&lt;/p&gt; 
 &lt;p&gt;如果每日輸出 1000 億 token，基於 DeepSeek 的服務每月的機器成本是 4.5 億元，虧損 4 億元；用 AMD 芯片月收入 4500 萬元，月機器成本 2.7 億元，這意味着虧損也超過 2 億元。&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/143832_4Tqd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此次 DeepSeek 的開源周並非要回應某個具體質疑，但其公佈的利潤率之高，顯然與這個計算完全相反。人們首先想到了尤洋。尤洋也在四個小時後發文&lt;em&gt;「&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27271377737&quot; target=&quot;_blank&quot;&gt;《關於 DeepSeek MaaS 成本》&lt;/a&gt;」&lt;/u&gt;&lt;/em&gt;回應，&lt;strong&gt;稱 DeepSeek 官方這一計算方法不能用於 MaaS 盈虧評估&lt;/strong&gt;。在論述中，他延續了「基於大模型的 Mass 服務不賺錢」的立場。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/144501_AKpd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;袁進輝也在 DeepSeek 文章發佈一小時後就火速評論道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「又顛覆了很多人的認知」，他認為「很多供應商做不到這個水平」，&quot;MaaS 能否成功，關鍵在於技術實力和用戶基礎&quot;。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0303/145540_di7S_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;緊接着兩家國產 AI Infra 公司創始人隔空互嗆的「對戰」開始了：&lt;/p&gt; 
&lt;p&gt;首先是尤洋直接發了一篇直接批評硅基流動這家公司的文章：&lt;em&gt;「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27282739710&quot; target=&quot;_blank&quot;&gt;《坑人的硅基流動》&lt;/a&gt;」&lt;/em&gt;（現已刪除）。&lt;/p&gt; 
&lt;p&gt;尤洋稱本來不想發這些東西，但是硅基流動的袁進輝老師頻繁在朋友圈裏陰陽他，&lt;strong&gt;&lt;em&gt;&quot;這家公司疑似組織水軍在網上長期黑我。今天 DeepSeek 有一篇文章指向我，他也在那裏煽風點火。&quot;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尤洋稱硅基流動三週前網站訪問量大增，原因是：&lt;/p&gt; 
&lt;p&gt;1、犧牲員工的春節假期，綁上國產芯片，宣傳效果很好。&lt;br&gt; 2、拉人頭病毒傳播，邀請碼直接送代金券，拉人頭在小紅書上快速形成病毒式擴散。&lt;/p&gt; 
&lt;p&gt;尤洋認為，2 月 12 日 superclue 發佈評測把硅基流動的 API 性能排到倒數第一，這很公平；從 pr 稿來看，硅基流動有 15 億的代金券需要兌現，但是這家公司只有 1-2 億的現金，風險很大。&lt;/p&gt; 
&lt;p&gt;尤洋不太相信硅基流動工程師的水平高於英偉達和 SGLang/vLLM 的頂尖工程師。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2068484324f86fbc8c0e03d41da3e8a7342.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;袁進輝第一時間進行了回應，一方面強調了硅基流動一系列動作背後的思路，另一方面直接抖出「潞晨代碼抄襲」的舊案。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-131e5dd073d8aa98e0146931f27b1bd3397.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0bccb574a6ddbdd7dd8607372263b2a63f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ab6ab01c5062ee007aa8128525e4b012ba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPTrxfca5HnQa30C4_k2Thw&quot; target=&quot;_blank&quot;&gt;ColossalAI 重大 Bug 揭祕：DeepSeek-R1 模型微調陷阱&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjcQPmYifLXzgW-UBuwA0jQ&quot; target=&quot;_blank&quot;&gt;維護創新：對潞晨雲算力雲平台的公開信&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;尤洋立馬在朋友圈轉發袁進輝的朋友圈截圖並回應：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「代碼都是潞晨 CTO 負責的，抄襲代碼事件後，璐晨 CTO 離職，加入了袁進輝老師的公司。你説可笑不可笑？」&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/152446_8T1l_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d47d3dbc1f62cf976348dc613f52bc28dde.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;差不多同一時間，尤洋的潞晨科技&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4WZ4nlFBei-1bdp7xJuBzw%3Ffrom%3Dgroupmessage%26scene%3D1%26subscene%3D10000%26sessionid%3D1740817599%26clicktime%3D1740827769%26enterid%3D1740827769%26ascene%3D1%26fasttmpl_type%3D0%26fasttmpl_fullversion%3D7622559-en_US-zip%26fasttmpl_flag%3D0%26realreporttime%3D1740827769421&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;將在一週後停供 DeepSeek API。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/143932_QGxE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在這期間，潞晨科技前 CTO 也針對抄襲代碼事件&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13752772042%2Fanswer%2F113786841913&quot; target=&quot;_blank&quot;&gt;揭露了一些往事&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1334&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0303/153806_xSWP_2720166.png&quot; width=&quot;1344&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;針對前 CTO 發文，尤洋&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fpin%2F1879419844941816823&quot; target=&quot;_blank&quot;&gt;回覆&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;928&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0303/153953_GcN1_2720166.png&quot; width=&quot;1428&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;次日（3 月 2 日）早上，尤洋向 DeepSeek 道歉：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-36027c94f1fd05eea0fc7e48fd0f697869f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;今日（3 月 3 日），尤洋再度&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fpin%2F1879818683184034076&quot; target=&quot;_blank&quot;&gt;回應&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原本只是討論 MAAS 盈利模式的測算，我就在跟 DeepSeek Infrastructure 團隊的技術探討中顯得很張揚，不是很有禮貌。現在微博小紅書知乎上到處都是對我個人或我的創業公司的人身攻擊和無端指責，我沒有精力一條一條地解釋。&lt;/p&gt; 
 &lt;p&gt;我跟 DeepSeek 的辯論我又沒有説錯，我的計算和分析都沒有問題，只是語氣不太好以及和技術無關的言論措辭不準確，一晚上幾十個人讓我道歉。&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a5a9c4469855baf3f01edf40e9e9acc63be.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;相關鏈接&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F27181462601&quot; target=&quot;_blank&quot;&gt;DeepSeek-V3 / R1 推理系統概覽&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13752772042%2Fanswer%2F113786841913&quot; target=&quot;_blank&quot;&gt;如何看待尤洋對 DeepSeek 成本文章的回應以及開團硅基流動&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13759294910&quot; target=&quot;_blank&quot;&gt;如何評價北京潞晨科技尤洋稱「deepseek 應該感謝美國恩情」？&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F13751256341&quot; target=&quot;_blank&quot;&gt;DeepSeek 和尤洋對模型服務成本的測算方式差別在哪裏？對 AI 產業有什麼參考意義？&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336640</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336640</guid>
            <pubDate>Thu, 27 Feb 2025 07:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>周鴻禕：人工智能將重塑所有行業，AI 安全需要「以模製模」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;em&gt;&lt;span style=&quot;color:#000000&quot;&gt;證券時報記者，王小偉&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作為全國政協委員，360 集團創始人周鴻禕今年第八年參加全國兩會。他關注的方向是人工智能和安全兩大主題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周鴻禕認為，人工智能將重塑所有行業，企業應該從找場景、打造專業知識庫、打造智能體、接入辦公流程等四個方面擁抱人工智能。他呼籲，國家對大模型發展實行柔性監管，更加包容審慎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於人工智能發展同步伴生的安全問題，周鴻禕認為，傳統網絡安全已經無法應對新挑戰，應由既懂安全又懂 AI 的企業牽頭，以模製模，通過打造安全大模型來解決大模型的應用安全問題。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;企業擁抱 AI「四步走」&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在周鴻禕看來，人工智能將重塑所有行業，每個行業都能找到降本增效的地方；對個人來説，則可以擁有自己的專業助手。「過去我們軟件、APP 經常是接收指令，完成一個功能。未來人工智能的模式，會像跟一個顧問一樣交流，傾訴問題，表達想法，通過多輪討論，幫個人找到答案或啓發。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;產業層面的改變會更大。他以醫療醫藥產業舉例分析説，醫院運營等傳統行業，人工智能可以通過加速數字化改造和智能化升級，來提升效率，比如使病人候診的時間縮短很多倍。生物製造等新興產業，用人工智能可以成為研究工具和範式。基因抗癌等領域則屬於 AI for Science（科學智能），用大模型這種算法模式套到生物學裏，變成生物學研究的工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「AI 的應用範圍非常多，成為個人助理只用到它 5% 的功能；更重要的是和產業結合。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周鴻禕建議，企業應該從四個方面擁抱人工智能。第一，找場景，需要大模型來解決效率低、成本高、體驗差的問題。第二，需要打造專業知識庫，在企業的數據庫裏、老闆的腦子裏、大家的開會記錄裏，都有很多隱藏的知識。第三，要打造智能體，比照數字員工。第四，通過企業的工作流軟件把智能體接到企業的 OA 辦公流程裏，企業應用才能做起來。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年春節期間，DeepSeek 在全球異軍突起，成為了 AI 發展史上的重要里程碑。在周鴻禕看來，DeepSeek 最大的成果不僅是讓中國大模型在技術上趕上了美國大模型，同時在中國用戶、企業和政府中做了一次人工智能的普及教育。由於 DeepSeek 免費、開源等特性，政府企業紛紛開始採用 DeepSeek 在內部降本增效，加速了中國爆發 AI 產業革命的步伐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「DeepSeek 對中國 AI 產業帶來最大的影響，是讓產業玩家各自歸位，否則大家一窩蜂地‘百模大戰’，等於都在造輪子。倘若都希望做通用大模型，都做 AGI，誰的卡也不夠，誰的數據也不足。」周鴻禕説，如今，連騰訊、百度都宣佈引入 DeepSeek。DeepSeek 做得好，就由它來做基座模型；其他廠商就不用重複造輪子，不用重複耗費算力；雲服務商也不用自己開發算力，可以直接用 DeepSeek 做服務，而且價格可以做得很便宜，因為沒有研發成本。他判斷，未來很多小應用都會做起來。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周鴻禕呼籲，就像「避風港原則」曾帶給互聯網巨大的產業發展機會，國家對大模型發展實行柔性監管，更加包容審慎，這樣中國人工智能才能藉助 DeepSeek 的機會實現更長遠的發展。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;「以模製模」應對安全挑戰&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年兩會提案中，周鴻禕還關注到「硬幣的另一面」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「DeepSeek 作為基座模型，存在着幻覺、提示注入攻擊等問題。同時，大模型要在企業內部真正發揮作用，還需要連上企業的專業知識庫、打造智能體，調用企業各種 IT 系統，這進一步加劇了安全風險。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;當大模型滲透率提升時，應用安全問題也迫在眉睫。周鴻禕認為，網上現在對 DeepSeek 等大模型安全問題，還是當成一個傳統 IT 設備看待。這個思路是過時的，傳統網絡安全的解題方法解決不了人工智能的安全問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，他建議，應由既懂安全又懂 AI 的企業牽頭，以模製模，通過打造安全大模型來解決大模型的應用安全問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在周鴻禕看來，人工智能的安全問題包括多個層面。比如，基座模型的安全問題，是如何在 AI 領域防止幻覺。「DeepSeek 用互聯網的知識庫來做校正、企業裏應用連上專有知識庫校正等，一部分幻覺可以通過知識庫來解決。同時，大模型很容易被 PUA，這是比較嚴重的問題，是基座模型的問題。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;再比如，大模型應用需要建立知識庫，尤其在企業應用，單靠提示詞是解決不了的。而一旦把企業很重要的資料放到知識庫裏餵給大模型了，大模型又會如實地把知識庫裏能看到的資料告訴任何人，這就會存在數據安全問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智能體的安全、知識數據的安全、客戶端的安全、基座模型的安全，構成人工智能安全的新領域。周鴻禕認為，解決的關鍵問題是「以模製模」——專門做安全大模型，用聰明的大模型智力能力去管理知識庫的使用，去管理智能體的調用，去管理基座模型的「胡説八道」和對人的「PUA 攻擊」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「幻覺是一把雙刃劍，是大模型具備真智能的體現，是走向 AGI 的基礎，它讓大模型體現出更多的創造性和想象力，能夠在科研領域發揮重要作用。」周鴻禕強調，大模型幻覺很難消除，但已經通過多個大模型交叉驗證、搜索矯正以及企業知識庫比對等方式進行了糾正。在大模型產業高速發展的過程中，不發展是最大的不安全，所以不能因為大模型的幻覺問題就因噎廢食。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;讓技術轉化為新質生產力&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「應該正確認識 AI 安全問題，不能誇大也不能忽視。」周鴻禕強調，不發展是最大的不安全，必須要抓住 AI 這次工業革命的機會，提升生產力，包括讓科技普惠在每個人身上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於網信安全產業競爭格局，周鴻禕表示，一直以來，我國安全行業內卷嚴重，很多廠商只是一味的賣硬件軟件，客戶也無法得到想要的安全服務，致使行業面臨普遍性經營困境，造成客戶和廠商雙輸的局面。同時，各種高級別攻擊日益嚴重，企業不只需要一個「安全盒子」，更需要高級網絡安全專家協助進行數據分析研判、數據追蹤及事件處置。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為瞭解決這個困境，周鴻禕認為，通過 SaaS 的方式來為更多企業提供安全服務，企業不僅可以直接體驗安全服務的效果，投入成本也降到了五分之一甚至十分之一。因此，周鴻禕在今年兩會上也會呼籲國家從政策上支持採購安全服務，特別是鼓勵採購 SaaS 化安全服務，實現安全的普惠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「築牢網絡安全根基，是為大模型發展鋪路；而解決 AI 應用安全與幻覺問題，則是讓技術真正轉化為新質生產力。」周鴻禕表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在記者採訪中，周鴻禕還談到了對 360AI 產品的未來規劃。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他介紹，自己一直都有危機感，搜索本來就是一個巨頭林立的賽道，公司要想辦法把納米 AI 搜索做得比 DeepSeek 好。「公司產品引入了 DeepSeek 以及國內其他 16 家一共 50 種模型，通過這些模型的協作，有的擅長改寫，有的擅長總結，有的擅長推理和分解任務。DeepSeek 春節期間 7 天新增用戶級別以億計算，我們 15 天漲了 2000 萬手機用戶。現在 PC 端 360 的產品流量很大，我們會耐心地把 PC 上再轉出來至少上千萬用戶。有了很好的基礎之後，剩下的問題就是要仔細打磨用戶的體驗和把各種深度的工具做好。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336639</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336639</guid>
            <pubDate>Thu, 27 Feb 2025 07:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>NVIDIA 在 2024 年出貨十億個 RISC-V 核心的背後</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在最近的 RISC-V 北美峯會上，NVIDIA 多媒體架構副總裁 Frans Sijstermans 深入闡述了 NVIDIA 選擇 RISC-V 作為其嵌入式微控制器架構的原因，以及它如何成為其產品成功的重要組成部分。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;背景：NVIDIA 從零到十億個 RISC-V 核心的歷程&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 與 RISC-V 的歷史可以追溯到 2016 年。當時，NVIDIA 開始將其內部的 Falcon 微處理器（用於 GPU 產品的邏輯控制）轉向新的架構。在評估了多種架構後，NVIDIA 選擇了 RISC-V ISA，並自此開始將 RISC-V 微控制器添加到其產品中，逐步替換舊版 Falcon。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在其 10 年的生命週期中，NVIDIA 估計出貨量約為 30 億個 Falcon 處理器，預計這一轉型最終將導致數十億個 RISC-V 處理器的出貨。通常，每個 NVIDIA 芯片包含 10 到 40 個 RISC-V 核心，具體數量取決於配置。2024 年，基於出貨的總芯片數量，NVIDIA 的 RISC-V 處理器出貨量超過了十億個。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;自 RISC-V 社區首次會議以來，NVIDIA 一直是該社區的積極成員，並且幾乎一直在董事會層面擁有代表權。NVIDIA 參與了許多技術工作組，不僅貢獻和分享自己的工作，還從其他社區成員的貢獻中受益，同時還參與了 RISE 軟件組織。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管如此，NVIDIA 並不常與 RISC-V 聯繫在一起，這可能是因為其許多工作都是內部進行的，儘管重要，但大多與面向客戶的產品無關。RISC-V 在 NVIDIA 產品組閤中主要涉及三個關鍵領域：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能級控制器，包括視頻編解碼器、顯示器、攝像頭、內存控制器（培訓）、芯片間接口和上下文切換。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;芯片/系統級控制，包括資源管理、電源管理和安全性。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;數據處理，包括網絡中的數據包路由以及 DLA（非 GPU）中的激活和其他深度學習網絡層。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 的 RISC-V 核心&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 從僅支持 32 位的 Falcon 核心過渡到 RISC-V 的初衷是為了滿足 64 位能力的需求。他們的第一個 RISC-V 開發是一個相對普通的雙發射亂序 RISC-V 核心，配備標準擴展，並可作為多處理器版本部署。隨後，他們還為面積受限的應用添加了 32 位版本，並增加了一個 1024 位向量單元的向量處理器。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;270&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3191fcdb0cf75d8a4eb715d8d266d2d5b3.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 還開發了幾個自定義擴展，有些是特定於 NVIDIA 的，另一些則對一般用戶有益。例如，2kB 頁面大小擴展是 NVIDIA 獨有的，能夠提高傳統軟件性能 50%。同樣，64 位地址擴展在大規模系統中非常有用，如數據中心，其內存是分佈式且相距甚遠。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，他們的指針掩碼擴展在安全和保護應用方面具有廣泛的潛力。因此，NVIDIA 將該擴展提交給 RISC-V 標準，並獲得批准，現在已被許多社區成員使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 還擁有額外的擴展，可實現通用功能、安全性和性能，雖然這些擴展在技術上並不特別先進，但對於整個系統來説至關重要。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;RISC-V 支持的子系統&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 的 SoC 使用自己的 RISC-V 子系統，名為 Peregrine。除了 RISC-V 核心外，它還包括其他外設，如 DMA 和安全 IP。Peregrine 對 NVIDIA 至關重要，因為它允許他們選擇和重用 30 多個系統控制和管理應用，而無需每次都進行獨立開發。RISC-V 架構使 NVIDIA 具備靈活性和模塊化，能夠根據需求配置子系統。例如，他們可以選擇 32 位或 64 位核心，並添加特定工作負載所需的擴展，從而最大化開發重用和投資回報。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;261&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e6d5efcf21fdd145bf9f47617faa322fab6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;類似地，在軟件方面，所有 30 多個應用使用單一堆棧，這使得諸如引導、操作系統、分離內核和應用程序庫等項目的重用變得顯著。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;261&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f29d3484f956627b0681c3d8db7e98230d6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 同樣致力於使其產品儘可能安全，內部設有一支進攻性安全團隊，作為「黑客」積極尋找設計中的弱點、漏洞和錯誤。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Peregrine 子系統的核心組件是分離內核，可以被視為一個非常基礎的虛擬機監控器。它將系統劃分為不同的獨立部分，便於單獨驗證。用戶可以在不同的分區上運行不同的軟件。例如，符合 ASIL-D 認證的安全合規應用可以在一個分區上運行，而另一個非認證應用可以在另一個分區獨立運行。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;275&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-18a85a32c31897f9d702222b068398b3f6f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;應用實例&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;NVIDIA 擁有 30 多個使用 RISC-V 核心的系統控制和管理應用，並且可以根據具體用例靈活部署。以下詳細介紹了其中兩個應用程序。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;首先，GPU 系統處理器（GSP）為 NVIDIA 的軟件開發方式帶來了根本性變化。GSP 是位於 GPU 頂部的處理器，負責創建 GPU 可執行的抽象。主處理器和內核驅動不再使用 GPU 內部的各個控制寄存器，而是直接與 GSP 通信，GSP 將這些高級命令轉換為低級控制寄存器的操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;275&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6d231c3a77b7674b3301eaaef98ab82b820.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;GSP Peregrine 配備 64 位 RISC-V 處理器，提供單線程和多線程版本。最重要的是，GSP 可以完全訪問 GPU 中的所有內容，包括內存和顯示控制器，這些在軟件中需要非常仔細地管理。從軟件的角度看，用戶可以部署具有內核驅動和多個訪客虛擬機的主處理器。訪客虛擬機在 GSP 上具有相應的 vGPU 運行時分區，而分離內核確保它們之間相互隔離，不會干擾。資源管理器會根據需要切換不同的訪客，並確保資源分配公平。這一功能支持了諸如保密計算等特定用例，在這種情況下，GPU 被分配給訪客，且不會受到虛擬機監控器的影響。在這種情況下，RISC-V 架構因其特定的隔離能力和 NVIDIA 自身的擴展特性而對安全性至關重要。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;第二個支持 NVIDIA RISC-V 的應用程序是深度學習加速器，作為一些專用 AI SoC 的一部分。它本質上是一個圖處理編程的推理引擎。例如，ONNX 程序表示深度學習網絡中處理的層圖。它使用標準的 RISC-V 編譯器，將內核代碼編譯為可執行文件。在此基礎上，還有一個 RVV 編譯器，將其轉換為可加載格式。也可以將不同內核組合成單一內核，以實現最優執行。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;DLA 並不會在 RISC-V 處理器上運行所有東西，主卷積核心和矩陣乘法器是獨立的實體。在下圖的硬件結構中，有兩個 RISC-V 處理器，一個是控制核心，簡單的 32 位單元，另一個是 NVRVV，這是一種 1024 位向量單元。還包括一個卷積核心，總共六個硬件引擎。例如，Rubik 是一個智能 DMA 數據轉換器，負責數據傳輸，而 RISC-V RVV 向量處理器用於大多數非矩陣乘法的層。簡而言之，它是一個在 DLA 上運行的完整 ONNX 實現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;259&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e14ba4b4de454267340f43ce5d702dc2803.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;總結：為何 RISC-V 適合 NVIDIA&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;總結來説，NVIDIA 選擇 RISC-V ISA 以及它取得成功的原因有 5 個：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;定製化&lt;/strong&gt;：定製能力至關重要，使 NVIDIA 能夠最大化使用硅片。RISC-V 的許可模型允許他們使用基本 ISA 作為構建塊，添加適合特定應用需求的擴展和配置文件。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;硬件/軟件協同設計&lt;/strong&gt;：確保硬件針對軟件負載進行了優化，從而提升效率和性能。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;配置選項&lt;/strong&gt;：標準的「現成」處理器往往對應用要求過高。通過 RISC-V，NVIDIA 可以通過配置實現僅需的特定擴展來節省成本和開發努力。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;自定義擴展&lt;/strong&gt;：允許 NVIDIA 添加特定功能、安全性和性能等要求。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;統一的硬件和軟件架構&lt;/strong&gt;：允許 NVIDIA 在其 30 多個應用程序中重複使用資產，而無需為每個應用程序創建或調整新架構。減少開發工作量、簡化部署並降低成本。&lt;/span&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;詳情可查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Friscv.org%2Fblog%2F2025%2F02%2Fhow-nvidia-shipped-one-billion-risc-v-cores-in-2024%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336623/nvidia-shipped-one-billion-risc-v-cores-2024</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336623/nvidia-shipped-one-billion-risc-v-cores-2024</guid>
            <pubDate>Thu, 27 Feb 2025 06:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國首款 AI IDE：Trae 國內版發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;字節跳動技術團隊微信公眾號發文宣佈，中國首個 AI 原生集成開發環境（AI IDE）Trae 國內版正式上線，配置 Doubao-1.5-pro，並支持切換滿血版 DeepSeek R1、V3 模型。&lt;/p&gt; 
&lt;p&gt;Trae 國內版不僅針對中國開發場景和習慣進行了一些優化，後續還即將支持模型自定義，用戶可以根據自己的喜好，接入合適的大模型 APP。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;346&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-377de0bceee6c5821234bc072a1e762f09b.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「作為更貼閤中國開發者開發習慣與開發場景的 AI IDE，Trae 以動態協作為核心，打造了一種人機協同，人與 AI 互相增強的全新開發體驗，助力開發者高效應對複雜技術挑戰，釋放創新潛能。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根據介紹。Trae 定位為「&lt;strong&gt;智能協作 AI IDE&lt;/strong&gt;」，以「人機協同、互相增強」為核心理念，對代碼補全，代碼理解，Bug 修復，基於自然語言生成代碼等開發過程全場景都有非常好的適應性，不僅是一個開發工具，更是一位全天候開發「拍檔」。Trae 希望成為更可靠的、值得開發者信賴的「AI 工程師」&lt;strong style=&quot;color:#3e3e3e&quot;&gt;（T&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;he&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;&amp;nbsp;R&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;eal&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;&amp;nbsp;A&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;I&amp;nbsp;&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;E&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;ngineer&lt;/span&gt;&lt;strong style=&quot;color:#3e3e3e&quot;&gt;）。&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全新 Builder 模式能充分利用 AI 的能力，無論是初學者還是資深的開發者，都能夠輕鬆通過自然語言描述迅速的，端到端的生成應用：只需要用簡單的語言描述需求，Trae 就可以迅速搭建起項目框架，還能持續進行調優修改，產出可用代碼。這種智能化的&quot;思想到代碼&quot;直通車能力，全程助力開發者將需求端到端完美落地，極大縮短了項目籌備週期，為高效開發奠定堅實基礎。&lt;/li&gt; 
 &lt;li&gt;在代碼理解維度，Trae 的能力邊界實現了質的突破，憑藉對開發項目上下文的極致理解，深入剖析代碼倉庫，實時獲取 IDE 中的各種環境上下文，精準洞察開發者的需求，從而為開發過程提供最為契合、準確的解決方法。&lt;/li&gt; 
 &lt;li&gt;針對需求溝通效率問題，Trae 的實時代碼續寫技術可基於開發項目整體上下文進行智能補全，提升編碼效率，而在交互體驗方面，開發者可以便捷地將 AI 生成的代碼一鍵應用到多個模塊，還能根據實際需求隨時靈活調整指令，並實時預覽 AI 生成代碼的前端效果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;詳情可訪問官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ftrae.com.cn&quot; target=&quot;_blank&quot;&gt;trae.com.cn&lt;/a&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336617</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336617</guid>
            <pubDate>Thu, 27 Feb 2025 05:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>聯想將推出 AI PC 產品矩陣、打造企業級 AI 基礎設施</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今天，聯想發文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3uzAYrlxpvr_me74s2Cj5g&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;，將在 3 月 3 日-6 日舉辦的 MWC2025 上，正式發佈一系列突破性的混合式人工智能技術。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/113731_tAhf_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI PC 產品矩陣&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;全新推出 ThinkPad T14s 2 合 1 筆記本、配備獨立 NPU 的 ThinkBook 16p Gen 6，以及 Yoga Pro 9i Aura。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/114026_WZsV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;em&gt;▲ 配備獨立 NPU 的 ThinkBook 16p Gen 6&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;前瞻性概念產品&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;包括 ThinkBook Flip AI PC，採用創新外摺疊屏設計；全新聯想 Magic Bay 配件；YOGA 太陽能筆記本電腦概念機，搭載太陽能供電技術，探索可持續計算未來。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/114140_frh2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/114240_nsMZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聯想 AI Now：端側 AI 智能體，可提供更自然、高效的個性化交互體驗。&lt;/li&gt; 
 &lt;li&gt;超級互聯 Smart Connect 2.0：一款統一數字生態的軟件解決方案，實現聯想 AI Now 與 moto ai 跨設備協同，為用戶帶來無縫銜接的智能體驗。·&lt;/li&gt; 
 &lt;li&gt;ThinkEdge SE100：高性價比的邊緣推理服務器，讓企業級 AI 計算觸手可及，助力智能轉型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3uzAYrlxpvr_me74s2Cj5g&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/3uzAYrlxpvr_me74s2Cj5g&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336601</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336601</guid>
            <pubDate>Thu, 27 Feb 2025 03:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「智御」個人信息保護大模型正式接入 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在工業和信息化部信息通信管理局的指導下，中國信息通信研究院（簡稱「中國信通院」）研發的「智御」個人信息保護大模型近日已正式接入 DeepSeek，實現了個人信息保護領域專業語義精準捕獲、多維信息關聯分析及持續進化的合規態勢感知綜合能力躍升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;280&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6c4a59474e0245277820404e2542af27d22.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，「智御」發佈以來，面向移動互聯網應用開發者、分發平台、終端廠商、檢測機構等行業上下游企業，提供多模態、多樣化的合規諮詢、風險檢測、代碼修復、決策支持等服務，已輸出合規優化建議 7200 餘條，有效助力企業提升個人信息保護意識和能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次「智御」完成與 DeepSeek 的融合升級後，藉助其卓越理解和推理能力，顯著提升了語義意圖識別和多源異構數據處理能力，能夠更精準地解析行業用戶需求，支持處理更復雜的場景任務，提供更加智能、高效、便捷的服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;下一步，中國信通院將持續深化技術攻關、創新實踐，加速拓展「智御」在行業領域的落地應用，輸出可複製、可推廣的個人信息保護智能解決方案，進一步為個人信息保護工作賦能賦智。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336600</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336600</guid>
            <pubDate>Thu, 27 Feb 2025 03:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>清華大學將擴招本科生，重點培養「AI+」人才</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYvq6vbM5TmaHeLpSPMPEyA&quot; target=&quot;_blank&quot;&gt;據新華網 3 月 2 日消息&lt;/a&gt;&lt;/u&gt;，清華大學決定有序適度擴大本科招生規模&lt;strong&gt;，2025 年擬增加約 150 名本科生招生名額&lt;/strong&gt;，同時將成立新的本科通識書院，&lt;strong&gt;着力培養人工智能與多學科交叉的複合型人才&lt;/strong&gt;，提升創新人才自主培養能力，以服務國家戰略需求與社會發展需要。&lt;/p&gt; 
&lt;p&gt;報道指出，該校新增本科生將進入新成立的書院學習。而新成立的本科通識書院將匯聚清華優勢學科資源，突出人工智能技術在教育教學、科研創新中的驅動作用，立足人工智能與多學科交叉融合，着力探索人工智能賦能教育教學範式，以培養具有深厚人工智能素養、掌握人工智能技術、具備突出創新能力的複合型人才。&lt;/p&gt; 
&lt;p&gt;此外，清華大學教務處相關負責人介紹，目前學校已在人工智能人才培養和人工智能賦能教育方面取得階段性成果。&lt;/p&gt; 
&lt;p&gt;具體來説，首批已有 117 門試點課程、147 個教學班開展人工智能賦能教學實踐，開發出智能助教、備課輔助、智能批改等多種功能場景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336597</guid>
            <pubDate>Thu, 27 Feb 2025 03:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>商湯董事長：建議探索「科創算力貸」破解痛點</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;央行等金融管理部門聯合全國工商聯日前召開金融支持民營企業高質量發展工作座談會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;當前，民營企業訴求主要包括，希望給予企業無本續貸貸款展期等信貸支持，希望獲得與企業生產週期匹配的中長期資金支持，希望能針對企業特點開發新型金融產品，以及在債券融資中能夠獲得與同評級國企同樣的票面利率待遇等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;商湯科技董事長兼首席執行官徐立表示，AI 技術和產業發展對資金的需求巨大，研發成本高昂、週期長、風險大，許多企業在融資和貸款方面面臨困難。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;徐立建議，針對 AI 行業給予更加精準的支持政策和措施。首先，探索「科創算力貸」，破解 AI 基礎設施融資痛點；其次，進一步放開股權融資、股債融合等股權融資渠道；另外，創新貸款工具，支持民營企業多元化融資。例如，利用算力資產為基礎，發行「科創算力債券」，吸引長期資金支持，專項用於算力基建。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336596</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336596</guid>
            <pubDate>Thu, 27 Feb 2025 03:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘋果或將回歸路由器市場：支持 Wi-Fi 7、自研芯片是亮點</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.macrumors.com%2F2025%2F03%2F01%2Fapple-airport-could-return-in-unexpected-way%2F&quot; target=&quot;_blank&quot;&gt;據 MacRumors 報道&lt;/a&gt;&lt;/u&gt;，蘋果為了加大智能家居產品的用戶羣體，或將回歸路由器市場。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eadbf2f9a578cd9b0628866d49ad1dc143a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，蘋果於 1999 年推出了 AirPort 系列首款產品，而後 AirPort 系列逐漸成為蘋果的路由器產品線，歷經 20 年的發展後，蘋果於 2018 年宣佈停止 AirPort 系列的更新與生產。AirPort 系列包括了 AirPort Express、AirPort Extreme 和 AirPort Time Capsule 時間膠囊等幾款主要設備。&lt;/p&gt; 
&lt;p&gt;在去年 12 月，彭博社記者 Mark Gurman 曾報道，蘋果正在開發自研的 Wi-Fi 藍牙集成芯片，該芯片將會在今年晚些時候推出的新款 Apple TV 和 HomePod mini 中亮相。其中 Gurman 提到，該款芯片十分複雜，理論上可以成為無線網絡的發送器。&lt;/p&gt; 
&lt;p&gt;MacRumors 指出，蘋果目前正在計劃加大對智能家居產品的推廣。報道推測，上述的 Apple TV 和 HomePod mini 未來搭載了蘋果的自研 Wi-Fi 藍牙芯片後，將有機會成為類似 AirPort 系列的路由器產品，而這也將成為蘋果在智能家居市場擴大市場佔比及影響力的一種新方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336592/apple-airport-could-return-in-unexpected-way</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336592/apple-airport-could-return-in-unexpected-way</guid>
            <pubDate>Thu, 27 Feb 2025 02:49:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>榮耀：未來 5 年將投入 100 億美元與夥伴共建 AI 終端生態</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2025 年世界移動通信大會 (MWC) 上，榮耀詳細介紹了其轉型的全新戰略——&quot;榮耀阿爾法計劃&quot;(HONOR ALPHA)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據介紹，&quot;阿爾法計劃&quot;分為三個階段：第一步是智慧手機，第二步是智慧生態系統，第三步是智慧世界。該計劃旨在將內容、服務、芯片、系統全部以人和 AI 設備為中心進行連接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;榮耀 CEO 新任李健宣佈，未來 5 年榮耀將投入 100 億美元，與全球合作夥手共建 AI 設備生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ae450daeb302cd65d509d255d49ccc475e2.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;榮耀發言人向媒體透露，這筆資金將用於將 AI 融入硬件以及開發下一代 AI 代理，投資的另一部分將用於創建&quot;各種 AI 設備的平台&quot;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&quot;這不僅限於我們自己的設備，還包括來自不同合作伙伴的 AI 設備，使不同類型的 AI 設備能夠相互交流，消費者可以有更多選擇和無縫體驗，&quot;榮耀發言人表示。此外，一小部分投資將用於&quot;為 AGI 時代做準備&quot;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336590</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336590</guid>
            <pubDate>Thu, 27 Feb 2025 02:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊元寶電腦版上線，支持 Windows 和 macOS 系統</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&amp;nbsp;3 月 1 日，騰訊 AI 助手「騰訊元寶」&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9V5XtAWdr_eEatKaUok3VQ&quot; target=&quot;_blank&quot;&gt;正式發佈電腦版&lt;/a&gt;&lt;/u&gt;，支持 Windows 和 MacOS 系統。&lt;/p&gt; 
&lt;p&gt;此次發佈的騰訊元寶電腦版面向工作和學習場景打造，旨在幫助用戶減輕負擔、提升效率。除具備與移動端和網頁版一致的核心功能外，電腦版後續還將推出更多便捷功能，如劃詞搜索與翻譯、截圖提問等，進一步提升用戶體驗。&lt;/p&gt; 
&lt;p&gt;電腦瀏覽器打開 yuanbao.tencent.com 即可下載元寶電腦版。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0303/103204_EBpg_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方介紹，騰訊元寶電腦版用戶可以體驗到與手機端、網頁端相同的智能對話能力。不僅能通過 DeepSeek-R1 滿血版和推理模型混元 T1 進行深度思考，也可以通過 DeepSeek-V3 和騰訊混元 Turbo S 快速獲得答案，滿足不同場景下的需求。結合公眾號等騰訊內容源與權威互聯網信息，確保提供的答案時效性更強、可信度更高。&lt;/p&gt; 
&lt;p&gt;此前，騰訊元寶還讓 DeepSeek 具備了讀圖能力，而該功能也完整上線電腦版，用戶隨手截圖或發送任意圖片，元寶都能結合圖片內容給出自己的分析和理解。&lt;/p&gt; 
&lt;p&gt;另外電腦版也支持解析文件，大幅提升文件、論文等閲讀效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336588/tencent-yuanbao-pc</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336588/tencent-yuanbao-pc</guid>
            <pubDate>Thu, 27 Feb 2025 02:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Ai.com 將以 1 億美元出售</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fai-com-is-for-sale-asking-price-100-million&quot; target=&quot;_blank&quot;&gt;據 The Information 報道&lt;/a&gt;&lt;/u&gt;，資深域名經紀人拉里·菲舍爾正在幫僱主尋求出售備受矚目的域名 ai.com，報價高達 1 億美元（摺合人民幣 7 億元）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cb8c4d9cfce15e676fdc256e077d3035846.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，62 歲的菲舍爾已有近 30 年域名交易經驗，曾促成多筆高價域名交易，包括將 Messenger.com 賣給 Facebook、Skincare.com 賣給歐萊雅、Teams.com 賣給微軟以及將 Chat.com 賣給 HubSpot 聯合創始人達梅什·沙阿（後者隨即將其轉售給 OpenAI）。&lt;/p&gt; 
&lt;p&gt;目前 ai.com 域名的所有者保持匿名，僅透露當初購買該域名是因為與自己的縮寫相符，而非看好 AI 的發展。菲舍爾認為 OpenAI、微軟、Google 和 Meta 等科技巨頭或加密貨幣富豪都可能是潛在買家。值得注意的是，目前已知最高域名交易記錄為 MicroStrategy 公司 2019 年以 3000 萬美元出售的 Voice.com。&lt;/p&gt; 
&lt;p&gt;此前，ai.com 多次蹭 AI 公司的熱度，&lt;strong&gt;曾跳轉過 DeepSeek、ChatGPT、xAI，以及 Google Gemini 官網&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;根據域名查詢網站 whois 顯示，ai.com 域名有效期至 2031 年 5 月 5 日，註冊聯繫人顯示來自馬來西亞首都吉隆坡。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336586/ai-com-is-for-sale-asking-price-100-million</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336586/ai-com-is-for-sale-asking-price-100-million</guid>
            <pubDate>Thu, 27 Feb 2025 02:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>穿皮夾克是抄襲英偉達黃仁勳？雷軍回應</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2 月 27 日進行的小米發佈會上，雷軍身着皮夾克引起熱議。3 月 2 日，雷軍在直播中回應此事表示，「皮夾克可能比較容易配得上 Ultra 這種極致駕駛的風格」，「我也沒想到這個皮夾克這麼多人喜歡，還上了熱搜」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-39311cf4b24afe864107f10886ca0fcdcd0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;雷軍回答：「為什麼選皮夾克呢，我是覺得皮夾克可能比較容易配得上 Ultra 這種極致駕駛的風格。所以我們就想到了皮夾克，然後同事們就挑選了三四件，我（從中）挑了一件。我也沒想到這個皮夾克這麼多人喜歡，還上了熱搜。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「其實我在選的時候，我就擔心，我要穿皮夾克肯定很多人説你抄那個 Nvidia 的老闆黃仁勳，好像我在認識黃仁勳之前，每個人家裏是不是都有兩三件皮衣。難道我一穿皮夾克就是抄黃仁勳？我一穿西服就是抄馬斯克？這太滑稽了。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/336585</link>
            <guid isPermaLink="false">https://www.oschina.net/news/336585</guid>
            <pubDate>Thu, 27 Feb 2025 02:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>