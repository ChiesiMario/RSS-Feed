<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 28 Jul 2025 02:43:10 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>中國政府倡議成立世界人工智能合作組織</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中國政府 26 日倡議成立世界人工智能合作組織，初步考慮總部設在上海。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="218" src="https://oscimg.oschina.net/oscnet/up-d0df9652b4e7e21e9148ac6f456ef0f67af.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;記者獲悉，這是中方堅持踐行多邊主義、推動共商共建共享全球治理的重要舉措，也是中方響應全球南方呼聲、助力彌合數字和智能鴻溝、促進人工智能向善普惠發展的實際行動。中方期待世界人工智能合作組織作為重要的國際公共產品，實現以下目標：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;一是深化創新合作，釋放智能紅利。中方願同各國分享中國式現代化帶來的廣闊機遇，將世界人工智能合作組織打造成供需對接平台，破除妨礙世界各國間生產要素流動的壁壘，促進中國同各國以及各國之間的人工智能務實合作，讓人工智能的無限潛力充分釋放，實現共同發展、共同繁榮。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;二是推動普惠發展，彌合智能鴻溝。中方將以世界人工智能合作組織為平台，持續推進落實「加強人工智能能力建設國際合作」聯大決議和《人工智能能力建設普惠計劃》，幫助全球南方國家加強能力建設、培育人工智能創新生態，確保發展中國家在智能化浪潮中平等受益，推動落實聯合國 2030 年可持續發展議程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;三是加強協同共治，確保智能向善。中方將依託世界人工智能合作組織，加強各國之間發展戰略、治理規則、技術標準的對接協調，在充分尊重各國政策和實踐差異性的基礎上，逐步形成具有廣泛共識的人工智能全球治理框架和標準規範，確保人工智能始終沿着人類文明進步的方向發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方倡議成立世界人工智能合作組織旨在加強人工智能領域的國際合作。中方初步考慮該組織總部設在上海，希望利用中國特別是上海人工智能先發優勢，凝聚國際共識，促進務實合作，讓人工智能真正造福全人類。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方將秉持共商共建共享的理念，同有意願加入的國家共同探討相關安排。包括尊重主權原則，堅持平等相待，支持各國結合自身國情開展人工智能合作。遵循聯合國憲章宗旨和原則，支持聯合國發揮人工智能治理主渠道作用，為聯合國及其相關機構的努力提供有益補充。採取開放包容的態度，踐行真正的多邊主義，通過世界人工智能合作組織進一步凝聚共識、促進合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方熱忱歡迎有誠意、有意願的國家積極參與世界人工智能合作組織的籌備工作，共同推進人工智能全球治理和國際合作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362669</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362669</guid>
      <pubDate>Mon, 28 Jul 2025 02:37:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>基於模型蒸餾的大模型文案生成最佳實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;大語言模型在生成高質量文案方面表現優異，然而其巨大的計算資源消耗和存儲需求，使得實際應用尤其是在資源受限場景中的應用充滿挑戰。企業在尋求高效的文案生成時，常常面臨着在性能和資源之間權衡的困境。在這種背景下，模型蒸餾技術為解決這一問題提供了新的思路。模型蒸餾是一種優化技術，旨在通過將知識從大型複雜模型中提取並轉移到更小、計算更高效的模型中，使得這些小型模型能夠在保留大多數性能優勢的情況下顯著降低資源需求。這一技術在大模型文案生成領域的應用，不僅能夠保持生成質量接近原有大模型，還極大地減少了計算成本和部署難度。本文介紹如何使用 EasyDistill 算法框架以及 PAI 產品，實現基於模型蒸餾的大模型文案生成，通過這種方式節省人力成本，同時提高用戶體驗，推動業務的可持續增長。&lt;/p&gt; 
&lt;h2&gt;部署教師大語言模型&lt;/h2&gt; 
&lt;h3&gt;部署模型服務&lt;/h3&gt; 
&lt;p&gt;您可以按照以下操作步驟，部署教師大語言模型生成對應回覆。&lt;/p&gt; 
&lt;p&gt;在 PAI-Model Gallery 選擇 DeepSeek-V3 模型或者其他教師大模型，在模型部署區域，系統已默認配置了模型服務信息和資源部署信息，您也可以根據需要進行修改，參數配置完成後單擊部署按鈕。以 DeepSeek-V3 為例，其模型卡片如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-28df44d9861762bd4497b14e096e764f133.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;模型部署和調用&lt;/h3&gt; 
&lt;p&gt;PAI 提供的 DeepSeek-V3 預置了模型的部署配置信息，可以選擇 SGLang 部署/vLLM 部署/Transformers 部署，用戶僅需提供推理服務的名稱以及部署配置使用的資源信息即可將模型部署到 PAI-EAS 推理服務平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cd9de19c221b06b8a1068309ddcb1fd7c0e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推理服務同樣支持以 OpenAI API 兼容的方式調用，調用示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

models = client.models.list()
model = models.data[0].id
print(model)

def main():
    stream = True
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "你好，介紹一下你自己，越詳細越好。",
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=stream,
    )
    if stream:
        for chunk in chat_completion:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion.choices[0].message.content
        print(result)


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多細節可以參考"一鍵部署 DeepSeek-V3、DeepSeek-R1 模型"。&lt;/p&gt; 
&lt;h2&gt;構建訓練數據&lt;/h2&gt; 
&lt;h3&gt;構建 SFT 訓練數據&lt;/h3&gt; 
&lt;p&gt;您可以按照以下操作步驟，構建 SFT 訓練數據。用戶可以根據如下輸入數據批量調用教師大模型，輸入數據格式如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "instruction": "xxx"
  },
  {
    "instruction": "xxx"
  },
  {
    "instruction": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，instruction 為調用大模型的 prompt，由任務模版和實際輸入數據組成。這裏，我們給出一個任務模版供您參考，實際內容可以根據業務場景和數據特徵進行調整：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;你是短視頻文案生成專家，專注於根據視頻原始標題、視頻內容，生成文案的標題和內容。
你的任務是確保文案與視頻核心內容高度匹配，並且吸引用戶點擊。

要求
1: 信息匹配度：確保文案准確反映視頻核心看點，禁止出現視頻中未呈現的虛構內容。
2. 情緒契合度：文案情緒需與視頻內容保持一致。嚴肅悲傷類內容不要使用搞笑戲謔風格。
3. 內容規範度：確保句意表達清晰、完整、通順、連貫，沒有出現無意義字符。
4. 嚴格按照 JSON 格式輸出：
{
   "title": "",
   "body": ""
}

避免出現情況
1. 標題要求在 10 個漢字以內。
2. 內容要求在 30 個漢字以內。
3. 禁止標題黨，和過度誇張的表述。
4. 不得出現高敏感內容，或者低俗用語。

請嚴格按照 JSON 格式輸出內容，不要在輸出中加入解析和説明等其他內容。

視頻原始標題和視頻內容分別如下所示：
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;給定上述輸入數據，我們可以批量調用教師大模型生成回覆，示例代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import json
from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# 獲取模型
models = client.models.list()
model = models.data[0].id
print(model)

# 讀取輸入數據
def read_input_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

# 調用大模型獲取輸出
def get_model_output(instruction):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": instruction,
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=False,
    )
    return chat_completion.choices[0].message.content

# 處理輸入數據並生成輸出
def process_data(input_data):
    results = []
    for item in input_data:
        instruction = item.get("instruction")
        output = get_model_output(instruction)
        results.append({
            "instruction": instruction,
            "output": output
        })
    return results

# 保存輸出數據到文件
def save_output_data(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump(data, file, ensure_ascii=False, indent=2)

def main(input_file_path, output_file_path):
    input_data = read_input_data(input_file_path)
    output_data = process_data(input_data)
    save_output_data(output_file_path, output_data)
    print("Data processing complete.")

if __name__ == "__main__":
    # 指定你的輸入和輸出文件路徑
    input_file_path = "input.json"
    output_file_path = "output.json"
    main(input_file_path, output_file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;當運行完上述代碼後，我們得到構造好的 SFT 訓練數據，格式如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "instruction": "xxx",
    "output": "xxx"
  },
  {
    "instruction": "xxx",
    "output": "xxx"
  },
  {
    "instruction": "xxx",
    "output": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了保證 SFT 訓練數據集的高質量，我們建議採用如下設置：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練數據量至少應在 3000 條以上，而且需要儘可能覆蓋輸入視頻的各種主題；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成文案的任務模版可以按照實際業務需求進行修改，需要根據明確的業務需求，用自然語言精確描述生成的文案要求達到的效果和避免出現的情況；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為了保證生成文案的高質量，使用的教師大模型底座參數量需要儘可能高，例如使用滿血版的 DeepSeek-V3，一般不需要使用深度思考的模型，例如 DeepSeek-R1 或 QwQ-32B；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在輸入中，視頻的內容可以通過 OCR、ASR 等多種途徑從原始視頻中抽取出來，需要保證抽取出來的內容具有較高的準確性；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建議在生成 SFT 訓練數據集後人工抽樣進行質量校驗，並且根據校驗結果，反覆調整調用大模型的任務模版，以達到滿意的效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;構建 DPO 訓練數據&lt;/h2&gt; 
&lt;p&gt;如果您需要通過 DPO 算法繼續優化較小的學生模型，則需要構造用於 DPO 算法訓練的數據集。我們可以基於構造好的 SFT 訓練數據進行繼續構造流程。其中，DPO 數據格式示例如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  },
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  },
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，prompt 對應 SFT 訓練數據集的 instruction，chosen 可以使用 SFT 訓練數據集的 output 字段，rejected 為 DPO 算法中提供的低質量文案。在 DPO 算法的訓練過程中，我們鼓勵大模型生成高質量的 chosen 文案，懲罰大模型生成類似 rejected 的文案。因此，我們需要額外生成 rejected 文案。我們可以同樣採用教師大模型生成 rejected 文案，利用 SFT 訓練數據集作為輸入，我們需要改變上文使用的任務模版。這裏我們給出一個示例供您參考：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;你是視頻文案生成初學者，嘗試根據視頻原始標題、視頻內容生成不夠吸引人的文案標題和內容。
目標是生成邏輯不清、可能誤導、不夠吸引用戶點擊的文案。

要求
1. 信息匹配度：不要求準確反映視頻核心看點，甚至可以與視頻內容無關。
2. 情緒契合度：文案情緒可以與視頻內容不一致。
3. 內容規範度：表達可以不清晰、不完整、不通順、不連貫，可以出現無意義字符。
4. 可不用嚴格按照 JSON 格式輸出。

視頻原始標題和視頻內容分別如下所示：
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我們同樣給出一個批量推理的腳本，生成上述數據，我們假設輸入數據格式與 SFT 訓練數據集相同，但是 instruction 字段採用上文生成低質量文案的任務模版：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import json
from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# 獲取模型
models = client.models.list()
model = models.data[0].id
print(model)

# 讀取輸入數據
def read_input_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

# 調用大模型獲取低質量文案
def get_rejected_output(instruction):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": instruction,
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=False,
    )
    return chat_completion.choices[0].message.content

# 處理輸入數據並生成輸出
def process_data(input_data):
    results = []
    for item in input_data:
        instruction = item.get("instruction")
        chosen = item.get("output")
        rejected = get_rejected_output(instruction)
        results.append({
            "prompt": instruction,
            "chosen": chosen,
            "rejected": rejected
        })
    return results

# 保存輸出數據到文件
def save_output_data(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump([data], file, ensure_ascii=False, indent=2)

def main(input_file_path, output_file_path):
    input_data = read_input_data(input_file_path)
    output_data = process_data(input_data)
    save_output_data(output_file_path, output_data)
    print("Data processing complete.")

if __name__ == "__main__":
    # 指定你的輸入和輸出文件路徑
    input_file_path = "input.json"
    output_file_path = "output.json"
    main(input_file_path, output_file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了保證 DPO 訓練數據集的高質量，我們建議採用如下設置：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練數據量至少應在 1000 條以上，而且需要儘可能覆蓋輸入視頻的各種主題；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成 rejected 文案的任務模版可以按照實際業務需求進行修改，需要和 chosen 文案在質量上有明顯的差距，特別可以注重生成 chosen 文案中避免出現的情況（即負向樣本）；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為了保證生成文案質量滿足要求，使用的教師大模型底座參數量需要儘可能高，例如使用滿血版的 DeepSeek-V3，一般不需要使用深度思考的模型，例如 DeepSeek-R1 或 QwQ-32B；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在輸入中，視頻的內容可以通過 OCR、ASR 等多種途徑從原始視頻中抽取出來，需要保證抽取出來的內容具有較高的準確性；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建議在生成 DPO 訓練數據集後人工抽樣進行質量校驗，並且根據校驗結果，反覆調整調用大模型的任務模版，以達到滿意的效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;通過 SFT 算法蒸餾訓練較小的學生模型&lt;/h2&gt; 
&lt;p&gt;接下來我們使用 EasyDistill 算法框架，利用準備好的訓練數據，訓練學生模型。在 PAI-DSW 中，根據"&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1664823" title="阿里雲人工智能平台 PAI 開源 EasyDistill 框架助力大語言模型輕鬆瘦身" target="_blank"&gt;阿里雲人工智能平台 PAI 開源 EasyDistill 框架助力大語言模型輕鬆瘦身&lt;/a&gt;"一文安裝 EasyDistill 算法包後使用如下命令進行 SFT 模型訓練：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python easydistill/kd/train.py --config=sft.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，sft.json 為 SFT 蒸餾訓練的配置文件，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
  "job_type": "kd_black_box_api",
  "dataset": {
    "labeled_path": "sft_train.json",
    "template" : "chat_template_kd.jinja",
    "seed": 42
  },
  "models": {
    "student": "model/Qwen/Qwen2.5-0.5B-Instruct/"
  },
  "training": {
    "output_dir": "result_sft/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "save_steps": 1000,
    "logging_steps": 1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
} 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，sft_train.json 為 SFT 訓練數據集，model/Qwen/Qwen2.5-0.5B-Instruct/為學生模型路徑，這裏以 Qwen2.5-0.5B-Instruct 為示例，result_sft/為模型輸出路徑。您可以根據實際需要，在 training 字段中調整訓練使用的超參數。&lt;/p&gt; 
&lt;h2&gt;通過 DPO 算法繼續優化較小的學生模型&lt;/h2&gt; 
&lt;p&gt;由於 SFT 訓練過程中提供給學生模型唯一的正確答案，因此這種訓練存在兩個限制條件：一為模型的泛化能力有限，二為缺乏更加細粒度的模型對齊。DPO 算法通過提供 chosen 和 rejected 的模型回覆，進一步提升模型的對齊能力。根據準備好的 DPO 訓練數據，我們在 SFT 訓練完的模型 Checkpoint 基礎上，使用 EasyDistill 的如下命令，進行 DPO 模型訓練：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python easydistill/rank/train.py --config=dpo.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，dpo.json 為 DPO 蒸餾訓練的配置文件，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-{"&gt;  "job_type": "rank_dpo_api",
  "dataset": {
    "labeled_path": "dpo_train.json",
    "template" : "chat_template_kd.jinja",
    "seed": 42
  },
  "models": {
    "student": "result_sft/"
  },
  "training": {
    "output_dir": "result_dpo/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "save_steps": 1000,
    "logging_steps": 1,
    "beta": 0.1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，dpo_train.json 為 SFT 訓練數據集，result_sft/為 SFT 訓練之後的學生模型路徑，result_dpo/為模型輸出路徑。您可以根據實際需要，在 training 字段中調整訓練使用的超參數。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5583868/blog/18685835</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18685835</guid>
      <pubDate>Mon, 28 Jul 2025 02:25:07 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>字節跳動 AI Agent 平台釦子擁抱開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;字節跳動旗下 AI Agent 開發平台釦子（Coze）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6jGoaE29S2oOrywCAB8zMg" target="_blank"&gt;宣佈&lt;/a&gt;正式擁抱開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;釦子旗下共有四款子產品：「釦子空間」、「釦子開發平台」、「釦子羅盤」 及 Eino。目前，釦子開發平台 （Coze Studio）與釦子羅盤 （Coze Loop）已在 Apache 2.0 許可證下開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="214" src="https://oscimg.oschina.net/oscnet/up-7117b00b0aec66eedb8cac42206d8cab2fa.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Coze Studio 是一個一站式的 AI Agent 可視化開發工具，此次開源的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;完整的工作流（Workflow）引擎：只需拖拽節點，就能輕鬆編排出複雜的業務邏輯。無論是簡單的問答機器人，還是需要執行多步任務的 Agent，都能輕鬆實現。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;插件（Plugin）核心框架：開放了插件的定義、調用與管理機制。你可以便捷地將任何第三方 API 或私有能力封裝成插件，無限擴展 Agent 的能力邊界。還提供了官方開源插件作為參考，讓用戶立刻上手。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;開箱即用的開發環境： 你只需一鍵部署，即可獲得一個功能完備的 Agent 開發平台，包括創建、調試、版本管理等全套界面，讓你專注於創造本身。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Coze Loop 聚焦於 Agent 從開發到運維的全鏈路管理，此次開源的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Prompt 開發： 提供從編寫、調試、一鍵優化到版本管理的強大能力，讓你的 Prompt 工程化、系統化。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多維度評測：AI 的效果好壞不再憑感覺。Coze Loop 提供系統化的評測能力，能從準確性、簡潔性、合規性等多個維度，自動化地評估 Prompt 和 Agent 的輸出質量。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;全鏈路可觀測性：Agent 的每一次執行過程都盡在掌握。提供覆蓋全過程的可視化觀測能力，詳細記錄每個環節的處理細節與狀態，讓 Debug 不再是大海撈針。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362658</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362658</guid>
      <pubDate>Mon, 28 Jul 2025 02:11:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>我國大模型數量超 1500 個</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;世界人工智能大會的最新數據顯示，目前全球已發佈的大模型總數達 3755 個，其中中國企業貢獻了 1509 個，位居全球首位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="1124" src="https://oscimg.oschina.net/oscnet/up-76a22434fb01383b49199810b0ee2c20962.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;從中國互聯網絡信息中心發佈的第 56 次報告中可以看出，2025 年上半年，我國的生成式人工智能在技術與應用層面均取得了全面進步，相關產品的數量也在快速增長，應用場景不斷擴展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在用戶方面，截至 6 月，使用生成式人工智能產品回答問題的比例高達 80.9%。從產業層面來看，預計到 2024 年，我國的人工智能產業規模將突破 7000 億元，並且連續多年保持 20% 以上的增長率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362654</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362654</guid>
      <pubDate>Mon, 28 Jul 2025 02:01:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟即將發佈 Visual Studio 重大升級，應對 AI 編程工具激烈競爭</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;儘管微軟向客戶提供了 Visual Studio Code 這款輕量級但功能強大的開源代碼編輯器，但其旗艦開發環境實際上是原生版 Visual Studio。這是一個功能齊全的集成開發環境 (IDE)，具有 .NET 集成和其他功能，使其更適合複雜的項目管理。現在，一份新報告顯示，微軟正計劃對 Visual Studio 進行重大升級。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/194445_SAV6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;媒體&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-plans-major-update-visual-studio-coding-service-ai-2025-7" target="_blank"&gt;Business Insider&lt;/a&gt;&amp;nbsp;看到了一份微軟內部備忘錄，其中詳細介紹了該公司計劃發佈 Visual Studio 的重大升級。不出所料，此次更新將重點關注人工智能 (AI)，這對於與亞馬遜 Kiro 等其他競爭對手競爭至關重要，亞馬遜 Kiro 被譽為基於 AI 的 IDE。&lt;/p&gt; 
&lt;p&gt;這份備忘錄由傑伊·帕裏克（Jay Parikh）於今年 4 月撰寫，他加入微軟不到一年，擔任執行副總裁（EVP）。帕裏克領導着公司的 CoreAI 部門，該部門負責開發人員工具，因此 Visual Studio 恰好屬於這位高管的職責範圍。&lt;/p&gt; 
&lt;p&gt;Parikh 的備忘錄將這次主要版本稱為「Visual Studio 18」，考慮到 Visual Studio 目前使用的是 17 版，這頗具趣味。該 IDE 上個月發佈了更新，允許開發人員訪問更強大的 AI 模型，同時靈活地管理計費。值得注意的是，Visual Studio 的上一次重大更新是在 2021 年，當時微軟發佈了 Visual Studio 2022 和 .NET 6，因此再次發佈主要版本也是合情合理的。&lt;/p&gt; 
&lt;p&gt;話雖如此，雖然 Visual Studio 的下一次重大升級有可能在今年推出，但目前尚未公佈具體的時間表。備忘錄還指出，這個由人工智能驅動的 IDE 版本目前正處於「早期內部測試」階段，這意味着微軟自己的員工正在積極地使用它進行測試。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362407</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362407</guid>
      <pubDate>Fri, 25 Jul 2025 11:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌短鏈接服務「goo.gl」將於下個月正式停用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Google 將於下個月正式棄用其網址縮短工具生成的鏈接。自 2025 年 8 月 25 日起，所有「&lt;span style="color:#2980b9"&gt;&lt;em&gt;https://goo.gl/*&lt;/em&gt;&lt;/span&gt;」格式的鏈接將不再有效，並返回 404 錯誤信息。&lt;/p&gt; 
&lt;p&gt;Google 於 2019 年關閉了其網址縮短服務，理由是「我們發現人們在互聯網上查找內容的方式發生了變化」。此後，使用該工具創建的鏈接仍然有效，但 Google 去年宣佈，隨着縮短網址流量的下降，將開始棄用這些服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3de2e977a212c4b76a27a10e76c003b1a75.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Google 在其&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F" target="_blank"&gt;2024 年 7 月的博客文章&lt;/a&gt;中表示：「事實上，超過 99% 的縮短網址在過去一個月內沒有任何活動。」&lt;/p&gt; 
&lt;p&gt;當時，Google 還開始在用戶點擊縮短的網址時顯示一個警告頁面，提示「此鏈接近期將不再有效」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bd067dfa47ef36f85743afb32cf6824b04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;距離「goo.gl」鏈接關閉僅剩一個月時間，如果您還沒有將網址轉換到其他縮短服務，現在正是轉換的好時機。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362402</guid>
      <pubDate>Fri, 25 Jul 2025 11:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV7-G0 7.2B 發佈，最強純 RNN 推理模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 22 日， &lt;strong&gt;RWKV7-G0 7.2B 推理模型&lt;/strong&gt;（Reasoning Model）正式開源發佈，它很可能是迄今為止人類訓練過的最強純 RNN 語言模型。&lt;/p&gt; 
&lt;p&gt;RWKV7-G0 7.2B 是在 RWKV6-World-V3-7.6B 的基礎上訓練 2T tokens 的純預訓練模型，但在預訓練加入了大量指令/對話/推理數據，可以解決各種推理問題。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果需要後訓練和對齊，最適合 RNN 的方式是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fadvanced%2FFine-Tune%2FRWKV-PEFT%2FState-Tuning" target="_blank"&gt;state-tuning&lt;/a&gt;，直接微調 RNN 的初始狀態，相當於終極 context engineering。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型客觀指標評測&lt;/h2&gt; 
&lt;h3&gt;英語和多語言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的基礎英語和多語言能力&lt;strong&gt;均強於同規模的開源模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval" src="https://oscimg.oschina.net/oscnet/up-3961b82f0302bbedafaae3e26ce721fe159.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;得益於架構和數據的提升，RWKV7-G0 7.2B 的 MMLU 準確度為 62.7%，顯著超過 RWKV6-World-V3-7.6B 的 54.2%。後續我們會發布訓練 8T tokens 的滿血 RWKV7-G1 7.2B，目標是 MMLU 達到 70%，看齊前沿模型。&lt;/p&gt; 
&lt;h3&gt;無法作弊的評測&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval" target="_blank"&gt;Uncheatable Eval&lt;/a&gt; 是"無法作弊的評測"，它使用最新的論文和新聞文章等實時數據，評估開源大語言模型的真實建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的 Uncheatable Eval 同樣顯著提升，滿血 8T tokens 預計超越 Llama3 8B（這裏測試 2024-07 數據，後續會測新數據，並對比 Qwen2.5、Qwen3）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="uncheatable-eval" src="https://oscimg.oschina.net/oscnet/up-00ee915e6a6642e230984bbad95c7adda04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;模型實戰：解數學題&lt;/h2&gt; 
&lt;p&gt;我們發現，RWKV7-G0 7.2B 解數學題可使用 &lt;code&gt;temperature top_p penalty&lt;/code&gt; 解碼參數都為 0 的純貪心解碼，且無限復讀現象較少。&lt;/p&gt; 
&lt;p&gt;但貪心解碼會導致推理過程探索度不足，因此可引入隨機性，例如 &lt;code&gt;temperature=0.3 top_p=0.3 penalty=0&lt;/code&gt;。模型會自動進行多輪驗算（類似 rollout），並可以自我糾錯。&lt;/p&gt; 
&lt;p&gt;那麼 &lt;code&gt;temperature=0.6 top_p=0.6 penalty=0&lt;/code&gt; 等隨機性更高的參數是否更好，後續我們會通過參數掃描實驗評估。&lt;/p&gt; 
&lt;p&gt;例子，第一題：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math1" src="https://oscimg.oschina.net/oscnet/up-0cd8d78f631ee7405c4bbca2340892aa1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改題目表述，模型換了種做法：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math2" src="https://oscimg.oschina.net/oscnet/up-dc97d5561c78acbb5117c3b214de082e7da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第二題，故意將原題的 99 改為 99.1，模型一開始看錯，後來成功糾正了自己：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math3" src="https://oscimg.oschina.net/oscnet/up-e607d6ca88eb49ab4caf0e417262eb39b2b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第三題，原題是計算 1 的冪，改為計算 i 的冪，增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math4" src="https://oscimg.oschina.net/oscnet/up-8d5d4f106fec7c3c72836c057b1de89bddd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第四題，原題是 2^8 = 4^x，改為 8^x 增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math5" src="https://oscimg.oschina.net/oscnet/up-4d801cfa9f331b3dca71d086a3c05004e6c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第五題，原題的概率是 1/5，改為 1/4 測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math6" src="https://oscimg.oschina.net/oscnet/up-39c45f49e2a398f59a7dc87fde27cf46756.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第六題，原題是 one hat，改為 two hat（故意不加 s 複數形式）測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math7" src="https://oscimg.oschina.net/oscnet/up-2d56afb40928ffd13d17308fc41c6e56369.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第七題，模型有點懵，但反覆驗算多次後，成功確認了正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math8" src="https://oscimg.oschina.net/oscnet/up-7730c44785334a3421428c0e7dd153ed6ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;結論：【純 RNN + 純預訓練】可以得到推理模型，而且它理解了一些解題方法，可以用不同方法解決修改過的題目。&lt;/p&gt; 
&lt;h2&gt;模型實戰：寫代碼&lt;/h2&gt; 
&lt;p&gt;在此我們測試用戶喜聞樂見的圖像輸出。生成一個有一隻貓的 SVG 的網頁：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code" src="https://oscimg.oschina.net/oscnet/up-06f4dbd1a7c9e178ed8408f93d7bb939c4d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用 Three.js 創建一個旋轉的 3D 紅色立方體（完整代碼在文末的附錄中）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code-1" src="https://oscimg.oschina.net/oscnet/up-5965c8a859ccc3bcc7f9db0d86caeb5f612.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;考慮到這是【純 RNN + 純預訓練 + 只訓練 2T tokens】，表現合理。後續更多數據的滿血版會顯著更強。&lt;/p&gt; 
&lt;h2&gt;RNN 的抗幹擾能力&lt;/h2&gt; 
&lt;p&gt;最新論文 &lt;code&gt;Inverse Scaling in Test-Time Compute&lt;/code&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.14417%25EF%25BC%2589%25E5%258F%2591%25E7%258E%25B0%25E5%2589%258D%25E6%25B2%25BF%25E6%25A8%25A1%25E5%259E%258B%25E5%259C%25A8%25E2%2580%259C%25E6%2581%25B6%25E6%2584%258F%25E9%2597%25AE%25E9%25A2%2598%25E2%2580%259D%25EF%25BC%2588%25E4%25BE%258B%25E5%25A6%2582%25E5%25B8%25A6%25E5%25B9%25B2%25E6%2589%25B0%25E9%25A1%25B9%25E7%259A%2584%25E8%25AE%25A1%25E6%2595%25B0%25E3%2580%2581%25E5%25B8%25A6%25E8%2599%259A%25E5%2581%2587%25E7%2589%25B9%25E5%25BE%2581%25E7%259A%2584%25E5%259B%259E%25E5%25BD%2592%25E9%25A2%2584%25E6%25B5%258B%25EF%25BC%258C%25E7%25AD%2589%25E7%25AD%2589%25EF%25BC%2589%25E4%25BC%259A%25E5%2587%25BA%25E7%258E%25B0%25E8%25B6%258A%25E6%2583%25B3%25E8%25B6%258A%25E5%25B7%25AE%25E7%259A%2584%25E6%2583%2585%25E5%2586%25B5%25EF%25BC%259A" target="_blank"&gt;https://arxiv.org/abs/2507.14417）發現前沿模型在「惡意問題」（例如帶幹擾項的計數、帶虛假特徵的迴歸預測，等等）會出現越想越差的情況：&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Inverse Scaling in Test-Time Compute" src="https://oscimg.oschina.net/oscnet/up-6ae323b74fd47a196c5d2c1f9fa0e6eba61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們發現 RWKV7-G0 7.2B 可以克服幹擾，得到正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test" src="https://oscimg.oschina.net/oscnet/up-ae61d209ca82eea02e344618caff2afca92.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;繼續測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-1" src="https://oscimg.oschina.net/oscnet/up-514174dd1deab6244d08e752e541b0fd36e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改數字再測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-2" src="https://oscimg.oschina.net/oscnet/up-203991398541247ca9e64b89fa8da85280d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可見 attention 會導致 transformer 更易受前文幹擾，而 RNN 在此有優勢。而且 RNN 的思考過程永遠勻速，不會越想越慢。我們未來訓練更大的 RNN 會更有趣。&lt;/p&gt; 
&lt;h2&gt;模型下載&lt;/h2&gt; 
&lt;p&gt;下載 RWKV7-G0 7.2B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain" target="_blank"&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社區：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles" target="_blank"&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile" target="_blank"&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何使用 RWKV 模型&lt;/h2&gt; 
&lt;h3&gt;在線 demo（續寫模式）&lt;/h3&gt; 
&lt;p&gt;可以在 RWKV 官方 Gradio 中試用 RWKV7-G0 7.2B 模型（為避免排隊，這裏限制了輸入和輸出長度）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank"&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Hugging Face Gradio 是續寫模式，使用時需要遵循 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fbasic%2FPrompt-Format" target="_blank"&gt;RWKV 的 prompt 格式&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B &lt;strong&gt;不思考模式&lt;/strong&gt;的 QA prompt 格式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如需開啓&lt;strong&gt;思考模式&lt;/strong&gt;，可在 QA prompt 的基礎上添加 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 標籤：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant: &amp;lt;think&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;本地部署 RWKV 模型&lt;/h3&gt; 
&lt;p&gt;可以使用 RWKV Runner、Ai00、RWKV pip 等推理工具本地部署 RWKV 模型。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 模型也適配了 llama.cpp、ollama 等熱門的模型推理工具。&lt;/p&gt; 
&lt;p&gt;由於 RWKV7-G0 7.2B 是新模型，目前建議使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate%2FRWKV-Runner%2FIntroduction" target="_blank"&gt;RWKV Runner&lt;/a&gt; 以保證得到正確結果。&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate" target="_blank"&gt;RWKV 官網 - 模型推理教程&lt;/a&gt;中查看上述推理工具的使用教程。&lt;/p&gt; 
&lt;h2&gt;未來訓練計劃&lt;/h2&gt; 
&lt;p&gt;我們也正在訓練 RWKV7-G0 13.3B 模型，以及使用更多 tokens、使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;DEA&lt;/a&gt; 技術的 RWKV-7s 模型。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;歡迎大家基於 RWKV-7 進行創業、科研，我們也會為基於 RWKV 的項目提供技術支持。&lt;/p&gt; 
 &lt;p&gt;如果您的團隊正在基於 RWKV 創業或開展研究，請聯繫我們！（在「RWKV 元始智能」微信公眾號留言您的聯繫方式，或發送郵件到「contact@rwkvos.com」。）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;附錄：旋轉的紅色立方體&lt;/h2&gt; 
&lt;p&gt;將以下代碼保存為 &lt;code&gt;3d.html&lt;/code&gt; 並雙擊運行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang="en"&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;meta charset="UTF-8"&amp;gt;
    &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&amp;gt;
    &amp;lt;title&amp;gt;Rotating Red Box&amp;lt;/title&amp;gt;
    &amp;lt;style&amp;gt;
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script&amp;gt;
        // Create scene
        const scene = new THREE.Scene();
        
        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;
        
        // Create renderer
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
        // Create box geometry and material
        const geometry = new THREE.BoxGeometry(1, 1, 1);
        const material = new THREE.MeshBasicMaterial({ color: 0xff0000 }); // Red color
        
        // Create box mesh
        const box = new THREE.Mesh(geometry, material);
        
        // Add lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(0, 0, 10);
        scene.add(light);
        
        // Add box to scene
        scene.add(box);
        
        // Animation loop
        let angleX = 0;
        let angleY = 0;
        
        function animate() {
            requestAnimationFrame(animate);
            
            // Update rotation angles
            angleX += 0.01;
            angleY += 0.01;
            
            // Update box rotation
            box.rotation.x = angleX;
            box.rotation.y = angleY;
            
            // Render scene
            renderer.render(scene, camera);
        }
        
        animate();
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362400</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362400</guid>
      <pubDate>Fri, 25 Jul 2025 10:54:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>谷歌 DeepMind 新架構 MoR 有望成為「Transformer 殺手」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 DeepMind 團隊發表論文《Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation》，&lt;strong&gt;提出新 Transformer 架構 Mixture-of-Recursions（MoR）&lt;/strong&gt;，旨在同時實現參數共享和自適應計算，以解決大型語言模型訓練和部署中的計算與內存開銷問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-17000d1f4f6bc815b75098237c70778d99f.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c76175988abdc82ca877e5b51ccc663dba8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/abs/2507.10524&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;MoR 的核心創新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;參數效率&lt;/strong&gt;：通過共享層堆棧在不同遞歸步驟中複用參數，減少參數量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;動態計算&lt;/strong&gt;：輕量級路由器為每個 token 動態分配遞歸深度，複雜 token 可深入處理，簡單 token 可提前退出，從而將計算資源精準分配 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;內存優化&lt;/strong&gt;：採用遞歸級鍵值（KV）緩存機制，僅緩存活躍 token 的 KV 對，顯著降低內存帶寬壓力並提升推理吞吐量 。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實驗結果顯示，在 135M 到 1.7B 參數規模的模型中，MoR 在相同訓練計算量下，驗證困惑度更低、少樣本準確率更高，推理吞吐量相比傳統 Transformer 和現有遞歸基線提升至多 2.18 倍，同時降低內存佔用和推理延遲。&lt;/p&gt; 
&lt;p&gt;因此，MoR 被認為可能在無需承擔大模型成本的情況下實現大模型質量，甚至被稱為「Transformer 殺手」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362399</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362399</guid>
      <pubDate>Fri, 25 Jul 2025 10:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>三分之一美國人藉助 AI 工具尋求職業轉型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據東南俄克拉荷馬大學（SOU）&lt;span&gt;最新&lt;/span&gt;發佈的一項報告，約三分之一的美國人已開始使用 AI 工具，如 ChatGPT，來幫助他們進行職業轉型。該報告基於對 1000 名來自四個不同世代的美國人的調查，旨在瞭解 AI 在當前美國勞動市場劇烈變化中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;調查顯示，超過一半的受訪者表示，他們正在積極考慮換工作或職業轉型，其中以 Z 世代的 57% 比例&lt;span&gt;最高&lt;/span&gt;，隨後是千禧一代的 55%，X 世代的 50%，以及僅 12% 的嬰兒潮一代。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在那些表示 AI 對他們的職業轉型有所幫助的受訪者中，43% 的人使用 AI 工具撰寫簡歷和求職信，47% 的人則利用 AI 進行新工作機會的研究，包括尋找薪資更高的職位。值得注意的是，近五分之一的受訪者（18%）表示，AI 建議了他們之前未曾考慮過的全新職業路徑。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，儘管有不少人依賴 AI 來提供職業建議，調查也顯示大多數受訪者對 AI 提供的信息持謹慎態度。60% 的受訪者表示，他們更傾向於相信人類職業顧問的意見，而只有 7% 的人選擇相信 AI。一部分人（17%）甚至選擇遵循 AI 的建議，即使這些建議與他們之前從人類顧問那裏得到的意見相悖。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在各年齡層中，受訪者主要關注的職業機會集中在技術領域，其次是醫療和金融。隨着 AI 技術的不斷發展，許多人認為這可能導致大量白領職位的消失。例如，Anthropic 的首席執行官達裏奧・阿莫德伊預測，AI 將在未來五年內消除一半的白領工作。而亞馬遜首席執行官安迪・賈西也表示，AI 驅動的自動化將取代一些人類工作，同時使其他職位變得更加 「有趣」，並創造出全新的崗位。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技術公司招聘方面的數據也表明，隨着 AI 工具開始接管許多原本由年輕、經驗較少的員工完成的日常任務，科技公司對新近計算機科學畢業生的招聘數量有所減少。此外，在硅谷的激烈人才爭奪戰中，企業之間的競爭愈發激烈，特別是在人工智能研究方面的&lt;span&gt;頂尖&lt;/span&gt;人才更是稀缺。許多公司都願意為此支付高額薪資，以吸引那些能夠在技術突破中發揮關鍵作用的優秀研究人員。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362398</guid>
      <pubDate>Fri, 25 Jul 2025 10:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>階躍星辰發佈最強開源多模態推理模型 Step3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;階躍星辰宣佈發佈新一代基礎大模型 Step3，主打多模態推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，這是階躍星辰首個全尺寸、原生多模態推理模型。在國產芯片 32K 上下文推理效率最高可達 DeepSeek R1 的 300%，在英偉達 H800 芯片將推理效率提升了 70% 以上。該模型將於 7 月 31 日向全球開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e93e689dafce5406835a7db40fe0043af4b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，階躍星辰宣佈與上海國有資本投資有限公司達成深度戰略合作，並透露上海國投將參與階躍星辰的新一輪融資。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;階躍星辰創始人、CEO 姜大昕表示，階躍的商業化的成果體現在了收入數字上，基於上半年的高速增長，公司將全年的衝刺目標定在 10 億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;會上，階躍還將聯合近 10 家芯片廠商和算力平台成立模新生態創新聯盟。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362393</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362393</guid>
      <pubDate>Fri, 25 Jul 2025 10:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技發佈第三款人形機器人 UnitreeR1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技在官微宣佈，正式發佈第三款人形機器人「Unitree R1 智能夥伴」，售價 3.99 萬元起，支持開發/改制，靈活超輕量約 25Kg，集成語音和圖像多模態大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宣傳視頻顯示，第三款人形機器人 Unitree R1 擁有 26 個關節，包括腿部 6*2+腰部 2+手臂 5*2+頭 2，可以實現翻跟頭、倒立行走、奔跑、打拳等動作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="361" src="https://oscimg.oschina.net/oscnet/up-47996978da023c9ec22be1f2e1c81a666e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，7 月 18 日，中國證監會官網顯示，宇樹科技已開啓上市輔導，由中信證券擔任輔導機構。輔導備案報告顯示，宇樹科技控股股東、實際控制人王興興直接持有公司 23.8216% 股權，並通過上海宇翼企業管理諮詢合夥企業（有限合夥）控制公司 10.9414% 股權，合計控制公司 34.7630% 股權。根據相關規定，宇樹科技最快將於 10 月完成輔導，這意味着宇樹科技有希望在今年年內登陸 A 股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技是一家知名民用機器人公司。2016 年成立於杭州，創始人兼 CEO 是王興興。公司專注於消費級、行業級高性能通用足式/人形機器人及靈巧機械臂的研發、生產和銷售。其明星產品有 Unitree Go1 四足機器人等，2023 年起推出 H1、G1 等人形機器人。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362388</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362388</guid>
      <pubDate>Fri, 25 Jul 2025 10:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>科大訊飛推出升級版星火 X1 深度推理大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;科大訊飛&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-crxs5LkH1UoU0BQsJzmkA" target="_blank"&gt;宣佈&lt;/a&gt;正式推出了升級版的星火 X1 深度推理大模型。一些亮點內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;綜合能力大幅提升。整體效果對標 OpenAI o3 等國內外一流大模型最新版本效果，在翻譯、推理、文本生成、數學等方面保持領先。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;幻覺治理取得顯著進步。幻覺問題是掣肘大模型落地應用的關鍵問題，升級後的星火 X1 在幻覺治理方面領先業界主流模型。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多語言能力已覆蓋 130+語種。為世界提供全棧自主可控大模型底座的「第二種選擇」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;基於星火 X1 底座的語音同傳大模型在翻譯效果、實時響應、語音聽感、專業精深等方面大幅躍升，持續行業領先。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;得益於星火 X1 模型的升級，教育、醫療、企業應用、代碼、科研等行業大模型和智能體也取得了新的進步，在複雜行業場景任務上進一步解決用戶關鍵剛需。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-ff3e38322ebbce182a8c6b9c032f75581ae.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="360" src="https://oscimg.oschina.net/oscnet/up-39ea728edd540a2fd33fd97fef826e1c5a7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-56fed82205eb5013f0c184ec5ea45dc94a2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，星火 X1 最新升級的各項能力可以通過訊飛星火的網頁版和手機應用體驗，同時新 API 也已上線。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362377</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362377</guid>
      <pubDate>Fri, 25 Jul 2025 09:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Genkit —— 用於構建全棧 AI 應用的框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Genkit 是一個用於構建全棧 AI 應用的開源框架，由 Google Firebase 構建並投入生產。它為多種編程語言提供 SDK，且穩定性級別各不相同：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JavaScript/TypeScript（穩定）&lt;/strong&gt;：已準備好投入生產，並支持全部功能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Go（測試版）&lt;/strong&gt;：功能齊全，但可能有重大變化&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Python（Alpha）&lt;/strong&gt;：具有核心功能的早期開發&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;它提供統一的接口，用於集成來自&lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-openai"&gt;OpenAI&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt;Anthropic&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/plugins/ollama/"&gt;Ollama&lt;/a&gt;等供應商的 AI 模型。使用精簡的 API（用於多模式內容、結構化輸出、工具調用和代理工作流），快速構建和部署可用於生產的聊天機器人、自動化和推薦系統。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;只需幾行代碼即可開始：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#cf222e"&gt;import&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;genkit&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;&lt;span style="color:#cf222e"&gt;from&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0a3069"&gt;'genkit'&lt;/span&gt;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;&lt;span style="color:#cf222e"&gt;import&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;googleAI&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;&lt;span style="color:#cf222e"&gt;from&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0a3069"&gt;'@genkit-ai/googleai'&lt;/span&gt;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;&lt;span style="color:#cf222e"&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;ai&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#6639ba"&gt;genkit&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;{&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;plugins&lt;/span&gt;&lt;/span&gt;: &lt;span&gt;[&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6639ba"&gt;googleAI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;}&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;&lt;span style="color:#cf222e"&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; text &lt;span&gt;}&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#cf222e"&gt;await&lt;/span&gt;&lt;/span&gt; &lt;span&gt;ai&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6639ba"&gt;generate&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;&lt;span style="color:#0550ae"&gt;model&lt;/span&gt;&lt;/span&gt;: &lt;span&gt;googleAI&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6639ba"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style="color:#0a3069"&gt;'gemini-2.0-flash'&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;&lt;span style="color:#0550ae"&gt;prompt&lt;/span&gt;&lt;/span&gt;: &lt;span&gt;&lt;span style="color:#0a3069"&gt;'Why is Firebase awesome?'&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;關鍵功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;table cellspacing="0" style="border-collapse:collapse; border-spacing:0px; border:undefined; box-sizing:border-box; display:block; font-variant:tabular-nums; margin-bottom:16px; margin-top:0px; max-width:100%; overflow:auto; width:max-content"&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;廣泛的人工智能模型支持&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用統一的界面集成來自&lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-openai"&gt;&amp;nbsp;OpenAI&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt;&amp;nbsp;Anthropic&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/plugins/ollama"&gt;Ollama&lt;/a&gt;等提供商的數百個模型。探索、比較並使用最符合你需求的模型。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;簡化的 AI 開發&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用精簡的 API 構建 AI 功能，包括&lt;a href="https://genkit.dev/docs/models#structured-output"&gt;&amp;nbsp;結構化輸出&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/tool-calling"&gt;代理工具調用&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/rag"&gt;上下文感知生成&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/models#multimodal"&gt;多模態輸入/輸出&lt;/a&gt;等。Genkit 可處理 AI 開發的複雜性，讓你能夠更快地構建和迭代。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;適用於網絡和移動設備&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用專門構建的&lt;a href="https://genkit.dev/docs/firebase"&gt;客戶端 SDK&lt;/a&gt;和幫助程序與 Next.js、React、Angular、iOS、Android 等框架和平台無縫集成。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;跨語言支持&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用最適合你項目的語言進行構建。Genkit 提供 JavaScript/TypeScript（穩定版）、Go（測試版）和 Python（Alpha 版）的 SDK，並在所有支持的語言中提供一致的 API 和功能。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;隨處部署&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;將 AI 邏輯部署到支持你選擇的編程語言的任何環境，例如&lt;a href="https://genkit.dev/docs/firebase"&gt;Firebase 的 Cloud Functions&lt;/a&gt;、&amp;nbsp;&lt;a href="https://genkit.dev/docs/cloud-run"&gt;Google Cloud Run&lt;/a&gt;或&lt;a href="https://genkit.dev/docs/deploy-node"&gt;第三方平台&lt;/a&gt;（無論是否帶有 Google 服務）。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;開發人員工具&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用專用的本地&lt;a href="https://genkit.dev/docs/devtools"&gt;CLI 和開發者 UI&lt;/a&gt;加速 AI 開發。針對單個輸入或數據集測試提示和流程，比較不同模型的輸出，使用詳細的執行軌跡進行調試，並使用即時視覺反饋快速迭代提示。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;生產監控&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用全面的生產監控，自信地交付 AI 功能。在&lt;a href="https://genkit.dev/docs/observability/getting-started"&gt;專用儀錶板&lt;/a&gt;中跟蹤模型性能、請求量、延遲和錯誤率。通過詳細的可觀察性指標快速識別問題，並確保你的 AI 功能在實際使用中滿足質量和性能目標。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/genkit</link>
      <guid isPermaLink="false">https://www.oschina.net/p/genkit</guid>
      <pubDate>Fri, 25 Jul 2025 09:24:00 GMT</pubDate>
    </item>
    <item>
      <title>一位 Oracle 鐵粉的「真香」轉變</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;「O 記我用了這麼多年，我最有發言權，我可不敢替，你們誰能搞定，誰上。」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧在會上，狠狠甩了一句氣話。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e5a3c8ce9de050c94ac215768d0a3edb.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧（鄧銘），某大型期貨交易所信息化主管，數據庫老司機。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;作為圈裏最早的一批 DBA，老顧是 O 記鐵桿，他的工位裏，最醒目的不是家人照片，而是歷代 O 記認證證書。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c290049cbab7bb43b66e5287b8f4ddf5.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;開完剛才的「數據庫替代」內部通氣會，老鄧「餘怒」未消。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;回到工位上，把鍵盤敲得噼裏啪啦響，在工作羣裏瘋狂輸出，一口氣寫出了自己的「六大不敢替」理由↓&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e1371f3a77ac19fc3d0e4478d5d0abc6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//7d4c80b48f32c5c74e48037cc963aac4.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;當然，老鄧也知道，既然監管發文了，這替換的趨勢肯定無法阻擋。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;只是，作為 O 記鐵粉，他心裏有點意難平。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f1f0ebe84f89381dca4a256c4aab9248.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;接下來，單位組織了技術選型會，讓一家家國產數據庫廠商來「過堂」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧心説這下可好，看我怎麼懟你們！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//3fc85c074efe5b87262e59a632017c4b.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;事情就像預料的那樣……&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;選型會上，老鄧一頓輸出，把前面幾家廠商都給噴走了。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1dfc10a63fc696d8dab13398e2ddd315.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//6f6bd107217abdfc5f942a777cf3e043.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;終於，輪到最後一家講方案，廠家專家上台了。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧翻了翻白眼，buff 已經疊滿了，只等對面講的有漏洞，就開噴。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//bd295f1eb278b037974d22f4534e693b.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;結果…&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這家一開場，啪啪啪啪啪啪，竟然把老鄧想懟的那些點，全堵上了。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//630199d4c3bce018152de5e751817795.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧有點懵，他在腦子裏仔細品味剛剛對方講的那幾個點…&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//30ff196d752b0d270b44e9436f425076.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;六大痛點怎麼破？&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;請看數據庫平替解決方案&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;痛點 1：擔心應用改造成本高、難度大&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;替換數據庫，最怕動應用，他倆捆綁太深了。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d6e479d982143780405e2bf6a680f187.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;一旦所選數據庫兼容性不夠，存儲過程、觸發器，甚至 SQL 語句全都得改，一改就是成千上萬行，沒人願意碰。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;所以説，換數據庫，別動應用才是最大的剛需。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;怎麼解：不用你改，我們來兼容！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;應用軟件 SQL、PL/SQL 零修改，如果不兼容，這家公司的數據庫反向適配，這就是底氣。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d83e9e4fc905ef39447f1c7f7b7b678e.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;都有哪些「姿勢」呢？&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;多語法原生兼容的一體化框架，可插拔、可擴展，支持對 Oracle/MySQL/SQL Server/PostgreSQL 等深度兼容；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;Oracle 兼容能力接近 100%，常見覆雜語法全支持，真實案例中，銀行系統百萬行 PL/SQL 代碼未改一行，成功遷移上線；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;MySQL 語法全面覆蓋，在大多數場景下性能甚至優於原庫；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;SQL Server 常用語法兼容度達 99% 以上。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這家公司主打「低難度」遷移—高兼容、零改造。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;往往，在遷移前，別人的內心戲是這樣的↓&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ec2e575c207b9364fbd8dd9783e2d34d.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;結果呢，再複雜的場景，他們都全部搞定了。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;看看這些超級複雜的遷移實戰吧，用戶應用代碼全部零修改。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ce9c4c6b68cb83df8352e4ad19727be2.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;於是，到最後，完美平替！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//66c758b2684c4fe65a89db21e0096f8c.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;痛點 2：擔心數據遷移複雜，工作量大，勞心勞力&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;數據庫遷移的另一大負擔，就是歷史數據量大、流程繁、比對難。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//36db9a916d1508c218ba85c088dba69a.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;歷史數據要搬、增量數據要同步，遷完之後還得一條條校驗一致性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;不僅費時費力，稍有差錯就可能返工重來。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//8d6799e1fd36f1de750d0625ff969996.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;怎麼解？&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這家廠商提供了一整套全自動遷移工具和解決方案↓&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;①「流水線」作業模式，結構遷移 + 全量遷移 + 增量同步，一次走完。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0cd7016653118b2421fb602f554281f6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//b0ea9d093dccecd94fcf59391d03ccbd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;②一致性比對，確保新舊數據一致，避免遷完了才發現丟數據或錯數據&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//396f9a0508a683459dc494943b6bb916.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這些工具久經沙場，經過大規模驗證：數據庫原廠人員每年直接為客戶遷移部署近萬套數據庫，服務客戶上線近 2000 個系統。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//14d2657c2c09231e79c61aebbf3b9d94.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;痛點 3：擔心繫統停機時間過長，影響業務連續性&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在許多業務關鍵、運行敏感的系統中，停機窗口極短，甚至「幾分鐘都不能斷」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這類「無法停」的系統，是數據庫替換中難啃的「硬骨頭」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//2ca4517d74500884d1fe8bca7b430968.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;怎麼解？他們提供柔性遷移方案，做到重要系統遷移不停機。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這套方案，包含一整套柔性遷移工具鏈，包括：KDMS、KDTS 和 KFS。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a7ce2f271d05002379843e42112baeee.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;其實，這三劍客在前面的數據遷移場景，就已經出過手了。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;KDMS：完成歷史數據的結構化遷移；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;KDTS：用於按變更記錄（如 SCN、LSN）進行全量增量數據遷移；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;KFS：用於在線增量數據的實時同步遷移。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;現在着重談，如何不停機遷移。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//aecb704aaa1e8c21b56c2a8179703a9c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這套方案的核心理念是：整個過程，原系統可以持續對外提供服務，而新系統利用三個工具的配合，在遷移歷史數同時，實時接收變更數據，確保兩邊數據始終一致。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;有了這套柔性遷移方案，遷移不再等「節假日」或「通宵窗口」，上線更可控，替換更輕鬆。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//047e82cdb96830bd682ba8a7c58a86b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;痛點 4：擔心繫統測試無法全面覆蓋生產環境，上線就「翻車」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這是一個靈魂拷問：在遷移測試環境跑得好好的，一上線到生產環境就出問題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0e1b6069777e33fe0d364b6df0e671ba.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;傳統測試只能覆蓋一部分功能，而真實生產環境業務邏輯繁雜、併發壓力大、數據鏈路長，很難完全模擬。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;甚至有些 PoC 測試專挑軟骨頭，刻意避坑，結果，真上線就踩坑。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//9001f323088732f298eec40d2e5e30d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;怎麼解？&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這家廠商提供了基於真實生產負載的全量回歸測試工具，讓企業上線前，就像在真實環境裏「預演」一遍。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f5f8ec22a3f9e1c5c530e5b30fd99d13.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這套測試工具的工作方式很直接也很聰明↓&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;從原 O 記系統中捕獲完整業務負載（包括 SQL 語句、事務、執行順序等）將這些業務流量一比一「重放」到自家數據庫上；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;自動對比執行效果與性能表現，生成分析報告，提前發現潛在問題，提前解決，確保上線後不「踩雷」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//dce877b174706ead9513de079b64b91f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;測試工具能做到無需應用源碼、覆蓋全場景、測試結果真實可信。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;讓系統上線之前，就像在生產環境裏跑了一遍，問題在上線前就被幹掉。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//914f012d035f431f32746223326fb08d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;痛點 5：擔心國產數據庫可能存在丟數據、宕機的風險，導致業務停擺&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在關鍵系統中，數據庫一旦完成割接替換，就意味着「只能成功，沒有回頭路」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;但實操中，有些意外總是讓人猝不及防。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c1d6f222372567af0446231f4a58c8ff.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;數據庫替換，不冒險，才是好方案。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;怎麼解？這家廠商提供雙軌並行，隨時可回退！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//790a6929e0c97106fbab2b468b69eca3.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;上線後如果國產數據庫出現故障，系統可秒級切換回原有數據庫繼續運行，業務不中斷，數據不丟失，真正做到「萬無一失」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;上線有保障，失敗可撤回，全程低風險。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//b882f7fa72be590193e0f1d77d42eca9.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;即使是在銀行、電網、軌交這類對連續性要求極高的行業，也能實現替完還可回頭。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;當然，這其實是一顆定心丸，這家廠商做了無數平替案例，還從來沒用過回退這一招。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//9d545b965390ed987cdd008f103449b6.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;痛點 6：性能能否達到 Oracle 同等水平？&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這恐怕是包括老鄧在內，最後一個顧慮了：「國產數據庫性能行嗎？能打得過 O 記嗎？」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;換成國產數據庫後，要是性能掉隊，業務慢半拍，系統卡頓，那真是換了個寂寞啊。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cf40186565f5ae94841359b6ec1be45f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;怎麼解？&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這家廠商有足夠的底氣，他們相信數據庫的性能優化並不是「紙上談兵」，而是&lt;strong&gt;真刀真槍地在覈心繫統中跑出來的&lt;/strong&gt;。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//96bbdabc9e694ce18008da75bcbd0b61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;目前，他們的數據庫產品已經在&lt;strong&gt;2000+關鍵業務系統&lt;/strong&gt;中實現替換上線，驗證了「替得了、跑得穩、上得去」的能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//991c911b18d738cc6d19c9ae40f7d539.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//258db050b5e3dea7e60bb04a2fd15718.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;六條講完，嚴絲合縫。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧萬萬沒想到，自己竟然聽得津津有味，還記了一大段筆記。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;不由暗暗感慨：士別三日，國產數據庫的進步這麼大。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//911768e37d0d72a6a859323baa01cc12.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;這時候，台上的廠商專家開始了總結：我們不止能替 O 記，更有「全家桶」級別的國產替代能力，涵蓋主流數據庫全譜系↓&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//93d272f74c5f3eba2ff93353ef8b527a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;講完這些，廠商專家頓了頓，翻到最後一頁——&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;沒錯，這家數據庫廠商就是「金倉數據庫」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;一句話，數據庫平替用金倉，讓「不敢替」的痛，變成「能平替」的路！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0304157f721af366b5a8acc4f835dd78.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;尾聲：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;老鄧終於放下了執念……&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;項目驗收那晚，老鄧望着穩定運行的系統、波瀾不驚的監控大屏，拿起手機，悄悄發了個朋友圈。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//2b19a56baa8bf8e03a189a362ded5fc3.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362375</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362375</guid>
      <pubDate>Fri, 25 Jul 2025 09:19:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>RWKV7-G0 7.2B 發佈，最強純 RNN 推理模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 22 日， &lt;strong&gt;RWKV7-G0 7.2B 推理模型&lt;/strong&gt;（Reasoning Model）正式開源發佈，它很可能是迄今為止人類訓練過的最強純 RNN 語言模型。&lt;/p&gt; 
&lt;p&gt;RWKV7-G0 7.2B 是在 RWKV6-World-V3-7.6B 的基礎上訓練 2T tokens 的純預訓練模型，但在預訓練加入了大量指令/對話/推理數據，可以解決各種推理問題。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果需要後訓練和對齊，最適合 RNN 的方式是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fadvanced%2FFine-Tune%2FRWKV-PEFT%2FState-Tuning" target="_blank"&gt;state-tuning&lt;/a&gt;，直接微調 RNN 的初始狀態，相當於終極 context engineering。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型客觀指標評測&lt;/h2&gt; 
&lt;h3&gt;英語和多語言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的基礎英語和多語言能力&lt;strong&gt;均強於同規模的開源模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval" src="https://oscimg.oschina.net/oscnet/up-3961b82f0302bbedafaae3e26ce721fe159.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;得益於架構和數據的提升，RWKV7-G0 7.2B 的 MMLU 準確度為 62.7%，顯著超過 RWKV6-World-V3-7.6B 的 54.2%。後續我們會發布訓練 8T tokens 的滿血 RWKV7-G1 7.2B，目標是 MMLU 達到 70%，看齊前沿模型。&lt;/p&gt; 
&lt;h3&gt;無法作弊的評測&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval" target="_blank"&gt;Uncheatable Eval&lt;/a&gt; 是"無法作弊的評測"，它使用最新的論文和新聞文章等實時數據，評估開源大語言模型的真實建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的 Uncheatable Eval 同樣顯著提升，滿血 8T tokens 預計超越 Llama3 8B（這裏測試 2024-07 數據，後續會測新數據，並對比 Qwen2.5、Qwen3）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="uncheatable-eval" src="https://oscimg.oschina.net/oscnet/up-00ee915e6a6642e230984bbad95c7adda04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;模型實戰：解數學題&lt;/h2&gt; 
&lt;p&gt;我們發現，RWKV7-G0 7.2B 解數學題可使用 &lt;code&gt;temperature top_p penalty&lt;/code&gt; 解碼參數都為 0 的純貪心解碼，且無限復讀現象較少。&lt;/p&gt; 
&lt;p&gt;但貪心解碼會導致推理過程探索度不足，因此可引入隨機性，例如 &lt;code&gt;temperature=0.3 top_p=0.3 penalty=0&lt;/code&gt;。模型會自動進行多輪驗算（類似 rollout），並可以自我糾錯。&lt;/p&gt; 
&lt;p&gt;那麼 &lt;code&gt;temperature=0.6 top_p=0.6 penalty=0&lt;/code&gt; 等隨機性更高的參數是否更好，後續我們會通過參數掃描實驗評估。&lt;/p&gt; 
&lt;p&gt;例子，第一題：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math1" src="https://oscimg.oschina.net/oscnet/up-0cd8d78f631ee7405c4bbca2340892aa1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改題目表述，模型換了種做法：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math2" src="https://oscimg.oschina.net/oscnet/up-dc97d5561c78acbb5117c3b214de082e7da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第二題，故意將原題的 99 改為 99.1，模型一開始看錯，後來成功糾正了自己：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math3" src="https://oscimg.oschina.net/oscnet/up-e607d6ca88eb49ab4caf0e417262eb39b2b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第三題，原題是計算 1 的冪，改為計算 i 的冪，增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math4" src="https://oscimg.oschina.net/oscnet/up-8d5d4f106fec7c3c72836c057b1de89bddd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第四題，原題是 2^8 = 4^x，改為 8^x 增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math5" src="https://oscimg.oschina.net/oscnet/up-4d801cfa9f331b3dca71d086a3c05004e6c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第五題，原題的概率是 1/5，改為 1/4 測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math6" src="https://oscimg.oschina.net/oscnet/up-39c45f49e2a398f59a7dc87fde27cf46756.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第六題，原題是 one hat，改為 two hat（故意不加 s 複數形式）測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math7" src="https://oscimg.oschina.net/oscnet/up-2d56afb40928ffd13d17308fc41c6e56369.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第七題，模型有點懵，但反覆驗算多次後，成功確認了正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math8" src="https://oscimg.oschina.net/oscnet/up-7730c44785334a3421428c0e7dd153ed6ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;結論：【純 RNN + 純預訓練】可以得到推理模型，而且它理解了一些解題方法，可以用不同方法解決修改過的題目。&lt;/p&gt; 
&lt;h2&gt;模型實戰：寫代碼&lt;/h2&gt; 
&lt;p&gt;在此我們測試用戶喜聞樂見的圖像輸出。生成一個有一隻貓的 SVG 的網頁：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code" src="https://oscimg.oschina.net/oscnet/up-06f4dbd1a7c9e178ed8408f93d7bb939c4d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用 Three.js 創建一個旋轉的 3D 紅色立方體（完整代碼在文末的附錄中）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code-1" src="https://oscimg.oschina.net/oscnet/up-5965c8a859ccc3bcc7f9db0d86caeb5f612.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;考慮到這是【純 RNN + 純預訓練 + 只訓練 2T tokens】，表現合理。後續更多數據的滿血版會顯著更強。&lt;/p&gt; 
&lt;h2&gt;RNN 的抗幹擾能力&lt;/h2&gt; 
&lt;p&gt;最新論文 &lt;code&gt;Inverse Scaling in Test-Time Compute&lt;/code&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.14417%25EF%25BC%2589%25E5%258F%2591%25E7%258E%25B0%25E5%2589%258D%25E6%25B2%25BF%25E6%25A8%25A1%25E5%259E%258B%25E5%259C%25A8%25E2%2580%259C%25E6%2581%25B6%25E6%2584%258F%25E9%2597%25AE%25E9%25A2%2598%25E2%2580%259D%25EF%25BC%2588%25E4%25BE%258B%25E5%25A6%2582%25E5%25B8%25A6%25E5%25B9%25B2%25E6%2589%25B0%25E9%25A1%25B9%25E7%259A%2584%25E8%25AE%25A1%25E6%2595%25B0%25E3%2580%2581%25E5%25B8%25A6%25E8%2599%259A%25E5%2581%2587%25E7%2589%25B9%25E5%25BE%2581%25E7%259A%2584%25E5%259B%259E%25E5%25BD%2592%25E9%25A2%2584%25E6%25B5%258B%25EF%25BC%258C%25E7%25AD%2589%25E7%25AD%2589%25EF%25BC%2589%25E4%25BC%259A%25E5%2587%25BA%25E7%258E%25B0%25E8%25B6%258A%25E6%2583%25B3%25E8%25B6%258A%25E5%25B7%25AE%25E7%259A%2584%25E6%2583%2585%25E5%2586%25B5%25EF%25BC%259A" target="_blank"&gt;https://arxiv.org/abs/2507.14417）發現前沿模型在「惡意問題」（例如帶幹擾項的計數、帶虛假特徵的迴歸預測，等等）會出現越想越差的情況：&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Inverse Scaling in Test-Time Compute" src="https://oscimg.oschina.net/oscnet/up-6ae323b74fd47a196c5d2c1f9fa0e6eba61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們發現 RWKV7-G0 7.2B 可以克服幹擾，得到正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test" src="https://oscimg.oschina.net/oscnet/up-ae61d209ca82eea02e344618caff2afca92.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;繼續測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-1" src="https://oscimg.oschina.net/oscnet/up-514174dd1deab6244d08e752e541b0fd36e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改數字再測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-2" src="https://oscimg.oschina.net/oscnet/up-203991398541247ca9e64b89fa8da85280d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可見 attention 會導致 transformer 更易受前文幹擾，而 RNN 在此有優勢。而且 RNN 的思考過程永遠勻速，不會越想越慢。我們未來訓練更大的 RNN 會更有趣。&lt;/p&gt; 
&lt;h2&gt;模型下載&lt;/h2&gt; 
&lt;p&gt;下載 RWKV7-G0 7.2B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain" target="_blank"&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社區：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles" target="_blank"&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile" target="_blank"&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何使用 RWKV 模型&lt;/h2&gt; 
&lt;h3&gt;在線 demo（續寫模式）&lt;/h3&gt; 
&lt;p&gt;可以在 RWKV 官方 Gradio 中試用 RWKV7-G0 7.2B 模型（為避免排隊，這裏限制了輸入和輸出長度）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank"&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Hugging Face Gradio 是續寫模式，使用時需要遵循 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fbasic%2FPrompt-Format" target="_blank"&gt;RWKV 的 prompt 格式&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B &lt;strong&gt;不思考模式&lt;/strong&gt;的 QA prompt 格式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如需開啓&lt;strong&gt;思考模式&lt;/strong&gt;，可在 QA prompt 的基礎上添加 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 標籤：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant: &amp;lt;think&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;本地部署 RWKV 模型&lt;/h3&gt; 
&lt;p&gt;可以使用 RWKV Runner、Ai00、RWKV pip 等推理工具本地部署 RWKV 模型。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 模型也適配了 llama.cpp、ollama 等熱門的模型推理工具。&lt;/p&gt; 
&lt;p&gt;由於 RWKV7-G0 7.2B 是新模型，目前建議使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate%2FRWKV-Runner%2FIntroduction" target="_blank"&gt;RWKV Runner&lt;/a&gt; 以保證得到正確結果。&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate" target="_blank"&gt;RWKV 官網 - 模型推理教程&lt;/a&gt;中查看上述推理工具的使用教程。&lt;/p&gt; 
&lt;h2&gt;未來訓練計劃&lt;/h2&gt; 
&lt;p&gt;我們也正在訓練 RWKV7-G0 13.3B 模型，以及使用更多 tokens、使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;DEA&lt;/a&gt; 技術的 RWKV-7s 模型。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;歡迎大家基於 RWKV-7 進行創業、科研，我們也會為基於 RWKV 的項目提供技術支持。&lt;/p&gt; 
 &lt;p&gt;如果您的團隊正在基於 RWKV 創業或開展研究，請聯繫我們！（在「RWKV 元始智能」微信公眾號留言您的聯繫方式，或發送郵件到「contact@rwkvos.com」。）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;附錄：旋轉的紅色立方體&lt;/h2&gt; 
&lt;p&gt;將以下代碼保存為 &lt;code&gt;3d.html&lt;/code&gt; 並雙擊運行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang="en"&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;meta charset="UTF-8"&amp;gt;
    &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&amp;gt;
    &amp;lt;title&amp;gt;Rotating Red Box&amp;lt;/title&amp;gt;
    &amp;lt;style&amp;gt;
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script&amp;gt;
        // Create scene
        const scene = new THREE.Scene();
        
        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;
        
        // Create renderer
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
        // Create box geometry and material
        const geometry = new THREE.BoxGeometry(1, 1, 1);
        const material = new THREE.MeshBasicMaterial({ color: 0xff0000 }); // Red color
        
        // Create box mesh
        const box = new THREE.Mesh(geometry, material);
        
        // Add lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(0, 0, 10);
        scene.add(light);
        
        // Add box to scene
        scene.add(box);
        
        // Animation loop
        let angleX = 0;
        let angleY = 0;
        
        function animate() {
            requestAnimationFrame(animate);
            
            // Update rotation angles
            angleX += 0.01;
            angleY += 0.01;
            
            // Update box rotation
            box.rotation.x = angleX;
            box.rotation.y = angleY;
            
            // Render scene
            renderer.render(scene, camera);
        }
        
        animate();
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362370</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362370</guid>
      <pubDate>Fri, 25 Jul 2025 09:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>特斯拉強調輔助駕駛安全性：AI 硬件加持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特斯拉官方微博今日發文，重申了輔助駕駛技術在提升車輛安全性方面的重要性。根據特斯拉 2025 年第二季度安全報告，開啓輔助駕駛功能的特斯拉車輛，其安全性是普通車輛的 9.5 倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="414" src="https://oscimg.oschina.net/oscnet/up-96c1d1ada610ee1272da23c291a011df993.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特斯拉表示，其旗下 S3XY 全系現款在售車型均標配了&lt;strong&gt;AI4 智能輔助駕駛硬件&lt;/strong&gt;和輔助駕駛功能。官方宣稱，得益於這些先進的 AI 技術，特斯拉的輔助駕駛系統比人類駕駛更為可靠。特斯拉強調，其最終目標是實現「零事故」，並承諾將持續努力，確保每一位車主都能安心出行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此次表態被視為特斯拉對近期懂車帝輔助駕駛測試的回應。近日，懂車帝聯合央視推出了《懂車智煉場》輔助駕駛科普節目，對 36 款車型進行了實測，測試結果引發了廣泛關注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，鴻蒙智行官微也疑似回應懂車帝測試表示，已看到某平台所謂「測試」，不予置評。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362357</guid>
      <pubDate>Fri, 25 Jul 2025 08:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claude 集成設計平台 Canva</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAnthropicAI%2Fstatus%2F1948489708385816666" target="_blank"&gt;宣佈&lt;/a&gt;其 AI 服務 Claude 已集成設計平台 Canva，這一集成旨在簡化從文本內容到圖形化表達的創作流程。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1458" src="https://static.oschina.net/uploads/space/2025/0725/155325_hioI_2720166.png" width="1290" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/155813_ek4B_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過這項新功能，用戶可以上傳任何書面內容，如博客文章、產品指南或會議記錄，並要求 Claude 將其轉化為帶有品牌風格的專業視覺設計。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362351</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362351</guid>
      <pubDate>Fri, 25 Jul 2025 07:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>《2025 年度技術人才報告》解讀：AI+開源重塑人才市場</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;LF Research 聯合 Linux Foundation Education 正式發佈了《2025 年度技術人才報告》。該報告是基於全球 500 多位招聘和培訓決策者的調研，重點探討了 AI 對技術崗位日益增長的影響、企業如何為這一工作轉型做好準備，以及如何通過開源與技能提升滿足新的人才需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="360" src="https://oscimg.oschina.net/oscnet/up-887ec60bec2ffdf3d0a7092dfbbd202fe35.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI 正在為眾多企業帶來深遠影響，94% 的組織認為 AI 將為其運營帶來顯著價值。但報告指出，不足一半的企業擁有適應 AI 時代所需的核心技術能力，難以釋放其業務與創新潛力。報告主要發現包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;68% 的企業缺乏具備 AI/ML 技能的員工；網絡安全與合規（65%）、FinOps（61%）、雲計算（59%）和平台工程（56%）等領域人才短缺的情況加劇了這個問題；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;44% 的受訪者認為「技術人才不足」是採納新技術的主要障礙；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;半數受訪組織表示，他們正在擴充 AI 專項人才隊伍，新增崗位包括 AI/ML 運維工程主管（64%）與 AI 產品經理（36%）。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;新興技術與技能缺口已開始實質地改變工作流程。三分之二的組織表示，AI 顯著改變了其團隊的工作方式。開發者需驗證 AI 生成的代碼，新員工需具備 AI 專業技能，許多初級的任務也被 AI 自動化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為應對這些變化，企業正在加大對技能提升的投入。報告發現：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;72% 的組織正在優先考慮提升現有員工的技能，遠高於 2024 年的 48%；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;技能提升的速度比招聘新人才快 62%，且技術培訓項目在提高員工留存率方面的效果高出 91%；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;71% 的組織在招聘時重視持有認證的人才，將其視為專業能力的有效驗證；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;56% 的組織依靠技能提升來滿足 AI/ML 崗位需求，而非新增招聘或外包。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;開源技術在 AI 落地中也起到了重要戰略作用。40% 的受訪者表示，企業正在利用開源框架、模型和工具來加速 AI 應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查顯示，採用開源實踐的企業在員工留存與技能發展方面表現更佳：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;91% 的組織認為技術培訓是提高員工留存的有效方式；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;84% 的組織表示，擁有開源文化可提高員工穩定性與滿意度。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362350</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362350</guid>
      <pubDate>Fri, 25 Jul 2025 07:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Qwen3-Coder 和 Kimi-K2 均已上線模力方舟</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Kimi-K2 和 Qwen3-Coder 這兩個模型是最近在編程任務上表現不錯的開源模型，關於二者的比較可閲讀這篇文章：&lt;em&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/news/362129/kimi-k2-vs-qwen-3-coder-coding-comparison"&gt;Kimi K2 和 Qwen-3 Coder 在編程任務的詳細對比&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/360215/kimi-k2"&gt;&lt;strong&gt;Kimi K2&lt;/strong&gt;&amp;nbsp;&lt;/a&gt;是一個最先進的混合專家 (MoE) 語言模型，激活參數為 320 億，總參數為 1 萬億。通過 Muon 優化器進行訓練，Kimi K2 在前沿知識、推理和編碼任務上表現出色，同時在智能體能力方面進行了精心優化。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/361848"&gt;&lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt;&lt;/a&gt;&amp;nbsp; 是一款專為代碼生成、代碼理解和高效開發場景設計的大型語言模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模力方舟已上線這兩個模型：&lt;/p&gt; 
&lt;p&gt;&lt;img height="798" src="https://static.oschina.net/uploads/space/2025/0725/153841_vb9V_2720166.png" width="2540" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/153900_equi_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;訪問網址&amp;nbsp;&lt;a href="https://ai.gitee.com/serverless-api" target="_blank"&gt;https://ai.gitee.com/serverless-api&amp;nbsp;&lt;/a&gt;即可體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362345</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362345</guid>
      <pubDate>Fri, 25 Jul 2025 07:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Solon 整合 LiteFlow 規則引擎：概念與實戰</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;一、引言&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在現代軟件開發中，規則引擎允許我們以聲明式的方式定義業務邏輯和決策路徑。LiteFlow 是一個輕量級、易於使用的組件式規則引擎，它可以與 Solon 應用無縫整合。本文將介紹如何在 Solon 項目中引入 LiteFlow，實現靈活的業務流程管理。&lt;/p&gt; 
&lt;h2&gt;二、LiteFlow 的核心概念&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;LiteFlow 簡介&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;LiteFlow 是一個基於 Java 的輕量級流程引擎，專為簡化複雜業務邏輯處理設計。通過將業務流程抽象為一系列的節點（components），LiteFlow 提供了一種清晰和可維護的方法來編排業務邏輯。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主要特點&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;組件化設計：業務邏輯分解為獨立的組件，每個組件執行特定的功能。 靈活的流程控制：支持同步和異步執行，以及條件分支、循環等控制結構。 易於配置：使用 XML、YAML 或程序式配置定義流程。&lt;/p&gt; 
&lt;h2&gt;三、實戰演示：在 Solon 中使用 LiteFlow&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;環境準備&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;確保你的開發環境已經安裝了 JDK 1.8 或以上版本，並且項目是基於 Solon 構建的。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加依賴&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在項目的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;pom.xml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件中添加 LiteFlow 的 Maven 依賴：&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;xml 複製代碼&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.yomahub&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;liteflow-solon-plugin&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;最新版本號&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;配置 LiteFlow&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;app.yml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件中配置 LiteFlow 的規則文件路徑：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;liteflow:&lt;/span&gt;
  &lt;span style="color:#986801"&gt;rule-source:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;classpath:liteflow-rules.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;定義組件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;創建組件類，每個類對應一個處理步驟：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; com.yomahub.liteflow.core.NodeComponent;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Component;

&lt;span style="color:#4078f2"&gt;@Component("componentA")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;ComponentA&lt;/span&gt; &lt;span style="color:#a626a4"&gt;extends&lt;/span&gt; &lt;span style="color:#c18401"&gt;NodeComponent&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;process&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        System.out.println(&lt;span style="color:#50a14f"&gt;"執行組件 A 的邏輯"&lt;/span&gt;);
        &lt;em&gt;// 添加業務邏輯代碼&lt;/em&gt;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;定義流程&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;liteflow-rules.xml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中定義業務流程，指定組件的執行順序：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;flow&lt;/span&gt; &lt;span style="color:#986801"&gt;id&lt;/span&gt;=&lt;span style="color:#50a14f"&gt;"chain1"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;then&lt;/span&gt; &lt;span style="color:#986801"&gt;value&lt;/span&gt;=&lt;span style="color:#50a14f"&gt;"componentA,componentB,componentC"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;flow&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;觸發流程執行&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在 Solon 應用中通過 LiteFlow 的 API 觸發流程執行：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; com.yomahub.liteflow.flow.FlowExecutor;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;FlowController&lt;/span&gt; {

    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; FlowExecutor flowExecutor;

    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/runFlow")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;runFlow&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;try&lt;/span&gt; {
            flowExecutor.execute2Resp(&lt;span style="color:#50a14f"&gt;"chain1"&lt;/span&gt;);
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"流程執行成功"&lt;/span&gt;;
        } &lt;span style="color:#a626a4"&gt;catch&lt;/span&gt; (Exception e) {
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"流程執行失敗: "&lt;/span&gt; + e.getMessage();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;測試與驗證&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;啓動 Solon 應用並訪問&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/runFlow&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;路徑，檢查控制枱輸出以驗證流程是否按預期執行。&lt;/p&gt; 
&lt;h2&gt;結論&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;通過整合 LiteFlow 規則引擎，Solon 應用可以更加靈活地處理複雜的業務流程。LiteFlow 的組件化和易配置性使得管理和維護業務邏輯變得更簡單。此外，藉助 LiteFlow 的強大功能，開發者可以構建出更加動態和可擴展的應用系統，滿足不斷變化的業務需求。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362560</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362560</guid>
      <pubDate>Wed, 16 Jul 2025 05:11:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
  </channel>
</rss>
