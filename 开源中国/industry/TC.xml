<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 10 Feb 2025 12:36:04 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Linux 內核新補丁調整 AC 電源插拔行為，向 Windows 看齊以提升硬件兼容性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;AMD 工程師主導優化，解決便攜設備休眠喚醒痛點。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;近日，AMD 工程師 Mario Limonciello 向 Linux 內核&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flinux-pm%2F20250208162210.3929473-1-superm1%40kernel.org%2F&quot; target=&quot;_blank&quot;&gt;提交了一系列補丁&lt;/a&gt;&lt;/u&gt;，旨在調整系統在&lt;strong&gt;s2idle（掛起到空閒）&lt;/strong&gt;狀態下的 AC 電源插拔行為，使其更貼近 Windows 11 的邏輯。&lt;/p&gt; 
&lt;p&gt;這一改動主要針對筆記本電腦、手持遊戲設備（如 Steam Deck 同類產品）在休眠時因電源狀態切換導致的兼容性問題，尤其是此前曝光的 Legion Go S（搭載 AMD Ryzen Z2 芯片）的固件級故障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;為何需要「模仿」Windows？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當前，Linux 與 Windows 在 s2idle 狀態下的電源行為存在關鍵差異：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;：插入或拔出 AC 電源時，系統會完全喚醒，若後續無用戶操作則重新進入睡眠。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;：AC 事件僅觸發短暫喚醒後立即重回休眠，可能導致硬件固件因快速狀態切換出現異常（例如某些設備無法正確處理快速進入/退出低功耗模式）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Limonciello 指出，由於 OEM 廠商通常基於 Windows 進行硬件驗證，Linux 的差異行為易暴露底層固件缺陷。新補丁通過記錄休眠前的電池狀態，並在 AC 事件後對比狀態變化，決定是否徹底喚醒系統，從而減少「兼容性陷阱」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技術細節：喚醒機制與能耗監控&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;喚醒邏輯重構&lt;/strong&gt;&lt;br&gt; 補丁在 ACPI 電池驅動中新增&lt;code&gt;suspend_state&lt;/code&gt;字段，休眠時保存當前電源狀態（如是否充電）。若喚醒後檢測到狀態變化（如從充電變為放電），則觸發系統完全喚醒，而非立即休眠。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;能耗統計透明化&lt;/strong&gt;&lt;br&gt; 新增&lt;code&gt;/sys/power/suspend_stats/last_sleep_energy&lt;/code&gt;文件，以&lt;strong&gt;毫安時（mAh）&lt;/strong&gt;為單位記錄上次休眠週期的電池消耗量，方便用戶空間工具分析功耗問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;爭議與用戶控制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;儘管新行為默認啓用，但開發者社區對其適用場景存在分歧。例如，若筆記本合蓋時連接電源，是否應強制喚醒？Limonciello 認為，這與用戶外接擴展塢的場景需求一致，但用戶仍可通過禁用 ACPI 電池設備的&lt;code&gt;power/wakeup&lt;/code&gt;屬性恢復舊邏輯。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;影響與未來展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此次調整尤其利好搭載 AMD 芯片的設備，但惠及所有支持 s2idle 的 x86/ARM 平台。隨着 Linux 在掌機市場的滲透（如 Steam OS 設備），此類優化將顯著提升用戶體驗。此外，補丁的「Windows 兼容性驅動」思路或成為未來硬件支持的新範式，減少廠商因生態差異對 Linux 的適配成本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;結語&lt;/strong&gt;&lt;br&gt; Linux 在電源管理領域的「向 Windows 學習」，並非妥協，而是以用戶體驗為優先的務實選擇。這一補丁不僅修復了長期存在的兼容性痛點，也為開源生態與 OEM 廠商的協作提供了新思路。未來，類似「求同存異」的優化或成常態，進一步模糊兩大操作系統在硬件支持上的體驗邊界。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</guid>
            <pubDate>Sat, 08 Feb 2025 11:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>圖解系列｜DeepSeek-R1 的出眾推理能力從何而來？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; DeepSeek-R1 到底有什麼特別之處？它為什麼能在推理任務上取得如此出色的表現？這背後的訓練方法又蘊含着怎樣的創新？&lt;/p&gt; 
 &lt;p&gt;當我們需要模型處理數學題、編程任務，或是進行邏輯分析時，高質量的推理能力顯得尤為重要。然而，傳統的訓練方法往往需要耗費大量人力物力，這對許多研究團隊和企業來説都是不小的負擔。&lt;/p&gt; 
 &lt;p&gt;今天這篇深度解析 DeepSeek-R1 訓練方法的文章，將展示一個令人耳目一新的解決方案：如何通過創新的強化學習方法，在少量高質量人工標註數據的情況下，打造出一個推理能力出眾的 AI 模型。文章詳細介紹了 DeepSeek 團隊如何通過&quot;自動驗證機制&quot;來訓練模型，這種方法不僅大大降低了對人工標註數據的依賴，還能持續提升模型的推理質量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Jay Alammar&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fa463c0670c30f6fa2098b0a2cfb8cedbd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 代表了人工智能發展的又一重要里程碑。對於機器學習領域的研究人員與開發者羣體而言，這次發佈之所以備受關注，主要有以下兩點：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;首先，這是一款開源權重的模型，並且提供了更小的、經過蒸餾的版本；&lt;/li&gt; 
 &lt;li&gt;其次，它公佈並深入探討了訓練方法，該方法能夠復現類似於 OpenAI O1 的推理模型。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;本文將帶您瞭解這一模型的構建過程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;目錄&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;01 回顧：大語言模型（LLMs）的訓練方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02 DeepSeek-R1 的訓練步驟&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.1- 長推理鏈的 SFT 數據&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.2- 一個過渡性的、擅長推理的高質量大語言模型（但在非推理任務上表現稍遜）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3- 利用大規模強化學習（RL）構建推理模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.1- 以推理為導向的大規模強化學習（R1-Zero）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.2- 利用過渡性推理模型生成 SFT 推理數據&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.3- 常規強化學習訓練階段&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03 模型架構&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 回顧：大語言模型（LLMs）的訓練方法&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;與大多數現有的大語言模型一樣，DeepSeek-R1 也是逐個生成 token，但其獨特之處在於擅長解決數學和推理問題。這是因為它能夠通過生成一系列思考 tokens 來詳細闡述其思考過程，從而更加深入地處理問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5b41809ec9dc436f27455aa39b8ef58c830.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下圖摘自書籍《Hands-On Large Language Models》的第 12 章，展示了創建高質量大語言模型的三個主要步驟：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5960076009014b645e62ad11df7e601f3dd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;語言建模階段&lt;/strong&gt;，我們利用海量的網絡數據訓練模型預測下一個詞彙，從而得到一個基礎模型。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;監督式微調階段&lt;/strong&gt;，這一步驟讓模型在執行指令和回答問題時更加得心應手，進而得到一個指令調優的模型或稱為監督式微調/SFT 模型。&lt;/p&gt; 
&lt;p&gt;3）最後是&lt;strong&gt;偏好調優階段&lt;/strong&gt;，這一步驟進一步優化模型的行為，使其更符合人類偏好，最終形成的是你在各種平台和應用中使用的偏好調優後的 LLM。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeek-R1 的訓練步驟&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek-R1 遵循了這一通用框架。其第一步的具體內容源自於之前關於 DeepSeek-V3 模型的研究論文[1]。R1 使用的是該論文中的基礎模型（並非最終的 DeepSeek-V3 模型），並且同樣經歷了 SFT（監督式微調）和偏好調優階段，但它的獨特之處在於這些階段的具體操作方法。&lt;/p&gt; 
&lt;p&gt;在 R1 的構建過程中，有三個關鍵點值得特別關注。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 長推理鏈的 SFT 數據&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71048a70e57a4dd98c33f2c0fb43d5a0d16.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這些長思維鏈推理的實例數量龐大（總共達到 60 萬個）。如此大規模的實例獲取難度極高，且若要依靠人工標註，成本也將極為昂貴。&lt;/strong&gt; 因此，這些實例的創建過程是我們需要強調的第二個獨特之處。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 一個過渡性的、擅長推理的高質量 LLM（但在非推理任務上表現稍遜）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;這些數據是由 R1 的前身，一個專注於推理但尚未命名的姊妹模型所生成的。這個姊妹模型受到了另一個模型 R1-Zero 的啓發（我們將在稍後討論）。它之所以意義重大，並不是因為它是一個非常好用的 LLM，而在於在它的創建過程中，幾乎無需依賴標註數據，僅通過大規模的強化學習，就能培育出一個擅長處理推理問題的模型。&lt;/p&gt; 
&lt;p&gt;接着，這個未命名的推理專家模型的輸出結果，可以用來訓練一個更為多能的模型，它不僅能夠處理推理任務，還能應對其他類型的任務，滿足用戶對大語言模型（LLM）的普遍期待。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4851fe74d4b6fa9ff29c1036a1790de83f4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 利用大規模強化學習（RL）構建推理模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此處分為兩個步驟：&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.1- 以推理為導向的大規模強化學習（R1-Zero）&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在此過程中，我們利用強化學習（RL）來構建一個臨時的推理模型。隨後，這個模型被用於生成用於監督式微調（SFT）的推理示例。然而，能夠創建這個模型的關鍵，在於之前的一項實驗，該實驗成功打造了一個名為 DeepSeek-R1-Zero 的早期模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fbae4d4fb50b77fa5484a9d220719bbe4d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;R1-Zero 的獨特之處在於，它能夠在沒有經過標註的 SFT 訓練集的情況下，依然在推理任務上表現卓越。它的訓練過程直接從預訓練的基礎模型出發，通過強化學習訓練（跳過了 SFT 階段）。它的表現非常出色，能夠與 O1 模型相媲美。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd68b8120aaa63d61a0ca7bb0b7333d62ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這一成就重要重大，因為數據一直是機器學習模型能力的助推器。那麼，這個模型是如何打破這一傳統的呢？這主要歸功於以下兩點：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 現代基礎模型在質量和能力上已經達到了一個臨界點（這個基礎模型是在高達 14.8 萬億的高質量 tokens 上訓練而成的）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 與通用聊天或寫作請求不同，推理問題可以實現自動驗證或標註。&lt;/strong&gt; 可以通過以下這個示例來説明這一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例：推理問題的自動驗證&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是一個可能出現在 RL 訓練步驟中的提示詞/問題：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;編寫一段 Python 代碼，獲取一個數字列表，返回排序後的列表，並在列表開頭添加數字 42。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這樣的問題非常適合自動驗證。假設我們將這個問題拋給正在訓練的模型，它會生成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用軟件語法檢查器可以驗證生成的代碼是否為有效的 Python 代碼。&lt;/li&gt; 
 &lt;li&gt;我們可以運行這段 Python 代碼，以檢查其是否能夠成功執行。&lt;/li&gt; 
 &lt;li&gt;其他現代代碼生成 LLM 可以創建單元測試來驗證代碼的行為是否符合預期（它們自身無需具備推理能力）。&lt;/li&gt; 
 &lt;li&gt;我們甚至可以進一步，通過測量代碼的執行時間，讓訓練過程偏好那些性能更優的解決方案，即使其他解決方案也是正確的 Python 程序。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在訓練步驟中，我們可以向模型提出這樣的問題，並生成多種可能的解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f83bf0627d5f3ff8f1fda69f2a0769899e6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們可以不依賴人工幹預，自動進行檢查，發現第一個輸出根本不是代碼。第二個輸出是代碼，但並非 Python 代碼。第三個輸出看似是一個解決方案，卻未能通過單元測試，而第四個輸出則是正確的解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1c61910f7a45c46610b945fcd73cf50a89.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這些反饋都是可以直接用來優化模型的信號。這一過程當然是在大量示例（以小批量形式）和連續的訓練步驟中完成的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c2e60359299a142483ec274c460a0c90dc6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這些獎勵信號和模型更新是模型在強化學習訓練過程中不斷進步的關鍵，如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ce02ceb2d7a3049768b4b796755b83f0f9f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;與此能力提升相伴的是，模型生成了更長的響應，即使用了更多的思考 tokens 來處理問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4c90ef53271c751b695ad334dddfbb87f40.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;儘管這個過程很有價值，但 R1-Zero 模型在推理問題上的高分表現背後，仍存在一些問題，使其實際可用性未達理想狀態。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;雖然 DeepSeek-R1-Zero 展現出了卓越的推理能力，並自主發展出了出人意料的強大推理行為，但它也遭遇了一些挑戰，比如文本可讀性不佳和語言混雜等問題。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;R1 模型的設計目標是提高可用性。因此，它（DeepSeek-R1-Zero）不僅僅完全依賴於強化學習過程，而是如前文所述，在以下兩個方面發揮作用：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 創建一個過渡性的推理模型，用以生成監督式微調（SFT）的數據點。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 訓練 R1 模型，以在推理和非推理問題上取得進步（利用其他類型的驗證器）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-694a728dfc22ac72182045659f53b114a1b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.2- 利用過渡性推理模型生成 SFT 推理數據&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;為了提升過渡性推理模型的實際效用，我們對其進行了監督式微調（SFT）訓練，這一步驟在數千個推理問題示例上進行（部分示例由 R1-Zero 生成並篩選）。在論文中，這些示例被稱為&quot;冷啓動數據&quot;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2.3.1. 冷啓動階段&lt;/p&gt; 
 &lt;p&gt;與 DeepSeek-R1-Zero 不同，為了防止基礎模型在強化學習訓練初期出現不穩定的冷啓動問題，對於 DeepSeek-R1，我們構建並收集了少量長思維鏈（CoT）數據對模型進行微調，將其作為初始的強化學習策略模型。為收集這類數據，我們探索了多種方法：使用帶有長 CoT 示例的小樣本提示技術、直接提示模型生成帶有反思和驗證的詳細答案、收集 DeepSeek-R1-Zero 生成的易讀格式輸出，並通過人工標註員對結果進行後處理細化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;但或許你會問，既然我們已經有了這些數據，為什麼還需要依賴強化學習過程呢？答案在於數據的規模。我們可以獲取的可能只有 5,000 個示例的數據集，而訓練 R1 則需要 600,000 個示例。&lt;/strong&gt; 這個過渡性模型幫助我們縮小了這一差距，並使我們能夠合成生成那些極為重要的數據。&lt;/p&gt; 
&lt;p&gt;對於監督式微調（SFT）這一概念，可能你還不太熟悉，它是一種訓練過程，通過向模型展示形式為提示詞和正確補全的訓練示例來進行。下面這個圖展示了書籍《Hands-On Large Language Models》第 12 章中的一些 SFT 訓練示例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e00bd1bb414511cf4a13d9225c9ed6bb7ba.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.3- 常規強化學習訓練階段&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;這樣，R1 模型不僅在推理任務上表現卓越，還能有效地應對其他非推理類任務。這一過程與我們之前提到的強化學習過程相似，但因為它涵蓋了非推理領域的應用，所以它還引入了一個實用性獎勵模型和安全性獎勵模型（與 Llama 模型有相似之處），用於處理這些應用領域的提示詞。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cd6bf829caa63d1804a38dcdf71e88e2293.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型架構&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;與 GPT2[2] 和 GPT3[3] 等同源的早期模型一樣，DeepSeek-R1 也是由 Transformer[4] 解碼器塊堆疊而成，總共包含了 61 個這樣的塊。其中，前三個塊是密集層，而後續的則是採用了混合專家層（MoE）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-817d8e03a6a9f616d918a3f53eb7e8bdede.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於模型的維度大小和其他超參數配置，具體信息如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0acee698853f2545eaf2350f4bae0ca92ea.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有關模型架構的更多詳細信息，可以在他們之前發表的兩篇論文中找到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V3 Technical Report[1]&lt;/li&gt; 
 &lt;li&gt;DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models[5]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 Conclusion&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;通過上述內容，相信你現在應該對 DeepSeek-R1 模型有了基本的理解。&lt;/p&gt; 
&lt;p&gt;如果你覺得需要更多基礎知識來理解這篇文章，我建議你獲取一本《Hands-On Large Language Models》[6]或者在線在 O&#39;Reilly[7] 上閲讀，並在 Github[8] 上查看相關內容。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Jay Alammar&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Machine learning R&amp;amp;D. Builder. Writer. Visualizing artificial intelligence &amp;amp; machine learning one concept at a time. @CohereAI.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你覺得 AI 模型最難掌握的是哪種推理能力？歡迎在評論區分享你的觀點👇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中鏈接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2412.19437v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2412.19437v1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-gpt2%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-gpt2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fhow-gpt3-works-visualizations-animations%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/how-gpt3-works-visualizations-animations/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-transformer%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-transformer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2401.06066&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llm-book.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.llm-book.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearning.oreilly.com%2Flibrary%2Fview%2Fhands-on-large-language%2F9781098150952%2F&quot; target=&quot;_blank&quot;&gt;https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FhandsOnLLM%2FHands-On-Large-Language-Models&quot; target=&quot;_blank&quot;&gt;https://github.com/handsOnLLM/Hands-On-Large-Language-Models&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsletter.languagemodels.co%2Fp%2Fthe-illustrated-deepseek-r1&quot; target=&quot;_blank&quot;&gt;https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17553692</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17553692</guid>
            <pubDate>Sat, 08 Feb 2025 10:19:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>豆包開源視頻生成模型 VideoWorld</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmXaktIsD3w5BgCJQb6R7xQ&quot; target=&quot;_blank&quot;&gt;據豆包大模型團隊官方公眾號消息&lt;/a&gt;&lt;/u&gt;，在北京交通大學和中國科學技術大學的聯合研究下，由豆包大模型團隊提出的 「VideoWorld」 視頻生成實驗模型近日正式開源。&lt;/p&gt; 
&lt;p&gt;據介紹，不同於 Sora 、DALL-E 、Midjourney 等主流多模態模型，&lt;strong&gt;VideoWorld 在業界首次實現無需依賴語言模型，即可認知世界&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.09781&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.09781&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代碼鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2FVideoWorld&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/VideoWorld&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;項目主頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmaverickren.github.io%2FVideoWorld.github.io&quot; target=&quot;_blank&quot;&gt;https://maverickren.github.io/VideoWorld.github.io&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;「VideoWorld」 通過分析和處理大量視頻數據，實現了複雜的推理、規劃和決策能力。研究團隊的實驗顯示，模型在僅有 300M 參數的情況下，便取得了顯著的效果。與現有依賴語言或標籤數據的模型不同，VideoWorld 能夠獨立進行知識學習，尤其在摺紙、打領結等複雜任務中，能夠提供更加直觀的學習方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fc6aac365dbf1a8e0403b8bb24da8452019.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了驗證該模型的有效性，研究團隊搭建了圍棋對戰和機器人模擬操控兩種實驗環境。圍棋作為一項高度策略性遊戲，可以有效評估模型的規則學習和推理能力，而機器人任務則考察模型在控制和規劃方面的表現。在訓練階段，模型通過觀看大量視頻演示數據，逐步建立起對未來畫面的預測能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332996</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332996</guid>
            <pubDate>Sat, 08 Feb 2025 10:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 服務站點大全</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;中國信息通信研究院去年 7 月 11 日發佈國內首個算力互聯公共服務平台，並聯合產業界開展算力互聯網共識共創行動。&lt;/p&gt; 
&lt;p&gt;該算力互聯公共服務平台是推進和管理全國算力互聯互通和算力互聯網體系的綜合服務平台，包括算力標識管理、算力互聯網業務查詢、算力統一大市場、政策和研究、標準體系、開源項目和運行監測等功能。&lt;/p&gt; 
&lt;p&gt;中國信通院今日宣佈，為便利國內 AI 開發者「找調用算力」需求，算力互聯公共服務平台宣佈增設全球雲服務商 DeepSeek 服務能力彙總功能頁面（截至 2 月 5 日已彙集 22 家服務商）。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstateioc.cn%2Farticle-details%2FVjX&quot; target=&quot;_blank&quot;&gt;https://stateioc.cn/article-details/VjX&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;最後歡迎各位使用 Gitee AI —— Gitee AI 的 Serverless API 為您提供開箱即用的企業級的大模型 API 服務。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/174609_Xr4I_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332995</guid>
            <pubDate>Sat, 08 Feb 2025 09:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>ai.com 域名現已跳轉至 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;現在在瀏覽器輸入&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.com%2F&quot; target=&quot;_blank&quot;&gt;ai.com&lt;/a&gt;，將直接重定向至 DeepSeek 官網 (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.deepseek.com%2F&quot; target=&quot;_blank&quot;&gt;https://chat.deepseek.com/&lt;/a&gt;)。&lt;/p&gt; 
&lt;p&gt;ai.com 域名的定位被視作前沿 AI 的象徵，此前這一域名曾長期跳轉至 ChatGPT、谷歌 Gemini 以及馬斯克的 xAI 官網。根據 Whois 數據，ai.com 域名註冊於 1993 年，有效期直至 2031 年 5 月，註冊聯繫人來自馬來西亞首都吉隆坡。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;219&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ceffc7eb4acfec05d9bcabc263bf478854.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332978</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332978</guid>
            <pubDate>Sat, 08 Feb 2025 08:30:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>消息稱軟銀投資 400 億美元，取代微軟成為 OpenAI 最大金主</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息人士向 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F07%2Fsoftbank-set-to-invest-40-billion-in-openai-at-260-billion-valuation-sources-say.html&quot; target=&quot;_blank&quot;&gt;CNBC &lt;/a&gt;透露，軟銀即將完成對 OpenAI 的 400 億美元初始投資，投資前估值為 2600 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Faber 報道稱軟銀將在未來 12 到 24 個月內支付這筆資金，這意味着 OpenAI 的投資後估值將達到 3000 億美元，第一筆款項最快將於今年春季到賬。軟銀最多可以籌集其中的 100 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;295&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-34a9ea12a4cc3504f16154eda1fdbbc331a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;部分資金預計將用於 OpenAI 對 Stargate 的承諾。Stargate 是軟銀、OpenAI 和甲骨文公司的合資企業，由美國現任總統唐納德-特朗普於今年 1 月宣佈成立。該計劃要求向美國的人工智能基礎設施投資數十億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一輪融資也意味着軟銀將超越微軟，成為 OpenAI 公司的最大投資者。去年 10 月，私人投資者對 OpenAI 的估值為 1570 億美元。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332971/softbank-40-billion-openai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332971/softbank-40-billion-openai</guid>
            <pubDate>Sat, 08 Feb 2025 08:15:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Yandex 開發並開源 Perforator，每年可為企業節省數十億美元的服務器基礎設施成本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;推出&lt;/span&gt; &lt;span&gt;Perforator&lt;/span&gt;&lt;span&gt;，這是一款可以識別和評估公司整個代碼庫中效率低下的代碼的工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;幫助開發人員識別最佔資源的代碼部分，並提供詳細的統計數據，以便後續優化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;該解決方案可以幫助企業每年減少 &lt;/span&gt;&lt;span&gt;20% &lt;/span&gt;&lt;span&gt;的 &lt;/span&gt;&lt;span&gt;CPU &lt;/span&gt;&lt;span&gt;資源使用量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通過利，用&lt;/span&gt;&lt;span&gt;Perforator&lt;/span&gt;&lt;span&gt;，企業可以根據公司規模節省數百萬甚至數十億美元的開支，並將資源用於進一步的創新和增長。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;可通過&lt;/span&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyandex%2Fperforator&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#1155cc&quot;&gt;GitHub&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;免費訪問。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（上海，&lt;/span&gt;&lt;span&gt;2025&lt;/span&gt;&lt;span&gt;年&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;月&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;日）全球領先的科技公司 &lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;開發並開源了&lt;/span&gt;&lt;span&gt; Perforator&lt;/span&gt;&lt;span&gt;，這是一款用於對服務器和應用程序進行持續實時監控和分析的創新工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;幫助開發人員識別最佔資源的代碼部分，並提供詳細的統計數據，以便進行後續優化。通過識別代碼中的低效部分並支持基於配置文件的優化，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;提供了準確的數據，使企業能夠手動優化其應用程序，根據公司規模，降低基礎設施成本最多可達 &lt;/span&gt;&lt;span&gt;20%&lt;/span&gt;&lt;span&gt;。這每年可能節省數百萬甚至數十億美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;幫助企業在不犧牲性能的情況下最大化服務器的使用效率，&lt;/span&gt;&lt;span&gt;」 Yandex &lt;/span&gt;&lt;span&gt;的高級開發人員、&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;團隊負責人&lt;/span&gt;&lt;span&gt; Sergey Skvortsov &lt;/span&gt;&lt;span&gt;表示。&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;企業使用&lt;/span&gt;&lt;span&gt; Perforator &lt;/span&gt;&lt;span&gt;可以優化代碼，減少服務器負載，最終降低能源和設備成本。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;為什麼使用 &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Perforator&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;資源優化對於大型數據中心、大型科技公司以及資源有限的小型企業和初創公司至關重要。公司可以利用 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;優化現有的基礎設施，而無需投資額外的設備，也不犧牲性能。該工具已經在 &lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;的許多服務中使用了超過一年，現在可以供全球的公司、開發人員和研究人員使用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;公司可以將 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;部署在自己的服務器上，減少對外部雲服務提供商的依賴，同時保持對數據的完全控制。這使得 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;非常適合那些對數據安全要求嚴格且在封閉基礎設施中運營的組織。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;可以為各種規模的公司帶來益處，從擁有&lt;/span&gt;&lt;span&gt; 10 &lt;/span&gt;&lt;span&gt;至&lt;/span&gt;&lt;span&gt; 100 &lt;/span&gt;&lt;span&gt;台服務器的小型企業，每年節省數百萬美元，到擁有數千台服務器甚至更多的大型企業，每年節省數億美元甚至數十億美元，&lt;/span&gt;&lt;span&gt;」 Sergey Skvortsov &lt;/span&gt;&lt;span&gt;指出。&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;無論公司規模如何，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;都能幫助您減少基礎設施成本，為進一步的創新和增長釋放更多資源。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;如何工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;提供了關於服務器資源使用的詳細洞察，並分析代碼對性能的影響，突出了哪些應用程序消耗了最多的系統資源。&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;使用&lt;/span&gt;&lt;span&gt; eBPF &lt;/span&gt;&lt;span&gt;技術在&lt;/span&gt;&lt;span&gt; Linux &lt;/span&gt;&lt;span&gt;內核中運行小程序，既安全又不會拖慢系統速度。&lt;/span&gt;&lt;span&gt;eBPF &lt;/span&gt;&lt;span&gt;能夠在不更改源代碼的情況下，改善監控、安全性和性能優化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;支持&lt;/span&gt;&lt;span&gt; C&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;C++&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Go&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Rust&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Python &lt;/span&gt;&lt;span&gt;和 &lt;/span&gt;&lt;span&gt;Java &lt;/span&gt;&lt;span&gt;等原生編程語言。該解決方案通過火焰圖提供深入的分析和數據可視化，使問題診斷變得易於管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;287&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f866d0af24a5577182b973257c103fef72e.png&quot; width=&quot;602&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;生成的火焰圖示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;在&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;的高需求環境中經過了超過一年的實戰測試，提供了廣泛的功能，使其成為一款可靠且多功能的服務器性能監控和優化解決方案，&lt;/span&gt;&lt;span&gt;」 Sergey Skvortsov&lt;/span&gt;&lt;span&gt;補充道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;的一個關鍵優勢是支持基於配置文件的優化（&lt;/span&gt;&lt;span&gt;PGO&lt;/span&gt;&lt;span&gt;），它能夠自動將&lt;/span&gt;&lt;span&gt; C++ &lt;/span&gt;&lt;span&gt;程序的速度提高多達 &lt;/span&gt;&lt;span&gt;10%&lt;/span&gt;&lt;span&gt;。此外，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;設計可以在個別計算機上無縫運行，使其不僅適合大型企業，還能為初創公司和科技愛好者提供便利。更重要的是，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;為大企業提供了包括&lt;/span&gt;&lt;span&gt; A/B &lt;/span&gt;&lt;span&gt;測試功能在內的重要特性，幫助做出更明智的決策。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;為開發人員和企業提供的開源解決方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;將&lt;/span&gt;&lt;span&gt; Perforator &lt;/span&gt;&lt;span&gt;開源的決定體現了&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;致力於促進社區合作開發系統技術的承諾。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「我們相信，開源諸如此類基礎系統的技術能夠推動全球技術創新」， &lt;/span&gt;&lt;span&gt;Sergey Skvortsov&lt;/span&gt; &lt;span&gt;補充道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;我們的目標是讓我們的技術造福全球，併為開發人員和企業提供價值。此外，技術的開放性使我們能夠與社區共同做出有關配置文件分析基礎設施開發的決策。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;接下來會發生什麼？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;將在近期增加更多功能，包括與&lt;/span&gt;&lt;span&gt; Python &lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt; Java &lt;/span&gt;&lt;span&gt;的更好集成以及對事件的更精確分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;的源代碼現已在&lt;/span&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyandex%2Fperforator&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#1155cc&quot;&gt;GitHub&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;上公開，和其他&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;開源解決方案一起提供，如&lt;/span&gt;&lt;span&gt;YaFSDP&lt;/span&gt;&lt;span&gt;，這是一個旨在加速大語言模型訓練的工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;是&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;開源工具系列中的最新成員。您可以在&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.yandex%2Fen%2F&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;此頁面&lt;/span&gt;&lt;/a&gt;&lt;span&gt;查看該公司所有的開源項目，包括&lt;/span&gt;&lt;span&gt; YaFSDP&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;AQLM&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Ytsaurus &lt;/span&gt;&lt;span&gt;等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332970</guid>
            <pubDate>Sat, 08 Feb 2025 08:14:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>GitHub Copilot：Agent 覺醒</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文翻譯自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fnews-insights%2Fproduct-news%2Fgithub-copilot-the-agent-awakens%2F&quot; target=&quot;_blank&quot;&gt;https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ad483c840f09803ba7d525bf909fa01465.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當我們於 2021 年推出 GitHub Copilot 時，我們有一個明確的目標：通過一個幫助開發者編寫更好代碼的 AI 編程助手，讓開發者的生活變得更輕鬆。這個名字反映了我們的信念，即人工智能（AI）不會取代開發者。相反，它始終站在開發者身邊。而且，就像任何優秀的副駕駛一樣，Copilot 也可以獨立飛行：例如，在提供 PR 回覆、自動修復安全漏洞或頭腦風暴如何實現問題解決方案時。&lt;/p&gt; 
&lt;p&gt;今天，我們用更加強大的&lt;strong&gt;代理式人工智能 (agentic AI)&lt;/strong&gt;升級了&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffeatures%2Fcopilot%2Fwhats-new%3Futm_source%3Dagent-awakens-announcement%26utm_medium%3Dblogtop%26utm_campaign%3Dagentic-ai&quot; target=&quot;_blank&quot;&gt;GitHub Copilot&lt;/a&gt;——推出&lt;strong&gt;代理模式 (agent mode)&lt;/strong&gt;，併發布 Copilot Edits 的 GA 版本，兩者均已在 VS Code 中上線。&lt;/p&gt; 
&lt;p&gt;我們在模型選擇器中為所有 Copilot 用戶增加了 Gemini 2.0 Flash。我們還首次展示了 Copilot 的新自主代理，代號為 Project Padawan。從代碼補全、聊天、多文件編輯到工作空間和代理，Copilot 將人類置於軟件開發這一創造性工作的中心。AI 幫助處理你不想做的事情，這樣你就有更多時間做自己想做的事情。&lt;/p&gt; 
&lt;h2&gt;代理模式 (Agent mode) 進入預覽階段&lt;/h2&gt; 
&lt;p&gt;GitHub Copilot 的新代理模式能夠迭代自己的代碼，識別錯誤並自動修復。它可以建議終端命令並要求您執行它們。它還可以分析運行時錯誤並具有自我修復功能。&lt;/p&gt; 
&lt;p&gt;在代理模式下，Copilot 不僅會迭代自己的輸出，還會迭代輸出結果。它會一直迭代，直到完成所有必要的子任務以完成您的提示。現在，Copilot 不僅能夠執行您請求的任務，還能夠推斷出一些未指定但也是實現主要請求所必需的額外任務。更好的是，它能夠捕捉到自己的錯誤，讓您無需從終端複製/粘貼回聊天中。&lt;/p&gt; 
&lt;p&gt;以下是一個示例，展示了 GitHub Copilot 如何構建一個用於跟蹤馬拉松訓練的 Web 應用程序：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fof--3Fq1M3w%3Ffeature%3Doembed&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/embed/of--3Fq1M3w?feature=oembed&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要開始使用，您需要下載 VS Code Insiders，然後為 GitHub Copilot Chat 啓用代理模式設置：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ba42dfaaf982a3e645b4436884e52e9dbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然後，在 Copilot 編輯面板中，從「編輯」切換到模型選擇器旁邊的「Agent」：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/113603_Wgac_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;代理模式將改變開發者在使用編輯器時的工作方式；因此，我們將其帶給 Copilot 支持的所有 IDE。我們也知道今天的 Insiders 版本並不完美，並歡迎您在接下來的幾個月裏提供反饋，以便我們改進 VS Code 和底層代理技術。&lt;/p&gt; 
&lt;h2&gt;Copilot Edits 在 VS Code 中已正式 GA&lt;/h2&gt; 
&lt;p&gt;去年 10 月在 GitHub Universe 上宣佈的 Copilot Edits，結合了 Chat 和 Inline Chat 的優點，具有對話流程和能夠在您管理的文件集中進行行內更改的能力。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%2Fissues%2F95&quot; target=&quot;_blank&quot;&gt;您之前提供的反饋&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%2Fissues%2F1098&quot; target=&quot;_blank&quot;&gt;在 GitHub Universe 上&lt;/a&gt;對於將此功能作為 GA 版本發佈到 VS Code 至關重要。感謝！&lt;/p&gt; 
&lt;p&gt;在 Copilot Edits 中，您指定要編輯的一組文件，然後使用自然語言向 GitHub Copilot 提出您所需的內容。Copilot Edits 通過為快速迭代設計的 UI，在您的代碼空間中對多個文件進行行內更改。在審查建議的更改、接受可行的更改並進行後續詢問時，您始終保持在代碼的流程中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c40d04de582b53363ee3ddcdea11b12a89a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在這背後，Copilot Edits 利用雙模型架構來提升編輯效率和準確性。首先，一個基礎語言模型會考慮 Edits 會話的完整上下文來生成初始編輯建議。您可以在以下基礎語言模型中選擇您偏好的一個：OpenAI 的 GPT-4o、o1、o3-mini、Anthropic 的 Claude 3.5 Sonnet，以及現在新增的 Google 的 Gemini 2.0 Flash。為了獲得最佳體驗，我們開發了一個推測性解碼端點，針對快速應用文件中的更改進行了優化。基礎模型提出的編輯建議會被髮送到推測性解碼端點，該端點隨後將在編輯器中直接提出這些更改。&lt;/p&gt; 
&lt;p&gt;Copilot Edits 之所以有效，是因為它將控制權交給了您，從設置正確上下文到接受更改。整個過程是迭代的：當模型出錯時，您可以審查多個文件中的更改，接受好的更改並迭代，直到與 Copilot 一起找到正確的解決方案。接受更改後，您可以運行代碼以驗證更改，並在需要時在 Copilot Edits 中撤銷更改，以回到先前的有效工作狀態。Copilot Edits 位於次級側邊欄（默認位於右側），這樣您在審查建議的更改時可以與主側邊欄中的視圖（如資源管理器、調試或源代碼控制視圖）進行交互。例如，您可以在左側的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fdocs%2Feditor%2Ftesting&quot; target=&quot;_blank&quot;&gt;測試視圖中&lt;/a&gt;運行單元測試，同時使用右側的 Copilot Edits 視圖，這樣在每次迭代中，您都可以驗證 Copilot Edits 提出的更改是否通過了您的單元測試。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fdocs%2Feditor%2Fvoice&quot; target=&quot;_blank&quot;&gt;通過語音&lt;/a&gt;在使用 Copilot 修改時是一種自然的體驗。只需與 Copilot 對話，就能使互動變得順暢且具有對話性。這幾乎就像是與一位在該領域具有專業知識的同事互動，使用你在現實生活中結對編程時相同的迭代流程。&lt;/p&gt; 
&lt;p&gt;接下來在我們的路線圖上，我們將改進「應用更改」的投機解碼端點性能，支持從 Copilot Chat 過渡到 Copilot Edits，通過保留上下文來實現，向工作集建議文件，並允許您撤銷建議的塊。如果您想成為第一批體驗這些改進的人，請確保使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Finsiders%2F&quot; target=&quot;_blank&quot;&gt;VS Code Insiders&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat&quot; target=&quot;_blank&quot;&gt;GitHub Copilot Chat&lt;/a&gt;擴展的預發佈版本。為了幫助我們改進這個功能，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%3Futm_source%3Dagent-awakens-announcement%26utm_medium%3Dblog%26utm_campaign%3Dagentic-ai&quot; target=&quot;_blank&quot;&gt;請在我們的倉庫中提交問題&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;除了 VS Code 的 GA 之外，Copilot Edits 現在也在 Visual Studio 2022 中處於預覽階段。&lt;/p&gt; 
&lt;h2&gt;Padawan 項目：GitHub 上的 SWE 代理&lt;/h2&gt; 
&lt;p&gt;我們激動地與大家分享我們自主開發的 SWE（軟件工程師）智能代理，以及我們設想這類代理將如何融入 GitHub 用戶體驗。&lt;/p&gt; 
&lt;p&gt;當我們在代號 Project Padawan 的產品今年晚些時候發佈時，您將可以直接將問題分配給 GitHub Copilot，使用任何 GitHub 客戶端，並讓它生成經過全面測試的拉取請求。一旦任務完成，Copilot 將指派人類審閲者對 PR 進行審核，並努力解決他們提出的反饋。從某種意義上説，這就像將 Copilot 作為貢獻者引入 GitHub 上的每一個倉庫。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/114025_eVHJ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fembed%2FVWvV2-XwBMM%3Ffeature%3Doembed&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/embed/VWvV2-XwBMM?feature=oembed&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;該功能背後，Copilot 會為分配給它的每個任務自動啓動一個安全的雲沙盒。然後它異步克隆倉庫，設置環境，分析代碼庫，編輯必要的文件，並構建、測試和檢查代碼。此外，Copilot 還會考慮問題或 PR 中的任何討論，以及倉庫中的任何自定義指令，以便它理解任務的全貌意圖，以及項目的指南和約定。&lt;/p&gt; 
&lt;p&gt;就像我們之前在 Copilot 擴展和 Copilot 模型選擇器中做的那樣，我們也將提供機會將集成到這個 AI 原生工作流程中，並與合作伙伴和客戶緊密合作，形成一個緊密的反饋循環。我們相信 Project Padawan 的最終狀態將改變團隊管理關鍵但日常任務的方式，例如修復錯誤或創建和維護自動化測試。因為最終，一切都是關於通過讓他們專注於重要的事情來賦予開發者力量，並讓協作者做其餘的工作。別擔心，我們會保持耐心，所以代理不會「黑化」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332928/github-copilot-the-agent-awakens</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332928/github-copilot-the-agent-awakens</guid>
            <pubDate>Sat, 08 Feb 2025 03:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 社區動態 2025 年 1 月</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎大家收看《RWKV 社區最新動態》，本期內容收錄了 RWKV 社區 2025 年 1 月的最新動態。&lt;/p&gt; 
&lt;p&gt;只需 3 分鐘，快速瞭解 RWKV 社區 1 月都有哪些新鮮事！&lt;/p&gt; 
&lt;h2&gt;1 月動態省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 學術研究動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新論文： Rate-Aware Learned Speech Compression（RWKV 語音壓縮）&lt;/li&gt; 
   &lt;li&gt;新論文： RWKV-UNet（RWKV 醫學圖像分割）&lt;/li&gt; 
   &lt;li&gt;新論文： FSSC（RWKV 觸覺傳感跨域適應）&lt;/li&gt; 
   &lt;li&gt;新論文： TRP（RWKV 知識圖譜補全）&lt;/li&gt; 
   &lt;li&gt;新論文： TCVADS（RWKV 視頻異常檢測）&lt;/li&gt; 
   &lt;li&gt;新論文： RWKV Voice Dialog System（RWKV 語音對話系統）&lt;/li&gt; 
   &lt;li&gt;新論文： Visualrwkv-Hm（RWKV 視覺語言模型）&lt;/li&gt; 
   &lt;li&gt;新論文： AutoGMM-RWKV（RWKV 無線傳感器網絡安全）&lt;/li&gt; 
   &lt;li&gt;新論文： Revenge of the Fallen?（RWKV 語言理解對比研究）&lt;/li&gt; 
   &lt;li&gt;新論文： Enhancing Transformer RNNs（RWKV 多時間視角增強）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新聞動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新模型： RKWV-7-1.5B&lt;/li&gt; 
   &lt;li&gt;新模型： RKWV-7-0.4B&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區活動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 創始人閉門會開啓報名&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區項目動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV Othello&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 學術研究動態&lt;/h2&gt; 
&lt;p&gt;RWKV 學術研究包括&lt;strong&gt;基於 RWKV 架構的新論文&lt;/strong&gt;或 &lt;strong&gt;RWKV 社區參加的學術研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Rate-Aware Learned Speech Compression&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Rate-Aware Learned Speech Compression&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.11999&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.11999&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-01-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這篇論文提出了一種基於通道感知熵模型的學習語音壓縮方案，該方案通過替換傳統的量化器來增強率失真性能。它利用多尺度卷積和 RWKV 混合塊來提高編碼器和解碼器的表示能力。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，與現有編解碼器相比，提出的方法在比特率節省和聲學質量指標方面取得了顯著改善。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f7caaf051f652da78952613f6f383bf0d0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-UNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：RWKV-UNet: Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-01-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 RWKV-UNet，它將 RWKV 結構融入 U-Net 用於醫學圖像分割。通過 IR-RWKV 模塊增強長距離依賴捕獲能力，結合 CCM 模塊改善跳躍連接。&lt;/p&gt; 
&lt;p&gt;實驗表明，RWKV-UNet 在多個數據集上取得 SOTA 性能，平衡了性能和效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ba61005fb424e4a90b230f40c5da963eedd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;FSSC&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Reducing Cross-Sensor Domain Gaps in Tactile Sensing via Few-Sample-Driven Style-to-Content Unsupervised Domain Adaptation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F1424-8220%2F25%2F1%2F256&quot; target=&quot;_blank&quot;&gt;https://www.mdpi.com/1424-8220/25/1/256&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-01-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這篇論文介紹了 FSSC，一種全新的 few-sample-driven style-to-content 無監督域適應方法。它採用基於 RWKV 架構的設計來應對跨傳感器域適應中的難題，例如傳感器差異導致的域差距等問題。藉助 GLAB 層、FST 模塊等重要組件，它達成了有效減少觸覺傳感跨傳感器域差距的目標。&lt;/p&gt; 
&lt;p&gt;實驗表明，FSSC 在跨傳感器域適應任務的準確性以及對少量樣本的利用效率上均超越了現有的先進方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c9929c53128b28220a6b2be13e7004e05d5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV Knowledge Graph Completion&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Efficient Relational Context Perception for Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00397&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.00397&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-12-31&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文提出一種用於知識圖譜補全的新方法，它採用受 Rwkv 啓發的 Triple Receptance Perception (TRP) 架構來解決先前知識圖譜嵌入模型的缺點，如表達能力有限、計算成本高等問題。通過 TRP 中的時間混合和通道混合模塊等關鍵要素，它實現了高效且高質量的知識圖譜補全。&lt;/p&gt; 
&lt;p&gt;實驗表明，該方法在鏈接預測和三元分類任務方面都優於最先進的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-651119224e074229f55231cb42a9b12bc21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;TCVADS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Injecting Explainability and Lightweight Design into Weakly Supervised Video Anomaly Detection Systems&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.20201&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.20201&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-12-28&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文介紹了一種名為 TCVADS 的視頻異常檢測系統。該系統採用兩個階段的運行模式。在第一階段，系統使用增強的 RWKV 模塊來進行高效的時間序列分析。通過結合知識蒸餾和跨模態學習技術，TCVADS 在性能上優於現有的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7948ea9998ad0a372ce2ede11942518b7bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV Voice Dialog System&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Voice dialog system based on RWKV model&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10762107&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10762107&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-11-28&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出開發一個面向老年人的智能語音對話系統，採用經 LoRA 微調的 RWKV 模型。實驗結果表明它提高了答案的流暢性和合理性，在老年護理方面有應用潛力，未來工作會對模型進行優化。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b9cb2625db793016ac552cb831c4bb0a7a0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Visualrwkv-Hm&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Visualrwkv-Hm: Enhancing Linear Visual-Language Models Via Hybrid Mixing&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5028149&quot; target=&quot;_blank&quot;&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5028149&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-11-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 VisualRWKV-HM，這是一種線性複雜度的視覺語言模型。它基於 RWKV 整合了時間和跨狀態混合。在多個基準測試上達到了 SOTA，在 24K 上下文時比 LLaVA-1.5 等模型效率更高，還展現出強大的可擴展性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d60804f11cb6f97d2d77b7d9b04c8202f47.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;AutoGMM-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：AutoGMM-RWKV: A Detecting Scheme Based on Attention Mechanisms Against Selective Forwarding Attacks in Wireless Sensor Networks&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10729884&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10729884&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-10-23&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 AutoGMM-RWKV 用於檢測無線傳感器網絡中的選擇性轉發攻擊。它聚焦於節點單輪轉發率時間序列，通過將自編碼器、高斯混合模型和 K - 均值與 RWKV 相結合，提高了檢測精度。模擬結果顯示誤檢率和漏檢率較低，提供了一個可靠的解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca49954aa5387686e8d7257714795a83744.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Revenge of the Fallen?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.19178&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.19178&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-08-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出，在語言任務中，Transformer 一直佔據主導地位，但近期 RWKV 等循環模型出現。本文表明像 RWKV 這樣的當代循環模型在模擬人類語言理解方面能夠與 Transformer 相媲美甚至超越它們，開啓了新的研究方向。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-950085a35252d8db50bb7a763699263aacf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Enhancing Transformer RNNs with Multiple Temporal Perspectives&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Enhancing Transformer RNNs with Multiple Temporal Perspectives&lt;/li&gt; 
 &lt;li&gt;論文鏈接：https://arxiv.org/abs/2402.02625&lt;/li&gt; 
 &lt;li&gt;發佈日期：2024-07-11&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出多時間視角概念以增強循環神經網絡（RNN）。將其應用於 RWKV 模型時，能以極少的參數增加豐富上下文理解。實證結果驗證了其有效性，在基準測試中表現提升且保持線性推理複雜度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a57d07d01cf1ad8f5a65263282fa35c72d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型動態&lt;/h2&gt; 
&lt;h3&gt;新模型： RKWV-7-1.5B&lt;/h3&gt; 
&lt;p&gt;RWKV-7-World-1.5B-v3 模型於 2025 年 1 月 28 日正式發佈！&lt;/p&gt; 
&lt;p&gt;RWKV-7-1.5B 模型基於 RWKV World v3 數據集（共 3.1T 數據）訓練而來。在英文和多語言評測中，RWKV-7-1.5B 模型的評分對比其他同參數模型處於&lt;strong&gt;絕對領先&lt;/strong&gt;地位。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-56b7f8f2ab08a6d01054853563dd460ec50.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;新模型： RKWV-7-0.4B&lt;/h3&gt; 
&lt;p&gt;RWKV-7-World-0.4B-v2.9 模型於 2025 年 1 月 8 日正式發佈！&lt;/p&gt; 
&lt;p&gt;RWKV-7-World-0.4B 在 world-2.9（從 world-v3 數據集中採樣 2T tokens）數據集上訓練。其英文和多語言能力&lt;strong&gt;顯著超越其他 0.4B 模型&lt;/strong&gt;，且支持全球 100+ 種語言和代碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-88a64b43559f9bbfd783387587d05122cf5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社區活動&lt;/h2&gt; 
&lt;p&gt;此版塊包含 &lt;strong&gt;RWKV 官方動態&lt;/strong&gt;，以及 &lt;strong&gt;RWKV 社區舉辦或參加的各類活動&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;RWKV 創始人閉門會開啓報名&lt;/h3&gt; 
&lt;p&gt;2 月 21 日晚 7 點，將在上海組織 「RWKV-7 與未來趨勢「 的閉門會。&lt;/p&gt; 
&lt;p&gt;RWKV 創始人彭博會線下參加，歡迎 RWKV 開發者、感興趣的業內人士掃碼報名🤝&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c23a88285bae005e1f5e9a0b05360a9ec7b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社區項目動態&lt;/h2&gt; 
&lt;h3&gt;RWKV Othello&lt;/h3&gt; 
&lt;p&gt;RWKV 社區成員 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042&quot; target=&quot;_blank&quot;&gt;@Jellyfish042&lt;/a&gt; 基於 RWKV-7 架構開發了 RWKV Othello 項目。&lt;/p&gt; 
&lt;p&gt;項目 GitHub 倉庫： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042%2FRWKV_Othello&quot; target=&quot;_blank&quot;&gt;https://github.com/Jellyfish042/RWKV_Othello&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RWKV Othello 項目利用 Othello（也稱為反轉棋或黑白棋）的 CoT 數據訓練了僅 8.8M 參數的 RWKV-7-Othello 模型。&lt;/p&gt; 
&lt;p&gt;RWKV-7-Othello 模型可以和人類或其他模型自動對戰 Othello 遊戲，且在與人類對戰時實現了非常高的勝率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5cdd352820faef98513bceb46e59e9a65b4.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332925</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332925</guid>
            <pubDate>Sat, 08 Feb 2025 03:36:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>諳流科技完成數千萬元天使輪融資，打造統一消息流 PaaS 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;開源中國獲悉，上海諳流科技有限公司（http://ascentstream.com）近期完成數千萬元人民幣天使輪融資，本輪融資由北極光創投領投，華泰創新參與投資，將主要用於開源社區建設、產品研發以及商業化落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;諳流科技正式成立於 2024 年初，由 Apache Pulsar 和 Apache BookKeeper 的核心人員傾力打造，專注為中國市場提供雲原生消息隊列（MQ）和流處理（Streaming）基礎軟件及解決方案，打造統一消息流 PaaS 平台，助力中國數字化新質生產力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;724&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0210/102221_CPG4_4489239.png&quot; width=&quot;2752&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;消息流系統是支撐企業數據系統運轉的關鍵基礎軟件之一。從上世紀 80 年代開始，IBM，甲骨文，TIBCO 等公司的消息中間件產品被廣泛使用在各行業的軟件系統中。在大數據時代，消息系統在實時數據領域作為數據傳輸的中樞管道，發揮着不可替代的作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;Apache Pulsar 是一款開源的新一代雲原生消息流平台產品，憑藉其卓越的架構設計和強大功能，迅速在全球範圍內獲得了廣泛關注。目前擁有超過 670 名貢獻者，被數千家頭部企業應用於核心業務場景中。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;Pulsar 依託存算分離的雲原生架構基礎，通過特別的設計和抽象，統一地支持消息流的使用場景。在此之上，Pulsar 為消息隊列（MQ）場景提供了高可靠和強一致性，同時彌補了開源 Kafka 使用中多租戶、異地多備、數據再平衡帶來的集羣可用性問題，是企業內部降本增效、構建統一消息流 PaaS 平台的理想選擇。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在國內，Apache Pulsar 已經在眾多核心業務場景中得到深度應用，並經過了長期高併發、低延遲場景的嚴格檢驗。例如，騰訊計費平台、華為終端 BG、滴滴出行、小紅書以及微信視頻號等場景中均藉助 Pulsar 實現了高效、穩定的消息流處理，充分證明瞭其在大規模生產環境中的卓越性能和可靠性。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;諳流科技聯合創始人兼 CEO 翟佳是 Apache Pulsar 的項目管理委員會成員，是 Apache Pulsar 代碼的重要貢獻者和社區構建者。翟佳曾是 StreamNative 的聯合創始人，過去 5 年曾擔任 CTO 和中國區負責人職務。諳流科技聯合創始人兼 CTO 劉德志和聯合創始人兼 COO 魏祥臣曾作為騰訊專家工程師，合作領導併成功將 Pulsar 落地在騰訊計費千億級消息總線和騰訊雲金融級分佈式消息服務等項目中。商業化合夥人桂佳傑擁有十多年的企業軟件銷售管理經驗以及基礎軟件創業經驗，在行業內有着深厚的積累和卓越的業績。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;2024 年成立至今，在短短一年的發展過程中，諳流科技已在產品和商業化領域實現了從無到有的突破，併成功組建了一支專業且完備的產品與服務團隊。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;諳流科技的企業級產品——ASP 消息流平台，是基於 Apache Pulsar 打造的新一代金融級消息平台。該平台憑藉優越的性能，適用於金融級低延遲、高吞吐量的消息傳輸，高可靠的多地多中心部署，以及海量 Topic 的泛物聯網場景。目前，該產品已完成國產化適配，並廣泛應用於國產信創環境，充分契合國內市場的高標準需求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在商業化進程中，諳流科技憑藉其卓越的技術實力和優質服務，贏得了眾多行業頭部客戶的青睞，客戶羣體涵蓋中國銀聯、華泰證券、中信證券、中國聯通、中國地震台網中心、中國鐵道科學院、吉利汽車、深南電路等知名企業。本輪融資完成後，諳流科技將通過持續投入，推動企業的持續發展與創新，為客戶提供更具價值的解決方案。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;作為本輪融資的領投方，北極光創投合夥人張朋表示：「消息流產品已經是構成企業應用的基礎組件。諳流科技團隊已經將 Pulsar 推廣落地到各行各業。我們看到了金融客戶將公司產品用在覈心關鍵業務中，也看到了超大數據規模的客戶通過零改造的方式完成了 Kafka 的切換。在過去一年的整體環境下，諳流科技依然表現亮眼，這充分證明瞭其巨大的發展潛力和廣泛的市場需求。我們也期待諳流科技能夠在未來的發展中，不斷創新，砥礪前行，為推動國產基礎軟件行業的蓬勃發展貢獻更多的力量。」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;華泰創新股權投資一部負責人胡雪飛也認為：「Apache Pulsar 是優秀的開源雲原生基礎軟件的代表，伴隨和引領着雲原生技術在消息流方向的發展，同時也是數據傳輸和流轉中的重要工具，已經具備紮實的商業化基礎。諳流科技聚焦在陪伴中國企業客戶降本增效和敏捷創新上，目標明確。我們相信諳流科技在未來一定會取得更多更好的成績。」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在眾多企業紛紛加速佈局出海的當下，諳流科技堅定地選擇了紮根國內，再次啓航，這一決定源自於翟佳和團隊對中國市場的深刻洞察。他們認為國內龐大的市場體量和豐富的應用場景，為開源基礎軟件初創企業提供了得天獨厚的發展機遇，是孕育技術創新的肥沃土壤。近年來國家在基礎軟件和開源領域的政策引導與支持成為了企業發展的強大後盾，團隊將倍加珍惜這一機遇，積極響應國家號召，深度挖掘國內企業在數字化轉型和智能化升級中的核心需求。同時，團隊將高度重視國內企業在數據場景複雜性、數據規模龐大性以及對基礎軟件的高標準、嚴要求，致力於打造更貼合本土需求的優質產品和服務，助力中國企業在全球競爭中脫穎而出。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332915/ascentstream-angelroundfunding</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332915/ascentstream-angelroundfunding</guid>
            <pubDate>Sat, 08 Feb 2025 02:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘋果 3 月在上海舉辦「Apple 智能」相關活動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，蘋果向開發者發送了關於「利用蘋果智能的力量」開發者活動的相關郵件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cdd018ef12a613a98fbadee0fe4c431a02f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得關注的是，本次活動將於 3 月 25 日 10:00 至 12:00 在上海舉行，活動主題將圍繞蘋果智能和機器學習兩個方面。&lt;span style=&quot;color:#f39c12&quot;&gt;&lt;strong&gt;而這一舉動，也暗示在中國大陸的蘋果智能 AI 功能或將上線&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;近期，有消息透露，蘋果 CEO 庫克在公司的 2024 年 Q4 財報電話會上表示，公司將會在今年 4 月對 Apple Intelligence 適配更多語言，其中包括中文。而蘋果也於 1 月 30 日，對 Apple 智能的官網信息進行更新，其中提到 Apple 智能將會支持中文。另外，在 2024 年 9 月秋季發佈會中蘋果也提到，將會在今年內支持中文等語言。&lt;/p&gt; 
&lt;p&gt;此外，1 月 10 日，據天眼查顯示，蘋果技術開發（上海）有限公司成立，其法定代表人為 Tejas Kirit Gala，註冊資本為 3,500 萬元；該公司行業歸屬為軟件和信息技術服務業；經營範圍包括軟件開發、大數據服務、數據處理服務、數據處理和存儲支持服務等。&lt;/p&gt; 
&lt;p&gt;此外，據彭博社記者 Mark Gurman 報道，iPhone 正在失去優勢，一方面是中國市場競爭激烈，另一方面是 iPhone 缺失 AI 的領先技術，儘管如今蘋果智能已經亮相，但依然不敵 Google 的 Gemini。&lt;/p&gt; 
&lt;p&gt;而本週發佈的 iPhone SE 將開啓蘋果的產品線關鍵年。Gurman 指出，iPhone 硬件負責高管 John Ternus 近期表示，即將推出的 iPhone 新品將會是其最具雄心的，並且相當看好新品的銷售未來。&lt;/p&gt; 
&lt;p&gt;據悉，Gurman 此前表示，新款 iPhone SE 的外觀設計看起來會更像 iPhone 14，同時將搭載 A18 芯片並支持 Apple Intelligence，接口也將升級成 USB-C。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332912</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332912</guid>
            <pubDate>Sat, 08 Feb 2025 02:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>國企官網被掛上「碼農的錢你也敢吞，還錢」字樣，涉事公司回應</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 8 日，有網友反映，湖北武漢一國企官網掛上了「碼農的錢你也敢吞，還錢」字樣，引發關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-240b17432f7906a65d06d459ce7d5ec7b92.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，涉事企業為武漢匯科智創科技有限公司，屬於國有獨資企業。該國企的官網為「www.focuz-in.com」，點擊網頁後，無法正常瀏覽官網主頁，只能看到上述頁面。&lt;/p&gt; 
&lt;p&gt;據最新測試，官網電腦版頁面顯示「無法訪問」，但手機版仍可訪問，頁面顯示與網傳信息一致。&lt;/p&gt; 
&lt;p&gt;媒體就此事聯繫到武漢匯科智創科技有限公司相關負責人賈某，她表示，官網被黑系惡意行為，公司方面已經報警，網警正在覈查此事，所謂「還錢「一事不屬實，後續肯定要澄清。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332909</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332909</guid>
            <pubDate>Sat, 08 Feb 2025 02:47:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek-V3 API 優惠期結束，每百萬輸出 tokens 由 2 元提高至 8 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek-V3 的 API 服務的「價格優惠」體驗期已經結束，從 2 月 9 日開始調整為新的價格，相關情況，5G 與 6G 公眾號（ID：angmobile）總結並分析如下。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;1、價格對比分析&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img height=&quot;152&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf2ea7640b7494ba3edf769e2ae2e46d433.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;輸入 Token 費用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;優惠期（以前）：緩存命中 0.1 元/百萬，緩存未命中 1 元/百萬。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;正常期（現在）：統一 2 元/百萬（緩存命中漲價 2000%，未命中漲價 100%）。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;輸出 Token 費用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;優惠期（以前）：2 元/百萬。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;正常期（現在）：8 元/百萬（漲幅 300%）。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;優惠體驗期是一種常見的市場推廣策略，在優惠期內吸引了大量用戶嘗試和使用 DeepSeek-V3 的 API 服務，積累了用戶基礎和市場口碑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;優惠期結束後調整價格，5G 與 6G 公眾號認為一方面可以篩選出對價格不敏感、真正有需求的長期用戶，另一方面也為後續可能的價格策略調整和服務升級留出空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;價格調整反映了 DeepSeek 考慮到了運營成本、服務器資源以及持續研發所需的資金投入。值得注意的是，儘管價格有所上漲，但 5G 與 6G 公眾號注意到 DeepSeek-V3 與市場上其他高端 AI 模型比如 OpenAI 的 GPT-4o 相比仍然保持了較高的性價比（如下表所示）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;116&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-62d33087cc179a4147e85ae33ada2927009.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;2、成本影響測算&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;假設典型場景：&lt;/strong&gt;100 萬輸入（50% 緩存命中）+ 50 萬輸出&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;優惠期（以前）成本：（0.1×50 + 1×50）+ 2×50 = 5+50+100=155 元。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;正常期（現在）成本：（2×100）+ 8×50 = 200+400=600 元（成本增長 287%）&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;優化使用方面，用戶可能會更加註重優化 token 的使用，一是緩存策略優化，比如 5G 與 6G 公眾號認為通過請求模式調整提升緩存命中率可將輸入成本降低 90%；此外針對對話類應用，可設計緩存+實時處理的混合架構。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;價格並不是用戶選擇 AI 模型服務的唯一考量因素，DeepSeek-V3 可以通過不斷提升自身的性能、功能和服務質量，與競爭對手形成更大的差異化競爭。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332908</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332908</guid>
            <pubDate>Sat, 08 Feb 2025 02:44:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek4j: Java 應用一行代碼集成 DeepSeek R1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;DeepSeek R1 憑藉其強大的思維鏈能力在開發者中廣受歡迎。deepseek4j 框架提供了完整的 Java 集成方案，支持多個平台包括 Gitee AI，並帶來聯網搜索、多渠道支持等重要特性。本文將詳細介紹如何使用 deepseek4j 快速集成 DeepSeek R1。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;一、為什麼需要 deepseek4j？&lt;/h2&gt; 
&lt;h3&gt;1.1 現有框架的侷限性&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;框架支持不足&lt;/strong&gt;：LangChain4j/Spring AI 對 DeepSeek 支持不完善&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;思維鏈內容丟失&lt;/strong&gt;：R1 最核心的推理過程完全被忽略&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;流式處理不完善&lt;/strong&gt;：用戶體驗欠佳&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1.2 deepseek4j 的優勢&lt;/h3&gt; 
&lt;p&gt;deepseek4j 是一個專為 Java 開發者打造的 DeepSeek 模型集成框架。通過優雅的 API 設計，只需一行代碼，即可實現接入 DeepSeek，並獲得以下核心能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✨ &lt;strong&gt;完整思維鏈保留&lt;/strong&gt;：完美保留 DeepSeek 模型的推理過程&lt;/li&gt; 
 &lt;li&gt;🚀 &lt;strong&gt;流式輸出體驗&lt;/strong&gt;：基於 Reactor 實現的流式響應&lt;/li&gt; 
 &lt;li&gt;🛠 &lt;strong&gt;簡單優雅的 API 設計&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;📦 &lt;strong&gt;開箱即用的 Spring Boot 集成&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;💡 &lt;strong&gt;內置調試頁面&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;詳細的請求響應日誌&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;靈活的代理配置&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;⚡️ &lt;strong&gt;響應式編程支持&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二、快速開始&lt;/h2&gt; 
&lt;h3&gt;2.1 添加依賴&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.github.pig-mesh.ai&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;deepseek-spring-boot-starter&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;last-version&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2 配置參數&lt;/h3&gt; 
&lt;p&gt;在 application.properties 或 application.yml 中添加以下配置：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;deepseek:
  # Gitee AI 平台配置
  base-url: https://ai.gitee.com/v1
  model: DeepSeek-R1
  api-key: your-gitee-ai-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.3 基礎使用&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Autowired
private DeepSeekClient deepSeekClient;

// sse 流式返回
@GetMapping(value = &quot;/chat&quot;, produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux&amp;lt;ChatCompletionResponse&amp;gt; chat(String prompt) {
    return deepSeekClient.chatFluxCompletion(prompt);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.4 進階配置&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public Flux&amp;lt;ChatCompletionResponse&amp;gt; chat(String prompt) {
    ChatCompletionRequest request = ChatCompletionRequest.builder()
            // 模型選擇，使用 Gitee AI 的 DeepSeek-R1
            .model(ChatCompletionModel.DEEPSEEK_CHAT)
            // 添加用戶消息
            .addUserMessage(prompt)
            // 添加助手消息，用於多輪對話
            .addAssistantMessage(&quot;上輪結果&quot;)
            // 添加系統消息，用於設置角色和行為
            .addSystemMessage(&quot;你是一個專業的助手&quot;)
            // 設置最大生成 token 數，默認 2048
            .maxTokens(1000)
            // 設置響應格式，支持 JSON 結構化輸出
            .responseFormat()
            .tools() // function calling
            .build();

    return deepSeekClient.chatFluxCompletion(request);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;三、高級特性&lt;/h2&gt; 
&lt;h3&gt;3.1 聯網搜索支持&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://minio.pigx.vip/oss/202502/1739118403.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;突破時間邊界&lt;/strong&gt;：模型不再受限於預訓練數據的時間範圍，可以獲取和處理最新信息&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;實時信息獲取&lt;/strong&gt;：通過高質量信息源獲取實時資訊，提供更精準的問答服務&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;差異化競爭&lt;/strong&gt;：在大模型同質化嚴重的當下，聯網搜索成為關鍵的差異化競爭點&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@GetMapping(value = &quot;/chat&quot;, produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux&amp;lt;ChatCompletionResponse&amp;gt; chat(String prompt) {
    // 指定聯網搜索參數
    SearchRequest searchRequest = SearchRequest.builder()
            .enable(true)
            .freshness(FreshnessEnums.ONE_DAY)// 一天內的數據
            .summary(true) // 返回摘要
            .count(10) // 返回 10 條
            .page(1) // 第一頁
            .build();
    return deepSeekClient.chatSearchCompletion(prompt,searchRequest);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3.2 智能系統提示詞&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://minio.pigx.vip/oss/202502/1739118117.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;系統提示詞（System Prompt）是基於模型開發的應用程序內置的指令，讓決定了模型在特定上下文中的表現方式、回答風格和功能範圍。&lt;/p&gt; 
&lt;p&gt;為瞭解決部分渠道模型部署時推理能力不穩定的問題，新版本引入了與 DeepSeek R1 官方版本一致的系統提示詞功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過精心設計的提示詞模板，確保模型輸出的一致性和可靠性&lt;/li&gt; 
 &lt;li&gt;內置多層級的提示詞優化策略，顯著提升推理質量&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.3 調試支持&lt;/h3&gt; 
&lt;p&gt;雙擊運行根目錄的 sse.html 文件，即可打開調試頁面。在頁面中輸入後端 SSE 接口地址，點擊發送後可實時查看推理過程和最終結果。&lt;/p&gt; 
&lt;p&gt;針對非標準平台，新增了智能化的調試功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自動處理 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 標籤內容&lt;/li&gt; 
 &lt;li&gt;智能提取 &lt;code&gt;reason_content&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;優化多輪對話的 token 佔用&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://minio.pigx.vip/oss/202502/1738864340.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;四、多渠道支持&lt;/h2&gt; 
&lt;p&gt;deepseek4j 支持多個部署渠道：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3018c10690532e0e916df5a50d7dc492bf4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;詳細的使用文檔請參考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjavaai.pig4cloud.com%2Fdeepseek&quot; target=&quot;_blank&quot;&gt;DeepSeek4j : https://javaai.pig4cloud.com/deepseek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitee.com/log4j/deepseek4j&quot;&gt;源碼地址 gitee.com/log4j/deepseek4j&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/giegie/blog/17553532</link>
            <guid isPermaLink="false">https://my.oschina.net/giegie/blog/17553532</guid>
            <pubDate>Sat, 08 Feb 2025 02:43:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>新晉 AI 開源項目 WGAI 加入 Dromara 社區，輕量級、模塊化的 AI 助手框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h3&gt;🚀 新的起點&lt;/h3&gt; 
&lt;p&gt;我們非常高興地宣佈，WGAI 項目正式加入了 Dromara 開源社區！這是一個重要的里程碑，標誌着 WGAI 將能夠與更多的開發者和研究者分享其獨特的功能，並且共同推動人工智能領域的發展。&lt;/p&gt; 
&lt;p&gt;關於 WGAI WGAI 是一個開放源碼的人工智能項目，它基於 Apache License 2.0 許可證發佈。這意味着您可以在滿足一定條件下自由使用、複製和分發本作品。在 WGAI 中，用戶不僅可以直接利用預訓練的模型進行各種應用，還可以根據自己的需求對模型進行自定義訓練，以適應特定場景下的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//cd9db1bee5f630a46628d6120df7d8c7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;🚀 功能設計&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;不懂 python 也可直接執行再也不用擔心技術瓶頸&lt;/li&gt; 
 &lt;li&gt;在線訓練、在線標註、模型列表&lt;/li&gt; 
 &lt;li&gt;包含 OCR、圖文、音視頻等識別&lt;/li&gt; 
 &lt;li&gt;本地化部署語音識別、熱詞配置&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 四大核心優勢&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Java 全棧友好&lt;/strong&gt; - 深度整合 Spring 生態，提供&lt;code&gt;wgai-spring-boot-starter&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自我訓練模型&lt;/strong&gt; - WGAI 的一大特色是支持用戶自行訓練模型。通過這種方式，無論是學術研究還是工業應用，用戶都能根據自身的數據集和任務目標來優化模型性能&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;工業級部署&lt;/strong&gt; - 支持 ONNX 導出與 TensorRT 加速&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;簡單易用&lt;/strong&gt; - WGAI 提供了簡潔的 API 接口和詳細的文檔，開發者可以快速上手並集成到自己的項目中&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🛠️ 適用場景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;安防監控-人臉識別（機場、車站的身份核驗）、行為檢測（識別異常行為（如跌倒、鬥毆），實時觸發警報）。&lt;/li&gt; 
 &lt;li&gt;交通物流-自動駕駛（實時識別道路標誌、行人、車輛，輔助導航決策）、車牌識別（高速公路 ETC 系統或停車場自動識別車牌號碼）。&lt;/li&gt; 
 &lt;li&gt;工業製造-缺陷檢測（AI 視覺檢查產品表面劃痕、尺寸偏差，提升質檢效率）、預測性維護（通過識別設備振動或溫度數據異常，預判故障）。&lt;/li&gt; 
 &lt;li&gt;金融安全-欺詐檢測（分析交易模式識別異常行為如異地大額轉賬）、證件核驗（OCR 技術自動提取身份證、銀行卡信息，比對真偽）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;💻 快速入門&lt;/h1&gt; 
&lt;h3&gt;一鍵訓練&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//7c3c9ac7eab73a95d23b5cbca535886f.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;一鍵識別&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//d987b0b90439aaf3a6614bb2267c4e46.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//3dbbdecda575418e251b8c24847d03e6.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;🚀開源地址&lt;/h2&gt; 
&lt;p&gt;WGAI 作為一個輕量級、模塊化的 AI 助手框架，旨在為開發者提供簡單易用的工具，幫助快速構建智能應用。無論你是 AI 領域的初學者，還是經驗豐富的開發者，WGAI 都能為你提供強大的支持。歡迎大家試用並反饋意見，共同推動項目的進步！&lt;/p&gt; 
&lt;p&gt;如果你覺得這個項目對你有幫助，別忘了給個 Star 哦！🌟&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gitee&lt;/strong&gt;:&amp;nbsp;&lt;a href=&quot;https://gitee.com/dromara/wgai&quot;&gt;https://gitee.com/dromara/wgai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;:&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdromara%2Fwgai&quot; target=&quot;_blank&quot;&gt;https://github.com/dromara/wgai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;感謝大家的支持！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332892</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332892</guid>
            <pubDate>Sat, 08 Feb 2025 01:06:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>2024 年 AI 編程工具的進化</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型觀點》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thoughtworks AI 輔助研發工具與開源解決方案負責人&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;黃峯達（Phodal）&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;分析了&lt;/span&gt;2024 年 AI 編程工具的進化路線&lt;span style=&quot;color:#999999&quot;&gt;。&lt;/span&gt;全文如下。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;2024 年 AI 編程工具的進化&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/黃峯達&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;與 2023 年相比，2024 年 AI 在軟件工程中的應用已經變得更加廣泛和深入。這一趨勢體現在 AI 編程工具的進化上，主要體現在以下幾個方面：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;全面探索：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 從輔助開發人員擴展到覆蓋軟件開發的整個生命週期，從需求分析到運維管理，每個階段都顯著提升了效率和質量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;演進路徑：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 工具從個體使用擴展到團隊和組織層面。個體使用的 AI 工具如 AutoDev，團隊助手如 Haiven，以及組織層面的 AI 集成到內部 IM 和 Chatbot 系統中，全面增強了協作和效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;形態變化：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從本地 AI IDE 發展到領域特定的智能代碼生成工具。智能雲開發環境如 Google 的 Project IDX 等工具，使得未來的開發流程更加智能化和高效。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;站在全球來看，在不同的國家、區域人們的關注點是不一樣的，比如在中國，人們更關注於如何提高軟件工程師的工作效率，而在其它一些區域，人們更關注於如何提高軟件工程的質量、如何輔助進行遺留系統的遷移。除了各自所處的數字化階段、水平不同，還存在一些技術人才數量、質量、分佈等方面的差異。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;全面探索：從輔助開發人員到全生命週期&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 技術已經從簡單的輔助開發人員發展到涵蓋軟件開發的整個生命週期。在這一過程中，AI 工具的應用範圍不斷擴展，從需求分析到運維管理，每個階段都得到了顯著提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從 2022 年 GitHub Copilot 的發佈，我們可以看到越來越多的 AI 工具開始涉足到軟件開發的不同階段。比如，面向需求階段的 Jira/Atlassian Intelligence，面向原型設計的 Vercel v0，面向編碼階段的 GitHub Copilot，以及運維階段的 Dynatrace Davis AI 等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;就 2023 年的結論而言，基於人工智能的工具與基礎大語言模型可以增強軟件開發在設計、需求、測試、發佈和運維等各個環節中的能力，提高質量和效率。但是，這些工具往往是破碎、割裂的，還可能並不適合我們現有的研發流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在市場上，我們也可以看到市面上的主流研發工具，如 JetBrains、GitHub（網站）等，都在逐漸加入 AI 功能，使得 AI 功能逐漸融入到我們的日常工作中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;935&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-80891774a0b75d9ea03764c0cd3d38f6a0e.png&quot; width=&quot;1600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 IntelliJ IDEA 中，我們可以看到 AI 功能的加入，如：原生的向量化模型、基於語義化搜索（SearchEverywhere）、結合補全統計的機器學習補全插件 Machine Learning Code Completion、適用於單個代碼行的 Full Line Code Completion 等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而除了 GitHub Copilot 工具本身，它還開放了其插件能力，使得我們可以定義自己的 AI 智能體，以適應我們自己的工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在多階段協同方面，2024 年有了更多的變化，比如在智能運維領域，AI 可以結合判別性 AI 分析日誌，生成式 AI 分析原因，再結合智能體根據運行錯誤，自動修代碼復問題等；在測試領域，AI 除了輔助進行測試用例的生成，還可以生成對應的單元測試代碼，甚至是自動化測試代碼；在 UI 設計領域，AI 可以直接生成對應的代碼，基於提示詞來修改 UI，所生成的是最終的 UI 代碼，而不是設計稿。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;諸如此類的變化，使得 AI 所能輔助的範圍更加廣泛，從而使得 AI 在軟件工程中的應用更加全面。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;演進路徑：個體、團隊、組織&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從企業採用 AI 的路徑來看，我們會發現：越來越多的組織開始探索在組織層面使用 AI 輔助整體軟件研發。因而，AI 輔助研發組織的技術藍圖便也逐漸清晰起來。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從形態上可以分為：帶擴展能力的 IDE 插件、團隊 AI 助手、結合 AI 的內部 IM，以及作為基礎能力的 Chatbot。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;995&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f81e8fe70439b9145dbc6c7c33d9fcb424.png&quot; width=&quot;1732&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 編程工具應該怎麼設計才能提效？在當前來説，國內的環境下，由於我們的目標是實現可見的效率提升，即要通過可度量的指標。因而，可以看到一些明顯的變化：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;代碼補全與生成是最容易度量的指標，並且市面上也以此類為主。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在不同環節，從時間角度來計算，如代碼審查、代碼測試等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;結合代碼的問答，以減少工具切換、複製粘貼，提高效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;過去，AI 編程工具主要針對的是個人開發者。但隨着探索不斷深入，我們發現，在結合團隊或組織的力量後，AI 編程工具出現了以下趨勢：多樣的 AI 工具正在融入自己的開發流程中；AI 工具開始融入內部的一系列規範；不斷結合內部知識庫，提升內容生成的質量；開始構建自己的場景化能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;故而，從個體到團隊，再到組織，都在思考如何擴大 AI 的應用範圍。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在設計團隊 AI 助手時，我們需要考慮到團隊的拓撲結構，以及團隊的工作流程。在一個組織中，必然會有大量不同類型的團隊，每個團隊受限於業務盈利模式等因素，其採用的技術、工作流程等都會有所不同。比如，核心的業務部門可以享受自己特有的開發流程，而其它非核心部門則會採用一些標準化的流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;考慮到盈利水平高的部門，通常是大型團隊，他們不僅可能有自己的 AI IDE 插件，還會有自己的 AI 團隊。因此，我們也建議設計一個可以讓不同團隊共享知識的 AI 團隊助手。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;回到整體組織層面，我們也會看到內部的 IM 工具也在融合 AI 功能，比如尋找負責人/專家、運維 Chatbot 輔助分析部署失敗問題、CI/CD 問題分析、AI 會議創建與管理等等，以提升協作體驗。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在另外一方面，我們也會有大量的其它 Chatbot 在不同的研發團隊中使用，諸如於輔助平台的使用、文檔查找等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;形態變化：從本地 AI IDE 到領域特定的智能代碼生成&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;與通用性的 AI 輔助相比，領域特定的 AI 輔助效果更好，因為它更瞭解領域的特點，更容易生成符合領域規範的代碼。從智能代碼生成的角度來看，由於過去包含大量的語料知識，生成的代碼質量更高，更符合領域規範。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在前面，我們已經看到了 AI 輔助研發中心的概念，即在一個組織中，AI 輔助研發中心可以為不同團隊提供 AI 能力，以提升整體的研發效率。需要注意的是，AI 在快速生成大量代碼的同時，也會帶來一些問題，如代碼質量、安全性等。我們需要考慮如何在 AI 生成代碼的同時，保證代碼的質量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;生成式 AI 與低代碼平台結合，可以在多個方面實現增強的生產力和創新。文本生成與聊天機器人、從 PDF 構建界面、工作流程自動生成、自助式分析都是經典場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，多模態 AI 代碼的生成，諸如於 Google 的 ScreenAI。它可以將圖像和文本結合起來，生成對應的 DSL，進而轉換成不同的代碼。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在雲時代，大型組織構建了大量的雲 IDE 和雲基礎設施，以嘗試賣出更多的雲服務以及解決最後一公里的部署問題。儘管，受限於雲 IDE 能力、網絡與計算能力，雲 IDE 採用並不高，但是隨着 AI 的發展，我們可以看到更多的智能雲開發環境的出現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們非常看好諸如 v0.dev 這一類針對於領域特定的開發工具。它可以快速幫助我們構建出一個原型，然後再結合其它 AI 工具，如代碼審查、代碼測試等，可以大大提高我們的開發效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;還有諸如 Google Project IDX 這一類 AI 輔助型工作區。IDX 支持眾多框架、語言和服務，還與 Google 產品集成，可簡化開發工作流程，讓開發者可以快速、輕鬆、高效地跨平台構建和發佈應用。儘管 IDX 還非常早期，但是我們可以看到，未來的雲 IDE 將會更加智能化，更加適應我們的工作流程。在國內，我們也可以看到 Babel Cloud、MarsCode 等一系列雲 IDE 工具，也在不斷的發展中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者簡介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3054d057b31f6423987fec6f0abd944b82d.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;黃峯達（Phodal）&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thoughtworks AI 輔助研發工具與開源解決方案負責人，開源 Unit Mesh AI 輔助研發方案的發起人，包含 AI IDE 插件 AutoDev 等工具；智能體編程語言 Shire 的創始人，架構治理平台 ArchGuard 的核心開發者。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;他在生成式 AI 輔助需求分析、開發和質量保障方面為多家金融和互聯網企業提供落地支持，著有《前端架構：從入門到微前端》《自己動手設計物聯網》等多本書籍。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#333333&quot;&gt;《2024 中國開源開發者報告》&lt;/span&gt;由開源中國 OSCHINA、Gitee 與 Gitee AI 聯合出品，聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;報告整體分為三章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;中國開源開發者生態數據&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;TOP 101-2024 大模型觀點&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;國產 GenAI 生態高亮瞬間&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告，請點擊&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中國開源開發者報告.pd&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529672</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529672</guid>
            <pubDate>Thu, 06 Feb 2025 10:50:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>大模型訓練中的開源數據和算法：機遇及挑戰</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot; rel=&quot;nofollow&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型觀點》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;蘇州盛派網絡科技有限公司創始人兼首席架構師蘇震巍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;分析了&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型訓練過程中開源數據集和算法的重要性和影響，分析其在促進 AI 研究和應用中的機遇，並警示相關的風險與挑戰。&lt;/span&gt;&lt;/span&gt;全文如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;大模型訓練中的開源數據和算法：機遇及挑戰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/蘇震巍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着人工智能（AI）技術的迅猛發展，尤其是大模型（如 GPT、OpenAI o1、Llama 等）的崛起，開源數據和算法在大模型訓練中的重要性愈發顯著。開源數據集和算法不僅推動了 AI 研究的進步，也在應用層面帶來了深遠的影響。然而，伴隨這些機遇的還有諸多風險與挑戰，如數據質量、版權問題和算法透明性等。本文將淺析大模型訓練過程中開源數據集和算法的重要性和影響，分析其在促進 AI 研究和應用中的機遇，並警示相關的風險與挑戰。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;任何方案都具有兩面性和在特殊環境下的討論的意義和前提，因此，本文不討論開源或對立面（閉源）的絕對取捨問題，僅對開源的有利之處加以淺析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;重要的開源數據集和算法在大模型訓練中的角色&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源數據集是大模型訓練的基石。沒有高質量的數據，大模型的性能和應用場景將受到極大限制。ImageNet、COCO、Wikipedia 和 Common Crawl 是非常重要一批高質量的開源數據集。以下是這幾個數據集在大模型訓練歷程中的重要角色。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;ImageNet：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ImageNet 是計算機視覺領域最著名的開源數據集之一，包含數百萬張帶有標籤的圖像。它為圖像分類、物體檢測等任務提供了豐富的數據資源，使得模型能夠在視覺理解方面取得突破。它由普林斯頓大學的計算機科學家李飛飛（Fei-Fei Li）及其團隊在 2009 年創建。ImageNet 包含超過 1400 萬張圖像，這些圖像分為超過 2 萬個類別，每個類別都與 WordNet 中的一個詞條對應。每個類別的圖像數量從數百到數千不等。ImageNet 每年都會舉辦一個大型的視覺識別競賽，即 ImageNet Large Scale Visual Recognition Challenge(ILSVRC)。該競賽吸引了全球眾多研究團隊參與，並在推動深度學習和卷積神經網絡（CNN）技術的發展中發揮了重要作用。今年的諾貝爾物理學獎得主之一 Geoffrey Hinton 帶領的團隊成員 AlexNet 在 2012 年的 ILSVRC 中取得了顯著的成功，使得深度學習在計算機視覺領域迅速崛起。也為如今我們看到的種類繁多的視覺大模型（VLMs）開啓了新的篇章。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;COCO（Common Objects in Context）：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COCO 數據集由微軟於 2014 年發佈，涵蓋了數十萬張日常生活中的圖像，並附有詳細的標註信息。雖然 COCO 對比 ImageNet 具有更少的類別,但每一個類別擁有更多的實例，假定這能幫助複雜模型提高物體定位的準確率。它的設計初衷適用於具有上下文信息的圖片中的物體檢測和分割，目前在目標檢測、分割等任務中發揮了重要作用，推動了計算機視覺技術的進步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Wikipedia 和 Common Crawl：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Wikipedia 是一個由全球用戶共同編輯和維護的高質量在線百科全書,以文字為主，知識高度結構化，Common Crawl 是一個非營利組織，定期抓取互聯網公開網頁，生成大量的網頁數據集，可提供大量的互聯網用戶知識及非結構化數據。他們的共同點是為模型訓練提供了充沛的文字素材。這些大型文本數據集為自然語言處理（NLP）模型的訓練提供了豐富的語料庫。像 GPT 這樣的語言模型正是通過大規模爬取和處理這些數據集，才能在文本生成和理解方面表現出色。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;開源算法的角色&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源算法是 AI 研究和應用的核心驅動力。開源算法的共享和複用使得研究者和開發者能夠在前人工作的基礎上迅速迭代和創新。以下是一些在這一輪 AI 大模型浪潮中扮演重要角色的的開源算法及其在大模型訓練中的角色：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;TensorFlow 和 PyTorch：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這兩個深度學習框架是當前最流行的開源工具，提供了強大的計算能力和靈活的模型構建方式。它們為大模型的訓練和部署提供了基礎設施支持，使得複雜的 AI 模型得以實現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Transformer 架構：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Transformer 架構是一種用於處理序列數據的開源算法，廣泛應用於 NLP 任務，也是作為這一輪 AI 浪潮推動者 GPT 模型的基礎算法。基於 Transformer 的模型，如 BERT 和 GPT，已經成為自然語言理解和生成的事實標準。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;GAN（生成對抗網絡）：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GAN 是一種用於生成數據的開源算法，廣泛應用於圖像生成、數據增強等領域。它通過生成器和判別器的對抗訓練，能夠生成高質量的圖像和其他數據。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此以外，如果把 Pre-Train 之後的微調（Fine-Tuning）等環節也看做廣義「訓練」的一部分，還有一系列開源方法及配套的工具，例如比較常見的 LoRA（Low-Rank Adaptation of Large Language Models）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;機遇&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從上述開源數據和算法在模型訓練過程中所扮演的角色可以看到，大模型訓練中的開源數據和算法為 AI 研究和應用帶來了諸多機遇，在加速創新、促進合作、資源共享等方便提供了廣泛而可靠的基礎條件和資源，圍繞這些資源，技術人員得以進行更加開放的交流和合作，並展開更加深入的教育和培訓，以此不斷提升整個行業人才的技術水平。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;由於目前主流的模型訓練算法都需要依靠對訓練數據（樣本）的統計（概率），因此，開放的數據和算法能夠在更大程度上確保樣本的質量，從而避免更多未知的風險。例如就在 2024 年 12 月 1 日，用戶發現 ChatGPT 在需要輸出「David Mayer」這個名字的時候會突然提示拒絕：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;614&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-54e711fc838017bab98b163b46d3a7de8d4.png&quot; width=&quot;375&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此事件一度被解讀為 GPT 模型在訓練過程中被植入了特定的樣本或算法，以避免討論特定的人名。雖然後續的一系列測試表明，這種限制似乎只存在於 ChatGPT 產品中，通過 OpenAI 對外提供的模型接口並不會觸發這樣的屏蔽機制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OpenAI 在隨後週二（12 月 3 日）立即確認「David Mayer」這個名字已經被內部隱私工具標記，其在一份聲明中説：「可能有些情況下，ChatGPT 不提供關於人們的某些信息，以保護他們的隱私。」公司不會提供有關工具或流程的更多細節。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;無論真實的原因是什麼，這個事件是一個反例，其顯示了封閉的系統以及中心化的模型提供者所具備的風險，也説明瞭不透明的處理環節對模型的輸出結果帶來更多的不確定性。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;類似的拒絕服務也是在模型服務過程中表現出來的另外一種偏見（Bias）行為，而偏見也是目前所有模型都在極力避免的情形，要進一步解決這個問題，使用更加開放的數據集和算法是一種更負責任的做法。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;種種事件的發生並不是壞事，這是所有技術在發展過程中接受實踐檢驗的必經之路，通過種種嘗試和反饋，目前對於開源數據集和算法的呼聲正在越來越高漲。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了對於訓練集和算法的開源之外，對於模型的「開源」定義也經受着各種議論。筆者比較認同的觀點是：開源模型不應該只把模型文件公佈出來，同時應該把對應的訓練集和算法進行公開，並能夠提供相應的訓練流程，是所有人能夠對結果進行重現。這好比我們討論開源項目的時候，通常不會指我們只能夠下載某個應用程序，而是我們能夠查看源碼，甚至通過修改源碼編譯出自己想要的應用程序。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在今年 10 月 29 日，開放源代碼促進會（Open Source Initiative，OSI）發佈了關於「開源 AI 定義（OSAID）」1.0 版本，其規定了 AI 大模型若要被視為開源必須具備三個三個：訓練數據透明性、完整代碼、模型參數。雖然對比目前市面上的「開源模型」，少有能力較高的模型能完全符合，但這種聲明本身就是一種開源開放態度的彰顯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我相信，在更加透明的數據集和算法的支持下，模型將在可控性上獲得更好的發展機遇，相關的技術社區也將迎來更大的發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;挑戰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然，大模型訓練中的開源數據和算法也伴隨着一定的風險和挑戰，這些風險需要在模型開發和應用的過程中被認真對待和解決。例如前文提到的「偏見」問題，以及數據質量問題，可能是最顯著的風險。由於開源數據集質量參差不齊，雖然一些廣泛使用的數據集如開頭介紹的 ImageNet 和 COCO 被認為是高質量的數據集，但其他開源數據集可能包含噪聲、錯誤標籤和不完整的信息。這種數據質量問題會直接影響模型的訓練效果，導致模型性能的下降，甚至可能產生錯誤的預測結果。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此以外，在 GPT 爆火之後，由於相關法律和政策的滯後，已經有大量大模型生成的文字、圖像、視頻、音頻內容被髮佈於互聯網，當這些內容再次被作為開放數據被採集，並再次進行訓練，可能會帶來更大的數據質量問題。因此，筆者認為對 AI 生成的觀點進行標註再發布是一種更加負責任的做法，當然，在實際操作過程中，要實現仍然有極大的難度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源數據集的版權問題也是一個需要重視的風險。儘管開源數據集通常是公開的，但其使用仍然受版權法的約束。未經授權使用受版權保護的數據，可能會導致法律糾紛。此外，某些數據集可能包含敏感信息，涉及個人隱私甚至危害公共安全。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在使用這些數據時，必須遵守相關的隱私保護法規，如歐盟的《通用數據保護條例》（GDPR）和美國的《健康保險可攜性和責任法案》（HIPAA）。在實際操作過程中，出於成本、工藝、能力、時間的制約，數據集的篩選和正確使用仍然將會是一個持久的挑戰。對於這個問題，閉源的數據集以及方法並不是不存在，只是更加隱蔽了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;也可能會有人擔心，所有的數據集和算法開放後，模型是否會面臨更多被操控的風險？筆者認為，這確實是一個很大的問題，例如模型可能會更容易被「越獄」，從而被操控或輸出原本不應輸出的內容，這是一個需要尤其重點關注的風險點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在應對策略方面，這場攻防戰的「藍方」同時也獲得了更多的信息，可以再次加固相關能力，在這個過程中，模型得以進行更加充沛的發展，就如同當下的互聯網一樣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;只有黑暗才能隱藏更多風險尤其中心化的控制風險，只有讓核心數據和算法經受陽光的洗禮，並在所有人的監督下不斷完善，才能讓模型在更多場景中被更深入地使用（即便如此，訓練完的模型本身對人類來説也仍然是一個「黑盒」）。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前我們已經看到的大量開源的模型在各行各業中展現出強大的生命力和生產力，相關的開源社區也正在迎來新的繁榮期，長期來看，大模型將繼續在各種風險、機遇、挑戰、倫理等複雜環境中不斷發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;結論&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源數據和算法在大模型訓練中的重要性不言而喻，它們為 AI 研究和應用帶來了前所未有的機遇。然而，這些機遇也伴隨着一定的風險和挑戰，需要在模型開發和應用的過程中被認真對待和解決。通過採取適當的應對策略，我們可以在充分利用開源數據和算法的同時，儘量減少其潛在的風險，推動 AI 技術的健康發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;相信在未來，隨着技術的不斷進步和相關政策的完善，開源數據和算法將在大模型訓練中發揮更加重要的作用，為 AI 及大模型的研究和應用帶來更多的創新和機遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者簡介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d7067c07019e3e8c6de531e38dbdac9ade.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;蘇震巍&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;蘇州盛派網絡科技有限公司創始人兼首席架構師，微軟 AI 和開發方向最有價值專家（MVP）、微軟 Regional Director（RD）、騰訊雲最具價值專家（TVP）、微軟技術俱樂部（蘇州）主席，蘇州市人工智能學會理事，機械工業出版社專家委員會委員，江蘇省司法廳電子數據鑑定人。《網站模塊化開發全程實錄》《微信開發深度解析》圖書作者，Senparc.Weixin SDK 等開源項目作者，盛派開發者社區發起人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#333333&quot;&gt;《2024 中國開源開發者報告》&lt;/span&gt;由開源中國 OSCHINA、Gitee 與 Gitee AI 聯合出品，聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;報告整體分為三章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;中國開源開發者生態數據&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;TOP 101-2024 大模型觀點&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;國產 GenAI 生態高亮瞬間&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告，請點擊&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;2024 中國開源開發者報告.pd&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529581</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529581</guid>
            <pubDate>Thu, 06 Feb 2025 10:49:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>RAG 市場的 2024：隨需而變，從狂熱到理性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型觀點》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;杭州萌嘉網絡科技 CEO&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;盧向東&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;分享了其&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作為大模型應用創業者，所感知到的 2024 年 RAG 市場環境的變化。&lt;/span&gt;&lt;/span&gt;全文如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#2d54a0&quot;&gt;&lt;strong&gt;RAG 市場的 2024：隨需而變，從狂熱到理性&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/盧向東&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;轉眼到了 2024 年尾，和小夥伴一起創立 TorchV 也接近一年。雖然這一年做了很多事情，但從技術層面上來説，RAG 肯定是不得不提的，所以今天分享一下作為大模型應用創業者所感知的這一年，RAG 市場環境的變化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;RAG vs Fine-tune&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 這一年，RAG 技術對應的市場需求變化也是挺大的。在講變化之前，我覺得有必要分享一下為什麼 RAG 是目前市場上不可或缺的一種大模型應用的技術實現方式，它的優點是什麼？以及它和主要競爭技術之間的現狀是怎麼樣的？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;RAG 最開始被大家熱推，更多是因為以下三個原因：可以避開大模型的上下文窗口長度的限制；可以更好地管理和利用客戶專有的本地資料文件；可以更好地控制幻覺。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這三點到現在來看依然還是成立的，但上下文窗口這個優勢已經慢慢淡化了，因為各大模型的上下文窗口都在暴漲，如 Baichuan2 的 192K，doubao、GLM-4 的 128K，過 10 萬 tokens 的上下文窗口長度已經屢見不鮮，更別説一些特長的模型版本，以及月之暗面這樣用長文本佔據用戶心智的模型。雖然這些模型是否內置了 RAG 技術不好説，但是 RAG 解決上下文窗口長度限制的特點已經不太能站得住腳。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是第二點管理和利用專屬知識文件，以及第三點控制幻覺，現在反而是我認為 RAG 最大的殺手鐧。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）專屬知識文件管理&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因為 RAG 這種外掛文件的形式，我們便可以構建一個知識文件管理的系統來維護系統內的知識，包括生效和失效時間，知識的協作，以及便捷地為知識更新內容等。RAG 在知識維護上，既不需要像傳統 NLP 那樣由人工先理解再抽取問答對，也不需要像微調（fine-tune）那樣需要非常專業的技術能力，以及微調之後的繁瑣對齊（alignment）優化。所以如果客戶的知識內容更新比較頻繁（假設每天需要追加、替換大量實時資訊內容），特別是金融證券、企業情報等場景，RAG 知識更新便捷的特性真的非常合適。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）RAG 的幻覺控制&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 的幻覺控制是一個有爭議的話題，我之前寫過類似觀點，也有同學斬釘截鐵地認為 RAG 和幻覺控制八竿子打不着，但我現在依然堅持 RAG 可以有效控制幻覺這個觀點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先我們可以來看看 LLM 幻覺產生的主要原因：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 對於用戶的提問輸入，LLM 內部完全沒有相應的知識來做應對。比如你問大模型，上週三我在思考一件事，但是現在想不起來，你幫我想想是什麼。例子雖然誇張，但顯而易見，LLM 也不知道，但是它會一本正經給你一些建議，當然肯定不是你想要的；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 當我們給 LLM 原始問題，以及多個模稜兩可或互相影響的參考材料，那麼 LLM 給出的最終答案也會出錯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;好，那麼針對以上問題，是否我們解決好對原始問題的「理解-檢索-召回」，送到 LLM 的 context 足夠清晰（指的是沒有歧義內容、檢索相關度高），結果就會非常準確？根據我們的實踐結果，答案是明確的：今年 9 月份我們對一些項目進行了槽位填充（消除模糊問答）和元數據輔助之後，問答準確率可達到 98% 以上。比直接把大文本扔進同一個 LLM 測試的問答準確率幾乎高出 14 個百分點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有同學會説，LLM 幻覺的深層原因是 temperature 或者説概率引起的。就我純個人觀點來看，現當下的 LLM 參數足夠大、知識量足夠多，temperature 引起的偏差對於最終結果的正確性影響已經微乎其微了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（三）市場表現&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你應該看出來了，在 RAG 和微調之間，我明顯站隊了，而且從一年前就開始站隊了，我們創業的技術方向也是如此。從今天來看，我覺得 RAG 在 2024 年的表現確實要強於微調。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;499&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3a36116d31e8f9dc257f8e00f317e80a982.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖：Menlo Ventures 在 2024 年 11 月 20 日發佈的市場調研報告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;來源：https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根據 Menlo Ventures 發佈的市場調研報告顯示，RAG 以 51% 的市場份額在企業市場份額中佔據絕對優勢，Fine-tune 和 Prompting 工程均下降兩倍多。Agent 今年屬於純增長，目前情況還不錯，但在企業應用領域，多 Agents 的編排依然存在理解能力不足和生成幻覺等問題有待提高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果去預測明年的企業級市場趨勢，我覺得應用（Application）可能會是最大的關鍵詞，甚至會超過 Agent 的熱度。其實今年下半年已經能明顯的看出來，越來越多傳統大企業開始將大模型技術引入到業務中，而且他們的特點是要求高、需求剛、付費爽。而一旦大家開始在大模型的應用側競賽，RAG 在整個業務流程中白盒流程多、易控等特點愈發會受到企業客戶和開發者的熱捧，優勢進一步拉大。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;企業 AI 應用市場在 2024 年的變化&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）上半年：AI 無所不能，大而全&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年的上半年，AI 市場充斥着激情，那種熱情似乎走在街上都會撲面而來，個人感覺最主要的推動者是自媒體和模型廠商。模型廠商的出發點很容易理解，快速打開市場嘛，但考慮到他們是要最終交付的，所以相對還是比較理性。但自媒體就不一樣了，整個上半年看過太多的文章，大家也都是把最好的一面呈現給了大眾，所以很多人會覺得我才幾個月沒關注，AI 已經發展到我不認識的地步了，AI 已經無所不能了。所以，在 2024 年上半年，我們接觸到的企業需求中，佔主流的是那種大而全的需求，要用 AI 替代他們業務的全流程或基本流程，氣味中充滿了使用者的野望。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但實際情況並不理想，AI 或者大模型還真沒到這個程度，而且最關鍵的是範式轉換也還需時間。什麼是範式轉換？最簡單的例子就是以前人們用笨重的蒸汽機推動主軸承轉動，帶動整車間的機器工作。但是換了電動機之後呢，工作方式變了，動力可是變得非常分散，比如你拿在手上吹頭髮的吹風機。帶着微型電動機的吹風機和傳統的蒸汽機在工作範式上就完全不同，採用 AI 大模型之後，企業的業務流程也存在範式改造的過程，並非一朝一夕可以完成的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所以，上半年我遇到的、參與的或者聽説的那些大而全的 AI 項目，一半是在可行性推演中沒有被驗證，一半是交付之後效果很不理想，成功者寥寥。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）下半年：迴歸理性，小而難&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在今年 7 月份開始，陸續有一些傳統大企業找上門來，包括非常知名的企業，以及世界 500 強和多家中國 500 強。如果從時間上來説，他們屬於 AI 投入相對較晚的了，但他們的優勢是需求非常明確，要求也極高。比如有些企業僅僅就是解決一個諮詢服務的需求，在產品範圍上就是一個 AI 問答，但要求準確率接近 100%，就像我們 CTO 在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《AIGC 時代的淘金者，TorchV 這一年的心路歷程》&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;説到社保諮詢一樣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;小而難的好處很明顯，我能看到的是下面幾點：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對企業現有業務流程改造相對較小，內部推動的阻力相對較小，企業客戶配合度高；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;切口小，需求明確，建設成果的考覈清晰可量化；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用功能較小但可用性較高的 AI 產品，可以讓企業內部員工快速接受 AI，做進一步業務流程改造的前期預熱；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;樂於承接大而全需求的合作廠商多半是外包性質的（這個觀點有點傷人，但確實是我看到的現狀），而專業的、交付成功率更高的廠商往往更喜歡需求清晰且有難度的任務。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（三）關於 2025 年的預測&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我在上文中已經有提到，2025 年會有更多企業需求方採用 AI 技術，但企業永遠不會為你的技術買單，他們只會為他們自己的使用價值買單。比如可以幫助他們提升銷售額、業務流轉效率更高，或者和競爭對手的競爭中獲得優勢，還有就是降低成本等等。所以，大模型應用端多端不夠，還需要生長出藤蔓圍繞着企業流程開花結果，這個任務最終會落在應用（Application）——內化了企業流程、藉助了大模型能力的、帶有可交互界面的程序。2025 年會成為大模型應用或 AI 應用之爭。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外還有一個趨勢也很明顯，就是知識管理和協作。我們都説這波 AI 浪潮把原來「沒用」的非結構化數據給激活了，所以我們馬上會看到那些原來堆在角落裏面的「冷」文件和知識（類似 wiki）會被大量啓用，「熱」文件和知識會爆炸性增長，知識的協作和管理會成為新的問題——就像你有再多的先進坦克和戰車，卻因為無序的交通都堵在阿登森林了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;AI 從業者觀察&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因為我看到的不代表真相，所以這一章節會很短，僅僅分享兩個發現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）AI 技術的下坡&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有兩個感受（非證據）可以説明這一點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 關於 AI 大模型的自媒體數量在減少，從搜索引擎趨勢，加上我和幾個業內朋友的 blog、公眾號以及 X 的閲讀量下降趨勢也可以佐證這一點，下半年雖然市場理性迴歸，但整體熱度是在下降的。OpenAI 不再持續放大招可能也是重要原因之一。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 我前期接觸了很多因為 AI 熱潮而在企業內部抽調精幹力量組成的 AI 小組、AI 研究組和 AI 創新組等團隊的成員，但下半年有不少類似團隊已經解散，人員迴歸到原有崗位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;還有一點就是上半年加我微信好友的很多獨立開發者或在職的個人，多半也已經在尋覓了半年機會之後放棄了繼續探索，這一點在和他們交流，以及他們朋友圈的內容變化中可以明顯感知。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;619&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e0b61fa320f93745cf792daf0e22d6fe227.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖：技術採用生命週期。現階段的 AI 大模型市場似乎正處於過高期望之後的下坡過程中&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是這並不是壞事，上圖已經告訴我們，這是必然規律。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）價值開始顯現&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前還奔跑在 AI 大模型應用賽道的公司，很多已經開始創造出客戶價值，有了自己的優勢。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;包括在海外風生水起的 Dify，在內容提取端的合合，以及肯定會成為國內 AI 巨無霸的火山引擎。當然我們還看到了一些深耕垂直行業的優秀團隊，特別是在法律、醫藥、教育等行業。我們也在今年 6 月份開始做了產品轉身，現在已經不再煩惱人家問我們「你們和 dify、fastgpt、ragflow 有什麼區別」，因為賽道已經開始慢慢不一樣了，而且這個不一樣依然是產品層面的，和服務什麼行業無關。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者簡介&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;198&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e8cb1ce63e159dcd77334342f311f629de.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;盧向東&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;國內最早的 RAG 實踐者之一，杭州萌嘉網絡科技 CEO，公司主要研發 TorchV 品牌的大模型應用和知識庫產品。公眾號：土猛的員外。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#333333&quot;&gt;《2024 中國開源開發者報告》&lt;/span&gt;由開源中國 OSCHINA、Gitee 與 Gitee AI 聯合出品，聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;報告整體分為三章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;中國開源開發者生態數據&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;TOP 101-2024 大模型觀點&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;國產 GenAI 生態高亮瞬間&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告，請點擊&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529520</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529520</guid>
            <pubDate>Thu, 06 Feb 2025 10:48:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>2024 年 AI 編程技術與工具發展綜述</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot; rel=&quot;nofollow&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;strong&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;em&gt;&lt;span style=&quot;background-color:#e67e22&quot;&gt;查看完整報告&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;：&lt;/em&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;第二章&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;《TOP 101-2024 大模型觀點》&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;中&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同濟大學特聘教授、CCF 傑出會員&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;朱少民&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;對 2024 年 AI 編程技術與工具發展進行了總結。全文如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年 AI 編程技術與工具發展綜述&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文/朱少民&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年 8 月下旬，一款 AI 代碼編輯器——Cursor 火爆全球，火到一位 8 歲小女孩拿着它學編程，幾十分鐘內搭起來一個聊天機器人，其演示吸引來 180 萬人在線圍觀。這導致有人大膽預言，未來編程只需要狂按 Tab 就夠了。Cursor 確實好用，包括新推出的「光標位置預測」功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是 AI 編程發展沒有那麼快，在國內生成代碼採納率還比較低，根據《2024 軟件研發應用大模型國內現狀調研報告》，多數團隊在 10-40% 之間，如圖 1 所示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;454&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce564f5bd0fc36ee2aaa7dc75de3d3e72f3.png&quot; width=&quot;1101&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;圖 1 大模型（LLM）在編程上的應用及其生成代碼的採納率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 2024 年，我們還看到了「AI 程序員」Devin 的誕生，Devin 能夠獨立完成複雜的編碼和調試任務、自主查找和修復代碼庫中的錯誤，構建和部署應用程序。在 SWE-bench 編碼基準測試中，Devin 能夠解決 GitHub 中 13.86% 的真實問題，有了很大提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;説起 SWE-bench 編碼基準測試（https://www.swebench.com/），2024 年進步很快，以 OpenAI 建立的 verified 子集（500 個問題）為例，4 月開始時，成功率只有 2.8%，到現在已提升到 53%，這表明 AI 在編程能力方面取得了顯著的進步。這一提升反映了 AI 編程幾個關鍵因素，正好用來總結 2024 年 AI 編程的進展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;模型能力的增強：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 模型的架構和算法不斷優化，如從 Claude 3 Opus、GPT-4o 到 Claude 3.5 Sonnet、Claude 3.5 Haiku，大模型自身的能力不斷提升，使得模型能夠更好地理解和解決複雜的編程問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;智能體（AI agent）的引進：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能體可以收集和學習與任務相關的知識，可以直接調用靜態代碼分析工具、直接調用搜索引擎和 API 為編程任務服務，並通過構建代碼倉庫知識圖來幫助大模型全面理解軟件倉庫的結構和依賴關係，從而更好地定位問題根源並生成有效的代碼補丁。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能體還可以動態獲取代碼片段和問題相關的信息，並分析和總結收集到的信息，以便規劃出更好的解決方案。例如從 RAG+GPT 4(1106) 的 2.8% 提升到 SWE-agent+GPT 4(1106) 的 22.4%、從 RAG+Claude 3 Opus 的 7% 提升到 SWE-agent+Claude 3 Opus 的 18.2%，效果都比較顯著。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;多模態能力：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多模態 LLM 使智能體能夠綜合利用視覺和文本信息，可以理解軟件用戶界面、處理的圖表、可視化數據、語法高亮和交互映射等內容，更好地理解任務陳述以及獲取任務相關的產品信息、開發過程信息，從而更全面地理解和解決問題。目前排在 SWE-bench verified 前 4 位都使用了 Claude-3.5-Sonnet，而它是多模態的、具備處理文本和視覺信息的能力，使其能夠理解和修復包含圖像或其他視覺元素的 GitHub 問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;和工具集成的框架：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以支持智能體在處理複雜任務時進行更好的任務管理和執行，並促進不同 AI 模型和工具之間的協作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如 Composio SWE-Kit 集成文件操作、代碼分析、Shell 命令執行、知識庫管理和數據庫操作等工具或能力，優勢互補，將 SWE-bench verified 大幅度提升到 48.6%。再比如 OpenHands+CodeAct v2.1 將智能體的行為整合到統一代碼行動空間的框架，允許 OpenHands 在編程任務中扮演全方位的智能助手角色，目前排在 SWE-bench verified 第一位（53%）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基於代碼大模型的自身進化，以及 RAG 技術、智能體的有力支持，從而 LLM 有更好的上下文感知能力。例如，在代碼大模型預訓練時，其訓練語料中加入抽象語法樹（AST）、代碼依賴關係等數據，新的代碼生成模型則具有更強的上下文感知能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在此基礎上，基於 AI 的編程工具能夠根據給定的上下文（如函數名、註釋、部分代碼等）檢索出最相關的代碼片段和文檔，能夠提供完整的函數或代碼塊建議。這也使得 LLM 能夠參考海量的代碼庫和技術文檔，這不僅能緩解大模型的幻覺問題，顯著提升代碼生成與理解的準確性，而且能符合上下文的代碼，更能滿足開發的業務需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未來，研發人員和多個智能體、工具協同工作來完成編程工作，如論文 Flows:Building Blocks of Reasoning and Collaborating AI 所描述的（圖 2 所示），構成一個複合競爭性編碼流程，研發人員更多是提需求，由 LLM 和智能體實現自主編程的過程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;546&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-243a86d5adf6ad21f5d418b5511f81f0f05.png&quot; width=&quot;1107&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;圖 2 由 LLM 和智能體實現自主編程的過程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着大模型技術的迅速發展，在今年，我們明顯能感到，AI 已從單一的輔助工具，逐漸演變為軟件開發人員不可或缺的助手或夥伴。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了前面已介紹的 Cursor、Composio SWE-Kit、OpenHands CodeAct 等工具之外，國內主要使用 chatGPT、GitHub copilot、通義靈碼、CodeGeeX、文心快碼、螞蟻 CodeFuse 等編程工具，國外還出現一些受歡迎的、新的編程工具，如 Codeium IDE Cascade、Solver ai、Websim ai 等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;493&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c4bc35246b3a57ea83c92f455823fb59b03.png&quot; width=&quot;796&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖 3 國內編程助手使用狀況（來源同圖 1）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這些工具讓我們能感受到 AI 卓越的生成能力和理解能力，幫助我們更高效地完成代碼生成、代碼評審、代碼解釋到單測生成、缺陷定位、代碼優化等任務。這種進步也體現在今年國內企業一些落地實踐中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一些大廠，LLM 已經實際應用到代碼審查或 CI/CD 流程中（如 pull request），自動識別代碼質量問題並提出改進建議。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些企業結合智能體和相關工具的支持，讓基於 LLM 的研發平台生成代碼流程圖和類圖，輔助自然語言解釋，使得開發者更直觀地理解代碼結構和執行流程，增強智能編程的可視性和交互性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些開發團隊藉助智能體和 RAG 技術檢索歷史上已知的代碼缺陷模式和已知問題，從而比較準確地識別潛在的缺陷和安全漏洞，甚至能夠分析代碼的功能意圖，全面提升代碼評審的能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些團隊，根據 UI 設計圖，讓 LLM 自動生成相應的前端代碼，大大減少了手動編碼的時間，加快了從設計到實現的流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從應用效果看，前面調研的數據可供參考。在國內 AI 編程開展比較好的大廠，超過 80% 的工程師在使用 AI 編程工具完成日常的編程工作，近 30% 入庫的代碼由 AI 生成，生成代碼平均採納率超過 40%，有些產品線達到 60%。僅僅在編程這一項工作（雖然只佔開發人員 20-30% 的工作量）上，研發效率能提升 20-30%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;850&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-33b0554523cedb9d91ec30064a650d426eb.png&quot; width=&quot;1292&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖 4 大模型時代的軟件研發正確方式&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然，我們不能侷限於這一個編程環境，最好要從需求開始就應用大模型。ATDD（驗收測試驅動開發）是大模型時代軟件研發的正確打開方式，讓大模型幫我們生成需求及其驗收標準，業務約束更明確了，上下文更清楚了，在此基礎上分別由不同的模型生成產品代碼和測試代碼，再讓它們之間相互驗證和博弈（如圖 4 所示），最終交付高質量的軟件。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未來，隨着 AI 技術的不斷成熟和創新，AI 編程工具將進一步提升智能化和可解釋性，支持更多的編程語言和平台，並通過強化學習實現自適應優化。為了全面發揮 AI 編程技術的潛力，開發團隊需要不斷學習和適應新技術，優化開發流程，確保 AI 工具的有效應用和高質量輸出。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;作者簡介：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ee7692932d7b07e9b2a9ffb1562965629.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;朱少民&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同濟大學特聘教授、CCF 傑出會員、CCF TF 軟件質量工程 SIG 主席、CCF2023 傑出演講者、軟件綠色聯盟標準評測組組長、QECon 大會和 AiDD 峯會發起人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近三十年來一直從事軟件工程的教學與研究工作，先後獲得多項省、部級科技進步獎，已出版了二十多部著作和 4 本譯作。曾任思科（中國）軟件有限公司 QA 高級總監、IEEE ICST 2019 工業論壇主席、IEEE ICST、QRS 等程序委員、《軟件學報》和《計算機學報》審稿人等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17529447</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17529447</guid>
            <pubDate>Thu, 06 Feb 2025 10:46:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>DeepSeek 官網全球日訪問量超越谷歌 Gemini</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.similarweb.com%2Fwebsite%2Fdeepseek.com%2F%23competitors&quot; target=&quot;_blank&quot;&gt;據 SimilarWeb 數據顯示&lt;/a&gt;，DeepSeek.com 的日訪問量已經超過了谷歌的 Gemini 和 Character.AI。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-75442688c9422272ece272970d296377818.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;報告顯示 DeepSeek 的 V3 模型在第三方基準測試中表現優於 Meta 的 Llama 3.1、OpenAI 的 GPT-4o 以及阿里巴巴的 Qwen 2.5，且成本顯著更低，這使得 DeepSeek 的熱度急劇攀升。&lt;/p&gt; 
&lt;p&gt;SimilarWeb 的數據顯示，DeepSeek.com 在上週二（1 月 27 日）創下了 4900 萬次訪問量的紀錄，與前一週相比增長了 614%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-64acd5aa419c5232f687b45cec93c369e7a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這一數字不包括基於應用的流量，足以凸顯 DeepSeek 的迅猛發展勢頭。一個月前，該網站的日均訪問量僅為 30 萬次，而到了 1 月 27 日，這一數字飆升至 3340 萬次，並引發了美國科技股的波動。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332691</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332691</guid>
            <pubDate>Thu, 06 Feb 2025 08:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>