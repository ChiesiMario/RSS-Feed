<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Sun, 03 Aug 2025 02:40:23 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Rust 跨平台開發框架 Tauri 開啓 2025 董事會選舉</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Tauri 是一個桌面 UI 框架，可讓開發者使用每個平台的 Webview 技術棧為所有主要桌面操作系統構建應用程序，目前支持 Windows/macOS/Linux 等平台。開發者通過 Tauri 幾乎可以使用任何編譯為 HTML、JS 和 CSS 的前端框架來構建桌面 UI。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Tauri 核心庫採用 Rust 編寫，使用 Tauri 開發的應用程序的後端是一個基於 Rust 的二進制文件，帶有一個前端可以與之交互的 API，通過 JS Api 調用後台接口。&lt;/p&gt; 
&lt;p&gt;日期，Tauri 社區正在進行 2025 董事會選舉。根據 Tauri 的治理結構，董事會（Board of Directors）為核心決策機構，負責項目的整體健康與穩定。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;董事會選舉安排&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;本次選舉將有 5 個席位開放&lt;/strong&gt;，董事任期為兩年，董事會規定最少 3 人，最多 7 人。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;選舉採用&lt;strong&gt;兩年輪換制&lt;/strong&gt;：每年選舉部分席位，兩年內覆蓋全部席位，確保連續性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;申請流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;有意者應按以下三個步驟申請成為候選人：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;閲讀 Tauri Governance 頁面中董事角色職責；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;準備一份介紹材料，包括個人背景、與 Tauri 的關聯，以及能為董事會貢獻的方面；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;在 2025 年 7 月 7 日前提交申請&lt;/strong&gt;，可通過電子郵件發送至 board@tauri.app，或在 Discord 上聯繫 &lt;code&gt;@board&lt;/code&gt; 角色。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftauri.app%2Fblog%2Ftauri-board-elections-2025%2F" target="_blank"&gt;https://tauri.app/blog/tauri-board-elections-2025/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363686/tauri-board-elections-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363686/tauri-board-elections-2025</guid>
      <pubDate>Tue, 15 Jul 2025 11:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>上半年我國軟件業務收入 70585 億元</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;工業和信息化部運行監測協調局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_68003fdb41984bcab3f1234f8c8eb449.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;2025 年上半年，我國軟件和信息技術服務業（以下簡稱「軟件業」）運行態勢良好，軟件業務收入穩健增長，利潤總額保持兩位數增長，軟件業務出口保持正增長。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;一、總體運行情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;軟件業務收入穩健增長。上半年，我國軟件業務收入 70585 億元，同比增長 11.9%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;利潤總額增速保持兩位數增長。上半年，軟件業利潤總額 8581 億元，同比增長 12.0%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;軟件業務出口保持正增長。上半年，軟件業務出口 283 億美元，同比增長 5.3%。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;二、分領域運行情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;軟件產品收入平穩增長。上半年，軟件產品收入 15441 億元，同比增長 10.6%，佔全行業收入比重為 21.9%。其中，基礎軟件產品收入 903 億元，同比增長 13.8%；工業軟件產品收入 1445 億元，同比增長 8.8%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;信息技術服務收入保持兩位數增長。上半年，信息技術服務收入 48362 億元，同比增長 12.9%，佔全行業收入的 68.5%。其中，雲計算、大數據服務共實現收入 7434 億元，同比增長 12.1%，佔信息技術服務收入的 15.4%；集成電路設計收入 2022 億元，同比增長 18.8%；電子商務平台技術服務收入 5882 億元，同比增長 10.2%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;信息安全收入穩定增長。上半年，信息安全產品和服務收入 1052 億元，同比增長 8.2%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;嵌入式系統軟件收入穩定增長。上半年，嵌入式系統軟件收入 5730 億元，同比增長 8.5%。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;三、分地區運行情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;上半年，東部地區、中部地區、西部地區和東北地區件業務收入分別同比增長 12.1%、12.5%、10.4% 和 9.2%。東部地區佔全國軟件業務總收入的 84.3%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;京津冀地區軟件業務收入同比增長 12.5%，長三角地區軟件業務收入同比增長 13.7%。北京、廣東、江蘇、山東、上海軟件業務收入居全國前 5，同比分別增長 12.6%、9.0%、14.4%、12.9% 和 18.0%。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363681</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363681</guid>
      <pubDate>Tue, 15 Jul 2025 10:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>agentUniverse 多智能體框架實現專家級金融分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt;
  7 月 26 日，【Al Agent：從工具助手到自主行動】OSC 源創會·杭州站·115 期活動成功舉辦，螞蟻集團智能投研架構師趙澤偉帶來了題為《agentUniverse 多智能體框架實現專家級金融分析》的精彩演講，深入闡述瞭如何利用多智能體技術突破金融智能化的關鍵瓶頸。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  趙澤偉展示了 agentUniverse 在金融投研核心場景的成功實踐： 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    語控金融分析： 首創「白盒化」分析過程，確保每一步思路、數據來源清晰可見、可追溯，嚴格滿足金融嚴謹性要求。支持靈活定製和修改分析流程，貼合不同金融專家的思維模式。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    報告解讀/市場分析/政策解讀/宏觀分析： 構建專業化智能體矩陣，實現 7×24 小時全市場動態感知與投資機會挖掘。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    QuantExpert®量化因子復現與計算： 攻克「精準可控代碼生成」難題。通過「量化專家知識框架注入」、「多模態信息抽取（財報提取、校驗）」、「代碼質檢與自迭代」等 Micro Agent 協作，平衡大模型創造力與金融計算所需的絕對精確性，確保結果基於真實金融數據與框架。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    QuantExpert®量化研報方法論復現： 同樣應用專家框架注入與精準代碼生成能力，擅長處理長文本拆解，保障量化研究的嚴謹復現。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    研報生成： 將 AI 分析能力無縫輸出至支付寶理財等豐富業務場景。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
  基於這些實踐，趙澤偉解釋，agentUniverse 的核心創新在於兩大關鍵技術：一是 PEER 仿金融專家協同推理，可以模擬人類金融專家團隊的分工協作模式。不同智能體扮演專業角色（如分析師、計算校驗員），通過高效協同提升整體分析的專業深度和可靠性，實現「分工帶來專業」。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height="734" src="https://oscimg.oschina.net/oscnet/up-5c9968e8248cd054725f87f10cc0546b22e.png" width="1408" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div&gt;
  二是 DITR 動態工具插值推理技術： 讓智能體「通過實踐檢驗推理」。智能體能在推理過程中動態調用並整合多樣化專業工具（如數據查詢、計算引擎、校驗模塊），實時驗證分析步驟與結果，極大增強了複雜金融邏輯處理的可信度。豐富的工具生態也使其能快速適應不同分析場景需求。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height="596" src="https://oscimg.oschina.net/oscnet/up-0de916b64349622118b22423e076ef33106.png" width="1392" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div&gt;
  具體組件方面，agentUniverse 多智能體框架集成經產業驗證的 
 &lt;code&gt;agentUniverse.RaG&lt;/code&gt;檢索增強能力，確保信息準確； 
 &lt;code&gt;agentUniverse.Mem&lt;/code&gt;提供強大的多輪會話與記憶管理。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  此外，agentUniverse 還具備一些企業級特性，包括效果可觀測與可反饋：，全鏈路記錄服務、模型交互，支持效果評測與迭代優化；一鍵服務化，便捷啓動 WebServer，輕鬆集成至現有業務系統；標準容器交付，提供標準 Docker 鏡像，支持 K8S 等雲原生部署；私有化擴展：，提供開放框架，支持企業無縫接入自研 RPC、消息、日誌等私有組件。 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;div&gt;
   下期活動預告： 
 &lt;/div&gt; 
 &lt;div&gt;
   【AIoT 共振場：重構萬物智聯新圖層】 OSC 源創會·深圳站·116 期 
 &lt;/div&gt; 
 &lt;div&gt;
   查看詳情： https://www.oschina.net/event/8598019 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18686762</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18686762</guid>
      <pubDate>Tue, 15 Jul 2025 09:58:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Black Forest Labs 聯手 Krea 開源 FLUX.1-Krea 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Black Forest Labs 與 AI 初創公司 Krea 攜手推出開源圖像生成模型 FLUX.1-Krea [dev]，該模型專注於解決當前 AI 生成圖像中普遍存在的"人工痕跡"問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;FLUX.1-Krea [dev] 的核心設計理念是擺脫傳統 AI 生成圖像的"塑料感"和過度處理效果。許多現有的 AI 圖像生成模型往往會產生過曝高光、不自然的色彩飽和度以及明顯的人工痕跡，這些特徵讓觀眾一眼就能識別出是 AI 生成的作品。新模型通過算法優化和訓練策略改進，着重呈現更加自然的光影效果和細節表現，讓生成的圖像更接近真實攝影作品的質感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-a8ccb9505eaffaaf11ac52a3315330cbaa7.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在技術架構方面，FLUX.1-Krea [dev]基於 Black Forest Labs 提供的 flux-dev-raw 基礎模型構建。這是一個經過預訓練並指導優化的 12B 參數擴散變換模型，為新模型的高質量輸出奠定了堅實基礎。Krea 團隊在此基礎上進行了深度定製化開發，通過監督微調和人類反饋強化學習兩個關鍵階段，精心策劃了高質量的圖像數據集用於模型訓練。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;人類反饋強化學習的引入是該模型的重要技術亮點。這種訓練方法讓 AI 模型能夠更好地理解和符合人類的審美標準，而不是僅僅依靠技術指標進行優化。通過大量人工標註和反饋數據，模型學會了區分什麼樣的圖像效果更符合人類的視覺偏好，從而在生成過程中自動避免那些看起來"不自然"的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;FLUX.1-Krea [dev]的另一個重要優勢是其與現有 FLUX 開源生態系統的完全兼容性。這意味着已經基於 FLUX 模型開發應用或工具的開發者可以無縫遷移到新模型，無需重新構建整個技術棧。這種兼容性設計大大降低了新技術的採用成本，有利於推動整個開源社區的技術升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Krea 表示，FLUX.1-Krea [dev]的開發不僅僅是技術層面的改進，更是對用戶創作體驗的全面優化。通過減少"AI 味"的視覺特徵，用戶可以創作出更具專業水準的視覺內容，無論是用於商業設計還是個人創作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363668</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363668</guid>
      <pubDate>Tue, 15 Jul 2025 09:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>如何修復上下文，緩解與避免上下文失敗</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;作為我們之前文章《長上下文如何失敗》的後續，這篇將介紹我們可以如何緩解甚至完全避免這些失敗。&lt;/p&gt; 
&lt;p&gt;但在開始之前，讓我們快速回顧一下&lt;/p&gt; 
&lt;p&gt;★ 長上下文常見的失敗方式：&lt;/p&gt; 
&lt;p&gt;1. 上下文污染（Context Poisoning）： 當幻覺或其他錯誤被加入上下文中，並被反覆引用。&lt;/p&gt; 
&lt;p&gt;2. 上下文幹擾（Context Distraction）： 當上下文過長，導致模型過度依賴上下文，而忽視了訓練中學到的知識。&lt;/p&gt; 
&lt;p&gt;3. 上下文混淆（Context Confusion）： 當上下文中包含冗餘信息，模型因此生成質量較低的回應。&lt;/p&gt; 
&lt;p&gt;4. 上下文衝突（Context Clash）： 當新信息或工具與原有 prompt 中的信息發生衝突。&lt;/p&gt; 
&lt;p&gt;這一切都是信息管理問題。上下文中的每一項信息都會影響模型輸出。正如老編程格言所説：「Garbage in, garbage out」。幸運的是，我們有很多方法可以應對這些問題。&lt;/p&gt; 
&lt;p&gt;★ 上下文管理策略&lt;/p&gt; 
&lt;p&gt;- RAG：選擇性地添加相關信息以提高 LLM 的回答質量&lt;/p&gt; 
&lt;p&gt;- 工具加載（Tool Loadout）：只添加任務相關的工具定義到上下文&lt;/p&gt; 
&lt;p&gt;- 上下文隔離（Context Quarantine）：將不同上下文隔離在獨立線程中使用&lt;/p&gt; 
&lt;p&gt;- 上下文剪枝（Context Pruning）：移除不相關或無用的信息&lt;/p&gt; 
&lt;p&gt;- 上下文摘要（Context Summarization）：將累積的上下文壓縮為摘要&lt;/p&gt; 
&lt;p&gt;- 上下文卸載（Context Offloading）：將信息存儲在 LLM 上下文之外的工具中&lt;/p&gt; 
&lt;p&gt;★ RAG（檢索增強生成）&lt;/p&gt; 
&lt;p&gt;RAG 是指選擇性地將相關信息加入上下文，以幫助 LLM 更好地生成回答。&lt;/p&gt; 
&lt;p&gt;雖然隨着模型上下文窗口越來越大（如 Llama 4 Scout 的 1000 萬 token），很多人覺得「把所有信息全塞進去」就夠了，但如果像雜物抽屜那樣使用上下文，雜物也會污染模型生成。&lt;/p&gt; 
&lt;p&gt;要想了解更多，作者推薦了一個新的課程：I don’t use RAG. I just retrieve documents.&lt;/p&gt; 
&lt;p&gt;★ 工具加載（Tool Loadout）&lt;/p&gt; 
&lt;p&gt;工具加載指的是為任務選擇合適的工具描述加入上下文。&lt;/p&gt; 
&lt;p&gt;術語「loadout」來自遊戲世界，指的是你選擇的技能、武器和裝備組合。&lt;/p&gt; 
&lt;p&gt;這項技術可以結合 RAG。例如，Tiantian Gan 和 Qiyao Sun 在其論文 RAG MCP 中展示瞭如何通過向量數據庫檢索相關工具描述。&lt;/p&gt; 
&lt;p&gt;- 研究發現，當工具數量超過 30 時描述會重疊，產生混淆；&lt;/p&gt; 
&lt;p&gt;- 超過 100 個工具幾乎必然導致模型失敗；&lt;/p&gt; 
&lt;p&gt;- 使用 RAG 技術將工具數控制在 30 以內，可將工具選擇準確率提升 3 倍。&lt;/p&gt; 
&lt;p&gt;對於小模型問題更早就會暴露，例如論文 Less is More 指出：LLaMA 3.1 8b 給 46 個工具會失敗，而給 19 個工具則表現良好。問題是混淆，而不是上下文長度限制。&lt;/p&gt; 
&lt;p&gt;即使動態工具選擇方法未提升模型準確率，它帶來的電量節省（18%）和速度提升（77%）也是值得的。&lt;/p&gt; 
&lt;p&gt;★ 上下文隔離（Context Quarantine）&lt;/p&gt; 
&lt;p&gt;這是指將不同任務拆分為獨立線程，每個線程使用獨立上下文。&lt;/p&gt; 
&lt;p&gt;例如 Anthropic 的多智能體研究系統就是用多個子智能體並行運行，彼此隔離、分別檢索，最後由主智能體整合輸出。&lt;/p&gt; 
&lt;p&gt;他們在評估中發現：&lt;/p&gt; 
&lt;p&gt;～ 使用多智能體時，相比單一 Claude Opus 4，回答準確率提升了 90.2%；&lt;/p&gt; 
&lt;p&gt;- 多智能體系統能將一個複雜任務拆分成多個子任務並行完成；&lt;/p&gt; 
&lt;p&gt;- 不同子智能體可使用不同的工具集，解決加載衝突問題。&lt;/p&gt; 
&lt;p&gt;★ 上下文剪枝（Context Pruning）&lt;/p&gt; 
&lt;p&gt;隨着任務進行，智能體會累積大量上下文，可能需要清理。&lt;/p&gt; 
&lt;p&gt;作者推薦了一款輕量剪枝工具：Provence，其模型大小僅 1.75GB，調用簡單，能將不相關信息剔除 95%，效果優秀。&lt;/p&gt; 
&lt;p&gt;剪枝更有效的方式是將上下文結構化成字典或模塊，方便根據規則進行刪減。&lt;/p&gt; 
&lt;p&gt;★ 上下文摘要（Context Summarization）&lt;/p&gt; 
&lt;p&gt;即便上下文足夠長，過長的歷史也會使模型過度依賴記憶，而非推理。&lt;/p&gt; 
&lt;p&gt;例如 Gemini 2.5 Pro 支持超過 100 萬 token 的上下文，但一旦超出 10 萬 tokens，模型就會偏向重複歷史行為，而非生成新計劃。&lt;/p&gt; 
&lt;p&gt;總結步驟可由獨立 LLM 實現，並可積累評估數據，以持續優化摘要質量。&lt;/p&gt; 
&lt;p&gt;★ 上下文卸載（Context Offloading）&lt;/p&gt; 
&lt;p&gt;即將筆記或中間推理步驟移出上下文，存放於外部工具中，例如 Anthropic 的 「think tool」（更貼切應叫 「scratchpad」）。&lt;/p&gt; 
&lt;p&gt;用途包括：&lt;/p&gt; 
&lt;p&gt;1. 工具調用後中間結果分析；&lt;/p&gt; 
&lt;p&gt;2. 嚴格政策/合規規則場景；&lt;/p&gt; 
&lt;p&gt;3. 多步決策路徑，每步都可能受前一步影響。&lt;/p&gt; 
&lt;p&gt;研究顯示，在這些場景中，配合領域定製 prompt，可提升性能最多達 54%。&lt;/p&gt; 
&lt;p&gt;★ 總結&lt;/p&gt; 
&lt;p&gt;構建智能體最困難的部分通常就是上下文管理。&lt;/p&gt; 
&lt;p&gt;Karpathy 曾説過，讓 LLM 「just pack the context window right」，就是智能體開發者的任務。&lt;/p&gt; 
&lt;p&gt;關鍵觀點是：上下文不是免費的，每個 token 都會影響模型行為。&lt;/p&gt; 
&lt;p&gt;即便擁有更大的上下文窗口，也不是信息管理可以鬆懈的理由。構建或優化智能體時請問自己：&lt;/p&gt; 
&lt;p&gt;&amp;gt; 上下文中的每一項，是否都值得留下？&lt;/p&gt; 
&lt;p&gt;如果答案是否定的，那麼你已經有了六種修復方法可用。&lt;/p&gt; 
&lt;p&gt;訪問：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.dbreunig.com%2F2025%2F06%2F26%2Fhow-to-fix-your-context.html" target="_blank"&gt;www.dbreunig.com/2025/06/26/how-to-fix-your-context.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;轉載自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5648162302%2FPDKpeqgWw%3Fpagetype%3Dprofilefeed" target="_blank"&gt;黃建同學，微博&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363652/how-to-fix-your-context</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363652/how-to-fix-your-context</guid>
      <pubDate>Tue, 15 Jul 2025 08:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>生命週期不足三個月，Windows 10 市佔率急劇下降</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;根據微軟的計劃，Windows 10 的主流支持將於 2025 年 10 月 14 日結束，雖然微軟會為用戶提供額外一年的免費更新，但許多用戶已經開始尋找替代方案。&lt;/p&gt; 
&lt;p&gt;根據 Statcounter 的最新數據，Windows 10 的市場份額正在急劇下降，2025 年 7 月，Windows 10 的市場份額從與 Windows 11 平分秋色，迅速跌落到低於 Windows 11。&lt;/p&gt; 
&lt;p&gt;目前 Windows 10 的市場份額為 42.99%，僅一個月就下降了 4.99 個百分點，而與去年同期相比，其市場份額更是從 64.99% 下降到了 42.99%，下降了 22 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6d94c0944c9e3ac49225685785d2e6635f1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與此同時，Windows 11 的市場份額則在迅速上升，從 47.98% 增加到 53.39%，僅一個月就增長了 5.41 個百分點，這一增長幅度對於備受爭議的 Windows 11 來説實屬罕見。與去年同期相比，Windows 11 的市場份額增長了 22.56 個百分點。&lt;/p&gt; 
&lt;p&gt;目前，還受支持的 Windows 版本（主要是 Windows 10 和 Windows 11）佔據了超過 96% 的 Windows 市場份額。&lt;/p&gt; 
&lt;p&gt;其餘的市場份額則被 Windows 7（2.04%）、Windows 8（0.88%）、Windows XP（0.44%）和 Windows 8.1（0.23%）瓜分。&lt;/p&gt; 
&lt;p&gt;對於仍在使用 Windows 10 的用戶來説，現在可能需要開始考慮替代方案了，一種選擇是加入微軟的擴展安全更新計劃，該計劃可以為用戶提供額外 12 個月的安全更新。&lt;/p&gt; 
&lt;p&gt;另一種選擇是直接升級到 Windows 11，隨着其它廠商也即將停止對 Windows 10 的驅動支持，放棄 Windows 10 也是遲早的選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363649</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363649</guid>
      <pubDate>Tue, 15 Jul 2025 08:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Wisdom SSH 新動態：代碼搜索精準化，AI 編輯再進階</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;div&gt;
 Wisdom SSH 是一款集成 AI 助手功能的工具，其操作便捷，能助力用戶高效完成服務器相關任務。近日，Wisdom SSH 宣佈已升級代碼搜索功能，通過深度整合先進的大語言模型及優化的搜索算法，進一步提升了代碼搜索的精準度與效率。
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 作為一款深受技術人員喜愛的 SSH 工具，Wisdom SSH 憑藉其 AI 助手，為用戶提供多種服務器操作便利。此次升級的代碼搜索功能，讓用戶在服務器眾多代碼文件中查找特定代碼片段更為輕鬆。
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 現在，用戶只需在 Wisdom SSH 的 AI 對話區輸入代碼搜索需求，如 「
 &lt;span style="background-color:rgba(0, 0, 0, 0.04); color:rgba(0, 0, 0, 0.85)"&gt;如 「分析/修改某項目處理用戶登錄的代碼片段」，系統便能快速定位並展示相關代碼內容。&lt;/span&gt;」，系統能快速定位並展開分析和修改相關代碼內容任務。
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;p&gt;&lt;img height="517" src="https://oscimg.oschina.net/oscnet/up-7ba15b3aeba7f8c123b5defb09455cc4cb5.png" width="423" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.85)"&gt;同時，Wisdom SSH 在 AI 編輯能力上也有大幅提升。比如在編輯代碼文件時，AI 不僅能更精準地理解用戶需求，像 「優化這段 Java 代碼的性能」，還能提供更全面且專業的修改建議。在備份原文件後，以更清晰的差異編輯形式展示修改內容，新增、刪除或修改的行一目瞭然。此外，校驗語法的能力也得到增強，確保修改後的代碼語法準確無誤，為用戶在服務器代碼編輯工作中提供更高效、可靠的支持。&lt;/span&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 「未來，Wisdom SSH 將持續探索大模型與先進搜索技術在服務器操作場景中的應用，拓展智能交互邊界，為用戶帶來更精準、高效、便捷的代碼搜索服務。」
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363648</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363648</guid>
      <pubDate>Tue, 15 Jul 2025 08:40:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Linus 仍在使用 AMD RX 580 顯卡搭配線程撕裂者</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;在 2025 年的今天，Linus Torvalds 依然在使用 2017 年發佈的 AMD RX 580 作為其主要桌面顯卡。這款基於 Polaris 架構的顯卡在 Linux 圈子裏得益於成熟完善的開源驅動支持，表現得相當出色，這也使得 Linus 對其青睞有加。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bbed3b6b8ea96e0939b6b75d90962a914e3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FRadeon-RX-590-Torvalds" target="_blank"&gt;Phoronix 發現&lt;/a&gt;&lt;/u&gt;，在 Linux 6.17 中，AMD 的 DSC 技術引發了黑屏問題，Linus 親自定位並回退了相關補丁，以保證內核開發的順利進行。&lt;/p&gt; 
&lt;p&gt;Linus 在郵件中提到 「還是那個老掉牙的 Radeon RX 580」，簡單一句話，盡顯其對穩定性的偏好。&lt;/p&gt; 
&lt;p&gt;&lt;img height="576" src="https://static.oschina.net/uploads/space/2025/0801/163801_oitH_2720166.png" width="1368" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;雖然 RX 580 在現代遊戲或 AI 工作負載下會力不從心，但對於編譯內核來説，配合 Linus 的 AMD 線程撕裂者系統，已經完全足夠。&lt;/p&gt; 
&lt;p&gt;Linus 幾年前從英特爾轉向了線程撕裂者 CPU，以加快 Linux 內核構建速度，事實證明這一選擇非常明智。&lt;/p&gt; 
&lt;p&gt;在筆記本方面，Linus 也重回英特爾陣營，此前他曾短暫使用過蘋果 M1 MacBook，他沒有透露具體型號，但確認它使用的是 Intel 集成「i915」顯卡。&lt;/p&gt; 
&lt;p&gt;Linus 一直對那些限制硬件或使內核開發複雜化的平台不太感興趣，不少人應該還記得 2012 年的那場問答，當時 Linus 豎起中指，破口大罵：「NVIDIA，Fxxk You」。&lt;/p&gt; 
&lt;p&gt;如今 NVIDIA 雖然發佈部分驅動源代碼並改進了對開放內核的支持，但很顯然 Linus 仍然偏愛開放的 AMD。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363647</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363647</guid>
      <pubDate>Tue, 15 Jul 2025 08:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MOSS-TTSD 開源：百萬小時訓練打造 AI 播客新王者</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;由清華大學語音與語言實驗室 (Tencent AI Lab) 聯合上海創智學院、復旦大學和模思智能打造的 MOSS-TTSD (Text to Spoken Dialogue) 近日正式開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這款基於 Qwen3-1.7B-base 模型續訓練的語音對話生成模型，以約 100 萬小時單説話人語音數據和 40 萬小時對話語音數據為基礎，採用離散化語音序列建模方法，實現了中英雙語的高表現力對話語音生成，特別適合 AI 播客、有聲小説和影視配音等長篇內容創作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-486a73dddfa4c43623c233fef6faa3175cd.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;MOSS-TTSD 的核心創新在於其 XY-Tokenizer，採用雙階段多任務學習方式，通過八層 RVQ 碼本將語音信號壓縮至 1kbps 比特率，同時保留語義與聲學信息，確保生成語音的自然度和流暢性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;模型支持最長 960 秒的超長語音生成，避免了傳統 TTS 模型拼接片段導致的不自然過渡。此外，MOSS-TTSD 具備零樣本音色克隆能力，可通過上傳完整對話片段或單人音頻實現雙人語音克隆，並支持聲音事件控制，如笑聲等非語言聲音，賦予語音更豐富的表現力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與市場上其他語音模型相比，MOSS-TTSD 在中文客觀指標上大幅領先開源模型 MoonCast，韻律和自然度表現優異。然而，相較於字節跳動的豆包語音模型，其語氣和節奏感略遜一籌，但在開源和免費商業使用的優勢下，MOSS-TTSD 仍展現出強大的應用潛力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;MOSS-TTSD 的發佈為 AI 語音交互領域注入新活力，尤其在長篇訪談、播客製作和影視配音等場景中，其穩定性和表現力將推動內容創作的智能化進程。未來，團隊計劃進一步優化模型，增強多説話人場景下的語音切換準確性和情感表達。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363646</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363646</guid>
      <pubDate>Tue, 15 Jul 2025 08:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MCP-Use - 將任何 LLM 連接到任何 MCP</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;MCP-Use 是一種開源方式，可將&lt;strong style="color:#1f2328"&gt;任何 LLM 連接到任何 MCP 服務器&lt;/strong&gt;並構建具有工具訪問權限的自定義 MCP 代理，而無需使用閉源或應用程序客戶端。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主要特點：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;開源&lt;/strong&gt; 將任何 LLM 連接到任何 MCP 服務器，無需供應商鎖定&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;靈活配置&lt;/strong&gt; 通過簡單的配置系統支持任何 MCP 服務器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;輕鬆設置&lt;/strong&gt; 用於 MCP 服務器集成的簡單基於 JSON 的配置&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用 LLM 支持&lt;/strong&gt; 與任何 LangChain 支持的 LLM 提供商兼容&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多服務器支持&lt;/strong&gt; 同時連接到多個 MCP 服務器以實現複雜的工作流程&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;動態服務器選擇&lt;/strong&gt; 代理可以為每個任務動態選擇最合適的 MCP 服務器&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span style="color:#1f2328"&gt;讓開發人員輕鬆地將任何 LLM 連接到網頁瀏覽、文件操作等工具。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果想快速開始，可訪問&lt;a href="https://mcp-use.com/"&gt;mcp-use.com 網站&lt;/a&gt;，使用你最喜歡的 MCP 服務器構建和部署代理。&lt;/li&gt;
&lt;li&gt;訪問&lt;a href="https://docs.mcp-use.com/"&gt;mcp-use 文檔&lt;/a&gt;以開始使用 mcp-use 庫&lt;/li&gt;
&lt;li&gt;對於 TypeScript 版本，可訪問&lt;a href="https://github.com/mcp-use/mcp-use-ts"&gt;mcp-use-ts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/mcp-use</link>
      <guid isPermaLink="false">https://www.oschina.net/p/mcp-use</guid>
      <pubDate>Tue, 15 Jul 2025 08:15:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 年化收入 120 億美元，ChatGPT 周活用戶突破 7 億</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fopenai-hits-12-billion-annualized-revenue-breaks-700-million-chatgpt-weekly-active-users" target="_blank"&gt;根據 The Information 的報道&lt;/a&gt;，OpenAI 年化收入已翻倍至 120 億美元，同時其旗艦產品 ChatGPT 的周活躍用戶數突破 7 億。&lt;/p&gt; 
&lt;p&gt;快速增長的同時，OpenAI 的現金消耗也在加速。該公司已將 2025 年現金消耗預期上調至約 80 億美元，較此前預期增加 10 億美元。其在服務器租賃方面的支出可能超過此前預計的 140 億美元。&lt;/p&gt; 
&lt;p&gt;在融資方面，OpenAI 正接近完成第二輪融資其中 75 億美元融投資的承諾，紅杉資本和 Tiger Global Management 等現有股東將各自投入數億美元，其他參與方包括 Dragoneer 和 Founders Fund 等知名投資機構。&lt;/p&gt; 
&lt;p&gt;據上述報道，OpenAI 在 2025 年前七個月實現收入翻番，年化收入達到 120 億美元，相比 2024 年約 40 億美元的收入水平實現大幅增長。這一強勁增長使得該公司有望超越其 2025 年 127 億美元的收入預期。&lt;/p&gt; 
&lt;p&gt;上述媒體援引知情人士透露，OpenAI 目前月收入約為 10 億美元，相比年初的約 5 億美元實現大幅躍升。主要驅動力來自更多企業和個人訂閲其用於編程和其他任務的聊天機器人服務。&lt;/p&gt; 
&lt;p&gt;用戶增長是推動收入上升的關鍵因素。ChatGPT 產品目前擁有約 7 億周活躍用戶，涵蓋消費者和企業客戶，相比 3 月底 OpenAI 所有產品 5 億周活躍用戶的數據實現顯著增長。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363632</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363632</guid>
      <pubDate>Tue, 15 Jul 2025 07:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Vercel 發佈 AI SDK 5，構建全棧 AI 應用的開發工具包</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Vercel 發佈了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-sdk-5" target="_blank"&gt;AI SDK 5&lt;/a&gt;，這是一個用於構建全棧 AI 應用的開發工具包，它在前代基礎上進行了全面升級，提供了更強大的功能、更高的靈活性和更好的開發體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img height="565" src="https://static.oschina.net/uploads/space/2025/0801/153828_B1BV_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是 AI SDK 5 的主要更新內容：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;聊天功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;徹底重建&lt;/strong&gt;：引入了兩種不同的消息類型——&lt;code&gt;UIMessage&lt;/code&gt; 和 &lt;code&gt;ModelMessage&lt;/code&gt;，解決了開發者在狀態管理和聊天曆史持久化方面的挑戰。&lt;code&gt;UIMessage&lt;/code&gt; 是應用程序狀態的「真實來源」，包含所有消息、元數據和工具結果，推薦用於持久化存儲；&lt;code&gt;ModelMessage&lt;/code&gt; 則是為語言模型優化的簡化表示。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;類型安全&lt;/strong&gt;：開發者可以創建自定義的 &lt;code&gt;UIMessage&lt;/code&gt; 類型，並在服務器和客戶端之間傳遞，實現端到端的完全類型安全。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;流式傳輸&lt;/strong&gt;：引入了 &lt;code&gt;Data Parts&lt;/code&gt; 功能，允許開發者發送自定義數據塊，如狀態更新或部分工具結果，同時保持代碼的可維護性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Agent 構建&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;精確的執行流控制&lt;/strong&gt;：&lt;code&gt;stopWhen&lt;/code&gt; 參數允許開發者定義工具調用循環的停止條件，例如達到特定步數或調用了某個特定工具；&lt;code&gt;prepareStep&lt;/code&gt; 鈎子則允許在每一步執行前動態調整參數，如更換模型、修改系統提示或啓用/禁用特定工具。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;面向對象封裝&lt;/strong&gt;：新增的 &lt;code&gt;Agent&lt;/code&gt; 類為構建 Agent 提供了面向對象的封裝。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;語音功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;統一提供商抽象&lt;/strong&gt;：通過 &lt;code&gt;experimental_generateSpeech&lt;/code&gt; 和 &lt;code&gt;experimental_transcribe&lt;/code&gt; API，為 OpenAI、ElevenLabs、DeepGram 等提供商的語音生成和轉錄服務提供了統一、類型安全的接口。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;工具調用增強&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;動態工具&lt;/strong&gt;：支持動態工具、提供商執行的工具（如 OpenAI 的網頁搜索）以及更精細的生命週期鈎子。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;其他更新&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;流媒體協議&lt;/strong&gt;：將 &lt;code&gt;SSE&lt;/code&gt; 作為標準的流媒體協議。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;全局提供商&lt;/strong&gt;：引入全局提供商（默認為 Vercel AI Gateway），簡化模型 ID 的使用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;訪問原始數據&lt;/strong&gt;：支持訪問原始請求和響應數據以增強調試和控制能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zod 4 支持&lt;/strong&gt;：增加了對 Zod 4 的支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;遷移工具&lt;/strong&gt;：為幫助用戶平滑遷移，Vercel 提供了自動化的代碼修改工具（&lt;code&gt;codemods&lt;/code&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-sdk-5" target="_blank"&gt;點此查看發佈説明&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363628/vercel-ai-sdk-5</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363628/vercel-ai-sdk-5</guid>
      <pubDate>Tue, 15 Jul 2025 07:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟向報告 .NET 漏洞的用戶支付高達 40000 美元的報酬</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;許多公司提供漏洞賞金計劃，鼓勵人們搜索並發現軟件中的安全漏洞，並私下向供應商報告，以便在惡意攻擊者利用漏洞之前實施並應用修復程序。安全研究人員和其他公眾會獲得金錢獎勵，從而獲得經濟激勵。&lt;/p&gt; 
&lt;p&gt;現在，微軟已宣佈對其 .NET Bounty 計劃進行重大更新。&lt;/p&gt; 
&lt;p&gt;獎勵金額現從 7000 美元起，最高可達令人垂涎的 40000 美元。請注意，最高獎勵僅適用於私下披露遠程代碼執行 (RCE) 或特權提升 (EoP) 漏洞，並提供完整文檔且造成嚴重影響的情況。&lt;/p&gt; 
&lt;p&gt;各獎勵等級的細分如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/153421_aSuq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，.NET 賞金計劃主要圍繞 .NET 和 ASP.NET&amp;nbsp;Core 展開，包括 Blazor 和 Aspire。但新的產品類別現在涵蓋了所有受支持的 .NET 和 ASP.NET 版本、適用於 .NET Framework 的 ASP.NET&amp;nbsp;Core、上述內容提供的模板、其存儲庫中的 GitHub Actions 以及 F# 等相關技術。&lt;/p&gt; 
&lt;p&gt;更新後的獎勵結構確保了嚴重性等級的明確定義，以便高影響的問題獲得更高的獎勵，同時還提供了關於如何將報告視為「完整」的指南。您可以在微軟的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmsrc.microsoft.com%2Fblog%2F2025%2F07%2F.net-bounty-program-now-offers-up-to-40000-in-awards%2F" target="_blank"&gt;專門博客文章&lt;/a&gt;中找到更多信息。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363626/dotnet-bounty-program-now-offers-up-to-40000-in-awards</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363626/dotnet-bounty-program-now-offers-up-to-40000-in-awards</guid>
      <pubDate>Tue, 15 Jul 2025 07:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>沒有套路，真的免費：模力方舟全免費的模型都在這了</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;想找無套路，真免費，不限額度的大模型？別再滿世界找了——來模力方舟就夠。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;立即訪問模力方舟 AI 模型廣場：&lt;a href="https://ai.gitee.com/serverless-api"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本文整理了目前模力方舟上完全免費開放使用的模型， 不是「每天送你 10 次體驗」，也不是「註冊送額度」，更不是「邀請獲禮金」，而是&lt;strong&gt;不限次數、毫無限制、直接免費用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;無論你是想&lt;strong&gt;生成文本、寫代碼、合成語音、做推理，還是想過濾下內容風險&lt;/strong&gt;，模力方舟都準備好了免費的相關模型，&lt;strong&gt;全部 0 元接入、不限次數&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;通用語言模型：超能聊，跑得快&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen3-8B / Qwen3-4B / Qwen3-0.6B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151643_pivg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;國產開源的 Qwen3 系列，從輕量級到中型參數都有，支持「思考模式」與「對話模式」自由切換，還能寫代碼、講英文、做推理。模型權重與 API 已全面開放，商用也不用擔心授權問題。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen2-7B-Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151659_Ojcp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;升級版 Qwen 架構，專為「你讓它幹啥它就幹啥」的指令模式設計，適合結構化問答、信息抽取等任務，照樣免費用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;InternLM3-8B-Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;書生·浦語第三代，和 Qwen 一樣屬於國產頭部陣營，指令跟隨能力強、推理不拉胯，在 8B 量級裏非常能打。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151711_9iVU_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GLM-4-9B / GLM-4-9B-Chat&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151725_ZpJL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;來自智譜的通用語言模型，性能紮實，特別適閤中文語境下的多輪問答和對話場景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-R1-Distill-Qwen 系列（14B / 7B / 1.5B）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151739_89cE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 模型的輕量蒸餾版，覆蓋大中小三種參數體型，推理性能不錯但定位仍是通用語言模型，適合對資源有要求的部署場景。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;數學 / 定理證明：專精模型上場&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-Prover-V2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151756_uzEG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;專為 Lean 4 定理證明設計，具備將複雜問題拆解為子目標、合成鏈式推理過程的能力。模型通過 DeepSeek-V3 驅動的遞歸證明管線進行冷啓動訓練，融合非形式與形式數學推理，顯著提升了定理證明效率與泛化能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;代碼生成模型：小身材，大能力&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;codegeex4-all-9b&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151809_32Qh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;多語言代碼生成模型，支持包括代碼補全和生成、代碼解釋器、網絡搜索、函數調用、倉庫級代碼問答在內的全面功能，覆蓋軟件開發的各種場景。是參數少於 10B 的頂尖代碼生成模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;語音識別/合成模型：小體積，大用途&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;SenseVoiceSmall&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151839_AoYq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;來自通義千問團隊的輕量級語音模型，結合高效算法和小型化設計，提供低延遲和高準確度的語音處理能力，適用於資源受限的應用場景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Spark-TTS-0.5B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151851_iZPk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;來自 Spark Audio 團隊的文本轉語音模型，能夠實現高精度、自然的語音合成。它高效、靈活、功能強大，適用於研究和生產環境。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;風控識別模型：確保內容合規&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;nsfw-classifier / Security-semantic-filtering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151909_OgHB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模力方舟提供了兩種風控識別模型，分別面向圖片分類和文本敏感內容過濾，確保內容合規與敏感信息保護。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;檢索增強開發者福利：向量 + 重排模型也全免費&lt;/h4&gt; 
&lt;p&gt;模力方舟攜手國產 GPU 夥伴，已將模型廣場中 Embedding 與 Reranker 模型&lt;strong&gt;全部開放免費使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;RAG 架構必備的檢索向量和重排序能力，即刻零成本上手！&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Embedding 向量模型：支持中文、英文、多語言編碼，適配主流語義檢索任務；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Reranker 重排序模型：優化文檔排序效果，讓你的檢索結果相關且可信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151936_fUHW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;所有模型支持 API 調用，無需申請、無需授權、直接接入，非常適合搜索類應用、知識庫問答、RAG 業務開發等場景使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;真免費，不限次，現在就能用&lt;/h3&gt; 
&lt;p&gt;馬建倉再強調一次：上面這些模型&lt;strong&gt;沒有「體驗額度」，是「完全免費」&lt;/strong&gt;。不限制調用次數、不限制模型功能，可以直接接入使用。&lt;/p&gt; 
&lt;p&gt;立即訪問模力方舟 AI 模型廣場：&lt;strong&gt;&lt;a href="https://ai.gitee.com/serverless-api"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363622</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363622</guid>
      <pubDate>Tue, 15 Jul 2025 07:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元 3D 世界模型技術亮點速覽</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;騰訊近日正式發佈&lt;strong&gt;混元 3D 世界模型 1.0（HunyunWorld-1.0）&lt;/strong&gt;並全面開源。據稱這是首個開源並且兼容傳統 CG 管線的可漫遊世界生成模型，為遊戲開發、VR、數字內容創作等領域帶來了全新的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/150655_8uFO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據該模型的技術報告，HunyunWorld-1.0 採用生成式架構，結合全景圖像合成與分層 3D 重建技術，實現了高質量、沉浸式的可漫遊 3D 場景生成。&lt;/p&gt; 
&lt;p&gt;該模型通過語義分層的 3D 場景表徵與生成算法，同時支持"文生世界"和"圖生世界"兩種生成方式。主要技術框架包括三部分，即全景世界代理生成、基於語義的世界分層與分層世界重建。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/150932_iXbY_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;混元 3D 世界模型 1.0（HunyunWorld-1.0）是融合兩類方法優勢的創新框架，能夠依據文本或圖像輸入生成沉浸式、可探索、可交互的 3D 場景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;360°沉浸體驗 ：通過全景圖將複雜的 3D 世界高效地表徵為 360 度覆蓋的 2D 圖像代理，為後續生成完整的 3D 世界建模提供了豐富的空間信息；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151052_YWxE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;工業級兼容性 ：生成的世界場景支持導出標準的 3D 網格格式，能夠無縫導入現有 3D 建模軟件和主流遊戲引擎，用於二次開發；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151131_DzWQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原子級交互&amp;nbsp;：通過物體解耦的 3D 建模方式，生成物體和背景可分離的 3D 世界，支持精準的物體級交互控制，提升了生成世界的操作自由度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151149_qD74_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.21809" target="_blank"&gt;點此查看更多技術細節&lt;/a&gt;&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363621</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363621</guid>
      <pubDate>Tue, 15 Jul 2025 07:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動 Seed 助力清華獲機器人足球世界盃冠軍</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;字節跳動 Seed 發文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4e6maGpWaEtWfj1rxkhI0w" target="_blank"&gt;宣佈&lt;/a&gt;，其與清華大學趙明國教授團隊聯合研發的人形機器人運動算法 「HumanoidKick」 在 2025RoboCup 機器人世界盃人形組成人組比賽中，成功幫助清華火神隊獲得冠軍。這也是中國機器人足球隊首次在機器人世界盃該組別奪冠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，此次奪冠的關鍵之一是&lt;strong&gt;基於視覺的&lt;strong&gt;&lt;strong&gt;端到端&lt;/strong&gt;&lt;/strong&gt;自主踢球算法 HumanoidKick&lt;/strong&gt;，由字節跳動 Seed 團隊與清華大學趙明國教授團隊聯合提出並驗證。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HumanoidKick 算法面向人形機器人硬件，通過基於視覺的深度強化學習，實現了「找球 - 追球 - 踢球」全過程的統一策略，在實際足球比賽中驗證有效。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="368" src="https://oscimg.oschina.net/oscnet/up-28b9adf735a26eea28efb96fd06fe8b5e72.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HumanoidKick 算法嘗試解決以下三項實際挑戰：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;從視覺到行動的實時聯動&lt;/strong&gt;：傳統機器人足球方案依賴手動編程的預設策略，面對場上變化，常陷入動作卡頓的困境，錯失進攻的有利時機。該算法通過端到端深度強化學習方法，構建了視覺感知與機器人運動控制的毫秒響應機制，讓機器人能像人類球員一樣邊「看」邊「動」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;從動作整合到自主決策&lt;/strong&gt;：經過數千個環境的並行訓練，機器人得以將多種分散的動作技能整合為統一連貫的端到端策略，構建起「單個動作」 「賽場行為」 「競技策略」之間的關聯。面對實時變化的賽場動態，機器人可以自主決策行動，並泛化出自適應的踢球能力。這種能力進化讓機器人擺脫了被動執行預設動作的侷限，實現了從零散技能到完整策略的突破。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;從仿真到真實環境的適應&lt;/strong&gt;：為了讓算法在真實世界中保持穩定，團隊採用精確建模和域隨機化結合的訓練方案——在仿真環境中，建模真實世界的感知噪聲和物理擾動（如地面條件、關節噪聲），讓機器人在仿真環境中「經歷」各種現實極端場景，實現從仿真環境到真機的無縫應用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;依託仿真環境中的海量訓練，HumanoidKick 算法在現實賽場中成功幫助機器人脫離既定動作流程束縛，依據瞬息萬變的賽場態勢，迅速自主規劃行動方案。在比賽中，機器人展現出了較好的反應速度，最終取得勝利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363620</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363620</guid>
      <pubDate>Tue, 15 Jul 2025 07:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌開源 LangExtract，從非結構化文本提取結構化信息的 Python 庫</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌開源了名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Flangextract" target="_blank"&gt;LangExtract&lt;/a&gt;的 Python 庫，該庫使用 LLMs 根據用戶定義的指令從非結構化文本文檔中提取結構化信息（諸如臨牀筆記或報告之類的材料），識別並整理關鍵細節，同時確保提取的數據與源文本相對應。&lt;/p&gt; 
&lt;p&gt;LangExtract 的核心優勢在於其強大的功能特性。首先是「精確的源文本溯源」，它能將每一個提取出的信息精確映射回其在原始文本中的位置，並支持交互式高亮可視化，便於用戶追溯和驗證。&lt;/p&gt; 
&lt;p&gt;項目主頁提供了快速上手的代碼示例，演示瞭如何定義提示、提供示例、運行提取，並將結果保存為.jsonl 文件，最後生成交互式 HTML 可視化報告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/145804_AbcO_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;LangExtract 適用於任何領域，用戶僅需提供少量示例即可定義提取任務，無需模型微調。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363619</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363619</guid>
      <pubDate>Tue, 15 Jul 2025 07:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>一張圖解釋上下文工程（Context Engineering ）</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;製圖： Victoria Slocum&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-38450d8633e8576132b7439b4dd873cf590.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下為解釋&lt;/p&gt; 
&lt;p&gt;---------------------------&lt;br&gt; 提示工程（Prompt Engineering）已死，上下文工程（𝗖𝗼𝗻𝘁𝗲𝘅𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴） 萬歲！&lt;/p&gt; 
&lt;p&gt;（好吧，也沒完全死掉——但它無疑正在進化成一種遠為更強大的形態）&lt;/p&gt; 
&lt;p&gt;讓我們來認識一下上下文工程（𝗖𝗼𝗻𝘁𝗲𝘅𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴）——這是一門藝術，致力於構建動態系統，從而精準地為大語言模型（LLM）提供成功完成任務所需的一切。&lt;/p&gt; 
&lt;p&gt;隨着我們從簡單的聊天機器人轉向複雜的 AI 代理（Agent），我們正逐漸意識到，僅僅靠巧妙的提示語是不夠的。真正重要的是精心編排一個完整的信息生態系統，並將這些信息輸入到你的大語言模型中。&lt;/p&gt; 
&lt;p&gt;那麼，這具體意味着什麼呢？&lt;/p&gt; 
&lt;p&gt;它的核心在於構建動態系統，以正確的格式提供正確的信息和工具，從而讓大語言模型能夠切實地完成任務。&lt;/p&gt; 
&lt;p&gt;一個經過上下文工程設計的系統的構成解析：&lt;/p&gt; 
&lt;p&gt;✨用戶信息 (𝗨𝘀𝗲𝗿 𝗜𝗻𝗳𝗼𝗿𝗺𝗮𝘁𝗶𝗼𝗻): 偏好、歷史記錄和個性化數據。&lt;br&gt; ✨工具使用 (𝗧𝗼𝗼𝗹 𝗨𝘀𝗲): API、計算器、搜索引擎——任何大語言模型完成工作所需的工具。&lt;br&gt; ✨RAG 上下文 (𝗥𝗔𝗚 𝗖𝗼𝗻𝘁𝗲𝘅𝘁): 從像 Weaviate 這樣的向量數據庫中檢索出的信息。&lt;br&gt; ✨用戶輸入 (𝗨𝘀𝗲𝗿 𝗜𝗻𝗽𝘂𝘁): 當前實際的查詢或任務。&lt;br&gt; ✨代理推理 (𝗔𝗴𝗲𝗻𝘁 𝗥𝗲𝗮𝘀𝗼𝗻𝗶𝗻𝗴): 大語言模型的思考過程和決策鏈。&lt;br&gt; ✨聊天曆史 (𝗖𝗵𝗮𝘁 𝗛𝗶𝘀𝘁𝗼𝗿𝘆): 提供對話連續性的先前交互記錄。&lt;/p&gt; 
&lt;p&gt;那麼，它的記憶架構是怎樣的呢？&lt;/p&gt; 
&lt;p&gt;✨短期記憶 (𝗦𝗵𝗼𝗿𝘁-𝘁𝗲𝗿𝗺 𝗺𝗲𝗺𝗼𝗿𝘆): 存在於上下文窗口中，處理當前對話。&lt;br&gt; ✨長期記憶 (𝗟𝗼𝗻𝗴-𝘁𝗲𝗿𝗺 𝗺𝗲𝗺𝗼𝗿𝘆): 存儲在向量數據庫（如 Weaviate）中，跨會話持久化存儲用戶偏好和過去的交互記錄。&lt;/p&gt; 
&lt;p&gt;這為什麼重要？&lt;br&gt; 因為當代理系統（agentic systems）失敗時，很少是因為模型本身不夠聰明，而是因為我們沒有給它提供正確的上下文。&lt;/p&gt; 
&lt;p&gt;信息的格式同樣重要。一條結構清晰的錯誤信息，永遠勝過一大堆雜亂的 JSON 數據。就像人類一樣，大語言模型也需要清晰、易於理解的溝通方式。&lt;/p&gt; 
&lt;p&gt;轉載自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FPDFOm8vhG" target="_blank"&gt;蟻工廠，微博&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363615</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363615</guid>
      <pubDate>Tue, 15 Jul 2025 06:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美國上訴法院維持谷歌應用商店壟斷裁決</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;位於舊金山的美國聯邦第九巡迴上訴法院 31 日裁定，駁回谷歌公司上訴，維持此前地方法院的陪審團裁決和法官指令。根據相關裁決和指令，谷歌將不得不改變其 Play 應用商店的一些重要管理方針，包括長期以來不允許其他應用商店在 Play 商店正常運營。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-097faa551a242c0ea617e6e9f397b03bcec.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Epic 遊戲公司此前在其開發的《堡壘之夜》遊戲中，通過技術手段讓玩家進行應用內購買時可選擇繞過谷歌的支付系統，從而避免向谷歌支付 30% 的佣金，谷歌隨後將該遊戲從 Play 商店中下架。Epic 遊戲公司在 2020 年就此提起針對谷歌的反壟斷訴訟。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;陪審團 2023 年裁決，谷歌違反了聯邦和加利福尼亞州反壟斷法，故意獲取或維持市場壟斷地位，不合理地限制交易，並非法將 Play 商店的使用與該公司的結算服務捆綁在一起。地方法官 2024 年簽發針對谷歌的指令，要求該公司整改 Play 商店，消除反競爭的行為。谷歌隨後提起上訴，上訴期間該指令暫緩實施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;聯邦第九巡迴上訴法院法官的裁決駁回了谷歌的上訴，稱地方法院在審理時並未濫用自由裁量權，所發佈的指令得到陪審團裁決以及地方法院自身調查結果的支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這一最新的裁決公佈後，Epic 首席執行官蒂姆·斯威尼在社交媒體平台上表示，安卓版 Epic 遊戲商店將登陸 Play 商店。谷歌方面則表示，會繼續上訴。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;按照相關法律程序，谷歌可以選擇要求第九巡迴上訴法院全體法官複審此案，也可以直接向最高法院上訴。（新華社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363614</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363614</guid>
      <pubDate>Tue, 15 Jul 2025 06:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌發佈面向程序員的開源字體：Google Sans Code</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌發佈了一款面向程序員的開源字體：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgooglefonts%2Fgooglesans-code" target="_blank"&gt;Google Sans Code&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-94ed522f81ee53d97857a1fa258ac6bd4a3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Google Sans Code 是一個等寬字體系列，為代碼帶來清晰度、可讀性以及一絲谷歌獨特的品牌特色。&lt;/p&gt; 
&lt;p&gt;主要特性&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增強可讀性：專為代碼編輯器和終端中的最佳可讀性而設計&lt;/li&gt; 
 &lt;li&gt;支持腳本：擴展拉丁文，支持多種語言&lt;/li&gt; 
 &lt;li&gt;變體字體：提供從 300 到 800 的廣泛字重軸範圍&lt;/li&gt; 
 &lt;li&gt;OpenType 功能：樣式集、本地化形式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該字體源自谷歌的品牌字體設計風格，併為 Gemini 和 Android Studio 等產品開發，它確保每個字符即使在較小尺寸下也能保持清晰可辨。 此外，它還針對編程語言語法的獨特排版需求進行了精細調整。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363609/googlesans-code</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363609/googlesans-code</guid>
      <pubDate>Tue, 15 Jul 2025 06:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
