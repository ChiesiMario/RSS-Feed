<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Thu, 19 Jun 2025 12:45:02 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>馬斯克駁斥 xAI 鉅額虧損傳聞：每月燒錢 10 億美元純屬無稽之談</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有媒體報道稱，科技巨頭埃隆・馬斯克創辦的人工智能初創公司 xAI 每月燒錢高達 10 億美元，這一説法引發了廣泛關注。消息稱，xAI 在構建先進的 AI 模型方面的成本遠遠超過其收入增長，公司的資金需求愈加迫切。對此，馬斯克進行了強烈反駁，稱這些報道 「純屬胡説八道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-34a4735e7445256b266cb4625e29a62693a.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 自 2023 年成立以來，正積極尋求通過債務和股權融資來填補資金缺口，目標是融資 93 億美元。儘管如此，馬斯克合併了 xAI 與社交媒體平台 X，令合併後的新公司的估值達 1130 億美元，其中 xAI 的估值為 800 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據相關人士透露，xAI 的支出速度在整個 AI 行業中顯得尤為顯著。公司預計在未來三個月內將花費超過一半的融資金額，而全年虧損預計達到 130 億美元。相比之下，競爭對手 OpenAI 預計在 2025 年的收入將達到 127 億美元，而 xAI 在同年僅預計收入 5 億美元，明年才有可能突破 20 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;馬斯克的巨大個人魅力和資源，使得 xAI 有理由保持樂觀。他曾在特斯拉和 SpaceX 的早期階段也經歷了類似的鉅額虧損，然而這些項目最終都取得了成功。馬斯克相信，xAI 將在 2027 年實現盈利，儘管當前仍需與時間賽跑，以應對鉅額支出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 計劃利用與 X 平台的整合，利用其龐大的數據檔案來訓練 AI 模型，從而降低昂貴的數據費用。雖然目前 xAI 正在進行大規模的資金籌集，但公司對於未來的發展前景充滿信心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356227</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356227</guid>
      <pubDate>Sun, 11 May 2025 10:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Boot 啓動優化實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網服務器團隊- Liu Di&lt;/p&gt; 
 &lt;p&gt;本文系統性分析並優化了一個 Spring Boot 項目啓動耗時高達 280 秒的問題。通過識別瓶頸、優化分庫分表加載邏輯、異步初始化耗時任務等手段，最終將啓動耗時縮短至 159 秒，提升近 50%。文章涵蓋啓動流程分析、性能熱點識別、異步初始化設計等關鍵技術細節，適用於大型 Spring Boot 項目的性能優化參考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;文章太長？1 分鐘看圖抓住核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//de4a19ad8ae5ee03f930e1ffa71b9716.gif" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、前言&lt;/h1&gt; 
&lt;p&gt;隨着業務的發展，筆者項目對應的 Spring Boot 工程的依賴越來越多。隨着依賴數量的增長，Spring 容器需要加載更多組件、解析複雜依賴並執行自動裝配，導致項目啓動時間顯著增長。在日常開發或測試過程中，一旦因為配置變更或者其他熱部署不生效的變更時，項目重啓就需要等待很長的時間影響代碼的交付。加快 Spring 項目的啓動可以更好的投入項目中，提升開發效率。&lt;/p&gt; 
&lt;p&gt;整體環境介紹：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Spring 版本：4.3.22&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Spring Boot 版本：1.5.19&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU：i5-9500&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內存：24GB&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化前啓動耗時：280 秒&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、Spring Boot 項目啓動流程介紹&lt;/h1&gt; 
&lt;p&gt;Spring Boot 項目主要啓動流程都在 org.spring-&lt;/p&gt; 
&lt;p&gt;framework.boot.SpringApplication#run(java.lang.String...) 方法中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public ConfigurableApplicationContext run(String... args) {
    StopWatch stopWatch = new StopWatch();
    stopWatch.start();
    // Spring 上下文
    ConfigurableApplicationContext context = null;
    FailureAnalyzers analyzers = null;
    configureHeadlessProperty();
    // 初始化 SpringApplicationRunListener 監聽器
    SpringApplicationRunListeners listeners = getRunListeners(args);
    listeners.starting();
    try {
        ApplicationArguments applicationArguments = new DefaultApplicationArguments(
                args);
        // 環境準備
        ConfigurableEnvironment environment = prepareEnvironment(listeners,
                applicationArguments);
         // 打印 banner
        Banner printedBanner = printBanner(environment);
        // 創建上下文
        context = createApplicationContext();
        analyzers = new FailureAnalyzers(context);
        // 容器初始化
        prepareContext(context, environment, listeners, applicationArguments,
                printedBanner);
        // 刷新容器內容
        refreshContext(context);
        afterRefresh(context, applicationArguments);
        // 結束監聽廣播
        listeners.finished(context, null);
        stopWatch.stop();
        if (this.logStartupInfo) {
            new StartupInfoLogger(this.mainApplicationClass)
                    .logStarted(getApplicationLog(), stopWatch);
        }
        return context;
    } catch (Throwable ex) {
        handleRunFailure(context, listeners, analyzers, ex);
        throw new IllegalStateException(ex);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到在啓動流程中，監聽器應用在了應用的多個生命週期中。並且 Spring Boot 中也預留了針對 listener 的擴展點。我們可以藉此實現一個自己的擴展點去監聽 Spring Boot 的每個階段的啓動耗時，實現如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Slf4j
public class MySpringApplicationRunListener implements SpringApplicationRunListener{
    private Long startTime;
    public MySpringApplicationRunListener(SpringApplication application, String[] args){
    }
    @Override
    public void starting(){
        startTime = System.currentTimeMillis();
        log.info("MySpringListener 啓動開始 {}", LocalTime.now());
    }
    @Override
    public void environmentPrepared(ConfigurableEnvironment environment){
        log.info("MySpringListener 環境準備，準備耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextPrepared(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文準備，耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextLoaded(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文載入，耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
   @Override
   public void finished(ConfigurableApplicationContext context, Throwable exception){
        log.info("MySpringListener 結束，耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接着還需要在 classpath/META-INF 目錄下新建 spring.factories 文件，並添加如下文件內容：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;org.springframework.boot.SpringApplicationRunListener=com.vivo.internet.gameactivity.api.web.MySpringApplicationRunListener
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;至此，藉助 Listener 機制，我們能夠追蹤 Spring Boot 啓動各階段的耗時分佈，為後續性能優化提供數據支撐。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e19075cd485d32e7d5029945fd7ba604.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;contextLoaded 事件是在 run 方法中的 prepareContext() 結束時調用的，因此 contextLoaded 事件和 finished 事件之間僅存在兩個語句：refreshContext(context) 和 afterRefresh&lt;/p&gt; 
&lt;p&gt;(context,applicationArguements) 消耗了 285 秒的時間，調試一下就能發現主要耗時在 refreshContext() 中。&lt;/p&gt; 
&lt;h1&gt;三、AbstractApplicationContext#refresh&lt;/h1&gt; 
&lt;p&gt;refreshContext() 最終調用到 org.spring-framework.context.support.AbstractApplicationContext#refresh 方法中，這個方法主要是 beanFactory 的預準備、對 beanFactory 完成創建並進行後置處理、向容器添加 bean 並且給 bean 添加屬性、實例化所有 bean。通過調試發現，finishBeanFactoryInitialization(beanFactory) 方法耗時最久。該方法負責實例化容器中所有的單例 Bean，是啓動性能的關鍵影響點。&lt;/p&gt; 
&lt;h1&gt;四、找出實例化耗時的 Bean&lt;/h1&gt; 
&lt;p&gt;Spring Boot 也是利用的 Spring 的加載流程。在 Spring 中可以實現 InstantiationAwareBeanPost-&lt;/p&gt; 
&lt;p&gt;Processor 接口去在 Bean 的實例化和初始化的過程中加入擴展點。因此我們可以實現該接口並添加自己的擴展點找到處理耗時的 Bean。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class TimeCostCalBeanPostProcessor implements InstantiationAwareBeanPostProcessor {
    private Map&amp;lt;String, Long&amp;gt; costMap = Maps.newConcurrentMap();

    @Override
    public Object postProcessBeforeInstantiation(Class&amp;lt;?&amp;gt; beanClass, String beanName) throws BeansException {
        if (!costMap.containsKey(beanName)) {
            costMap.put(beanName, System.currentTimeMillis());
        }
        return null;
    }
    @Override
    public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {
        return true;
    }
    @Override
    public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException {
        return pvs;
    }
    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        return bean;
    }
    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
         if (costMap.containsKey(beanName)) {
            Long start = costMap.get(beanName);
            long cost = System.currentTimeMillis() - start;
            // 只打印耗時長的 bean
             if (cost &amp;gt; 5000) {
                System.out.println("bean: " + beanName + "\ttime: " + cost + "ms");
            }
        }
         return bean;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;具體原理就是在 Bean 開始實例化之前記錄時間，在 Bean 初始化完成後記錄結束時間，打印實例化到初始化的時間差獲得 Bean 的加載總體耗時。結果如圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//28a73a7adfed28c5eff40855c8260121.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到有許多耗時在 10 秒以上的類，接下來可以針對性的做優化。值得注意的是，統計方式為單點耗時計算，未考慮依賴鏈上下文對整體加載順序的影響，實際優化還需結合依賴關係分析。&lt;/p&gt; 
&lt;h1&gt;五、singletonDataSource&lt;/h1&gt; 
&lt;pre&gt;&lt;code&gt;@Bean(name = "singletonDataSource")
public DataSource singletonDataSource(DefaultDataSourceWrapper dataSourceWrapper) throws SQLException {
    //先初始化連接
    dataSourceWrapper.getMaster().init();
    //構建分庫分表數據源
    String dataSource0 = "ds0";
    Map&amp;lt;String, DataSource&amp;gt; dataSourceMap = new HashMap&amp;lt;&amp;gt;();
    dataSourceMap.put(dataSource0, dataSourceWrapper.getMaster());
    //分庫分表數據源
    DataSource shardingDataSource = ShardingDataSourceFactory.createDataSource
    (dataSourceMap,shardingRuleConfiguration, prop);
    return shardingDataSource;    
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;singletonDataSource 是一個分庫分表的數據源，連接池採用的是 Druid，分庫分表組件採用的是公司內部優化後的中間件。通過簡單調試代碼發現，整個 Bean 耗時的過程發生在 createDataSource 方法，該方法中會調用 createMetaData 方法去獲取數據表的元數據，最終運行到 loadDefaultTables 方法。該方法如下圖，會遍歷數據庫中所有的表。因此數據庫中表越多，整體就越耗時。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//05283b802a6c9c0a6c8653f9a7f080cd.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;筆者的測試環境數據庫中有很多的分表，這些分表為了和線上保持一致，分表的數量都和線上是一樣的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//eee1a3f0f0dd73861b2894776a40850b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此在測試環境啓動時，為了加載這些分表會更加的耗時。可通過將分表數量配置化，使測試環境在不影響功能驗證的前提下減少分表數量，從而加快啓動速度。&lt;/p&gt; 
&lt;h1&gt;六、初始化異步&lt;/h1&gt; 
&lt;p&gt;activityServiceImpl 啓動中，主要會進行活動信息的查詢初始化，這是一個耗時的操作。類似同樣的操作在工程的其他類中也存在。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class ActivityServiceImpl implements ActivityService, InitializingBean{
     // 省略無關代碼
     @Override
     public void afterPropertiesSet() throws Exception {
        initActivity();
    }
     // 省略無關代碼
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以通過將 afterPropertiesSet() 異步化的方式加速項目的啓動。&lt;/p&gt; 
&lt;p&gt;觀察 Spring 源碼可以注意到 afterPropertiesSet 方法是在 AbstractAutowireCapableBeanFactory#&lt;/p&gt; 
&lt;p&gt;invokeInitMethods 中調用的。在這個方法中，不光處理了 afterPropertiesSet 方法，也處理了 init-method。&lt;/p&gt; 
&lt;p&gt;因此我們可以寫一個自己的 BeanFactory 繼承 AbstractAutowireCapableBeanFactory，將 invokeInitMethods 方法進行異步化重寫。考慮到 AbstractAutowireCapableBeanFactory 是個抽象類，有額外的抽象方法需要實現，因此繼承該抽象類的子類 DefaultListableBeanFactory。具體實現代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitListableBeanFactory extends DefaultListableBeanFactory{
     public AsyncInitBeanFactory(ConfigurableListableBeanFactory beanFactory){
         super(beanFactory);
    }
     @Override
     protected void invokeInitMethods(String beanName, Object bean, RootBeanDefinition mbd)throws Throwable {
        if (beanName.equals("activityServiceImpl")) {
            AsyncTaskExecutor.submitTask(() -&amp;gt; {
                try {
                      super.invokeInitMethods(beanName, bean, mbd);
                } catch (Throwable throwable) {
                    throwable.printStackTrace();
                }
            });
        } else {
              super.invokeInitMethods(beanName, bean, mbd);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;又因為 Spring 在 refreshContext() 方法之前的 prepareContext() 發放中針對 initialize 方法提供了接口擴展 (applyInitializers())。因此我們可以通過實現該接口並將我們的新的 BeanFactory 通過反射的方式更新到 Spring 的初始化流程之前。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public interface ApplicationContextInitializer&amp;lt;C extends ConfigurableApplicationContext&amp;gt; {
     /**
     * Initialize the given application context.
     * @param applicationContext the application to configure
     */
    void initialize(C applicationContext);

}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;改造後的代碼如下，新增 AsyncAccelerate-&lt;/p&gt; 
&lt;p&gt;Initializer 類實現 ApplicationContextInitializer 接口：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncBeanFactoryInitializer implements ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt; {
    @SneakyThrows
    @Override
    public void initialize(ConfigurableApplicationContext applicationContext){
        if (applicationContext instanceof GenericApplicationContext) {
            AsyncInitListableBeanFactory beanFactory = new AsyncInitListableBeanFactory(applicationContext.getBeanFactory());
            Field field = GenericApplicationContext.class.getDeclaredField("beanFactory");
            field.setAccessible(true);
            field.set(applicationContext, beanFactory);
        }
    }
}
public class AsyncBeanInitExecutor{
    private static final int CPU_COUNT = Runtime.getRuntime().availableProcessors();
    private static final AtomicReference&amp;lt;ThreadPoolExecutor&amp;gt; THREAD_POOL_REF = new AtomicReference&amp;lt;&amp;gt;();
    private static final List&amp;lt;Future&amp;lt;?&amp;gt;&amp;gt; FUTURES = new ArrayList&amp;lt;&amp;gt;();
     /**
      * 創建線程池實例
      */
     private static ThreadPoolExecutor createThreadPoolExecutor(){
         int poolSize = CPU_COUNT + 1;
         return new ThreadPoolExecutor(poolSize, poolSize, 50L, TimeUnit.SECONDS, new LinkedBlockingQueue&amp;lt;&amp;gt;(), new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }
    /**
     * 確保線程池已初始化（線程安全）
     */
     private static void ensureThreadPoolExists(){
         if (THREAD_POOL_REF.get() != null) {
              return;
        }
        ThreadPoolExecutor executor = createThreadPoolExecutor();
         if (!THREAD_POOL_REF.compareAndSet(null, executor)) {
            executor.shutdown(); // 另一線程已初始化成功
        }
    }
    /**
     * 提交異步初始化任務
     *
     * @param task 初始化任務
     * @return 提交後的 Future 對象
     */
    public static Future&amp;lt;?&amp;gt; submitInitTask(Runnable task) {
        ensureThreadPoolExists();
        Future&amp;lt;?&amp;gt; future = THREAD_POOL_REF.get().submit(task);
        FUTURES.add(future);
        return future;
    }
    /**
     * 等待所有初始化任務完成並釋放資源
     */
    public static void waitForInitTasks(){
        try {
            for (Future&amp;lt;?&amp;gt; future : FUTURES) {
                future.get();
            }
        } catch (Exception ex) {
            throw new RuntimeException("Async init task failed", ex);
        } finally {
            FUTURES.clear();
            shutdownThreadPool();
        }
    }
     /**
     * 關閉線程池並重置引用
     */
     private static void shutdownThreadPool(){
        ThreadPoolExecutor executor = THREAD_POOL_REF.getAndSet(null);
         if (executor != null) {
            executor.shutdown();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;實現類後，還需要在 META-INF/spring.factories 下新增説明 org.springframework.context.&lt;/p&gt; 
&lt;p&gt;ApplicationContextInitializer=com.xxx.AsyncAccelerateInitializer，這樣這個類才能真正生效。&lt;/p&gt; 
&lt;p&gt;這樣異步化以後還有一個點需要注意，如果該初始化方法執行耗時很長，那麼會存在 Spring 容器已經啓動完成，但是異步初始化任務沒執行完的情況，可能會導致空指針等異常。為了避免這種問題的發生，還要藉助於 Spring 容器啓動中 finishRefresh() 方法，監聽對應事件，確保異步任務執行完成之後，再啓動容器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitCompletionListener implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt;, ApplicationContextAware, PriorityOrdered{
    private ApplicationContext currentContext;
    @Override
    public void setApplicationContext(ApplicationContext applicationContext)throws BeansException {
         this.currentContext = applicationContext;
    }
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event){
        if (event.getApplicationContext() == currentContext) {
            AsyncBeanInitExecutor.waitForInitTasks();
        }
    }
    @Override
    public int getOrder(){
         return Ordered.HIGHEST_PRECEDENCE;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;七、總結&lt;/h1&gt; 
&lt;p&gt;啓動優化後的項目實際測試結果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2f535724d8b21204e9e881711c6acf6f.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過異步化初始化和分庫分表加載優化，項目啓動時間從 280 秒縮短至 159 秒，提升約 50%。這對於提升日常開發效率、加快測試與聯調流程具有重要意義。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18627678</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18627678</guid>
      <pubDate>Sun, 11 May 2025 09:43:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>數據「熵增」時代，AI 如何以標準重構治理秩序?</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;Agent 熱潮不減,但數據分析與治理狀況卻仍存在短板。據 Gartner 公司預測,到 2027 年,80% 的數據和分析治理舉措或將因各類原因而失效。如何在 AI 時代重塑數據治理體系,讓混亂數據重歸有序,成為企業智能轉型的關鍵命題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;近日,在 infoQ 舉辦的全球人工智能開發與應用大會上,瓴羊智能數據建設與治理產品 Dataphin 高級技術專家，周鑫，受邀出席,以&lt;strong&gt;「基於統一標準的智能數據治理&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;Dataphin&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;的落地實踐」&lt;/strong&gt;為主題,系統闡述了以數據標準為核心,實現可持續數據治理的方法論,以及以 AI 賦能自動化數據治理、重構複雜業務流程的實踐路徑。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;01&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;數據「&lt;/strong&gt;&lt;strong&gt;熵減」之道:基於統一標準,打造數據治理方法論&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「事物天生具有‘變混亂’的趨勢,數據也是如此。如何將無序變得有序?按照熱力學第二定律,需要從外界輸入能量,並且具備感知能力。」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示:「對於數據治理來説,能量就是治理工具,感知就是標準規範。」數據治理是實現數據世界的「熵減」,它可以通過&lt;strong&gt;現狀評估、制定目標、執行計劃、持續監測&lt;/strong&gt;四個治理階段,幫助數據生產者打破孤島,實現低成本數據開發,幫助數據管理者做好資產盤點,確保數據質量與安全,幫助數據使用者便捷用數,助力決策分析。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//5ca3fd8084d8b3ffa1e3874b915a46b8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;但在現實情況中,許多數據治理的結果通常會面臨失敗,周鑫將其歸結為四個原因:1) 治理動作分散,缺乏體系化方法論;2) 治理流程複雜,重度依賴人的能力和素質;3) 缺乏工具支撐,導致理論與實施脫節;4) 無法持續治理,治理策略難以快速調整。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c19a9aa3073e13c96e65f3ea454ed7c5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面對以上四類問題,Dataphin 提出了一套以數據標準為中心的數據治理方法論及產品化的落地。其核心邏輯為:&lt;strong&gt;聚焦&lt;/strong&gt;&lt;strong&gt;Data x AI&lt;/strong&gt;&lt;strong&gt;,用中台方法論構建統一的數據標準&lt;/strong&gt;,打造企業級好數據,幫助企業形成數據生產、數據消費、行業數據流通的數據要素服務鏈,驅動數據價值的釋放。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「方法論的核心關鍵,在於以數據標準為中心。數據標準貫穿數據整個生命週期,它讓數據治理具備核心抓手,不會漫無目的」,周鑫表示,&lt;strong&gt;企業需從核心業務入手,先行試點開展業務梳理與盤點工作,將相關統一納入&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;DataCatalog&lt;/strong&gt;&lt;strong&gt;,並在此過程中逐步形成對應的數據標準。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;標準梳理完成後,平台即可開展標準構建:通過統一的數據標準,自動實現質量監控與安全分類,保障開發過程規範,阻斷不規範數據開發。同時,統一標準可提升數據的可理解性與細節清晰度,實現數據從生成、開發到消費的全生命週期標準化管理。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a79214da341aeb304b867992344fd1c8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「整個治理鏈路就是以數據標準為中心,將傳統的複雜的治理手段,簡化成數據標準的梳理與治理效果的評估過程,數據符合標準的程度越高,整體數據質量也就越好」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,該方案以數據標準為核心,通過插件集成、API 註冊和準實時同步等多種方式採集元數據,並統一納入 DataCatalog,結合質量規則和安全策略進行自動識別與治理。這一方法論具備三大優勢:一是&lt;strong&gt;體系化&lt;/strong&gt;,明確治理目標與路徑;二是&lt;strong&gt;易落地&lt;/strong&gt;,藉助一體化工具和 AI 能力,貫穿數據全生命週期;三是&lt;strong&gt;可持續&lt;/strong&gt;,以標準驅動模式便於應對業務變化,有效降低治理成本與複雜度。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;02&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;語義知識&lt;/strong&gt;&lt;strong&gt;+&lt;/strong&gt;&lt;strong&gt;流程提效,智能&lt;/strong&gt;&lt;strong&gt;Agent&lt;/strong&gt;&lt;strong&gt;多場景賦能數據治理&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;許多企業在應用 Agent 時都難免遇到一個難題:Agent 雖然具備一定的智能和對話能力,但在複雜業務場景中常常「空轉」,無法真正理解業務語境、解決預期的實際問題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,造成這一現象的根本原因,「在於數據質量偏低或數字化基礎薄弱,導致 Agent 無法有效發揮價值,最終企業只能被迫放棄」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;AI 時代,優質數據至關重要,但「好數據」應如何獲取?AI 又該如何賦能數據治理?&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;首先,「Agent 在沒有豐富準確的語義知識下,不可能達到可生產使用的準確率」,周鑫認為,&lt;strong&gt;企業獲取好數據,需要構建準確且豐富的語義知識體系&lt;/strong&gt;。Dataphin 針對這一需求,打造了包含&lt;strong&gt;元數據&lt;/strong&gt;、&lt;strong&gt;數據標準&lt;/strong&gt;、&lt;strong&gt;數據模型&lt;/strong&gt;、&lt;strong&gt;業務知識&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;四大語義知識體系。企業可以通過採集豐富且統一的元數據,建立涵蓋碼錶、詞根、值域及安全分類分級的標準體系,依託 Dataphin 智能構建的概念模型、邏輯模型和物理模型,以及對業務詞條和邏輯的高效管理,實現對複雜業務知識的精準映射和應用。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e35e9b9658db17cdacdbbccf911c6633.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 為例,Dataphin 通過引入業務語義,不僅提升了問題泛化能力,還大幅提高了 SQL 匹配的準確率,顯著增強了對自然語言的理解能力。實測數據顯示,在 Dataphin 開放數據共享模型涵蓋的 45 個典型問題中,&lt;strong&gt;簡單問題的&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;strong&gt;準確率從&lt;/strong&gt;&lt;strong&gt;70%&lt;/strong&gt;&lt;strong&gt;提升至&lt;/strong&gt;&lt;strong&gt;80%&lt;/strong&gt;&lt;strong&gt;,而中等及複雜問題的準確率更是從&lt;/strong&gt;&lt;strong&gt;10%&lt;/strong&gt;&lt;strong&gt;躍升至&lt;/strong&gt;&lt;strong&gt;60%&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;其次,企業還需藉助 AI,對數據治理鏈路進行提效。基於 TaskWeaver 改造,Dataphin 構建了具備生產化能力的 Agent 框架,覆蓋研發、治理、資產問答等多個場景,顯著提升了現有流程效率,拓展了 Agent 的應用邊界。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 為例,系統可在識別信息不全時自動發起反問,補全後再繼續處理,確保複雜業務場景下依然具備高理解力與執行準確率。同時,Dataphin 的開放能力不斷演進,從傳統的 API 和數據服務擴展至 MCP 模式,支持更靈活的接入方式,適配非固定流程和動態交互等複雜需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;智能找表&lt;/strong&gt;場景,Dataphin 有效解決了用戶將複雜業務問題,轉化為準確搜索詞的難題。「引入 AI 後,你可以用業務的語言直接問,比如‘我要做客戶分層’,‘我要用哪張表’,AI 會用大模型去對業務問題進行拆解和泛化,最後找關聯到你已有的全域資產」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 5.png" height="366" src="https://oscimg.oschina.net/oscnet//44b7bd5fb943546e95785c6a26a72115.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;數據分析&lt;/strong&gt;場景,Dataphin 通過專輯機制與豐富的語義知識,解決了因語義知識的缺失或混亂,相似口徑和命名幹擾、以及海量表格帶來的找表難題,顯著提升了找表的效率與準確率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 6.png" height="366" src="https://oscimg.oschina.net/oscnet//5484c3d0938ae4172448aca47dd0d73a.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;數據治理&lt;/strong&gt;場景,Dataphin 通過「性別」等複雜字段特徵識別,解決了正則表達式「不會寫」、「看不懂」難題,取代了傳統人工探查的繁瑣過程,以往需要耗費十幾分鐘的特徵識別,如今只需幾十秒即可完成。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 7.png" height="460" src="https://oscimg.oschina.net/oscnet//5ada55aa58b287d443496c220aa124d5.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;數據管家&lt;/strong&gt;場景中,資產上架往往涉及表描述、字段註釋、目錄歸屬、標籤分類等複雜操作,尤其在字段數量眾多時,人工維護工作量大、耗時長且易出錯。通過引入 AI 能力,Dataphin 支持屬性信息的智能生成,可一鍵生成表/字段描述信息、目錄、標籤等,使人力成本與操作門檻大大降低。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 8.png" height="359" src="https://oscimg.oschina.net/oscnet//004299cfcc7d5766516ace7402af26ad.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;隨着 AI 對複雜節點的處理能力增強,Dataphin 正在以「智能工作台」有機整合獨立模塊,重構整體業務流程。 「有了 AI 之後,工作台模式可以讓很少的人,完成複雜的業務,每個環節都有大量 AI 和自動化能力支撐,人們乾的最多的事情是進行確認」,周鑫表示,未來,AI 還將在更多場景中深度參與,從輔助提效逐步向自動化、智能化方向邁進,推動企業實現數據治理範式的全面升級。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356211</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356211</guid>
      <pubDate>Sun, 11 May 2025 08:27:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Workout.cool —— 現代開源健身教練平台</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;一個全面的健身指導平台，可以為你制定鍛鍊計劃、跟蹤進度並訪問包含詳細説明和視頻演示的龐大鍛鍊數據庫。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;項目包含一個全面的練習數據庫。要導入練習樣本，請執行以下操作：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;導入的先決條件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;準備 CSV 文件&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你的 CSV 應該包含以下列：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以使用提供的示例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;導入命令&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Import exercises from a CSV file&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full /path/to/your/exercises.csv

&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Example with the provided sample data&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full ./data/sample-exercises.csv&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;CSV 格式示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,TYPE,STRENGTH
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,PRIMARY_MUSCLE,QUADRICEPS&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可用的屬性類型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRENGTH&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CARDIO&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;PLYOMETRICS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRETCHING&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRIMARY_MUSCLE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;QUADRICEPS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CHEST&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BACK&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;SHOULDERS&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SECONDARY_MUSCLE&lt;/strong&gt;: Secondary muscle groups targeted&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EQUIPMENT&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BARBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;DUMBBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BODYWEIGHT&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;MACHINE&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MECHANICS_TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;COMPOUND&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ISOLATION&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/workout-cool</link>
      <guid isPermaLink="false">https://www.oschina.net/p/workout-cool</guid>
      <pubDate>Sun, 11 May 2025 08:20:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenBMB 開源輕量級 CUDA 推理框架 CPM.cu</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 推出了 CPM.cu，這是一個輕量級且高效的開源 CUDA 推理框架，專為端側大型語言模型（LLMs）的部署而設計，併為&lt;a href="https://www.oschina.net/news/354328"&gt;MiniCPM4&lt;/a&gt;提供優化，核心支持&lt;strong&gt;稀疏架構&lt;/strong&gt;、&lt;strong&gt;投機採樣&lt;/strong&gt;和&lt;strong&gt;低位寬量化&lt;/strong&gt;等前沿技術創新。&lt;/p&gt; 
&lt;p&gt;CPM.cu 亮點包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集成了 InfLLM v2 可訓練稀疏注意力內核，可加速長上下文預填充和解碼；&lt;/li&gt; 
 &lt;li&gt;FR-Spec（頻率排序推測採樣）通過壓縮詞彙空間提高草稿效率，顯著降低計算開銷；&lt;/li&gt; 
 &lt;li&gt;結合了 EAGLE-2 推測採樣、4 位量化和基於滑動窗口注意力的長上下文支持，從而在資源受限設備上實現高效部署。&lt;/li&gt; 
 &lt;li&gt;性能方面，在 128K-token 序列上，預填充速度比 Qwen3-8B 快 2-4 倍，解碼速度快 4-6 倍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CPM.cu&amp;nbsp; 框架結構：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CPM.cu/
├── src/
│   ├── flash_attn/ # 修改後的 Flash-Attention, 支持稀疏和投機採樣
│   ├── model/
│   │   ├── minicpm4/ # minicpm4 模型
│   │   │   ├── minicpm4_model.cuh # 模型的核心實現
│   │   │   └── minicpm4_eagle.cuh # 投機採樣實現
│   │   ├── model.cuh # 其他代表性模型
│   │   ├── w4a16_gptq_marlin/ # GPTQ 量化計算 kernel
│   │   ├── memory.cuh # 顯存分配
│   │   └── layer.cuh # 通用層
│   ├── entry.cu # pybind: 連接 C/CUDA 和 Python
│   └── ...
├── cpmcu/ # python interface
└── ...&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;cpmcu/ 代碼提供了一個 python 的調用接口，裏面涉及在 Python 側 tokenize，調用 C 代碼得到模型的輸出 logits，在 Python 側根據 logits 採樣並 detokenize 這些過程。我們使用了 pybind 將 C 代碼與 Python 代碼進行綁定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/memory.cuh 這裏實現了整個推理框架的內存管理，這裏我們採用了先分配模型權重，再分配模型中間計算結果所需的空間，最後把所有剩餘顯存分配給 kv-cache 的內存管理策略。這一點設計上是和 vLLM, SGLang 類似的。分配中間計算結果的空間時可以考慮一下中間計算結果的生命週期，做一點顯存複用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/w4a16_gptq_marlin/ 量化的計算 kernel。這裏直接使用了 vLLM 的 Marlin 代碼。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/minicpm4/ 這裏是模型的架構實現。src/model/下也有其他代表性模型實現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/flash_attn/ 我們基於 flash_attn 2.6.3 版本，在上面增加了對 InfLLM v2、投機採樣的適配支持。下面我們主要介紹這一部分，也是整個框架實現的難點。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FCPM.cu" target="_blank"&gt;https://github.com/OpenBMB/CPM.cu&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356197</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356197</guid>
      <pubDate>Sun, 11 May 2025 07:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源模型上下文協議 MCP 更新規範文檔，添加對結構化工具輸出的支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源模型上下文協議 MCP 昨天更新了規範文檔，主要變更如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;移除對 JSON-RPC 批處理的支持（PR #416）&lt;/li&gt; 
 &lt;li&gt;添加對結構化工具輸出的支持（PR #371）&lt;/li&gt; 
 &lt;li&gt;將 MCP 服務器歸類為 OAuth 資源服務器，添加受保護資源元數據以發現相應的授權服務器。（PR #338）&lt;/li&gt; 
 &lt;li&gt;要求 MCP 客戶端按照 RFC 8707 中描述的方式實現資源指示器，以防止惡意服務器獲取訪問令牌。（PR #734）&lt;/li&gt; 
 &lt;li&gt;在授權規範中闡明安全注意事項和最佳實踐，並在新的安全最佳實踐頁面中説明。&lt;/li&gt; 
 &lt;li&gt;增加引導支持，使服務器能夠在交互過程中向用戶請求更多信息。（PR #382）&lt;/li&gt; 
 &lt;li&gt;在工具調用結果中增加資源鏈接支持。（PR #603）&lt;/li&gt; 
 &lt;li&gt;在使用 HTTP 時，後續請求中需通過&amp;nbsp;&lt;code&gt;MCP-Protocol-Version&lt;/code&gt;&amp;nbsp;頭指定協商的協議版本。（PR #548）&lt;/li&gt; 
 &lt;li&gt;將生命週期操作中的 SHOULD 改為 MUST&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fspecification%2F2025-06-18%2Fchangelog" target="_blank"&gt;https://modelcontextprotocol.io/specification/2025-06-18/changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356195</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356195</guid>
      <pubDate>Sun, 11 May 2025 07:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源代碼編輯器 Zed 上線「調試器」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源代碼編輯器 Zed &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fdebugger" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出「調試器（Debugger）」功能，稱這是向 Zed 1.0 邁出的重要一步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;調試器特性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;快速&lt;/strong&gt; ：減少上下文切換時間，讓用戶能更專注於調試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;熟悉&lt;/strong&gt; ：與 Zed 的設計語言保持一致，支持典型的調試流程，方便用戶快速上手。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可配置&lt;/strong&gt; ：用戶可自定義 UI、鍵綁定、調試配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-43c899b5d73c5470109aecf601bbff05ba7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Zed 開箱即支持調試多種流行編程語言，包括 Rust、C/C++、JavaScript、Go 和 Python。通過擴展系統，Zed 可以支持任何實現調試適配器協議（DAP）的調試適配器。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;技術架構&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   採用兩層架構，數據層與調試適配器直接通信，UI 層從數據層獲取數據進行界面渲染。
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   數據層負責維護會話狀態、緩存響應、使失效數據，UI 層按需請求數據，避免不必要的請求，便於後續實現協作調試。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;調試適配器集成&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   擴展了 Zed 的擴展 API 以支持調試器集成，通過定義自定義架構等方式，讓擴展作者能輕鬆將調試適配器集成到 Zed 中。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;內聯變量值實現&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   利用 Tree-sitter 查詢準確識別當前執行範圍內的變量，無需依賴 LSP 服務器與調試適配器的緊密集成，目前支持 Python、Rust、Go 等語言。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fdocs%2Fdebugger" target="_blank"&gt;https://zed.dev/docs/debugger&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356190/zed-debugger</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356190/zed-debugger</guid>
      <pubDate>Sun, 11 May 2025 06:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 Rust 瀏覽器引擎 Servo 支持 GIF</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Servo 是一款開源的瀏覽器引擎，最初由 Mozilla 開發。它使用 Rust 語言編寫，旨在提供高效、安全的網頁渲染能力，並且採用並行渲染技術，以提高網頁加載速度和性能。&lt;/p&gt; 
&lt;p&gt;近日，Servo 團隊介紹了最近的更新內容，其中一項重要新功能是&lt;strong&gt;支持顯示動態 GIF&lt;/strong&gt;，並且還可以通過 HTML "img"標籤加載 SVG 圖像。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/142856_yG2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 還在推進其 Trusted Types API、輸入類型 &amp;lt;input type=color&amp;gt; 支持、更好的佈局和 CSS 支持，以及支持各種其他 API 和功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f8cd0cc574887e5f2e0cc055fb9586cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 還在繼續努力提升圍繞 Servo 嵌入支持的開發者體驗，以 Servo 作為 Chromium 的 CEF 替代方案在應用程序中利用 Servo。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2025%2F06%2F18%2Fthis-month-in-servo%2F" target="_blank"&gt;https://servo.org/blog/2025/06/18/this-month-in-servo/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</guid>
      <pubDate>Sun, 11 May 2025 06:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美國科技巨頭推動聯邦立法，禁止各州單獨監管 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《金融時報》報道稱，近日美國多家大型科技公司正積極推動一項聯邦禁令，旨在禁止各州自行制定人工智能（AI）監管法規。此次立法倡議得到了亞馬遜、谷歌、微軟和 Meta 等公司的支持，目的是避免各州在 AI 監管方面各自為政，影響行業的整體發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士透露，這項禁令提案已經被納入眾議院版本的 「大而美」 預算法案中。參議院也計劃在近期推出自己的版本，並希望能夠在 7 月 4 日之前完成相關立法工作。前聯邦眾議員、現任 INCOMPAS 首席執行官 Chip Pickering 是這項提案的重要推動者，他表示，保持美國在技術領域的領導地位是確保國家競爭力的關鍵。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;INCOMPAS 組織於 2024 年成立了 「人工智能競爭中心」（AICC），專注於遊説國會與監管機構，以適應快速發展的 AI 行業。隨着 AI 監管討論的加劇，尤其是在歐盟出台新規後，亞馬遜和 Meta 也加入了該組織，試圖通過統一監管來增強競爭力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，此提案引發了廣泛的爭議。反對者認為，大型科技公司推動禁令的真正目的是為了鞏固自身在 AGI（通用人工智能）競爭中的壟斷地位。範德比爾特大學的政策加速中心 AI 與科技政策主任 Asad Ramzanali 表示，負責任的創新不應該懼怕法律的約束。同時，麻省理工學院的教授 Max Tegmark 也批評稱，這種行為是科技巨頭為了進一步集中財富和權力的擴張。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，支持禁令的人士認為，聯邦層面的統一監管將有助於避免各州的分歧，保持行業的創新能力，從而在全球 AI 競爭中處於有利地位。AI 安全倡導者如 Anthropic 聯合創始人 Dario Amodei 則警告稱，如果完全依賴企業自我監管，可能會帶來嚴重的社會風險。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356176</guid>
      <pubDate>Sun, 11 May 2025 06:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度垂搜數據管理系統彈性調度優化實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;百度垂直搜索系統將搜索核心能力賦能阿拉丁（百度搜索特型結果）、垂直領域搜索、應用內搜索等場景，支撐了數百個檢索場景、百億級內容數據的檢索。隨着接入業務數量和數據量不斷增長，系統在海量數據管理與調度上遭遇新的挑戰，通過垂搜數據管理系統彈性調度優化實踐來滿足業務增長需求。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 簡介&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;百度垂搜架構的召回引擎經過歷史架構演進確定了&lt;strong&gt;&lt;strong&gt;異構&lt;/strong&gt;&lt;/strong&gt;部署的架構模型，相較於同構部署在容量自動調整、數據按需存儲等方面更具效率與成本的優勢，同時在海量數據和海量檢索方面也實現了高可用和高性能。目前系統已承接 80+業務，全機房部署了數百個檢索服務，數千個索引庫，共計數百億文檔收錄。隨着接入新業務數量的增加，以及存量業務的深入迭代，我們遇到了更加複雜多樣的場景，進而對系統提出更高的要求。本文主要介紹我們的系統在海量數據管理與調度上面臨的問題， 以及各項優化工作落地後在系統擴展性、穩定性等方面取得的效果。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&amp;nbsp;當前數據管理架構存在的問題&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此前我們的系統設計了彈性伸縮機制應對流量和數據量的上漲，冷熱分離機制實現了資源按需部署。隨着接入業務的增加，系統逐漸暴露出一些新的問題，主要體現在以下幾點:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;元信息管理瓶頸。系統使用 ETCD 進行服務發現和心跳管理， 然而所有業務實例&lt;strong&gt;&lt;strong&gt;直連 ETCD&lt;/strong&gt;&lt;/strong&gt;存在嚴重讀寫放大問題， 導致 ETCD 負載超發出現&lt;strong&gt;&lt;strong&gt;單點瓶頸&lt;/strong&gt;&lt;/strong&gt;, 限制集羣規模進一步增長。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依靠人工評估資源。新業務的接入或者一些大事件運營保障依賴人工估算所需資源，&lt;strong&gt;&lt;strong&gt;不僅耗費人力，而且不夠準確&lt;/strong&gt;&lt;/strong&gt;，估算過高，服務長期處於低負載會造成資源浪費，估算過低，服務容易過載，進而導致穩定性問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據量增長瓶頸。 當前的架構可以在無需重新建庫的情況下原地擴分片，但是分片數只能倍數擴展，並且&lt;strong&gt;&lt;strong&gt;分片數量有限制&lt;/strong&gt;&lt;/strong&gt;，大庫場景容易觸發上限，進而導致數據量無法繼續增長。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;02 檢索系統與數據管理系統架構&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1&amp;nbsp;檢索系統架構概覽&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先簡單介紹下垂搜檢索系統的各模塊，如下圖所示:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6fa6c464ffb4e6ea05cb47989be85fcbaf.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;RANK。檢索精排模塊，負責 query 理解、請求構造、多隊列拆分、正排數據獲取、策略因子計算、算分排序、返回結果組裝等流程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS。檢索召回引擎，負責基礎召回/粗排，根據基礎相關性等權重因子進行數據的粗篩，支持基於 term 倒排拉鍊和 ANN 向量基礎召回。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BUILD。數據建庫模塊，負責數據處理、切詞、生成正排/倒排/向量/摘要等功能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;每個垂類 (業務) 擁有一套獨立的上述檢索系統服務，數據管理系統為每個業務的檢索系統提供&lt;strong&gt;&lt;strong&gt;實例調度、容量管理、服務發現、心跳管理、路由控制&lt;/strong&gt;&lt;/strong&gt;等能力，數據管理系統面向的核心管理對象是召回引擎 (BS)。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1&amp;nbsp;垂搜召回引擎&lt;/h3&gt; 
&lt;p&gt;如下圖所示，百度垂搜的召回引擎是一個&lt;strong&gt;&lt;strong&gt;流式、多分片、異構、有狀態的倒排+向量&lt;/strong&gt;&lt;/strong&gt;索引引擎:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6a59f451eae4330c4d002228c9ca5d20b51.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;流式。業務經過離線建庫環節產出建庫包並生效到 Kafka 中，召回引擎再從 Kafka 消費，數據從建庫到檢索可實現&lt;strong&gt;&lt;strong&gt;秒級生效&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多分片。業務數據量超過單機存儲上限，會被拆分成多個分片 (slice)，每個分片由 PaaS 層面實例承載，並對應 Kafka 的一段 partition 區間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;異構。單個業務的若干個資源號 (resource) 之間支持獨佔或者混部，一般根據服務負載設置不同副本數，根據數據量設置不同分片數。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;有狀態。每個實例承載一個或多個分片數據，週期性彙報心跳，消費分片由中控服務統一調度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;名詞解釋:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;resource(資源號): 一類或者一個場景的數據集合，即一個&lt;strong&gt;&lt;strong&gt;索引庫&lt;/strong&gt;&lt;/strong&gt;，一個業務通常包含多個資源號 (如圖中 mobile_game，pc_game， game_video 等)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slice(分片):數據調度基本單位，一個 resource 根據數據量可能會拆分成多個 slice(mobile_game 有三個 slice, pc_game 和 game_video1 個)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slot:數據劃分的基本單位，一個 slice 下有若干個 slot， 與 Kafka 的 partition 一一對應，在業務接入時根據數據量級確定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;pod:PaaS 層面實際的物理存儲容器，一個 pod 會承載一個或多個 slice，由中控服務統一調度。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&amp;nbsp;動態化數據管理系統&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;動態化數據管理系統負責召回引擎的每個實例從建庫到檢索，從部署到下線的全生命週期管理。經過&lt;strong&gt;&lt;strong&gt;服務重構、架構升級、新功能建設&lt;/strong&gt;&lt;/strong&gt;等方面的優化工作，形成了包括中控服務，心跳服務 (HeartbeatService), 名字服務 (NamingService), 存儲 ETCD 等模塊的現有系統架構:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-da1b5525954986be5194f44d536e0d8d45b.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1&amp;nbsp;中控服務&lt;/h3&gt; 
&lt;p&gt;整個動態化數據管理系統的核心模塊，負責各類調度任務的發起、控制等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;資源號接入/下線。新增資源號 (索引庫)，為每個資源號根據副本數、資源號之間部署關係等調度實例；下線資源號， 對應資源號的數據發起清理以及實例回收。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;副本保活。每個資源號實際副本數可能由於擴縮副本或 PaaS 層面遷移，導致與目標副本數不一致，中控服務負責定期輪訓所有資源號 (分片)，維持副本數與目標一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;容量管理。自動擴縮容服務/人工基於負載調整資源號的副本數，並通過副本保活生效，基於數據量調整資源號分片數，通過任務控制器生效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可用度控制。上線重啓需要保證分片維度的可用度，變更由 PaaS 發起，每個實例重啓前需要請求中控服務的探針，中控服務根據當前分片可用度決定實例是否可以重啓。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2&amp;nbsp;名字服務 NamingService&lt;/h3&gt; 
&lt;p&gt;提供服務發現，實例屏蔽，建庫路由控制等能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;服務發現。週期性加載並更新全量業務的資源號檢索路由拓撲信息，對每個分片過濾心跳丟失、未消費完成、重啓中等暫不可用實例。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實例屏蔽。支持異常實例的分片維度/App 維度屏蔽，線上快速止損，並保留現場便於後續問題追查。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建庫路由控制。提供離線建庫側全量業務資源號與 Kafka partition 映射關係查詢，資源號倒排索引雙寫控制。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.3&amp;nbsp;心跳服務 HeartbeatService&lt;/h3&gt; 
&lt;p&gt;負責召回引擎 (BS) 實例、分片心跳信息收集並持久化，實例消費區間信息傳遞等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;心跳管理。收集召回引擎實例上報的心跳信息，包括實例自身心跳以及消費分片信息， 並將心跳信息聚合後寫入 ETCD。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實例調度信息傳遞。獲取由中控調度下發的最新消費分片信息，寫入心跳請求 response，實例感知到消費分片發生變化後，清理舊分片數據，並重新消費新分片數據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.4&amp;nbsp;存儲 ETCD&lt;/h3&gt; 
&lt;p&gt;動態化數據管理系統各類元信息持久化存儲:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;實例心跳信息。包括版本號，實例唯一標識，上報時間戳，消費分片等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分片路由拓撲信息。分片下全量副本狀態信息，包括 endpoint，snapshot 版本，上報時間戳，消費狀態等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;業務資源號拓撲信息、建庫路由信息。單業務視角下全量資源號信息，包括版本號，分片數，副本數，對應 Kafka partition 區間，rpc 參數配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;03 彈性調度機制優化實踐&lt;/h1&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1&amp;nbsp;服務發現、心跳管理模塊重構&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.1&amp;nbsp;原有架構&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f12910e29c40a1a821609e09c774e7296d.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到在原有架構，業務 RANK 和 BS 實例都是直連 ETCD，隨着業務接入數量的增加逐漸暴露出一些問題:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;讀流量放大。同業務的不同 RANK 實例會各自訪問 ETCD 獲取相同的路由拓撲，導致讀流量放大，對於 RANK 實例數多的業務放大現象愈發明顯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;寫流量放大。每個分片含有多個副本，在進行更新時，一輪週期內同一個分片會被寫入多次，導致寫流量放大，對於副本數多的分片寫競爭愈發激烈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;升級改造困難。路由篩選策略、心跳上報策略均內嵌在 sched-lib 中, 進行升級需要給每個業務 RANK/BS 上線，人力成本巨大。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為瞭解決上述問題，我們對心跳管理和服務發現模塊進行了微服務拆分，新增心跳服務 (以下簡稱 HS) 和名字服務 (以下簡稱 NS) 避免了業務實例直連 ETCD，同時引入了 Prometheus，對心跳上報狀態和路由獲取狀態等信息進行監控和可視化展示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bb9efb9826cf2b2ebe1bae522ce0df14546.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.2&amp;nbsp;NS(NamingService) 設計&lt;/h3&gt; 
&lt;p&gt;我們對 NS 的定位是作為 ETCD 的 cache，採用 Read-Through 的模式，對全量業務的 RANK 提供拓撲信息查詢，RANK 不再直接訪問 ETCD:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;NS 本身設計為一個&lt;strong&gt;&lt;strong&gt;無狀態服務&lt;/strong&gt;&lt;/strong&gt;， RANK 可以訪問任意一台 NS 獲取拓撲，NS 實例之間拓撲路由&lt;strong&gt;&lt;strong&gt;保證最終一致性&lt;/strong&gt;&lt;/strong&gt;，NS 在拓撲變更時返回拓撲信息+MD5(拓撲)+更新時間戳，未變更時僅返回 MD5 和時間戳， RANK 基於 MD5 和時間戳自行判斷是否需要更新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;拓撲更新策略下沉到 NS 中，RANK 獲取到的拓撲即為直接可用拓撲，針對不同業務提供不同的控制策略並且後續升級改造只需上線 NS，成本大幅降低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;單機房 3 台 NS 實例即可支撐全部業務拓撲查詢，重構前後 ETCD 讀流量比例為 M:3，M 為平均每個業務 RANK 實例數，假設 N 取 30，則讀流量下降 90%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-93ea29c3774379e1a2cabf37f1ed095a248.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.3&amp;nbsp;HS(HeartbeatService) 設計&lt;/h3&gt; 
&lt;p&gt;HS 負責收集 BS 實例本身的心跳以及實例消費的分片的心跳，週期性&lt;strong&gt;&lt;strong&gt;聚合寫入&lt;/strong&gt;&lt;/strong&gt;ETCD，並且向 BS 實例返回其最新的消費分片信息:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;HS 採用無主節點設計，也支持任意水平擴展。同一個業務的不同 BS 實例通過&lt;strong&gt;&lt;strong&gt;一致性 hash&lt;/strong&gt;&lt;/strong&gt;方式請求同一台 HS 實例, 便於 HS 進行分片維度的信息聚合，這樣在大部分時間，每個分片無論有多少個副本一個週期內只會被寫入一次，實例本身的心跳採用批量更新形式，寫競爭大幅降低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 在上報心跳的同時會從 HS 的 response 中獲取自身消費的最新分片信息，如果分片信息變化，則清理老分片數據，消費新分片數據，後續只上報新分片狀態信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;單機房 3 台 NS 實例即可支撐全部業務心跳更新，重構前後 ETCD 寫流量比例為 N:1，N 為平均每個分片副本數，假設 N 取 5，則寫流量下降 80%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f141ad59566f2bbe45c04a1a0dac2046805.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_17"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;自動擴縮容&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1&amp;nbsp;當前現狀&lt;/h3&gt; 
&lt;p&gt;BS 是一個&lt;strong&gt;&lt;strong&gt;多分片、異構&lt;/strong&gt;&lt;/strong&gt;服務，即每個 App 內通常部署了多個資源號，各業務 App 在 PasS 層面隔離部署，在資源利用率、擴縮容管理等方面我們遇到以下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;整體資源利用率低。全機房擁有上百個 BS 業務 App、上千個資源號，PaaS 層面的整體平均峯值 CPU 利用率低於平均水平，峯值 CPU 超過 70% 的資源號佔比不足 20%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依賴人工進行資源號副本數調整。一般上線前通過人工壓測評估放量後所需的資源然後進行申請，有時候通過壓測難以估算真實的資源，並且後續業務迭代或者流量變化也會引起資源使用的變化，如果負載超發，服務穩定性難以保障，如果負載太過空閒，也會造成資源浪費。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無法直接接入 PaaS 層面自動擴縮容能力。一方面 PaaS 無法感知每個 App 內資源號維度負載信息，另一方面每個實例承載分片信息只能由中控服務調度，因此無法直接服用 PaaS 層面自動擴縮容能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-05f53f5b84434e08c78529d148cd54a6dcb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2&amp;nbsp;自動擴縮容實現&lt;/h3&gt; 
&lt;p&gt;為了實現容量自適應調整，我們開發了一個自動擴縮容服務，對全量資源號進行容量管理。自動擴縮容服務週期性計算資源號維度負載，根據負載情況，觸發中控服務進行資源號副本數調整，或者 PaaS 層面實例數調整。對於擴容，優先調度存量資源池中實例，如果存量實例不足則觸發 PaaS 擴容；對於縮容，先將空閒副本數回收至空閒資源池，再觸發 PaaS 縮容。對於自動擴縮容服務的設計我們主要考慮了以下幾點:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-53d9ad28a3b34ec0ecb4706a0bc8f9316eb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;負載指標選取&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;垂搜系統大部分業務 BS 為純內存版本，且幾乎沒有下游網絡請求，屬於典型的計算密集型業務， 因此我們選擇 CPU 作為負載計算參考指標，另外資源號混部場景進一步結合 QPS 和 Latency 進行判斷。此前我們已經實現了基於 Prometheus 採集實分片維度 CPU、MEM、QPS、Latency、建庫數據量等指標全量業務覆蓋，因此可以低成本的獲取到全量&lt;strong&gt;&lt;strong&gt;資源號維度&lt;/strong&gt;&lt;/strong&gt;的負載數據。&lt;/p&gt; 
&lt;span id="OSC_h4_21"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;負載狀態流轉&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;每個資源號從擴容到縮容，共定義如下 7 種狀態：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;enum LoadStatus { LOAD_STATUS_LOAD_OK = 0; //正常負載 LOAD_STATUS_OVERLOAD = 1; //超負載 LOAD_STATUS_IDLELOAD = 2; //低負載 LOAD_STATUS_BS_ADD_REPLICA = 3; //bs 擴副本中 LOAD_STATUS_BS_REMOVE_REPLICA = 4; // bs 縮副本中 LOAD_STATUS_TRIGGER_PAAS_EXPENSION = 5; // PaaS 擴容中 LOAD_STATUS_TRIGGER_PAAS_SHRINK = 6; // PaaS 縮容中 }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;每個資源號根據負載情況在上述狀態之間流轉:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8fa2f7581ed63466a8f24640ad7258bba52.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_22"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;擴縮容執行流程&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;擴副本&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;優先調度 App 內空閒實例，不足則觸發 PaaS 層面實例數擴容，循環執行直到負載恢復正常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-edfbd8b326a5709833d414a5fb013f357ed.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;縮容&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;先將資源號多餘副本釋放為空閒實例，再觸發 PaaS 層面縮容，循環執行直到資源號負載以及空閒實例數回到正常水平。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-504ce96574f2dc384b323509ab32bd78022.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3&amp;nbsp;&lt;strong&gt;資源號擴分片進階&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;每個資源號隨着數據量級不斷增長，分片數也需要動態擴展，否則會出現分片內存超發的情況。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.1&amp;nbsp;&lt;strong&gt;當前擴分片方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;每個資源號按 resource-&amp;gt;slice-&amp;gt;slot 的層級劃分，slot 是數據劃分最小單位與 kafka partion 一一對應，在業務接入時每個資源號 slot(partion) 的數量已經確定。擴層時，資源號的 slot 數量不變，&lt;strong&gt;&lt;strong&gt;分片數變成原來 2 倍， 每個分片的 slot 數則為原來的 1/2&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8db852d84d0b6a8d63c9bac9fed576d9490.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;原有的擴分片方案可以在無需重新建庫的情況下實現業務無感的原地分片擴縮操作，然而依舊存在兩個問題:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;分片數按指數增長，當分片數超過一定數值，將帶來不容忽視的資源成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果初始分配 slot 數太少，當 slice:slot=1:1 時，無法再擴層，數據增長出現瓶頸。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.2&amp;nbsp;&lt;strong&gt;進階擴展方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;對於分片無法繼續擴展但是依舊需要繼續建庫的情況，先前的方案只能是重建一個新的資源號，需要業務、架構共同介入，歷史上我們使用原方案遷移一個資源號，前後&lt;strong&gt;&lt;strong&gt;投入近 3 周時間&lt;/strong&gt;&lt;/strong&gt;，耗費成本巨大，因此我們需要一個成本更低的方案。通過分析，當前分片的擴展瓶頸主要有以下三個限制條件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;每個資源號的 slots 是一段連續的區間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 的 slot 與 Kafka 的 partition 一一對應。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始分配 slot 數太少，且後續不支持調整。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;只需要打破其中任意一個條件，則可以消除瓶頸。綜合考慮改造成本、擴展靈活性、實現難度等因素，我們選擇從條件三入手，在新的 partition 區間重建分片，分片數和 slot 數根據數據量設置，將舊分片的數據全量複製到新的分片上，再將新分片替換舊分片，如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1534a9d4b6b75072160e0a0470563a1c8c8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_26"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;整體實現&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;對於一個流式建庫系統，業務可能時刻都在進行數據建庫，我們希望做到遷移過程中業務依舊可以持續建庫，並且保證數據不丟失、時序不錯亂。我們的方案是將數據分為存量數據 (老分片中的全量數據) 和增量數據 (實時寫入的新數據)，對於增量數據可以通過雙寫機制，同時寫入新舊分片，存量數據則通過構建 snapshot 的方法遷移至新分片，新分片數據 ready 後，再由服務發現層將檢索流量切換至新分片，整體流程如下:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;離線側開啓雙寫，保證增量倒排索引數據同時寫入新舊分片，正排和摘要部分數據無需變化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基於舊分片構建新分片 snapshot, 並記錄構建時間點。將該時間點前舊分片所有數據進行 resharding 構建新分片 snapshot。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新分片的 BS 實例加載構建好的 snapshot，然後每個 partition 的消費 offset&lt;strong&gt;&lt;strong&gt;回退到 snapshot 構建時間點開始重新消費&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;服務發現層將資源號到 slot 區間映射切換到新分片上，檢索流量從老分片遷移至新分片。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;將舊分片 BS 實例回收，並關閉雙寫。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2cc22fbbf1492e639ef2bf5cbd76b4f8c3a.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_27"&gt;&lt;/span&gt; 
&lt;h1&gt;04 總結與展望&lt;/h1&gt; 
&lt;span id="OSC_h2_28"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1&amp;nbsp;&lt;strong&gt;總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本文介紹了百度垂搜檢索數據管理架構在彈性機制建設上的一系列優化工作，並且在擴展性、穩定性、以及成本效率等方面均取得了預期成果:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;擴展性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 負載下降一個量級，單機房 BS、RANK 集羣規模提升兩個量級， 單分片副本數上限提升至 5000+。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;分片擴展數量不再受限，解決了部分存量業務無法擴展分片導致的內存超發問題，並支持搜索創新業務數據量從百萬級逐步增加至數十億量級。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;穩定性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;存量調度問題被修復，新增多種路由調度策略以應對不同場景，分片可用度不足幹預時間從小時級縮短至分鐘級。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 負載不再超發，慢查詢基本消失，穩定性風險基本消除，心跳上報、拓撲獲取狀態建立監控，異常情況及時感知。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成本效率&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;全機房 BS 接入自動擴縮容，實現容量自適應調整，整體峯值 CPU 利用率提升了 15%+，同時相比之前減少了 80% 人工介入容量調整的情況出現。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;部分業務通過分片合併，最終使用存儲資源為下降至原來的 20%，並且檢索 97 分位耗時降低了 20ms，業務側效果與先前打平。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_29"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2&amp;nbsp;&lt;strong&gt;展望&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;目前索引庫的自動擴縮容機制實現了副本數隨負載 (CPU) 的自動調整，後續將實現分片數隨數據量的自動調整。另外，在大庫場景將持續建設流批一體機制，以追求用更低的存儲成本實現更高的檢索性能。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18627327</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18627327</guid>
      <pubDate>Sun, 11 May 2025 03:11:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Sam Altman 透露將在今年夏季發佈 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 發佈了其聯合創始人兼首席執行官 Sam Altman 的 40 分鐘深度專訪。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/105636_pUBl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1935357512011890815" target="_blank"&gt;透露&lt;/a&gt;&lt;/u&gt;，備受矚目的 GPT-5 預計將於今年夏天推出，不過具體發佈日期尚未確定。&lt;/p&gt; 
&lt;p&gt;據報道，GPT-5 性能將遠超 GPT-4，測試者表示其在多方面有顯著進步。據悉，這款新模型將整合 OpenAI 的核心技術，融合 GPT-4o 自然語言處理的靈活性與 o3 在代碼及科學推理方面的優勢，打造更強大的統一系統。&lt;/p&gt; 
&lt;p&gt;Altman 暗示，GPT-5 或許不僅是性能上的升級，更可能是 OpenAI 邁向統一、類似代理模型的重要一步，使其向人工通用智能（AGI）目標更進一步。&lt;/p&gt; 
&lt;p&gt;此外，據 AI 工程師 Tibor Blaho 和投資者「Chris（chatgpt21）」消息透露，OpenAI 或將在 7 月發佈一個大規模模型，而該模型有望為 GPT-5。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/354761" target="news"&gt;OpenAI 推遲開源模型的發佈時間&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356142</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356142</guid>
      <pubDate>Sun, 11 May 2025 02:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 終止與 Scale AI 合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 發言人當地時間週三向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-18%2Fopenai-is-phasing-out-its-work-with-scale-ai-after-meta-deal" target="_blank"&gt;彭博社&lt;/a&gt;透露，在 Meta 與 Scale AI 達成交易後，OpenAI 將逐步停止與 Scale AI 的合作，並切斷與該數據供應商的聯繫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 表示，早在 Meta 上週宣佈向這家初創公司投資數十億美元並任命 Alexandr Wang 擔任首席執行官之前，該公司就已開始逐步結束與 Scale AI 的合作。OpenAI 一直在尋找其他供應商來獲取更專業的數據，以開發日益先進的 AI 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="336" src="https://oscimg.oschina.net/oscnet/up-77faf9c892257b37289b5ccb5a6d4304d54.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 斷絕關係的決定引發了人們對 Scale AI 核心數據標籤業務的質疑。上週，路透社報道稱，谷歌也在討論放棄 Scale AI 作為數據提供商的計劃。隨着 Meta 與 Scale AI 達成合作，Scale AI 的一些競爭對手錶示，他們收到了大量尋求「中立」合作伙伴的 AI 模型供應商的興趣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在週三發佈的一篇博客文章中，Scale AI 的總法律顧問試圖駁斥 Meta 將在此次交易後獲得優待的説法。Scale AI 的高管表示，公司不會與 Meta 分享其他客戶的機密信息，並且新任首席執行官 Wang 不會直接參與公司的日常運營。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在週三發佈的另一篇博客文章中，Scale AI 的臨時首席執行官 Jason Droege 則表示，公司將「加倍投入」其應用程序業務，其中包括為政府和企業構建定製的 AI 應用程序。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</guid>
      <pubDate>Sun, 11 May 2025 02:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Midjourney 發佈首個 AI 視頻生成模型 V1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 初創公司 Midjourney &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1935377193733079452" target="_blank"&gt;宣佈&lt;/a&gt;推出其備受期待的首款 AI 視頻生成模型 V1，支持圖像到視頻的生成，並可實現從文本直接生成視頻。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1216" src="https://static.oschina.net/uploads/space/2025/0619/102551_SwUy_2720166.png" width="1286" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;V1 目前僅通過 Discord 平台的網頁端提供服務，基礎訂閲費為每月 10 美元。&lt;/p&gt; 
&lt;p&gt;根據 Midjourney 的官方介紹，V1 基於此前的圖像模型生態進行打造。&lt;/p&gt; 
&lt;p&gt;Midjourney V1 操作分為自動和手動兩種模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自動模式下，平台會根據用戶生成的圖片，自動創建「動作提示詞」並讓畫面運動起來；&lt;/li&gt; 
 &lt;li&gt;手動模式則是由用戶提供提示詞。同時，Midjourney V1 也分為「低動態」和「高動態」兩種運動模式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;V1 的發佈讓 Midjourney 加入與 OpenAI 的 Sora、Runway 的 Gen 4 等 AI 視頻模型的競爭。其目標不止於為好萊塢或廣告業生成素材，公司 CEO David Holz 稱這是邁向 「實時開放世界模擬」 AI 模型的一步，後續還計劃開發 3D 渲染和實時 AI 模型。 &amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 考慮赴港 IPO？知情人士：屬實，仍處於初步籌備階段</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息稱，AI 獨角獸稀宇科技 (MiniMax) 正考慮在香港進行首次公開募股（IPO）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對此，有接近 MiniMax 的知情人士向澎湃新聞記者表示，MiniMax 內部確實有類似想法，但目前仍處於初步籌備階段。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-1c8fdc630a51d77c2dbbdb3ff2131f20e68.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官網介紹顯示，MiniMax 是全球領先的通用人工智能科技公司。自 2022 年初成立以來，以「與所有人共創智能」為使命，致力於推動人工智能科技前沿發展，實現通用人工智能 (AGI）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，MiniMax 已自主研發了一系列多模態通用大模型，包括 MiniMax M1、Hailuo-02、Speech-02 和 Music-01，具備超長上下文處理能力，能夠理解、生成並整合包括文本、音頻、圖像、視頻和音樂在內的多種模態。並基於這些自研模型推出一系列 AI 原生產品，包括 MiniMax、海螺 AI、MiniMax Audio、星野等，以及面向企業和開發者的開放平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 3 月，MiniMax 獲 6 億美元 A 輪融資，投後估值 25 億美元，由阿里巴巴領投，此前融資的投資方也包括騰訊等。據媒體報道稱，MiniMax 的實際估值目前已經超過 2024 年所報道過的「25 億美元」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356108</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>融雲 AI 機器人上線，獨家直連 AI 平台，加速落地創新探索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 技術的爆發為各行各業帶來了前所未有的機遇，各類創新應用如雨後春筍般湧現——從圖像生成、視頻創作，到智能搜索引擎、代碼助手，AI 正在重塑人們的工作與生活方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;而在這一波浪潮中，ChatBot 類產品及其衍生形態——如虛擬角色、智能客服和 AI 助理——作為 AI 普及的「OG」，始終佔據着核心地位。無論是全球科技巨頭的佈局，還是創業團隊的創新嘗試，這一領域依然活力十足，不斷有優秀的新產品嶄露頭角。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;深度整合 IM 對話與 AI 能力，融雲 AI 機器人正式上線。&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;獨立的機器人用戶類型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，擁有&lt;/span&gt;&lt;strong&gt;&lt;span&gt;詳細的事件回調能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，&lt;strong&gt;獨家直連 AI 平台&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，大幅降低開發者落地 AI 社交、智能回覆等業務的成本，給開發者的創新探索加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;無論是以全新產品角逐市場，還是在現有產品中增加附加玩法。融雲 AI 機器人都可以&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效縮短業務上線週期，助力開發者快速探索充滿潛力的 AI 賽道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;無論是以全新產品角逐市場，還是在現有產品中增加附加玩法。融雲 AI 機器人都可以&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效縮短業務上線週期，助力開發者快速探索充滿潛力的 AI 賽道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;場景豐富，響應穩定&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融雲 AI 機器人支持基於指定機器人的詳細事件回調，方便開發者精準掌握用戶與機器人的互動，如單聊消息、羣聊@指令等，並基於不同事件進行定製化處理，靈活響應各類業務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;無論是自動回覆、任務觸發，還是羣聊助手，都可以藉助融雲 AI 機器人輕鬆實現更智能、更豐富的交互，&lt;/span&gt;&lt;span&gt;&lt;span&gt;提升產品的用戶體驗及業務運營效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;以單聊和羣聊兩種主要對話場景來看：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在單聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通過與機器人對話，可觸發多輪智能對話、內容生成等功能，支持流式或非流式輸出，適用於&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 陪伴、角色扮演&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等社交場景&lt;/span&gt;&lt;span&gt;&lt;span&gt;及&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 知識問答、智能客服&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等商務社交場景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="636" src="https://oscimg.oschina.net/oscnet/up-faa3c43ddca6e7fdc989dafeddb8f0d1286.png" width="585" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;除了穩定高效的多輪對話支持外，還可以實現智能任務執行功能，響應用戶發起的智能操作請求，如「生成北京出行計劃」、&lt;span&gt;「寫一封郵件」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;等；或&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;查詢個人事務，如「我今天還有哪些未完成的任務」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在羣聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通過 @ 機器人，觸發與 AI 機器人的溝通或智能業務處理流程，如：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;FAQ 問答：解析用戶意圖並自動回覆；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;工單創建：識別需求並提交至工單系統；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;日程提醒：識別時間表達並添加到日曆服務。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;快速上線，降本增效&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;提供獨立的機器人類型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;融雲 IM 提供獨立的機器人服務，自帶區別於真實用戶類型的業務邏輯，大幅降低開發者在 AI 對話類業務實現時針對機器人的特殊處理邏輯，從底層能力上滿足開發者靈活創新的 AI 對話需求，極具拓展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;獨家直連&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;&amp;nbsp;AI 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;融雲 AI 機器人業內獨家實現了與第三方 AI 平台的對接，開發者無需進行繁瑣的中間處理，即可快速接入 AI Agent 創建調試及大模型推理服務，顯著降低開發難度，為開發者的 AI 社交、智能客服等業務落地打開了一個「綠色極速通道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;此前，開發者若想借助 AI 平台賦能自身的 AI 對話類業務，需要自行實現中間的需求中轉和消息流轉，鏈路長、問題多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通過融雲 AI 機器人，開發者可在簡單調用接口後實現對 AI 平台能力的關聯，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;鏈路穩定、響應高效&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，並可以在融雲&lt;/span&gt;&lt;strong&gt;&lt;span&gt;流式消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等底層能力和&lt;/span&gt;&lt;strong&gt;&lt;span&gt;內容審核&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等周邊服務的配套支持下實現靈活的業務需求。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;接入便捷，靈活搭建&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融雲 AI 機器人支持 Webhook 回調、Dify 平台對接，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方便開發者根據自身的業務情況選擇對接方式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;設置 Webhook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客戶可通過 Webhook 回調，將用戶向機器人發送的消息同步到自己的業務服務器，由業務服務器自由對接自研或私有大模型自建服務（&lt;em&gt;如私有部署的 LLM、LangChain、RAG 檢索系統等&lt;/em&gt;）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通過這一方式可以實現靈活的消息接入、參數定製、響應策略，&lt;/span&gt;&lt;span&gt;&lt;span&gt;適合有高度定製化、私有化部署、安全隔離等要求的業務場景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;對接 AI Agent 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;支持對接已&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;接入 OpenAI、Claude、Gemini 等多種大模型的 Dify 平台。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客戶可在 Dify 平台上創建一個自己的 AI Agent（&lt;/span&gt;&lt;em&gt;&lt;span&gt;如：聊天機器人&lt;/span&gt;&lt;/em&gt;&lt;span&gt;），同時在融雲服務端創建一個機器人，並將該機器人通過配置直接與 Dify 平台創建的 AI Agent 進行對接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;這樣，&lt;/span&gt;&lt;span&gt;&lt;span&gt;無需自行搭建模型服務，就可以實現多輪 AI 對話、知識庫問答、RPA 流程（&lt;em&gt;機器人流程自動化&lt;/em&gt;）等&lt;/span&gt;&lt;span&gt;&lt;span&gt;高級功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="148" src="https://oscimg.oschina.net/oscnet/up-7518cc39e9922c3ad838434add534928cc3.png" width="580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;快速搭建 AI 陪伴應用示例&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;以 AI 陪伴應用為例，融雲提供從 AI 角色配置、Prompt 預設到 IM 對接的全鏈路服務，&lt;/span&gt;&lt;span&gt;&lt;span&gt;快速搭建 AI 陪伴應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在 Dify 中創建和調試 AI Agent&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪創建聊天助手&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪填寫人設&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪設置 LLM 和參數&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪配置開場白&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在融雲服務端創建機器人並完成關聯&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通過 Server API 創建機器人&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通過&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;Agent 地址&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;設置機器人的回調配置信息，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;關聯 AI Agent&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑在客戶端集成 IM SDK， AI 角色便可出現在 App 中，提供&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能破冰、AI 陪伴等能力，助力應用提升用戶粘性和商業價值。&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;詳細接入流程可見本期推文次條&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;更多詳情見&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;em&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.rongcloud.cn%2Fplatform-chat-api%2Fbot%2Foverview" target="_blank"&gt;開發者文檔&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356103</guid>
      <pubDate>Sun, 11 May 2025 02:01:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Firefox 139 測試內置 Perplexity AI 搜索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;負責 Firefox 搜索的產品經理&amp;nbsp;Gayatri &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconnect.mozilla.org%2Ft5%2Fdiscussions%2Ftry-out-perplexity-ai-search-in-firefox-139%2Ftd-p%2F98352" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;團隊正在與 Perplexity 合作，將&amp;nbsp;Perplexity AI 搜索內置到 Firefox 139 中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db094748597759caee52fd4a82e08cdcb33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0618/191849_B1yu_2720166.png" width="1390" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Perplexity 是一個 AI 驅動的搜索引擎，能直接以對話形式回答你的問題——無需翻閲大量搜索結果。它特別適用於以下情況：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅&amp;nbsp;需要快速簡潔的答案，避免在多個信息源中迷失&lt;/li&gt; 
 &lt;li&gt;📚&amp;nbsp;在研究或學習時需要準確且引用充分的資料&lt;/li&gt; 
 &lt;li&gt;✍️&amp;nbsp;在創作或處理技術內容，如博客文章或代碼片段&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Firefox 團隊表示，這是他們更廣泛目標的組成部分，即在使用搜索方式以及信任哪些工具來幫助他們完成任務方面為用戶提供更多選擇。如果體驗良好，可能會考慮在未來支持更多 AI 回答或搜索選項。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepEP —— 開源 EP 通信庫</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;DeepEP 是專為&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Mixture-of-Experts (MoE)&lt;/span&gt;&amp;nbsp;和 &lt;span style="background-color:#ffffff; color:#1f2328"&gt;expert parallelism (EP)&lt;/span&gt;&amp;nbsp;定製的通信庫。它提供高吞吐量和低延遲的&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;all-to-all&lt;/span&gt;&amp;nbsp;GPU 內核，也就是所謂的 MoE 調度和組合。該庫還支持低精度操作，包括 FP8。&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;為了與 DeepSeek-V3&amp;nbsp;論文中提出的 group-limited gating algorithm 保持一致，DeepEP 提供了一組針對非對稱域帶寬轉發（例如將數據從 NVLink 域轉發到 RDMA 域）進行優化的內核。這些內核提供高吞吐量，使其適合訓練和推理預填充任務。此外，它們還支持 SM (Streaming Multiprocessors)&amp;nbsp;數量控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對於延遲敏感的推理解碼，DeepEP 包含一組具有純 RDMA 的低延遲內核，以最大限度地減少延遲。該庫還引入了一種 hook-based 通信計算重疊方法，該方法不佔用任何 SM 資源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;要求&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;Hopper GPU（以後可能支持更多架構或設備）&lt;/li&gt;
&lt;li style="text-align:start"&gt;Python 3.8 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;CUDA 12.3 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;PyTorch 2.1 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;用於節點內通信的 NVLink&lt;/li&gt;
&lt;li style="text-align:start"&gt;用於節點內通信的 RDMA 網絡&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepep</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepep</guid>
      <pubDate>Sat, 10 May 2025 10:35:00 GMT</pubDate>
    </item>
    <item>
      <title>Gitee MCP 現已支持遠程訪問：無需本地部署，AI 助手即插即用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今年三月，&lt;a href="https://www.oschina.net/news/338794/gitee-mcp-server"&gt;Gitee 正式發佈了官方 MCP Server&lt;/a&gt;，讓 AI 助手深度參與代碼倉庫的管理，助力開發者更高效地工作。&lt;/p&gt; 
&lt;p&gt;今天，Gitee MCP 正式支持遠程訪問，上線了&lt;code&gt;Remote mcp-gitee&lt;/code&gt;：無需安裝、即開即用，讓 AI 助手可以遠程、安全地與 Gitee 交互，真正做到「即連即用」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源地址：&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;什麼是 Remote mcp-gitee？&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;是 Gitee 推出的遠程版 MCP Server，無需本地部署，默認運行在雲端，同時也擁有全面的接口能力，支持倉庫、文件、Issue、PR、用戶信息獲取、評論等眾多操作，滿足常見開發協作需求。&lt;/p&gt; 
&lt;p&gt;你可以通過簡單配置直接將其接入任意支持 MCP Streamable HTTP 協議的客戶端，&lt;strong&gt;無需安裝依賴、編譯構建，也無需配置本地環境&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;與此前的本地部署方式不同，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;將服務完全託管在雲端，為用戶提供了開箱即用、跨平台、跨設備的一致使用體驗。&lt;/p&gt; 
&lt;h2&gt;遠程 MCP 有哪些使用場景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI 驅動的協作&lt;/strong&gt;：通過&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手能夠自動創建 Issue、提取任務、拆解子任務、發起/合併 PR，減輕日常操作負擔。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;低門檻接入&lt;/strong&gt;：無需本地搭建或安裝依賴，企業或個人團隊只需配置一次，即可將 MCP 能力集成至工作流中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨團隊標準化流程&lt;/strong&gt;：所有操作通過遠端 MCP 接入，統一管理權限、審計、日誌，便於追蹤和審查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;無需部署即可讀寫代碼倉庫&lt;/h2&gt; 
&lt;p&gt;藉助&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手將具備完整的上下文訪問能力，能夠直接調用 Gitee 接口，獲取倉庫結構、讀取文件內容、創建 Issue、生成 PR，甚至合併代碼、發佈版本。&lt;/p&gt; 
&lt;p&gt;你只需要準備一個 Gitee 訪問令牌，並將其配置在客戶端中，即可激活整個智能協作流程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"gitee": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"https://api.gitee.com/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"headers": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Authorization":&amp;nbsp;"Bearer &amp;lt;YOUR PERSONAL ACCESS TOKEN&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;本方法適用於 Cursor、Trae 等多種主流客戶端，配置完畢後，即可直接連接 Remote mcp-gitee。&lt;/p&gt; 
&lt;h3&gt;在 Cursor 中連接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;進入 Cursor 設置頁面，選擇&lt;code&gt;Tools &amp;amp; Integrations&lt;/code&gt;，新建一個 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182420_lanO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;將配置信息複製到文件中，填入 Gitee 賬號的私人令牌，保存即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182431_KJ6X_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;返回設置頁面，可以看到 mcp-gitee server 已正常連接。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182440_lOSn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;在 Trae 中連接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;選擇任意一種方式進入 MCP 設置頁面。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182451_sEtI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;搜索 Gitee 並添加。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182501_L5XD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;將配置信息複製到文件中，填入 Gitee 賬號的私人令牌（Trae 暫時未支持遠程連接，需手動複製遠程連接的配置信息）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182511_Y51c_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;確認後，mcp-gitee server 已成功連接至 Trae。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="360" src="https://static.oschina.net/uploads/space/2025/0618/182521_D6Qz_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182549_TvrI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;同時，開發者也可選擇自行部署 Remote mcp-gitee 至本地，具體流程可訪問項目倉庫查看：&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;即插即用的智能協作，就在 Gitee&lt;/h2&gt; 
&lt;p&gt;Gitee 始終致力於在 AI 時代持續探索智能開發的邊界。無論是底層協議支持，還是工具鏈能力拓展，我們都希望為開發者&lt;strong&gt;提供更開放、更易用、更高效、更先進的基礎設施&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;讓 Gitee MCP 能力以即插即用的方式走進開發者日常。無需安裝、無需配置環境，只需一段 JSON 與私人令牌，就能讓 AI 真正參與項目開發的各個環節。&lt;/p&gt; 
&lt;p&gt;現在，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;已全面開放使用，歡迎體驗輕量、流暢的智能協作能力，歡迎訪問項目倉庫瞭解更多信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee" target="_blank"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356026</guid>
      <pubDate>Sat, 10 May 2025 10:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>國家互聯網信息辦公室：中國已有 433 款大模型完成備案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 上海世界移動通信大會（MWC 上海 2025）開幕式上，國家互聯網信息辦公室副主任王京濤在致辭中指出，截至目前，中國已經有 433 款大模型完成備案，上線提供服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京濤表示，目前中國已成為全球最大的互聯網市場，擁有全球最多的網民和移動互聯網的用戶，以及最活躍的數字技術和應用創新生態，建成了全球規模最大、技術領先、性能優越的網絡基礎設施。在追求自身發展的同時，中國也積極地推進各國共享互聯網發展機遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向未來，中國要堅持發展與安全並重研究，加強發展戰略、治理規則和技術標準的對接協調，推動人工智能朝着有益、安全、公平的方向健康、有序發展。要尊重各國網絡主權，尊重各國的互聯網發展道路和治理模式，共同構築和平、開放、安全、合作、有序的網絡空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京濤還表示，以人工智能為代表的新的數字技術，給人類生產生活帶來前所未有的機遇的同時，不同地區、國家、羣體間享受數字紅利的差距依然較大。對此，他建議，秉持人類共同體理念，廣泛開展人工智能國際合作，幫助發展中國家加強能力建設，提高人工智能的技術的可及性，彌合全球智能鴻溝，釋放更多的智能紅利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356024</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356024</guid>
      <pubDate>Sat, 10 May 2025 10:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「最火 AI 編程軟件」 Cursor 備受風投公司青睞，公司估值超過 180 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-17%2Fai-startup-anysphere-fields-vc-offers-at-over-18-billion-valuation"&gt;據彭博援引知情人士報道&lt;/a&gt;，近幾周來，投資者已與 Cursor 開發商 Anysphere 接洽，商討一項融資協議，該協議將使這家初創公司的估值達到 180 至 200 億美元。該提議是在這家 AI 初創公司年收入超過 5 億美元后不久提出的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/180654_RHv6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;知情人士透露，該公司並未主動尋求新一輪融資，而是投資者主動接洽。&lt;/p&gt; 
&lt;p&gt;Anysphere 首席執行官 Michael Truell 此前透露，超過半數財富 500 強企業使用 Cursor，日活用戶超過 100 萬人。OpenAI、Spotify、美國職業棒球大聯盟和 Instacart 等知名公司均為其用戶。&lt;/p&gt; 
&lt;p&gt;這家成立於 2023 年的公司年化收入已突破 5 億美元，被硅谷投資者譽為 「史上收入增長最快的初創公司」。雖然公司目前並不缺乏現金，但考慮到有利的融資條件，Anysphere 可能會選擇增加更多資本儲備。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356022</guid>
      <pubDate>Sat, 10 May 2025 10:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
