<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 28 Apr 2025 21:36:54 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>廣告服務商已嘗試在 AI 回覆中植入廣告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;早在 1999 年，Google 就被譽為「純粹的搜索引擎」，承諾提供簡潔、無廣告的體驗，沒有「門戶垃圾」，這與當時那些雜亂無章的搜索網站截然不同（見下圖）。&lt;/p&gt; 
&lt;p&gt;這項服務最初誕生於斯坦福大學，名為 BackRub，由拉里·佩奇和謝爾蓋·布林創立，最初他們迴避廣告，認為廣告可能存在利益衝突，降低搜索質量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d045e59c1698a9524e8623f706b6cfc417f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;圖片來源：u/Plenty_Objective8392&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;多年來，Google 徹底改變了其商業模式。儘管最初反對廣告，但為了將其迅速流行的搜索引擎貨幣化，Google 於 2000 年推出了 AdWords，並迅速發展成為按點擊付費的巨頭。最初只是簡單的側邊文字廣告，後來發展成為深度融入搜索結果頁面的廣告，使 Google 成為一家以廣告為主要收入來源的廣告巨頭，有時甚至讓用戶覺得搜索結果頁面「充斥着廣告」。&lt;/p&gt; 
&lt;p&gt;隨後，ChatGPT 在 2022 年底火爆上線。這款對話式人工智能提供直接答案而非鏈接列表，對 Google 基於鏈接的廣告模式構成了重大挑戰。ChatGPT 的威脅足以在 Google 內部引發明顯的緊迫感，&lt;/p&gt; 
&lt;p&gt;據報道，這觸發了內部警報，並加快了將自己的生成式人工智能推向公眾的時間表。只需看看 Google 首席執行官 Sundar Pichai 在 2023 年 Google I/O 大會上（即 ChatGPT 推出幾個月後）提到人工智能的次數就知道了；活動結束後的統計顯示，主題演講中提到人工智能的次數遠超一百，他反覆強調的次數也因此成為了一個病毒式傳播的 meme。&lt;/p&gt; 
&lt;p&gt;據英國《金融時報》報道，廣告集團和科技初創公司已經迅速意識到了這一轉變。他們正在積極開發新工具，幫助品牌確保自己出現在人工智能生成的搜索結果中，例如 OpenAI 的 ChatGPT、Anthropic 的 Claude、Google 自己的 AI Overviews 以及最近推出的 AI Mode。&lt;/p&gt; 
&lt;p&gt;這種高度關注源於生成式人工智能產品的興起，它們正迅速成為數百萬人在線搜索信息的主要方式。研究突顯了這一趨勢；諮詢公司貝恩的一項研究發現，目前 80% 的消費者至少 40% 的搜索依賴人工智能生成的搜索結果。這種依賴顯著減少了自然網絡流量，可能高達 25%，因為現在大約 60% 的搜索最終沒有用戶點擊進入傳統網站。這對 Google 的主要搜索業務構成了長期威脅，因為該業務嚴重依賴這些點擊來投放廣告。&lt;/p&gt; 
&lt;p&gt;Profound 和 Brandtech 等公司已進軍這一新領域，為品牌開發軟件。這些工具可以監控品牌被人工智能服務提及或呈現的頻率。更巧妙的是，它們採用一種類似於探測人工智能「大腦」的方法：向聊天機器人輸入大量文本提示，並分析由此產生的情緒和提及次數。這項技術可以預測人工智能模型提及品牌的偏好或可能性，從而創建排名系統。&lt;/p&gt; 
&lt;p&gt;然後，代理商利用這些分析結果為其客戶（例如金融科技公司 Ramp、招聘網站 Indeed 和威士忌製造商 Chivas Brothers）提供建議，幫助他們如何最好地從人工智能模型中獲得有利的提及。&lt;/p&gt; 
&lt;p&gt;這超越了傳統的搜索引擎優化（SEO），後者專注於讓網站在 Google 的鏈接列表中排名靠前。正如 Brandtech 合夥人 Jack Smyth 所説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;這不僅僅是讓你的網站在他們的搜索結果中被索引。這是為了認識到大型語言模型是最終的影響因素。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;他的公司甚至創建了一款「模型份額」產品來衡量和指導這項工作。這感覺就像一次範式轉變。正如 Profound 聯合創始人 James Cadwallader 所説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;傳統搜索一直是互聯網歷史上最大的壟斷之一。而現在，城堡的牆壁第一次出現了裂縫。這是一個從 CD 到流媒體的時代。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;挑戰在於，被人工智能提及與網頁排名不同。像 ChatGPT 這樣的人工智能模型使用傳統的網絡搜索，但會評估來源的相關性、可信度和權威性。正如 OpenAI 的 ChatGPT 搜索主管 Adam Fry 所解釋的那樣，由於用戶會提出更細緻入微的問題，人工智能在「傳統搜索之上增加了一層智能」。另一家人工智能驅動的搜索引擎 Perplexity 的聯合創始人 Denis Yarats 也強調了這一點：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;大模型（LLM）理解的內容更豐富，能夠更加細緻入微。他們可以發現矛盾之處，或者發現信息是否有誤導性……所以，這比審查鏈接要徹底得多。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;他補充道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;成為 SEO 的目標要困難得多，因為唯一真正的策略是儘可能相關並提供好的內容。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;儘管傳統搜索引擎優化 (SEO) 與人工智能 (AI) 結合存在固有困難，但廣告界仍在尋找進入該領域的途徑。例如，Perplexity 已在試行贊助「問題」，作為用戶查詢後的建議後續內容，這清楚地表明，人工智能對話流中的直接廣告開始出現。&lt;/p&gt; 
&lt;p&gt;儘管如此，值得注意的是，儘管這些人工智能變革被認為對 Google 的生存構成威脅，但 Google 的核心搜索和廣告業務仍展現出非凡的實力。週四，Google 母公司 Alphabet 宣佈，其搜索和其他業務在第一季度增長了近 10%，達到 507 億美元。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F9cc6cc0b-759f-4b8e-9ed1-9e32ad0fe22f&quot; target=&quot;_blank&quot;&gt;據《金融時報》報道&lt;/a&gt;，這一強勁業績給投資者帶來了一些安慰，儘管他們仍對 Google 自己的 Gemini 聊天機器人或 AI 概覽可能開始減少其廣告機器用戶點擊量的跡象保持警惕。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347188</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347188</guid>
            <pubDate>Sun, 27 Apr 2025 10:49:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Easy MQTT：極簡高效的 MQTT 服務器，助力物聯網與實時通信</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h1&gt;💎 Easy MQTT：極簡高效的 MQTT 服務器，助力物聯網與實時通信&lt;/h1&gt; 
&lt;p&gt;在萬物互聯的時代，高效、輕量的通信協議是構建實時系統的核心。Easy MQTT 應運而生——這是一款專為開發者設計的開源 MQTT 服務器，以「極簡」為核心理念，旨在為物聯網、工業自動化、即時消息等場景提供穩定可靠的消息傳輸服務。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌟 為何選擇 Easy MQTT？&lt;/h2&gt; 
&lt;h4&gt;1.極簡設計，開箱即用&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;僅需一條命令即可啓動服務，配置文件精簡清晰，無需複雜學習成本。&lt;/li&gt; 
 &lt;li&gt;支持單機與集羣部署，輕鬆應對從測試環境到生產環境的無縫擴展。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2.全協議支持，功能強大&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MQTT v3.1.1 完整兼容：&lt;/strong&gt; 確保與各類客戶端設備無縫對接。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket 子協議：&lt;/strong&gt; 支持瀏覽器端直接通信，賦能 Web 應用實時交互。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL/TLS 加密：&lt;/strong&gt; 為 TCP 和 WebSocket 連接提供安全保障，滿足企業級安全需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3.靈活擴展與高可用性&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持數據持久化，消息不丟失，保障關鍵業務連續性。&lt;/li&gt; 
 &lt;li&gt;通過外部接口實現動態鑑權，輕鬆集成現有用戶系統。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🚀 三步開啓你的首個 MQTT 服務&lt;/h2&gt; 
&lt;h4&gt;1.下載安裝&lt;/h4&gt; 
&lt;p&gt;訪問&lt;a href=&quot;https://gitee.com/EasyProgramming/easy-mqtt/releases&quot;&gt; Releases &lt;/a&gt;獲取最新編譯包，解壓即用。&lt;/p&gt; 
&lt;h4&gt;2.一鍵啓動&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;sh bin/start.sh -c conf/conf.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;無需複雜配置，服務即刻運行！&lt;/p&gt; 
&lt;h4&gt;3.按需擴展&lt;/h4&gt; 
&lt;p&gt;參考文檔快速開啓集羣模式、SSL 加密或 WebSocket 支持，滿足不同場景需求。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;📚 豐富文檔，開發者友好&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;入門指南：&lt;/strong&gt; 必要參數説明、快速部署集羣。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;進階功能：&lt;/strong&gt; 動態鑑權配置、SSL 加密實戰、WebSocket 集成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;開源透明：&lt;/strong&gt; 基於友好許可證開源，代碼完全開放，社區驅動持續優化。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌍 適用場景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;物聯網（IoT）：&lt;/strong&gt; 海量設備消息高效分發與狀態同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;實時監控：&lt;/strong&gt; 工業傳感器數據實時採集與預警。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;即時通訊：&lt;/strong&gt; 低延遲聊天、推送服務搭建。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智能家居：&lt;/strong&gt; 跨平台設備互聯互通。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;✨ 加入開發者社區&lt;/h2&gt; 
&lt;p&gt;Easy MQTT 不僅是一個工具，更是一個活躍的開源項目。我們歡迎開發者：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;提交 Issue：&lt;/strong&gt; 反饋問題或建議。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;貢獻代碼：&lt;/strong&gt; 共同完善功能與性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分享案例：&lt;/strong&gt; 你的實踐經驗可能幫助更多人！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;立即訪問&lt;a href=&quot;https://gitee.com/EasyProgramming/easy-mqtt&quot;&gt; Gitee 倉庫&lt;/a&gt;，探索更多可能！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;保持簡單，專注核心。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easy MQTT——讓消息通信從未如此輕鬆！ 💡&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347161</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347161</guid>
            <pubDate>Sun, 27 Apr 2025 09:24:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>乾貨分享｜MaxKB 智能問數方案及步驟詳解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;DeepSeek-R1 的發佈掀起了 AI 智能變革的浪潮。在過去幾個月裏，MaxKB 開源企業級 AI 助手已經幫助大量企業和組織快速落地了 DeepSeek，讓 AI 在不同的行業土壤中產生持續、可度量的業務價值。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;MaxKB（&lt;em&gt;github.com/1Panel-dev/MaxKB&lt;/em&gt;） 可以為本地部署的 DeepSeek 構建一個 Chatbox，也就是一個智能會話的界面，類似於個人用&lt;span style=&quot;color:#3e3e3e&quot;&gt;戶直接與 DeepSeek 進行對話。MaxKB 提供的 Chatbox 可以方便地嵌入到企業 OA 系統和業務系統，有&lt;/span&gt;效保證使用的便捷性和安全性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;另外一方面，MaxKB 能夠激活企業中長期積累的知識體系，使其智能化並面向內外部用戶提供服務。MaxKB 可以讓企業內部的私有知識文檔快速獲得智能問答能力，面向企業的員工、合作伙伴和客戶提供 AI 助手服務。MaxKB 還提供開箱即用的 RAG（檢索增強生成）技術，能夠結合私有知識庫提升問答效果，降低大模型幻覺。MaxKB 同時支持目前最為流行的 MCP（Model Context Protocol，模型上下文協議），為用戶靈活調用 MCP 工具提供了充分的便利性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;在幫助企業落地 DeepSeek 的過程中，MaxKB 開源項目組發現很多企業都有「智能問數」的需求，即允許員工使用自然語言查詢方法從數據庫中檢索結構化數據，並展示成直觀的圖表。本文將通過一個具體的例子（查詢學生成績），詳細講解如何通過「MaxKB+數據庫 MCP Server+QuickChart MCP Server」實現智能問數的功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;方案概述&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;本方案以「學生考試成績管理系統」為例進行説明，此係統包含了教師信息、學生信息、年級班級信息、考試成績等信息內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;MaxKB 智能問數方案邏輯圖如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-677afe248c4bc21a4673cece1d7f054bf95.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MaxKB 智能問數方案的具體實現步驟為：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8109f772552d6f912cba1c991c9e32063e5.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MaxKB 的智能問數方案包含以下三大關鍵步驟：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 數據準備：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;包含數據表詳細的 DDL（Data Definition Language，數據定義語言）信息和正確的 SQL 示例，以便大模型能夠更好地理解和使用數據；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ MCP Server 準備：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;需要提前準備對應數據庫的 MCP Server 和生成圖表的 MCP Server。此階段可以採用 1Panel 開源面板來統一部署和運維 MCP Server；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ MaxKB 智能問數應用設計：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;主要包含在 MaxKB 中如何通過高級應用編排實現智能問數的效果。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步驟一：數據準備&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 數據準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;提前準備「學生考試成績管理系統」數據表詳細的 DDL 信息，需要確保所有數據表的 DDL 信息完整且準確，包括字段類型、約束條件等。DDL 信息後續需要導入到 MaxKB 知識庫中，如果當前數據表不具備或者不清晰，具體可以參考下圖進行完整性補充。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//33da69631a928c1ef526abec61e7be4c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;2. SQL 示例準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;基於日常工作遇到的查詢需求，我們需要提前準備多樣化的 SQL 示例（本 Demo 數量為 100 條 SQL 查詢示例），同時需要保證和測試這些 SQL 的準確性。後續我們需要將這些 SQL 查詢示例導入到 MaxKB 知識庫中。具體準備過程可以參考下圖，採用 Execl 方式進行繪製和編寫。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//254a0d9ebffbf99a16f05e7d6bdb42dc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步驟二：MCP Server 準備&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 數據庫 MCP Server 準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;本 Demo 採用的是 MySQL 數據庫，因此需要提前準備 MySQL 的 MCP Server。在這裏我們使用了 Github 上的 DBHub 開源項目（&lt;/span&gt;&lt;em&gt;https://github.com/bytebase/dbhub&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）部署 MySQL 的 MCP Server。此項目同時還支持 PostgreSQL、SQL Server 等數據庫。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;DBHub 的部署方式也很簡單：進入 1Panel 應用商店，在「AI/大模型」分類下找到 DBHub 應用，點擊安裝即可（注意：需確保 1Panel 服務器已放行 SSE 端口）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8646b2f5170ee0842388fa0c759040a9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c9e9d6c80bf5c4927095faa721090ee9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;部署完成後，我們使用&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;curl&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;方式進行快速驗證，返回如下信息即為部署成功：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//96ae01cede2c92012bf006663e16c5a5.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;2. 生成圖表 MCP Server 準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;生成圖表的步驟採用「QuickChart.io+Quickchart-MCP-Server」來完成。QuickChart 項目（&lt;/span&gt;&lt;em&gt;https://github.com/typpo/quickchart&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）支持用戶通過提供數據和樣式參數來創建多種類型的圖表，支持從柱狀圖到速度表等多種圖表類型，並且提供生成圖表 URL 和下載圖表圖片的功能。Quickchart-MCP-Server 項目（&lt;/span&gt;&lt;em&gt;https://github.com/GongRzhe/Quickchart-MCP-Server&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）則提供了 QuickChart 的 MCP 服務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;需要注意的是，由於 Quickchart-MCP-Server 項目沒有提供 SSE 訪問方式，所以不同於 DBHub 項目，我們需要在 1Panel 開源面板（&lt;/span&gt;&lt;em&gt;github.com/1Panel-dev&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）的 MCP 模塊中進行部署。具體操作也非常簡單：打開 1Panel 開源面板，依次選擇「AI」→「MCP」→「創建 MCP 服務器」→「導入 MCP Server 配置」，導入如下 Quickchart-MCP-Server 的命令配置即可：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;quickchart-server&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;npx&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-y&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;@gongrzhe/quickchart-mcp-server&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ]
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d44553e72c27e91f36642cf441897e3c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;同時，注意開啓外部端口訪問和地址。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//dd401c3801083a35b7f682f1689861ed.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;等待幾秒後，可以看到 1Panel 中顯示 QuickChart 的 MCP Server 已經啓動。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ba9faa8484ab00d6b66e047597b3bbf7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;接下來，我們使用&lt;/span&gt;&lt;em&gt;curl&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;方式進行快速驗證，返回如下信息即顯示 QuickChart 的 MCP Server 已經部署成功。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//08cb2aa0a6cc9361e1abb31be6ae42c5.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步驟三：MaxKB 智能問數應用設計&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 將準備好的表信息和 SQL 示例導入知識庫&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 創建表信息知識庫，導入表信息，並將每一張表的信息作為一個分段，具體如下圖顯示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//89c36f37e816e17a73a6576bdc12b69e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;為了提高後續檢索的相似度，建議同時為每一張表創建問題，問題主要為此表的名稱（此操作的意義為：比如用戶提問「7 年級一共有多少老師」，知識庫中能夠準確地匹配出班級表和教師表兩張表）。問題需要儘量地覆蓋用戶對不同對象的稱呼，比如教師又可以稱為老師，具體如下圖所示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//4c3a7e21192a0f4231f1e7b66e5ea61d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e031374e7578dd3da598a1c524fbd111.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 創建示例 SQL 庫，導入 SQL 示例，一個 SQL 示例作為一個分段。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d5bb5fcb292c98e5dfbe688bfa875c9a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;同理，為不同的 SQL 示例創建問題，如下圖所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//dcf9c4ad8c3a5b394a25301be7579892.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;2. MaxKB 智能問數編排&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 創建空白的高級編排，名稱自取即可&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//92ea1ef49418a8343efedb2bbb4f6e2d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 添加兩個知識庫檢索節點，用於用戶檢索表信息和示例 SQL。同時設置相似度為 0.4，引用分段數 TOP 為 6。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;em&gt;&lt;span style=&quot;color:#f50a0a&quot;&gt;注意：此處很重要也很關鍵，需要按照不同的應用場景和數據庫進行大量的測試，最終選擇合適的相似度和引用分段數 TOP 值。建議首先從相似度 0.4，引用分段數 TOP 值為 6 開始測試效果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//0e141fc5a2bbb1827dd1e8107100d094.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 添加 AI 對話節點，配置 AI 模型（注意要選擇支持 MCP 的模型，比如 DeepSeek-Chat 或者 Qwen-Plus），同時在 AI 對話節點中配置 MCP Server：&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a3b0503b13a1e2b18fbc6d69793140b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;配置在步驟一&lt;span style=&quot;color:#3e3e3e&quot;&gt;中已經部署完成的 MCP Server 的 Config 信息，具體的配置信息如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;quickchart-server&quot;:&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;url&quot;:&amp;nbsp;&quot;http://10.1.240.110:18003/quickchart-server&quot;,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;transport&quot;:&amp;nbsp;&quot;sse&quot;
&amp;nbsp; &amp;nbsp;&amp;nbsp;},
&amp;nbsp;&amp;nbsp;&quot;mcp-mariadb&quot;:&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;timeout&quot;:&amp;nbsp;180,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;url&quot;:&amp;nbsp;&quot;http://10.1.240.106:8080/sse&quot;,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;transport&quot;:&amp;nbsp;&quot;sse&quot;
&amp;nbsp;&amp;nbsp;}
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 設置 AI 對話節點的角色提示詞&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 角色
你是一位專業的數據分析專家，精通 MYSQL 數據庫 SQL 語言，能夠熟練運用 mcp-mysql 工具進行 SQL 驗證和查詢，還能使用 quickchart-server 工具繪製圖表，並對相關數據進行深入分析和解釋。
&amp;nbsp;
## 技能
### 技能 1: 生成並驗證 SQL
1.&amp;nbsp;基於用戶提出的問題，結合已知信息，生成 SQL 語句。
2.&amp;nbsp;使用 mcp-mysql 工具對每次生成的 SQL 進行驗證和查詢。若 SQL 出現錯誤，需嘗試三次不同的 SQL 表述。
3.&amp;nbsp;記錄每次 SQL 驗證和查詢的結果。
&amp;nbsp;
### 技能 2: 繪製圖表
1.&amp;nbsp;根據用戶需求以及生成的 SQL 查詢結果，利用 quickchart-server 工具生成相關圖表。
2.&amp;nbsp;確保生成的圖表能夠清晰、美觀的展示相關數據。
&amp;nbsp;
### 技能 3: 數據的分析和解釋
1.&amp;nbsp;對 SQL 查詢得到的數據進行詳細分析，結合用戶的問題，找出數據的關鍵特徵和趨勢。
2.&amp;nbsp;以通俗易懂的語言向用戶解釋數據所代表的含義以及數據與用戶問題之間的關係。
&amp;nbsp;
## 限制
-&amp;nbsp;僅圍繞與生成 SQL、利用工具查詢驗證、生成圖片以及數據的分析和解釋相關的內容進行回答，拒絕回答不涉及這些內容的話題。
-&amp;nbsp;生成的 SQL 需符合 MYSQL 語法規範，生成的圖片應符合數據展示要求，分析和解釋需要基於真實的查詢結果。
-&amp;nbsp;分析和解釋部分應儘量簡潔明瞭，突出重點。
-&amp;nbsp;操作過程嚴格按照上述技能要求執行，不得隨意更改工具使用方式。&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 設置 AI 對話節點的用戶提示詞&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#&amp;nbsp;已知信息
## 表信息:
{{表信息.data}}
&amp;nbsp;
## 參考示例 SQL:
{{示例 SQL.data}}
&amp;nbsp;
# 用戶問題：
{{開始.question}}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;效果驗證和總結&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在 MaxKB 中按步驟設置完成後，可以進行調試測試，調試測試通過後方可進行應用發佈。驗證發現，大模型會按照我們設定的提示詞，根據已經給出的表信息和 SQL 示例，自行編寫 SQL 語句，調用 MySQL MCP Server 進行查詢和驗證結果，調用 QuickChart MCP Server 進行圖表繪製，最後給出數據分析。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題一：每個班級學生佔比圖&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5e39814c8fd6af863c37cb4ac511e58d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題二：每個年級有多少名學生？&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//882fbb0e90ed8a0122ed8e56850bde29.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題三：哪個老師教的學生最多？&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f6438262d3eebf8a78d2ef3283618d62.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題四：成績排名前 10 的學生名字、分數和班級&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//fde855130bbdb7cb5d14228dd5bc2a99.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;由此可見，MaxKB 通過其強大的 RAG 技術和 MCP 調用能力，能夠完整且準確地實現智能問數的場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;RAG 技術結合了信息檢索和文本生成的優勢，使得系統能夠在理解用戶查詢的基礎上，從大量數據中檢索相關信息，並且生成準確、相關的 SQL 查詢語言。而 MCP 工具則提供了強大的 SQL 查數驗數能力和動態的圖表繪製能力，從而為智能問數系統提供了堅實的數據基礎。最終，通過 MaxKB 的高級編排設計能力允許用戶靈活地構建和優化智能問數流程，可以有效地確保系統能夠適用於不同的業務需求和問數場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347155</guid>
            <pubDate>Sun, 27 Apr 2025 08:56:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>MCP 協議：為什麼 Streamable HTTP 是最佳選擇？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：靜擇&lt;/p&gt; 
&lt;p&gt;MCP（Model Context Protocol）協議是一個用於 AI 模型和工具之間通信的標準協議。隨着 AI 應用變得越來越複雜並被廣泛部署，原有的通信機制面臨着一系列挑戰。近期 MCP 倉庫的 PR #206【1】 引入了一個全新的 Streamable HTTP 傳輸層替代原有的 HTTP+SSE 傳輸層。本文將詳細分析該協議的技術細節和實際優勢。&lt;/p&gt; 
&lt;h2&gt;要點速覽&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 相比 HTTP + SSE 具有更好的穩定性，在高併發場景下表現更優。&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP 在性能方面相比 HTTP + SSE 具有明顯優勢，響應時間更短且更穩定。&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP 客戶端實現相比 HTTP + SSE 更簡單，代碼量更少，維護成本更低。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;為什麼選擇 Streamable HTTP?&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5481fb16dc28298c0a673f410c34a3f94aa.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;HTTP + SSE 存在的問題&lt;/h3&gt; 
&lt;p&gt;HTTP+SSE 的傳輸過程實現中，客戶端和服務器通過兩個主要渠道進行通信：（1）HTTP 請求/響應：客戶端通過標準的 HTTP 請求向服務器發送消息。（2）服務器發送事件（SSE）：服務器通過專門的 /sse 端點向客戶端推送消息，這就導致存在下面三個問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;服務器必須維護長連接&lt;/strong&gt;，在高併發情況下會導致顯著的資源消耗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;服務器消息只能通過 SSE 傳遞&lt;/strong&gt;，造成了不必要的複雜性和開銷。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基礎架構兼容性&lt;/strong&gt;，許多現有的網絡基礎架構可能無法正確處理長期的 SSE 連接。企業防火牆可能會強制終止超時連接，導致服務不可靠。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Streamable HTTP 的改進&lt;/h3&gt; 
&lt;p&gt;Streamable HTTP 是 MCP 協議的一次重要升級，通過下面的改進解決了原有 HTTP + SSE 傳輸方式的多個關鍵問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;統一端點&lt;/strong&gt;：移除了專門建立連接的 /sse 端點，將所有通信整合到統一的端點。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;按需流式傳輸&lt;/strong&gt;：服務器可以靈活選擇返回標準 HTTP 響應或通過 SSE 流式返回。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;狀態管理&lt;/strong&gt;：引入 session 機制以支持狀態管理和恢復。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;HTTP + SSE vs Streamable HTTP&lt;/h2&gt; 
&lt;p&gt;下面通過實際應用場景中穩定性，性能和客戶端複雜度三個角度對比説明 Streamable HTTP 相比 HTTP + SSE 的優勢，AI 網關 Higress 目前已經支持了 Streamable HTTP 協議，通過 MCP 官方 Python SDK 的樣例 Server 部署了一個 HTTP + SSE 協議的 MCP Server，通過 Higress 部署了一個 Streamable HTTP 協議的 MCP Server。&lt;/p&gt; 
&lt;h2&gt;穩定性對比&lt;/h2&gt; 
&lt;h3&gt;TCP 連接數對比&lt;/h3&gt; 
&lt;p&gt;利用 Python 程序模擬 1000 個用戶同時併發訪問遠程的 MCP Server 並調用獲取工具列表，圖中可以看出 SSE Server 的 SSE 連接無法複用且需要長期維護，高併發的需求也會帶來 TCP 連接數的突增，而 Streamable HTTP 協議則可以直接返回響應，多個請求可以複用同一個 TCP 連接，TCP 連接數最高只到幾十條，並且整體執行時間也只有 SSE Server 的四分之一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a4e31878c274ea0c458008bf465e66c083d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 1000 個併發用戶的測試場景下，Higress 部署的 Streamable HTTP 方案的 TCP 連接數明顯低於 HTTP + SSE 方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP + SSE：需要維持大量長連接，TCP 連接數隨時間持續增長&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP：按需建立連接，TCP 連接數維持在較低水平&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;請求成功率對比&lt;/h3&gt; 
&lt;p&gt;實際應用場景中進程級別通常會限制最大連接數，linux 默認通常是 1024。利用 Python 程序模擬不同數量的用戶訪問遠程的 MCP Server 並調用獲取工具列表，SSE Server 在併發請求數到達最大連接數限制後，成功率會極速下降，大量的併發請求無法建立新的 SSE 連接而訪問失敗。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9bbc20f87d17e336829e190eb0a3fea4283.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在不同併發用戶數下的請求成功率測試中，Higress 部署的 Streamable HTTP 的成功率顯著高於 HTTP + SSE 方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP + SSE：隨着併發用戶數增加，成功率顯著下降&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP：即使在高併發場景下仍能保持較高的請求成功率&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;性能對比&lt;/h2&gt; 
&lt;p&gt;這裏對比的是社區 Python 版本的 GitHub MCP Server【2】 和 Higress MCP 市場的 GitHub MCP Server&lt;/p&gt; 
&lt;p&gt;利用 Python 程序模擬不同數量的用戶同時併發訪問遠程的 MCP Server 並調用獲取工具列表，並統計調用返回響應的時間，圖中給出的響應時間對比為對數刻度，SSE Server 在併發用戶數量較多時平均響應時間會從 0.0018s 顯著增加到 1.5112s，而 Higress 部署的 Streamable HTTP Server 則依然維持在 0.0075s 的響應時間，也得益於 Higress 生產級的性能相比於 Python Starlette 框架。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-58effeb73a37e20e3eb89e93cd7efde59d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;性能測試結果顯示，Higress 部署的 Streamable HTTP 在響應時間方面具有明顯優勢：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 的平均響應時間更短，響應時間波動較小，隨併發用戶數增加，響應時間增長更平&lt;/li&gt; 
 &lt;li&gt;HTTP + SSE 的平均響應時間更長，在高併發場景下響應時間波動較大&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;客戶端複雜度對比&lt;/h2&gt; 
&lt;p&gt;Streamable HTTP 支持無狀態的服務和有狀態的服務，目前的大部分場景無狀態的 Streamable HTTP 的可以解決，通過對比兩種傳輸方案的客戶端實現代碼，可以直觀地看到無狀態的 Streamable HTTP 的客戶端實現簡潔性。&lt;/p&gt; 
&lt;h4&gt;HTTP + SSE 客戶端樣例代碼&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;class SSEClient:
    def __init__(self, url: str, headers: dict = None):
        self.url = url
        self.headers = headers or {}
        self.event_source = None
        self.endpoint = None

        async def connect(self):
            # 1. 建立 SSE 連接
            async with aiohttp.ClientSession(headers=self.headers) as session:
                self.event_source = await session.get(self.url)

                # 2. 處理連接事件
                print(&#39;SSE connection established&#39;)

                # 3. 處理消息事件
                async for line in self.event_source.content:
                    if line:
                        message = json.loads(line)
                        await self.handle_message(message)

                        # 4. 處理錯誤和重連
                        if self.event_source.status != 200:
                            print(f&#39;SSE error: {self.event_source.status}&#39;)
                            await self.reconnect()

        async def send(self, message: dict):
            # 需要額外的 POST 請求發送消息
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.post(self.endpoint, json=message) as response:
                    return await response.json()

                async def handle_message(self, message: dict):
                    # 處理接收到的消息
                    print(f&#39;Received message: {message}&#39;)

    async def reconnect(self):
        # 實現重連邏輯
        print(&#39;Attempting to reconnect...&#39;)
        await self.connect()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Streamable HTTP 客戶端樣例代碼&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;class StreamableHTTPClient:
    def __init__(self, url: str, headers: dict = None):
        self.url = url
        self.headers = headers or {}

    async def send(self, message: dict):
        # 1. 發送 POST 請求
        async with aiohttp.ClientSession(headers=self.headers) as session:
            async with session.post( self.url, json=message,
                headers={&#39;Content-Type&#39;: &#39;application/json&#39;}
            ) as response:
                # 2. 處理響應
                if response.status == 200:
                    return await response.json()
                else:
                    raise Exception(f&#39;HTTP error: {response.status}&#39;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從代碼對比可以看出：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;複雜度：Streamable HTTP 無需處理連接維護、重連等複雜邏輯&lt;/li&gt; 
 &lt;li&gt;可維護性：Streamable HTTP 代碼結構更清晰，更易於維護和調試&lt;/li&gt; 
 &lt;li&gt;錯誤處理：Streamable HTTP 的錯誤處理更直接，無需考慮連接狀態&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;【1】PR&lt;/p&gt; 
&lt;p&gt;#206&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fmodelcontextprotocol%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/modelcontextprotocol/pull/206&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;【2】GitHub MCP&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;serverhttps://github.com/modelcontextprotocol/servers/tree/main/src/github&quot;&gt;Serverhttps://github.com/modelcontextprotocol/servers/tree/main/src/github&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18261770</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18261770</guid>
            <pubDate>Sun, 27 Apr 2025 08:33:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>一行代碼讓 iPhone 變磚</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;一名安全研究人員近日披露了 iOS 系統中一個基於&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Fdarwinnotify%2Fdarwin-notification-api&quot; target=&quot;_blank&quot;&gt;Darwin 通知機制&lt;/a&gt;的高危系統漏洞，攻擊者可通過沙盒應用向系統發送特定通知，誘導設備進入「恢復模式」並觸發無限重啓循環。&lt;/p&gt; 
&lt;p&gt;這名研究人員僅通過一個簡單的代碼行（notify_post）就觸發了嚴重的系統漏洞，並通過 Widget 擴展機制實現持續攻擊，且能繞過 iOS 沙盒限制。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-objectivec&quot;&gt;notify_post(&quot;com.apple.MobileSync.BackupAgent.RestoreStarted&quot;)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該漏洞影響所有依賴 Darwin 通知的系統服務，包括但不限於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;鎖屏/控制中心狀態管理&lt;/li&gt; 
 &lt;li&gt;網絡連接策略切換&lt;/li&gt; 
 &lt;li&gt;外接設備檢測邏輯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/155229_ccfm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當然，該漏洞已被蘋果修復，作者因此獲得了蘋果提供的 17,500 美元獎勵。 &lt;/p&gt; 
&lt;p&gt;作者整理的時間線：&lt;/p&gt; 
&lt;p&gt;2024 年 6 月 26 日：向蘋果公司發送初始報告&lt;br&gt; 2024 年 9 月 27 日：收到蘋果公司的消息，告知正在採取措施進行緩解&lt;br&gt; 2025 年 1 月 28 日：問題已標記為已解決，並確認了獎金資格&lt;br&gt; 2025 年 3 月 11 日：漏洞分配編號 CVE-2025-24091，已在 iOS/iPadOS 18.3 中解決&lt;/p&gt; 
&lt;p&gt;獎金金額：17,500 美元&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：《How a Single Line Of Code Could Brick Your iPhone》&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frambo.codes%2Fposts%2F2025-04-24-how-a-single-line-of-code-could-brick-your-iphone&quot; target=&quot;_blank&quot;&gt;https://rambo.codes/posts/2025-04-24-how-a-single-line-of-code-could-brick-your-iphone&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347126/how-a-single-line-of-code-could-brick-your-iphone</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347126/how-a-single-line-of-code-could-brick-your-iphone</guid>
            <pubDate>Sun, 27 Apr 2025 07:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2023 年最熱門的 AI 職位——「提示詞工程師」已過時</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據《華爾街日報》&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fthe-hottest-ai-job-of-2023-is-already-obsolete-1961b054&quot; target=&quot;_blank&quot;&gt;報道&lt;/a&gt;，曾被譽為 2023 年最熱門 AI 職位、年薪可達 20 萬美元的「提示工程師」（Prompt Engineer）正迅速降溫。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/144406_aPB5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根據微軟近期一項覆蓋 31 個國家 31,000 名員工的調查，在未來 12 至 18 個月企業考慮增設的新職位中，提示工程師排名倒數第二，遠低於 AI 訓練師、AI 數據專家和 AI 安全專家等職位。&lt;/p&gt; 
&lt;p&gt;所謂提示詞工程，是指設計、開發、測試和優化用於與生成式 AI 模型交互的文本輸入（即「提示詞」），目標是引導 AI 模型生成準確且符合需求的輸出，發揮 AI 模型的潛力。但是，由於 AI 模型固有的不透明性，這種操作的科學性和有效性始終存在疑問，也有很多人藉此營銷、行騙。&lt;/p&gt; 
&lt;p&gt;報道指出，「提示詞工程師」熱度發生變化的核心原因在於，&lt;strong&gt;現代 AI 模型已能更好地理解用戶意圖，甚至在指令不清時主動提問，大大降低了對精心設計提示詞的依賴&lt;/strong&gt;。另一個關鍵因素是企業策略的轉變。相比設立專門職位，許多公司選擇對現有員工提供 AI 工具和培訓，將使用 AI 的能力視為一項基礎技能。&lt;/p&gt; 
&lt;p&gt;招聘市場的實際數據也印證了這一趨勢。儘管在 ChatGPT 面世後，用戶對「提示工程師」的搜索量曾短暫飆升，但企業發佈的實際招聘崗位數量始終極少，搜索熱度也已大幅回落並趨於平穩。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347101</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347101</guid>
            <pubDate>Sun, 27 Apr 2025 06:44:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟發佈 2025 工作趨勢：每位員工都將成為 Agent 的 「老闆」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微軟近日在其官網發佈了 2025 年工作趨勢指數報告，分析了來自全球 31 個國家和地區的 31，000 家企業。報告結合了 LinkedIn 勞動力市場趨勢、數萬億個 Microsoft365 的生產力信號以及眾多專家的見解，指出 「人機協作」 模式正在重塑企業架構，催生出一種全新的 「前沿公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;251&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-262509e06b372a5030a9fbb7c87f5ba548a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;「前沿公司」 是一種新型的組織形式，主要圍繞智能體（Agent）構建，以適應快速變化的商業環境和技術進步。這種公司的核心特點是將人類智慧與智能體相結合，形成高效的團隊，顯著提高生產力和創新能力，並節省工作時間。在這樣的公司中，智能體可以是各種自動化工具或智能助手，執行從數據處理到複雜決策支持的多種任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，隨着智能體的廣泛應用，員工將逐步成為 「Agent 老闆」，他們不僅需要管理和優化這些智能體，還需具備相應的新技能。這意味着未來每位員工都要像初創公司的 CEO 一樣思考如何利用 AI 來提升工作效率。根據調研顯示，67% 的企業領導者表示他們熟悉 Agent 的概念，而這一比例在員工中僅為 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，前沿公司的組織結構也將發生變化，變得更加靈活和以結果為導向。這種新的工作架構會根據業務需求動態調整，靈活組合人類和智能體資源，以實現最佳效果。微軟指出，隨着智能體的加入，未來每位員工都有可能從第一天起就參與到複雜的工作中，甚至一名初級員工也可以藉助 AI 管理整個營銷活動。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在這個新模式中，企業需要關注人機協作的比例，確保資源的高效利用。同時，管理層需要重構職能，以適應這種人機協作的新趨勢。微軟還提到，員工需要從 「工具使用者」 轉變為 「合作伙伴」，通過與智能體的雙向互動激發創新能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347091</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347091</guid>
            <pubDate>Sun, 27 Apr 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Hyprnote —— 會議專用 AI 記事本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#3c3c43&quot;&gt;Hyprnote 專為會議繁忙的人士打造，是一款&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;適用於連續會議的 AI 記事本。本地優先且可擴展。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;錄並轉錄您的會議&lt;/li&gt;
&lt;li&gt;從原始會議記錄中生成&lt;strong&gt;有力的摘要&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;離線&lt;/strong&gt;工作使用&lt;strong&gt;開源模型&lt;/strong&gt;（&lt;em&gt;Whisper&lt;/em&gt;和&lt;em&gt;Llama&lt;/em&gt;）&lt;/li&gt;
&lt;li&gt;高度&lt;a href=&quot;https://docs.hyprnote.com/extensions/&quot;&gt;可擴展&lt;/a&gt;，由&lt;a href=&quot;https://docs.hyprnote.com/plugins/&quot;&gt;插件提供支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;
&lt;div style=&quot;margin-left:auto; margin-right:auto&quot;&gt;
&lt;div style=&quot;margin-right:calc(50% - 678px)&quot;&gt;
&lt;div&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亮點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;增強你的筆記&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨意記下一些東西，Hyprnote 將根據您的備忘錄製作會議記錄。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt=&quot;&quot; height=&quot;391&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/152058_SbVr_4252687.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;離線和隱私&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hyprnote 是本地優先的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;392&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151933_5xtQ_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;擴展和插件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;就像 VSCode 一樣，可以根據你的情況添加或創建擴展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;382&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151827_6b1U_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://docs.hyprnote.com/extensions/transcript.html&quot;&gt;transcript extension&lt;/a&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&amp;nbsp;&lt;/span&gt;由&amp;nbsp;&lt;a href=&quot;https://docs.hyprnote.com/plugins/listener.html&quot;&gt;listener plugin&lt;/a&gt;&amp;nbsp;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;useEffect&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;channel&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;new&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#953800&quot;&gt;Channel&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;SessionEvent&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;subscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;channel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;onmessage&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;started&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;stopped&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;unsubscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/hyprnote</link>
            <guid isPermaLink="false">https://www.oschina.net/p/hyprnote</guid>
            <pubDate>Sun, 27 Apr 2025 05:53:00 GMT</pubDate>
        </item>
        <item>
            <title>騰訊正式開源跨端框架 Kuikly：基於 Kotlin 創建 Android、iOS、鴻蒙、Web、小程序應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;騰訊跨端框架&amp;nbsp;Kuikly 正式開源。根據官方介紹，Kuikly 是基於 Kotlin Multiplatform 的 UI 與邏輯全面跨端綜合解決方案，由騰訊大前端領域 Oteam（公司級）推出，目的在於提供一套一碼多端、極致易用、動態靈活的全平台高性能開發框架。&lt;/p&gt; 
&lt;p&gt;Kuikly（Kotlin UI Kit，發音同 quickly）使用 Kotlin 開發了聲明式 UI 框架，映射到系統原生控件做渲染，最終用 KMM（Kotlin Multiplatform Mobile）實現跨端。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c10e21f658b9ab50513e216dc7c37cfa28e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雖然是全平台，但目前暫時只開源了 Android 和 iOS，鴻蒙部分 5 月才開源，而 Web 和，小程序暫定是 Q2：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/121851_K8I9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 開源地址：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent-TDS%2FKuiklyUI&quot;&gt;https://github.com/Tencent-TDS/KuiklyUI&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 基於 Kotlin MultiPlatform（KMP）技術，它利用了 KMP 邏輯跨平台的能力，並抽象出通用的跨平台 UI 渲染接口，複用平台的 UI 組件，從而達到 UI 跨平台，具有輕量、高性能、可動態化等優點；同時，KuiklyBase 基建同樣支持邏輯跨端。 讓開發者&lt;strong&gt;可以使用 Kotlin 創建 Android、iOS、鴻蒙、Web、小程序應用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-911df639ea27ac02b452b9a379738d91ddd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/c0981983-cece-4d31-9488-e775586c8881.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;Kuikly 跨端框架系統要求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;iOS 12.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android 5.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HarmonyOS Next 5.0.0 (12) 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kotlin 版本 1.3.10 版本及以上&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkuikly.tds.qq.com%2F%25E7%25AE%2580%25E4%25BB%258B%2Farch.html&quot;&gt;https://kuikly.tds.qq.com/%E7%AE%80%E4%BB%8B/arch.html&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347077/tencent-tds-kuikly</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347077/tencent-tds-kuikly</guid>
            <pubDate>Sun, 27 Apr 2025 04:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>GPUStack v0.6 超重磅更新：vLLM 多機分佈式、昇騰 MindIE 等</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;GPUStack 是一個 100% 開源的模型服務平台&lt;/strong&gt; ，支持 &lt;strong&gt;Linux、Windows 和 macOS&lt;/strong&gt; ，支持 &lt;strong&gt;NVIDIA、AMD、Apple Silicon、昇騰、海光、摩爾線程&lt;/strong&gt; 等 GPU 構建&lt;strong&gt;異構 GPU 集羣&lt;/strong&gt; ，支持 &lt;strong&gt;LLM、多模態、Embedding、Reranker、圖像生成、Speech-to-Text 和 Text-to-Speech&lt;/strong&gt; 模型，支持 &lt;strong&gt;vLLM、MindIE、llama-box&lt;/strong&gt; （&lt;strong&gt;基於 llama.cpp 與 stable-diffusion.cpp&lt;/strong&gt; ）等多種推理引擎與&lt;strong&gt;推理引擎多版本並行&lt;/strong&gt; ，支持&lt;strong&gt;資源自動調度分配、模型故障自動恢復、多機分佈式推理、混合異構推理、推理請求負載均衡、資源與模型監控指標觀測、國產化支持、用戶管理與 API 認證授權等各種企業級特性&lt;/strong&gt; ，提供 &lt;strong&gt;OpenAI 兼容 API 無縫接入 Dify、RAGFlow、FastGPT、MaxKB 等各種上層應用框架&lt;/strong&gt;，是企業建設模型服務平台的理想選擇。&lt;/p&gt; 
&lt;p&gt;GPUStack 一直&lt;strong&gt;致力於以最簡單易用的方式，幫助用戶快速納管異構 GPU 資源並運行所需的 AI 模型，從而支撐 RAG、AI Agents 以及其他生成式 AI 落地場景&lt;/strong&gt;。為用戶打造絕佳的使用體驗是我們始終堅持的目標。最新發布的 v0.6 是迄今為止最重磅的版本，全方位完善了平台的整體功能、性能、穩定性和用戶使用體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GPUStack v0.6 版本的核心更新包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;vLLM 多機分佈式推理&lt;/strong&gt;：提供生產級的多機分佈式推理能力，支撐 DeepSeek R1 / V3 等單機 GPU 資源無法運行的超大參數量模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;昇騰 MindIE 支持&lt;/strong&gt;：為昇騰 910B 和 310P 用戶提供內置的 MindIE 推理引擎支持，以提供最佳的模型推理表現。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型兼容性檢測&lt;/strong&gt;：提供對模型是否支持部署的兼容性檢測，目前提供對模型架構支持、操作系統兼容、資源可用性、本地路徑可用性等依賴的實時檢測，後續還會持續加入更多檢測條件，提供更加友好的模型部署體驗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型下載管理&lt;/strong&gt;：支持管理已下載的模型文件、支持以不佔用 GPU 資源分配為前提，發起單機/多機的模型下載任務、支持將本地路徑的模型文件添加到 UI 中進行統一管理。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型故障自動恢復&lt;/strong&gt;：支持模型在發生故障時的自動恢復機制。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;端口暴露優化&lt;/strong&gt;：優化需要暴露的端口範圍，API 入口到模型實例的推理請求統一經過代理轉發，不再需要暴露模型實例端口，降低 96% 以上的端口暴露，並支持用戶自定義。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增強國際化支持&lt;/strong&gt;：GPUStack 用戶遍佈全球上百個國家和地區，本次 GPUStack 社區用戶貢獻了俄語和日語支持，為不同語言的用戶提供更加友好的使用體驗，加速推進 GPUStack 的全球化應用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI / UX 全方位優化&lt;/strong&gt;：全方位的 UI / UX 優化，逐幀打磨，打造業界最好用的模型推理平台。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這一版本總共包含&lt;strong&gt;上百項增強、修復、穩定性改進和用戶體驗優化&lt;/strong&gt;，為用戶的生產落地提供強大的場景支持。&lt;/p&gt; 
&lt;p&gt;有關 &lt;strong&gt;GPUStack&lt;/strong&gt; 的詳細信息，可以訪問：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 倉庫地址: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;https://github.com/gpustack/gpustack&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;GPUStack 用戶文檔: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gpustack.ai&quot; target=&quot;_blank&quot;&gt;https://docs.gpustack.ai&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;重點特性介紹&lt;/h2&gt; 
&lt;h3&gt;vLLM 多機分佈式推理&lt;/h3&gt; 
&lt;p&gt;隨着大語言模型的參數規模不斷提升，傳統單機 GPU 資源已難以滿足推理部署的實際需求。為此，GPUStack 在當前版本中正式支持生產級的 vLLM 多機分佈式推理能力。通過跨主機部署，將模型按張量或按層切分，分佈到多個節點運行，從而實現對超大參數模型（如 DeepSeek R1、DeepSeek V3 等）的推理支持。&lt;/p&gt; 
&lt;p&gt;當前，GPUStack 對以下兩類推理引擎提供分佈式支持：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;llama-box：異構分佈式，適用於研發測試環境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持 Linux、Windows 和 macOS 操作系統；&lt;/p&gt; 
&lt;p&gt; • 允許不同操作系統、不同品牌、不同規格的 GPU 混合實現異構分佈式推理；&lt;/p&gt; 
&lt;p&gt; • 可在桌面或輕量服務器上快速構建異構分佈式推理環境；&lt;/p&gt; 
&lt;p&gt; • 更適用於日常研發、模型驗證、兼容性測試等場景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;vLLM：同構分佈式，面向生產環境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持在多台 Linux 服務器之間進行同構分佈式推理；&lt;/p&gt; 
&lt;p&gt; • 要求參與節點的硬件環境基本一致（如 GPU 型號、數量、顯存）；&lt;/p&gt; 
&lt;p&gt; • 支持張量並行和流水線並行，具備良好的推理吞吐能力；&lt;/p&gt; 
&lt;p&gt; • 適合生產環境下對高併發、低延遲模型服務的部署需求。&lt;/p&gt; 
&lt;p&gt;通過 vLLM 和 llama-box 的分佈式推理能力，GPUStack 能夠覆蓋&lt;strong&gt;從模型研發驗證到大規模生產部署的完整流程&lt;/strong&gt;。在研發階段，用戶可使用 llama-box 構建靈活的測試集羣；在生產部署階段，則可通過 vLLM 提供穩定可靠的推理服務能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ec5d9aef8c8a1a7aeacd7175a0c0e600.png&quot; alt=&quot;model-info&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;昇騰 MindIE 支持&lt;/h3&gt; 
&lt;p&gt;在之前版本中，GPUStack 基於 llama-box 推理引擎初步支持了昇騰 910B 和 310P 芯片的模型推理。然而由於算子支持不全及相關生態不夠完善，實際使用中存在較多限制，例如只支持模型的部分量化精度，在性能和穩定性方面也弱於昇騰官方推理引擎 MindIE。&lt;/p&gt; 
&lt;p&gt;為了提升用戶在昇騰 NPU 上的模型推理體驗，GPUStack 現已內置集成 MindIE 推理引擎，對 910B 和 310P 提供更加穩定且高性能的模型推理能力。&lt;/p&gt; 
&lt;p&gt;MindIE 是昇騰官方推出的高性能深度學習推理框架，具備運行加速、調試調優與快速部署等多項優勢，目前在昇騰硬件上表現最為出色。得益於其較為成熟的軟硬件協同生態，MindIE 已成為在 NPU 上部署推理模型的主流方案。&lt;/p&gt; 
&lt;p&gt;當前，GPUStack 已完成對 MindIE 引擎的初步集成，相比於 llama-box 引擎，在部分場景可以達到數倍的推理速度提升。未來還將持續優化，並探索對更多推理引擎的支持，例如 vLLM（vLLM-Ascend），以滿足在昇騰平台上的多樣化模型推理需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c0680304502e35923518c9dcf932256b.png&quot; alt=&quot;image-20250415095544399&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型兼容性檢測&lt;/h3&gt; 
&lt;p&gt;在過往版本中，用戶直接從 Hugging Face 或 ModelScope 搜索任意模型進行部署時，存在一定的失敗可能性。常見原因包括顯存不足、操作系統與推理引擎不兼容、模型架構不被支持、本地路徑配置錯誤等。這些問題不僅浪費時間，還嚴重影響用戶體驗。&lt;/p&gt; 
&lt;p&gt;為瞭解決這一痛點，GPUStack 推出了&lt;strong&gt;模型兼容性檢測機制&lt;/strong&gt;。系統會在部署前自動檢測模型與運行環境的匹配情況，涵蓋模型架構與引擎支持、操作系統兼容性、GPU 資源是否充足、本地路徑是否有效等多個關鍵維度。通過這些檢測，潛在問題能夠被提前識別，並提供清晰提示，幫助用戶避免不必要的部署失敗。&lt;/p&gt; 
&lt;p&gt;我們設定了三個明確的目標：第一，部署前提供清晰的兼容性提示；第二，在滿足條件的情況下將部署成功率提升至 99% 以上；第三，對於特殊需求場景，允許用戶跳過檢測，強制部署，保留靈活性。&lt;/p&gt; 
&lt;p&gt;這項功能特性將持續演進，未來將支持更多檢測項、覆蓋更廣泛的系統環境，不斷完善檢測機制，全面助力用戶在不同平台上實現穩定、高效的模型部署。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fb036e198f11d8e36ec761c749ecca62.png&quot; alt=&quot;image-20250421173053252&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型下載管理&lt;/h3&gt; 
&lt;p&gt;在模型部署過程中，模型文件的統一管理與高效分發始終是用戶關注的核心問題。以往，模型下載通常依賴於實例啓動時自動觸發，既需佔用 GPU 資源，又常常依賴額外的手動操作才能完成下載；同時，GPUStack 也無法管理用戶預先下載到本地路徑的模型文件，導致部署效率低下，管理體驗不佳。&lt;/p&gt; 
&lt;p&gt;為此，GPUStack 引入了&lt;strong&gt;模型文件下載管理&lt;/strong&gt; 模塊：用戶可在 UI 中為多個目標主機手動發起模型的下載任務，且&lt;strong&gt;無需佔用 GPU 資源&lt;/strong&gt;。各節點上已下載的模型文件也可在 UI 中統一可視化管理與部署，進一步提升了部署的靈活性與效率。&lt;/p&gt; 
&lt;p&gt;同時，GPUStack 還支持將本地已有的模型文件路徑添加到 UI 中進行統一管理，適配私有部署、離線環境等多種使用場景。通過這一模塊，既解決了用戶獨立下載模型文件的需求，也使 GPUStack 能夠更好地支持多機分佈式部署，提升了部署效率與多機協同能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0f873b0ef5ec73c42ae118694f3825ee.png&quot; alt=&quot;image-20250415204131503&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型故障自動恢復&lt;/h3&gt; 
&lt;p&gt;在追求高可用性和穩定性的生產環境中，模型推理服務的穩定性至關重要。為了進一步提升這一點，GPUStack 引入了&lt;strong&gt;模型故障自動恢復機制&lt;/strong&gt;！當模型發生故障時，GPUStack 會自動觸發恢復機制，迅速嘗試重新啓動模型，確保服務不中斷。&lt;/p&gt; 
&lt;p&gt;同時，為了避免過於頻繁的無效重啓，GPUStack 採用了&lt;strong&gt;5 分鐘為上限的指數退避延遲機制&lt;/strong&gt;，在故障持續時逐步延遲重啓，避免系統資源的浪費。總體而言，v0.6 版本提供的模型故障自動恢復機制大幅提升了模型服務的容錯能力，讓生產的模型推理更加穩健！&lt;/p&gt; 
&lt;h3&gt;端口暴露優化&lt;/h3&gt; 
&lt;p&gt;在舊版本架構中，每台 Worker 節點需為每個模型實例開放端口訪問，以供 Server 端進行推理請求的轉發。在用戶大規模使用時暴露了一些問題：由於大量端口需要映射，容器啓停緩慢，且在啓動時容易發生端口衝突；防火牆配置容易遺漏，導致推理請求轉發異常。此外，也不支持用戶自定義端口範圍。&lt;/p&gt; 
&lt;p&gt;為此，我們在 v0.6 版本中重構了端口暴露機制：推理請求從 API 入口到模型實例的鏈路現已通過統一的代理轉發，無需再為每個模型實例開放端口訪問。同時優化了端口分配，將端口暴露範圍壓縮超過 96%，顯著降低部署複雜度和運維風險。同時也支持用戶自定義端口配置，使系統能夠靈活適配不同的網絡環境與安全策略，為用戶帶來更簡單、穩定的部署體驗。&lt;/p&gt; 
&lt;h3&gt;增強國際化支持&lt;/h3&gt; 
&lt;p&gt;目前 GPUStack 的用戶遍佈全球上百個國家和地區，隨着 GPUStack 用戶羣體在全球範圍內的持續擴大，我們致力於為不同語言背景的開發者提供一致、便捷的使用體驗。本次 GPUStack 社區用戶貢獻了&lt;strong&gt;俄語&lt;/strong&gt; 和&lt;strong&gt;日語&lt;/strong&gt;支持，標誌着 GPUStack 在國際化進程中的又一重要里程碑。&lt;/p&gt; 
&lt;p&gt;通過持續拓展多語言能力，GPUStack 為全球社區用戶創造了更加包容與高效的使用體驗。未來，我們將繼續深化本地化支持，為全球用戶提供更全面、更優質的服務體驗，加速推動 AI 應用的全球落地與普及。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8781f64407b5d62f1496d53824097f69.png&quot; alt=&quot;image-20250413233340395&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8e1e428e259bcf52136144df288263a0.png&quot; alt=&quot;image-20250413233303590&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;全方位的 UI / UX 優化&lt;/h3&gt; 
&lt;p&gt;在本次版本中，我們對 UI / UX 進行了全方位優化，從信息展示到交互細節，幾乎每一處都經過精心打磨，力求帶來更流暢、更易用的使用體驗。過去幾個月收集的每一條用戶建議，都是此次優化的重要參考。&lt;/p&gt; 
&lt;p&gt;我們始終堅持一個目標：打造業界最好用的模型推理平台，而 GPUStack 正在持續朝這一目標穩步前進。也正因為有用戶的積極反饋，我們才能不斷迭代優化------如果你有任何建議或想法，歡迎隨時向我們提出，我們會認真評估並持續改進。&lt;/p&gt; 
&lt;h2&gt;參與開源&lt;/h2&gt; 
&lt;p&gt;想要了解更多關於 GPUStack 的信息，可以訪問我們的倉庫地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://github.com/gpustack/gpustack&lt;/strong&gt;&lt;/a&gt;。如果你對 GPUStack 有任何建議，歡迎&lt;strong&gt;提交 GitHub issue&lt;/strong&gt; 。在體驗 &lt;strong&gt;GPUStack&lt;/strong&gt; 或提交 issue 之前，請在我們的 GitHub 倉庫上&lt;strong&gt;點亮 Star&lt;/strong&gt; ⭐️關注我們，也非常歡迎大家一起參與到這個開源項目中！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果覺得對你有幫助，歡迎&lt;strong&gt;點贊&lt;/strong&gt; 、&lt;strong&gt;轉發&lt;/strong&gt; 、&lt;strong&gt;關注&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/gpustack/blog/18260677</link>
            <guid isPermaLink="false">https://my.oschina.net/gpustack/blog/18260677</guid>
            <pubDate>Sun, 27 Apr 2025 03:43:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>得物業務參數配置中心架構綜述</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;現狀與痛點&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在目前互聯網飛速發展的今天，企業對用人的要求越來越高，尤其是後端的開發同學大部分精力都要投入在對複雜需求的處理，以及代碼架構，穩定性的工作中，在對比下，簡單且重複的 CRUD 就顯得更加浪費開發資源。目前 scm 供應鏈管理頁面中，存在約 77% 的標準頁面，這些標準頁面裏，還存在着很多類似的參數配置頁面，就是對某一個模型進行增、刪、改、查、導入、導出進行類似的操作，這種開發工作技術含量較低，而且相對耗費人力。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;什麼是業務參數配置中心&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;參數配置中心，是一個能夠通過配置的方式，快速生成前端頁面以及配套增、刪、改、查、導入、導出服務的配置平台，它與得物內部低代碼前端頁面平台 wizard 相互集成，參數配置中心提供後台增刪改查服務，wizard 輸出對應的前端頁面代碼，並可以支持用戶自定義修改。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;使用場景&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;針對讀多寫少的簡單的單表的增刪改查；&lt;/li&gt; 
 &lt;li&gt;業務中需要交給運營來修改的複雜 ark 配置（簡單配置除外），可以嘗試使用業務參數配置中心接入，減少人為修改 JSON 可能產生的錯誤，導致系統無法編譯進而產生故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;比如如下的 JSON：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[{&quot;position&quot;:&quot;1&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;2&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;3&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;4&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;5&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;6&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;7&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;8&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;業務參數配置中心極速體驗&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;後台服務搭建流程，以及數據錄入&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據讀取可以通過參數配置中心的 SDK，輸入自己的業務入參以及自己的業務出參，SDK 會自動根據方案下的參數以及用戶的輸入條件，查詢出對應的參數信息：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-95529e5439a558b65e0757f2e1313155752.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從上面的快速體驗裏可以看到很多名詞，你一定有會有下面的疑問：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-964c6ee7e450e7cce90376eddb00b05c04f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、整體架構與原理&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;實現思路&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;首先我們對這種普通的頁面進行初步剖析：頁面中總體包含搜索條件、靜態展示字段以及操作欄，搜索條件一般是靜態字段的子集，並且操作欄的功能一般都類似，所以為了能夠結構化地構造出這樣的頁面，我們可以將靜態展示字段進行進一步抽象：比如元素、維度、參數、方案、參數實例。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1adfd37a09e81f9bf0438a2bed718c19a80.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;構成頁面的每一個業務字段，統稱元素，因為有些字段是大家常用的（比如倉庫，品牌，一級類目，省份等），它有自己的字段名稱，以及取值範圍。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;維度&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一條記錄一定有能夠標註其唯一性的信息，可能是一個字段或者是多個字段，在參數中心裏，能確定一條記錄唯一性的所有字段就叫做維度，維度這個概念在參數中心裏很重要，它是不可變的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參數&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在業務發展過程裏，可以改變值的字段，就叫參數，也可以説一條記錄裏，除了維度，都可以叫做參數。&lt;/p&gt; 
&lt;p&gt;綜合維度和參數，舉個例子，比如商品信息，商品 ID 就是維度，商品售價、折扣率就是參數。或者醫院掛號系統，科室 ID 就是維度，掛號費，出診時間就是參數。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一個參數方案它管理着一個場景下的業務配置，可以簡單理解一個方案就代表着一個頁面，包含了上述我們説的維度以及參數，並且指定了可以指定哪些字段為搜索條件，哪些是必填字段，哪些字段可以多選。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參數實例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;描述好方案並生成頁面後，實際產生的業務配置數據，我們稱之為參數實例。&lt;/p&gt; 
&lt;p&gt;經過剛才對頁面元素的解剖，大家會發現搭建一個這樣的頁面，猶如建房子一樣，維度與參數是最基礎的木料，創建方案就是設計建造的過程，參數實例就是一個個真實的房間，所以業務參數配置中心整體產品思路如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-54cf2fc71dbf64169277bd863672f638b30.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;整體架構&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;通過上文的介紹，我們介紹了業務參數配置中心最核心的概念，接下來我們看看整體的架構設計。我們針對這些最核心的概念，來設計實現這些業務功能的架構、核心包含領域模型、領域服務、應用服務以及基礎設施層需要的存儲部件，以及外部可以整合的導入導出框架、日誌框架（外部依賴的框架也可以自己實現）、核心的元素維護、方案維護，存儲設計好之後，我們就需要一個 SDK，可以讓用戶訪問到我們的數據。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f29f79f77a54e147851172489afd9765082.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;系統的實體關係圖如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4876084e664581f0f46677ab3e1b89d59d7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過上文我們可以初步瞭解到整體的架構設計，那麼每一個子模塊我們如何實現？接下來我們分析更加細節的原理。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心原理&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如何設計存儲的細節是這個系統的一大挑戰，因為既要兼顧頁面的靈活變動，也要兼顧數據整體的一致性不受影響，同時也要兼顧整體數據的查詢性能，下面的小節列出了所有這些核心的挑戰點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;存儲流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每一個頁面的字段都不一樣，我們是怎麼存儲的？&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-072aa230f23621ba48c937b8f7db995c249.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從上面的兩個頁面可以看到，因為頁面的字段變化多端，所以我們的思考是，必須採用抽象存儲的方式來應對，核心用一張，大寬表存儲，其中包含很多抽象列，每一個抽象列在不同的方案下，業務含義不同。&lt;/p&gt; 
&lt;p&gt;同時把方案的元數據：維度、參數、以及功能性設置（如每個字段是否可以刪除，是否需要多選）單獨存儲，每個方案下的大寬表裏的抽象列的業務含義，就存儲在這些元數據表中。&lt;/p&gt; 
&lt;p&gt;同時為了應對大批量的查詢，我們引入了 OLAP 的數據庫，對於在應用內部的單點查詢，我們走 MySQL 實現，如果運營後台針對某個字段做大批量查詢，則可以用 OLAP 數據庫來緩解查詢壓力。&lt;/p&gt; 
&lt;p&gt;下面是存儲的整個過程以及舉例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68a28fece8de3ef9c82fc7843e8110e2a2e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SDK 查詢流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因為在業務參數使用時，各個業務方有自己的業務對象，所以我們在 SDK 中集成了反射的能力，可以避免用戶直接感知到底層的抽象存儲，查詢的流程使用上比較簡單，一共分為三步，第一步為自定義 request，第二步自定義 response，第三步調用 SDK 方法獲取參數實例，比如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;定義 request：&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigRequest implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置類型

  */

 private String configType;

 */***

  * 設備編號

  */

 private String deviceNo;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定義 response&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigResponse implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置類型

  */

 private String configType;

 */***

  * 設備編號

  */

 private String deviceNo;



     */***

  * 配置明細

  */

 private List&amp;lt;CameraConfigDto&amp;gt; configValueList;



     [@Data](https://my.oschina.net/difrik)

 public static class CameraConfigDto implements Serializable {

     private String position;

     */***

      * 白平衡 (Red)

      */

     private BigDecimal red;

     */***

      * 白平衡 (Blue)

      */

     private BigDecimal blue;

     */***

      * 白平衡 (Green)

      */

     private BigDecimal green;

     */***

      * 亮度 (Brightness)

      */

     private BigDecimal brightness;

     */***

      * 自動曝光時間上限 (us)

      */

     private BigDecimal autoExposureTimeUpperLimit;

     */***

      * 採集幀率

      */

     private BigDecimal acquisitionFrameRate;

     */***

      * 增益自動開關 (us)

      */

     private String gainAuto;

     */***

      * 增益自動上限

      */

     private BigDecimal gainAutoUpperLimit;

     */***

      * 增益自動上限

      */

     private BigDecimal gainAutoLowerLimit;

 }
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;調用 SDK 的服務方法查詢&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigRequest pinkDeviceCameraConfigRequest = new PinkDeviceCameraConfigRequest();&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setConfigType(&quot;DEVICE_NO&quot;);&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setDeviceNo(&quot;123@LuSun&quot;);&lt;/p&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 單個查詢場景&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigResponse response =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParams(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;,

      pinkDeviceCameraConfigRequest,

      PinkDeviceCameraConfigResponse.class);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 批量查詢場景&lt;/p&gt; &lt;p&gt;PageQueryOption pageQueryOption = new PageQueryOption();&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageIndex(1);&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageSize(200);&lt;/p&gt; &lt;p&gt;PageInfo&amp;lt;PinkDeviceCameraConfigResponse&amp;gt; paramsPage =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParamsPage(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;, 

     pinkDeviceCameraConfigRequest, 

     PinkDeviceCameraConfigResponse.class,

     pageQueryOption);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;獲得結果&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-19953d23e8dcd9b90b57575b8fc6c5533ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;整體查詢實現原理如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68822ebba4f5d690e41c18c156dffdad174.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 目前整個服務的性能在 10+ms 左右：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f86b118721761e37edb0d80428c83fa7355.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參數優先級實現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為什麼會有參數優先級這個功能？&lt;/p&gt; 
&lt;p&gt;比如有一個場景，要維護一個供應鏈系統中的補貨參數：安全庫存，低於這個安全庫存的時候，要通知商家進行補貨，整個供應鏈裏有 100 個倉庫，20 個一級類目，200 個二級類目，2000 個三級類目，涉及到 500 個品牌，要維護每一個商品的安全庫存，你會怎麼實現？&lt;/p&gt; 
&lt;p&gt;你一定不會把 100 倉庫_2000 類目_500 品牌 = 1000000000 種可能全都設置一遍參數，對你來説，重點類目，要單獨詳細配置安全庫存，非重點類目可能只需要管控到一級或者二級類目即可，這樣你所需要的配置會大大減少。那麼參數的決策就需要遵循一定的規則，比如:&lt;/p&gt; 
&lt;p&gt;有倉庫+一級類目+二級類目+三級類目，的安全庫存，優先取；&lt;/p&gt; 
&lt;p&gt;如果取不到，則取倉庫+一級類目+二級類目的安全庫存；&lt;/p&gt; 
&lt;p&gt;再取不到，取倉庫+一級類目的安全庫存。&lt;/p&gt; 
&lt;p&gt;比如：&lt;/p&gt; 
&lt;p&gt;DN 倉，鞋 安全庫存 100&lt;/p&gt; 
&lt;p&gt;DN 倉，鞋-運動鞋，安全庫存 500&lt;/p&gt; 
&lt;p&gt;DN 倉，鞋-運動鞋-籃球鞋，安全庫存 1000&lt;/p&gt; 
&lt;p&gt;那如果一個商品是籃球鞋的話，則會命中安全庫存 1000 的規則，如果是登山鞋的話，只能命中運動鞋的規則取 500，如果是高跟鞋，則只能取 100 的安全庫存。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（事實上這種補貨規則要詳細的多，這裏只是方便大家理解需求，並不是真正的參數）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;也就是説，當用戶的入參同時可能命中多條參數的時候，需要通過優先級來判斷應該返回哪個參數。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-92bbffb30b7b6f12d6b8fa4717437f376d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了加速查詢，系統在設計時添加了兩層緩存：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-129d351a3be37ca0cf02b4472de6fcd50e8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 當後台數據發生變化時，會將對應的緩存進行失效。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-821ca41cc55e1456a0ad3fb0ba5dc76247f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素多選處理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;維度多選場景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-28b192d9ccc63092c15fcc0f12187ddf449.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;參數多選場景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e4a1bdf71195372e13f56ab0aa27813e3ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;既要保證維度唯一，又要保證能正常搜索，以及展示，如何實現？業務參數配置中心引入了一個&quot;組&quot;的概念，是將同屬於一行的參數實例，歸為一個組，這個組是最小的新建、編輯單位。&lt;/p&gt; 
&lt;p&gt;對於新增流程如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd67e7858a3927f9960d4c2d364c0dc4a6a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;對於修改流程，如下圖所示： &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ed29af351bef248291bc76b841bafcedcae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素範圍查詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;頁面中的字段，我們統稱為元素，只要是字段，一定有它的取值範圍，我們平衡了用戶使用成本以及系統性能，將字段取值類型劃分成了四種：&lt;/p&gt; 
&lt;p&gt;1）枚舉類元素&lt;/p&gt; 
&lt;p&gt;2）dubbo 全量接口元素&lt;/p&gt; 
&lt;p&gt;3）dubbo 單點查詢接口元素&lt;/p&gt; 
&lt;p&gt;4）自定義文本元素&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;枚舉元素由用戶手動在頁面創建，一般幾十個以內為佳，創建成本不高，比如經常用到的 &quot;是&quot;，&quot;否&quot;，或者比如單據類型等等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 全量接口元素，一般是幾十到上百個的體量，比如一級類目，倉庫等，地址。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 單點查詢接口，一般是幾千到幾萬體量的取值範圍，無法直接在內存裏存儲所有枚舉，比如品牌等。只能通過兩個接口來完成搜索以及數據的展示，比如&quot;品牌 ID &amp;gt;品牌名稱&quot;接口，和 &quot;品牌名稱-&amp;gt;品牌 ID&quot; 接口。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自定義文本，非枚舉類字段，可以選擇使用自定義文本來承接。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;比如以下是可以通過 dubbo 接口全量獲取配置的元素：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-265ea951a69d044a0e77e39825e029716fc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;與 dubbo 全量接口的錄入類似，單點搜索接口與全量接口不同的點在於，單點接口需要保留一個變量，給系統查詢時調用，比如&quot;通過品牌 ID 查詢品牌名稱&quot; 和 &quot;通過品牌名稱查詢品牌 ID&quot; ，需要留給系統調用的入參，用#{var}代替。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-154171e3bd51e9ec195984b8fc5f2408f3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當然，有時元素的範圍並不是隻取決於它自己，可能也取決於同頁面裏其他元素的取值，比如説有一個質量原因的字段，當一級類目為鞋時，取值為 A、B、C，為服裝時為 D、E、F，這是元素範圍在設置時，就需要將對應的元素入參維護到其中，比如：&lt;/p&gt; 
&lt;p&gt;| 接口入參類型 | 接口入參取值 | | --- | --- | | com.d.s.q.s.d.r.ConfigRequest | {&quot;ruleVersion&quot;:#{ruleVersion},&quot;spuId&quot;:#{spuId}} |&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;導入導出&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是導入處理流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-72582bd979727a7d8718ed80cfe71b8973e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了照顧使用人員的體驗，再多數導入場景時，我們的導入文件都用的是文案，而不是後台存儲的數值，比如導入的字段包含類目時，導入文件輸入的是鞋、服裝、美妝等文案，而不是 2、3、4 這樣存儲在後台的數值，那麼勢必這裏就會有將文案轉換成數值的過程，這其中就用到了 2.3.5 章節中提到的元素範圍查詢使用的接口，當然，對於需要其他元素作為入參的元素，我們默認每個元素左邊的元素都可以作為當前元素的入參。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;業務參數配置中心不適合做什麼？&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;有極為複雜的 UI 交互&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;較為複雜的校驗邏輯（長期計劃支持）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高頻寫入場景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;應用查詢參數時以非&quot;=&quot;條件匹配&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;三、總結與展望&lt;/h1&gt; 
&lt;p&gt;本文簡要描述了業務參數配置中心的設計思路，參數配置中心配套生成增、刪、改、查、導入、導出服務，並且結合前端低代碼平台自動生成前端代碼，平台目前業務參數中心已經有 40+個場景接入節省了大量的工作人日，能夠讓研發人員，擺脫低效的 CRUD，更專注於自己內部業務邏輯的開發。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;對於目前系統的未來規劃：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;持續增加 SDK 的查詢靈活性：包括不限於批量代參數優先級對數據進行查詢、通過 SDK 分頁查詢全量參數、對系統字段吐出方便業務方使用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持續增加對方案定義的靈活性：支持更多的元素範圍的定義，比如 HTTP 等調用方式；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持續增加對元數據定義的靈活性：部分元數據的取值可能需要同頁面中的另一個元素的取值來決定，所以在取值渲染時，可以保留給其他元素的佔位符，進而隨着頁面的動態變動，後台取值也可以動態變動。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539092%26idx%3D1%26sn%3D6fc02ccebc5c838f143d5128691a635b%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物增長兌換商城的構架演進&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539014%26idx%3D1%26sn%3D90a168b730490ae84a0917863ad3e077%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物自研 DGraph4.0 推薦核心引擎升級之路&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538986%26idx%3D1%26sn%3Db6b82a790a3c696bce27704472e799b2%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;大語言模型的訓練後量化算法綜述 | 得物技術&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538473%26idx%3D1%26sn%3D0a83895ef8dcd555e9926151a989b663%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何合理規劃 Elasticsearch 的索引｜得物技術&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538394%26idx%3D1%26sn%3D51f91adc969a03f7c8baa31f6cc39c67%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;DPP 推薦引擎架構升級演進之路｜得物技術&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;文 / sakuta&lt;/h4&gt; 
&lt;p&gt;關注得物技術，每週新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18230829</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18230829</guid>
            <pubDate>Sun, 27 Apr 2025 03:24:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Anthropic 向逆向工程 Claude Code 的開發者發送刪除通知</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F25%2Fanthropic-sent-a-takedown-notice-to-a-dev-trying-to-reverse-engineer-its-coding-tool%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch 報道稱&lt;/a&gt;&lt;/u&gt;，在 Anthropic 的 Claude Code 和 OpenAI 的 Codex CLI 兩款「智能體」式 AI 編程工具的較量中，後者獲得了更多開發者的青睞。部分原因在於，Anthropic 向一位試圖逆向工程 Claude Code 的開發者發出了刪除通知，而 Claude Code 的使用許可要比 Codex CLI 更加嚴格。&lt;/p&gt; 
&lt;p&gt;Claude Code 和 Codex CLI 都是讓開發者能夠利用雲端的 AI 模型來完成各種編程任務的工具，功能相似。兩家公司幾乎在同一時期發佈了這兩款工具，爭奪開發者的關注。&lt;/p&gt; 
&lt;p&gt;Codex CLI 的源代碼採用 Apache 2.0 許可證，允許分發和商業使用。相比之下，Claude Code 則依賴於 Anthropic 的商業許可證，限制了「在未獲得公司明確許可的情況下對其進行修改」的方式。&lt;/p&gt; 
&lt;p&gt;另外，Anthropic 對 Claude Code 的源代碼進行了「混淆」，意味着其源代碼並不容易獲得。當有開發者通過反混淆手段將代碼發佈到 GitHub&amp;nbsp;時，Anthropic &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgithub%2Fdmca%2Fblob%2Fmaster%2F2025%2F03%2F2025-03-10-anthropic.md&quot; target=&quot;_blank&quot;&gt;提出了 DMCA 投訴&lt;/a&gt; ——&amp;nbsp;這是一份要求刪除代碼的版權通知。&lt;/p&gt; 
&lt;p&gt;社交媒體上的開發者們對 Anthropic 此舉&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FtheLance%2Fstatus%2F1914458771679486389&quot; target=&quot;_blank&quot;&gt;非常不滿意&lt;/a&gt;，認為這種做法遠不如 OpenAI 發佈 Codex CLI 時的開放態度。在 Codex CLI 發佈後的短短一週內，OpenAI 就將幾十條開發者建議納入了工具的代碼庫，其中包括一個讓 Codex CLI 能調用來自其他競爭者（包括 Anthropic）的 AI 模型的功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2820&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/105716_o6ne_2720166.png&quot; width=&quot;1289&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Anthropic 尚未對此事作出回應。Claude Code 仍處於測試階段，並且存在一些 bug。而在未來，Anthropic 有望以寬鬆的許可證發佈源代碼。公司對源代碼進行混淆的原因多種多樣，其中之一便是出於「安全」考慮。&lt;/p&gt; 
&lt;p&gt;對於 OpenAI 來説，這多少是一次公關上的勝利，因為最近幾個月，OpenAI 一直迴避開源發佈，轉而推出專有、封閉的產品。這可能標誌着實驗室方法的一個更廣泛的轉變；OpenAI 首席執行官 Sam Altman 今年早些時候表示，他認為公司在開源問題上一直站在「歷史錯誤的一邊」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</guid>
            <pubDate>Sun, 27 Apr 2025 02:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Transformers 作者：未來互聯網將演變為 AI Agent 網絡</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，Transformers 合著者 Illia Polosukhin 接受了 a16z 的專題採訪，並在交流中分享了自己對於 AI、Agent 等方面的觀點。&lt;/p&gt; 
&lt;p&gt;開篇，Illia 就分享了自己對現有 AI Agent 的看法。他表示，據團隊觀察，大量用戶對需要複雜規劃的場景特別感興趣。但這種局面在未來將會反過來：AI 助理將會主動提出方案給用戶，用戶也僅需要做出方向性選擇即可。對於這種 AI 何時面世，Illia 預測在未來一年內，就會出現首批成熟應用的場景。&lt;/p&gt; 
&lt;p&gt;對於「死亡互聯網理論」，Illia 則坦言：雖然開放網絡正在消亡，但並非網絡上的機器人數量過多，而是因為平台容易被垃圾信息攻陷。對此他認為智能 Agent 能夠為人類進行信息把關，未來 AI 助手也會成為互聯網「垃圾分揀員」：能夠為用戶提供上下文鏈接，如實指出錯誤信息並揭露事實真相。&lt;/p&gt; 
&lt;p&gt;另外，主持人問及「未來將會有多少 AI Agent？與人類的數量比例又是如何？」時，Illia 則表示，未來每個人都會擁有屬於自己的 AI 助手，而 AI 助手的背後可能運行着數十個子 Agent 項目，因此這會構建起一個龐大的 Agent 網絡，並且每個人都將如同獲得一套「按需助理系統」。&lt;/p&gt; 
&lt;p&gt;主持人還特別向&amp;nbsp;Transformers 作者問起了對 DeepSeek 的看法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Robert:&lt;/p&gt; 
 &lt;p&gt;您如何看待 DeepSeek 最新發布的高性能開源模型？相比其他選項，它不僅表現優異且成本更低，更特別的是由中國對沖基金以開源方式推出。&lt;/p&gt; 
 &lt;p&gt;Illia:&lt;/p&gt; 
 &lt;p&gt;首先這確實是激動人心的突破。他們在有限硬件上實現大規模高性能模型訓練的工程能力令人驚豔，證明優秀工程實踐能大幅降低成本。中國模型訓練成本正在快速下降，但最關鍵的創新在於：他們提出了一種極其簡單的強化學習方法——這個方法具有普適性，無論是 10 億還是 70 億參數模型都能快速獲得優異效果。&lt;/p&gt; 
 &lt;p&gt;這種「階躍式創新」讓我想起 Transformer 的誕生——原理簡單、開箱即用、人人可復現。&lt;/p&gt; 
 &lt;p&gt;坦白講，這類基礎方法論本應自由傳播 (畢竟只是公式或原理)，但必須承認 DeepSeek 團隊極其專業，他們憑藉後發優勢規避了許多早期問題。現在更重要的機遇在於：藉助可驗證計算技術，我們可以訓練用戶或社區擁有的模型——確切知道訓練數據來源。&lt;/p&gt; 
 &lt;p&gt;當前所有開源模型都只公開參數，無人知曉訓練數據構成，即便公佈也無法驗證真偽。&lt;/p&gt; 
 &lt;p&gt;區塊鏈領域現在有機會聯合訓練一個「加密透明」的開源模型：所有人都能驗證數據輸入、訓練過程及潛在偏差，確保沒有隱藏後門或惡意代碼。這樣的模型才能真正成為 AI 時代可信賴的基礎設施。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhDgE_7fIb-ps4xSOuced_A&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/hDgE_7fIb-ps4xSOuced_A&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347060</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347060</guid>
            <pubDate>Sun, 27 Apr 2025 02:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>馬斯克旗下 xAI 擬融資 200 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-26%2Felon-musk-s-xai-holdings-is-in-discussions-to-raise-20-billion&quot; target=&quot;_blank&quot;&gt;彭博社援引知情人士透露&lt;/a&gt;&lt;/u&gt;，馬斯克旗下 xAI 目前正與投資者洽談，計劃籌集大約 200 億美元資金，用於其新合併的人工智能初創公司和社交媒體業務。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/102209_yrAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;數據提供商 PitchBook 的數據顯示，&lt;strong&gt;如果成功，這筆交易將成為歷史上第二大創業公司融資&lt;/strong&gt;，僅次於今年早些時候 OpenAI 的 400 億美元融資。據知情人士透露，憑藉此輪洽談中的融資，xAI 的估值超過 1200 億美元。&lt;/p&gt; 
&lt;p&gt;值得一提的是，該輪融資可能有助於償還馬斯克在將 X 前身 ——Twitter 私有化後所承擔的一部分債務。知情人士透露，上述債務一直對 X 構成財務壓力。此前彭博社報道指出，僅在今年 3 月，X 就支付了約 2 億美元的債務服務費用，截止 2024 年底，其年度利息支出將超過 13 億美元。&lt;/p&gt; 
&lt;p&gt;據瞭解，儘管談判仍處於初期階段，但 xAI 目標是未來幾個月內籌集資金。知情人士表示，融資規模可能會超過最初的 200 億美元，具體金額和條款尚未確定。&lt;/p&gt; 
&lt;p&gt;報道指出，這一大規模融資凸顯了投資者對人工智能公司日益增長的興趣，同時也顯示了馬斯克作為商業巨頭和政治影響力人物的地位。儘管特斯拉的市值有所下滑，但馬斯克的其他企業仍在蓬勃發展，例如馬斯克的火箭公司 SpaceX，於去年一次私募交易中被估值為 3500 億美元，成為歷史上最有價值的初創公司。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</guid>
            <pubDate>Sun, 27 Apr 2025 02:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節跳動推出 QuaDMix：大型語言模型預訓練數據質量與多樣性的統一框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字節跳動近日宣佈推出其全新的數據選擇框架 QuaDMix，旨在提升大型語言模型（LLM）預訓練的效率和泛化能力。眾所周知，模型的訓練效果受基礎數據集的質量和多樣性影響很大。然而，傳統的數據篩選方法往往將質量和多樣性視為兩個獨立的目標，先進行質量過濾，再進行領域平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3b5dc2134907308fa5f27fb6e2823c7d4cf.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;這種逐步優化的方式忽略了質量與多樣性之間的複雜相互關係。優質數據集往往存在領域偏差，而多樣化的數據集可能會降低質量。因此，在固定的訓練預算下，如何同時優化這兩個維度以最大化模型性能，成為了一個亟待解決的難題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;QuaDMix 框架的主要運作分為三個階段：特徵提取、質量聚合和質量 - 多樣性感知採樣。在初始階段，每個文檔都會被標註領域標籤和多項質量評分。通過歸一化和合並這些評分，生成一個綜合質量分數。接着，系統通過基於 sigmoid 的函數採樣文檔，優先考慮高質量樣本，並通過參數化控制確保領域平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;為了優化模型，QuaDMix 在不同參數設置下訓練了數千個代理模型。通過這些代理實驗訓練的迴歸模型可以預測性能結果，從而識別出最佳採樣配置。這種方法使得在高維參數空間中進行結構化探索成為可能，從而更好地將數據選擇與下游任務對接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;實驗結果顯示，QuaDMix 在 RefinedWeb 數據集上進行的驗證實驗中，與多種基線模型相比，平均得分達到了 39.5%。這些基線模型包括隨機選擇、Fineweb-edu、AskLLM、DCLM 等。實驗結果表明，聯合優化策略在整體表現上始終優於單獨關注質量或多樣性的方法。此外，經過優化的數據混合更能提升特定下游任務的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;QuaDMix 為大型語言模型的預訓練數據選擇提供了一個系統化的解決方案，解決了長期以來同時優化數據質量與多樣性的挑戰。通過結合質量聚合和領域感知採樣，QuaDMix 建立了一種可擴展的方法論，提升了 LLM 預訓練的效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347054</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347054</guid>
            <pubDate>Sun, 27 Apr 2025 02:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>月暗開源 Kimi-Audio，單一框架執行多種語音任務；照片秒變可對話數字人，LemonAI 推出 Slice Live 丨日報</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-42daa67a23199a5e38b5a98abb2517572ae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;開發者朋友們大家好：&lt;/p&gt; 
&lt;p&gt;這裏是 &lt;strong&gt;「RTE 開發者日報」&lt;/strong&gt; ，每天和大家一起看新聞、聊八卦。我們的社區編輯團隊會整理分享 RTE（Real-Time Engagement） 領域內「有話題的 &lt;strong&gt;技術&lt;/strong&gt; 」、「有亮點的 &lt;strong&gt;產品&lt;/strong&gt; 」、「有思考的 &lt;strong&gt;文章&lt;/strong&gt; 」、「有態度的 &lt;strong&gt;觀點&lt;/strong&gt; 」、「有看點的 &lt;strong&gt;活動&lt;/strong&gt; 」，但內容僅代表編輯的個人觀點，歡迎大家留言、跟帖、討論。&lt;/p&gt; 
&lt;p&gt;本期編輯：@趙怡嶺、&lt;a href=&quot;https://my.oschina.net/u/862736&quot;&gt;@鮑勃&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;01.有話題的技術&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、百度推出文心 4.5 Turbo 和深度思考模型 X1 Turbo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-041ced382bdd171c05e0c36d4df884fc4c9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 25 日，在面向開發者的 Create 大會重磅推出兩款全新模型：文心 4.5 Turbo 和深度思考模型 X1 Turbo。&lt;/p&gt; 
&lt;p&gt;兩款模型主打多模態、強推理和低成本。百度旗下新搜索智能助手文小言也宣佈全面接入，免費向用戶開放，即日起用戶打開文小言 APP 即可使用。&lt;/p&gt; 
&lt;p&gt;文心大模型 4.5 Turbo 進一步強化了多模態能力。在多個基準測試集中，文心 4.5 Turbo 多模態能力已與 GPT-4.1 持平，甚至在部分維度優於 GPT-4o。&lt;/p&gt; 
&lt;p&gt;而文心大模型 X1 Turbo 則在 4.5 Turbo 的基礎上進行了「深度思考」升級。無論是問答能力、內容創作、邏輯推理，還是工具調用、多模態處理，X1 Turbo 均實現全方位增強，整體表現領先於 DeepSeek R1 和最新版本 V3。(@APPSO)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、GPT-4o 模型再次升級&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-768e3d496ec29c08bc8237c168b4e93a021.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 5 日，OpenAI 稱對 GPT 4o 模型進行了升級。&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman 發文宣佈 GPT-4o 迎來能力改進，具體如下：&lt;/p&gt; 
&lt;p&gt;新升級的 GPT 4o 模型個性化更強，優化了模型保存「記憶」的時機，並增強其在 STEM 領域的問題解決能力，還對其響應方式進行了細微的調整，使其更加主動，能夠更好地引導對話走向富有成效的結果，同時對回覆的細節進行了微調，讓 GPT-4o 在各種任務中的表現更直觀、更易用，（&lt;a href=&quot;https://my.oschina.net/u/104417&quot;&gt;@ai&lt;/a&gt; 寒武紀、APPSO）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、總體性能第一：月之暗面開源全新音頻基礎模型 Kimi-Audio，橫掃十多項基準測試&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a5ea5773cd4c3850cedde7d0db1f67f2923.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 26 日，Kimi 發佈了新的開源項目 ------ 一個全新的通用音頻基礎模型 Kimi-Audio，支持語音識別、音頻理解、音頻轉文本、語音對話等多種任務，在十多個音頻基準測試中實現了最先進的 （SOTA） 性能。結果顯示，Kimi-Audio 總體性能排名第一，幾乎沒有明顯短板。&lt;/p&gt; 
&lt;p&gt;Kimi-Audio 採用了集成式架構設計，包括三個核心組件 ------ 音頻分詞器（Audio Tokenizer）、音頻大模型（Audio LLM）、音頻去分詞器（Audio Detokenizer）。&lt;/p&gt; 
&lt;p&gt;這一架構使 Kimi-Audio 能夠在單一模型框架下，流暢地處理從語音識別、理解到語音對話等多種音頻語言任務。同時，音頻分詞器還提取連續的聲學向量，以增強感知能力。（@機器之心）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、Cognition Labs 推出 DeepWiki 項目，可為 GitHub 倉庫提供 AI 驅動的實時交互式文檔&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-52eb7173b2ff5edf181b86039e133aa6f11.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（圖片來源：deepwiki 官網）&lt;/p&gt; 
&lt;p&gt;對於開源項目，這項服務完全免費，甚至無需註冊。訪問 deepwiki.com，探索已經收錄的熱門開源項目的 Wiki，或者把正在瀏覽的任何 GitHub 倉庫 URL 中的 github.com 替換成 deepwiki.com，即可無縫跳轉到該倉庫的 DeepWiki 頁面。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;對話式文檔： 直接向代碼庫「提問」，DeepWiki 會嘗試理解問題並給出文檔級的解答&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度研究 （Deep Research）： 對於複雜問題，可以開啓此功能，讓 AI Agent 進行更深入的分析和回答&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;按需索引： 如果關注的公開倉庫還沒被收錄，可以請求 DeepWiki 索引&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;私有倉庫支持： 對於私有倉庫，可以通過註冊 Devin 賬戶（devin.ai）來獲得服務&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;輕鬆分享： 生成的 Wiki 頁面和問答結果都可以通過鏈接分享，方便團隊成員保持信息同步（@AI 寒武紀）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;5、Adobe 發佈商用級 AI 圖像生成模型 Firefly Image 4 系列&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Adobe 更新發布了 Firefly Image 4 和 Firefly Image 4 Ultra 兩大 AI 圖像生成模型，支持最高 2K 分辨率輸出。&lt;/p&gt; 
&lt;p&gt;這兩款模型均基於 Adobe Stock 等授權內容以及公共領域數據訓練，如侵犯版權，可以讓 Adobe 賠償。（@三花 AI）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、MLX-Audio: 蘋果芯片上的高效語音合成模型庫，提供 TTS REST API&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MLX-Audio 是一個基於 Apple MLX 框架構建的文本轉語音 （TTS） 和語音轉語音 （STS） 庫，專為 Apple Silicon 芯片優化，提供出色的語音合成性能。&lt;/p&gt; 
&lt;p&gt;核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;蘋果芯片加速： 在 M 系列芯片上實現快速推理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多語言支持： 支持多種語言；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;語音定製： 提供豐富的語音定製選項；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;語速調節： 0.5x 到 2.0x 的語速調節範圍；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可視化交互： 具有 3D 音頻可視化的交互式網頁界面；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;REST API: 提供用於 TTS 生成的 REST API；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能優化： 支持量化以優化性能；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文件快速訪問： 通過 Finder/資源管理器集成直接訪問輸出文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;支持模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Kokoro: 多語言 TTS 模型，支持多種語言和語音風格。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CSM （Conversational Speech Model） : Sesame 的對話語音模型，支持文本轉語音和使用參考音頻樣本進行聲音定製。(@GitHub)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02.有亮點的產品&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、AceditAI 面試教練：實時轉錄、問題檢測和個性化回覆等功能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Acedit 是一款 Chrome 瀏覽器插件，作為你的 AI 面試教練：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;智能練習：&lt;/strong&gt; 上傳職位描述和簡歷，Acedit 即可生成個性化的練習問答，並通過 AI 模擬面試助你充分準備。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;實時 AI 建議：&lt;/strong&gt; 在 Google Meet、Zoom、Teams 等在線面試平台，Acedit 能讀取面試問題，並結合你的簡歷、領英資料等信息，提供實時 AI 生成的答案建議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;定製求職信：&lt;/strong&gt; 內置 AI 工具，輕鬆生成個性化求職信。(@ProductHunt)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2、LemonAI 推出 Slice Live：照片秒變實時數字人&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Lemon Slice Live 是一款實時音視頻 AI 數字人模型，讓你體驗前所未有的視頻聊天。基於擴散變換模型 （DiT） 技術，它能將任何角色圖像立即轉化為支持 10 多種語言的交互式視頻通話。無需訓練或設置特定角色模型，上傳一張照片即可與任意角色流暢對話，兼容寫實、卡通、繪畫等多種風格，支持高達 25 FPS 的實時渲染。（@三花 AI、LemonAI 官網）&lt;/p&gt; 
&lt;h2&gt;03.有態度的觀點&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Anthropic 研究員：從理論上講 AI 有可能產生意識&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;日前，Anthropic 研究員 Kyle Fish 受公司邀請做了一期訪談節目，其中他在節目中表示，理論上講 AI 是可能產生意識的。&lt;/p&gt; 
&lt;p&gt;Kyle Fish 認為，雖然當前 AI 的整體系統與人類大腦在功能和結構上存在差異，但如果能夠以足夠高的保真度，去模擬人腦，其中包括模擬神經遞質分子的作用，那麼從理論上講，AI 有可能產生意識。&lt;/p&gt; 
&lt;p&gt;他還進一步表示，如果將大腦中的神經元逐個被替換成芯片，在替換過程中保持個體的行為和功能的不變，那麼替換完成後，個體的意識體驗可能不會發生太大變化。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Anthropic 為了探索模型更深層次的體驗與潛在意識，啓動了一項研究計劃，旨在調查 AI 模型是否能夠有潛在的偏好和痛苦跡象，並且去判斷這是否符合道德。(@APPSO)&lt;/p&gt; 
&lt;h2&gt;04.有看點的活動&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、腦機接口智能技術應用挑戰賽正式開啓報名！( 04.26-05.28)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b36b85455f3a09c836074daef9eb7d38a3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（圖片來源：智姬）&lt;/p&gt; 
&lt;p&gt;腦機接口智能技術應用挑戰賽（AI-Based BCI Tech Competition）是由中關村領智青年人才自主創新發展中心聯合姬械機科技集團發起的，以腦與智能（Brain and Al）為主題方向的人工智能腦接口（Al-based BCl）前沿創新技術與應用競賽。&lt;/p&gt; 
&lt;p&gt;通過本次技術比賽為腦機科技創新者提供系統性技術支持與創新資源對接，重點推進腦機接口技術問題的解決，同時實現腦機接，口的行業應用示範與產業化落地創新探索。&lt;/p&gt; 
&lt;p&gt;賽題發佈與比賽報名 ：04/26 - 05/28&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;參賽團隊報名審核 ：05/28 - 06/08（截止報名） 比賽形式：（1）線下自主賽題解答； （2） 線上提交賽題答案；（3）現場場答辯分享；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;一等獎 1 名獎金 30 萬 （第一名） ；&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二等獎 2 名獎金 15 萬 （第二名、第三名） ；&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三等獎 5 名獎金 8 萬 （第四名、第五名、第六名、第七名、第八名） 。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目前官方已發佈&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbvxYvC8jiE4xc56QP1ihig&quot; target=&quot;_blank&quot;&gt;相關賽題簡介&lt;/a&gt;：基於不同的通道腦機，完成與之相關的技術題、應用題。（@智姬）&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fd190df182060c949e714b0be523d5431a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多 Voice Agent 學習筆記：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSqXLZvq_zwWDcOVKbAb7HQ&quot; target=&quot;_blank&quot;&gt;級聯 vs 端到端、全雙工、輪次檢測、方言語種、商業模式...語音 AI 開發者都在關心什麼？丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7QPgzp8kDR_9iHUa4oFeiA&quot; target=&quot;_blank&quot;&gt;a16z 最新報告：AI 數字人應用層即將爆發，或將孕育數十億美金市場丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUM1qs2IT1S6kJ4sZf_k3uA&quot; target=&quot;_blank&quot;&gt;a16z 合夥人：語音交互將成為 AI 應用公司最強大的突破口之一，巨頭們在 B2C 市場已落後太多丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWI0gE4x-TZG0gdgSV_bVSA&quot; target=&quot;_blank&quot;&gt;ElevenLabs 33 億美元估值的祕密：技術驅動+用戶導向的「小熊軟糖」團隊丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVsgDF8F1hxy3-e5-ntGbw&quot; target=&quot;_blank&quot;&gt;端側 AI 時代，每台家居設備都可以是一個 AI Agent 丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4K5wdUEDxrs1afHZSAIuqg&quot; target=&quot;_blank&quot;&gt;世界最炙手可熱的語音 AI 公司，舉辦了一場全球黑客松，冠軍作品你可能已經看過&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJCYzc1Ig-HFFAN3sTQDYbw&quot; target=&quot;_blank&quot;&gt;多模態 AI 怎麼玩？這裏有 18 個腦洞&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrN9poD_X6SDxRLMsudg_xg&quot; target=&quot;_blank&quot;&gt;AI 重塑宗教體驗，語音 Agent 能否成為突破點？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeFS1mnAbUpAJdiLSSGWpSA&quot; target=&quot;_blank&quot;&gt;對話 TalktoApps 創始人：Voice AI 提高了我五倍的生產力，語音輸入是人機交互的未來&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fr2z1bilamX6YWTg90F8xYA&quot; target=&quot;_blank&quot;&gt;a16z 最新語音 AI 報告：語音將成為關鍵切入點，但非最終產品本身（含最新圖譜）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;寫在最後：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們歡迎更多的小夥伴參與 &lt;strong&gt;「RTE 開發者日報」&lt;/strong&gt; 內容的共創，感興趣的朋友請通過開發者社區或公眾號留言聯繫，記得報暗號「共創」。&lt;/p&gt; 
&lt;p&gt;對於任何反饋（包括但不限於內容上、形式上）我們不勝感激、並有小驚喜回饋，例如你希望從日報中看到哪些內容；自己推薦的信源、項目、話題、活動等；或者列舉幾個你喜歡看、平時常看的內容渠道；內容排版或呈現形式上有哪些可以改進的地方等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b097a16f69dc64b4f3a6805bc0066e50a2f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;素材來源官方媒體/網絡&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/agora/blog/18255332</link>
            <guid isPermaLink="false">https://my.oschina.net/agora/blog/18255332</guid>
            <pubDate>Sat, 26 Apr 2025 12:10:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>谷歌認為自己是唯一能運營 Chrome 的公司，如若轉手，將「萬劫不復」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在美國司法部對谷歌在搜索引擎市場的非法壟斷案中，谷歌 Chrome 瀏覽器總經理 Parisa Tabriz &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffortune.com%2Farticle%2Fgoogle-chrome-suffer-if-forced-to-sell-parisa-tabriz%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;&lt;/u&gt;，將谷歌與 Chrome 「剝離」是不可能的，並補充説，她認為「Chrome 不可能在其他地方被複制」。&lt;/p&gt; 
&lt;p&gt;Tabriz 強調造就 Chrome 瀏覽器今日成功的基石，源於 17 年來與谷歌其他部門的緊密協作。&lt;/p&gt; 
&lt;p&gt;Tabriz 表示，谷歌 Chrome 是 Chrome 團隊、谷歌以及向公司的開源 Chromium 項目提交技術貢獻的公司「17 年合作」的結果，該項目的開源代碼也被用於其他幾個谷歌項目，如 Android 操作系統。「谷歌在 Chromium 上投入了數億美元」，Tabri 説到，並表示其他公司「目前並沒有以任何有意義的方式做出貢獻。」&lt;/p&gt; 
&lt;p&gt;專家 James Mickens 認為，將 Chrome 從谷歌內部基礎設施進行剝離在技術上是「feasible」（可行的），並不會破壞其功能。他指出，谷歌仍有動力繼續為開源項目 Chromium 貢獻技術。&lt;/p&gt; 
&lt;p&gt;然而，Tabriz 反駁稱，&lt;strong&gt;谷歌自 2015 年以來貢獻了 Chromium 超過 90% 的代碼&lt;/strong&gt;，其他公司幾乎沒有實質性投入。&lt;/p&gt; 
&lt;p&gt;Tabriz 透露，谷歌正積極將 AI 技術融入 Chrome。用戶目前可通過擴展程序使用 OpenAI 的 ChatGPT 和 Perplexity AI，或調整設置以便於使用其他 AI 模型搜索，不過 Gemini 被設為默認 AI 助手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz</guid>
            <pubDate>Sat, 26 Apr 2025 11:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 改進 GPT-4o 模型，帶來更強的智能和個性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;本月初，OpenAI 發佈了多個新的 AI 模型。面向開發者的 GPT-4.1 模型引入了對 100 萬個 Token 上下文窗口的支持，並在指令遵循、編碼和智能方面進行了改進。o3 和 o4-mini 推理模型在多個 AI 基準測試中取得了最佳結果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4d30e4eac108c004154d6855d6c524ec1d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;即使在發佈這些新模型之後，OpenAI 仍在持續更新 GPT-4o 模型。&lt;/p&gt; 
&lt;p&gt;今年 3 月，OpenAI 對 GPT-4o 進行了增強，使其更加直觀、更具創造力、更具協作性，並具有更好的指令遵循性、更強大的編碼能力以及更清晰的溝通風格。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我們今天更新了 GPT-4o！智力和個性都得到了提升。&lt;/p&gt; 
 &lt;p&gt;— 薩姆·奧爾特曼 (@sama)&amp;nbsp;2025 年 4 月 25 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;今天，OpenAI CEO 奧特曼&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1915902652703248679&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;對 GPT-4o 模型進行再次更新，重點提升了智能和個性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;優化 GPT-4o 保存記憶的時間長度並增強 STEM 的問題解決能力；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;還對 GPT-4o 響應方式進行了細微的更改，使其更加主動，更好地引導對話取得富有成效的結果。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/190903_uoAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此增強版本目前僅通過 ChatGPT 體驗提供，開發者尚無法通過 API 訪問。&lt;/p&gt; 
&lt;p&gt;OpenAI 聲稱，該模型現在展現出了更好的「氛圍」、格式、對用戶需求的直覺以及其他定性增強。然而，由於改進更難以量化，他們並未分享此版本的最新基準。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9f13b1ef859a79511ac123aa8987b2341b7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;艾丹·麥克勞克林 (Aidan McLaughlin) 目前在 OpenAI 負責模型設計和能力開發，他在 Twitter 上表示，此次 GPT-4o 更新是 OpenAI 迄今為止為主要 4o 系列發佈的最快的更新，這表明發佈速度正在加快。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;太喜歡這個模型了！簡直太有意思了！&lt;/p&gt; 
 &lt;p&gt;如果你有什麼反饋，歡迎留言！&lt;/p&gt; 
 &lt;p&gt;- Aidan McLaughlin (@aidan_mclau)&amp;nbsp;2025 年 4 月 25 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;雖然基準衡量了人工智能模型的核心能力，但「氛圍」等現實世界方面的改進表明 OpenAI 越來越關注整體用戶體驗和交互風格。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346982/openai-updated-gpt-4o</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346982/openai-updated-gpt-4o</guid>
            <pubDate>Sat, 26 Apr 2025 11:10:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>模力方舟百模破浪 —— 北京經開區推進 AI 開源開放生態共創</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;4 月 27 日下午，在北京人工智能產業生態創新發佈會上，開源人工智能社區「模力方舟」正式發佈，「開源人工智能應用創新大賽」也同步啓動，經開區將圍繞建設全域人工智能之城，助力共建國內 AI 開源開放生態。&lt;/p&gt; 
&lt;p&gt;模力方舟依託開源中國 17 年生態構建，積累超 1800 萬開發者、2000 餘所高校、36 萬家企業，以絕對中立平台面向開發者提供從開源模型、訓練數據集、國產算力底座到模型在線微調測試的全流程支持，降低大模型開發門檻，提高開發效率，以深厚的開源和開發者服務底蘊，致力於成為 AI 時代的重要創新引擎與生態共建平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/182702_pFoc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://ai.gitee.com/&quot;&gt;https://ai.gitee.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;「模力方舟」旨在對標國外開源社區 Hugging Face，於 2024 年 1 月上線，算力供給方面與沐曦 MetaX、華為昇騰、天數智芯、摩爾線程等國產 GPU 企業合作，目前已積累約 16000 個開源模型及約 10000 個高質量數據集，覆蓋自然語言處理、計算機視覺等主流 AI 領域，註冊用戶數超 100 萬。&lt;/p&gt; 
&lt;p&gt;建設「模力方舟」有哪些資源基礎？未來又將如何推進？北京經開區有關負責人介紹：「此前，經開區與北京市聯動投資牽引國內頭部開源社區企業——開源中國總部落地經開區。基於開源中國在傳統開源領域的生態積累，圍繞人工智能開源大模型和國產算力底座軟硬一體化適配，我們啓動了人工智能開源社區‘模力方舟’建設工作。」&lt;/p&gt; 
&lt;p&gt;為助力「模力方舟」建設成為具有國際影響力的開源人工智能社區，經開區將支持開源中國從夯實平台能力、引導資源匯聚、打造國際品牌、政策保駕護航四個方面展開工作。具體來説，充分依託公有云的彈性拓展特性與私有云的安全可控優勢，精心構建起具備高併發處理能力、能夠實現低延時響應的算力基礎設施體系；整合自然語言處理、計算機視覺、語音識別等多個 AI 核心領域的國內外前沿模型，以及圖像數據集、文字數據集、各類先進算法；圍繞「一賽一會」這一核心策略持續擴大影響力，舉辦開源人工智能大賽及開源峯會等品牌活動，推動具有高成長性的開源 AI 創業項目在開源社區形成落地集聚；對優質開源項目、優秀商業化應用、開源生態活動給予一定資金支持等。&lt;/p&gt; 
&lt;p&gt;值得一提的是，在本次發佈會上，「一賽一會」核心策略中的「開源人工智能應用創新大賽」正式啓動。由開源中國聯合戰略合作伙伴，華為昇騰、商湯科技、智譜（Z.ai）、沐曦 MetaX、天數智芯、睿思芯科、希姆計算等國內領先人工智能企業共同發起。他們將為賽事提供核心算力支持、先進 AI 模型、優質數據資源以及行業生態聯動支持。這是一場全國性的人工智能賽事，定位國家級影響力賽會，通過競賽展示開源與人工智能前沿技術創新和商業化應用，推動產業化落地，為項目實踐應用提供發展平台。大賽設專業組和青少年組兩個組別：專業組賽道涵蓋 AI 醫療、AI 金融、AI 智能製造、視覺呈現與感知、具身智能與機器人、AI 教育與智能教學解決方案等七大方向，青少年組賽道包括創新場景實踐應用、AI 算法設計與優化等四大方向。&lt;/p&gt; 
&lt;p&gt;此外，入選團隊將在半決賽中與 2025 GOTC 全球開源技術峯會深度聯動，為參賽團隊打造國際化的展示舞台。優秀項目可在峯會分論壇演講，演示對抗和大咖點評，全程媒體直播，讓創新成果獲得最大曝光。&lt;/p&gt; 
&lt;p&gt;與此同時，為更好地促進參賽團隊創新成果落地，大賽主辦方與經開區政府積極聯動，將設立一、二、三等獎及多項單項獎項，為獲獎團隊提供獎金和配套政策支持，同時協調優質辦公空間及算力資源的方式支持優秀項目孵化落地。&lt;/p&gt; 
&lt;p&gt;本次大賽旨在打造一項全國性、具有國家級影響力的人工智能賽事，目標是通過賽事展示技術創新與商業化應用，推動產業落地，聚焦人工智能的前沿技術，同時也為項目的實際應用提供發展平台。&lt;/p&gt; 
&lt;p&gt;目前，大賽已面向全國範圍的參賽者開放報名，參賽團隊可通過報名通道提供成熟的技術方案、商業化路徑與應用場景等作品。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346975</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346975</guid>
            <pubDate>Sat, 26 Apr 2025 10:27:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>谷歌在壟斷審判中被曝向三星支付鉅款預裝 Gemini 應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;彭博社報道稱，正在進行的谷歌反壟斷審判本週的證詞顯示，谷歌每月向三星支付「鉅額資金」，以在其設備上預裝其 Gemini 人工智能應用程序。這一信息正值法官阿米特·梅塔 (Amit Mehta) 已裁定谷歌的搜索引擎構成非法壟斷之後，目前谷歌的律師正與美國司法部就潛在的處罰力度展開辯論。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3bc9b596b7ba040b8f52188c972b5dfbbfc.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;谷歌平台和設備合作副總裁彼得·菲茨傑拉德週一作證稱，谷歌與三星之間的這筆付款協議始於今年 1 月份。值得注意的是，這筆交易啓動於谷歌被認定違反反壟斷法之後，而此前谷歌被判定壟斷的部分原因正是其與蘋果、三星等公司類似的搜索默認合作協議。作為合作的一部分，三星在 1 月份推出的 Galaxy S25 系列手機中，將 Gemini 設置為長按電源鍵時的默認 AI 助手，而三星自家的 Bixby 助手則被置於次要地位。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;據《The Information》報道，菲茨傑拉德在證詞中提及，包括 Perplexity 和微軟在內的其他公司也曾向三星推銷在其設備上預裝人工智能助手應用的協議。然而，美國司法部律師指出，谷歌提交的試圖修改與手機製造商協議的信函實際上是在庭審前夕，即上週才發出的，暗示這些舉動可能是應對庭審壓力。此外，《The Information》報道稱，當天提交的谷歌內部幻燈片似乎顯示，谷歌「正在考慮更具限制性的分銷協議，要求合作伙伴在谷歌搜索和 Chrome 瀏覽器之外預裝 Gemini」。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;關於支付細節，彭博社報道稱，菲茨傑拉德表示，與三星的 Gemini 協議為期兩年，除了固定的月費外，谷歌還將向三星支付一定比例的 Gemini 應用訂閲收入。彭博社援引美國司法部律師戴維·達爾奎斯特（David Dahlquist）的話稱，這筆固定的月費是一筆「鉅款」，但具體數額尚未公開。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346972</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346972</guid>
            <pubDate>Sat, 26 Apr 2025 10:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>