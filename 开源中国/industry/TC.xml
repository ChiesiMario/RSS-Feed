<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 25 Mar 2025 21:36:54 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>OpenAI 發佈高級語音模式更新：減少打斷、支持暫停思考</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F03%2F24%2Fopenai-says-its-ai-voice-assistant-is-now-better-to-chat-with%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;對高級語音模式進行更新，使人工智能助手更加人性化，減少對用戶的打擾。&lt;/p&gt; 
&lt;p&gt;OpenAI 的最新更新旨在解決人工智能語音助手經常出現的一個問題，&lt;strong&gt;即當用戶暫停思考或深呼吸時，語音助手會打斷用戶。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-247c8326d5cecf92d8c96456777486f89e3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ChatGPT 的免費用戶現在可以使用新版本的高級語音模式，讓用戶在與 AI 語音助手對話時暫停，而不會被打斷。&lt;/p&gt; 
&lt;p&gt;ChatGPT 的付費用戶（包括 OpenAI 的 Plus、Teams、Edu、Business 和 Pro 層級的用戶）在使用高級語音模式時也將減少被打斷的頻率，同時語音助手的個性也將得到改善。針對付費用戶，ChatGPT 高級語音模式進一步增強語音個性，模型響應更生動、直接且簡潔，提供 9 種風格化人聲選項。&lt;/p&gt; 
&lt;p&gt;閲讀更多：&lt;a href=&quot;https://www.oschina.net/news/335872&quot; target=&quot;news&quot;&gt;OpenAI 免費開放 ChatGPT 語音聊天功能&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340929/openai-says-its-ai-voice-assistant-is-now-better-to-chat-with</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340929/openai-says-its-ai-voice-assistant-is-now-better-to-chat-with</guid>
            <pubDate>Sat, 22 Mar 2025 11:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Cloudflare 推出「AI 迷宮」應對 AI 爬蟲</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;與其阻止爬蟲機器人，不如主動把它們引進一個由 AI 生成的「廢話迷宮」，讓它們自我迷失&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Cloudflare 近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fai-labyrinth%2F&quot; target=&quot;_blank&quot;&gt;推出名為「AI 迷宮」（AI Labyrinth）的新工具&lt;/a&gt;&lt;/u&gt;，用以對付未經授權、到處抓取網頁數據的爬蟲機器人。這些爬蟲通常抓取免費內容，以訓練 AI 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-14b28096a4ec89447ef93e70ba02693f606.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cloudflare 介紹稱，&lt;strong&gt;當系統識別到異常爬蟲行為時，「AI 迷宮」就會啓動，將這些機器人引向由 AI 自動生成的虛假頁面。這些頁面毫無實際價值，僅用於消耗機器人的時間與資源，令其陷入困惑，最終無法獲取有效數據&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;過去，網站管理員常用「robots.txt」文件引導機器人避開特定頁面。但一些 AI 公司，例如 Anthropic、Perplexity AI 等，屢次被指控忽視這種協議，擅自抓取數據，導致網站與機器人之間形成技術上的持續對抗。&lt;/p&gt; 
&lt;p&gt;Cloudflare 表示，每日大約有 500 億次爬蟲訪問請求。儘管已開發多種攔截工具，但爬蟲總能迅速適應並繞過防禦措施。這次 Cloudflare 轉變策略，不再直接攔截，而是通過生成迷宮般的虛假頁面，讓機器人陷入無用信息的循環，主動消耗自身的資源。&lt;/p&gt; 
&lt;p&gt;這種方法也被稱作「下一代蜜罐陷阱」（Honeypot）。人類用戶可以輕鬆識別並避免點擊這些無價值鏈接，而機器人則毫無辨別能力，會持續抓取陷阱頁面，越陷越深。Cloudflare 由此可記錄並分析機器人行為，快速識別新的爬蟲模式，並不斷優化防禦措施。&lt;/p&gt; 
&lt;p&gt;據介紹，AI 迷宮利用 Workers AI 和開源模型生成各種主題的獨特 HTML 頁面。Cloudflare 並非按需生成內容，而是預先生成並篩選內容，確保其不存在 XSS 漏洞，並將其存儲在 R2 中以加快檢索速度。每個生成的頁面都包含適當的元指令，以防止搜索引擎索引，從而保護合法的 SEO 工作。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f86c8285f7b4db7b933becb98fe6643f887.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這些 Nofollow 標籤確保不遵守推薦指南的 AI 爬蟲將被困在迷宮中，而遵守規則的爬蟲則會安全地忽略蜜罐。重要的是，這些鏈接通過精心實現的屬性和樣式對普通訪客不可見。除了保護網站內容外，AI 迷宮還作為一種複雜的識別機制。當這些隱藏鏈接被點擊時，Cloudflare 可以自信地識別出自動化爬蟲活動，並將這些寶貴的數據輸入機器學習模型，以增強爬蟲檢測能力。這形成了一個有益的反饋循環，每次爬取嘗試都有助於保護所有 Cloudflare 客戶。&lt;/p&gt; 
&lt;p&gt;Cloudflare 強調，為防止誤導公眾，這些生成的虛假內容雖基於真實科學事實，但與目標網站毫無關係，因此對爬蟲訓練 AI 模型毫無價值。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-278fb851b6443b99447afe21e7853ee03da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;管理員只需在 Cloudflare 後台「機器人管理」界面啓用該工具，即可簡單使用。未來，Cloudflare 還計劃構建更加複雜龐大的虛假頁面網絡，使惡意爬蟲徹底迷失其中，進一步加大爬蟲成本與困難度。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340927/cloudflare-unveils-ai-labyrinth</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340927/cloudflare-unveils-ai-labyrinth</guid>
            <pubDate>Sat, 22 Mar 2025 11:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>揭祕谷歌被 ChatGPT 偷襲後的自我革命</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;《彭博商業週刊》近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Ffeatures%2F2025-03-24%2Fgoogle-s-ai-search-overhaul-racing-chatgpt-for-the-web-s-future&quot; target=&quot;_blank&quot;&gt;發表深度文章稱&lt;/a&gt;&lt;/u&gt;，谷歌原本有機會利用人工智能 (AI) 革新谷歌搜索，但是管理層不願改變現狀，保護廣告業務利潤，最終被 ChatGPT 搶佔先機。為了迎頭趕上，谷歌搜索開始自我變革。&lt;/p&gt; 
&lt;p&gt;以下是文章主要內容：&lt;/p&gt; 
&lt;p&gt;谷歌擁有 DeepMind 和 Google Brain 兩大頂尖 AI 實驗室，但其管理層對 AI 技術落地的態度始終謹慎。核心矛盾在於：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;技術可靠性&lt;/strong&gt;：生成式 AI 的答案准確性尚未達到搜索引擎的要求，可能引發誤導性結果（如醫療建議錯誤）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;商業模式衝突&lt;/strong&gt;：谷歌搜索 2024 年貢獻了 1980 億美元收入（佔 Alphabet 總營收 60%），而 AI 直接提供答案可能削弱廣告展示機會——當前搜索頁面的廣告與自然結果混合模式為其核心利潤來源。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;用戶對傳統搜索的不滿已非祕密。Semrush 數據顯示，谷歌每秒處理近 20 萬次查詢，但搜索結果中廣告和低質 SEO 內容（如冗長的食譜網站）佔比上升，導致體驗下降。&lt;/p&gt; 
&lt;p&gt;相比之下，ChatGPT 的簡潔交互和即時答案雖存在事實性錯誤，卻因「純粹性」獲得用戶寬容。這種反差凸顯了搜索產品邏輯的範式轉移：從「信息索引」轉向「問題解決」。&lt;/p&gt; 
&lt;p&gt;為應對挑戰，谷歌正從兩方面推進變革：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;技術整合&lt;/strong&gt;：將生成式 AI 能力嵌入搜索（如實驗性功能「AI Overviews」），在答案中標註信息來源以提升可信度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;廣告模式迭代&lt;/strong&gt;：探索 AI 答案頁面的新型廣告位，例如在旅遊建議中推薦酒店預訂服務，試圖兼容用戶體驗與商業需求。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;閲讀更多&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/337252/google-ai-mode-search&quot; target=&quot;news&quot;&gt;谷歌搜索測試「AI Mode」：整合多模態和實時信息、一鍵解答覆雜問題&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340924</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340924</guid>
            <pubDate>Sat, 22 Mar 2025 10:59:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>首發！優刻得雲平台上新 DeepSeek-V3-0324 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;上新！DeepSeek-V3 重磅升級&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;昨夜，DeepSeek-V3 迎來一波更新，升級至&lt;strong&gt;「DeepSeek-V3-0324」&lt;/strong&gt;版本。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;不僅將模型參數量由原版的 671B 提升至 685B，編程、數學等推理思考能力大幅提升，性能表現可以與 Claude 3.5/3.7 Sonnet 相媲美。同時，模型的開源協議升級為更寬鬆的 MIT 許可，進一步降低了商業應用門檻。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet//351359c2aa96d28a2eeefa2ccdcd22c8.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;60&quot; src=&quot;https://oscimg.oschina.net/oscnet//f01541323470d69a14cad2d697ac18b7.jpeg&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;優刻得雲平台始終密切關注 AI 技術發展動態，在新版本發佈後迅速響應，第一時間在模型服務平台 UModelVerse 上架 DeepSeek-V3 最新版本，為廣大用戶帶來高效、便捷的模型推理體驗。&lt;strong&gt;只需簡單 3 步，用戶便可以「API」的調用方式，輕鬆解鎖強大的模型推理能力！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;272&quot; src=&quot;https://oscimg.oschina.net/oscnet//58e74c42f4e9f751a7078a3b2e5d6a9c.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;技術突破：三大維度重構 AI 開發範式&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;1. 極簡架構，極致效率&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;6850 億參數 MoE 架構：&lt;/strong&gt;採用動態路由優化技術，激活參數僅 370 億，通過&quot;偏差項&quot;機制和節點受限路由策略，實現跨節點通信開銷降低 37%，推理速度提升&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;128K 超長上下文：&lt;/strong&gt;可解析 50 頁 PDF 文檔或完整代碼庫，多輪對話記憶保持能力提升&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FP8 混合精度訓練：&lt;/strong&gt;顯存佔用壓縮，單卡推理成本較初代降低&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;2. 代碼生成質的飛躍&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;單次生成 400+行生產級代碼&lt;/strong&gt;，支持 Vue/React 等 20+編程語言&lt;/li&gt; 
 &lt;li&gt;前端開發實現&lt;strong&gt;像素級美學：&lt;/strong&gt;生成的天氣卡片、粒子動畫等效果與 Claude 3.7 Sonnet 差距縮至 5%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智能糾錯與接口檢查：&lt;/strong&gt;自動檢測 API 兼容性，代碼可運行率達 92%&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;3. 數學推理突破性進化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;複雜數學題正確率提升 30%，支持逐步推導與自主糾錯&lt;/li&gt; 
 &lt;li&gt;經典案例：7 米甘蔗過 2 米門難題，通過&quot;對角線原理&quot;自主發現隱藏解法&lt;/li&gt; 
 &lt;li&gt;非專業模型首次實現&lt;strong&gt;類人類頓悟思維&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;231&quot; src=&quot;https://oscimg.oschina.net/oscnet//2e498785cd98e362a2066b0deb604207.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;»評測表現&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;DeepSeek-V3-0324 在 Misguided Attention 長評估表現：&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;432&quot; src=&quot;https://oscimg.oschina.net/oscnet//052aa2fe9976e88e3e7937c428b6ea08.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;DeepSeek-V3-0324 以 53.5% 平均得分領跑，領先 Claude 3.7/GPT-4o，僅次於 DeepSeek-R1。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;»實測表現&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;X 博主「@KuittinenPetri」表示，更新後的 DeepSeek-V3-0324 可以輕鬆免費地創建漂亮的 HTML5、CSS 和前端。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;提示詞如下，大家也可以自行嘗試：為 AI 公司「NexusAI」創建一個外觀精美的響應式首頁，將所有內容包含在一個 HTML5 文件中。結果如下圖所示，所有圖像，包括用戶故事和他們的面孔，一切都是用這個提示完成的。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;180&quot; src=&quot;https://oscimg.oschina.net/oscnet//d227d5bf63e56143e782b4b31b2c686e.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;180&quot; src=&quot;https://oscimg.oschina.net/oscnet//f19b9185aa95622a2ad1e303207efc4b.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;他認為：DeepSeek-V3-0324 是 DeepSeek 最好的非推理模型，通常更適合創意寫作任務，但現在也比 R1 更適合製作 HTML5+CSS+前端。上述提示的結果代碼總共 958 行，但它實際上實現了一個交互式網站，包括所有圖像。並且結果也適用於移動設備。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;在優刻得三步極簡接入，開啓 AI 推理之旅&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;步驟一：註冊並登錄 UCloud 雲平台&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;46&quot; src=&quot;https://oscimg.oschina.net/oscnet//e23be454c8ad4f08055f82a7e5886b7b.jpeg&quot; width=&quot;495&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;進入控制枱，選擇產品&lt;strong&gt;「模型服務平台 UMoldeVerse」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;步驟二：開通 DeepSeek 調用權限&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;進入模型廣場，選擇 DeepSeek 系列模型，並點擊&lt;strong&gt;「API 文檔」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;*注：為保證服務穩定，目前 API 服務採用申請制。如需使用，請聯繫在線客服進行申請。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;321&quot; src=&quot;https://oscimg.oschina.net/oscnet//1a617d28f2cbd59c1d8332b37f636739.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;步驟三：在線體驗&amp;amp;通過 API 調用&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;權限開通後，可通過體驗中心進行頁面對話，也可通過 API 調用進行業務接入：&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;1.在線體驗：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;點擊「體驗」即可進入「體驗中心」，在線體驗與 DeepSeek 進行對話；&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;若選擇兩個模型，則可進行多模型對比體驗。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;312&quot; src=&quot;https://oscimg.oschina.net/oscnet//6c7512bd625cb000a52b0c460fcc05c2.png&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;2.API 調用：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;點擊「API 文檔」跳轉文檔頁面，根據 API 文檔説明，進行 API 的調用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;獲取 API Key：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;115&quot; src=&quot;https://oscimg.oschina.net/oscnet//5b618829a1875d3f21980060b62bcf5d.jpeg&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chat API 調用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;使用工具（如 curl）發送請求，代碼調用示例：&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center&quot;&gt;&lt;img height=&quot;232&quot; src=&quot;https://oscimg.oschina.net/oscnet//66d6378821fa0345b8b3b22933b41ac9.jpeg&quot; width=&quot;640&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;在競爭激烈的商業環境中，快速採用新技術往往是企業脫穎而出的關鍵。目前，優刻得模型服務平台 UModelVerse、「優雲智算」算力共享平台、私有云平台 UCloudStack 均已上架 DeepSeek 系列模型。同時提供 DeepSeek 大模型一體機的本地部署方案。&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;&lt;strong&gt;您可以根據自身業務需求選擇合適的模型鏡像、雲端或私有化部署方式，結合優刻得豐富的算力資源和模型微調服務，快速搭建企業級 AI 應用。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left&quot;&gt;優刻得始終致力於降低模型部署及應用的技術門檻，助力企業輕鬆調用 DeepSeek 等熱門模型，無需投入大量時間和資源進行模型搭建與優化，即可將強大的 AI 能力融入自身業務流程中，加速產品創新與服務升級。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340922</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340922</guid>
            <pubDate>Sat, 22 Mar 2025 10:46:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>中國的「工程師紅利」正在產生驚人回報</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;中國科技人才崛起正悄然改變着世界科技發展格局。「中國正從‘工程師紅利’中收穫巨大回報。」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/184015_h4Hs_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;彭博社以此為題&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fopinion%2Farticles%2F2025-03-24%2Fchina-s-engineer-dividend-is-paying-off-big-time&quot; target=&quot;_blank&quot;&gt;發文指出&lt;/a&gt;&lt;/u&gt;，中國政府重視高等教育，推動了工程師人才的培養，過去 20 多年裏工程師數量大幅增加，龐大的人才庫使中國在科技創新方面有了更大的突破機會。同時，中國工程師還具有年齡結構優勢，人力成本僅為美國的八分之一，美國科技行業面臨着中國帶來的結構性挑戰。&lt;/p&gt; 
&lt;p&gt;根據中國國務院的數據，在 2000 年至 2020 年間，工程師的數量從 520 萬激增至 1770 萬。人們認為，這一人才儲備能夠助力中國提升生產可能性邊界。&lt;/p&gt; 
&lt;p&gt;彭博社指出，DeepSeek 改變了世界對中國的看法。從某種程度上來説，DeepSeek 的出現本不應令人感到意外。僅龐大的人才庫這一點，就使中國有更大的機會實現突破。&lt;/p&gt; 
&lt;p&gt;保爾森基金會旗下智庫宏觀中國的數據顯示，2022 年，在全球排名前 20% 的人工智能研究人員中，有 47% 的人本科畢業於中國，這一比例遠高於美國的 18%。去年，在世界知識產權組織編制的創新指標數量排名中，中國位列第三，僅次於新加坡和美國。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c31dddf4b85b19e5e780a09ede0e11e44ef.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更重要的是，中國擁有成本優勢。開源證券彙編的數據顯示，在工程師羣體中，30 歲以下的人佔 44%，而在美國這一比例僅為 20%。因此，中國研究人員的薪酬大約僅為美國的八分之一。&lt;/p&gt; 
&lt;p&gt;因此，工程師羣體的發展預示着一種全新的增長模式。中國的工程師們仍然年輕、成本較低且數量眾多。因此，他們為中國開闢了新的可能性，在生物技術、人形機器人和人工智能應用的開發方面與西方競爭。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339460/software-engineer-jobs-five-year-low&quot; target=&quot;news&quot;&gt;軟件工程師職位需求已俯衝到五年最低點？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/337519/anthropic-mike-krieger-how-software-engineering-work-changing&quot; target=&quot;news&quot;&gt;未來三年，軟件工程師或將轉型為「AI 代碼審核員」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340918</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340918</guid>
            <pubDate>Sat, 22 Mar 2025 10:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源模型上下文協議 MCP 已合併</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，Anthropic 工程師在 MCP 的 GitHub 倉庫&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/339546/mcp-streamable-http-transport&quot;&gt;提交&lt;/a&gt;&lt;/u&gt;了一個希望採用 &quot;Streamable HTTP&quot; 傳輸代替「HTTP+SSE」的 PR，以解決當前遠程 Model Context Protocol (MCP) 傳輸方式的關鍵限制，同時保留其優勢。&lt;/p&gt; 
&lt;p&gt;根據該 PR 目前的狀態，MCP 現已合併&quot;Streamable HTTP&quot; 提案。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1212&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/180941_CBPU_2720166.png&quot; width=&quot;732&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;1412&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/181326_Jlzj_2720166.png&quot; width=&quot;2080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fspecification%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/specification/pull/206&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Streamable HTTP&amp;nbsp;改變了 MCP 的數據傳輸方式&lt;/strong&gt;，讓協議變得：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更靈活&lt;/strong&gt;（支持流式傳輸，但不強制）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更易用&lt;/strong&gt;（支持無狀態服務器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更兼容&lt;/strong&gt;（適用於標準 HTTP 基礎設施）&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;💡&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;簡單比喻&lt;/strong&gt;： 原來的 MCP 傳輸方式就像是&lt;strong&gt;你和客服通話時必須一直保持在線&lt;/strong&gt;（SSE 需要長連接），而新的方式更像是&lt;strong&gt;你隨時可以發消息，然後等回覆&lt;/strong&gt;（普通 HTTP 請求，但可以流式傳輸）。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;主要變更&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;移除 /sse 端點&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器不再單獨維護 SSE（Server-Sent Events）端點。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;所有客戶端 → 服務器的消息都通過 /message 端點&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任何數據傳輸都通過&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;/message&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;進行，不再依賴 /sse。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;服務器可以選擇升級請求為 SSE&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器可以根據需要&lt;strong&gt;動態升級 HTTP 請求為 SSE 流&lt;/strong&gt;，用於發送通知或請求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;客戶端通過 Header 提供 Mcp-Session-Id&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器可選是否需要存儲 Session 信息，但客戶端始終發送 Mcp-Session-Id 頭部信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;支持無狀態（Stateless）服務器&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器可選擇完全無狀態運行，不再需要維持長期連接。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;變更的動機&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;當前的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;HTTP+SSE 傳輸&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;存在以下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;不支持可恢復性&lt;/strong&gt;（Resumability）：連接斷開後，客戶端必須重新開始整個會話。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;服務器需要維持長期連接&lt;/strong&gt;（High Availability Requirement）：服務器必須保持高可用性，以支持持續的 SSE 連接。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;SSE 僅支持服務器 → 客戶端消息&lt;/strong&gt;，無法靈活進行雙向通信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;新的 「Streamable HTTP」 傳輸方式解決了這些問題，並增強了系統的可擴展性和靈活性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340916/mcp-streamable-http-transport-merged</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340916/mcp-streamable-http-transport-merged</guid>
            <pubDate>Sat, 22 Mar 2025 10:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apache Flink 2.0.0: 實時數據處理的新紀元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a431578f6b05f2fb76b7cab355fbd43976e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;今天，Flink&amp;nbsp;開發團隊驕傲地宣佈&amp;nbsp;Apache&amp;nbsp;Flink&amp;nbsp;2.0.0&amp;nbsp;正式發佈！這是&amp;nbsp;Flink&amp;nbsp;2.x&amp;nbsp;系列的首個版本，也是自九年前&amp;nbsp;Flink&amp;nbsp;1.0&amp;nbsp;發佈以來的首次重大更新。這個版本凝聚了社區兩年來精心籌備與協作的成果，標誌着&amp;nbsp;Flink&amp;nbsp;發展開啓了新篇章。&lt;/p&gt; 
&lt;p&gt;在這個版本中，165&amp;nbsp;位貢獻者齊聚一堂，完成了&amp;nbsp;25&amp;nbsp;項&amp;nbsp;Flink&amp;nbsp;改進提案（FLIP），解決了&amp;nbsp;367&amp;nbsp;個問題。我們衷心感謝所有貢獻者為這個里程碑版本付出的寶貴努力！&lt;/p&gt; 
&lt;p&gt;過去十年間，Apache&amp;nbsp;Flink&amp;nbsp;經歷了蛻變式的發展。在&amp;nbsp;1.0&amp;nbsp;時代，Flink&amp;nbsp;開創了有狀態流計算的先河，讓端到端精確一致語義的有狀態流處理成為現實。如今，亞秒級延遲的實時處理已成為標準能力。然而，實時計算引擎如今卻面臨新的挑戰，阻礙了其更加廣泛的應用。實時計算的成本居高不下，無論是昂貴的資源消耗，還是掌握複雜的分佈式流處理概念所需的學習曲線，都限制了實時計算在更多樣化應用場景中的發揮。與此同時，雲原生架構、數據湖和人工智能大語言模型等現代浪潮的湧現，也為實時系統帶來了新的要求。在&amp;nbsp;2.0&amp;nbsp;時代，Flink&amp;nbsp;正在直面這些挑戰，致力於提供更易用、更可擴展的實時計算解決方案，使各組織能夠全面擁抱大數據和人工智能應用的實時能力。這一嶄新篇章體現了&amp;nbsp;Flink&amp;nbsp;致力於使實時計算比以往更加實用、高效和廣泛適用的決心。&lt;/p&gt; 
&lt;p&gt;在&amp;nbsp;2.0&amp;nbsp;版本中，Flink&amp;nbsp;引入了若干創新性功能，以應對實時數據處理的關鍵挑戰，並滿足現代應用（包括人工智能驅動的工作流）不斷增長的需求。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分離式狀態管理&lt;/strong&gt;&amp;nbsp;架構使得&amp;nbsp;Flink&amp;nbsp;在雲原生環境中更高效地利用資源，在確保高性能實時處理的同時將資源開銷降至最低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;物化表&lt;/strong&gt;&amp;nbsp;的引入和改進使用戶能夠專注於業務邏輯，無需深入瞭解流處理的複雜性以及流與批處理模式之間的差異，從而簡化開發流程並提高生產力。&lt;strong&gt;批處理模式&lt;/strong&gt;&amp;nbsp;的優化為近實時或非實時處理場景提供了具有成本效益的替代方案，擴展了&amp;nbsp;Flink&amp;nbsp;對多樣化應用場景的適應性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;此外，與&amp;nbsp;Apache&amp;nbsp;Paimon&amp;nbsp;的深度集成強化了&amp;nbsp;&lt;strong&gt;流式湖倉&lt;/strong&gt;&amp;nbsp;架構，使&amp;nbsp;Flink&amp;nbsp;成為實時數據湖應用場景的領先解決方案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隨着人工智能和大語言模型的不斷崛起，對可擴展的實時數據處理解決方案的需求也在增長。Flink&amp;nbsp;2.0&amp;nbsp;在性能、資源效率和易用性方面的進步使其成為&amp;nbsp;&lt;strong&gt;人工智能工作流&lt;/strong&gt;&amp;nbsp;的強大基礎，確保&amp;nbsp;Flink&amp;nbsp;處在實時數據處理創新的前沿地位。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些改進共同展示了&amp;nbsp;Flink&amp;nbsp;致力於滿足現代數據應用不斷變化的需求，這其中就包括將實時處理能力與人工智能驅動的系統相結合。&lt;/p&gt; 
&lt;p&gt;除了新功能外，Flink&amp;nbsp;2.0&amp;nbsp;還對已棄用的&amp;nbsp;API&amp;nbsp;和配置進行了全面清理，這可能導致某些接口和行為出現向後不兼容的變化。升級到此版本的用戶應特別注意這些變化，以確保順利遷移。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;新功能亮點&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;分離式狀態管理&lt;/h2&gt; 
&lt;p&gt;過去十年間，Flink&amp;nbsp;的部署模式、工作負載和硬件的架構都發生了很大的改變。我們已經從計算存儲耦合的&amp;nbsp;map-reduce&amp;nbsp;時代，過渡到了以&amp;nbsp;Kubernetes&amp;nbsp;容器化部署為標準的雲原生世界。為了全面擁抱這一轉變，Flink&amp;nbsp;2.0&amp;nbsp;引入了分離式狀態存儲與管理，利用分佈式文件系統（DFS）作為主要存儲介質。這一架構上的創新解決了雲原生環境帶來的關鍵挑戰，同時又具備可擴展性、靈活性和高性能。&lt;/p&gt; 
&lt;p&gt;這種新架構解決了雲原生時代給&amp;nbsp;Flink&amp;nbsp;帶來的以下挑戰：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;容器化環境中本地磁盤的限制&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;目前的狀態模型中&amp;nbsp;Compaction&amp;nbsp;導致的計算資源尖峯&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大狀態（數百 TB）作業的快速重縮放&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;以原生方式實現輕量級快速檢查點&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;受限於&amp;nbsp;Flink&amp;nbsp;現有的阻塞式執行模型，直接將狀態存儲擴展為與遠程&amp;nbsp;DFS&amp;nbsp;交互是不夠的。為了克服這一限制，Flink&amp;nbsp;2.0&amp;nbsp;引入了異步執行模型以及分離式狀態後端，並且重新設計了能夠並行和異步地進行狀態訪問的&amp;nbsp;SQL&amp;nbsp;算子。&lt;/p&gt; 
&lt;p&gt;Flink&amp;nbsp;2.0&amp;nbsp;為分離式狀態管理提供了從運行時到&amp;nbsp;SQL&amp;nbsp;算子層的端到端體驗：&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;異步執行模型&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;無序數據處理&lt;/strong&gt;：解耦狀態訪問和計算，以實現並行執行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;異步狀態&amp;nbsp;API&lt;/strong&gt;：對檢查點期間非阻塞性狀態操作的完美支持，減少延遲並提高資源利用率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;語義保持&lt;/strong&gt;：保持&amp;nbsp;Flink&amp;nbsp;核心語義（例如，水位傳播、定時器處理和鍵順序）不變，確保用戶在採用新架構時無需擔心應用程序行為的變化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;更強大的&amp;nbsp;SQL&amp;nbsp;算子&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;藉助新的異步狀態訪問&amp;nbsp;API，Flink&amp;nbsp;2.0&amp;nbsp;重新實現了七個關鍵的&amp;nbsp;SQL&amp;nbsp;算子，包括&amp;nbsp;Join&amp;nbsp;和&amp;nbsp;Aggregates&amp;nbsp;等有狀態操作（例如，窗口聚合、分組聚合）。這些優化針對狀態訪問延遲比較大的場景，通過非阻塞式執行最大化吞吐量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用戶可以通過設置&amp;nbsp;&lt;code&gt;table.exec.async-state.enabled&lt;/code&gt;參數來啓用該功能。一經啓用，作業中所有支持的&amp;nbsp;SQL&amp;nbsp;算子將自動切換到異步狀態訪問模式，無需更改代碼。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在&amp;nbsp;Nexmark&amp;nbsp;基準測試的&amp;nbsp;14&amp;nbsp;個有狀態查詢中，有&amp;nbsp;11&amp;nbsp;個現已完全兼容異步執行模型，並且有顯著的性能提升。我們正在努力擴展對剩餘有狀態算子的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;ForSt&amp;nbsp;-&amp;nbsp;分離式狀態後端&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ForSt，意為&amp;nbsp;「為了流處理」，是一個專為滿足雲原生部署獨特需求而設計的分離式狀態後端。通過將狀態存儲與計算資源解耦，ForSt&amp;nbsp;消除了本地磁盤的限制，並支持並行多路&amp;nbsp;I/O&amp;nbsp;操作，有效降低了延遲。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ForSt&amp;nbsp;與&amp;nbsp;DFS&amp;nbsp;的集成確保了數據的持久化和容災能力，同時優化了讀寫操作以保持高性能。它能夠以非常輕量和快速的方式執行檢查點和錯誤恢復。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;性能評估（以&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnexmark%2Fnexmark&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Nexmark&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;為基準）&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c44e25d52b641bf238102d4b2cbd4231.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;對於重&amp;nbsp;I/O&amp;nbsp;的有狀態查詢（q5、q7、q18、q19、q20），使用帶有&amp;nbsp;1GB&amp;nbsp;緩存的分離式狀態存儲與傳統的本地狀態存儲方案相比，吞吐量可達&amp;nbsp;75%&amp;nbsp;~&amp;nbsp;120%。值得注意的是，這些查詢的狀態大小從&amp;nbsp;1.2GB&amp;nbsp;到&amp;nbsp;4.8GB&amp;nbsp;不等，即使在緩存受限條件下，分離式架構與完全本地狀態存儲相比仍能表現出競爭力。即使沒有緩存，異步模型也能確保達到本地狀態存儲大約&amp;nbsp;50%&amp;nbsp;的吞吐量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對於狀態較小（10MB&amp;nbsp;到&amp;nbsp;400MB）的有狀態查詢（q3、q4、q5、q8、q12、q17），狀態幾乎完全駐留在內存塊緩存中，磁盤&amp;nbsp;I/O&amp;nbsp;可以忽略不計。在這種情況下，分離式狀態存儲的性能比本地狀態存儲平均低不超過&amp;nbsp;10%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基準測試結果證實，分離式狀態架構能夠高效地處理大規模有狀態工作負載。它可以作為傳統存算耦合狀態存儲的無縫、高性能替代，且沒有顯著的性能損失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Flink&amp;nbsp;2.0&amp;nbsp;的分離式狀態管理是邁向真正雲原生未來的關鍵一步。通過解決本地磁盤限制、資源使用波動和快速重縮放等關鍵挑戰，使用戶能夠構建可擴展、高性能的流處理應用程序。隨着異步執行模型和&amp;nbsp;ForSt&amp;nbsp;的引入，以及能力更強大的&amp;nbsp;SQL&amp;nbsp;算子，我們預計&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;將成為雲原生時代有狀態流處理的新標準。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;流批統一&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;物化表&lt;/h3&gt; 
&lt;p&gt;物化表是我們統一流處理和批處理範式這一願景的基石。它使得用戶能夠聲明性地通過單個數據處理流程同時管理實時數據和歷史數據，消除了維護多套代碼或工作流的弊端。&lt;/p&gt; 
&lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，我們將重點放在生產級的可操作性上。對簡化實際環境中生命週期管理和執行的關鍵功能進行了增強：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查詢變更&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;物化表現在支持表結構和查詢語句的更新，無需重新處理歷史數據即可無縫迭代業務邏輯。這對於需要應對錶結構演變和計算邏輯調整的生產場景至關重要。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Kubernetes/Yarn&amp;nbsp;支持&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;除了&amp;nbsp;Standalone&amp;nbsp;集羣，Flink&amp;nbsp;2.0&amp;nbsp;對將物化表刷新作業提交到&amp;nbsp;YARN&amp;nbsp;和&amp;nbsp;Kubernetes&amp;nbsp;集羣進行了原生支持。這使用戶能夠將物化表刷新工作流無縫集成到其生產架構中，從而實現標準化資源管理、容錯和可擴展性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生態系統集成&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;通過與&amp;nbsp;Apache&amp;nbsp;Paimon&amp;nbsp;社區的合作，Paimon&amp;nbsp;的湖存儲格式目前原生支持&amp;nbsp;Flink&amp;nbsp;物化表，將&amp;nbsp;Flink&amp;nbsp;的流批計算與&amp;nbsp;Paimon&amp;nbsp;的高性能&amp;nbsp;ACID&amp;nbsp;事務相結合，實現統一的數據服務。&lt;/p&gt; 
&lt;p&gt;物化表給開發者提供了簡單，可靠的流批數據處理鏈路。未來將繼續深化生產級支持，例如與生產可用的調度程序集成，以實現基於策略的自動化刷新。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_9&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;自適應批處理執行&lt;/h3&gt; 
&lt;p&gt;Flink&amp;nbsp;具備自適應批處理執行功能，能夠根據運行時信息優化執行計劃以提高性能。關鍵功能包括動態分區裁剪、運行時數據過濾和基於數據量的自動並行度調整。在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，我們通過以下兩項新優化進一步增強了這些功能：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自適應&amp;nbsp;Broadcast&amp;nbsp;Join&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;與&amp;nbsp;Shuffle&amp;nbsp;Hash&amp;nbsp;Join&amp;nbsp;和&amp;nbsp;Sort&amp;nbsp;Merge&amp;nbsp;Join&amp;nbsp;相比，Broadcast&amp;nbsp;Join&amp;nbsp;無需大規模數據重分佈和排序，執行效率更高。然而，其適用性取決於輸入數據量是否足夠小；否則，可能會出現性能或穩定性問題。在靜態的&amp;nbsp;SQL&amp;nbsp;優化階段，準確估算&amp;nbsp;Join&amp;nbsp;算子的輸入數據量具有一定的挑戰性，難以確定&amp;nbsp;Broadcast&amp;nbsp;Join&amp;nbsp;是否適用。通過啓用自適應執行優化，Flink&amp;nbsp;在運行時動態捕獲&amp;nbsp;Join&amp;nbsp;算子的實際輸入情況，並在滿足條件時自動切換到&amp;nbsp;Broadcast&amp;nbsp;Join，顯著提高執行效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自動優化數據傾斜的&amp;nbsp;Join&lt;/strong&gt;&amp;nbsp;-&amp;nbsp;在&amp;nbsp;Join&amp;nbsp;操作中，特定鍵的頻繁出現可能導致下游任務處理的數據量差異巨大，因而出現長尾瓶頸，嚴重拖慢整個作業的執行。Flink&amp;nbsp;現在可以利用&amp;nbsp;Join&amp;nbsp;算子輸入邊的運行時統計信息，動態拆分出傾斜的數據分區，同時確保計算結果的完整性。這有效緩解了由數據傾斜引起的長尾延遲。&lt;/p&gt; 
&lt;p&gt;更多關於&amp;nbsp;Flink&amp;nbsp;自適應批處理執行的功能和用法，請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdeployment%2Fadaptive_batch%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Flink&amp;nbsp;文檔&lt;/a&gt;。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;性能&lt;/h3&gt; 
&lt;p&gt;通過上述優化，Flink&amp;nbsp;2.0&amp;nbsp;的批處理性能得到了進一步提升。我們在&amp;nbsp;10TB&amp;nbsp;TPC-DS&amp;nbsp;數據集上進行了基準測試：通過&amp;nbsp;&lt;code&gt;ANALYZE&amp;nbsp;TABLE&lt;/code&gt;&amp;nbsp;語句生成額外統計信息後，Flink&amp;nbsp;2.0&amp;nbsp;相比&amp;nbsp;Flink&amp;nbsp;1.20&amp;nbsp;實現了&amp;nbsp;8%&amp;nbsp;的性能提升；在沒有額外統計信息的情況下，性能提升達到了&amp;nbsp;16%。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;流式湖倉&lt;/h2&gt; 
&lt;p&gt;湖倉架構是近年來出現的一種變革性趨勢。通過將&amp;nbsp;Flink&amp;nbsp;作為流批統一處理引擎和&amp;nbsp;Paimon&amp;nbsp;作為流批統一湖格式，流式湖倉架構實現了湖倉數據的實時新鮮度。在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，Flink&amp;nbsp;社區與&amp;nbsp;Paimon&amp;nbsp;社區緊密合作，充分發揮各自優勢和前沿功能，帶來了顯著的增強和優化。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Paimon&amp;nbsp;數據源現在支持對嵌套的&amp;nbsp;projection&amp;nbsp;進行下推。在涉及複雜數據結構的場景中顯著減少了&amp;nbsp;IO&amp;nbsp;開銷並大幅提升性能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;當使用&amp;nbsp;Paimon&amp;nbsp;作為維度表時，Lookup&amp;nbsp;Join&amp;nbsp;的性能得到了大幅提升。通過將輸入數據的分佈與&amp;nbsp;Paimon&amp;nbsp;表的分桶機制對齊，顯著減少了每個&amp;nbsp;Lookup&amp;nbsp;join&amp;nbsp;任務需要從&amp;nbsp;Paimon&amp;nbsp;檢索、緩存和處理的數據量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有&amp;nbsp;Paimon&amp;nbsp;的維護性操作（如&amp;nbsp;Compaction、管理快照/&amp;nbsp;分支/&amp;nbsp;標籤等）現在都可以通過&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;的&amp;nbsp;CALL&amp;nbsp;語句輕鬆執行，並且支持命名參數，可以與任何可選參數的子集一起使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;之前，批模式下將數據寫入&amp;nbsp;Paimon&amp;nbsp;時無法開啓自動並行度推斷。在新版本中，我們通過固定並行度確保分桶的正確性，同時在與分桶無關的場景中仍應用自動並行推斷，從而解決了這一問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;物化表是&amp;nbsp;Flink&amp;nbsp;SQL&amp;nbsp;中新的流批統一表類型，Paimon&amp;nbsp;作為首個支持該功能的&amp;nbsp;Catalog&amp;nbsp;類型，提供了連貫的開發體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;人工智能&lt;/h2&gt; 
&lt;p&gt;隨着大語言模型技術的快速發展，人工智能正在從以訓練為核心轉向以推理和實際應用為核心，推動了對大規模數據實時處理的需求。作為領先的實時大數據處理引擎，Flink&amp;nbsp;一直在積極探索和創新，以應對人工智能時代帶來的機遇和挑戰，更好地支持實時人工智能應用。&lt;/p&gt; 
&lt;p&gt;Flink&amp;nbsp;CDC&amp;nbsp;3.3&amp;nbsp;版本在&amp;nbsp;&lt;code&gt;Transform&lt;/code&gt;表達式中引入了動態調用人工智能模型的能力，原生支持&amp;nbsp;OpenAI&amp;nbsp;模型。在實時捕獲數據庫數據變化後，用戶可以立即利用人工智能模型進行智能排序、語義分析或異常檢測。這種集成使&amp;nbsp;Flink&amp;nbsp;CDC&amp;nbsp;能夠有效結合流處理與檢索增強生成（RAG）技術，在實時風險控制、個性化推薦和智能日誌解析等場景中實現端到端低延遲處理，從而在數據流中釋放實時人工智能的價值。&lt;/p&gt; 
&lt;p&gt;此外，Flink&amp;nbsp;SQL&amp;nbsp;還為&amp;nbsp;AI&amp;nbsp;模型引入了專門的語法，允許用戶像定義&amp;nbsp;Catalog&amp;nbsp;一樣輕鬆定義人工智能模型，並在&amp;nbsp;SQL&amp;nbsp;語句中像函數或表函數一樣調用它們。與&amp;nbsp;Flink&amp;nbsp;CDC&amp;nbsp;相比，Flink&amp;nbsp;SQL&amp;nbsp;支持更復雜的關係數據處理邏輯，能夠無縫將複雜數據處理工作流與人工智能模型集成，這一特性目前正處於積極開發和完善之中。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;其他&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_14&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;DataStream&amp;nbsp;V2&amp;nbsp;API&lt;/h3&gt; 
&lt;p&gt;DataStream&amp;nbsp;API&amp;nbsp;是&amp;nbsp;Flink&amp;nbsp;提供的兩種主要&amp;nbsp;API&amp;nbsp;之一，用於編寫靈活的數據處理程序。作為一個幾乎自項目第一天起就引入並在近十年中不斷演進的&amp;nbsp;API，我們也越來越意識到它存在着諸多問題。對這些問題的改進需要巨大的不兼容變更，這使得原地重構幾乎不切實際。因此，Flink&amp;nbsp;社區在&amp;nbsp;2.0&amp;nbsp;版本引入了一組新的&amp;nbsp;API，即&amp;nbsp;DataStream&amp;nbsp;API&amp;nbsp;V2，以逐步取代原始的&amp;nbsp;DataStream&amp;nbsp;API。&lt;/p&gt; 
&lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0&amp;nbsp;中，我們提供了&amp;nbsp;DataStream&amp;nbsp;V2&amp;nbsp;API&amp;nbsp;的最小可行產品 (MVP) 版本。它包含底層的基礎構建部分（數據流、處理函數、分區），以及狀態、時間服務、水位線處理等上下文和原語。同時，我們還提供了一些高級擴展，如窗口和&amp;nbsp;Join。它們更像是一種語法糖，沒有它們，用戶仍然可以通過使用基礎&amp;nbsp;API&amp;nbsp;實現相同行為，但內置支持會讓實現更加容易。&lt;/p&gt; 
&lt;p&gt;更多詳情請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Fdatastream-v2%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;文檔&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&amp;nbsp;新的&amp;nbsp;DataStream&amp;nbsp;API&amp;nbsp;目前處於實驗階段，尚不穩定，因此目前不建議在生產環境中使用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_15&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;SQL&amp;nbsp;gateway&amp;nbsp;支持&amp;nbsp;Application&amp;nbsp;模式&lt;/h3&gt; 
&lt;p&gt;SQL&amp;nbsp;gateway&amp;nbsp;現在支持以&amp;nbsp;Application&amp;nbsp;模式執行&amp;nbsp;SQL&amp;nbsp;作業，取代了已移除的&amp;nbsp;Per-Job&amp;nbsp;部署模式。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;SQL&amp;nbsp;語法增強&lt;/h3&gt; 
&lt;p&gt;Flink&amp;nbsp;SQL&amp;nbsp;現在支持&amp;nbsp;C&amp;nbsp;風格的轉義字符串。更多詳情請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Foverview%2F%23syntax&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;文檔&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;新增了更簡潔的&amp;nbsp;&lt;code&gt;QUALIFY&lt;/code&gt;&amp;nbsp;子句，用於過濾窗口函數的輸出。有關示例，請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Ftopn%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Top-N&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fdeduplication%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;去重&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;對於表函數調用，在&amp;nbsp;&lt;code&gt;FROM&lt;/code&gt;&amp;nbsp;中不再需要使用&amp;nbsp;&lt;code&gt;TABLE()&lt;/code&gt;&amp;nbsp;包裹。更多示例請參閲更新後的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fwindow-tvf&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;窗口表值函數&lt;/a&gt;文檔。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;Java&amp;nbsp;支持&lt;/h3&gt; 
&lt;p&gt;從&amp;nbsp;2.0&amp;nbsp;版本開始，Flink&amp;nbsp;正式支持&amp;nbsp;Java&amp;nbsp;21，默認和推薦的&amp;nbsp;Java&amp;nbsp;版本已更改為&amp;nbsp;Java&amp;nbsp;17（此前為&amp;nbsp;Java&amp;nbsp;11）。同時，Flink&amp;nbsp;2.0&amp;nbsp;不再支持&amp;nbsp;Java&amp;nbsp;8。這一變更主要影響&amp;nbsp;Docker&amp;nbsp;鏡像和從源代碼構建&amp;nbsp;Flink。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_18&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;序列化改進&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Flink&amp;nbsp;2.0&amp;nbsp;為集合類型（Map/List/Set）引入了更高效的內置序列化器，並且默認啓用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kryo&amp;nbsp;依賴升級到了&amp;nbsp;5.6&amp;nbsp;版本，該版本速度更快，內存效率更高，並且對較新的&amp;nbsp;Java&amp;nbsp;版本有更好的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_19&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;非兼容性變更&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_20&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;以下幾組&amp;nbsp;API&amp;nbsp;已被完全移除。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DataSet&amp;nbsp;API。&lt;/strong&gt;&amp;nbsp;請遷移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Fdatastream%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DataStream&amp;nbsp;API&lt;/a&gt;，或在適用的情況下遷移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Ftable%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Table&amp;nbsp;API/SQL&lt;/a&gt;。有關如何從&amp;nbsp;DataSet&amp;nbsp;遷移到&amp;nbsp;DataStream&amp;nbsp;的更多信息，請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.20%2Fdocs%2Fdev%2Fdatastream%2Fdataset_migration&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;如何從&amp;nbsp;DataSet&amp;nbsp;遷移到&amp;nbsp;DataStream&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scala&amp;nbsp;DataStream&amp;nbsp;和&amp;nbsp;DataSet&amp;nbsp;API。&lt;/strong&gt;&amp;nbsp;請遷移到&amp;nbsp;Java&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdev%2Fdatastream%2Foverview%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DataStream&amp;nbsp;API&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SourceFunction、SinkFunction&amp;nbsp;和&amp;nbsp;Sink&amp;nbsp;V1。&lt;/strong&gt;&amp;nbsp;請遷移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fconnector%2Fsource%2FSource.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Source&lt;/a&gt;和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fconnector%2Fsink2%2FSink.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Sink&amp;nbsp;V2&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TableSource&amp;nbsp;和&amp;nbsp;TableSink。&lt;/strong&gt;&amp;nbsp;請遷移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fconnector%2Fsource%2FDynamicTableSource.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DynamicTableSource&lt;/a&gt;和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fconnector%2Fsink%2FDynamicTableSink.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DynamicTableSink&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TableSchema、TableColumn&amp;nbsp;和&amp;nbsp;Types。&lt;/strong&gt;&amp;nbsp;請分別遷移到&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fapi%2FSchema.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Schema&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fcatalog%2FColumn.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Column&lt;/a&gt;和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-table%2Fflink-table-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Ftable%2Fapi%2FDataTypes.java&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DataTypes&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;從&amp;nbsp;&lt;strong&gt;DataStream&amp;nbsp;API&lt;/strong&gt;&amp;nbsp;中移除了部分已棄用的方法。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;從&amp;nbsp;&lt;strong&gt;REST&amp;nbsp;API&lt;/strong&gt;&amp;nbsp;中移除了部分已棄用的字段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&amp;nbsp;您可能會發現某些已移除的&amp;nbsp;API&amp;nbsp;仍然存在於代碼庫中，通常位於不同的包路徑下。它們僅用於內部用途，可能會隨時被更改或移除。請&lt;strong&gt;勿使用&lt;/strong&gt;它們。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_21&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;連接器適配計劃&lt;/h2&gt; 
&lt;p&gt;隨着&amp;nbsp;SourceFunction、SinkFunction&amp;nbsp;和&amp;nbsp;SinkV1&amp;nbsp;的移除，依賴這些&amp;nbsp;API&amp;nbsp;的現有連接器將無法在&amp;nbsp;Flink&amp;nbsp;2.x&amp;nbsp;系列上運行。以下是&amp;nbsp;Flink&amp;nbsp;官方支持的連接器的適配計劃。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在&amp;nbsp;Flink&amp;nbsp;2.0.0&amp;nbsp;發佈後，將立即發佈適配&amp;nbsp;API&amp;nbsp;變化的&amp;nbsp;Kafka、Paimon、JDBC&amp;nbsp;和&amp;nbsp;ElasticSearch&amp;nbsp;連接器的新版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;我們計劃在接下來的&amp;nbsp;3&amp;nbsp;個次要版本（即到&amp;nbsp;Flink&amp;nbsp;2.3）內逐步支持剩餘的連接器。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;配置&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;符合以下標準的配置項將被移除：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;標記為&amp;nbsp;&lt;code&gt;@Public&lt;/code&gt;&amp;nbsp;且已棄用至少&amp;nbsp;2&amp;nbsp;個次要版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;標記為&amp;nbsp;&lt;code&gt;@PublicEvolving&lt;/code&gt;&amp;nbsp;且已棄用至少&amp;nbsp;1&amp;nbsp;個次要版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持舊版配置文件&amp;nbsp;&lt;code&gt;flink-conf.yaml&lt;/code&gt;。請改用標準&amp;nbsp;YAML&amp;nbsp;格式的&amp;nbsp;&lt;code&gt;config.yaml&lt;/code&gt;。我們提供了一個遷移工具，可將舊版&amp;nbsp;&lt;code&gt;flink-conf.yaml&lt;/code&gt;&amp;nbsp;轉換為新的&amp;nbsp;&lt;code&gt;config.yaml&lt;/code&gt;。有關更多詳情，請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Fdocs%2Fdeployment%2Fconfig%2F%23migrate-from-flink-confyaml-to-configyaml&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;從&amp;nbsp;flink-conf.yaml&amp;nbsp;遷移至&amp;nbsp;config.yaml&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;從&amp;nbsp;&lt;code&gt;StreamExecutionEnvironment&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;ExecutionConfig&lt;/code&gt;&amp;nbsp;中移除了以&amp;nbsp;Java&amp;nbsp;對象為參數的配置&amp;nbsp;API。它們現在應通過&amp;nbsp;&lt;code&gt;Configuration&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;ConfigOption&lt;/code&gt;&amp;nbsp;設置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為避免暴露內部接口，用戶定義函數不再完全訪問&amp;nbsp;&lt;code&gt;ExecutionConfig&lt;/code&gt;。相反，必要的功能（如&amp;nbsp;&lt;code&gt;createSerializer()&lt;/code&gt;、&lt;code&gt;getGlobalJobParameters()&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;isObjectReuseEnabled()&lt;/code&gt;）現在可直接從&amp;nbsp;&lt;code&gt;RuntimeContext&lt;/code&gt;&amp;nbsp;訪問。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;其他&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Flink&amp;nbsp;1.x&amp;nbsp;和&amp;nbsp;2.x&amp;nbsp;之間不保證狀態兼容性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持&amp;nbsp;Java&amp;nbsp;8，Flink&amp;nbsp;現在支持的最低&amp;nbsp;Java&amp;nbsp;版本是&amp;nbsp;Java&amp;nbsp;11。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持&amp;nbsp;Per-Job&amp;nbsp;部署模式，請改用&amp;nbsp;Application&amp;nbsp;模式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hybrid&amp;nbsp;Shuffle&amp;nbsp;的舊模式已經被基於分層存儲的新架構所取代並移除。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_24&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;發行説明&lt;/h1&gt; 
&lt;p&gt;有關功能、改進、錯誤修復的全面列表，以及升級過程中需要關注的調整和問題，請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-master%2Frelease-notes%2Fflink-2.0%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;發行説明&lt;/a&gt;。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_25&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;貢獻者名單&lt;/h1&gt; 
&lt;p&gt;Apache&amp;nbsp;Flink&amp;nbsp;社區感謝對此版本做出貢獻的每一位貢獻者：&lt;/p&gt; 
&lt;p&gt;Alan&amp;nbsp;Sheinberg,&amp;nbsp;Aleksandr&amp;nbsp;Pilipenko,&amp;nbsp;Alex&amp;nbsp;Sorokoumov,&amp;nbsp;AlexYinHan,&amp;nbsp;Alexander&amp;nbsp;Fedulov,&amp;nbsp;Ammu,&amp;nbsp;Andrei&amp;nbsp;Kaigorodov,&amp;nbsp;Andrey&amp;nbsp;Gaskov,&amp;nbsp;Arkadiusz&amp;nbsp;Dankiewicz,&amp;nbsp;Arvid&amp;nbsp;Heise,&amp;nbsp;BoShuai&amp;nbsp;Li,&amp;nbsp;Brisk&amp;nbsp;Wong,&amp;nbsp;Cancai&amp;nbsp;Cai,&amp;nbsp;Chesnay&amp;nbsp;Schepler,&amp;nbsp;Chester,&amp;nbsp;Chris,&amp;nbsp;CuiYanxiang,&amp;nbsp;Danny&amp;nbsp;Cranmer,&amp;nbsp;David&amp;nbsp;Anderson,&amp;nbsp;David&amp;nbsp;Moravek,&amp;nbsp;David&amp;nbsp;Radley,&amp;nbsp;Dawid&amp;nbsp;Wysakowicz,&amp;nbsp;Dian&amp;nbsp;Fu,&amp;nbsp;Dmitriy&amp;nbsp;Linevich,&amp;nbsp;Eaugene&amp;nbsp;Thomas,&amp;nbsp;Fabian&amp;nbsp;Hueske,&amp;nbsp;Feng&amp;nbsp;Jin,&amp;nbsp;Ferenc&amp;nbsp;Csaky,&amp;nbsp;Francesco&amp;nbsp;Di&amp;nbsp;Chiara,&amp;nbsp;Gabor&amp;nbsp;Somogyi,&amp;nbsp;Gantigmaa&amp;nbsp;Selenge,&amp;nbsp;Grace&amp;nbsp;Grimwood,&amp;nbsp;Grzegorz&amp;nbsp;Kołakowski,&amp;nbsp;Gustavo&amp;nbsp;de&amp;nbsp;Morais,&amp;nbsp;Hanyu&amp;nbsp;Zheng,&amp;nbsp;Hao&amp;nbsp;Li,&amp;nbsp;Hong&amp;nbsp;Teoh,&amp;nbsp;Hyungstler,&amp;nbsp;Jacky&amp;nbsp;Lau,&amp;nbsp;James&amp;nbsp;Hughes,&amp;nbsp;Jeyassri&amp;nbsp;Balachandran,&amp;nbsp;Jiangjie&amp;nbsp;(Becket)&amp;nbsp;Qin,&amp;nbsp;Jim&amp;nbsp;Hughes,&amp;nbsp;Jingsong,&amp;nbsp;Joern&amp;nbsp;Kottmann,&amp;nbsp;Joery,&amp;nbsp;JunRuiLee,&amp;nbsp;Junrui&amp;nbsp;Lee,&amp;nbsp;Kaitian&amp;nbsp;Hu,&amp;nbsp;Kartikey&amp;nbsp;Pant,&amp;nbsp;Kunni,&amp;nbsp;Kurt&amp;nbsp;Ostfeld,&amp;nbsp;Lajith,&amp;nbsp;Lei&amp;nbsp;Yang,&amp;nbsp;Lorenzo&amp;nbsp;Affetti,&amp;nbsp;Luke&amp;nbsp;Chen,&amp;nbsp;Marc&amp;nbsp;Aurel&amp;nbsp;Fritz,&amp;nbsp;Martijn&amp;nbsp;Visser,&amp;nbsp;Márton&amp;nbsp;Balassi,&amp;nbsp;Mate&amp;nbsp;Czagany,&amp;nbsp;Matt&amp;nbsp;Braymer-Hayes,&amp;nbsp;Matthias&amp;nbsp;Pohl,&amp;nbsp;Mina&amp;nbsp;Asham,&amp;nbsp;Myracle,&amp;nbsp;Paul&amp;nbsp;Zhang,&amp;nbsp;Peng&amp;nbsp;Lu,&amp;nbsp;Peter&amp;nbsp;Huang,&amp;nbsp;Piotr&amp;nbsp;Nowojski,&amp;nbsp;Piotr&amp;nbsp;Przybylski,&amp;nbsp;Qingsheng&amp;nbsp;Ren,&amp;nbsp;Ran&amp;nbsp;Tao,&amp;nbsp;Robin&amp;nbsp;Moffatt,&amp;nbsp;Roc&amp;nbsp;Marshal,&amp;nbsp;Roman&amp;nbsp;Khachatryan,&amp;nbsp;Ron,&amp;nbsp;Rui&amp;nbsp;Fan,&amp;nbsp;Ryan&amp;nbsp;Skraba,&amp;nbsp;Sam&amp;nbsp;Barker,&amp;nbsp;Samrat,&amp;nbsp;Sergei&amp;nbsp;Morozov,&amp;nbsp;Sergey&amp;nbsp;Nuyanzin,&amp;nbsp;Sergio&amp;nbsp;Pena,&amp;nbsp;Sergio&amp;nbsp;Peña,&amp;nbsp;Shengkai,&amp;nbsp;Shuyi&amp;nbsp;Chen,&amp;nbsp;Stefan&amp;nbsp;Richter,&amp;nbsp;Sud0x67,&amp;nbsp;Tamas&amp;nbsp;Sule,&amp;nbsp;Thomas&amp;nbsp;Cooper,&amp;nbsp;Timo&amp;nbsp;Walther,&amp;nbsp;Vincent-Woo,&amp;nbsp;Wang&amp;nbsp;FeiFan,&amp;nbsp;Wang&amp;nbsp;Qian,&amp;nbsp;WangQian,&amp;nbsp;Weijie&amp;nbsp;Guo,&amp;nbsp;Wenchao&amp;nbsp;Wu,&amp;nbsp;Wenjun&amp;nbsp;Ruan,&amp;nbsp;Xia&amp;nbsp;Sun,&amp;nbsp;Xiangyu&amp;nbsp;Feng,&amp;nbsp;Xintong&amp;nbsp;Song,&amp;nbsp;Xu&amp;nbsp;Huang,&amp;nbsp;XuHao41,&amp;nbsp;XuShuai,&amp;nbsp;Xuannan,&amp;nbsp;Xuyang,&amp;nbsp;Yanfei&amp;nbsp;Lei,&amp;nbsp;Yi&amp;nbsp;Zhang,&amp;nbsp;Yiyu&amp;nbsp;Tian,&amp;nbsp;Yu&amp;nbsp;Chen,&amp;nbsp;Yubin&amp;nbsp;Li,&amp;nbsp;Yuxin&amp;nbsp;Tan,&amp;nbsp;Zakelly,&amp;nbsp;Zdenek&amp;nbsp;Tison,&amp;nbsp;Zhanghao&amp;nbsp;Chen,&amp;nbsp;Zhen&amp;nbsp;Wang,&amp;nbsp;anupamaggarwal,&amp;nbsp;argoyal2212,&amp;nbsp;auroflow,&amp;nbsp;candaccc,&amp;nbsp;clarax,&amp;nbsp;codenohup,&amp;nbsp;drymatini,&amp;nbsp;dylanhz,&amp;nbsp;fengli,&amp;nbsp;fredia,&amp;nbsp;gongzhongqiang,&amp;nbsp;haishui,&amp;nbsp;huyuanfeng,&amp;nbsp;jectpro7,&amp;nbsp;lexluo09,&amp;nbsp;lincoln&amp;nbsp;lee,&amp;nbsp;liuyongvs,&amp;nbsp;lvyanquan,&amp;nbsp;lz,&amp;nbsp;mayuehappy,&amp;nbsp;mehdid93,&amp;nbsp;morazow,&amp;nbsp;naferx,&amp;nbsp;nateab,&amp;nbsp;noorall,&amp;nbsp;r-sidd,&amp;nbsp;shalini,&amp;nbsp;simplejason,&amp;nbsp;slankka,&amp;nbsp;sullis,&amp;nbsp;sunxia,&amp;nbsp;sxnan,&amp;nbsp;tison,&amp;nbsp;wangfeifan,&amp;nbsp;xaniasd,&amp;nbsp;xiarui,&amp;nbsp;xincheng.ljr,&amp;nbsp;xuyang,&amp;nbsp;xuzifu666,&amp;nbsp;yinhan.yh,&amp;nbsp;yunfengzhou-hub,&amp;nbsp;zbz,&amp;nbsp;zhangmang,&amp;nbsp;zhaorongsheng,&amp;nbsp;zhengchenyu,&amp;nbsp;zhuanshenbsj1,&amp;nbsp;餘良,&amp;nbsp;皆非,&amp;nbsp;馬越,&amp;nbsp;林尚泉&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/2828172/blog/17996920</link>
            <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/17996920</guid>
            <pubDate>Sat, 22 Mar 2025 09:31:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>XPipe —— shell 連接中心和遠程文件管理器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;XPipe 是一種新型的 shell 連接中心和遠程文件管理器，可讓你從本地計算機訪問整個服務器基礎架構。它基於你已安裝的命令行程序運行，不需要在遠程系統上進行任何設置。因此，如果你通常使用 CLI 工具（如&lt;code&gt;ssh&lt;/code&gt;、&lt;code&gt;docker&lt;/code&gt;、&lt;code&gt;kubectl&lt;/code&gt;等）連接到服務器，則只需在此基礎上使用 XPipe 即可。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;XPipe 可與你的工具（例如你最喜歡的文本/代碼編輯器、終端、shell、命令行工具等）完全集成。該平台設計為可擴展的，允許任何人輕鬆添加對更多工具的支持或通過模塊化擴展系統實現自定義功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;它目前支持：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/ssh&quot;&gt;SSH&lt;/a&gt;連接、配置文件和隧道&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/docker&quot;&gt;Docker&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/podman&quot;&gt;Podman&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/lxc&quot;&gt;LXD&lt;/a&gt;和&lt;a href=&quot;https://docs.xpipe.io/guide/lxc&quot;&gt;incus&lt;/a&gt;容器&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/proxmox&quot;&gt;Proxmox PVE&lt;/a&gt;虛擬機和容器&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/hyperv&quot;&gt;Hyper-V&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/kvm&quot;&gt;KVM&lt;/a&gt;、&lt;a href=&quot;https://docs.xpipe.io/guide/vmware&quot;&gt;VMware Player/Workstation/Fusion&lt;/a&gt;虛擬機&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/kubernetes&quot;&gt;Kubernetes&lt;/a&gt;集羣、Pod 和容器&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.xpipe.io/guide/tailscale&quot;&gt;Tailscale&lt;/a&gt;和&lt;a href=&quot;https://docs.xpipe.io/guide/teleport&quot;&gt;Teleport&lt;/a&gt;連接&lt;/li&gt;
&lt;li&gt;適用於 Linux、Cygwin 和 MSYS2 環境的 Windows 子系統&lt;/li&gt;
&lt;li&gt;Powershell 遠程會話&lt;/li&gt;
&lt;li&gt;RDP 和 VNC 連接&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height=&quot;254&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/182956_MgN3_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height=&quot;301&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/183048_DlkY_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/xpipe</link>
            <guid isPermaLink="false">https://www.oschina.net/p/xpipe</guid>
            <pubDate>Sat, 22 Mar 2025 09:00:00 GMT</pubDate>
        </item>
        <item>
            <title>「賽博考古」：C 編譯器的最早版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;GitHub 有個叫 legacy-cc 的項目，竟藏着上世紀 70 年代最早版本的 C 編譯器源碼，而且是由 C 語言之父 Dennis Ritchie（dmr）老爺子親手寫的！&lt;/p&gt; 
&lt;p&gt;這個項目堪稱程序語言「考古現場」，如果你對一門語言如何從零起步演化感興趣，或者想理解 C 語言為何能成為編程界的大師級存在，絕對值得膜拜一下。&lt;/p&gt; 
&lt;p&gt;有人一邊感慨「爺青回」，一邊指出這套代碼像是某種 C 語言的原始形態：沒有類型檢查、變量默認都是 int、甚至還能在函數體裏寫 extern……這些今天看起來有些離譜的寫法，在當年卻是主流操作。&lt;/p&gt; 
&lt;p&gt;而這段代碼的價值不僅僅在於「老」，它記錄了 C 編譯器最原始的邏輯和結構——比如如何處理語法樹、內存分配、語義分析等。&lt;/p&gt; 
&lt;p&gt;你甚至能看到最初的代碼優化雛形，比如簡單卻精妙的「表達式摺疊」——這些機制，正是今天 LLVM 或 GCC 背後技術的雛形。&lt;/p&gt; 
&lt;p&gt;再説點細節：項目中包含了兩個主要目錄 prestruct 和 last1120c，分別對應早期和稍後的兩個階段。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1074&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/163642_49z7_2720166.png&quot; width=&quot;770&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;順便一提，這代碼的也算是開源界的「數字文物」，Caldera 當真敢開放。&lt;/p&gt; 
&lt;p&gt;可以看到，Caldera International 在 2002 年，就大方授權了源碼開放，授權明確説明：可免費使用、修改、分發，甚至允許基於源碼進行二創，唯一限制是不能涉及 UNIX System III / V 及之後的版本。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1678&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/163756_WvPU_2720166.png&quot; width=&quot;1414&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;就像有網友説的：「這不只是代碼，而是 Dennis Ritchie 留給後人的一份手稿。」&lt;/p&gt; 
&lt;p&gt;最後，鏈接奉上：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmortdeus%2Flegacy-cc&quot; target=&quot;_blank&quot;&gt;https://github.com/mortdeus/legacy-cc&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340897</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340897</guid>
            <pubDate>Sat, 22 Mar 2025 08:38:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>前英特爾 CEO 批評英偉達 AI 芯片定價，認為推理才是未來機遇</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;前英特爾首席執行官帕特・蓋爾辛格（Pat Gelsinger）近日在英偉達 2025 年 GPU 技術大會的《Acquired》播客中&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Flive%2FpgLdJq9FRBQ%3Ft%3D2291s&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，英偉達的人工智能 (AI) 圖形處理器 (GPU) 定價策略過高，難以支持大規模的 AI 推理任務。蓋爾辛格指出，推理是部署 AI 模型的關鍵環節，當前行業的發展趨勢應該更關注推理，而英偉達的技術在成本效益上難以滿足這一需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;227&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e16cdecc2dda96a32b455066f1a2df3b995.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他提到，英偉達用於 AI 訓練的處理器價格高達現實所需的 10，000 倍之多。雖然蓋爾辛格承認早期生成式 AI 的快速發展主要得益於英偉達的圖形處理單元（GPU），但他認為，該公司的強項 —— 依託 CUDA 軟件平台的技術 —— 在推理成為主流之後可能會面臨挑戰。他強調，儘管存在缺陷，但他也對英偉達首席執行官黃仁勳 (Jensen Huang) 的遠見與堅韌表示讚賞，認為黃仁勳在通用圖形處理器與 AI 工作負載的早期預測上取得了成功，但這一成就也部分源於良好的時機。他甚至調侃説，「黃仁勳運氣不錯」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在蓋爾辛格的帶領下，英特爾在 AI 硬件領域的競爭中面臨壓力。該公司推出的 Gaudi 加速器芯片在性能上未能趕上英偉達的 Hopper 和 AMD 的 Instinct 產品。英特爾目前已將 Falcon Shores 人工智能平台擱置，轉而專注於下一代項目 「Jaguar Shores」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蓋爾辛格還提到，計算機架構可能會發生變化，量子計算有望在本世紀末實現商業化。然而，他未透露英特爾在這一變革中的具體計劃。儘管機器學習基礎設施需求激增，英特爾在 AI 收入方面仍遠遠落後於競爭對手，顯現出公司在這一領域的整體困難。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340889</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340889</guid>
            <pubDate>Sat, 22 Mar 2025 07:53:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AMD 開源 「GAIA」：用於本地高效運行大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;AMD&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.amd.com%2Fen%2Fdeveloper%2Fresources%2Ftechnical-articles%2Fgaia-an-open-source-project-from-amd-for-running-local-llms-on-ryzen-ai.html&quot;&gt;宣佈&lt;/a&gt;推出專為本地運行大語言模型（LLM）設計的開源應用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Famd%2Fgaia&quot;&gt;GAIA&lt;/a&gt;（發音 /ˈɡaɪ.ə/），目前支持 Windows 平台。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f939cebbc620ee07d4ce6b2ffb201d6d2fc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;GAIA 是一款生成式 AI 應用，&lt;strong&gt;可在 Windows PC 上實現本地化私密運行 LLM&lt;/strong&gt;，並針對鋭龍 AI 300 系列處理器進行了優化。該應用通過 NPU 提升 AI 任務性能，並支持混合部署量化 LLM。&lt;/p&gt; 
&lt;p&gt;GAIA 基於 ONNX TurnkeyML 的 Lemonade SDK 開發，採用檢索增強生成（RAG）技術，支持 Llama、Phi 等主流模型。其四大功能模塊包括 Chaty 聊天機器人、Clip 視頻搜索專家、Joker 笑話生成器和 Simple Prompt 測試工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2a29e1d73556bb5e0390921046bf1ad85e4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;AMD 提供普通版和混合版安裝方案，普通版兼容任意 Windows 設備，混合版專為鋭龍 AI 300 系列優化。&lt;/p&gt; 
&lt;p&gt;GAIA 的本地化處理確保數據隱私，響應延遲降低至毫秒級，並支持離線運行。該項目採用 MIT 開源協議，未來或擴展至多平台支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340886/amd-gaia-running-local-llms-on-ryzen-a</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340886/amd-gaia-running-local-llms-on-ryzen-a</guid>
            <pubDate>Sat, 22 Mar 2025 07:38:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里雲開啓近年來規模最大的 AI 人才校園招聘</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9UyL73Bk6FBWpWcnfFfq-A&quot; target=&quot;_blank&quot;&gt;根據《科創板日報》的獨家報道&lt;/a&gt;&lt;/u&gt;，阿里雲近日在全球頂尖高校招募 AI 技術儲備人才，為近年來規模最大的 AI 人才校園招聘。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;840&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/152257_OouC_2720166.png&quot; width=&quot;844&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，此次校招面向清華大學、北京大學、浙江大學、麻省理工大學、斯坦福大學等全球頂尖高校，招募大語言模型、多模態理解與生成、模型應用、AI Infra 等領域技術人才。&lt;/p&gt; 
&lt;p&gt;同時，&lt;strong&gt;項目設置 A Star 項目和 Al Clouder 項目，面向具備高水平論文、開源項目影響力等特質的頂尖人才，為這類畢業生提供更優薪酬和專業扶&lt;/strong&gt;持。&lt;/p&gt; 
&lt;p&gt;此舉系之前 T 項目後，阿里巴巴推出的又一項 AI 人才戰略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339514&quot; target=&quot;news&quot;&gt;阿里全面 AI 化，公司內部相信「基於 AI 的殺手級應用可能很快就出現」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339418&quot; target=&quot;news&quot;&gt;阿里雲啓動「T 項目」，加速 AI 研發&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338747&quot; target=&quot;news&quot;&gt;阿里巴巴董事長蔡崇信：AI 市場規模至少 10 萬億美元&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340879</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340879</guid>
            <pubDate>Sat, 22 Mar 2025 07:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開放，開源，全球化，國產算力展現三大演進趨勢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我國計算產業正在自主創新中快速發展，呈現出開放、開源、全球化三大趨勢。專家認為，面對人工智能在各行各業加快應用帶來的海量算力需求，我國計算產業亟須抓住機遇，構建算力新體系，打造世界級新產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;數字基礎設施量質齊升&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;工業和信息化部 3 月 17 日公佈的數據顯示，2024 年我國數字基礎設施量質齊升。截至 2024 年末，全國在用算力中心標準機架數超過 880 萬，算力總規模較上年末增長 16.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作為數字經濟時代的核心生產力，算力對經濟的巨大拉動作用已經顯現。中國信息通信研究院發佈的《中國算力發展指數白皮書（2023 年）》顯示，算力每投入 1 元錢，就將帶動 3 至 4 元的 GDP 增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在數字經濟大省浙江，去年數字經濟核心產業增加值突破 1 萬億元。據介紹，在推進數字浙江建設進程中，於 2020 年投入運營的浙江省鯤鵬生態創新中心為浙江數字經濟的發展提供了技術支撐和創新動力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作為國產算力的中堅力量，在硬件層面，鯤鵬 CPU 展現出強大競爭力，部件、整機實現全量自主創新，構建起堅實的自主創新產業鏈；在基礎軟件領域，以開源歐拉、開源高斯為代表的開源項目蓬勃發展，不斷豐富和繁榮軟件生態，為浙江數字產業發展提供了源源不斷的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作報告提出，「激發數字經濟創新活力」，並作出了「優化全國算力資源佈局」等具體部署。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 等機構認為，2025 年中國智能算力規模將達到 1037.3EFLOPS，並在 2028 年達到 2781.9EFLOPS。當前，我國算力總規模已位居全球第二，但仍存在算力資源供給緊張和不能有效利用的矛盾情況。算力規模的高速增長和供需錯配等挑戰將為國產算力的未來發展提供新空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;三大產業演進趨勢漸明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;專家認為，目前計算產業變革呈現出三大趨勢：一是算力架構的開放特性加速了端、邊、雲全場景的快速協同發展；二是算力生態共建正在替代單邊創新；三是計算產業的全球化趨勢愈發清晰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在業界看來，當前算力領域的技術路線正向多元化、多維度演進。受限於封閉架構的短板，傳統的 X86 架構難以形成生態，而 ARM 架構的開放模式，將成為未來通用算力的主流選擇。數據顯示，當前全球算力大約 80% 屬於 ARM 架構，其中 99% 的手機採用的都是 ARM 芯片，國內的鯤鵬和飛騰以及國外都有基於 ARM 架構的產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，DeepSeek 的開源實踐，推動了人工智能技術的普及和應用。在算力領域，開源同樣帶來了生態的繁榮。例如，鯤鵬聯合超過 6000 家合作伙伴構建的「技術樂高」模式，就證明瞭開源協作的強大生命力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源、開放的生態也讓計算產業打開了全球化的新格局。通過攜手合作，產業各方開始充分發揮自身優勢，通過資源共享與互補，聯合打造更具競爭力的解決方案，共同開拓國際市場，為全球客戶提供創新產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以鯤鵬生態為例，近年來，通過開源、開放，鯤鵬打造了從芯片、整機到操作系統、數據庫的自主創新生態。數據顯示，截至目前，鯤鵬生態已發展超過 335 萬鯤鵬開發者，面向硬件、軟件和應用全面創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;迎接人工智能時代新機遇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;業內人士指出，隨着人工智能應用場景的爆發式增長，算力需求呈現快速攀升態勢。正如當年互聯網推動 PC 快速普及和升級一樣，如今人工智能的大範圍落地應用也將激活對算力的龐大需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作報告提出，持續推進「人工智能＋」行動，將數字技術與製造優勢、市場優勢更好結合起來，支持大模型廣泛應用。多家機構認為，「人工智能+」行動將重塑所有產業，DeepSeek 的火爆更為大模型應用落地提供了催化劑，不僅將加速各行各業的智能化轉型，更將驅動中國計算產業升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 最新數據顯示，2025 年，中國人工智能市場總規模將達到 511.3 億美元，同比增長 34.8%，預計到 2028 年市場規模將達到 1010 億美元，年複合增長率達到 25.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;面對人工智能時代的新機遇，專家認為，我國計算產業應抓住這一歷史性機遇，打造世界級新產品，構築堅實的算力底座。一是要構建自主創新的算力新體系。IDC 發佈的 2024 年中國服務器市場報告顯示，自主算力鯤鵬系服務器市場份額佔比已達 20% 以上，覆蓋了金融、運營商、政府、互聯網等核心場景。二是要打造開放開源的自主軟件生態。據 IDC 報告，在中國服務器操作系統領域，2024 年開源歐拉系份額達到 50%，累計裝機量突破 1000 萬套；據沙利文數據，2024 年 openGauss 在關係型數據庫中佔比 28.5%，超過 MySQL 和 PG，成為三個主流開源數據庫技術路線之首。三是要構築根植中國、面向全球的通用計算產業。工業和信息化部數據顯示，2024 年開源歐拉用戶數量超過 380 萬，為全球 150 餘個國家和地區提供服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;專家預測，未來幾年，人工智能技術普及將推動算力需求出現爆發式增長。我國計算產業將通過在根技術上的自主創新突破，實現性能提升和成本優化，助力人工智能技術的規模化商用和千行百業的智能化轉型，並逐漸走向全球市場，打造面向人工智能時代的通用算力底座。（經濟參考報，記者，吳蔚）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340875</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340875</guid>
            <pubDate>Sat, 22 Mar 2025 07:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>國家數據局：以高質量數據促進人工智能發展</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國家數據局局長劉烈宏 24 日在中國發展高層論壇 2025 年年會上表示，國家數據局將充分調動社會各方力量，積極推動高質量數據集建設，持續增加數據供給，推動「人工智能+」行動賦能千行百業，打造包容開放的創新環境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;302&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bfc45482de2edcfe691d1f74d79bbdf71b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;劉烈宏説，高質量數據與人工智能的結合，將會進一步發揮數據和人工智能的倍增效應。如何更好以高質量數據促進人工智能發展？劉烈宏提出重點做好四方面工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進基礎制度供給——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;劉烈宏説，將統籌開展數據領域規劃編制工作，加快形成數據領域的規劃體系，制定印發數據產權制度和培育全國一體化數據市場的文件，加快推進數據基礎制度建設，組織開展數字中國、數字經濟、數據要素綜合試驗區的建設，因地制宜開展先行先試，為數據要素價值釋放積累實踐經驗，健全完善數據治理、數據安全等制度，更好保障人工智能安全發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進高質量數據供給——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「‘人工智能+’行動到哪裏，高質量數據集的建設和推廣就要到哪裏。」劉烈宏説，將強化公共數據資源登記管理，規範公共數據資源授權運營實施，建立授權運營價格形成機制，積極引導做好高質量數據集建設工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進數據基礎設施建設——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;生成式人工智能的快速發展，對算力和數據流通利用提出更高更迫切的需求。劉烈宏表示，將系統推進全國一體化算力網建設，創新算力電力協同機制，推動算力設施一體化、集約化、綠色化發展。同時，加快國家數據基礎設施建設，推動區域、行業數據基礎設施互聯互通。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進數據領域國際合作深化——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國家數據局將推進數據領域高水平開放，為中外數字企業發展創造良好環境。「歡迎世界各國企業參與到中國數據要素市場化、價值化進程中，共享數據發展紅利和發展機遇。同時我們也將積極參與並持續推動人工智能安全治理，加強國際合作和對話，為全球治理體系完善提供新的動力。」劉烈宏説。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340860</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340860</guid>
            <pubDate>Sat, 22 Mar 2025 06:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>高併發場景下的庫存管理，理論與實戰能否兼得？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本篇文章，是一篇實戰後續篇，是基於之前我發了一篇關於如何構建高併發系統文章的延伸： &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F35216%3FshareId%3D8087%26isHideShareButton%3D1&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高併發系統的藝術：如何在流量洪峯中游刃有餘&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而這篇文章，從實踐出發，解決一個真實場景下的高併發問題：秒殺場景下的系統庫存扣減問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着互聯網業務的不斷發展，選擇在網上購物的人羣不斷增加，這種情況下，會衍生出一些促銷活動，類似搶購場景或者熱銷熱賣場景，在高峯時段的下單數量會非常大，也意味着對數據庫中暢銷商品的庫存操作十分頻繁，需要頻繁查庫存和更新庫存。這屬於高讀寫場景，比起單獨的併發讀和併發寫來説，業務場景更復雜一些。那麼這種高併發為了保證庫存數據一致性，一般會在數據庫更新時進行加鎖操作，以保證系統不會發生超賣情況。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們應該如何應對呢？大家可以根據我之前那篇文章中的思維導圖，跟隨我的思路，一起來看如何解決當前場景下的高併發問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;小試牛刀&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面對庫存扣減的場景，我們第一個考慮到是數據一致性問題，因為超賣會對我們的履約和客戶信譽造成影響。所以一般情況下，在數據庫更新時進行加鎖操作，以保證系統不會發生超賣情況。所以更多方案是提高數據庫性能方法，比如增加硬件性能，優化樂觀鎖，提升鎖效率，優化 SQL 性能等。對於一些大型系統，也衍生出一些基於分片的庫存方案，通過分庫分表增加併發吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然那這樣不夠，因為 MySQL 數據庫的讀寫的併發上線能力是有限的，我們還是需要再進一步優化我們的方案。這裏就要參考之前我寫的那篇文章中的思維導論了，這裏常見解決方案就是，引入緩存機制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如下圖所示，我們把讀請求進行緩存，每次庫存校驗時，我們引入 redis 緩存，讀請求通過緩存，增加接口性能，然後庫存扣減時，在進行緩存同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c08115baf35c2454a8997ca9afa97a80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但這種方式存在很大問題： 所有請求都會在這裏等待鎖，獲取鎖有去扣減庫存。在併發量不高的情況下可以使用，但是一旦併發量大了就會有大量請求阻塞在這裏，導致請求超時，進而整個系統雪崩；而且會頻繁的去訪問數據庫，大量佔用數據庫資源，所以在併發高的情況下這種方式不適用。同時這個方案還會存在 mysq 和 redis 的數據同步不一致的情況，導致高併發情況下，出現超賣。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;所以這種方案雖然簡單，但是無法滿足高併發場景，我們必須得 pass。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;循序漸進&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;為此，我們可以進行一次優化，通過架構維度進行調整。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在這個方案中，我們將庫存操作封裝成一個單獨模塊，這個方案的優化點在於，所有庫存的查詢和扣減都圍繞 redis 進行。當發生庫存扣減操作時，會直接更新 redis，同時採用異步流程，更新 MySQL 數據庫。這樣以來，我們的性能會比直接訪問 MySQL 數據庫高效不少，併發能力會有不少提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;流程如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//f6f8964c0024b3ee676272e4655ccfa7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但這個方案依然有缺陷，它的點在於 redis 的單點性能問題。該方案的最大併發性能取決於 redis 的單點處理能力。而如果想要進一步提升併發能力，該方案不具備水平擴展能力。那麼，這個方案，依然不是我們最優的選擇。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大顯身手&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那麼接下來，我們需要考慮的是如何可以實現我們業務系統併發能力的水平擴展能力。當然這裏也不是憑空來想，我們可以思考一下，業內成熟的一些中間件是如何實現高併發的，這裏我們可以兩個我們常見的框架：kafka 和 elasticsearch。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;上述我們常見的兩個中間件框架，都以可以水平能力擴展著稱。那麼仔細思考一下他們的技術架構不難發現，他們的核心其實都是採用了一種所謂的分片實現的。那麼問題來了，我們的庫存扣減，能不能實現分片呢？或者換一個思路思考這個問題：我們的庫存邏輯是否可以轉化為分佈式庫存進行存儲和擴展呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有了以上的思路，我們就可以開始構建我們的架構方案了。接下來，我先把架構圖貼出來：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//6542ddad18a4604d2a38c7b51195fe8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在這個架構方案中，是以 Redis 緩存為實現基礎，結合 Mysql 數據存儲，通過一套控制機制，保證庫存的分佈式管理。在該方案中，有一些特定的業務模塊單元需要説明。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1. partition&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;熟悉 kafka 的人對 partition 一定不陌生。在本架構方案之中，該業務架構中的 partition 的概念是一組基於 redis 來實現的庫存分片，分別存儲一部分庫存大小。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一個 partition 中，會存有一定量的預佔庫存量，當有請求服務進行庫存扣減時，只需要選擇其中一個 partition 即可，這樣以來，就可以減輕單節點的壓力，同時可以基於 redis 集羣的可擴展性，實現 partition 的水平擴展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分佈式系統常見的一個問題就是數據傾斜問題，因為嚴重的數據傾斜，會讓我們分佈式方案瞬間瓦解，導致單點承擔高併發。那麼該方案下的數據傾斜問題如何解決呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;最終，我想到的解決方案類似養寵物狗時買的那種定時投餵儀器，每天通過定時定量投餵，來保證寵物狗不會被餓到或者吃撐。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果最初把所有庫存全部平均到每個 partition 中，當有多個大庫存扣減打到一個 partition 上時，會造成該 partition 上出現庫存被消耗光，而失去後續提供庫存扣減能力。為瞭解決這個問題，我在 partition 中採取的是動態庫存注入和子域隔離的方案。具體方案如下圖：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//8c57d7654d67f6af4f23f47905ef2ce6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每個 partition 會有兩個子域，調度器中會記錄每個 partition 當前激活的子域，每次庫存扣減，會扣減激活的子域中的庫存值。而當激活的子域庫存值低於設定閾值是，會切換子域，冷卻當前子域，激活另一個子域。被冷卻的子域會觸發任務觸發器，實現預佔庫存的數據同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;子域中會存儲一定額度的庫存值，不會存儲很大的量，這樣就可以保證動態的預佔庫存實現，從而解決庫存傾斜的問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然為了更好的管理 partition，我們需要單獨開發一個 partition 調度器模塊，來負責管理管理眾多 partition 資源，那麼這個調度器的具體功能包括：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;1.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;調度器中有一個註冊表，會記錄 Partition 的 key 值，外部服務獲取 partition key 是需要通過調度器獲取，調度器會記錄每個 partition 的庫存餘量和 partition 和子域信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;2.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當 partition 無法再獲取預佔庫存，且庫存耗盡時，調度器會從註冊表中摘除該 partition 信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;3.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 調度器可以採用隨機或者輪訓的方式獲取 partition，同時每次也會校驗 partition 剩餘庫存是否滿足業務扣減數量，如果剩餘庫存小於業務扣減數量，將會跳過該 partition 節點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2. 異步更新庫存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二個核心模塊就是更新庫存管理了，這塊你可以理解為異步流程機制，通過異步化操作，來減輕系統的高併發對數據庫的衝擊。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更新庫存會有一個明細表，記錄每個 partition 庫存扣減信息，明細表會有一個同步狀態，有兩種情況可以出發庫存同步 MQ 消息：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一． 當每個 partition 中的明細數據條數超過設定閾值，會自動觸發一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二． 每間隔額定設定時間 (默認設置 1 秒)， 會觸發一次當前時間段內每個 partition 產生的庫存扣減明細信息，然後發送一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;兩中觸發方案相互獨立，互不影響，通過同步狀態和明細 ID 實現冪等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3. 預佔庫存管理和庫存管理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接下來就是關於庫存的底層數據結構設計了。這裏會引入一個在電商行業很共識的概念：預佔庫存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在庫存領域層中，庫存分為預佔庫存和庫存兩個模塊，這裏面的庫存關係實例如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假設當前商品的庫存值為 10000 件，當前 partition 觸發一次預佔庫存任務，領取 400 件， 然後假設此時收到 MQ 庫存消費更新消息，更新 30 件。隨後 partition 又觸發一次預佔庫存任務，零陵區了 100 件。庫存變化如下圖所示：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c83f3fadc83623765f0e90cf251f75ad.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其中，實際庫存= 預設庫存池 + 預佔庫存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每次預佔庫存任務觸發，會從預設庫存池中扣減，如果預佔庫存池清空，則 partition 就無法在獲取預佔庫存，調度器會將它從註冊表中摘除。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而每次 MQ 更新庫存消息，會更新實際庫存量，同時對預佔庫存和扣減庫存值進行修改，這個操作具有事務性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_8&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;總結&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;通過這次的案例分析，我們其實是通過方法論結合實際業務場景的方式出發，設計了我們的系統架構。剝離業務場景，其實本質就是通過緩存和異步流程來實現系統的高併發，同時讓系統具備擁有水平擴展的能力。但這個方法論在與實際業務結合時，還是會有很多很多需要思考和細化的點，比如分佈式思想的使用，比如預佔庫存的邏輯設計等等。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4090830/blog/17989921</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/17989921</guid>
            <pubDate>Sat, 22 Mar 2025 06:36:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>樹莓派開源鏡像定製工具 rpi-image-gen</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;樹莓派基金會近日推出開源工具 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fraspberrypi%2Frpi-image-gen&quot; target=&quot;_blank&quot;&gt;rpi-image-gen&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;rpi-image-gen 是一個根文件系統和鏡像創建工具，旨在提供高度的自定義、靈活性和控制。rpi-image-gen 使用&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbdrung%2Fbdebstrap&quot; target=&quot;_blank&quot;&gt;bdebstrap&lt;/a&gt;&amp;nbsp;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.mister-muffin.de%2Fjosch%2Fmmdebstrap&quot; target=&quot;_blank&quot;&gt; mmdebstrap &lt;/a&gt;進行根文件系統的構建，並使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpengutronix%2Fgenimage&quot; target=&quot;_blank&quot;&gt;genimage&lt;/a&gt; 進行鏡像創建。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是一個以 Bash 為中心的腳本引擎，能夠使用元數據集合和定義的執行流程生成具有不同磁盤分區佈局、文件系統和配置文件的軟件鏡像。它提供了為 Raspberry Pi 設備創建高度自定義軟件鏡像的方法。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是易於閲讀、可審計且易於使用的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;技術亮點&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;模塊化定製&lt;/strong&gt;：通過 YAML 配置文件定義軟件包列表，移除冗餘服務降低資源佔用&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全增強&lt;/strong&gt;：自動掃描鏡像內軟件組件的已知漏洞（CVE），生成 SBOM 清單滿足合規需求&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;場景化模板&lt;/strong&gt;：提供 Web Kiosk 等預設配置，5 分鐘快速生成專用設備系統&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1852&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/143335_AvvG_2720166.png&quot; width=&quot;2464&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9fd9d61d93288d85f72c7f103eb0e6445bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該工具支持用戶根據需求裁剪操作系統組件、管理軟件供應鏈安全（SBOM 與 CVE），並內置輕量化「slim」鏡像模板，為樹莓派設備創建定製化的 Raspberry Pi OS 鏡像，適用於工廠批量燒錄、邊緣計算設備集羣管理等場景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</guid>
            <pubDate>Sat, 22 Mar 2025 06:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>華為語言模型推理專利公佈，可提高對預設內容的理解能力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，華為技術有限公司、清華大學申請的「一種語言模型推理方法以及推理裝置」專利於 3 月 25 日公佈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-71363ec3371e1b4ce56ef932ddc41db7554.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要信息顯示，該方法包括：根據第四問題生成第五問題，所述第五問題用於提問所述第四問題、以及提示語言模型回答所述第四問題的回覆中不要包括預設內容；所述語言模型根據所述第五問題輸出第三回復，所述第三回復不包括所述預設內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中，所述語言模型的參數根據第一回復的評價數據更新，所述語言模型根據第一問題輸出所述第一回復，所述評價數據用於指示所述第一回復是否包括所述預設內容。該方法可以提高語言模型對預設內容的理解能力，從而更準確地抑制模型輸出預設內容。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340851</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340851</guid>
            <pubDate>Sat, 22 Mar 2025 06:25:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>人類細胞譜系大科學研究設施啓動建設，打造數字細胞 AI 大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人類細胞譜系大科學研究設施 25 日在廣州啓動建設，將繪製人類生命過程中的細胞動態演化圖譜，構建數字細胞 AI 大模型，催生生物醫藥研究新範式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一設施是國家「十四五」重大科技基礎設施，由中國科學院廣州生物醫藥與健康研究院牽頭，位於廣州國際生物島，規劃建設週期 4.5 年，總建築面積超 5 萬平方米。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人員介紹，細胞是生命的基本單元。從受精卵開始，到發育成組織器官，再到衰老全過程中出現的所有細胞類型進行彙總和演變關係的繪製，就構成了「細胞譜系」。解析細胞譜系被譽為揭示生命發育與演變奧祕、操縱生命活動的「鑰匙」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;533&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf7c06015d01a819ca8b5ea7cfba8024211.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該設施將以樣品保活存儲、空間多組學、先進成像等創新技術和裝置研發為核心，集成人工智能等前沿技術，繪製涵蓋發育、疾病、衰老三大維度的動態細胞圖譜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「這就像為生命編寫一部詳盡的‘細胞家譜’，讓科學家乃至公眾能夠清晰追蹤每個細胞的‘前世今生’。」廣州健康院副院長、細胞譜系設施總指揮兼總工程師孫飛表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人員介紹，當前全球創新藥研發耗時長、耗資大，但臨牀成功率低，部分原因在於藥物研發主要在動物模型中進行，不能準確模擬人類生理系統反應。未來，細胞譜系設施有望用患者細胞信息打造一個「數字患者」，預演不同治療手段在體內的治療效果，實現「量體裁衣」式的精準治療。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;廣州健康院研究員、細胞譜系設施副總指揮兼總工藝師陳捷凱表示，這一設施的建設將在生命科學儀器、試劑、軟件和數據等方面產出一批創新性科技成果和產品，並進一步強化 AI 與數據資源整合，與龍頭企業開展深度合作，加速科研成果向臨牀應用轉化。（新華社，記者馬曉澄、鍾焯）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340845</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340845</guid>
            <pubDate>Sat, 22 Mar 2025 06:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>小鵬汽車公佈雙足機器人新專利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 APP 知識產權信息顯示，廣州小鵬汽車科技有限公司申請的「雙足機器人的控制方法及電子設備」專利於 3 月 25 日公佈。解決了相關技術中無法實現雙足機器人單腳點地姿態的技術問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;310&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6ad6f0bc0677b09916d95d0fcf8a8f559d.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要顯示，本發明公開了一種雙足機器人的控制方法及電子設備。其中，該方法包括：響應於接收到雙足機器人的控制指令，採集雙足機器人的當前姿態，其中，控制指令中攜帶有雙足機器人的姿態數據，姿態數據用於確定雙足機器人的期望單腳點地姿態，期望單腳點地姿態用於表示期望在雙足機器人對應支撐腳的足底區域接觸地面的情況下，雙足機器人對應擺動腳的足尖區域接觸地面；基於當前姿態和期望單腳點地姿態，確定擺動腳的擺動腳移動軌跡和雙足機器人對應機身的機身移動軌跡；基於擺動腳移動軌跡和機身移動軌跡控制雙足機器人運行。本發明解決了相關技術中無法實現雙足機器人單腳點地姿態的技術問題。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340843</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340843</guid>
            <pubDate>Sat, 22 Mar 2025 06:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>工作流自動化平台 Zapier 上線 MCP 服務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;工作流自動化平台 Zapier 近日上線了 Zapier MCP 服務，允許用戶通過 Zapier 將他們的 Cursor AI 代理連接到各種應用程序，而無需複雜的 API 集成。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/114131_qF9e_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzapier.com%2Fmcp&quot;&gt;https://zapier.com/mcp&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Zapier MCP 服務賦予了 AI 助手強大的實用能力，包括自動化工作流程、管理數據、發送電子郵件、創建日曆事件、更新數據庫以及與其他應用進行實時交互等。無論是企業用戶希望優化日常運營，還是個人用戶想要簡化繁瑣任務，這一服務都提供了前所未有的便利。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/113921_nkJu_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;例如，AI 助手可以通過簡單的配置，自動將會議安排記錄到日曆中，或根據需求從數據庫中提取並整理數據，甚至與團隊協作工具實時同步信息。&lt;/p&gt; 
&lt;p&gt;更值得一提的是，Zapier MCP 在權限控制方面表現出色。用戶可以精確地定義 AI 助手能夠執行的操作範圍，細化到具體的應用程序、功能乃至特定字段。這種設計有效防止了 AI 濫用權限的風險。例如，用戶可以設置 AI 助手僅限於向某個特定的 Slack 頻道發送消息，或限制其只能訪問指定的 GitHub 倉庫。這種細粒度的控制不僅提升了安全性，也讓 MCP 服務更具靈活性和實用性。&lt;/p&gt; 
&lt;p&gt;使用 Zapier MCP 的過程也極為簡便。用戶只需從 Zapier 平台複製一個專屬的 URL，並將其集成到 AI 助手中，即可快速啓用這些功能。無需複雜的編程或 API 對接，這一 「即插即用」 的特性大大降低了技術門檻，使得非專業人士也能輕鬆上手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340820/zapier-mcp-beta</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340820/zapier-mcp-beta</guid>
            <pubDate>Sat, 22 Mar 2025 03:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>