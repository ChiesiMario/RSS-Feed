<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 17 Feb 2025 07:36:07 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>最新屍檢報告認定 OpenAI「吹哨人」死因為自殺</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 11 月 26 日，前 OpenAI 員工 Suchir Balaji 在舊金山的公寓中被發現死亡，年僅 26 歲。時至今日，舊金山法醫部門在最新公佈的屍檢報告裁定 Balaji 的死因為開槍自殺，駁斥了 Balaji 家人有關他殺的懷疑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;344&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1a05ba4a3131262dbb151b1411f9a3d8cd9.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;資料顯示，Balaji 是一名印度裔美國人，曾在加州大學伯克利分校學習並獲得了計算機科學學士學位。大學期間，他於 2019 年在 Scale AI 實習，並於 2021 年畢業後加入 OpenAI，參與過 WebGPT 的研發，後來又加入 GPT-4 的預訓練團隊，o1 的推理團隊以及 ChatGPT 的後訓練團隊。2024 年 8 月，他因對公司的商業行為感到失望後離職，並公開表達了自己的擔憂：「如果你相信我所相信的，你就必須離開公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;10 月份，Balaji 因指控 OpenAI 非法使用受版權保護的材料來訓練其 AI 模型而廣受關注。《紐約時報》後來將他列為該報對 OpenAI 的訴訟中「擁有獨特和相關文件」的關鍵人物。彼時，OpenAI 正在被眾多著名作家和新聞出版商起訴侵犯版權。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;離開 OpenAI 後，Balaji 表示自己一直在從事「個人項目」。據他母親説，他計劃創建一個以機器學習和神經科學為中心的非營利組織。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334332/death-of-openai-suchir-balaji</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334332/death-of-openai-suchir-balaji</guid>
            <pubDate>Mon, 17 Feb 2025 07:13:04 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Asahi Linux 創始人宣佈辭去項目負責人職務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;上週，Hector Martin 辭去了 Linux 內核 Apple Silicon 代碼的上游維護工作。當時他仍然計劃為 Asahi Linux 項目的下游內核做出貢獻，但就在前兩天，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarcan.st%2F2025%2F02%2Fresigning-as-asahi-linux-project-lead%2F&quot; target=&quot;_blank&quot;&gt;他出人意料地決定辭去 Asahi Linux 項目負責人的職位&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/143821_rzmV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Asahi Linux 項目創始人 Hector Martin 在博客宣佈，他將辭去項目負責人的職務。Martin 説道，隨着時間的推移，參與項目變得越來越沒有樂趣，並注意到了關於 Asahi Linux 在 Apple Silicon 上缺乏 Apple M3/M4 支持以及其他缺失功能（如 Thunderbolt 和 USB-C 顯示器）的用戶投訴。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由於圍繞 Apple 芯片硬件上 Asahi Linux 的用戶期望感到沮喪，並且最近還與 Linux 內核中 Rust 代碼的上游挫折/爭論/挑戰以及其他因素相關，Hector Martin 決定辭職&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「我立即辭去 Asahi Linux 項目負責人的職務。Asahi Linux&amp;nbsp;項目將繼續進行，我正在與團隊的其他成員一起處理職責和行政憑證的移交。我的個人 Patreon 將暫停，那些曾向我個人捐贈的用戶建議轉移到 Asahi Linux OpenCollective（GitHub Sponsors 不允許我單方面暫停付款，但我的贊助者將被告知這一變化，以便他們可以手動取消贊助）。&lt;/p&gt; 
 &lt;p&gt;我想感謝整個 Asahi Linux 團隊，沒有你們，我獨自一人根本無法取得任何進展。我還對我的所有 Patreon 和 GitHub 贊助者表示最深切的感激，是你們讓這個項目從一開始就成為一個可行的現實。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Martin 在博客中也表達了對 Linus 的失望：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Rust for Linux 作為一個上游 Linux 項目所遇到的問題已經有詳細的記錄，我就不在此贅述了。我只想説，我認為 Linus 在處理將 Rust 整合到 Linux 中的問題上是其作為領導者的一大敗筆。&lt;strong&gt;這樣一個大型項目需要得到主要利益相關者的大力支持才能生存下去，而他的做法似乎只是靜觀其變&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;與此同時，在他下游的多個子系統維護者卻竭力阻撓或妨礙項目的進行，發出令人無法接受的辱罵，並普遍打擊士氣。幾個月前，一位主要的 Rust for Linux 維護者已經辭職。&lt;/p&gt; 
 &lt;p&gt;當蘋果發佈 M1 時，Linus Torvalds 希望它能運行 Linux，但並不抱太大希望。我們實現了這一願望，Linux 5.19 從運行 Asahi Linux 的 M2 MacBook Air 上發佈。我曾希望他的熱情能轉化為對我們社區的支持，並幫助我們解決上游問題。&lt;/p&gt; 
 &lt;p&gt;遺憾的是，這一切都沒有實現。2023 年 11 月，我向他發出邀請，與他討論內核貢獻和維護方面的挑戰，看看我們能提供什麼幫助。他從未回覆。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Asahi Linux 博客也&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fasahilinux.org%2F2025%2F02%2Fpassing-the-torch%2F&quot; target=&quot;_blank&quot;&gt;已確認了 Hector 的辭職&lt;/a&gt;，而剩餘的開發者計劃繼續推動 Linux 在 Apple Silicon 硬件上的發展。&lt;/p&gt; 
&lt;p&gt;當前 Asahi Linux 成員包括 Alyssa Rosenzweig、chaos_princess、Davide Cavalca、Neal Gompa、James Calligeros、Janne Grunau 和 Sven Peter。剩餘的開發者表示他們仍將專注於將代碼提交到 Linux 內核。預計 Apple M3 和 M4 硬件支持將在他們更多的代碼被提交到上游以及持續集成取得進展之後才會實現。&lt;/p&gt; 
&lt;p&gt;對於今年的 Apple M1/M2 硬件，他們希望實現 DP Alt Mode、Vulkan 驅動程序中的稀疏圖像以及內置麥克風支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead</guid>
            <pubDate>Mon, 17 Feb 2025 06:44:04 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>GNOME 官網全新改版</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;GNOME 全新官網已&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnome.org%2F&quot; target=&quot;_blank&quot;&gt;上線&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;screenshot&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142818_JmM4.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新的設計看起來既時尚又現代，它簡化了頭部設計、空間更寬敞，色彩更鮮豔，還有簡單而有效的動畫，等等，比之前（相對單調）的舊版本更能傳達 GNOME 充滿活力、以用戶為中心的理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142819_RWzj.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;文檔方面，GNOME 開發文檔和設計指南現在各自擁有專門的章節，並附上了相關鏈接，還有一個部分展示了支持 GNOME 的組織列表（包括 Canonical），以強調 GNOME 在更廣泛的 Linux 生態中扮演的關鍵角色。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142820_bW25.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;詳情訪問 GNOME 官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnome.org%2F&quot; target=&quot;_blank&quot;&gt;https://www.gnome.org/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334308/gnome-website-revamp-goes-live</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334308/gnome-website-revamp-goes-live</guid>
            <pubDate>Sat, 08 Feb 2025 06:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「天工」成為全球首例登百級台階的人形機器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國地共建具身智能機器人創新中心宣佈，在戶外真實地形測試中，「天工」機器人連續攀爬多級階梯，成功登上北京通州區海子牆公園最高點，成為全球首例可在室外連續攀爬多級階梯的人形機器人。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國創中心持續提升具身小腦能力，實現了基於視覺的感知行走，可實現無磕碰、不踩稜、不踏空地跨越連續多級樓梯和 35 釐米大高差台階，奔跑時速提高至 12km/h，並且能在雪地進行高速奔跑，同時具備更強的抗幹擾能力，大外力衝擊下仍可保持平衡。應對複雜地形的移動能力提升，將成為人形機器人走出實驗室，在真實環境執行任務，甚至在山地、雪地救援、廢墟等極端環境下作業的基礎，為具身智能機器人規模化應用夯實技術底座。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fb4868df102f12e166908215d6ce18410f2.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，升級後的「天工」能夠輕鬆應對超 10KG 重物落下所造成的高達 45Ns 衝量，相當於一名職業拳擊手以 450 N 的力，重擊對手的一瞬間打出的力道，即使在光滑的雪地上從各個方向突然出現的各類幹擾等，「天工」均能保持穩定平衡不發生摔倒，達到業內領先水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過具身小腦所帶來的全身控制能力升級，「天工」面對複雜環境的移動能力再次大幅提升，首次真正發揮出雙足結構為人形機器人帶來的多地形通用性優勢，在實現全地形場景技術閉環的同時，更為行業確立了複雜環境移動能力的全新標杆。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;未來，該技術也將納入國創中心所打造的開源開放生態彙總，通過技術共享降低行業創新門檻將加速具身智能機器人在千行百業的規模化落地，為具身智能產業化開闢更具想象力的落地路徑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289801&quot; target=&quot;_blank&quot;&gt;北京人形機器人創新中心發佈全球首個純電驅擬人奔跑的全尺寸人形機器人 「天工」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334302</guid>
            <pubDate>Sat, 08 Feb 2025 06:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>ReasonFlux：通過分層模板縮放提升 LLM 推理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大型語言模型（LLMs）已經展現出了卓越的問題解決能力，然而，複雜的推理任務——例如競技級別的數學問題或複雜的代碼生成——仍然具有挑戰性。這些任務需要精確地穿越龐大的解空間，並進行細緻的逐步思考。現有的方法雖然在提高準確性方面有所改進，但往往面臨着高計算成本、僵化的搜索策略以及難以跨不同問題進行泛化的難題。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.marktechpost.com%2F2025%2F02%2F15%2Freasonflux-elevating-llm-reasoning-with-hierarchical-template-scaling%2F&quot; target=&quot;_blank&quot;&gt;https://www.marktechpost.com/2025/02/15/reasonflux-elevating-llm-reasoning-with-hierarchical-template-scaling/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在這篇論文中，研究人員介紹了一個新的框架，&lt;strong&gt;ReasonFlux&lt;/strong&gt;，它通過重新構想 LLMs 如何使用分層、模板引導的策略來規劃和執行推理步驟，從而解決了這些侷限性。 最近用於增強大型語言模型推理的方法分為兩大類：&lt;em&gt;深思熟慮的搜索_和_獎勵引導的方法&lt;/em&gt;。像思維樹（ToT）這樣的技術使 LLM 能夠探索多個推理路徑，而蒙特卡洛樹搜索（MCTS）則將問題分解為步驟，這些步驟由過程獎勵模型（PRM）引導。&lt;/p&gt; 
&lt;p&gt;儘管這些方法有效，但由於採樣過多和手動搜索設計，它們的可擴展性較差。例如，MCTS 需要遍歷成千上萬的潛在步驟，這使得它在實際應用中計算成本過高。與此同時，像思維緩衝（BoT）這樣的檢索增強生成 RAG 方法利用存儲的問題解決模板，但在適應性地整合多個模板方面存在困難，這限制了它們在複雜場景中的效用。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1066&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/135909_MMin_3820517.png&quot; width=&quot;1750&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;ReasonFlux 引入了一個結構化的框架，該框架結合了精選的高層次思維模板庫與分層強化學習（HRL），以動態規劃和優化推理路徑。它不是優化單個步驟，而是專注於配置最優的 &lt;em&gt;模板軌跡&lt;/em&gt;——從結構化知識庫中檢索出的抽象問題解決策略序列。這種方法簡化了搜索空間，並使高效適應子問題成為可能。該框架由三個主要組件組成：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;結構化模板庫&lt;/strong&gt;：研究團隊構建了一個包含 500 個思維模板的庫，每個模板封裝了一種問題解決策略（例如，「三角代換優化積分」）。模板包含元數據——名稱、標籤、描述和應用步驟——以實現高效的檢索。例如，一個標記為「有理函數優化」的模板可能會指導大型語言模型（LLM）應用特定的代數替換。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分層強化學習&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;基於結構的微調&lt;/strong&gt;：將基本 LLM（例如，Qwen2.5-32B）微調以將模板元數據與其功能描述關聯起來，確保它理解何時以及如何應用每個模板。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;模板軌跡優化&lt;/strong&gt;：利用偏好學習，該模型學會根據效果對模板序列進行排序。對於給定的問題，會採樣多個軌跡，並根據它們在類似問題上的成功率來確定獎勵。這訓練模型優先考慮高獎勵序列，從而提高其規劃能力。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自適應推理縮放&lt;/strong&gt;：在推理過程中，ReasonFlux 充當「導航員」，分析問題以檢索相關模板，並根據中間結果動態調整軌跡。例如，如果一個涉及「多項式因式分解」的步驟產生了意外的約束，系統可能會轉向「約束傳播」模板。這種規劃和執行之間的迭代互動反映了人類的解決問題方式，其中部分解決方案會指導後續步驟。&lt;/p&gt; &lt;img height=&quot;376&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/135928_eZy6_3820517.png&quot; width=&quot;1686&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ReasonFlux 在 MATH、AIME 和 OlympiadBench 等競爭級基準測試中進行了評估，超越了前沿模型（GPT-4o、Claude）以及專業開源模型（DeepSeek-V3、Mathstral）。關鍵結果包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MATH 準確率達到 91.2%，超過 OpenAI 的 o1-preview 6.7%。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 準確率為 56.7%，超出 DeepSeek-V3 45%，與 o1-mini 相當。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OlympiadBench 準確率為 63.3%，比先前方法提高了 14%。&lt;/strong&gt;此外，結構化模板庫展示了強大的泛化能力：當應用於不同的問題時，它將小型模型（例如，7B 參數）的能力提升至能夠通過直接推理超越大型模型。此外，ReasonFlux 實現了更好的探索-利用平衡，在複雜任務上比 MCTS 和 Best-of-N 需要少 40% 的計算步驟（見圖 5）。 總結來説，ReasonFlux 重新定義了 LLMs 處理複雜推理的方式，通過將高級策略與逐步執行解耦。其分層模板系統減少了計算開銷，同時提高了準確性和適應性，解決了現有方法中的關鍵差距。通過利用結構化知識和動態規劃，該框架為高效、可擴展的推理設定了新的標準——證明即使是小型、有良好指導的模型也能與最大的前沿系統相媲美。這一創新為在資源受限的環境中部署高級推理開闢了道路，從教育到自動化代碼生成。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334301/reasonflux-llm</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334301/reasonflux-llm</guid>
            <pubDate>Sat, 08 Feb 2025 06:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>FocusAny 支持 DeepSeek 模型，每天可領取 100W Token</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:0&quot;&gt;近日，領先的 AI 工具平台 FocusAny 接入 DeepSeek 模型，正式集成其先進的大語言模型。此次合作旨在為用戶提供更強大的 AI 支持，進一步提升工作效率和創造力。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//9c01f3c5c8b3e42afb8182d15f5b275e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;每日免費領取 100W Token&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;為慶祝此次合作，FocusAny 推出限時福利：即日起，所有用戶每天可免費領取 100W Token，用於體驗 DeepSeek 模型的強大功能。無論是文本生成、代碼編寫，還是數據分析，DeepSeek 模型都能為用戶提供高效、精準的解決方案。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//5038c86744ea401feae4ac2c6e409313.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;DeepSeek 模型：智能助手的新標杆&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;DeepSeek 模型以其卓越的自然語言處理能力和廣泛的應用場景著稱。通過與 FocusAny 的集成，用戶可以在日常工作中輕鬆調用 DeepSeek 模型，享受智能化的寫作、編程和決策支持。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//036551e3cdfcc5944030070159b6789f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;strong&gt;&lt;span&gt;關於 FocusAny&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;FocusAny 作為一家致力於提供高效、便捷 AI 服務的平台，此次接入 DeepSeek 無疑將為用戶帶來更加豐富的功能和體驗。通過&amp;nbsp;FocusAny，用戶可以輕鬆接入 DeepSeek 模型，利用其強大的推理能力解決各種問題。同時，每天可領取的 100 萬 Token 也為用戶提供了充足的資源，讓他們能夠盡情體驗 DeepSeek 模型的各項功能。&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//d77626550ffe45ef7e3be5e04b0d8c4e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;關於 DeepSeek&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;DeepSeek 是由幻方量化創立的人工智能公司推出的一系列 AI 模型，包括 DeepSeekCoder、DeepSeekLLM、DeepSeek-V2、DeepSeek-V3 和 DeepSeek-R1 等多個版本。這些模型在技術架構上展現出了前所未有的突破，採用了混合專家架構（MoE）、多頭潛在注意力（MLA）機制等創新技術，極大地提升了模型的處理效率和準確性。DeepSeek 模型在自然語言處理、代碼生成與編程輔助、多模態數據處理等多個領域內展示了卓越的能力，成為了眾多企業和開發者首選的解決方案。&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;隨着 AI 技術的不斷發展，DeepSeek 系列模型的應用場景也將越來越廣泛。FocusAny 接入 DeepSeek，無疑將為 AI 技術的應用和發展注入新的活力。我們期待未來 FocusAny 能夠為用戶帶來更多驚喜和突破，共同推動 AI 技術的進步和發展。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334299</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334299</guid>
            <pubDate>Sat, 08 Feb 2025 05:57:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>微軟開源「專業領域知識-推理能力 RAG」 —— PIKE-RAG</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近年來，大語言模型（LLM）憑藉強大的文本生成能力在各個領域引起了廣泛關注。它們不僅能寫文章、翻譯語言，還能完成創作任務。但當遇到需要專業領域知識支持的工業級問題時，比如半導體設計、製藥研發或法律條文解讀，這些模型往往力不從心。這不僅因為訓練數據中缺少足夠的專業信息，還因為單靠「生成」能力，難以構建嚴謹的邏輯推理和多層次的信息整合。&lt;/p&gt; 
&lt;h2&gt;為什麼傳統方法會遇到瓶頸？&lt;/h2&gt; 
&lt;p&gt;目前，為瞭解決這一問題，業界提出了「檢索增強生成」（Retrieval-Augmented Generation，簡稱 RAG）的思路。其核心理念是在生成答案之前，先從一個龐大的外部知識庫中檢索出相關信息，再將這些信息融入生成的上下文中，從而使回答更準確、更有事實依據。&lt;/p&gt; 
&lt;p&gt;然而，傳統 RAG 方法存在以下幾個問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知識來源複雜&lt;/strong&gt;：現實中的數據不僅僅是純文本，還包括表格、圖表、圖片等多種格式。單一的文本檢索難以捕捉這些多樣信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;專業領域知識不足&lt;/strong&gt;：工業應用中的專業知識具有特定術語和邏輯，普通模型難以準確提取和理解，從而導致回答不夠嚴謹。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「一刀切」的策略&lt;/strong&gt;：不同類型的問題（如簡單事實問答與需要多步推理的複雜問題）要求不同的處理策略，而傳統方法往往採用統一流程，無法兼顧所有需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PIKE-RAG 的創新之處&lt;/h2&gt; 
&lt;p&gt;為瞭解決上述不足，微軟亞洲研究院提出了 PIKE-RAG —— 一種專注於「知識」和「推理」增強的生成框架。PIKE-RAG 不僅幫助模型檢索相關知識，更注重如何理解、拆解和合理組織這些信息，從而構建出嚴謹的推理鏈。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;788&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121127_pF8y_3820517.png&quot; width=&quot;2072&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;792&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121200_n64m_3820517.png&quot; width=&quot;2058&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;810&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121040_68c7_3820517.png&quot; width=&quot;2088&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面我們來看看它的核心設計：&lt;/p&gt; 
&lt;h3&gt;1. 分級任務設計&lt;/h3&gt; 
&lt;p&gt;論文將問題大致分為四類：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事實型問題&lt;/strong&gt;：例如「這款 LED 產品的額定電流是多少？」&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;鏈式推理問題&lt;/strong&gt;：需要跨多個信息點進行關聯，比如比較多個產品的性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;預測型問題&lt;/strong&gt;：例如「未來 5 年半導體技術可能有哪些突破？」&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;創造型問題&lt;/strong&gt;：要求模型發揮創造力，提出新見解。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種分類使得系統能根據問題的難度和性質，採用針對性的處理策略，從而「量體裁衣」地提升答案的準確性和邏輯性。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1246&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/120535_p84F_3820517.png&quot; width=&quot;1124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;2. 知識「原子化」與任務分解&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知識原子化&lt;/strong&gt;：面對複雜問題，系統會將長文檔或複雜數據拆分成最基本的信息單元（知識原子）。這種拆分類似於把大問題拆成小問題，每個小單元便於獨立檢索和理解。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知識感知的任務分解&lt;/strong&gt;：系統根據問題需求，動態分解任務，並利用已提取的知識原子構建邏輯推理鏈。這樣一來，即使是多步推理的問題，系統也能循序漸進地「拼湊」出最終答案。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;任務分解器訓練&lt;/strong&gt;：為實現高效分解，系統還引入了可訓練的任務分解模塊，通過大量領域數據學習如何將問題正確拆解併合理組合各個知識點。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 分階段系統構建&lt;/h3&gt; 
&lt;p&gt;PIKE-RAG 採用了分階段的開發策略，逐步提升系統的處理能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;初級階段&lt;/strong&gt;：專注於構建一個多模態知識庫。系統會從文本、表格、圖像等多種格式中抽取信息，並利用解析算法將它們統一組織成一個結構化、關聯緊密的知識網絡。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中級階段&lt;/strong&gt;：在事實型問題上引入多粒度檢索技術，結合增強型文本切分和自動標記機制，確保能精確提取出關鍵信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高級階段&lt;/strong&gt;：逐步引入鏈式推理模塊、知識原子化處理和任務分解器，使系統不僅能夠檢索信息，更能在多跳推理、預測和創造性回答等複雜任務中表現優異。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;實現原理：如何讓系統「知曉」與「推理」&lt;/h2&gt; 
&lt;p&gt;在 PIKE-RAG 系統中，設計者採用了層次化、分階段的實現策略，確保系統能逐步提升對複雜問題的處理能力。下面詳細介紹各個主要環節的實現原理：&lt;/p&gt; 
&lt;h3&gt;1. 知識庫構建（Level-0）&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;文件解析&lt;/strong&gt;：系統首先從各種格式的數據中抽取信息，將非結構化數據（如掃描文檔、表格、圖片中的文字）經過專門算法轉換為統一的文本數據。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知識組織&lt;/strong&gt;：解析後的信息被組織成一個多層次的異構圖，各類數據節點（例如產品技術規格、圖表、説明文字等）通過超鏈接、引用關係等方式互相連接，形成結構化的知識庫，便於後續的高效檢索和利用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 專門模塊針對不同問題&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;事實型問題模塊（Level-1）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;增強型切分與自動標記&lt;/strong&gt;：長文檔被切分成更小的信息塊，並自動為每個信息塊打上標籤，以便在檢索時更精確地匹配查詢內容。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;多粒度檢索&lt;/strong&gt;：系統在檢索時不僅搜索全文，還能在不同層級和粒度上查找相關信息，提高檢索的準確性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;鏈式推理問題模塊（Level-2）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;知識原子化&lt;/strong&gt;：將大塊複雜知識拆解成最小的基本單元，使得每個單元都能獨立檢索並參與推理。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;任務分解&lt;/strong&gt;：針對複雜問題，系統動態分解成多個子任務，每個子任務依次解決後再組合成最終答案。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;訓練可調的任務分解器&lt;/strong&gt;：通過大量領域數據訓練，系統學會如何針對不同專業問題設計合適的分解策略和推理流程。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;預測型與創造型問題模塊（Level-3 &amp;amp; Level-4）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在高級階段，系統不僅能處理已知信息，還能在已有數據基礎上推演預測未來趨勢或提出創造性觀點，從而滿足更高層次的應用需求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;684&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/120551_g5tH_3820517.png&quot; width=&quot;828&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3. 分階段開發策略&lt;/h3&gt; 
&lt;p&gt;整個系統從構建基礎知識庫開始，逐步引入不同層次的檢索與推理模塊。每個階段的開發都以解決特定問題為目標：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;初級階段&lt;/strong&gt;確保系統在簡單事實問答上表現出色；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中級階段&lt;/strong&gt;引入多跳推理和任務分解，處理更復雜的問題；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高級階段&lt;/strong&gt;則針對預測和創造性任務進行優化，使系統具備更強的靈活性和適應性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;實驗效果與應用前景&lt;/h2&gt; 
&lt;p&gt;通過大量實驗驗證，PIKE-RAG 在開放領域和法律領域的問答任務中均展現了卓越的性能。得益於知識原子化、任務分解以及多粒度檢索技術，該系統在處理多步推理和複雜查詢時表現尤為出色。這不僅為工業級問答系統的發展提供了新思路，也為未來在更多複雜場景中的應用奠定了基礎。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FPIKE-RAG&quot; target=&quot;_blank&quot;&gt;https://github.com/microsoft/PIKE-RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpike-rag.azurewebsites.net%2F&quot; target=&quot;_blank&quot;&gt;https://pike-rag.azurewebsites.net&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334286/microsoft-pike-rag</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334286/microsoft-pike-rag</guid>
            <pubDate>Sat, 08 Feb 2025 04:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OBS Studio 批評 Fedora 的 Flatpak 打包，稱其是惡意分支</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;開源屏幕錄製和直播應用 OBS Studio 近日向 Fedora 提出了批評，指出它對該應用程序的 Flatpak 打包存在問題，並威脅説如果不加以解決，將採取法律行動。&lt;/p&gt; 
&lt;p&gt;三週前 OBS Studio 團隊就提交了&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.com%2Ffedora%2Fsigs%2Fflatpak%2Ffedora-flatpaks%2F-%2Fissues%2F39%23note_2344970813&quot; target=&quot;_blank&quot;&gt;Fedora Flatpak SIG 工單&lt;/a&gt;&amp;nbsp;—— 關於 Fedora 提供「損壞」的 OBS Studio Flatpak 被視為官方軟件包：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「Fedora Flatpaks 應用商店提供的非官方 OBS Studio Flatpak 似乎打包不佳且已損壞，導致用戶向上遊投訴，因為他們認為這是 OBS Studio 的官方軟件包。這種情況在 OBS Studio 之外也存在多個例子，許多用戶對 Fedora Flatpaks 被強制推廣，缺少或沒有明確的選項退出感到不滿。&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.gnome.org%2FGNOME%2Fgnome-software%2F-%2Fissues%2F2754&quot; target=&quot;_blank&quot;&gt;https://gitlab.gnome.org/GNOME/gnome-software/-/issues/2754&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpagure.io%2Ffedora-workstation%2Fissue%2F463&quot; target=&quot;_blank&quot;&gt;https://pagure.io/fedora-workstation/issue/463&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;我們希望請求將該軟件包移除，或者明確指出它是一個第三方軟件包。&lt;strong&gt;確保下游軟件包正常工作不應是上游的責任，尤其是當它們覆蓋官方軟件包時&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;我還想了解為什麼有人認為將一個運行得非常完美的 Flatpak 版本破壞後，以更高的優先級發佈到我們的官方構建中是一個好主意。我們在官方 Flatpak 上投入了大量的努力，以確保它們在 Flathub 上發佈時能儘可能地正常運行。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;但然後在過去的一天裏，Fedora 不但沒有刪除，似乎還和 OBS Studio 團隊對罵起來，這讓後者非常不爽，因此認定 Fedora Flatpak 上的 OBS Studio 是個惡意分支，並威脅採取法律行動：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由於目前很明顯 Fedora 對此沒有興趣進行理性討論，並決定訴諸於人身攻擊，我們現在將 Fedora Flatpaks 分發的 OBS Studio 視為惡意分支。&lt;/p&gt; 
 &lt;p&gt;這是一個正式請求，要求從您的分發中移除我們所有的品牌標識，包括但不限於我們的名稱、我們的標誌、屬於 OBS 項目的任何附加知識產權。&lt;/p&gt; 
 &lt;p&gt;如果不遵守，可能會導致採取進一步的法律行動。我們期望在接下來的 7 個工作日內收到回覆（截至 2025 年 2 月 21 日星期五）。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334282/obs-studio-poor-fedora-flatpak</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334282/obs-studio-poor-fedora-flatpak</guid>
            <pubDate>Sat, 08 Feb 2025 03:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 快速集成和使用 solon-flow 規則與流引擎（用 yaml 編寫業務規則）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本文參考自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnblogs.com%2Fstudyjobs%2Fp%2F18125096&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/studyjobs/p/18125096&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;規則引擎技術的主要思想是將應用程序中的業務規則分離出來，業務規則不再以程序代碼的形式駐留在系統中，而是存儲在獨立的文件或者數據庫中，完全獨立於程序。業務人員可以像管理數據一樣對業務規則進行管理。業務規則在程序運行時被加載到規則引擎中供應用系統調用。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 是新的規則引擎技術，由 OpenSolon 開源組織提供的基於 Java 語言開發的開源規則引擎，可以將複雜且多變的業務規則從硬編碼中解放出來，以 yaml 規則腳本的形式存放在文件或特定的存儲介質中（例如數據庫），使得業務規則的變更不需要修改項目代碼、不需要重啓服務器就可以立即生效。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本篇博客的 demo 以個稅計算器為例，介紹如何使用 solon-flow 規則引擎，有關具體技術細節，限於篇幅有限，這裏不會介紹，具體細節可以參考官網。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 官網地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2Flearn-solon-flow&quot; target=&quot;_blank&quot;&gt;https://solon.noear.org/article/learn-solon-flow&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 源碼下載地址：&lt;a href=&quot;https://gitee.com/opensolon/solon/tree/main/solon-projects/solon-flow/solon-flow&quot;&gt;https://gitee.com/opensolon/solon/tree/main/solon-projects/solon-flow/solon-flow&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1、搭建工程&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;搭建一個 solon 工程，結構如下：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a2c3e430e7024d75925e6ced1b180c30.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 規則引擎將規則編寫在以 .yml （很流行的配置文）為後綴的文件中，yml 文件默認也是使用 yaml + java 語言編寫，所以學習起來很容易。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;一般情況下，我們使用 IDEA 編寫業務規則，默認情況下 .yml 文件會被打包到項目 jar 包中，為了方便後續調整規則，我們可以將 yml 文件的內容，存儲到數據庫中或者 oss 雲盤中，程序在運行時從 jar 包外部讀取規則內容。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;完束上的 pom 文件的內容：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;&amp;lt;?xml version=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;1.0&quot;&lt;/span&gt; encoding=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;project&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;xmlns&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://maven.apache.org/POM/4.0.0&quot;&lt;/span&gt;
         &lt;span style=&quot;color:#986801&quot;&gt;
                xmlns:xsi&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt;
         &lt;span style=&quot;color:#986801&quot;&gt;xsi:schemaLocation&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;modelVersion&lt;/span&gt;&amp;gt;&lt;/span&gt;4.0.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;modelVersion&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-parent&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;3.0.8&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;relativePath&lt;/span&gt; /&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.example&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;demo-rule&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;java.version&lt;/span&gt;&amp;gt;&lt;/span&gt;11&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;java.version&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-web&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;em&gt;&amp;lt;!-- 規則與流引擎 --&amp;gt;&lt;/em&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-flow&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-logging-simple&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.projectlombok&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;lombok&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;provided&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-test&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;test&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;build&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;finalName&lt;/span&gt;&amp;gt;&lt;/span&gt;${project.artifactId}&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;finalName&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;plugins&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;plugin&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-maven-plugin&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;plugin&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;plugins&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;build&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;project&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2、代碼細節展示&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;此文的 demo 是個稅計算器，我們創建一個用於向規則引擎傳遞數據的實體類&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#a626a4&quot;&gt;package&lt;/span&gt; com.example.demo.model;

&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; lombok.Data;

&lt;span style=&quot;color:#4078f2&quot;&gt;@Data&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;Calculation&lt;/span&gt; {
    &lt;em&gt;//稅前工資&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wage;
    &lt;em&gt;//應納稅所得額&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wagemore;
    &lt;em&gt;//稅率&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; cess;
    &lt;em&gt;//速算扣除數&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; preminus;
    &lt;em&gt;//扣稅額&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wageminus;
    &lt;em&gt;//稅後工資&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; actualwage;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;這裏不考慮繳納社保和專項扣除等因素，個稅計算的規則如下：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img height=&quot;250&quot; src=&quot;https://oscimg.oschina.net/oscnet//ebd65a9942d8b3bc121987723eeaa014.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;之後我們在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;flow/rule.yml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中編寫的規則如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;rule&lt;/span&gt;
&lt;span style=&quot;color:#986801&quot;&gt;nodes:&lt;/span&gt;
  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_setWagemore&quot;&lt;/span&gt; &lt;em&gt;#計算應納稅所得額&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      import java.time.LocalDate;
      //2022-10-1 後生效
      return cal.getWage() &amp;gt; 0 &amp;amp;&amp;amp; LocalDate.now().compareTo(LocalDate.of(2022,10,1)) &amp;gt; 0;
&lt;/span&gt;    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      double wagemore = cal.getWage() - 5000;
      cal.setWagemore(wagemore);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_3000&quot;&lt;/span&gt;  &lt;em&gt;#設置稅率、速算扣除數&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;lt;= 3000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.03);//稅率
      cal.setPreminus(0);//速算扣除數
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 3000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.1);//稅率
      cal.setPreminus(210);//速算扣除數
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_25000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 12000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 25000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.2);
      cal.setPreminus(1410);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_35000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 25000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 35000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.25);
      cal.setPreminus(2660);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_55000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 35000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 55000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.25);
      cal.setPreminus(2660);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 55000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.35);
      cal.setPreminus(7160);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_max&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.45);
      cal.setPreminus(15160);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_result&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWage() &amp;gt; 0 &amp;amp;&amp;amp; cal.getWagemore() &amp;gt; 0 &amp;amp;&amp;amp; cal.getCess() &amp;gt; 0&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      //扣稅額
      double wageminus = cal.getWagemore() * cal.getCess() - cal.getPreminus();
      double actualwage = cal.getWage() - wageminus;
      cal.setWageminus(wageminus);
      cal.setActualwage(actualwage);
      System.out.println(&quot;--稅前工資：&quot;+cal.getWage());
      System.out.println(&quot;--應納稅所得額：&quot;+cal.getWagemore());
      System.out.println(&quot;--稅率：&quot; + cal.getCess());
      System.out.println(&quot;--速算扣除數：&quot; + cal.getPreminus());
      System.out.println(&quot;--扣稅額：&quot; + cal.getWageminus());
      System.out.println(&quot;--稅後工資：&quot; + cal.getActualwage());
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本 demo 設定每次被調用時，都去讀取 rule.yml 的內容（可時實生效），具體代碼在 RuleService 中實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#a626a4&quot;&gt;package&lt;/span&gt; com.example.demo.dso;

&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; com.example.demo.model.Calculation;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.annotation.Component;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.flow.ChainContext;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.flow.FlowEngine;

&lt;span style=&quot;color:#4078f2&quot;&gt;@Component&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;RuleService&lt;/span&gt; {
    &lt;em&gt;//調用 Drools 規則引擎實現個人所得稅計算&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Calculation &lt;span style=&quot;color:#4078f2&quot;&gt;calculate&lt;/span&gt;&lt;span&gt;(Calculation calculation)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; Throwable {
        &lt;span style=&quot;color:#986801&quot;&gt;FlowEngine&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;flowEngine&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; FlowEngine.newInstance();
        flowEngine.load(Chain.parseByUri(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;file:src/main/resources/flow/rule.yml&quot;&lt;/span&gt;)); &lt;em&gt;//動態加載源碼下的文件，修改後實時生效&lt;/em&gt;

        &lt;em&gt;//構建上下文&lt;/em&gt;
        &lt;span style=&quot;color:#986801&quot;&gt;ChainContext&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;ctx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;ChainContext&lt;/span&gt;();
        ctx.put(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal&quot;&lt;/span&gt;, calculation);

        &lt;em&gt;//執行規則&lt;/em&gt;
        flowEngine.eval(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;rule&quot;&lt;/span&gt;, ctx);

        &lt;em&gt;//返回運行算後的&lt;/em&gt;
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; calculation;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;然後在 RuleController 中對外提供計算個稅的接口，只需要傳遞一個稅前工資額即可計算得出結果&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;rule&quot;)&lt;/span&gt;
&lt;span style=&quot;color:#4078f2&quot;&gt;@Controller&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;RuleController&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    RuleService ruleService;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;calculate&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Calculation &lt;span style=&quot;color:#4078f2&quot;&gt;calculate&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wage)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; Throwable {
        &lt;span style=&quot;color:#986801&quot;&gt;Calculation&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;calculation&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;Calculation&lt;/span&gt;();
        calculation.setWage(wage);
        calculation = ruleService.calculate(calculation);
        System.out.println(calculation);
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; calculation;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3、驗證成果&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;啓動後，可以訪問接口&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;http://localhost:8080/rule/calculate?wage=10000&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;即可查看到靜態頁面，輸入 10000 元計算個稅，如下圖：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df17e27488d65c9710b199cfd67a33fb.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;結果可以發現，稅率是 0.1，執行的是 rule.yml 文件中的名稱為 tax_12000 的規則，此時你可以使用 IDEA 修改一下，比如將稅率修改為 0.2&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 3000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.2);//這裏故意將稅率修改為 0.2
      cal.setPreminus(210);//速算扣除數
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;注意不需要重啓 IDEA 的項目（可時實生效），此時重新點擊頁面中的計算，發現剛剛修改的規則生效了，如下圖所示：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3887df8f59e854e1ad073beefcebd3da.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;好了，以上就是有關 solon-flow 規則引擎的介紹（在 spring 裏差不多），有興趣的話可以下載源代碼進行驗證。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本示例，源碼下載地址：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;a href=&quot;https://gitee.com/opensolon/solon-flow_rule-demo&quot;&gt;https://gitee.com/opensolon/solon-flow_rule-demo&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            
            
            </description>
            <link>https://www.oschina.net/news/334278</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334278</guid>
            <pubDate>Sat, 08 Feb 2025 03:33:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>2024 年 Rust 社區調查報告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Rust 調查團隊很高興與大家分享我們關於 Rust 編程語言的 2024 年調查結果，該調查於 2024 年 12 月 5 日至 2024 年 12 月 23 日進行。與往年一樣，2024 年的 Rust 狀態調查旨在收集 Rust 用戶以及更廣泛地關注 Rust 未來的所有人的見解和反饋。&lt;/p&gt; 
&lt;p&gt;這份調查的第九版揭示了來自全球 Rust 語言社區的全新見解和學習機會，以下我們將進行總結。除了這篇博客文章外，&lt;strong&gt;我們還&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fraw.githubusercontent.com%2Frust-lang%2Fsurveys%2Fmain%2Fsurveys%2F2024-annual-survey%2Freport%2Fannual-survey-2024-report.pdf&quot; target=&quot;_blank&quot;&gt;準備了一份報告&lt;/a&gt;&lt;/u&gt;&lt;/strong&gt;，其中包含了調查中所有問題的彙總結果圖表。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我們對每一位在過去一年中抽出時間表達對 Rust 看法和體驗的社區成員表示最誠摯的感謝。您的參與將幫助我們使 Rust 對每個人來説都變得更好。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下文包含了大量數據，所以請坐穩，享受閲讀！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參與&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111550_gaCL_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，2024 年，我們收到的調查查看次數比上一年少。這可能是由於調查僅進行了兩週，而上一年調查進行了近一個月。然而，完成率也有所下降，這似乎表明調查可能有點太長了。我們將考慮這一點，為下一次調查的版本進行調整。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;社區&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Rust 狀態調查不僅為我們提供了關於世界各地有多少 Rust 用戶在使用和體驗該語言的寶貴見解，而且還讓我們瞭解了我們全球社區的結構。這些信息讓我們瞭解到語言的使用情況以及隨着時間的推移，我們可能需要解決的接入差距。我們希望這些數據和我們的相關分析能進一步促進關於我們如何繼續優先考慮 Rust 社區的全球接入和包容性的重要討論。&lt;/p&gt; 
&lt;p&gt;與往年一樣，我們詢問了受訪者他們居住在哪個國家。排名前十的國家依次是：美國（22%）、德國（14%）、英國（6%）、法國（6%）、中國（5%）、加拿大（3%）、荷蘭（3%）、俄羅斯（3%）、澳大利亞（2%）和瑞典（2%）。我們很高興看到 Rust 受到世界各地用戶的喜愛！您可以在下面的圖表中嘗試找到您的國家：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111604_Xkme_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們也詢問了受訪者是否認為自己屬於一個邊緣化社區的一員。在回答者中，74.5% 選擇了「否」，15.5% 選擇了「是」，10% 選擇不願意透露。&lt;/p&gt; 
&lt;p&gt;我們詢問了選擇「是」的羣體，他們將自己識別為哪些特定羣體的成員。將自己視為技術領域中被代表性不足或邊緣化羣體成員的大多數人將自己識別為女同性戀、男同性戀、雙性戀或其他非異性戀。其次是神經多樣性羣體，佔比 46%，其次是跨性別羣體，佔比 35%。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111617_hrzo_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;每年，我們必須承認 Rust 社區和開源整體在多樣性、公平性和包容性（DEI）方面的差距。我們相信，Rust 基金會在推進 Rust 社區聚會全球訪問和在每個週期向多元化的維護者羣體分配補助金方面正在開展出色的工作，您可以在這裏瞭解更多信息。即便如此，全球包容性和訪問性只是 DEI 的一個要素，調查工作組將繼續在這個領域推動進步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust 使用情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自認是 Rust 用戶的人數與去年相當，大約為 92%。這個高比例並不令人驚訝，因為我們主要針對現有的 Rust 開發者進行這項調查。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111627_7qhc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;同樣地，像去年一樣，大約 31% 的未將自己標識為 Rust 用戶的人士將難度感知作為不使用 Rust 的主要原因。不使用 Rust 的最常見原因是受訪者們還沒有機會嘗試它。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111639_1Cns_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在參與 2024 年調查的前 Rust 用戶中，36% 的人士將不可控因素列為他們不再使用 Rust 的原因，這比去年下降了 10 個百分點。&lt;/p&gt; 
&lt;p&gt;今年，我們還詢問受訪者如果有機會，他們是否會考慮再次使用 Rust，結果發現很大一部分受訪者（63%）會這麼做。這真是令人欣慰！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111652_RnJ5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;標記為 N/A 的封閉答案在調查的前一個版本中並未出現。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;不再使用 Rust 的人告訴我們，這主要是因為他們實際上並不需要它（或他們公司的目標發生了變化），或者因為它不是這項工作的合適工具。少數人報告稱，他們被這種語言或其生態系統整體所壓倒，或者認為轉向或引入 Rust 在人力成本上過於昂貴。&lt;/p&gt; 
&lt;p&gt;在 2024 年使用 Rust 的人中，有 53% 的人是每天（或幾乎每天）使用它——比上一年增加了 4 個百分點。我們可以觀察到，在過去的幾年中，Rust 的使用頻率呈上升趨勢，這表明 Rust 在工作場所的使用越來越多。這一點也由下文「Rust at Work」部分中提到的其他答案所證實。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111737_L7g6_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rust 的專業技能在我們的受訪者中也持續增長！20% 的受訪者能夠編寫（僅）簡單的 Rust 程序（相比 2023 年下降了 3 個百分點），而 53% 的人認為自己使用 Rust 是高效的——這一比例在 2023 年為 47%。雖然這項調查只是衡量 Rust 整體技能變化的一個工具，但這些數字令人鼓舞，因為它們代表了每年迴歸調查的許多 Rustaceans 的知識增長。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111747_VI2v_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不出所料，最受歡迎的 Rust 版本是最新穩定版，無論是最新版本還是與用戶的 Linux 發行版一起提供的版本。幾乎三分之一的用戶也使用最新的夜間版本，由於各種原因（見下文）。然而，似乎 beta 工具鏈的使用並不多，這有點遺憾。我們希望鼓勵 Rust 用戶更多地使用 beta 工具鏈（例如在 CI 環境中），以幫助測試即將穩定化的 Rust 版本。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111759_RPoz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;人們使用夜間工具鏈主要是為了獲取特定的不穩定語言功能。也有幾位用戶提到，他們對夜間版本的 rustfmt 更滿意，或者他們使用夜間編譯器是因為編譯速度更快。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111809_jJfZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;學習 Rust&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;要使用 Rust，程序員首先必須學習它，所以我們總是對他們是怎樣學習的很感興趣。根據調查結果，似乎大多數用戶通過 Rust 文檔以及《Rust 編程語言》這本書來學習，這本書長期以來一直是新 Rustaceans 最喜歡的學習資源。許多人似乎也通過閲讀 Rust crate 的源代碼來學習。事實上，成千上萬 Rust crate 的文檔和源代碼都可在 docs.rs 和 GitHub 上找到，這使得學習變得更加容易。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111822_KHvR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於屬於「其他」類別的回答，它們可以歸納為三個類別：使用 LLM（大型語言模型）助手（如 Copilot、ChatGPT、Claude 等）、閲讀官方 Rust 論壇（Discord、URLO）或在貢獻 Rust 項目時接受指導的人。我們想向那些使我們的空間對新來者友好和歡迎的人表示衷心的感謝，因為這是一項重要的工作，而且它是有回報的。有趣的是，相當數量的人通過「做中學」來學習，並使用 rustc 錯誤信息和 clippy 作為指南，這是 Rust 診斷質量的良好指標。&lt;/p&gt; 
&lt;p&gt;至於正規教育，似乎 Rust 尚未滲透到大學課程中，因為這是一個通常發展緩慢的領域。只有極少數受訪者（大約 3%）曾上過大學的 Rust 課程或使用過大學學習材料。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111833_l4Zn_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編程環境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;關於 Rustaceans 使用的操作系統，Linux 是最受歡迎的選擇，而且它似乎每年都在變得越來越受歡迎。其次是 macOS 和 Windows，它們的使用份額非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111844_giEi_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9695c9f7f5975eb79647c3db5c61467af25.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;順便提一下，如您在詞雲中看到的，還有一些用戶更喜歡 Arch。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Rust 程序員使用他們的 Rust 程序針對一系列的平台。我們發現針對嵌入式和移動平台的目標用戶有所增加，但除此之外，平台分佈與去年大致相同。由於 WebAssembly 目標相當多樣化，我們這次將其分為兩個單獨的類別。根據結果，很明顯，在使用 WebAssembly 時，它主要是在瀏覽器（23%）的上下文中，而不是其他用例（7%）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111901_JLWt_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當然，我們不能忘記許多程序員最喜愛的主題：他們使用哪個 IDE（開發環境）。儘管 Visual Studio Code 仍然是最受歡迎的選擇，但今年的市場份額下降了 5 個百分點。另一方面，Zed 編輯器似乎最近獲得了相當大的關注度。選擇「其他」的少數人正在使用各種各樣的不同工具：從 CursorAI 到經典如 Kate 或 Notepad++。特別提一下使用「ed」的 3 個人，這真是一項了不起的成就。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111912_hDw1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e87b497c85dbd1dced8a457b81fc3d05e46.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;您還可以查看詞雲，它總結了對此問題的開放性回答（「其他」類別），以瞭解其他哪些編輯器也受歡迎。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Rust 在工作中的使用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們很高興看到越來越多的人在工作時使用 Rust 進行大部分編碼，從去年的 34% 上升到 38%。在過去幾年中，這一指標呈現出明顯的上升趨勢。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111924_MVQm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rust 在公司中的使用似乎也在增加，因為 45% 的受訪者表示他們的組織在 Rust 上的使用並非微不足道，這比 2023 年增加了 7 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111934_YhGk_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再次強調，我們調查受訪者僱主投資 Rust 的首要原因是可以構建相對正確且無 bug 的軟件。其次受歡迎的原因是 Rust 的性能特性。21% 在工作中使用 Rust 的受訪者這麼做是因為他們已經熟悉它，因此它是他們的默認選擇，比 2023 年增加了 5 個百分點。這似乎表明，Rust 正成為越來越多公司選擇的基礎語言之一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111945_PfzP_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;與上一年相似，很大比例的受訪者（82%）報告説 Rust 幫助他們的公司實現了目標。總的來説，似乎程序員和公司對他們在 Rust 上的使用感到非常滿意，這真是太好了！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111956_tivA_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在技術領域，情況與前一年相當相似。Rust 似乎特別受歡迎，用於創建服務器後端、Web 和網絡服務以及雲計算技術。它似乎也在嵌入式用例方面獲得了更多的關注。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112012_w7WV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;您可以向右滾動圖表以查看更多領域。請注意，在 2023 年的調查中，汽車領域並未作為封閉答案提供（它只是通過開放式答案輸入的），這或許可以解釋為什麼會有如此大的跳躍。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;看到專業 Rust 使用的持續增長以及許多用戶對其性能、控制、安全性、安全性、愉悅性等方面的信心，這令人興奮！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;挑戰&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正如往常一樣，State of Rust 調查的主要目標之一是揭示過去一年 Rustaceans 心中的挑戰、擔憂和優先事項。&lt;/p&gt; 
&lt;p&gt;我們詢問了用戶關於限制他們生產力的 Rust 方面。不出所料，緩慢的編譯速度位列榜首，這似乎一直是 Rust 用戶的永久性擔憂。一如既往，有努力正在進行中以提高編譯器的速度，例如啓用並行前端或默認切換到更快的鏈接器。我們邀請您測試這些改進，並告訴我們如果您遇到任何問題。&lt;/p&gt; 
&lt;p&gt;其他挑戰包括對 Rust 調試的支持不佳以及 Rust 編譯器工件的高磁盤使用量。另一方面，大多數 Rust 用戶似乎對它的運行時性能、編譯器的正確性和穩定性以及 Rust 的文檔都非常滿意。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112026_HY9X_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於 Rust 用戶希望穩定（或實現）的具體不穩定（或缺失）功能，最希望的是異步閉包和 if/let while 鏈。嗯，好消息是！異步閉包將在 Rust 的下一個版本（1.85）中穩定，而 if/let while 鏈有望在 Edition 2024 發佈後不久跟進很快之後，這次發佈也將發生在 Rust 1.85 中。&lt;/p&gt; 
&lt;p&gt;其他備受渴望的功能包括生成器（同步和異步）以及更強大的泛型常量表達式。您可以關注 Rust 項目目標以跟蹤這些（以及其他）功能的進展。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112038_zfN3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在對此問題的公開回答中，人們真的很有幫助，並盡力描述限制他們生產力的最顯著問題。我們看到了關於異步編程（永恆的寵兒）的挑戰，錯誤的可調試性（人們普遍喜歡，但並不適合每個人）或 Rust 工具緩慢或資源密集（rust-analyzer 和 rustfmt）的提及。一些用戶還希望有更好的 IDE 故事和與其他語言的改進互操作性。&lt;/p&gt; 
&lt;p&gt;今年，我們還增加了一個關於 Rust 進化速度的新問題。雖然大多數人似乎對現狀感到滿意，但回答此問題的人中有超過四分之一的人希望 Rust 能夠更快地穩定和/或添加新功能，只有 7% 的受訪者希望 Rust 放慢或完全停止添加新功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112052_mhgg_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有趣的是，當我們詢問受訪者關於他們對 Rust 未來發展的主要擔憂時，其中一個最常提到的答案是擔心 Rust 會變得過於複雜。這似乎與上一個問題的答案形成了對比。也許 Rust 用戶仍然認為 Rust 的複雜性是可控的，但他們擔心有一天它可能會變得過於複雜。&lt;/p&gt; 
&lt;p&gt;我們很高興地看到，對 Rust 項目治理和 Rust 基金會支持不足的擔憂在 2023 年下降了約 6 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112103_2fAx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展望未來&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每年，Rust 狀態調查的結果都有助於揭示 Rust 項目和生態系統中許多需要改進的領域，以及對我們社區運作良好的方面。&lt;/p&gt; 
&lt;p&gt;如果您對 Rust 年度調查有任何建議，請告訴我們！&lt;/p&gt; 
&lt;p&gt;我們非常感謝參與 2024 年 Rust 狀態調查並幫助其創建的人們。雖然開發和維護一種編程語言總是伴隨着挑戰，但今年我們很高興看到高水平的調查參與和坦率的反饋，這將真正幫助我們讓 Rust 更好地服務於每個人。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334273/2024-state-of-rust-survey-results</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334273/2024-state-of-rust-survey-results</guid>
            <pubDate>Sat, 08 Feb 2025 03:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 首屆全球開發者大會定檔 2 月 21 日，研討 RWKV-7 架構與未來趨勢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;新一代大模型架構 RWKV 將於 &lt;strong&gt;2025 年 2 月 22 日&lt;/strong&gt;在&lt;strong&gt;上海&lt;/strong&gt;舉辦首屆主題為 &lt;strong&gt;《RWKV-7 架構與未來趨勢》&lt;/strong&gt; 的開發者大會，大會將深入探討 RWKV-7 的獨家技術亮點、應用場景以及未來趨勢，展示 RWKV 在推動全球 AI 發展中的前瞻性與領導力。&lt;/p&gt; 
&lt;p&gt;RWKV-7 架構採用動態狀態演化（dynamic state evolution）機制，超越了傳統的 attention/linear attention 範式，擁有強大的上下文學習（in-context learning）能力和持續學習能力。RWKV-7 模型在推理過程中就能不斷自動根據新的數據進行自我優化和改進（test-time training），從而顯著提升了模型的理解力和處理能力。例如 RWKV-7 2.9B 模型的英文和多語言能力（英文評測 71.1%，多語言評測 62.3%），均顯著超越所有同尺寸模型，包括 Llama 3.2 3B（英文評測 68.7%，多語言評測 57.3%）、Qwen2.5 3B（英文評測 68.6%，多語言評測 57.0%）等知名優秀開源模型。且 RWKV-7 2.9B 只訓練了 3T tokens，另兩者訓練了接近 20T tokens。更大規模的 RWKV-7 也在訓練中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0dde119f43dfd830ac5ecc616e6a70e1783.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此次大會將匯聚來自全球的技術專家、頂尖大學教授、行業領袖與創業者，預計超過 3000 名開發者和 AI 技術愛好者將參與其中。大會將設有多個&lt;strong&gt;分享和互動環節&lt;/strong&gt;，為參與者提供一個寶貴的交流與合作平台，幫助全球開發者共同探索 AI 的未來發展方向。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV 開發者論壇演講嘉賓及議程：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a9aff24ab7e5cc3158b5d66b43b45612a83.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV 開發者大會 | 大會信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;時間：2025 年 2 月 22 日 14:00&lt;/li&gt; 
 &lt;li&gt;地點：上海漕河涇現代服務園大廈 A6 號樓&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;RWKV 開發者大會 | 報名二維碼：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1646ff713189f4ad7d2790a64066d4124a6.jpg&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;未來，RWKV 將繼續通過持續創新和生態建設，致力於為全球開發者提供強大的技術支持與資源，推動 AI 技術的普及與應用，敬請期待！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334263</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334263</guid>
            <pubDate>Sat, 08 Feb 2025 02:51:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>Zadig：首個深度集成 DeepSeek 的 DevOps 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img height=&quot;383&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2230cda1042253217386ec9e74ab4b9bf7b.png&quot; width=&quot;898&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言：當工程效能遭遇數據迷霧&lt;/h1&gt; 
&lt;p&gt;在微服務與雲原生架構普及的今天，DevOps 團隊正面臨雙重挑戰：日均千次的流水線執行產生 TB 級數據，卻難以轉化為有效洞見；K8s 生產環境複雜度指數級增長，人工巡檢如同大海撈針。Zadig 與 DeepSeek 的深度協同，首次將 AGI 技術注入 DevOps 全生命週期，推出「&lt;strong&gt;AI 效能分析&lt;/strong&gt;」與「&lt;strong&gt;AI 環境巡檢&lt;/strong&gt;」兩大核心能力，實現從經驗驅動到智能決策的範式轉移。現已面向社區用戶全面開放，開源力量再進化！&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;AI 效能診斷：讓數據説話，精準定位效能瓶頸&lt;/h1&gt; 
&lt;p&gt;傳統工程效能分析往往依賴人工統計與經驗判斷，效率低且易受主觀因素影響，而 Zadig 沉澱了研發過程的構建、部署、測試等大量效能數據，基於 DeepSeek 的 AI 能力，通過智能分析數據，為團隊提供客觀、可操作的改進建議。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能數據分析&lt;/strong&gt;：通過自然語言交互（Prompt 方式），AI 可快速分析流水線、構建、測試等環節的效能數據，識別瓶頸問題。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1530&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74e2b55272658d6609a7f07b0434738960b.png&quot; width=&quot;2942&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;問題精準定位&lt;/strong&gt;：無論是構建耗時過長、測試通過率低，還是資源利用率不足，AI 都能清晰指出問題所在。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1486&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-888422976ca2585f16a7cfc4a352681b7ad.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;科學改進建議&lt;/strong&gt;：基於分析結果，AI 提供具體的優化建議，例如並行測試策略、資源分配調整等，幫助團隊快速提升效能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1486&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d89c13f6e249b6d1517a5d28bd169d63f7d.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;場景價值：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;無需手動分析海量數據，AI 自動生成效能報告，節省大量時間。&lt;/li&gt; 
 &lt;li&gt;通過數據驅動的優化建議，團隊可快速落地改進措施，提升交付效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;AI 環境巡檢：全天候守護，讓環境問題無所遁形&lt;/h1&gt; 
&lt;p&gt;面對複雜的 Kubernetes 生產環境，傳統人工巡檢耗時費力，且難以覆蓋潛在風險。Zadig 的 AI 環境巡檢功能，通過定時巡檢與智能告警，確保環境穩定性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;定時自動巡檢&lt;/strong&gt;：AI 定期對 Kubernetes 環境進行全方位檢查，覆蓋資源狀態、服務健康度等關鍵指標。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;2170&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6351737e713118924456d4aa5a02c16d82b.png&quot; width=&quot;3410&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能問題識別&lt;/strong&gt;：自動識別常見環境問題，如 Pod 異常、資源不足、配置錯誤等，並給出相應的解決方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1530&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f291d5d35f8a63fbb52c7f1a73cd20d7696.png&quot; width=&quot;2942&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;即時告警推送&lt;/strong&gt;：巡檢結果通過 IM 工具（如飛書、釘釘、企業微信等）實時通知相關責任人，確保問題第一時間被處理。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1666&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c8ddc2f1472da2e9cebbc2efb6f9a52cdef.png&quot; width=&quot;2234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;場景價值：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;無需手動巡檢，AI 自動完成環境健康檢查，大幅降低人力成本。&lt;/li&gt; 
 &lt;li&gt;通過即時告警，團隊可快速響應環境問題，避免小問題演變為大故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;結語&lt;/h1&gt; 
&lt;p&gt;Zadig 通過集成 DeepSeek 的 AI 能力，將智能技術深度融入 DevOps 流程，為研發運維團隊帶來了前所未有的效能提升和環境穩定性保障。未來，隨着 AI 技術的不斷發展，Zadig 將繼續探索更多創新應用場景，助力企業實現數字化轉型，提升核心競爭力。&lt;/p&gt; 
&lt;p&gt;Zadig 免費基礎版已全面支持 AI 能力，0 成本解鎖智能 DevOps！&lt;/p&gt; 
&lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;即日起，Zadig 新版發佈&lt;br&gt; 掃碼諮詢搶先體驗&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191b1f; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;943&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0c7876673ed701ed97107bb53b607d661dd.png&quot; width=&quot;1797&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Zadig 在 Github&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://gitee.com/koderover/zadig&quot; rel=&quot;nofollow&quot;&gt;Zadig 在 Gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;&lt;span&gt;推薦閲讀：&lt;/span&gt;&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#002a64; margin-left:0; margin-right:0&quot;&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/11210095&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Zadig 官網博客正式發佈，技術乾貨實踐管飽&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/16492101&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;流水線早已 out 了？你需要更高效能的工作流&lt;/a&gt;&amp;nbsp;/&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10316143&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Jenkins 遷移 Zadig，新項目實施上線效率提升 6 倍&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/16507771&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;🚀 重大更新！Zadig V3.2.0 重塑工作流體驗，強勢推出迭代管理&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/koderover/blog/17622087</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/17622087</guid>
            <pubDate>Sat, 08 Feb 2025 02:44:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>月之暗面因 DeepSeek 調整工作重心，內部人士：強化學習或許會是個方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據媒體報道，月之暗面內部已經將「持續拿到 SOTA 結果」確定為當下最重要的工作目標。&lt;/p&gt; 
&lt;p&gt;2025 年，月之暗面圍繞模型能力的關鍵方向除了繼續強化多模態部分外，還會繼續強化長文本推理能力。報道分析稱，DeepSeek 爆火後，DeepSeek 與月之暗面存在的路線差異，讓外界面臨重新審視月之暗面技術模式、用戶增長模式的情況。&lt;/p&gt; 
&lt;p&gt;而今，DeepSeek 採用區別與月之暗面的路線，也取得了現階段更為出色的效果。業內人士認為，月之暗面如果想守住生態位，「需要做一些改變或者嘗試，比如開源，比如調整引流策略等。」&lt;/p&gt; 
&lt;p&gt;不過目前，月之暗面尚未明確是否「接入」DeepSeek，對於接下來是否「開源」，公司也未置評媒體問詢。&lt;/p&gt; 
&lt;p&gt;對於月之暗面是否會因 DeepSeek 而調整工作重心一事，向月之暗面方面求證，截止發稿公司暫無回應。不過有內部人士透露稱，&lt;strong&gt;「RL（強化學習）大概率會是一個（工作重點）方向」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;去年 11 月份月之暗面宣佈推出&lt;a href=&quot;https://www.oschina.net/news/320859&quot; target=&quot;_blank&quot;&gt;新一代數學推理模型 k0-math &lt;/a&gt;之際，Kimi 探索版便通過運用強化學習技術創新了搜索體驗，在意圖增強、信源分析和鏈式思考三大推理能力上實現突破。彼時，月之暗面 Kimi 創始人楊植麟便對強化學習這一技術路線帶來的模型能力提升給予了高度評價。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f3ef9f71486f2898a14d0b17103cbd4308a.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而在近日 OpenAI 發佈關於推理模型在競技編程中應用的研究論文報告《Competitive Programming with Large Reasoning Models》中，論文也特別提到，「中國的 DeepSeek-R1 和 Kimi k1.5 通過獨立研究顯示，利用思維鏈學習（COT）方法，可顯著提升模型在數學解題與編程挑戰中的綜合表現。其中 k1.5 便是 DeepSeek 和 Kimi 在 1 月 20 日同時發佈的新型推理模型。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334255</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334255</guid>
            <pubDate>Sat, 08 Feb 2025 02:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微信搜索接入 DeepSeek，正在灰度測試中</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 15 日，部分微信用戶發現，微信搜索已經上線「AI 搜索」功能，並接入 DeepSeek-R1 提供的「深度思考」服務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2 月 16 日，記者從騰訊集團確認，微信搜一搜在調用混元大模型豐富 AI 搜索的同時，正式灰度測試接入 DeepSeek&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/101747_uyUN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;騰訊方面表示，部分測試用戶可在微信對話框頂部搜索入口，看到「AI 搜索」字樣，點擊進入後，可免費使用 DeepSeek-R1 滿血版模型，獲得更多元化的搜索體驗。若未顯示該入口，説明此次灰度測試暫未覆蓋到該用戶賬號，可耐心等待後續開放。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/101729_EaEQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用戶表示，通過在微信 AI 搜索「如何在微信上使用 DeepSeek 的 R1 模型」問題得到的答案是，該功能正灰度測試中，僅部分用戶可見，微信版本需更新至最新版本。若暫未獲得測試方案，微信團隊正逐步擴大測試範圍，建議定期檢查更新及搜索功能變化。&lt;/p&gt; 
&lt;p&gt;從功能附帶的開源與鳴謝聲明能看出，&lt;strong&gt;微信中內置的 DeepSeek R1 基於開源版本構建而來，但其中並未明確提及其使用的模型體積，是否是 671B 的「滿血」R1 版本&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/101712_mjq7_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據證券時報今日消息，對於一些相關細節，騰訊方面還作了進一步説明：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;1、AI 搜索的數據源包含公眾號嗎？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;微信 AI 搜索接入的 DeepSeek 支持聯網搜索（用戶無需手動選擇），基於公眾號等豐富的微信生態內容，以及全網優質內容，能為用戶提供更全面的高質量回答。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2、AI 搜索已經全量嗎？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;目前該能力還在灰度測試中，將根據用戶體驗和反饋持續優化。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3、微信的搜索場景為什麼要接入大模型？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;大模型可以提升搜索的智能化和精準度，如更好地理解用戶的搜索意圖，分析和處理複雜的查詢內容等。&lt;/p&gt; 
 &lt;p&gt;結合用戶需求，騰訊在搜索場景中接入了包括混元、DeepSeek 在內的大模型，進一步豐富用戶的搜索體驗。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4、AI 搜索會用我微信內的朋友圈、聊天等個人信息嗎？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;AI 搜索僅整合公眾號及互聯網其他公開信息，不會使用用戶的個人信息和相關隱私信息。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334252</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334252</guid>
            <pubDate>Sat, 08 Feb 2025 02:18:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度搜索宣佈將全面接入 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度搜索發文宣佈，&lt;span&gt;&lt;span&gt;&lt;span&gt;為豐富更多元化的搜索體驗，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;百度搜索將全面接入&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;DeepSeek&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;和文心大模型最新的深度搜索功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;搜索用戶可免費使用 DeepSeek 和文心大模型深度搜索功能，文心智能體平台的開發者也將能隨時調用 DeepSeek 模型創建並調優智能體。&lt;/p&gt; 
&lt;p&gt;根據介紹，文心大模型深度搜索功能於 2 月 13 日上線，具備更強大的思考規劃和工具調用能力，可為用戶提供專家級內容回覆，並處理多場景任務，實現多模態輸入與輸出。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;161&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7a3cff12b27c30d05def83a2c2f4477122.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334250</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334250</guid>
            <pubDate>Sat, 08 Feb 2025 02:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>10W+爆款 AI 流水線：Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;img alt=&quot;2AGI.NET | 2AGI 前沿資訊，探索 AI 無限潛力！&quot; height=&quot;628&quot; src=&quot;https://oscimg.oschina.net/oscnet//e19340e9d109e32404fdefea56b33329.png&quot; width=&quot;1370&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;2AGI.NET | 探索 AI 無限潛力，2AGI 為您帶來最前沿資訊。&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:var(--head-color); margin-left:0; margin-right:0&quot;&gt;熬夜趕稿、追熱點到頭禿、爆文全靠運氣……這些是不是你創作路上的「噩夢」？別急，這裏有個祕密武器，能讓你輕鬆告別這些煩惱，甚至讓爆款內容像印鈔機一樣源源不斷！想知道是什麼「黑科技」嗎？往下看，解鎖 15 分鐘生成爆款的神奇公式！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;454&quot; src=&quot;https://oscimg.oschina.net/oscnet//2304e0e9bc4ab082d0af0f4eb2a538ec.png&quot; width=&quot;1092&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;一、先看效果&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;技術大揭祕：智能爆款流水線的祕訣就是——&lt;strong&gt;Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版&lt;/strong&gt;！從熱點挖掘到爆款文案，再到精美排版和短視頻腳本，15 分鐘自動化生成！&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;今天，我們將逐步拆解這一神奇的流程，手把手教你如何輕鬆打造爆款內容。相信看到最後，你一定收穫滿滿！&lt;/p&gt; 
&lt;h2&gt;二、配置專屬智能體&lt;/h2&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;訪問 Coze 官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.coze.cn%2F&quot; target=&quot;_blank&quot;&gt;https://www.coze.cn/&lt;/a&gt;，並創建智能體。如果還不瞭解 Coze，建議查看基礎教程：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fcoze-creating-fully-automated-ai-intelligence-assistant%2F&quot; target=&quot;_blank&quot;&gt;震撼！用 Coze 打造純自動化 AI 情報助手&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;654&quot; src=&quot;https://oscimg.oschina.net/oscnet//14c420384a03b82b8bcb1edb70d09c3e.png&quot; width=&quot;1088&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;輸入一段功能描述：&lt;strong&gt;你是一位營銷大師，擅長將一段文字內容總結，並給出一段爆款文案&lt;/strong&gt;。選擇「AI 創建」，點擊「生成」按鈕。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;564&quot; src=&quot;https://oscimg.oschina.net/oscnet//809e1484b8f66685d34ed9543d84df9b.png&quot; width=&quot;1132&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;等待系統創建完成，即可看到下面界面：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;708&quot; src=&quot;https://oscimg.oschina.net/oscnet//c9e2e775306e547f445343f0618aa5d6.png&quot; width=&quot;1702&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;br&gt; &lt;strong&gt;注意&lt;/strong&gt;：這裏我們要用到 DeepSeek-R1，所以記得切一下模型。如果不懂 DeepSeek ，可以查看之前的介紹文章：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fwhy-deepseek-became-popular-so-quickly-a-deep-technical-analysis%2F&quot; target=&quot;_blank&quot;&gt;DeepSeek 為何迅速走紅？技術層面的深度剖析（建議收藏）&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;三、驗證智能體&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;按照上述步驟，一款使用了 DeepSeek 的「文案精靈」創造完成，接下來我們來測試下。&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;1、先給 DeepSeek-R1 一篇內容&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1042&quot; src=&quot;https://oscimg.oschina.net/oscnet//6f640e89d1c68ed61d0ad995906c1699.png&quot; width=&quot;972&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;2、等待 DeepSeek-R1 完成分析&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1160&quot; src=&quot;https://oscimg.oschina.net/oscnet//5968cd8f682731bd8072471cd1f8be6b.png&quot; width=&quot;932&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;3、生成卡片形式，並按照 HTML 格式整理&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;884&quot; src=&quot;https://oscimg.oschina.net/oscnet//fd112438ec29e6f4bb8ce5f346667b76.png&quot; width=&quot;678&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;4、下載該 HTML 文件，並使用瀏覽器打開&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;選擇文件，右鍵「打開方式」，選擇默認瀏覽器即可。這裏演示 Google Chrome 瀏覽器效果。&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1024&quot; src=&quot;https://oscimg.oschina.net/oscnet//7b5a845a231ac6b8486554372af6ef83.png&quot; width=&quot;1018&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;5、預覽效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;這裏使用了 CSS 漸變色背景，當然，你也可以用圖片背景，使其效果更佳。&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;916&quot; src=&quot;https://oscimg.oschina.net/oscnet//66e59b13ba02a1f5d4d6726b238f891e.png&quot; width=&quot;1100&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;strong&gt;四、圖文和視頻創作&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;按照上述步驟，我們已經通過內容，得到了一段爆款文案，以及配套圖文。接下來，可以就可以發「圖文」和「視頻」了。&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;1、圖文創作&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;圖文比較典型的就是「小紅書」渠道，將上述截圖保存即可。接下來，打開小紅書，選擇音樂和圖片，完成創作。&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1204&quot; src=&quot;https://oscimg.oschina.net/oscnet//09040beef1cb6c126ac57c718a263a63.png&quot; width=&quot;1026&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;br&gt; &lt;strong&gt;2、視頻創作&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;這裏筆者使用了騰訊的秒剪，選擇「文字轉視頻」，這裏可以用 AI 生成一段口播文案，並配上圖文，使用「一鍵快剪」即可完成。&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;990&quot; src=&quot;https://oscimg.oschina.net/oscnet//f303967e214d7e8f0ecc43dac5f0afd8.png&quot; width=&quot;2046&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;strong&gt;總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;在當今快節奏的內容創作時代，熬夜趕稿、追逐熱點、靈感枯竭以及對爆款內容的渴望，幾乎是每個創作者的日常寫照。然而，隨着技術的進步，AI 的出現為創作者帶來了全新的解決方案。&lt;strong&gt;通過智能爆款流水線——結合 Coze 深度寫作、DeepSeek 算法洞察和 HTML 極速排版，創作者能夠從熱點挖掘到爆款文案、精美排版，甚至短視頻腳本的生成，實現全流程的自動化，僅需 15 分鐘即可完成&lt;/strong&gt;。&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;這不僅大大提升了創作效率，還讓爆款內容的產出變得更加穩定和高效。告別傳統創作的困境，擁抱 AI 助力的新時代，讓創作變得輕鬆且高效。&lt;/p&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;h1&gt;🔥 熱門文章推薦（2AGI.NET）&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2F10w-plus-hit-ai-pipeline-coze-depth-writing-deepseek-algorithm-insight-html-fast-typesetting%2F&quot; target=&quot;_blank&quot;&gt;10W+爆款 AI 流水線：Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 16 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fexploring-the-secrets-of-world-models%2F&quot; target=&quot;_blank&quot;&gt;探索世界模型奧祕&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 16 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Funderstanding-intelligent-emergence%2F&quot; target=&quot;_blank&quot;&gt;如何理解智能湧現（emergence）&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 15 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250214&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 14 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250213%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250213&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 13 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250212%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250212&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 12 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250211%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250211&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 11 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250210%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250210&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 10 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fmflops-million-flops-computational-speed%2F&quot; target=&quot;_blank&quot;&gt;MFLOPS（Million FLOPS）：百萬次運算速度&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 9 日&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;掃碼加入社羣，參與討論&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img alt=&quot;2AGI 技術社區，歡迎掃碼加入&quot; height=&quot;558&quot; src=&quot;https://oscimg.oschina.net/oscnet//c64927e8ffa21e3d0cf23db880e103cf.png&quot; width=&quot;1180&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fagi%2F&quot; target=&quot;_blank&quot;&gt;AGI&lt;span&gt;(102)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-agent%2F&quot; target=&quot;_blank&quot;&gt;AI Agent&lt;span&gt;(3)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-app%2F&quot; target=&quot;_blank&quot;&gt;AI App&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-celebrity%2F&quot; target=&quot;_blank&quot;&gt;AI Celebrity&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Faigc%2F&quot; target=&quot;_blank&quot;&gt;AIGC&lt;span&gt;(124)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e5%2590%258d%25e4%25ba%25ba%25e5%25a0%2582%2F&quot; target=&quot;_blank&quot;&gt;AI 名人堂&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334239</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334239</guid>
            <pubDate>Sat, 08 Feb 2025 01:15:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>跨瀏覽器兼容性再升級：Interop 2025 計劃正式啓動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在萬眾期待中，跨瀏覽器兼容性項目 Interop 2025 於 2 月 12 日正式揭開帷幕。這是繼 2022 年首次啓動以來的第四個年度計劃，彙集了包括蘋果、谷歌、微軟和 Mozilla 在內的主要瀏覽器廠商，以及 Bocoup 和 Igalia 等重要的開源貢獻者，共同致力於提升 Web 平台的跨瀏覽器一致性體驗。&lt;/p&gt; 
&lt;p&gt;回顧 2024 年的成果，各大瀏覽器在兼容性測試中交出了令人矚目的成績單。Safari 18.2 在穩定版中達到了 98% 的通過率，其技術預覽版更是與 Chrome Canary、Edge Dev 和 Firefox Nightly 一起，均實現了 99% 的測試通過率。這意味着從無障礙功能到自定義屬性，從字體大小調整到文本方向等一系列特性，現在都能在各大瀏覽器中保持一致的表現。&lt;/p&gt; 
&lt;p&gt;新一年的計劃涵蓋了 19 個重點關注領域，其中 17 個是全新加入的特性。這些新特性涉及 Web 開發的方方面面。首先是錨點定位系統，它允許元素相對於其他元素進行精確定位，為複雜佈局提供了更靈活的解決方案。背景濾鏡特性則為元素背景區域添加模糊等視覺效果，增強了頁面的視覺表現力。在性能監測方面，核心網絡指標的跨瀏覽器支持將為開發者提供更統一的性能評估工具。&lt;/p&gt; 
&lt;p&gt;在用戶界面交互方面，details 元素將獲得增強支持，Flexbox 和 Grid 佈局系統也將進一步優化。為了提升開發效率，JSON 模塊和導入屬性將實現標準化，導航 API 也將在各瀏覽器中獲得統一實現。指針和鼠標事件的改進將帶來更流暢的交互體驗，同時傳統的 Mutation 事件將被更高效的方案所取代。&lt;/p&gt; 
&lt;p&gt;CSS 相關特性也得到了重點關注，包括 CSS 作用域的統一支持、scrollend 事件的標準化、文本裝飾特性的統一等。存儲訪問 API 的增強和 URLPattern API 的實現將為開發者提供更強大的數據處理工具。此外，視圖轉換效果的優化、WebAssembly 的增強特性、Web 兼容性問題的解決、WebRTC 的改進以及書寫模式的擴展支持，都將為 Web 應用帶來更豐富的可能性。&lt;/p&gt; 
&lt;p&gt;除了具體的功能改進，Interop 2025 還設立了五個重要的調查項目。無障礙測試將繼續深化，確保 Web 內容對所有用戶都更加友好。遊戲 API 測試的完善將推動 Web 遊戲生態的發展。移動端測試基礎設施的建設將為未來的移動 Web 體驗提供保障。隱私保護測試框架的構建體現了對用戶隱私的重視，而 WebVTT 字幕系統的優化則將提升多媒體內容的可訪問性。&lt;/p&gt; 
&lt;p&gt;本次計劃的一個顯著特點是對現代 Web 應用需求的全面覆蓋。從視圖轉換 API 到 WebAssembly 的性能優化，從隱私保護到無障礙訪問，都體現了對用戶體驗的全方位考慮。特別值得一提的是，Safari 瀏覽器已經在 18.0 和 18.2 版本中實現了視圖轉換特性，並在 17.4 版本中支持了 CSS 作用域規則，展現了項目參與方推動 Web 標準發展的決心。&lt;/p&gt; 
&lt;p&gt;對於 Web 開發者來説，Interop 2025 的啓動意味着更加便捷的開發體驗和更少的跨瀏覽器兼容性問題。隨着這些新特性的逐步落地，開發者將能夠更自信地使用最新的 Web 技術，而無需擔心瀏覽器兼容性問題。&lt;/p&gt; 
&lt;p&gt;展望未來，隨着瀏覽器廠商之間合作的深入，Web 平台的統一性和可靠性將繼續提升。Interop 項目的成功證明，通過開放合作，Web 技術生態可以在保持創新的同時，為用戶提供更加一致和優質的體驗。正如 Safari 團隊所展示的，在 Interop 2024 中取得的 98% 通過率證明瞭這一點。隨着 2025 年計劃的推進，我們有理由相信，Web 平台將迎來更加光明的未來。對於開發者、設計師和最終用戶來説，這無疑是一個激動人心的消息。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334136</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334136</guid>
            <pubDate>Fri, 07 Feb 2025 09:13:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>從數據到情感：全維度解析哪吒 2 的 212 億票房之戰</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; text-align:start&quot;&gt;綜合目前的數據來看，我分析一下哪吒 2 的最終票房和衝擊第一名可能性。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;當前態勢：票房現狀説明&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;目前票房：110 億&lt;/li&gt; 
 &lt;li&gt;國內貢獻：90% 以上（約 108 億）&lt;/li&gt; 
 &lt;li&gt;海外表現：僅 2300 萬&lt;/li&gt; 
 &lt;li&gt;已上映：春節檔 15 天左右&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;三條預測路徑分析（含日均計算）&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;A. 基礎預測線（160-170 億）&lt;/p&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-plain_text&quot;&gt;目標缺口：50-60 億
時間週期：45 天
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;具體路徑：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;第一階段（15 天）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：2 億&lt;/li&gt; 
   &lt;li&gt;階段貢獻：30 億&lt;/li&gt; 
   &lt;li&gt;工作日表現：1.5 億/天&lt;/li&gt; 
   &lt;li&gt;週末表現：3 億/天&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第二階段（15 天）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：1.5 億&lt;/li&gt; 
   &lt;li&gt;階段貢獻：22.5 億&lt;/li&gt; 
   &lt;li&gt;工作日表現：1 億/天&lt;/li&gt; 
   &lt;li&gt;週末表現：2.5 億/天&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第三階段（15 天）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：0.5 億&lt;/li&gt; 
   &lt;li&gt;階段貢獻：7.5 億&lt;/li&gt; 
   &lt;li&gt;預期總貢獻：60 億&lt;/li&gt; 
   &lt;li&gt;最終票房：約 170 億&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;實現可能性：80%&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;B. 目標預測線（180-190 億）&lt;/p&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-plain_text&quot;&gt;目標缺口：70-80 億
時間週期：60 天
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;路徑設計：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;首 20 天&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：2 億&lt;/li&gt; 
   &lt;li&gt;階段目標：40 億&lt;/li&gt; 
   &lt;li&gt;工作日表現：1.5 億/天&lt;/li&gt; 
   &lt;li&gt;週末表現：3.5 億/天&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中 20 天&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：1.2 億&lt;/li&gt; 
   &lt;li&gt;階段目標：24 億&lt;/li&gt; 
   &lt;li&gt;工作日表現：1 億/天&lt;/li&gt; 
   &lt;li&gt;週末表現：2 億/天&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;末 20 天&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：0.8 億&lt;/li&gt; 
   &lt;li&gt;階段目標：16 億&lt;/li&gt; 
   &lt;li&gt;預期總貢獻：80 億&lt;/li&gt; 
   &lt;li&gt;最終票房：約 190 億&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;實現可能性：40%&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;C. 極限預測線（212 億+）&lt;/p&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-plain_text&quot;&gt;目標缺口：102 億以上
時間週期：90 天
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;路徑規劃：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;第一月（30 天）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：1.8 億&lt;/li&gt; 
   &lt;li&gt;月度目標：54 億&lt;/li&gt; 
   &lt;li&gt;工作日表現：1.5 億/天&lt;/li&gt; 
   &lt;li&gt;週末表現：3 億/天&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第二月（30 天）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：1.2 億&lt;/li&gt; 
   &lt;li&gt;月度目標：36 億&lt;/li&gt; 
   &lt;li&gt;工作日表現：1 億/天&lt;/li&gt; 
   &lt;li&gt;週末表現：2 億/天&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第三月（30 天）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;日均要求：0.6 億&lt;/li&gt; 
   &lt;li&gt;月度目標：18 億&lt;/li&gt; 
   &lt;li&gt;預期總貢獻：108 億&lt;/li&gt; 
   &lt;li&gt;最終票房：約 218 億&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;實現可能性：10%&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;關鍵影響因素：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;45 天基礎線：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需保持穩定排片&lt;/li&gt; 
   &lt;li&gt;工作日票房穩定&lt;/li&gt; 
   &lt;li&gt;週末效應明顯&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;60 天目標線：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需獲批延期放映&lt;/li&gt; 
   &lt;li&gt;維持較高排片比&lt;/li&gt; 
   &lt;li&gt;市場熱度不減&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;90 天極限線：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需超長放映許可&lt;/li&gt; 
   &lt;li&gt;海外市場突破&lt;/li&gt; 
   &lt;li&gt;保持高排片佔比&lt;/li&gt; 
   &lt;li&gt;無強力競爭對手&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;合理預期：160-170 億目標分析&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;我預測哪吒 2 的最終票房應該是 160-170 億！我來分析一下為什麼是這個結果？&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;市場現實面：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;春節紅利消退，日均票房自然下滑&lt;/li&gt; 
   &lt;li&gt;學生返校、上班族返工，觀影時間受限&lt;/li&gt; 
   &lt;li&gt;新片 successively 上映，分流壓力加大&lt;/li&gt; 
   &lt;li&gt;排片佔比逐步下降，優質場次減少&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;觀眾基本盤：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;核心粉絲觀影基本完成&lt;/li&gt; 
   &lt;li&gt;春節檔家庭觀影潮已過&lt;/li&gt; 
   &lt;li&gt;二刷三刷人羣逐漸飽和&lt;/li&gt; 
   &lt;li&gt;上班族工作日觀影意願降低&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;市場天花板：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;動畫電影受眾羣體有限&lt;/li&gt; 
   &lt;li&gt;票價結構難以提升&lt;/li&gt; 
   &lt;li&gt;排片比例難以維持春節檔水平&lt;/li&gt; 
   &lt;li&gt;市場自然規律制約&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;衝擊 212 億的可能性分析&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;現實困難：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;距離目標還差 102 億&lt;/li&gt; 
   &lt;li&gt;需要持續 90 天以上放映期&lt;/li&gt; 
   &lt;li&gt;每日需保持 1 億以上票房增長&lt;/li&gt; 
   &lt;li&gt;海外市場需突破性增長&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;外部阻力：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;外媒對中國電影的偏見&lt;/li&gt; 
   &lt;li&gt;文化認知差異帶來的理解障礙&lt;/li&gt; 
   &lt;li&gt;海外發行渠道受限&lt;/li&gt; 
   &lt;li&gt;國際市場競爭激烈&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;特殊因素：外媒唱衰與國內情緒&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;這裏我要特別提出一個有意思的點：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;外媒態度：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;對中國神話理解偏差&lt;/li&gt; 
   &lt;li&gt;對中國傳統文化認知不足&lt;/li&gt; 
   &lt;li&gt;對票房真實性質疑&lt;/li&gt; 
   &lt;li&gt;對市場表現不客觀評價&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;國內反應：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;民族自豪感推動觀影熱情&lt;/li&gt; 
   &lt;li&gt;對外媒質疑的情緒反彈&lt;/li&gt; 
   &lt;li&gt;支持國產動畫的集體意識&lt;/li&gt; 
   &lt;li&gt;票房破 212 億的強烈期待&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;我的最終預測&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;基礎預期：160-170 億，原因：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;符合市場自然規律&lt;/li&gt; 
   &lt;li&gt;考慮實際觀影條件&lt;/li&gt; 
   &lt;li&gt;顧及排片壓力變化&lt;/li&gt; 
   &lt;li&gt;預留合理增長空間&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;突破可能：212 億+ 條件：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;外媒負面聲音刺激國內情緒&lt;/li&gt; 
   &lt;li&gt;國家政策支持延期放映&lt;/li&gt; 
   &lt;li&gt;民族文化自信推動觀影&lt;/li&gt; 
   &lt;li&gt;全民支持形成觀影高潮&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;特別觀點&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;我認為這次哪吒 2 的票房之戰已經超越了單純的市場行為，它正在演變成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文化自信的展現&lt;/li&gt; 
 &lt;li&gt;國產動畫的里程碑&lt;/li&gt; 
 &lt;li&gt;中國電影市場的實力證明&lt;/li&gt; 
 &lt;li&gt;對外媒質疑的最好回應&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;結語&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;哪吒 2 的最終票房到底能達到多少？我認為這不僅僅是一個數字遊戲。從目前市場規律來看，160-170 億是相對理性的預期。但如果考慮到外媒的不實報道可能激起國內觀眾的情緒共鳴，突破 212 億也並非不可能。畢竟，這已經不僅僅是一部動畫電影的票房之戰，而是中國電影人和觀眾用實際行動展現文化自信的集體行為。讓我們拭目以待！&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:start&quot;&gt;（數據及分析截至 2025 年 2 月）&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本分析不代表最終的結果，只是我個人的一個模擬預測數據。僅供參考！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333968</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333968</guid>
            <pubDate>Thu, 06 Feb 2025 17:44:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>MyBatis-MP 這個 ORM 框架強過你寫的 100 行 SQL</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;MyBatis-MP 這個 ORM 框架強過你寫的 100 行 SQL，操作簡單到不敢相信，在繁雜的 Java 項目中，如何優雅、高效地進行數據庫操作？MyBatis-MP，一個基於 MyBatis 的輕量級 ORM 框架，或許就是你的救星！本文將介紹 MyBatis-MP 的基本信息、獨特功能，以及如何快速上手。&lt;/p&gt; 
&lt;p&gt;項目簡介 MyBatis-MP 是一款基於 MyBatis 的輕量級 ORM 框架。與其他龐大複雜的 ORM 框架不同，MyBatis-MP 既保持了 MyBatis 強大的靈活性，又提供了許多便捷的擴展功能，簡化了開發人員的工作。&lt;/p&gt; 
&lt;p&gt;它不僅是輕量級的，而且具有高性能，適合各種數據庫場景，能夠處理大部分的 SQL 需求，無論是簡單查詢還是複雜多層嵌套查詢，MyBatis-MP 都能輕鬆搞定。&lt;/p&gt; 
&lt;p&gt;項目亮點 MyBatis-MP 有許多亮點，簡直就是開發者的福音：&lt;/p&gt; 
&lt;p&gt;• 動態默認值：支持自定義動態默認值，再也不用手動設置那些繁瑣的初始化數據。&lt;/p&gt; 
&lt;p&gt;• 多數據庫自增配置：支持不同數據庫的 ID 自增配置，不再為 ID 自增而煩惱。&lt;/p&gt; 
&lt;p&gt;• 邏輯刪除：支持邏輯刪除，還能自動填充刪除時間，不用再手動處理複雜的刪除操作。&lt;/p&gt; 
&lt;p&gt;• 自定義 SQL 模板：支持自定義 SQL 模板，讓你輕鬆編寫複用性高的 SQL 語句。&lt;/p&gt; 
&lt;p&gt;• Map 轉換：查詢結果直接轉成 Map，想象一下，查詢再也不用自己組裝數據了！&lt;/p&gt; 
&lt;p&gt;• 自動分頁：無需額外配置，XML 和 @Select 查詢自動分頁，讓你的分頁操作如絲般順滑。&lt;/p&gt; 
&lt;p&gt;• 多層嵌套支持：支持複雜嵌套的 VO 對象自動映射，數據庫複雜的嵌套查詢也能輕鬆應對。&lt;/p&gt; 
&lt;p&gt;使用 MyBatis-MP 的好處，高性能 MyBatis-MP 的性能對比其他同類框架毫不遜色，接近最優，特別是在大規模數據處理上表現尤為突出。它會自動優化 SQL，去除不必要的 left join 和 order by，極大提高了查詢效率。&lt;/p&gt; 
&lt;p&gt;靈活方便，它擁有極簡的 API，幾乎零學習成本！即便你是初次接觸 ORM 框架，也能輕鬆上手。它提供了非常豐富的功能，涵蓋了大部分的日常需求。&lt;/p&gt; 
&lt;p&gt;安全可靠 API 設計簡潔易懂，沒有複雜的設計結構，確保代碼簡潔且不易出錯，同時提供了豐富的安全功能和異常處理機制，保證項目運行安全穩定。&lt;/p&gt; 
&lt;p&gt;快速開始，想要快速上手 MyBatis-MP？這裏有幾步簡單的操作指南：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;基於 Spring Boot 項目開發，先引入 spring-boot-starter 依賴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;配置數據源，常見的 jdbc:mysql:// 地址、用戶名和密碼等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用 MyBatis-MP 提供的鏈式查詢 API，編寫你的第一段代碼：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;List list = QueryChain.of(sysUserMapper) .forSearch() // 自動忽略空值和空字符串 .eq(SysUser::getId, 1) .like(SysUser::getUserName, &quot;admin&quot;) .list(); 是不是非常簡潔又強大？&lt;/p&gt; 
&lt;p&gt;部署與集成 MyBatis-MP 非常輕量，集成到 Spring Boot 項目中幾乎無縫對接。通過簡單的 Maven 配置即可上手：&lt;/p&gt; 
&lt;p&gt;cn.mybatis-mp mybatis-mp-spring-boot-starter 1.6.9&lt;/p&gt; 
&lt;p&gt;只需幾步，你的項目就已經集成了 MyBatis-MP。&lt;/p&gt; 
&lt;p&gt;源代碼下載地址，如果你想親自體驗這個框架，可以從 Gitee 克隆項目：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://gitee.com/mybatis-mp/mybatis-mp.git&quot;&gt;https://gitee.com/mybatis-mp/mybatis-mp.git&lt;/a&gt; 結語 MyBatis-MP 作為一個輕量且強大的 ORM 框架，幫助開發者輕鬆高效地處理各種數據庫操作，無論是增刪查改，還是複雜的查詢優化，它都能一手搞定。&lt;/p&gt; 
&lt;p&gt;如果你還沒試過 MyBatis-MP，趕緊去下載體驗吧！絕對是你開發中的一大利器。&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333928</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333928</guid>
            <pubDate>Thu, 06 Feb 2025 12:41:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>天天 AI-20250215</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h4&gt;&lt;strong&gt;1. Karpathy 大神問懵 DeepSeek：一個🤣竟藏 53 個 Token&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，量子位報道了 AI 領域的一場有趣交鋒。AI 專家 Andrej Karpathy 向 DeepSeek 提出了一個看似簡單卻極具挑戰性的問題：一個「🤣」表情符號中竟隱藏了 53 個 Token。DeepSeek 在思考了 10 分鐘後未能給出令人滿意的解釋，這一事件引發了社區的廣泛討論。這不僅展示了 AI 模型在處理複雜任務時的侷限性，也提醒了開發者在設計 AI 系統時需要更加註重邏輯和解釋能力。未來，AI 模型需要在性能和可解釋性之間找到更好的平衡。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fh4j-4lJylmHWisskaF14TQ&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;2. 官宣！阿里巴巴與蘋果合作，為中國 iPhone 提供 AI&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AIGC 開放社區報道了阿里巴巴與蘋果公司的重大合作。阿里巴巴將為中國市場的 iPhone 提供 AI 技術支持，這一合作標誌着兩大科技巨頭在 AI 領域的強強聯合。通過整合雙方的技術優勢，此次合作有望為中國用戶提供更智能、更個性化的 AI 體驗。同時，這也反映了 AI 技術在全球消費電子市場中的重要性日益增加。未來，AI 將成為智能手機的核心競爭力之一。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTcmlNrPZahBiausPQe3_-A&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;3. OpenAI 發佈最新模型規範&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AIGC 開放社區報道了 OpenAI 的最新動態。OpenAI 發佈了其最新模型的規範，這一規範不僅詳細介紹了模型的架構和性能，還提供了開發者在使用和優化模型時的具體指導。OpenAI 的這一舉措旨在推動 AI 技術的標準化和普及化，幫助更多開發者更好地利用其技術。未來，AI 模型的標準化將成為行業發展的重要趨勢，促進技術的廣泛應用。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F8Jg8f4KexpvpTCP9nGFHyw&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;4. 歐盟投資 2000 億美元，全力發展 AI&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AIGC 開放社區報道了歐盟在 AI 領域的重大投資計劃。歐盟宣佈將投資 2000 億美元用於 AI 技術的研發和基礎設施建設。這一計劃顯示了歐盟對 AI 技術的高度重視，旨在通過大規模投資提升其在全球 AI 市場的競爭力。未來，AI 將成為推動歐洲經濟和社會發展的關鍵力量，同時也為全球 AI 技術的發展提供重要支持。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F59opmkkH-tNsFMGdfdotdg&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;5. 釦子（coze）一鍵生成爆款短視頻並全自動發佈到剪映&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 14 日，傑克船長的 AIGC 報道了釦子（coze）的最新功能。釦子通過行業熱詞一鍵生成爆款短視頻，並能夠全自動發佈到剪映。這一功能不僅展示了 AI 在內容創作領域的強大能力，也為創作者提供了高效的工具支持。通過 AI 技術，創作者可以更輕鬆地生成高質量的視頻內容，提升創作效率。未來，AI 將在內容創作領域發揮更大的作用，推動行業的創新和發展。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FgQj1d1VdMZMgn2gOwj9Xjw&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;6. AI 營銷，誰是成長最快企業？&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，數説商業分析了 AI 營銷領域的最新動態。隨着 AI 技術的普及，越來越多的企業開始利用 AI 進行市場營銷，提升用戶參與度和轉化率。文章指出，AI 營銷領域正在快速成長，一些企業通過創新的 AI 應用取得了顯著的市場優勢。未來，AI 將成為營銷領域的核心工具，推動企業更好地理解和滿足用戶需求。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrvD3kausogNXH3ru-pVh1g&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;7. 感謝 DeepSeek，OpenAI 不再只是畫餅&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，探索 AGI 報道了 DeepSeek 對 OpenAI 的影響。文章指出，DeepSeek 的出現讓 OpenAI 的技術突破變得更加具體和實際。DeepSeek 不僅展示了強大的 AI 能力，還推動了 OpenAI 在技術研發和應用推廣上的進步。未來，AI 技術需要更多像 DeepSeek 這樣的創新者，將技術從理論推向實際應用。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fcz5cBcJVPIRTNFuFjj87cw&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;8. 字節即夢、快手可靈快速崛起，AI 創作呼喚爆款&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，量子位智庫分析了字節即夢和快手可靈的快速崛起。這兩家公司通過 AI 技術在內容創作領域取得了顯著成就，展示了 AI 在短視頻和直播領域的巨大潛力。文章指出，AI 創作正在呼喚更多爆款應用，推動行業的進一步發展。未來，AI 將在內容創作領域發揮更大的作用，為用戶帶來更多創新體驗。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FBasnTOwbDWXmq53i4_UjTg&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;9. ollama 小白手冊（Linux）發佈&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AIGC 前沿技術追蹤報道了 ollama 發佈的小白手冊（Linux 版本）。這一手冊為初學者提供了詳細的指導，幫助他們在 Linux 環境下快速上手 ollama 框架。通過降低技術門檻，ollama 旨在推動更多開發者參與到 AI 項目的開發中。未來，AI 技術的普及化將成為行業發展的重要趨勢，吸引更多開發者加入這一領域。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3JDaL0n1icHPVsH6Z6iWlg&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;10. 蘋果官宣「硬件新成員」：帶屏 HomePod 會是今年最重要的 AI 硬件嗎？&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，極客公園報道了蘋果公司推出的新硬件產品——帶屏 HomePod。這款設備被認為是蘋果在 AI 硬件領域的又一重要佈局。帶屏 HomePod 不僅具備強大的智能語音交互功能，還集成了先進的顯示技術，使其在智能家居控制、信息展示和娛樂功能上更具優勢。業界普遍認為，帶屏 HomePod 可能會成為今年最重要的 AI 硬件之一，推動智能家居市場的發展。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F17AAmPdmy7Hf7cAxPzhLTA&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;11. 十多個模型打不過 DeepSeek 一個？奧特曼怒將 GPT 和 o 系列合併&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AI 前線報道了 DeepSeek 在 AI 模型領域的強大表現。據報道，DeepSeek 在多項測試中超越了十多個競爭對手，這引發了行業的廣泛關注。為了應對這一挑戰，OpenAI 的創始人 Sam Altman 決定將 GPT 和 o 系列模型合併，以提升其在市場中的競爭力。這一舉措不僅反映了 AI 市場競爭的激烈，也表明了技術整合將成為未來 AI 發展的重要趨勢。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwhWISrNRt0pHRSiDqnf5SQ&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;12. 連播 12 天！深度揭祕 DeepSeek&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AI 前線推出了一系列關於 DeepSeek 的深度報道，連續 12 天詳細解讀其技術細節和市場表現。這些報道揭示了 DeepSeek 在 AI 領域的多項創新，包括其強大的語言生成能力、高效的推理效率以及獨特的模型架構。通過這些報道，公眾對 DeepSeek 的技術優勢和市場潛力有了更深入的瞭解。未來，DeepSeek 有望在更多領域實現突破，推動 AI 技術的進一步發展。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_yBVcvsVC-fH3UIZt5Jw0g&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;13. 百度宣佈：文心一言 4 月 1 日起全面免費，退費事宜已同步展開&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，AI 前線報道了百度的重大決定：文心一言將從 4 月 1 日起全面免費，並同步展開退費事宜。這一舉措不僅展示了百度在 AI 領域的戰略佈局，也表明了其對市場推廣的積極態度。通過免費開放文心一言，百度有望吸引更多用戶和開發者，進一步提升其在 AI 市場的影響力。同時，這一決定也引發了行業對 AI 服務商業模式的進一步探討。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Faxfz9_LXhz4XTcf2JHe-qw&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;14. DeepSeek 的「服務器繁忙」讓所有人抓狂，背後究竟是怎麼回事&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，硅星人 Pro 分析了 DeepSeek 近期頻繁出現的「服務器繁忙」問題。這一問題引發了用戶的廣泛不滿，許多人對 DeepSeek 的服務穩定性提出了質疑。據報道，這一問題可能與 DeepSeek 用戶量的快速增長有關，其服務器資源未能及時跟上需求。未來，DeepSeek 需要進一步優化其技術架構，提升服務穩定性，以應對用戶增長帶來的挑戰。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FxZzMgVkHczjSXhz15EipnA&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;15. DeepSeek-R1 超高幻覺率解析：為何大模型總「胡説八道」？&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 2 月 13 日，硅星人 Pro 對 DeepSeek-R1 模型的超高幻覺率進行了深入解析。報道指出，儘管 DeepSeek 在多項任務中表現出色，但其模型仍存在生成幻覺的問題，即在某些情況下會生成不符合邏輯或事實的內容。這一問題引發了對 AI 模型可靠性的討論，許多專家認為，未來 AI 模型需要在生成質量和邏輯準確性上進一步優化，以減少類似問題的發生。&lt;br&gt; 來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhORpVg1pWyODN9WgxuskVg&quot; target=&quot;_blank&quot;&gt;鏈接&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;原文&lt;/a&gt;&lt;/p&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;h1&gt;🔥 熱門文章推薦（2AGI.NET）&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Funderstanding-intelligent-emergence%2F&quot; target=&quot;_blank&quot;&gt;如何理解智能湧現（emergence）&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 15 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250214&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 14 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250213%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250213&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 13 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250212%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250212&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 12 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250211%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250211&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 11 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250210%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250210&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 10 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fmflops-million-flops-computational-speed%2F&quot; target=&quot;_blank&quot;&gt;MFLOPS（Million FLOPS）：百萬次運算速度&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 9 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftokenizer-efficient-tokenization-text-analysis-tool%2F&quot; target=&quot;_blank&quot;&gt;Tokenizer：高效詞元化器，文本分析利器&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 8 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250207%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250207&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 2 月 7 日&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;掃碼加入社羣，參與討論&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img alt=&quot;2AGI 技術社區，歡迎掃碼加入&quot; height=&quot;558&quot; src=&quot;https://oscimg.oschina.net/oscnet//8a2c37a50230777dd42b65047d3037bb.png&quot; width=&quot;1180&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fagi%2F&quot; target=&quot;_blank&quot;&gt;AGI&lt;span&gt;(101)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-agent%2F&quot; target=&quot;_blank&quot;&gt;AI Agent&lt;span&gt;(3)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-app%2F&quot; target=&quot;_blank&quot;&gt;AI App&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-celebrity%2F&quot; target=&quot;_blank&quot;&gt;AI Celebrity&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Faigc%2F&quot; target=&quot;_blank&quot;&gt;AIGC&lt;span&gt;(122)&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333823</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333823</guid>
            <pubDate>Thu, 06 Feb 2025 00:44:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
    </channel>
</rss>