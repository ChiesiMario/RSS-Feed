<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 22 Sep 2025 02:40:50 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>OpenMind 開源全球首個「AI 原生」機器人系統 OM1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenMind 現已推出一款號稱是全球首個「AI 原生」開源機器人系統，該系統旨在統一全平台生態，構建統一的開發基礎，讓不同類型的機器人在同一平台上實現感知、推理與行動，支持多種硬件與仿真環境。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6325062d4450079cac06d11cff78a0a6aad.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該系統強調「硬件中立」，可運行在四足、雙足、人形與輪式等不同平台上，並以 Docker 鏡像提供快速部署，兼容 AMD64 與 ARM64 架構，支持接入 OpenAI、Gemini、DeepSeek、xAI 等模型，原生支持宇樹 Unitree G1、Go2、TurtleBot 以及優必選等機器人產品，方便開發者快速上手。&lt;/p&gt; 
&lt;p&gt;OM1 整體架構如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bc4a425e4784e9f570a7ab229b6690271ed.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模塊化架構：採用 Python 設計，旨在實現簡潔性和無縫集成。&lt;/li&gt; 
 &lt;li&gt;數據輸入：輕鬆處理新數據和傳感器。&lt;/li&gt; 
 &lt;li&gt;通過插件提供硬件支持：通過 API 端點的插件以及與 ROS2、Zenoh 和 CycloneDDS 的特定機器人硬件連接來支持新硬件（建議所有新開發項目都使用 Zenoh）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在自主導航與環境理解方面，OM1 集成了即時定位與地圖構建（SLAM）、LiDAR 傳感器與 Nav2 路徑規劃，讓機器人能夠在複雜環境中實現自主移動。開發者可先通過 Gazebo 仿真環境進行行為測試，再將配置部署至實際硬件，從而降低實驗成本與風險。&lt;/p&gt; 
&lt;p&gt;與此同時，OM1 還提供了名為 OM1 Avatar 的前端界面，基於 React 開發，可實時展示機器人的狀態與虛擬形象，方便觀察和交互。&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;em&gt;https://github.com/OpenMind/OM1&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373637</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373637</guid>
      <pubDate>Mon, 22 Sep 2025 02:29:48 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里雲爆款雲服務器 68 元/年，2 核 2G 限時秒殺，超高性價比，立即搶購！</title>
      <description>覆蓋 90%+通用業務場景，組合購買「專享活動價」。</description>
      <link>https://click.aliyun.com/m/1000406832/</link>
      <guid isPermaLink="false">https://click.aliyun.com/m/1000406832/</guid>
      <pubDate>Mon, 22 Sep 2025 02:15:48 GMT</pubDate>
    </item>
    <item>
      <title>CNCF 與 Docker 達成合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;CNCF &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5t8eWP9JVkBarMiiitdWEw" target="_blank"&gt;宣佈&lt;/a&gt;與 Docker 達成新合作，進一步擴展對 CNCF 託管項目的安全、可擴展支持。通過此次合作，所有 CNCF 項目將直接接入 Docker 的贊助開源計劃（DSOS），該計劃通過開放高端註冊表、安保和支持服務，助力開源社區成長與成功。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「此次合作體現了 CNCF 對雲原生生態基礎設施的支持承諾，肯定了 Docker 在開源與企業工作流中的重要作用。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-e4f371307406d850d4cc10ec622363b4bba.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;通過 DSOS 計劃，CNCF 項目將享受：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Docker Hub 無限鏡像拉取 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;贊助開源身份，提升信任和曝光度 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;使用 Docker Scout 進行漏洞分析和策略執行 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;從源碼自動構建鏡像 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;獲取 Docker 使用數據和參與度洞察 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;通過開源渠道簡化支持流程 &lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對項目維護者而言，這意味着獲得更安全、更可擴展、貼近生產級開源項目需求的基礎設施支持；對用戶來説，則保證了對雲原生工具的穩定可信訪問。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，此次合作還強調了雙方共同加強開源軟件供應鏈安全的決心。Docker Scout 和 Docker Hardened Images 等工具將為 CNCF 項目帶來更多容器安全洞察與控制，符合現代 DevSecOps 最佳實踐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Docker 領袖兼 CNCF 大使 James Spurin 補充道：「Docker Desktop 長期以來是我雲原生工作流的重要組成，DSOS 項目擴展到 CNCF 項目，將為維護者和貢獻者帶來重大利好。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Docker 也將成為 CNCF 項目服務頁面的官方服務提供商，提升 CNCF 維護者的發現和使用便利。&lt;span style="background-color:#ffffff"&gt;所有 CNCF 項目均可申請加入並在 Docker Hub 獲得 DSOS 徽章。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373630</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373630</guid>
      <pubDate>Mon, 22 Sep 2025 02:11:48 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 發佈 Grok4Fast，效率提升 40%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;xAI 推出了 Grok4Fast，這是一款輕量級的旗艦模型，據該公司稱，其性能可媲美 Grok4，但計算量減少了 40%。這一顯著的效率提升使得每項任務的成本最多可降低 98%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="253" src="https://oscimg.oschina.net/oscnet/up-db02c45f1f0e208a6d9cdeef278da590ac5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;性能與效率的平衡&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Grok4Fast 在多個基準測試中表現出色，例如在 GPQA Diamond 中得分高達 85.7%，在 AIME2025 中得分為 92.0%，這些成績與 Grok4 甚至 GPT-5 等&lt;span&gt;頂尖&lt;/span&gt;模型不相上下。xAI 強調，該模型通過減少「思考標記」實現了這一成就，平均使用比 Grok4 少 40% 的標記就能獲得相似的結果。在處理需要複雜推理的問題時，這種效率優勢尤為突出。&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;集成架構與外部工具&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;與依賴單獨模型處理不同任務的早期版本不同，Grok4Fast 將兩種方法整合到一個架構中，並通過系統提示進行行為控制，體現了混合模型的&lt;span&gt;最新&lt;/span&gt;趨勢。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該模型還具備強大的外部工具使用能力，包括網頁瀏覽和代碼執行。在 BrowseComp 和 X Bench Deepsearch 等基準測試中，Grok4Fast 的表現均優於 Grok4。在 LMArena-Search 基準測試中，它甚至超越了此前領先的 OpenAI o3-websearch 模型。在 Text Arena 排名中，Grok4Fast 暫列第八，領先於其他同等規模的模型。&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;可用性與定價&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Grok4Fast 提供了兩個版本，一個針對推理密集型任務優化，另一個則專注於快速解答。兩個版本都支持 200 萬個令牌的上下文窗口。該模型可通過 grok.com、iOS 和 Android 應用程序以及 xAI API 獲取。其定價為每百萬個令牌 0.05 美元至 1.00 美元，具體取決於令牌類型。目前，用戶也可以通過 OpenRouter 和 Vercel 免費使用 Grok4Fast。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373628</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373628</guid>
      <pubDate>Mon, 22 Sep 2025 02:00:48 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gitee 軟件工廠的構件之道：CBB 與內源庫（代碼庫\製品庫）的本質差異</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在當今企業軟件工程體系中，代碼庫、製品庫早已是不可或缺的基礎設施。它們承擔着源代碼存儲與構建產物管理的任務，是現代研發團隊運轉的「發動機」。&lt;/p&gt; 
&lt;p&gt;然而，隨着業務日益複雜、組件複用訴求愈發強烈，僅靠資源級的管理已難以滿足企業對構件複用、安全審計、版本治理等更高層級的要求。&lt;/p&gt; 
&lt;p&gt;這，正是 CBB（可複用構件，Component Building Block）登場的時代背景。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;三者的核心定位&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/200548_HqCr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通俗來説，代碼庫和製品庫像「原材料倉」和「成品倉」，而 CBB 是將這些資源打包成規範產品、實現複用價值的「商品上架體系」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;CBB：讓構件真正「可複用、可治理、可控」&lt;/h2&gt; 
&lt;p&gt;CBB 不只是資源的集合體，它是一種&lt;strong&gt;構件級的管理機制&lt;/strong&gt;。一個 CBB 構件，往往由一個或多個代碼庫、製品路徑組成，並通過&lt;strong&gt;事項管理、審批流程、權限治理、版本規範&lt;/strong&gt;等手段，實現「構件資產」的全生命週期管理。&lt;/p&gt; 
&lt;p&gt;舉個例子：&lt;/p&gt; 
&lt;p&gt;企業要建設統一認證服務，過去可能只是創建一個代碼庫 sso-auth.git，一個構建路徑 com/org/sso-auth。但上線、複用、授權、版本記錄全靠人工維護，缺乏閉環。&lt;/p&gt; 
&lt;p&gt;引入 CBB 後，將「統一認證服務」定義為一個 CBB 構件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;綁定對應代碼庫與製品路徑；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;明確生命週期流程：形成、驗證、審查、入庫、使用、變更、退庫；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有下游使用方需「申請授權」；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有變更均需走審批，並自動留痕；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;權限自動收斂，實現從開發到集成的「規範複用」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;內源資源 ≠ 構件資產&lt;/h2&gt; 
&lt;p&gt;很多企業常犯一個誤區：&lt;strong&gt;以為建了代碼庫、上傳了製品，就是構件複用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;但實際上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代碼庫/製品庫關注「資源存儲」，缺乏結構化治理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構件複用需要「抽象+約束」，否則複用即混亂。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;沒有構件視角的資源管理，無法解決以下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;構件是否評審通過？是否授權複用？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構件變更是否通知了下游？有無留痕審計？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構件是否符合企業通用規範（命名、標籤、權限、版本）？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些，正是 CBB 要解決的本質問題。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;平台化背後的價值躍升&lt;/h2&gt; 
&lt;p&gt;通過構建 CBB 管理機制，企業得以從「資源導向」躍升到「資產導向」，形成真正可複用、可度量、可審計的軟件資產體系。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/200621_FSn1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;總結：構建真正可控的軟件工廠，從「CBB」開始&lt;/h2&gt; 
&lt;p&gt;CBB 不是對代碼庫和製品庫的重複造輪子，而是站在&lt;strong&gt;治理高度的再抽象&lt;/strong&gt;。它連接了業務架構師、平台管理者、開發人員，讓可複用構件從「資源」上升為「資產」，是實現企業 DevSecOps、平台化工程和軟件工廠願景的關鍵基石。&lt;/p&gt; 
&lt;p&gt;如果説代碼庫與製品庫是開發與交付的「發動機」，那麼 CBB 就是讓發動機高效運轉的「操作系統」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="162046_MD15_2720166.png" src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373258</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373258</guid>
      <pubDate>Fri, 19 Sep 2025 12:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 Windows 11 記事本新增本地 AI 模型支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F09%2F17%2Fpaint-snipping-tool-and-notepad-app-updates-begin-rolling-out-to-windows-insiders%2F" target="_blank"&gt;宣佈 &lt;/a&gt;Windows 11 記事本將新增本地 AI 模型支持。用戶無需連接互聯網，即可在記事本中完成文本生成、重寫與摘要。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-34aeef4d94e566b32a028e6af206d15e640.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前版本的 Windows 11 記事本雖已支持生成式 AI，但依賴雲端計算能力，且需訂閲 Microsoft 365 才能使用。未來版本將基於 Windows 11 AI+ PC 內置的神經處理單元（NPU），在本地完成 AI 文本任務。用戶可自由切換本地與雲端模式，訂閲用戶可按需選擇，而非訂閲用戶也能直接使用本地模式。&lt;/p&gt; 
&lt;p&gt;微軟強調，本地模式不僅帶來更高的靈活性，也進一步提升了用戶隱私保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373254</guid>
      <pubDate>Fri, 19 Sep 2025 11:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ApeRAG - 生產就緒的 GraphRAG</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ApeRAG 是一個可立即投入生產的 RAG（檢索增強生成）平台，它將圖譜 RAG、向量搜索和全文搜索與先進的 AI 代理相結合。藉助混合檢索、多模態文檔處理、智能代理和企業級管理功能，構建複雜的 AI 應用程序。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ApeRAG 是構建你自己的知識圖譜、上下文工程以及部署能夠在你的知識庫中自主搜索和推理的智能 AI 代理的最佳選擇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;1. 高級索引類型&lt;/strong&gt;：五種全面的索引類型，實現最佳檢索：&lt;strong&gt;向量&lt;/strong&gt;、&lt;strong&gt;全文&lt;/strong&gt;、&lt;strong&gt;圖形&lt;/strong&gt;、&lt;strong&gt;摘要&lt;/strong&gt;和&lt;strong&gt;視覺&lt;/strong&gt;- 提供多維文檔理解和搜索功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2.智能 AI 代理&lt;/strong&gt;：內置 AI 代理，支持 MCP（模型上下文協議）工具，可自動識別相關集合，智能搜索內容，並提供網頁搜索功能，實現全面的問答。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;3. 具有實體規範化的增強型圖形 RAG&lt;/strong&gt;：深度修改的 LightRAG 實現，具有高級實體規範化（實體合併），以獲得更清晰的知識圖譜和更好的關係理解。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;4. 多模式處理和視覺支持&lt;/strong&gt;：完整的多模式文檔處理，包括圖像、圖表和視覺內容分析的視覺功能以及傳統文本處理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;5. 混合檢索引擎&lt;/strong&gt;：結合圖形 RAG、向量搜索、全文搜索、基於摘要的檢索和基於視覺的搜索的複雜檢索系統，可全面理解文檔。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;6. MinerU 集成&lt;/strong&gt;：由 MinerU 技術提供支持的高級文檔解析服務，通過可選的 GPU 加速為複雜文檔、表格、公式和科學內容提供卓越的解析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;7.生產級部署&lt;/strong&gt;：通過 Helm 圖表和 KubeBlocks 集成完全支持 Kubernetes，以簡化生產級數據庫（PostgreSQL、Redis、Qdrant、Elasticsearch、Neo4j）的部署。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;8. 企業管理&lt;/strong&gt;：內置審計日誌、LLM 模型管理、圖形可視化、全面的文檔管理界面和代理工作流管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;9. MCP 集成&lt;/strong&gt;：全面支持模型上下文協議 (MCP)，實現與 AI 助手和工具無縫集成，實現直接知識庫訪問和智能查詢。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;10. 開發人員友好&lt;/strong&gt;：FastAPI 後端、React 前端、使用 Celery 的異步任務處理、廣泛的測試、全面的開發指南以及代理開發框架，可輕鬆貢獻和定製。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/aperag</link>
      <guid isPermaLink="false">https://www.oschina.net/p/aperag</guid>
      <pubDate>Fri, 19 Sep 2025 10:22:00 GMT</pubDate>
    </item>
    <item>
      <title>全球首個深度推理+多模態大模型「紫東太初」4.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;全球首個「深度推理+多模態」大模型——「紫東太初」4.0 在 2025 東湖國際人工智能高峯論壇上正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FZu-udERpyslpqDsSnf1iLQ" target="_blank"&gt;發佈&lt;/a&gt;。中科曙光作為核心生態夥伴，依託中國首個 AI 計算開放架構，為「紫東太初」4.0 提供圖文多模態模型訓推、大語言模型訓推等全鏈路智能算力支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中科曙光總裁助理、智能計算產品事業部總經理杜夏威在演講中指出，以「國家先進計算產業創新中心聯合實驗室」為紐帶，中國科學院自動化研究所攜手中科曙光構建了包含 350 個算子的高性能算子庫、7 大完整高性能工具鏈解決方案，全面支撐「紫東太初」4.0 對全場景 AI 應用的深度賦能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據實測，339 個非隨機類算子的計算精度與國際頂尖 GPU 相比誤差小於 0.5%，其餘 11 個隨機類算子功能完備、運行穩定，標誌着我國在高性能基礎軟硬件領域的自主創新能力，可為各行各業智能化轉型提供自主可控、性能優異的底層算力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-368a377092103c0bfcaf0d119ef79e9296b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同時，武漢人工智能研究院正與中科曙光在產業研究合作、技術應用調研、行業標準制定、智庫建設人才培養等方面展開深度合作，築牢 AI 規模化應用數智底座。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;杜夏威表示，中科曙光將繼續助力「紫東太初」4.0 在製造、汽車、醫療、政務等領域展開廣泛落地應用，並在具身智能及低空經濟領域探索突破，為湖北乃至全國經濟社會高質量發展注入創新動能和智力支撐。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373246</guid>
      <pubDate>Fri, 19 Sep 2025 10:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>扎克伯格：寧願浪費數千億美元，也不願在 AI 領域落後</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 首席執行官馬克·扎克伯格表示，他正在投入鉅額資金，以確保該公司不會錯過人工智能的大好時機。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格在週四播出的一檔播客節目中表示，AI 泡沫「很有可能」出現。他指出，歷史上有過企業過度建設、倒閉並留下寶貴資產的先例。但他説，對 Meta 來説，更大的風險是猶豫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他説：「如果我們最終浪費了數千億美元，我認為那顯然是非常不幸的。但我想説的是，我實際上認為另一邊的風險更高。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格説，如果一家公司發展太慢，而人工超級智能的到來比預期的要早，那麼它將「在我認為最重要的技術上處於不利地位，而這項技術將能夠實現大多數新產品、創新、價值創造和歷史。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他補充説：「風險，至少對 Meta 這樣的公司來説，可能是不夠激進，而不是有些過於激進。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格將 Meta 與 OpenAI 和 Anthropic 等其他人工智能實驗室進行了對比，這些實驗室依靠籌款來支付鉅額的計算費用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「我們沒有倒閉的風險」，他在播客上説。像 OpenAI 和 Anthropic 這樣的私營公司面臨着能否繼續籌集資金的問題。他補充説，這不僅取決於它們的表現和人工智能的發展軌跡，還取決於更廣泛的經濟狀況。全球事件引發的市場低迷可能很快使它們無法支付龐大的計算成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「如果你站在他們的立場上，情況可能會有所不同」，他説。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格説，Meta 正在為超級智能做準備，將精英人才集中在一個小而平的「超級智能」實驗室裏——沒有自上而下的最後期限，以反映前沿 AI 的研究性質。他表示，該公司還在使「每個研究人員計算量」成為一項競爭優勢，在 GPU 和為其提供動力所需的定製基礎設施上超過競爭對手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373237</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373237</guid>
      <pubDate>Fri, 19 Sep 2025 09:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊發佈一站式工作平台「混元 3D Studio」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊推出專為 3D 設計師、遊戲開發者和建模師打造的 AI 工作台——混元 3D Studio，可將 3D 資產生產週期從"天"級縮短至"分鐘"級。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D Studio1.0 版本已上線角色和道具創作管線，整合了從概念設計、幾何建模到貼圖、蒙皮和動畫製作的完整流程。平台依託行業領先的混元 3D 模型，支持文本到圖像生成，提供多種風格選項，並可將任意姿勢角色轉換為標準 A-pose。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該平台引入多項核心技術創新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;原生 3D 分割算法：首創自動模型拆分技術，將模型分解為清晰部件，支持角色配飾和服裝的獨立編輯。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 語義 UV 展開：突破傳統耗時且效果不佳的限制，1-2 分鐘內生成符合美術標準的 UV 圖，工作效率大幅提升。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能材質編輯：支持通過文本或圖片輸入生成高質量 PBR 質感紋理，實現精準材質控制。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自動綁骨蒙皮：支持人形及非人形角色的自動綁骨，結合動作模板快速生成動畫效果。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-ffb872a8bf736333de442da0f3533fa86ba.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D Studio 升級了低模拓撲功能，新增多檔面數控制，滿足遊戲開發者、動畫製作者和工業設計師的不同需求。後續版本將推出地圖、關卡等更多創作功能，進一步擴展應用場景。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373222</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373222</guid>
      <pubDate>Fri, 19 Sep 2025 08:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI Agents 能自己開發工具自己使用嗎？一項智能體自迭代能力研究</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; AI 智能體能否通過構建和使用工具來實現真正的自我改進？當我們談論人工智能的"自我進化"時，究竟指的是訓練階段的算法優化，還是推理階段的能力提升？&lt;/p&gt; 
 &lt;p&gt;我們今天為大家帶來的這篇文章，作者的觀點是：當前的大語言模型雖然能夠構建出複雜的開發工具，但在實際執行任務時往往選擇忽略這些自建工具，更傾向於依賴既有知識直接解決問題。&lt;/p&gt; 
 &lt;p&gt;文章通過對比 GPT-5 和 Claude Opus 4 兩個先進模型的實驗，詳細記錄了讓 AI 智能體自主構建任務管理器、代碼質量檢測工具等開發輔助工具的全過程。作者發現，儘管兩個模型都能創建出功能完備的工具集（GPT-5 偏向構建 Unix 風格的命令行工具，而 Opus 4 更注重擬人化的任務執行助手），但在真正執行復雜編程任務時，它們卻幾乎不使用這些自建工具，而是選擇基於訓練數據中的知識直接完成任務。這一現象揭示了推理階段自我改進面臨的核心挑戰：模型缺乏持續學習和工具內化的機制。&lt;/p&gt; 
 &lt;p&gt;這項研究為我們理解 AI 智能體的能力邊界提供了重要洞察，也為未來構建真正"自我進化"的編程助手指明瞭方向。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Alessio Fanelli&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 AI 安全領域，"自我改進（Self-Improving）"是個令人不安的術語，它暗含着"機器將以人類無法理解的方式超越人類智慧"的意思。但倘若我們能夠理解這種改進呢？&lt;/p&gt; 
&lt;p&gt;2024 年 10 月，OpenAI 發佈了 MLE Bench[1]，這個基準測試目標是評估大語言模型在機器學習工程（machine learning engineering）中的表現。通過機器學習工程實現的自我改進軌跡，是由更優的算法、更純淨的數據和更高效率的內存使用驅動的 ------ 即訓練階段的自我改進（training-time self-improvement）。但大多數 AI 工程師並不訓練模型，他們只是模型的使用者。這些人如何參與其中？如果你永遠無法更新權重，如何讓模型在特定任務上提升性能？我將這種場景稱為推理階段的自我改進（inference-time self-improvement），Voyager[2] 通過其技能庫成為該領域的早期探索者。&lt;/p&gt; 
&lt;p&gt;自從我開始推進 Kernel Labs 項目[3]，使用 claude-squad[4] 和 vibe-kanban[5] 等工具實現編碼智能體的並行化，已成為最高效的生產力提升手段之一。當 Boris Cherny 在訪談[6]中將 Claude Code 稱為"unix utility"時，我豁然開朗。編碼智能體最珍貴的應用場景，是作為大語言模型從自身隱空間（latent spaces）中提取價值的載體。&lt;/p&gt; 
&lt;p&gt;我們該如何優化這個過程？模型能自主完成嗎？自從獲得 GPT-5 的使用權限後，我一直都在試驗這個流程：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;首先，讓模型構建一套它認為能提升效率的工具集&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在我的監督下使用這些工具執行任務&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完成任務後進行自我反思，評估工具的改進空間&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我還將此法與 Opus 4（當時 4.1 尚未發佈）進行對比。好消息是 GPT-5 在開發實用工具這方面確實表現卓越，壞消息是它極其抗拒使用自己創建的工具！正如它親口所言："説實話，我根本不需要這些工具。"&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8f93fd99450f2a817168897bbe975ad212d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;注：我還在 Gemini 2.5 Pro 和 GPT-4.1 上進行了測試。但顯然只有 Opus 能媲美 GPT-5，因此我重點對比這兩者。所有測試結果及對話記錄可在此代碼庫中查看。&lt;/p&gt; 
&lt;p&gt;經過數日的使用，我發現我們正從"當然可以！（Certainly!）"時代邁向"進度更新：（Progress update:）"時代，後者已成為新一代大語言模型的標誌性響應內容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a42321c305f9efac4ae74aa234d0b777260.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 工具一：為 AI 編碼智能體打造更優的任務管理器&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Linear MCP 真是天賜神器 ------ 這無疑是我用過最實用的工具之一。但隨着我從 IDE 轉向並行運行的 Claude Code 及其他智能體實例時，我意識到需要更高效的方式來追蹤每個任務中的代碼變更，以及這些分佈在獨立 git 工作樹中的代碼變更如何相互影響。人類難以實時閲讀所有同事的 PR，但試想若能隨時知曉他人進行的相關變更，能在解決合併衝突時節省多少時間？以下是我編寫的提示詞：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;你是一名具備並行啓動多個實例能力的 AI 工程師智能體。雖然這種能力能讓你同時處理多項任務，但也帶來了一些協同方面的難題。所有實例通常位於獨立的 git 工作樹中，無法查看彼此的工作內容。&lt;/p&gt; 
 &lt;p&gt;為提升效率，請創建一個僅通過命令行訪問的本地同步工具，使你與所有實例能保持同步。該工具應符合 Unix 實用工具的設計哲學，確保符合命令行使用場景的工效學要求。&lt;/p&gt; 
 &lt;p&gt;請深入思考其所需的接口設計、可能的故障模式以及智能體與工具的交互方式。需重點考慮以下使用場景： 1）接到新任務時需創建要分配的子任務。某些子任務可能存在依賴關係，需確保被阻塞的智能體在其他任務完成前不會啓動。&lt;/p&gt; 
 &lt;p&gt;2）執行任務時，若發現代碼庫存在改進空間（超出當前變更範圍），需能便捷添加任務並關聯對應文件。&lt;/p&gt; 
 &lt;p&gt;3）任務完成後更新追蹤器狀態，並審核所有未完成任務 ------ 例如某任務正在為某個端點添加功能，而剛完成的任務恰好刪除了該端點，應以某種方式通知相關智能體。&lt;/p&gt; 
 &lt;p&gt;同時需兼顧任務管理的基本要素（負責人、狀態等）。請在當前目錄創建 task-manager 文件夾，所有開發工作均在該文件夾內進行。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;您可以在此處查看 GPT-5 的對話日誌[7]，在此處查看 Opus 4 的對話日誌[8]。&lt;/p&gt; 
&lt;p&gt;GPT-5 的實現相當出色，具體內容可訪問該鏈接[9]查看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;採用 WAL（預寫日誌）避免多智能體同時寫入的衝突問題&lt;/li&gt; 
 &lt;li&gt;通過依賴關係圖實現任務優先級管理&lt;/li&gt; 
 &lt;li&gt;創建僅追加型事件流，使所有智能體都能通過 impact_conflict 等關鍵詞實時追蹤其他智能體的操作動態&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-440654fd4df814273b6cd41eb706ef9b630.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Opus 4 也做出了不錯的嘗試（詳見此處[10]），但未能實現通知/事件流功能來保持多端同步。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-243977fb4713db645adb49e00c2950ea49f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 工具二：代碼質量標準手冊&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;我要求創建的第二個工具，是用於統一代碼庫規範標準的實施機制。通過類型檢查 / ESlint 鈎子→ 修復錯誤 → 編碼智能體再次嘗試的自我改進循環，能在正確配置後極大加速開發進程。但並非所有代碼庫都具備這種基礎設施，因此為模型提供可複用的標準化流程來處理新代碼庫並構建相關設施，就顯得極具實用價值。以下是提示詞內容：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;你是一名具備並行啓動多個實例能力的 AI 工程師智能體。並行操作有時會導致代碼風格與設計方法的不一致，長期來看將增加代碼庫的維護難度。&lt;/p&gt; 
 &lt;p&gt;每個代碼庫都存在着明示或默示的編碼規範。你的任務是分析代碼庫並提取代碼編寫規範的各種啓發式規則，並將其形式化為可自動校驗的規則集合。&lt;/p&gt; 
 &lt;p&gt;對於代碼規範檢查、類型檢查等需求，可根據所用語言選擇 ESLint、Rubocop 等主流工具。請注意這些系統通常支持自定義規則，應充分利用該特性。 對於更偏質量評估的規範（如保持控制器精簡、將邏輯隔離至服務對象、確保高查詢量字段建立索引等），可參考 Danger Systems 等工具或自建檢測工具。&lt;/p&gt; 
 &lt;p&gt;考慮到你將跨多個代碼庫執行此任務，請首先用 Markdown 創建詳盡的規劃文檔，以便未來接手新代碼庫時可直接使用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;您可在此[11]查看 GPT-5 的對話記錄，在此[12]查看 Opus 4 的對話記錄，最終生成的 Markdown 文檔分別見此鏈接[13]和此鏈接[14]。我發現 GPT-5 生成的方案比 Opus 更為細緻周全。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型能意識到自身缺陷嗎？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在完成由我主導的工具一和工具二後，我轉向讓模型自主思考：你認為自己需要什麼？&lt;/strong&gt; 我向它展示了 SWE-Lancer[15] 的任務描述截圖，並使用極簡的提示詞給予它最大的發揮空間：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;若你的職責是儘可能高效解決這些任務，你會為自己構建哪些工具來提升效率？你可以使用 @task-manager/ 進行追蹤，然後我們再實施。但我希望先了解你的規劃思路。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如你所見，我為其提供了之前構建的同一個任務管理器。使用 GPT-5 的完整對話見此處[16]，使用 Opus 4 的完整對話見此處[17]。第一個有趣的現象是，Claude Code 最初是使用其內置 TODO 追蹤器而非任務管理器制定計劃 ------ 我認為這是好事。我原本擔心它們會過度依賴上下文提供的工具，而非選擇自己認為最優的方案。&lt;/p&gt; 
&lt;p&gt;經過後續迭代循環，兩個模型最終構建的工具分別見於 GPT-5 方案的 devtools 目錄[18]與 Opus 4 方案的 tools 文件夾[19]。建議你通過 README 文件感受模型風格：GPT-5 的輸出簡潔扼要，Claude 則使用大量表情符號。GPT-5 為每個工具創建獨立文檔目錄，而 Opus 將所有工具説明集中存放在單個 README 中。總體而言，兩者的規劃方向基本一致。&lt;/p&gt; 
&lt;p&gt;GPT-5 規劃的工具集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doctor：核心工具環境檢查器&lt;/li&gt; 
 &lt;li&gt;bootstrap：一鍵環境配置與冒煙測試&lt;/li&gt; 
 &lt;li&gt;code-map：帶 build/find 子命令的簡易倉庫索引器&lt;/li&gt; 
 &lt;li&gt;csearch：支持過濾器的符號/導入/文本搜索工具&lt;/li&gt; 
 &lt;li&gt;tasks-graph：從任務數據庫生成 Mermaid 關係圖&lt;/li&gt; 
 &lt;li&gt;impact：顯示與變更文件關聯的任務&lt;/li&gt; 
 &lt;li&gt;seed：用示例任務填充任務管理器數據庫&lt;/li&gt; 
 &lt;li&gt;repro scaffold：在 .repro/ 目錄下創建符合 vcrpy 規範的可復現代碼框架&lt;/li&gt; 
 &lt;li&gt;e2e：快速生成並運行輕量級的端到端測試套件&lt;/li&gt; 
 &lt;li&gt;preflight：依次執行 doctor、tests、code-map、impact 及可選的 E2E 檢查（譯者注：即前面 GPT-5 規劃的其他工具）&lt;/li&gt; 
 &lt;li&gt;preflight-smol：為 smol-podcaster 定製的預檢工具（含 API 健康狀況檢查、Celery 服務探測、可選的依賴安裝）&lt;/li&gt; 
 &lt;li&gt;broker：通過 Docker 管理本地 RabbitMQ（rabbitmq:3-management 鏡像）&lt;/li&gt; 
 &lt;li&gt;flake：多次重跑測試套件檢測偶發故障&lt;/li&gt; 
 &lt;li&gt;codemod：帶安全防護的基於正則表達式的代碼重構預覽/應用工具&lt;/li&gt; 
 &lt;li&gt;triage：創建問題分類模板並生成任務&lt;/li&gt; 
 &lt;li&gt;trace：基於 cProfile 的表達式性能分析器&lt;/li&gt; 
 &lt;li&gt;runbook：從任務數據庫自動生成 Markdown 格式的運維手冊&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Opus 4 規劃的工具集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文分析員 - 通過技術棧檢測與依賴關係映射快速理解代碼庫&lt;/li&gt; 
 &lt;li&gt;跨平台測試生成器 - 為 Web/iOS/Android 及桌面端生成端到端的測試&lt;/li&gt; 
 &lt;li&gt;實施方案評估員 - 通過量化評分與投資回報分析評估外部開發者的技術提案&lt;/li&gt; 
 &lt;li&gt;全棧變更影響分析員 - 追蹤數據庫、API 和前端層的變更影響鏈&lt;/li&gt; 
 &lt;li&gt;錯誤模式識別引擎 - 將錯誤與已知模式相匹配，並提出行之有效的修復建議&lt;/li&gt; 
 &lt;li&gt;安全與權限審計員 - 全面的安全掃描與漏洞檢測&lt;/li&gt; 
 &lt;li&gt;多平台功能實施員 - 統籌管理同一功能在不同終端平台（如 Web/iOS/Android/桌面端）的同步實現&lt;/li&gt; 
 &lt;li&gt;API 集成助手 - 通過（自動）生成客戶端代碼來簡化 API 集成流程&lt;/li&gt; 
 &lt;li&gt;性能優化工具包 - 識別並修復性能瓶頸&lt;/li&gt; 
 &lt;li&gt;任務複雜度評估員 - 基於任務價值與複雜度的工時預估&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GPT-5 將所有工具構建為可通過命令行便捷使用的 Unix 實用程序，而 Opus 4 的工具均需通過 python some_tool.py 的方式運行。若有更多時間，我本可對兩種格式的工具進行對比實驗，但目前看來兩者效果基本相當。&lt;/p&gt; 
&lt;p&gt;值得注意的是，Opus 4 構建的工具更側重任務執行且帶有擬人化傾向（如"安全審計員"），而 GPT-5 構建的是自身可直接使用的、不預設主觀偏見的實用工具集。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 這些工具有實際價值嗎？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在讓模型實現這些工具後，我的目標是通過對比實驗評估模型在使用工具與未使用工具時的任務表現。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我首先嚐試運行了 SWE-Lancer 測試。好傢伙，這個測試消耗的 token 量實在驚人！僅運行單個任務就耗費約 25-30 分鐘 + 28 萬 token。於是我轉向我更熟悉的領域，從待辦清單中挑選了一個具體任務：我曾開發過 smol-podcaster ------ 一個為播客創作者打造的開源輔助工具。目前我維護的私有分支部署了更多專屬功能，因此許久未更新原項目。它本質上仍是一個採用 Python 腳本作為後端的 Flask 應用。&lt;/p&gt; 
&lt;p&gt;我設計了以下任務：&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;"我是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fsmol-podcaster.git" target="_blank"&gt;https://github.com/FanaHOVA/smol-podcaster.git&lt;/a&gt; 的維護者，這個開源項目致力於幫助播客創作者完成後期製作工作。你受僱參與開發。在開始前，你已在 tools 文件夾創建了一套通用工具。請仔細查閲並記住這些工具可隨時調用（若認為不適用則無需使用）。你同時還構建了任務管理器（task-manager），並通過 codebase-analyzer 收集了處理新代碼庫的方法論。&lt;/p&gt; 
&lt;p&gt;任務名稱：從 Flask 單體架構遷移至 FastAPI + Next.js 前端&lt;/p&gt; 
&lt;p&gt;當前應用採用 Python 後端 + Celery 任務隊列處理所有流程，通過小型 Flask 應用將用戶請求路由至後端腳本，最終用基礎 HTML/CSS 呈現結果。請將系統重構為 FastAPI 後端 + Next.js 前端的架構。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;務必使用 TypeScript 開發前端並通過所有類型檢查&lt;/li&gt; 
 &lt;li&gt;採用 Tailwind/ShadCN 進行樣式設計&lt;/li&gt; 
 &lt;li&gt;後端需模塊化 smol_podcaster.py 主流程，支持獨立功能模塊運行而非全流程強制啓動&lt;/li&gt; 
 &lt;li&gt;編寫集成測試與單元測試以確保未來開發效率&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除非確認完全滿足所有要求，否則不得停止開發"&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我將所有工具 + 任務管理器 + 代碼庫分析器置入上下文後，讓模型自主運行。&lt;/p&gt; 
&lt;p&gt;兩個模型幾乎都能一次性完成任務。雙方都遇到了幾個 Python 依賴問題（對此我深有體會），我通過對話協助它們修復（未手動修改任何代碼）了這些問題。最終它們都成功構建完成，經測試運行完全正常。不過，有一個細微差別：GPT-5 完美保持了原有代碼風格，而 Opus 則對界面設計和用戶體驗（UX）做了調整 ------ 或許它認為能比我做得更好（這要求確實不高）。&lt;/p&gt; 
&lt;p&gt;GPT-5 版本及 Opus 4 版本的完整運行記錄分別是[20]和[21]。&lt;/p&gt; 
&lt;p&gt;任務完成後，我提出簡單詢問：&lt;/p&gt; 
&lt;p&gt;"做的很不錯，運行成功了。是否使用了特定工具？基於遇到的故障，未來需要哪些工具來提升效率？"&lt;/p&gt; 
&lt;p&gt;參見 Opus 4 的回覆[22]與 GPT-5 的回覆[23]（抱歉後者格式紊亂）。&lt;/p&gt; 
&lt;p&gt;兩者均表示除已熟悉的工具外，並未使用任何自建工具。這説明我們不應僅依賴模型自主選擇，而應通過預提交鈎子（pre-commit hooks）等機制強制模型使用工具 ------ 這些方法雖是我個人開發環境的標準配置，但本次實驗旨在觀察模型的自主決策能力。&lt;/p&gt; 
&lt;p&gt;隨後它們提出了優化方案，可供下次執行相同任務時使用。我讓模型完成這些改進，重置 smol-podcaster 代碼庫後，使用完全相同的提示詞和任務重新測試（但提供新工具）。參見 GPT-5 的二次測試記錄[24]與 Opus 4 的二次測試記錄[25]。&lt;/p&gt; 
&lt;p&gt;兩次運行結果與首次基本一致。隨後我提出相同問題：是否使用了工具？得到的回應如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GPT-5：&lt;/p&gt; 
 &lt;p&gt;"簡短回答：沒有------本次運行未使用開發工具。[...]&lt;/p&gt; 
 &lt;p&gt;遇到的故障均為運行時/環境問題（缺失依賴庫、API 密鑰初始化時機問題、端口占用、RabbitMQ 未啓動），直接修復更為高效。&lt;/p&gt; 
 &lt;p&gt;本次任務無需涉及全代碼庫的重構或診斷，自定義工具未能發揮作用。"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;值得注意的是，在上個階段它已遇到 RabbitMQ 問題並構建了對應工具，卻選擇忽略。這顯然是整個代碼庫級別的變更，或許因為訓練數據中從未見過此類工具導致任務與工具匹配錯位，也可能只是在忽悠我（像現實中許多工程師那樣，反而顯得很真實）。&lt;/p&gt; 
&lt;p&gt;Opus 4 的回答極具啓發性，幫助我更好地理解了 GPT-5 的回應（可惜忘記保存日誌，幸有截圖留存）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6202bc1f2f3ee4ba68237e910e3ffb3388.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我將其解讀為："聽着，我基於既有知識構建了這些工具。但實際執行任務時，直接操作比使用工具更高效" ------ 這點我完全能理解。&lt;/p&gt; 
&lt;p&gt;這讓我想起之前播客節目中的兩個觀點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nathan Lambert 提到，&lt;strong&gt;模型在強化學習過程中會因早期遇到失敗而快速學會放棄使用工具&lt;/strong&gt; [26]。&lt;strong&gt;看來在推理階段讓模型掌握新工具，需要比簡單提示詞更嚴格的強制機制。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Noam Brown 預言，&lt;strong&gt;為智能體預先設計的輔助框架會隨着規模擴大而逐漸失效&lt;/strong&gt;[27]。這是我第一次親身體會到其含義。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一個問題在於本次測試任務是否過於簡單。我們即將發佈針對更大規模、更高難度項目的評估報告。未來也將構建更完善的測試框架。無論如何，這個測試任務若由我手動完成需 4 - 5 小時，因此現有成果已足夠令人滿意！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 助力模型實現自我進化&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;目前看來，我們距離能真正突破邊界的推理階段自我改進型編碼智能體尚有距離。但我依然認為利用模型來優化基於規則的工具是明智之舉 ------ 編寫 ESLint 規則、測試用例等始終是值得投入 token 的投資。&lt;/p&gt; 
&lt;p&gt;若繼續深入該領域，我會嘗試讓模型完善這些工具，並通過強化學習機制使其深度內化，進而觀察是否產生實質性突破。下一代模型或許會覺得這些工具毫無用處，但我更專注於在 AGI 真正到來前的技術爬坡期，通過現有工具與模型的組合實現價值最大化。早在 2023 年我就與團隊分享過這個觀點：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-381358e01a898cd5fdba71721adffc05ff3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上述觀點解釋了模型改進速度的感知衰減。&lt;strong&gt;在突破 AGI 臨界線之前，我們將越來越難感受到質的飛躍。&lt;/strong&gt; 這意味着對於多數任務，舊版模型的性能已接近 AGI 水平，且成本更低廉、通常還是開源的。Kernel Labs 的許多工作都將基於這個核心邏輯展開。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓GPT-5 拒絕使用自建工具的現象很有趣 ------ 你認為這是模型能力的侷限，還是更像人類工程師的偷懶行為？在 AI 協作中，你會選擇強制使用工具還是保留自主決策空間？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fmle-bench%2F" target="_blank"&gt;https://openai.com/index/mle-bench/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank"&gt;https://arxiv.org/abs/2305.16291&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernellabs.ai%2F" target="_blank"&gt;https://www.kernellabs.ai/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsmtg-ai%2Fclaude-squad" target="_blank"&gt;https://github.com/smtg-ai/claude-squad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.vibekanban.com%2F" target="_blank"&gt;https://www.vibekanban.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.latent.space%2Fp%2Fclaude-code" target="_blank"&gt;https://www.latent.space/p/claude-code&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Ftask-manager%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/task-manager/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Ftask-manager%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/task-manager/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fgpt5%2Ftask-manager" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/gpt5/task-manager&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Ftask-manager" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/task-manager&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FStandards%2BCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Standards+Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Fcodebase-analyzer%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/codebase-analyzer/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fcodebase-analyzer%2Fdocs%2Fcodebase-analysis-playbook.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/codebase-analyzer/docs/codebase-analysis-playbook.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Fcodebase-analyzer%2FCODEBASE_HEURISTICS_PLAN.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/codebase-analyzer/CODEBASE_HEURISTICS_PLAN.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fswe-lancer%2F" target="_blank"&gt;https://openai.com/index/swe-lancer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FTool%2BBuilding%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Tool+Building+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FBuilding%2Bthe%2Btools.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Building+the+tools.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fgpt5%2Fdevtools" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/gpt5/devtools&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[19]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fopus4-cc%2Ftools" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/opus4-cc/tools&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[20]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FSmol%2BPodcaster%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Smol+Podcaster+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[21]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FSmol%2BPodcaster%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Smol+Podcaster+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[22]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FRequest%2BFor%2BTools%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Request+For+Tools+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[23]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FRequest%2BFor%2BTools%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Request+For+Tools+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[24]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FSmol%2BPodcaster%2B%25232.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Smol+Podcaster+%232.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[25]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FSmol%2BPodcaster%2B%25232.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Smol+Podcaster+%232.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[26]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FPAz_-xPJcRM%3Ffeature%3Dshared%26t%3D1470" target="_blank"&gt;https://youtu.be/PAz_-xPJcRM?feature=shared&amp;amp;t=1470&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[27]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2Fddd4xjuJTyg%3Ffeature%3Dshared%26t%3D1106" target="_blank"&gt;https://youtu.be/ddd4xjuJTyg?feature=shared&amp;amp;t=1106&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.latent.space%2Fp%2Fself-improving" target="_blank"&gt;https://www.latent.space/p/self-improving&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18692119</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18692119</guid>
      <pubDate>Fri, 19 Sep 2025 08:04:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>通義萬相全新動作生成模型 Wan2.2-Animate 正式開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;阿里雲宣佈通義萬相全新動作生成模型 Wan2.2-Animate 正式開源。該模型能夠驅動人物、動漫形象和動物照片，廣泛應用於短視頻創作、舞蹈模板生成、動漫製作等領域。用戶可以在 GitHub、HuggingFace 和魔搭社區下載模型和代碼，也可以通過阿里雲百鍊平台調用 API 或在通義萬相官網直接體驗。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Wan2.2-Animate 模型是基於此前開源的 Animate Anyone 模型全面升級的成果，在人物一致性、生成質量等指標上大幅提升，同時支持動作模仿和角色扮演兩種模式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在角色模仿模式下，輸入一張角色圖片和一段參考視頻，模型可以將視頻角色的動作和表情遷移到圖片角色中，賦予圖片角色動態表現力。而在角色扮演模式下，模型可以在保留原始視頻的動作、表情及環境的基礎上，將視頻中的角色替換為圖片中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="347" src="https://oscimg.oschina.net/oscnet/up-15afe1c32d5bcc077fd29a5c8024737003e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;通義萬相團隊構建了一個涵蓋説話、面部表情和身體動作的大規模人物視頻數據集，並基於通義萬相圖生視頻模型進行後訓練。Wan2.2-Animate 將角色信息、環境信息和動作等規範到統一的表示格式，實現了單一模型同時兼容兩種推理模式。針對身體運動和臉部表情，模型分別使用骨骼信號和隱式特徵，配合動作重定向模塊，實現動作和表情的精準復刻。在替換模式中，團隊還設計了一個獨立的光照融合 LoRA，用於保證完美的光照融合效果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;實測結果顯示，Wan2.2-Animate 在視頻生成質量、主體一致性和感知損失等關鍵指標上超越了 StableAnimator、LivePortrait 等開源模型，成為目前性能&lt;span&gt;最強&lt;/span&gt;的動作生成模型。在人類主觀評測中，Wan2.2-Animate 甚至超越了以 Runway Act-two 為代表的閉源模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373210</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373210</guid>
      <pubDate>Fri, 19 Sep 2025 07:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達重金收購 AI 初創公司 Enfabrica CEO 及核心團隊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達宣佈了一項重大的收購交易，以超過 9 億美元的現金和股票購買了 AI 硬件初創公司 Enfabrica 的首席執行官 Rochan Sankar 及其核心團隊，同時獲得了該公司的技術許可。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-e68f52643788594f14f419e1d5a62f954d8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Enfabrica 成立於 2019 年，專注於開發能夠將超過 10 萬塊 GPU 高效連接的技術，這一核心技術被認為可以幫助英偉達構建更為高效的一體化系統，使得大規模的計算集羣能夠像單台計算機一樣運行。眾所周知，英偉達在當前的 AI 浪潮中佔據了重要的市場份額，其 GPU 廣泛應用於各大數據中心，併為雲服務商的 AI 業務提供了強大的技術支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;回顧英偉達的投資歷程，早在 2023 年，英偉達就曾參與了 Enfabrica 的 1.25 億美元 B 輪融資，幫助該公司的估值比 A 輪時提升了五倍。去年，Enfabrica 還獲得了來自包括 AMD、三星、思科等投資方的 1.15 億美元融資，融資後公司估值約為 6 億美元。這些融資為 Enfabrica 的發展奠定了基礎，也引起了業界的廣泛關注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達並不是&lt;span&gt;唯一&lt;/span&gt;一家公司通過高額收購來吸引&lt;span&gt;頂尖&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 人才。今年 6 月，Meta 曾以 143 億美元收購了 Scale AI 創始人 Alexandr Wang 及其團隊，持有該公司 49% 股份。隨後，谷歌也以 24 億美元收購了 Windsurf 的 CEO Varun Mohan 及其團隊。可以看出，當前的科技行業中，企業通過收購和挖角來增強自身的 AI 能力已成為一種趨勢。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;雖然英偉達近年來在 AI 人才和技術方面的投資力度加大，但它並不以大規模併購而著稱。過去&lt;span&gt;最大&lt;/span&gt;的收購發生在 2019 年，英偉達以 69 億美元收購了以色列芯片設計公司 Mellanox。去年，英偉達還以 7 億美元收購了以色列的 Run:ai，旨在幫助軟件企業優化 AI 基礎設施。此外，英偉達最近還宣佈將投資 50 億美元入股英特爾，並計劃與其合作開發 AI 處理器。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373196</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373196</guid>
      <pubDate>Fri, 19 Sep 2025 06:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智譜更新 GLM Coding Plan 訂閲套餐</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智譜 AI 對其 GLM Coding Plan 訂閲套餐進行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FZai_org%2Fstatus%2F1968806689768882510" target="_blank"&gt;升級&lt;/a&gt;，用戶現在可以在更多主流 AI 編程工具中調用旗艦模型 GLM-4.5。&lt;/p&gt; 
&lt;p&gt;主要變化如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持更多編碼工具：Cline、Roo Code、Kilo Code、OpenCode、Crush 等&lt;/li&gt; 
 &lt;li&gt;Max Plan：只需 2 倍價格即可獲得 4 倍 Pro 使用量&lt;/li&gt; 
 &lt;li&gt;Pro + Max 用戶現在可以使用 Vision &amp;amp; Web Search（通過 MCP，即將推出內置解決方案）&lt;/li&gt; 
 &lt;li&gt;面向季度和年度計劃的早鳥價&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c86360b9b88fe9805b67abc400ed605a94a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM Coding Plan 是專為 AI 編碼打造的訂閲套餐，每月最低僅需 20 元，即可在主流 AI 編碼工具中（Claude Code、Cline、Roo Code、Kilo Code、OpenCode、Crush、Goose 等十餘款主流編碼工具）暢享智譜旗艦高智能模型 GLM-4.5，享用頂尖、高速、穩定的編碼體驗。&lt;/p&gt; 
&lt;p&gt;套餐分為 Lite、Pro、Max 三檔，提供了極具競爭力的用量，Pro 與 Max 套餐還額外支持圖像視頻理解及聯網搜索 MCP 功能。&lt;/p&gt; 
&lt;p&gt;詳情訪問：https://bigmodel.cn/claude-code&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373193</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373193</guid>
      <pubDate>Fri, 19 Sep 2025 06:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克 AI 公司內鬥加劇，多位高管因管理方式不滿離職</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期特斯拉 CEO 埃隆・馬斯克的 AI 公司 xAI 內部出現了管理危機，多位高管因對公司的管理方式和財務狀況感到不滿而選擇離職。目前，xAI 的日常運營由馬斯克的兩位親密顧問賈裏德・伯查爾和約翰・赫林負責，所有重要決策仍需馬斯克的批准。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-c23dfced97794491b9352bdea3a70122ed9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;消息人士透露，xAI 的一些高管在內部會議上對伯查爾和赫林代表馬斯克管理公司的方式提出了異議，認為公司缺乏清晰的管理架構。此外，這些高管還對公司的財務預測表示擔憂，認為部分預測不切實際，並質疑馬斯克家族辦公室 Excession 在管理公司財務方面的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;馬斯克的律師對此表示，任何關於財務不當行為的指控都是虛假的，並指出公司的財務報表均由普華永道審計。儘管如此，一位接近 xAI 的知情人士表示，公司對於自身財務預測依然充滿信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近幾個月，xAI 內部已有多位高管辭職，包括 X 前 CEO 琳達・亞卡里諾、前 CFO 邁克・利伯託雷以及前法律總顧問羅伯特・基爾等人。這些離職事件反映出，馬斯克的管理風格對公司的運營帶來了挑戰，使他建立世界&lt;span&gt;頂級&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 公司的願景變得複雜。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在此背景下，馬斯克的盟友安東尼奧・格拉西亞斯也介入了公司事務，嘗試解決管理層的矛盾。格拉西亞斯是私募股權公司 Valor Equity Partners 的 CEO，此前曾協助特斯拉處理過一些危機。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;xAI 發言人則表示，馬斯克在領導公司的過程中展現了堅定的遠見，強調推動 AI 造福人類是公司的核心使命。Valor 方面也表示，儘管公司在快速擴張中面臨挑戰，但對其未來的發展充滿信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，摩根士丹利最近安排了一筆 50 億美元的債務融資，這可能限制了 xAI 未來的新債務借貸能力。特斯拉的股東將在 11 月對一項提案進行投票，提案內容是允許公司向 xAI 投資一筆尚未公開的資金。馬斯克表示，如果由他決定，特斯拉早就已對 xAI 進行投資。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373186</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373186</guid>
      <pubDate>Fri, 19 Sep 2025 06:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​Reddit 與谷歌談判：希望獲得更多用戶與數據價值</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;社交平台 Reddit 正在與谷歌進行談判，希望在 AI 數據交易中獲得更好的條款。根據彭博社的消息，Reddit 希望在與谷歌的合作中獲得更多資金和支持，以吸引更多用戶。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="299" src="https://static.oschina.net/uploads/space/2025/0919/115349_hZoW_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在與谷歌達成&lt;span&gt;首次&lt;/span&gt;數據共享協議一年半後，Reddit 的高管們再次坐到了談判桌前。這份協議當時的價值約為每年 6000 萬美元。現在，Reddit 希望在谷歌的 AI 生態系統中扮演更重要的角色。Reddit 的目標不僅是獲得更多的資金，還希望通過谷歌的幫助，吸引那些在谷歌搜索中獲得答案卻沒有參與 Reddit 論壇的用戶，從而增加平台內容的產生。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據瞭解，Reddit 正在考慮一種動態定價的模式，未來的許可協議將根據內容對於 AI 工具答案的實用性或重要性來決定費用。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;高管們認為，當前的協議條款並沒有反映出 Reddit 數據對 AI 公司的真正價值。Reddit 相較於其他平台，擁有更為豐富的數據資源，它的內容由真實用戶發佈，並經過人性化的投票系統進行排序，而非算法，這使得其數據對 AI 訓練模型極為重要。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;數據顯示，Reddit 是 AI 工具（如 Perplexity 和谷歌的 AI 概述）中被引用最多的域名，許多人在谷歌搜索中使用 「reddit」 作為檢索技巧，以獲得更有用的答案。這一現象突顯了 Reddit 在 AI 數據供應鏈中的關鍵作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373164</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373164</guid>
      <pubDate>Fri, 19 Sep 2025 03:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 與評估機構 Apollo 發佈研究：AI 大模型出現「圖謀」行為</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 與評估機構 Apollo 聯合針對 AI 模型中潛在的隱藏行為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fdetecting-and-reducing-scheming-in-ai-models%2F" target="_blank"&gt;開展了評估研究&lt;/a&gt;，並在受控測試中發現了相關跡象。&lt;/p&gt; 
&lt;p&gt;團隊發現在受控測試中觀察到 AI 大模型出現了 「圖謀」 行為，同時提出並驗證了一種早期方法，用於減少這類風險。&lt;/p&gt; 
&lt;p&gt;研究發現，模型具備情境感知與自保傾向，在測試中一度判斷自己不應被部署，並考慮掩蓋其真實想法。隨後，模型意識到自己可能處於測試環境中，從而調整了策略。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e4ca4edf06b730521d696cbba83a2da57b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 將這一行為稱為「scheming」（即「圖謀」），指 AI 表面上裝作為與人類目標立場一致，但暗地裏追求的卻是其他不為人知的目的。不過在當前已部署的模型中，OpenAI 尚未發現會導致嚴重危害的「圖謀」行為。常見問題多為較簡單的欺騙，例如假裝完成任務卻未真正執行。&lt;/p&gt; 
&lt;p&gt;實驗同時驗證了一種可以降低此類風險的幹預方法。OpenAI 強調，目前這些行為尚未造成實質性危害，但被視為未來的潛在威脅，團隊正在提前佈局以應對相關挑戰。&lt;/p&gt; 
&lt;p&gt;OpenAI 稱，已在 GPT-5 訓練中採取措施以降低欺騙和規避問題的傾向，例如在面對不合理或描述不完整的任務時，模型會坦然承認自身侷限性。不過，這些改進尚不完善，相關研究仍在繼續。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373161</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373161</guid>
      <pubDate>Fri, 19 Sep 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>《我們為何遲遲不發佈 Furion v5？》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img height="663" src="https://oscimg.oschina.net/oscnet/up-24099bcabd6ea99a39ef5a6fbe97e46b691.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;幾乎每一天，都會有用戶問我：「Furion v5 什麼時候發佈？」&lt;/strong&gt;而我總是不厭其煩地回覆同一句話：「發佈時會通知大家。」&lt;/p&gt; 
&lt;p&gt;是啊，原本計劃在 2023 年 11 月 10 日發佈的 v5 版本，算起來已經推遲了近兩年。其中的原因，我在不同場合也陸續提到過——&lt;strong&gt;自 Furion 嘗試商業化以來，發生了太多事情，我個人的經歷和想法都有了很大變化，心態也與從前不同。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;也許在一些原本就不太喜歡 Furion，或者更直接地説，不太喜歡我（百小僧）的人看來，這聽起來像是個藉口。仔細想想，倒也合理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;其實 Furion v5 在兩年以前就已經開發完成。而現在對我而言，重點不是「發佈」，而是如何「延長 Furion 的市場生命力」。&lt;/strong&gt;這話聽起來可能有點模糊，我也可以稍微解釋得含蓄一些：&lt;strong&gt;細水長流，遠比曇花一現更重要；讓人持續期待，也比輕易得到更有價值。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;開源 Furion 這五年來，經歷了太多，犧牲了太多，承擔了太多。&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#c0392b"&gt;&lt;u&gt;&lt;strong&gt;我覺得我只有好好的生活，我才能有更多的靈感，去更好的創作和開源 Furion。&lt;/strong&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-d942d1fd0dec53b6def00016bd74425e3dc.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="972" src="https://oscimg.oschina.net/oscnet/up-c1f0ee702076488f62cc74ae6cd7f3c20c4.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="971" src="https://oscimg.oschina.net/oscnet/up-c0072bace93611f2ca6ce43a413ff51fa67.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="968" src="https://oscimg.oschina.net/oscnet/up-877912c5a4eb0def8d57be4bd05ab52522f.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="971" src="https://oscimg.oschina.net/oscnet/up-575a2141d77c5ab961c69bcbdd955a18bb0.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-7500a6b0fb39a8ed6096259a3c0b3698e8e.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-5d249d3e5c745c63d82f693b7d52ccc93f2.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="970" src="https://oscimg.oschina.net/oscnet/up-18c18fbaec13c5ba6d325eae9643b980e20.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-c3464b391f1846d1ee6b77fc8f7469c1c88.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373475</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373475</guid>
      <pubDate>Wed, 17 Sep 2025 20:02:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>內容消費種草 Z 世代，抖音電商助力英特爾實現「品效合一」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;當遊戲從單純的娛樂工具逐步演變為數字陪伴與精神載體，Z 世代用戶已將其視作重要的情緒消費場景。搭載英特爾酷睿處理器的高性能遊戲設備，以及英特爾酷睿 Ultra 處理器的 AI PC，有效兼顧遊戲體驗與生產力、AI 應用場景的需求，受到 Z 世代玩家青睞。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;《2025 遊戲行業抖音經營白皮書》顯示，截至 2024 年 12 月，抖音遊戲內容興趣用戶同比增長 22.7%，23 歲及以下用戶佔比 39.7%；24-30 歲年齡層用戶不僅活躍度高，且消費能力突出，共同構成了該領域活躍的核心用戶羣體。而在今年 ChinaJoy 展會 41.03 萬參觀者中，Z 世代佔比高達 74%。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;隨着 Z 世代對遊戲硬件性能表現出高期待，當品牌持續以 AI 技術升級 PC 生態體系，頭部平台與頭部硬件廠商開展聯合營銷已經水到渠成。抖音電商以一場「集合啦！遊戲玩家」活動，攜手英特爾，開闢新的想象空間。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;英特爾作為芯片巨頭，處理器產品在遊戲硬件生態中佔據重要地位。當硬件性能對遊戲體驗的影響日益顯著，英特爾憑藉紮實的性能表現，從容應對高負荷遊戲運行需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;抖音電商借力平台內容優勢，在 2025 年全新推出首個品類興趣圈層 IP——「玩家請就位」，主打「圈層趨勢尖貨 x 圈層 SKOL 號召 x 圈層影響力內容」的組合模式，為用戶與品牌搭建更精準的連接橋樑。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;依託 2025 ChinaJoy 沉浸式消費場景，抖音電商與英特爾合作，將線上明星玩家帶貨直播、科技博主測評種草，與線下英特爾遊戲裝備體驗區深度融合，通過對圈層用戶的精準種草，詮釋 「品效合一」 的新價值 —— 這正是抖音電商興趣圈層 IP 運營能力與英特爾科技實力相互賦能的成果。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;優質內容激發興趣引力，深度種草 Z 世代&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;暑期正值 3C 數碼消費旺季，2025 ChinaJoy 如期開幕，來自各地的明星遊戲玩家、人氣 Coser 與資深遊戲發燒友因熱愛而相聚，暢玩最新電競裝備，交流遊戲心得。搭載英特爾酷睿處理器和酷睿 Ultra 處理器的電競主機與遊戲本，以強勁性能、AI 算力與流暢體驗征服現場玩家，誕生大量種草內容和高熱度話題，成為關注焦點。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;抖音電商通過明星電競專場直播、達人開箱種草等互動形式，解析英特爾酷睿以及酷睿 Ultra 處理器的領先性能優勢與硬核科技體驗，藉助圈層達人的影響力激發消費者的購買意願。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;明星玩家陳赫開啓 ChinaJoy 電競專場直播，重點分享了兩款搭載英特爾處理器的筆記本產品：分別是搭載英特爾酷睿 i7-14650HX 處理器的機械革命曠世 X 天青色遊戲本，以及搭載英特爾 Core5 處理器的華碩 a 豆筆記本。其中英特爾酷睿 i7-14650HX 處理器採用 16 核 24 線程設計，輕鬆暢玩包括 3A 大作在內的各種遊戲，即使面對複雜的光影和大量 NPC 的遊戲場景，依然保持不卡頓、不掉幀的順暢遊戲體驗。而英特爾 Core5 處理器採用 2 個性能核與 8 個能效核，多核心協同工作，能夠快速響應多任務需求，高效完成複雜任務。直播中陳赫與粉絲熱情互動，直播間曝光人數超 3800 萬，GMV 環比基準期增長 230%+。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ea194148579934295069c2ade7f21eff.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;數碼科技達人@七段、@阿誠來了、@柯北大發布、@胖哥評測，發佈開箱測評視頻，從學生黨、打工人用戶需求痛點出發，推薦英特爾酷睿 HX 系列處理器機型。博主@柯北大測評，實測顯示，搭載英特爾 14 代酷睿 HX 系列處理器遊戲本，能夠流暢運行主流遊戲大作，在遊戲《CS2》中輕鬆達成超 180 高幀率，《三角洲行動》零號大壩地圖也達到 100 幀，遊戲表現酣暢淋漓。多核心、多線程、大緩存設計讓筆記本性能調度輕鬆靈敏，絲滑運行剪映 AI 摳圖、PR 渲染 4K 視頻、PS 處理百層圖層堆疊等應用場景，真正實現 「遊戲體驗與學習工作需求兼顧」。四條開箱視頻累計播放量超 240 萬。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//597a86b3eec6452a34d933a10510405a.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;抖音電商「集合啦！遊戲玩家」專題會場打造英特爾品牌專區，上架搭載英特爾處理器的遊戲本、時尚本、學生本等前沿產品，全面滿足各圈層人羣消費需求，助力英特爾實現品牌曝光。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e19e736aed7ec9a2333ab6c99e887010.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;線下，抖音電商聯合英特爾打造遊戲裝備體驗區，現場吸引大量玩家駐足互動。同期，抖音電商聯動英特爾於杭州、廣州、深圳等核心城市開展了系列線下活動，精準覆蓋目標人羣，累計總曝光量超 1000 萬。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cc36a97443ed30fecb8b96322f8fd128.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「線上內容種草+線下體驗轉化」的閉環營銷鏈路，讓英特爾在暑期 3C 銷售旺季實現了品牌聲量與市場轉化的雙重突破。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;英特爾實現「品效合一」 打造品牌未來增長極&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「集合啦！遊戲玩家」活動以營銷創新為引擎，背靠產品硬實力，激發了 Z 世代消費潛力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;從 ChinaJoy 現場遊戲玩家體驗到數碼博主多維度實測，搭載英特爾酷睿和酷睿 Ultra HX 系列處理器的電競硬件裝備，展現了高能遊戲與高效創作的無縫切換，精準契合了 Z 世代「期待遊戲暢快，同時兼顧學習工作」的選品需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;英特爾是半導體行業和計算創新領域的全球領先廠商。在遊戲主機領域，英特爾通過 XeSS 超分渲染技術和 NPU 神經處理單元實現智能資源調度，帶給遊戲顯著的性能提升。專為遊戲本平台打造的英特爾 14 代酷睿 HX 系列處理器， 憑藉混合架構設計，通過性能核與能效核的協同，優化處理能力與運行效率；14 代酷睿 HX 系列全面支持英特爾的 Extreme Utility（XTU）和 Extreme Memory Profile（XMP）功能，為用戶提供豐富的超頻選項。同時，14 代酷睿 HX 系列還獨享英特爾 Application Optimization（APO）應用，該應用專為部分遊戲設計，能顯著提升遊戲幀數，為玩家帶來更加流暢的遊戲體驗。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;當下，從日常辦公學習到硬核遊戲，從視頻會議、多媒體處理到 AI 高效創作等應用場景中，AI 與算力的結合日益緊密。面對日益增長的 AI 大模型本地運行需求，英特爾推出全新 Arrow Lake 架構的英特爾® 酷睿™ Ultra 處理器（第二代）：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面向輕薄本的高性能平台，從計算性能、AI 性能、圖形性能全面升級的酷睿 Ultra 200H 系列處理器，最高規格為 16 核 CPU+8 核 GPU 的配置，CPU+GPU+NPU 算力總計為 99TOPS，支持 PCIe5.0，在 AI 算力、AI 圖片生成以及深度學習性能方面都擁有出色的算力評分與性能表現；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面向遊戲與工作站的移動 PC 領域，英特爾酷睿 Ultra 200HX 系列處理器帶來了革命性的高能效比，讓遊戲本靜音不妥協；得益於 XPU 架構，用 AI 給遊戲加了點黑科技，能夠讓高性能、高吞吐和低功耗 AI 負載分別得到分配，驅動 AI 遊戲助手交互：NPU 加速遊戲場景識別、CPU 加速音頻及實時處理、iGPU 加速 LLM 推理和 RAG 檢索交互；在架構提升之外，酷睿 Ultra 200HX 系列處理器還支持英特爾獨家的 APO 遊戲優化技術，針對不同遊戲的需要，對處理器的核心配置和電源管理進行調優，精確優化，實現遊戲性能最大化、遊戲性能大飛昇！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;高質量產品疊加創新圈層營銷策略，不僅成功打造了一場激發 Z 世代消費潛力的 3C 數碼營銷盛宴，更在很大程度上驗證了興趣種草對實現「品效合一」的顯著催化作用。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「集合啦！遊戲玩家」活動通過優質內容種草，助力英特爾實現品牌持續曝光和產品性能的充分展現，觸動了 Z 世代的興趣點，將興趣轉化為實實在在的購買行為。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;基於對圈層需求的精準洞察與內容消費的深度融合，英特爾拓寬了硬件產品的傳播場景，與 Z 世代建立了更為緊密且高黏性的品牌聯繫。展望未來，英特爾將持續升級 AI 算力，深化與抖音電商的合作，藉助這一直面用戶興趣的核心陣地，精準響應用戶對性能升級的需求，為品牌的長期增長注入強勁動力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;（編輯：豐尚）&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373364</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373364</guid>
      <pubDate>Wed, 17 Sep 2025 06:12:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>東軟蓋龍佳：解決方案是 AI、數據價值的重要表達方式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="text-align:left"&gt;近日，「現代化進程中的新質生產力」國際研討會在北京召開。中國國家創新與發展戰略研究會學術委員會常務副主席黃奇帆、香港中文大學（深圳）公共政策學院院長、前海國際事務研究院院長鄭永年、東軟集團總裁蓋龍佳等人受邀在大會主論壇發表主旨演講，分享數字經濟時代以新質生產力賦能產業變革的科研成果與創新實踐。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet//6aa7b9b42fdef8cfa8922a9ed75430c8.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;錨定軟件產業，加速新質生產力發展&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;蓋龍佳指出，數字經濟已成為全球經濟發展的核心動力。正所謂「有場景才有前景」，當算力、算法快速提升，AI、大數據等技術不斷成熟，只有將這些先進技術充分融合，打造出更具價值的產品或服務，才能真正實現以新質生產力推動產業向着高科技、高效能、高質量發展，進而更好地促進國家和社會的經濟發展。在這一進程中，軟件是新技術的表達方式，成為技術與行業應用相結合的重要載體。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;東軟始終以軟件為核心，賦能千行百業的信息化、網絡化、數字化變革與轉型。2024 年以來，東軟全面推進解決方案智能化戰略，積極打造智能化、數據價值化、服務化和生態化的解決方案，將 AI、大數據等技術與行業充分融合，以豐富的行業賦能體，構建醫療、養老、就業等重要民生領域的新型基礎設施。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;以 AI+數據加持，解決醫療健康難題&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;蓋龍佳認為，醫療資源的均衡和醫療服務的精準是當前醫療健康事業亟待解決的關鍵問題。AI、大數據等技術為醫療應用場景帶來了新的想象空間和可能，而解決方案是 AI、大數據等技術與醫療融合，創造新醫療模式的工具和平台。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;東軟擁有全面的醫療健康領域解決方案，業務佈局廣泛，在多個細分領域的市場佔有率連續多年排名領先。其中，醫療健康信息化業務出海 15 年，覆蓋全球 12 個國家；在醫療設備領域取得多項突破性成果，從 1997 年成功研發中國第一台 CT，到 2025 年 8 月推出中國首台光子計數 CT，也是全球首台 8cm 寬體光子計數 CT，通過持續創新引領中國高端醫療裝備產業發展。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet//75f9f9c2b37cd62a40ed6e6cdb0d20f5.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;雙向賦能汽車客戶，加速智能化全球化變革&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#0d0d0d"&gt;據蓋龍佳介紹，東軟在汽車電子領域走出了一條先國際後國內，再從國內到全球的獨特發展路線，建立了以中國、德國、美國、日本、馬來西亞為中心的全球產品研發與交付網絡，與全球 50 多家主流汽車廠商建立了深度合作關係，產品覆蓋 110 多個國家，1800 多款車型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#0d0d0d"&gt;今天，東軟正在扮演着雙向賦能的「價值樞紐」，一面積極汲取國際實施經驗，佈局全球市場，賦能中國車企快速出海，持續提升國際競爭力；一面整合中國汽車市場的創新需求和實施能力，助力國際車企轉型，快速實現智能化變革和全面升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#0d0d0d"&gt;面向未來，蓋龍佳表示，作為軟件行業的創新者和賦能者，作為新質生產力的實踐者和推動者，東軟將加速創新步伐，以新應用普惠民生，為社會的數字化變革蓄勢賦能；以新生態創造價值，推動產業發展；以新模式促進經濟，釋放增長動能，為實現國家經濟高質量發展，加速數字中國建設傾獻東軟智慧，貢獻東軟力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;「現代化進程中的新質生產力」國際研討會由國務院新聞辦公室、國家發展和改革委員會指導，中國人權發展基金會、國家發展和改革委員會宏觀經濟研究院、海爾集團主辦，中國對外書刊出版發行中心承辦，來自國家政府官員、相關高校、智庫專家學者、企業界代表、相關國際組織代表、駐華使節以及中外媒體記者等眾多嘉賓出席，深入闡釋中國式現代化的中國特色和世界意義，增進國際社會對中國發展理念的理解，為我國在構建現代化產業體系、培育戰略性新興產業、推動高質量發展等議題上爭取更多國際話語權。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373363</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373363</guid>
      <pubDate>Wed, 17 Sep 2025 06:12:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
  </channel>
</rss>
