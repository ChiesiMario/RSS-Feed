<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Sun, 13 Jul 2025 21:40:16 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>PTerm —— 可以製作漂亮 CLI 的現代 Go 框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;PTerm 是一個現代的 Go 模塊，用於輕鬆美化控制枱輸出。它具有圖表、進度條、表格、樹形結構、文本輸入、選擇菜單等諸多功能。它完全可配置，並且 100% 兼容跨平台。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主要特點&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;易於使用 PTerm 強調易用性，並配有示例和一致的組件設計。&lt;/li&gt;
&lt;li&gt;跨平台 PTerm 可在各種操作系統和終端上運行，包括 Windows CMD、，macOS iTerm2 以及像 GitHub Actions 這樣的 CI 系統。&lt;/li&gt;
&lt;li&gt;經過充分測試，高測試覆蓋率和 28774 項自動化測試確保了 PTerm 的可靠性。&lt;/li&gt;
&lt;li&gt;一致的顏色 PTerm 使用 ANSI 配色方案以保持一致性，併為高級終端提供 TrueColor 支持。&lt;/li&gt;
&lt;li&gt;組件系統 PTerm 的靈活性 Printers 可以單獨使用，也可以組合使用以生成漂亮的控制枱輸出。&lt;/li&gt;
&lt;li&gt;可配置 PTerm 無需配置即可使用，但可以輕鬆定製獨特的終端輸出。&lt;/li&gt;
&lt;li&gt;文檔，訪問&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://pkg.go.dev/github.com/pterm/pterm#section-documentation"&gt;pkg.go.dev&lt;/a&gt;&amp;nbsp;上的綜合文檔並在示例部分查看&lt;a href="https://github.com/pterm/pterm#-examples"&gt;實際示例&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="348" src="https://static.oschina.net/uploads/space/2025/0605/161415_KReV_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/pterm</link>
      <guid isPermaLink="false">https://www.oschina.net/p/pterm</guid>
      <pubDate>Fri, 11 Jul 2025 10:57:00 GMT</pubDate>
    </item>
    <item>
      <title>解碼鴻蒙生態及核心技術 + 2025 HarmonyOS 創新賽，攜手共創萬物互聯新未來</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;7 月 8 日晚，一場聚焦 HarmonyOS 應用開發的線上技術交流會成功舉行。本次活動由開源中國（OSCHINA）《數智漫談》欄目主辦，以「三步上手鴻蒙開發：工具·能力·進階」為主題，旨在幫助開發者高效掌握鴻蒙應用開發核心技能，把握萬物互聯時代的創新機遇。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播吸引了大量開發者關注，觀看人次超過 1.45 萬，全網累計曝光量達 740 萬。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="960" src="https://oscimg.oschina.net/oscnet/up-3b3809a860224eb959066196672471a33d8.png" width="2560" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;交流會上，三位來自鴻蒙生態的技術專家進行了深入分享。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;華為雲 HCDE、鴻蒙應用認證開發者姚聖偉&lt;/strong&gt;&lt;/span&gt;介紹了鴻蒙操作系統的最新進展。截至 2025 年 6 月，鴻蒙生態設備突破 10 億台，中國市場佔有率 17%，超越 iOS 成為中國市場的第二大移動操作系統。 鴻蒙的核心能力包括分佈式架構、跨端開發、AI 集成等，支持一次開發多端部署。鴻蒙 6.0 版本強化了分佈式軟總線技術，提供更高帶寬、更低時延、更安全可靠的設備間通信能力，支持更流暢、更強大的多設備協同體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;專家特別提到，相比&lt;/strong&gt; &lt;strong&gt;Web 應用，鴻蒙元服務具備獨特的核心優勢。&lt;/strong&gt;在用戶體驗上的提升，元服務實現了「原子化」場景滲透，無需打開完整載體，可直接嵌入系統場景（如負一屏卡片、日曆提醒），實現 「服務找用戶」，而 Web 需依賴瀏覽器跳轉，體驗割裂。另外，得益於系統級深度協同，元服務能直接調用系統底層能力（如本地計算、狀態響應），Web 應用受沙箱限制無法做到。它重構了服務觸達方式，以輕量化、場景化打破傳統應用壁壘，推動生態從 「下載安裝」 向 「按需流轉」 升級，這是 Web 應用難以替代的生態級突破。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;華為開發者專家（HDE）張一弛&lt;/strong&gt;&lt;/span&gt;詳細演示了鴻蒙官方開發工具 DevEco Studio。他表示，DevEco Studio 的安裝與項目創建流程十分便捷，集成 SDK、模擬器，支持 Stage 模型；同時具備構建加速（並行/增量編譯）、AI 輔助編程、3D UI 視圖分析複雜組件層級、AI 性能分析優化、以及創新的多屏模擬器實現單窗口多設備聯調等諸多亮點。&lt;/p&gt; 
&lt;p&gt;專家指出，相比安卓開發環境，DevEco Studio 更加輕量，更加高效。DevEco Studio 基於 IntelliJ IDEA 精簡打造，剔除冗餘組件，安裝包更小，專注鴻蒙開發時資源佔用更低。其&amp;nbsp;AI 輔助編程（CodeGenie）功能可快速生成代碼、修復問題；Hvigor 構建工具優化流程，編譯更快；支持多端實時預覽，遠程真機測試便捷，大幅提升開發效率。而安卓開發常用的 Android Studio 因需要兼容的安卓 SDK 廣泛，且需集成大量組件，資源佔用較高，且操作複雜。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;上海杉達學院副教授、華為開發者專家（HDE）祝欣蓉&lt;/strong&gt;&lt;/span&gt;則針對開發者成長路徑提出建議。她提出三步路徑：一是要提高對鴻蒙技術演進趨勢和生態發展的認知；二是高效學習：以官網知識地圖為綱，從行業白皮書切入，快速入門，分階段學習，並推薦了「代碼工坊」和「開發案例」兩個實用工具。三是積極參與生態：活用新工具（如智能體框架）開發智能體，積極參與開源，抓住鴻蒙生態爆發期的機遇。&lt;/p&gt; 
&lt;p&gt;活動同時重點介紹了正在進行的「2025 HarmonyOS 創新賽」。該賽事由華為發起，是鴻蒙生態規模最大的官方開發者賽事，面向全球開發者。賽事設立專項獎金，總激勵近千萬（包含 450 萬元人民幣及 450 萬耀星券），鼓勵開發者基於 HarmonyOS 6 開發者 Beta 版本，調用其創新 Kit 能力，開發具有創新性和極致體驗的應用或解決方案。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="3508" src="https://oscimg.oschina.net/oscnet/up-37b1f3dd2c128d26fe03b30f4282474a458.jpg" width="2481" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;專家在解讀賽事時指出，評審注重創新性、技術實現和用戶體驗，建議參賽團隊緊扣六大方向賽題，明確分工，善用 AI 工具，並關注社會關懷與跨設備協同等加分項。衝擊高獎項的作品需融合技術創新、商業潛力和社會價值。&lt;/p&gt; 
&lt;p&gt;本次技術交流會通過場景化演示與案例拆解，為開發者提供了實用的開發指導和生態洞察。與會專家表示，鴻蒙操作系統的快速發展及其構建的萬物互聯生態，為全球開發者提供了廣闊的創新舞台。活動的成功舉辦，將進一步激發開發者的創新熱情，推動鴻蒙生態的繁榮發展。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;微信掃碼，觀看直播回放：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="4480" src="https://oscimg.oschina.net/oscnet/up-5426237e33bbcf93dda59aa74a9e482ad0c.png" width="3800" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18684360</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18684360</guid>
      <pubDate>Fri, 11 Jul 2025 10:33:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Mistral AI 發佈 Devstral2507 系列</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Mistral AI 與 All Hands AI 合作，推出了針對開發者的大型語言模型 Devstral2507 系列，包含兩款新模型：Devstral Small1.1 和 Devstral Medium2507。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這些模型旨在支持基於智能代理的代碼推理、程序合成和結構化任務執行，適用於大型軟件代碼庫的實際應用。這次發佈在性能和成本上進行了優化，使其在開發工具和代碼自動化系統中具有廣泛的應用潛力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-c447bd09a61245b75a244d3bea9665c071a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Devstral Small1.1 是一款開源模型，基於 Mistral-Small-3.1 基礎模型，擁有約 240 億個參數。該模型支持 128k 的上下文窗口，能夠處理多文件代碼輸入和複雜的長提示，符合軟件工程工作流程的特點。此版本特別針對結構化輸出進行微調，包括 XML 和函數調用格式，使其與 OpenHands 等代理框架兼容，適合程序導航、多步驟編輯和代碼搜索等任務。Devstral Small1.1 的許可為 Apache2.0，支持研究和商業用途。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在性能測試方面，Devstral Small1.1 在 SWE-Bench Verified 基準測試中獲得 53.6% 的成績，證明其在為真實的 GitHub 問題生成正確補丁方面表現優異。雖然其性能不及大型商業模型，但在大小、推理成本和推理能力之間找到了一個平衡點，適合多種編碼任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，該模型以多種格式發佈，包括可以在高內存 GPU（如 RTX4090）或 32GB RAM 以上的 Apple Silicon 機器上進行本地推理的量化版本。同時，Mistral 還通過其推理 API 提供模型，當前的收費標準與 Mistral-Small 系列模型相同。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Devstral Medium2507 則僅通過 Mistral API 或企業部署協議提供，並不開放源代碼。該模型在 SWE-Bench Verified 基準測試中得分為 61.6%，在長上下文的推理能力上表現出色，能夠超越一些商業模型，如 Gemini2.5Pro 和 GPT-4.1。此模型的 API 收費標準高於 Small 版本，但其強大的推理能力使其非常適合在大型代碼庫中執行任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Devstral Small 更適合本地開發、實驗或集成到客戶端開發工具中，而 Devstral Medium 則在結構化代碼編輯任務中提供更高的準確性和一致性，適合需要高性能的生產服務。兩款模型的設計都支持與代碼代理框架的集成，使其能夠簡化測試生成、重構和錯誤修復的自動化工作流程。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359903</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359903</guid>
      <pubDate>Fri, 11 Jul 2025 10:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>從 Python 演進探尋 AI 與雲對編程語言的推動</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：孤弋&lt;/p&gt; 
&lt;h2&gt;引言&lt;/h2&gt; 
&lt;p&gt;Python 作為當今最受歡迎的編程語言之一，從 2008 年 Python 3.0 的發佈到 2024 年 Python 3.13 的正式發佈，以及 2025 年計劃發佈的 Python 3.14，十六年的演進過程不僅見證了編程語言技術的進步，更反映了整個軟件行業的深刻變化。從人工智能的興起到雲計算的普及，從微服務架構的流行到開發者體驗的重視，多重因素共同推動着 Python 語言的持續發展。&lt;/p&gt; 
&lt;h3&gt;近十六年版本演進圖&lt;/h3&gt; 
&lt;p&gt;先給下面這張圖從版本發佈的時間上先給大家一個直觀的印象。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b53f869abba56459700db4ef23ebfbcd1b9.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Python 3 從 2008 年推出，起初的核心目標是解決 Python 2 中積累的語言設計缺陷和一致性問題。以犧牲向前兼容為代價，來修復語言設計中的根本缺陷。其中包括字符串與編碼的混亂、類型安全的不足、標準庫的臃腫等。但是隨着雲計算、AI 等新興技術的興起，Python 3 逐漸開始追求更現代的編程風格和體驗、更極致的性能等。寫這篇文章的目的，主要是想從編程風格、類庫能力、性能優化、虛擬機技術、開發工具鏈等多個維度，闡明 Python 語言的各個版本間的能力變化，為大家呈現一個儘量完整的 Python 演進視圖。&lt;/p&gt; 
&lt;h2&gt;一、編程風格的現代化轉型&lt;/h2&gt; 
&lt;h3&gt;1.1 語法層面的革命性變化&lt;/h3&gt; 
&lt;p&gt;這些版本的迭代，給程序員的編程風格帶來了深刻的變化。根據 Python 官方文檔的統計，這些變化不僅體現在語法層面，更體現在編程範式和開發理念的根本轉變。&lt;/p&gt; 
&lt;h4&gt;變化一：字符串處理的演進&lt;/h4&gt; 
&lt;p&gt;Python 2.7 時代，字符串處理是開發者的一大痛點，需要顯式處理 Unicode 和字節串的區別：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 2.7 - 字符串處理複雜
# -*- coding: utf-8 -*-
name = u"EDAS 用戶"  # Unicode 字符串
message = u"Hello, %s!" % name
print message.encode('utf-8')
# 字符串格式化方式有限
template = u"用戶{name}在{timestamp} 登錄了 EDAS 應用管理平台"
result = template.format(name=name, timestamp="2023-01-01")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Python 3.0 的發佈標誌着字符串處理的重大改進，字符串默認為 Unicode：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.0+ - 字符串處理簡化
name = "EDAS 用戶"  # 默認 Unicode
message = "Hello, {}!".format(name)
print(message)  # print 變為函數
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Python 3.6 引入的 f-string 徹底革命了字符串格式化，根據官方性能測試，f-string 在多數場景中比傳統格式化方法快 20-30%：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.6+ - f-string 革命 
name = "EDAS 用戶"
timestamp = "2023-01-01"
message = f"Hello, {name}!"
complex_message = f"用戶{name}在{timestamp}登錄了 EDAS 應用管理平台"
# 支持表達式和格式化
price = 123.456
formatted = f"價格: {price:.2f}元"  # 價格: 123.46 元
# 支持調試模式（Python 3.8+）
debug_info = f"{name=}, {timestamp=}"  
# name='世界', timestamp='2023-01-01'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;性能對比測試結果：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-30278ff5db0358f8f0e2c6043e4274568a4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;基於 10,000 次字符串格式化操作後的平均時間得出。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;變化二：異步編程語法的演進&lt;/h4&gt; 
&lt;p&gt;異步編程是 Python 演進過程中最重要的變化之一。從基於生成器的複雜模式到直觀的 async/await 語法，這一變化的推動力來自現代 Web 應用對高併發處理的需求。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.4 - 基於生成器的異步編程 - for Python in EDAS
import asyncio
@asyncio.coroutine
def fetch_data(url):
    response = yield from aiohttp.get(url)
    data = yield from response.text()
    return data
@asyncio.coroutine
def main():
    tasks = []
    for url in urls:
        task = asyncio.ensure_future(fetch_data(url))
        tasks.append(task)
    results = yield from asyncio.gather(*tasks)
    return results
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Python 3.5 引入的 async/await 語法使異步編程更加直觀：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.5+ - async/await 語法 - for Python in EDAS
import asyncio
import aiohttp
async def fetch_data(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()
async def main():
    urls = ['http://edas.console.aliyun.com', 
            'http://www.aliyun.com/product/edas' ]
    tasks = [fetch_data(url) for url in urls]
    results = await asyncio.gather(*tasks)
    return results
# Python 3.7+ - 更簡潔的運行方式
asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;異步性能基準測試：&lt;/p&gt; 
&lt;p&gt;同時處理 1000 個 HTTP 請求&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-df35a7afcee57806a5f1966027c074f90fe.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;模擬 1000 個併發 HTTP 請求，每個請求延遲 100ms 。值得注意的是大家看到的 "同步處理總耗時"小幅下降得益於解釋器整體優化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;1.2 類型系統的建立與完善&lt;/h3&gt; 
&lt;p&gt;Python 類型系統的發展是編程風格現代化的重要體現。從 Python 3.5 引入 PEP 484 類型提示開始，Python 逐步建立了功能完整的類型系統。&lt;/p&gt; 
&lt;h4&gt;類型提示的演進歷程&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.5 - 基礎類型提示 - for Python in EDAS
from typing import List, Dict, Optional, Union
def process_users(users: List[str]) -&amp;gt; Dict[str, int]:
    result = {}
    for user in users:
        result[user] = len(user)
    return result
def find_user(user_id: int) -&amp;gt; Optional[str]:
    # 可能返回 None
    return database.get_user(user_id)
# 聯合類型
def handle_input(value: Union[str, int]) -&amp;gt; str:
    return str(value)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Python 3.9 簡化了泛型語法，減少了從 typing 模塊的導入需求：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.9+ - 內置集合泛型
def process_data(items: list[str]) -&amp;gt; dict[str, int]:
    return {item: len(item) for item in items}
def merge_lists(list1: list[int], list2: list[int]) -&amp;gt; list[int]:
    return list1 + list2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Python 3.10 引入聯合類型操作符，進一步簡化語法：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.10+ - 聯合類型語法糖
def handle_input(value: str | int) -&amp;gt; str:
    return str(value)
def process_result(data: dict[str, str | int | None]) -&amp;gt; str:
    # 處理混合類型字典
    return json.dumps(data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在這之後 python 也有了更多的類型檢查工具，如 mypy、pyright、pyre 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-63073fc70aa7d3e5d24ddc0b90f8e22b295.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;二、類庫生態的戰略性調整&lt;/h2&gt; 
&lt;h3&gt;2.1 標準庫的精簡與優化&lt;/h3&gt; 
&lt;p&gt;Python 標準庫的演進體現了從"已包含"到"精選"的戰略轉變。根據 PEP 594 的統計，Python 3.13 移除了 19 個過時的標準庫模塊，這一變化體現了 Python 社區對代碼質量和維護性的重視。&lt;/p&gt; 
&lt;h4&gt;標準庫模塊的變遷&lt;/h4&gt; 
&lt;p&gt;下表展示了 Python 標準庫的重要變化：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ab7604d25a59043fd51cc77e2be43112ee5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4&gt;新模塊的實際應用示例&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;pathlib 模塊的現代化路徑操作（Python 3.4+）：&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 傳統方式 vs pathlib 方式 - for Python in EDAS
import os
import os.path
from pathlib import Path
# 傳統方式
old_way = os.path.join(os.path.expanduser("~"), "documents", "EDAS-python-file.txt")
if os.path.exists(old_way):
    with open(old_way, 'r') as f:
        content = f.read()
# pathlib 方式
new_way = Path.home() / "documents" / "EDAS-python-file.txt"
if new_way.exists():
    content = new_way.read_text()
# 更多 pathlib 優勢
config_dir = Path.home() / ".config" / "myapp"
config_dir.mkdir(parents=True, exist_ok=True)
for py_file in Path(".").glob("**/*.py"):
    print(f"Python 文件: {py_file}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;性能對比測試：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4187629c93667852e476abfc2dcb4d6d86e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：除目錄遍歷外，pathlib 在大多數場景下性能相當或更優，Pathlib 犧牲少量性能換取 API 現代化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2.2 第三方生態的爆發式增長&lt;/h3&gt; 
&lt;p&gt;雖然標準庫趨於精簡，但 Python 的第三方生態卻經歷了爆發式增長。根據 PyPI 統計數據，截至 2024 年，PyPI 上的包數量已超過 500,000 個，相比 2015 年的約 60,000 個包，增長了 8 倍以上。&lt;/p&gt; 
&lt;p&gt;數據科學庫性能對比：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fbeb7b699de037b89c01edf8b2b4c5d1bfe.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;測試環境：1GB CSV 數據處理，包括讀取、過濾、聚合操作。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;三、性能優化的突破性進展&lt;/h2&gt; 
&lt;h3&gt;3.1 Faster CPython 項目的革命性影響&lt;/h3&gt; 
&lt;p&gt;Python 3.11 引入的 Faster CPython 項目是 Python 性能優化歷史上的重要里程碑。根據官方文檔，這一項目通過多個層面的系統性優化，實現了顯著的性能提升。&lt;/p&gt; 
&lt;h4&gt;官方性能數據驗證&lt;/h4&gt; 
&lt;p&gt;根據 Python 官方文檔的明確聲明：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"CPython 3.11 is an average of 25% faster than CPython 3.10 as measured with the pyperformance benchmark suite, when compiled with GCC on Ubuntu Linux. Depending on your workload, the overall speedup could be 10-60%."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;驗證測試結果：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b01518d712716654789451c496be7bf907b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;數據來源：Python 官方 pyperformance 基準測試結果。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;啓動性能的優化實例&lt;/h4&gt; 
&lt;p&gt;根據官方文檔，Python 3.11 的啓動時間改進了 10-15%：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 測試啓動性能的腳本 - for Python in EDAS
# 標準啓動時間測試
time python3 -c "import sys; print('Python', sys.version_info[:2])"
# 模塊導入性能測試
time python3 -c "import json, os, re, datetime, pathlib"
# 應用啓動模擬測試
time python3 -c "
import sys
import json
import os
from pathlib import Path
config = {'app': 'test', 'version': '1.0'}
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)
print('Application started')
"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;啓動時間測試結果（官方驗證）：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1cedc3189210fcf45d637d02704e6f32f2e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.2 JIT 編譯技術的前瞻性佈局&lt;/h3&gt; 
&lt;p&gt;Python 3.13 引入的 JIT 編譯器標誌着 Python 性能優化進入新階段。根據 PEP 744 和官方文檔，這一技術仍處於實驗階段。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9b7d7a73607cb96baf80c0efba1f999aefb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;JIT 編譯器在不同基準測試中的預期性能提升（實驗性數據）&lt;/p&gt; 
&lt;h4&gt;JIT 編譯器的官方狀態&lt;/h4&gt; 
&lt;p&gt;根據 Python 3.13 官方文檔：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"When CPython is configured and built using the --enable-experimental-jit option, a just-in-time (JIT) compiler is added which may speed up some Python programs."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;JIT 編譯器測試環境：&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 編譯啓用 JIT 的 Python 3.13
./configure --enable-experimental-jit
make -j4
# 運行 JIT 性能測試
python3.13 --jit benchmark_script.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;保守性能估算（基於實驗數據）：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9daf7a2687a0ac193a082fb546a86a5a8cf.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：以上數據為實驗性估算，實際效果可能因工作負載而顯著不同。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;3.3 內存管理的系統性改進&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-09a9f3aa3172d648ae792672cb2cd951afe.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Python 內存管理的優化效果。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;內存使用優化示例&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;# 內存使用優化對比示例 - for Python in EDAS
import sys
import gc
from memory_profiler import profile  # 需要安裝: pip install memory-profiler
class OldStyleClass:
    """傳統類定義 - 內存使用較多"""
    def __init__(self, name, data):
        self.name = name
        self.data = data
        self.metadata = {}
        self.cache = {}
class OptimizedClass:
    """優化後的類定義 - 使用__slots__"""
    __slots__ = ['name', 'data', '_metadata']
    def __init__(self, name, data):
        self.name = name
        self.data = data
        self._metadata = None
@profile
def memory_comparison():
    """內存使用對比測試"""
    # 創建大量對象測試內存使用
    old_objects = [OldStyleClass(f"obj_{i}", list(range(10))) for i in range(1000)]
    print(f"傳統類對象內存使用: {sys.getsizeof(old_objects)} bytes")
    optimized_objects = [OptimizedClass(f"obj_{i}", list(range(10))) for i in range(1000)]
    print(f"優化類對象內存使用: {sys.getsizeof(optimized_objects)} bytes")
    # 手動垃圾回收
    del old_objects
    del optimized_objects
    gc.collect()
memory_comparison()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述腳本執行結果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-822b55758fafbb0b18c1c403534a4c9742f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其他內存優化測試結果：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-88c8c9d615e1a1f4b7a171dbff6b7d93ede.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以上對比表格由 100,000 個對象的批量創建得出。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;四、虛擬機技術的前沿探索&lt;/h2&gt; 
&lt;h3&gt;4.1 GIL 問題的歷史性突破&lt;/h3&gt; 
&lt;p&gt;全局解釋器鎖（GIL）一直是 Python 併發性能的最大瓶頸。Python 3.13 引入的自由線程模式是解決這一歷史性問題的重要嘗試。不過根據 PEP 703 來看，這一特性目前處於實驗階段，但是的確令人期待。&lt;/p&gt; 
&lt;h4&gt;官方自由線程模式狀態&lt;/h4&gt; 
&lt;p&gt;根據 Python 3.13 官方文檔：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"CPython now has experimental support for running in a free-threaded mode, with the global interpreter lock (GIL) disabled. This is an experimental feature and therefore is not enabled by default."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;啓用自由線程模式：&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 編譯支持自由線程的 Python
./configure --disable-gil
make -j4
# 或使用預編譯版本
python3.13t  # 't'表示 free-threaded 版本
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;GIL 影響實驗測試結果：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5409dc3f6bf367d3c9d4f2e3a5d37334b2b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在 4C8G 的機器中，批量執行對應任務一百萬次計算操作得出。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;4.2 字節碼系統的智能化演進&lt;/h3&gt; 
&lt;p&gt;Python 的字節碼系統在演進過程中變得越來越智能化。Python 3.11 引入的自適應字節碼技術是這一演進的重要成果。&lt;/p&gt; 
&lt;h4&gt;字節碼優化的實際效果&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;# 字節碼分析示例 - for Python in EDAS
# -*- coding: utf8
import dis
import time
def simple_function(x, y):
    """簡單函數 - 用於字節碼分析"""
    result = x + y
    if result &amp;gt; 10:
        return result * 2
    else:
        return result
def complex_function(data):
    """複雜函數 - 展示字節碼優化"""
    total = 0
    for item in data:
        if isinstance(item, (int, float)):
            total += item ** 2
        elif isinstance(item, str):
            total += len(item)
    return total
print("簡單函數字節碼:")
dis.dis(simple_function)
print("\n 複雜函數字節碼:")
dis.dis(complex_function)
# 將以上的文件保存成 dis.py 之後，
# 分別以 python2 dis.py 與 python3.13 dis.py 執行完之後查看字節碼優化的對比效果
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;字節碼優化效果測試：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4bcbff340de08294d63beac5bb1090c845c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;複雜函數執行 100,000 次迭代。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;五、演進背後的核心推動力&lt;/h2&gt; 
&lt;h3&gt;5.1 AI 與機器學習帶來的生態繁榮&lt;/h3&gt; 
&lt;p&gt;Python 在 AI 和機器學習領域的成功是其演進的最重要推動力。根據 Stack Overflow 2024 年開發者調查，Python 連續第四年成為最受歡迎的編程語言，其中 AI/ML 應用佔據了重要地位。&lt;/p&gt; 
&lt;h4&gt;數據科學革命的量化影響&lt;/h4&gt; 
&lt;p&gt;根據 GitHub 統計數據，與 AI/ML 相關的 Python 項目數量從 2015 年的約 50,000 個增長到 2024 年的超過 800,000 個，增長了 16 倍。&lt;/p&gt; 
&lt;h4&gt;主要 AI/ML 框架的發展時間線：&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6028fd335feaacbb7a0cd598b5e45550227.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以上數據截止至 2025 年 6 月整理。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;企業級 AI 應用場景直接受益&lt;/h4&gt; 
&lt;p&gt;數據分析樣例代碼&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 現代機器學習工作流示例  - for Python in EDAS
# requirement.txt 內容
pandas&amp;gt;=2.0
numpy&amp;gt;=1.24
matplotlib&amp;gt;=3.7
seaborn&amp;gt;=0.12
scikit-learn&amp;gt;=1.2
# 腳本內容：for Python in EDAS
# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
# 1️⃣ 加載數據並查看基本信息
def load_data(file_path='EDAS.csv'):
    """
    加載原始數據，並展示前幾行和基礎信息。
    """
    df = pd.read_csv(file_path)
    print("數據前幾行：")
    print(df.head())
    print("\n 數據基本信息：")
    print(df.info())
    return df
# 2️⃣ 特徵工程：日期解析 + 滾動窗口特徵
def feature_engineering(df):
    """
    將 'date' 列轉為 datetime 類型，並構造滾動窗口平均值作為新特徵。
    """
    df['processed_date'] = pd.to_datetime(df['date'])
    df['feature_engineered'] = df['value'].rolling(window=7).mean()
    return df
# 3️⃣ 可視化：時間序列趨勢圖
def visualize_time_series(df):
    plt.figure(figsize=(14, 6))
    sns.lineplot(data=df, x='processed_date', y='feature_engineered')
    plt.title('時間序列特徵工程結果 - 滾動窗口平均值 (Window=7)')
    plt.xlabel('日期')
    plt.ylabel('滾動均值')
    plt.tight_layout()
    plt.show()
# 4️⃣ 準備建模數據
def prepare_model_data(df):
    X = df[['feature1', 'feature2', 'feature_engineered']].fillna(0)
    y = df['target']
    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# 5️⃣ 構建模型並訓練
def train_model(X_train, y_train):
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    return model
# 6️⃣ 模型評估
def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    print("模型評估報告：")
    print(classification_report(y_test, predictions))
    # 顯示特徵重要性
    feat_names = X_test.columns
    importances = model.feature_importances_
    plt.figure(figsize=(10, 6))
    sns.barplot(x=importances, y=feat_names)
    plt.title('隨機森林模型特徵重要性')
    plt.xlabel('重要性得分')
    plt.ylabel('特徵名稱')
    plt.show()
# 7️⃣ 超參數調優（可選）
def hyperparameter_tuning(X_train, y_train):
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5]
    }
    grid_search = GridSearchCV(
        estimator=RandomForestClassifier(random_state=42),
        param_grid=param_grid,
        scoring='f1_weighted',
        cv=5,
        n_jobs=-1
    )
    grid_search.fit(X_train, y_train)
    best_params = grid_search.best_params_
    print("最佳超參數組合：", best_params)
    return grid_search.best_estimator_
# 主函數：執行整個流程
def main():
    df = load_data()
    df = feature_engineering(df)
    visualize_time_series(df)
    X_train, X_test, y_train, y_test = prepare_model_data(df)
    model = train_model(X_train, y_train)
    print("使用默認參數訓練模型：")
    evaluate_model(model, X_test, y_test)
    print("\n 開始超參數調優：")
    tuned_model = hyperparameter_tuning(X_train, y_train)
    print("使用調優後的模型重新評估：")
    evaluate_model(tuned_model, X_test, y_test)
if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;注：以上代碼片段內容由 tongyi 生成。以下是 Prompt:&lt;/p&gt; 
&lt;p&gt;你是一位專業的數據科學家，擅長使用 Python 進行端到端的數據分析和機器學習建模。請根據以下代碼示例，幫我完成/解釋/優化一個用於 EDAS 數據集的數據分析流水線：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;數據預處理部分包括：日期解析、滾動窗口特徵構建；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用 matplotlib 和 seaborn 對時間序列數據進行可視化；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構建了一個基於 RandomForestClassifier 的分類模型，並輸出 classification_report。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;請根據這個流程，提供清晰的步驟説明、代碼註釋、潛在改進點或可擴展方向（例如特徵選擇、超參數調優、交叉驗證等）。要求代碼規範、邏輯清晰，適合在實際項目中使用。&lt;/p&gt; 
&lt;h3&gt;5.2 雲技術的推動和影響&lt;/h3&gt; 
&lt;p&gt;雲計算的普及深刻改變了 Python 的發展方向。根據 CNCF 2024 年調查報告，Python 是容器化應用開發中第二受歡迎的語言，僅次於 Go。雲技術的不斷向前演進，也在催生着 Python 的不斷變化。其中雲廠商中推動的事件驅動模型的應用架構，直接推動 Python 3.4 引入 asyncio 標準庫，async/await 語法進一步優化了協程可讀性，gevent 等第三方庫的協程方案也被納入標準生態。&lt;/p&gt; 
&lt;p&gt;彈性和容器等主流雲的場景下，對於應用程序的冷啓動有着極致訴求，從 Python 3.11 中 Faster CPython 項目的誕生，之後引入的 Frame Caching、Zero-Cost Exception、專用系統 LOAD 操作碼、隔離堆等內存技術的引入，對冷啓動的優化有着立竿見影的效果。&lt;/p&gt; 
&lt;p&gt;同時雲函數 (Function) 的高頻觸發、瞬時生命週期、事件多樣性等特性，迫使 Python 在語言層面對異步範式進行深度重構。這種壓力傳導機制，正是 Python 從"腳本工具"蛻變為"雲原生核心語言"的技術動力源。未來隨着事件總線架構的深化以及 AI 協同推理等新場景出現，Python 的響應式編程能力將持續進化。&lt;/p&gt; 
&lt;h2&gt;六、未來展望與發展趨勢&lt;/h2&gt; 
&lt;h3&gt;6.1 性能優化的持續深化&lt;/h3&gt; 
&lt;p&gt;基於當前的發展趨勢和官方路線圖，Python 在性能優化方面將繼續深化，也相當令人期待。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;預期的性能改進路線圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e5f2f0a9e6fbe505c019c9c2e5802342e17.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：以上時間表和性能數據為基於當前趨勢的預測，實際情況可能有所不同。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;6.2 類型系統的進一步完善&lt;/h3&gt; 
&lt;p&gt;Python 的類型系統將繼續向着更強大、更易用的方向發展。根據 Typing Council 的路線圖，未來的重點包括：&lt;/p&gt; 
&lt;h4&gt;高級類型特性展望舉例&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;# Python 3.14+ 預期類型系統改進 - For Python in EDAS
from typing import TypeVar, Generic, Protocol, runtime_checkable
# typing_extensions module 為潛在的類型系統改進能力
from typing_extensions import Self, TypedDict, Required, NotRequired
# 更強大的泛型支持
T = TypeVar('T', bound='Comparable')
class Comparable(Protocol):
    def __lt__(self, other: Self) -&amp;gt; bool: ...
    def __eq__(self, other: object) -&amp;gt; bool: ...
class SortedContainer(Generic[T]):
    """類型安全的排序容器"""
    def __init__(self) -&amp;gt; None:
        self._items: list[T] = [ ]
    def add(self, item: T) -&amp;gt; Self:
        """添加元素並保持排序"""
        # 二分插入
        left, right = 0, len(self._items)
        while left &amp;lt; right:
            mid = (left + right) // 2
            if self._items[mid] &amp;lt; item:
                left = mid + 1
            else:
                right = mid
        self._items.insert(left, item)
        return self
    def get_items(self) -&amp;gt; list[T]:
        """獲取所有元素"""
        return self._items.copy()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;結語&lt;/h2&gt; 
&lt;p&gt;Python 從 2.7 到 3.13 的演進歷程展現了一個編程語言如何在快速變化的技術環境中保持活力和競爭力。從編程風格的現代化到性能優化的突破，從類庫生態的戰略調整到虛擬機技術的前沿探索，Python 的演進是多重推動力協同作用的結果。AI 與機器學習的浪潮、雲計算和 DevOps 的影響、編程語言競爭的壓力，這些因素共同塑造了 Python 的發展軌跡。Python 的故事還在繼續，這一演進歷程將為整個編程語言領域的發展提供重要啓示，也將繼續推動軟件技術的進步和創新。&lt;/p&gt; 
&lt;p&gt;這裏我們也提前做一個預告，阿里雲 EDAS 產品即將於 7 月初推出針對 Python 應用的託管、微服務、可觀測的一站式應用治理的能力，敬請進羣關注（釘釘羣： 21958624）。&lt;/p&gt; 
&lt;h2&gt;數據來源與參考文獻&lt;/h2&gt; 
&lt;p&gt;本文所有技術聲明和性能數據均基於以下權威來源：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Python 11 官方文檔 - What's New in Python 3.11：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fwhatsnew%2F3.11.html" target="_blank"&gt;https://docs.python.org/3/whatsnew/3.11.html&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;pyperformance 基準測試套件：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpython%2Fpyperformance" target="_blank"&gt;https://github.com/python/pyperformance&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Python 3.13 移除模塊列表：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fwhatsnew%2F3.13.html%5B%23removed%5D" target="_blank"&gt;https://docs.python.org/3/whatsnew/3.13.html[#removed]&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;PyPI 統計數據：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpypistats.org%2F" target="_blank"&gt;https://pypistats.org/&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Python 3.11 Faster CPython 項目：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fwhatsnew%2F3.11.html" target="_blank"&gt;https://docs.python.org/3/whatsnew/3.11.html&lt;/a&gt;&lt;a href=""&gt;#whatsnew311&lt;/a&gt;-faster-cpython&lt;/p&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;Python 3.13 JIT 編譯器：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fwhatsnew%2F3.13.html" target="_blank"&gt;https://docs.python.org/3/whatsnew/3.13.html&lt;/a&gt;&lt;a href=""&gt;#whatsnew313&lt;/a&gt;-jit-compiler&lt;/p&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;PEP 703 - Making the Global Interpreter Lock Optional：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpeps.python.org%2Fpep-0703%2F" target="_blank"&gt;https://peps.python.org/pep-0703/&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="8"&gt; 
 &lt;li&gt;自由線程模式文檔：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fhowto%2Ffree-threading-python.html" target="_blank"&gt;https://docs.python.org/3/howto/free-threading-python.html&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="9"&gt; 
 &lt;li&gt;Stack Overflow 2024 開發者調查：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurvey.stackoverflow.co%2F2024%2F" target="_blank"&gt;https://survey.stackoverflow.co/2024/&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="10"&gt; 
 &lt;li&gt;GitHub 統計數據：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsearch%3Fq%3Dmachine%2Blearning%2Blanguage%3Apython" target="_blank"&gt;https://github.com/search?q=machine+learning+language:python&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="11"&gt; 
 &lt;li&gt;Typing Council 路線圖：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftyping.readthedocs.io%2Fen%2Flatest%2F" target="_blank"&gt;https://typing.readthedocs.io/en/latest/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18684302</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18684302</guid>
      <pubDate>Fri, 11 Jul 2025 08:32:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Manus 清空國內社交平台賬號內容，前員工透露「不會繼續推進」中文版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;網友發現，通用 AI 智能體公司「Manus」的官方微博和小紅書賬號的內容今日均已清空。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-85bd05e3a02aa43e5707cbefe10364949bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與此同時，打開 Manus 的官網發現，其官網首頁顯示&lt;strong&gt;「Manus 在你所在的地區不可用」&lt;/strong&gt;，而此前為「Manus 中文版本正在開發中」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0ff951397f8da8a43d06253d76df2ada848.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Manus 近期因大規模裁員的傳聞而再度引發外界關注。據澎湃新聞 7 月 8 日報道，Manus 方面對此回應記者表示：「&lt;strong&gt;基於公司自身經營效率考量，我們決定對部分業務團隊進行調整。公司將繼續專注核心業務發展，提升整體運營效率。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;另據藍鯨新聞 7 月 10 日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1837269038810525490%26wfr%3Dspider%26for%3Dpc" target="_blank"&gt;報道&lt;/a&gt;，Manus 將與阿里通義千問合作開發中文版一事，&lt;strong&gt;Manus 一員工稱「不會繼續推進」&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359869</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359869</guid>
      <pubDate>Fri, 11 Jul 2025 08:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>工信部將在 2025 世界人工智能大會上發佈《國際人工智能開源合作倡議》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 10 日，上海市政府新聞辦舉行 2025 世界人工智能大會暨人工智能全球治理高級別會議新聞發佈會，介紹大會籌備進展情況。&lt;/p&gt; 
&lt;p&gt;工業和信息化部科技司副司長杜廣達表示，本屆大會上，工信部將總結國家人工智能產業發展和賦能應用的趨勢和成果，推動國際交流合作。積極倡導全球人工智能的開源合作。以 DeepSeek 為代表的中國大模型，為全球用戶提供了高質價比的人工智能產品服務，有力推動人工智能技術在全球的普及應用，向世界貢獻了中國智慧。&lt;/p&gt; 
&lt;p&gt;為進一步推動全球共建開源生態，&lt;span style="color:#0000cc"&gt;&lt;strong&gt;工信部&lt;/strong&gt;&lt;/span&gt;將推動中國—金磚國家人工智能發展與合作中心建設，&lt;strong&gt;聯合開放原子開源基金會、中國開發者網絡、開源中國等機構&lt;/strong&gt;，在大會上發佈&lt;strong&gt;&lt;span style="color:#0000cc"&gt;《國際人工智能開源合作倡議》&lt;/span&gt;&lt;/strong&gt;，號召全球以開源為紐帶，共商技術創新路線，共促技術成果賦能，共建開放包容社區，共享時代發展紅利。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;來源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thepaper.cn%2FnewsDetail_forward_31147953" target="_blank"&gt;澎湃新聞&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359852</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359852</guid>
      <pubDate>Fri, 11 Jul 2025 07:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gitee Pipe：關鍵領域 DevSecOps 的核心引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：Gitee DevSecOps 團隊，李穎萍，吳茂佳&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;軟件工廠的核心是高效、安全，而關鍵領域行業的特殊性決定了軟件工廠必須將安全與保密放在首位。Gitee Pipe 提供標準化的 CI/CD 流水線，通過自動化技術精準控制開發各環節，確保關鍵領域軟件從代碼提交到最終交付的全路安全、高效、穩定。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;關鍵領域軟件交付的挑戰&lt;/h2&gt; 
&lt;p&gt;關鍵領域軟件關係國家安全與國防策略，對保密性、質量安全、合規性和期限成本等方面有極高要求，任何環節的缺陷都可能造成難以估量的損失。傳統 CI/CD 流程難以完全應對這些複雜要求，需要更加系統、可控、可應對的方案。&lt;/p&gt; 
&lt;p&gt;Gitee Pipe 作為新一代自動化引擎，通過「安全左移、合規內建、智能協同」三位一體的技術架構，靈活編排和管理代碼掃描、功能測試、編譯構建、發佈部署等工具類任務，實現軟件從代碼提交到產品部署的全流程自動化，助力企業實現高效、安全、智能的軟件交付，成為解決關鍵領域軟件交付難題的有力工具。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee Pipe：從標準化到智能化&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;標準化、自動化軟件生產過程，實現合規計算&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Gitee Pipe 內置的檢查模板培基於關鍵領域特殊需求，對軟件開發過程進行精精細的模型化維護，包括代碼質量、依賴管控、部署參數等各環節的規範設置，降低了人為操作風險，確保交付的穩定性。&lt;/p&gt; 
&lt;p&gt;&lt;img height="707" src="https://static.oschina.net/uploads/space/2025/0711/151512_UpCS_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過模塊化腳本和工具，Gitee Pipe 可實現代碼編譯、單元測試、集成測試等重複性工作的全路封裝。系統可自動引擎流水線，生成測試報告並反饋質量問題，同時節約人力成本，推動交付同步進入高效環節。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;生產過程安全可控，打造可跟蹤生產設備&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Gitee Pipe 培基於 Gitee 代碼庫與製品庫的安全能力，封共從代碼評審、依賴拉取到製品部署全鏈路。通過 BuildData 體系，每次構建都有明確的代碼、環境、依賴、壓縮包、發佈記錄等數據支持，實現全鏈路可查可跟蹤，減少調試或驚魂問題排查成本。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0711/151539_Io7V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能協同交付，打通需求、代碼、製品、部署&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Gitee Pipe 支持與需求管理、質量管理等第三方系統打通，實現信息得以流通，支撐團隊高效協同。同時，通過系統合成，完成需求、代碼、製品、部署的八連相接，打造四維跟蹤體系，確保軟件交付過程真正可精準控制。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Pipe+AI：通向智能交付的新時代&lt;/h2&gt; 
&lt;p&gt;Gitee Pipe 添入自然語言處理技術後，支持開發人員通過自然語言指令操作流水線，例如輸入「檢查最近提交代碼是否存在安全漏洞」，系統可自動啓動代碼掃描工作流程並給出結果。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0711/151553_izjT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 還可根據正在執行的流水線情況，自動分析執行錯誤，給出修復建議；培基於歷史執行數據，生成最佳模板和流程設置建議，推動流水線持續優化。未來還可改善安全防護設施，創建智能化安全運維體系，推動關鍵領域軟件交付全鏈路向更智能、更安全、更高效方向發展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0711/151604_RDas_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitee.cn%2Ffactory" target="_blank"&gt;https://gitee.cn/factory&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359849</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359849</guid>
      <pubDate>Fri, 11 Jul 2025 07:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>歐盟公佈最終版《通用人工智能行為準則》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;歐盟委員會 10 日公佈《通用人工智能行為準則》最終版本，旨在幫助企業遵守歐盟《人工智能法案》的相關規定。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該準則為通用人工智能模型提供透明度、版權及安全與保障三方面的自律指導，適用於包括美國開放人工智能研究中心的 ChatGPT、谷歌的 Gemini、「元」公司的 Llama 以及 xAI 公司推出的 Grok 等主流通用人工智能模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據歐盟《人工智能法案》，通用人工智能模型是指能執行廣泛任務並可被集成至下游應用系統的人工智能模型。這類模型通常基於大規模、多樣化的數據集進行訓練，是語言生成、多模態內容創作等人工智能服務的核心。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;歐盟委員會表示，最終版本的準則由 13 位獨立專家起草，採納了包括人工智能開發者、學術界、民間組織、版權持有者以及安全專家等 1000 多位利益相關方的意見和建議。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據悉，該準則仍需獲得歐盟成員國及歐盟委員會批准。歐盟稱屆時企業可自願簽署，以減少行政負擔並獲得更大的法律確定性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;歐盟的《人工智能法案》於去年正式生效，其中有關通用人工智能的治理與合規條款將於今年 8 月 2 日起正式實施。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359848</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359848</guid>
      <pubDate>Fri, 11 Jul 2025 07:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源流存儲項目 Fluss 正式加入 Apache 孵化器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;由阿里巴巴開源並捐贈的新一代流存儲 Fluss 項目，順利通過了投票，正式成為全球最大的開源基金會 Apache 軟件基金會（ASF）的孵化項目！這是 Fluss 社區發展的重要里程碑，標誌着項目邁入更加開放、中立和規範的新階段。未來，Fluss 將依託 Apache 生態，加速構建全球化的開發者社區，持續推動新一代實時數據基礎設施的創新與落地。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d6c9e868f11150ce9ea8e7b7d7dbc218.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Fluss 社區已於近日完成了所有捐贈的流程，並將 Fluss 項目正式移交到了 Apache 軟件基金會名下。在 7 月 3 日於新加坡舉辦的 Flink Forward Asia 2025 的主題演講中，項目發起人，伍翀（雲邪）正式宣佈了這一激動的消息，並分享了新倉庫地址（https://github.com/apache/fluss/）和官方網站域名（https://fluss.apache.org/）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//3e3dddc4fea638df872e33210fbe0e3b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;什麼是 Fluss？&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//8f73383e6304d7500811bc429a200f70.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Fluss 是一款面向實時分析場景設計的下一代流存儲引擎，致力於解決傳統流存儲技術在流計算、Lakehouse 等分析場景中面臨的高成本與低效率問題。它具備以下核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;列式流存儲：支持毫秒級延遲的實時流讀流寫能力，以 Apache Arrow 列存格式存儲實時流數據，通過列裁剪、分區裁剪等查詢下推技術，可提升 10 倍讀取性能並降低網絡成本。&lt;/li&gt; 
 &lt;li&gt;實時更新與點查：創新性地將實時更新能力引入流存儲中。通過高性能流式更新、部分列更新、binlog、維表點查以及 DeltaJoin 等特性，高效協同 Flink 構建低成本流式實時數倉。&lt;/li&gt; 
 &lt;li&gt;湖流一體：湖與流一體化存儲，實現數據共享。Lakehouse 為流存儲提供低成本的歷史數據支持，而流存儲則為 Lakehouse 注入實時數據能力，帶來實時數據分析的體驗，構建流批一體秒級湖倉。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Fluss 的發展歷史與現狀&lt;/h2&gt; 
&lt;p&gt;2023 年 7 月，阿里雲智能 Flink 團隊正式啓動了 Fluss 項目。項目名稱源自 "&lt;strong&gt;Fl&lt;/strong&gt;ink&lt;strong&gt;U&lt;/strong&gt;nified&lt;strong&gt;S&lt;/strong&gt;treaming&lt;strong&gt;S&lt;/strong&gt;torage"的縮寫，寓意為 Apache Flink 打造統一的流式存儲底座。巧合的是，"Fluss"在德語中意為" 河流 "，正如源源不斷的數據流。&lt;/p&gt; 
&lt;p&gt;經過一年多的內部孵化與打磨，2024 年 11 月 29 日，在上海舉辦的 Flink Forward Asia 2024 大會主題演講中，阿里巴巴正式宣佈&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU3Mzg4OTMyNQ%3D%3D%26mid%3D2247512139%26idx%3D2%26sn%3D43f5f39c8b78ac340b5b2486e9aab82a%26scene%3D21%23wechat_redirect" target="_blank"&gt;開源 Fluss 項目&lt;/a&gt;。自此，Fluss 迎來了多元化的國際化發展，吸引了來自全球的 60 多位開發者貢獻代碼，社區活躍度持續提升，平均每三個月發佈一個重大版本。&lt;/p&gt; 
&lt;p&gt;與此同時，Fluss 在阿里巴巴集團內部也實現了大規模落地應用。目前，已支持超過 3 PB 數據規模，集羣吞吐峯值達 40 GB/s，最大單表點查 QPS 達到 50 萬次 / 秒，單表數據量最高可達 5000 億條。在日誌流量分析、搜索推薦、實時數倉等關鍵業務場景，Fluss 展現出卓越的性能與能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//858f7e5fbeedce0ed1d8a419a7806f3f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;為什麼加入 ASF 孵化器？&lt;/h2&gt; 
&lt;p&gt;Apache 軟件基金會是全球開源大數據技術的搖籃，孕育了眾多改變世界的項目：Hadoop, Spark, Iceberg, Kafka, Flink 等。Fluss 期待加入 ASF，成為改變未來實時基礎設施的一員。與此同時，Fluss 與這些 Apache 項目之間有着深度集成的需求，加入 ASF 能夠加速與生態集成的進程。更重要的是，ASF 所倡導的 "開放、協作、中立" 理念，與 Fluss 的發展願景高度契合。通過加入 Apache 孵化器，Fluss 不僅延續這一開源精神，也將融入更廣闊的開發者社區，獲得更完善的治理機制與可持續發展的堅實保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359845</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359845</guid>
      <pubDate>Fri, 11 Jul 2025 06:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniCPM 端側客戶端正式發佈並開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MiniCPM 端側客戶端已正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0J_CpJpvaKAP61oK1RjnGg" target="_blank"&gt;發佈&lt;/a&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全面支持 Intel Core Ultra 系列處理器本地部署，低延遲、高效率、隱私更安全。&lt;/li&gt; 
 &lt;li&gt;基於 OpenVINO 推理框架深度優化，推理速度至高可達每秒 80 tokens！&lt;/li&gt; 
 &lt;li&gt;專為開發者、研究人員與 AI 愛好者打造的本地大模型新體驗。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0711/144320_ZE4E_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;主要功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持，與模型進行文本&amp;amp;圖片對話&lt;/li&gt; 
 &lt;li&gt;支持，調用 Intel 集成顯卡加速&lt;br&gt; 支持模型： 
  &lt;ul&gt; 
   &lt;li&gt;MiniCPM 4.0 8B &amp;amp; 0.5B&lt;/li&gt; 
   &lt;li&gt;MiniCPM 3.0 4B&lt;/li&gt; 
   &lt;li&gt;MiniCPM-V 2.6 8B（多模態）&lt;/li&gt; 
   &lt;li&gt;MiniCPM-V 2.0 2.8B（多模態）&lt;/li&gt; 
   &lt;li&gt;MiniCPM-2B-128K&lt;/li&gt; 
   &lt;li&gt;MiniCPM-1B-SFT-BF16&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;配置要求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;建議使用英特爾酷睿 ultra7 及以上移動端處理器&lt;/li&gt; 
 &lt;li&gt;建議運行內存 32GB 及以上&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FMiniCPM%2Freleases%2Ftag%2F2.4.2" target="_blank"&gt;https://github.com/OpenBMB/MiniCPM/releases/tag/2.4.2&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359843</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359843</guid>
      <pubDate>Fri, 11 Jul 2025 06:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中國團隊發佈中微子動能轉化發電技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;國內一家能源科技公司「宇太能源」近日宣佈，該團隊利用「中微子泵」技術製造的發電設備，實現連續 24 小時運轉，併產生了平均 7.2kw 的電力淨輸出。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;宇太能源負責人介紹，經過 8 年研發孵化和技術改進，當前規模化設備發電成本已降低至 0.195 元/kwh，具備了商業化的技術可行性和經濟可行性。負責人稱，更大型化的設備正在研發中。隨着「中微子泵」發電技術的改進及商業化，未來有使發電成本繼續大幅下降的潛力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//61ea1ca9d2fb62c13b37f9b9795b2207.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;據瞭解，中微子又稱「幽靈粒子」，質量極小，數量極大，在宇宙中以接近光速運動，具有極大的穿透力。據科學家研究統計，地球表面每平方釐米有 600 億個中微子穿透。利用穿透地球的中微子等宇宙輻射能量轉化為電力，是一種取之不盡的清潔能源。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;自 1930 年中微子假説首次被提出，科學家的「幽靈」追尋之旅已走近百年曆史。1998 年至今，已經有 5 個諾貝爾物理學獎頒發給了中微子領域的研究。中國科學院也在廣東也建設了對中微子捕捉和研究的實驗基地。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//6776a3cd52ec4b0654fcb07cabbf945b.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;圖：中微子模擬圖（來源於 AI）&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;目前，在歐洲、美國、俄羅斯等地，已有多家研究機構和企業對以中微子為能量來源的發電技術進行研究和商業化，並取得了突破性進展。中微子電力作為一種潛力巨大的清潔能源，正逐漸走向台前。如能實現技術的規模化、低成本普及，中微子發電技術將對當前工業、生活及運輸等領域產生重大影響。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;當前，化石燃料仍是我國能源系統的主力，作為定海神針支撐我國能源供給穩定。作為新能源主力的風電及光電，大幅降低了二氧化碳排放，佔中國能源來源的比例不斷提升但由於受光照及風速等外部環境影響較大，電力輸出負荷有波動，對電網穩定性也產生了不小的挑戰。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;作為未來電力技術的前沿，可控核聚變技術被寄以厚望。在眾多風險資本、企業巨頭和政府數百億投資的加持下，我國可控核聚變技術企業實現了多項突破，正在快速奔跑，也使我國進入了該領域的第一梯隊。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//63bfa750f815a95dd8bdd57a8d58f9fc.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;圖：可控核聚變裝置（來源於網絡）&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;宇太能源負責人稱，「中微子」泵發電技術利用巨量且高速穿透地球的中微子等宇宙粒子流產生電力能源，不需要化石燃料，不涉及高溫高壓，取之不盡用之不竭，也沒有二氧化碳排放。中微子電力作為正走向台前的新型清潔能源，有潛力與可控核聚變技術共同成為我國和全球下一代清潔能源的主力軍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359810</guid>
      <pubDate>Fri, 11 Jul 2025 03:54:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>vivo Pulsar 萬億級消息處理實踐（3）-KoP 指標異常修復</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網大數據團隊- Chen Jianbo&lt;/p&gt; 
 &lt;p&gt;本文是《vivo Pulsar 萬億級消息處理實踐》系列文章第 3 篇。&lt;/p&gt; 
 &lt;p&gt;Pulsar 是 Apache 基金會的開源分佈式流處理平台和消息中間件，它實現了 Kafka 的協議，可以讓使用 Kafka API 的應用直接遷移至 Pulsar，這使得 Pulsar 在 Kafka 生態系統中更加容易被接受和使用。KoP 提供了從 Kafka 到 Pulsar 的無縫轉換，用戶可以使用 Kafka API 操作 Pulsar 集羣，保留了 Kafka 的廣泛用戶基礎和豐富生態系統。它使得 Pulsar 可以更好地與 Kafka 進行整合，提供更好的消息傳輸性能、更強的兼容性及可擴展性。vivo 在使用 Pulsar KoP 的過程中遇到過一些問題，本篇主要分享一個分區消費指標缺失的問題。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;系列文章：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247501335%26idx%3D1%26sn%3D3701be0b8b7b789e29c1ca53ba142e9d%26scene%3D21%23wechat_redirect" target="_blank"&gt;vivo Pulsar 萬億級消息處理實踐（1）-數據發送原理解析和性能調優&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247501426%26idx%3D1%26sn%3D76c04879cfa2c6b38a731b5c49f19d3a%26scene%3D21%23wechat_redirect" target="_blank"&gt;vivo Pulsar 萬億級消息處理實踐（2）-從 0 到 1 建設 Pulsar 指標監控鏈路&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;文章太長？1 分鐘看圖抓住核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9cc55a5274f293b9c0ef2789a68fa19c.gif" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、問題背景&lt;/h1&gt; 
&lt;p&gt;在一次版本灰度升級中，我們發現某個使用 KoP 的業務 topic 的消費速率出現了顯著下降，具體情況如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-7459cc8dccb2e8b05af39aa90db0851bbe7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;什麼原因導致正常的升級重啓服務器會出現這個問題呢？直接查看上報採集的數據報文：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;kop_server_MESSAGE_OUT{group="",partition="0",tenant="kop",topic="persistent://kop-tenant/kop-ns/service-raw-stats"} 3
kop_server_BYTES_OUT{group="",partition="0",tenant="kop",topic="persistent://kop-tenant/kop-ns/service-raw-stats"} 188
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我們看到，KoP 消費指標 kop_server_MESSAGE&lt;/p&gt; 
&lt;p&gt;_OUT、kop_server_BYTES_OUT 是有上報的，但指標數據裏的 group 標籤變成了空串（缺少消費組名稱），分區的消費指標就無法展示了。是什麼原因導致了消費組名稱缺失？&lt;/p&gt; 
&lt;h1&gt;二、問題分析&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;1、找到問題代碼&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們去找下這個消費組名稱是在哪裏獲取的，是否邏輯存在什麼問題。根據 druid 中的 kop_subscription 對應的消費指標 kop_server_&lt;/p&gt; 
&lt;p&gt;MESSAGE_OUT、kop_server_BYTES_OUT，找到相關代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private void handleEntries(final List&amp;lt;Entry&amp;gt; entries,
                               final TopicPartition topicPartition,
                               final FetchRequest.PartitionData partitionData,
                               final KafkaTopicConsumerManager tcm,
                               final ManagedCursor cursor,
                               final AtomicLong cursorOffset,
                               final boolean readCommitted) {
....
        // 處理消費數據時，獲取消費組名稱
        CompletableFuture&amp;lt;String&amp;gt; groupNameFuture = requestHandler
                .getCurrentConnectedGroup()
                .computeIfAbsent(clientHost, clientHost -&amp;gt; {
                    CompletableFuture&amp;lt;String&amp;gt; future = new CompletableFuture&amp;lt;&amp;gt;();
                    String groupIdPath = GroupIdUtils.groupIdPathFormat(clientHost, header.clientId());
                    requestHandler.getMetadataStore()
                            .get(requestHandler.getGroupIdStoredPath() + groupIdPath)
                            .thenAccept(getResultOpt -&amp;gt; {
                                if (getResultOpt.isPresent()) {
                                    GetResult getResult = getResultOpt.get();
                                    future.complete(new String(getResult.getValue() == null
                                            ? new byte[0] : getResult.getValue(), StandardCharsets.UTF_8));
                                } else {
                                    // 從 zk 節點 /client_group_id/xxx 獲取不到消費組，消費組就是空的
                                    future.complete("");
                                }
                            }).exceptionally(ex -&amp;gt; {
                                future.completeExceptionally(ex);
                                return null;
                            });
                    returnfuture;
                });

        // this part is heavyweight, and we should not execute in the ManagedLedger Ordered executor thread
        groupNameFuture.whenCompleteAsync((groupName, ex) -&amp;gt; {
            if (ex != null) {
                log.error("Get groupId failed.", ex);
                groupName = "";
            }
.....
            // 獲得消費組名稱後，記錄消費組對應的消費指標
            decodeResult.updateConsumerStats(topicPartition,
                    entries.size(),
                    groupName,
                    statsLogger);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;代碼的邏輯是，從 requestHandler 的 currentConnectedGroup(map) 中通過 host 獲取 groupName，不存在則通過 MetadataStore（帶緩存的 zk 存儲對象）獲取，如果 zk 緩存也沒有，再發起 zk 讀請求（路徑為/client_group_id/host-clientId）。讀取到消費組名稱後，用它來更新消費組指標。從復現的集羣確定走的是這個分支，即是從 metadataStore(帶緩存的 zk 客戶端) 獲取不到對應 zk 節點/client_group_id/xxx。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、查找可能導致 zk 節點/client_group_id/xxx 節點獲取不到的原因&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有兩種可能性：一是沒寫進去，二是寫進去但是被刪除了。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    @Override
    protected void handleFindCoordinatorRequest(KafkaHeaderAndRequest findCoordinator,
                                                CompletableFuture&amp;lt;AbstractResponse&amp;gt; resultFuture) {
...
        // Store group name to metadata store for current client, use to collect consumer metrics.
        storeGroupId(groupId, groupIdPath)
                .whenComplete((stat, ex) -&amp;gt; {
                    if (ex != null) {
                        // /client_group_id/xxx 節點寫入失敗
                        log.warn("Store groupId failed, the groupId might already stored.", ex);
                    }
                    findBroker(TopicName.get(pulsarTopicName))
                            .whenComplete((node, throwable) -&amp;gt; {
                                ....
                            });
                });
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從代碼看到，clientId 與 groupId 的關聯關係是通過 handleFindCoordinatorRequest（FindCoordinator）寫進去的，而且只有這個方法入口。由於沒有找到 warn 日誌，排除了第一種沒寫進去的可能性。看看刪除的邏輯：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;protected void close(){
    if (isActive.getAndSet(false)) {
        ...
        currentConnectedClientId.forEach(clientId -&amp;gt; {
            String path = groupIdStoredPath + GroupIdUtils.groupIdPathFormat(clientHost, clientId);
            // 刪除 zk 上的 /client_group_id/xxx 節點
            metadataStore.delete(path, Optional.empty())
                    .whenComplete((__, ex) -&amp;gt; {
                        if (ex != null) {
                            if (ex.getCause() instanceof MetadataStoreException.NotFoundException) {
                                if (log.isDebugEnabled()) {
                                    log.debug("The groupId store path doesn't exist. Path: [{}]", path);
                                }
                                return;
                            }
                            log.error("Delete groupId failed. Path: [{}]", path, ex);
                            return;
                        }
                        if (log.isDebugEnabled()) {
                            log.debug("Delete groupId success. Path: [{}]", path);
                        }
                    });
        });
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;刪除是在 requsetHandler.close 方法中執行，也就是説連接斷開就會觸發 zk 節點刪除。&lt;/p&gt; 
&lt;p&gt;但有幾個&lt;strong&gt;疑問：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;/client_group_id/xxx 到底是幹嘛用的？消費指標為什麼要依賴它&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為什麼要在 handleFindCoordinatorRequest 寫入？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;節點/client_group_id/xxx 為什麼要刪除，而且是在連接斷開時刪除，刪除時機是否有問題？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;首先回答第 1 個問題，通過閲讀代碼可以知道，/client_group_id/xxx 這個 zk 節點是用於在不同 broker 實例間交換數據用的 (相當 redis cache)，用於臨時存放 IP+clientId 與 groupId 的映射關係。由於 fetch 接口（拉取數據）的 request 沒有 groupId 的，只能依賴加入 Group 過程中的元數據，在 fetch 消費時才能知道當前拉數據的 consumer 是哪個消費組的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ffc0dfd7d8ea6675518bf1a2621d6f9be67.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、復現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;若要解決問題，最好能夠穩定地復現出問題，這樣才能確定問題的根本原因，並且確認修復是否完成。&lt;/p&gt; 
&lt;p&gt;因為節點是在 requsetHandle.close 方法中執行刪除，broker 節點關閉會觸發連接關閉，進而觸發刪除。假設：客戶端通過 brokerA 發起 FindCoordinator 請求，寫入 zk 節點/client_group&lt;/p&gt; 
&lt;p&gt;_id/xxx，同時請求返回 brokerB 作為 Coordinator，後續與 brokerB 進行 joinGroup、syncGroup 等交互確定消費關係，客戶端在 brokerA、brokerB、brokerC 都有分區消費。這時重啓 brokerA，分區均衡到 BrokerC 上，但此時/client_group_id/xxx 因關閉 broker 而斷開連接被刪除，consumer 消費剛轉移到 topic1-partition-1 的分區就無法獲取到 groupId。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9beb2b836116dbb5a58a6e794e16d006de7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;按照假設，有 3 個 broker，開啓生產和消費，通過在 FindCoordinator 返回前獲取 node.leader() 的返回節點 BrokerB，關閉 brokerA 後，brokerC 出現斷點復現，再關閉 brokerC，brokerA 也會復現（假設分區在 brokerA 與 brokerC 之間轉移）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//48e469db783cf92252e89bf874a31591.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;復現要幾個條件：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;broker 數量要足夠多 (不小於 3 個）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;broker 內部有 zk 緩存 metadataCache 默認為 5 分鐘，可以把時間調小為 1 毫秒，相當於沒有 cache&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;findCoordinator 返回的必須是其他 broker 的 IP&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;重啓的必須是接收到 findCoordinator 請求那台 broker，而不是真正的 coordinator，這時會從 zk 刪除節點&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分區轉移到其他 broker，這時新的 broker 會重新讀取 zk 節點數據&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;到此，我們基本上清楚了問題原因：連接關閉導致 zk 節點被刪除了，別的 broker 節點需要時就讀取不到了。那怎麼解決？&lt;/p&gt; 
&lt;h1&gt;三、問題解決&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;方案一&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;既然知道把消費者與 FindCoordinator 的連接進行綁定不合適的，那麼是否應該把 FindCoordinator 寫入 zk 節點換成由 JoinGroup 寫入，斷連即刪除。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e408f5ca0dd6d8ce1dacd59b9e1d1067.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;consumer 統一由 Coordinator 管理，由於 FindCoordinator 接口不一定是 Coordinator 處理的，如果換成由 Coordinator 處理的 JoinGroup 接口是否就可以了，這樣 consumer 斷開與 Coordinator 的連接就應該刪除數據。但實現驗證時卻發現，客戶端在斷連後也不會再重連，所以沒法重新寫入 zk，不符合預期。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;方案二&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;還是由 FindCoordinator 寫入 zk 節點，但刪除改為 GroupCoordinator 監聽 consumer 斷開觸發。&lt;/p&gt; 
&lt;p&gt;因為 consumer 統一由 Coordinator 管理，它能監聽到 consumer 加入或者離開。GroupCoordinator 的 removeMemberAndUpdateGroup 方法是 coordinator 對 consumer 成員管理。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private void removeMemberAndUpdateGroup(GroupMetadata group,
                                        MemberMetadata member) {
    group.remove(member.memberId());
    switch (group.currentState()) {
        case Dead:
        case Empty:
            return;
        case Stable:
        case CompletingRebalance:
            maybePrepareRebalance(group);
            break;
        case PreparingRebalance:
            joinPurgatory.checkAndComplete(new GroupKey(group.groupId()));
            break;
        default:
            break;
    }
    // 刪除 /client_group_id/xxx 節點
    deleteClientIdGroupMapping(group, member.clientHost(), member.clientId());
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;調用入口有兩個，其中 handleLeaveGroup 是主動離開，onExpireHeartbeat 是超時被動離開，客戶端正常退出或者宕機都可以調用 removeMemberAndUpdateGroup 方法觸發刪除。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public CompletableFuture&amp;lt;Errors&amp;gt; handleLeaveGroup(
    String groupId,
    String memberId
) {
    return validateGroupStatus(groupId, ApiKeys.LEAVE_GROUP).map(error -&amp;gt;
        CompletableFuture.completedFuture(error)
    ).orElseGet(() -&amp;gt; {
        return groupManager.getGroup(groupId).map(group -&amp;gt; {
            return group.inLock(() -&amp;gt; {
                if (group.is(Dead) || !group.has(memberId)) {
                    return CompletableFuture.completedFuture(Errors.UNKNOWN_MEMBER_ID);
                } else {
                    ...
                
                    // 觸發刪除消費者 consumer
                    removeMemberAndUpdateGroup(group, member);
                    return CompletableFuture.completedFuture(Errors.NONE);
                }
            });
        })
        ....
    });
}

void onExpireHeartbeat(GroupMetadata group,
                       MemberMetadata member,
                       long heartbeatDeadline) {
    group.inLock(() -&amp;gt; {
        if (!shouldKeepMemberAlive(member, heartbeatDeadline)) {
            log.info("Member {} in group {} has failed, removing it from the group",
                member.memberId(), group.groupId());
            // 觸發刪除消費者 consumer
            removeMemberAndUpdateGroup(group, member);
        }
        return null;
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;但這個方案有個問題是，日誌運維關閉 broker 也會觸發一個 onExpireHeartbeat 事件刪除 zk 節點，與此同時客戶端發現 Coordinator 斷開了會馬上觸發 FindCoordinator 寫入新的 zk 節點，但如果刪除晚於寫入的話，會導致誤刪除新寫入的節點。我們乾脆在關閉 broker 時，使用 ShutdownHook 加上 shuttingdown 狀態防止關閉 broker 時刪除 zk 節點，只有客戶端斷開時才刪除。&lt;/p&gt; 
&lt;p&gt;這個方案修改上線半個月後，還是出現了一個客戶端的消費指標無法上報的情況。後來定位發現，如果客戶端因 FullGC 出現卡頓情況，客戶端可能會先於 broker 觸發超時，也就是先超時的客戶端新寫入的數據被後監聽到超時的 broker 誤刪除了。因為寫入與刪除並不是由同一個節點處理，所以無法在進程級別做併發控制，而且也無法判斷哪次刪除對應哪次的寫入，所以用 zk 也是很難實現併發控制。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;方案三&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;其實這並不是新的方案，只是在方案二基礎上優化：數據一致性檢查。&lt;/p&gt; 
&lt;p&gt;既然我們很難控制好寫入與刪除的先後順序，我們可以做數據一致性檢查，類似於交易系統裏的對賬。因為 GroupCoordinator 是負責管理 consumer 成員的，維護着 consumer 的實時狀態，就算 zk 節點被誤刪除，我們也可以從 consumer 成員信息中恢復，重新寫入 zk 節點。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private void checkZkGroupMapping(){  
    for (GroupMetadata group : groupManager.currentGroups()) {  
        for (MemberMetadata memberMetadata : group.allMemberMetadata()) {  
            String clientPath = GroupIdUtils.groupIdPathFormat(memberMetadata.clientHost(), memberMetadata.clientId());  
            String zkGroupClientPath = kafkaConfig.getGroupIdZooKeeperPath() + clientPath;  
            // 查找 zk 中是否存在節點
            metadataStore.get(zkGroupClientPath).thenAccept(resultOpt -&amp;gt; {  
                if (!resultOpt.isPresent()) {  
                    // 不存在則進行補償修復
                    metadataStore.put(zkGroupClientPath, memberMetadata.groupId().getBytes(UTF\_8), Optional.empty())  
                            .thenAccept(stat -&amp;gt; {  
                                log.info("repaired clientId and group mapping: {}({})",  
                                        zkGroupClientPath, memberMetadata.groupId());  
                            })  
                            .exceptionally(ex -&amp;gt; {  
                                log.warn("repaired clientId and group mapping failed: {}({})",  
                                        zkGroupClientPath, memberMetadata.groupId());  
                                return null;  
                            });  
                }  
            }).exceptionally(ex -&amp;gt; {  
                log.warn("repaired clientId and group mapping failed: {} ", zkGroupClientPath, ex);  
                return null;  
            });  
        }  
    }  
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;經過方案三的優化上線，即使是歷史存在問題的消費組，個別分區消費流量指標缺少 group 字段的問題也得到了修復。具體效果如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//67385096ca5f780cc62269343e58cde7.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;四、總結&lt;/h1&gt; 
&lt;p&gt;經過多個版本的優化和線上驗證，最終通過方案三比較完美的解決了這個消費指標問題。在分佈式系統中，併發問題往往難以模擬和復現，我們也在嘗試多個版本後才找到有效的解決方案。如果您在這方面有更好的經驗或想法，歡迎提出，我們共同探討和交流。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18684129</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18684129</guid>
      <pubDate>Fri, 11 Jul 2025 03:47:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>微軟開源輕量級推理模型 Phi-4-mini-flash-reasoning</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟發佈了一款專為受限環境設計、參數量僅為 3.8B 的輕量級開源模型 Phi-4-mini-flash-reasoning，其在數學推理任務上表現出色，且吞吐量大幅提升。&lt;/p&gt; 
&lt;p&gt;Phi-4-mini-flash-reasoning 專為在內存和計算資源受限的環境下執行高強度、多步驟的數學推理任務而設計。該模型採用了混合 SambaY 架構，結合了差分注意力、狀態空間模型（SSM）和分組查詢注意力（GQA），並支持 64K 的上下文長度。&lt;/p&gt; 
&lt;p&gt;Phi-4-mini-flash-reasoning 的訓練數據完全由更強大的推理模型 Deepseek-R1 生成的合成數學內容構成，旨在從更強的模型中提煉知識。&lt;/p&gt; 
&lt;p&gt;在 AIME、Math500 和 GPQA Diamond 等多個數學推理基準測試中，Phi-4-mini-flash-reasoning 的表現與許多參數量遠大於它的模型相當。與 Phi-4-mini-reasoning 相比，新模型在處理長序列生成任務時，吞吐量提升高達 10 倍，且延遲增長接近線性。&lt;/p&gt; 
&lt;p&gt;&lt;img height="787" src="https://static.oschina.net/uploads/space/2025/0711/111702_PrZL_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0711/111739_1PUS_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該模型已在 Hugging Face 上以 MIT 許可證發佈，並可在 Azure AI Foundry 中使用。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning&lt;br&gt; https://azure.microsoft.com/en-us/blog/reasoning-reimagined-introducing-phi-4-mini-flash-reasoning/&lt;br&gt; https://aka.ms/flashreasoning-paper&lt;br&gt; https://github.com/microsoft/PhiCookBook&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359805</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359805</guid>
      <pubDate>Fri, 11 Jul 2025 03:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>可靈 AI 上線可圖 2.1 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;可靈 AI 上線可圖 2.1 模型，在指令遵循能力、響應能力等方面進行了升級，同時新模型還進一步增強了文字生成效果。新模型的推出讓會員用戶能夠在 7 月 17 日之前免費體驗，為用戶提供了文生圖、單圖參考和多圖參考等核心功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-8e8dcbf6bf63f5ea25a5b01a05b97ae1da9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;可圖 2.1 在理解複雜指令方面表現突出，可以準確捕捉提示詞中的各種元素和邏輯關係。例如，當輸入 「3D 微縮沙盤模型，展示其獨特的橫截面剖面，海底火山爆發的劇烈瞬間，史詩級災難場景，CG 特效，光影對比，冷暖對比」 時，生成的圖像清晰展現了宏大的災難場景，並通過光影和色調的細膩處理，真實再現了火山爆發的震撼瞬間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在畫面質量方面，模型在清晰度、元素豐富度和細節真實感等方面均取得了突破。特別是在展示人像時，無論是水下攝影中一位少女的光影效果，還是復古風格照片中女性的優雅姿態，均能細膩呈現。模型還具備生成電影質感圖像的能力，能夠通過高級構圖與光影色彩運用，為畫面賦予強烈的美學調性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，文字生成能力的提升使得用戶可以快速生成清晰、設計感十足的中英文文字，這對製作海報、電影宣傳和唱片封面等創意內容非常有幫助。可圖 2.1 支持超過 180 種風格響應，涵蓋特殊材質、數字藝術和繪畫技法等類型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359804</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359804</guid>
      <pubDate>Fri, 11 Jul 2025 03:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智譜上線類似 Manus 的 PPT 生成功能 AI Slides，免費使用無限制</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智譜悄然上線了一項全新的 PPT 生成功能 ——AI Slides。該功能借助最新的 GLM-Experimental 模型，能夠根據用戶提供的研究主題或文檔，快速生成高質量的 PPT 展示。這一新功能目前可以免費使用，並且沒有使用限制。&lt;/p&gt; 
&lt;p&gt;&lt;img height="277" src="https://oscimg.oschina.net/oscnet/up-db9e3a332510563defec56f8b09fe2d4950.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在使用 AI Slides 時，用戶只需輸入相關的主題或文檔，該功能便會首先分析內容，生成結構大綱。這一過程確保了 PPT 的邏輯性與條理性。隨後，系統會根據大綱自動生成各個頁面，極大地簡化了傳統 PPT 製作過程中需要投入的時間和精力。&lt;/p&gt; 
&lt;p&gt;在排版效果上，AI Slides 生成的 PPT 結構清晰，主次分明，便於觀眾理解。此外，系統會運用圖表展示數據，讓信息的傳達更加直觀。同時，通過色塊和字體顏色的巧妙運用，突出重點信息，並適當留白，使得整體佈局更加協調。這些設計理念都充分考慮了觀眾的閲讀體驗，旨在提升 PPT 的觀賞性和實用性。&lt;/p&gt; 
&lt;p&gt;目前，GLM-Experimental 模型尚未正式發佈，但用戶可以在智譜的聊天界面中進行體驗。為了使用這一新功能，用戶只需訪問 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.z.ai" target="_blank"&gt;https://chat.z.ai&lt;/a&gt;，登錄後切換到 GLM-Experimental 模型，並點擊 「AI Slides」 圖標即可開始製作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359795</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359795</guid>
      <pubDate>Fri, 11 Jul 2025 02:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Windows 11 最新「黑屏死機」界面現已推出</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟現在開始將其藍屏死機 (BSOD) 更改為全新設計的黑色版本。這是自微軟在 Windows 8 中添加悲傷表情以來對 BSOD 的首次重大更改，刪除表情和二維碼後轉而採用更簡化的黑色屏幕。&lt;/p&gt; 
&lt;p&gt;新的 BSOD 現已向 Windows 11 Release Preview 用戶推出，這意味着它將在幾周內出現在所有 Windows 11 用戶面前。簡化的 BSOD 看起來很像您在 Windows 更新期間通常會看到的黑屏。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b6af25fcf60b165d0c0e8ddd4c0be715da0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;它會列出停止代碼和故障系統驅動程序，方便 Windows 用戶和 IT 管理員追溯電腦藍屏死機 (BSOD) 的根源。「這實際上是為了更清晰地提供更準確的信息，讓我們和客戶能夠真正瞭解問題的核心，以便更快地解決問題」，微軟企業和操作系統安全副總裁 David Weston 在 6 月份時表示。&lt;/p&gt; 
&lt;p&gt;微軟在 2021 年 Windows 11 測試版中曾短暫地將 BSOD 改為黑屏，但這次是永久性的。BSOD 的改變是 Windows 11 更新的一部分，該更新還包含微軟新的快速機器恢復 (QMR) 功能，該功能旨在快速恢復無法正常啓動的機器。QMR 是微軟在去年 CrowdStrike 事件後為提高 Windows 彈性而採取的更大努力的一部分。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359790</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359790</guid>
      <pubDate>Fri, 11 Jul 2025 02:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美政府內部再現信息安全漏洞 「AI 魯比奧」與多名官員聯絡</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據央視新聞消息，近日，美國政府內部再次出現信息安全漏洞。國務卿魯比奧在即時通信平台「信號」應用軟件上被冒名頂替，其聲音被人工智能技術模仿，隨後與多名政府官員聯絡。目前，美國國務院已就此事展開調查。&lt;/p&gt; 
&lt;p&gt;美國《華盛頓郵報》9 日報道稱，政府內部的一份電文顯示，今年 6 月中旬，有人在「信號」平台創建了一個極具迷惑性的賬戶，賬戶名刻意模仿了魯比奧的電子郵箱。隨後，藉助人工智能軟件，復刻了魯比奧的聲音，開始實施詐騙。官方記錄顯示，這個仿冒賬號聯絡了至少 5 名「非國務院人員」，其中包括一名州長以及一名國會議員。作案過程中，冒名頂替者通過留下語音信息、發送短信邀請等方式，試圖騙取對方信任，目的是「獲得信息或賬戶」。&lt;/p&gt; 
&lt;p&gt;事發後，美國國務院向各外交機構下達指示，要求下級單位向外交安全局上報是否有人曾被冒名頂替。&lt;/p&gt; 
&lt;p&gt;美國國務院發言人，塔米·布魯斯回應稱，「國務院已瞭解這一事件，目前正在調查中。我們正在認真履行信息保護的職責，不斷採取措施改善網絡安全狀況，以防範未來出現的各種情況，出於安全原因，現在暫無更多細節可以提供。」&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-10ac9da184c07b51b2bc8391d676ba7986a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359787</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359787</guid>
      <pubDate>Fri, 11 Jul 2025 02:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Chromium 引擎啓用 Skia Graphite 後性能飆升</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在一項被許多開發者關注的性能優化進展中，Chromium 項目正逐步將其圖形渲染後台從經典的 Ganesh 遷移至 Skia 新一代圖形後端 Graphite，而最新測試結果顯示，這一舉措帶來了顯著的性能提升。&lt;/p&gt; 
&lt;p&gt;Skia 是谷歌主導的跨平台 2D 圖形庫，長期以來一直是 Chromium 瀏覽器的核心組成部分。Ganesh 是 Skia 的傳統渲染後端，而 Graphite 是為現代 GPU 和圖形 API（如 Vulkan 和 Metal）量身打造的新架構，支持更高效的命令緩衝和多線程渲染策略。&lt;/p&gt; 
&lt;p&gt;近日在 Chromium 的每日構建版本中，默認啓用了 Skia Graphite 後端，適用於使用 Vulkan 或 Metal 的平台。根據谷歌工程師的評估，這一改動帶來了約 &lt;strong&gt;30% 的 Skia 渲染性能提升&lt;/strong&gt;，尤其在圖形密集型頁面和動畫渲染中效果顯著。這種提升不僅對瀏覽器的整體流暢性有直接好處，也對未來 WebGPU 等高級圖形功能的支持奠定了技術基礎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f76242842a1a18bdf12d51d895dbc56b21c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前 Graphite 支持 Vulkan（適用於 Linux 和 Windows）以及 Metal（適用於 macOS 和 iOS）。雖然 Web 渲染工作鏈仍在適配 Graphite，但其架構已被視作 Skia 發展的未來方向。谷歌也在積極推動更多平台（如 Android）納入 Graphite 支持。&lt;/p&gt; 
&lt;p&gt;值得注意的是，Graphite 並不僅僅是一次簡單的「後端替換」，而是重新構思了整個渲染數據流。它採用圖形管線狀態管理和「Render Tasks」機制，使得 GPU 能夠批處理更多渲染命令，從而最大化硬件利用率。這與 Ganesh 時代相對靜態的命令序列設計形成鮮明對比。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2f4c31571ba223d0feff7d4e5c352dd6619.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對於開發者而言，這意味着 Chromium 的圖形性能未來將更加依賴現代 GPU 特性，可能會激發新一輪對 GPU 渲染優化的關注。同時，Graphite 的模塊化設計也有望加速 Web 平台向更高性能圖形能力演進。&lt;/p&gt; 
&lt;p&gt;目前，這一更改已出現在 Chromium 的 Canary 和 Dev 通道版本中，並計劃在穩定版逐步鋪開。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;詳情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.chromium.org%2F2025%2F07%2Fintroducing-skia-graphite-chromes.html" target="_blank"&gt;https://blog.chromium.org/2025/07/introducing-skia-graphite-chromes.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359717/skia-graphite-chromes</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359717/skia-graphite-chromes</guid>
      <pubDate>Thu, 10 Jul 2025 10:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百川智能聯合創始人謝劍或將離職，多位聯創相繼出走</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息稱，百川智能技術聯合創始人謝劍將離職。其離職原因尚未公開，下一步動向也暫無明確消息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據瞭解，謝劍碩士畢業於武漢大學人工智能方向，2012 年獲得碩士學位後加入百度，後在職攻讀博士，並獲得清華大學計算機科學博士學位。謝劍曾是百度集團內最年輕晉升為主任研發架構師的工程師之一，深度參與並推動了鳳巢廣告、搜索、智能助手等核心 AI 業務的發展。2023 年 3 月，謝劍與王小川共同創立百川智能，擔任技術聯合創始人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="322" src="https://oscimg.oschina.net/oscnet/up-be6fa46b2101c0616723184ab78b8d9bacc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;百川智能近期高管動盪，據不完全統計，目前已經離開的包括聯合創始人、模型研發負責人陳煒鵬；商業合夥人、金融事業羣總裁鄧江；聯合創始人、商業化負責人洪濤等。有消息稱，百川智能聯合創始人茹立雲近期也在低調接觸外部機會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 4 月 10 日，百川智能 CEO&amp;nbsp;王小川發佈了一封內部信回顧了公司創立兩年來的功過得失。對於創業以來的不足，王小川進行了兩點反思。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他反思，第一是百川智能戰線拉得過長，不夠聚焦，「從通用基礎模型，到醫學增強的推理模型，到百小應和 AI 醫生應用，再到過早進入商業化，極大增加了組織的複雜度。」他在信中反思道。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;第二點，雖然 2024 年中戰略會已經明確了聚焦醫療，沒有足夠透傳在醫療上的決心和路徑要求，沒有讓每個團隊在醫療價值創造中深度思考「why」和「how」。進而部分團隊工作目標出現了搖擺和偏差。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359694</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359694</guid>
      <pubDate>Thu, 10 Jul 2025 08:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>逐本卸妝水以「輕旅護膚」切入旅遊市場，開啓便攜美妝新藍海</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;隨着國內旅遊市場全面復甦，2024 年暑期旅遊人次預計突破 12 億，年輕消費者對「輕裝出行」和「高效護膚」的需求激增。在此背景下，主打「天然溫和、便攜高效」的逐本卸妝水憑藉差異化定位迅速出圈，成為旅遊場景下的美妝新寵。近日，逐本發佈《2024 中國旅遊護膚消費趨勢報告》，數據顯示其卸妝水產品上半年旅遊渠道銷量同比增長 230%，印證了「旅行美妝」賽道的爆發潛力。&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center"&gt;&lt;img height="854" src="https://oscimg.oschina.net/oscnet//d389352aec160d32133ffbac2827f907.png" width="640" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;旅遊消費升級：卸妝場景從「將就」到「講究」&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;過去，旅遊人羣常因行李空間有限或追求便捷，選擇犧牲卸妝品質，甚至用洗面奶簡單替代。然而，隨着「精緻旅行」理念普及，消費者開始意識到：長途飛行、戶外暴曬及異地水質差異易導致肌膚敏感，專業卸妝成為剛需。&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;逐本敏鋭捕捉這一痛點，推出「旅行裝卸妝水」系列，採用 100ml 小容量設計，符合民航安檢標準，可隨身攜帶上飛機；配方上以「90% 天然植物水+5 重神經酰胺」為核心，兼顧清潔力與溫和性，30 秒即可卸除防曬、淡妝，避免過度摩擦損傷屏障。此外，產品包裝採用防漏密封技術，解決傳統卸妝水漏液困擾，成為戶外運動、城市漫遊等場景的理想選擇。&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;「旅遊場景的卸妝需求被嚴重低估。」逐本市場總監李然表示，「我們的調研顯示，76% 的遊客會因卸妝不便減少化妝頻率，而逐本旅行裝上市後，復購用戶中有 41% 明確表示‘為旅行囤貨’，這驗證了細分市場的巨大空間。」&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;渠道聯動：打通「線上種草+線下體驗」閉環&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;為搶佔旅遊市場先機，逐本構建了多維渠道網絡：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;線上精準觸達&lt;/li&gt; 
 &lt;li&gt;聯合小紅書、抖音發起#旅行卸妝急救包#話題，聯動 1000+旅行博主、美妝 KOL 創作場景化內容，播放量超 3 億次；同時與攜程、飛豬等 OTA 平台合作，推出「機票+卸妝水」聯名套餐，覆蓋超 500 萬出行人羣。&lt;/li&gt; 
 &lt;li&gt;線下場景滲透&lt;/li&gt; 
 &lt;li&gt;入駐全國 30 個核心城市的高鐵站、機場便利店及熱門景區美妝集合店，如三亞免稅城、杭州湖濱銀泰等；針對酒店場景，與華住、亞朵等連鎖品牌合作，在客房配備試用裝，提升品牌曝光度。&lt;/li&gt; 
 &lt;li&gt;跨界聯名破圈&lt;/li&gt; 
 &lt;li&gt;攜手國潮旅行箱品牌「地平線 8 號」推出限量禮盒，將卸妝水與行李箱、收納包組合銷售，首發 10 分鐘售罄，帶動品牌搜索量激增 15 倍。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:center"&gt;&lt;img height="854" src="https://oscimg.oschina.net/oscnet//bf0733c79b907230af3df31c0ff644dc.png" width="640" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;產品迭代：從「滿足需求」到「創造需求」&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;基於旅遊場景的深度洞察，逐本持續優化產品線：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;分膚定製系列：針對油皮、幹皮、敏感肌推出不同配方，如「沙漠肌救星」含玻尿酸與 B5，「油痘肌專研」添加水楊酸與茶樹精華。&lt;/li&gt; 
 &lt;li&gt;多功能創新：2024 年 8 月上線「卸妝水+濕巾」二合一產品，採用可降解無紡布材質，單片獨立包裝，滿足登山、露營等極端場景需求。&lt;/li&gt; 
 &lt;li&gt;環保可持續：旅行裝瓶身使用 50% 再生塑料，空瓶回收可兌換積分，吸引注重生態的年輕遊客。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;行業展望：旅遊美妝或成下一個千億賽道&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;據艾瑞諮詢預測，2025 年中國旅遊美妝市場規模將達 480 億元，年複合增長率超 25%。逐本創始人劉倩菲認為：「旅遊不僅是空間移動，更是生活方式的延伸。未來，我們將圍繞‘出行場景’拓展防曬、面膜等品類，同時通過 AI 測膚技術為遊客提供個性化護膚方案，讓‘逐本’成為旅行箱中的必備品牌。」&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;目前，逐本已與敦煌研究院、九寨溝等文旅 IP 達成合作意向，計劃推出地域限定款卸妝水，將文化元素與護膚科技結合，進一步深化「旅行+美妝」的品牌認知。在這場旅遊消費升級的浪潮中，逐本正以「小而美」的卸妝水為支點，撬動一個充滿想象力的新市場。&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;關於逐本化妝品&lt;/p&gt; 
&lt;p style="color:#191919; margin-left:1.8em; margin-right:.63em; text-align:left"&gt;逐本創立於 2016 年，專注天然植物護膚，以「分膚分時、東方植愈」為理念，打造敏感肌友好型產品。其卸妝水系列憑藉溫和配方與便攜設計，連續三年蟬聯天貓卸妝品類銷量 TOP3，並榮獲 2023 年「年度國貨創新品牌」獎項&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/359992</link>
      <guid isPermaLink="false">https://www.oschina.net/news/359992</guid>
      <pubDate>Wed, 09 Jul 2025 03:21:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
  </channel>
</rss>
