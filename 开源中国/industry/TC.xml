<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 19 Feb 2025 12:36:37 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Svelte 5 不是 JavaScript</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文翻譯自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhodlbod.npub.pro%2Fpost%2F1739830562159%2F&quot; target=&quot;_blank&quot;&gt;https://hodlbod.npub.pro/post/1739830562159/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在過去幾周裏，我一直忙於處理將一個 Web 應用程序升級到 Svelte 5 所帶來的後果。拋開對框架更新換代和遷移煩惱的抱怨，我在遷移過程中遇到了一些有趣的問題。到目前為止，我沒有看到很多人報告過相同的問題，所以我覺得自己闡述這些問題可能會有所幫助。&lt;/p&gt; 
&lt;p&gt;我會盡量不在這篇帖子中抱怨太多，因為我很感激多年來享受的 Svelte 3/4。但我想我不會再選擇 Svelte 來開發任何新的項目了。我希望我在這裏的一些反思對其他人也會有所幫助。&lt;/p&gt; 
&lt;p&gt;如果您對我在這裏提到的問題的復現感興趣，可以在以下鏈接找到。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsveltejs%2Fsvelte%2Fissues%2F15327&quot; target=&quot;_blank&quot;&gt;無法將狀態保存到 indexeddb&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsveltejs%2Fsvelte%2Fissues%2F15327&quot; target=&quot;_blank&quot;&gt;組件卸載導致閉包中的變量未定義&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;對速度的需求&lt;/h2&gt; 
&lt;p&gt;首先，讓我簡要地認可一下 Svelte 團隊所努力的方向。看起來版本 5 的大部分重大變化都是圍繞&lt;strong&gt;「深層響應性」(deep reactivity)&lt;/strong&gt;構建的，這允許更細粒度的響應性，從而帶來更好的性能。這當然很好，Svelte 團隊在性能與開發體驗（DX）的協調方面一直表現出色。&lt;/p&gt; 
&lt;p&gt;在 Svelte 的早期版本中，實現這一目標的主要方式是通過 Svelte 編譯器。涉及許多輔助技術來提高性能，但擁有一個框架編譯步驟給了 Svelte 團隊很大的靈活性，可以在幕後重新排列事物，而無需讓開發者學習新概念。這就是 Svelte 最初如此獨特的原因。&lt;/p&gt; 
&lt;p&gt;同時，這也導致了一個比以往更加晦澀難懂的系統框架，使得開發者調試更復雜的問題變得更加困難。更糟糕的是，編譯器存在缺陷，導致了一些只能通過「盲猜」重構問題組件才能修復的錯誤。我個人至少遇到過五六次這樣的情況，這也是我最終轉向 Svelte 5 的原因。&lt;/p&gt; 
&lt;p&gt;儘管如此，我始終認為這是為了速度和生產力而可以接受的權衡。當然，有時我不得不刪除我的項目，並將其遷移到一個新的倉庫，但這個框架確實是一個使用起來的樂趣。&lt;/p&gt; 
&lt;p&gt;Svelte 5 更是加大了這種權衡的力度——這是有意義的，因為這正是該框架與眾不同的地方。這次的不同之處在於，抽象/性能的權衡並沒有停留在編譯器領域，而是以兩種重要的方式侵入了運行時：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;使用 proxies 來支持 deep reactivit&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隱式組件生命週期狀態。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這兩個改動不僅提升了性能，還讓開發者的 API 看起來更加整潔。為什麼不喜歡呢？&lt;/p&gt; 
&lt;p&gt;不幸的是，這兩個特性都是&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.joelonsoftware.com%2F2002%2F11%2F11%2Fthe-law-of-leaky-abstractions%2F&quot; target=&quot;_blank&quot;&gt;抽象泄漏&lt;/a&gt;的典型例子，最終是開發變得更加複雜，而不是更簡單。&lt;/p&gt; 
&lt;h2&gt;Proxies 不是 Objects&lt;/h2&gt; 
&lt;p&gt;使用 proxies 似乎讓 Svelte 團隊能夠在不要求開發者做額外工作的前提下，從框架中榨取更多性能。&lt;/p&gt; 
&lt;p&gt;在 React 等框架中，通過多個組件層級傳遞狀態而不引發不必要的重新渲染，是一項臭名昭著的困難任務。 Svelte 的編譯器避免了與虛擬 DOM 比較解決方案相關的一些陷阱，但顯然仍有足夠的性能提升，足以證明引入 proxies 的合理性。&lt;/p&gt; 
&lt;p&gt;Svelte 團隊似乎也 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fblog%2Frunes&quot; target=&quot;_blank&quot;&gt;認為&lt;/a&gt; 他們的引入代表了開發者體驗的改進：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我們……可以最大化兼顧效率和人體工學。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;問題是：Svelte 5 &lt;em&gt;看起來&lt;/em&gt; 更簡單，但實際上引入了 &lt;em&gt;更多&lt;/em&gt; 的抽象。&lt;/p&gt; 
&lt;p&gt;使用 proxies 來監控數組方法很有吸引力，因為它允許開發者忘記確保狀態是響應性的所有古怪啓發式方法，只需向數組中 &lt;code&gt;push&lt;/code&gt; 即可。我無法計算我在 Svelte 4 中寫了多少次 &lt;code&gt;value = value&lt;/code&gt; 來觸發響應性。 在 Svelte 4 中，開發者必須瞭解 Svelte 編譯器的工作原理。編譯器作為一個有缺陷的抽象，迫使用戶知道賦值是用來表示響應性的方式。在 Svelte 5 中，開發者可以「忘記」編譯器！&lt;/p&gt; 
&lt;p&gt;但實際上，他們不能。所有新抽象的引入實際上只是引入了更多複雜的啓發式方法，開發者必須將它們記在心裏，以便讓編譯器按照他們的意願工作。&lt;/p&gt; 
&lt;p&gt;事實上，這就是為什麼在使用 Svelte 多年後，我發現自己在越來越多地使用 Svelte stores，而響應性聲明則越來越少。原因在於 Svelte stores 就是 JavaScript。在 store 上調用&lt;code&gt;update&lt;/code&gt;很簡單，而且能夠用&lt;code&gt;$&lt;/code&gt;來引用它們只是個額外的便利——無需記住，如果編譯器出錯，它就會提醒我。&lt;/p&gt; 
&lt;p&gt;proxies 引入了與響應性聲明類似的問題，那就是它們看起來像一件事，但在邊緣上卻表現得像另一件事。 當我開始使用 Svelte 5 時，一切運行得都很順利——直到我嘗試將 proxies 保存到 indexeddb（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsveltejs%2Fsvelte%2Fissues%2F15327&quot; target=&quot;_blank&quot;&gt;GitHub 上的 issue&lt;/a&gt;），那時我遇到了 &lt;code&gt;DataCloneError&lt;/code&gt;。更糟糕的是，沒有通過 &lt;code&gt;try/catch&lt;/code&gt; 結構化克隆來可靠地判斷某個對象是否是 &lt;code&gt;Proxy&lt;/code&gt;，這是一個性能密集型操作。&lt;/p&gt; 
&lt;p&gt;這迫使開發者記住哪些是 proxies，哪些不是，每次將 proxies 傳遞給一個不期望或不知道它們的上下文時，都要調用 &lt;code&gt;$state.snapshot&lt;/code&gt;。這抵消了他們最初給予我們的所有美好抽象。&lt;/p&gt; 
&lt;h2&gt;組件不是函數&lt;/h2&gt; 
&lt;p&gt;虛擬 DOM 在 2013 年之所以能夠流行起來，是因為它能夠將應用程序建模為一系列組合函數，每個函數接收數據並輸出 HTML。Svelte 保留了這種範式，使用編譯器來規避虛擬 DOM 的低效和生命週期方法的複雜性。&lt;/p&gt; 
&lt;p&gt;在 Svelte 5 中，組件生命週期又回來了，採用了 react-hooks 風格。 在 React 中，hooks 是一種抽象，它允許開發者避免編寫與組件生命週期方法相關的所有狀態代碼。現代 React 教程普遍推薦使用 hooks，這些 hooks 依賴於框架在不可見的方式下同步狀態與渲染樹。&lt;/p&gt; 
&lt;p&gt;雖然這確實會導致代碼更簡潔，但也要求開發者謹慎行事，以避免破壞圍繞 hooks 的假設。只需嘗試在&lt;code&gt;setTimeout&lt;/code&gt;中訪問狀態，你就會明白我的意思。&lt;/p&gt; 
&lt;p&gt;Svelte 4 有幾個類似的陷阱——例如，與組件的 DOM 元素交互的異步代碼必須跟蹤組件是否已卸載。這和你在依賴生命週期方法的舊 React 組件中看到的那種模式非常相似。&lt;/p&gt; 
&lt;p&gt;在我看來，Svelte 5 通過添加與組件生命週期相關的隱式狀態來協調狀態變化和效果，似乎是走上了 React 16 的道路。 例如，以下是 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fdocs%2Fsvelte%2F%24effect&quot; target=&quot;_blank&quot;&gt;$effect&lt;/a&gt; 文檔的摘錄：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;您可以將 $effect 放置在任何位置，而不僅僅是組件的最頂層，只要它在組件初始化期間（或父級效果激活時）被調用。然後它將與組件（或父級效果）的生命週期相關聯，因此當組件卸載（或父級效果被銷燬）時，它將自動銷燬。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這非常複雜！為了有效地使用 $effect...（抱歉），開發者必須理解狀態變化是如何被追蹤的。組件生命週期 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fdocs%2Fsvelte%2Flifecycle-hooks&quot; target=&quot;_blank&quot;&gt;文檔&lt;/a&gt; 聲稱：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在 Svelte 5 中，組件的生命週期只包含兩個部分：其創建和其銷燬。介於兩者之間的一切——當某些狀態更新時——與組件整體無關；只有需要響應狀態變化的那些部分才會收到通知。這是因為底層最小的變化單位實際上不是組件，而是組件在初始化時設置的（渲染）效果。因此，並沒有「更新前」/「更新後」鈎子這樣的東西。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;然而，它接着介紹了與 &lt;code&gt;$effect.pre&lt;/code&gt; 結合的「tick」概念。本節解釋説，「&lt;code&gt;tick&lt;/code&gt; 返回一個 promise，它在任何掛起的州變化被應用後解決，或者在下一個微任務中如果沒有掛起的變化時解決。」&lt;/p&gt; 
&lt;p&gt;我確信有一些心理模型可以證明這一點，但我不認為當必須緊接着關於狀態變化的補充説明時，聲稱組件的生命週期僅由掛載/卸載組成真的很有幫助。 這個地方真正讓我感到困擾，也是這篇博客帖子的動機所在，那就是當狀態與組件的生命週期耦合在一起時，即使這個狀態被傳遞給一個對 Svelte 一無所知的函數。&lt;/p&gt; 
&lt;p&gt;在我的應用程序中，我通過在存儲中保存我想要渲染的組件及其屬性來管理模態對話框，並在應用程序的&lt;code&gt;layout.svelte&lt;/code&gt;中渲染它。這個存儲也與瀏覽器歷史同步，以便使用後退按鈕關閉它們。有時，向這些模態之一傳遞一個回調是有用的，將調用者特定的功能綁定到子組件上：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot;&gt;const {value} = $props()
const callback = () =&amp;gt; console.log(value)
const openModal = () =&amp;gt; pushModal(MyModal, {callback})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img height=&quot;1&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/174804_lFSI_2720166.gif&quot; width=&quot;1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;這是 JavaScript 中的一個基本模式。傳遞迴調只是你做的事情之一。&lt;/p&gt; 
&lt;p&gt;不幸的是，如果上述代碼位於模態對話框本身中，調用組件會在回調被調用之前被卸載。在 Svelte 4 中，這運行得很好，但在 Svelte 5 中，當組件卸載時，&lt;code&gt;value&lt;/code&gt;會被更新為&lt;code&gt;    &lt;/code&gt;。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsveltejs%2Fsvelte%2Fissues%2F15325&quot; target=&quot;_blank&quot;&gt;這裏有一個最小化複製的例子&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;這只是一個例子，但對我來説，很明顯，任何被生命週期比其組件長的回調函數封閉的屬性，在我想要使用它時都會是&lt;code&gt;    &lt;/code&gt;——沒有任何重新賦值存在於詞法作用域中。&lt;/p&gt; 
&lt;p&gt;這根本不是 JavaScript 的工作方式。我認為 Svelte 之所以這樣做，&lt;strong&gt;是因為它試圖重新發明垃圾回收&lt;/strong&gt;。因為&lt;code&gt;value&lt;/code&gt;是組件的屬性，它顯然需要在組件生命週期的末尾被清理。我確信這背後有很好的工程原因，但這確實令人驚訝。&lt;/p&gt; 
&lt;h2&gt;結論&lt;/h2&gt; 
&lt;p&gt;簡單的事情很美好，但正如 Rich Hickey 所説，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoq.com%2Fpresentations%2FSimple-Made-Easy%2F&quot; target=&quot;_blank&quot;&gt;簡單的事情並不總是簡單的&lt;/a&gt;。而且像 Joel Spolsky 一樣，我不喜歡感到意外。Svelte 一直充滿了魔法，但在我看來，隨着最新版本的發佈，重複咒語的認知成本終於超過了它賦予的力量。&lt;/p&gt; 
&lt;p&gt;在這篇文章中，我的目的並不是貶低 Svelte 團隊。我知道很多人喜歡 Svelte 5（以及 react hooks）。我試圖表達的觀點是，在為用戶做事和賦予用戶自主權之間有一個權衡。&lt;strong&gt;好的軟件是建立在理解之上，而不是聰明之上&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;我也認為，隨着 AI 輔助編碼越來越受歡迎，記住這一點非常重要。不要選擇讓你與工作疏遠的工具。選擇那些利用你已經積累的智慧，並幫助你深化對這門學科理解的工具。 感謝 Rich Harris 及其團隊多年來愉快的開發經歷。我希望（如果你看到這段話的話），其中的不準確之處不至於影響作為用戶反饋的價值。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334755</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334755</guid>
            <pubDate>Sat, 08 Feb 2025 10:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>工人日報：越來越多科創企業選擇開源影響幾何</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《工人日報》（2025 年 02 月 18 日 07 版）記者，楊冉冉&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025 年伊始，中國本土科創企業的代表 DeepSeek，成為一匹 AI 創新黑馬，其推出的開源通用人工智能模型 DeepSeek-V3 和 R1 系列，以低成本、高性能震動全球科技界。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同樣引發高度關注的還有宇樹科技，16 個身着花襖、手持彩絹的宇樹 H1 人形機器人站上春晚舞台，以一場靈動歡快的「扭秧歌」表演驚豔世界。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得關注的是，這兩家科創企業得到全球科技巨頭認可的背後，有一個關鍵核心要素——那就是都選擇了開源。DeepSeek 將 R1 訓練技術全部公開，通過開源為全球開發者提供了一個創新與應用的開放平台。宇樹科技則在 2024 年宣佈開源強化學習代碼庫，吸引全球超萬名開發者參與創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;什麼是開源？開源可以看作源代碼可開放共享的開發模式，具有大眾協同、開放共享、持續創新的特性。其源起於軟件領域，並發展延伸到開源硬件、開源設計，還有由貢獻者、用戶和愛好者組成的開源社區。在智能化轉型的浪潮下，開源在雲計算、大數據、區塊鏈、人工智能、生物工程、腦科學、智能駕駛、機器人、工業軟件等新賽道不斷深化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公開數據顯示，目前，全球 97% 的軟件開發者和 99% 的企業使用開源軟件，70% 以上的新立項軟件項目採用開源模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為什麼越來越多的企業參與到開源的研發模式中，核心原因還是開源能夠降低總體生產成本、提升產品創新速度、構建合作伙伴生態，推動產業發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源可以降低創新門檻，讓更多貢獻者「站在巨人的肩膀上」，參與前沿領域的創新；還能集合產業智慧，產業鏈上下游都可以進入，構建良性生態系統；同時可以促進人才聚集，不斷產生創新的思維火花。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以 DeepSeek 為例，目前華為雲、阿里雲等雲廠商、國產芯片企業以及智能硬件、汽車、金融等上下游產業鏈企業都在積極接入 DeepSeek 模型，希望藉助其能力來升級自身服務。業界評價，「通過開源，DeepSeek 推動了全球技術的協同創新，加速了 AI 技術的普及。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了技術層面的選擇，科創企業選擇開源更是為了適應市場競爭環境。在智能手機市場，相比蘋果，安卓就是憑藉開源戰略實現了市場份額的領先。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;總之，開源作為信息技術發展的重要協作方式和生態構建的形式，已經成為科技創新的重要引擎。這一輪中國科創企業嶄露頭角，正是開源的受益者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，我國已成為全球開源生態的重要貢獻力量，參與國際開源社區協作的開發者數量排名全球第二。企業「擁抱」開源趨勢明顯，本土發起的開源項目不斷湧現、使用開源技術的企業佔比近 90%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不能忽視的是，開源與閉源之間向來是共存的。閉源體系在商業化閉環、服務質量和數據安全可控性上展現出獨特的優勢。開源體系也一直面臨商業模式的質疑。有業內人士評估：「如果 DeepSeek 能持續保持開源第一的地位，其經濟價值可能突破十萬億元人民幣，並通過金融槓桿進一步放大。」DeepSeek 讓人們看到了開源商業模式的價值和影響力，看到撬動產業格局的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源，正為企業帶來翻天覆地的變革，也是加快發展新質生產力的有效措施，如何深入挖掘開源的巨大潛力，實現技術革新與商業利益的雙重豐收，開闢從科技創新向新質生產力轉化的共贏局面，科創企業還有很長的路要走。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334754</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334754</guid>
            <pubDate>Sat, 08 Feb 2025 09:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里 AI To C 業務開放數百個招聘崗位</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《科創板日報》記者多方獲悉，阿里 AI To C 業務近期開啓大規模人員招聘，開放招聘崗位達到數百個，集中在 AI 大模型相關的產品、技術研發崗位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據悉，此次招聘崗位數量數百個，其中 AI 技術、產品研發崗位佔比達到 90%，主要分佈在 AI 產品和 AI 技術研發方向，將重點投入到文本、多模態大模型、AI Agent 等前沿技術與應用的相關工作中。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2 月初，全球頂尖人工智能科學家、前 Salesforce 集團副總裁許主洪出任阿里集團副總裁，負責 AI To C 業務的多模態基礎模型及 Agents 相關基礎研究與應用解決方案。據內部人士透露，許主洪目前正在籌備規模超百人的頂級 AI 大模型研究團隊，推動前沿科研成果向實際應用解決方案的轉化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334751</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334751</guid>
            <pubDate>Sat, 08 Feb 2025 09:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>xbatis 一款非常好用 ORM 框架，它是如何多表 join 查詢的？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;h1&gt;聯表查詢&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Ffunction%2Fbase%2Fjoin-query.html%23%25E8%2581%2594%25E8%25A1%25A8%25E6%259F%25A5%25E8%25AF%25A2&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h1&gt; 
  &lt;h2&gt;內聯查詢&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Ffunction%2Fbase%2Fjoin-query.html%23%25E5%2586%2585%25E8%2581%2594%25E6%259F%25A5%25E8%25AF%25A2&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
  &lt;div&gt;
   &lt;span style=&quot;color:var(--vp-code-lang-color)&quot;&gt;java&lt;/span&gt; 
   &lt;pre&gt;&lt;code&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; class&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; Demo&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    @&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;Autowired&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    private&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; SysUserMapper sysUserMapper;&lt;/span&gt;&lt;/span&gt;

&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; void&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; page&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;() {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;        Pager&amp;lt;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&amp;gt; pager&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; QueryChain.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(sysUserMapper)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;join&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getRoleId, SysRole&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getId)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;like&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getUserName,&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&quot;abc&quot;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;paging&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(Pager.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;));&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    }&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
  &lt;/div&gt; 
  &lt;h2&gt;左聯查詢&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Ffunction%2Fbase%2Fjoin-query.html%23%25E5%25B7%25A6%25E8%2581%2594%25E6%259F%25A5%25E8%25AF%25A2&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
  &lt;blockquote&gt; 
   &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;左聯查詢，適合 1 對 1 情況，如果不是，則分頁時需要關閉框架優化：Pager.of(1).setOptimize(false)&lt;/p&gt; 
  &lt;/blockquote&gt; 
  &lt;div&gt;
   &lt;span style=&quot;color:var(--vp-code-lang-color)&quot;&gt;java&lt;/span&gt; 
   &lt;pre&gt;&lt;code&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; class&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; Demo&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    @&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;Autowired&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    private&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; SysUserMapper sysUserMapper;&lt;/span&gt;&lt;/span&gt;

&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; void&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; page&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;() {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;        Pager&amp;lt;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&amp;gt; pager&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; QueryChain.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(sysUserMapper)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;leftJoin&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(SSysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getRoleId, SysRole&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getId)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;like&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getUserName,&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&quot;abc&quot;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;paging&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(Pager.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;));&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    }&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
  &lt;/div&gt; 
  &lt;h2&gt;右聯查詢&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Ffunction%2Fbase%2Fjoin-query.html%23%25E5%258F%25B3%25E8%2581%2594%25E6%259F%25A5%25E8%25AF%25A2&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
  &lt;div&gt;
   &lt;span style=&quot;color:var(--vp-code-lang-color)&quot;&gt;java&lt;/span&gt; 
   &lt;pre&gt;&lt;code&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; class&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; Demo&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    @&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;Autowired&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    private&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; SysUserMapper sysUserMapper;&lt;/span&gt;&lt;/span&gt;

&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; void&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; page&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;() {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;        Pager&amp;lt;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&amp;gt; pager&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; QueryChain.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(sysUserMapper)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;join&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(JoinMode.RIGHT, SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getRoleId, SysRole&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getId)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;like&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getUserName,&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&quot;abc&quot;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;paging&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(Pager.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;));&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    }&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
  &lt;/div&gt; 
  &lt;h2&gt;全連接查詢&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Ffunction%2Fbase%2Fjoin-query.html%23%25E5%2585%25A8%25E8%25BF%259E%25E6%258E%25A5%25E6%259F%25A5%25E8%25AF%25A2&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
  &lt;div&gt;
   &lt;span style=&quot;color:var(--vp-code-lang-color)&quot;&gt;java&lt;/span&gt; 
   &lt;pre&gt;&lt;code&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; class&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; Demo&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    @&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;Autowired&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    private&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; SysUserMapper sysUserMapper;&lt;/span&gt;&lt;/span&gt;

&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    public&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; void&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; page&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;() {&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;        Pager&amp;lt;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&amp;gt; pager&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt; QueryChain.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(sysUserMapper)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;join&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(JoinMode.FULL, SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getRoleId, SysRole&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getId)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;like&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(SysUser&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;::&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;getUserName,&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&quot;abc&quot;&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;                .&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;paging&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(Pager.&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;of&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;));&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;    }&lt;/span&gt;&lt;/span&gt;
&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;&lt;span style=&quot;color:var(--shiki-light, inherit)&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334750</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334750</guid>
            <pubDate>Sat, 08 Feb 2025 09:12:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>螞蟻下場自研具身智能機器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日有招聘平台信息顯示，螞蟻集團開放招聘具身智能人形機器人系統和應用等崗位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《科創板日報》記者從知情人士處獲悉，相關招聘主體為上海螞蟻靈波科技有限公司，該公司於 2024 年底註冊成立，註冊資本 1 億元。「螞蟻確實在做具身智能。」上述人士表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;611&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-af588e63ca4b7228c8a7f06a89489f1b1eb.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334747</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334747</guid>
            <pubDate>Sat, 08 Feb 2025 08:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>雲風宣佈最新開源項目 Soluna：基於 Lua 的 2D 遊戲框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;知名遊戲開發者雲風&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcloudwu%2Fstatus%2F1891688746216484976&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;創建新的開源項目 Soluna，這是一個基於 Lua 的遊戲框架，支持使用多線程製作 2D 遊戲。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b8941a90590dd71f627b51d8eb00c0405d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雲風介紹了&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcloudwu%2Fsoluna%2Fdiscussions%2F1&quot; target=&quot;_blank&quot;&gt;創建 Soluna 的動機&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我的遊戲項目不希望牽扯太多圖形技術（分散精力），主要是實踐 gameplay 方面的想法。策略向遊戲目前用 2d 就夠了，之前的 ANT 以 3d 為主，如果用來做 2d 遊戲，多了許多不必要的複雜性。&lt;/p&gt; 
 &lt;p&gt;另外，新項目不需要主打手機平台，不必圍繞手機設備開發，所以 ANT 核心之一的 vfs 可以極大簡化。直接使用本地文件系統能加快工作流。2d 遊戲的美術資產製作簡單（僅僅圖片和非常有限數量的 shader ），也不需要複雜的資源編譯過程。&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;我已經半年沒有寫複雜的程序，而寫程序對我是一件非常有樂趣的事，開一個新坑會更有意思&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/291324&quot; target=&quot;news&quot;&gt;雲風從阿里離職，未來計劃製作 Windows 平台的獨立遊戲&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/276078/cloudwu-ant-engine-open-source&quot; target=&quot;news&quot;&gt;雲風宣佈開源基於 Lua 的自研遊戲引擎 Ant Engine&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334730</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334730</guid>
            <pubDate>Sat, 08 Feb 2025 07:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度 Q4 業績會實錄：DeepSeek 讓我們明白要將最優秀的模型開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度昨天&lt;a href=&quot;https://www.oschina.net/news/334611&quot;&gt;發佈&lt;/a&gt;了截至 12 月 31 日的 2024 年第四季度及全年財報。第四季度，營收為 341 億元，同比下滑 2%。屬於百度的淨利潤為 52 億元。不按美國通用會計準則，歸屬於百度的淨利潤為 67 億元。整個 2024 年，總營收為 1331 億元，同比下滑 1%。歸屬於百度的淨利潤為 238 億元。不按美國通用會計準則，歸屬於百度的淨利潤為 270 億元。&lt;/p&gt; 
&lt;p&gt;財報發佈後，百度董事長兼 CEO 李彥宏，移動生態事業羣總裁羅戎，智能雲事業羣總裁沈抖，代理 CFO 何俊傑等高管出席隨後召開的財報電話會議，解讀財報要點並回答分析師提問。&lt;/p&gt; 
&lt;p&gt;以下是分析是問答環節主要內容：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;花旗銀行分析師 Alicia Yap&lt;/strong&gt;：DeepSeek 最近備受關注，百度也宣佈即將開源文心大模型 4.5 系列，並且將免費提供使用。請問管理層，此舉背後的戰略考量是什麼？另外，我們如何看待當前基礎模型領域的競爭格局？百度計劃如何在這個不斷演變的市場中保持領先地位？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李彥宏&lt;/strong&gt;：生成式人工智能和基礎模型市場仍處於初期階段，但發展速度極快，DeepSeek 的成功案例肯定會加快基礎模型的應用速度。隨着基礎模型變得更容易獲取且成本降低，我們正進入一個真正的變革階段，我們會看到新的人工智能應用和使用案例在數量上呈爆發式增長，這將為所有人帶來巨大的機遇，並拓展人工智能的邊界，增加更多可能性。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;從 DeepSeek 我們學到一點，那就是將最為優秀的模型開源供所有人使用，將可以極大地推動其應用，因為大家出於好奇自然會想去嘗試開源模型，進而推動其更廣泛的應用。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;文心大模型 4.5 早期版本將是我們有史以來最出色的模型，我們希望用戶和客戶試用起來能比以往更容易，更輕鬆。我們決定將 4.5 早期系列進行開源，也源於對自身技術領先地位的堅定信心，這種信心源自我們數十年在研發方面的持續投入、不斷的技術創新，以及我們作為全球為數不多具備全棧人工智能能力公司之一的獨特地位。&lt;/p&gt; 
&lt;p&gt;文心一言已經展現出強大的市場吸引力，日 API 調用量在短短一年內從 5000 萬激增至 16.5 億。通過開源，我們相信更多開發者和用戶將認識到文心一言的真正價值，推動其更廣泛應用，並擴大其在更多場景中的影響力。&lt;/p&gt; 
&lt;p&gt;同樣，將文心一言機器人免費提供使用，能讓更多用戶在同等條件下將我們的基礎模型與其他模型進行比較，尤其是其他模型收費而我們不收費的情況。我們上次對文心大模型進行重大升級是在 2023 年 10 月，距今已有很長時間，所以，未來幾個月大家敬請期待文心大模型的 4.5 版本。&lt;/p&gt; 
&lt;p&gt;話説回來，我也想強調一個關鍵的重點。無論開源還是閉源，基礎模型只有在能夠大規模有效解決現實世界問題時才真正有價值，我們致力於以應用為導向，持續迭代文心大模型。秉持這種理念，自推出以來，我們一邊利用文心大模型升級內部產品，一邊服務企業客戶。&lt;/p&gt; 
&lt;p&gt;藉助文心大模型成功改造了百度面向消費者的產品，如百度搜索和百度文庫；此外，通過千帆平台，我們正在提升企業客戶的模型和應用開發體驗。文心一言在指令遵循、先進的檢索增強生成技術（該技術將幻覺問題降至最低）等方面的行業領先能力，使其在各種場景中得到廣泛應用。千帆平台的綜合工具鏈讓我們的客戶能夠針對自身應用場景定製任何模型。展望未來，我們將瞄準性能提升和成本削減的潛力，加快文心大模型的迭代，繼續在對現實世界影響潛力最大的領域對其進行開發。我們對人工智能發展的新篇章感到興奮，期待看到人工智能技術帶來更多具有開創性且對社會有持久價值的應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;高盛分析師 Lincoln Kong&lt;/strong&gt;：我有一個關於公司搜索業務的問題。在經歷了最近幾個季度的搜索改版後，我們應該如何看待未來的調整或變化？目前生成式人工智能結果在搜索結果中的佔比是多少，我們的目標佔比又是多少？另外，隨着人工智能整合的不斷深入，鑑於像 Deepseek 和豆包這樣的人工智能聊天機器人也具備搜索功能，能否分享更多關於用戶指標方面的信息？您如何看待百度搜索與這些人工智能聊天機器人之間的競爭態勢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;羅戎&lt;/strong&gt;：目前，約 22% 的搜索結果頁面包含人工智能生成的內容，但幕後還有更多的工作在進行，我們正在從根本上對搜索服務進行了變革，使其比以往任何時候都更強大、更高效。就像李彥宏在事先準備好的發言中提到的，藉助文心一言，我們將搜索範圍從文本和鏈接擴展到提供多樣化的內容形式，包括短視頻、直播、智能助理筆記和商品展示。這些不同的形式可以動態組合，創造出個性化的搜索體驗。在持續改革搜索產品的過程中，我們也在開發能實現更深度個性化的功能，以適應每位用戶的習慣和偏好。&lt;/p&gt; 
&lt;p&gt;我們的努力帶來了更好的用戶使用效果，包括在每月使用百度進行搜索的活躍用戶中，83% 的用戶會與生成式人工智能進行內容互動。更令我們倍受鼓舞的是，12 月百度應用上每位用戶的搜索查詢量同比增長了 2%。我們專注於不斷提升用戶體驗，考慮到用戶參與度日益積極，我們也會擴大人工智能的作用。&lt;/p&gt; 
&lt;p&gt;在此基礎上，我可以同大家分享一個文心一言智能助理如何在剛剛過去的春節假期為我們的廣告客戶創造價值的案例。春節期間，許多中小企業放假一週，但某些行業的客戶需求卻達到高峯。我們的文心一言智能助理有效地彌補了這一缺口。例如，一家助聽器公司因為家庭團聚，子女關心年邁父母的健康需求，諮詢量有所增加，但該公司的客服團隊因放假不在崗。通過文心一言智能助理，該公司有效地識別並篩選出高度相關的銷售線索，使其即便在假期人員減少的情況下，也能高效跟進並無縫服務客戶。&lt;/p&gt; 
&lt;p&gt;關於你提到的人工智能聊天機器人與搜索的問題，我們認為，由基礎模型驅動的人工智能革命仍處於非常早期的階段。無論是像 Deepseek 這樣原生的人工智能工具，還是我們基於人工智能的產品，這些努力都代表了探索人工智能潛力的不同方式。作為擁有數億用戶的中國搜索市場領導者，我們通過採用最優秀的創新成果並融入真正創新的人工智能功能，保持靈活性和全面的市場視野。百度將繼續引領人工智能變革，為我們龐大的用戶羣體提升搜索體驗。&lt;/p&gt; 
&lt;p&gt;此外，搜索本質上深深紮根於語言和文本理解，這與大語言模型的能力完美契合，使我們能夠在人工智能賦能的搜索變革中佔據領先地位。我們相信，搜索正在演變成一個集成平台，它超越了人工智能驅動的探索階段，不僅能提供智能答案，還能引導用戶完成整個流程，從尋找答案、進行深入分析、完成任務，最終提供全面的服務和解決方案。&lt;/p&gt; 
&lt;p&gt;雖然人工智能驅動的探索是人工智能應用開發的一個重要但仍處於早期發展的階段，目前尚未出現具有決定性影響力的應用程序，而對我們來説，關鍵是要保持這種快速且堅定的發展態勢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;摩根大通分析師 Alex Yao&lt;/strong&gt;：能否請管理層談談 2025 年第一季度和 2025 年全年核心廣告業務的增長前景？支撐這些預測的宏觀假設是什麼？我們看到業務在 2024 年第四季度觸底並開始復甦。最後一個問題是，生成式人工智能搜索的潛在盈利機會有哪些，預計何時能實現盈利？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;羅戎&lt;/strong&gt;：過去幾個月，我們看到各類支持政策相繼出台，比如貨幣寬鬆政策、財政政策以及貿易政策。我們相信這些舉措最終會推動經濟增長，但它們需要時間才能產生效果。鑑於百度的廣告業務與中小企業高度相關，而中小企業對宏觀經濟狀況尤為敏感，再加上競爭環境持續嚴峻，儘管短期內可能面臨壓力，我們還會繼續利用基礎模型對搜索進行變革，這些工作正在穩步推進。正如我們在事先準備的發言稿中提到的，相信這種人工智能變革將持續提升用戶體驗，並創造新的可能性。&lt;/p&gt; 
&lt;p&gt;本季度，我們進一步深化了搜索在人工智能方向的變革，用戶指標也出現了令人鼓舞的改善。我們認為這將推動收入增長，並在長期內開啓新的盈利機會。此外，我們尚未大規模實現人工智能生成搜索結果的盈利，目前這類結果約佔總查詢量的 22%，而一旦我們的人工智能驅動搜索功能得到充分優化，我們將憑藉更高質量的用戶產品推進盈利進程。基於這些因素，我們看到了未來增長的機會，判斷我們的廣告業務正在觸底。我們預計業務未來將逐步改善，今年上半年的表現會好於第四季度，下半年相比上半年會有進一步提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;摩根士丹利分析師 Gary Yu&lt;/strong&gt;：我的問題是關於人工智能雲服務的。鑑於公司人工智能雲業務增長強勁，我們能否期待該業務能夠在 2025 年繼續保持良好的發展態勢？在收入和盈利能力方面，其主要驅動因素是什麼？另外，管理層能否分享一下對 2025 年人工智能雲市場的展望？我們應如何看待企業雲服務需求？人工智能又給這一領域帶來了哪些新增機會？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;沈抖&lt;/strong&gt;：正如李彥宏前面提到的，我們人工智能雲業務的收入在 2024 年第四季度同比增長加速至 26% ，推動 2024 年全年收入增長 17%。值得注意的是，2024 年與生成式人工智能相關的收入同比增長近兩倍，這一增長得益於對文心一言和人工智能基礎設施的需求不斷上升，以及市場對百度在技術方面的領導力高度認可。因此，我們成功吸引了多樣化的客戶羣體，並建立了強大的潛在業務渠道。&lt;/p&gt; 
&lt;p&gt;在人工智能基礎設施方面，我們已與多個行業建立合作關係，涵蓋互聯網、汽車、智能設備、製造業、能源、金融、公用事業以及眾多人工智能生成內容初創企業。我們的客戶羣體持續健康增長，在大中型客戶中均取得顯著進展，這表明我們在中國雲市場的份額正在不斷擴大。&lt;/p&gt; 
&lt;p&gt;通過千帆大模型平台，我們為市場提供具有行業領先性價比的全面基礎模型。我們推出了從旗艦版到輕量版的文心大模型系列，旨在滿足各種不同的需求。除了文心大模型，我們還提供廣泛的優質第三方基礎模型，包括 DeepSeek V3 和 R1 模型。得益於百度的全棧人工智能能力和端到端優化，我們能夠確保平台上託管的任何模型都具備最佳性能和穩定性，同時保持極具競爭力的價格。此外，我們還提供一整套用於微調模型和構建原生人工智能應用程序的工具，客戶能夠輕鬆制定滿足自身特定需求的解決方案。&lt;/p&gt; 
&lt;p&gt;關於人工智能雲市場展望的問題，我們認為未來將迅速增長。一方面，在最近的春節假期期間，大語言模型成為了廣泛討論的話題，這不僅進一步提高了公眾對基礎模型的認知度，還促使更多人深入思考如何利用這些模型來提升自身業務。另一方面，我們相信基礎模型的性能將不斷提升，而成本會穩步下降，這無疑將進一步降低使用這些模型的門檻。因此，我們認為更多企業會將基礎模型整合到從研發到生產的業務運營各個環節，從而推動 API 調用量的顯著增長。&lt;/p&gt; 
&lt;p&gt;我們也預計百度人工智能雲服務的支出將會增加，因為過去我們已經觀察到一個明顯的趨勢：通過千帆大模型平台的 API 調用而使用基礎模型的客戶，也傾向於增加在我們人工智能雲服務上的支出。在利潤方面，由於我們專注於符合戰略重點的高價值機會，推動了穩健的可持續增長，我們 2024 年第四季度非通用會計準則下的運營利潤率持續同比擴大。展望 2025 年，我們有信心人工智能雲業務收入增長將保持強勁勢頭，同時繼續產生正的運營利潤。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;瑞銀證券分析師 Wei Xiong&lt;/strong&gt;：我想問一下利潤率趨勢的問題。鑑於核心廣告業務近期面臨的壓力以及雲業務收入佔比的不斷增加，我們應該如何看待 2025 年第一季度和全年的核心利潤率水平？在運營效率方面還有進一步優化的空間嗎？另外，公司全年有哪些投資計劃？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何俊傑&lt;/strong&gt;：儘管面臨短期壓力，但對於人工智能領域的戰略投資將產生更為可持續的影響方面，我們仍然非常樂觀。我們始終專注於提升業務運營各方面的韌性，並且在各項業務中都看到了令人鼓舞的進展。&lt;/p&gt; 
&lt;p&gt;首先，對於我們的在線營銷業務，預計受到人工智能生成搜索結果和技術變現計劃的推動，以及百度在捕捉增長機遇方面的準備和市場宏觀環境的改善，我們的廣告收入將逐步提升。其次，我們的人工智能雲業務已經展現出強勁的增長，隨着市場份額的不斷擴大，以及我們在自主研發獨特全層級人工智能架構和全棧人工智能能力方面的競爭優勢，利潤率得到持續改善，因此，我們有信心在未來保持這一強勁勢頭。第三，對於我們的智能駕駛業務，尤其是蘿蔔快跑，我們將繼續致力於通過提高運營效率和改善單位經濟效益來縮小虧損，我們也在探索創新的運營模式，包括輕資產模式。&lt;/p&gt; 
&lt;p&gt;關於你問到 2025 年的投資與優化情況，我們將保持對高增長機遇的最優資源配置，同時與我們的長期戰略保持一致。我們的投資將繼續聚焦於那些既擁有巨大未來機遇，又具備強大投資回報率潛力的項目，包括進一步提升盈利能⼒、深化搜索業務的人工智能轉型、增強我們的人工智能雲產品，以及拓展我們的自動駕駛項目。在推進這些項目的過程中，我們將繼續致力於提高運營效率，促進各業務集團之間的協同效應，以最大限度地發揮這些戰略投資的影響力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;美銀美林分析師 Miranda Zhuang&lt;/strong&gt;：我有一個關於蘿蔔快跑業務的問題。管理層能否介紹一下 2025 年該業務的進展情況，包括車隊規模目標、能夠貢獻哪些獨特的經濟效益，以及業務的價值主張是什麼？管理層認為行業目前處於什麼階段？我們是否正在接近一個轉折點？鑑於國內自動駕駛出租車市場上的競爭對手正在與汽車製造商和打車平台合作，採用生態系統戰略，管理層對於接下來該行業的競爭態勢有何看法？請問百度的競爭和規模化策略是什麼？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李彥宏&lt;/strong&gt;：我們在自動駕駛技術領域已經投入了十多年，通過蘿蔔快跑，我們將宏偉願景變為了現實，確立了公司在自動駕駛技術領域的全球領先地位。中國的自動駕駛市場環境是非常具有挑戰性的，由於中國人口眾多、路況多樣、交通場景動態變化以及城市佈局繁複，其交通狀況是非常複雜的，而在中國乘坐自動駕駛出租車的價格約為美國的七分之一。因此，我們在中國的成功運營展示了百度卓越的技術和運營能力，包括我們所設計的全新第六代量產無人車 RT6，是世界上有史以來最具成本效益的自動駕駛出租車。憑藉我們的這些優勢，這一商業模式得到成功驗證，併為進一步規模化發展和全球擴張奠定了堅實基礎。&lt;/p&gt; 
&lt;p&gt;在第四季度，蘿蔔快跑在全國範圍內提供了約 110 萬次出行服務，同比增長 36%。到 1 月份，向公眾提供的累計出行服務次數已超過 900 萬次。此外，正如我之前提到的，我們在中國實現了 100% 完全無人駕駛運營，這意味着車輛上不再配備安全員，這是一個新的行業標杆，鞏固了我們在該領域的領先地位。正如我之前提到的，去年 11 月，自動駕駛業務獲得批准在香港開始開放道路測試，這是非常重要的一步，因為香港是我們首個右舵駕駛和靠左行駛的交通市場。這表明我們有能力使自動駕駛技術適應不同的交通系統，為拓展到其他具有類似駕駛設置的市場打開了大門。&lt;/p&gt; 
&lt;p&gt;今年對我們的業務拓展至關重要，隨着業務的推進，預計車隊規模和出行服務量的增長速度將超過以往任何時候。同時，我們也在積極尋找合作機會，我們已經確定了各種潛在合作伙伴，包括出行服務提供商、當地出租車公司、第三方車隊運營商以及其他潛在合作伙伴，這種輕資產模式將使我們能夠高效擴大規模，同時保持靈活性。通過與不同類型的合作伙伴合作，我們旨在加強市場地位，讓更多人體驗到自動駕駛服務。從更廣闊的市場來看，正如我在上次財報電話會議中提到的，由於市場仍處於起步階段，競爭實際上有助於加速市場發展，並營造更有利於創新的監管環境。在這個不斷增長的市場中，我們的使命始終明確，那就是為更多用戶提供更安全、便捷和舒適的出行體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;傑富瑞分析師 Thomas Chong&lt;/strong&gt;：展望 2025 年，百度業務投資的戰略重點會是什麼？具體而言，資源將如何在搜索、自動駕駛、雲服務和基礎模型之間分配？此外，管理層對 2025 年全年的資本支出以及股東回報有何展望？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何俊傑&lt;/strong&gt;：在評估 2025 年的資本配置選項時，我們的方法基於以下戰略考量。我們將繼續把提升人工智能能力作為長期戰略重點進行投資。在此基礎上，我們將進一步深化全產品線的人工智能轉型，尤其是搜索業務。在人工智能雲業務方面，我們旨在推動企業客戶採用我們的人工智能基礎設施、飛槳（PaddlePaddle）深度學習平台以及文心一言，滿足他們對人工智能產品和解決方案以及人工智能雲服務日益增長的需求。在智能駕駛方面，我們專注於擴大國內業務規模，探索創新運營模式，並拓展國際業務。&lt;/p&gt; 
&lt;p&gt;在確保嚴格的投資回報率管理和有效控制資本支出損失的同時，有兩個關鍵優先事項驅動我們的決策，那就是強化我們的技術領先地位，以及加速人工智能產品和人工智能雲服務在不同行業的應用。至於你問到的股東回報，自 2024 年初以來，我們的股票回購金額已超過 10 億美元，這顯著高於 2023 年全年的回購總額。對於截至 2025 年 12 月，規模為 50 億美元的股票回購計劃，我們總計已回購 17 億美元。展望未來，作為持續回報股東長期信任的舉措之一，我們計劃加快股票回購計劃的推進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334727</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334727</guid>
            <pubDate>Sat, 08 Feb 2025 07:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技申請春晚機器人圖形商標</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，2 月 5 日，杭州宇樹科技有限公司申請註冊一枚「春晚機器人」樣式圖形商標，國際分類為廚房潔具，當前商標狀態為等待實質審查。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;269&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bc4fda9d3052fe48a476a7f163206880819.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;杭州宇樹科技有限公司成立於 2016 年 8 月，法定代表人為王興興，註冊資本約 259 萬人民幣，並已於 2024 年完成了 C 輪，交易金額數億人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;經營範圍包括智能機器人的研發、智能機器人銷售、工業機器人制造、工業機器人銷售等，由王興興、漢海信息技術（上海）有限公司、寧波紅杉科盛股權投資合夥企業（有限合夥）等共同持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，宇樹科技有四足機器狗和通用人形機器人兩大系列產品。在創業早期，宇樹科技以四足機器狗起家，第一款產品為 XDog。隨後，Laikago、AlienGo、A1、Go1、B1 等一系列機器狗產品相繼研發問世，推出市場。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334724</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334724</guid>
            <pubDate>Sat, 08 Feb 2025 07:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Omdia：2029 年電信 IT 人工智能軟件市場達 50 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究機構 Omdia 最新發布了一份《電信 IT 人工智能市場預測》報告，展示了 Omdia 對於在跟蹤的電信 IT 軟件的五個主要產品類別中 AI 所佔價值的估算。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Omdia 觀點：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們估計，2023 年，電信 IT 軟件中 AI 的價值為 18 億美元，而且我們預測，到 2024 年底，其價值會達到 23 億美元。從 2024 年至 2029 年，整體價值會以 17% 的複合年增長率（CAGR）增長，達到 50 億美元。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;233&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-175f0c5940f60ad73ea3821a680982bf8f1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;預測性 AI 將佔整個預測期中大部分價值，於 2029 年達到總價值的 76%。在預測期期間，預測性 AI 將以 13% 的 CAGR 增長。然而，生成式 AI 會增長得更快，CAGR 為 37%，到 2029 年佔電信 IT 軟件中 AI 價值的 24%。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本預測的前幾年將由自動化和相關用例驅動，相比於預計到預測期末會更普遍的推薦和預測用例，這些用例相對價值更低。消費者互動和網絡管理將佔大部分的增長，因為 AI 已經在這些細分市場獲得關注，也正在推動運營效率提升，CSP 可以在此基礎上再接再厲。在沒有 AI 益處的情況下，分析已經能夠完成很多任務，所以其增長會稍慢一點。目前 AI 對於創收和服務管理的作用更加受限，並且我們預測，在預測期期間這些細分市場的增長最低。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334718</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334718</guid>
            <pubDate>Sat, 08 Feb 2025 06:53:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 年中國在開源人工智能模型領域的崛起和變革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;報告地址：&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
&lt;p&gt;在第二章《TOP 101-2024 大模型觀點》中，Hugging Face 工程師 &lt;strong&gt;Tiezhen&lt;/strong&gt;、Hugging Face 中文社區項目經理 &lt;strong&gt;Adina &lt;/strong&gt;以及 Hugging Face Fellow &lt;strong&gt;Lu Cheng&lt;/strong&gt;，從崛起與變革兩個維度，探討中國開源模型在 2024 年取得的重大成就和未來展望：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國在開源人工智能模型領域從 「追隨者」 到 「引領者」 轉變，體現技術實力且反映人工智能生態系統快速完善。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國學術界和產業界推進自主研發，在技術創新和模型能力上飛躍，多款自主研發模型在國內外評測表現卓越。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen 系列因多尺寸選項、多語言支持及友好授權功能獲高度評價；DeepSeek 引入 MLA 技術實現性能成本突破；智譜 CogVideoX 系列成全球首批開源文生視頻模型之一。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源模型從質疑中崛起獲廣泛認可，其成功得益於政府支持與行業鉅額投入，中國人工智能生態體系迅速完善，未來可能在全球佔更核心地位。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隨着開源模型影響力提高，中國開源社區活躍度提升，企業、研究機構、個體開發者積極參與，如 Qwen 系列被廣泛集成促進交流協作，智源研究院等機構建立協作機制貢獻基礎工作和資源。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國開源社區湧現高質量自發研究成果，如 MAP 團隊的 Map Neo、InstantX 團隊的 InstantID，為中國模型贏得國際認可。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國在推動人工智能技術發展同時建立完善透明治理機制，如《人工智能示範法 2.0（專家建議稿）》《生成式人工智能服務管理暫行辦法》，為開源模型發展提供穩定政策環境並確保技術應用符合社會價值導向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;端上模型興起，中國 AI 社區推出多款移動友好型模型，如 Qwen2 - 1.5B 等，雖有挑戰但代表 AI 技術隱私保護和成本優化未來方向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源社區在邏輯推理領域推出創新項目，如 Macro - o1、QwQ 等，通過開源策略分享研究細節，推動小模型推理能力提升與行業技術進步。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源模型發展從 「百模大戰」 邁向多元化和深度細分，發佈大量高質量開源模型，涵蓋多模態理解與生成等多個領域，模型競爭轉向應用場景細化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/135245_kWl7_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;完整全文：&lt;a href=&quot;https://my.oschina.net/u/3859945/blog/17503717&quot; target=&quot;_blank&quot;&gt;https://my.oschina.net/u/3859945/blog/17503717&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334705</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334705</guid>
            <pubDate>Sat, 08 Feb 2025 05:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 將在 4 月底舉辦首屆 AI 開發者大會 LlamaCon</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Meta&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llama.com%2Fevents%2Fllamacon%2Fsignup%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;將在今年 4 月 29 日舉行首屆 LlamaCon——專門面向生成式人工智能的開發者大會。大會的名字源於 Meta 的開源 AI 模型 Llama 系列。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-26ace593ef0174eac7b8b3e6bcbe581ade6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Meta&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.meta.com%2Fblog%2Ffuture-of-ai-built-with-llama%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，隨着開源 Llama 模型和工具集合的空前增長和發展勢頭強勁，公司決定於 4 月 29 日舉行首屆專門面向 AI 領域的開發者大會 LlamaCon。他們將&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;在大會上分享開源 AI 發展的最新動態，來幫助開發者構建「令人驚歎的應用和產品」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;在接下來的幾周裏，Meta 也將公佈更多與 LlamaCon 有關的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在 1 月底的財報説明會上，扎克伯格曾表示，Llama 4 的目標是引領（市場），具備原生的多模態能力。他當時也暗示 Llama 4 最早也要到今年二季度才會發佈，所以 4 月 29 日會是一個較為合適的日期。&lt;/p&gt; 
&lt;p&gt;留出兩個月的時間，也給 Meta 公司帶來了不確定性。目前 OpenAI 已經確認會在近期發佈 GPT-4.5、Anthropic 也被爆料將在「數週內」發佈混合 AI 模型 Claude 4。&lt;/p&gt; 
&lt;p&gt;最令 Meta 忌憚的是，DeepSeek 是否會在未來兩個月裏搞出更多的「大新聞」。&lt;/p&gt; 
&lt;p&gt;據報道，在 DeepSeek 發佈 R1 模型之後，Meta 迅速組建了四個「戰情室」，核心憂慮是 DeepSeek 的最新大模型可能會比 Llama AI 的下一代版本更強。&lt;/p&gt; 
&lt;p&gt;知情員工透露，四個「戰情室」中有兩個負責研究 DeepSeek 如何降低訓練和運行 AI 模型的成本，並將心得用於訓練 Llama。另外兩個團隊，負責嘗試找出 DeepSeek 用於訓練的數據，以及如何將中國 AI 的先進訓練方法用於重構 Meta 自己的產品。&lt;/p&gt; 
&lt;p&gt;在分析師電話會議上，扎克伯格曾表示：「他們（DeepSeek）做了一些新穎的事情，我認為我們仍在消化中。他們取得的一些進展，我們希望在我們的系統中應用，這就是開源世界運作的本質。」&lt;/p&gt; 
&lt;p&gt;與此同時，扎克伯格也已經宣佈，今年將在人工智能相關的項目上投資 600-650 億美元，包括建設一個超大型數據中心和更多的人才招聘。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334689/meta-llamacon-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334689/meta-llamacon-2025</guid>
            <pubDate>Sat, 08 Feb 2025 04:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 前 CTO 官宣新創業 AI 公司，團隊成員多來自 OpenAI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 前 CTO Mira Murati 今天凌晨&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmiramurati%2Fstatus%2F1891918876029616494&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;創立了新的 AI 公司 Thinking Machines Lab（思維機器實驗室）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d07fc6d37ca4e1534888a3ca6098802c5d2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthinkingmachines.ai%2F&quot; target=&quot;_blank&quot;&gt;官網寫道&lt;/a&gt;，公司將專注於構建人工智能（AI）模型和產品，以支持更多、跨工作領域的「人類-AI 協作」，「雖然當前的系統擅長編程和數學，但我們正在構建能夠適應人類所有專業知識並實現更廣泛應用的人工智能。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;他們還強調這會是一家重視研究開放的公司，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fthinkymachines%2Fstatus%2F1891919141151572094&quot; target=&quot;_blank&quot;&gt;其推文中承諾&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我們致力於通過論文發表和代碼發佈來開放科學，同時會重點關注應用於不同領域的人機協作。我們的方法包括共同設計研究和產品，以便從實際部署和快速迭代中學習。這項工作需要三個核心基礎：&lt;strong&gt;SOTA 的模型智能、高質量的基礎設施和先進的多模態能力&lt;/strong&gt;。我們致力於構建處於能力領先的模型來兌現這一承諾。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該公司官方網站對這三核心基礎進行了展開説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;模型智能是基石。除了強調人機協作和定製之外，模型智能也至關重要，我們正為科學和編程等領域構建前沿能力模型。最終，最先進的模型將解鎖最具變革性的應用和優勢，例如實現新穎的科學發現和工程突破。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基礎設施質量是重中之重。研究生產力至關重要，在很大程度上取決於基礎設施的可靠性、效率和易用性。我們的目標是長期正確地構建事物，以最大限度地提高生產力和安全性，而不是走捷徑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;先進的多模態能力。我們認為多模態對於實現更自然、更高效的通信、保存更多信息、更好地捕捉意圖以及支持與現實環境的更深入集成至關重要。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;官網貼出了公司 29 人團隊名單，其中超過 20 人有在 OpenAI 供職的經驗。其中較為知名的有 OpenAI 聯合創始人約翰·舒爾曼（John Schulman），他正擔任新公司的首席科學家。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334684</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334684</guid>
            <pubDate>Sat, 08 Feb 2025 03:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>沒有所謂的 1875 紀元，美國 150 多歲老人領社保福利不是 COBOL 語言的鍋</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期，一位美國政府官員曾宣稱：「我們這裏有些人看起來都已經 150 歲了」，並指出這些人正在領取社會保障福利。由此，有人開始流傳這樣一種説法：社會保障局（SSA）在存儲日期時使用了一個 1875 年的紀元，把那些未知出生年份的記錄存為 0，從而默認顯示為 1875 年。&lt;/p&gt; 
&lt;p&gt;這種觀點的起源可以追溯到某個帖子，帖子中有人調侃道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「看起來埃隆那羣天才程序員根本就不懂 COBOL 的工作原理。社會保障系統正是運行在 COBOL 上，而 COBOL 並沒有專門的日期或時間類型。於是日期就以數字形式存儲，按照 ISO 8601 標準計算，紀元定在了 150 年前（1875 年）——也就是米制標準的開始。結果如果不知道某個日期，就會存儲成 0，而在 COBOL 中這就會默認解析為 1875 年，也就是 150 年前。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;1668&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/112214_BPqK_3820517.png&quot; width=&quot;1198&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然而，筆者對此並不認同，主要基於以下幾點理由：&lt;/p&gt; 
&lt;h2&gt;數據庫中存在 1875 年前的出生年份&lt;/h2&gt; 
&lt;p&gt;2007 年，社會保障局曾發佈過一份數據集，該數據集包含了在 2007 年 1 月之前發放的社會保障號碼持有者的收入記錄（約佔全部數據的 1%）。在這份數據集中，他們明確説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;移除了出生年份早於 1870 年的 5,935 條記錄&lt;/li&gt; 
 &lt;li&gt;移除了出生年份等於 2007 的 1,096 條記錄&lt;/li&gt; 
 &lt;li&gt;以及少數缺失出生年份的記錄&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這表明，SSA 的數據庫中確實保存了 1875 年前（甚至 1869 年及更早）的出生年份數據，並非將未知年份一律默認為 1875。&lt;/p&gt; 
&lt;h2&gt;數據中沒有 1875 年出生人數激增的異常&lt;/h2&gt; 
&lt;p&gt;如果系統將所有未知出生年份的記錄默認轉換為 1875 年，那麼在統計數據中，1875 年的出生人數應該會異常增多。但實際上，從公開數據來看，並不存在這樣一個「高峯」。（注：該數據集只是 1% 的樣本，若存在默認值問題，趨勢應當更加明顯。）&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;698&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/112303_XwHt_3820517.png&quot; width=&quot;1174&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;社會保障局並未使用 ISO 8601 標準存儲日期&lt;/h2&gt; 
&lt;p&gt;負責跟蹤社會保障福利支付的主記錄（Master Beneficiary Record, MBR）建立於 1962 年，這遠早於 ISO 8601 標準於 1988 年的發佈。即便是其前身 ISO 2016 標準也在 1976 年發佈，並且並沒有任何依據指向 1875 年。實際上，有研究論文基於 SSA 數據指出，SSA 對生日等信息的存儲採用的是固定寬度格式，而不是 ISO 8601 標準的日期字符串格式。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;The data abstracted from the MBR consisted of a 26-character record for each deceased individual. The four data items on each record were… the month and year of death&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ISO 8601 標準本身並不涉及紀元概念&lt;/h2&gt; 
&lt;p&gt;ISO 8601 僅僅是一種用於表示日期和時間的字符串格式，其本質並不是基於數字計算時間流逝，因此根本無需設定一個「紀元」。雖然 ISO 8601:2004 版曾固定引用 1875 年 5 月 20 日——即《米制公約》在巴黎簽署的那一天——作為參考日期，但這一引用在 ISO 8601-1:2019 版中已被移除。換句話説，這個日期僅用於定義格里高利曆，並非作為一個時間計數的起點。&lt;/p&gt; 
&lt;h2&gt;沒有任何證據顯示 1875 年被用作時間計算的起點&lt;/h2&gt; 
&lt;p&gt;經過查找，筆者沒有發現任何系統或標準會將 1875 年作為時間紀元。尤其在 COBOL 語言中，也沒有這樣的約定或實踐。所有跡象都表明，所謂的「1875 紀元」只是個誤解。&lt;/p&gt; 
&lt;p&gt;總的來説，從 SSA 的數據實踐、存儲方式以及國際標準的角度來看，都沒有任何證據支持「1875 紀元」這一説法。該觀點看似有趣，但實際上缺乏堅實的依據。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fiter.ca%2Fpost%2F1875-epoch%2F&quot; target=&quot;_blank&quot;&gt;https://iter.ca/post/1875-epoch&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334682/1875-epoch-cobol-150-american</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334682/1875-epoch-cobol-150-american</guid>
            <pubDate>Sat, 08 Feb 2025 03:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>沒有處理過遺留項目，別自稱資深工程師</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家都不喜歡維護遺留項目，我也不例外。命運總愛跟人開玩笑，最近一個遺留項目正好落到了我手上。雖然在這個項目上工作的經歷並沒有減少我對遺留系統的厭惡，反而讓我對當下所採用的流程與實踐有了更深刻的認識。&lt;/p&gt; 
&lt;p&gt;我為自己所在的團隊感到自豪，因為我們遵循了許多業界最佳實踐：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;編寫簡潔且易維護的代碼，並配以自動化測試&lt;/li&gt; 
 &lt;li&gt;積極參與代碼合併請求和任務評審&lt;/li&gt; 
 &lt;li&gt;合併到主分支後，當天就能將應用推向生產環境&lt;/li&gt; 
 &lt;li&gt;高度採用敏捷開發模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;當然，一切並非盡善盡美。合併請求中偶爾會出現一些無關痛癢的建議和討論；運維團隊有時也會搞砸一些事情（至少在我們開發人員看來是這樣）；而產品負責人也時不時催促我們加快推出某些「簡單」的新功能……總的來説，情況還算不錯。&lt;/p&gt; 
&lt;h2&gt;穿越回 Ant 時代&lt;/h2&gt; 
&lt;p&gt;由於團隊表現出色，公司決定將我們的開發效率借調給另一個由其他部門負責的產品。令我們略感失望的是，這個項目不僅使用的是較老版本的 Java，其代碼風格也與我們的習慣大相徑庭。&lt;/p&gt; 
&lt;p&gt;任務要求我們添加幾個簡單的監控指標，比如應用是否正常運行、運行時長、數據處理是否足夠迅速等。由於項目正處於維護模式，已經有段時間沒有添加新功能了。按理説，添加這些指標對我們來説應該是小菜一碟。&lt;/p&gt; 
&lt;p&gt;然而，當我們捲起袖子開始工作時，首先發現這個項目竟然使用了一種非常古老的構建方式——Ant 構建文件。那是一種龐大的 XML 文件，詳細描述瞭如何構建整個項目：從編譯、測試到打包，每個環節都必須顯式配置，包括源碼路徑、目標路徑以及資源位置。過去，這種做法在許多編程語言中都很常見：寫好一個構建文件，複製到每個新項目中，再不斷調整直至適應新項目需求。&lt;/p&gt; 
&lt;p&gt;例如，一個簡單的「Hello World」項目的 Ant 構建文件可能如下所示：&lt;/p&gt; 
&lt;pre&gt;&amp;lt;project&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;clean&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;delete dir=&quot;build&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;compile&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;mkdir dir=&quot;build/classes&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;javac srcdir=&quot;src&quot; destdir=&quot;build/classes&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;jar&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;mkdir dir=&quot;build/jar&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;jar destfile=&quot;build/jar/HelloWorld.jar&quot; basedir=&quot;build/classes&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;manifest&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;attribute name=&quot;Main-Class&quot; value=&quot;oata.HelloWorld&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;/manifest&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;/jar&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;run&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;java jar=&quot;build/jar/HelloWorld.jar&quot; fork=&quot;true&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/pre&gt; 
&lt;p&gt;難道就沒有更便捷的方式嗎？正因如此，「約定優於配置」的理念應運而生。這一理念主張：開發者只需關心那些偏離約定的特殊情況，而現代構建工具正是基於這一思想，通過提供可覆蓋的默認配置，免去了重複配置的麻煩。正因為如此，大多數 Java 源碼統一存放在 &lt;code&gt;src/main/java&lt;/code&gt; 目錄下，而編譯後的文件則放在 &lt;code&gt;target&lt;/code&gt; 目錄中，避免了繁瑣的重複設置。&lt;/p&gt; 
&lt;p&gt;這一發現啓發了我們：或許同樣的原則也能應用到我們當前項目中的應用配置上。面對一個龐大且大部分數值雷同（如應用端口）的配置文件，採用默認值機制無疑能讓配置文件變得更精簡。&lt;/p&gt; 
&lt;h2&gt;被我們視為理所當然的事情&lt;/h2&gt; 
&lt;p&gt;回到遺留項目，我們順利構建並打包了應用！那枯燥的部分終於過去，可以安心開始編碼了。但問題隨之而來：如何將我們負責監控的指標組件嵌入到這套老舊的代碼庫中？在我們的常規開發框架中，這一切通常是自動處理的，因此我們一度認為這毫不費事。&lt;/p&gt; 
&lt;p&gt;但實際上，將指標組件「注入」到遺留代碼的各個角落，最佳方案是什麼呢？初看起來，單例模式似乎是最簡單的選擇；不過，開發社區普遍認為單例是一種反模式。為什麼呢？畢竟，我們鍾愛的某某框架不也依賴單例嗎？如果不是，那它到底採用了什麼機制？依賴注入究竟是什麼？其底層又是如何運作的？&lt;/p&gt; 
&lt;p&gt;這一連串問題促使我們重新審視那些一直視為理所當然的基本概念。雖然在這種情況下使用單例並非最糟，因為代碼大部分缺乏單元測試，但要讓我們心安理得，代碼必須經得起推敲。經過嘗試，我們最終採用了一種不同的方案，寫出了既簡潔又清晰的代碼——既沒有依賴單例，也未引入多餘的抽象層。&lt;/p&gt; 
&lt;h2&gt;開發者角色的侷限性&lt;/h2&gt; 
&lt;p&gt;項目的最後一步是部署，只有部署成功後才能進行測試。但問題來了——這一次，我們既不負責部署，也不負責測試。部署工作由運維團隊完成，而測試則交由專門的測試團隊。為什麼開發者就不能全程掌控，從開發到上線，而要先提交工單，再等待其他團隊的配合呢？&lt;/p&gt; 
&lt;p&gt;首先，由於代碼測試覆蓋率不足，手動測試不可避免；其次，公司的基礎設施也不允許我們自行部署應用。&lt;/p&gt; 
&lt;p&gt;這一系列經歷使我們開始思考職責分離的原因，以及現行模式為何更為合理。事實證明，這個項目的任務交付時間和迭代週期遠遠超過平時（通常幾天就能交付的工作，此次竟拖延了數週），這無疑驗證了分工合作的必要性。&lt;/p&gt; 
&lt;h2&gt;通過舊實踐理解現代方法&lt;/h2&gt; 
&lt;p&gt;到了月底，我們的監控指標終於在生產環境中順利運行。雖然我對遺留項目的看法依舊——我仍然討厭它們，也不奢望你會因此改變看法——但這段經歷給了我們寶貴的啓示。&lt;/p&gt; 
&lt;p&gt;我們無法選擇所分配到的項目，但我們可以調整對待遺留系統的態度。與其心存無奈，不如把它當作一個提問、學習與成長的機會。通過瞭解過去的做法及其侷限，我們不僅掌握了當下的最佳實踐，更獲得了背後歷史的寶貴經驗。&lt;/p&gt; 
&lt;p&gt;一旦你積累了這種深厚的知識，其他開發者自然會認可並信賴你的專業能力。如果你希望成為這樣的人，就得勇於鑽研那些看似繁瑣的遺留項目。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infobip.com%2Fdevelopers%2Fblog%2Fseniors-working-on-a-legacy-project&quot; target=&quot;_blank&quot;&gt;https://www.infobip.com/developers/blog/seniors-working-on-a-legacy-project&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;作者：Alen Kosanovic&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334678/seniors-working-on-a-legacy-project</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334678/seniors-working-on-a-legacy-project</guid>
            <pubDate>Sat, 08 Feb 2025 03:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Grok 3 是否意味着大力出奇跡的大模型法則仍然成立？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文轉載自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F24609799526&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/24609799526&lt;/a&gt;&lt;br&gt; 作者：張俊林（中科院軟件所，博士）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;媒體風向變化太快，讓人目不暇接。早上還在誇 Deepseek 成本低，性價比高，預訓練 Scaling Law 死了，不需要太多機器和 GPU 卡，性價比優先，英偉達休矣；中午 Grok 3 一出來，説是用了 10 萬張英偉達 H100 卡，效果力壓 OpenAIo3 mini 和 Deepseek R1，就轉向説 Scaling law 還成立，還需要大量的卡，英偉達股價有救了，還是要大力出奇跡……&lt;/p&gt; 
&lt;p&gt;這兩個觀點明顯對立，有一真必有一假，那事實的真相到底是啥呢？我們來推一推。&lt;/p&gt; 
&lt;h2&gt;一、預訓練階段的 Scaling Law 是否仍然成立&lt;/h2&gt; 
&lt;p&gt;-預訓練階段的 Scaling Law 成立嗎？當然是成立的，所謂「Scaling Law 撞牆」，大家普遍遇到的問題是數據不夠了，沒有大量新數據，導致預訓練階段的 Scaling Law 走勢趨緩，注意是趨緩但不是停頓，預訓練階段的 Scaling Law 並沒到天花板。按照 Chinchilla Scaling Law 推斷，即使沒有新數據，也並不意味着模型效果提不上去了，很簡單，只要增加基座模型尺寸，效果仍然會提高，只是從付出的算力和獲得的效果提升來説很不合算，性價比過低，這是為何大家轉到 RL Scaling Law 和 Test Time Scaling Law 的原因，是因為付出同樣的算力，在後面兩個階段大模型智商提升更明顯，就是性價比高。&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;目前可以提高模型效果的 Scaling 方法，按照性價比由高到低排序的話: Test time Scaling Law&amp;gt; RL Scaling Law&amp;gt;預訓練階段 Scaling Law(數據不夠了，只能推大模型尺寸)&lt;/strong&gt;，有性價比高的 Scaling，當然優先做這種，性價比低的 Scaling，只有在沒有性價比更高的情況下才會採用。這跟購物一個道理，有性價比高的當然不會去買性價比低的商品。&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;如果哪天 RL Scaling Law 和 Test Time Scaling Law 到了天花板，又沒有找到新的性價比更合算的 Scaling law，也不是説模型效果就提不上去了，大家仍然可以迴歸預訓練階段的 Scaling Law，沒有新數據也沒關係，推大模型尺寸規模就可以，效果仍然會上升&lt;/strong&gt;。但這基本是最後的選擇，沒辦法的辦法，只要有性價比高的方法就不會走這條路。&lt;/p&gt; 
&lt;p&gt;-有人問了：那按照你的意思，囤那麼多 GPU 算力，其實對訓最好的模型也沒啥用？要是按照上面的理論，那確實是沒有太大必要，比如 Deepseek 2000 卡也可以作出最好的模型不是。但是卡多有個好處，就是能壓縮實驗新想法和訓練大模型基座的時間週期。比如你總得探索一些不同的算法、參數或數據配比的模型進行各種實驗，你有 10 個新想法，如果只有 2000 張卡，可能得跑 5 天才能得出結論，要是有幾萬張卡，可能 1 天就能得出結論，所以卡多對於探索效率是有極大幫助的。卡多創新多，這點肯定成立。&lt;/p&gt; 
&lt;h2&gt;二、Grok 3 基座模型（對標 Deepseek V3，非 R1 這種邏輯推理模型）&lt;/h2&gt; 
&lt;p&gt;-為何 Grok 3 作為通用基座模型，它的評測指標只有數學、科學和代碼數據集？沒有通用能力比如最常用的 MMLU 指標的對比，這是不太規範的對比模式。推斷可能 Grok 3 的通用能力相對 OpenAI 和 Deepseek 的模型沒有大幅提升，所以不拿出來比？&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;如果想要提升基座模型的數學、科學和代碼能力，無論從方法還是從成本角度來講，難度並不大，目前比較標準的做法是類似 Deepseek V3 從 Deepseek R1 蒸餾數學、代碼等邏輯題的長 COT 數據，即深度思考過程數據，就是説把深度思考長 COT 數據引入基座的 Post-Training 階段、甚至前置到預訓練階段（所謂大模型「左腳（Deepseek 基座）踩右腳（Deepseek R1）自我飛昇」的模式），這樣就能大幅提升基座模型在數學和代碼方面相關的能力，也就是 Grok3 宣傳具備的「有思維鏈推理和自我糾錯機制」，評測指標看着會比較好看，而且蒸餾的數據總量也不會太大（幾百 B 級別應該夠了），成本很低，對算力要求不高。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;-OpenAI 很快會發布的非邏輯推理模型 GPT 4.5，大概也應是類似的思路，從 o3 模型蒸餾 COT 數據，用深度思考數據來提升 GPT 4.5 基座模型的智商，大模型「左腳踩右腳自我飛昇」大法，這會是之後基座模型提升能力的主要手段。&lt;/p&gt; 
&lt;p&gt;-Grok 3 的算力消耗是 Grok 2 的 10 倍，如果遵照 Chinchilla Scaling Law，最佳做法是 Grok 3 的訓練數據量比 Grok 2 增加 3 倍，模型大小同時比 Grok 2 增加 3 倍（但是目前的趨勢是減小模型大小，增大數據量[就是説「小模型大數據」的模式]，儘管這樣不滿足訓練最優原則，但因為模型尺寸小了，所以這種模型更適合在線推理服務，降低服務成本）。&lt;/p&gt; 
&lt;p&gt;-如果像發佈會宣稱的，Grok 3 耗費算力是 Grok 2 的 10 倍消息為真的話，那有兩種可能。一種是數據量增長極大，這樣只能是增加了大量多模態數據，比如數據量從 10T 增長到 30T（目前文本模型使用的數據量，最多到 18T 到 20T 之間，基本到頂，再多沒有了，要大幅增加只能加多模態數據，但是增加多模態數據對提升大模型智商幫助不大，所以這個增量按理説不應該太大），如果這樣推算，Grok3 的模型規模增長 3 倍左右；第二種可能是訓練數據量比 20T 增加的不多，如果這樣可以推出 Grok3 模型尺寸比 Grok 2 要大很多，至少 4 到 5 倍起步（若新增數據不多，那隻能靠增加模型尺寸來消耗新增算力）。不論是哪種可能，Grok 3 的模型大小肯定比 Grok 2 大了很多，而 Grok 2 模型本身可能就不小（Grok 2 發佈網頁評測效果超過 Llama 3.1405B，所以無論數據還是模型大小，都不會太小，要是 Dense 模型， 70B 是最小的估計了），&lt;strong&gt;所以 Grok 3 的尺寸規模很可能不是一般的大&lt;/strong&gt;（感覺在 200B 到 500B 之間）。&lt;/p&gt; 
&lt;p&gt;-很明顯，Grok 3 仍然在採取推大基座模型尺寸的「傳統」做法，也就是上面「Scaling Law」部分分析的預訓練階段增大模型尺寸的方法來提升基座模型能力，上面分析過，這種做法是性價比很低的。比較時髦的做法是把訓練重心放在 RL Scaling 方面，性價比會高太多。但是為啥他要做這種賠本買賣呢？在後面會給出一個可能的解釋。&lt;/p&gt; 
&lt;h2&gt;三、Grok 3 邏輯推理版本 (深度思考版本，對標 Deepseek R1)&lt;/h2&gt; 
&lt;p&gt;-Grok 3 的深度思考版本，不説體驗，單從評測指標看，達到或者超過了 o3 mini，確實是目前效果最好的，或者説最好的之一沒有什麼問題。&lt;/p&gt; 
&lt;p&gt;-説回上面提到的問題，為啥明知靠推大預訓練階段模型尺寸規模性價比低，Grok 3 還要用這種模式呢？很可能內在的原因在於（推斷無證據）：&lt;strong&gt;Post-Training 階段採取 RL Scaling，其效果可能跟基座模型的大小是有正相關關係的，就是説，同樣的 RL 階段的算力消耗，如果基座模型尺寸更大，則 RL 階段的 Scaling 效果越好。&lt;/strong&gt;只有這樣，才有在預訓練階段儘量把模型規模推大的必要性。而我們可以假設，Grok 3 之所以採取這種過於耗費算力，看着性價比不高的方式，是希望通過加大基座，把深度思考版本的能力明顯提起來。&lt;/p&gt; 
&lt;p&gt;-貌似 Deepseek R1 效果很好又開源，獲得一片好評，但大家想要實際用起來，會發現基座太大，部署難度和消耗資源太高，對下游應用不太友好。那為啥 Deepseek 非得推這種對下游應用來説明顯過大的模型呢？（小點的蒸餾模型看着指標很好，但是實際應用效果貌似差不少），是否也是因為基座模型如果不夠大，深度思考模型效果就沒那麼好的原因？&lt;/p&gt; 
&lt;p&gt;-如果上述假設成立，那意味着：&lt;strong&gt;三個 Scaling Law(Pre-train、RL 、Test Time)，從提高大模型智商的性價比來説，由高到低是：Test Time &amp;gt; RL &amp;gt; Pre-Train，這個是之前的結論。但如果上述假設成立，説明 Test Time Scaling 的天花板最低，它的天花板依賴於 RL 階段的 Scaling 能力，而 RL 階段 Scaling 天花板次低，它的天花板依賴於預訓練階段 Pre-Train 的 Scaling？&lt;/strong&gt;如果這樣，如果有一天當 RL 和 Test Time 天花板到頂，意味着我們可以再啓動一輪，去推大基座模型的模型尺寸，RL 階段 Scaling 的天花板隨之升高，然後可以再去 Scale RL 和 Test Time，就進一步得到智商更高的大模型。如果這成立，那意味着 AGI 的解決方案已經完整了？其實不需要新的 Scaling Law 存在就夠？&lt;/p&gt; 
&lt;p&gt;-上述推論，是在一個前提成立的條件下的推出來的，這個前提是：Grok 3 耗費這麼大算力推大模型規模，這是個深思熟慮或小規模實驗的結果，而不是僅僅受到之前老觀念（預訓練階段算力越高效果越好）影響下的決策。&lt;/p&gt; 
&lt;p&gt;如果這個前提不成立，則上述推論不成立。總之，一切責任在馬斯克，Over。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334674</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334674</guid>
            <pubDate>Sat, 08 Feb 2025 03:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 提出新的注意力機制：原生稀疏注意力 (NSA)，創始人親自提交論文</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 18 日，DeepSeek 官方發文公佈了一篇新的論文，&lt;strong&gt;論文提出了一種新的注意力機制「NSA」&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-adf24ce9b3e5ac8760a1ec13688871f61ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2502.11089v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2502.11089v1&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據 DeepSeek 介紹，&lt;strong&gt;&lt;span&gt;「原生稀疏注意力 (Native Sparse Attention, NSA) 」&lt;/span&gt;&lt;/strong&gt;是一個用於超快長上下文訓練和推斷的本地可訓練的稀疏注意力機制，並且還具有與硬件對齊的特點。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;論文摘要：&lt;/p&gt; 
 &lt;p&gt;長文本建模對下一代語言模型來説至關重要，但標準注意力機制的高計算成本帶來了顯著的計算挑戰。稀疏注意力為提高效率同時保持模型能力提供了一個有前景的方向。我們提出了 NSA（原生稀疏注意力），這是一個將算法創新與硬件對齊優化相結合的、原生可訓練的稀疏注意力機制，用於實現高效的長文本建模。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d43b8ad2a0cb2e2f280f11b7d2d96a63fba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NSA 核心組件包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;動態分層稀疏策略&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;粗粒度 token 壓縮&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;細粒度 token 選擇&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;研究通過對現實世界語言語料庫的綜合實驗來評估 NSA。其中作者評估了 NSA 在通用語言評估、長上下文評估和鏈式推理評估中的表現。實驗結果表明，NSA 實現了與 Full Attention 基線相當或更優的性能，同時優於現有的稀疏注意力方法。&lt;/p&gt; 
&lt;p&gt;此外，與 Full Attention 相比，NSA 在解碼、前向和後向階段提供了明顯的加速，且加速比隨着序列長度的增加而增加。這些結果驗證了分層稀疏注意力設計有效地平衡了模型能力和計算效率。&lt;/p&gt; 
&lt;p&gt;另外，有網友發現，arXiv 上 NSA 這篇論文的提交記錄顯示，它於 2 月 16 日提交，提交者正是梁文鋒本人，他也是這篇論文的合著者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-521d0ee94e504b1caa033cbf984b6fde938.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334671/deepseek-nsa</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334671/deepseek-nsa</guid>
            <pubDate>Sat, 08 Feb 2025 02:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Linus Torvalds 將不顧維護者反對合並 Rust 內核代碼</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 &lt;a href=&quot;https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead&quot;&gt;Asahi Linux 創始人宣佈辭去項目負責人職務&lt;/a&gt;之後，圍繞 Linux 內核中 Rust 代碼的爭議還在繼續。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DMA 映射助手及內核其他多個領域的維護者 Christoph Hellwig 一直對 Linux 內核中的 Rust 代碼及其長期可維護性持批評態度，他在最新發布的一封郵件列表帖子中指出， Linus Torvalds 私下提到將推翻維護者對內核中 Rust 代碼的否決權。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;409&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-84071f688bda1ac854a0ee922963f204016.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;考慮到最近幾天的討論，我決定發佈此頁面，其中包含我們的理解：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frust-for-linux.com%2Frust-kernel-policy&quot; target=&quot;_blank&quot;&gt;https://rust-for-linux.com/rust-kernel-policy&lt;/a&gt;……&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Linus 私下表示，他絕對會不顧維護者的反對合並 Rust 代碼。因此，從現在開始，作為 Linux 開發者或維護者，無論你是否願意，都必須處理 Rust。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這裏的 Rust 代碼不僅僅是指 Rust 代碼——這些綁定看起來一點也不像地道的 Rust 代碼，它們是一種完全不同的存在，試圖彌合巨大的語義鴻溝。而且它們在某些地方並沒有做到這一點，因為它們現在被塞進了每個小子系統和庫中。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，這些綁定會像癌症一樣蔓延到各處，並迅速從一個允許並追求全局改進的軟件項目，轉向日益增加的隔離化。這將使 Linux 變成一個用多種語言編寫的項目，而沒有明確的指南説明在何處使用何種語言。即使在綁定之外，由於內核數據結構（如無處不在的鏈表）的侵入性和自引用特性，許多代碼也不會是非常地道的 Rust。我們是否既對不起那些試圖將現有代碼庫帶入更安全空間的人，也對不起那些用 Rust 進行系統編程的人？&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我曾經在類似的代碼庫上工作過，它們是我最糟糕的噩夢，因為由於原因 X，不斷有部分代碼從語言 A 重寫為語言 B，然後又由於原因 Z 重寫回去。而這還沒有算上 Linux 維護者之間常見的‘創造性’內鬥。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我想了解這個 Rust ‘實驗’的目標是什麼：如果我們想解決現有的內存安全問題，我們需要針對現有代碼進行修復，並找到改進的方法。最近在這方面做了很多工作，我們還需要更多。但這也表明，核心維護者對諸如檢查整數溢出或編譯器強制同步（如 clang hread sanitizer)）等瑣碎事情感到厭煩。我們如何彌合內核中一部分甚至不接受相對簡單的安全改進規則，而另一部分卻強制執行更嚴格規則之間的差距？&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;如果我們只是想使編寫驅動程序更容易，那麼引入一種新語言只會增加更多工作，並加重已經超負荷工作的核心基礎設施維護者的負擔。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，我認為這份政策文件沒有太大用處。目前的規則是，Linus 可以強迫你做任何他想要的事情，我認為他需要非常清楚地闡明這一點，包括對貢獻者的期望。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;就我個人而言，我可以很好地處理 Rust 本身，我很樂意將內核帶入一個更安全的內存世界，但處理一個不受控制的多語言代碼庫肯定會讓我把業餘時間花在其他事情上。我聽到其他一些人嘀咕類似的話，但並不是每個人都像我這樣直言不諱。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Frust-for-linux%2FZ7SwcnUzjZYfuJ4-%40infradead.org%2F&quot; target=&quot;_blank&quot;&gt;查看郵件列表&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334666/linus-torvalds-rust-code</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334666/linus-torvalds-rust-code</guid>
            <pubDate>Sat, 08 Feb 2025 02:34:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中軟國際被曝不協商直接降薪，有人直降 35%，引發員工抗議</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7884923627%2FPeQTeBEot&quot; target=&quot;_blank&quot;&gt;有網友爆料&lt;/a&gt;，華為外包大廠中軟國際員工在公司樓下聚集維權，抗議公司未提前協商突然降薪操作，疑似降薪幅度 10%-35%，甚至還有傳出 0 元工資的極端情況，引發員工強烈不滿。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/102639_R1Xq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/102923_eWur_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，目前 IT 中心產品部確認降薪，其他受影響部門暫不清楚。有員工反映，公司在降薪的同時還在大力拓展新業務，高層薪資福利卻絲毫未減，這讓員工心裏很不平衡。&lt;/p&gt; 
&lt;p&gt;據透露，中軟國際提供了三種選擇：一是按照薪資比例摺合 13 個月+的薪資，多出來的月份按照績效年終發放；第二種方案為直接降薪 18%；或者選擇在 3 月底主動離職。三種方案任選其一，且沒有書面形式，只是口頭通知。更讓員工難以接受的是，此次降薪並未明確説明原因，且強制執行。&lt;/p&gt; 
&lt;p&gt;面對員工的質疑，截至目前，該外包大廠派了一個所謂的辦事員前來收集員工的訴求，並承諾將與高層協商解決。「他們只是來聽我們説話，卻沒有給出任何實質性的答覆。」一位參與溝通的員工表示，「感覺就像是走過場，根本沒有解決問題的誠意。」&lt;/p&gt; 
&lt;p&gt;值得注意的是，據員工爆料，中軟國際的郵箱讓員工可以收到郵件，但是員工發送郵件出去，發件箱和發件記錄是空的，「這是怕員工留痕特意設置的。」該員工表示。更有網友爆料，甲方開價不低，到手的錢卻層層縮水，之前就有裁員 2.2 萬人的先例，現在又不協商直接降薪。&lt;/p&gt; 
&lt;p&gt;資料顯示，中國軟件外包市場規模已突破 4454 億元，年增速超 10%，而該公司作為在岸外包龍頭，客戶包括瞭如華為等互聯網大廠。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334665</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334665</guid>
            <pubDate>Sat, 08 Feb 2025 02:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>李彥宏：文心大模型 4.5 系列將開源，是最強大的文心大模</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在百度 2024 年 Q4 及全年財報電話會上，百度創始人、董事長兼首席執行官李彥宏透露，文心大模型 4.5 將開源，4.5 將是百度有史以來最強大的大模型，「希望客戶和用戶能比之前更方便地體驗這款模型」。&lt;/p&gt; 
&lt;p&gt;他表示，開源 4.5 系列的決策源自於對技術領先地位的堅定信心，開源將進一步促進文心大模型的廣泛應用，並在更多場景中擴大其影響力，「但我想強調的是，無論開源閉源，基礎模型只有在大規模解決現實問題時，才具備真實價值」。未來，百度將加速推動文心大模型的性能升級與成本降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;400&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f76b9accbca6162153bf21f08d99a59ecc.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，李彥宏還在業績會上表示，2025 年是蘿蔔快跑重要的擴張之年。他透露，百度將尋求與移動服務運營商、出租車公司及第三方車隊運營方等合作，以加速業務擴展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334659</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334659</guid>
            <pubDate>Sat, 08 Feb 2025 02:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>天天 AI-20250218</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;DeepSeek 加持，北大通院幾何模型達 IMO 金牌水平！32 個 CPU 核心和 1 塊 4090 就能實現滿血解題&lt;/h3&gt; 
&lt;p&gt;北大通院的 TongGeometry 模型在 DeepSeek 的加持下，達到了國際數學奧林匹克競賽（IMO）金牌水平。該模型不僅能夠解決 IMO-AG-30 數據集中的所有 30 題，還在 IMO-AG-50 數據集上解決了 42 題，超越了人類金牌選手的平均水平。TongGeometry 通過使用歸納數據庫方法（DD）、構造對稱圖形、利用策略網絡和價值網絡聯合搜索等技術，實現了高效解題。此外，該模型還具備出題能力，其生成的題目已被權威數學競賽收錄。值得注意的是，TongGeometry 僅需 32 個 CPU 核心和 1 塊 4090 顯卡即可實現滿血解題，展現了極高的效率。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Feswmr-dcYx_oeYrKJwX0qQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;6 個 DeepSeek 指令，讓 AI 成為你的超級助手！掌握這些，效率翻倍！&lt;/h3&gt; 
&lt;p&gt;在信息爆炸的時代，高效處理複雜信息、全面分析問題、精準預測趨勢已成為現代人必備的技能。而 DeepSeek，作為一款強大的 AI 工具，憑藉其獨特的指令功能，能夠幫助你輕鬆應對這些挑戰。今天，我們就來揭祕 DeepSeek 的 6 個神奇指令，讓你在內容傳播和推廣中如虎添翼！&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIBow-N4IFbwNKEQGmuWdNQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;大決戰！OpenAI 可能發佈 GPT-4.5，狙擊馬斯克 Gork3&lt;/h3&gt; 
&lt;p&gt;OpenAI 首席執行官 Sam Altman 透露，GPT-4.5 已進入測試階段，可能在近期發佈。這一消息正值馬斯克宣佈發佈「地球最聰明的 AI」——Gork3 之際，引發了行業的廣泛關注。GPT-4.5 被認為是對抗 Gork3 的有力武器，OpenAI 團隊甚至計劃在 Gork3 發佈後決定是否推出 GPT-4.5。這一競爭不僅展示了 AI 領域的激烈競爭，也預示着未來 AI 技術的快速發展。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX33kBcSq3ieMSfPx-gnW_Q&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;10W+爆款 AI 流水線：Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版&lt;/h3&gt; 
&lt;p&gt;熬夜趕稿、追熱點到頭禿、爆文全靠運氣……這些是不是你創作路上的「噩夢」？別急，這裏有個祕密武器，能讓你輕鬆告別這些煩惱，甚至讓爆款內容像印鈔機一樣源源不斷！想知道是什麼「黑科技」嗎？往下看，解鎖 15 分鐘生成爆款的神奇公式！&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSA9KUAscPemgXMnwDssHyw&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;深圳上線 70 名「AI 員工」，滿足 240 個政務場景&lt;/h3&gt; 
&lt;p&gt;深圳福田區上線了基於 DeepSeek 開發的「AI 數智員工」，覆蓋政務服務全鏈條 240 個場景。這些「AI 員工」能夠處理公文、提供民生服務、支持應急管理等任務。福田區政務大模型 2.0 版以 DeepSeek R1 為核心，通過混合專家架構（MoE）和強化學習技術，實現了高效、精準的政務服務。該模型不僅提升了公文處理和審核效率，還為招商引資、執法文書生成等場景提供了強大支持。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcRalKSPJxLYgzsApONMTUw&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Adobe 發佈全新生成式 AI 應用 Firefly，進軍商業化&lt;/h3&gt; 
&lt;p&gt;Adobe 推出了生成式 AI 應用 Firefly，集成了圖像、矢量圖形和視頻生成功能。Firefly 支持從文本提示生成高質量視頻，並提供多種語言翻譯功能，能夠將音頻翻譯成 20 多種語言。該應用還與 Adobe 全家桶深度集成，支持無縫切換和創作流程優化。Firefly 的推出標誌着 Adobe 在生成式 AI 領域的商業化佈局，為創意產業帶來了革命性體驗。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-AiIZ08-vk1-xWOPt7a97A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;搞定 DeepSeek R1 部署，這個開源項目有點東西！&lt;/h3&gt; 
&lt;p&gt;開源項目 GPUStack 為 DeepSeek R1 的部署提供了高效解決方案。該項目支持 Windows、Linux 和 macOS，能夠自動處理資源分配，支持多機協同計算和異構硬件適配。GPUStack 通過分佈式推理技術，解決了單機資源不足的問題，使 DeepSeek R1 能夠在各種硬件環境下穩定運行。此外，GPUStack 還支持模型管理、高可用性、監控與可視化等功能，為 AI 模型的部署和管理提供了全面支持。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FQmbVjWXO2tGNPFHIjwfa3A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;清華最新綜述解讀，大模型推理能力的進化之路！&lt;/h3&gt; 
&lt;p&gt;清華大學發佈了一篇關於大模型推理能力發展的綜述論文，全面梳理了 LLM 推理能力的進化路徑。論文指出，大模型的推理能力建立在預訓練、微調和對齊三個關鍵階段之上。高質量的推理數據和先進的訓練方法（如強化學習）是提升模型推理能力的關鍵。此外，論文還探討了測試時優化技術（如樹搜索和集束搜索）對提升推理能力的作用。該綜述為理解大模型推理能力的發展提供了重要參考。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FY_bmJUObwyoD0AI6yCqYIQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;微信也接不住 DeepSeek 的流量？&lt;/h3&gt; 
&lt;p&gt;微信開始灰度測試接入 DeepSeek R1，用戶可以在微信搜索中體驗 AI 搜索功能。這一舉措不僅是微信對 AI 技術的積極探索，也反映了騰訊對流量變現的佈局。儘管 DeepSeek 的接入帶來了高昂的算力成本，但微信希望通過 AI 技術提升用戶體驗，吸引更多用戶。此外，騰訊旗下的多個產品也在持續接入 DeepSeek，顯示出騰訊在 AI 領域的全面佈局。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJ9XMqSdz00x_TFsMXRZbfg&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;DeepSeek 顛覆了什麼？學習不靠「人盯」，AI 自己「卷」自己&lt;/h3&gt; 
&lt;p&gt;DeepSeek 通過純強化學習路線，顛覆了傳統 AI 訓練模式。其 R1 模型證明瞭無需過程監督，僅通過結果控制即可訓練出優秀的推理模型。DeepSeek 的 Zero 研究展示了模型自主生成思維鏈的能力，為 AI 的平民化鋪平了道路。此外，DeepSeek 在語言文字創作和風格模仿方面也取得了顯著突破，進一步拓展了 AI 的應用範圍。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsYRgyuGy7rE5sfMjzHsWlA&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;比亞迪掀起「全民智駕」風暴：接入 DeepSeek，7 萬級車型標配高階智駕&lt;/h3&gt; 
&lt;p&gt;比亞迪發佈了「天神之眼」高階智能駕駛系統，將高階智駕功能推廣至 7 萬級車型。該系統由比亞迪全棧自研，能夠實現全程高速自動駕駛和城區穩定駕駛。比亞迪還宣佈將接入 DeepSeek R1 大模型，進一步提升車輛的智能化水平。這一舉措標誌着智能駕駛技術的普及化，為未來交通帶來了新的可能性。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6hNhK_NmeKCsAcE0QnS80A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;馬斯克用程序員和 AI 算法「整頓」華盛頓，此刻已亂成一鍋粥&lt;/h3&gt; 
&lt;p&gt;馬斯克領導的 DOGE（政府效率部）正在通過 AI 技術和高強度工作模式對美國聯邦政府機構進行「現代化改造」。DOGE 團隊由一羣年輕工程師組成，他們被賦予極高權限，直接接入財政部、教育部等核心部門的數據庫，利用 AI 算法審查開支、識別欺詐行為，並推動自動化流程。馬斯克甚至聲稱，AI 已發現財政部每年有高達 500 億美元的可疑支出。此外，DOGE 還計劃開發名為「GSAi」的生成式 AI 聊天機器人，用於梳理政府合同和採購數據。然而，這一系列激進措施引發了爭議，許多聯邦機構員工面臨裁員，部分項目被暫停，甚至引發了多起法律訴訟。批評者認為，馬斯克的團隊缺乏透明度和問責機制，可能對公共服務造成負面影響。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5Co4_4bNFiZCc9x7opxuvA&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;DeepSeek 衝擊之下，大模型六小強如何「回應」？&lt;/h3&gt; 
&lt;p&gt;DeepSeek 的出現對全球大模型市場產生了巨大沖擊。國內六家獨角獸大模型公司（零一萬物、百川智能、階躍星辰、智譜華章、月之暗面、MiniMax）紛紛採取行動應對。零一萬物與蘇州高新區合作，成立產業大模型基地，聚焦垂直產業解決方案；百川智能發佈全場景推理大模型 Baichuan-M1-preview，並推出「AI 兒科醫生」；階躍星辰發佈多款新模型，並在應用中接入 DeepSeek；智譜華章繼續與三星合作，推動大模型在手機端的應用；月之暗面發佈 Kimi k1.5 多模態思考模型；MiniMax 開源 MiniMax-01 系列模型，推動技術進化。這些動作表明，大模型公司正在通過技術創新和產業合作來應對 DeepSeek 帶來的挑戰。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FfdbEWhQekN1w3WvI_vCg7A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1100 萬人都在玩的 AI 視頻神器，三步把你 P 進任何名場面&lt;/h3&gt; 
&lt;p&gt;Pika 是一款 AI 視頻工具，最近推出了 Pikaddition 功能，允許用戶通過簡單的三步操作將任何圖片融入視頻中。用戶只需上傳視頻和圖片，並輸入提示詞，Pika 就能生成融合效果。該功能支持多種創意玩法，例如將人物融入影視名場面、製作表情包等。儘管 Pika 的特效可能不是專業級，但其低門檻和高趣味性吸引了大量用戶，註冊用戶已突破 1100 萬。此外，Pika 還推出了 Pikamemes 功能，一鍵生成表情包，進一步降低了 AI 視頻創作的門檻。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjcUdGPLBYHV6TT5zuOhK7Q&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;政務雲，DeepSeek 下一個風口？&lt;/h3&gt; 
&lt;p&gt;多地政務系統開始接入 DeepSeek 大模型，推動政務數字化轉型。山東煙台、蘇州、廣州、深圳、無錫等地已部署 DeepSeek 模型，用於提升政務服務效率、優化數據管理和降低錯誤率。例如，深圳市的「AI 公務員」錯誤率控制在 5% 以內，顯著提升了政務處理效率。相關研報指出，DeepSeek 的開源特性為雲服務廠商提供了低門檻部署世界級 AI 應用的機會，政務雲作為重要細分領域有望加速發展。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeAlm4IVXiqpJXRizqMCywQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;🔥 熱門文章推薦（2AGI.NET）&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250218&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 18 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250217%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250217&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 17 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2F10w-plus-hit-ai-pipeline-coze-depth-writing-deepseek-algorithm-insight-html-fast-typesetting%2F&quot; target=&quot;_blank&quot;&gt;10W+爆款 AI 流水線：Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 16 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fexploring-the-secrets-of-world-models%2F&quot; target=&quot;_blank&quot;&gt;探索世界模型奧祕&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 16 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Funderstanding-intelligent-emergence%2F&quot; target=&quot;_blank&quot;&gt;如何理解智能湧現（emergence）&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 15 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250214&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 14 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250213%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250213&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 13 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250212%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250212&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 12 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250211%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250211&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 11 日&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;掃碼加入社羣，參與討論&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img alt=&quot;2AGI 技術社區，歡迎掃碼加入&quot; height=&quot;558&quot; src=&quot;https://oscimg.oschina.net/oscnet//88cbcd3a747ff3c416c80d739b5a3a82.png&quot; width=&quot;1180&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fagi%2F&quot; target=&quot;_blank&quot;&gt;AGI&lt;span&gt;(102)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-agent%2F&quot; target=&quot;_blank&quot;&gt;AI Agent&lt;span&gt;(3)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-app%2F&quot; target=&quot;_blank&quot;&gt;AI App&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-celebrity%2F&quot; target=&quot;_blank&quot;&gt;AI Celebrity&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Faigc%2F&quot; target=&quot;_blank&quot;&gt;AIGC&lt;span&gt;(126)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e5%2590%258d%25e4%25ba%25ba%25e5%25a0%2582%2F&quot; target=&quot;_blank&quot;&gt;AI 名人堂&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e6%2590%259c%25e7%25b4%25a2%2F&quot; target=&quot;_blank&quot;&gt;AI 搜索&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai%25e6%2595%2599%25e7%25a8%258b%2F&quot; target=&quot;_blank&quot;&gt;AI 教程&lt;span&gt;(7)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e6%2595%2599%25e7%25a8%258b%2F&quot; target=&quot;_blank&quot;&gt;AI 教程&lt;span&gt;(2)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai%25e7%2594%259f%25e4%25ba%25a7%25e5%258a%259b%25e5%25b9%25b3%25e5%258f%25b0%2F&quot; target=&quot;_blank&quot;&gt;AI 生產力平台&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai%25e7%2594%25b5%25e5%25bd%25b1%25e5%2588%25b6%25e4%25bd%259c%2F&quot; target=&quot;_blank&quot;&gt;AI 電影製作&lt;span&gt;(2)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fclaude%2F&quot; target=&quot;_blank&quot;&gt;Claude&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fclaude-3-5-sonnet%2F&quot; target=&quot;_blank&quot;&gt;claude 3.5 sonnet&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fcoze%2F&quot; target=&quot;_blank&quot;&gt;Coze&lt;span&gt;(2)&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334648</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334648</guid>
            <pubDate>Sat, 08 Feb 2025 01:11:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
    </channel>
</rss>