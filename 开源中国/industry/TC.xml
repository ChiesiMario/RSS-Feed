<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 17 Apr 2025 07:36:44 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Spark on K8s 在 vivo 大數據平台的混部實戰</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網大數據團隊- Qin Yehai&lt;/p&gt; 
 &lt;p&gt;在離線混部可以提高整體的資源利用率，不過離線 Spark 任務部署到混部容器集羣需要做一定的改造，本文將從在離線混部中的離線任務的角度，講述離線任務是如何進行容器化、平台上的離線任務如何平滑地提交到混部集羣、離線任務在混部集羣中如何調度的完整實現以及過程中的問題解決。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、在離線業務差異&lt;/h1&gt; 
&lt;p&gt;互聯網數據業務服務一般可以分為在線服務和離線任務兩大類，在線服務是指那些長時間運行、隨時響應對實時性要求高、負載壓力隨着接收流量起伏的服務，如電商、遊戲等服務，離線任務是指運行週期短、可執行時間提交對實時性要求低、有一定容錯性、負載壓力基本可控的服務，如離線計算任務、模型訓練等。一般在線服務在白天時段繁忙，離線任務在凌晨繁忙，兩者的業務高峯期存在錯峯現象，如果按傳統方式在線和離線都是分別獨立機器部署，業務高峯時期需要更多機器來支持，業務低峯期又存在部分機器空閒，整體資源利用率都不高。因此行業提出來在離線混部的解決方案，在線和離線業務通過混部系統部署在同一批機器，實現共享資源並錯峯互補，提高整體的資源利用率。目前業內利用混部技術可以將數據中心的 CPU 利用率提升至 40% 左右，vivo 在 2023 年混部平台投入生產也已經將部分混部集羣的 CPU 利用率提升至 30% 左右，整體收益也是可觀的。&lt;/p&gt; 
&lt;p&gt;混部系統需要有強大的隔離能力，絕大部分都是基於容器，所以混部的前提是在線和離線業務都容器化，對於容器管理工具如 K8s 來説是更適應於運行時間長、啓停次數少、容器數量少的在線服務，在線服務也能比較容易地上容器，而對於運行時間短、啓停頻繁、容器數量大的離線任務，對 K8s 來説不是天然地適應，但容器化已是大勢所趨，K8s 也推出了性能更好的調度器、用於離線任務的控制器，Spark 在 2.3 版本後也支持容器化，諸多技術的發展也推動離線任務實現容器化以及在離線混部的落地。&lt;/p&gt; 
&lt;p&gt;本文將從在離線混部中的離線任務的角度，講述離線任務是如何進行容器化、平台上的離線任務如何平滑地提交到混部集羣、離線任務在混部集羣中如何調度的完整實現以及過程中的問題解決。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、離線任務容器化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Spark Operator 方案&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 方案對比&lt;/h3&gt; 
&lt;p&gt;vivo 離線任務大部分任務是以 Spark 作為執行引擎，Spark 任務運行在 K8s 上，目前業界有兩種架構的方案：Spark on K8s 及 Yarn on K8s。兩者部分優缺點對比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//944f211eda9a472ce3e9c7cc7342579a.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark on K8s 是 Spark 容器化，由 K8s 直接創建 Driver 和 Executor 的 Pod 來運行 Spark 作業，Yarn on K8s 是 Yarn 的容器化，由 K8s 創建 RM 和 NM 的 Pod，Spark 的 Driver 和 Executor 運行在 NM Pod 的 container 中，正是由於兩種架構方案的區別，它們各自也會存在優缺點。&lt;/p&gt; 
&lt;p&gt;Yarn on K8s 方案可以支持原生的 Hive、Spark、Flink 等引擎，它僅需要創建一定數量的 NodeManager Pod 來滿足作業需求，Pod 運行相對穩定因此對 K8s 的壓力比較小，本身 Yarn 支持調度性能和調度策略也是專門為離線任務設計的，調度性能比 K8s 的強很多。由於 NodeManager ESS 服務是對磁盤有容量和讀寫性能要求的，混部機器的磁盤一般難以滿足，所以也需要能支持不同引擎的 Remote Shuffle Service。在資源利用上，NodeManager 需要滿足多個作業的資源，最小單位是 Container，Pod 的資源粒度比較大，自身也會佔用一些資源，如果資源粒度得不到有效地彈性伸縮，也會造成資源的浪費，因此需要引入額外的組件來協調,根據 Kubernetes 集羣節點的剩餘資源，動態調整 NodeManager 的 CPU 和內存，然而這也需要一定的改造成本。在資源緊張的情況下，NodeManager Pod 如果被驅逐也就意味着整個 NodeManager 被銷燬，將會影響多個任務。&lt;/p&gt; 
&lt;p&gt;Spark on K8s 方案目前在 Spark 3.1 以上版本才正式可用，它需要頻繁的創建、查詢、銷燬大量的 Executor Pod，對 K8s 的 ApiServer 和 ETCD 等組件都會造成比較大的壓力，K8s 的調度器也不是專門為離線的大批量任務設計的，調度性能也比較弱。另一方面，Spark on K8s 雖然只能支持 Spark3.X 的 RSS，不過目前有較多的開源產品可選擇。在資源利用上，最小單位是 Driver 和 Executor 的 Pod，資源粒度小，可以填充到更多的碎片資源，調度時直接與 K8s 對接，資源的彈性調度更多由 K8s 來承擔，不需要額外的組件，改造成本比較低。在資源緊張的情況下，Executor、Driver 的 Pod 將依次逐個被驅逐，任務的穩定性會更高。&lt;/p&gt; 
&lt;p&gt;而對於 Spark on K8s 方案，還細分 2 種實現方案：Spark Submit on K8s 和 Spark Operator on K8s。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//65d397e91ee4e5dc2fd2dc1392df5e8c.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SparkOnK8s 架構圖&lt;/p&gt; 
&lt;p&gt;(圖片來源：Spark 官網)&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9690ad754f277e44ce4a6a09f6f7058a.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark Operator 架構圖&lt;/p&gt; 
&lt;p&gt;(圖片來源：Spark Operator 開源項目)&lt;/p&gt; 
&lt;p&gt;以 spark-submit 方式提交到 K8s 集羣是 Spark 在 2.3 版本後提供的原生功能，客戶端通過 spark-submit 設置 K8s 的相關參數，內部再調用 K8sApi 在 K8s 集羣中創建 Driver Pod，Driver 再調用 K8sApi 創建需要的 Executor Pod，共同組成 Spark Application，作業結束後 Executor Pod 會被 Driver Pod 銷燬，而 Driver Pod 則繼續存在直到被清理。使用 spark-submit 方式的最大好處是由 spark-submit 來與 K8s 的進行交換，提交作業的方式幾乎保持一致。但是因為使用的便利性所需要的封裝也會帶來一些缺點，spark-submit 是通過 K8sApi 創建 Pod，使用非聲明式的提交接口，如果需要修改 K8s 配置就需要重新開發新接口，二次開發複雜繁瑣，雖然 Spark 提供了大量的 K8s 配置參數，但也遠比不了 K8s YAML 的聲明式的提交方式更加靈活，而且 Spark Application 和 K8s Workload 的生命週期還不能較好地對應起來，生命週期不能靈活控制，任務監控也比較難接入 Prometheus 集羣監控。雖然 Spark 社區也不斷地在推出新特性來和 K8s 集成地更加靈活，不過對於些複雜場景需要定製開發，spark-submit 的封裝性也會成為阻礙。&lt;/p&gt; 
&lt;p&gt;spark-submit 還是離線任務提交的思維，而 Spark Operator 方式就更傾向於 K8s 作業的思維，作為 K8s 的自定義控制器，在集成了原生的 Spark on K8s 的基礎上利用 K8s 原生能力提供了更全面管控功能。Spark Operator 使用聲明式的 YAML 提交 Spark 作業，並提供額外組件來管理 Spark 作業的生命週期，SparkApplication 控制器，負責 SparkApplicationObject 的創建、更新和刪除，同時處理各種事件和作業狀態，Submission Runner, 負責調用 spark-submit 提交 Spark 作業，Driver 和 Executor 的運行流程是一致的，Spark Pod Monitor，負責監控和同步 Spark 作業相關 Pod 的狀態。Spark Operator 最大的好處是為在 K8s 中的 Spark 作業提供了更好的控制、管理和監控的功能，可以更加緊密地與 K8s 結合並能靈活使用 K8s 各種特性來滿足複雜場景，例如混部場景，而相對地它也不再像 spark-submit 那樣方便地提交任務，所以如何使用 Spark Operator 優雅提交任務將是在離線混部中一項重要的工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 最終選項&lt;/h3&gt; 
&lt;p&gt;在大的架構選型上，我們選擇了 Spark on K8s，一方面因為 Spark3.X 是 vivo 當前及未來 2~3 年的主流離線引擎，另一方面 vivo 有比較完善的 K8s 生態體系，內部對 K8s 研發也比較深入，環境和能力都能很好地支持，在應用的小方向上，我們選擇了 Spark Operator，因為它在混部這種複雜場景下使用更加靈活、擴展性更強、改造成本更低，我們最終決定使用 Spark Operator 方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 Spark 優化&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 Spark 鏡像&lt;/h3&gt; 
&lt;p&gt;Spark 任務容器化的第一步就是構建具有 Spark 相關環境的鏡像，Spark 任務類型主要分為 sql 任務和 jar 任務，在實踐的過程中我們發現 Spark 的鏡像構建需要&lt;strong&gt;注意幾個問題&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark 環境的完整性&lt;/strong&gt;：鏡像中除了打入自研的 Spark 包以外，還需要打入相應的依賴如 Hadoop、ZSTD、RSS 等包，對於 SparkJar 任務還有直接調用 Hadoop 客戶端的，因此 Hadoop 客戶端也需要打入鏡像中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JDK 版本問題&lt;/strong&gt;：K8s 使用的 Spark 是基於 3.2.0 版本，鏡像打包工具默認使用 JDK11，而自研的 Spark 用的 JDK1.8，由於在 Yarn 和 K8s 上使用的 JDK 版本不同，導致在雙跑驗證數據一致性時發現了 hash 函數、時間戳不一致的問題，因此 Spark 鏡像中的 JDK 版本需要和 Yarn 保持一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;環境變量問題&lt;/strong&gt;：鏡像生成容器後需要預置如 Spark、Hadoop 的環境變量，如果鏡像中相關目錄的位置不能完全和 Yarn 的提交節點保持一致，則需要檢查各啓動腳本，如 spark-env.sh 中的環境變量的路徑是否存在，發生衝突時可以修改為絕對路徑。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Spark 鏡像構建完成後，區分 SparkSql 任務和 SparkJar 任務實質就是啓動命令的不同，事實上 SparkSql 任務也就是 SparkJar 任務的一種，只是啓動的主類是固定的，兩者的啓動參數如下：&lt;/p&gt; 
&lt;p&gt;SparkSql 任務：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver -f {sql 文件}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SparkJar 任務：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class {jar 任務主類} {jar 任務 jar 包} {參數}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;早期不僅構建了 Spark 鏡像，還構建了 Spark 日誌鏡像，容器組成結構會複雜一些。如圖例如 Driver 容器，我們將 Spark、Hadoop 等配置文件構建了 configMap，啓動 initContainer 來拉取從 configMap 拉取配置文件，然後啓動 Driver 容器執行 Spark 任務，同時也使用 sidecar 創建日誌上報的容器，在 Spark 任務運行完成後上報 Driver 和 Executor 日誌到 Spark HistoryServer。這樣的方案看似充分應用了 K8s 技術，但是在實踐的過程中這些技術卻被一一棄用，轉而逐步地把各種功能集中到了一個 Driver 容器上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c1f0bf5a2f03578b42831a80908e1aad.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體演進如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 initContainer&lt;/strong&gt;，拉取 Spark 等配置文件步驟寫在啓動命令中，Spark 作業執行前執行下載配置，原因在多個 namespace 下不方便統一管理，而且 configmap 內容較大，會導致 Pod 啓動時配置加載的延遲增加，影響了 Pod 創建速度，同時 K8s 的內存和 CPU 資源佔用增加，對 kube-apiserver、ETCD 負載有一些影響。去掉 initContainer 還有個重要的好處就是減小 ETCD 的存儲壓力，事實上我們在移除 initContainer 拉取配置的功能後的一段時間內還保留着 initContainer，在任務逐漸上量後發現 ETCD 的存儲比較滿，分析後發現 Spark 作業中的一個 Pod 生命週期大約 8 次更新，其中 initContainer 更新會佔用 2 次，移除了之後理論上是可以減少 1/4 的 ETCD 存儲，實際應用中完全去除了 initContainer 也確實能減小了 ETCD 的存儲壓力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 sidecar 創建日誌上報的容器&lt;/strong&gt;，Driver 和 Executor 日誌上報步驟寫在啓動命令中，Spark 作業執行完後再執行腳本上報，原因是 sidecar 在同一個 Pod 中與主容器共享相同的生命週期，不使用 sidecar 方式就能更快創建 Pod，Spark 任務執行完成後能更快釋放資源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於 Spark 作業會頻繁創建、更新和銷燬大量的 Pod，所以去除非必要的容器，提高 Pod 生命週期流轉速度，就能降低 kube-apiserver、ETCD 工作負載，也能提高 Spark 的作業效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 Spark 改造&lt;/h3&gt; 
&lt;p&gt;Spark 任務運行在 K8s 上，對於一些使用的兼容問題也進行了&lt;strong&gt;相關改造&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HistoryServer 改造&lt;/strong&gt;，因為 Spark Operator 沒有存儲已結束作業的日誌，因此參考了 on Yarn 的方式，在 Spark 作業結束後，通過日誌上傳腳本把 Driver 和 Executor 的日誌上傳 HDFS，與 Yarn 日誌聚合類似，同時也在 Spark HistoryServer 做了二次開發工作，增加了 on K8s 方式的日誌查看接口，用戶查看已完成的 Executor 日誌時，不再請求 JobHistory Server，而是請求 Spark HistoryServer 接口。但日誌上傳方式需要 Executor 執行完才能查看到日誌，為了能實時查看到執行中的日誌，可以在 Executor 內部實現一個 HTTP 服務，根據 Pod 以及端口信息拼接出日誌請求 URL，Executor 啓動一個 Servlet 自動獲取本地日誌並返回。日誌查看體驗上做到了基本與 Yarn 一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主機 ip 通信&lt;/strong&gt;，Spark Driver 和 Executor 之間的通信通常是通過主機名進行的，不過隨着 Spark 任務增多，CoreDNS 因為頻繁的域名解釋請求導致壓力增大，甚至會影響到在線服務，因此我們將 Hadoop 的配置文件改為 ip 格式、設置 Driver 和 Executor 使用 ip 地址，同時去除了對應的 K8s Service，通過訪問 ip 而不是域名的方式來規避這個問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件參數兼容&lt;/strong&gt;，Spark Driver 在 K8s 上是運行在某一個 Pod 中的，所以文件需要是全局可視的，如 HDFS 文件，否則就會報文件未找到的錯誤，但 Spark 作業運行在大數據作業平台時有的任務使用的上傳的本地文件，因此對於提交到 K8s 的任務，第一步是要把上傳到大數據作業平台的文件再次上傳到 HDFS，第二步是改造 add jar 和--file 等命令邏輯，Spark 任務在未能讀取本地文件後將再嘗試讀取二次上傳到 HDFS 的文件，實現任務無需修改成全局可視的文件路徑也能讀取到文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;non-daemon 線程終止&lt;/strong&gt;，在 K8s 上運行的 Spark 任務是指定 Client 模式，Client 模式下 Driver 遇到異常時停掉 SparkContxet，等所有 non-daemon 線程結束後，Driver 才會退出，但如果存在一直運行的 non-daemon 線程，那麼 Driver 一直不退出，任務就一直處於執行中。因此需要改造成 Cluster 模式的異常退出機制，即異常時以非 0 退出碼退出，不再等待其他的 non-daemon 線程結束，Driver 直接終止，以確保 Driver Pod 的正常結束。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Spark Operator 優化&lt;/h2&gt; 
&lt;p&gt;隨着在 K8s 上運行的 Spark 任務不斷增加，K8s 集羣的負載也逐漸顯現。因此，需要對 Spark Operator 進行一系列優化，以減輕 K8s 集羣的壓力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;離線使用獨立的 kube-apiserver&lt;/strong&gt;，混部集羣中離線容器佔了很大一部分，而且離線任務由於生命週期短，容器創建銷燬更加頻繁，這對 kube-apiserver 造成了很大的壓力，然而在線業務需要更高的穩定性，為了減少離線對在線業務的影響，我們拆分了 kube-apiserver，離線任務通過指定 master 參數來使用獨立的 kube-apiserver。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 K8s 的 HostNetwork 網絡模式&lt;/strong&gt;，在 K8s 上啓動 Driver 與 Executor 雖然使用的是獨立 ip+固定端口，但頻繁的 ip 申請和釋放也對 kube-apiserver 造成了一定的壓力，因此我們改為使用 HostNetwork 網絡模式，同時不指定端口避免端口衝突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化 Spark Operator 控制器的隊列&lt;/strong&gt;，在任務量比較大的情況下，Spark Operator 對 Pod 創建消耗效率會遇到瓶頸，排查後發現是 Spark Operator 的事件處理隊列的併發數和限速桶的默認配置地太小，因此我們調低 Spark maxPendingPods 參數，調高 schedulerBacklogTimeout、 sustainedSchedulerBacklogTimeout 參數，減少 Pending Pod 個數，使 Pod 的處理效率符合集羣的承載水平。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化 Spark Driver List Pod 接口&lt;/strong&gt;，使用 kube-apiserver 緩存，避免對 ETCD 產生影響，同時修改 Spark Driver 清理 Executor 邏輯，直接 Delete，減少 List Pod 對 kube-apiserver 壓力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存儲 emptydir + log lv 存儲優化&lt;/strong&gt;，開發 CSI 插件，Spark 任務的離線日誌單獨存儲，避免對在線業務 pod 的影響和磁盤負載高等問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark Secret 標記 immutable&lt;/strong&gt;，減少 kubelet watch secret 請求，降低 kube-apiserver 的負載。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、離線任務提交&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 平台任務提交平滑切換&lt;/h2&gt; 
&lt;p&gt;離線任務容器化方案確定後就要落地到生產，目前有 SparkSql 和 SparkJar 兩種離線任務實現了容器化，這裏以 SparkSql 任務為例描述 Spark 提交到混部 K8s 集羣的流程並達到與傳統客戶端提交任務幾乎無差異的平滑切換。目前 vivo 的離線任務都是通過大數據平台進行提交和調度的，平台會把主要的提交流程進行封裝形成簡單操作的功能，例如在平台上提交 SparkSql 任務流程一般是編寫 sql、提交任務、查看 Driver 日誌或在跳轉到 SparkUI、執行完成後獲取結果以及更新任務狀態。&lt;/p&gt; 
&lt;p&gt;在平台內部，SparkSql 任務使用傳統的 spark-submit&lt;strong&gt;提交流程&lt;/strong&gt;是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用戶編寫好的 sql 上傳到提交節點生成一個 sql 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交節點使用 Spark 客戶端執行該 sql 文件啓動 SparkSql 任務；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務啓動後，通過不斷地 tail 操作查詢日誌轉存到 HBase 方便在平台頁面上查詢到 Driver 日誌；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務結束後，再查詢輸出結果轉存到 HBase 方便在平台頁面上查詢到執行結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根據提交 sql 任務命令的返回碼來更新任務狀態。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;傳統 Spark 客戶端提交任務大部分只會涉及到提交節點的客戶端與平台服務器之間的交互，而 SparkSql 任務提交到混部 K8s 集羣，從上節的 Spark 容器化方案的原理可知最終目的是要將 Spark 任務的任務參數按一定的格式封裝好傳入 Spark Operator 控制器來創建相關的容器，平台需要通過會調用容器團隊提供的封裝好 K8sApi 的統一接入層來創建 Spark 容器。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//15dcd589c32637e1dde5ed6757b4eed7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在平台內部，SparkSql 任務提交到混部 K8s 集羣的&lt;strong&gt;完整流程&lt;/strong&gt;為：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用戶編寫好的 sql 上傳到 HDFS 生成一個遠程可訪問的 HDFS 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SparkSql 任務參數封裝好傳入容器接入層的 createSpark 接口來調用 Spark Operator 控制器容器，再由 Spark Operator 控制器創建 Driver Pod，最後由 Driver Pod 根據 Spark 任務需要創建多個 Executor Pod，這些 Driver、Executor 的 Pod 相當於 Driver 和 Executor 的角色，共同配合執行 Spark 作業；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務啓動後，通過容器接入層的 getDriverLog 接口週期性地查詢 Driver 日誌，實質上是查詢 Driver 容器的日誌，查詢到的 Driver 日誌會轉存到 HBase 方便在平台頁面上查詢；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務結束後，一方面通過 Spark 啓動腳本中的日誌上傳命令，把 Driver 和 Executor 的日誌上傳 HDFS，可以在改造後的 Spark HistoryServer 直接查看，另一方面執行結果也會先輸出到 HDFS，再從 HDFS 轉存到 HBase 方便在平台頁面上查詢到執行結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過輪詢接入層的 getSpark 接口根據返回的狀態碼來更新任務狀態，在任務結束後，此時 Driver Pod 不會主動退出，首先將任務狀態更新為成功，在日誌和結果都存儲完成後，再調用 deleteSpark 接口主動地殺死 Driver Pod 釋放資源，完成整個 Spark 任務流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;可以看出 SparkSql 任務提交到混部 K8s 的執行主體是容器，因此需要增加容器接入層來管理 Spark 相關的容器，同時容器的使用更傾向於存算分離的效果，因此需要使用 HDFS 作為遠程文件中轉。&lt;/p&gt; 
&lt;p&gt;大數據平台上傳統使用 spark-submit 和 onK8s 使用 spark-operator 的 SparkSql 任務執行流程對比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//024fa2e15ecb64123b58156eb1fd2188.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 混部任務的資源參數調整&lt;/h2&gt; 
&lt;p&gt;Spark 任務的 Driver 和 Executor，在 Yarn 上執行實質是運行在 NodeManager 節點上的，而在 K8s 上執行實質是運行在對應的 Pod 中的，由於 Spark on K8s 的提交方式和運行環境都不同於 on Yarn，任務的資源參數不能直接套用，需要做一些參數調整才能提交到 K8s 上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、資源參數提取和轉換&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SparkSql 任務在 Yarn 上可以靈活地調整 sql 中的配置來滿足不同特性的任務，sql 中的資源配置會覆蓋客戶端啓動時的全局配置，因為 Executor 是運行在 NodeManager 節點上的，資源會相對充裕能滿足 Executor 的資源需求，與此不同的是 Spark on K8s 的 Executor 是運行在 Executor Pod 中的，使用的資源會受到 Pod 資源規格大小的限制，而 spark-operator 的提交方式是要先獲取 Executor 全局資源規格並生成相應資源規格大小的 Executor Pod，所以在提交 Spark 任務到 K8s 前就要準確地獲取任務真正生效的資源參數。在大數據平台中資源參數會存在多中類型的參數中，參數的優先級為：任務配置參數 &amp;lt; 任務模板參數 &amp;lt; sql 中設置參數 &amp;lt; HBO 優化參數 &amp;lt; 平台統一參數，按此優先級順序依次提取最終的資源參數並傳入容器接入層創建 Spark 作業。另外容器接入層對於 Spark 的 arguments 和 sparkConf 參數都是要求以字符數組的方式傳入，需要做好對原任務參數中的單引號、雙引號、反斜槓和回車等符號以及分段落的處理和轉換。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、overheadMemory 的計算&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Yarn 上 Executor 是運行在 NodeManager 節點上的，節點的資源一般都大於並能滿足 container 申請的資源，所以在 Yarn 上只需要關心 container 本身申請的資源即可，而在 K8s 上 Executor 運行在對應的 Pod 中，可以把 Pod 理解為只一台獨立的節點，除了要滿足 container 申請的資源量，還需要一些 Pod 容運行時網絡、存儲等基礎設施的自身開銷資源，如果把 Spark 任務中 Driver 和 Executor 申請的資源直接設置為 K8s 中 Driver Pod 和 Executor Pod 的資源規格，有可能出現 OOM 情況，另外還要考慮非 JVM 內存，Spark 默認會把申請的 Executor 內存乘以一個係數或者至少預留 384 MiB 內存作為額外的非 JVM 內存緩衝區，用於堆外內存分配、非 JVM 任務以及各類系統進程的使用，可以通過設置 overheadMemory 進行覆蓋。因此 K8s 的 Pod 除了要滿足申請的 Memory 和運行時需要的 overheadMemory 的資源，還會再添加 100M 資源用於 Pod 運行的自身開銷。&lt;/p&gt; 
&lt;p&gt;pod 的資源規格 = memory + pod overheadMemory&lt;/p&gt; 
&lt;p&gt;對於 overheadMemory 也需要先獲取到並加到 Pod 的資源規格，如果任務有配置就直接使用配置的 overheadMemory，如果沒有配置值則按一定計算公式來計算得到。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = overheadMemory + 100M&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;無配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = (max(384M，0.1*memory)) 向上取整到 512MB 的整數倍 + 100M&lt;/p&gt; 
&lt;p&gt;不過在實際應用中發現對於個別任務，即使 K8s 上配置的 overheadMemory 比在 Yarn 的配置多 100M，完全一樣的任務在 K8s 上則有較多的 Executor OOM 情況，而在 Yarn 上卻完全沒有，目前排查到的現象是有 JVM 堆外的內存無法回收，如果任務需要較多的對外內存，堆外內存一直增長最終導致 OOM，但哪些內存無法回收的還未排查到。目前對於這些 OOM 過多且實際影響到運行效率的任務，在原 overheadMemory 基礎上再增加 512M 後就沒有 OOM 情況了，同時也有采用了大數據平台的 HBO 能力自動調整內存參數來事後規避這個問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、CPU 超分配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spark 任務申請的 CPU 使用一般不會使用完，事實上 Executor Pod 的 CPU 利用率也並不是很高，比如 Executor 申請 1 個核，通常只能利用 0.6 個核，存在 CPU 浪費的現象。Executor Pod 的資源規格是創建的時候分配的，利用容器的能力，可以採取 CPU 超分的方式提高 CPU 的利用率，例如 Executor 申請 1 核，實際用 0.6 核，如果 Pod 分配 1 核，那利用率就只有 60%，但如果 Pod 只分配 0.8 核，那利用率就有 75% 了，所以超分的策略就是申請了 1 核只給 0.8 核，但還是要按 1 核的申請量來運行任務。目前平台使用的是靜態的固定比例超分設置為 0.8，實施超分配置策略後 Pod 的實際 CPU 利用率打到 80% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//29fe0829e28d1e2084e2dbba0910de3a.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 混部任務的篩選提交&lt;/h2&gt; 
&lt;p&gt;經過上面的任務提交方式的改造和任務資源參數的調整，原 SparkSql 和 SparkJar 任務就可以平滑切換提交到混部 K8s 上執行了，但在大規模切換之前平台還做了比較長期的雙跑驗證工作，在執行成功率、數據一致性和執行時效等方案都進行了雙跑比較，雙跑通過的任務才能切換到 K8s 上執行。除了雙跑通過，前期還設置了其他的篩選條件如下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//698830de13538cf7b2a6cf67d0b6fa45.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前期按這些條件篩選出可以提交到 K8s 的任務，然後分批的進行 K8s 任務的參數標記，並把標記的這批任務添加監控進行跟蹤。經過雙跑驗證、任務篩選、批量標記、監控跟蹤和問題解決這一整套 SparkSql 任務上量 K8s 的流程，K8s 上的任務運行逐步穩定，K8s 的兼容問題也基本解決，因此目前取消了雙跑通過的這一條件，主要保留了任務重要性、運行時長和重試次數這幾個篩選指標。隨着 SparkSql 任務上量和穩定，提交到 K8s 的任務類型也增加了 SparkJar 任務，SparkJar 任務無法進行雙跑驗證，所以在各種 K8s 兼容問題解決後再推進會更加穩妥。&lt;/p&gt; 
&lt;p&gt;目前大數據平台會定期篩選和標記一批 SparkSql 和 SparkJar 任務允許提交到混部 K8s，用戶也可以自行開啓，在任務配置頁面只顯示已開啓混部，則該任務就有機會被提交到混部 K8s 上執行。當然，用戶也可以手動關閉這一開關，並且手動操作的優先級最高，手動關閉後平台的自動開啓功能將不再生效。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、彈性調度系統&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 彈性調度功能矩陣&lt;/h2&gt; 
&lt;p&gt;Spark 任務開啓了混部也不是必定能提交到混部，最終能不能在混部集羣上執行，還要根據當時混部集羣的資源和運行情況等來確定，為了更好地協調離線任務和混部集羣的供需關係，大數據平台構建了離線任務混部彈性調度系統。彈性調度系統的設計目是混部集羣有資源了就調度離線任務，但在生產環境中不管是混部集羣還是離線任務都會各自的問題需要解決和優化的需求，彈性調度系統也逐步演變成了全面管理離線任務提交到混部以實現混部資源最大化利用的功能矩陣。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.1 資源水位線調度&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//878bdd653f0ec47e7c32fe0b09e8f975.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;彈性調度的流程，任務按調度時間以任務流的形式過來，如果任務標記了允許提交到混部，那就會先去查詢 K8s 的各個集羣，如果某一個集羣資源充足就直接提交到 K8s，如果當時沒有足夠資源就等待資源再判斷，這裏分為有三類任務，第一類是一直等 K8s 資源，永不超時，只會提交到 K8s；第二類是長時間等待，超時時間在 1 到 5 分鐘，可以等久一點；第三類是短時等待，超時時間為 30-60 秒，稍微等一下，如果 K8s 沒有資源就回到 Yarn 上執行，目前平台標記的任務大部分任務都是第三類短時等待。&lt;/p&gt; 
&lt;p&gt;混部集羣提供給離線任務的資源是呈潮汐波動的，使用百分比的水位線方式才能更好地貼合資源的波動情況。混部集羣提供的資源是指 CPU 和內存，但離線任務一般不能百分之百地獲取到這部分資源，需要設置一個折算比例也就是水位線來計算出離線任務能使用的真正資源是多少，水位線的設置需要考慮&lt;strong&gt;幾個因素&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、混部集羣的碎片化率&lt;/strong&gt;，混部集羣中的機器規格和正在運行的業務佔用量都是不確定的，但一般大規格的機器多的集羣碎片化率較低，所以小規格的機器多的集羣的水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、資源動態分配容納率&lt;/strong&gt;，對於開啓了動態分配的 Spark 任務，無法提前知道任務所需的資源，需要留有一部分資源用於動態分配的消耗，如果同樣的水位線資源規模大的混部集羣容納率會高，所以資源規模小的集羣的水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、資源配比的均衡性&lt;/strong&gt;，不同的集羣或者同一集羣的不同時間段的 CPU 和內存配比可能會存在很大的差異，例如 Spark 任務的 CPU 和內存的平均比例是 1 核 6G，即 1:6，如果有 CPU 和內存比為 1:2 的，內存會被用完而 CPU 有剩餘，此時為了內存留有部分餘量，水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部資源可用量 = 混部資源提供量 * 資源水位線&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;資源水位線有 CPU 水位線和內存水位線，設計時以 CPU 或內存中的最低水位線為準，哪個資源先分配完就停止提交任務，不過在實際生產中大部分混部集羣都是受內存限制較多，個別時段 CPU 比內存多但通過其他的限制手段即使 CPU 滿載對任務影響不大，因此目前只開啓了內存資源水位線。以上提到的 3 點可以當成集羣的固有消耗需要保留有一定的餘量，為了直觀地控制混部資源使用率和引入優先策略，計算方式調整為：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部資源可用量 = 混部資源提供量 * (1-餘量水位線) * 優先水位線&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;餘量水位線根據各個集羣來調整，一般為 0.05，優先水位線的範圍可以在 0-1 之間。優先水位線的作用是對於一些符合優先條件的任務可以優先提交，但是任務調度是一有任務就要調度的流式調度，不能夠先集中再挑選優先任務而是先到先得，所以要為優先任務預留一部分資源，例如優先水位線為 0.8，混部資源使用到 0.8 以下的時候任何任務都可以調度上來，但使用量超過了 0.8，那只有優先任務能調上來，也就是為優先任務預留了 0.2 的資源，當然即使資源使用量達到了 1，由於餘量水位線的存在，實際的使用量為 0.95，混部集羣仍有資源維持週轉。優先水位線是最常用的調整參數，它實質就是控制混部任務提交量，不僅能調整混部資源的使用量，還在灰度測試、壓力測試和問題排查等事項起到了靈活調節的作用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.2 其他調度能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1.多集羣管理&lt;/strong&gt;：混部集羣通常會有多個，vivo 目前就有多個生產環境的混部集羣，各混部集羣由於建設週期、機器規格和業務接入的不同，混部資源的規模和變化趨勢都會呈現比較大的差異，因此每個集羣的調度策略配置都需要做到能獨立調整來適應各自的資源特點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.分時段控制&lt;/strong&gt;：每個混部集羣上的在線業務一般是潮汐波動的，給到離線任務的資源也是潮汐波動的，因此每個集羣需要做到在每天不同時段可以調整不同的調度策略，尤其在波峯波谷差異較大的時間段各自調整配置的差異會更大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.分散 namespace&lt;/strong&gt;：Spark 任務的 Driver Pod 和 Executor Pod 都會放在一個 namespace 中管理，如果所有任務都由一個 namespace 管理，那需要管理的 pod 數量會達到數十萬的級別，會對 K8s 集羣的性能和穩定性產生影響。因此需要將 Spark 任務平均分配到多個 namespace，採用的方案是輪詢填充，任務優先分配到多個 namespace 中任務最少 namespace。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.失敗回退 Yarn&lt;/strong&gt;：離線任務混部推進的過程中還有會有 Spark 兼容問題、混部集羣異常和平台變更等問題導致的離線任務在混部 K8s 上運行失敗，為了減少失敗對任務的影響，任務在 K8s 上首次執行失敗後就會自動回到 Yarn 重新執行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.資源准入粒度&lt;/strong&gt;：各混部集羣的機器規格和碎片率是不一樣的，如 executorMemory=2G 這樣較小粒度的 Spark 任務即使碎片率較高的混部集羣可以填充，而對於 executorMemory=16G 這樣較大粒度的 Spark 任務，機器規格大的集羣才更容易獲取到資源，因此不同混部集羣可以設置不同的准入粒度，小規格和碎片率高的集羣准入粒度可以設置小一些。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6.任務偏好配置&lt;/strong&gt;：對於一些灰度任務和特殊要求的任務，例如只有在 0 到 8 點才允許提交到混部、只提交到某幾個指定的混部集羣等調度要求，需要支持任務偏好配置，在任務參數中調整混部控制參數實現相應的調度需求。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 彈性調度策略優化&lt;/h2&gt; 
&lt;p&gt;彈性調度的核心是通過資源水位線的調節，有混部資源就調度離線任務，但實際生產中還要考慮混部集羣的運行情況，是否能穩定地接收和消化離線任務，同時在存在多個差異較大的集羣時提交到哪個集羣最優。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1 任務調度穩定優化&lt;/h3&gt; 
&lt;p&gt;大數據平台的離線任務提交高峯在凌晨時段而且調度時間集中在整點半點，還有 5 分和 10 分這樣的整分，例如 03:00 調度的任務達 1000 個，但在 03:01 調度的任務只有 10 個，過於集中地提交任務會導致混部集羣 Pending Pod 數量急劇上升，這是因為無論是查詢集羣資源還是 Pending 數的接口，更新數據都需要一定的週期時間，而且離線任務提交上去到獲取資源也受 K8s 的調度時間的影響，所以獲取集羣運行情況總會滯後於任務提交。例如 03:00 查詢集羣是有資源的並且是健康的，由於任務開啓了動態分配所以不能確定需要多少資源，此時集中提交了 1000 個任務，這 1000 個任務首先會創建 1000 個 Driver Pod，集羣資源還是能滿足的並且優先創建，假如每個 Driver 需要創建 100 個 Executor，如果集羣沒有這麼多資源，那就會產生大量的 Penging Pod，嚴重影響集羣的性能和穩定以及任務的執行效率，因此需要對彈性調度的穩定性進行優化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短時提交限制&lt;/strong&gt;：避免集中提交任務的直接方案就是根據各混部集羣的資源規模設置短時提交的任務數量限制，例如 1 分鐘內只能提交 100 個任務，集羣短時間內 Pending Pod 數量會增加但仍在可以承受範圍內，集羣和任務都會穩定運行。短時提交限制相當於攔截並捨棄了部分某個時間點集中提交的任務，這裏相當於捨棄了 900 個任務，那麼提交的總任務量就減少了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;延遲打散提交&lt;/strong&gt;：為解決短時提交限制導致捨棄部分任務的問題，增加了短時延遲打散提交，例如 03:00 提交的 1000 個任務，隨機打散到 03:00 到 03:03 的 3 分鐘內，即使有短時提交限制，這 3 分鐘內也可以提交 300 個任務。理論上將集中提交的任務延遲更久，能提交到混部的任務會更多，但是增加延遲時長就等於增加任務的執行時長，會影響到業務數據產出的及時性，因此延遲打散提交策略只能是短時的，進一步的優化是執行時長更久的任務延遲更久一點，但根本解決方案還是用戶能將調度時間儘量打散。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集羣反饋限制&lt;/strong&gt;：短時提交限制和延遲打散提交都屬於靜態限制，需要人為地根據各個混部集羣的情況去判斷和設置限制值，因此需要做到動態限制，就需要獲取集羣的運行情況並根據運行情況進行限制。事實上 K8s 的調度性能相比於 Yarn 還是有差距的，從提交的 Spark 任務到獲取到資源運行 Pod 有一定的滯後時間差，這段時間查詢內還是有剩餘資源，但如果還繼續提交新任務就會產生更多 Pending Pod，因此需要做集羣運行情況的反饋控制，例如查詢 Pending Pod 數、等待的 SparkApp 數，當數量達到一定數量就不再提交新任務。&lt;/p&gt; 
&lt;p&gt;集羣反饋限制雖然是動態的能根據混部集羣情況進行反饋調節，但是查詢集羣狀態是滯後的，這種滯後的控制就容易被集中提交給打垮，所以要加上短時提交限制來上一道保險，為緩解短時提交限制造成的任務損失，就引入了延遲打散提交，而在延時打散的過程中集羣能逐步消化任務，查詢集羣狀態逐步接近真實情況，這時又可以交給集羣反饋限制來動態調節，逐步從突增恢復到穩定，三個調度穩定優化策略相輔相成。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 集羣分配均勻優化&lt;/h3&gt; 
&lt;p&gt;離線任務會調度到多個混部集羣，每個集羣的資源總量和可用資源量，以及集羣運行狀況都不相同，為保證離線任務的運行穩定和執行效率，需要在多個混部集羣中選擇一個最合適的集羣。各個集羣會按一定的規則進行排序，離線任務會按這個排序依次輪詢各個集羣，只要集羣剩餘資源滿足且沒有被短時提交限制、集羣反饋限制等拒絕，離線任務就提交到該集羣。集羣排序的&lt;strong&gt;演化順序&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;①初始方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排隊隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;剩餘資源量多的優先&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b0cade1eb777379e3744a4104790af8.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源最多的集羣，保證離線任務運行穩定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於小集羣剩餘資源量很小一直分配不到任務容易「餓死」（事實上有的小集羣全部資源量都達不到一個大集羣的 20%）&lt;/p&gt; 
&lt;p&gt;② 優化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;將資源使用量超過一定比例的集羣放到排序隊列，剩餘的集羣放到隨機隊列&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c8b8441d6a201f0d2e84113fcc307c2f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源較多的集羣，即保證任務的運行穩定，隨機的方式也能均勻「餵飽」每個集羣&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨機分配在大任務量時相當於是平均分配，每個集羣都會調度差不多的任務量，當前情況會存在整點集中提交大量任務，小集羣接收和大集羣同樣任務量會抗不住，影響任務執行穩定和效率，小集羣容易「撐死」&lt;/p&gt; 
&lt;p&gt;③再優化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加權隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;按剩餘資源進行加權隨機，剩餘資源多的集羣有更多概率分配到任務&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39918d1411bca61982582118837a610.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源較多的集羣，「大集羣多吃，小集羣少吃」，每個集羣都能填充同時保證任務的運行穩定&lt;/p&gt; 
&lt;p&gt;④ 最終方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優先隊列（排序）+加權隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考慮優先隊列，無視其他排序規則，優先隊列裏的集羣將最優先，在優先隊列中的集羣再按資源排序&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//db44e6961fb051bfbb59cb66ff17797f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;繼承上一方案的優點，同時對於特定項目或機房的離線任務，能優先調度到某些特定的集羣&lt;/p&gt; 
&lt;p&gt;目前只以內存作為資源水位線的衡量標準，這裏的資源量指的是內存量。最開始方案是按集羣的剩餘資源排序，內存資源剩餘多的集羣優先，缺點是小集羣一直分配不到任務容易「餓死」，然後使用隨機的方式也能均勻「餵飽」每個集羣，但小集羣接收同樣任務量時容易「撐死」，於是隨機隊列按剩餘資源進行加權隨機，剩餘資源多的集羣有更多概率分配到任務，這樣離線任務優先提交到資源較多的集羣，「大集羣多吃，小集羣少吃」，每個集羣都能填充同時保證任務的運行穩定，在此基礎上增加優先隊列，無視其他排序規則，優先隊列裏的集羣將最優先，在優先隊列中的集羣再按資源排序，能優先調度到某些特定的集羣，形成最終集羣選擇排序方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_21&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、混部的效果與未來規劃&lt;/h1&gt; 
&lt;p&gt;經過以上的對 Spark 組件、K8s 混部系統、大數據平台以及彈性調度系統的改造和優化，目前混部集羣及提交混部的離線任務運行持續穩定，每天任務調度到混部的次數達 10+萬次，在凌晨的高峯期通過混部能為離線任務額外增加數百 TB 內存的計算資源，部分混部集羣的 CPU 利用率提升至 30% 左右，整體收益也是可觀的。&lt;/p&gt; 
&lt;p&gt;雖然目前 vivo 的在離線混部達到了一定的規模，但未來要繼續提高混部的規模和收益，還有規劃一些改進工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;1、提高離線任務混部規模。&lt;/h2&gt; 
&lt;p&gt;離線任務混部的節點是在線業務提供的，節點規模取決於在線業務峯值，峯值越高那麼在業務低峯期能提供給離線混部資源就越多，因此提高混部規模的重要因素是提交更多的離線任務。然而目前採用的 Spark Operator 方案能提交的離線任務只有標準的 SparkSql 和 SparkJar 任務，而對於非標準的任務如腳本任務，腳本中除了調用 spark-submit 提交 Spark 作業還有額外的處理邏輯，這類任務還不能直接以 Spark Operator 的方式提交。事實上 Spark 作業更多是來自腳本任務的非標準任務，如果要繼續增加離線任務的量，就必須把非標準任務也提交到混部，因此後續是選擇改造 spark-submit 客戶端支持 Spark Operator，或是選擇使用 Yarn on K8s，還需要綜合評估。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2、提高離線任務混部收益。&lt;/h2&gt; 
&lt;p&gt;目前混部節點 CPU 的平均利用率達到 30%，但仍有提升空間。從離線任務的角度來看，一方面是要增加錯峯互補的時間段，例如離線任務的高峯期是 02:00 到 08:00，在線業務的高峯期是 06:00 到 23:00，在 06:00 後在線業務逐步上量開始回收資源，所以離線任務能顯著提高混部集羣 CPU 利用率的黃金時間是有 02:00 到 06:00 這 4 個小時，因此如果能把離線任務高峯期提前到 00:00 到 06:00，混部提效的黃金時間就能達到 6 小時。所以需要推動離線任務高峯期的前移，對於有依賴鏈路的任務，儘量減少調度時間的間隔，上游任務完成後能儘快調起下游任務，而對於沒有依賴的任務，可以儘量提前調度時間，不過這兩種調整都需要推動業務方來調整，平台也可以給予一定的計算成本優惠作為激勵。另一方面是要提高混部資源的填充率，Spark 任務需要創建大量的 Executor Pod，目前混部集羣的調度器為了保證調度效率就沒有開啓預選、優先策略，事實上 Spark 的資源粒度比較小更適合填充資源碎片，所以在不影響 K8s 調度效率的情況下優化資源調配策略，把合適的資源粒度的 Pod 分配到合適的混部節點，也是提高混部收益的方向。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18181972</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18181972</guid>
            <pubDate>Thu, 17 Apr 2025 06:42:40 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>開源多模態大模型「書生·萬象 3.0」發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海人工智能實驗室（上海 AI 實驗室）升級並開源了通用多模態大模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frb_gVjQTuwdx0hse6KuAkA&quot; target=&quot;_blank&quot;&gt;書生·萬象 3.0&lt;/a&gt;（InternVL3）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，通過採用創新的多模態預訓練和後訓練方法，InternVL3 多模態基礎能力全面提升，在專家級基準測試、多模態性能全面測試中，10 億~780 億參數的全量級版本在開源模型中性能均位列第一，同時大幅提升了圖形用戶界面（GUI）智能體、建築場景圖紙理解、空間感知推理以及通識學科推理等方面的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;292&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1e01575a2bc4dfc8530b94281d9005d52e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在專家級多學科領域知識推理基準測試 MMMU 中再次突破開源模型極限，取得 72.2 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;基於司南 OpenCompass 開源評測框架，研究團隊對 InternVL3 進行了全面系統的評估，包括多學科推理、文檔理解、多圖像 / 視頻理解、現實世界理解、多模態幻覺檢測、視覺定位、多語言能力以及以語言為中心的基準測試。評測結果顯示，InternVL3 在開源多模態大模型中性能表現最優，創造了開源多模態大模型的性能新標杆，性能接近閉源模型 Gemini-2.5-Pro；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;創新提出原生多模態預訓練方法，將語言和多模態學習整合於同一個預訓練階段，提升及拓展多模態能力的同時，進一步提升純語言能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;提出混合偏好優化算法以及多模態測試階段增強，通過負監督修正模型響應分佈，大幅提升模型推理能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;公測版本：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.intern-ai.org.cn%2F%C2%A0&quot; target=&quot;_blank&quot;&gt;https://chat.intern-ai.org.cn/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345071</guid>
            <pubDate>Mon, 14 Apr 2025 06:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>豆包 1.5·深度思考模型發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今日火山引擎 AI 創新巡展杭州站現場，火山引擎總裁譚待發布了最新的豆包 1.5·深度思考模型，升級豆包·文生圖模型 3.0、豆包·視覺理解模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時，面向 Agent 服務，發佈 OS Agent 解決方案、GUI Agent 大模型——豆包 1.5·UI-TARS 模型；面向大規模推理，發佈 AI 雲原生·ServingKit 推理套件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據透露，截至 2025 年 3 月底，豆包大模型日均 tokens 調用量已超過 12.7 萬億，是 2024 年 12 月的 3 倍，是一年前剛剛發佈時的 106 倍。IDC 報告顯示，2024 年中國公有云大模型調用量激增，火山引擎以 46.4% 的市場份額位居中國市場第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;豆包 1.5·深度思考模型在數學、編程、科學推理等專業領域及創意寫作等通用任務中表現突出。同時，模型採用 MoE 架構，總參數 200B，激活參數為 20B，低於業界同類模型參數規模的 50%，具備顯著的推理成本優勢。基於高效算法，豆包 1.5·深度思考模型在提供行業極高併發承載能力的同時，實現 20 毫秒極低延遲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;363&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be145536aac0c4457023c8127490097c66a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，豆包 1.5·深度思考模型還具備視覺理解能力，可以像人類一樣，不光基於文字思考，更能基於所見畫面思考，思考更立體，讓模型同時擁有「大腦」和「眼睛」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;升級的豆包·文生圖模型 3.0 則能夠實現更好的文字排版表現、實拍級的圖像生成效果，以及 2K 的高清圖片生成方式。可以廣泛應用於影視、海報、繪畫、玩偶設計等營銷、電商、設計場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本的豆包·視覺理解模型具備更強的視覺定位能力，支持多目標、小目標、通用目標的框定位和點定位，並支持定位計數、描述定位內容、3D 定位。可應用於線下門店的巡檢場景、GUI agent、機器人訓練、自動駕駛訓練等。新版本在視頻理解能力上也有大幅提升，比如記憶、總結理解、速度感知、長視頻理解等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRYJ2OiZM_M-Jh27x3OFEdg&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345068</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345068</guid>
            <pubDate>Mon, 14 Apr 2025 05:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌推出了超越 Sora 的 Veo 2，生成 8 秒超逼真視頻</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;谷歌 DeepMind 終於將大家期待已久的 Veo 2 整合到 GeminiApp 應用中，全面開放使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/114154_vVro_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Veo 是谷歌迄今為止最強大的視頻生成模型。它可以生成各種電影和視覺風格的視頻，捕捉提示中的細微之處，以便在各個畫面中一致呈現精緻細節。&lt;/p&gt; 
&lt;p&gt;據介紹，Veo 2 可以最高生成 8 秒 720P 電影級視頻，在運鏡、文本語義還原、物理模擬、動作一致性等方面非常優秀，同時支持圖片轉視頻功能。谷歌公佈的測試數據顯示，Veo 2 在用戶偏好和提示還原方面已經超過了 Sora、可靈 1.5、Meta Movie Gen 和 Minimax。&lt;/p&gt; 
&lt;p&gt;開發者可以在 Google AI Studio 中通過 API 使用 Veo 2。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fvideo%3Fhl%3Dzh-cn&quot; target=&quot;_blank&quot;&gt;https://ai.google.dev/gemini-api/docs/video?hl=zh-cn&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345050/google-gemini-veo2</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345050/google-gemini-veo2</guid>
            <pubDate>Mon, 14 Apr 2025 03:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Reachy 2 開源人形機器人 7 萬美元正式開售</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Pollen Robotics 推出其最新開源人形機器人 Reachy2，正式開啓銷售，定價為 7 萬美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 並非面向消費市場，而是專為 AI 與機器人實驗室設計，目標是推動開源機器人生態的發展。據 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fzh%2Fnews%2F17257&quot; target=&quot;_blank&quot;&gt;AIbase&lt;/a&gt;瞭解，這款機器人已在 Cornell 大學、Carnegie Mellon 大學及多家頂級 AI 實驗室投入使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;324&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be15587448f52736ea558e37ca046b43429.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 以其高度仿人的外形與交互能力脫穎而出，主要亮點如下：&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;仿人設計：配備雙臂、頭部及獨特的天線，Reachy2 的 7 自由度（DoF）手臂模仿成人手臂的尺寸與運動方式，可實現自然、精準的動作，每隻手臂能負重高達 3 公斤。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;全向移動：其移動底盤採用三全向輪設計，結合 LiDAR 與多傳感器系統，確保平滑、精準的導航，適應多樣化應用場景。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;豐富的傳感器陣列：集成雙 1080p 攝像頭、麥克風陣列、揚聲器、LiDAR 及慣性測量單元（IMU），為環境感知與交互提供強大支持。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源與模塊化：基於 ROS2 和 Hugging Face 的 LeRobotHF 框架，Reachy2 支持 Python SDK 編程，開發者可輕鬆擴展與定製功能，滿足特定研究或應用需求。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Reachy2 已被全球 20 多個國家的 100 多台機器人部署，客戶包括 Hugging Face、Accenture、CNRS、Ecole Polytechnique 等。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345048</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345048</guid>
            <pubDate>Mon, 14 Apr 2025 03:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌宣佈將全球搜索流量統一重定向至 google.com</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fcountry-code-top-level-domains%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;將淘汰用於搜索的單獨國家代碼頂級域名（如 google.ng 或 google.com.br），並將其統一為 google.com。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;當您在 Google 上搜索時，我們致力於提供最實用的信息，這在很多情況下包括提供與本地相關的搜索結果。一直以來，為了提供本地化結果，我們都會使用國家/地區代碼頂級域名 (ccTLD)，例如尼日利亞的 google.ng 或巴西的 google.com.br。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;多年來，我們提供本地化體驗的能力不斷提升。2017 年&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fmaking-search-results-more-local-and-relevant%2F&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;，&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們開始為所有使用 Google 搜索的用戶提供一致的本地搜索結果體驗，無論他們使用的是&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;還是其所在國家/地區的國家代碼頂級域名 (ccTLD)。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;由於這項改進，國家/地區級域名已不再必要。因此，我們將開始將這些國家/地區頂級域名 (ccTLD) 的流量重定向至&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以簡化用戶的搜索體驗。此項更改將在未來幾個月內逐步推出，在此期間，您可能會被提示重新輸入部分搜索偏好設置。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，雖然此更新將改變人們在瀏覽器地址欄中看到的內容，但它不會影響搜索的工作方式，也不會改變我們處理國家法律規定的義務的方式。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5aaedebd84aee9085474149ca6015d401f8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟發佈安全提醒：攻擊者濫用 Node.js 來傳播惡意軟件</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微軟近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fsecurity%2Fblog%2F2025%2F04%2F15%2Fthreat-actors-misuse-node-js-to-deliver-malware-and-other-malicious-payloads%2F&quot; target=&quot;_blank&quot;&gt;發佈博文&lt;/a&gt;&lt;/u&gt;，稱 Node.js 正日益被用於傳播惡意軟件和其他惡意負載。自 2024 年 10 月以來，微軟持續監測到針對其客戶的攻擊活動，部分惡意活動甚至延續至 2025 年 4 月。&lt;/p&gt; 
&lt;p&gt;儘管與 Node.js 相關的惡意軟件並不普遍，但它們正迅速發展，成為威脅環境的一部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/112133_vXu9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微軟表示，Node.js 是開源、跨平台的 JavaScript 運行時環境，它允許 JavaScript 代碼在瀏覽器之外運行，被廣泛使用並被開發者信任，因為它讓開發者能夠構建前端和後端應用程序。然而，攻擊者也在利用這些 Node.js 特性來嘗試將惡意軟件與合法應用程序混合，繞過傳統的安全控制，並在目標環境中持續存在。&lt;/p&gt; 
&lt;p&gt;微軟舉例稱，犯罪分子利用與加密貨幣相關的惡意廣告（malvertising）誘導用戶下載偽裝成來自 TradingView 或 Binance 等平台的合法文件的惡意安裝程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e9b941943b28336312ced97e7c00094ce72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這個安裝程序內含惡意 DLL 文件，用於收集基本的系統信息。隨後，一個 PowerShell 腳本會下載 Node.js 二進制文件和一個 JavaScript 文件，並通過 Node.js 執行。&lt;/p&gt; 
&lt;p&gt;該 JavaScript 文件運行一系列程序，包括加載多個模塊、向設備添加證書，以及竊取瀏覽器中的敏感信息。微軟指出，這些行為可能預示後續的憑據竊取、規避檢測或二次負載執行等惡意活動。&lt;/p&gt; 
&lt;p&gt;微軟在第二個攻擊實例中表示，黑客採用了 ClickFix 社交工程技術，試圖欺騙受害者執行惡意的 PowerShell 命令。&lt;/p&gt; 
&lt;p&gt;該命令會啓動多個組件的下載和執行，包括 Node.js 二進制文件，讓 JavaScript 代碼無需通過文件執行，能夠直接在命令行中運行。&lt;/p&gt; 
&lt;p&gt;微軟強調，儘管 Python、PHP 和 AutoIT 等傳統腳本語言仍被廣泛用於威脅活動，但威脅行為者正轉向編譯後的 JavaScript，甚至直接利用 Node.js 在命令行中運行腳本，實施惡意行為。&lt;/p&gt; 
&lt;p&gt;微軟警告，這種威脅行為者技術、戰術和程序（TTPs）的轉變表明，儘管 Node.js 相關的惡意軟件數量上相對其它攻擊手段並不凸顯，但正迅速融入不斷演變的網絡威脅。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>JetBrains 宣佈推出 AI 工具免費套餐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;JetBrains 發文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2025%2F04%2F16%2Fjetbrains-ides-go-ai%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;，所有 JetBrains AI 工具（包括改進的 AI Assistant 和新的編碼代理 Junie）現在都可以通過單一訂閲在 IDE 中使用，並提供免費套餐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，為了讓每個人都能使用 IDE 內的 AI 功能，從 2025.1 版本開始，所有的 IDE 許可證中都包含了 JetBrains AI free&amp;nbsp;套餐。AI Free 套餐為用戶提供無限代碼補全和本地 AI 模型訪問權限，以及基於積分的雲端 AI 輔助功能和編碼代理 Junie。此外，免費套餐還包含 30 天的 AI Pro 訪問權限。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Pro（10 美元/月）和 AI Ultimate（20 美元/月）套餐計劃將為高要求的工作流程提供更高的使用配額，&amp;nbsp;All Products Pack 和 dotUltimate 訂閲則將包含 AI Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7661cb02397405a130e0974ef8e9b7b5ef6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;與此同時，該公司宣佈其&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI 編碼助手&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;color:#585858&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsdtimes.com%2Fai%2Fjetbrains-releases-ai-coding-agent-junie%2F&quot; target=&quot;_blank&quot;&gt;Junie&lt;/a&gt;&amp;nbsp;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;現已面向所有 JetBrains 客戶開放。Junie 已進行更新，能夠執行更復雜的任務，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;並提供更精細的控制，實現真正的「人機交互」方法。目前，&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;Junie 已兼容 IntelliJ IDEA Ultimate、PyCharm Pro、WebStorm 和 GoLand。預計 PhpStorm、RustRover 和 RubyMine 也將很快獲得支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;除了 Junie 的公開發布之外，該公司還發布了 JetBrains AI Assistant 的新版本。包含多項重大改進，旨在加速編碼工作流程並減少重複性任務，為開發者提供全程開發支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI Assistant 現在擁有更多模型選擇，包括 Claude 3.7 Sonnet、Google Gemini 2.5 Pro 以及 OpenAI 的最新模型，以及具備更強大的本地模型集成功能。其他更新包括改進的代碼補全、更強的上下文感知、可以編輯多個文件的新編輯模式，以及從代碼生成到測試到文檔的整個工作流程的更智能的支持。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fjetbrains.com%2Fai-ides%2F&quot; target=&quot;_blank&quot;&gt;立即開始&lt;/a&gt;在 IDE 中使用 AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;相關閲讀：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;margin-left: 0px; margin-right: 0px; text-align: start;&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/345083/intellij-idea-2025-1-released&quot; target=&quot;news&quot;&gt;IntelliJ IDEA 2025.1 現已發佈&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345039/jetbrains-ides-go-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345039/jetbrains-ides-go-ai</guid>
            <pubDate>Mon, 14 Apr 2025 03:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>美國政府不再為 CVE/CWE 項目提供資金支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;4 月 15 日，MITRE 向 CVE 委員會發送了一封郵件，告知美國政府對 CVE/CWE 項目的資助合同將於 4 月 16 日到期。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/110904_ginQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;受此影響，CVE 漏洞可能更新受到影響，並影響 NVD 等下游的漏洞庫。&lt;/p&gt; 
&lt;p&gt;CVE 項目始於 1999 年，由美國國土安全部（DHS）和網絡基礎設施安全局（CISA）的贊助，MITRE 負責運營，NVD（美國國家漏洞庫）等下游漏洞庫基於 CVE 的數據進一步加工分析。&lt;/p&gt; 
&lt;p&gt;在過去的二十多年裏，CVE 是對通用漏洞標識的標準，是漏洞情報共享、漏洞庫、各類安全工具的重要基礎數據，這是一項非常有意義的偉大工作。&lt;/p&gt; 
&lt;p&gt;若資金鍊斷裂，CVE 系統的崩潰將摧毀最受信賴的安全工具和流程。&lt;/p&gt; 
&lt;p&gt;前 CISA 負責人 Jean Easterly 在 LinkedIn 上警告，CVE 雖不常上頭條，但卻是現代網絡安全最重要的支柱之一，失去它如同「同時拆除所有圖書館的卡片目錄」，防禦者將陷入混亂，攻擊者則有機可乘。她強調，網絡威脅無國界，CVE 是全球共享情報和協調行動的通用語言，失去它等於「所有人都在盲飛」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345038</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345038</guid>
            <pubDate>Mon, 14 Apr 2025 03:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 發佈開源 AI 編程工具 Codex CLI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI 發佈了一個名為「Codex CLI」的實驗性新工具。這是一個輕量級的 AI 編程助手，可以直接在用戶的終端命令行運行，旨在充分發揮 o3、o4-mini 等模型強大的推理能力，連接本地代碼環境，甚至支持處理截圖或草圖進行多模態編程。&lt;/p&gt; 
&lt;p&gt;Codex CLI 已在 GitHub 完全開源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Fcodex&quot; target=&quot;_blank&quot;&gt;https://github.com/openai/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9e6e21608c2ed84ac64e14c0758cff7933.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Codex 有兩種運行模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;「建議模式」（默認）：&lt;/strong&gt;提出命令供用戶確認；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「全自動模式」&lt;/strong&gt;：禁用網絡訪問，讓 Agent 自主工作但保持安全。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OpenAI Agent 研究團隊成員 Michael 為了展示 Codex CLI 的功能，截取了一張在 X 上關於一個「圖像到 ASCII 風格轉換」工具的推文截圖。&lt;/p&gt; 
&lt;p&gt;他將這個截圖直接拖入終端，通過 Codex CLI 並利用 o4-mini 的多模態推理能力，最終成功創建了一個簡單的 ASCII 風格圖像轉換工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-289ad265fb8a85af1f5a6e370f846aaffec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 認為 Codex CLI 是一個將其模型與用戶及其計算機連接起來的最小化界面。&lt;strong&gt;Codex CLI 是為已經生活在終端的開發者設計的&lt;/strong&gt;，他們想要 ChatGPT 級別的推理能力，以及實際運行代碼、操作文件和迭代的權力 —— 所有這些都在版本控制之下。&lt;/p&gt; 
&lt;p&gt;簡而言之，它是一種理解並執行倉庫的聊天驅動開發工具。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;零配置 — 導入 OpenAI API 密鑰，即可直接使用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全自動批准，同時通過運行網絡禁用和目錄沙箱化確保安全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多模態 — 輸入截圖或圖表就可以實現推理功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Codex CLI 可以在 macOS&amp;nbsp;12+、Ubuntu&amp;nbsp;20.04+/Debian&amp;nbsp;10+、Windows&amp;nbsp;11 的 WSL2 子系統中使用，要求最少擁有 4GB 內存（建議 8GB）。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345034/openai-codex-cli</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345034/openai-codex-cli</guid>
            <pubDate>Mon, 14 Apr 2025 02:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 發佈 o3 與 o4-mini：開啓多模態推理新時代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;距離 OpenAI 發佈 &lt;a href=&quot;https://www.oschina.net/news/344606/openais-gpt-4-1-models&quot;&gt;GPT-4.1&lt;/a&gt; 僅過去兩天，OpenAI 在本週再次投下「重磅炸彈」—— &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-o3-and-o4-mini%2F&quot; target=&quot;_blank&quot;&gt;正式發佈&lt;/a&gt;&lt;/u&gt;其新一代推理模型 o3 與輕量級模型 o4-mini。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104452_zQp5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這兩款模型在推理能力、視覺理解、個性化對話和跨領域應用等方面實現了顯著飛躍，代表了當下人工智能技術的新高度。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o3：迄今為止最強的通用推理模型&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI o3 是目前最強大的推理型模型，專為應對複雜、多步驟的任務而打造，廣泛適用於編程、數學、科學分析、圖像理解等領域。&lt;/p&gt; 
&lt;p&gt;它在多個權威基準測試中創下新紀錄，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codeforces 編程排名&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SWE-bench 軟件工程測試&lt;/strong&gt;（無需構建自定義腳手架）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MMMU 多模態任務測試&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不僅如此，&lt;strong&gt;o3 在圖像、圖表和視覺感知任務中表現尤為出色&lt;/strong&gt;。對於需要圖像分析、圖表解讀等多模態輸入的複雜問題，o3 能給出結構化、深入且精準的回答。&lt;/p&gt; 
&lt;p&gt;外部專家評估結果顯示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;o3 在處理真實、複雜任務時比 o1 少 20% 的重大錯誤。尤其在編程、商業諮詢、科研假設等場景中，o3 表現出色，能提出新穎想法並進行深度自我審查。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;首批使用者評價 o3 是 「值得信賴的思維夥伴」，特別擅長在生物、數學和工程領域中生成並評估新假設。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104214_ZHcj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o4-mini：更小、更快、更高效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;與 o3 不同，&lt;strong&gt;o4-mini 是一款輕量級、優化後的高性價比推理模型&lt;/strong&gt;，在計算資源、響應速度與實際效果之間達成了優秀的平衡。&lt;/p&gt; 
&lt;p&gt;亮點包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 和 2025 數學競賽中表現最佳&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在非 STEM 任務（如數據科學）中的表現超越 o3-mini&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數學、編程、圖像識別任務中效率極高&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;✅ 由於模型本身更輕量，o4-mini 支持更高的調用頻率和更低的成本，非常適合&lt;strong&gt;大批量、多併發、快響應&lt;/strong&gt;的應用場景。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;更自然的人機互動體驗&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;無論是 o3 還是 o4-mini，這一代模型在對話體驗上也有明顯提升。得益於智能水平的增強與網絡信息的集成支持，&lt;strong&gt;兩款模型都能更好地理解用戶意圖，提供可驗證、結構清晰的回答&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持上下文記憶引用，更貼合用戶歷史對話&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令遵循能力增強，響應更精準自然&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;更加個性化、情境感知的交互&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;專家評語摘要&lt;/h3&gt; 
&lt;table style=&quot;min-width:155px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;優勢亮點&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o3&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;推理最強，圖像理解領先，適用於高複雜任務&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o4-mini&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;高性價比，適合大規模調用，非 STEM 場景表現躍升&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;外部專家一致認為，&lt;strong&gt;新模型在可用性、可靠性和語言自然度上均優於前代產品&lt;/strong&gt;，是未來 AI 助手的重要里程碑。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;總結&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI 的 o3 與 o4-mini 的發佈，標誌着 AI 推理模型的又一次躍遷。從性能到體驗，從通用性到多模態理解，它們都展現出前所未有的能力。&lt;/p&gt; 
&lt;p&gt;如果你在尋找一個既能處理複雜問題，又能快速響應且個性化的 AI 模型，這一代產品值得你深入瞭解與使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</guid>
            <pubDate>Mon, 14 Apr 2025 02:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>多模態視覺理解大模型推理優化</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div class=&quot;rich_media_content js_underline_content
                       autoTypeSetting24psection
            &quot; id=&quot;js_content&quot;&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;01&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;背景&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 85px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;大模型時代是人工智能領域的一個重要發展階段，在當今人工智能研究領域，基於 Transformer 架構的多模態視覺理解大模型（VLM）在全世界範圍內引發了深度的技術關注。多模態視覺理解大模型的主要創新在於將語言和視覺兩種模態進行有效的對齊，使其不僅能夠進行基本的圖像識別，還能執行基於視覺輸入的動態內容推理和複雜問題解答。可以應用在房內傢俱家電識別、涉黃涉爆檢測、商家店鋪門頭識別等多個場景，相比傳統模型取得更好的效果。但是由於多模態視覺理解大模型的推理性能比傳統模型低，導致整體成本高，嚴重阻礙了多模態視覺理解大模型的推廣。提高多模態視覺理解大模型的推理性能成為研究重點。我們是多模態大模型技術部門，負責多模態大模型相關的模型研發、推理優化和推廣的工作。我們在 58 的多模態視覺理解的項目場景中，對推理框架和模型進行優化，使用多種方法提高多模態視覺理解模型的推理性能。&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;02&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
     &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;場景介紹&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 58 的多模態視覺理解的項目中，都是後台提交任務對圖片進行推理，沒有與用戶進行實時對話的場景，所以目前性能優化的重點是批量輸出的場景。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;場景一：長 token 輸入、短 token 輸出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;多模態視覺大模型輸入的是提示詞+圖片，輸入的 token 通常都比較長，在 58 的場景內，98% 以上的推理場景是輸出短 token，通常在 5 個 token 以內。比如在信安定製數據治理項目中，輸出的 token 是隻有「是」或者「否」。我們重點對這種場景進行性能優化。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;場景二：長 token 輸入、長 token 輸出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;另外 2% 的推理場景是輸出長 token，比如給一張簡歷的 pdf 圖片，讓大模型識別圖片中的內容，輸出的 token 一般是幾百個以上。這種場景的佔比很少，不是性能優化的重點方向。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;03&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;性能指標&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;VLM 推理服務重點關注兩個指標：&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量&lt;/span&gt;&lt;/strong&gt;&lt;span leaf=&quot;&quot;&gt;和&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;時延&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要從系統的角度來看，即系統在單位時間內能處理的 tokens 數量。由於我們的主要場景是長輸入 token，短輸出 token，所以吞吐量的計算以單位時間內能處理的請求作為衡量指標，即模型推理的 qpm。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;時延：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要從用戶的視角來看，即用戶平均收到每個 token 所需的時間。計算方法為用戶從發出請求到收到完整響應所需的時間除以生成序列長度。一般來講，當時延不大於 50 ms/token 時，用戶使用體驗會比較流暢。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;由&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;於我們的場景都是批量輸出的場景，沒有流式輸出的場景，所以我們重點關注的性能指標是吞吐量。&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;04&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;優化內容&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_1&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.1 圖像預處理優化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在多模態推理中 Vision Transformer (ViT) 是一個關鍵的模塊，圖像的預處理是將圖像轉換為適合 ViT 模型輸入數據的過程。主要包括圖像顏色空間轉換、尺寸調整 (Resize)、劃分圖像塊 (Patch Partitioning)、歸一化（Normalize）等步驟。在 LMDeploy 框架中，圖像預處理過程中主要通過 PIL(Pillow) 的 Image 模塊在 CPU 上對圖像進行處理，在圖像 Resize 及 Partition 過程中，效率較低，耗時佔整個 ViT 過程的 20% 以上。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;為了提升系統吞吐能力，減少圖像預處理耗時，我們分別使用 Pillow 與 OpenCV 進行預處理測試，具體表現如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;CPU: Intel(R) Xeon(R) Silver 4410Y&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Python 3.10.12&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Pillow 10.2.0&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;opencv_python 4.8.1.78&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2000 張不同分辨率圖像&lt;/span&gt;&lt;/span&gt; 
       &lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014200&quot; data-ratio=&quot;0.10252996005326231&quot; src=&quot;https://oscimg.oschina.net/oscnet/1bfb0234-fa3d-4e69-ad7e-225bcbe39f01.png&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 1：Pillow 與 OpenCV 預處理耗時對比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;使用 OpenCV 可以極大的減少圖像預處理的耗時，平均處理單張圖片的耗時由 23.67ms 減少到 12.03ms，性能提升 49.18%。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 Resize 過程中，雖然兩個處理庫對應的插值方式均使用 BICUBIC，但當圖像進行下采樣時效果存在明顯差異，使用 OpenCV 進行處理的圖像存在波紋。如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014201&quot; data-ratio=&quot;0.5472222222222223&quot; data-s=&quot;300,640&quot; src=&quot;https://oscimg.oschina.net/oscnet/b96df915-b9d8-40bd-ba95-705072874e44.png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;width: 509px;height: 279px;&quot; type=&quot;block&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-size: 15px; text-align: center; cursor: default; line-height: 2em; margin-bottom: 8px; margin-top: 8px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 2：Pillow 與 OpenCV 效果對比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;通過對比源碼實現，發現二者在插值與邊界處理實現上有所差異：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;插值計算方式有差異&lt;/span&gt;：二者均使用 4x4 的卷積核進行插值計算，OpenCV 直接使用三次多項式公式計算每個像素的權重，並對周圍 16 個像素進行加權平均；而 Pillow 將三次卷積操作分解為兩個一維卷積，先對水平方向進行卷積，然後再對垂直方向進行卷積。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;邊界處理的差異&lt;/span&gt;：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;OpenCV 供多種邊界處理方式，例如 BORDER_REPLICATE, BORDER_REFLECT, BORDER_WRAP 等；Pillow 通常使用邊界複製的方式進行處理，即邊緣像素值被複制到圖像外部，以避免在邊緣出現偽影。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;針對這個問題，OpenCV 説明文檔中提供了相應的解決方案：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);color: rgb(0, 0, 0);&quot;&gt;To shrink an image, it will generally look best with INTER_AREA interpolation, whereas to enlare an image, it will generally look best with INTER_CUBIC (slow) or INTER_LINEAR (faster but still looks OK).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;於是我們根據不同的圖像採樣對插值方式進行動態調整，對圖像降採樣時，使用 INTER_AREA 插值，上採樣時，使用 INTER_CUBIC(速度較慢，但效果最好)，調整後，Resize 結果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e376a935-28bc-49af-a8c6-cabb4db7286f.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38425925925925924&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; type=&quot;block&quot; data-imgfileid=&quot;100014202&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 3：OpenCV 優化前後與&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;Pillow 效果對比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.2 ViT 模塊支持 TensorRT&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;ViT 模塊是多模態推理框架中一個必不可少的組成模塊，主要負責圖像相關處理及編碼工作。ViT 模塊的處理速度，直接影響整個框架的整體推理效率。為了進一步提升框架的推理效率，我們對 ViT 模塊的耗時進行了分塊分析，結果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/7c067863-ae5f-4261-bc0f-f16e4b12bb25.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.10119840213049268&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; data-imgfileid=&quot;100014203&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 4：vision 模型推理耗時及內存佔用情況&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;內存拷貝相關邏輯：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ce4defef-9707-41cd-88e1-c878c4646834.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5291181364392679&quot; data-type=&quot;png&quot; data-w=&quot;601&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;601&quot; data-imgfileid=&quot;100014175&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 5：LMdeploy VIT 階段內存拷貝代碼截圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;經過驗證，內存拷貝耗時主要是等待 GPU 異步處理結果，所以實際上主要耗時模塊為圖像預處理及特徵提取兩部分。具體定位步驟如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;list-style-type: disc;margin-left: 8px;margin-right: 8px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;內存拷貝邏輯修改&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;ul style=&quot;list-style-type: circle;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/vl/engine.py 取消結果拷貝至 cpu 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/serve/vl_async_engine.py 取消拷貝到 cpu 及轉換 numpy 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/pytorch/message.py 中修改 InputEmbeddings 及類型為 Torch.Tensor(GPU)&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
     &lt;/ul&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;內存拷貝邏輯修改引起異常的分析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;邏輯調整後，推理結果異常。在 vl/engine.py forward 增加輸出結果日誌後，推理正常。經驗證輸出結果日誌操作起到同步等待作用，使用 torch.cuda.synchronize() 或者 sleep 驗證猜想正確。後續在模型內增加日誌輸出結果或者以上兩個操作，推理結果均正常。推理結果正常後定位耗時模塊，定位到 ViT 中 extract_feature 為主要耗時模塊。為了進一步提升推理效率，我們借鑑了 TensorRT-LLM 中的推理加速方案 TensorRT。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;TensorRT 是一個高性能的深度學習推理（Inference）優化器，可以為深度學習應用提供低延遲、高吞吐率的部署推理。TensorRT 可對多種應用場景進行推理加速，並且支持 TensorFlow、Caffe、Mxnet、Pytorch 等幾乎所有的深度學習框架。將 TensorRT 和 NVIDIA 的 GPU 結合起來，能在幾乎所有的框架中進行快速和高效的部署推理。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/92358ef8-bc80-4bf8-817c-4301d087eec0.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.486&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014176&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 6：Tensorrt 優化過程圖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在對 ViT 模塊進行 TensorRT 改造時，主要包含模型轉換、模型優化和推理部署三個階段。模型轉化支持 TensorFlow、PyTorch、ONNX 等主流深度學習框架的模型轉換和優化，本文以 ONNX 為例進行説明。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;1、模型轉換&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/be6a8f15-e0da-4080-aeac-586ca6fb9964.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7807308970099668&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;602&quot; data-imgfileid=&quot;100014173&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 7&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;ONNX 模型轉換代碼截圖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;導出 ONNX 時可能會遇到不支持的算子，如在導出快速傅裏葉變換（FFT）和快速傅裏葉逆變換（IFFT）時會遇到如下錯誤，&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;Exporting the operator &#39;aten::fft_rfftn&#39; to ONNX opset version 17 is not supported&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;這時需要調整模型網絡結構或者自定義算子。在對 ViT 模塊進行 ONNX 轉換過程中，部分多模態模型的 ViT 中使用了 FlashAttention2 進行注意力加速，而 FlashAttention2 中的 flash_attn_func 是作為獨立的內核實現的，不是 torch.nn.Module 的實例，導致導出器無法捕獲計算圖，如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;/usr/local/lib/python3.10/dist-packages/flash_attn/flash_attn_interface.py:90: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;因此，對 Attention 模塊進行了調整，使用 PyTorch 內部實現的縮放點積注意力（Scaled Dot-Product Attention, SDPA），如下圖，至此模型便可成功轉換成 ONNX 格式。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e60836a9-5141-4603-9d85-270e50fd40be.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5825&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014174&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 8&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;縮放點積注意力 (SDPA) 代碼截圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2、模型優化&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;該階段主要完成模型優化，如下圖所示，在模型優化過程中會完成層間融合，精度校準等。這一步的輸出是一個針對特定 GPU 平台和網絡模型的優化過的 TensorRT 模型，這個 TensorRT 模型可以序列化存儲到磁盤或內存中，存儲到磁盤中的文件為 TensorRT planfile。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/1ef2a7d7-071f-44da-aa1f-150b5e299114.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.224&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014172&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 9：Tensorrt 模型優化及系列化流程圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;3、推理部署&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/8169cdc0-de30-4af8-9617-1e080e14ec9c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2064&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014177&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 10：Tensorrt 部署及推理流程圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署階段將上一個步驟中的 plan 文件反序列化，並創建一個 runtime engine，輸入對應的圖像數據，輸出推理結果。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4、推理效率&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;經過 TRT 加速後，ViT 模塊 feature_extract 速度縮減 45% 左右（不包含圖片預處理），feature_extract 耗時在 ViT 中佔比從 60% 減少至 45.36%，整體推理耗時耗時縮減在 70ms 左右。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.3 ViT 模塊支持 CudaGraph&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;推理框架 lmdeploy 在 0.6.0 版本引入了 CUDA Graph,並提升了近 30% 的推理性能：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;&amp;nbsp;Employ CUDA graph to boost the inference performance (30%)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;不過受多方因素限制，目前 lmdeploy 只在語言模型中引入了 CUDA Graphs。為了進一步提升推理速度，我們在 ViT 模塊中引入了 CUDA Graphs。CUDA Graphs 可以用於優化執行過程中的 CUDA 操作，在 GPU 上實現更加高效的深度學習模型推理。在使用 CUDA Graphs 時需要對 CUDA 操作進行錄製（capture）和重放（replay），以此來減少 CPU 到 GPU 的調度開銷，提高整體的執行效率。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;如下圖，簡單展示了 CUDA Graphs 的優勢。在頂部，CPU 逐個啓動一系列短內核。CPU 啓動開銷導致內核之間出現明顯間隙。如果我們用 CUDA 圖替換此內核序列，最初我們需要花費一些額外的時間來構建圖並在第一次啓動整個圖時一次性啓動整個圖，但後續執行將非常快，因為內核之間的間隙將非常小。當多次重複相同的操作序列時，例如在許多訓練步驟中重複，差異會更加明顯。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac8a403c-ee90-4fe0-81cd-65e63efbb452.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.372&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014178&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 11：CUDA Graphs 性能優勢圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;首先，在 ViT 支持 CUDA Graphs 時，需要 torch.cuda.CUDAGraph 創建對應的圖，然後使用 torch.cuda.graph() 對 ViT 的推理過程進行錄製，在推理過程中，使用剛創建的圖對錄製的過程進行重放 CUDAGraph.play()。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;但是要注意，由於 CUDA Graphs 不支持動態控制流（如條件語句和循環），因此在設計算法時應儘量避免使用這些結構；其次，確保輸入張量的形狀在圖創建時是固定的，因為 CUDA Graphs 的設計是基於靜態形狀的張量結構，創建 Graph 時，所有操作及其輸入輸出的形狀必須在圖創建時確定。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;而 ViT 模塊在進行圖像處理時，輸入的圖像數張量的形狀是 [batch_size, channel, width, height]，其中 batch_size 是可變的且各視覺模型均已限定最大值。於是，我們在框架內部維護了 Graphs Pool，推理時使用 batch_size 索引至相應的 graph，再執行重放操作。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;增加 CUDA Graphs 後 ViT 模塊平均耗時減少 30ms 左右。雖然 CUDA Graphs 可以在一定程度上提升推理的效率，但是在構建 graphs 也需要佔用一些額外的顯存，在使用時需要綜合衡量具體的業務場景及硬件資源。&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.4 圖像 Token 化處理&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;輸入 token 的長度對推理耗時影響很大，多模態模型中，圖像部分佔據了很大比例的 token 數，降低圖像轉換的 Token 數可提升推理性能。如下是結果對比：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/f660d32a-1b9f-4656-98d1-dbecee5fe26c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.29894179894179895&quot; data-type=&quot;png&quot; data-w=&quot;378&quot; style=&quot;width: 382px;height: 114px;&quot; data-imgfileid=&quot;100014204&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;圖 12：&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif; font-size: 15px; letter-spacing: normal; background-color: rgb(255, 255, 255); cursor: default; text-align: justify; margin-top: 8px; margin-bottom: 8px; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;Token 數和推理耗時基本成正比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;圖像轉換的 Token 數計算主要流程如下&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;（1）根據圖像寬高比和分辨率大小將原圖拆分成若干個 448*448 的 patch，拆分的原則是儘量保持圖像不失真。拆分代碼如下：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/30811eb3-1df8-4dc0-b6e3-6ea8f054445d.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9367088607594937&quot; data-type=&quot;png&quot; data-w=&quot;869&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014179&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 13：VLLM 中 InternVL2-8B 模型拆圖代碼截圖&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;上述代碼基本流程是，給定動態拆分的閾值範圍，窮舉出所有可能的目標比例，再根據原圖比例匹配最佳的拆分規則，拆分邏輯圖示如下圖左上部分，圖示中會被拆分成 6 個 path 塊和一張縮略圖。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/9b84a37b-1304-4f2d-84ad-324785e09a4b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.526&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014180&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 14&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;InternVL 模型整體框架圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（2）一個 448*448 的 patch 生成的 token 數計算方式如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);font-weight: normal;&quot;&gt;image_tokens_per_patch=(force_image_size // patch_size)**2 * (downsample_ratio**2))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;force_image_size=448,patch_size=14,downsample_ratio=0.5,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;這個計算後結果為 256。不同的模型值可能會有所差異。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（3）分辨率為 896*1344 的圖像，經過步驟 1 處理，會拆分成 2*3=6 個 patch，再加上一張縮略圖（可選，有效果會更好），最終堆疊後 shape 是[7,3,448,448]，圖像轉換的 token 數為 7*256=1792。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署到線上時，單卡吞吐量上不去，其中一個原因是拆圖規則導致拆分後的圖片數量比較多，如分辨率 612*464，最合適的寬高比是 (4, 3)，按模型的圖片拆分規則，圖像將被拆分成[13,3,448,448]，轉化後的 token 數達到 3328，再加上 prompt 的 token，總 token 數會達到 3400+，太長的輸入 token 對模型推理速度影響很大，再加上顯存和算力的限制，無法做到更大 batch 的推理，使得單卡推理的吞吐量很低。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;基於此原因，我們的優化思路是降低圖像的總 token 數，經實驗分析，官方代碼在實現上存在比較大的冗餘設計，如圖像分辨率為 480*360，也會轉換成 3328 個 token 數，對於低分辨率圖像生成太多的 token 存在資源浪費。在保持圖像內容不拉伸前提下，對圖像的寬高比做調整，以適應 vit 的要求，優化後，480*320 的圖像只轉換成 512 個 token 數，這樣在推理時能做到更大的 batch 處理。在我們實際落地場景中，處理後吞吐量能提升 1 倍。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.5 prefixcache 在多模態模型裏應用&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;在&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;PagedAttention 中，KV Cache 只是在一個請求內複用，而沒有做到跨請求的 KV Cache 複用。長 prompt 的場景，prompt 在不同的請求中是相同的，KV Cache 的計算也是相同的，如果能把 prompt 的 KV Cache 保存下來，留給後續的請求複用，將會極大地降低首 Token 的耗時。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;在 LLM 模型裏，prefixcache 分二個階段，第一個階段，當 prompt 第一次被推理時，是按 block_size(通常是 64) 大小對 input tokens 從前往後進行分塊，計算每個分塊的 hash 作為唯一標識，每個分塊的 token_id 作為 key 進行緩存，這裏不足 block_size 長度的塊不會被緩存；第二階段，當新 prompt 被推理時，會進行 prefix cache matching，命中就直接複用 kvcache，只計算未命中部分的 input tokens。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;多模態模型區別在於，一次任務的輸入 tokens 組成由純文本變成了文本+圖片，由 system+prompt 變成了 system+image+prompt，在計算 prefix cache 時，image 對應的只是 padding tokens，那麼在計算 prefix cache matching 時，不同圖片可能匹配到一樣的 prefix 上，這樣推理結果就會出現錯誤。針對這個問題，在 input tokens 中對 image 進行範圍標記，在計算 prefix cache 時不對 image token 進行 kvcache，只 cache image 之前的部分；在 prefix cache matching 時，也同樣保證 image token 不會被複用。經實驗驗證，修改後能保證在開啓 prefix cache 時，推理結果是正確的。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;需要注意，Prefix Caching 只節省了 prefill 階段的耗時（也就是降低了 TTFT，Time To First Token），並不能節省解碼階段的耗時（也就是 TPOT，Time Per Output Token）。如果請求的主要耗時是在解碼階段（例如 prompt 很短而 completion 很長），或者多個請求的 prompt 並沒有公共的前綴，那麼 Prefix Caching 就對於整個 LLM 推理的性能提升幫助不大&lt;/span&gt;。&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.6 模型量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化是大模型領域中的一項關鍵技術，它通過降低模型參數的精度，將浮點數轉換為整數或定點數從而實現模型的壓縮和優化。模型量化可以減少模型尺寸，進而減少在推理時的顯存消耗，並且在一些低精度運算較快的處理器上可以增加推理速度。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化分很多情況。從量化對象來説，量化可以是權重、激活、kv cache 和梯度；從量化的形式上來説分為線性量化和非線性量化，其中線性量化又分為對稱量化和非對稱量化；根據應用量化壓縮模型的階段，又可以將模型量化分為量化感知訓練、量化感知微調、訓練後量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;我們現階段使用的量化方式是 AWQ 和 GPTQ，這兩種量化都屬於訓練後量化，是針對權重的線性量化，其中 AWQ 採用對稱量化，GPTQ 採用非對稱量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;AWQ 量化的原理是對於 LLM，權重不是同等重要的，通過保留 1% 的顯著權重可以大大減少量化誤差。在此基礎上採用激活感知的方法，考慮更大的激活幅度應該對應更重要的權重通道，在處理重要特徵時起關鍵作用，逐通道確定最佳縮放因子。從而在量化所有權重的同時，最小化量化誤差。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;GPTQ 對模型的每一層（通常是線性層或卷積層）進行單獨處理，考慮了量化帶來的誤差，並通過調整未量化的權重來補償這些誤差。利用了二階偏導 Hessian 矩陣的逆，來指導權重的調整，以減少整體的量化誤差。將權重矩陣分成多個子矩陣（block），對每個子矩陣中的權重逐個進行量化，同時調整同一子矩陣內其他權重，以保持模型輸出的相似性。其量化後的誤差依賴一份高質量的校準數據。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;整體上來看，AWQ 相較於 GPTQ 量化的算法更直接，對校準數據依賴小；GPTQ 則更容易有比較好的量化效果，但是算法相對複雜，對校準數據依賴比較大，實際過程中用哪個更合適需要根據實際的場景選用。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在實際測試中，不論是 AWQ 還是 GPTQ 實際採用的都是 w4A16 的量化策略，在推理的時候，性能差異比較小，在 RTX4090 顯卡下，我們使用 vllm，對應不同參數，並且設置最優 batch，實際測試值如下：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;針對單個請求的延時：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac7dd996-e553-40fb-b9a8-4832f70c1a3b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2084507042253521&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;710&quot; type=&quot;block&quot; data-imgfileid=&quot;100014210&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 15: 原始模型和量化模型的推理耗時比較&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;從測試結果看：在 4090 下，大 batch 的計算，使用 gemm 內核，速度不如原精度，原因是在大 batch 的情況下，增加了反量化的時間。使用 marlin 內核，計算的速度有優化，但是在大 batch 下，優化速度不明顯。低 batch 的計算原精度是計算最慢的，gemm 的內核計算與 marlin 計算差別不是很大，都比原生的有大幅提高。原因是 gemm 在低 batch 下，也做了內核優化，這一點可以從原代碼中驗證：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/89dafcc6-de64-4e34-b8ac-72982e9aeb04.png&quot; class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.30575035063113604&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;713&quot; type=&quot;block&quot; data-imgfileid=&quot;100014211&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 16&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;VLLM 中 awq 量化模型 mul 計算邏輯代碼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: left;line-height: 2em;&quot;&gt; 
    &lt;span leaf=&quot;&quot;&gt;針對吞吐量：&lt;/span&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/c2d58729-66c8-42cd-ad10-c69be338f6b4.jpg&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.15281501340482573&quot; data-s=&quot;300,640&quot; data-type=&quot;webp&quot; data-w=&quot;746&quot; data-croporisrc=&quot;https://oscimg.oschina.net/oscnet/22f3d6f2-bfb2-465f-9504-408778ea5dbd.jpg&quot; data-cropselx2=&quot;578&quot; data-cropsely2=&quot;120&quot; data-imgfileid=&quot;100014212&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 17：原始模型和量化模型的吞吐量比較&lt;/span&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;從測試結果看，對於短輸出，其實吞吐量並沒有優化，還下降了一點，原因是，對於短輸出，主要的耗時在 prefill，prefill 是大 batch 的計算，在推理過程中，吞吐量會下降。但是對於長輸出，decode 階段佔比比較高，內核對於 decode 的優化比較明顯，綜合吞吐量會上升。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;總結：在實際使用中對於 W4A16 量化後的模型來説，模型佔用的顯存一定能節省。但是推理的整體性能和吞吐量，需要根據不同的任務特點，部署的硬件環境，調整部署的參數，以達到最優。而不是量化後的整體性能一定會優於未量化的模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;05&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp; 優化數據&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;評測模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：InternVL2-8B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;數據集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：信安羣租房檢測 4524 張圖片&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;提示詞&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：圖中有 3 張以上的牀，或者是有雙層牀，請直接給出是或者否，然後給出詳細的解釋。注意 1 張雙層牀有 2 張牀&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;輸出 token 數量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：max_tokens=1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;GPU&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;: RTX4090&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;對比框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;優化框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0 優化版本&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;吞吐量：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;由於我們的場景是長輸入 token 和短輸出 token，所以按單位時間內處理的請求數作為衡量指標。比較兩個框架的推理 QPM&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/1b84899b-305c-4427-8131-5600a10b72b8.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1893687707641196&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; data-imgfileid=&quot;100014207&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p data-pm-slice=&quot;0 0 []&quot; style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 18：LMDeploy-0.6.0 優化前後召回率和吞吐量比較&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;LMDeploy-0.6.0 優化版本在推理效果不受影響的情況下，吞吐量提升到 LMDeploy-0.6.0 版本的 3.05 倍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;作者簡介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;徐海芳、李海洋、朱辰、張輝，MPai 平台視覺理解大模型推理團隊&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;font-size: large;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/section&gt; 
  &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;display: none;&quot;&gt; 
  &lt;mp-style-type data-value=&quot;3&quot;&gt;&lt;/mp-style-type&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color: #858585; font-size: 13px;&quot;&gt;本文分享自微信公眾號 - 58 技術（architects_58）。&lt;br&gt;如有侵權，請聯繫 support@oschina.cn 刪除。&lt;br&gt;本文參與「&lt;a href=&quot;https://www.oschina.net/sharing-plan&quot; target=&quot;_blank&quot;&gt;OSC 源創計劃&lt;/a&gt;」，歡迎正在閲讀的你也加入，一起分享。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5359019/blog/18160034</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5359019/blog/18160034</guid>
            <pubDate>Mon, 14 Apr 2025 02:30:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>《流浪地球 3》發佈 AI 問答應用 WEi</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;電影《流浪地球 3》近日在青島舉行開機儀式，郭帆導演攜主創團隊齊聚亮相。在開機儀式現場，《流浪地球 3》劇組正式發佈劇組專屬的自研 AI 問答應用 WEi。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;365&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b58e821f644cfcd13feb137d9d2cac2428.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該應用依託大語言模型，基於 DeepSeek R1 大語言模型，NVIDIA、火山引擎作為「AI 支持合作伙伴」所開發，本地推理部分由 NVIDIA GeForce RTX 5090 D 加速，旨在為劇組提供一站式智能服務，大幅提升劇組創作效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，WEi 通過整合多元化知識庫資源，包括在線信息源的專業資料、圖像和影視參考，以及電影《流浪地球》系列劇本、世界觀、編年史、人物小傳、美術設定等內部資料，為劇組工作人員提供高效檢索通道，同時期望在參考信息上既符合科學基礎又保持設定一致性，提高劇組工作人員創作效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345026</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345026</guid>
            <pubDate>Mon, 14 Apr 2025 02:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 擬以 30 億美元收購 AI 編程工具 Windsurf</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社報道稱，OpenAI 正與人工智能輔助編程工具 Windsurf（前身為 Codeium）展開收購談判，交易金額約為 30 億美元。這一潛在收購將成為 OpenAI 迄今為止最大規模的併購交易，標誌着其在 AI 驅動的開發者工具市場邁出重要一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;262&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5591fcd5e926e90d56e1521a2184484a0b3.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Windsurf 是一款廣受開發者歡迎的 AI 編程助手，能夠基於自然語言提示生成代碼、解釋現有代碼並執行相關任務。它不僅支持通過插件嵌入主流代碼編輯器（如 Visual Studio Code），還提供專為 AI 輔助開發設計的自定義編輯器。Windsurf 自稱是首款「代理式」集成開發環境 (IDE)，強調其在自動化和智能化編程流程中的獨特優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;成立於 2021 年的 Windsurf（正式名稱為 Exafunction Inc.）已累計融資超 2 億美元，投資者包括 General Catalyst、Kleiner Perkins 和 Greenoaks Capital Partners。2023 年，其在 General Catalyst 領投的 1.5 億美元融資中估值達 12.5 億美元，而近期與投資者的談判顯示其估值已升至 30 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;X 平台上的討論顯示，業界對此次收購的反應複雜而熱烈。一方面，許多開發者對 OpenAI 整合 Windsurf 的前景表示期待，認為這可能帶來更強大的 AI 編程工具;另一方面，部分觀點擔憂收購可能對其他 AI 編程工具（如 Cursor）造成衝擊，尤其是考慮到 OpenAI 此前通過其創業基金投資了 Cursor 的母公司 Anysphere。此外，微軟近期對 Visual Studio Code 生態的收緊政策可能為 OpenAI 的收購策略帶來變數。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，Windsurf 近期向用戶發送郵件，宣佈因「本週晚些時候的重大公告」而提供鎖定 10 美元/月價格的機會，這一舉動被外界解讀為收購談判的間接證據。然而，交易條款尚未最終敲定，談判仍存在變數或破裂的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次收購若達成，將成為 OpenAI&amp;nbsp;最大規模的併購交易。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345019</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345019</guid>
            <pubDate>Mon, 14 Apr 2025 02:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>xAI 發佈新 AI 工具 Grok Studio：可生成文檔、代碼和瀏覽器遊戲</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;xAI 宣佈為旗下 AI 聊天助手 Grok 增加全新功能 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgrok%2Fstatus%2F1912318583532872166&quot; target=&quot;_blank&quot;&gt;Grok Studio&lt;/a&gt;，可以用於編輯和創建文檔，以及基礎應用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-19a1c88ab76742bcfab01237646b8b0dc40.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Grok Studio 將在一個單獨的窗口中打開，支持生成文檔、代碼、報告和瀏覽器遊戲。&lt;/p&gt; 
&lt;p&gt;生成代碼時，Grok Studio 會在「預覽」選項卡中快速向用戶展示其運行效果。HTML 代碼片段可以運行 Python、C++、JavaScript、Typescript 和 Bash 腳本，也可以在此預覽選項卡中查看。所有新項目都會在 Grok 回覆的右側打開。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1424&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/194259_TbOH_2720166.png&quot; width=&quot;1940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;xAI 表示，免費和付費的 Grok 用戶都可以在 Grok.com 上使用該功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344972/xai-grok-studio</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344972/xai-grok-studio</guid>
            <pubDate>Sun, 13 Apr 2025 11:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊「元寶」可添加為微信好友：一鍵解析公眾號文章、甚至把它置頂</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;就在剛剛，騰訊 AI 助手「元寶」支持添加為微信好友進行聊天。 &amp;nbsp;你可以和他對話，也可以發鏈接、文件給他——甚至可以把它置頂 。&lt;/p&gt; 
&lt;p&gt;如下圖，在微信直接搜索「元寶」，點擊「聊天」進入。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/190446_4eYx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191425_HCo3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1592&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190642_X4B1_2720166.png&quot; width=&quot;806&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;978&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190707_Op4X_2720166.png&quot; width=&quot;814&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，這是騰訊元寶 APP 入駐微信的 AI 助手，搭載了混元和 DeepSeek 雙模引擎，可一鍵解析公眾號文章和任何圖片和文檔，短評後會發送詳解文章，支持對解讀內容做各種智能互動，支持陪伴互動。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191518_XlEd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1662&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/191457_Jiq2_2720166.png&quot; width=&quot;764&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344970</guid>
            <pubDate>Sun, 13 Apr 2025 11:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國團隊自研 AI 圖像生成大模型 HiDream-I1 正式開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;HiDream 智象未來團隊宣佈正式開源圖像生成大模型 HiDream-I1 與交互編輯模型 HiDream-E1。&lt;/p&gt; 
&lt;p&gt;HiDream-I1 在權威榜單 Artificial Analysis 中 24 小時內&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-ouXGp3kyyT7AfFmQ_Y5Cw&quot; target=&quot;_blank&quot;&gt;登頂&lt;/a&gt;&lt;/u&gt;，成為首個躋身全球第一梯隊的中國自研生成式 AI 模型，並在圖像質量、語義理解、藝術表現三大維度刷新行業紀錄，實現圖像的多風格生成，涵蓋動漫、肖像、科幻等場景。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;984&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/183653_vhQa_2720166.png&quot; width=&quot;1462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，設計工具 Recraft 已集成 HiDream 模型，用戶 3 步即可實現 「一鍵出圖 + 智能編輯」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175700_50WE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1&amp;nbsp; 已開源三個版本的模型，分別是：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175710_8HLD_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中 HiDream-I1-Full 是由 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhidreamai.com%2Fhome&quot; target=&quot;_blank&quot;&gt;HiDream.a&lt;/a&gt;i 團隊發佈的開源圖像生成基礎模型，具備 170 億參數，旨在實現高質量的圖像生成。該模型採用 Diffusion Transformer（DiT）架構，支持多種風格的圖像生成，包括寫實、卡通、藝術等，適用於多種創作場景。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心特性&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;卓越的圖像質量&lt;/strong&gt;：在多個基準測試中表現出色，HPS v2.1 平均得分為 33.82，優於 SDXL、DALL·E 3 等主流模型&amp;nbsp;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;強大的提示詞理解能力&lt;/strong&gt;：在 GenEval 和 DPG-Bench 等評測中，HiDream-I1 的表現優於其他開源模型，展示了其在理解和執行復雜提示詞方面的能力。騰訊網+1 阿里雲開發者社區-雲計算社區-阿里雲+1&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;開源且商業友好&lt;/strong&gt;：採用 MIT 許可證，允許用戶在個人、科研和商業項目中自由使用生成的內容。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;性能評估&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在多個評測中，HiDream-I1 展示了其強大的性能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DPG-Bench&lt;/strong&gt;：在整體、實體、屬性等多個維度上得分領先，展示了其在圖像生成質量方面的優勢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GenEval&lt;/strong&gt;：在單目標、雙目標、計數、顏色等任務中表現優異，反映了其對提示詞的準確理解和執行能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HPS v2.1&lt;/strong&gt;：在動畫、概念藝術、繪畫、照片等風格的圖像生成中，HiDream-I1 的得分均高於其他主流模型，展示了其多風格生成的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175722_YQIr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175731_9IFw_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175741_2jbr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1-Full 模型整體採用 MIT 協議開源，可自由商用，但部分依賴組件（如 LLaMA3 編碼器）需遵守各自協議，商用前應留意其具體限制。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344955</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344955</guid>
            <pubDate>Sun, 13 Apr 2025 09:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節 AI Lab 將全部併入 Seed</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 科技評論獨家獲悉，字節 AI Lab 即將全部收歸 Seed 團隊下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字節 AI Lab 是 Seed 成立之前字節主要的 AI 研發部門，目前由李航管理，自 2024 年開始向 Seed 時任負責人朱文佳彙報。今年 2 月下旬，原 Google DeepMind 副總裁吳永輝入職字節，成為 Seed 基礎研究負責人。此後李航的彙報對象變為吳永輝。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字節 AI Lab 成立於 2016 年，最初由微軟亞洲研究院前常務副院長馬維英負責，直接向張一鳴彙報。 AI lab 目前有多個子團隊，包括機器人、AI4S 等方向，幾乎覆蓋人工智能領域所有前沿技術研究。2018 年其團隊規模達到 150 人，為字節跳動 AI 研究的核心部門。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Lab 主要研究重點是開發為字節跳動內容平台服務的創新技術，字節推薦算法、短視頻特效等功能均脫胎於此。其研究成果應用於今日頭條、抖音等產品，是支持抖音成長為國民級應用的基石，並奠定了當時字節在國內 AI 領域的領先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着抖音、TikTok 佔據絕對優勢的市場地位，流量商業化成為字節面臨的 Top 級問題，AI Lab 在字節內部重要性下降。2020 年，AI Lab 定位從集團級前瞻性項目轉為技術中台，為字節商業化團隊業務提供支持，馬維英的彙報對象也從張一鳴變為抖音負責人張楠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2020 年年中，馬維英離開字節，AI Lab 負責人一職由李航接任至今。之後團隊重組，2023 年開始，AI Lab 下屬負責大語言模型的 NLP 組及開發視頻生成模型的 PixleDance 被先後轉入 Seed 之下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時為了應對新一輪大模型競爭，字節決定迴歸「始終創業」的價值觀，建立獨立的新組織，於是加快籌建了獨立於原有組織架構的 Flow 和 Seed，前者做 AI 產品，後者做大模型研發。截至 2023 年底，兩者已成為與抖音、TikTok、火山引擎等字節各大業務平級的組織。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Seed 自成立就在不斷吸納來自字節內外的人才。除收攏搜索、AML、AI Lab 等內部部門中大模型方向人才外，對外也在積極爭搶人才。以面向應屆博士的 Top Seed 招募計劃為例，字節會給優秀候選人 3-1 職級，薪資不低於百萬元。截至 2024 年底，字節 AI 研究者中超 40％比例是近兩年加入的新人，對人才的渴求和重視程度可見一斑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據 AI 科技評論調查，加入字節以來，吳永輝已在字節署名三篇論文，均在強化學習方向。吳永輝於上月在 Seed 內部新建虛擬小組、縮短了彙報流程，創建一個更扁平的彙報體系，此次 AI Lab 將全部併入 Seed，也是吳永輝調整內部組織架構的一個重要舉措。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344946</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344946</guid>
            <pubDate>Sun, 13 Apr 2025 09:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Notion Mail 正式發佈：AI 驅動郵箱新體驗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Notion 正式推出電子郵件服務 Notion Mail，首發登陸 macOS 平台，iOS 和 Android 版即將上線。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1140&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/165124_3l5R_2720166.png&quot; width=&quot;2124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 並非要取代 Gmail，而是作為重新設計的郵箱前端，提供獨特的郵件管理體驗。其核心為高度模塊化系統，用戶可自定義收件箱配置，並整合了豐富的 AI 功能，如智能文件夾、自動分類、快速回復、寫作改進及智能會議安排等。產品與 Notion Calendar 無縫銜接，核心 AI 功能提供免費使用限額，無限制需訂閲付費。目前僅支持英文，未來將擴展至 13 種語言。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/165012_T6gr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 主頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail&lt;/a&gt;&lt;br&gt; 下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail%2Fdownload&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail/download&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344936/notion-mail</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344936/notion-mail</guid>
            <pubDate>Sun, 13 Apr 2025 08:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>從理論到落地：MCP 實戰解鎖 AI 應用架構新範式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：計緣&lt;/p&gt; 
&lt;p&gt;編者按：應用越智能，背後的設計會越複雜。軟件的本質是解決複雜性問題，MCP 雖打開了智能的創意上限，但也給後端的設計帶來了無限的複雜度。本文旨在從 MCP 的技術原理、降低 MCP Server 構建複雜度、提升 Server 運行穩定性等方面出發，分享我們的一些實踐心得。文章內容較長，以下是導讀大綱。（點擊閲讀原文，獲取 78 頁完整版 PPT）&lt;/p&gt; 
&lt;p&gt;1、介紹 MCP 的概念及其運作機制。&lt;/p&gt; 
&lt;p&gt;2、解釋 MCP 和 Function Calling 之間的區別。&lt;/p&gt; 
&lt;p&gt;3、講述 MCP 的本質和挑戰，包括描述 MCP 信息的系統提示詞的挑戰，MCP Client 與 MCP Server 之間協同關係的挑戰，快速構建 MCP Server，自建 Dify 的痛點等。&lt;/p&gt; 
&lt;p&gt;4、分析如何解決 MCP 的各個挑戰，包括 MCP Register、MCP Server 和 Promt 的統一管理、MCP 效果驗證體系和安全性保障、MCP 網關、MCP Server 的動態服務發現、Streamable HTTP、彈性效率、可觀測等。&lt;/p&gt; 
&lt;p&gt;5、最後探討 MCP 對 AI 應用架構新範式的影響，並介紹 MCP Server First 的理念。&lt;/p&gt; 
&lt;h2&gt;AI Agent 現狀及架構&lt;/h2&gt; 
&lt;p&gt;人工智能（AI）在商業領域的應用正日益成為推動創新和效率提升的核心力量。其核心在於多個 AI Agent 的協作，這些 AI Agent 通過分工與合作，共同承載 AI 應用所支持的業務需求。這種協作模式不僅優化了企業運營，還展現了 AI 在解決高影響力挑戰中的潛力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-76b1a0b5eb99a3069f519e05de7f8273c8f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當前的 AI Agent，無論是和各種 Tools（各類業務服務接口）交互，還是和各類 Memory（各類存儲服務接口）交互，亦或是和各類 LLMs（各類大語言模型）交互，都是通過 HTTP 協議的，除了 LLM 因為基本都遵循 OpenAI 範式以外，和其他的 Tools 和 Memory 交互都需要逐一瞭解它們的返回格式進行解析和適配。當一個 AI 應用包含多個 AI Agent 時，或者一個 AI 應用需要和多個業務服務接口和存儲服務接口交互時，整體的開發工作量是很大的，主要體現在 3 個方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;找適合該 AI 應用的業務接口和存儲服務接口：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;找三方服務接口。&lt;/li&gt; 
   &lt;li&gt;在公司內部找合適的服務的接口。&lt;/li&gt; 
   &lt;li&gt;找不到就自己先開發接口。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;解析接口的返回格式：無論是三方服務接口還是公司內部的服務接口，返回格式可能都千奇百怪，需要逐一進行了解和解析。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;編排多個 AI Agent：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;有 Dify 這類流程可視化的工具輔助編排，減輕了很多編排工作，但複雜度依然不低，且運行效率和性能方面還是有瓶頸的。&lt;/li&gt; 
   &lt;li&gt;通過編碼方式做編排（比如使用 Spring AI Alibaba 或 LangChain 等），雖然性能上更優，但是複雜度更高，編排效率和靈活性都有不足。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以目前很多 AI 應用就只有少數幾個 AI Agent，甚至很多 AI 應用背後就只有一個 AI Agent。這也是目前 AI 應用背後的 AI Agent 依然還處在第一個階段（Siloed, Single-Purpose Agents）的原因。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e25347863ed2a9c56ba0532f785a792e3ed.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了能使 AI Agent 進入到第二階段（Platform-Level Agents），我們使用雲原生 API 網關做了統一的接入層，通過一個網關三種不同角色的方式，解決了一部分複雜度：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;作為南北向流量網關，統一管理 AI Agent 的入口流量，核心做轉發、負載、鑑權認證、安全、流控等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;作為 AI 網關，代理各類 LLMs，向 AI Agent 屏蔽了繁雜的接入，並且解決了很多生產級的問題，比如多模型切換、模型 Fallback、多 API Key 管理、安全、聯網搜索等。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;AI 網關代理 LLMs 的詳細文章參見：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247573215%26idx%3D1%26sn%3Df77c5dd8423a9480afb6a03fce0d997c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247573215%26idx%3D1%26sn%3Df77c5dd8423a9480afb6a03fce0d997c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/tZ0wsTlZK67r9IxNZ57TDQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;作為東西向網關，統一管理來自不同源（ACK、ECS、函數計算 FC、SAE、三方服務）的各類服務，供 AI Agent 使用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;但如我所説，這隻解決了一部分複雜度問題，更核心的&lt;strong&gt;找接口&lt;/strong&gt; 和&lt;strong&gt;解析接口&lt;/strong&gt;這兩個問題依然沒有解決。直到 MCP（Model Context Protocol）的出現，讓我們看到了真正通往第二階段（Platform-Level Agents）的路，甚至可以嘗試觸摸第三階段（Universal Agents, Multi-Agents）。&lt;/p&gt; 
&lt;h2&gt;MCP 是什麼&lt;/h2&gt; 
&lt;p&gt;MCP 是模型上下文協議（Model Context Protocol）的簡稱，是一個開源協議，由 Anthropic（Claude 開發公司）開發，旨在讓大型語言模型（LLM）能夠以標準化的方式連接到外部數據源和工具。它就像 AI 應用的通用接口，幫助開發者構建更靈活、更具上下文感知能力的 AI 應用，而無需為每個 AI 模型和外部系統組合進行定製集成。MCP 被設計為一個通用接口，類似於 USB-C 端口，允許 LLM 應用以一致的方式連接到各種數據源和工具，如文件、數據庫、API 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-46b7eef569ef0b1f4357d3f79f965843530.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP 目前一共有 3 個核心概念：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MCP Server：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;基於各語言的 MCP SDK 開發的程序或服務。&lt;/li&gt; 
   &lt;li&gt;基於某種&lt;strong&gt;神祕的機制&lt;/strong&gt;將現存的程序或服務進行了轉換，使其成為了 MCP Server。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP Tool：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MCP Tool 所屬於 MCP Server，一個 MCP Server 可以有多個 MCP Tool。可以理解為一個類裏有多個方法，或者類似一個服務裏有多個接口。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP Client：當一段代碼，一個 Agent，一個客戶端，基於 MCP 的規範去使用、去調用 MCP Server 裏的 MCP Tool 時，它就是 MCP Client。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MCP 的運作機制&lt;/h3&gt; 
&lt;p&gt;要真正理解 MCP 是什麼，我們需要了解它的運作機制，然後你就能知道 MCP 的調用方式和傳統的 HTTP 調用方式有什麼不同，可能也能隱約體會到為什麼我説 MCP 可以讓 AI Agent 進入第二階段。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3316ba085c95379e9635dfbbefb726a0388.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，一次基於 MCP 的調用，一共有 6 個核心的步驟。我們先擬定一個前提：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我要開發一個獲取時間的 AI Agent，用戶在使用這個 AI Agent 時，只需要問類似&quot;現在幾點了？&quot;這種問題即可。&lt;/li&gt; 
 &lt;li&gt;我已經有了一個關於處理時間的 MCP Server，這個 MCP Server 裏有 2 個 MCP Tool，一個負責獲取當前時區，一個負責獲取當前時間。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;調用步驟解析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;第一步：用戶向 AI Agent 問&quot;現在幾點了？&quot;，此時 AI Agent 就是 MCP Client，它會把用戶的問題和處理時間的 MCP Server 以及 MCP Tool 的信息一起發送給 LLM。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第二步：LLM 拿到信息後開始推理，基於用戶的問題和 MCP Server 的信息，選出解決用戶問題最合適的那個 MCP Server 和 MCP Tool，然後返回給 AI Agent（MCP Client）。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;這裏 LLM 返回給 AI Agent 的信息是：&quot;你用 time 這個 MCP Server 裏的 get_current_time 這個 MCP Tool 吧，它可以解決用戶的問題&quot;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第三步：AI Agent（MCP Client）現在知道該使用哪個 MCP Server 裏的哪個 MCP Tool 了，直接調用那個 MCP Tool，獲取結果。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;調用 time 這個 MCP Server 裏的 get_current_time 這個 MCP Tool。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第四步：Time MCP Server 返回結果（當前的時間）給 AI Agent（MCP Client）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第五步：AI Agent（MCP Client）也很懶啊，把用戶的問題和從 Time MCP Server 處拿到的結果再一次給了 LLM，目的是讓 LLM 結合問題和答案再規整一下內容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;第六步：LLM 把規規整整的內容返回給 AI Agent（MCP Client），最後 AI Agent（MCP Client）再原封不動的返回給了用戶。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MCP 的整個調用過程中有一個非常核心的點就是 MCP Server 以及 MCP Tool 的信息。從第一步，第二步可以看出，這個信息非常關鍵，是它讓 LLM 知道了該如何解決用戶的問題，這個信息就是 MCP 中最重要的 System Prompt，本質上就是 PE 工程。&lt;/p&gt; 
&lt;h3&gt;MCP System Prompt&lt;/h3&gt; 
&lt;p&gt;MCP 不像傳統的協議定義，它沒有一個確定的數據結構。它的核心是通過自然語言描述清楚有哪些 MCP Server，承擔什麼作用，有哪些 MCP Tool，承擔什麼作用，然後讓大語言模型通過推理去選擇最合適的 MCP Server 以及 MCP Tool。所以它的核心本質上還是提示詞工程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-120aa561c4f9d67cebd623ba4cb5ceab2eb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-86391324e806a590732d3b9ffd5e4358359.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上面兩張圖是 Cline（一個 MCP Client）中的 System Prompt，可以清晰的看到它對 MCP Server 和 MCP Tool 都有明確的描述。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8c589278bba00c8154935bf90b5922f5e85.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上圖是流程中的第一步，將用戶的問題和 System Prompt 一起發送給 LLM 的內容。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7f1b4a7b3fc2d4626d822b43aee01b16cef.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上圖是流程中的第二步，LLM 返回瞭解決用戶問題明確的 MCP Server 和 MCP Tool 信息。&lt;/p&gt; 
&lt;h3&gt;MCP 和 Function Calling 之間的區別&lt;/h3&gt; 
&lt;p&gt;看到這，我想大家應該對 MCP 是什麼有一定感覺了。MCP 是不是解決了&lt;strong&gt;找接口&lt;/strong&gt; 和&lt;strong&gt;解析接口&lt;/strong&gt;的問題？因為這兩個工作都交給了 LLM。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLM 負責幫 AI Agent 找到最合適的接口。&lt;/li&gt; 
 &lt;li&gt;AI Agent 調用接口，壓根不用做返回結果的解析，原封不動再交給 LLM。&lt;/li&gt; 
 &lt;li&gt;LLM 結合用戶問題和接口返回的結果，做內容規整處理。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;那麼可能有小夥伴會問，MCP 和 LLM 的 Function Calling 又有什麼區別呢？核心區別是是否綁定模型或模型廠商：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP 是通用協議層的標準，類似於&quot;AI 領域的 USB-C 接口&quot;，定義了 LLM 與外部工具 / 數據源的通信格式，但&lt;strong&gt;不綁定任何特定模型或廠商&lt;/strong&gt;，將複雜的函數調用抽象為客戶端-服務器架構。&lt;/li&gt; 
 &lt;li&gt;Function Calling &lt;strong&gt;是大模型廠商提供的專有能力&lt;/strong&gt;，由大模型廠商定義，不同大模型廠商之間在接口定義和開發文檔上存在差異；允許模型直接生成調用函數，觸發外部 API，依賴模型自身的上下文理解和結構化輸出能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b8eff8e848cb828269fb1e47357cb5a7ddb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，LLM Function Calling 需要 LLM 為每個外部函數編寫一個 JSON Schema 格式的功能説明，精心設計一個提示詞模版，才能提高 Function Calling 響應的準確率，如果一個需求涉及到幾十個外部系統，那設計成本是巨大，產品化成本極高。而 MCP 統一了客戶端和服務器的運行規範，並且要求 MCP 客戶端和服務器之間，也統一按照某個既定的提示詞模板進行通信，這樣就能通過 MCP 加強全球開發者的協作，複用全球的開發成果。&lt;/p&gt; 
&lt;h3&gt;MCP 的本質和挑戰&lt;/h3&gt; 
&lt;p&gt;根據上文的一系列解釋，我們可以總結一下 MCP 的本質：&lt;strong&gt;模型上下文協議（Model Context Protocol）並不是一個確定的數據格式或數據結構，它是&lt;/strong&gt; 描述 MCP Server/MCP Tool 信息的系統提示詞&lt;strong&gt;和&lt;/strong&gt; MCP Server 與 LLM 之間的協同關係&lt;strong&gt;的結合&lt;/strong&gt; &lt;strong&gt;，&lt;/strong&gt; &lt;strong&gt;解決的是&lt;/strong&gt; 找接口&lt;strong&gt;和&lt;/strong&gt; 解析接口&lt;strong&gt;的問題&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-dd0578fcdb7e680a0c9312663e7727d8586.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;明確了 MCP 本質之後，將其帶入到企業級生產應用中，你就會發現，這兩個核心點上會有很多挑戰，或者説不足。&lt;/p&gt; 
&lt;h4&gt;描述 MCP 信息的系統提示詞的挑戰&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;系統提示詞的安全性如何保證？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;這個最核心的系統提示詞如果被污染了，LLM 就不能準確知道你有哪些 MCP Server，有哪些 MCP Tool，甚至可能告訴 LLM 錯誤的，有安全漏洞的 MCP Server 和 MCP Tool，那麼對你的 AI 應用來説將是巨大的風險，會導致整個 MCP 流程的癱瘓。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;系統提示詞如何管理？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MCP Server 或者 MCP Tool 有了新版本，系統提示詞應該也許要有對應的版本管理策略。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;系統提示詞寫的不好，如何方便的快速調試？能不能實時生效？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系統提示詞是沒有標準定義的，理論上每個企業可以定義自己的系統提示詞模板，類似 PE 工程。提示詞不可能一次性就能寫好，需要反覆調試，需要有機製做快速的調整，並且可以做到使其實時生效。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 MCP Server 很多，那麼系統提示詞會非常長，豈不是很消耗 Token？如何縮小或精確 MCP Server 和 MCP Tool 的範圍？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;如果你有幾十個或更多 MCP Server，那麼就有可能有上百個或更多 MCP Tool，所有的信息描述下來放在系統提示詞後，這個提示詞模板會非常大，顯而易見的對 Token 消耗非常大，變相的就是成本高。應該需要一套機制，基於用戶的問題，預圈選 MCP Server 和 MCP Tool 的範圍，減少 Token，提高效率，很類似聯網搜索裏的意圖識別。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;MCP Client 與 MCP Server 之間協同關係的挑戰&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;負責做協同的是 MCP Client，但目前 MCP Client 很少，比如 Cline， Claude，Cursor 等，而且都是 C/S 工具，支持的都是 SSE 協議，企業級的 AI 應用該如何結合？能不能結合？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;基本上目前市面中的 MCP Client 都無法和企業級的 AI 應用做結合，SSE 這種有狀態的協議有很多弊端，比如不支持可恢復性，服務器需要維持長期連接，僅支持服務器 → 客戶端消息，無法靈活進行雙向通信等。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;現存的傳統業務能快速轉成 MCP Server 嗎？能 0 代碼改動的轉換嗎？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;開發一個 MCP Server 是強依賴各語言的 MCP SDK 的，目前只支持 Python、Java、TS、Kotlin、C#。那如果是 Go 或者 PHP 技術棧的企業怎麼辦？並且那麼多現存的業務全部用 MCP SDK 重構一遍，工作量巨大，也很不現實。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP Server 會很多，如何統一管理？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;有自己開發的 MCP Server，有三方的 MCP Server，還有大量通過某種神祕機制將傳統業務轉換而來的 MCP Server。這些都應該有一個類似 MCP Hub 或 MCP 市場的東西統一管理起來，方便 MCP Client 去使用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企業級 AI 應用中，身份認證、數據權限、安全這些如何做？&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在企業級的應用中，無論哪種協議，哪種架構，哪種業務。身份認證、數據權限、安全防護這些問題都是永遠繞不開的。那麼在 MCP 這種協同方式下如何實現。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;AI 應用架構新範式&lt;/h2&gt; 
&lt;p&gt;我們結合 MCP 範式，以解決上述挑戰點為目的，將 AI Agent 的架構進行了重構。在雲原生 API 網關 &lt;strong&gt;，&lt;/strong&gt; 微服務引擎 Nacos &lt;strong&gt;兩個產品中做了 MCP 增強能力，解決了上述大部分的挑戰點。在&lt;/strong&gt; 函數計算 FC &lt;strong&gt;，&lt;/strong&gt; Serverless 應用引擎 SAE &lt;strong&gt;兩個產品中做了 MCP 增強能力，前者解決快速開發 MCP Server 的問題，後者解決開源 Dify 性能的問題。共同構建了基於 MCP 的&lt;/strong&gt; AI 應用開發新範式。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-03e42880c942d913877ccf06ee2afa243e7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;AI 應用架構新範式剖析&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ff32b45cf513d2b21df5bf3986ed678137a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;首先我對圖中的 8 步核心調用鏈路做以解析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步：用戶向 AI 應用發起請求，請求流量進入流量網關（雲原生 API 網關）。&lt;/li&gt; 
 &lt;li&gt;第二步：雲原生 API 網關側維護管理了不同類型的 AI Agent 的 API 或路由規則，將用戶請求轉發至對應的 AI Agent。&lt;/li&gt; 
 &lt;li&gt;第三步：AI Agent 無論以哪種方式實現，只要其中的節點需要獲取數據，便向 MCP 網關（雲原生 API 網關）請求獲取可用的 MCP Server 及 MCP Tool 的信息。&lt;/li&gt; 
 &lt;li&gt;第四步：因為 MCP 網關處可能維護了很多 MCP 信息，可以藉助 LLM 縮小 MCP 範圍，減少 Token 消耗，所以向 AI 網關（雲原生 API 網關）發請求和 LLM 交互。（這一步可選）&lt;/li&gt; 
 &lt;li&gt;第五步：MCP 網關將確定好範圍的 MCP Server 及 MCP Tool 的信息 List 返回給 AI Agent。&lt;/li&gt; 
 &lt;li&gt;第六步：AI Agent 將用戶的請求信息及從 MCP 網關拿到的所有 MCP 信息通過 AI 網關發送給 LLM。&lt;/li&gt; 
 &lt;li&gt;第七步：經過 LLM 推理後，返回解決問題的一個或多個 MCP Server 和 MCP Tool 信息。&lt;/li&gt; 
 &lt;li&gt;第八步：AI Agent 拿到確定的 MCP Server 和 MCP Tool 信息後通過 MCP 網關對該 MCP Tool 做請求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實際生產中 ③ - ⑧ 步會多次循環交互。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-10882473c8c301e063c2f4542b92db86114.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們依然基於 MCP 的兩個本質來刨析這個新的架構。&lt;/p&gt; 
&lt;h4&gt;如何解決 MCP 提示詞的各個挑戰&lt;/h4&gt; 
&lt;p&gt;我們團隊是中間件開源最多的團隊，比如 Nacos，Higress，Sentinel，RocketMQ，Seata 等，並且還維護着 Spring Cloud Alibaba，Spring AI Alibaba，Dubbo 這些開源開發框架，在微服務架構領域有着豐富的經驗。所以在 MCP Server 和 MCP 提示詞統一管理這個點上，天然的就想到了微服務領域裏基於 Nacos 做服務註冊發現和配置統一管理的模式，我們將其轉嫁到了 MCP 範式，大家可以想一下以下這些對應關係：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SpringCloud 服務/Dubbo 服務/Go 服務 -&amp;gt; 各類 MCP Server&lt;/li&gt; 
 &lt;li&gt;SpringCloud 服務/Dubbo 服務/Go 服務暴露的接口 -&amp;gt; 各類 MCP Server 提供的 MCP Tool&lt;/li&gt; 
 &lt;li&gt;SpringCloud 服務/Dubbo 服務/Go 服務暴露的接口描述 -&amp;gt; 各類 MCP Server 提供的 MCP Tool 的描述&lt;/li&gt; 
 &lt;li&gt;SpringCloud 服務/Dubbo 服務/Go 服務的配置文件 -&amp;gt; 各類 MCP Server 的系統提示詞&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6116237b6f29c9c47ddc3920068838f27b1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所以在 MSE Nacos 這個產品中，我們做了一系列增強 MCP 的能力，使 MSE Nacos 成為統一管理 MCP Server 的 MCP Register（MCP Server 註冊/配置中心）。是 AI 應用開發新範式的核心組件。&lt;/p&gt; 
&lt;p&gt;另外，MCP 官方的 Roadmap 中，也在規劃 MCP Register 的能力，我們會基於 Nacos 作為 MCP Register 的方案和 MCP 在開源側進行共建。&lt;/p&gt; 
&lt;h5&gt;MCP Register（MCP Server 註冊/配置中心）&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c723b1909c83c053b67c2e0435ec0551977.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP Server 統一管理&lt;/h5&gt; 
&lt;p&gt;MCP Server 註冊到 MSE Nacos 有兩種方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 MSE Nacos 控制枱手動創建。也就是將 MCP Server 的 Endpoint 配置到 MSE Nacos 中。&lt;/li&gt; 
 &lt;li&gt;通過 Nacos SDK，自動將 MCP Server 註冊進 Nacos。和當前 Java SpringCloud，Java Dubbo 服務邏輯一樣。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MSE Nacos 中對 MCP Server 進行統一管理，可以實現對 &lt;strong&gt;MCP Server 的健康檢查，負載均衡，描述信息 Json 向 XML 轉換，MCP Server 上下線管控等功能&lt;/strong&gt;。&lt;/p&gt; 
&lt;h5&gt;MCP Prompt 統一管理&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-693257655e2f075fee6fe4cf19c69710116.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 MSE Nacos 中維護 MCP Server 的 Prompt 有兩種方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;手動創建 MCP Server 的配置信息，配置文件的 Data ID 的命名格式為&lt;code&gt;[MCP Server name]-mcp-tools.json&lt;/code&gt;。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在配置文件中管理 MCP Tool 的提示詞信息，比如整體作用描述，入參描述等。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;結合 MSE 治理的能力，如果是 Java 或者 Go，可以自動感知服務的 Schema，自動生成 MCP Server 和 MCP Tool 的提示詞信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MSE Nacos 中對 MCP Server 提示詞進行統一管理，可以實現 &lt;strong&gt;MCP 提示詞版本管理（回滾），MCP 提示詞灰度管理，MCP 提示詞安全管理，MCP 提示詞動態調優實時生效等功能&lt;/strong&gt;。&lt;/p&gt; 
&lt;h5&gt;MCP 效果驗證體系（進行中）&lt;/h5&gt; 
&lt;p&gt;上文中提到當 MCP Server 很多時，MCP Server 的各描述信息會很多，也就是 Prompt 會很長，Token 消耗很大，所以需要有機制基於用戶的輸入縮小 MCP Server 範圍，減少 Token 消耗，增加 LLM 推理效率。除此以外，大家知道，只要是和 LLM 交互的場景，提示詞的好壞是需要多次調試的，MCP 的整個流程強依賴提示詞工程，如果提示詞調整不好，LLM 無法返回準確的 MCP Server 和 MCP Tool，那麼整個流程就是不可用的狀態了。所以在 Nacos 中我們正在做一個 MCP 效果驗證的體系。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-168928facd996f1d8f0df17cc8fedd1005e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;核心的原理是我們會提供一個基於 Spring AI Alibaba 開發的 AI Agent，通過用戶配置的業務輸入、LLM、圈定的 MCP Server 和 MCP Tool 的集合不斷的做驗證，將結果以視圖的方式展現出來（比如成功率等）。用戶可以在 Nacos 中動態的對成功率低的 MCP Server 的提示詞做調整優化。&lt;/p&gt; 
&lt;h5&gt;MCP 安全性保障（持續完善中）&lt;/h5&gt; 
&lt;p&gt;無論哪種架構，哪種模式，安全性在企業生產中必然都是第一位的，MCP 領域也不例外，並且需要考慮的環節更多。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-2fa44d5a0dbc05da8d02a3a41e69d32e0ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP Server 敏感信息安全管理：註冊進 MSE Nacos 的各類 MCP Server 都會有類似 API Key、AK/SK、密鑰、登錄密碼等敏感信息。MSE Nacos 和阿里雲 KMS 深度集成，可以對這些敏感信息做加密處理。&lt;/li&gt; 
 &lt;li&gt;MCP Prompt 安全管理：同樣依託於 MSE Nacos 和 KMS 的深度集成，可以將 MCP Server，MCP Tool 完整的 Prompt（描述信息）做加密處理，避免 Prompt 污染。&lt;/li&gt; 
 &lt;li&gt;MCP Prompt 安全校驗：結合上述的驗證體系以及與內容安全做集成，實現 MSE Nacos 對 MCP Server 的 Prompt 的合法性校驗。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;如何解決 MCP Client 與 MCP Server 之間協同關係的挑戰&lt;/h4&gt; 
&lt;p&gt;在 MCP 範式中，其實是三個角色在互相協同：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP Client -&amp;gt; LLM&lt;/li&gt; 
 &lt;li&gt;MCP Client -&amp;gt; MCP Server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這兩類協同關係本質上還是服務提供方和服務消費方之間的關係，涉及到&lt;strong&gt;代理協作&lt;/strong&gt; 和&lt;strong&gt;流量管控&lt;/strong&gt;兩個核心點。在傳統開發範式下，通常是由網關來負責的。所以我們在雲原生 API 網關中增強了 LLM 代理和 MCP Server 代理的能力，使其同時具備流量網關，AI 網關（LLM 代理）和 MCP 網關的能力。是 AI 應用開發新範式的核心組件。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-be80748631259c1b0803fc6e483b5a0c941.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所以在企業的整體系統架構中，只需要一個雲原生 API 網關，即可作為流量網關、API 網關、微服務網關、AI 網關、MCP 網關，在代理和流量管控層面實現傳統業務和 AI 業務的大統一，並且再結合 AI 應用開發的新範式，平滑的將 AI 業務和傳統業務相結合。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8619b9be1118c77b682923cbfbec24b5780.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;雲原生 API 網關 Dog Food&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b0b6f6f53c814320166453d81b7f32b99bf.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;秉承着自己吃自己狗糧的原則，雲原生 API 網關在阿里集團內部已經有很多業務在深度使用，在企業級產品能力，穩定性，性能方面已經有多個大體量業務的背書。&lt;/p&gt; 
&lt;h5&gt;AI 網關&lt;/h5&gt; 
&lt;p&gt;MCP Client 與 LLM 之間的交互和傳統業務與 LLM 之間的交互本質是一樣的，只要應用上生產，都會有一系列的問題需要去解決：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;成本平衡問題：比如部署 DeepSeek R1 671B 滿血版模型，至少需要 2 台 8 卡 H20 機器，列表價年度超過 100W，但 2 台的 TPS 有限，無法滿足生產部署中多個用戶的併發請求。即使 Meta 新發布的 Llama4，也至少需要一張 H100 去運行。所以需要有方案找到 TPS 和成本之間的平衡點。&lt;/li&gt; 
 &lt;li&gt;模型幻覺問題：即使是 DeepSeek R1 671B 滿血版模型，如果沒有聯網搜索，依然有很嚴重的幻覺問題。&lt;/li&gt; 
 &lt;li&gt;多模型切換問題：單一模型服務有較大的風險和侷限性，比如穩定性風險，比如無法根據業務（消費者）選擇最優模型。目前也沒有開源組件和框架解決這類問題。&lt;/li&gt; 
 &lt;li&gt;安全合規問題：企業客戶需要對問答過程做審計，確保合規，減少使用風險。&lt;/li&gt; 
 &lt;li&gt;模型服務高可用問題：自建平台性能達到瓶頸時需要有一個大模型兜底方案，提升客戶大模型使用體驗。&lt;/li&gt; 
 &lt;li&gt;閉源模型 QPS/Token 限制問題：商業大模型都有基於 API Key 維度的 QPS/Token 配額限制，需要一個好的方式能夠做到快速擴展配額限制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以上問題都是實實在在的客戶在使用過程中遇到的問題，有些是模型自身問題，有些是部署架構問題，如果要客戶一個一個去解決，複雜度和時間成本都是比較高的。所以就需要 AI 網關的介入來快速的，統一的收斂掉這些核心問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-979c884967f9dd509ee14425480408fa609.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雲原生 API 網關的 AI 網關增強能力主要有四部分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多模型適配：可以代理市面上所有主流的模型託管服務，以及兼容 OpenAI 協議的 AI 服務。在這個模塊中包括協議轉換、多 API Key 管理、Fallback、多模型切換等多個核心功能。&lt;/li&gt; 
 &lt;li&gt;AI 安全防護：安全防護分為三個層面，一個是輸入輸出的內容安全防護，另一個是保護下游 LLM 服務的穩定，以及管控 AI 接口消費者。在這個模塊中包括內容審核、基於 Token 的限流降級、消費者認證等多個核心功能。&lt;/li&gt; 
 &lt;li&gt;AI 插件：AI 網關的靈活擴展機制我們使用插件的形式來實現，目前有很多預置的插件，用戶也可以開發自定義插件來豐富 AI 場景流量的管控。比如基於 AI 插件機制我們實現了結果緩存、提示詞裝飾器、向量檢索等能力。&lt;/li&gt; 
 &lt;li&gt;AI 可觀測：AI 場景的可觀測和傳統場景的可觀測是有很大區別的，監控和關注的指標都是不同的，雲原生 AI 網關結合阿里雲日誌服務和可觀測產品實現了貼合 AI 應用業務語義的可觀測模塊和 AI 觀測大盤，支持比如 Tokens 消費觀測，流式/非流式的 RT，首包 RT，緩存命中等可觀指標。同時所有的輸入輸出 Tokens 也都記錄在日誌服務 SLS 中，可供用戶做更詳細的分析。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 網關代理 LLM 更詳細的方案可以參見我之前的文章： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtZ0wsTlZK67r9IxNZ57TDQ&quot; target=&quot;_blank&quot;&gt;AI 網關代理 LLMs 最佳實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ad17af83a1e5f0e85f744f7f6c2467e9eb5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP 網關&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1b333f6b4365a768b67f0134cb276dfa56f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP Client 和 MCP Server 之間的交互和傳統的服務提供者和服務消費者之間的交互就有所區別了，所以我們在雲原生 API 網關中增加了 MCP 相關的能力，但從產品版本劃分層面，MCP 相關的能力依然包含在 AI 網關的能力範疇內。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3bd22ce32b62b13d4980394307caec2bb17.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP Server 動態發現&lt;/h5&gt; 
&lt;p&gt;上文中介紹了 MSE Nacos 作為 MCP Server 註冊/配置中心，那麼 MCP Client 如何來發現呢？如果是 MCP Client 直接和 MSE Nacos 交互，那麼又會在 MCP Client 中引入 Nacos SDK，增加了編碼的複雜度。&lt;/p&gt; 
&lt;p&gt;鑑於雲原生 API 網關和 MSE Nacos 在傳統服務領域早已做了深度集成，打通了雲原生 API 網關自動發現註冊在 MSE Nacos 中的服務，所以在 MCP 範式下，我們同樣實現了雲原生 API 網關自動發現註冊在 MSE Nacos 中的 MCP Server 的能力。&lt;/p&gt; 
&lt;p&gt;通過這種方式，MCP Client 只需要使用雲原生 API 網關的接入點，即可自動的、動態的獲取到所有註冊在 MSE Nacos 中的 MCP Server。雲原生 API 網關（MCP 網關）就變成了一個 MCP Hub，無論如何更新、變更 MCP Server，都只需要在 MSE Nacos 操作即可，MCP Client 無需做任何修改。&lt;/p&gt; 
&lt;h5&gt;將傳統服務 0 代碼改造轉換為 MCP Server&lt;/h5&gt; 
&lt;p&gt;在 AI 的時代下，我認為最有價值的是使用 AI 增強、提升客戶的現存業務，使其變成一個 AI 應用或 AI 加持的業務，而不是完全新開發一套 AI 應用。&lt;/p&gt; 
&lt;p&gt;所以開發一個 AI 應用或者做現存業務的 AI 增強，AI Agent 是需要和大量現存業務做交互的，MCP 雖然統一的協議，但將現存業務重構為 MCP Server 的成本是非常高的，並且目前支持的開發語言有限，像 Go，PHP 都沒有對應的 MCP SDK，所以會讓很多企業想擁抱 MCP，但又無從下手。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bc61c6005adb6f765e14b59cdbeea0fe3d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;網關最擅長做的事情就是協議轉換，Nacos 在傳統微服務場景下已經註冊了很多現存的傳統服務，那麼兩者一拍即合，通過網關將註冊在 Nacos 中的傳統服務 0 代碼改造的轉換為 MCP Server。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;註冊在 MSE Nacos 中的現存業務服務（SpringCloud 服務、Dubbo 服務、Go 服務）不需要做任何改變。&lt;/li&gt; 
 &lt;li&gt;在 MSE Nacos 中新增&lt;code&gt;[Server Name]-mcp-tools.json &lt;/code&gt;命名規範的配置文件，在配置文件中使用 MCP 規範對現存業務的接口進行描述。&lt;/li&gt; 
 &lt;li&gt;通過雲原生 API 網關（MCP 網關），MCP Client 側自動發現由傳統服務轉換來的 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;將 SSE 轉換為 Streamable HTTP&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6c6e2f8f134ba0aca592c05df3946d05fc9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP 範式默認的傳輸協議是 SSE（Server Sent Event），本質上是一種長連接，有狀態的傳輸協議。這種協議在企業級應用中有很多弊端：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;不支持可恢復性（Resumability）：連接斷開後，客戶端必須重新開始整個會話。&lt;/li&gt; 
 &lt;li&gt;服務器需要維持長期連接（High Availability Requirement）：服務器必須保持高可用性，以支持持續的 SSE 連接。&lt;/li&gt; 
 &lt;li&gt;SSE 僅支持服務器 → 客戶端消息，無法靈活進行雙向通信。&lt;/li&gt; 
 &lt;li&gt;目前只有少數幾個 C/S 架構的客戶端和 MCP 提供的用於測試驗證的 Web 客戶端支持 MCP 範式和 SSE 協議。無法用在企業級的生產應用中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;好在 MCP 官方也意識到了該問題，所以在 3 月下旬，發佈了新的 Streamable HTTP 協議。Streamable HTTP 改變了 MCP 的數據傳輸方式，讓協議變得更靈活、更易用、更兼容：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;更靈活：支持流式傳輸，但不強制。&lt;/li&gt; 
 &lt;li&gt;更易用：支持無狀態服務器。&lt;/li&gt; 
 &lt;li&gt;更兼容：適用於標準 HTTP 基礎設施。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;簡單來説，原來的 MCP 傳輸方式就像是你和客服通話時必須一直保持在線（SSE 需要長連接），而新的方式更像是你隨時可以發消息，然後等回覆（普通 HTTP 請求，但可以流式傳輸）。&lt;/p&gt; 
&lt;p&gt;這裏大家可以思考一下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 打破了目前幾個 C 端 MCP Client 的壁壘。也就意味着任何請求方（甚至就是一段簡單的 HTTP Request 代碼），都可以像請求標準 HTTP API 的方式一樣和 MCP Server 交互。&lt;/li&gt; 
 &lt;li&gt;換句話説，當可以使用標準 HTTP API 的方式和 MCP Server 交互後，是不是就不存在所謂的 MCP Client 了？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;雖然 Streamable HTTP 還在草案階段，但云原生 API 網關作為 MCP 網關已經支持了將 SSE 傳輸協議自動轉換為 Streamable HTTP 傳輸協議。或者説，通過雲原生 API 網關（MCP 網關）代理的 MCP Server 同時支持 SSE 和 Streamable HTTP 兩種傳輸協議供 Client 使用。&lt;/p&gt; 
&lt;h5&gt;MCP 模式下的身份認證和權限管控&lt;/h5&gt; 
&lt;p&gt;身份認證和權限管控在任何架構，任何業務場景下都是剛需，在 MCP 範式下也不例外，這裏有兩個層面的權限管控：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Client 有權使用哪些 MCP Server。有權使用某 MCP Server 裏的哪些 MCP Tool。&lt;/li&gt; 
 &lt;li&gt;Client 通過 MCP Tool 有權獲取到哪些數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6d6595b637a2f9c12b007739e38fb843885.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;MCP Server 和 MCP Tool 的使用權限&lt;/h5&gt; 
&lt;p&gt;大家設想一下，當傳統業務可以 0 代碼轉換為 MCP Server 後，註冊在 Nacos 中的 MCP Server 和 MCP Tool 肯定會有很多，從業務領域來説，可能有和財務相關的 MCP Server，有和銷售相關的 MCP Server，有和售後服務相關的 MCP Server。在返回 MCP Server 和 MCP Tool 信息時不可能將所有信息都返回，肯定只能返回 Client 身份有權使用的 MCP Server 信息。&lt;/p&gt; 
&lt;p&gt;雲原生 API 網關作為 MCP 網關，通過成熟的插件機制提供了 HTTP Basic Auth，OAuth2.0，JWT，API Key，外部認證等多種認證方式，以及基於消費者認證功能，可以讓用戶靈活的管理和控制 Client 的身份認證和 MCP Server/MCP Tool 使用權限。&lt;/p&gt; 
&lt;h5&gt;MCP Server 和 MCP Tool 的數據權限&lt;/h5&gt; 
&lt;p&gt;當 MCP Server 是數據類服務時會比較常見，比如 Mysql MCP Server，Redis MCP Server 等。權限會下探到庫級別，表級別。在這種場景下，雲原生 API 網關作為 MCP 網關，可以通過插件機制，改寫或增加 Request Header 的值，結合 MSE 治理將 Header 的值透傳下去，然後在服務內部進一步做數據權限管控。&lt;/p&gt; 
&lt;p&gt;我舉例一個通過這種方式實現的數據庫讀寫分離的場景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-141201d3bda7f80ef0e2186996e5f78e5fa.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;如何快速構建 MCP Server&lt;/h4&gt; 
&lt;p&gt;眾所周知，AI 應用裏涉及到 LLM 推理的場景，大都用在調用相對稀疏的場景，MCP 範式強依賴 LLM 推理，所以無論是基於 HTTP API 模式的 AI 應用開發架構還是基於 MCP 的 AI 應用開發架構，目前也都是應用在相對稀疏調用的場景。所以這裏可以延伸出兩個問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在稀疏調用的場景下，運行 MCP Server 的計算資源如何優化資源利用率，説的再直白一些就是如何能做到成本最優。&lt;/li&gt; 
 &lt;li&gt;在新的業務中，如何快速構建 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在所有的計算產品中，函數計算（FC）這種 Serverless FaaS 類型的計算產品，在資源粒度、彈性策略、彈性效率方面都是最適合稀疏調用場景的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-226f328add64bac9730162c080868382b86.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;函數計算（FC）目前支持了 Python 和 NodeJS 兩種語言的 MCP 運行環境（其他語言的 MCP 運行環境也馬上會支持）。用戶選擇 MCP 運行環境創建函數後，只需要編寫 MCP Tool 的業務邏輯即可，不需要考慮如何使用 MCP SDK。並且雲原生 API 網關和函數計算（FC）有深度集成，可以天然適配 AI 應用開發的新範式。&lt;/p&gt; 
&lt;h5&gt;MCP Server 的彈性效率&lt;/h5&gt; 
&lt;p&gt;基於函數計算（FC）構建的 MCP Server 在彈性效率方面可以從兩個維度來看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;資源規格細粒度管控。&lt;/li&gt; 
 &lt;li&gt;完全按請求彈性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;函數計算（FC）的實例規格從 0.05C 128MB 到 16C 32GB 不等，有幾十種規格的組合方式，可以靈活的根據不同 MCP Server 承載的業務選擇合適的資源規格。另外，在 AI 應用中，尤其是流程式構建的模式中，大多數 AI Agent 的職責都是單一的，計算邏輯不復雜的任務，所以都可以用較小資源規格的函數承載。資源規格小，在資源調度，彈性效率方面自然就會有優勢。&lt;/p&gt; 
&lt;p&gt;再看函數計算（FC）的彈性機制，它是完全按照請求彈性的，有多少 QPS，就拉起對應數量的實例，並且實例可以複用，當 QPS 降下來後，空閒的實例會自動釋放，整個過程完全不需要用戶介入參與。在默認按請求彈性的的基礎上，用戶還可以自行設置按照時間定時彈，或按照指標閾值彈的策略，進一步滿足複雜多變的業務場景，做到資源成本最優。&lt;/p&gt; 
&lt;h5&gt;MCP Server 的可觀測&lt;/h5&gt; 
&lt;p&gt;函數計算（FC）有完善的可觀測體系，也就意味着，基於函數計算（FC）構建的 MCP Server 同樣具備指標、鏈路、日誌三個維度的可觀測能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b5f9da48cc9bb3dc9d0a1a704532ed62b69.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過這套可觀測體系，用戶可以清晰的瞭解每個 MCP Server 的各類運行狀態。&lt;/p&gt; 
&lt;h4&gt;如何解決開源自建 Dify 的痛點問題&lt;/h4&gt; 
&lt;p&gt;目前，Dify 基本已是可視化流程編排 AI Agent 使用最廣泛的工具，但是目前還沒有任何一家雲廠商有 Dify 託管產品，所以很多基於開源自建 Dify 平台的客戶會遇到很多共性的問題，尤其是從個人開發者、開發 Demo 轉向企業級生產應用構建時，這些問題往往都是致命的。&lt;/p&gt; 
&lt;p&gt;企業基於開源自建 Dify 遇到的問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;流量防護弱：基於開源自建沒有任何防護措施，很容易被穿透。&lt;/li&gt; 
 &lt;li&gt;管控與數據鏈路耦合：AI 應用設計與 Agent 的執行耦合在一起，在高併發場景下無法保證穩定性。&lt;/li&gt; 
 &lt;li&gt;負載均衡問題：在大流量情況下，Dify 的核心服務可能會因為流量負載不均導致穩定性下降。&lt;/li&gt; 
 &lt;li&gt;可觀測缺失：開源 Dify 本身不帶可觀測能力，需要額外搭建可觀測體系。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為瞭解決這些問題，阿里雲上的 Serverless PaaS 類型的計算產品 Serverless 應用引擎（SAE）做了企業生產級別的 Dify 託管部署方案，旨在解決上述問題，讓企業在使用 Dify 的時候不用再關心穩定性、健壯性、性能這些問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c555e83a9fc792a92b986916955d7f9752c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h5&gt;快速部署 Dify&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1ba31b5a2dd05293386af6ce14de2ee831e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SAE 提供了 Dify 應用模板，可以一鍵拉起 Dify 應用，並且提供可視化構建的能力，可以對 Dify 裏的每一個環節進行單獨調整。&lt;/p&gt; 
&lt;h5&gt;保障 Dify 穩定高可用&lt;/h5&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-32b0e7199c97341bf0d0222faacf34ca011.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SAE 部署 Dify 支持配置化，三 AZ 部署，實例粒度的自動化遷移，結合雲原生 API 網關和 SAE 內置的服務治理能力，保障負載均衡穩定性，同時還支持 Dify 6 個核心服務的健康檢查，以及無損上下線。&lt;/p&gt; 
&lt;p&gt;同樣依託於底層 Serverless 架構，部署在 SAE 中的應用同樣具備優秀的橫向擴展效率，並且支持多種方式的彈性規則配置，使整套 Dify 服務可以根據不同的業務場景進行彈縮，在保證高可用的同時，又兼具成本優勢。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1cd91079e9cbc4492cadd0a21b9bd65f100.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;除此以外，SAE 還支持小流量預熱，CPU Burst 等能力，進一步保證 Dify 應用在極端情況下的穩定性。&lt;/p&gt; 
&lt;h5&gt;Dify 任務調度方案&lt;/h5&gt; 
&lt;p&gt;定時執行工作流做 AI 數據處理是通用的業務場景，Dify 官網已經把通過定時任務做 Dify 工作流的定時執行和狀態監控作了最佳實踐，可以參考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.dify.ai%2Fzh-hans%2Flearn-more%2Fuse-cases%2Fdify-schedule%E3%80%82%E4%BD%86%E6%98%AF%E8%AF%A5%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84&quot; target=&quot;_blank&quot;&gt;https://docs.dify.ai/zh-hans/learn-more/use-cases/dify-schedule。但是該實踐中的&lt;/a&gt; Dify Schedule 比較簡陋，通過 Github Actions 做定時調度，只能調度公網的 dify 工作流，且不是一個企業級解決方案。&lt;/p&gt; 
&lt;p&gt;開源 Dify 在調度方面的痛點主要有 3 點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;執行記錄過多會導致慢查詢。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;執行歷史記錄存儲在數據庫中，數量太多會影響 Dify 性能，導致慢查詢。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;執行記錄查詢不支持條件過濾。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;比如通過時間區間查詢，通過任務狀態查詢，這些都是通用的需求，但開源 Dify 都不支持。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;沒有報警監控。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任務調度系統需要監控工作流的執行狀態，工作流運行失敗，需要報警給對應的負責人，開源無報警監控能力。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們的方案是通過 MSE 任務調度（SchedulerX）來解決上述問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-89118308221a8bc52e81bd3914f14e5ce97.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用戶在 MSE 任務調度中配置 Dify 的 Endpoint，MSE 任務調度通過 Dify API 拉取工作流應用。&lt;/li&gt; 
 &lt;li&gt;用戶通過 MSE 任務調度配置定時調度和報警監控。&lt;/li&gt; 
 &lt;li&gt;Dify 工作流定時調度的時候，MSE 任務調度通過 Dify 提供的 API 調度用戶的 Dify 應用，並且實時拉取執行結果和詳情，存儲在 MSE 的 AI 任務調度中。&lt;/li&gt; 
 &lt;li&gt;通過 AI 任務調度做報警監控、可觀測增強。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MSE 任務調度集成 Dify 方案對比開源方案有以下 7 點優勢：&lt;/p&gt; 
&lt;p&gt;| 功能 | MSE 任務調度 + Dify | 開源 Dify | | -------- | ---------------- | ------------------- | | 定時調度 | 有 | 無 | | 監控告警 | 有 | 無 | | 執行記錄保留時長 | 保留最近 2 個月 | 無限制，但數據量太大會導致查詢性能太差 | | 執行記錄查詢 | 支持時間區間、狀態等多種查詢條件 | 過濾條件有限 | | 權限管理 | 操作級別精細化權限管理 | 用戶級別 | | 限流 | 應用限流、Token 限流 | 無 | | 失敗自動重試 | 有 | 無 |&lt;/p&gt; 
&lt;h4&gt;AI 應用可觀測體系&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8875e63ae3bd892339ee44b4da9f62c1832.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;結合阿里雲可觀測產品 ARMS，鏈路追蹤 OpenTelemetry，我們構建了 AI 應用全環節的可觀測體系。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f5517df414e4d4c1f132161ef3acac072f9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;AI 應用整體的可觀測體系構建主要有兩部分核心：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;數據採集。&lt;/li&gt; 
 &lt;li&gt;數據串聯與分析。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;觀測數據採集&lt;/h5&gt; 
&lt;p&gt;數據採集的核心是要覆蓋足夠的廣，這裏又分兩個層面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;編程語言，開發框架要支持的足夠廣，足夠全。&lt;/li&gt; 
 &lt;li&gt;AI 應用架構新範式裏涉及到的雲產品也需要以相同的標準上報數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在這兩個層面，我們通過阿里雲應用監控產品 ARMS 和鏈路追蹤 OpenTelemetry 實現了全覆蓋：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;遵循最新 OpenTelemetry 社區 GenAI 語義約定。&lt;/li&gt; 
 &lt;li&gt;支持常見的 AI 框架和 AI 模型，包括 Spring AI Alibaba / LLamaIndex / Langchain / 通義千問 2 / OpenAI / PromptFlow 等。&lt;/li&gt; 
 &lt;li&gt;支持 AI 應用開發的主流編程語言，Python，Java，Go。並且相比社區規範提供更加精細化的埋點和屬性。&lt;/li&gt; 
 &lt;li&gt;支持在不同的調用鏈中傳播會話信息。&lt;/li&gt; 
 &lt;li&gt;雲原生 API 網關支持 OpenTelemetry 協議，網關自身和插件都會基於 OpenTelemetry 上報觀測數據。&lt;/li&gt; 
 &lt;li&gt;函數計算 FC 和 Serverless 應用引擎 SAE 均與應用監控 ARMS 以及鏈路追蹤 OpenTelemetry 版產品均做了深度集成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;數據串聯與分析&lt;/h5&gt; 
&lt;p&gt;應用監控 ARMS 中，專門構建了 LLM 應用監控模塊，針對 AI 應用場景提供了完善的可觀測體系。&lt;/p&gt; 
&lt;p&gt;縱向的指標有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在線 AI 應用數。&lt;/li&gt; 
 &lt;li&gt;Trace 數。&lt;/li&gt; 
 &lt;li&gt;Span 數。&lt;/li&gt; 
 &lt;li&gt;大模型數。&lt;/li&gt; 
 &lt;li&gt;Token 使用情況。&lt;/li&gt; 
 &lt;li&gt;會話數。&lt;/li&gt; 
 &lt;li&gt;用戶數。&lt;/li&gt; 
 &lt;li&gt;模型調用次數。&lt;/li&gt; 
 &lt;li&gt;Token 消耗情況。&lt;/li&gt; 
 &lt;li&gt;模型調用耗時。&lt;/li&gt; 
 &lt;li&gt;Token 消耗排行。&lt;/li&gt; 
 &lt;li&gt;等等...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;橫向鏈路方面提供了專業的調用鏈分析功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Span 列表。&lt;/li&gt; 
 &lt;li&gt;Trace 列表。&lt;/li&gt; 
 &lt;li&gt;散點圖。&lt;/li&gt; 
 &lt;li&gt;全鏈路聚合。&lt;/li&gt; 
 &lt;li&gt;全鏈路拓撲。&lt;/li&gt; 
 &lt;li&gt;錯/慢 Trace 分析。&lt;/li&gt; 
 &lt;li&gt;調用鏈上的每個環節都會輸入、輸出、Token 消耗的展示。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;更多在途的功能規劃&lt;/h4&gt; 
&lt;h5&gt;Dify DSL 轉 Spring AI Alibaba 編碼&lt;/h5&gt; 
&lt;p&gt;雖然 Dify 在做 AI Agent 開發時已足夠便利，但是受限於 Dify 的開發語言（Python）和流程引擎的實現邏輯。在運行復雜 AI 應用時，性能方面是有缺陷的。所以我們在探索將 Dify 流程的 DSL 自動轉換為基於 Spring AI Alibaba 開發框架的代碼。&lt;/p&gt; 
&lt;p&gt;相當於只使用 Dify 低代碼可視化構建 AI 應用的皮，運行的內核基於 Spring AI Alibaba 開發框架的代碼，這樣既具備了便捷的 AI Agent 編排能力，又具備了更好的運行性能。&lt;/p&gt; 
&lt;h5&gt;基於 LLM 編排 MCP Server&lt;/h5&gt; 
&lt;p&gt;目前的 MCP 模式，LLM 針對用戶的輸入，只返回一個確定的 MCP Server 和 MCP Tool，這是其實是由系統提示詞控制的。理論上 LLM 可以針對用戶的輸入返回多個 MCP Server 和多個 MCP Tool，並且基於 MCP Server 和 MCP Tool 的描述告訴 Client 它們之間的調用順序，相當於由 LLM 做好了 MCP Server 的編排。這個模式我們還在探索中，很類似現在的 Multi-Agent 的模式。&lt;/p&gt; 
&lt;h5&gt;提高 MCP 模式的性能&lt;/h5&gt; 
&lt;p&gt;因為 MCP 模式中，會頻繁和 LLM 交互，顯而易見，相比傳統 API 調用，MCP 這種模式的性能是不好的，所以在一些時延敏感的業務場景中，目前大概率還不適合 MCP 模式。&lt;/p&gt; 
&lt;p&gt;目前我們也在探討和探索如何提高 MCP 模式下的請求性能問題，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;固化 MCP Server/MCP Tool 組合，減少和 LLM 的交互。尤其當實現 LLM 編排 MCP Server 後，和 LLM 的交互可能就只存在於開發態或調試態，雲形態時使用的都是固化好的 MCP Server 和 MCP Tool 的調用關係。&lt;/li&gt; 
 &lt;li&gt;函數計算探索邊緣場景，將 MCP Server 運行在離用戶更近的地方。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;AI 應用架構新範式對企業的影響&lt;/h2&gt; 
&lt;p&gt;至此，企業級 AI 應用架構新範式的介紹就結束了，整個架構裏有很多環節，每個環節裏又有許多細節，在文章中無法一一展開説明。有興趣的同學可以聯繫我共同探討。&lt;/p&gt; 
&lt;p&gt;我們可以設想一下在這個 AI 應用架構新範式下，企業的運營、產品、研發、運維團隊之間的組織結構和協作關係可能會發生哪些變化？應用或系統的開發模式會發生哪些變化？&lt;/p&gt; 
&lt;p&gt;這裏我來分享一下我的暢想。&lt;/p&gt; 
&lt;h3&gt;MCP Server First&lt;/h3&gt; 
&lt;p&gt;API First，前後端分離這兩個概念已經存在很久了，海外企業遵循和實踐的會比較好。因為我深耕在 Serverless 計算領域也有 5 年時間，對 AWS 的 Lambda 架構方案，Azure Functions 架構方案，Azure App Service 架構方案，GCP CloudFunction 架構方案，GCP CloudRun 架構方案有比較多的研究。接觸了很多 Serverless FaaS 和 Serverless PaaS 架構的客戶案例，包括負責落地了不少從雙 A 遷移到阿里雲的客戶。基本上都是標準的基於 APIG+FaaS 模式的 API First 形態。但是在國內，這個模式實踐的並不好，除了高德下決定使用函數計算重構了系統，實現了真正的 API First，前後端分離模式以外，鮮有客戶有這種模式的實踐，也許是有太重的歷史包袱。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f46ebae566ede2fd2c9350a771a8dffac0e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;上圖為高德前後的架構對比&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;在 AI 應用的時代，本質上依然是對各種 API 的調用，但是將 HTTP API 改成 REST API，改造成本是巨大的。但當 MCP 出現後，當我們的方案可以幫助客戶 0 代碼的轉型 AI 應用架構新範式的時候，MCP Server First 是有可能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cb265611348b21fd749d36609d4cfaa1f74.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;運維團隊：負責雲產品的維護（比如雲原生 API 網關，MSE Nacos，Serverless 應用引擎，PAI 這些產品的開通、升配），可觀測體系的維護（也是基於雲產品），和雲廠商保持持續溝通。&lt;/li&gt; 
 &lt;li&gt;研發團隊：理解公司業務的原子化能力，負責構建 MCP Server 池。&lt;/li&gt; 
 &lt;li&gt;運營/市場/產品：通過低代碼可視化方式構建業務流程（業務編排），大白話描述業務需求，快速完成業務流程的搭建，或者説 AI 應用的構建。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以未來很有可能每個企業都有自己的 MCP Server 市場，在 MCP Server 市場裏分門別類，每類 MCP Server 有專門的研發團隊負責，不用太需要考慮統一返回格式，不用考慮開發語言統一。運營、市場、產品等業務方有業務需求或者有新的產品功能需求時，可以通過統一界面用大白話快速構建 AI 應用，MCP+LLM 來實現業務編排，實現 PRD 即產品（PRD as a Product）的新的開發模式。&lt;/p&gt; 
&lt;p&gt;點擊&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Febook%2F8442&quot; target=&quot;_blank&quot;&gt;此處&lt;/a&gt;獲取 78 頁完整版 PPT&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18175077</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18175077</guid>
            <pubDate>Sun, 13 Apr 2025 08:51:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>