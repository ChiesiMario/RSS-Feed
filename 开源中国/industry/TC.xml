<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Wed, 20 Aug 2025 07:41:34 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Reddit 季度收入創歷史新高，得益於人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;Reddit 依託其獨特的小眾社區文化和活躍的問答氛圍，正在人工智能（AI）領域實現盈利增長。該平台的&lt;span&gt;最大&lt;/span&gt;資產在於其用戶生成的真實內容，這一優勢讓 Reddit 在與大型科技公司合作時，佔據了有利位置。公司通過 AI 授權，將平台上的子版塊內容整合入搜索引擎結果中，顯著提升了網站流量，併為廣告主提供了精準的目標受眾。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-4397aa3bf8abe3165b1b0cc3c7e0843e093.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近年來，Reddit 在財務業績方面屢次超越市場預期，用戶每位收入（ARPU）增長速度遠遠快於其他社交媒體平台。這一趨勢推動了 Reddit 股票的上漲，令其市場估值達到新高。隨着投資者對 Reddit 未來增長的信心增強，該公司的股票在過去三個月內上漲了 123%，年內漲幅更是超過 344%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;分析師們對 Reddit 的盈利前景持續看好。數據顯示，Reddit2025 年的每股收益（EPS）預期從最初的 1.14 美元上調至 1.86 美元，增幅達 63%。此外，2026 年和 2027 年的 EPS 預期也有所上升，分別增長了 31% 和 14%。這表明市場對紅迪網的長遠發展充滿信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的快速增長得益於其在人工智能整合和數據授權方面的成功。最近發佈的 「Reddit 問答」 搜索引擎大大提高了用戶互動和流量，帶動了廣告支出的顯著增加，用戶每位收入年增長率達到 47%。這一成果超出了行業內對其逐步發展的預期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的競爭優勢在於其豐富的用戶數據和問答文化，結合 AI 技術，使得每一條內容不僅具有高價值，還能與廣告信息無縫對接。這種獨特的 「防禦性」 網絡效應，讓其他社交平台難以複製 Reddit 的成功模式，幫助其在 AI 應用上走在了行業前列。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管 Reddit 目前的市盈率較高，投資者仍然看好其市場前景。分析師們對 Reddit 的股票保持普遍樂觀，雖然有少數持謹慎態度的觀點，但整體市場支持度依然強勁。只要 Reddit 能夠持續保持良好的增長趨勢，其股票溢價便是合理的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367390</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367390</guid>
      <pubDate>Wed, 20 Aug 2025 07:25:31 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Manus 年化收入運行率突破 9000 萬美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在新加坡舉行的 Stripe Tour 活動上，AI Agent 初創公司 Manus 聯合創始人兼首席科學家季逸超（Peak）公佈了一項令業界矚目的數據：公司當前收入運行率 (RRR) 已達到 9000 萬美元，約合人民幣 5400 萬元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;收入運行率是高速成長型企業常用的財務指標，通過將特定時期收入推算為年化數值。雖然季逸超未透露具體計算方式，但按月度收入推算，Manus 月收入約為 750 萬美元。對於一家成立不足三年的 AI Agent 公司，這一表現已遠超行業平均水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-61c3893c8632aefbb4164d5eab1a71cbd70.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Manus 表示，公司收入主要依託訂閲型服務模式，顯示出較強的用戶粘性和相對穩定的現金流結構。業內分析師認為，9000 萬美元的收入運行率將為 Manus 在下輪融資中帶來更強議價能力。按照當前表現，公司可能被資本市場按"年度收入過億美元"的預期進行估值，這將顯著提升其市場地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，今年 7 月 Manus 總部遷至新加坡的戰略調整，結合此次公佈的財務數據，顯示公司正在全球市場加速佈局。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管數據亮眼，業內人士提醒投資者保持理性。收入運行率並非實際收入，其可持續性仍需市場長期驗證。在 AI 商業化競爭日趨激烈的環境下，Manus 能否將運行率轉化為穩定的年度實際收入，以及在全球市場的擴張執行力，將成為決定其未來發展的關鍵因素。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367382</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367382</guid>
      <pubDate>Wed, 20 Aug 2025 06:55:31 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動即將發佈「世界模型」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fbytedances-upcoming-world-model-altmans-thoughts-gpt-5-fiasco-profitability-going-public" target="_blank"&gt;根據 The Information 的報道&lt;/a&gt;，字節跳動正在籌備自己的「世界模型」（world model），以追隨谷歌和 Meta 的步伐。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/145228_hX8P_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該項目由字節跳動的「Seed」人工智能研發部門主導，項目負責人是前阿里通義千問（Qwen）核心高管周暢。字節跳動在視頻生成領域的積累——尤其是旗下抖音和 TikTok 的海量視頻數據，以及近期開源的 EX-4D 框架（可將單目視頻轉化為 4D 多視角場景）——為其構建世界模型提供了技術基礎和訓練資源。&lt;/p&gt; 
&lt;p&gt;「世界模型」旨在模擬真實環境的物理規律和人類互動方式，未來可用於訓練機器人、自動駕駛系統或構建虛擬世界，被視為通向通用人工智能（AGI）的重要路徑之一。&lt;/p&gt; 
&lt;p&gt;近期，谷歌和 Meta 都分別推出了自家新款世界模型——Genie 3 和 V-JEPA 2。世界模型能模擬出真實的環境，旨在獲得與真實世界相似的物體運動以及人類與周圍環境互動的物理方式，從而用於訓練機器人和自動駕駛模型。&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/364530/genie-3" target="_blank"&gt;谷歌發佈世界模型 Genie 3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/355002/meta-vjepa-2-world-model" target="_blank"&gt;Meta 發佈開源世界模型 V-JEPA 2&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367380</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367380</guid>
      <pubDate>Wed, 20 Aug 2025 06:54:31 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智譜發佈 AutoGLM 2.0：全球首個手機 Agent、雲端自主完成任務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj6BGkYXc8sMsh-iOMYTiaw" target="_blank"&gt;智譜宣佈推出 AutoGLM 2.0&lt;/a&gt;，聲稱將 Agent 應用提升到新的高度：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;全球首個手機 Agent，人人可用；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;開創 Agent + 雲手機 / 雲電腦的新技術範式，不搶佔用戶手機和電腦；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;突破硬件限制，在任何設備、任何場景下運行，幫助用戶代理操作；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;國產模型（GLM-4.5、GLM-4.5V）驅動，具備推理、代碼與多模態的全能能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="786" src="https://static.oschina.net/uploads/space/2025/0820/143328_bZzY_2720166.png" width="1800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;智譜稱，即刻起，人人都可使用 AutoGLM。該公司還將快速迭代推出新功能（「定時任務」 很快上線，AI 每天主動替你幹活）。&lt;/p&gt; 
&lt;p&gt;在 AutoGLM 1.0 中，智譜已探索過讓 AI 代替用戶完成部分手機操作，但只在有限場景下生效。&lt;/p&gt; 
&lt;p&gt;據介紹，隨着 AutoGLM 2.0 的發佈，它已經成長為一名執行型助手，能夠在「雲端」自主完成多樣化的任務。在生活場景中，用戶只需一句話，就能讓 AutoGLM 操作美團、京東、小紅書、抖音等幾十個高頻應用：點外賣、訂機票、查房源，例如幫你買「秋天的第一杯奶茶」。在辦公場景中，它同樣能跨網站執行全流程工作，操作網頁版的飛書、網易郵箱、知乎、微博、抖音、微頭條等網站：從信息檢索到內容撰寫，再到生成視頻、PPT 或播客，並直接完成小紅書、抖音等社交媒體平台內容發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/143743_Rif8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;智譜稱，「這意味着，AI 不再是一個 「聊天工具」，而是一個能真正替你幹活的全能代理人。不僅能給出答案，還能把任務完整執行，幫助用戶節省時間與精力，徹底改變人與 AI 的協作方式。」&lt;/p&gt; 
&lt;p&gt;在 AutoGLM 2.0 中，智譜為 AI 配備了專屬智能體手機 / 智能體電腦，讓它可以在雲端自主幹活、完成任務，而無需佔用用戶的本地設備，期間用戶可以使用其他 App（如刷抖音、打遊戲）。&lt;/p&gt; 
&lt;p&gt;據介紹，AutoGLM 由智譜最新開源 SOTA 語言模型 GLM-4.5 與視覺推理模型 GLM-4.5V 驅動。AutoGLM 將基座模型原生能力發揮到極致，並結合在「端到端異步強化學習」方面的多項突破成果，可以完成推理、編碼、研究、Agentic 與 GUI 操作等多類任務，並可根據需求靈活調用最合適的「大腦」完成執行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ComputerRL&lt;/strong&gt;：提出 API-GUI 協同範式，提升數據多樣性與計算效率；改進 GRPO 並提出 Entropulse 機制，增強探索與策略多樣性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MobileRL&lt;/strong&gt;：創新難度自適應強化學習方法（推理自舉預熱 + 難度自適應 GRPO），顯著提升移動端任務的穩定性與收斂效率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AgentRL&lt;/strong&gt;：通過交叉採樣與任務優勢歸一化機制，解決多任務訓練中的不穩定與梯度分佈不均，增強整體魯棒性與效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在&lt;strong&gt;Device Use 基準測試&lt;/strong&gt;（涵蓋手機、電腦和網頁操作）中，AutoGLM 表現優於&lt;strong&gt;ChatGPT Agent、UI-TARS-1.5 和 Claude Sonnet 4&lt;/strong&gt;，展現出更強的魯棒性與通用性，處於主流 Agent 的&lt;strong&gt;SOTA&lt;/strong&gt;水平。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/143914_h7cV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;智譜稱，已將 AutoGLM 的操作執行能力封裝為 API，開發者只需簡單接入，即可將這一能力無縫融入各類硬件設備，從 AI 眼鏡等可穿戴設備到傳統家電。AutoGLM 首次讓硬件具備完整的手機級操作能力，無需在端側堆疊複雜系統或大容量電池。例如，可以通過智能眼鏡點一杯咖啡。&lt;/p&gt; 
&lt;p&gt;今日起，AutoGLM 移動端 API 申請通道及開發者生態共建計劃正式上線。除手機與電腦外，手錶、眼鏡、家電等設備都能成為 Agent 驅動的智能助手。&lt;/p&gt; 
&lt;p&gt;傳送門：&lt;em&gt;https://autoglm.zhipuai.cn/misc/developer-apply&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;更多技術細節，請參閲 GLM 團隊的三篇最新技術論文：&lt;/p&gt; 
&lt;p&gt;ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents&lt;br&gt; &lt;em&gt;https://arxiv.org/abs/2508.14040&lt;/em&gt;&lt;br&gt; MobileRL: Advancing Mobile Use Agents With Adaptive Online Reinforcement Learning&lt;br&gt; &lt;em&gt;https://github.com/Xiao9905/AutoGLM/blob/main/static/papers/mobilerl_0820.pdf&lt;/em&gt;&lt;br&gt; AgentRL: Reinforcing Multi-task LLM Agents From Zero (Upcoming)&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367374</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367374</guid>
      <pubDate>Tue, 19 Aug 2025 06:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>金山等軟件被常用工具彈窗推廣，流氓行為傳播數十萬終端</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;火絨安全發佈報告稱，近日收到多位用戶反饋稱在安裝某些工具類軟件時遭遇廣告彈窗及其他流氓行為。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對捕獲的樣本進行分析發現，該樣本主要通過捆綁在 Zip 解壓縮、PDF 轉換器及錄屏軟件等常用工具的安裝包中進行傳播，會執行包括靜默推廣安裝金山毒霸、WPS、CAD 看圖王等軟件在內的一系列流氓行為，並最終偽裝成插件進行集成和大規模傳播。流氓行為已傳播數十萬終端。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據火絨威脅情報系統監測，該樣本已感染超過數萬台電腦，傳播範圍波及數十類網站，包括 Zip 解壓縮、錄屏、PDF 轉換器、壁紙、DLL 修復、全能格式轉換、OCR 掃描等多種類型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;樣本流程圖如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="393" src="https://oscimg.oschina.net/oscnet/up-a8431841a25501ff7ae752027ae9d182859.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該樣本採用 C# 開發，初始版本為一個簡單的下載器（Loader），主要功能是從阿里雲存儲桶中獲取安裝包，並通過命令行實現靜默安裝壓縮包的功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;樣本的主要邏輯為：通過代碼偽造安裝界面，包括構造所需數據、下載配置文件、獲取雲端配置信息，並完成 UI 設置；隨後，通過用戶點擊按鈕的操作觸發靜默安裝。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對網站 https://zip.njzhqlkj.cn 進行溯源分析發現，其 JS 腳本被多個域名引用。進一步分析表明，這些域名中有相當一部分在下載的程序中都捆綁了該惡意服務，其中還有大部分已經失效的域名。涉及的域名包括：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="224" src="https://oscimg.oschina.net/oscnet/up-793cbede66ca1a1645e4e110f2ecefeed51.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;部分失效域名如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="627" src="https://oscimg.oschina.net/oscnet/up-13f6f36640b14098198360613753d93765e.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcyngfrD--tEEY02_sbSiRw" target="_blank"&gt;查看官方公告&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367373</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367373</guid>
      <pubDate>Tue, 19 Aug 2025 06:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 崗位月薪最高 7.8 萬，實習生日薪可達 4000 元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;職場社交招聘平台脈脈發佈的崗位統計數據顯示，2025 年人工智能領域人才需求呈現爆發式增長，相關崗位數量與薪資水平均大幅上漲，從業者跳槽意向也較為顯著。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;數據顯示，2025 年 7 月，脈脈平台上人工智能新發崗位量相較 2024 年 1 月暴漲 29 倍，同比增長 10 倍。目前已有超過 1000 家人工智能企業在平台招聘人才，相關在招崗位數量超過 7.2 萬個。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得注意的是，除技術崗位外，設計、銷售、人事、財務、行政、運營、市場等多個非技術崗位也在熱招，顯示出人工智能行業對複合型人才的廣泛需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="261" src="https://oscimg.oschina.net/oscnet/up-572a37607adc58b4b4ce2afe6c1f0054471.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;薪資方面，人工智能相關崗位的薪酬水平持續走高。2025 年 7 月，人工智能相關崗位的招聘薪資下限均值為 4.7 萬元/月，較 2024 年 1 月上漲 14.16%；上限均值為 7.8 萬元/月，較 2024 年 1 月上漲 8.98%。即便在實習崗位中，部分人工智能實習生的日薪可達 4000 元，遠超多數行業正式員工的收入水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與此同時，人工智能領域從業者的跳槽意向較為明顯。脈脈商業運營總監楊瀅透露，自 2025 年 2 月以來，脈脈上每月新增上萬名「正在看機會」的 AI 人才。截至 2025 年 7 月，國內 AI 頭部公司中有 41.07% 的員工求職狀態為「正在看機會」，具有明確的跳槽意願。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對於求職者而言，在脈脈上搜索「AI」，不僅可以發現正在熱招的人工智能高薪崗位，還能與多家人工智能企業的高管、員工直接取得聯繫，從而獲取更多人工智能領域的職場新機遇。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367372</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367372</guid>
      <pubDate>Tue, 19 Aug 2025 06:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 聯合多家公司推出 AGENTS.md，開放且供應商中立的編程 Agent 指導文件標準</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;由 OpenAI Codex、Amp、Google Jules、Cursor、RooCode 和 Factory 組成的 AGENTS.md 工作組宣佈，正式推出一個名為 AGENTS.md 的單一、開放且供應商中立的標準，旨在指導編碼 Agent 在代碼庫中的工作方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a900f271b1a5c51b12eb76900d35ea72fa3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/openai/agents.md&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://agents.md/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AGENTS.md 被定位為 「&lt;strong&gt;為 Agent 設計的 README&lt;/strong&gt;」，是一個簡單、開放的格式，用於向編碼 Agent 提供指導。其設計初衷是為了補充專為人類開發者設計的 README.md 文件。README.md 通常包含快速入門、項目描述和貢獻指南，而 AGENTS.md 則專注於提供編碼 Agent 所需的額外、詳細的上下文信息，例如構建步驟、測試指令、項目結構、代碼約定和安全注意事項等。&lt;/p&gt; 
&lt;p&gt;AGENTS.md&amp;nbsp;作為面向 AI 編程 Agent 提供項目上下文和操作指令的開放格式，它通過結構化的方式詳細指導 AI 代理如何進行開發環境設置、執行代碼測試以及遵循拉取請求（PR）的提交規範，例如使用特定命令導航、安裝依賴、運行各種測試以及格式化 PR 標題等。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# AGENTS.md

## Setup commands
- Install deps: `pnpm install`
- Start dev server: `pnpm dev`
- Run tests: `pnpm test`

## Code style
- TypeScript strict mode
- Single quotes, no semicolons
- Use functional patterns where possible
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這種分離設計旨在為 Agent 提供一個清晰、可預測的指令來源，同時保持 README.md 對人類貢獻者的簡潔性和專注度。&lt;/p&gt; 
&lt;p&gt;使用 AGENTS.md 的方法很簡單：在代碼倉庫的根目錄下創建一個 AGENTS.md 文件。對於大型的 monorepo，可以在每個子項目或包內放置一個嵌套的 AGENTS.md 文件。Agent 會自動讀取目錄樹中最近的該文件，使其指令具有針對性，最接近的配置文件將擁有優先權。&lt;/p&gt; 
&lt;p&gt;目前，該標準已獲得 Cursor、Amp、Jules、Factory、RooCode 和 Codex 等多種 AI 編碼 Agent 和工具的支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367347</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367347</guid>
      <pubDate>Tue, 19 Aug 2025 04:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源剪貼板工具 Ditto 「刪庫」，GitHub 主頁顯示 404</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;知名 Windows 開源剪貼板工具 Ditto 託管在 GitHub 的源代碼已經無法訪問，頁面顯示 404。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-04239240a2badd23bca6b79fbcde83c0d9a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;而且不僅是 Ditto 項目本身，開發者整個的賬號都不見了，不過 Ditto 的官方網站仍然可以正常訪問，在微軟 Microsoft Store 也可以下載。&lt;/p&gt; 
&lt;p&gt;Ditto 自 2004 年發佈以來，一直以其開源、免費且功能強大的特點受到用戶的喜愛，它能夠保存用戶複製的所有內容，包括文本、圖片、HTML 等，並允許用戶後續快速調用。&lt;/p&gt; 
&lt;p&gt;此外，Ditto 還支持網絡共享剪貼板內容，提供了合併粘貼、純文本粘貼、分組、置頂、快速搜索和熱鍵粘貼等功能。目前，關於 Ditto 源代碼庫被刪除的具體原因尚不清楚，也沒有官方聲明對此作出解釋。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367341</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367341</guid>
      <pubDate>Tue, 19 Aug 2025 03:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>扎克伯格計劃重組 Meta 人工智能部門</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta 首席執行官馬克・扎克伯格正積極調整公司的人工智能業務。為了更好地應對市場競爭，Meta 計劃將其人工智能部門 ——Meta&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;超級&lt;/span&gt;智能實驗室拆分為四個小組。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據知情人士透露，其中一個小組將專注於人工智能研究，另一個小組將致力於開發名為 「&lt;span&gt;超級&lt;/span&gt;智能」 的新一代強大人工智能技術。其他兩個小組則分別負責產品開發和基礎設施建設，包括數據中心及相關硬件。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-753b04ace93aaef5886ed55fd23ec57f818.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這一改革的目的在於優化資源配置，提高人工智能產品的開發效率。然而，隨着部門的重組，一些高管可能會離職。此外，由於人工智能部門的規模近年來已擴展至數千人，Meta 正在考慮整體精簡，包括裁員或將部分員工調至其他部門。這些討論仍在進行中，尚未做出最終決定。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta 的人工智能戰略此前經歷了多次動盪，扎克伯格對此表示愈發重視。他願意投入巨資，進行徹底改革，以在快速發展的人工智能領域保持競爭力。今年 6 月，Meta 成立了&lt;span&gt;超級&lt;/span&gt;智能實驗室，專注於打造超越人類大腦的人工智能。為此，Meta 向初創公司 Scale AI 投資了 143 億美元，並聘請該公司的首席執行官亞歷山大・王擔任人工智能首席官。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在過去的幾個月裏，扎克伯格的決策引發了公司內部的緊張局勢。亞歷山大・王的新團隊正在努力打造公司&lt;span&gt;最強&lt;/span&gt;大的人工智能模型，並討論將新模型設為 「閉源」，這與 Meta 長期以來的 「開源」 理念形成鮮明對比。同時，部分 Meta 的老員工對新團隊的引入表示不滿，尤其是在 OpenAI 的研究員趙勝佳被任命為首席人工智能科學家後，老員工們的工作受到了更多審視。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;人事變動還在持續，早期參與 Meta 人工智能研究的高管們也在不斷離職。Meta 的一些&lt;span&gt;頂尖&lt;/span&gt;科學家相繼跳槽，導致公司內部的士氣和穩定性受到影響。儘管如此，一些&lt;span&gt;資深&lt;/span&gt;的人工智能負責人依然留在公司，繼續推動基礎研究的進展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367332</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367332</guid>
      <pubDate>Tue, 19 Aug 2025 03:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美團智能頭盔研發實踐系列 01：硬件設計篇</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;本文系《美團智能頭盔研發實踐》系列的第一篇文章，聚焦硬件設計維度。針對外賣騎手傳統頭盔佩戴體驗不佳等痛點，從安全保障、體驗優化、效率提升三大方向切入，詳細解析安全防護、多傳感器預警、通風減重、長效續航、音頻降噪、工藝控制等關鍵技術，並提煉研發過程中行之有效的設計經驗。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-79872a5be02de16ae8c86ed25e8abf50075.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;前言&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;在現代城市的喧囂中，外賣騎手穿梭於大街小巷，只為將餐食及時送達顧客手中。然而，這份看似簡單的工作背後，卻隱藏着諸多痛點。騎手們面臨的交通環境複雜，這不僅對他們自身的安全構成嚴重威脅，也增加了交通事故的風險。同時，在配送過程中，騎手需要頻繁操作手機接單、打電話與顧客溝通，這在騎行過程中極不方便，還容易分散注意力。此外，長時間佩戴傳統頭盔，悶熱、不舒適以及頭盔穩定性差等問題，也極大地影響了騎手的工作體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//19f460a4db11dda9787ef4225c0142c3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;面對這些痛點，美團推出了智能頭盔，努力為騎手們提供一種全新的安全守護解決方案，展現出安全保障、體驗優化以及效率提升三大核心價值。本文為美團技術團隊在硬件設計層面的一些思考和探索。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;智能頭盔革新：重新定義配送安全裝備&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美團智能頭盔作為專為外賣騎手打造的智能安全裝備，在傳統頭盔基礎上，增加了喇叭、麥克風、快捷按鍵、尾燈等硬件模組，具備藍牙耳機/語音助手功能，實現智能語音交互、實時感知戴盔、碰撞和摔倒等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//dabfa05505233a93228ada853953d011.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;美團研發智能頭盔已有 6 年時間，研發模式從 ODM、JDM 直至 OEM 純自研模式，目前已覆蓋全國 S/A/B 級別 28 座城市的全量專送騎手，累計出貨量突破 100 萬，已經成為 B 端/C 端智能頭盔行業出貨量最大的機構之一。這些智能頭盔，針對行業痛點，為外賣騎手提供了更安全、高效、領先行業的戴盔體驗，努力為外賣騎手提供了一份守護。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a69aebc2198de8ad37a204fa71fce72c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;安全防護體系：超越國標與主動預警的雙重守護&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;2.1 更嚴苛的頭盔設計標準&lt;/h3&gt; 
&lt;p&gt;頭盔設計需要滿足國家強制標準，在行業中，電動車頭盔設計滿足電動自行車乘員頭盔標準就足夠了（GB 811-2022 B3 電動自行車乘員頭盔國家標準）。但從騎手安全角度出發，美團主動將設計標準提升至摩托車頭盔級別（GB 811-2022 A3 摩托車乘員頭盔國家標準）。世界衞生組織（WHO）數據顯示，佩戴頭盔能顯著降低摩托車事故傷亡率，可減少近 40% 的死亡風險、超 70% 的嚴重受傷概率。美團智能頭盔從基礎防護層面，努力為騎手安全築牢根基。&lt;/p&gt; 
&lt;h3&gt;2.2 智能預警系統主動防護安全&lt;/h3&gt; 
&lt;p&gt;美團智能頭盔以「傳感器 + 算法」構建主動安全防護網，將被動保護升級為智能預警。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;佩戴狀態智能監測&lt;/strong&gt;：在實際工作中，即便配備了頭盔，仍存在部分騎手有盔不戴的現象。美團智能頭盔通過三軸傳感器與紅外傳感器的聯動組合，並與騎手 App 緊密聯動，有效解決了這一難題。一旦檢測到騎手未正確佩戴頭盔，系統會及時發出提醒，確保騎手在騎行過程中時刻處於頭盔的保護之下。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自適應尾燈預警&lt;/strong&gt;：夜晚或光線較暗的環境下，騎行安全面臨更大挑戰。美團智能頭盔內置光敏傳感器，當外界光線變弱時，自感應尾燈會自動亮起，而且其較高的尾燈位置，能夠有效地引起大噸位貨車、卡車等高駕駛位司機的注意，減少因駕駛盲區而引發的事故。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;碰撞摔倒應急響應&lt;/strong&gt;：頭盔還具備碰撞摔倒檢測功能，一旦檢測到騎手摔倒，會在第一時間發出報警，並迅速聯繫騎手確認情況，為騎手的生命安全增添了一份有力的保障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.3 三重鎧甲防護電池安全&lt;/h3&gt; 
&lt;p&gt;針對智能頭盔複雜的工況，如不同地區環境溫度的差異、對各類手機充電器和充電線的適配、長期高頻次充電習慣帶來電池壽命衰減、佩戴區域敏感等考慮。頭盔設計了三重防護"鎧甲"，守護每一次騎行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;來自底層硬件的"鋼鐵守衞"&lt;/strong&gt;：智能充電芯片 24 小時監控電壓電流，電池過壓、過流和過放時快速斷電。即使芯片失效，電池自帶過充、過放、短路保護提供雙重保險，安全無死角。同時高精度電量計實時採集電池數據，精準監測電池健康狀態。針對目前市場上由於劣質或長期破損的充電線在 TYPE_C 處出現的自發熱問題，頭盔在 TYPE_C 處加入 NTC 實時溫度檢測，該處高溫時自動停止充電。避免該處發熱引起的電池安全隱患，進一步提高頭盔電池的安全保障。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;來自軟件的"溫度管家"&lt;/strong&gt;：0℃~55℃ 智能溫控，電池溫度超出範圍立刻停止充電。同時具備高溫自動緊急處理，充電時超過 75°C 語音告警。未充電時超過 75°C 自動切斷電池，進入安全模式。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;來自雲端的"大數據哨兵"&lt;/strong&gt;：實時分析頭盔上報的數據，提前預警異常。通知官方介入，防患於未然。電池安全防護的引入是智能頭盔向高可靠性、長生命週期發展的必然結果。它既是功能實現的基石，也是用戶體驗的核心要素。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//7bea5408d9da2db656fa4f3969851c56.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;穿戴體驗革命：輕量化與功能性的極致平衡&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;3.1 從頭盔到電子模組的極致結構減重技術&lt;/h3&gt; 
&lt;p&gt;對於外賣騎手而言，頭盔減重技術絕非簡單的數字遊戲，而是關乎職業體驗的關鍵革新。700g 左右的傳統頭盔如同 "鐵帽" 般壓在頭頂，每騎行一小時就可能累積近半公斤的垂直壓力，導致頸椎勞損與疲勞感加劇。美團智能頭盔通過「材料基因 + 工藝重構 + 系統集成」的三重減重革命，將整機重量降至 550g，在摩托車頭盔國標框架內實現「安全不減重」的技術突破。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;吸塑工藝 - 給頭盔外殼"削骨減肥"&lt;/strong&gt;：摩托車頭盔設計的困難點在於，頭盔保護頭部的要求和輕量化之間的矛盾，行業上一般使用注塑的方式生產頭盔外殼，常用的工程塑料成本低，但密度較高，輕量化空間有限。而且因注塑工藝的侷限性，外殼無法設計的很薄，否則將無法生產。K3SX1 智能頭盔採用吸塑一體成型工藝替代傳統注塑方案，吸塑工藝可以將頭盔外殼設計的很薄，配合高強度 PC 材料，頭盔外殼厚度可減薄一半，大幅度減輕重量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;雙密度材料 - 給防護層"精準減脂"&lt;/strong&gt;：吸塑一體成型工藝解決外殼重量的問題，但為了通過穿刺測試，緩衝層的密度還是比較大，導致緩衝層重量過重。雙密度減重技術通過精確控制材料密度分佈（頭盔對安全要求高的部分使用高密度緩衝材料，頭盔主體部分使用低密度緩衝材料），在保證外殼抗衝擊、穿刺強度符合 GB 811-2022 摩托車乘員頭盔國家標準的前提下，實現結構輕量化。經實測，相較於前代產品，頭盔盔體重量減輕 85g，降幅達 25%。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;配件系統 - 從鏡片到織帶的"全身協同瘦身"&lt;/strong&gt;：鏡片、織帶等配件通過高強度複合材料應用與薄壁化設計，在滿足抗穿透性與佩戴安全性的基礎上，進一步降低產品整體重量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c2edb6d8b96f33e8e1d09a85dd6afa3e.png" alt="雙密度盔體：頭盔測試區部分使用高密度緩衝材料（灰色），頭盔主體部分使用底密度緩衝材料（黃色）" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;電子模組 - 模塊化集成的"系統級輕量革命"&lt;/strong&gt;：電子系統，採用模塊化設計方案，分為主控模組、喇叭模組、按鍵模組和麥克紅外模組。採用一拖三的方式，都和主控模組用線連接，沒有對接端子，可以實現防水和減重。模組採用薄壁輕量化設計，在保證模型性能不受影響的前提下，有效降低了模組的重量。主控模組集成尾燈設計，相比單獨的尾燈，減少了尾燈配件，大幅降低重量。麥克紅外模組，採用灌膠密封的工藝，相比常規 AB 殼方案，減少了後殼、密封圈、螺絲、線束密封等配件，有效降低了組裝複雜性和重量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過盔體、鏡片、織帶、電子模組等多重的減重措施，最終實現整機重量僅 550g，成為當前符合摩托車頭盔國標認證的智能頭盔中最輕量級產品。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a14c1d21837b140f455e181aae203417.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.2 多孔道通風結構設計與安全強化&lt;/h3&gt; 
&lt;p&gt;對騎手而言，頭盔通風技術是對抗酷暑的關鍵剛需。傳統頭盔在高溫下如蒸籠，易致頭部悶熱、注意力分散，甚至引發安全隱患。為解決傳統頭盔通風不足問題，K3SX1 在原有 4 個通風孔基礎上，新增 16 個導流式通風孔，構建 20 孔三維貫通通風系統。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多孔道通風結構設計&lt;/strong&gt;：在頭盔行業裏，一般只有自行車頭盔頂部有開孔，且因自行車頭盔標準無穿刺測試要求，開孔設計挑戰較低；而摩托車頭盔出於安全考量，頂部通常不設置開孔，即便少數產品開孔，也多見於注塑外殼的頭盔，吸塑一體成形的摩托車頭盔開孔案例極少。這一設計面臨着國標穿刺測試（要求頭盔抵禦 3kg 鋼錐從 1m 高度自由落體的衝擊）的嚴峻挑戰。研發團隊通過有限元分析（FEA）技術和實際實驗，對不同孔徑、緩衝層密度方案進行驗證，最終確定採用雙密度方案與局部 PC 片加強設計，在保證通風效率提升的同時，確保穿刺測試通過率達 100%，實現通風性能與安全標準的完美平衡。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//09159c0e5e4fef53b56f425763da3bc5.png" alt="雙密度方案與局部加強設計" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;空氣動力學優化與熱濕交換效率提升&lt;/strong&gt;：基於 CFD（計算流體動力學）仿真技術，K3SX1 的通風系統採用前側進氣口導流設計與後側負壓抽氣結構，360°全方面散熱，騎行風感更加強勁。搭配疏水速幹三明治網布內襯，加速導濕排汗，顯著改善騎手長時間作業的熱舒適性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ab6491389696f42319264e9beaf29e89.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.3 硬件極致設計引領續航三倍飛躍&lt;/h3&gt; 
&lt;p&gt;傳統智能頭盔續航體驗較差，騎手基本一天就需要充電一次，嚴重影響騎手的工作效率和使用體驗。為瞭解決頭盔續航時間短這個痛點，通過分析問題的根本原因，發現主控系統+藍牙系統+通信模組的多系統工作模式，以及音頻功放器件是功耗的主要消耗點。K3SX1 從這兩個點進行重構和變革，大幅降低產品的能耗，提升產品的續航能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;複雜多系統到單中國"芯"的改革&lt;/strong&gt;：多系統的複雜硬件架構，硬件複雜度和功耗都居高不下，全新的硬件設計採用全自主知識產權的國產高性能藍牙芯片，芯片採用 32 位雙核 DSP 架構，系統時鐘最高達 160MHz，具備更廣泛的匹配兼容性與更智能的內置算法等特點。通過優化主芯片電源管理單元、採用先進製程工藝等創新，實現主芯片在高性能運行的同時將功耗控制在較低水平。芯片的靜態功耗低於 100uA，工作功耗僅有 mA 級別。單芯片系統也大幅減少了外設器件，同時大幅降低整體功耗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;音頻功放的換代升級&lt;/strong&gt;：音頻功放是頭盔的使用場景中使用頻次最高的器件，傳統的 AB 類音頻功放，工作效率低。K3SX1 把音頻功放從 AB 類升級為 D 類，工作效率由 50% 提升至 90%，大幅延長電池續航時間。在電池容量減少 40%（從 2000mAh 降至 1200mAh）的情況下，續航時間從 12 小時提升至 36 小時，達到行業領先水平，徹底消除騎手對電量不足的擔憂，讓其更專注於騎行工作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.4 六層堆疊助力出色音頻&lt;/h3&gt; 
&lt;p&gt;在智能頭盔行業，主流方案多依賴高性能算法芯片實現降風噪，雖有效但成本較高；部分產品嚐試採用泡棉降噪，卻因泡棉面積小導致過濾效果有限，且吸水後性能易失效。K3SX1 通過六層堆疊設計，突破傳統方案侷限，實現 50km/h 騎行速度下的清晰語音通話。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;下沉式拾音區域設計&lt;/strong&gt;：拾音區域低於頭盔前沿，可以減弱風對拾音面的衝擊，使氣流繞過拾音區域，減少湍流噪聲。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高強度柵格化外殼&lt;/strong&gt;：鏤空柵格設計確保充足拾音面積，避免聲學遮擋，高強度外殼可以物理防護內部的防風綿，防止損壞。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大面積鍍疏水膜防風綿&lt;/strong&gt;：高密度大面積海綿結構，能夠對騎行中產生的風噪進行均勻過濾與消解。防風泡綿採用整體真空鍍疏水塗層的工藝，不僅能夠做到不沾水、不吸水、不存水，有效防止雨水、汗水等對麥克風的侵蝕，還能在全生命週期內保持穩定的物理防風降噪性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;防水透聲膜&lt;/strong&gt;：既能阻擋水、灰塵等雜質進入，又能保證聲波高效穿透，平衡防護性與拾音靈敏度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2mm 深 36°密閉式拾音通道&lt;/strong&gt;：通過 36°傾斜角收聲孔設計，使得拾音通道的深度只有 2mm，可以有效減小聲波傳導損耗，確保拾音清晰。拾音孔與 PCBA 通過膠水密封粘接，杜絕漏音與二次迴音，保證語音信號純淨度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高性能音頻處理芯片&lt;/strong&gt;：主芯片其內置的音頻編解碼模塊性能卓越，降噪算法更加智能，24bit DAC 的 SNR 高達 104dB，換算後噪聲基底僅為 4.5μV。芯片可對智能頭盔接收和播放的音頻信號進行高保真處理，確保騎手通話時，無論在嘈雜的城市街道，還是高速騎行的呼嘯風聲中，芯片也能通過智能音頻算法有效過濾背景噪音，突出人聲。保證騎手聲音清晰、不失真，為騎手提供優質的溝通體驗。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;K3SX1 通過 "硬件結構創新 + 芯片算法賦能 + 模塊化工程思維"，多層結構與高性能芯片的協同設計，在強風環境降噪與成本控制間取得平衡，為智能頭盔從 "功能型" 向 "普及型" 跨越提供了關鍵技術支撐。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6105dcd962c0165c4fa1afa81a28f8c4.png" alt="36°傾斜角收聲孔+柵格化外殼設計+高密度海綿物理降噪方案" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.5 極端環境適應&lt;/h3&gt; 
&lt;p&gt;在智能頭盔領域，多數產品的防水標準僅設定在 IPX4 或 IPX5 等級，這意味着它們僅能抵禦少量濺水或短時淋雨，一旦遭遇暴雨、強風裹挾雨水等極端天氣，設備內部電子元件極易因進水短路而損壞。而美團智能頭盔打破常規，以 IPX6 級防水性能脫穎而出。這一等級要求設備能承受強水流從任意方向持續噴射 15 分鐘而不受損，相當於在每小時 150 毫米降水量的特大暴雨中電子模組不進水無損壞。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在設計上精益求精，提高防護級別&lt;/strong&gt;：各個模塊按照 IPX7 的要求進行設計，主控模組採用硅膠密封圈疊加設計，配合對外連接線束點膠密封，TypeC 接口 IPX7 硅膠密封，按鍵位置大面積雙面膠密封防水等方案，形成無縫防水屏障，確保各種苛刻的使用環境模組不進水。音頻模塊、麥克風等核心部件均配備防水透氣膜，既能隔絕液態水侵入，又能平衡內部氣壓，防止因溫差產生水霧凝結。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在生產上嚴格要求，全檢出貨&lt;/strong&gt;：模組全部通過氣密檢測設備進行檢測，執行的測試標準是 IPX7，進行嚴格管控全檢測試出貨，確保每一個智能頭盔模組都具有卓越的防水性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;正是這些精密的設計與嚴苛的出廠測試，這種 "設計 + 生產" 雙維度防水方案，讓騎手在暴雨傾盆的街道、狂風呼嘯的騎行途中，都能放心使用美團智能頭盔，無需擔憂雨水侵襲影響設備功能，真正實現風雨無阻地安全配送，為城市配送的高效運轉築牢可靠防線。&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;配送效率重構：人機協同的智能操作升級&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;對騎手而言，配送效率直接關乎收入水平。美團智能頭盔在提升配送效率方面，展現出了強大的功能。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;一體化耳機設計&lt;/strong&gt;：其一體化頭盔耳機設計，極為便捷，拿起頭盔自動開機，自動連接藍牙，騎手戴上頭盔後，無需再額外佩戴耳機。並且，通過先進的降噪算法，即使在高達 50km/h 的騎行速度下，也能確保語音通話清晰流暢，讓騎手與顧客、商家之間的溝通毫無障礙。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;實體按鍵一鍵接單&lt;/strong&gt;：頭盔上精心配備的大號實體按鍵，操作簡便，騎手能夠快速一鍵接單、確認到店、到客，以及接打電話。即便是在寒冷的冬天，騎手戴着手套也能輕鬆操作，無需拿出手機點擊屏幕，大大節省了操作時間，提高了配送效率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大模型助手主動提率&lt;/strong&gt;：此外，頭盔所搭載的連接騎手 App 的大模型語音助手，更是騎手的得力助手。它不僅能在工作上為騎手提供路線規劃、訂單信息查詢等幫助，還能在騎手感到疲憊或壓力大時，給予情感上的支持與鼓勵，讓騎手在忙碌的工作中感受到溫暖與關懷，以更飽滿的精神狀態投入到配送工作中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;產業賦能實踐：傳統製造的智能化躍遷&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;5.1 傳統頭盔廠的技術短板&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;音頻性能測試的困境&lt;/strong&gt;：智能頭盔需要支持高質量的語音交互，因此必須進行精確的音頻曲線測試（如頻響、失真等）。傳統頭盔廠通常缺乏專業的聲學實驗室和測試設備，導致產品在音質方面表現不佳，騎手感覺聲音刺耳，有雜音等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;硬件生產測試系統的缺失&lt;/strong&gt;：智能頭盔涉及藍牙模塊、傳感器、電池管理等複雜電子組件，需要專業的上位機測試系統來驗證其穩定性。傳統廠商往往依賴人工檢測，效率低且難以覆蓋所有故障模式。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自動化程度低&lt;/strong&gt;：智能頭盔有很高的防水和性能要求，但傳統頭盔廠通常缺乏自動化設備，基本依賴手工操作造成組裝速度慢，工藝不穩定，不同班次的產品性能差異較大。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;生產監控系統的缺失&lt;/strong&gt;：智能頭盔有許多電子器件，需要監控性能指標和追溯歷史測試結果，但傳統盔廠缺乏相應的系統監控，無法做到實時數據監控和歷史追溯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5.2 美團頭盔產線的智能升級&lt;/h3&gt; 
&lt;h4&gt;5.2.1 六大核心工藝，打造極致可靠的頭盔&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能自動功能測試&lt;/strong&gt;：智能系統檢測按鍵、藍牙、傳感器等功能，不良品自動剔除，努力確保 100% 達標。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高精度自動點膠&lt;/strong&gt;：精準控制膠量與路徑，提高密封性，徹底解決傳統手工點膠的溢膠、漏膠問題。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;無人化鎖螺釘&lt;/strong&gt;：機器人精準緊固螺絲，扭矩實時監控，螺絲零鬆動、零滑牙。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;氣密性測試&lt;/strong&gt;：5 秒快速篩查，微漏無所遁形，防水性能行業領先。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;音頻調校+音頻參數測試&lt;/strong&gt;：智能聲學實驗室模擬真實場景，優化麥克風降噪算法，產線 100% 進行喇叭和麥克頻響、失真、R&amp;amp;B、平衡度等參數測試，確保通話質量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;加速老化試驗體系&lt;/strong&gt;：85℃/85%RH 雙 85 測試，高強度溫濕度循環+跌落測試+穿刺測試，保證頭盔的壽命和安全性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//28544b39db414b0b088fa18094b0f28e.png" alt="六大核心工藝，打造極致可靠的頭盔" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4&gt;5.2.2 數字化轉型：老產線的華麗轉身&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;數據驅動決策&lt;/strong&gt;：MES 系統實時監控生產參數，問題提前預警，問題追溯源頭。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;柔性生產&lt;/strong&gt;：同一產線可快速切換不同型號，換型時間縮短 50%。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;人機協同&lt;/strong&gt;：工人從重複勞動解放，專注工藝優化與技術創新。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;市場與行業影響：用數據樹立價值新標杆&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;K3SX1 產品從騎手到業務逐步得到認可，佩戴舒適度、藍牙語音體驗和性價比等方面產品力顯著提升，滿意度從 3.2 提升至 4.2（5 分制），語音功能使用率從加盟 54% 提升至加盟 87%、眾包 98%。&lt;/p&gt; 
&lt;p&gt;因為智能頭盔功能實用性決策購買的騎手較多（79%），朋友推薦成為第二高的騎手瞭解智能頭盔的渠道（最新佔比提升至 22%）。該產品的成功推出，不僅為外賣騎手提供了更優質的防護裝備解決方案，更推動行業從單純的功能競爭轉向用戶體驗與成本效益並重的新階段，為智能頭盔產品的發展樹立了新的技術與價值標杆。&lt;/p&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;未來技術前瞻：硬件升級與智能夥伴的革新&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美團智能頭盔，通過多年的經驗積累和技術迭代，新一代 K3SX1 智能頭盔頭盔通過多方面技術改進實現有效減重，兼顧安全、舒適性與性能提升。隨着美團智能頭盔的 NPS 和滿意度屢創新高，取得了歷代智能頭盔最佳表現。&lt;/p&gt; 
&lt;p&gt;在未來，美團智能頭盔搭載的大模型語音助手，將進化為騎手的 "全場景認知夥伴"。它不僅能精準處理 "規劃路線"、" 播報訂單"等基礎指令，更能通過深度學習騎手的配送習慣與行為模式，實現主動式智能輔助 ------ 比如在暴雨天氣自動播報實時路況並推薦防滑路線，檢測到騎手連續配送超 3 小時後主動推送附近休息站信息，甚至能根據商家出餐速度預判延誤風險，提前建議騎手調整接單節奏。&lt;/p&gt; 
&lt;p&gt;在複雜場景中，語音助手可通過多輪對話理解騎手需求，例如當騎手説"找最近的修車站"，系統會同步考慮距離、口碑及維修時長，生成帶語音導航的優選方案；遇到顧客改地址等突發情況，還能自動生成標準化溝通話術並同步更新配送系統。更值得期待的是，其情感交互能力將實現"溫度服務"------ 在騎手遭遇差評時推送心理疏導語音，節日時送上定製化問候，甚至能根據騎手的方言習慣調整播報語氣，讓科技真正成為有"人情味"的工作夥伴，徹底重構即時配送行業的人機協作範式。&lt;/p&gt; 
&lt;p&gt;未來的美團智能頭盔，硬件上還會搭載更加強大的傳感器，幫助騎手解決更加複雜的問題。並逐步推廣到全國每一個騎手，讓他們都能體驗到科技帶來的價值和快樂，為騎手帶來更安全、高效、舒適的工作體驗，不斷引領智能頭盔行業邁向新的高度。&lt;/p&gt; 
&lt;p&gt;| 關注「美團技術團隊」微信公眾號，在公眾號菜單欄對話框回覆【2024 年貨】、【2023 年貨】、【2022 年貨】、【2021 年貨】、【2020 年貨】、【2019 年貨】、【2018 年貨】、【2017 年貨】等關鍵詞，可查看美團技術團隊歷年技術文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9b6ae5ef223651e842d935a4a4533aa3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美團技術團隊出品，著作權歸屬美團。歡迎出於分享和交流等非商業目的轉載或使用本文內容，敬請註明"內容轉載自美團技術團隊"。本文未經許可，不得進行商業性轉載或者使用。任何商用行為，請發送郵件至 &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank"&gt;tech@meituan.com&lt;/a&gt; 申請授權。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/meituantech/blog/18688335</link>
      <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/18688335</guid>
      <pubDate>Tue, 19 Aug 2025 02:53:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>字節跳動即將發佈開源模型 SeedOss-36B</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;根據 Hugging Face Transformers 庫的信息，字節跳動即將發佈一款名為 SeedOss-36B 的 360 億參數稠密開源模型。&lt;/p&gt; 
&lt;p&gt;相關信息來源於 Hugging Face Transformers 開源倉庫中的一個 Pull Request。該 Pull Request 由 GitHub 用戶「Fazziekey」提交，標題為「Addiing ByteDance Seed Seed-Oss」，旨在為即將推出的 Seed Oss 模型添加代碼支持。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1304" src="https://static.oschina.net/uploads/space/2025/0820/105108_ez5K_2720166.png" width="1790" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="739" src="https://static.oschina.net/uploads/space/2025/0820/104957_sQ2l_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/105135_a86e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/huggingface/transformers/pull/40272&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;從目前披露的信息來看，SeedOss-36B 很可能是一個 360 億參數的稠密模型，而非 MoE（Mixture-of-Experts）架構。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367325</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367325</guid>
      <pubDate>Tue, 19 Aug 2025 02:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek V3.1-Base 開源發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 最新開源模型 V3.1-Base 已上架 HuggingFace，相關信息如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型參數為 685B&lt;/li&gt; 
 &lt;li&gt;基座模型（Base），用於微調和二次開發&lt;/li&gt; 
 &lt;li&gt;基於 DeepSeek V3 架構，包含自定義代碼實現&lt;/li&gt; 
 &lt;li&gt;混合精度設計，支持 BF16、FP8（E4M3）、FP32 張量類型&lt;/li&gt; 
 &lt;li&gt;支持 FP8 量化，提升推理效率&lt;/li&gt; 
 &lt;li&gt;採用 Safetensors 安全張量格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1240" src="https://static.oschina.net/uploads/space/2025/0820/104516_2Mto_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104605_duz9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104713_pqfx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3.1-Base" target="_blank"&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Base&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367323</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367323</guid>
      <pubDate>Tue, 19 Aug 2025 02:47:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>再獲國際權威機構認可｜綠盟抗 D 解決方案斬獲業界首個 Frost &amp; Sullivan 競爭戰略領導獎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;近日，綠盟科技憑藉在抗 DDoS 領域的深厚積累與全球戰略佈局，一舉斬獲國際權威機構 Frost &amp;amp; Sullivan 頒發的 2025 年度競爭戰略領導獎（2025 Competitive Strategy Leader）。這一重磅獎項不僅彰顯了權威機構的高度認可，同時也標誌着綠盟抗 D 解決方案正在持續向全球安全行業展現強勁的技術創新力與市場領導力。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 1.jpg" height="400" src="https://oscimg.oschina.net/oscnet//68c662dce7d7be9538563f3bd0e5ae88.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 2.jpg" height="785" src="https://oscimg.oschina.net/oscnet//c77b2f3fbb86054cf4ed258924ce184a.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;Frost &amp;amp; Sullivan 分析師 Iqra Azam 表示：「在全球市場，綠盟抗 D 以智能、敏捷、以客戶為核心的解決方案脫穎而出。面對愈發複雜的大規模 DDoS 威脅，綠盟科技以創新驅動戰略，已經成為國際市場中不可忽視的競爭力量。更重要的是憑藉抗 D 設備+平台的智能增值運營方案，不僅為客戶帶來了實打實的價值轉化，更幫助企業釋放了新的商業增長潛能。」&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;從國際競爭力的視角來看，綠盟抗 D 解決方案近年來在亞太、拉美等重點新興市場持續深耕，成功服務於多個國家級運營商、金融機構及關鍵基礎設施客戶，其中最受海外客戶關注的正是三位一體抗 D 增值運營解決方案：&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;方案組件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;綠盟抗拒絕服務攻擊系統-ADS&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;ADS 融合了機器學習建模、交互式動態防護算法、行為模式分析以及動態指紋識別等先進技術，提供高效的多層（L3-L7）DDoS 攻擊流量清洗能力，在高效阻斷各類 DDoS 惡意報文的同時快速放行合法業務流量，同時支持基於業務特點進行策略隔離，讓防護更加靈活化。ADS 防護流程全程透明可視，統計展示各防護策略結果，並支持在線抓包和在線查看報文關鍵特性，幫助用戶快速分析攻擊細節與業務特徵，真正實現可視、可控、可驗證的主動防護體驗。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;綠盟網絡流量分析系-NTA&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;NTA 專注於流量異常監測及 DDoS 攻擊快速告警，提供基於 FLOW（深度流檢測）或者基於 DPI（深度包檢測）雙模監測模型，可靈活適配不同規模網絡、不同流量及重點業務精細化分析等不同業務場景。藉助基於機器學習建模的動態流量基線能力，NTA 可自動生成告警閾值，有效降低漏報與誤報，減輕運維負擔。設備搭配雲端實時檢測規則，能快速識別新興威脅，顯著提升防護響應效率。此外 NTA 支持聯動綠盟威脅情報，實時識別礦機、礦池、殭屍網絡等威脅信息，可通過 flowspec 實現精細化阻斷。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;綠盟流量清洗業務運營系統-ADBOS&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;致力於為運營商、金融、跨國企業及網絡服務提供商賦能基於抗 D 雲清洗、流量分析、MSS 等雲上安全服務，助力客戶構建多層次的運營體系。平台支持跨地域、跨廠商的態勢可視化與策略管理，助力用戶實現抗 D 資源的統一調度與高效運維。平台搭載抗 D 專家策略庫和自適應策略調整模塊，配合探針的自學習建模、基於劇本編排的自動化處置，讓用戶體驗一站式運營管理和全託管式運維，輕鬆降低運營複雜度的同時還能提供增值運營的快速變現。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 3.jpg" height="210" src="https://oscimg.oschina.net/oscnet//e1def71af4771d74670ec4ab7e2ce7f8.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;三位一體的抗 D 增值運營解決方案，依託 ADBOS 平台接入 ADS/NTA，構建高性能、可擴展的抗 D 清洗與檢測資源池，並通過分權分域的集中管理，實現跨地域、跨廠商設備的統一資源調度與數據融合，做到最大化設備利用率與投資回報率。平台集成客戶管理、售賣規格、費用套餐等一站式增值運營功能幫助用戶輕鬆上線增值抗 D 服務，實現從防護能力到商業變現的無縫銜接。在服務體驗方面，平台提供包括自助門戶與移動端 APP 在內的多種自助服務方式，讓最終用戶可以隨時隨地掌握業務狀態、靈活配置防護策略，並生成自定義、多維度的業務與防護報表，全面提升操作便捷性與服務可視化，顯著增強用戶粘性與滿意度。該方案形成了從精準流量檢測，智能資源調度，高效 DDoS 清洗形成完整業務閉環，全面滿足服務提供商對精細化運營和差異化服務的核心訴求。結合 MSS 可管理安全服務訂閲，客戶可一站式享受從攻擊監控、快速響應、威脅分析、事件處置到全流程報告的無感知式託管防護，真正實現高效、省心的智能化運營。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;未來，綠盟抗 D 產品將持續突破技術邊界，迭代產品能力和服務質量，打造更具前瞻性、智能化的防護體系，持續為全球客戶提供強有力的抗 D 支撐，護航關鍵業務穩健前行。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367321</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367321</guid>
      <pubDate>Tue, 19 Aug 2025 02:39:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>小米集團基於 Apache Doris + Apache Paimon 實現 6 倍性能飛躍</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;企業在數據驅動的道路上，始終面臨一對核心矛盾：既需要低成本、可擴展的存儲方案來承載海量結構化、半結構化乃至非結構化數據（這正是數據湖的強項），又渴望實時、低延遲的分析能力來支撐業務決策（這是分析型數據庫的核心優勢）。&lt;/p&gt; 
&lt;p&gt;然而現實是，單獨的解決方案往往難以兩全：以 Apache Paimon 為代表的數據湖技術，雖憑藉開放格式、彈性擴展和低成本存儲成為企業數據中台的基石，但在低延遲響應上存在天然短板；而以 Apache Doris 為代表的分析型數據庫，雖能提供高效的查詢性能，卻缺乏數據湖的存儲靈活性與開放性。&lt;/p&gt; 
&lt;p&gt;本文的核心觀點是："架起數據庫與數據湖的橋樑" 並非趨勢，而是破局的關鍵。小米通過將 Apache Doris（數據庫）與 Apache Paimon（數據湖）深度融合，不僅解決了數據湖分析的性能瓶頸，更實現了 "1+1&amp;gt;2" 的協同效應。&lt;/p&gt; 
&lt;h2&gt;數據庫與數據湖的互補之力&lt;/h2&gt; 
&lt;p&gt;"橋接數據庫與數據湖"的核心價值，在於構建"&lt;strong&gt;存儲靈活、計算高效、格式協同&lt;/strong&gt; "的一體化架構------不僅是存儲與計算能力的分工互補，更包含&lt;strong&gt;數據格式層面的深度協同&lt;/strong&gt;，讓兩者的技術特性形成疊加效應。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 數據湖倉的分工定位&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;從基礎能力來看，兩者的分工已形成天然互補：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Apache Paimon 作為數據湖，核心優勢體現在存儲層：其開放格式（兼容 Spark、Flink、Trino 等多引擎）、基於對象存儲（S3、HDFS）的 PB 級彈性擴展能力，以及對事務、Schema 演進的原生支持，使其成為海量異構數據的"統一存儲基座"，兼顧低成本與兼容性。&lt;/li&gt; 
 &lt;li&gt;Apache Doris 作為分析型數據庫，核心優勢體現在計算層：分佈式並行引擎、向量化執行框架、以及針對複雜聚合場景的算子優化，使其能提供毫秒至秒級的低延遲查詢響應，成為數據價值挖掘的"高效計算引擎"。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;2. 數據格式的特性互補&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;更深層的協同點，在於數據格式的特性互補：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;數據湖格式（如 Paimon）為適配多引擎讀寫與大規模存儲場景，在設計上以通用性為優先，雖能滿足跨引擎兼容需求，但在高頻查詢、複雜計算場景下，其通用格式的解析效率、IO 開銷難以進一步優化；&lt;/li&gt; 
 &lt;li&gt;而數據庫（如 Doris）則擁有專為查詢性能設計的 &lt;strong&gt;高效內部存儲格式&lt;/strong&gt;------例如基於列存的分層存儲結構、自適應編碼壓縮算法（如字典編碼、RLE 壓縮）、原生索引（如前綴索引、 bloom filter）等，這些格式通過深度耦合計算引擎的執行邏輯，可最大限度減少數據掃描量與 IO 消耗，實現亞秒級查詢響應。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;3. 橋接架構的雙向賦能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;橋接架構下，數據湖倉可實現&lt;strong&gt;雙向賦能&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;海量冷數據、全量歷史數據以 Paimon 格式存儲於數據湖，保持低成本與多引擎兼容性；&lt;/li&gt; 
 &lt;li&gt;高頻訪問的熱數據、需複雜聚合的核心指標，則通過 Doris 的物化視圖、本地緩存等機制，轉換為 Doris 高效內部格式存儲，藉助其原生存儲與計算的協同優化，實現極致查詢性能。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;這種模式既避免了單一數據湖格式在查詢性能上的瓶頸，又解決了單一數據庫格式在存儲成本與擴展性上的侷限。唯有通過"橋接"，才能讓數據湖的通用存儲優勢與數據庫的高效格式特性形成合力，實現"存儲成本可控、查詢性能最優"的理想狀態。&lt;/p&gt; 
&lt;h2&gt;Apache Doris &amp;amp; Paimon 在小米的實踐與挑戰&lt;/h2&gt; 
&lt;p&gt;Apache Paimon 是一款優秀的開放數據湖格式，其流批一體的設計很好的滿足了湖上數據的實時處理需求。&lt;/p&gt; 
&lt;p&gt;Doris 在 2.1 版本開始支持 Paimon Catalog，可以直接訪問 Paimon 數據並加速 Paimon 數據分析。在 Paimon TPC-DS 1TB 測試集上，Doris 的總體查詢性能是 Trino 的 5 倍。&lt;/p&gt; 
&lt;p&gt;從 2.1 版本到 3.0、3.1 版本，Doris 在持續針對 Paimon 格式進行功能更新和性能增強，包括但不限於以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;通過元信息對 Paimon 數據進行分區、分桶裁剪和謂詞下推，優化查詢效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Deletion Vector 讀取，利用向量化 C++ 引擎加速 Paimon 更新數據的讀取。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 數據的本地文件緩存，充分利用本地高速磁盤提升熱點數據的查詢效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 時間旅行、增量數據讀取、Branch/Tag 數據讀取，方便用戶進行 Paimon 數據的多版本管理。&lt;/li&gt; 
 &lt;li&gt;支持基於 Paimon 的物化視圖，包括分區級別的增量物化視圖構建，以及本文後續將要介紹的基於快照級別的增量構建，同時支持強一致的物化視圖透明改寫能力，將湖和倉的能力深度結合。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Rest Catalog（DLF），方便雲上用戶接入 Paimon 生態，實現統一元數據管理。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在本文中，我們將重點介紹小米如何基於 Doris + Paimon 構建統一湖倉平台，以及在項目開發過程中的功能貢獻和優化思路。&lt;/p&gt; 
&lt;h2&gt;01 化繁為簡：基於 Doris + Paimon 的統一湖倉平台建設&lt;/h2&gt; 
&lt;p&gt;作為一家業務覆蓋汽車、IoT、手機、互聯網服務等多個領域的大型企業，小米集團對 OLAP 系統和湖倉平台提出瞭如下關鍵需求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多維度分析&lt;/strong&gt;：支持高併發、低延遲的多維聚合分析（如用戶行為、設備狀態、運營監控等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多源接入&lt;/strong&gt;：需要打通 Flink、Spark、Flink CDC 等流批框架的輸入，覆蓋離線、實時全鏈路數據處理場景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;統一數據訪問&lt;/strong&gt;：支持跨引擎、多格式的數據消費需求（如 Doris、Paimon、Iceberg 等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;降低平台複雜度&lt;/strong&gt;：減少技術棧分裂，統一數據建模與管控，提升數據平台運維效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;當前架構的挑戰與瓶頸&lt;/h3&gt; 
&lt;p&gt;儘管已有較成熟的數據平台體系，但小米的 OLAP 湖倉架構長期存在如下"繁雜、割裂"的結構問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;存儲多源異構，數據重複堆疊&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;為滿足不同業務對數據的不同時效性需求，需要按照分鐘、小時、天級別的時效性要求，將數據存儲在不同的數據系統中（Iceberg、Paimon、Druid、Doris），導致數據冗餘、不一致等問題&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;湖倉割裂，缺乏統一接口&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需要同時使用不同的引擎進行數據查詢，（如 Presto、Druid、Doris、Spark 等）。各系統有獨立的數據建模、運維和權限控制邏輯，平台治理成本高，入口不統一，使用方式不統一。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//54a06d5419f01bd3f147603a3e36c475.png" alt="化繁為簡：基於 Doris + Paimon 的統一湖倉平台建設.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這些問題不僅增加了平台負擔，也制約了 OLAP 架構在大規模實時應用場景下的穩定性和擴展性。&lt;/p&gt; 
&lt;h3&gt;統一引擎 + 統一存儲&lt;/h3&gt; 
&lt;p&gt;為應對上述挑戰，小米構建了基於 &lt;strong&gt;Apache Doris + Apache Paimon&lt;/strong&gt; 的統一湖倉一體化架構，作為未來 OLAP 平台的核心形態。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;統一計算引擎：Apache Doris + Spark&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;採用 Doris + Spark 的計算引擎組合。Doris 負責實時數據和交互式數據分析，以及高併發查詢場景。Spark 負責離線批處理場景。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;統一數據湖存儲：Apache Paimon&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;以 Apache Paimon 作為統一數據存儲格式。Paimon 的設計非常適合流、批數據一體化存儲。實現批流一體、湖倉一體的數據管理。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4523b53882f118d0fe114ba1b214b893.png" alt="統一引擎 + 統一存儲.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過這一架構轉型，極大地簡化了系統架構：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算引擎：Presto、Druid、Doris、Spark -&amp;gt; Doris、Spark&lt;/li&gt; 
 &lt;li&gt;存儲格式：Iceberg、Paimon、Doris、Druid -&amp;gt; Doris、Paimon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02 深度融合：基於 Doris + Paimon 查詢加速實踐&lt;/h2&gt; 
&lt;p&gt;小米在引入 Apache Paimon 構建湖倉平台後，雖解決了海量數據的存儲問題，卻在實際業務中遭遇了三大關鍵瓶頸，直接影響了數據價值的釋放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聚合性能不足&lt;/strong&gt;：Doris 在讀取 Paimon 的 Merge-on-Read 表時，受限於 Paimon SDK（Java）單線程處理多文件的排序與合併，在高併發場景下完全無法滿足業務對 "秒級響應" 的需求。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;物化視圖更新代價高昂&lt;/strong&gt;：分區級增量更新機制粒度在某些場景下可以滿足用戶的增量更新需求。但對於非分區表，或者單分區數據量較大的表，依然有較高的更新成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HDFS 讀取延遲不穩定&lt;/strong&gt;：HDFS 多副本讀取時，默認 60 秒的超時閾值和網絡抖動，導致查詢延遲波動極大，業務方難以依賴數據結果快速做出決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些問題並非單純的技術瑕疵 ------ 它們直接拖慢了業務決策速度，同時因資源浪費和低效運行增加了企業成本。&lt;/p&gt; 
&lt;p&gt;針對上述瓶頸，小米通過深度整合 Apache Doris 與 Apache Paimon 的特性，打造了&lt;strong&gt;三大 "橋接" 方案&lt;/strong&gt;，實現了從 "問題" 到 "解決方案" 的精準突破。&lt;/p&gt; 
&lt;h3&gt;方案一：用 Doris 計算引擎加速 Paimon 聚合能力&lt;/h3&gt; 
&lt;p&gt;Doris 本身擁有強大的數據聚合計算能力，同時支持 Aggregate Key 聚合表模型，該模型在應用場景上和 Paimon 聚合表非常類似，因此可以作為 Paimon 聚合表很好的補充。&lt;/p&gt; 
&lt;p&gt;針對原先 Doris 讀取 Paimon 聚合表性能不足的問題，小米採用了將文件合併與排序邏輯 "上移" 至 Doris 的查詢引擎的方案，利用 Doris 的分佈式並行計算與向量化執行能力，替代 Paimon SDK 的單線程處理模式。具體而言：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;放棄 JNI 調用 Paimon Java SDK 的方式，改用 Doris 原生 Parquet Reader 直接讀取 Paimon 數據文件；&lt;/li&gt; 
 &lt;li&gt;藉助 Doris 的 Hash 算子實現分佈式聚合（無需排序步驟），充分發揮 C++ 引擎的性能優勢。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2e1dbabcb52805e9fb9c1bbdabf4dcec.png" alt="方案一：用 Doris 計算引擎加速 Paimon 聚合能力.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;經過此方案改造，聚合表的查詢時長&lt;strong&gt;從 40 秒縮短至 8 秒，性能提升近 5 倍。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案二：快照級增量物化視圖實現高效更新&lt;/h3&gt; 
&lt;p&gt;Doris 支持 Paimon、Iceberg 等數據湖表格式的異步物化視圖構建，並且支持分區級別的增量物化視圖刷新與查詢透明改寫。物化視圖作為數據庫與數據湖的直接橋樑，對查詢加速起到了至關重要的作用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//46574d04066c2797c966cd797925a8f0.png" alt="方案二：快照級增量物化視圖實現高效更新.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了進一步提高物化視圖的時效性，並降低物化視圖的更新開銷。小米進一步研發了基於快照級別的物化視圖增量刷新能力，並且貢獻到了 Apache Doris 社區。&lt;/p&gt; 
&lt;p&gt;首先，小米開發了 Paimon 表的快照級別的增量讀取能力，如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;SELECT * FROM paimon_table@incr('startSnapshotId'='0', 'endSnapshotId'='5')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該功能可以僅讀取指定 snapshot 區間的增量數據。&lt;/p&gt; 
&lt;p&gt;基於該功能，小米進一步開發了基於快照級別的增量物化視圖功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;在 Paimon 中創建一張聚合表&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;CREATE TABLE paimon_aggregate_table (
  dt bigint,
  k1 bigint
  k2 string,
  v1 int,
  v2 double
)
USING paimon
PARTITIONED BY (dt)
TBLPROPERTIES (
  'bucket' = '2',
  'bucket-key' = 'k1,k2',
  'fields.v1.aggregate-function' = 'sum',
  'fields.v2.aggregate-function' = 'max',
  'merge-engine' = 'aggregation',
  'primary-key' = 'dt,k1,k2'
);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Doris 中創建對應的物化視圖&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;  CREATE MATERIALIZED VIEW paimon_aggregate_table_mv
  BUILD DEFERRED
  REFRESH INCREMENTAL
  PARTITION BY (dt)
  DISTRIBUTED BY RANDOM BUCKETS 2
  AS 
  SELECT dt, k1, SUM(a1) AS a1
  FROM paimon_aggregate_table
  GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Doris 的異步物化視圖框架會在後台定時執行如下語句：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;INSERT INTO paimon_aggregate_table_mv
SELECT dt, k1, SUM(a1) AS a1
paimon_aggregate_table@INCR('startSnapshotId'='1', 'endSnapshotId'='2')
GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;利用快照讀取功能和 Doris 聚合功能，準實時的更新物化視圖，避免全量計算。&lt;/p&gt; 
&lt;p&gt;通過此方案，&lt;strong&gt;更新成本顯著降低，數據時效性大幅提升，且得益於 Doris 優化的 SQL 透明改寫能力，用戶無需修改 SQL 即可自動享受物化視圖的加速效果。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案三：HDFS 讀取長尾優化與緩存機制&lt;/h3&gt; 
&lt;p&gt;針對 HDFS 讀取延時不穩定的問題，小米採用瞭如下兩方面措施：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. HDFS 快速超時與重試&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;HDFS 在讀取數據時，會利用多副本機制，當一個副本的讀取時間超過閾值後，會切換到另一個副本嘗試讀取。超市閾值由參數 &lt;code&gt;dfs.client.socket-timeout&lt;/code&gt;控制，默認是 60 秒。這導致首次讀取的超時時間過長，在 HDFS 抖動或負載較高的情況下，會導致查詢延遲顯著增加。我們通過將該閾值降低到 100 毫秒，讓讀取情況進行快速的超時重試，顯著降低了查詢長尾，&lt;strong&gt;P99 性能提升 1 倍，總體性能提升 10%。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e3d184f7c8d525920cddc271ac838bcf.png" alt="方案三：HDFS 讀取長尾優化與緩存機制.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Doris 數據緩存&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;針對高併發查詢場景，單純的降低 HDFS 的重試超時時間，無法徹底的解決 HDFS 查詢延遲高的問題。因此，我們利用 Doris 的數據緩存能力，將熱點數據緩存在本地高速磁盤上，完美解決了高併發場景的查詢延遲問題。在開啓緩存的情況下，從 5 併發到 80 併發，查詢延遲可以&lt;strong&gt;降低&lt;/strong&gt; &lt;strong&gt;25% 到 300%。&lt;/strong&gt; 同時，得益於數據剪枝能力、高性能的算子，&lt;strong&gt;Doris 的整體查詢併發能力是 Presto 的 5 倍。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//29901c93faeb0f8dfc37da040b805da1.png" alt="2. Doris 數據緩存.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;總結與展望&lt;/h2&gt; 
&lt;p&gt;小米在 Apache Doris 和 Paimon 上的深度融合實踐，是典型的數據庫與數據湖的互補增效的體現。在這些實踐下，小米在湖倉數據分析場景下獲得了可觀的業務收益：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;查詢平均延遲從 60 秒降至 10 秒，性能提升 6 倍；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高併發場景下（5 併發提高至 80 併發），查詢延遲降低 25% 到 300%；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;整體查詢併發能力達到 Presto 的 5 倍，有效減少了計算資源。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;目前，這些能力已經全部回饋到了 Apache Doris 社區。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在未來，小米將繼續探索和拓展 Apache Doris 在數據湖倉上的能力和場景，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 Doris 全流量替換 Presto 集羣實現降本增效。&lt;/li&gt; 
 &lt;li&gt;進一步加強針對 Paimon、Iceberg 湖格式增量物化視圖的能力。&lt;/li&gt; 
 &lt;li&gt;Doris 湖倉架構容器化以滿足更靈活的部署方式。&lt;/li&gt; 
 &lt;li&gt;基於 Doris 的 Compute Group 虛擬計算組能力實現多業務間的資源隔離，提高資源利用率，降低維護成本。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/selectdb/blog/18688781</link>
      <guid isPermaLink="false">https://my.oschina.net/selectdb/blog/18688781</guid>
      <pubDate>Tue, 19 Aug 2025 02:35:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>英偉達正開發新款「中國特供」 AI 芯片，性能強於 H20</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fworld%2Fchina%2Fnvidia-working-new-ai-chip-china-that-outperforms-h20-sources-say-2025-08-19%2F" target="_blank"&gt;據路透社援引知情人士透露&lt;/a&gt;，英偉達正在研發面向中國市場的新型 AI 芯片 B30A，其性能超越當前獲準銷售的 H20 芯片，並計劃最快於 2025 年 9 月向中國客戶提供測試樣品。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/103840_kcWl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，該芯片採用單芯片設計，預計其算力約為旗艦級 B300 加速卡雙芯片配置的一半。此外，該芯片將配備高帶寬內存（HBM）和 NVLink 技術，以提升處理器間的數據傳輸效率。&lt;/p&gt; 
&lt;p&gt;單芯片設計指所有主要電路都製作在同一塊連續的硅晶圓上，而不是分散在多個芯片上。消息人士表示，目前芯片最終規格還沒完全敲定，但 NVIDIA 希望最快下個月向中國客戶提供樣品進行測試。&lt;/p&gt; 
&lt;p&gt;根據相關曝光的信息，B30A 很可能是基於同樣單芯片設計的 Blackwell B300A 修改而來。通過單芯片集成核心電路，B30A 在保持 Blackwell 架構先進性的同時，降低了被認定為「高性能計算設備」的風險，從而規避更嚴格的出口審查。&lt;/p&gt; 
&lt;p&gt;該芯片基於最新 Blackwell 架構、其核心戰略定位在於，在滿足美國商務部出口管制條例（EAR）的前提下，提供超越上一代特供芯片 H20 的性能，以應對中國市場日益增長的 AI 算力需求和本土廠商的競爭。&lt;/p&gt; 
&lt;p&gt;此前，有消息稱，美國政府與 NVIDIA、AMD 達成協議，將在中國銷售芯片的 15% 營收上繳給美國政府，以取得半導體出口許可。與此同時，中國官媒指控 NVIDIA 芯片存在安全風險，並警告中國科技公司謹慎購買 H20。&lt;/p&gt; 
&lt;p&gt;此外，據知情人士透露，NVIDIA 也正準備推出另一款針對中國市場的新芯片，同樣基於最新 Blackwell 架構，主要用於 AI 推理任務。該芯片暫名 RTX6000D，售價將低於 H20，其規格較弱且製造需求更簡單。該芯片設計是為了落在美國政府設定的門檻之下，採用傳統 GDDR 內存，內存帶寬為 1398 GB/s，計劃 9 月提供少量產品給中國客戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367317</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367317</guid>
      <pubDate>Tue, 19 Aug 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動否認自研 AI 手機</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;針對近日市場上有關字節跳動正在研發「豆包手機」的傳言，字節跳動相關負責人明確回應稱，該消息不實，豆包目前並無推出自有手機產品的計劃。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據介紹，豆包始終致力於將自身 AI 能力向包括手機廠商在內的各類硬件廠商開放。在此過程中，雖會與部分合作夥伴共同開展完整解決方案的嘗試，但所有合作均不涉及自有手機產品的研發與推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="339" src="https://oscimg.oschina.net/oscnet/up-70f77e4956e520cdce2146bdfaa4e1c28a6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據瞭解，2019 年 1 月，字節跳動收購錘子科技部分專利使用權，當時便引發市場對於字節將進入手機市場的猜測。此後，原堅果手機團隊在字節跳動內部以「新石實驗室」為名開展工作，定位為集團硬件中台，探索智能手機及教育硬件等智能硬件產品。不過，2021 年 1 月，「新石實驗室」併入由 Musical.ly 原創始人陽陸育負責的教育硬件團隊，合併後的團隊專注於教育領域，不再研發堅果手機、TNT 顯示器等其他無關產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年以來，類似傳聞亦多次出現。1 月，有消息稱字節跳動選擇與努比亞合作開發 AI 手機，字節跳動回應稱消息不實；2 月，關於榮耀前 CEO 趙明將加盟字節跳動並負責手機業務的傳言，字節跳動同樣表示信息不實。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;豆包大模型作為字節跳動旗下重要的 AI 產品，數據顯示，其 2024 年累計用戶規模已超 1.6 億，11 月平均每日新增下載用戶達 80 萬，單日活躍用戶近 900 萬。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技術應用方面，2025 年 7 月 30 日，火山引擎宣佈豆包·圖像編輯模型 SeedEdit 3.0 正式登陸火山方舟；8 月 1 日，小米瀏覽器升級「AI 搜索」功能，通過接入豆包大模型及火山方舟高代碼智能體產品，進一步提升了 AI 搜索的效率與服務豐富度。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367315</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367315</guid>
      <pubDate>Tue, 19 Aug 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 計劃通過股權出售成為全球最有價值私營公司，估值達 5000 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 正在考慮進行一輪價值 60 億美元的股權出售，這將使其估值達到 5000 億美元，超越目前全球最有價值的私人公司 SpaceX（估值 3500 億美元）。這次股權出售的股份將主要由現有和前員工出售。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-6a3f4b40ac1c67918c3c1507155d1ac2163.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;過去一年，OpenAI 經歷了迅猛的增長，微軟和軟銀等投資者已經為該公司投入了至少 400 億美元，使其在 2023 年 3 月的估值達到了 3000 億美元。而在 2022 年 10 月，OpenAI 的估值僅為 1570 億美元。如果此次股權出售成功，OpenAI 將成為全球估值&lt;span&gt;最高&lt;/span&gt;的私人公司。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;當前，參與此次股權出售談判的投資者包括已經對 OpenAI 投資的三家機構:軟銀、Dragoneer 投資集團和 Thrive 資本。根據彭博社的報道，相關談判仍處於早期階段，最終的數字可能會有所變動。OpenAI 對此未作出評論。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在人工智能領域，OpenAI 正處於激烈的競爭之中。全球多家科技巨頭，包括 Meta、谷歌、亞馬遜和微軟，正在大力投入人工智能研發， hiring engineers and building data centers。僅在 2025 年，這四家公司在人工智能領域的投入就超過了 1550 億美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管自 2022 年發佈 ChatGPT 以來，人工智能技術有了顯著提升，但 OpenAI 在本月發佈的&lt;span&gt;最新&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 模型 GPT-5 的表現卻並未得到熱烈反響。用戶反饋稱，該版本的寫作質量不如之前的版本，且缺乏以往的個性化特徵。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 首席執行官山姆・奧特曼表示，雖然公司追求的是 「通用人工智能」，即能在大多數任務上超越人類的 AI，但他在最近的發佈會上表示，GPT-5 是 「普遍智能」 的，但尚未能夠 「持續學習」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367312</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367312</guid>
      <pubDate>Tue, 19 Aug 2025 02:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 剛剛更新線上模型版本至 V3.1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 在官方社羣宣佈，其線上模型版本已升級至 V3.1，上下文長度拓展至 128k。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0819/193913_BlOM_2720166.png" width="1196" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;歡迎前往官方網頁、APP、小程序測試，API 接口調用方式保持不變。&lt;/p&gt; 
&lt;p&gt;接口信息：https://platform.deepseek.com/usage&lt;/p&gt; 
&lt;p&gt;近日市場再度傳出深度求索下一代 AI 大模型 DeepSeek-R2 的發佈消息，預計時間窗口為 8 月 15 日至 30 日。對此，接近 DeepSeek 人士表示，該消息不實，並確認 DeepSeek-R2 在 8 月內並無發佈計劃。 &lt;/p&gt; 
&lt;p&gt;DeepSeek 創始人梁文鋒在內部表示，他對 R2 取得的進展並不滿意，並一直在竭力投入更多的時間來研發一款能夠讓該公司在 AI 領域保持領先地位的先進模型。&lt;/p&gt; 
&lt;p&gt;梁文峯要求模型達到更出色的結果才批准發佈，R2 的發佈還因更新版模型的數據標註時間超出預期而被推遲。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367254</guid>
      <pubDate>Mon, 18 Aug 2025 11:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 總裁透露 OpenAI 的 AGI 之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在最新一期的《Latent Space》訪談中，OpenAI 總裁 Greg Brockman 深入闡述了公司邁向 AGI 的整體路線圖，核心可概括為「三個轉向」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技術轉向：從「一次性預訓練」到「強化學習推理」&lt;/li&gt; 
 &lt;li&gt;資源轉向：把「算力」視為唯一稀缺資源&lt;/li&gt; 
 &lt;li&gt;落地轉向：從「科研樣品」到「可審計的生產 Agent」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7470bcfe83cc59abb3b2fd2b11145f80512.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Greg Brockman 透露，GPT-4 發佈之後，團隊內部覆盤「它為何還不是 AGI」，結論是僅靠大規模預訓練無法解決可靠性不足的問題，必須讓模型在與真實世界的交互中「試錯—反饋—再訓練」。因此 GPT-5 首次引入強化學習驅動的「動態推理」範式：模型邊使用邊生成數據，再用這些數據進行再訓練，逼近人類「邊做邊學」的循環。&lt;/p&gt; 
&lt;p&gt;他將這種「推理-重訓」飛輪稱為「超臨界學習」（supercritical learning）：當算力放大 10× 乃至 10 000× 時，模型不僅能掌握任務本身，還能推演出二階、三階後果，從而快速逼近 AGI。&lt;/p&gt; 
&lt;p&gt;Greg Brockman 還把「算力」視為唯一稀缺資源，他認為算法壁壘往往可通過堆算力解決；AGI 進度條幾乎與可用計算量線性相關。OpenAI 已把「持續投入大規模計算」寫入長期資源策略，並認為未來 AGI 的形態會是「一個模型管理器」——本地小模型按需調用雲端大算力，實現自適應計算。&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;總的來説，OpenAI 的 AGI 路線圖可概括為「用強化學習把模型放進真實世界，用算力把反饋循環推到極致，用安全可控的 Agent 形態把能力嵌入千行百業」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367248</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367248</guid>
      <pubDate>Mon, 18 Aug 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 143 被發現不適用於某些舊 Windows 10 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在舊版 Windows 10 上運行 Firefox 瀏覽器的用戶即將迎來很大困擾。目前在 Nightly 頻道提供的最新版本 Firefox 143 已不再適用於 1803 之前的版本。&lt;/p&gt; 
&lt;p&gt;在 Windows 10 1703、1709 或 2015 LTSB 等老版本上啓動該瀏覽器時，用戶會收到以下錯誤：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由於未找到 api-ms-win-core-console-11-2-0.dll，代碼無法繼續執行。重新安裝程序或許可以解決此問題。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0700df38d95ae0494d0de12f07efb1ce47d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FTheBobPony%2Fstatus%2F1955740560292999460" target="_blank"&gt;這一發現&lt;/a&gt;迅速引發了用戶的討論（他們已經對 Mozilla 向瀏覽器添加不必要的、耗費資源的內容&lt;a href="https://www.oschina.net/news/366029" target="_blank"&gt;感到不滿&lt;/a&gt;），他們要求 Mozilla 放棄舊版 Windows 10，這並非罕見之舉。儘管 Windows 10 總體上仍然受支持，但許多應用程序已無法在舊的版本上運行。&lt;/p&gt; 
&lt;p&gt;儘管如此，考慮到 Mozilla 瀏覽器仍然支持 Windows 7，放棄對部分 Windows 10 市場份額的支持卻令人意外，不過某些舊版本（例如 2015 LTSB 和 2016 LTSC）仍然受支持。Windows&amp;nbsp;10 2015 LTSB 版本將於 2025 年 10 月停止支持，而 2016 LTSC 版本將繼續獲得更新，直到 2016 年 10 月。&lt;/p&gt; 
&lt;p&gt;然而事實證明，Mozilla 並沒有在 1803 之前的 Windows 10 版本上淘汰 Firefox。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ffirefox%2Fcomments%2F1mph4ra%2Fstarting_with_firefox_143_it_will_now_only%2F" target="_blank"&gt;Mozilla 工程師在 Reddit 上&lt;/a&gt;迅速處理了此事，並確認 Firefox 143 Nightly 無法在舊版 Windows 10 上運行的問題只是一個 bug，而非故意為之。因此，該問題應該很快就會得到修復。您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1983020" target="_blank"&gt;在 Bugzilla 官方網站上&lt;/a&gt;跟蹤發現的 bug 。&lt;/p&gt; 
&lt;p&gt;與此同時，用戶創建了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faubymori%2FFirefox-OldWindows%252010-Fix" target="_blank"&gt;一個臨時解決方案&lt;/a&gt;，讓瀏覽器在 Firefox 軟件工程師準備永久修復程序期間能夠正常運行。這也可以提醒大家不要依賴 Nightly 版本，因為這些版本的更改有時可能會導致瀏覽器完全崩潰。&lt;/p&gt; 
&lt;p&gt;Mozilla 尚未宣佈終止 Windows 10 支持的計劃。不過，由於 Windows 7 仍受支持，因此可以預期開發人員將在相當長的一段時間內繼續在 Windows 10 上更新 Firefox。另一方面，微軟近日透露，Edge 瀏覽器在 2025 年 10 月主流支持結束後，仍將在 Windows 10 上繼續支持三年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367246</guid>
      <pubDate>Mon, 18 Aug 2025 11:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
