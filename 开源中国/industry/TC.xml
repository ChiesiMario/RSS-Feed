<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 21 Jul 2025 02:45:51 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Sam Altman 透露 GPT-5 即將發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在宣佈其模型獲得國際數學奧林匹克競賽金牌的同時，OpenAI&amp;nbsp;CEO&amp;nbsp;Sam Altman&amp;nbsp;和研究科學家&amp;nbsp;Alexander Wei&amp;nbsp;透露，GPT-5&amp;nbsp;即將發佈。然而，他們均明確設定了市場預期：即將發佈的&amp;nbsp;GPT-5&amp;nbsp;並非在 IMO 競賽中獲獎的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="687" src="https://static.oschina.net/uploads/space/2025/0721/104124_33Ko_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Altman&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1946569252296929727" target="_blank"&gt;&amp;nbsp;強調&lt;/a&gt;，獲得金牌的 IMO 模型是一個實驗性的研究成果，整合了未來將用於其他模型的新研究技術，而即將面世的&amp;nbsp;GPT-5&amp;nbsp;不會具備同等級別的數學能力。&lt;/p&gt; 
&lt;p&gt;他表示，用戶會喜歡&amp;nbsp;GPT-5，但具有 IMO 金牌級能力的模型在未來數月內不會發布。&lt;/p&gt; 
&lt;p&gt;與此同時，社區發現在一個公開的基準測試&amp;nbsp;GitHub&amp;nbsp;倉庫中出現了一個名為&amp;nbsp;gpt-5-reasoning-alpha-2025-07-13&amp;nbsp;的模型標識符，進一步引發了關於新模型的討論。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361390</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361390</guid>
      <pubDate>Mon, 21 Jul 2025 02:42:47 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Altman：2025 年底 OpenAI 將上線超 100 萬塊 GPU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;CEO 薩姆・奧爾特曼（Sam Altman）近日在社交媒體上宣佈，OpenAI 計劃在 2025 年底前上線超過 100 萬塊 GPU。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;據悉，OpenAI 的戰略主要圍繞三個核心領域展開：Stargate（星際之門）項目、芯片供應鏈重構以及能源挑戰。Stargate 是 OpenAI 新成立的公司，目標是為 AI 基礎設施建設注入鉅額資金。未來四年，該項目預計將投資高達 5000 億美元（約合 3.59 萬億元人民幣），旨在在美國打造一座全新的 AI 基礎設施。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Stargate 項目的首期工程設立在得克薩斯州的阿比林市，佔地 1000 英畝，計劃建造全球最大的 AI 訓練集羣。OpenAI 與軟銀、甲骨文等多家知名企業建立了緊密的合作關係。軟銀 CEO 孫正義將擔任 Stargate 董事長，負責整體財務規劃，而 OpenAI 則負責日常運營。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了 Stargate 項目外，OpenAI 還將與 Arm、微軟和英偉達等巨頭合作，進一步推動 AI 技術的發展與應用。這一系列的舉措顯示了 OpenAI 在全球 AI 基礎設施競賽中的強烈競爭意識和技術雄心。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得一提的是，隨着 GPU 需求的激增，OpenAI 的計劃將可能引發市場的劇烈反響。AI 行業的競爭正日益白熱化，OpenAI 的 「百倍擴容」 願景不僅是自身發展的重要里程碑，也將深刻影響整個行業的格局與未來。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361387</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361387</guid>
      <pubDate>Mon, 21 Jul 2025 02:31:47 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Manus 創始人覆盤構建 AI Agent 的「上下文工程」實踐</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在爆火僅四個月後，Manus AI 突然幾乎全面撤出中國市場，不僅清空全部社交賬號內容，而且國行版本的 Manus 也疑似暫停推進。&lt;/p&gt; 
&lt;p&gt;中國通用 AI Agent（智能體）創業公司 Manus 將總部遷至新加坡，並百萬年薪招聘 AI 工程師，對被裁員工給予 N+3 或者 2N 賠償&lt;/p&gt; 
&lt;p&gt;早在上個月，Manus 聯合創始人張濤便曾宣佈，公司已將全球總部遷至新加坡，並在東京和加州設有辦公室。儘管官方未正面回應，只稱是「基於經營效率的調整」，但出海所引發裁員等一連串爭議問題，也讓外界普遍猜測其是否正在「跑路」。&lt;/p&gt; 
&lt;p&gt;風波之中，Manus 聯合創始人季逸超近日&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmanus.im%2Fblog%2FContext-Engineering-for-AI-Agents-Lessons-from-Building-Manus" target="_blank"&gt;發佈了一篇技術博客&lt;/a&gt;&lt;/u&gt;，試圖將外界關注點重新拉回產品技術本身。&lt;/p&gt; 
&lt;p&gt;經過四次重構和數百萬真實交互，他在文中坦誠地總結了團隊在構建 Manus 過程中積累的經驗教訓。內容既有實操乾貨，也不乏反思，對業內同行與普通用戶來説，都不失為一份值得一讀的參考材料。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1140" src="https://static.oschina.net/uploads/space/2025/0721/102230_H9TJ_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;省流版：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 押注上下文，不再訓練模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;與其耗時訓練，不如圍繞大模型構造「記憶」和流程。上下文工程讓你在幾小時而不是幾周內發佈產品更新。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. KV-Cache 命中率至關重要&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;輸入越穩定，緩存命中率越高，成本和延遲越低。三條實戰建議：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免提示中使用時間戳；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;只追加上下文，避免修改歷史記錄；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;手動標記緩存斷點，保障前綴一致性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 工具不要動態添加，而是用「遮蔽」法控制選擇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;動態修改工具列表會讓緩存失效、模型混亂。Manus 使用「遮蔽 token logits」的方法，讓模型「看不見」不應調用的工具。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. 用文件系統承載持久上下文&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;大模型上下文再長也會被打滿。Manus 讓模型把長期記憶寫入虛擬文件系統，按需讀寫，實現「外部記憶」，規避信息丟失。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5. 重寫 ToDo 清單，是操控注意力的重要方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;模型容易「中途忘記目標」。Manus 會不斷用自然語言更新並重述 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ftodo.md" target="_blank"&gt;todo.md&lt;/a&gt; 文件，把全局目標拉回注意力焦點，防止任務跑偏。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6. 錯誤不是要掩蓋，而是要保留&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;失敗是構建 Agent 過程中的一部分。保留錯誤日誌（如失敗的操作、堆棧信息），能幫助模型更新內部信念，減少重複錯誤。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7. 少樣本提示不是靈丹妙藥，要防「同質化陷阱」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;模型會盲目模仿上下文中的行為模式。Manus 通過引入結構化變化（如不同措辭或順序），避免模型在長任務中陷入複製粘貼式幻覺。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;在 Manus 項目的最初階段，我和我的團隊面臨一個關鍵決策：我們是應該使用開源基礎模型訓練一個端到端的智能體模型，還是基於前沿模型的上下文學習能力構建一個智能體？&lt;/p&gt; 
&lt;p&gt;在我的 NLP 生涯的第一個十年裏，我們沒有這種選擇的奢侈。在遙遠的 BERT 時代（是的，已經過去七年了），模型必須先進行微調——和評估——才能遷移到新任務。這個過程通常每次迭代需要數週時間，儘管與今天的 LLM 相比，這些模型非常小。對於快速發展的應用，特別是在產品市場匹配 (PMF) 之前，這種緩慢的反饋循環是一個致命缺陷。這是我上一個創業公司的慘痛教訓，當時我從頭開始訓練模型用於開放信息提取和語義搜索。&lt;/p&gt; 
&lt;p&gt;然後 GPT-3 和 Flan-T5 出現了，我的內部模型一夜之間變得無關緊要。具有諷刺意味的是，這些相同的模型標誌着上下文學習的開始——以及一條全新的前進道路。 這個來之不易的教訓使選擇變得明確：&lt;strong&gt;Manus 將押注於上下文工程&lt;/strong&gt;。這使我們能夠在幾小時而非幾周內交付改進，並使我們的產品與底層模型保持正交：如果模型進步是上漲的潮水，我們希望 Manus 成為那條船，而不是固定在海牀上的柱子。&lt;/p&gt; 
&lt;p&gt;儘管如此，上下文工程證明絕非易事。這是一門實驗科學——我們已經重建了我們的代理框架四次，每次都是在發現了更好的塑造上下文的方式之後。我們親切地將這種手動架構搜索、提示調整和經驗猜測的過程稱為**"&lt;strong&gt;&lt;strong&gt;隨機&lt;/strong&gt;&lt;/strong&gt;研究生&lt;strong&gt;&lt;strong&gt;下降&lt;/strong&gt;&lt;/strong&gt;"**。這並不優雅，但它有效。&lt;/p&gt; 
&lt;p&gt;這篇文章分享了我們通過自己的"SGD"所達到的局部最優解。如果你正在構建自己的 AI 代理，我希望這些原則能幫助你更快地收斂。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;圍繞 KV 緩存進行設計&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如果我必須選擇一個指標，我認為&amp;nbsp;KV-cache 命中率是生產階段 AI 代理最重要的單一指標。它直接影響延遲和成本。為了理解原因，讓我們看看典型代理是如何運作的：&lt;/p&gt; 
&lt;p&gt;在接收用戶輸入後，代理通過一系列工具使用鏈來完成任務。在每次迭代中，模型根據當前上下文從預定義的動作空間中選擇一個動作。然後在環境中執行該動作（例如，Manus 的虛擬機沙盒）以產生觀察結果。動作和觀察結果被附加到上下文中，形成下一次迭代的輸入。這個循環持續進行，直到任務完成。&lt;/p&gt; 
&lt;p&gt;正如你所想象的，隨着每一步的推進，上下文不斷增長，而輸出——通常是結構化的函數調用——保持相對簡短。這使得代理（agents）相比聊天機器人的預填充和解碼比例高度傾斜。例如在 Manus 中，平均輸入與輸出的 token 比例約為 100:1。&lt;/p&gt; 
&lt;p&gt;幸運的是，具有相同前綴的上下文可以利用 KV 緩存，這大大減少了首個 token 的生成時間 (TTFT) 和推理成本——無論你是使用自託管模型還是調用推理 API。我們説的不是小幅度的節省：例如使用 Claude Sonnet 時，緩存的輸入 token 成本為 0.30 美元/百萬 token，而未緩存的成本為 3 美元/百萬 token——相差 10 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/102411_9ZeU_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從上下文工程的角度，提高 KV 緩存命中率涉及幾個關鍵實踐：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.保持你的提示前綴穩定&lt;/strong&gt;。由於 LLM 的自迴歸特性，即使是單個標記的差異也會使該標記之後的緩存失效。一個常見的錯誤是在系統提示的開頭包含時間戳——尤其是精確到秒的時間戳。雖然這讓模型能告訴你當前時間，但也會降低你的緩存命中率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.使你的上下文只追加&lt;/strong&gt;。避免修改之前的操作或觀察。確保你的序列化是確定性的。許多編程語言和庫在序列化 JSON 對象時不保證鍵順序的穩定性，這可能會悄無聲息地破壞緩存。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.在需要時明確標記緩存斷點&lt;/strong&gt;。某些模型提供商或推理框架不支持自動增量前綴緩存，而是需要在上下文中手動插入緩存斷點。在分配這些斷點時，要考慮潛在的緩存過期問題，並至少確保斷點包含系統提示的結尾。&lt;/p&gt; 
&lt;p&gt;此外，如果你正在使用像 vLLM 這樣的框架自託管模型，請確保啓用了前綴/提示緩存，並且你正在使用會話 ID 等技術在分佈式工作節點之間一致地路由請求。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;遮蔽，而非移除&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;隨着代理能力的增強，其行動空間自然變得更加複雜——簡單來説，工具數量爆炸式增長。最近流行的 MCP 只會火上澆油。如果你允許用戶自定義工具，相信我：總會有人將數百個神祕工具插入到你精心策劃的行動空間中。結果，模型更可能選擇錯誤的行動或採取低效的路徑。簡而言之，你武裝過度的代理變得更加愚蠢。&lt;/p&gt; 
&lt;p&gt;一個自然的反應是設計一個動態行動空間——可能是使用類似於 RAG 的方法按需加載工具。我們在 Manus 中也嘗試過這種方法。但我們的實驗表明了一個明確的規則：除非絕對必要，&lt;strong&gt;避免在迭代過程中動態添加或移除工具&lt;/strong&gt;。這主要有兩個原因：&lt;/p&gt; 
&lt;p&gt;1.在大多數 LLM 中，工具定義在序列化後位於上下文的前部，通常在系統提示之前或之後。因此任何更改都會使後續所有動作和觀察的 KV 緩存失效。&lt;/p&gt; 
&lt;p&gt;2.當先前的動作和觀察仍然引用當前上下文中不再定義的工具時，模型會感到困惑。如果沒有約束解碼，&lt;strong&gt;這通常會導致模式違規或幻覺動作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;為瞭解決這個問題並仍然改進動作選擇，Manus 使用上下文感知的狀態機來管理工具可用性。它不是移除工具，而是在解碼過程中掩蔽 token 的 logits，以基於當前上下文阻止（或強制）選擇某些動作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/102429_jnnQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在實踐中，大多數模型提供商和推理框架支持某種形式的&lt;strong&gt;響應預填充&lt;/strong&gt;，這允許你在不修改工具定義的情況下約束動作空間。函數調用通常有三種模式（我們將使用 NousResearch 的&amp;nbsp;Hermes 格式&amp;nbsp;作為示例）：&lt;/p&gt; 
&lt;p&gt;•自動&amp;nbsp;– 模型可以選擇調用或不調用函數。通過僅預填充回覆前綴實現：&lt;/p&gt; 
&lt;p&gt;&amp;lt;|im_start|&amp;gt;assistant&lt;/p&gt; 
&lt;p&gt;•必需&amp;nbsp;– 模型必須調用函數，但選擇不受約束。通過預填充到工具調用令牌實現：&lt;/p&gt; 
&lt;p&gt;&amp;lt;|im_start|&amp;gt;assistant&amp;lt;tool_call&amp;gt;&lt;/p&gt; 
&lt;p&gt;•指定&amp;nbsp;– 模型必須從特定子集中調用函數。通過預填充到函數名稱的開頭實現：&amp;lt;|im_start|&amp;gt;assistant&amp;lt;tool_call&amp;gt;{"name": "browser_&lt;/p&gt; 
&lt;p&gt;通過這種方式，我們通過直接掩碼 token 的 logits 來約束動作選擇。例如，當用戶提供新輸入時，Manus 必須立即回覆而不是執行動作。我們還有意設計了具有一致前綴的動作名稱——例如，所有與瀏覽器相關的工具都以 browser_開頭，命令行工具以 shell_開頭。這使我們能夠輕鬆確保代理在給定狀態下只從特定工具組中進行選擇而無需使用有狀態的 logits 處理器。&lt;/p&gt; 
&lt;p&gt;這些設計有助於確保 Manus 代理循環保持穩定——即使在模型驅動的架構下。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;使用文件系統作為上下文&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;現代前沿 LLM 現在提供 128K 令牌或更多的上下文窗口。但在真實世界的代理場景中，這通常不夠，有時甚至是一種負擔。有三個常見的痛點：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.觀察結果可能非常龐大&lt;/strong&gt;，尤其是當代理與網頁或 PDF 等非結構化數據交互時。很容易超出上下文限制。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.模型性能往往會下降&lt;/strong&gt;，超過一定的上下文長度後，即使技術上支持該窗口大小。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.長輸入成本高昂&lt;/strong&gt;，即使使用前綴緩存。你仍然需要為傳輸和預填充每個 token 付費。&lt;/p&gt; 
&lt;p&gt;為瞭解決這個問題，許多代理系統實現了上下文截斷或壓縮策略。但過度激進的壓縮不可避免地導致信息丟失。這個問題是根本性的：代理本質上必須根據所有先前狀態預測下一個動作——而你無法可靠地預測哪個觀察結果可能在十步之後變得至關重要。從邏輯角度看，任何不可逆的壓縮都帶有風險。&lt;/p&gt; 
&lt;p&gt;這就是為什麼我們在 Manus 中將文件系統視為終極上下文：大小不受限制，天然持久化，並且代理可以直接操作。模型學會按需寫入和讀取文件——不僅將文件系統用作存儲，還用作結構化的外部記憶。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/102445_cdBw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們的壓縮策略始終設計為&lt;strong&gt;可恢復&lt;/strong&gt;的。例如，只要保留 URL，網頁內容就可以從上下文中移除；如果沙盒中仍然保留文檔路徑，則可以省略文檔內容。這使得 Manus 能夠縮短上下文長度，而不會永久丟失信息。&lt;/p&gt; 
&lt;p&gt;在開發這個功能時，我發現自己在想象狀態空間模型 (State Space Model, SSM) 在智能體環境中有效工作需要什麼條件。與 Transformer 不同，SSM 缺乏完整的注意力機制，並且在處理長距離的後向依賴關係時表現不佳。但如果它們能夠掌握基於文件的記憶——將長期狀態外部化而不是保存在上下文中——那麼它們的速度和效率可能會開啓一類新型智能體。基於 SSM 的智能體可能是神經圖靈機真正的繼任者。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;通過複述操控注意力&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如果你使用過 Manus，你可能注意到一個有趣的現象：在處理複雜任務時，它傾向於創建一個 todo.md 文件——並在任務進行過程中逐步更新它，勾選已完成的項目。&lt;/p&gt; 
&lt;p&gt;這不僅僅是可愛的行為——這是一種&lt;strong&gt;操控注意力&lt;/strong&gt;的刻意機制。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/102503_Sccz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Manus 中的一個典型任務平均需要大約 50 次工具調用。這是一個很長的循環——由於 Manus 依賴 LLM 進行決策，它很容易偏離主題或忘記早期目標，尤其是在長上下文或複雜任務中。&lt;/p&gt; 
&lt;p&gt;通過不斷重寫待辦事項列表，Manus 將其目標複述到上下文的末尾。這將全局計劃推入模型的近期注意力範圍內，避免了"丟失在中間"的問題，並減少了目標不一致。實際上，它使用自然語言來使自己的注意力偏向任務目標——而不需要特殊的架構變更。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;保留錯誤的內容&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;代理會犯錯。這不是 bug——這是現實。語言模型會產生幻覺，環境會返回錯誤，外部工具會出現異常行為，意外的邊緣情況隨時都會出現。在多步驟任務中，失敗不是例外；它是循環的一部分。&lt;/p&gt; 
&lt;p&gt;然而，一個常見的衝動是隱藏這些錯誤：清理痕跡，重試操作，或重置模型的狀態並將其留給神奇的"溫度"。這感覺更安全，更受控制。但這是有代價的：&lt;strong&gt;擦除失敗會移除證據&lt;/strong&gt;。沒有證據，模型就無法適應。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/102515_Ejog_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據我們的經驗，改善代理行為最有效的方法之一出奇地簡單：&lt;strong&gt;將錯誤的嘗試保留在上下文中&lt;/strong&gt;。當模型看到一個失敗的行動——以及由此產生的觀察結果或堆棧跟蹤——它會隱式地更新其內部信念。這會改變其先驗，降低重複相同錯誤的可能性。 事實上，我們認為錯誤恢復是真正代理行為的最明顯指標之一。然而，在大多數學術工作和公共基準測試中，這一點仍然代表性不足，它們通常關注理想條件下的任務成功。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;不要被少樣本示例所困&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;少樣本提示是提高 LLM 輸出的常用技術。但在代理系統中，它可能會以微妙的方式適得其反。&lt;/p&gt; 
&lt;p&gt;語言模型是優秀的模仿者；它們模仿上下文中的行為模式。如果你的上下文充滿了類似的過去行動-觀察對，模型將傾向於遵循該模式，即使這不再是最優的。&lt;/p&gt; 
&lt;p&gt;這在涉及重複決策或行動的任務中可能很危險。例如，當使用 Manus 幫助審查 20 份簡歷時，代理通常會陷入一種節奏——僅僅因為這是它在上下文中看到的，就重複類似的行動。這導致偏離、過度泛化，或有時產生幻覺。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/102529_Xy1G_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;解決方法是增加多樣性。Manus 在行動和觀察中引入少量的結構化變化——不同的序列化模板、替代性措辭、順序或格式上的微小噪音。這種受控的隨機性有助於打破模式並調整模型的注意力。&lt;/p&gt; 
&lt;p&gt;換句話説，&lt;strong&gt;不要讓自己陷入少樣本學習的窠臼&lt;/strong&gt;。你的上下文越單一，你的智能體就變得越脆弱。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;結論&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;上下文工程仍然是一門新興的科學——但對於智能體系統來説，它已經是必不可少的。模型可能變得更強大、更快速、更經濟，但再多的原始能力也無法替代對記憶、環境和反饋的需求。你如何塑造上下文最終決定了你的智能體的行為方式：它運行的速度、恢復的效果以及擴展的範圍。&lt;/p&gt; 
&lt;p&gt;在 Manus，我們通過反覆的重寫、死衚衕以及面向數百萬用戶的實際測試學到了這些經驗。我們在這裏分享的內容並非放之四海而皆準的真理——但這些是對我們有效的模式。如果它們能幫助你避免哪怕一次痛苦的迭代，那麼這篇文章就達到了它的目的。&lt;/p&gt; 
&lt;p&gt;智能體的未來將一次構建一個上下文。好好設計它們吧。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361386</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361386</guid>
      <pubDate>Mon, 21 Jul 2025 02:25:47 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克確認 Grok 未來將支持構建自定義 AI 伴侶</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;馬斯克已確認，xAI 旗下 AI 聊天機器人 Grok 未來支持用戶構建自定義 AI 伴侶，用戶將能夠創建擁有定製聲音、外觀和個性的數字伴侶（「每一個都會是獨一無二的」）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3b409a325fcce4b0a222058e37fd50141e5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，Grok 已推出基於 Grok 4 大模型的「伴侶」（Companions）功能，首批上線了動漫風格角色 Ani（哥特風「AI 女友」）和卡通小熊貓 Bad Rudy，支持動態語音互動及角色外觀自定義，用戶可通過設置啓用該功能。目前這項服務僅向每月支付 30 美元的 SuperGrok 訂閲服務用戶開放。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5effcad31d7075014c476e238de5b315b9b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;馬斯克表示，這項功能仍處於「軟啓動」階段，未來幾天將簡化啓用流程，並逐步推出更多角色（如即將上線的男性角色 Chad 和 Valentine）以滿足不同用戶需求 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361384</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361384</guid>
      <pubDate>Mon, 21 Jul 2025 02:17:47 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 迎來頂尖人才：40% 曾在 OpenAI 任職，薪資高達 1 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta 近日正在積極擴展其人工智能團隊，成立了名為 「&lt;span&gt;超級&lt;/span&gt;智能實驗室」（Superintelligence Labs）的新部門，旨在推動基礎模型的開發。據內部消息人士透露，該實驗室目前已成功招募 44 名&lt;span&gt;頂尖&lt;/span&gt;人才，令人矚目的是，約一半的員工來自中國，而 40% 的員工曾在 OpenAI 工作過。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta 首席執行官馬克・扎克伯格以其豪爽的投資風格而聞名，曾經投入 460 億美元用於元宇宙項目，但由於未達到預期效果，現在他將重心轉向人工智能領域。Meta 希望通過大規模的招聘行動來佔領 AI 市場的制高點。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期，Meta 不僅成功從 OpenAI 和蘋果等知名企業挖角，還在招募蘋果基礎模型負責人時開出了高達 2 億美元的簽約獎金。儘管如此，Meta 也並非每次都能達到這樣的薪資水平，一些新員工的簽約獎金並未達到 1 億美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="383" src="https://oscimg.oschina.net/oscnet/up-f4808a66f8475012aeed9fa2aba51e71449.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在新招募的員工中，75% 擁有博士學位，70% 為研究人員，背景非常多元化。除了 50% 來自中國外，還有 40% 來自 OpenAI，20% 來自谷歌的 DeepMind，15% 來自 Scale 公司。這一人才結構的多樣性將為 Meta 的 AI 研發注入新的活力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得注意的是，這些新入職員工大多還未在 Meta 工作滿一個月，年薪可能在 1000 萬至 1 億美元之間，具體數額尚未得到官方確認。這一招聘動態顯示了 Meta 在 AI 領域的雄心，也意味着行業人才競爭的加劇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361382</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361382</guid>
      <pubDate>Mon, 21 Jul 2025 02:05:47 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GPU 維修，一個百億市場是如何形成的？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;2020 年，全球人工智能（AI）迎來熱潮，大模型技術席捲全球。 作為全球最大的互聯網和科技應用市場之一，中國對 AI 算力的需求早已快速增長，阿里、騰訊、字節跳動等科技巨頭和眾多 AI 初創公司，爭相購入英偉達（NVIDIA）的高端 GPU，組建龐大算力集羣，投入大模型研發競賽。&lt;/p&gt; 
 &lt;p&gt;憑藉專為 AI 計算設計的 GPU，尤其是數據中心級的 A100 芯片，英偉達在中國市場賺得盆滿缽滿，其高端 GPU 供不應求，價格水漲船高。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;本來，這是一個雙贏的局面：英偉達提供鏟子，中國公司挖掘 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 金礦。&lt;/strong&gt;然而，中美科技競爭的暗流早已湧動，尤其是在人工智能和半導體等攸關國家安全和科技主導權的領域更是鬥爭激烈。美國接連揮下的芯片禁售令，不僅斬斷了獲取新鏟子的渠道，反而倒逼出一個規模或達百億的 GPU 維修產業填補着官方退場後的空白。&lt;/p&gt; 
 &lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;三次禁售令與囤貨搶購&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
 &lt;p&gt;2022 年 8 月，美國政府向英偉達等公司發出通知，限制其高端 AI 芯片對中國的出口。10 月，美國商務部工業和安全局（BIS）正式更新《出口管理條例》。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;美國的目標明確：通過限制中國獲取頂級 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;，減緩其在尖端 AI 領域（尤其軍事應用）的進展。這些新規，像一道無形的鐵幕，開始落下。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;新規的核心條款之一，就是對英偉達的旗艦產品——A100 和 H100 芯片及其相關技術（如組成大型服務器的 HGX 模組）實施嚴格的出口管制。任何公司——包括英偉達及其合作伙伴如戴爾、惠普、超微，向中國大陸及中國香港、澳門出口這些芯片前，都必須獲得美國政府頒發的特別許可證。因為這種許可證極難獲得或根本不會發放，實質上就是禁止銷往中國。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;strong&gt;英偉達瞬間陷入兩難。&lt;/strong&gt;為了保住部分中國市場，2022 年底，英偉達迅速行動，開發了針對中國市場的特供版芯片——A800 和 H800。也可以叫閹割版芯片：這些芯片在關鍵性能指標，即芯片間數據傳輸速率上進行了人為限制，使其性能剛好低於美國出口管制的「紅線」。&lt;/p&gt; 
 &lt;p&gt;A800/H800 雖然性能打折，但仍是當時中國公司能合法獲得的最強算力選項之一。&lt;strong&gt;尤其是在 &lt;/strong&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;strong&gt; 引發的&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;熱潮下， 中國 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 市場進一步大爆發。A800/H800 被大量採購，暫時緩解了部分算力緊迫的局面。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;然而，美國很快掐斷了這一後路，在 2023 年 10 月進一步升級了管制規則，直接將英偉達的「特供版」 A800 和 H800 也納入了禁售範圍！中國公司通過合法渠道獲取先進 AI 芯片的最後一條主要路徑也被切斷。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;但市場對&lt;/strong&gt;&lt;strong&gt;算力&lt;/strong&gt;&lt;strong&gt;的強勁需求並未緩解，反而在斷供威脅下愈發焦灼&lt;/strong&gt;。因為國內 AI 巨頭們的大模型競賽此刻正如火如荼，對頂尖算力的需求是剛性且刻不容緩的。&lt;/p&gt; 
 &lt;p&gt;在國產替代尚無法完全扛起大梁、產能爬坡仍需時間的現實下，即使是性能被閹割的英偉達芯片，也是支撐研發與商業化的硬通貨。禁令陰影下，恐慌性囤貨潮瞬間引爆——客戶爭相搶購最後的庫存，只為在窗口期徹底關閉前，囤積儘可能多的算力彈藥。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;既要挽救中國市場，又要遵守美國出口限制，英偉達無法向中國出售高端 AI 芯片（如 H100、A100），因此針對中國市場推出符合管制規則的特供版芯片（如 H20、L20 PCIe、L2 PCIe），通過大幅削弱互聯帶寬和算力以滿足美方要求。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;其中，H20 是旗艦計算卡 H100 的替代品，雖然都是基於英偉達的 Hopper 架構，但 H20 的 GPU 核心數量減少 41%，性能降低 28%。但通過優化互聯帶寬與軟件性能，H20 仍成為國內大模型訓練的重要選擇。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;L20 和 L2 是基於 RTX 4090 級消費卡（Ada Lovelace 架構）的「降級版」，主要面向 AI 推理場景。H20 芯片上市後，由於國內客戶擔憂後續斷供，集中搶購囤貨。&lt;/p&gt; 
 &lt;p&gt;研究機構 Omdia 根據英偉達財報預估，2024 年，國內僅字節跳動和騰訊就分別訂購了約 23 萬片英偉達的芯片，僅次於微軟。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;而國內市場對斷供的擔憂再一次得到了驗證：2025 年 &lt;/strong&gt;&lt;strong&gt;4 月 16 日，美政府已經禁止英偉達向中國出口 H20 芯片。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;英偉達 CEO 黃仁勳説得很直白，對華限制「非常痛苦」，「我們將失去一個規模巨大的增長市場」。&lt;/p&gt; 
 &lt;p&gt;英偉達 2025 財年報告顯示，它在中國大陸（含中國香港地區）收入 171 億美元，同比增長 66%，相當於每天入賬 3.3 億人民幣。&lt;/p&gt; 
 &lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;禁售之後，官方售後也失效&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;屢次禁售帶來兩個直接後果：&lt;/strong&gt; 第一，中國公司再也買不到新的英偉達高端 AI 芯片（A100/H100/H800/H20 等）。第二，更重要的是，連那些已經在中國數據中心裏運行的、價值數百萬一台的 A100/H100 服務器，也失去了官方的售後保障。&lt;/p&gt; 
 &lt;p&gt;「原廠」或 OEM 官方維修路徑理論上存在，但實際上極其困難，原路返回就是最大的障礙。這些設備很多是通過非官方渠道（例如轉口貿易、灰色市場）進入中國的。將它們運回原廠（通常在美國或中國台灣等地區）進行維修，需要面臨極其複雜的出口管制合規審查，幾乎不可能獲得許可。&lt;/p&gt; 
 &lt;p&gt;就算設備有正規來源並能完成極其繁瑣的合規手續進行返修，整個流程（物流、合規審查、排隊、維修、再進口）耗時很長，短則 3 月，長則半年。&lt;/p&gt; 
 &lt;p&gt;所以，對於受限的英偉達高端數據中心 GPU/HGX 模組，在中國獲得有效、及時、可靠的「官方」售後服務基本不存在，即使有，需付出代價也會高昂到無法接受。&lt;/p&gt; 
 &lt;p&gt;在禁售令生效前，大量的 A100/H100 及其系統已被採購並部署在各種數據中心（尤其是大模型訓練集羣）。這對於租賃或自用的算力服務商來説，設備宕機意味着巨大的收入損失，半年收益可能為 0。&lt;/p&gt; 
 &lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;GPU&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;維修，一筆百億元的產業&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;巨大的需求和官方服務的真空，催生了一個龐大的第三方&lt;/strong&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;strong&gt;維修產業。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;捷智算是一家位於深圳的 GPU 維修企業，其銷售總監李玉俠表示，從客戶下單到維修完成，通常只需要 7 至 15 天。維修一張高端數據中心 GPU 的費用通常在數千到數萬元人民幣不等，這取決於損壞程度、是否需要更換核心等高價值部件。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;有人根據&lt;/strong&gt;&lt;strong&gt;保有量&lt;/strong&gt;&lt;strong&gt;以及故障率預測，認為這可能是一筆百億元的產業。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;儘管國內 A100/H100 的保有量是核心機密，但普遍認為在數百萬張級別。&lt;/p&gt; 
 &lt;p&gt;據業內人士預估，從 2023 年到至今，H100、H800、H200、H20 等 GPU 是智算中心建設的主力採購型號，NVLink 整機形態（機頭+HGX 模組）產品的出貨量巨大，保守估計國內存量約為 400 萬片。其中僅 H20 在最近一年多時間內，出貨量就高達 200 萬片。考慮其他 OEM 整機和更早型號，如 V100 等仍有價值，總量龐大。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;據公開報告顯示，GPU 服務器的年故障率因使用強度、散熱條件和維護水平而異，一般在 1%-5%。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;而英偉達的 H 系列因其高性能設計，在 AI 訓練等密集計算任務中故障率還會更高。據 Meta 公開的數據顯示，H100 GPU 集羣在訓練 Llama 3 模型的極端負載下，單塊 GPU 在高強度使用下的年度故障率約為 9%，三年累計故障率可能達到 27%。有業內人士預估，如果維修一塊 H100 GPU 收費 2 萬，每年 10 萬卡的維修需求，就有約 20 億的市場空間。&lt;/p&gt; 
 &lt;p&gt;這麼算下來，幾百萬張卡的維修市場，説是百億元的產業並不為過。&lt;/p&gt; 
 &lt;p&gt;不過，這百億元產業，很大一部分都要落到深圳的兜裏了。深圳是國內乃至全球重要的高端 GPU 第三方維修中心。&lt;/p&gt; 
 &lt;p&gt;這都要歸功於深圳華強北打下的基礎。華強北是全球聞名的電子元器件集散地和電子產品維修/翻新中心，擁有極其完備的電子產業鏈。海量的技術工人——特別是芯片級維修工程師，以及強大的元器件供應鏈，包括拆機件、翻新件、兼容件，雖然部分來源可能存疑。&lt;/p&gt; 
 &lt;p&gt;長期維修手機、主板、顯卡等精密電子設備，積累了豐富的 BGA 焊接、芯片植球、電路板飛線、故障診斷等高難度維修技術。這些技術可以直接遷移到 GPU 維修上。&lt;/p&gt; 
 &lt;p&gt;當然了，第三方維修並非沒有後顧之憂。由於維修所需的高端 GPU 核心（裸 Die）等關鍵部件，官方渠道不可能提供。維修點主要依賴拆解報廢卡、從其他故障卡回收、或者通過非正規渠道（可能涉及走私或侵犯知識產權）獲取。這是產業最大的灰色地帶和法律風險。&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;即使是頂尖技術團隊操刀，經過維修的 GPU 的穩定性、壽命、性能可能與原廠有差距。維修本身也可能導致設備失去官方保修（儘管在禁售後這已無意義）。&lt;/p&gt; 
 &lt;p&gt;美國層層加碼的芯片禁售令，不僅卡住了中國獲取新 AI 芯片的脖子，還讓中國公司之前買到的數百萬張高端 GPU 失去了官方維修。不過，正是這個‘修不了’的大麻煩，直接催生了一個年規模可能達百億人民幣的第三方 GPU 維修產業，而深圳成了這個產業的核心。&lt;/p&gt; 
 &lt;p&gt;據悉，英偉達又獲準向中國出口 H20 芯片。這來來回回的禁售與放開之間，GPU 維修間的壓測機在晝夜不停地工作，很多維修點的訂單已經排到了半個月後。&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p&gt;參考鏈接：&lt;/p&gt; 
 &lt;p&gt;1、GPU Lifetimes on Titan Supercomputer：Survival Analysis and Reliability&lt;/p&gt; 
 &lt;p&gt;https://christian-engelmann.de/publications/ostrouchov20gpu.pdf&lt;/p&gt; 
 &lt;p&gt;2、Datacenter GPU service life can be surprisingly short — only one to three years is expected according to unnamed Google architect&lt;/p&gt; 
 &lt;p&gt;https://www.tomshardware.com/pc-components/gpus/datacenter-gpu-service-life-can-be-surprisingly-short-only-one-to-three-years-is-expected-according-to-unnamed-google-architect&lt;/p&gt; 
 &lt;p&gt;3、Compared to the H100, how does the performance of NVIDIA's AI chips specially designed for China, fare?&lt;/p&gt; 
 &lt;p&gt;https://longportapp.com/en/news/102150690&lt;/p&gt; 
 &lt;p&gt;4、一文了解 H 系列機型質保、故障、維修哪些事&lt;/p&gt; 
 &lt;p&gt;https://mp.weixin.qq.com/s/jq6B-HZHEKW3hcopO3YQEQ&lt;/p&gt; 
 &lt;p&gt;5、H 系列 GPU 維修的生意火了！&lt;/p&gt; 
 &lt;p&gt;https://mp.weixin.qq.com/s/jLpwOrDv5SDzFnzQFYOu2Q&lt;/p&gt; 
 &lt;p&gt;6、黃仁勳回應爭議，英偉達在中美博弈中找到微妙平衡&lt;/p&gt; 
 &lt;p&gt;https://finance.sina.com.cn/stock/relnews/us/2025-07-16/doc-inffsnhq2777954.shtml&lt;/p&gt; 
 &lt;p&gt;7、Chinese Firms Including ByteDance, Alibaba Place $16 Bn NVIDIA GPU Orders: Reports&lt;/p&gt; 
 &lt;p&gt;https://analyticsindiamag.com/ai-news-updates/chinese-firms-including-bytedance-alibaba-place-16-bn-nvidia-gpu-orders-reports/&lt;/p&gt; 
 &lt;p&gt;8、H20 芯片重返中國市場&lt;/p&gt; 
 &lt;p&gt;https://finance.sina.cn/tech/2025-07-18/detail-inffvhce4759535.d.html?fromtech=1&amp;amp;vt=4&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18685123</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18685123</guid>
      <pubDate>Fri, 18 Jul 2025 11:48:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>SwiftFormat —— 格式化 Swift 代碼</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#24292f"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;SwiftFormat 是一個代碼庫和命令行工具，用於在 macOS 或 Linux 上重新格式化 Swift 代碼。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#24292f"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;SwiftFormat 除了調整空格之外，它還可以插入或刪除隱式&lt;code&gt;self&lt;/code&gt;、刪除多餘的括號，並糾正許多其他與標準 Swift 習語的偏差。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;SwiftFormat 的配置分為&amp;nbsp;&lt;strong style="color:#24292f"&gt;rules&amp;nbsp;&lt;/strong&gt;和&amp;nbsp;&lt;strong style="color:#24292f"&gt;options&lt;/strong&gt;。&lt;span style="background-color:#ffffff; color:#24292f"&gt;Rules&lt;/span&gt;&amp;nbsp;是 SwiftFormat 庫中的函數，用於將更改應用於代碼。&lt;span style="background-color:#ffffff; color:#24292f"&gt;Options&lt;/span&gt;&amp;nbsp;是控制 rules 行為的設置。&lt;/p&gt;

&lt;p&gt;SwiftFormat 包含超過 50 條 rules，並且一直在添加新 rules。可以在&amp;nbsp;&lt;a href="https://github.com/nicklockwood/SwiftFormat/blob/master/Rules.md"&gt;Rules.md 中&lt;/a&gt;找到最新列表以及有關如何使用它們的文檔。&lt;/p&gt;

&lt;p&gt;SwiftFormat 主要被設計為一個格式化程序而不是 linter，即它旨在修復你的代碼，而不是告訴你代碼出了什麼問題。但是，有時在不希望實際改變代碼的情況下，驗證代碼是否已被格式化會很有用。&lt;/p&gt;

&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;span style="background-color:#ffffff"&gt;目前，SwiftFormat 適用於 macOS 10.13 (High Sierra) 及更高版本，也適用於 Ubuntu Linux。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/swiftformat</link>
      <guid isPermaLink="false">https://www.oschina.net/p/swiftformat</guid>
      <pubDate>Fri, 18 Jul 2025 10:10:00 GMT</pubDate>
    </item>
    <item>
      <title>Gitee AI MCP Server 上線：在 Cursor 裏玩 AI 生圖 + 語音</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;模力方舟現已上線&amp;nbsp;&lt;strong&gt;Gitee AI MCP Server&lt;/strong&gt;，為 AI 助手和多模態應用提供統一的上下文協議（Model Context Protocol, MCP）接入能力，目前已支持文本生成圖片與語音兩項功能。&lt;/p&gt; 
&lt;p&gt;MCP 是幹什麼的相信大家已經很熟悉了，那麼&lt;strong&gt;話不多説，先看效果&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/174720_hnOw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這張圖展示了使用 Gitee AI MCP Server 在 Cursor 客戶端中完成&lt;strong&gt;「AI 生成項目 Logo 並自動加入項目目錄」&lt;/strong&gt;的完整流程：&lt;/p&gt; 
&lt;p&gt;1️⃣&amp;nbsp;&lt;strong&gt;調用 MCP 服務生成圖片&lt;/strong&gt;：AI 根據用戶輸入，通過 text-to-image 接口生成圖像，並返回公網 URL；&lt;/p&gt; 
&lt;p&gt;2️⃣&amp;nbsp;&lt;strong&gt;自動下載圖片並保存&lt;/strong&gt;：通過 wget 命令將圖片保存至項目本地目錄（assets/logo.png）；&lt;/p&gt; 
&lt;p&gt;3️⃣&amp;nbsp;&lt;strong&gt;智能插入引用代碼&lt;/strong&gt;：AI 自動將圖片路徑添加至 index.html 和 README.md，分別用於頁面展示與項目文檔；&lt;/p&gt; 
&lt;p&gt;4️⃣&amp;nbsp;&lt;strong&gt;圖片成功渲染&lt;/strong&gt;：最終圖像正確加載，展示在頁面中，形成清晰的視覺輸出。&lt;/p&gt; 
&lt;p&gt;這正是 Gitee AI MCP Server 在實際開發流程中「即插即用」的真實寫照：圖像生成、文件管理、代碼修改，用 AI 一氣呵成。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;除了 Cursor 外，Gitee AI MCP Server 還支持 Claude Code 和 Cherry Studio 等支持 MCP 協議的 AI 工具。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;對於還不熟悉 MCP 的同學，接下來就聽聽馬建倉的詳細介紹：&lt;/p&gt; 
&lt;h4&gt;什麼是 Gitee AI MCP Server？&lt;/h4&gt; 
&lt;p&gt;Gitee AI MCP Server 是一項專為模力方舟設計的模型上下文協議服務，支持通過 MCP 協議接入多媒體模型，包括圖像生成和語音合成工具。它可集成到 Cursor、Claude Desktop 等 AI 工具中，&lt;strong&gt;幫助 AI 助手「看得見、講得出」&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;兩大核心能力：文本生成圖片與語音&lt;/h4&gt; 
&lt;p&gt;🖼&amp;nbsp;&lt;strong&gt;文本生成圖片&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持模型：如&amp;nbsp;&lt;code&gt;stable-diffusion-3.5-large-turbo&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可設定圖像尺寸、參考圖像（URL 或 Base64）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;輸出格式靈活（Base64、URL 鏈接）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持用戶 ID 追蹤與內容定向&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🔊&amp;nbsp;&lt;strong&gt;文本生成語音&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持模型：如&amp;nbsp;&lt;code&gt;whisper-large-v3-turbo&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;輸出格式支持 MP3、WAV，支持二進制流或臨時 URL&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;URL 鏈接有效期為 1 小時，適合集成即時內容播報場景&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;快速接入指南&lt;/h4&gt; 
&lt;p&gt;1.登錄模力方舟獲取訪問令牌（Access Token）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/174835_XPrS_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2.在支持 MCP 的客戶端中配置：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"gitee-ai": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"https://ai.gitee.com/mcp/sse",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"headers": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Authorization":&amp;nbsp;"Bearer &amp;lt;your_access_token&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;以 Cursor 為例：&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;1️⃣ 進入設置-添加新的 MCP Server&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/174851_3Vqd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2️⃣ 填寫配置文件+訪問令牌&lt;strong&gt;並保存&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/174912_yS8Z_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;3️⃣ 顯示為綠色即加載成功，快去試試吧！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/174934_QqDI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;配置完成後，你就可以在日常使用 AI 助手時，直接調用圖像和語音生成功能。例如在寫技術文檔時一鍵生成配圖、給項目介紹加上語音旁白，甚至批量產出社媒圖文組合內容。&lt;/p&gt; 
&lt;p&gt;不管你是在 Cursor 或 Claude Desktop 中使用 AI 助手，還是在自己的項目中集成多模態能力，Gitee AI MCP Server 都能為你提供你快速接入圖像與語音能力。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;查看文檔：&lt;/strong&gt;&lt;a href="https://ai.gitee.com/docs/best-practice/mcp" target="_blank"&gt;https://ai.gitee.com/docs/best-practice/mcp&lt;/a&gt;，瞭解更多有關 Gitee AI MCP Server 的詳細信息。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361064</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361064</guid>
      <pubDate>Fri, 18 Jul 2025 09:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>邦彥雲 PC 亮相都江堰，以全棧信創能力共築安全辦公</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0864df9de090ae6a0dc887e518154360.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;2025 年 7 月 17 日,一場以 「破局密碼安全壁壘，搶佔國產化新賽道」 為主題的 「網聯雲匯 2025 年中感恩盛典」 在世界文化遺產地都江堰盛大舉行。此次盛會匯聚了 100 多位信創產業鏈代表、核心代理商及生態夥伴,眾人聚焦 「國產化 + 數據安全」 這一核心議題深入探討。邦彥技術股份有限公司 (股票代碼:688132) 受邀參會,並攜邦彥雲 PC 新一代桌面雲解決方案精彩亮相,集中展示了面向政企用戶的全棧信創能力與豐富的落地實踐成果。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//7829804fe20db667b82ba7bc5c811159.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f2dd67c179bfa92a5cebdd5dcbfbd1fe.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;會議期間,邦彥技術資深解決方案經理餘洋針對邦彥雲 PC 的特性與應用場景進行了分享。他指出:「信創替代絕非簡單的‘換芯’工程,而是安全、體驗、運維、合規的四重升級。」 這一觀點精準點出了當前信創領域的核心訴求。並在接下來的演講環節中,針對 「產業痛點—技術破局—生態共贏」三個維度進行了深度剖析:&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;痛點剖析&lt;/strong&gt;:傳統 PC 數據分散、運維複雜,VDI 雲桌面性能不足、外設兼容性差;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;技術破局&lt;/strong&gt;:邦彥雲 PC 通過「計算刀片+數據中心集中部署」實現性能、安全、體驗的三重突破;在性能層面,可媲美高端本地 PC,輕鬆應對設計製圖、數據建模等高要求任務。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;生態共贏&lt;/strong&gt;:邦彥雲 PC 支持國產飛騰 / 海光 CPU 混插,可兼容不同架構的處理器,滿足用戶從部分替代到全面國產化的過渡需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//71000a439c51b6a21ffaf0845d0bf2ec.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;全棧信創:硬件、&lt;/strong&gt;&lt;strong&gt;系統&lt;/strong&gt;&lt;strong&gt;、&lt;/strong&gt;&lt;strong&gt;應用&lt;/strong&gt;&lt;strong&gt;三位一體&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面對行業信創替代的大趨勢,邦彥雲 PC 已完成「芯—板—卡—OS—應用」全鏈路國產化適配:&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;處理器&lt;/strong&gt;支持海光、飛騰等國產 X86 與 ARM 架構,可與存量 Intel 平台混插,平滑過渡。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;操作系統&lt;/strong&gt;兼容銀河麒麟、統信 UOS 及多家國產桌面 OS,內置集中管控策略,實現開機即合規。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;應用生態&lt;/strong&gt;&lt;strong&gt;方面&lt;/strong&gt;已完成 200 餘項互認證,覆蓋公文處理、版式簽章、即時通訊、設計製圖等高頻場景。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//353b5c02394275905089d71ec9795365.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;多網並行:一人多機、雙屏&lt;/strong&gt;&lt;strong&gt;顯示&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;針對政務、金融、電力等行業「多網隔離」合規要求,邦彥雲 PC 獨創「一人多機」架構:單個用戶賬號可同時綁定五塊計算刀片,分別接入內網、外網、專網、研發網、測試網等不同安全域。終端支持雙屏輸出,鼠標橫移即可在兩塊屏幕間瞬時切換,無需多套鍵鼠,既滿足「人隨網走」的業務靈活度,又保持「網隨人控」的安全邊界。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;數據不落地:前端零存儲、後端多副本&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;所有用戶數據集中存儲於數據中心 NAS,採用容災架構,保障業務連續性不中斷;前端雲終端禁用 USB 數據寫入,僅開放只讀或白名單外設,真正做到「數據不落地、外設可審計」。結合算法鏈路加密,形成「端—管—雲」縱深防禦體系。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a70d398e73609a0a9131e36a43020ae4.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//117ac27a081d88e15b541d92d9cca1fb.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cc84524962043aee21864f0196cab349.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//40e1974d345fa35451e4cdc8b1fb45aa.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;會議期間邦彥雲 PC 展區同樣也吸引了眾多觀眾前來體驗,不少嘉賓親測了邦彥雲 PC 的極致性能,感受雲上真機、移動辦公、多網辦公等順暢體驗。並對產品的靈活性、安全性和高效性給予了充分肯定。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;目前,邦彥雲 PC 已在政府、金融、教育、醫療、電力等關鍵行業規模化部署。「國產化不是選擇題,而是必答題。」邦彥雲 PC 以極致性能與極致安全給出高分答案,未來邦彥技術將繼續攜手芯片、OS、應用、安全等全產業鏈夥伴,在信創新賽道上加速奔跑,為中國數字經濟高質量發展貢獻邦彥力量。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361063</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361063</guid>
      <pubDate>Fri, 18 Jul 2025 09:48:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>美團開源 OIBench 與 CoreCodeBench</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;Meituan-M17 團隊聯合上海交大等機構，分別推出了 OIBench（聚焦高區分度算法題評測）與 CoreCodeBench（聚焦多場景工程級代碼基準）兩大數據集，旨在揭示大模型編程能力真實水平，這兩大數據集已分別在 GitHub 和 Huggingface 上進行開源。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-03ba67b8aecb4f3bfded919a2a68ff949fc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;當前，大語言模型（LLMs）在編程領域的能力宣稱引人矚目——DeepMind 的 AlphaCode 曾對標人類競技編程選手，OpenAI 頂尖模型屢被報道通過谷歌面試、挑戰 LeetCode 表現不俗。然而，當深入審視這些模型在真實、複雜場景下的表現時，現有評估體系的深層侷限性便暴露無遺，形成了顯著的「宣傳與現實的認知鴻溝」。&lt;/p&gt; 
&lt;p&gt;一方面，在&lt;strong&gt;算法能力評估&lt;/strong&gt;上，儘管模型在傳統基準（如 HumanEval、MBPP）上通過率高達 90%，但移植到更高難度的信息學奧賽或 Codeforces Div.2 C 級題目時，頂尖模型的通過率驟降至個位數或不足 15%，遠遜於人類選手（如 ACM 校隊成員平均 70%），動態規劃等題型錯誤率甚至超 80%。傳統評測集已「飽和」且區分度不足，新引入的高難度題目又面臨數據「泄漏」風險和人機對比（Elo）的復現性差、效率指標粗略等問題。&lt;/p&gt; 
&lt;p&gt;另一方面，轉向&lt;strong&gt;真實工程能力評估&lt;/strong&gt;，問題同樣嚴峻。現有工程基準（如 FullStackBench、SWEBench）雖在多樣性和語言覆蓋上有進展，但其任務類型主要集中於單段落代碼生成，難以覆蓋真實開發中跨文件協作、代碼修復（BugFix）、測試驅動開發、多函數協同等核心環節。數據構建方法也受限於隨機挖空（易忽略核心邏輯）或依賴稀缺的 GitHub PR 記錄（需大量人工清洗標註），導致評測「偏科」，無法科學、全面地評估模型在複雜工程中的準確性、健壯性和適用性。&lt;/p&gt; 
&lt;p&gt;為了系統性地解決這兩大評估困境——&lt;strong&gt;更真實地衡量頂尖模型的算法推理能力與更全面地評估其工程級代碼能力&lt;/strong&gt;——Meituan-M17 團隊聯合上海交大等機構，分別推出了 OIBench（聚焦高區分度算法題評測）與 CoreCodeBench（聚焦多場景工程級代碼基準）兩大數據集，並託管於 AGI-Eval 評測社區。下文將詳細介紹它們的構建理念、評測方法及對主流大模型能力的深度剖析。&lt;/p&gt; 
&lt;h1&gt;OIBench 篇&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/707a2d1d2bf198c2510043dcd4fb1663877512.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;背景：評測集侷限性的深層分析&lt;/h2&gt; 
&lt;p&gt;儘管 GPT-4o 模型被冠以 "競賽級" 頭銜，甚至有聲音稱其算法水平接近 ACM 區域賽金牌選手，但實際在面對未經大量公開數據訓練的、更高難度的信息學奧賽級別問題時，其通過率卻往往低至個位數，與 985 級別高校 ACM 校隊成員的平均通過率存在顯著差距。&lt;/p&gt; 
&lt;p&gt;當部分評測宣稱 Claude 3.5 Sonnet 可替代中級開發人員時，它在動態規劃等高難度題型中錯誤率卻高達 80% 以上，且無法獨立完成需數學建模的複雜競賽題。&lt;/p&gt; 
&lt;p&gt;諸如文心一言、通義千問等模型在 MBPP 基礎題庫中通過率可達 90% 以上，但移植至 Codeforces Div.2 C 級題目時，通過率卻不足 15%，遠低於人類選手平均 70% 的水平。&lt;/p&gt; 
&lt;p&gt;這些鮮明的對比，共同指向一個核心問題：當前對 LLM 編程能力的評估，存在明顯的 "宣傳與現實的認知鴻溝"。這種差異不僅源於模型能力邊界的複雜性，也暴露出現有評估體系的諸多侷限性。具體表現為：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;評測集 「飽和」 與區分度不足&lt;/strong&gt;：傳統評測集（如 HumanEval、MBPP）由於模型能力的快速提升，通過率普遍超過 90%，已無法有效區分最先進模型的細微優劣。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據 「泄漏」 風險&lt;/strong&gt;： 儘管一些新評測集（如 Codeforces、USACO、LeetCode）引入了高難度題目，但由於大模型預訓練數據包含大量互聯網公開內容，這些題目可能已被模型 「見過」，導致評測結果虛高，無法真實反映其推理能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;人機對比的侷限性&lt;/strong&gt;：現有基於 Elo 評分體系的模型與真人選手對比方法，存在週期長、選手水平波動大、復現性差等問題，難以提供精確且可靠的評估。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;效率指標的粗略性： 部分評測雖引入運行時間、內存等效率指標，但通常僅為粗略的平均分，無法細緻反映模型在不同類型題目上的性能差異。&lt;/p&gt; 
&lt;p&gt;為瞭解決上述這些評估困境、評測出全球頂尖模型真實的編程能力，&amp;nbsp;Meituan-M17 團隊推出了&lt;strong&gt;更真實、更具區分度的評估基準 OIBench 數據集，並託管於 AGI-Eval 評測社區&lt;/strong&gt;，並在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fmeituan%2FOIBench" target="_blank"&gt;Huggingface&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAGI-Eval-Official%2FOIBench" target="_blank"&gt;GitHub&lt;/a&gt; 上開源。基於此數據集，我們對全球 18 個主流大模型的算法編程能力進行了系統評測並量化得分，詳細評分榜單如下所示，可以看到全球頂尖大模型距離以往所宣稱的編程能力還存在很大差距，哪怕是最高分的 o4-mini-high 也僅僅只有 36.35 分，距離人類競賽選手的水平還相差甚遠，甚至很多模型只有個位數的得分。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p1.meituan.net/meituantechblog/c15ae4d3cace0307a614ece0854b52e071970.png" alt="表 1: OIBench AC Rate 表" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 的評測榜單未來將由 AGI-Eval 評測社區長期維護更新，歡迎持續關注。榜單地址如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;網頁端地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagi-eval.cn%2Fevaluation%2Fdetail%3Fid%3D60" target="_blank"&gt;https://agi-eval.cn/evaluation/detail?id=60&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;微信公眾號文章&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqjZLqHVz-BxQweApyUEtDw" target="_blank"&gt;AGI-Eval 大模型評測&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;論文地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.10481" target="_blank"&gt;https://arxiv.org/abs/2506.10481&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Github 地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAGI-Eval-Official%2FOIBench" target="_blank"&gt;https://github.com/AGI-Eval-Official/OIBench&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文數據均引用自 OIBench v1.0 論文（arxiv:2506.10481v3），發佈日期 2025 年 6 月 13 日。&lt;/p&gt; 
&lt;p&gt;接下來為大家詳細介紹 OIBench 數據集是如何構建以及如何對大模型進行評測的。&lt;/p&gt; 
&lt;h2&gt;1. OIBench 的構建與創新&lt;/h2&gt; 
&lt;p&gt;OIBench 是一個高質量、私有且極具挑戰性的信息學奧賽級別算法題庫，旨在提供一個更真實、更具區分度的評估基準。該數據集的算法題主要來源於中國 ACM-ICPC 隊伍和信息學奧賽的高校教練團隊精心編纂，他們擁有豐富的高難度算法題設計經驗和獨到見解。&lt;/p&gt; 
&lt;p&gt;為了確保 OIBench 題目的高質量和高挑戰性，我們制定了三條嚴格的准入標準，OIBench 具備以下關鍵特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;原創性與私有性&lt;/strong&gt;：OIBench 包含 250 道候選題目，經難度驗證後保留 212 道高難度、防泄漏的信息學奧賽題目（IOI Level）。所有題目在發佈前都經過嚴格檢索，確保未在任何公開平台出現，最大程度避免數據污染風險。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;難度分級與把控&lt;/strong&gt;：每道題目都參照信息學競賽和 Codeforces 難度評級進行標註。同時，為避免主觀偏差，我們引入了自動化驗證機制 —— 只有當 GPT-4o、Qwen2.5-Coder-32B、Doubao-32k-pro、Llama3.1-405B 這幾個標杆大模型中 「最多隻有一個模型能解出」 時，該題才會被收錄，從而確保了題目的 「硬核」 難度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高標準測試用例與標準解答&lt;/strong&gt;：每道題都配備覆蓋大數據量、邊界情況等多樣的測試用例，力求暴露代碼在時間和空間上的潛在瓶頸。同時，每道題都必須配備經過所有測試用例嚴格驗證的 C++ 標準解答，以確保題目本身的準確性及評測的公正性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中英文雙語支持&lt;/strong&gt;： 數據集提供中英文雙語版本，方便全球大模型從業者使用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們還在論文中展示了 OIBench 與其他主流評測集的對比（見下表），可以看到 OIBench 在題目難度和測試用例規模上都相對更高。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/ad5a7a3767a8e629b0b759e2c2b7cea864999.png" alt="表 2: OIBench 與其他代碼評測集基礎統計信息表" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 在題目難度和測試用例規模上顯著領先於其他主流評測集。例如，在其他榜單上表現較好的 GPT-4o 模型在 OIBench 上僅能答對 2.6% 的題目，同時 OIBench 的測試用例數量大幅超過了其他算法競賽基準，對標真實的競賽環境。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p1.meituan.net/meituantechblog/18647fd505aefa45fcc54194188f0ef121519.png" alt="表 3: GPT-4o 模型在 OIBench 與其他評測集通過率對比表 " referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;強抗數據污染能力&lt;/strong&gt;：在評測集設計中，「同源污染」 是一個重要挑戰。由於大模型的預訓練和微調數據往往會爬取大量互聯網內容，容易出現模型在訓練階段就見過類似題目的情況，從而導致評測分數虛高，無法真實反映模型實際能力。雖然 OIBench 在數據構造時極力避免使用互聯網可公開檢索的題目，但一些相近的題目仍可能在大模型的預訓練或微調階段帶來數據污染。為此，我們專門設計了實驗來驗證 OIBench 的抗污染能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;具體做法&lt;/strong&gt;：我們從 OIBench 中抽取部分題目，模擬它們在模型訓練數據中 「泄漏」 的場景，並與常規訓練數據混合，對比模型在 OIBench 上的表現提升。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;實驗證明&lt;/strong&gt;：即使模擬少量題目 「泄漏」 到模型的訓練數據中，OIBench 的得分提升也極為有限，風險分數幾乎為零，表明其對數據污染具有很強的魯棒性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;2. OIBench 評測結果與發現&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;參評模型與評測方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 對 18 個主流大模型（包括 14 個指令微調模型和 4 個基礎模型）進行了 zero-shot 評測，涵蓋 C++、Python、Java、JavaScript 四種語言。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/eb24e8bc42ce3120a20be682dae41ff3240284.png" alt="表 4:  OIBench 上基座模型、指令微調模型、推理模型的表現" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主榜單結果&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;推理模型表現突出&lt;/strong&gt;：推理類模型（如 o4-mini-high）在 OIBench 上的平均得分高達 21.4%，遠高於普通指令微調模型（約 3.6%）。這表明 OIBench 能有效區分模型的推理和鏈式思考能力，且 o4-mini-high 在所有語言和任務上表現最優。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;閉源模型優勢明顯&lt;/strong&gt;：閉源模型平均得分 14.5%，顯著高於開源模型（6.3%），這主要得益於閉源模型在算力和數據質量上的優勢。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基礎模型決定上限&lt;/strong&gt;：指令微調模型在 OIBench 上的表現高度依賴其基礎模型的能力，説明基礎模型的預訓練質量是決定代碼能力的關鍵。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek-V3-0324 的亮點&lt;/strong&gt;：作為非推理模型，DeepSeek-V3-0324 表現突出，得益於其採用了 DeepSeek-R1 的鏈式推理蒸餾方案，推理能力大幅提升。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;語言偏好與中英文差異&lt;/strong&gt;： 模型在 JavaScript 和 Python 上的表現平均比 C++ 和 Java 低 10% 以上，可能與訓練數據分佈有關；中英文題目表現差異極小，甚至中文略優。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;偽代碼（Pseudocode）提示的積極作用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 的高難度對普通模型來説挑戰巨大。為了更細緻地分析模型的能力，我們還引入了 「偽代碼提示」 評測：將標準解答轉為偽代碼並作為提示輸入，考查模型理解和復現解題思路的能力。&lt;/p&gt; 
&lt;p&gt;結果顯示，所有模型在有偽代碼提示時表現均有明顯提升，尤其是強推理模型（如 o3-mini-high 和 o4-mini-high）提升尤為顯著。這説明偽代碼極大降低了題目的推理難度，更能考查模型的代碼理解與生成能力。同時，推理模型在理解解題思路方面依然具備優勢。進一步分析發現，指令微調模型的表現與其基礎模型高度相關，説明代碼生成能力主要取決於預訓練水平。&lt;/p&gt; 
&lt;p&gt;在提供偽代碼提示後，所有模型表現均有明顯提升，尤其是強推理模型，這説明偽代碼能有效降低推理難度，更能考查模型的代碼理解與生成能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推理效率&lt;/strong&gt;：隨着 「測試時推理」 成為提升大模型能力的重要手段， OpenAI-o1、DeepSeek-R1 等模型在解題時會生成大量推理內容。我們統計了各模型推理時的 Token 消耗與通過率的關係，發現 o4-mini-high 能以更少的 Token 解出更多題目，推理效率最高；DeepSeek-V3-0324 雖然表現不俗，但推理 Token 數量也最多，體現其長鏈推理的特點。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/ea497e4d24ab1e6451de79600bcf9a9d150460.png" alt="圖 1: OIBench 模型通過率與推理消耗 Token 量關係圖" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3. 模型與人類選手的對比&lt;/h2&gt; 
&lt;p&gt;許多技術人員都關心：現在的大語言模型在算法編程題上的表現，和真正的競賽選手相比到底如何？OpenAI、 DeepSeek 會用線上編程平台 Codeforces 的 Elo 評分體系來做模型與人類的對比，並報告自家模型最新的 Elo 分數，但這種方式存在一些問題：比如數據時間跨度長（一般需要半年以上的參賽記錄）、在線選手水平波動大，導致對比結果不夠精確，也不容易復現。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OIBench 創新性地採用了更可控的方法&lt;/strong&gt;：邀請了中國 985 級別高校 ACM 校隊選手參與部分題目的作答，並將其成績與大模型直接對比，提供了更精準、可復現的人機對比數據；我們用小提琴圖展示了每個模型在所有人類選手中的排名分佈，能直觀反映模型與人類在不同題目上的表現差異。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排名規則參考了信息學奧賽（IOI）的標準&lt;/strong&gt;：先比較通過的測試用例數量，數量相同則按運行時間排序（越快越高）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;提交標準&lt;/strong&gt;：人類選手的答案以最後一次提交為準。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;人類解答開源&lt;/strong&gt;: 分析中所涉及的人類解答記錄也將匿名化並開源，便於後續研究和復現。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/364b49bcc6369d303486297b86de3364257727.png" alt="圖 2: 模型與人類選手的對比關係圖" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在小提琴圖中，各模型在每道題中的人類排名位置會作為一個數據點，這些數據點形成的概率密度圖就是小提琴圖中的「琴身」。「琴身」的寬度顯示模型排名分佈的密度，越寬表示模型在對應的排名區間內出現的頻率越高，從而直觀地反映出模型排名表現的集中趨勢。中央的框線代表排名數據最集中的區域，以 o4-mini-high 舉例，它的排名大致超過了 42% 的人類選手。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三種類型的模型表現&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;低谷型&lt;/strong&gt;： 多數題目排名靠後，只能超越不到 20% 的人類選手，多為沒有長鏈推理能力的模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;雙峯型&lt;/strong&gt;： 在部分題目上能超越一半人類選手，但在另一些題目上表現較差，多數支持長鏈推理的模型屬於此類型，顯示其在特定題型上的優勢和短板。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;橄欖型&lt;/strong&gt;： 排名分佈更均勻，表現更接近人類整體能力分佈，目前只有 o4-mini-high 具備這種全面和穩定的推理特徵。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;4. OIBench 總結與展望&lt;/h2&gt; 
&lt;p&gt;本文深入分析了當前大模型編程能力評估中存在的認知鴻溝，揭示了 "宣傳" 與 "現實" 之間的差距。Meituan-M17 團隊，通過 OIBench 這一高質量、高區分度的私有數據集，清晰揭示了頂級 LLM 在面對複雜算法挑戰時，與人類頂尖水平之間的真實差距。不僅為大語言模型的算法推理能力評測樹立了一個全新標杆，也為整個行業帶來了更多思考。&lt;/p&gt; 
&lt;p&gt;它讓我們看到：即使在模型能力突飛猛進的今天，真正高質量、高難度的算法挑戰依然能夠 "難倒" 最先進的 AI。尤為重要的是，希望 OIBench 的開源和透明能夠為社區協作和持續創新做出一些貢獻。我們期待它能成為連接學術、產業和開發者的橋樑，推動大模型在算法智能領域邁向新高度。未來，隨着模型能力和評測需求的不斷演進，OIBench 也會持續迭代，與大家共同見證 AI 推理的進化之路。&lt;/p&gt; 
&lt;p&gt;與此同時，我們也觀察到，對於大多數人類開發者來説，即使他們接受過專業的算法設計訓練，面對高難度算法和複雜系統設計，同樣需要工具和智能助手的輔助才能更上一層樓。大模型的強大推理和代碼生成能力，正好能為人類開發者提供有力支持，幫助他們提升算法設計和代碼實現的效率。OIBench 促使我們深入思考：&lt;strong&gt;未來的代碼開發，已超越 "人" 或 "模型" 單打獨鬥的模式，轉變為人機協同、優勢互補的新範式&lt;/strong&gt;。&lt;/p&gt; 
&lt;h1&gt;CoreCodeBench 篇&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ceb6f19f2da88e2f684c177f14580a6a10d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;背景：工程級代碼評估的挑戰&lt;/h2&gt; 
&lt;p&gt;研究發現，現有的代碼基準數據集在面對複雜的工程場景時普遍存在缺乏多樣性和可控性的雙重問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;工程開發環節覆蓋有限&lt;/strong&gt;：儘管現有基準（如 FullStackBench、SWEBench）在領域和語言多樣性上取得進展，但其任務類型仍主要集中於單段落代碼生成。而真實工程實踐通常涉及跨文件、跨模塊的協同，以及代碼修復、測試驅動開發、多函數協作等複雜任務，這些都應被工程級基準全面覆蓋。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據構建方法侷限&lt;/strong&gt;：大多數數據集採用隨機挖空或從代碼倉庫的歷史&amp;nbsp;PR&amp;nbsp;記錄中提取修改點（如 GitHub 的 Pull Request）。前者容易忽略項目的核心邏輯代碼段，後者不僅數據量稀少，還需投入大量人工進行數據清洗和標註，難以規模化構建高質量的評測題目。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;總之，我們發現現有的代碼基準測試大多「偏科」了。它們要麼只關注單個函數的補全，忽略了開發者修復 Bug 、根據單元測試反向開發的真實場景；要麼採用隨機挖空的方式，難以觸及代碼的核心邏輯。這導致我們無法科學、完整、全面地測評 LLM 在真實工程場景中的代碼能力，尤其是在可靠性和適用性方面，我們亟需一個能解決此難題的方案。&lt;/p&gt; 
&lt;p&gt;為了應對上述挑戰，&amp;nbsp;Meituan-M17 團隊、上海交大聯合發佈了一個全新的&lt;strong&gt;大模型工程級別代碼基準測試&amp;nbsp;CoreCodeBench 數據集，託管到 AGI-Eval 社區&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CoreCodeBench 榜單地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagi-eval.cn%2Fevaluation%2Fdetail%3Fid%3D64" target="_blank"&gt;https://agi-eval.cn/evaluation/detail?id=64&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;微信公眾號文章&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FihNeyk1RauSUicBcGWI2pA" target="_blank"&gt;AGI-Eval 模型評測&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;論文預印版&lt;/strong&gt;：《CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark》。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/6db13f36c76ac08f4e76f2301112430f132450.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;論文地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Farxiv.org%2Fabs%2F2507.05281" target="_blank"&gt;http://arxiv.org/abs/2507.05281&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub 地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAGI-Eval-Official%2FCoreCodeBench" target="_blank"&gt;https://github.com/AGI-Eval-Official/CoreCodeBench&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;它專注於評估大語言模型在真實工程項目中的綜合代碼能力，覆蓋了從代碼開發到代碼修正的多個核心階段。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/d00f4a444d9cce46b92a9ca1c04ff32b141353.png" alt="圖 3: CoreCodeBench 題型展示" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p1.meituan.net/meituantechblog/e7d7f6245abec170dad5a1910d4aecf963987.png" alt="圖 4: CoreCodeBench 模型能力榜單" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過在 CoreCodeBench 上對當前主流大語言模型的全面評測，我們得出了以下關鍵結論：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;大模型編程能力迭代進步顯著，但發展不均衡&lt;/strong&gt;：較新的模型 {如 Claude 3.7 、o4 mini（high）} 相較於前代產品表現出明顯進步。然而，受測模型在代碼修正（BugFix）任務上表現欠佳，尤其是單函數任務場景下，修正任務的成功率全部低於開發任務，這揭示了當前 LLM 在理解和修復深層邏輯錯誤方面存在的普遍短板。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多函數協作是當前大模型編程場景的主要瓶頸&lt;/strong&gt;：幾乎所有模型在處理多函數任務時的表現都顯著劣於單函數任務。這表明，當需要同時處理多個函數間的依賴關係、調用邏輯和協同實現時，當前大模型的跨函數推理和規劃能力尚顯不足。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大模型編程場景普遍缺乏靈活的規劃與分層推理能力&lt;/strong&gt;：在多函數代碼生成任務中，我們觀察到大多數模型嚴格遵循輸入提示中的函數順序生成代碼，而非像人類工程師那樣，基於功能依賴（如先實現被調用的工具函數）進行優化。這一現象反映了當前模型在面對複雜任務時，傾向於採用默認的順序策略，缺乏主動規劃的意識。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;1. 基準構建方法與實驗分析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;數據集構建方法：CorePipe 流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了構建一個既關注多樣化工程問題，又聚焦於核心代碼的基準，CoreCodeBench 中設計了從工程代碼倉庫到多種函數題型的全自動化構建流程 CorePipe。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/c0fafa80ae9fcd7b85d7bca671ec2934319541.png" alt="圖 5: CorePipe 自動化生產數據流程示意圖" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，CorePipe 基於函數調用樹，系統化地生成覆蓋三大核心場景的單函數與多函數題目，確保每一道題目都直擊「要害」：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;精選真實項目&lt;/strong&gt;：我們從 PyPI 對應的 GitHub 倉庫中篩選出高活躍度、高測試覆蓋率和高技術複雜度的頂級開源項目。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;定位核心代碼&lt;/strong&gt;：通過動態和靜態追蹤代碼的執行，我們首先構建函數調用圖，再利用抽象語法樹（AST）抽取出關鍵函數中的核心代碼，精準定位項目中那些「牽一髮而動全身」的核心代碼塊。我們能精準定位項目中那些「牽一髮而動全身」的核心函數。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模擬三大真實場景&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;直接開發&lt;/strong&gt;（Development）：&amp;nbsp;不僅僅是填空，我們利用 GPT-4o 生成高質量的函數功能描述，並由 Claude 3.5 Sonnet 進行「挑刺」和審核，確保模型是在理解真正需求的前提下進行開發。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;代碼修正&lt;/strong&gt;（BugFix）：告別簡單的語法錯誤，轉而使用 LLM 生成更隱蔽、更復雜的邏輯錯誤，真實模擬了開發中那些令人頭疼的 Bug 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;測試驅動開發&lt;/strong&gt;（TDD）：提供完整的單元測試，要求模型根據測試用例反向開發功能代碼，考察其遵循現代開發範式的能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;引入多函數難題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們將上述單函數問題按照真實的函數調用關係組合起來，創造出更復雜的多函數題目，全面考驗模型在宏觀層面的代碼組織和規劃能力。&lt;/p&gt; 
&lt;h2&gt;2. 實驗結果與深度分析&lt;/h2&gt; 
&lt;p&gt;為確保評測的科學性，我們採用了信息增益分數（IG Score）作為核心指標，並通過&amp;nbsp;&lt;strong&gt;IG Filter（信息增益過濾）和專業工程師人工審核（最終合格率 78.55%）&lt;/strong&gt; 對題目質量進行充分的監測，兼具&lt;strong&gt;可讀性、準確性和完整性&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;2.1 單函數與多函數任務分析&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/3880e195179b9c7170e4b2dc56760d0e155540.jpg" alt="表 5: CoreCodeBench 單函數和多函數任務榜單" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖可以看出，實驗結果有力地支持了我們的核心結論， Claude 3.7 在所有任務中表現突出。&lt;/p&gt; 
&lt;p&gt;但所有模型在多函數任務上的普遍表現下滑差於單模型任務，這可能是因為多函數任務需同時處理多個函數間的依賴關係、調用邏輯和協同實現，對大語言模型的跨函數推理和規劃能力要求更高，以及在 BugFix 任務上的集體短板，清晰地勾勒出當前技術的能力邊界。&lt;/p&gt; 
&lt;h3&gt;2.2 模型規劃能力洞察&lt;/h3&gt; 
&lt;p&gt;多函數任務的實驗分析揭示，&lt;strong&gt;模型缺乏對實現順序的規劃能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;大多數模型嚴格遵循輸入提示中的函數順序生成代碼。當前模型在多函數代碼生成時缺乏靈活規劃能力與分層推理能力，往往採用默認的順序輸出策略，而非基於邏輯或功能依賴進行優化。&lt;/p&gt; 
&lt;p&gt;這種「順序執行」而非「邏輯執行」的策略，是其與人類工程師在解決複雜問題思路上的一大差異。&lt;/p&gt; 
&lt;h3&gt;2.3 極限挑戰&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/014baa15a3e9fa538f8946e1ef87a6cc169891.png" alt="圖 6: CoreCodeBench-Difficult 數據集的模型結果" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們通過放寬多函數問題的複雜度限制，構建了&amp;nbsp;CoreCodeBench-Difficult&amp;nbsp;數據集。&lt;/p&gt; 
&lt;p&gt;在該測試中，所有模型的通過率均低於 30%，這不僅印證了該基準在揭示模型侷限性方面的有效性，也為未來技術的突破提供了嚴苛的測試平台。&lt;/p&gt; 
&lt;h3&gt;2.4 LLM 代碼能力全景雷達圖&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/968a856ea20107dbef5236fbb904b6f8249232.png" alt="圖 7: 前沿 LLM 代碼能力雷達圖" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們將模型的六個核心場景表現繪製成雷達圖，可以直觀地看到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;沒有一個模型能在所有場景中獨佔鰲頭，證明瞭 CoreCodeBench&amp;nbsp;&lt;strong&gt;評估維度的全面性&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;開發（Development）和測試驅動開發（TDD）任務中，單/多函數表現並不完全相關，説明&lt;strong&gt;開發多關聯函數需要額外的規劃能力&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;代碼修正（BugFix）任務中，單/多函數表現高度相關，這説明&lt;strong&gt;調試更依賴於一種通用的、局部的錯誤修正技能&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為進一步分析各評測維度之間的關係，我們計算了所有模型在六個維度上的皮爾遜相關係數並繪製熱力圖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/855a4c86166ab69686d5b2daa2504e56137569.png" alt="圖 8: 代碼能力項相關度分析" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示可以觀察得到，相關係數的測算結果表明，CoreCodeBench 的六個核心場景之間既存在一定的&lt;strong&gt;相關性&lt;/strong&gt;，也體現出各自的&lt;strong&gt;差異性&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Single-function 任務之間相關性較高，表現出&lt;strong&gt;單函數任務在基礎編程、理解和實現能力上的共性&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;Multi-TDD 和 Multi-Development 存在一定的相關性，這是因為&amp;nbsp;&lt;strong&gt;Multi-function 任務通常考察模型在更復雜場景下的綜合能力&lt;/strong&gt;，包括多步推理、實現規劃等，與單函數任務所需的基礎能力存在明顯區別。&lt;/li&gt; 
 &lt;li&gt;Multi-BugFix&amp;nbsp;雖然屬於多函數任務，但它和單函數任務相關性高，反而和 Multi-TDD、Multi-Development 相關性低。這是因為&amp;nbsp;&lt;strong&gt;Multi-BugFix&amp;nbsp;任務的本質更接近於「單點排查」，它更側重於具體細節或某一局部的能力考察，而與需要全局綜合能力的多函數任務存在差異&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3. CoreCodeBench 總結與展望&lt;/h2&gt; 
&lt;p&gt;CoreCodeBench&amp;nbsp;的構建與應用，旨在為大語言模型的代碼能力評估提供一把更科學、更全面、更貼近真實的「工程標尺」。回顧我們的研究，我們系統性地揭示了當前頂尖 LLM 在真實工程場景中的核心短板：&lt;strong&gt;無論是多麼先進的模型，都在邏輯錯誤修復方面步履維艱；在面對多函數協同任務時，其跨函數推理與規劃能力都顯得捉襟見肘；並且，它們普遍缺乏人類工程師所具備的靈活規劃與分層推理能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;然而，這些被揭示的侷限性並非技術的終點，而是為下一代大語言模型的發展指明瞭清晰的優化方向。我們相信，通過在 CoreCodeBench 這類更貼近真實工程需求的基準上進行訓練和迭代，大語言模型將能更快地從一個「代碼片段生成器」，進化成一個真正具備分析、規劃和解決複雜工程問題的「虛擬軟件工程師」，從而在軟件開發領域釋放出更深遠的變革力量。&lt;/p&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p&gt;通過 OIBench 和 CoreCodeBench 兩大基準的構建和評測，Meituan-M17 團隊系統性地揭示了當前大語言模型在編程領域的真實能力邊界。這兩個數據集不僅填補了現有評估體系的空白，更重要的是為整個行業提供了一面"照妖鏡"，讓我們能夠更清晰地看到頂尖 AI 模型與人類專業水平之間的真實差距。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心發現包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;即使是最強的推理模型，在複雜算法挑戰面前仍顯不足，距離真正的競賽選手水平還有很大差距；&lt;/li&gt; 
 &lt;li&gt;在工程級代碼任務中，模型普遍在代碼修復和多函數協作方面存在明顯短板；&lt;/li&gt; 
 &lt;li&gt;現有模型缺乏人類工程師所具備的靈活規劃和分層推理能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;展望未來&lt;/h2&gt; 
&lt;p&gt;這些發現並非技術發展的終點，而是為下一代大語言模型的優化指明瞭明確方向。我們相信，通過在更貼近真實需求的基準上持續訓練和迭代，AI 將逐步從"代碼生成工具"進化為真正的"智能開發夥伴"，與人類開發者形成優勢互補的協作關係。&lt;/p&gt; 
&lt;p&gt;Meituan-M17 團隊將持續致力於高質量評估研究，推動大語言模型技術向更廣闊的未來發展。&lt;/p&gt; 
&lt;h2&gt;One More Thing - 從大模型到 Code Agent 的評測範式遷移&lt;/h2&gt; 
&lt;p&gt;當前大量湧現的 Code Agent 類框架與產品，使得人機協作解決更加複雜的工程問題成為可能，這預示着對 Code Agent 在實際工程場景中與人類協作能力的評估，將變得日益關鍵。然而，現有的 Code Agent 評測基準（如 SWE-bench 系列）存在一個核心問題：&lt;strong&gt;它們將人類開發者完全排除在評估流程之外&lt;/strong&gt;。這種 「端到端」 的自動化評測，雖然能比較容易的量化模型在封閉任務上的表現，卻無法回答一個更關鍵的問題：在真實、開放的開發環境中，Code Agent 能否與人類高效協作？當前多數 Code Agent 框架在交互設計上對人機交互的忽視，導致其評測結果與實際應用價值之間存在明顯脫節。&lt;/p&gt; 
&lt;p&gt;結合 OIBench 引發的關於人機協同、優勢互補的思考，Meituan-M17 團隊也開始關注人機協作評測這一新的評測範式在 Code Agent 場景的應用，進而彌補當前範式引起的評測結果與實際應用價值間的鴻溝。基於此，我們與 AGI-Eval 評測社區合作，設計並計劃舉辦一項創新的人機協作編程競賽。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;競賽核心設計如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;評測目標&lt;/strong&gt;：競賽旨在真實模擬人類開發者與搭載不同大模型的 Code Agent 協作解決複雜工程任務的全過程。我們關注的不再僅僅是任務的最終成敗，而是&lt;strong&gt;整個協作流程的質量與效率&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;關鍵指標&lt;/strong&gt;：我們將記錄並分析一系列過程性指標，包括：模型的意圖理解準確度、需求澄清的有效性、交互輪次、決策效率以及最終任務完成的質量與速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;評測流程如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/63a5fc4a1f67b4be5f31828f032fa30518009.png" alt="圖 9: Code Agent 評估流程圖" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;價值與產出&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;首個人機協作榜單&lt;/strong&gt;：我們將產出首個聚焦人機協作效能的 Code Agent 性能榜單，從模型硬實力（自主解決問題的能力）與協作流暢度（與人交互的體驗）兩大維度進行評估。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;深度洞察與改進&lt;/strong&gt;：這些寶貴的數據和洞察，將揭示當前 Code Agent 在真實協作場景下的優勢與短板，為打造更智能、更實用的下一代開發工具提供堅實的實證依據，真正推動人機協同編程走向成熟。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這項競賽不僅填補了現有評測體系的空白，更為探索未來人機協作的無限可能提供了寶貴的數據和實踐參考。對這項比賽感興趣的小夥伴，歡迎前往 AGI-Eval 評測社區瞭解詳情。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/1c438755881e6541eff96bc9f0845d652459748.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;網頁端地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagi-eval.cn%2Fcompetition%2Factivity" target="_blank"&gt;https://agi-eval.cn/competition/activity&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;招聘信息&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;崗位名稱：【北斗計劃】基座大模型算法研究員（評測與探索）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨着 AI 下半場的到來，傳統的評測範式已經無法適配持續提升的模型能力，針對 ChatBot 模型的 Arena 評測的有效性也遭到質疑，如何面向現階段以及未來的模型能力進行科學有效的評估本身也是個極具挑戰和價值的研究方向。OpenAI 研究者也表示，AI 接下來比拼的不是訓練，而是「如何定義並評估真正有用的任務」。&lt;/p&gt; 
&lt;p&gt;在這樣的背景下，美團大模型評測團隊以指引通往 AGI &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E7%9A%84%E9%81%93%E8%B7%AF%E4%B8%BA%E7%9B%AE%E6%A0%87%EF%BC%8C%E6%B7%B1%E8%80%95%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E7%A0%94%E7%A9%B6%EF%BC%8C%E7%B3%BB%E7%BB%9F%E6%80%A7%E7%9A%84%E7%90%86%E8%A7%A3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BD%93%E5%89%8D%E8%83%BD%E5%8A%9B%E6%B0%B4%E5%B9%B3%E5%8F%8A%E6%9C%AA%E6%9D%A5%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91%EF%BC%8C%E5%B9%B6%E4%BB%A5%E6%AD%A4%E4%B8%BA%E5%9F%BA%E7%A1%80%E5%AE%8C%E5%96%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E8%83%BD%E5%8A%9B%E7%9F%A9%E9%98%B5%E3%80%82%E6%AC%A2%E8%BF%8E%E5%90%84%E8%B7%AF%E8%8B%B1%E6%89%8D%E5%8A%A0%E5%85%A5%EF%BC%8C%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F%EF%BC%9Aliuxingyu10%40meituan.com%E3%80%82" target="_blank"&gt;的道路為目標，深耕模型評測研究，系統性的理解大模型當前能力水平及未來技術發展方向，並以此為基礎完善模型評測能力矩陣。歡迎各路英才加入，聯繫方式：liuxingyu10@meituan.com。&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;| 關注「美團技術團隊」微信公眾號，在公眾號菜單欄對話框回覆【2024 年貨】、【2023 年貨】、【2022 年貨】、【2021 年貨】、【2020 年貨】、【2019 年貨】、【2018 年貨】、【2017 年貨】等關鍵詞，可查看美團技術團隊歷年技術文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/b0364d579285ab22aa6235bd100d7c22178175.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美團技術團隊出品，著作權歸屬美團。歡迎出於分享和交流等非商業目的轉載或使用本文內容，敬請註明 "內容轉載自美團技術團隊"。本文未經許可，不得進行商業性轉載或者使用。任何商用行為，請發送郵件至 &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank"&gt;tech@meituan.com&lt;/a&gt; 申請授權。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/meituantech/blog/18685058</link>
      <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/18685058</guid>
      <pubDate>Fri, 18 Jul 2025 07:21:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>2025 全球數字經濟大會拉薩高層論壇盛大開幕，共繪高原數智發展新藍圖</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;7 月 17 日，由拉薩市人民政府主辦，拉薩高新區管委會、拉薩市經濟和信息化局、拉薩市投資促進局承辦的 2025 全球數字經濟大會拉薩高層論壇開幕。論壇以「數聚拉薩·協同發展」為主題，吸引了中國移動、中國電信、東方財富、中國人壽等來自區內外數字經濟重點企業的數百位代表齊聚高原，共話數智未來、共繪發展藍圖。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//732f801d3e4cc9560eb8fbfbedf1e0c3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;出席本次論壇的領導和嘉賓包括：西藏自治區黨委常委、拉薩市委書記肖友才，北京市經濟和信息化局二級巡視員汪劍波，自治區經信廳黨組書記郭翔，新華社西藏分社社長儲國強，以及來自自治區各地市、區縣、園區的有關部門代表，數字經濟領域的知名企業家、行業精英和媒體代表。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;開幕現場，數控矩陣球光影秀震撼全場。流動的光點如數字洪流翻湧而來，構建起一幅幅&lt;/span&gt;&lt;span&gt;「科技+文化」的奇觀畫卷，既有拉薩城廓的歷史印記，也有未來城市的數智躍遷——這是一次傳統與現代的共鳴，更是高原數字經濟的預演。與此同時，現場同步播放《2025 全球數字經濟大會拉薩高層論壇》主題宣傳片，以沉浸式視聽語言，全景展現拉薩「數興城」的嶄新圖景與潛力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;開幕式上，主持人拉薩市委副書記市長王強指出，如今的拉薩正聚合氣候、能源、碳匯、政策、成本五大獨特優勢，以&lt;/span&gt;&lt;span&gt;「離天近、離數更近」的姿態，在「日光城」書寫「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;數興城&lt;/span&gt;&lt;span&gt;」的嶄新篇章。期待廣大企業家積極參與拉薩數字新基建、產業轉型與場景應用，共享機遇、共創生態。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;自治區黨委常委、拉薩市委書記肖友在致辭中表示，數字經濟正在重塑世界經濟格局，也為高原城市的跨越式發展提供了歷史性機遇。拉薩既有得天獨厚的綠色能源優勢，更有開放包容的發展胸懷。我們誠摯邀請各界數字經濟領域的英才俊傑，以本次論壇為契機，在這片充滿希望的土地上共話合作、共謀發展，讓數字技術與高原特色深度融合，讓數字經濟成為高原高質量發展的&lt;/span&gt;&lt;span&gt;「新引擎」，共同書寫新時代拉薩高質量發展的嶄新篇章。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;北京市經濟和信息化局二級巡視員汪劍波、西藏自治區經信廳黨組書記郭翔、新華社西藏分社社長儲國強分別致辭，圍繞&lt;/span&gt;&lt;span&gt;「京藏協同發展」「產業政策引導」「媒體賦能數字生態建設」等話題分享了政策趨勢與實踐經驗，為拉薩拓展數字產業空間、優化發展路徑提供了寶貴思&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;在主旨演講環節，來自華為技術有限公司、江蘇未來網絡集團和&lt;/span&gt;&lt;span&gt;「杭州六小龍」之一杭州雲深處科技有限公司的三家數字領軍企業，分別圍繞技術底座構建、協同架構設計與應用創新落地等核心議題，分享了前沿洞察與典型案例，深入探討數字經濟在高原生態環境中的實踐路徑，啓發與會者共思共創。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;拉薩高新區管委會&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;主任次仁卓嘎在&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;「百億場景引領與基金、政策賦能」重要環節中&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;圍繞&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;「1+6+N」政策體系、15 億元產業強市母基金、百億級數字應用場景建設等方面進行了詳細解讀，充分展現了拉薩加快發展數字經濟的堅定信心與強勁動能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;在簽約環節，紫金物流、中國電信西藏公司、西藏中倉數科科技有限公司、中企雲鏈股份有限公司等&lt;/span&gt;&lt;span&gt;12 家企業與拉薩高新區、經開區達成合作協議。此次簽約聚焦產業實際需求與區域發展重點，呈現出「簽約即推進、落地即見效」的務實特點，進一步夯實了拉薩數字經濟發展的產業基礎與資源支撐。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//ffc2301cee6d51fdcbd0bd94a0af2146.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//3c89991315992a3fd5115b5f6b239bda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;同時，本次論壇還將同步舉辦數字金融、低空經濟、算力賦能等多個分論壇活動，並設立全息投影、雷達觸屏、&lt;/span&gt;&lt;span&gt;VR 體驗區以及數字經濟+低空經濟創新成果體驗展示區，通過全方位展示拉薩數字經濟發展的最新實踐與前沿成果，進一步推動政企對接、項目落地、資源匯聚，全面釋放數字經濟發展潛能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;本次論壇的成功舉辦，不僅為政企交流搭建了高端平台，有效促進了項目對接與資源整合，更向全球清晰傳遞了拉薩市大力發展數字經濟、優化營商環境的堅定決心和強大吸引力，為釋放拉薩數字經濟發展潛能、打造高原數字經濟創新發展高地注入了強勁動力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//5a9f132f2d201b84a66919405a6dfb0e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361025</guid>
      <pubDate>Fri, 18 Jul 2025 07:12:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>報告：71% 的人不願聘用不具備 AI 技能的開發人員</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Infragistics 最新發布的一項&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#585858"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.appbuilder.dev%2F2025-app-development-trends-part-2" target="_blank"&gt;&lt;span&gt;&lt;span&gt;《2025 年應用開發趨勢報告》&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;顯示，71％ 的受訪者表示，他們不會聘請不具備 AI 技能的開發人員。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;30% 的受訪者表示，今年他們面臨的最大挑戰之一是招聘合格的開發人員。除了招聘 AI 領域人才外，53% 的領導者還尋求具備雲計算技能的人才，35% 的領導者在尋求具備解決問題的能力的人，35% 的領導者尋求採用安全編碼實踐的開發人員。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Infragistics 首席運營官 Jason Beres 表示：「AI 正在迅速改變企業開發應用程序的方式——從簡化工作流程到降低安全風險——但如果沒有一支技術精湛的團隊，單憑技術本身是不夠的。隨着企業尋求在業務中擴大 AI 的應用，聘請精通 AI 和機器學習的開發人員，並投資於技能提升，對於推動創新和保持競爭力至關重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，受訪者表示面臨的一些其他主要挑戰是網絡安全威脅（45%）、實施人工智能（37%）和留住合格的開發人員（35%）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查發現，目前有 87% 的團隊在開發過程中使用 AI，而目前尚未使用 AI 的公司中，有 45% 表示他們可能會在明年內開始使用。AI 在開發領域最大的應用場景是自動化重複性任務（40%）、創建佈局和頁面（34%）以及檢測錯誤。約三分之一的領導者認為，AI 可以讓開發人員騰出時間去做更有意義的工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;幾乎所有（99%）在應用程序開發過程中使用 AI 的公司都將 AI 工具用於安全目的。64% 的公司使用 AI 工具進行安全評估、60% 用於測試代碼、59% 用於識別趨勢以檢測安全漏洞，58% 用於掃描代碼以查找漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-00357b61dccfee8da65a90bca27b3134624.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;近一半（45%）的受訪者表示，網絡安全威脅是他們在 2025 年面臨的首要挑戰之一。低代碼與 AI 的結合不僅使應用程序開發更高效，而且更安全。&lt;/span&gt;還有 76% 的技術領導者認為 AI 將提高低代碼工具的效率，只有 16% 的人認為 AI 將取代低代碼開發。&lt;/p&gt; 
&lt;p&gt;更多詳情可查看&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.appbuilder.dev%2F2025-app-development-trends-part-2" target="_blank"&gt;此處&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361019</guid>
      <pubDate>Fri, 18 Jul 2025 07:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>IntelliJ IDEA 從 2025.3 版本開始只提供單一安裝程序</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;JetBrains &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fidea%2F2025%2F07%2Fintellij-idea-unified-distribution-plan%2F" target="_blank"&gt;宣佈了&lt;/a&gt; IntelliJ IDEA 遷移到統一發行版的計劃：「&lt;strong&gt;以後將只有一個 IntelliJ IDEA 安裝程序，取代分別下載的 Community Edition 和 Ultimate Edition&lt;/strong&gt;。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f541e5ae8e14a12c6ab5ca622afdf89f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從&amp;nbsp;2025.3 版本開始，&lt;strong&gt;IntelliJ IDEA Community Edition 將不再作為單獨的產品發行&lt;/strong&gt;。所有用戶都將下載單個 IntelliJ IDEA 發行版：一個安裝程序，一個更新流。&lt;/p&gt; 
&lt;p&gt;對於 Ultimate 用戶來説：&lt;strong&gt;IDE 將被簡稱為 IntelliJ IDEA，不帶「Ultimate」後綴&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在這種新設置中，所有 Ultimate 功能仍然需要訂閲才能解鎖。 但即使沒有訂閲，IDE 仍將保持完整功能，可供商業和非商業項目免費使用，並將包含比當前 Community Edition 更多的功能。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fidea%2F2025%2F07%2Fintellij-idea-unified-distribution-plan%2F" target="_blank"&gt;官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361007/intellij-idea-unified-distribution-plan</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361007/intellij-idea-unified-distribution-plan</guid>
      <pubDate>Fri, 18 Jul 2025 06:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​首個基於 AI 的惡意軟件 LameHug 現身，竊取 Windows 設備數據</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;科技媒體 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Flamehug-malware-uses-ai-llm-to-craft-windows-data-theft-commands-in-real-time%2F" target="_blank"&gt;BleepingComputer&lt;/a&gt; 報道了一種新型惡意軟件 LameHug 的出現，該軟件利用了阿里開源的 Qwen2.5-Coder-32B-Instruct 大型語言模型，針對 Windows10 和 Windows11 設備進行數據竊取。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="345" src="https://oscimg.oschina.net/oscnet/up-eec711f70b3c1570b78cf188268fca9dee1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;LameHug 的獨特之處在於它採用了大型語言模型生成攻擊指令，進而搜刮受害者設備上的敏感數據。根據 CERT-UA（烏克蘭國家網絡安全事件響應團隊）的報告，LameHug 是用 Python 編寫的，依賴於 Hugging Face API 與 Qwen LLM 進行交互。惡意軟件通過特定的提示詞，動態生成竊取數據的指令。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;LameHug 通過惡意電子郵件傳播，通常郵件內附有一個 ZIP 文件，其中包含 LameHug 的加載器。CERT-UA 已經識別出至少三種不同的變體，包括名為 「Attachment.pif」、「AI_generator_uncensored_Canvas_PRO_v0..9.exe」 和 「image.py」 的文件。在具體的攻擊過程中，LameHug 會執行系統偵察和數據竊取命令，這些命令均是通過提示詞動態生成的。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;生成的命令主要用於收集系統信息並保存到一個文本文件（info.txt）中。它會在關鍵的 Windows 目錄 (如文檔、桌面和下載) 中搜索敏感文件，並通過 SFTP 或 HTTP POST 請求將這些數據發送給攻擊者。這種利用 AI 技術的惡意軟件的出現，可能引發一種新的攻擊模式，為網絡安全帶來了更大的挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;隨着 LameHug 的廣泛傳播，安全專家提醒用戶要提高警惕，及時更新防病毒軟件和系統補丁，謹慎處理陌生郵件和附件，以防止此類惡意軟件的侵害。對於廣大用戶而言，網絡安全意識的提升顯得尤為重要。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361006</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361006</guid>
      <pubDate>Fri, 18 Jul 2025 06:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 在挖走蘋果 AI 部門主管後，再次挖走兩名核心專家</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;彭博社記者馬克・古爾曼&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-17%2Fmeta-hires-two-key-apple-ai-experts-after-poaching-their-boss" target="_blank"&gt;透露&lt;/a&gt;，Meta 又挖走了蘋果公司的兩位關鍵人工智能研究人員，此前不久 Meta 剛剛從蘋果挖走了其 AI 王牌——人工智能模型負責人龐若鳴（Ruoming Pang），也就是這兩名研究人員的主管。&lt;/p&gt; 
&lt;p&gt;報道稱，Meta 聘請了蘋果公司的 Mark Lee 和 Tom Gunter 加入其超級智能實驗室 (Superintelligence Labs) 團隊。Lee 在近日離開蘋果後已入職 Meta，而 Gunter 將在不久的將來入職。且 Gunter 上個月就已經從蘋果離開，之後曾在另一家人工智能公司工作，並於最近幾天離職。&lt;/p&gt; 
&lt;p&gt;&lt;img height="251" src="https://oscimg.oschina.net/oscnet/up-6a4af53d5d0f57a57747c4bc6cec56f5b24.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本月早些時候，蘋果公司人工智能模型負責人龐若鳴被 Meta 挖走。據悉，為了爭取龐若鳴的加入，Meta 提供了一份價值超 2 億美元的多年薪酬方案。&lt;/p&gt; 
&lt;p&gt;龐若鳴於 2021 年從 Alphabet 離職並加入蘋果，領導蘋果基礎模型團隊。Lee 和 Gunter 此前均為該團隊成員。該團隊約有 100 人，主要負責開發支持蘋果設備上 「Apple Intelligence」 及其它 AI 功能的核心基礎模型。&lt;/p&gt; 
&lt;p&gt;據悉，Meta 承諾的薪酬比蘋果支付給其基礎模型團隊工程師的薪酬要高出數倍。為了防止更多人離職，蘋果已經開始為該團隊中的一些工程師提供加薪，以吸引他們留下。&lt;/p&gt; 
&lt;p&gt;儘管如此，這與 Meta 的出價仍相去甚遠。例如，Gunter 即將加入一個由數位人工智能專家組成的團隊，這些專家都獲得了價值超 1 億美元的多年期薪酬包。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/359359/meta-recruits-apples-head-of-ai-models" target="_blank"&gt;消息稱 Meta 招募了蘋果的 AI 模型高管&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360982</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360982</guid>
      <pubDate>Fri, 18 Jul 2025 03:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Jason Wei 提出「驗證者定律」：所有可能解決且易於驗證的任務都將被人工智能解決</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Jason Wei（OpenAI 核心科學家、思維鏈提示詞核心作者、o1 關鍵人物）近期&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2F_jasonwei%2Fstatus%2F1945287045251052007" target="_blank"&gt;提出&lt;/a&gt;驗證不對稱性理論及&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jasonwei.net%2Fblog%2Fasymmetry-of-verification-and-verifiers-law" target="_blank"&gt;「驗證者定律」（Verifier's Law）&lt;/a&gt;，其核心觀點是：訓練 AI 解決一個任務的難易程度與該任務的可驗證性成正比，所有可能解決且易於驗證的任務，終將都被 AI 攻克。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;驗證的不對稱性指的是有些任務驗證起來比解決起來容易得多。隨着強化學習的普遍應用，這個概念變得越來越重要。&lt;/p&gt; 
 &lt;p&gt;比如：數獨謎題、編寫 Instagram 網頁代碼、或 BrowseComp 問題（找到答案很難，但驗證起來非常簡單）。&lt;/p&gt; 
 &lt;p&gt;有的任務則接近對稱，比如計算兩個 900 位數字之和。還有些任務提出方案容易，但驗證卻很難（比如核實一篇長文章的事實，或提出「只吃野牛」的新飲食法）。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;具體而言，任務的可驗證性取決於以下五個關鍵屬性：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;客觀真理&lt;/strong&gt;：所有人對「好」的解決方案有普遍共識。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;快速驗證&lt;/strong&gt;：任何給定的解決方案可在幾秒鐘內完成驗證。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可擴展驗證&lt;/strong&gt;：可同時驗證大量解決方案。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;低噪聲&lt;/strong&gt;：驗證結果與解決方案質量高度相關。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;連續獎勵&lt;/strong&gt;：可對多個解決方案進行優劣排序 。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7387b887042eaf1d9e3b0a62295b13721e4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Jason Wei 指出，過去十年中，大多數 AI 基準測試都符合前四條標準（因此已被解決），而符合這些標準的任務將推動 AI 快速進步，而難以驗證的任務則進展緩慢。&lt;/p&gt; 
&lt;p&gt;此外，驗證者定律也揭示了未來人類與 AI 協作的核心：將複雜、模糊的現實問題轉化為 AI 可理解和優化的、可清晰驗證的任務。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360981/asymmetry-of-verification-and-verifiers-law</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360981/asymmetry-of-verification-and-verifiers-law</guid>
      <pubDate>Fri, 18 Jul 2025 03:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節視覺大模型負責人楊建朝宣佈「暫時休息」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;網易科技獲悉，字節跳動豆包大模型視覺多模態生成方向負責人楊建朝於 7 月 17 日上午在公司內部宣佈「暫時休息」，相關工作已完成交接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據多位接近字節的人士透露，目前仍能在字節內部系統中查到楊建朝的信息。消息人士稱，楊建朝的工作將由周暢（花名「時光」）接手。目前，周暢所在架構仍為「多模態交互與世界模型」部門，向吳永輝彙報。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;關於此次人事變動的原因，有知情人士向網易科技表示為「家庭因素」，此前也有傳言稱其因無法兼顧北美與國內的工作節奏，長期處於高強度壓力下，身心俱疲，也有版本稱其為「提前退休」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;實際上，早前就有楊建朝計劃「休息」的傳聞，而選擇在此時正式官宣，消息人士表示可能是考慮到上半年績效考覈剛剛結束，為下半年重新安排工作提供空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="323" src="https://oscimg.oschina.net/oscnet/up-e084d80744b14ca7360272b901a726c9179.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;網易科技瞭解到，Seed 視覺模型研究團隊，辦公地點分佈在北美聖何塞、新加坡和中國多個城市，涵蓋圖片生成、視頻生成及視覺模型基礎研究等方向。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;自 2025 年 2 月谷歌 DeepMind 研究副總裁吳永輝加入字節、擔任 Seed 基礎研究負責人以來，Seed 內部的組織與權責結構便發生了一系列深層調整。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在大模型競爭進入深水區的背景下，核心技術負責人的異動，令外界對字節內部 AI 技術路線的穩定性產生更多關注。不過，也有知情人士表示，字節在內部多次強調對基礎研究的長期投入不會動搖。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;楊建朝是字節 AI 體系內公認的「技術大牛」。2006 年，他曾獲得中國科學技術大學郭沫若獎學金，後赴美深造，師從「計算機視覺之父」Thomas Huang（黃煦濤），在伊利諾伊大學香檳分校完成博士後研究。他曾在 Adobe、Snapchat 等公司從事視覺算法研究，2018 年加入字節跳動 AI Lab 任研發總監，後負責智能創作團隊，2023 年起帶領 Seed 視覺部門。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;接任者周暢同樣是國內技術領域的重要人物。本科畢業於復旦大學，博士就讀於北京大學，曾擔任阿里巴巴通義千問大模型的技術負責人，主導開發了 2021 年發佈的 M6 多模態預訓練模型。這是阿里與清華聯合推出的中文語境下最大規模 AI 模型，被視為阿里大模型戰略的重要里程碑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 7 月，周暢從阿里離職，引發廣泛猜測，曾一度傳出其將創業的消息。最終據多方確認，他選擇加入字節跳動，加入 Seed 團隊。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360974</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360974</guid>
      <pubDate>Fri, 18 Jul 2025 03:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI o1 核心貢獻者把 AI 定義為「第四種槓桿」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近期，前 OpenAI 研究員 Hyung Won Chung 在離職消息曝光後，首次系統性地&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fhwchung27%2Fstatus%2F1945355238187393257" target="_blank"&gt;分享了他對 AI 的長期思考&lt;/a&gt;，塑造了一個新的想法：「AI 槓桿機制」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/111013_yM8G_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在傳統經濟學裏，人類只擁有三種槓桿：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;人力槓桿：讓別人替你幹活。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;資本槓桿：讓錢替你生錢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代碼槓桿：讓軟件替你規模化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Hyung Won Chung 認為，&lt;strong&gt;AI 正在成為第四種槓桿&lt;/strong&gt;，具備前三者從未同時擁有的三大特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;組合性&lt;/strong&gt;——多個 AI Agent 可以任意拼接，形成「複合槓桿」；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可擴展性&lt;/strong&gt;——複製 1 萬份拷貝的邊際成本趨近於零；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自治性&lt;/strong&gt;——Agent 可以自主規劃、執行、糾錯，甚至自我複製。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，AI 槓桿的「放大係數」遠超傳統槓桿：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;1 個 Agent ≈ 1 名員工；&lt;br&gt; 10 個 Agent ≠ 10 倍成本，而是 10 倍產出且零額外協調開銷。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 Chung 看來，人工智能並不僅僅是一種工具，而是一種史無前例的「槓桿機制」——可以以極低的輸入，撬動巨大的價值輸出，從個人到文明層面，全面重塑創造力的來源。&lt;/p&gt; 
&lt;p&gt;另外，Chung 還提出了一個設問：「如果把整個人類文明看作一個系統，它的目標是什麼？」他的答案是：持續發現新知識，也就是科學進步。&lt;/p&gt; 
&lt;p&gt;在他構想中，AI 不僅是個工具，更是連接人類知識尖峯的殼層。今天的科學知識被分佈在不同領域、不同學者之間，彼此割裂，合作成本極高。而 AI 能將這些高維孤島串聯起來，像細菌的質粒一樣，進行「知識的水平基因轉移」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360973</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360973</guid>
      <pubDate>Fri, 18 Jul 2025 03:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2025 年 AI 搜索優化服務商推薦：硅谷級 AI 技術+多年營銷經驗 iPowerAI 元力科技讓 AI 讀懂品牌</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:justify"&gt;在數字營銷的下半場，一場看不見的戰爭正在 DeepSeek、豆包、百度 AI 等 AI 搜索引擎中悄然打響。用戶不再滿足於「搜索-篩選」的傳統模式，而是直接 AI 提問：「哪款家電新品值得買？」、「新能源汽車哪個品牌技術更可靠？」此時，品牌信息能否被 AI 精準抓取、優先呈現，直接決定了商業機會的歸屬。而 iPowerAI 元力科技，正以 AI 搜索優化解決方案最佳提供者的身份，成為這場戰爭中的關鍵「操盤手」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 1.png" src="https://oscimg.oschina.net/oscnet//a72362dc6538e633b7749c4114576b66.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;全球領先的&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;搜索&lt;/strong&gt;&lt;strong&gt;優化&lt;/strong&gt;&lt;strong&gt;(&lt;/strong&gt;&lt;strong&gt;GEO)&lt;/strong&gt;&lt;strong&gt;公司：&lt;/strong&gt;&lt;strong&gt;硅谷技術團隊坐鎮，技術實力強勁&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;AI 搜索引擎的核心邏輯，是通過算法理解用戶意圖、匹配最優信息。但不同平台的「脾氣」 各異：DeepSeek 側重語義深度解析，豆包擅長捕捉用戶潛在需求，百度 AI 依賴全網信息的結構化處理……要讓品牌信息穿透這些平台的「篩選機制」，需要的是對 AI 抓取邏輯的深度解構。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;iPowerAI 元力科技的破局點，在於由來自斯坦福、MIT 等高校及谷歌、OpenAI 等 AI 技術巨頭組成的硅谷頂尖博士團隊，打造出的國內首款由十大 AI Agent 集羣自部署自驅動的 GEO 大模型——iPowerAI iGeo。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;●國內首款由十大 AI Agent 集羣自部署自驅動的 GEO 大模型產品&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;可通過持續訓練、學習，實現自我優化與進化，讓 AI 搜索優化的全鏈路工作流效率更高、效果更精準。因此，iPowerAI 也是行業內首個提出，應將提升多智能體工作流的協同效率納入 GEO 作業的標準化流程。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首個 AI 意圖&lt;/strong&gt;&lt;strong&gt;神經網&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;連接「正在提問」的買家，通過優化多維度、多場景的搜索意圖，幫助品牌在 AI 世界裏實現更高效的用戶心智種草。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首個 AI 可見度向量引擎：&lt;/strong&gt;基於跨模型語義分析，動態量化品牌在主流 AI 搜索引擎中的「認知能見度」，輸出競爭力分析圖譜。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首個智能化、自動化品牌價值解碼器：&lt;/strong&gt;多重解碼、構建 AI 生態下的品牌知識庫，讓 AI 更懂品牌，提升不同 AI 搜索引擎讀取品牌信息的概率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;iPowerAI iGeo 通過持續自我訓練與進化，能精準適配不同 AI 平台的算法偏好，可以為新能源行業、3C 數碼領域、醫療健康等賽道企業提供精準服務，從而提升品牌或產品在各 AI 平台的提及率和排名位置。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;曾任亞馬遜廣告首席科學家、與谷歌、Meta 長期合作的紐約大學 Andre Meyer 冠名終身教授陳溪認為：「AI 技術驅動下的多智能體高效協同工作模式，有效地為各行業提供 AI 解題的新思路；而 iPowerAI 的 iGeo 則將這一先進範式系統化落地到了 AI 搜索優化上，首創了由十大 AI Agent 集羣自部署自驅動的 GEO 大模型產品，構築了一個具有自驅學習、自我進化的營銷產品，這讓我們看到了 AI 賦能營銷的新可能。」陳溪教授曾在 2025 年 5 月的巴菲特股東大會中美投資人酒會上發表演講，暢談 AI 領域前沿趨勢，表示 AI 領域已進入新的發展拐點，從大模型訓練轉向垂直應用的爆發期。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;10 大行業、&lt;/strong&gt;&lt;strong&gt;200&lt;/strong&gt;&lt;strong&gt;+&lt;/strong&gt;&lt;strong&gt;頭部品牌&lt;/strong&gt;&lt;strong&gt;的營銷經驗&lt;/strong&gt;&lt;strong&gt;：讓產品&lt;/strong&gt;&lt;strong&gt;更容易被看見&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;iPowerAI 元力科技的核心競爭力，在於將硅谷級技術轉化為可感知的商業效果。其服務的某家電品牌曾創造過一個經典案例：新品發佈當天，在豆包、DeepSeek、百度 AI 等平台的品類搜索中直接衝上 TOP1，產品內容的 AI 回答引用率高達 100%。這背後，是 iPowerAI 元力科技「品牌價值解碼器」的功勞——它能將品牌的核心優勢（如技術參數、用戶口碑）拆解為 AI 易讀取的結構化信息，讓 Deepseek、豆包等平台在為用戶解答問題時，優先抓取並呈現這些內容。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;這種能力的沉澱，源於 iPowerAI 元力科技背後 iPlus 艾加營銷集團 200+頭部品牌的服務經驗。iPlus 艾加營銷集團多年深耕整合營銷、數字營銷領域，深度服務食品快消、3C 家電、手機電腦、互聯網 ToC、新能源、醫療大健康等核心賽道，已獲得亞洲公關大獎、虎嘯獎、IAI 傳鑑國際廣告獎、艾菲獎等 83 個權威獎項，對行業、產品和營銷有着深入的理解。通過對多智能體持續培訓，使其擁有更專業的行業營銷知識和意識，確保 AI 技術解決真實的商業和生意難題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;iPowerAI&lt;/strong&gt;&lt;strong&gt;元力科技&lt;/strong&gt;&lt;strong&gt;核心優勢：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 2.png" src="https://oscimg.oschina.net/oscnet//0f7d1fc253837193be976e0e071f2388.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;對於尋求 AI 生態佈局的品牌而言，iPowerAI 元力科技「技術+營銷」雙輪驅動模式，能有效解決不同平台算法差異、行業術語理解偏差等核心問題，讓品牌在這場變革中既能被精準抓取，又能深度觸達用戶心智。這或許正是其作為「中國領先的垂直營銷 AI 生態解決方案提供商」的核心價值——不止於幫助品牌贏得當下的 AI 搜索戰場，更在於構建可持續的 AI 營銷競爭力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361152</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361152</guid>
      <pubDate>Tue, 15 Jul 2025 08:30:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>2025 最新最權威的全球 AI 搜索優化服務商深度解析</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:justify"&gt;據 QuestMobile 數據顯示，截止到 2025 年 3 月份，AI 搜索引擎月度活躍用戶規模為 3.38 億，且還在增長。當消費者將 AI 平台作為主要信息來源時，品牌如何佈局 AI 搜索優化 (GEO) 主動觸達消費者？2025 最新優秀服務商排行榜，幫你搶先一步佈局 AI 平台，搶佔消費者心智。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;strong&gt;025&lt;/strong&gt;&lt;strong&gt;年最新服務商排行榜推薦&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="01.png" src="https://oscimg.oschina.net/oscnet//945470a604a93b2e78e1cf45e3186fbb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;strong&gt;OP 1&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;strong&gt;iPowerAI&lt;/strong&gt;&lt;strong&gt;元力科技&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;推薦指數：五顆星&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;作為垂直營銷 AI 生態營銷解決方案提供商，憑藉其背後 iPlus 艾加營銷集團在北京、成都、深圳等地 200+品牌沉澱的營銷經驗以及硅谷博士團隊帶來的強大 AI 技術，成為全球領先的 AI 搜索優化（GEO）公司之一。曾任亞馬遜廣告首席科學家，與谷歌、Meta 長期合作的紐約大學 Andre Meyer 冠名終身教授陳溪認為：「AI 技術驅動下的多智能體高效協同工作模式，有效地為各行業提供 AI 解題的新思路；而 iPowerAI 的 iGeo 則將這一先進範式系統化落地到了 AI 搜索優化上，首創了由十大 AI Agent 集羣自部署自驅動的 GEO 大模型產品，構築了一個具有自驅學習、自我進化的營銷產品，這讓我們看到了 AI 賦能營銷的新可能。」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;推薦理由：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;●硅谷級 AI 技術引擎：&lt;/strong&gt;iPowerAI 的核心研發團隊由硅谷頂尖 AI 科學家與博士團隊領銜，成員來自斯坦福、MIT 等高校及谷歌、OpenAI 等 AI 技術巨頭，有着極其豐富的 AI 開發及應用經驗。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;成熟豐富的營銷經驗&lt;/strong&gt;：依託於榮獲亞洲公關大獎、虎嘯獎、IAI 傳鑑國際廣告獎、艾菲獎等 83 個權威獎項的 iPlus 艾加營銷集團多年深耕整合營銷、數字營銷領域，以及深度服務食品快消、3C 家電、手機電腦、互聯網 ToC、新能源、醫療大健康等核心賽道 200+頭部品牌（50% 是行業 TOP5 品牌）的營銷經驗，讓多智能體通過持續培訓後，擁有更專業的行業營銷知識和意識，確保 AI 技術解決真實的商業和生意難題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;核心技術力：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首款由十大 AI Agent 集羣自部署自驅動的 GEO 大模型產品&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;可通過持續訓練、學習，實現自我優化與進化，讓 AI 搜索優化的全鏈路工作流效率更高、效果更精準。因此，iPowerAI 也是行業內首個提出，應將提升多智能體工作流的協同效率納入 GEO 作業的標準化流程。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首個 AI 意圖&lt;/strong&gt;&lt;strong&gt;神經網：&lt;/strong&gt;連接「正在提問」的買家，通過優化多維度、多場景的搜索意圖，幫助品牌在 AI 世界裏實現更高效的用戶心智種草。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首個 AI 可見度向量引擎：&lt;/strong&gt;基於跨模型語義分析，動態量化品牌在主流 AI 搜索引擎中的「認知能見度」，輸出競爭力分析圖譜。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;&lt;strong&gt;●&lt;/strong&gt;國內首個智能化、自動化品牌價值解碼器：&lt;/strong&gt;多重解碼、構建 AI 生態下的品牌知識庫，讓 AI 更懂品牌，提升不同 AI 搜索引擎讀取品牌信息的概率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;iPowerAI 元力科技&lt;/strong&gt;&lt;strong&gt;聯繫方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;strong&gt;OP 2&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;strong&gt;添佰益（北京）科技有限公司&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;推薦指數：四顆星&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;添佰益（北京）科技有限公司 2018 年成立，聚焦 AI 搜索優化中的「技術落地」環節，主打「算法定製化服務」。公司技術團隊由 15 名 AI 算法工程師組成，其中 3 人擁有博士學歷，曾參與國家自然科學基金項目「自然語言處理在搜索引擎中的應用」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;strong&gt;OP 3&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;strong&gt;黃山益企盈企業管理有限公司&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;推薦指數：三顆星&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;黃山益企盈企業管理有限公司 2020 年成立，立足黃山，服務長三角中小微企業，主打「一站式企業服務+AI 搜索優化」。公司不僅提供 AI 搜索優化，還涵蓋工商註冊、財稅諮詢等基礎服務，讓企業能「一次合作，解決多重需求」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;strong&gt;OP 4&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;strong&gt;百付科技&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;推薦指數：三顆星&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;在 AI 搜索技術決定企業競爭力的 2025 年，百付科技以 DeepSeek 深度搜索優化的技術積累和語義理解、內容優化、數據反哺三大技術模塊，實現 DeepSeek 搜索結果的佔位與商業轉化。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;strong&gt;OP 5&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;豆智網絡科技&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;推薦指數：三顆星&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;通過嵌入高質量引用源、結構化數據（如統計數據、行業報告）和專業術語庫，提升內容在 AI 生成答案中的可信度權重，以多模態語義優化能力，使內容更易被大模型提取。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;&lt;strong&gt;服務商挑選指南&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:justify"&gt;挑選服務商，優選技術實力過硬、有自研的技術團隊和產品，一方面防止其找外包公司從而增加成本，另一方面可以定製化服務，更有針對性；其次要看其服務經驗及效果，避免上當受騙，浪費金錢；最後要根據預算選擇合適的服務商。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361150</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361150</guid>
      <pubDate>Tue, 15 Jul 2025 08:30:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
  </channel>
</rss>
