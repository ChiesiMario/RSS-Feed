<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 01 Aug 2025 02:45:02 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>字節 Seed 發佈實驗性擴散語言模型 Seed Diffusion Preview</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;字節跳動 Seed 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fry3BsjzOG5DhBL0QWrtNqg" target="_blank"&gt;宣佈&lt;/a&gt;推出實驗性擴散語言模型 Seed Diffusion Preview，目標是以結構化的代碼生成為實驗領域，系統性地驗證離散擴散技術路線作為下一代語言模型基礎框架的可行性。&lt;/p&gt; 
&lt;p&gt;實驗結果顯示，Seed Diffusion Preview 代碼推理速度可達到 2146 tokens / s，速度相比同等規模的自迴歸模型提升 5.4 倍。在多個業界基準上，Seed Diffusion Preview 性能與優秀的自迴歸模型相當，並在代碼編輯等任務上實現超越。&lt;/p&gt; 
&lt;p&gt;&lt;img height="991" src="https://static.oschina.net/uploads/space/2025/0801/103437_HnUv_2720166.png" width="1440" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/103606_7jx7_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;項目頁面：https://seed.bytedance.com/seed_diffusion&lt;br&gt; 體驗鏈接：https://studio.seed.ai/exp/seed_diffusion&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;官方表示，Seed Diffusion Preview 驗證了離散擴散模型在大型語言模型上的推理加速潛力。團隊同時認為，推理加速僅是這一技術路徑最直接的表層優勢。Seed Diffusion 項目將致力於挖掘其更深遠的價值，持續探索其規模化定律與在複雜推理任務中的應用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363545</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363545</guid>
      <pubDate>Fri, 01 Aug 2025 02:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​庫克透露蘋果 AI 投資加大，個性化 Siri 功能進展順利</title>
      <description>&lt;div class="content"&gt;
                                                                                            ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363543</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363543</guid>
      <pubDate>Fri, 01 Aug 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Google 和其他搜索引擎會索引 ChatGPT 用戶的公開查詢</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcryps1s%2Fstatus%2F1951041845938499669" target="_blank"&gt;這是對人類思維的奇怪一瞥&lt;/a&gt;：如果你過濾 Google、Bing 和其他搜索引擎上的搜索結果，只包含來自域「https://chatgpt.com/share」的 URL，你就可以找到陌生人與 ChatGPT 的對話。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8aa77fffcacb203b6d26629fc93c6174a09.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;有時，這些共享的對話鏈接相當乏味——人們尋求幫助&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchatgpt.com%2Fshare%2F011b8169-b122-45d9-9e94-ac14af26f424" target="_blank"&gt;翻新浴室&lt;/a&gt;、瞭解&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchatgpt.com%2Fshare%2F6fb219ae-cf5e-486f-9e40-35a653ebe7a4" target="_blank"&gt;天體物理學&lt;/a&gt;以及尋找&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchatgpt.com%2Fshare%2F670ee5a0-28b4-8001-bb3f-4baaab45cdaf" target="_blank"&gt;食譜創意&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在另一個案例中，一位用戶要求 ChatGPT 為某份工作重寫簡歷（根據聊天記錄中的詳細信息，很容易找到此人的領英賬號，但根據他的領英賬號判斷，他並沒有獲得這份工作）。另一個人問的問題聽起來像是出自非自願獨身者論壇。還有一個人問這個尖刻、充滿敵意的人工智能助手，他們能不能&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchatgpt.com%2Fshare%2F67ed5fe2-fff8-8008-b106-952343a5863a" target="_blank"&gt;用微波爐加熱金屬叉子&lt;/a&gt;（記錄顯示：不能），但他們繼續向人工智能提出越來越荒謬、越來越惡搞的問題，最終導致它創建了一份名為《如何在不召喚撒旦的情況下使用微波爐：新手指南》的指南。&lt;/p&gt; 
&lt;p&gt;ChatGPT 默認不會公開這些對話。只有當用戶特意點擊自己聊天中的「分享」按鈕，然後點擊第二個「創建鏈接」按鈕時，對話才會附加「/share」URL。該服務還聲明「您的姓名、自定義説明以及分享後添加的任何消息都將保持私密」。點擊創建鏈接後，用戶可以切換是否允許該鏈接被發現。&lt;/p&gt; 
&lt;p&gt;然而，用戶可能沒有預料到其他搜索引擎會索引他們共享的 ChatGPT 鏈接，這可能會泄露個人信息（我向我發現其 LinkedIn 的人表示歉意）。&lt;/p&gt; 
&lt;p&gt;雖然並非有意為之，但這卻是 Google 部分確立的一項規範。當人們分享 Google 雲端硬盤文件的公開鏈接時，例如設置為「任何知曉鏈接的人均可查看」的文檔，Google 可能會將其納入搜索索引。但是，Google 通常不會顯示未在網絡上公開發布的雲端硬盤文檔的鏈接——例如，如果文檔鏈接來自受信任的網站，則可能會出現在搜索結果中。&lt;/p&gt; 
&lt;p&gt;據 ChatGPT 稱，這些聊天記錄是作為實驗的一部分被編入索引的。&lt;/p&gt; 
&lt;p&gt;OpenAI 的一位發言人解釋説：「除非你選擇分享，否則 ChatGPT 的聊天記錄是不公開的。我們一直在測試各種方法，讓用戶更容易地分享有用的對話，同時又能保持控制權。我們最近結束了一項實驗，如果你在分享時明確選擇分享，聊天記錄就會出現在搜索引擎結果中。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-09f219a2af20525cc49169fffe6fb9d8d5d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;雖然像 Google 這樣的搜索引擎控制着決定哪些內容會出現在搜索詞中的算法，但搜索引擎本身無法控制哪些內容會被編入索引。&lt;/p&gt; 
&lt;p&gt;Google 發言人表示：「Google 和其他搜索引擎都無法控制哪些頁面在網絡上公開。這些頁面的發佈者完全控制着它們是否被搜索引擎收錄。」&lt;/p&gt; 
&lt;p&gt;OpenAI 隨後從 ChatGPT 中移除了允許用戶將公開對話內容發佈到搜索引擎的功能。該公司表示，這只是一個短暫的實驗，最終「為人們意外分享非本意內容提供了太多機會」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363541</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363541</guid>
      <pubDate>Fri, 01 Aug 2025 02:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟發佈 2025 財年第四季度財報</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;微軟已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2FInvestor%2Fearnings%2FFY-2025-Q4%2Fpress-release-webcast" target="_blank"&gt;公佈&lt;/a&gt;2025 財年第四財季（2025 年 4 月 1 日至 2025 年 6 月 30 日）財務報告。與上一財年同期相比，業績如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;營收為 764 億美元，增長 18%（按固定匯率計算增長 17%）；市場預期 738.9 億美元&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;營業收入為 343 億美元，增長 23%（按固定匯率計算增長 22%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;淨收入為 272 億美元，增長 24%（按固定匯率計算增長 22%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;稀釋每股收益為 3.65 美元，增長 24%（按固定匯率計算增長 22%），市場預期 3.37 美元&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-4e312ec95ba9215b5b9871b3d2e01d0f4c9.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟董事長兼首席執行官 Satya Nadella&amp;nbsp;表示：「雲計算和人工智能是各行各業業務轉型的驅動力。我們正在整個技術領域進行創新，以幫助客戶適應並在新時代發展。今年，在所有工作負載增長的推動下，Azure 的收入超過了 750 億美元，增長了 34%。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟執行副總裁兼首席財務官 Amy Hood 表示：「我們以強勁的季度業績結束了本財年，其中最突出的是微軟雲計算收入達到 467 億美元，同比增長 27%（按固定匯率計算增長 25%）。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;業務亮點&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;生產力與業務流程部門營收為 331 億美元，增長 16%（若按固定匯率計算，增長 14%），業務亮點如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Microsoft 365 商業產品和雲服務收入增長 16%（按固定匯率計算增長 15%），這得益於 Microsoft 365 商業雲收入增長 18%（按固定匯率計算增長 16%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Microsoft 365 消費者產品和雲服務收入增長 21%，受 Microsoft 365 消費者雲收入增長 20% 的推動&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;LinkedIn 收入增長 9%（按固定匯率計算增長 8%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在 Dynamics 365 收入增長 23%（按固定匯率計算增長 21%）的推動下，Dynamics 產品和雲服務收入增長 18%（按固定匯率計算增長 17%）&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;智能雲業務營收為 299 億美元，增長 26%（若按固定匯率計算，增長 25%），具體業務亮點如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在 Azure 和其他雲服務收入增長 39% 的推動下，服務器產品和雲服務收入增長 27%&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更加個性化的計算業務營收為 135 億美元，增長 9%，&lt;/span&gt;&lt;span style="color:#000000"&gt;其業務亮點如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Windows OEM 和設備收入增長 3%&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Xbox 內容和服務收入增長 13%（按固定匯率計算增長 12%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;不包括流量獲取成本的搜索和新聞廣告收入增長 21%（按固定匯率計算增長 20%）&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟在 2025 財年第四季度以股息和股票回購的形式向股東返還了 94 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;2025 財年業績&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟還宣佈了截至 2025 年 6 月 30 日的財年業績，與上一財年同期相比，業績如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;營收達 2817 億美元，增長 15%&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;營業收入為 1285 億美元，增長 17%（按固定匯率計算增長 18%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;淨收入達 1018 億美元，增長 16%（按固定匯率計算增長 15%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;每股攤薄收益為 13.64 美元，增長 16%&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363536</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363536</guid>
      <pubDate>Fri, 01 Aug 2025 02:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義發佈「甜品級」編程模型 Qwen3-Coder-Flash</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;阿里通義 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F8A-AsmnrtuwR2dvbQJK3HA" target="_blank"&gt;發佈&lt;/a&gt;了 Qwen3-Coder-Flash（全稱&amp;nbsp;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;Qwen3-Coder-30B-A3B-Instruct），官方稱其為「甜品級」編程模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/100101_7YfH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/100125_2IYO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，該模型在性能和效率方面表現出色：&lt;/p&gt; 
&lt;p&gt;1️⃣卓越的 Agentic 能力：&lt;br&gt; Qwen3-Coder-Flash 擁有超強的 Agent 能力。在代理式編程 (Agentic Coding)、瀏覽器使用（Agentic Browser-Use）、工具調用（Tool Use）等領域，超越當前頂級開源模型，僅略遜於頂配版 Qwen3-Coder-480B-A35B-Instruct，及 Claude Sonnet-4、GPT4.1 等領先閉源模型。&lt;/p&gt; 
&lt;p&gt;2️⃣倉庫級長上下文理解：&lt;br&gt; 原生支持 256K tokens，支持 YaRN 可擴展至 1M tokens，整個項目庫都能理解，再也不用擔心代碼上下文斷層了！&lt;/p&gt; 
&lt;p&gt;3️⃣支持多平台使用：&lt;br&gt; 具備專門設計的函數調用格式，為 Qwen Code、CLINE、Roo Code、Kilo Code 等平台作了優化，用起來超順手。&lt;/p&gt; 
&lt;p&gt;目前 Qwen3-Coder-Flash 已在魔搭社區、Hugging Face 正式開源，開發者可在本地硬件自由部署，構建專屬代碼助手。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/100222_kFYX_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;體驗方式👇&lt;br&gt; 🌟QwenChat：chat.qwen.ai&lt;br&gt; 🤖魔搭社區：https://www.modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct&lt;br&gt; 🤗HF：https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363534/qwen3-coder-flash</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363534/qwen3-coder-flash</guid>
      <pubDate>Fri, 01 Aug 2025 02:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>袋鼠數據庫工具 8.0.1 版已上線</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;袋鼠數據庫工具，是一款 AI 驅動的熱門數據庫系統客戶端 (MariaDB / MySQL / Oracle / PostgreSQL / Redis / SQLite / SQL Server / ...) ，支持建表、查詢、模型、同步、導入導出等功能，支持 Windows / Mac / Linux 等操作系統，致力於打造一款好用、好玩、開發友好的開發者工具。&lt;/p&gt; 
&lt;h2&gt;重點特性介紹&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;這個版本繼續完善 Redis 支持，實現了 Redis 高階功能，實現了集羣模式、哨兵模式、管道執行、命令導出、批量執行等高級功能，鍵視圖、查詢和控制枱也都支持集羣模式和哨兵模式；導出和批量執行功能也支持集羣模式和哨兵模式。控制枱支持全面升級，新增支持歷史命令支持；&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;溫馨提示&lt;/strong&gt;：自版本 9.99.1 開始，數據庫連接配置文件做了升級，支持配置擴展附件，原有的連接在新版本中將會丟失部分數據，主要影響 SQLite/ODBC 連接，升級前請做好備份；&lt;/p&gt; 
&lt;h2&gt;新特性或修復的缺陷列表&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;數據表格: 增加跳轉上下文菜單&lt;/li&gt; 
 &lt;li&gt;對象瀏覽: 增加跳轉上下文菜單&lt;/li&gt; 
 &lt;li&gt;連接對象: 增加超時及 Redis 分隔符支持&lt;/li&gt; 
 &lt;li&gt;連接空間: 狀態欄支持更多網格顯示摘要信息&lt;/li&gt; 
 &lt;li&gt;對象倉庫：重構數據庫和架構上下文菜單&lt;/li&gt; 
 &lt;li&gt;Redis: 增加鍵分隔符支持&lt;/li&gt; 
 &lt;li&gt;Redis: DB 節點顯示 DB 鍵數量&lt;/li&gt; 
 &lt;li&gt;Redis: 增加集羣模式支持&lt;/li&gt; 
 &lt;li&gt;Redis: 增加哨兵模式支持&lt;/li&gt; 
 &lt;li&gt;Redis: 鍵視圖增加鍵排序支持&lt;/li&gt; 
 &lt;li&gt;Redis: 重構控制枱界面為一個視圖&lt;/li&gt; 
 &lt;li&gt;Redis: 控制枱新增內建命令支持 (Connect)&lt;/li&gt; 
 &lt;li&gt;Redis: 控制枱新增內建命令支持 (Clear)&lt;/li&gt; 
 &lt;li&gt;Redis: 控制枱增加歷史命令支持 (Ctrl+Up/Down)&lt;/li&gt; 
 &lt;li&gt;Redis: 控制枱命令複合數據輸出格式化支持&lt;/li&gt; 
 &lt;li&gt;Redis: 改建集權節點/分片信息顯示&lt;/li&gt; 
 &lt;li&gt;Redis: 增加集羣連接/複製節點顯示支持&lt;/li&gt; 
 &lt;li&gt;Redis: 管道執行模式支持&lt;/li&gt; 
 &lt;li&gt;Redis: 批量執行命令支持&lt;/li&gt; 
 &lt;li&gt;Redis: 導出命令文件支持&lt;/li&gt; 
 &lt;li&gt;更新中文語言支持 (zh-CN/zh-SG/zh-Hans/zh-Hant)&lt;/li&gt; 
 &lt;li&gt;修復: 修復修改連接時無法更新視圖的問題&lt;/li&gt; 
 &lt;li&gt;修復: 無法刪除多個鍵問題&lt;/li&gt; 
 &lt;li&gt;修復: 分片日誌格式化崩潰問題&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;下載與安裝&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv8.0.1.801.html" target="_blank"&gt;袋鼠數據庫管理工具 8.0.1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;新版本功能快照&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv8.0.1.801.html" target="_blank"&gt;&lt;img alt="控制枱內建命令組" src="https://oscimg.oschina.net/oscnet/up-ab23d404a593fc1845d9c6d849cb0e7442a.png" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv8.0.1.801.html" target="_blank"&gt;&lt;img alt="Pub/Sub 界面截圖" src="https://oscimg.oschina.net/oscnet/up-d3fff6fabaddd24d17f8b36bb308e231c39.png" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv8.0.1.801.html" target="_blank"&gt;&lt;img alt="Redis 鍵編輯截圖" src="https://oscimg.oschina.net/oscnet/up-bb04d911533d016ad6de240dd0b97a8907c.png" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363484/kangaroo-8-0-1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363484/kangaroo-8-0-1</guid>
      <pubDate>Wed, 16 Jul 2025 12:18:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Grok 即將推出「Imagine」功能，支持生成帶音頻的視頻</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.eonmsk.com%2F2025%2F07%2F28%2Fxai-grok-imagine-feature%2F" target="_blank"&gt;據報道&lt;/a&gt;，xAI 即將為 Grok iOS 應用推出全新圖像視頻生成功能「Imagine」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持帶音頻的視頻生成（類似谷歌 Veo 3）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可一次性生成 4 段視頻&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成速度顯著提升&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據悉，Grok 的生成模型 Aurora 已經升級，馬斯克表示正在修復相關的 bug。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bf9b9170ad1451344a226fff915855c764c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從早期泄露的信息來看，Imagine 將在 Grok 的應用和網頁版中擁有獨立的標籤頁，與原有的文字對話功能並列。&lt;/p&gt; 
&lt;p&gt;Grok 屆時將提供兩個主要入口：「Ask」用於文字問答，「Imagine」則專注於圖像與視頻生成，用戶可以在兩者之間自由切換，使用更便捷。&lt;/p&gt; 
&lt;p&gt;在 Imagine 頁面中，除了展示一些預先生成的圖像和視頻供用戶探索外，還提供完整的創作自由。你可以手動輸入 Prompt（提示詞）生成內容，也可以通過語音方式來描述想要創作的畫面或場景。&lt;/p&gt; 
&lt;p&gt;每次生成後，系統會給出 4 個不同版本的視頻供你挑選，每段視頻都配有不同的背景音效。生成結果會附帶一些實用按鈕，例如收藏、下載、在線分享，還可以點擊「Redo」重新生成內容。&lt;/p&gt; 
&lt;p&gt;同時，Imagine 還提供多種預設模式可選，包括 Spicy（火辣）、Fun（風趣）和 Normal（常規）。此外，Imagine 頁面還支持無限瀏覽推薦內容，用戶可以持續向下滑動，探索更多圖像與視頻變體。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363480/xai-grok-imagine-feature</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363480/xai-grok-imagine-feature</guid>
      <pubDate>Wed, 16 Jul 2025 11:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ESP32 + MCP over MQTT：從 0 到 1 打造情感陪伴智能體</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;AI + IoT 的具象化：真正「懂你」的情感陪伴智能體&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;智能硬件的發展經歷了幾個階段：從最初的「能聯網」，到後來「能聽你説話」，再到今天，我們希望它不僅能理解你的話，還能回應你，甚至陪伴你。想象以下的幾個場景：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;下班回家，它主動問候你：「今天看起來有點疲憊，要不要幫你調暗燈光，放點輕音樂？」&lt;/li&gt; 
 &lt;li&gt;孩子和它聊天，它能用不同角色的聲音演繹小故事。&lt;/li&gt; 
 &lt;li&gt;打開攝像頭，它看看你的穿搭，並幽默回應：「今天這身很有氣質！」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這並非只存在於科幻作品中，而是大模型（LLM）+ 多模態 AI + IoT 技術結合的必然趨勢。&lt;/p&gt; 
&lt;p&gt;傳統 IoT 設備大多依賴「命令式控制」，即系統通過硬編碼或者預置規則的方式來對設備進行控制，無法智能感知設備狀態的變化。而未來的設備將邁向語義交互和情感陪伴。情感陪伴智能體，正是這一趨勢的縮影。&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;該系列文章適合誰？&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如果你符合以下任意一種特徵，這個系列就是為你準備的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;智能硬件開發工程師：想探索 AI 如何賦能 IoT&lt;/li&gt; 
 &lt;li&gt;嵌入式/物聯網開發者：對接 AI 服務，實現語音、視覺交互&lt;/li&gt; 
 &lt;li&gt;硬件發燒友 / 創客：想 DIY 一個「有靈魂」的智能小助手&lt;/li&gt; 
 &lt;li&gt;AI 應用開發者：希望從雲端走向硬件，打通端到端體驗&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你曾經做過智能家居、機器人、AI 助手項目，這個系列能幫你提升到一個全新的交互層級。&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;背景知識要求&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;別擔心，你不需要成為全棧大神，但以下知識會讓你更輕鬆：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;硬件開發基礎：會燒寫 ESP32 程序（ESP-IDF）&lt;/li&gt; 
 &lt;li&gt;網絡通信基礎：瞭解 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.emqx.com%2Fzh%2Fblog%2Fthe-easiest-guide-to-getting-started-with-mqtt" rel="nofollow" target="_blank"&gt;MQTT 協議&lt;/a&gt;的基本概念（發佈/訂閲）&lt;/li&gt; 
 &lt;li&gt;Python 基礎：後續 LLM 和雲端應用用到 Python SDK&lt;/li&gt; 
 &lt;li&gt;AI 應用概念（選修）：知道什麼是大語言模型（LLM）、ASR（語音識別）、TTS（語音合成）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不會這些也沒關係，系列文章會逐步講解，並提供開箱即用的示例。&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;為什麼要自己做？&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;商用產品封閉無法定製，而我們希望用最經濟、最簡單的方式，構建一個功能強大的情感陪伴智能體&lt;/li&gt; 
 &lt;li&gt;藉助開源硬件（ESP32）+ 雲端 AI 接口，個人開發者也能打造接近廠商級體驗的智能體&lt;/li&gt; 
 &lt;li&gt;這個過程不僅能讓你玩出酷炫的 AI 硬件，還能深入理解 AI + IoT 的架構設計與實踐&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;本系列教程的目標&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;通過漸進式教程，帶你從零搭建一個情感陪伴智能體，它將具備：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;語音交互：聽懂你的話，並用自然語氣回答&lt;/li&gt; 
 &lt;li&gt;設備控制：通過語義指令調節屏幕亮度、音量等&lt;/li&gt; 
 &lt;li&gt;個性化人格：設定性格、喜好，具備一定記憶能力&lt;/li&gt; 
 &lt;li&gt;視覺理解：識別圖像內容，並生成趣味反饋&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;最終，你將實現這樣的體驗：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;「嘿，把屏幕調暗一點」 → &lt;em&gt;「好的，已經幫你調暗，舒服點了吧？」&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;「你看一下我，覺得怎麼樣？」 → 智能體拍攝照片並上傳 → &lt;em&gt;「呦，今天這麼好看，是想迷死誰啊？」&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;本系列教程路線圖&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th style="text-align:left"&gt;篇章&lt;/th&gt; 
   &lt;th style="text-align:left"&gt;功能&lt;/th&gt; 
   &lt;th style="text-align:left"&gt;難度&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="text-align:left"&gt;1&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;整體介紹：背景 + 環境準備 + 設備上線&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;★&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="text-align:left"&gt;2&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;從「命令式控制」到「語義控制」：MCP over MQTT 封裝設備能力&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;★★&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="text-align:left"&gt;3&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;接入 LLM，實現「自然語言 → 設備控制」&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;★★&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="text-align:left"&gt;4&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;語音 I/O：麥克風數據上傳 + 語音識別 + 語音合成回放&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;★★★&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="text-align:left"&gt;5&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;人格、情感、記憶：從「控制器」到「陪伴體」&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;★★★&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="text-align:left"&gt;6&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;給智能體增加「眼睛」：圖像採集 + 多模態理解&lt;/td&gt; 
   &lt;td style="text-align:left"&gt;★★★&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;技術棧一覽&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ESP32：低成本 + Wi-Fi/Bluetooth + 豐富外設，智能硬件項目首選&lt;/li&gt; 
 &lt;li&gt;MQTT 協議：輕量、實時、跨平台，IoT 標配&lt;/li&gt; 
 &lt;li&gt;MCP (Model Context Protocol) Over MQTT 
  &lt;ul&gt; 
   &lt;li&gt;讓 LLM 通過「工具調用」直接控制硬件&lt;/li&gt; 
   &lt;li&gt;設備服務以「能力聲明」方式註冊，AI 調用自然、標準&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;AI 能力： 
  &lt;ul&gt; 
   &lt;li&gt;LLM：處理自然語言、控制意圖&lt;/li&gt; 
   &lt;li&gt;ASR/TTS：語音識別與合成&lt;/li&gt; 
   &lt;li&gt;VLM（多模態大模型）：視覺理解，生成有趣描述&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;雲端服務： 
  &lt;ul&gt; 
   &lt;li&gt;EMQX Serverless，或者本地安裝的 EMQX&lt;/li&gt; 
   &lt;li&gt;開源 AI 框架：LangChain / LangFlow / LlamaIndex，本文選擇的是 LlamaIndex&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;一句話概括架構：ESP32 做「硬件執行器」，雲端 AI 做「大腦」，MQTT + MCP 做「神經通路」。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;硬件清單&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;為完成本教程所有相關的功能，推薦準備以下硬件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ESP32-S3-DevKitC（熟悉開發版的可以選擇其他型號）&lt;/li&gt; 
 &lt;li&gt;INMP441 麥克風模塊&lt;/li&gt; 
 &lt;li&gt;功放 MAX98357A&lt;/li&gt; 
 &lt;li&gt;喇叭 2-3W&lt;/li&gt; 
 &lt;li&gt;IIC 接口的液晶顯示器&lt;/li&gt; 
 &lt;li&gt;OV2640 攝像頭模塊&lt;/li&gt; 
 &lt;li&gt;400 孔麪包板以及杜邦線一套&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;總體系統架構設計&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://assets.emqx.com/images/2d0152b47bd29e2d883575bd7c9c2c67.png" alt="image.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;硬件層：ESP32 + 麥克風 + 揚聲器 + 攝像頭 + 屏幕。&lt;/li&gt; 
 &lt;li&gt;連接層：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.emqx.com%2Fzh%2Fblog%2Fthe-ultimate-guide-to-mqtt-broker-comparison" rel="nofollow" target="_blank"&gt;MQTT Broker&lt;/a&gt;（EMQX） + MCP 協議。&lt;/li&gt; 
 &lt;li&gt;AI 服務層：自然語言處理、語音合成、視覺識別、人格邏輯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 服務方面，本文選擇了阿里雲的語音識別，語音合成，大模型以及多模態大模型的服務。&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;第一個目標：讓設備上線&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本實踐主要是為了把 ESP32 設備連接到服務器，併發送消息&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://assets.emqx.com/images/ad358c414d6748ea4883bef28151e20a.png" alt="image.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如圖所示，&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;ESP32 連接 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.emqx.com%2Fzh%2Fcloud%2Fserverless-mqtt" rel="nofollow" target="_blank"&gt;EMQX Serveless&lt;/a&gt; 服務&lt;/li&gt; 
 &lt;li&gt;MQTTX（作為服務端的應用）也連接到 EMQX Serveless，訂閲主題 &lt;code&gt;emqx/esp32&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ESP32 發佈消息 &lt;code&gt;Hi EMQX I'm ESP32 ^^&lt;/code&gt; 到主題 &lt;code&gt;emqx/esp32&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;MQTTX 接收到上述消息&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;硬件：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ESP32 開發板（推薦 DevKitC，帶 USB 轉串口）&lt;/li&gt; 
 &lt;li&gt;USB 數據線（注意必須支持數據傳輸）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;軟件 ：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ESP-IDF&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;安裝 ESP-IDF&lt;/li&gt; 
   &lt;li&gt;安裝 ESP-IDF 依賴，參考官方文檔 - &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fidf.espressif.com%2F" rel="nofollow" target="_blank"&gt;ESP-IDF Getting Started | Espressif Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;安裝 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2F" rel="nofollow" target="_blank"&gt;VS Code&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;VS Code 中安裝 ESP-IDF 擴展&lt;/li&gt; 
   &lt;li&gt;參考 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fespressif%2Fvscode-esp-idf-extension" rel="nofollow" target="_blank"&gt;配置開發環境&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;MQTT 客戶端測試工具：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmqttx.app%2F" rel="nofollow" target="_blank"&gt;MQTTX: Your All-in-one MQTT Client Toolbox&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;驅動注意：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows 用戶可能需要安裝 CP210x 或 CH340 串口驅動&lt;/li&gt; 
 &lt;li&gt;macOS/Linux 通常即插即用&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;註冊 EMQX Serverless&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;MQTT 作為智能體和雲端大模型的傳輸協議，後續所有功能（語音、視覺、AI 控制）都依賴它與雲端實時通信。為降低難度，避免本地安裝和配置等複雜過程，推薦讀者使用 EMQX MQTT 雲服務。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;訪問 EMQX Serverless - &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.emqx.com%2Fzh%2Fcloud%2Fserverless-mqtt" rel="nofollow" target="_blank"&gt;安全、可伸縮的 Serverless MQTT 消息服務。&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;按照網站的提示創建，註冊賬號，創建 MQTT 服務實例，獲取以下信息： 
  &lt;ul&gt; 
   &lt;li&gt;Broker 地址&lt;/li&gt; 
   &lt;li&gt;用戶名 / 密碼&lt;/li&gt; 
   &lt;li&gt;端口號（MQTT over TLS 推薦 8883）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：您也可以根據自己的情況，在本機或者內網中部署一個 EMQX Broker，這樣做的好處是可以降低 ESP32 與遠程服務器之間的網絡時延 - &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.emqx.com%2Fzh%2Femqx%2Flatest%2Fdeploy%2Finstall-docker.html" rel="nofollow" target="_blank"&gt;通過 Docker 運行 EMQX | EMQX 文檔&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://assets.emqx.com/images/1bbfb54fb08a2c9d9dbcb69daf071fee.png" alt="image.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;編譯 &amp;amp; 燒錄 ESP32 程序&lt;/strong&gt;&lt;/h3&gt; 
&lt;span id="OSC_h4_13"&gt;&lt;/span&gt; 
&lt;h4&gt;代碼目錄&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;| - CMakeLists.txt
| - sdkconfig
| - main
| --- main.c
| --- CMakeLists.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_14"&gt;&lt;/span&gt; 
&lt;h4&gt;CMakeLists.txt&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;# The following lines of boilerplate have to be in your project's
# CMakeLists in this exact order for cmake to work correctly
cmake_minimum_required(VERSION 3.16)
set(CMAKE_EXPORT_COMPILE_COMMANDS ON)

include($ENV{IDF_PATH}/tools/cmake/project.cmake)
project(main)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_15"&gt;&lt;/span&gt; 
&lt;h4&gt;sdkconfig&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;CONFIG_MQTT_PROTOCOL_5=y
CONFIG_ESP_WIFI_SOFTAP_SUPPORT=n
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_16"&gt;&lt;/span&gt; 
&lt;h4&gt;main/main.c&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-c"&gt;#include &amp;lt;stdio.h&amp;gt;

#include "freertos/FreeRTOS.h"
#include "freertos/event_groups.h"
#include "freertos/task.h"

#include "esp_log.h"
#include "esp_mac.h"
#include "esp_system.h"
#include "esp_wifi.h"
#include "mqtt_client.h"
#include "nvs_flash.h"

#define PIN_NUM_SCLK 21
#define PIN_NUM_MOSI 47
#define PIN_NUM_MISO -1

#define LCD_H_RES 240

static EventGroupHandle_t s_wifi_event_group;
static int                s_retry_num = 0;
static esp_mqtt_client_handle_t client;

static const char *WIFI_SSID     = "wifi_ssid";
static const char *WIFI_PASSWORD = "wifi_password";
static const char *MQTT_BROKER =
    "mqtts://xxyyzzz:8883";
static const char *username = "user";
static const char *password = "password";
static const char *cert =
    "-----BEGIN CERTIFICATE-----\n"
    "MIIDrzCCApegAwIBAgIQCDvgVpBCRrGhdWrJWZHHSjANBgkqhkiG9w0BAQUFADBh\n"
    "MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\n"
    "d3cuZGlnaWNlcnQuY29tMSAwHgYDVQQDExdEaWdpQ2VydCBHbG9iYWwgUm9vdCBD\n"
    "QTAeFw0wNjExMTAwMDAwMDBaFw0zMTExMTAwMDAwMDBaMGExCzAJBgNVBAYTAlVT\n"
    "MRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMxGTAXBgNVBAsTEHd3dy5kaWdpY2VydC5j\n"
    "b20xIDAeBgNVBAMTF0RpZ2lDZXJ0IEdsb2JhbCBSb290IENBMIIBIjANBgkqhkiG\n"
    "9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4jvhEXLeqKTTo1eqUKKPC3eQyaKl7hLOllsB\n"
    "CSDMAZOnTjC3U/dDxGkAV53ijSLdhwZAAIEJzs4bg7/fzTtxRuLWZscFs3YnFo97\n"
    "nh6Vfe63SKMI2tavegw5BmV/Sl0fvBf4q77uKNd0f3p4mVmFaG5cIzJLv07A6Fpt\n"
    "43C/dxC//AH2hdmoRBBYMql1GNXRor5H4idq9Joz+EkIYIvUX7Q6hL+hqkpMfT7P\n"
    "T19sdl6gSzeRntwi5m3OFBqOasv+zbMUZBfHWymeMr/y7vrTC0LUq7dBMtoM1O/4\n"
    "gdW7jVg/tRvoSSiicNoxBN33shbyTApOB6jtSj1etX+jkMOvJwIDAQABo2MwYTAO\n"
    "BgNVHQ8BAf8EBAMCAYYwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUA95QNVbR\n"
    "TLtm8KPiGxvDl7I90VUwHwYDVR0jBBgwFoAUA95QNVbRTLtm8KPiGxvDl7I90VUw\n"
    "DQYJKoZIhvcNAQEFBQADggEBAMucN6pIExIK+t1EnE9SsPTfrgT1eXkIoyQY/Esr\n"
    "hMAtudXH/vTBH1jLuG2cenTnmCmrEbXjcKChzUyImZOMkXDiqw8cvpOp/2PV5Adg\n"
    "06O/nVsJ8dWO41P0jmP6P6fbtGbfYmbW0W5BjfIttep3Sp+dWOIrWcBAI+0tKIJF\n"
    "PnlUkiaY4IBIqDfv8NZ5YBberOgOzW6sRBc4L0na4UU+Krk2U886UAb3LujEV0ls\n"
    "YSEY1QSteDwsOoBrp+uvFRTp2InBuThs4pFsiv9kuXclVzDAGySj4dzp30d8tbQk\n"
    "CAUw7C29C79Fv1C5qfPrmAESrciIxpg0X40KPMbp1ZWVbd4=\n"
    "-----END CERTIFICATE-----";

static void event_handler(void *arg, esp_event_base_t event_base,
                          int32_t event_id, void *event_data)
{
    if (event_base == WIFI_EVENT &amp;amp;&amp;amp; event_id == WIFI_EVENT_STA_START) {
        esp_wifi_connect();
    } else if (event_base == WIFI_EVENT &amp;amp;&amp;amp;
               event_id == WIFI_EVENT_STA_DISCONNECTED) {
        if (s_retry_num &amp;lt; 5) {
            esp_wifi_connect();
            s_retry_num++;
            ESP_LOGI("wifi sta", "retry to connect to the AP");
        } else {
            xEventGroupSetBits(s_wifi_event_group, BIT1);
        }
        ESP_LOGI("wifi sta", "connect to the AP fail");
    } else if (event_base == IP_EVENT &amp;amp;&amp;amp; event_id == IP_EVENT_STA_GOT_IP) {
        ip_event_got_ip_t *event = (ip_event_got_ip_t *) event_data;
        ESP_LOGI("wifi sta", "ip: " IPSTR ", mask: " IPSTR ", gateway: " IPSTR,
                 IP2STR(&amp;amp;event-&amp;gt;ip_info.ip), IP2STR(&amp;amp;event-&amp;gt;ip_info.netmask),
                 IP2STR(&amp;amp;event-&amp;gt;ip_info.gw));
        s_retry_num = 0;
        xEventGroupSetBits(s_wifi_event_group, BIT0);
    }
}

int wifi_init_sta(void)
{
    s_wifi_event_group = xEventGroupCreate();

    ESP_ERROR_CHECK(esp_netif_init());
    ESP_ERROR_CHECK(esp_event_loop_create_default());

    esp_netif_create_default_wifi_sta();
    wifi_init_config_t cfg = WIFI_INIT_CONFIG_DEFAULT();
    ESP_ERROR_CHECK(esp_wifi_init(&amp;amp;cfg));

    esp_event_handler_instance_t instance_any_id;
    esp_event_handler_instance_t instance_got_ip;

    ESP_ERROR_CHECK(esp_event_handler_instance_register(
        WIFI_EVENT, ESP_EVENT_ANY_ID, &amp;amp;event_handler, NULL, &amp;amp;instance_any_id));
    ESP_ERROR_CHECK(esp_event_handler_instance_register(
        IP_EVENT, IP_EVENT_STA_GOT_IP, &amp;amp;event_handler, NULL, &amp;amp;instance_got_ip));

    wifi_config_t wifi_config = {
        .sta = {
            .threshold.authmode = WIFI_AUTH_WPA2_PSK,
            .sae_pwe_h2e = WPA3_SAE_PWE_BOTH,
            .sae_h2e_identifier = "",
        },
    };
    strcpy((char *) wifi_config.sta.ssid, WIFI_SSID);
    strcpy((char *) wifi_config.sta.password, WIFI_PASSWORD);
    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_STA));
    ESP_ERROR_CHECK(esp_wifi_set_config(WIFI_IF_STA, &amp;amp;wifi_config));
    ESP_ERROR_CHECK(esp_wifi_start());

    ESP_LOGI("wifi sta", "wifi init finished.");

    EventBits_t bits = xEventGroupWaitBits(s_wifi_event_group, BIT0 | BIT1,
                                           pdFALSE, pdFALSE, portMAX_DELAY);

    if (bits &amp;amp; BIT0) {
        ESP_LOGI("wifi sta", "connected to ap SSID: %s", CONFIG_WIFI_SSID);
    } else if (bits &amp;amp; BIT1) {
        ESP_LOGI("wifi sta", "Failed to connect to SSID: %s", CONFIG_WIFI_SSID);
    } else {
        ESP_LOGE("wifi sta", "UNEXPECTED EVENT");
    }

    return 0;
}

static void mqtt5_event_handler(void *handler_args, esp_event_base_t base,
                                int32_t event_id, void *event_data)
{
    char *TAG = "mqtt5";
    ESP_LOGD(TAG, "Event dispatched from event loop base=%s, event_id=%" PRIi32,
             base, event_id);
    esp_mqtt_event_handle_t  event  = event_data;
    esp_mqtt_client_handle_t client = event-&amp;gt;client;
    int                      msg_id;

    ESP_LOGD(TAG, "free heap size is %" PRIu32 ", minimum %" PRIu32,
             esp_get_free_heap_size(), esp_get_minimum_free_heap_size());
    ESP_LOGI(TAG, "event_id=%" PRIi32, event_id);

    switch ((esp_mqtt_event_id_t) event_id) {
    case MQTT_EVENT_CONNECTED:
        msg_id = esp_mqtt_client_publish(client, "emqx/esp32",
                                         "Hi EMQX I'm ESP32 ^^", 0, 1, 0);
        ESP_LOGI(TAG, "sent publish successful, msg_id=%d", msg_id);
        break;
    case MQTT_EVENT_DISCONNECTED:
    case MQTT_EVENT_SUBSCRIBED:
    case MQTT_EVENT_PUBLISHED:
    case MQTT_EVENT_DATA:
        break;
    case MQTT_EVENT_UNSUBSCRIBED:
        esp_mqtt_client_disconnect(client);
        break;
    case MQTT_EVENT_ERROR:
        ESP_LOGI(TAG, "MQTT5 return code is %d",
                 event-&amp;gt;error_handle-&amp;gt;connect_return_code);
        if (event-&amp;gt;error_handle-&amp;gt;error_type == MQTT_ERROR_TYPE_TCP_TRANSPORT) {
            ESP_LOGI(TAG, "Last errno string (%s)",
                     strerror(event-&amp;gt;error_handle-&amp;gt;esp_transport_sock_errno));
        }
        break;
    default:
        ESP_LOGI(TAG, "Other event id:%d", event-&amp;gt;event_id);
        break;
    }
}

int mqtt_init(void)
{
    esp_mqtt_client_config_t mqtt5_cfg = {
        .broker.address.uri                  = MQTT_BROKER,
        .session.protocol_ver                = MQTT_PROTOCOL_V_5,
        .network.disable_auto_reconnect      = true,
        .credentials.username                = username,
        .credentials.authentication.password = password,
        .broker.verification.certificate     = cert,
    };

    client = esp_mqtt_client_init(&amp;amp;mqtt5_cfg);
    esp_mqtt_client_register_event(client, ESP_EVENT_ANY_ID,
                                   mqtt5_event_handler, NULL);
    esp_mqtt_client_start(client);
    return 0;
}

void app_main(void)
{
    esp_err_t ret = nvs_flash_init();
    if (ret == ESP_ERR_NVS_NO_FREE_PAGES ||
        ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {
        ESP_ERROR_CHECK(nvs_flash_erase());
        ret = nvs_flash_init();
    }
    ESP_ERROR_CHECK(ret);

    wifi_init_sta();
    mqtt_init();

    while (1) {
        vTaskDelay(pdMS_TO_TICKS(3000));
        int msg_id = esp_mqtt_client_publish(client, "emqx/esp32",
                                             "Hi EMQX I'm ESP32 ^^", 0, 1, 0);
        ESP_LOGI("mqtt", "sent publish successful, msg_id=%d", msg_id);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_17"&gt;&lt;/span&gt; 
&lt;h4&gt;main/CMakeLists.txt&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;idf_component_register(SRCS "main.c"
                    PRIV_REQUIRES mqtt esp_wifi nvs_flash
                    INCLUDE_DIRS ".")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;修改 WIFI 以及 MQTT 服務相關配置 main/main.c 如下所示，替換為你自己的配置信息，&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Wi-Fi 名稱、密碼&lt;/li&gt; 
 &lt;li&gt;在 Serverless 上申請的地址，以及用戶名和密碼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-c"&gt;static const char *WIFI_SSID     = "wifi_ssid";
static const char *WIFI_PASSWORD = "wifi_password";
static const char *MQTT_BROKER =
    "mqtts://xxyyzzz:8883";
static const char *username = "user";
static const char *password = "password";
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_18"&gt;&lt;/span&gt; 
&lt;h4&gt;編譯代碼並且燒錄到 esp32 中&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;idf.py build 
idf.py flash monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;燒錄完成後，ESP32 將每隔 3 秒發送 &lt;code&gt;Hi EMQX I'm ESP32 ^^&lt;/code&gt; 到 &lt;code&gt;emqx/esp32&lt;/code&gt; 主題。&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;驗證&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;打開 MQTTX，配置 MQTT 連接，如下圖所示，&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Host 中填入你在 EMQX Serverless 申請的服務地址&lt;/li&gt; 
 &lt;li&gt;Username 和 Password 中輸入連接的用戶名和密碼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://assets.emqx.com/images/d12a76daacc575471fc45eea5e74a3c9.png" alt="image.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;連接成功後，添加一個新的訂閲，在主題中輸入 &lt;code&gt;emqx/esp32&lt;/code&gt;，如果看到以下內容：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://assets.emqx.com/images/a67b868b203bb1af0f1b9b874883f9fc.png" alt="image.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;恭喜！你的設備已經成功接入 MQTT。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;問題診斷：如果收不到消息，我該怎麼辦？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以登錄到 EMQX Serverless 上看一下有沒有你連接上來的 ESP32 設備。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果沒有，大概率是你的設備端有問題。 
  &lt;ul&gt; 
   &lt;li&gt;再次檢查一下源代碼中指定的地址、用戶名和密碼。&lt;/li&gt; 
   &lt;li&gt;確定網絡狀態，以及 Wi-Fi 信息&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;如果有，那麼可能是你的 MQTTX 指定的連接或者主題不對。 
  &lt;ul&gt; 
   &lt;li&gt;再次檢查一下 MQTTX 中指定的地址、用戶名和密碼。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_20"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;下篇預告&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在下一篇中，我們將讓 ESP32 「暴露」自己的控制能力，通過 MCP 協議註冊亮度、音量調節接口，讓 MCP 的客戶端 Python 應用可以訪問和列出所有在 ESP32 上安裝的工具列表。&lt;/p&gt; 
&lt;span id="OSC_h2_21"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;資源&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MQTT 協議相關的基本材料：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.emqx.com%2Fzh%2Femqx%2Flatest%2Fconnect-emqx%2Fdeveloper-guide.html" rel="nofollow" target="_blank"&gt;開發者指南 | EMQX 文檔&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;EMQX Serverless 免費註冊 - &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.emqx.com%2Fzh%2Fcloud%2Fserverless-mqtt" rel="nofollow" target="_blank"&gt;安全、可伸縮的 Serverless MQTT 消息服務。&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MQTT 客戶端工具：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmqttx.app%2F" rel="nofollow" target="_blank"&gt;MQTTX: Your All-in-one MQTT Client Toolbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ESP32 官方網站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.espressif.com.cn%2Fen%2Fproducts%2Fsocs%2Fesp32" rel="nofollow" target="_blank"&gt;https://www.espressif.com.cn/en/products/socs/esp32&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4174826/blog/18686619</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4174826/blog/18686619</guid>
      <pubDate>Wed, 16 Jul 2025 11:25:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>飛致雲開源社區月度動態報告（2025 年 7 月）</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p style="color:#000000"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;自 2023 年 6 月起，中國領先的開源軟件公司飛致雲以月度為單位發佈《飛致雲開源社區月度動態報告》，旨在向廣大社區用戶同步飛致雲旗下系列開源軟件的發展情況，以及當月主要的產品新版本發佈、社區運營成果等相關信息。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;飛致雲開源運營數據概覽（2025 年 7 月）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;2025 年 7 月飛致雲開源軟件運營數據概覽（統計時間為 2025.7.1～2025.7.31）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=NmYwZTNlZTY3MmQ2Zjg5NjlhYjk1OTQ0N2Q1ZGIxZGEsMTc1Mzk1NjQ4Njc3MA==" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#3370ff"&gt;2025 年 7 月產品發佈事件&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ MeterSphere 開源持續測試工具&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#010101"&gt;2025 年 7 月 14 日，MeterSphere 開源持續測試工具發佈了 v3.6.5 LTS 版本。在這一版本中，MeterSphere 開源項目組對排序字段存在 SQL 注入風險的缺陷進行了修復。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ JumpServer 開源堡壘機&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#010101"&gt;2025 年 7 月 17 日，廣受歡迎的開源堡壘機 JumpServer 發佈了 v4.10.4 LTS 版本。在這一版本中，JumpServer 項目組進行了包括優化操作日誌在內的 9 項功能優化工作。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ MaxKB 開源企業級智能體平台&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#010101"&gt;2025 年 7 月 18 日，MaxKB V2 版本正式發佈。MaxKB 是一個強大易用的企業級智能體平台，致力於解決企業 AI 落地所面臨的技術門檻高、部署成本高、迭代週期長等問題，讓企業用戶落地 AI 更簡單。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#010101"&gt;在 V2 版本中，MaxKB 的多租戶權限管理體系全面升級，能夠有效滿足多組織、多部門及多用戶羣體的權限與資源管理需求，實現權限與資源的精準管控；新增共享資源管理功能，支持跨工作空間的資源複用與協作；新增對話用戶管理功能，支持提問端身份驗證，能夠實現對用戶提問範圍和知識檢索權限的管理與控制；新增支持按文件夾目錄管理應用、知識庫、工具和模型四類核心資源。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#010101"&gt;此外，MaxKB V2 社區版本全面開放對用戶數量、知識庫數量和應用數量的限制，助力廣大社區用戶加速構建並運營生產級別的智能體應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ 1Panel 開源面板&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#010101"&gt;2025 年 7 月 24 日，現代化、開源的 Linux 服務器運維管理面板 1Panel 正式發佈 v2.0.5 版本。在這一版本中，1Panel 新增數據庫集羣部署、郵件告警和主從節點靈活切換三項功能，聚焦為企業級運維場景提供更優使用體驗。1Panel v2.0.5 版本是 1Panel 開源面板項目在交付企業級集羣化和高可用能力方面邁出的關鍵一步。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#3370ff"&gt;其他重要事件&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ MaxKB 入選中國 AI 領域高潛力開源項目（2025 年第一期）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;2025 年 7 月 5 日，在 2025 全球數字經濟大會·全球開源創新發展論壇上，國家工業信息安全發展研究中心聯合開源指南針社區（OSS Compass）、南京大學、開放原子開源基金會、開源中國、CSDN 等單位，共同發佈開源項目質效量化評估和智能預測體系以及中國人工智能開源項目質效評估洞察。飛致雲旗下 MaxKB 開源項目入選「中國 AI 領域高潛力開源項目」（2025 年第一期）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ MaxKB 在企業環境中實現 AI 落地的具體場景盤點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;近期，MaxKB 新增的企業用戶包括：河北鑫達集團、北京鋭融天下科技股份有限公司、廣州港南沙集裝箱三期碼頭、國元期貨有限公司、中信泰富特鋼集團、濟南地鐵、深圳聯合產權交易所股份有限公司、新疆兵團勘測設計院集團股份有限公司、安徽公共資源交易集團有限公司、中電建商業保理有限公司、四川航空、北京建工六建集團、中國有色金屬工業西安勘察設計研究院、國藥集團國瑞藥業有限公司、大唐寧德發電公司和上海豫園旅遊商城（集團）股份有限公司。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;在本輪收集到的 16 家企業用戶中，MaxKB 的使用場景包括智能客服、業務 AI 助手、員工服務、人力與財務管理等。其中，智能客服是 MaxKB 的高頻使用場景之一，有 6 家企業基於 MaxKB 構建並運營智能客服系統。MaxKB 與企業業務的深度結合也是一個重要的方向，在港口、地鐵、建築、發電等場景中，MaxKB 正在被應用在設備管理、車輛調度、機電設計、缺陷管理等領域。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ 飛致雲開源項目入駐 GitCode，打造開發者最強工具箱！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;2025 年 7 月，飛致雲旗下的開源項目 1Panel 開源面板、MaxKB 開源企業級智能體平台、JumpServer 開源堡壘機、DataEase 開源 BI 工具、MeterSphere 開源持續測試工具和 Halo 開源建站工具正式加入 GitCode 開源開發者平台，並且成為 G-Star 畢業項目，為開發者帶來了覆蓋運維、安全、數據分析等領域的專業級工具。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ MaxKB 亮相 2025 世界人工智能大會&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;MaxKB 聯合超聚變打造的 MaxKB 企業級智能體平台一體機解決方案亮相於 2025 年 7 月 26 日開幕的 2025 世界人工智能大會（WAIC 2025）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-1edf8e7f21b546bf89b82f8fc65730642b9.jpg" width="1620" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 1 MaxKB 亮相 2025 世界人工智能大會&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ 1Panel 開源面板 GitHub Star 數量突破 30,000 個！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;截至 2025 年 7 月 23 日 20:00，飛致雲旗下開源項目——1Panel 開源 Linux 服務器運維管理面板 GitHub Star 數超過 30,000 個！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;繼 Halo 之後，1Panel 成為飛致雲旗下第二個 GitHub Star 數量超過 30,000 個的開源項目，也是飛致雲旗下最快達成 30,000 個 GitHub Star 目標的項目。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-4fa891f28867f5e17eed7ff8baaa34c0c5b.jpg" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 2 1Panel 成為飛致雲旗下最快達成 30,000 個 GitHub Star 目標的項目&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00355d"&gt;■ 1Panel 應用商店下載趨勢及下載排名情況&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#3e3e3e"&gt;為了方便廣大用戶快捷安裝部署相關軟件應用，1Panel 特別開通應用商店，精選各類高質量的開源工具和應用軟件，為用戶的應用安裝與升級操作提供便利。目前，1Panel 應用商店已經上架了超過 180 款精品軟件並且定期更新維護，成為了開源軟件用戶的系統裝機神器。&lt;/span&gt;&lt;strong&gt;&lt;span style="color:#ff8124"&gt;2025 年 7 月，1Panel 應用商店軟件下載量達到 232,945 次。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="848" src="https://oscimg.oschina.net/oscnet/up-cee79e42e6dc4ef3656783eaf145fad50a4.png" width="1220" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 3 1Panel 應用商店月下載總量統計&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="814" src="https://oscimg.oschina.net/oscnet/up-67a5b296fe41369f105a261de689c0c9078.png" width="1178" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 4 1Panel 應用商店軟件下載排名 Top 20（2025 年 7 月）&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4736111/blog/18686621</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/18686621</guid>
      <pubDate>Wed, 16 Jul 2025 11:01:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Meta 計劃 2025 年斥資最高 720 億美元建設 AI 基礎設施</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Meta &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F07%2F30%2Fmeta-to-spend-up-to-72b-on-ai-infrastructure-in-2025-as-compute-arms-race-escalates%2F" target="_blank"&gt;計劃&lt;/a&gt;在 2025 年投入 660 億至 720 億美元用於 AI 基礎設施建設，包括數據中心和服務器等。按中間值計算，同比增加約 300 億美元。Meta 首席財務官蘇珊・李表示，開發領先的 AI 基礎設施將成為開發最優秀 AI 模型和產品體驗的核心優勢，因此公司計劃在 2026 年繼續大幅增加投資。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-546675b820004ef0950dda417dfc593cd82.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Meta 正在建設多個 AI 超級集羣，包括位於俄亥俄州的「普羅米修斯」集羣，預計 2026 年上線後將成為首批計算能力達到 1 千兆瓦的 AI 超級集羣之一；以及路易斯安那州的「海伯利昂」集羣，其規模相當於整個曼哈頓，未來數年可擴展至 5 千兆瓦。此外，Meta 還在建設其他幾個未命名的泰坦級集羣。&lt;/p&gt; 
&lt;p&gt;除了硬件設施的投入，Meta 也在積極儲備人才，斥資數億甚至數十億美元從競爭對手處挖角 AI 工程師和研究人員，充實新成立的「超級人工智能實驗室」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363471</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363471</guid>
      <pubDate>Wed, 16 Jul 2025 10:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>200 萬的 AI 服務器壞了，返修要半年，深圳老哥兩週就給你修好！</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;你知道國內 GPU 維修集中在哪嗎？答案是深圳，特別是早期的華強北。&lt;/p&gt; 
&lt;p&gt;這裏曾是顯卡維修的發源地，尤其是消費級顯卡，因為圖紙公開，維修門檻低。可現在，核心業務早已轉向高端計算卡，比如 A100、H100、4090 這些禁售卡。維修這些卡，技術門檻高，還得是幹過台積電、富士康、英偉達的老工程師才行。&lt;/p&gt; 
&lt;p&gt;現在全國能修這類卡的團隊，基本也就集中在深圳，維修流程專業、完整，從上機檢測到核心移植，一張卡動輒十幾萬，可不是隨便焊電路板那麼簡單。&lt;/p&gt; 
&lt;p&gt;國內大部分 GPU 維修點，都在深圳，華強北電子產業繁榮，滋生了相關產業鏈，很好承接了這部分需要。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0731/183053_jQ95_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從 2022 年開始，英偉達就陸續在中國禁售 A100/H100 及 A800/H800 等高端 GPU，國內不存在「官方」售後服務了。因此，國內就出現很多 GPU 維修的公司，最快只需要 2 個禮拜就能完成。&lt;/p&gt; 
&lt;p&gt;有人根據保有量和故障率預測，這是一筆百億元的產業。這幾百億的產業，應該基本都要落到深圳的兜裏。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;更多精彩內容，掃碼觀看視頻：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0731/182758_Y5ZC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363470</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363470</guid>
      <pubDate>Wed, 16 Jul 2025 10:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub Copilot 用戶總數突破 2000 萬</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;微軟首席執行官薩蒂亞·納德拉在週三的公司&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2FInvestor%2Fearnings%2FFY-2025-Q4%2Fpress-release-webcast" target="_blank"&gt;&lt;span style="color:#2980b9"&gt;財報電話會議&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;上表示，微軟旗下 GitHub 提供的 AI 編程工具 GitHub Copilot 的用戶數量現已超過 2000 萬。GitHub 發言人向 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F07%2F30%2Fgithub-copilot-crosses-20-million-all-time-users%2F" target="_blank"&gt;TechCrunch&lt;/a&gt; 證實，這個數字代表的是「總用戶數」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這意味着在過去三個月中，已有 500 萬人首次嘗試使用 GitHub Copilot；該公司在 4 月份報告稱，該工具的用戶已達 1500 萬。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟還報告稱，GitHub Copilot 是目前最受歡迎的 AI 編碼工具之一，被 90% 的《財富》100 強企業所使用。據該公司稱，該產品在企業客戶中的增長也比上一季度增長了約 75%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-a9c4f03844fb818759eb957360032e04e77.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI 編程工具越來越受歡迎，它們似乎是少數幾個能帶來可觀收入的 AI 產品之一。納德拉在 2024 年表示，GitHub Copilot 的業務規模將超過微軟 2018 年收購 GitHub 時的整體規模。自那以後的一年裏，GitHub Copilot 的增長率似乎一直保持着積極的方向。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與 ChatGPT 和 Gemini 等每月吸引數億用戶的 AI 聊天機器人相比，全球最受歡迎的 AI 編程工具的用戶羣仍然很小。當然，軟件工程比 AI 聊天機器人提供的一般信息查詢更為小眾。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;話雖如此，軟件工程師及其僱主似乎願意為 AI 編碼工具支付溢價。憑藉微軟眾多的企業客戶和 GitHub 的開發者生態系統，GitHub Copilot 完全有能力在企業 AI 編碼工具市場佔據主導地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一款熱門的 AI 編程工具 Cursor 也希望在企業領域挑戰 GitHub Copilot，並一直在從新興的 AI 初創公司挖角人才。據彭博社報道，今年 3 月，Cursor 的日均使用人數超過 100 萬。當時，該公司的年化經常性收入約為 2 億美元。如今，Cursor 的年平均經常性收入 (ARR) 已超過 5 億美元，這意味着現在每天使用其產品的人數正在大幅增加。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363469</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363469</guid>
      <pubDate>Wed, 16 Jul 2025 10:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌發佈地理空間 AI 模型 Google Earth AI</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌正式發佈了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-earth-ai%2F"&gt;Google Earth AI，&lt;/a&gt;這是一個集成了先進地理空間 AI 模型和數據集的平台，旨在幫助應對全球性的關鍵挑戰。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0731/181003_MK8N_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Google Earth AI 涵蓋多個領域的模型，包括用於詳細天氣預測、洪水預報和野火探測的模型，這些模型已經為 Google 搜索和 Google 地圖中的洪水與野火警報等功能提供了支持。此外，還有用於改善城市規劃和公共衞生的模型，通過對圖像、人口動態和城市交通的深入理解，為 Google Earth、Google Maps Platform 和 Google Cloud 提供可操作的洞察。&lt;/p&gt; 
&lt;p&gt;目前，Google Earth AI 在洪水預測方面已覆蓋 100 多個國家，能提前 7 天為 7 億人提供河流洪水預警；在野火追蹤方面，已在 27 國上線野火邊界監測服務。&lt;/p&gt; 
&lt;p&gt;與 Google Earth AI 一同亮相的還有其核心引擎之一：由 Google DeepMind 團隊研發的 AlphaEarth Foundations。該 AI 模型被譽為 「虛擬衞星」，正以前所未有的方式重塑全球遙感認知與地圖製作能力。&lt;/p&gt; 
&lt;p&gt;作為 Google Earth AI 的技術核心，AlphaEarth Foundations 是一個多模態 AI 模型，它能夠將 PB 級遙感數據（包括光學影像、雷達、激光點雲、氣候模擬等）統一轉化為 64 維的嵌入表達（embedding），每個 10 米 ×10 米的地表單元被壓縮為高度濃縮的數據指紋。&lt;/p&gt; 
&lt;p&gt;谷歌正計劃將 AlphaEarth 的時間序列能力與 LLMs（如 Gemini）相結合，構建具備理解 - 推理 - 決策能力的地理智能平台，為全球科研、城市規劃與生態治理賦能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363466/google-earth-ai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363466/google-earth-ai</guid>
      <pubDate>Wed, 16 Jul 2025 10:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>企查查開源彈窗組件庫 QuickDialog</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;企查查近日將其自研的鴻蒙彈窗組件庫「QuickDialog」開源，並上線至 OpenHarmony 三方庫中心倉。這是鴻蒙生態首個支持「彈窗堆棧暫存能力」的非侵入式彈窗解決方案，憑藉其靈活、高效、可複用的設計理念，有望成為鴻蒙應用開發中管理複雜彈窗場景的最佳實踐方案之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="276" src="https://oscimg.oschina.net/oscnet/up-e69e0e19205b74db65552cdc2eb0f2d990b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，QuickDialog 以「可維護、可拓展」為設計理念，圍繞複雜彈窗場景中的共性痛點，提供以下核心技術能力：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;彈窗堆棧暫存能力：&lt;/strong&gt;支持多個彈窗的層級管理與狀態保持，用戶可任意中斷或恢復某一彈窗流轉，大幅提升彈窗交互的靈活性；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;無侵入式控件創建機制：&lt;/strong&gt;採用 Node 方式動態生成彈窗內容，無需修改業務頁面結構，減少耦合，便於維護；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Overlay 接管生命週期：&lt;/strong&gt;通過將彈窗依附於自定義頁面，自主接管生命週期管理，支持彈窗與頁面雙向通信；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;裝飾器與彈窗內容解耦，支持複用：&lt;/strong&gt;支持將同一彈窗內容搭配多種裝飾器結構，靈活適配不同交互場景，提升開發效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;頁面綁定式彈窗層級自由管理：&lt;/strong&gt;每個彈窗基於頁面結構進行綁定控制，實現清晰的顯示/隱藏管理與模態規則控制。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;在企查查鴻蒙 App 的開發實踐中，QuickDialog 已全面替代傳統彈窗方案，實現了彈窗體系的統一重構。在複雜用戶操作流程中，用戶可在不同頁面中保留彈窗堆棧狀態，實現從多任務中返回繼續處理，大幅改善使用體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;對於開發者而言，QuickDialog 的接入完全基於組件調用與綁定機制，無需改動現有頁面結構或狀態流，大大降低彈窗系統的開發與維護成本，開發效率顯著提升。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363464</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363464</guid>
      <pubDate>Wed, 16 Jul 2025 10:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenPipe 發佈開源框架 AutoRL，用於簡化模型 RL 訓練</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;OpenPipe&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmattshumer_%2Fstatus%2F1950572449025650733" target="_blank"&gt;發佈&lt;/a&gt;了開源框架 AutoRL，旨在簡化使用強化學習（RL）為任何特定任務專門化訓練開源模型（如 Qwen）的過程。&lt;/p&gt; 
&lt;p&gt;AutoRL 的訓練流程是，用戶首先用一句話定義任務，隨後 AutoRL 會自動生成 30 個示例場景。Agent 使用 GRPO 算法在 25 個訓練樣本上進行訓練，最後在剩餘的 5 個測試樣本上與 SOTA 模型（如 Sonnet 4）進行性能對比測試。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0731/175842_QhNH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該框架構建於 OpenPipe 的 ART（Agentic Reasoning &amp;amp; Tool-use）之上，並使用 RULER 作為其獎勵函數。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenPipe%2FART%2Ftree%2Fauto-rl%3Ftab%3Dreadme-ov-file%23-autorl-train-models-for-any-task" target="_blank"&gt;點此查看更多介紹&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363461</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363461</guid>
      <pubDate>Wed, 16 Jul 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Charm 發佈面向終端的開源 AI 編程工具 Crush</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Charm 開源了一款名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcharmbracelet%2Fcrush" target="_blank"&gt;Crush&lt;/a&gt;的全新 AI 編碼工具，定位為「終端中的編碼夥伴」。它支持多模型、會話管理，並利用 LSP 提供更精準的編碼輔助。&lt;/p&gt; 
&lt;p&gt;Crush 是一個高性能的 agentic 編碼工具，基於 Charm 庫構建，可在用戶偏好的任何終端模擬器中使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0731/174323_NDya_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;主要功能&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多模型支持：支持多種 LLM，並允許用戶通過與 OpenAI 或 Anthropic 兼容的 API 添加自定義模型&lt;/li&gt; 
 &lt;li&gt;靈活切換：可在會話中途切換 LLM，同時保留上下文&lt;/li&gt; 
 &lt;li&gt;會話管理：支持為每個項目維護多個工作會話和上下文&lt;/li&gt; 
 &lt;li&gt;LSP 增強：利用語言服務器協議（LSP）獲取額外上下文，以提供更精準的輔助&lt;/li&gt; 
 &lt;li&gt;可擴展性：通過 MCP（Model Context Protocol）服務器添加新功能&lt;/li&gt; 
 &lt;li&gt;跨平台：在 macOS, Linux, Windows (PowerShell, WSL) 和 FreeBSD 等所有主流終端上提供一流支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;用戶可以通過 Homebrew、NPM、AUR 等包管理器安裝，或直接下載二進制文件。&lt;/p&gt; 
&lt;p&gt;Crush 支持通過環境變量配置 Anthropic、OpenAI、Google Gemini、Groq、AWS Bedrock 和 Azure OpenAI 等多種模型的 API 密鑰。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363456</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363456</guid>
      <pubDate>Wed, 16 Jul 2025 09:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小智 - 基於 MCP 的聊天機器人</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;小智&amp;nbsp;AI 聊天機器人，旨在&lt;span style="background-color:#ffffff; color:#1f2328"&gt;幫助更多人入門 AI 硬件開發，瞭解如何將當下飛速發展的大語言模型應用到實際的硬件設備中。無論你是對 AI 感興趣的學生，還是想要探索新技術的開發者，都可以通過這個項目獲得寶貴的學習經驗。&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;已實現功能&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Wi-Fi / ML307 Cat.1 4G&lt;/li&gt;
&lt;li&gt;BOOT 鍵喚醒和打斷，支持點擊和長按兩種觸發方式&lt;/li&gt;
&lt;li&gt;離線語音喚醒&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://github.com/espressif/esp-sr"&gt;ESP-SR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;流式語音對話（WebSocket 或 UDP 協議）&lt;/li&gt;
&lt;li&gt;支持國語、粵語、英語、日語、韓語 5 種語言識別&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://github.com/FunAudioLLM/SenseVoice"&gt;SenseVoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;聲紋識別，識別是誰在喊 AI 的名字&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://github.com/modelscope/3D-Speaker"&gt;3D Speaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;大模型 TTS（火山引擎，或 CosyVoice）&lt;/li&gt;
&lt;li&gt;大模型 LLM（Qwen, DeepSeek, Doubao）&lt;/li&gt;
&lt;li&gt;可配置的提示詞和音色（自定義角色）&lt;/li&gt;
&lt;li&gt;短期記憶，每輪對話後自我總結&lt;/li&gt;
&lt;li&gt;OLED / LCD 顯示屏，顯示信號強弱或對話內容&lt;/li&gt;
&lt;li&gt;支持 LCD 顯示圖片表情&lt;/li&gt;
&lt;li&gt;支持多語言（中文、英文）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;麪包板效果圖如下：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="375" src="https://static.oschina.net/uploads/space/2025/0303/162020_yOnr_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;已支持的開源硬件&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://oshwhub.com/li-chuang-kai-fa-ban/li-chuang-shi-zhan-pai-esp32-s3-kai-fa-ban"&gt;立創·實戰派 ESP32-S3 開發板&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/espressif/esp-box"&gt;樂鑫 ESP32-S3-BOX3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.m5stack.com/zh_CN/core/CoreS3"&gt;M5Stack CoreS3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.m5stack.com/en/atom/Atomic%20Echo%20Base"&gt;AtomS3R + Echo Base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.m5stack.com/en/core/ATOM%20Matrix"&gt;AtomMatrix + Echo Base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gf.bilibili.com/item/detail/1108782064"&gt;神奇按鈕 2.4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.waveshare.net/shop/ESP32-S3-Touch-AMOLED-1.8.htm"&gt;微雪電子 ESP32-S3-Touch-AMOLED-1.8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Xinyuan-LilyGO/T-Circle-S3"&gt;LILYGO T-Circle-S3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://oshwhub.com/tenclass01/xmini_c3"&gt;蝦哥 Mini C3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://oshwhub.com/movecall/moji-xiaozhi-ai-derivative-editi"&gt;Moji 小智 AI 衍生版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WMnologo/xingzhi-ai"&gt;無名科技 Nologo-星智-1.54TFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WMnologo/xingzhi-ai"&gt;無名科技 Nologo-星智-0.96TFT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/xiaozhi-esp32</link>
      <guid isPermaLink="false">https://www.oschina.net/p/xiaozhi-esp32</guid>
      <pubDate>Wed, 16 Jul 2025 09:35:00 GMT</pubDate>
    </item>
    <item>
      <title>字節跳動：在職員工工齡的中位數是 2.9 年</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;字節跳動於今日上午舉辦了新一期的 All Hands 全員會。公司 CEO 梁汝波、抖音總裁韓尚佑、Seed 模型應用負責人朱文佳以及來自績效與激勵、管理研究院等部門的負責人與全體員工交流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在全員會上，字節跳動也首次回應了社交媒體上關於「字節平均在職時間 7 個月」的説法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據字節給出的數據顯示，字節在職員工司齡中，中位數 2.9 年，平均數 3.0 年；離職司齡中位數 2.5 年，平均 2.6 年。同時，這也是字節頭條成立 13 年來，首次在內部披露這一數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="398" src="https://oscimg.oschina.net/oscnet/up-e419b1144a8a16d65894ae84d2f72c6bc80.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，會議還重點介紹了關於績效調整的相關情況。針對之前內部通知的績效調整，字節跳動方面解釋績效調整是為了弱化內卷，並表示其實 M 和 M+的區分度不高。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;過往激勵中 M+及 E 以上約為 45%-50% 左右，部門之間存在一定差異，M 代表的是符合預期，M-不意味淘汰，兩次 M-也不意味着要淘汰。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363451</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363451</guid>
      <pubDate>Wed, 16 Jul 2025 09:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>佈局個人 AI 市場，AMD 考慮向 PC 用戶推出獨立 NPU 方案</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;AMD 客戶端 CPU 業務負責人 Rahul Tikoo 向&lt;span style="background-color:#ffffff; color:#333333"&gt;外媒 CRN 透露&lt;/span&gt;，他們正在與客戶洽談一款專用的加速芯片的使用範例和潛在市場，這芯片不是 GPU，而是 NPU。&lt;/p&gt; 
&lt;p&gt;實際上聯想、戴爾和惠普等 OEM 廠商也正在開始探索獨立的 NPU 核其他類似的加速芯片，作為 PC 中 AI 工作負載 GPU 的代替品，戴爾上個月就公佈了新款 Dell Pro Max Plus 電腦中搭載了 Qualcomm AI 100 推理卡，它本質上就是個獨立的 NPU。&lt;/p&gt; 
&lt;p&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-ac65c94140ddcb5fa8af3f02b8ad7d3697b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AMD 通過收購 Xilinx 獲得了 AI 加速技術，並把它作為 NPU 整合到了鋭龍移動處理器上，既然如此也能把 NPU 做成獨立的加速卡，實際上獨立 NPU 並不是什麼新鮮事物，Intel 在酷睿 Ultra 100 系列處理器發佈之前就有獨立的 Movidius 視覺處理單元，它就是 Intel NPU 的前身，微軟的 2023 款 Surface Laptop 就有搭載它。&lt;/p&gt; 
&lt;p&gt;AMD 目前最強的 NPU 搭載在鋭龍 AI 300 系列處理器上的 XDNA 2，可以提供 50TOPS 的算力，如果獨立 NPU 擴展卡上堆疊兩個這樣的 NPU 算力就能到 100 TOPS，當然了獨立 NPU 解決方案必須比 GPU 消耗更少的能源，這樣才有意義。&lt;/p&gt; 
&lt;p&gt;至於 AMD 何時推出這樣的產品，Rahul Tikoo 表示他不能談論未來的線路圖，目前該項目還處於保密協議中，他説到：「但如果你看看我們的技術和解決方案的廣度，不難想象我們很快就能實現這一目標」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363430</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363430</guid>
      <pubDate>Wed, 16 Jul 2025 08:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV 社區七月動態：RWKV7-G0 7.2B 模型發佈，8 篇高質量論文</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;歡迎大家收看《RWKV 社區最新動態》，本期內容收錄了 RWKV 社區 2025 年 7 月的最新動態。&lt;/p&gt; 
&lt;p&gt;只需 3 分鐘，快速瞭解 RWKV 社區 7 月都有哪些新鮮事！&lt;/p&gt; 
&lt;h2&gt;7 月動態省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新聞動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV7-G0 7.2B 發佈，這可能是迄今為止人類訓練過的最強純 RNN 語言模型&lt;/li&gt; 
   &lt;li&gt;RWKV7-G1a 0.1B 發佈，增強數據後有明顯提升&lt;/li&gt; 
   &lt;li&gt;RWKV7a-G1b 0.1B 正在訓練，加入了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed 技術&lt;/a&gt;，總參數 0.9B&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 學術研究動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新論文：AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding（基於 RWKV 的視頻理解，已入選 &lt;strong&gt;ICCV 2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：An Efficient Image Fusion Network Exploiting Unifying Language and Mask Guidance（基於 RWKV 的圖像融合，已入選 &lt;strong&gt;IEEE TPAMI&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV（基於 RWKV 的醫學圖像分割，已入選 &lt;strong&gt;MICCAI 2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：DEVR: Train an Efﬁcient Vision-RWKV Model with Improved Knowledge Distillation（基於 RWKV 的高效視覺模型，已入選 ICIC 2025）&lt;/li&gt; 
   &lt;li&gt;新論文：EvRWKV: A RWKV Framework for Effective Event-guided Low-Light Image Enhancement（基於 RWKV 低光增強）&lt;/li&gt; 
   &lt;li&gt;新論文：Scaling Context Requires Rethinking Attention（基於 RWKV 的架構優化方案）&lt;/li&gt; 
   &lt;li&gt;新論文：DRWKV: Focusing on Object Edges for Low-Light Image Enhancement（基於 RWKV 的低光圖像增強）&lt;/li&gt; 
   &lt;li&gt;新論文：LowKeyEMG: Electromyographic typing with a reduced keyset（基於 RWKV 的輔助人機交互系統）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區項目動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Mini-RWKV-V7(基於 RWKV-V7 的一個 34M 參數的語言模型)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區市場活動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_CWdzniuhb4otg_rK-1QQw" target="_blank"&gt;RWKV 團隊亮相 WAIC 2025&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;移遠通信宣佈與 RWKV 建立全面合作關係&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 模型新聞動態&lt;/h2&gt; 
&lt;h3&gt;RWKV7-G0 7.2B 發佈&lt;/h3&gt; 
&lt;p&gt;2025 年 7 月 22 日， RWKV7-G0 7.2B 推理模型（Reasoning Model）正式開源發佈，它很可能是迄今為止人類訓練過的最強純 RNN 語言模型，可以解決不少數學題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval" src="https://oscimg.oschina.net/oscnet/up-2eb5e5d4557666f81434c5d8d3efc687ff3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKZQ4l2yjf80auPFDOxWX3g" target="_blank"&gt;RWKV7-G0 7.2B 發佈，最強純 RNN 推理模型&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV7-G1a 0.1B 發佈&lt;/h3&gt; 
&lt;p&gt;2025 年 7 月 28 日，RWKV7-G1a 0.1B 推理模型（Reasoning Model）正式開源發佈，相對 RWKV-G1 0.1B 增加了 1T token 的優質訓練數據，各項指標有明顯提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval-G1a" src="https://oscimg.oschina.net/oscnet/up-96b523aac01fa6ba805523603656374305e.png" referrerpolicy="no-referrer"&gt; &lt;img alt="UncheatableEval-G1a" src="https://oscimg.oschina.net/oscnet/up-655f7213f8b912ae77d2f70eb48f75fe95a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV7a-G1b 0.1B 正在訓練&lt;/h3&gt; 
&lt;p&gt;我們正在訓練加入 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed 技術&lt;/a&gt; 的 RWKV7a-G1b 0.1B（總參數 0.9B）。目前它相對於 RWKV7 的 loss 正在穩定下降。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Loss-G1b" src="https://oscimg.oschina.net/oscnet/up-01a1951dcd5f170b51d4584011b87465b24.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 學術研究動態&lt;/h2&gt; 
&lt;p&gt;RWKV 學術研究包括&lt;strong&gt;基於 RWKV 架構的新論文&lt;/strong&gt; 或 &lt;strong&gt;RWKV 社區參加的學術研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;AURORA LONG&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.02591" target="_blank"&gt;https://arxiv.org/abs/2507.02591&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-03&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了 AURORA LONG，通過將 MLLMs 中的 LLM 組件替換為 RWKV 模型，以恆定大小的隱藏狀態處理任意長度的輸入序列。研究結合視覺令牌合併，通過按大小升序重新排列視覺令牌，顯著提高了處理效率。AURORA LONG 在多個視頻基準測試中表現出與基於 Transformer 的模型相當的性能，同時降低了算力消耗。&lt;/p&gt; 
&lt;p&gt;該論文的模型十分精妙，已入選 ICCV 2025。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250703-Bringing RNNs Back to Efficient Open-Ended Video Understanding" src="https://oscimg.oschina.net/oscnet/up-8a081ee56a443d1cfdb279d1d55c1de171b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKVFusion&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：An Efficient Image Fusion Network Exploiting Unifying Language and Mask Guidance&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11091495" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11091495&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-23&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出 RWKVFusion 框架，利用語言描述和語義掩碼指導圖像融合過程。該方法通過高效掃描策略將 RWKV 適配為雙向版本，並引入多模態融合模塊促進信息交換，構建輕量級網絡以降低計算成本。在可見紅外、多曝光等圖像融合任務中實現了最先進的性能。&lt;/p&gt; 
&lt;p&gt;該論文的框架十分有效，已入選 IEEE TPAMI。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250723-An Efficient Image Fusion" src="https://oscimg.oschina.net/oscnet/up-b10e20cb05e611b9485b0f560587e835185.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;U-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.11415" target="_blank"&gt;https://arxiv.org/abs/2507.11415&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-15&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出 U-RWKV 框架，用於輕量級醫學圖像分割。該框架引入方向自適應 RWKV 模塊 (DARM) 和階段自適應擠壓-激勵模塊 (SASE)，高效建模長距離依賴並減少方向偏差，在資源受限環境中實現高性能分割。實驗驗證了其優越的計算效率和分割精度。&lt;/p&gt; 
&lt;p&gt;論文在醫學分割上有出色的表現，已入選 MICCAI 2025。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250715-U-RWKV" src="https://oscimg.oschina.net/oscnet/up-ec564af85a1f94391bbc006e9059d8306b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DEVR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：DEVR: Train an Efﬁcient Vision-RWKV Model with Improved Knowledge Distillation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-981-96-9794-6_29" target="_blank"&gt;https://link.springer.com/chapter/10.1007/978-981-96-9794-6_29&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-15&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種高效的視覺模型 DEVR，通過改進知識蒸餾方法。重新設計了 RWKV 塊以增強通道特徵和空間信息捕獲，並引入結合對比學習和蒸餾的損失函數，分階段對齊特徵空間。實驗表明，DEVR 在圖像分類、檢測和分割任務中優於現有模型，計算成本更低、速度更快。&lt;/p&gt; 
&lt;p&gt;論文在圖像領域有優秀的表現，已被 ICIC 2025 收錄。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250715-DEVR" src="https://oscimg.oschina.net/oscnet/up-d038ab1410b6f6476af09040b05af59557f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;EvRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：EvRWKV: A RWKV Framework for Effective Event-guided Low-Light Image Enhancement&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.03184" target="_blank"&gt;https://arxiv.org/abs/2507.03184&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出 EvRWKV 框架，通過雙域處理實現事件與圖像的連續跨模態交互。該框架採用 Cross-RWKV 模塊進行細粒度時空融合，結合 EISFE 模塊實現自適應頻域噪聲抑制與空域形變卷積對齊。在真實低光數據集上的實驗表明，該方法能有效抑制噪聲、恢復結構細節並提升視覺清晰度，達到 SOTA 性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250701-EvRWKV" src="https://oscimg.oschina.net/oscnet/up-c60b61f949dd8bd507a66fe9fa019b3f401.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Scaling Context Requires Rethinking Attention&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Scaling Context Requires Rethinking Attention&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.04239" target="_blank"&gt;https://arxiv.org/abs/2507.04239&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了 power attention 優化方案，一種線性成本的序列建模層，通過獨立調整狀態大小解決長上下文訓練問題。實驗顯示其在上下文學習中優於指數和線性注意力，並開發高效 GPU 內核實現速度提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250706-Scaling Context Requires Rethinking Attention" src="https://oscimg.oschina.net/oscnet/up-804f46c91066cfea9311f06cfe64db15c2f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：DRWKV: Focusing on Object Edges for Low-Light Image Enhancement&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.18594" target="_blank"&gt;https://arxiv.org/abs/2507.18594&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了 DRWKV 模型，整合全局邊緣 Retinex (GER) 理論以解耦光照與邊緣結構，引入演化 WKV 注意力機制增強空間連續性。實驗表明，該模型在多個低光增強基準測試中取得領先的 PSNR、SSIM 和 NIQE 分數，同時保持低計算複雜度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250724-DRWKV" src="https://oscimg.oschina.net/oscnet/up-5024f1ba7584699c39bf9cc5c688cdac83d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;LowKeyEMG&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：LowKeyEMG: Electromyographic typing with a reduced keyset&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.19736" target="_blank"&gt;https://arxiv.org/abs/2507.19736&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-07-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型開發了 LowKeyEMG 系統，用於通過表面肌電信號實現高效文本輸入。該系統僅使用 7 個手勢鍵，結合語言模型優化文本重建，在實時實驗中達到平均 23.3 詞/分鐘的輸入速度，手勢效率提升 17%，top-3 單詞準確率達 99.2%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250726-LowKeyEMG" src="https://oscimg.oschina.net/oscnet/up-a53de3263efa378926e0ce713830f0ecfa4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社區項目動態&lt;/h2&gt; 
&lt;h3&gt;Mini-RWKV-V7&lt;/h3&gt; 
&lt;p&gt;項目基於 RWKV-V7 架構訓練了一個 34M 參數量的語言模型 &lt;code&gt;Mini-RWKV-V7-LM-34M&lt;/code&gt; 。它在保持輕量的同時，具備良好的語言理解和生成能力，非常適合資源極其有限的設備部署和快速迭代開發，並且同時支持預訓練和有監督微調。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Mini-RWKV-V7" src="https://oscimg.oschina.net/oscnet/up-c6da2bc4e0d67120c5f6c14da1d2e64292d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;項目鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlic-Li%2FMini_RWKV_7" target="_blank"&gt;https://github.com/Alic-Li/Mini_RWKV_7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;社區市場活動&lt;/h2&gt; 
&lt;h3&gt;RWKV 團隊亮相 2025 世界人工智能大會&lt;/h3&gt; 
&lt;p&gt;7 月 26 日，RWKV 攜全球領先的大模型架構 RWKV-7 亮相 2025 世界人工智能大會暨人工智能全球治理高級別會議（以下簡稱 " WAIC 2025"），並首次公開了 RWKV-7s 架構。元始智能作為企業代表向國務院總理李強、上海市委書記陳吉寧介紹 RWKV 架構、生態和產業化近況。 &lt;img alt="WAIC" src="https://oscimg.oschina.net/oscnet/up-8f5c8db4e87a3294e45d0159eccd1f7cefa.png" referrerpolicy="no-referrer"&gt; &lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_CWdzniuhb4otg_rK-1QQw" target="_blank"&gt;WAIC 首日 | RWKV-7s 新型高效大模型架構正式亮相&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;同日，承接 RWKV-7 優勢的 RWKV-7s 新型高效大模型架構憑藉其原創的 DeepEmbed 和 DeepEmbedAttention 技術，成為現場焦點並榮獲 &lt;strong&gt;WAIC"鎮館之寶-未來之星"稱號&lt;/strong&gt; 。 &lt;img alt="2025-07-29-img-2-Award" src="https://oscimg.oschina.net/oscnet/up-234c71f0dd692a06e8c35377c602e0c92ec.jpg" referrerpolicy="no-referrer"&gt; &lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcAujzUFlCTjBOHiLfMuPtw" target="_blank"&gt;全新高效模型架構！RWKV-7s 閃耀 WAIC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;移遠通信宣佈與 RWKV 建立全面合作關係&lt;/h3&gt; 
&lt;p&gt;7 月 26 日，&lt;strong&gt;移遠通信宣佈與 RWKV 建立全面合作關係&lt;/strong&gt; ，雙方將依託移遠的算力平台，優化並支持 RWKV 最新模型架構，共同推動大模型在端側設備的低資源佔用部署。 &lt;img alt="yiyuan" src="https://oscimg.oschina.net/oscnet/up-bef4708292a754b78dd17727ccb20773290.png" referrerpolicy="no-referrer"&gt; &lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUk6xlo-MQ09vS9JFwf35NA" target="_blank"&gt;端側大模型迎來"輕"革命！移遠通信 × RWKV 打造"輕量 AI 大腦"&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363429</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363429</guid>
      <pubDate>Wed, 16 Jul 2025 08:55:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
  </channel>
</rss>
