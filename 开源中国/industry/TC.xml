<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 15 Sep 2025 16:41:10 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>BentoML 發佈 llm-optimizer，LLM 推理和性能優化開源工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;BentoML 近日發佈了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bentoml.com%2Fblog%2Fannouncing-llm-optimizer" target="_blank"&gt;llm-optimizer&lt;/a&gt;，這是一個用於基準測試和優化 LLM 推理的開源工具。它支持多個推理框架，併兼容任何開源 LLM。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4e424ad07868e5d205d0e99984f6e8bf1b4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;llm-optimizer 旨在將 LLM 性能優化的繁瑣手動工作自動化。您可以在一個地方運行結構化實驗、應用約束並可視化結果，只需幾個命令即可。&lt;/p&gt; 
&lt;p&gt;使用示例&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;llm-optimizer estimate \
  --model meta-llama/Llama-3.1-8B-Instruct \
  --input-len 1024 \
  --output-len 512 \
  --gpu A100 \
  --num-gpus 2&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;預期輸出&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;=== Configuration ===
Model: meta-llama/Llama-3.1-8B-Instruct
GPU: 2x A100
Precision: fp16
Input/Output: 1024/512 tokens
Target: throughput

Fetching model configuration...
Model: 8029995008.0B parameters, 32 layers

=== Performance Analysis ===
Best Latency (concurrency=1):
  TTFT: 43.1 ms
  ITL: 2.6 ms
  E2E: 1.39 s

Best Throughput (concurrency=512):
  Output: 18873.3 tokens/s
  Input: 23767.8 tokens/s
  Requests: 14.24 req/s
  Bottleneck: Memory

=== Roofline Analysis ===
Hardware Ops/Byte Ratio: 142.5 ops/byte
Prefill Arithmetic Intensity: 52205.5 ops/byte
Decode Arithmetic Intensity: 50.9 ops/byte
Prefill Phase: Compute Bound
Decode Phase: Memory Bound

=== Concurrency Analysis ===
KV Cache Memory Limit: 688 concurrent requests
Prefill Compute Limit: 8 concurrent requests
Decode Capacity Limit: 13 concurrent requests
Theoretical Overall Limit: 8 concurrent requests
Empirical Optimal Concurrency: 16 concurrent requests

=== Tuning Commands ===

--- SGLANG ---
Simple (concurrency + TP/DP):
  llm-optimizer --framework sglang --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tp_size*dp_size=[(1, 2), (2, 1)]" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_sglang.json
Advanced (additional parameters):
  llm-optimizer --framework sglang --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tp_size*dp_size=[(1, 2), (2, 1)];chunked_prefill_size=[1434, 2048, 2662];schedule_conservativeness=[0.3, 0.6, 1.0];schedule_policy=fcfs" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_sglang.json

--- VLLM ---
Simple (concurrency + TP/DP):
  llm-optimizer --framework vllm --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tensor_parallel_size*data_parallel_size=[(1, 2), (2, 1)]" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_vllm.json
Advanced (additional parameters):
  llm-optimizer --framework vllm --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tensor_parallel_size*data_parallel_size=[(1, 2), (2, 1)];max_num_batched_tokens=[1024, 1177, 1331]" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_vllm.json&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該工具解決了 LLM 部署中的一個常見挑戰：在不依賴手動試錯的情況下，為延遲、吞吐量和成本找到最佳配置。llm-optimizer 為探索 LLM 性能景觀提供了一種結構化的方式。它通過實現系統基準和跨可能配置的自動搜索，消除了重複的猜測。&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;em&gt;https://github.com/bentoml/llm-optimizer&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372359/bentoml-llm-optimizer</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372359/bentoml-llm-optimizer</guid>
      <pubDate>Sat, 13 Sep 2025 11:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>北京中小學全面開設人工智能通識課</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FecvZHwNwJg6PafacKW5iEg" target="_blank"&gt;據報道&lt;/a&gt;，自 2025 年秋季學期起，北京市 1400 餘所中小學全面開設人工智能通識教育課程，覆蓋 183 萬餘名中小學生，成為全國首個省級全域推進人工智能通識教育的地區。&lt;/p&gt; 
&lt;p&gt;報道稱，課程資源方面，首批覆蓋全學段的 160 套市級課程資源已上線，每套資源包含 15 分鐘左右的核心教學視頻、教學指南及活動任務單；&lt;/p&gt; 
&lt;p&gt;通過「視頻 + 工具 + 任務單」模式滿足教師授課、備課及學生自主學習 3 類場景需求，搭建 AI「課程超市」和「應用超市」，為課堂教學提供基礎支撐。&lt;/p&gt; 
&lt;p&gt;市教委相關負責人表示，北京市將持續優化人工智能教育課程資源，結合教學反饋迭代更新；開展應用示範校評選和優秀案例推廣，形成可複製經驗。&lt;/p&gt; 
&lt;p&gt;同時，負責人還表示，要深化「京娃」系列智能體研發，拓展「AI + 教育」應用場景等，以首批課程資源為起點，力爭將北京中小學人工智能教育打造成全國標杆，真正讓數字技術賦能每一位師生，為培養擔當民族復興大任的時代新人奠定堅實基礎。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372356</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372356</guid>
      <pubDate>Sat, 13 Sep 2025 11:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI Evals 新增原生音頻輸入和評估功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 的 Evals 工具現已支持原生音頻輸入和音頻評分，無需文本轉錄即可直接評估模型的音頻響應。這項新功能極大簡化了語音識別和生成模型的評估過程，使得開發者能夠更高效地測試和優化其音頻應用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9522f36b3f1e768600ee99a85f02e860156.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過使用 Evals 的原生音頻支持，用戶可以上傳音頻文件，並直接在平台上進行性能評估。這一改進不僅減少了數據處理的複雜性，還提高了評估結果的準確性和可靠性。對於需要頻繁測試和調整音頻模型的開發者來説，這是一個重要的進步。&lt;/p&gt; 
&lt;p&gt;應用場景包括但不限於：智能語音助手的開發與優化、語音識別系統的性能評估，以及音頻內容生成的質量控制。&lt;/p&gt; 
&lt;p&gt;如需瞭解更多關於如何使用 Evals 的新功能，參考官方 Cookbook 指南：&lt;em&gt;https://cookbook.openai.com/examples/evaluation/use-cases/evalsapi_audio_inputs&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372353</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372353</guid>
      <pubDate>Sat, 13 Sep 2025 11:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟研究院發佈 RenderFormer，基於 Transformer 的神經渲染模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟研究院近日發佈了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Frenderformer-how-neural-networks-are-reshaping-3d-rendering%2F" target="_blank"&gt;RenderFormer&lt;/a&gt;，這是一個純機器學習的神經架構，旨在通過機器學習完全替代傳統圖形計算，實現全功能 3D 渲染，無需傳統圖形計算。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-973c5649e34320d01d3888bfd65c9a319d3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2008d874aeabcfe09955bf61fd0b256737b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RenderFormer 整體架構如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;雙分支 Transformer 架構：分為視角無關（View-Independent）和視角相關（View-Dependent）兩個階段。視角無關階段通過自注意力機制捕捉陰影、漫反射等全局光照效果；視角相關階段通過交叉注意力機制建模可見性、反射等視角依賴效果。&lt;/li&gt; 
 &lt;li&gt;相對空間位置編碼：創新性地採用改進的旋轉位置編碼（RoPE），基於三角形的 3D 空間位置而非序列索引，保持場景平移不變性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79adce0f291f87580ef10043c6928fce017.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，RenderFormer 是首個證明神經網絡能學習完整圖形渲染流水線的模型，支持任意 3D 場景和全局光照效果，無需依賴光線追蹤或光柵化技術。它通過三角形令牌（triangle tokens）表示 3D 場景，編碼空間位置、表面法線及材質屬性，結合光線束令牌（ray bundle tokens）處理視角信息，實現端到端渲染。該成果已獲 SIGGRAPH 2025 接收並開源。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://microsoft.github.io/renderformer&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372349</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372349</guid>
      <pubDate>Sat, 13 Sep 2025 10:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>亞馬遜雲科技否認大中華區裁員</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;9 月 15 日，有消息稱亞馬遜雲科技（AWS）大中華區計劃裁員，預計將發生在 9 月底至 10 月之間，或涉及超 20% 的員工，目前 AWS 大中華區人員規模不到 1700 人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對此，亞馬遜雲科技發言人表示：「相關報道嚴重失實，亞馬遜雲科技持續在中國積極招聘人才，為中國企業提供全球領先、安全可靠的雲技術。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 7 月，亞馬遜發佈了 2025 年第二季度財報，二季度營收同比增長 13% 至 1677 億美元；淨利潤 181.64 億美元，與上年同期的 134.85 億美元相比大幅增長 35%；稀釋後每股收益為 1.68 美元。亞馬遜已承諾今年在 AI 領域的投資將高達 1000 億美元。亞馬遜 AWS 雲業務在二季度營收 308.73 億美元，略高於市場預期的 308 億美元，同比增長 17%，增速與上一季度持平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AWS 的增速仍低於其主要競爭對手微軟雲和谷歌雲。在電話會上，亞馬遜 CEO 安迪·賈西試圖向分析師保證，和其雲計算競爭對手相比，AWS 一直保持着「相當重要」的領導地位，他對公司 AI 產品的發展感到樂觀：「我們 AWS 領域的業務規模比其他公司的雲業務大得多，我認為第二位的規模約為 AWS 的 65%。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官網資料顯示，亞馬遜雲科技於 2013 年進入中國，通過本地合作伙伴北京光環新網科技股份有限公司（光環新網）和寧夏西雲數據科技有限公司（西雲數據），提供與全球一致的雲服務體驗和安全級別，API（應用程序接口）、SDK（軟件開發工具包）、CLI（命令行工具）與全球其他地區相同，開發者無需額外適配，即可實現全球化應用部署。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，亞馬遜雲科技在中國雲計算市場面臨激烈的競爭。根據研究機構 Canalys 的報告顯示，2025 年第一季度中國大陸的雲計算支出達到 116 億美元，前三名阿里雲、華為雲和騰訊雲的市場份額分別為 33%、 18% 和 10%，三家巨頭合計佔領了整個中國雲計算市場的 61%。（澎湃新聞）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372348</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372348</guid>
      <pubDate>Sat, 13 Sep 2025 10:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Roo Code 上線遠程連接功能 Roomote Control</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程工具 Roo Code 近期推出了名為 &lt;strong&gt;Roomote Control&lt;/strong&gt; 的新功能，旨在提升用戶在 VS Code 中的編碼體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0915/181541_VqYx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Froo_code%2Fstatus%2F1966280158031335625" target="_blank"&gt;據介紹&lt;/a&gt;，Roomote Control 允許用戶通過手機或瀏覽器遠程連接和控制本地 VS Code 環境中的 Roo Code。該工具直接在用戶的系統上運行，確保代碼庫保持私有和完全安全。&lt;/p&gt; 
&lt;p&gt;用戶可以在遠程設備上啓動新任務、選擇模式和模型，所有更新會實時同步回本地 IDE。即使暫時離開，用戶也可以讓任務在後台繼續運行，提高工作效率。&lt;/p&gt; 
&lt;p&gt;Roomote Control 作為 Roo Code Pro 訂閲的一部分，提供 14 天的免費試用期，之後每月收費 20 美元。&lt;/p&gt; 
&lt;p&gt;使用方法如下&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;連接步驟&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;在 Roo Code 中導航到 Cloud 菜單並點擊「Connect」。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;登錄 Roo Code 網站並在 IDE 中啓用遠程控制。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;在瀏覽器中訪問 Roo Code Cloud，確保遠程切換已啓用。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;功能體驗&lt;/strong&gt;：用戶可以在遠程部分查看 IDE 的開放目錄，點擊加號圖標啓動新任務，輸入提示並觀察任務的執行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過 Roomote Control，Roo Code 進一步擴展了其作為 AI 驅動的自主編碼代理的功能，使用戶能夠隨時隨地高效地管理編碼任務。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372344</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372344</guid>
      <pubDate>Sat, 13 Sep 2025 10:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全球首個 AI 政府部長來了</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;綜合環球網等媒體報道，阿爾巴尼亞總理埃迪·拉馬當地時間 11 日宣佈新內閣名單，&lt;strong&gt;&lt;strong&gt;其中包括任命一個名為「迪埃拉」（在阿爾巴尼亞語中意為「太陽」）的人工智能擔任公共採購部長&lt;/strong&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;這也使得阿爾巴尼亞成為世界上第一個任命非實體的人工智能擔任政府部長的國家。&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-01dfab898dc0952c33998cbf206a06145f0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月，拉馬歷史性地第四次當選阿爾巴尼亞總理。今年夏天，拉馬曾暢想有朝一日該國能有一位數字部長，甚至是一位人工智能總理，不過當時幾乎沒人想到這一天會這麼快到來。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;拉馬在週四宣佈新內閣的講話中表示：「迪埃拉是第一位並非以實體形式存在，而是由人工智能虛擬生成的內閣成員。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拉馬還表示，招標決定權將從各部手中逐步移交給「迪埃拉」，「迪埃拉」將審查政府與私營公司簽訂的每一份招標合同，並客觀評估每一份招標合同的優點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拉馬強調，「迪埃拉」將幫助阿爾巴尼亞「成為一個公共招標 100% 沒有腐敗的國家」。長期以來，授予此類合同一直是這個巴爾幹國家腐敗醜聞的根源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這種形象對阿爾巴尼亞加入歐盟的夢想造成了打擊。阿爾巴尼亞目前是歐盟的候選國，拉馬希望在 2030 年之前成為歐盟正式成員國，但政治分析人士稱，這一目標過於雄心勃勃。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拉馬還稱，將有一個專用部門為「迪埃拉」提供支持，並推動人工智能在政府各部門的應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不過，阿爾巴尼亞政府並未提供有關「迪埃拉」可能會受到何種人類監督的詳細信息，也沒有就有人可能操縱這個人工智能機器人的風險作出説明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「迪埃拉」此前已經為阿爾巴尼亞公民所知，她的虛擬形象是一個身穿阿爾巴尼亞傳統服飾的女子，於今年年初在電子平台作為一款人工智能虛擬助手上線，該平台允許公民以數字方式訪問幾乎所有政府服務。「迪埃拉」負責幫助公民和企業獲取政府文件，通過語音指令提供幫助，以及簽發帶有電子印章的文件。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372341</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372341</guid>
      <pubDate>Sat, 13 Sep 2025 10:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊 AI 編程工具 CodeBuddy 推出個人訂閲方案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊旗下 AI 編程工具 CodeBuddy 正式公佈了其個人訂閲方案。用戶每月支付 9.95 美元即可獲得 1000 credits，並且每日還會額外贈送 100 credits（於零點重置）。&lt;/p&gt; 
&lt;p&gt;付費版功能&lt;br&gt; ✅1000 credits/month&lt;br&gt; ✅100 credits/day, reset daily&lt;br&gt; ✅All premium models&lt;br&gt; ✅Unlimited BuddyTab&lt;br&gt; ✅Unlimited Next Edit Prediction&lt;br&gt; ✅Previews&lt;/p&gt; 
&lt;p&gt;免費版功能&lt;br&gt; ✅2 week pro trial with 500 credits&lt;br&gt; ✅50 credits/day, reset daily&lt;br&gt; ✅All premium models&lt;br&gt; ✅Unlimited BuddyTab&lt;br&gt; ✅Unlimited Next Edit Prediction&lt;/p&gt; 
&lt;p&gt;&lt;img height="733" src="https://static.oschina.net/uploads/space/2025/0915/175958_W3lT_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.codebuddy.ai/profile/plan&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;訂閲用戶可以調用全部高級模型，並無限使用 BuddyTab 與 Next Edit Prediction 功能。對於新用戶，CodeBuddy 提供一次性的為期 2 周，的 Pro 試用，其中包含 500 credits 以及每日 50 credits 的贈送。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372340</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372340</guid>
      <pubDate>Sat, 13 Sep 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 正在測試 Grok 4 Fast，宣稱是「地球上最快思考模型」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 已開始對 Grok 4 Fast &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.testingcatalog.com%2Fxai-launches-grok-4-fast-in-early-access-beta-with-up-to-10x-speed%2F" target="_blank"&gt;進行灰度測試&lt;/a&gt;，並宣稱這是「目前地球上最快的思考模型」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-820d3dda386ef2105d157daacaa4058bcfd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3fbbb5515d6180fa2258e4d055d8fdc166e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該模型據稱是 Grok 4 的加速版，已在 Grok 網頁端、iOS 應用以及 X 平台上向部分用戶推送。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0915/174413_VUST_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新版本主打極速響應，同時力求保持高水平的智能密度。為了方便用戶體驗，網頁端為訂閲用戶新增了「Enable early access models」開關，允許他們提前試用尚在實驗階段的新模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372333</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372333</guid>
      <pubDate>Sat, 13 Sep 2025 09:47:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Pantheon CLI - 科學 「聊天式分析」 類人框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#1f2328; text-align:start"&gt;Pantheon-CLI 是專為科學研究打造的&lt;strong&gt;首個完全開源的「聊天式分析」類人框架&lt;/strong&gt;。定義 AI 時代研究者與數據交互的新方式。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;strong&gt;博士水平的科學助手&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Pantheon-CLI 是首個用於複雜真實世界分析的命令行智能（CLI）Agent 助手，能夠像人類一樣處理博士級別的單細胞與空間組學任務。這不僅是一個工具——&lt;strong&gt;它是一位加入你科研團隊的 AI 科學家&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;strong&gt;混合式編程&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;在同一個環境中，你可以：
&lt;ul&gt;
&lt;li&gt;第一行寫 Python 代碼&lt;/li&gt;
&lt;li&gt;下一行使用自然語言描述&lt;/li&gt;
&lt;li&gt;甚至混合使用 R/Julia 語言&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;科學家只需專注於&lt;strong&gt;探索&lt;/strong&gt;，無需在不同工具與環境之間來回切換。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;功能特性&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;用 Pantheon-CLI 的開源力量重塑你的數據分析工作流——它為多語言無縫集成、輕鬆數據分析與下一代科研發現而生。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.1 與數據對話&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;使用 Pantheon-CLI，你可以處理任何本地數據，不侷限於文本、CSV、Excel，還包括 anndata、pkl、torch，以及任何 Python/R/Julia 支持的數據格式。&lt;/li&gt;
&lt;li&gt;你無需將任何數據上傳至服務器——分析能力完全依賴於你的計算機。也可以將 Pantheon-CLI 安裝在服務器上，解鎖無限分析可能。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.2 混合式編程&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;在 Pantheon-CLI 中，所有變量都保存在環境中，突破了傳統編程的限制。你可以隨時用自然語言「編程」，CLI 會自動生成 Python/R/Julia 代碼並運行。&lt;/li&gt;
&lt;li&gt;這是全球首個具備變量持久化支持的 Agent。在編碼過程中，你可以隨時輸入自然語言，Pantheon-CLI 將自動執行你想要的分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.3 MCP 集成&lt;a href="https://github.com/aristoteleo/pantheon-cli/blob/main/assets/feature_3.jpg" target="_blank"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;通過 Pantheon-CLI，構建了一個具備人機交互全棧能力的助手：讀寫文件、創建文件、運行命令、生成代碼、讀取網頁。&lt;/li&gt;
&lt;li&gt;不同於傳統 Agent，該項目幾乎實現了 Claude Code 的所有能力，並進一步優化——致力於讓 Pantheon-CLI 更適合數據分析，而非純粹的代碼編程。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.4 類人行為&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;像人類科學家一樣，Pantheon-CLI 可讀取網頁教程與 PDF 論文，然後開始規劃分析。&lt;/li&gt;
&lt;li&gt;給 LLM 輸入教程常能得到更好的輸出，但並非所有網頁都易於訪問。項目重構了更強大的網頁抓取能力，儘可能復現人類在分析前會做的一切準備工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.5 任務規劃&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;在 Pantheon-CLI 中，可從論文中學習並自動規劃、構建科學 Agent。學習論文的 Method 部分，像人類專家一樣搭建逐步執行的 Agent。&lt;/li&gt;
&lt;li&gt;對於數據科學任務，現有 Agent 的通用做法是「計劃並逐步執行」，但這依賴於人類預先定義的步驟。Pantheon-CLI 則能從論文或教程中自動學習並規劃工作流。這與人類專家的做法有何不同？&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.6 多模型提供商支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Pantheon-CLI 支持主流大模型提供商，包括 OpenAI、Anthropic、Gemini、Deepseek、Qwen 等，因此你不受制於任一模型。&lt;/li&gt;
&lt;li&gt;這看似簡單，卻非常實用：支持任何大模型，且無需「Claude Code 風格」的專用 API——通用 LLM API 即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.7 本地 LLM 支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;出於某些數據隱私合規需求，Pantheon-CLI 可基於 ollama 使用本地大模型離線完成數據分析。&lt;/li&gt;
&lt;li&gt;在本地運行數據與本地運行模型，是 Pantheon-CLI 的另一個有趣優勢。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.8 多 RAG 支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;提供完整的預學習 RAG 方案。通過強大的網頁爬蟲彙集文檔信息，構建一個「外置大腦」，隨後將用戶意圖與之匹配，生成更可靠的輸出。&lt;/li&gt;
&lt;li&gt;雖然 RAG 仍在爭論中，但很多時候用戶找不到「合適教程」作為精確輸入。在這種情況下，RAG 就很有價值——畢竟極長上下文也會消耗大量 tokens。後續會釋放更大的 RAG 數據庫供下載。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.9 生物學支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;藉助在生物組學分析方面的經驗，預置了系統級組學工具集，幫助你完成上游測序比對、下游註釋與差異分析，甚至完整復現一篇生物學論文中的全部分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.10 Notebook Support&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;想象一下：從現在起，當你在筆記本中分析數據時，如果你有特定的需求，卻不想翻閲複雜的文檔，你只需要進行一次對話，分析工作就能瞬間完成。&lt;/li&gt;
&lt;li&gt;它不僅用於編寫代碼，還能自動運行和修改代碼以生成正確結果，甚至能夠處理文件並從網站學習——這些功能是其他任何工具都無法比擬的。&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/pantheon-cli</link>
      <guid isPermaLink="false">https://www.oschina.net/p/pantheon-cli</guid>
      <pubDate>Sat, 13 Sep 2025 09:45:00 GMT</pubDate>
    </item>
    <item>
      <title>《人工智能安全治理框架》2.0 版發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;在國家互聯網信息辦公室的指導下，國家計算機網絡應急技術處理協調中心組織專業機構、科研院所、行業企業等持續跟蹤人工智能風險變化演進，梳理調整風險分類，研究形成風險分級方法，動態調整更新防範治理措施，制定&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaFGCdWSxHxGdxC9e76wuXw" target="_blank"&gt;《人工智能安全治理框架》2.0 版&lt;/a&gt;，&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;作為網安標委技術文件發佈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;旨在&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;推動增進人工智能安全治理共識，促進協同共治、普惠共享，為應對人工智能快速發展的新⻛險新挑戰，安全有效地釋放應用需求，促進人工智能技術和產業發展提供參考指引。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#222222"&gt;《人工智能安全治理框架》1.0 版（以下簡稱《框架》）於 2024 年 9 月發佈。國家互聯網應急中心負責同志表示，《框架》2.0 版的發佈，順應全球人工智能發展潮流，統籌技術創新與治理實踐，在人工智能安全、倫理、治理等方面不斷深化共識，促進形成安全、可信、可控的人工智能發展生態，構建跨國界、跨領域、跨行業的協同治理格局。同時，有助於推進多邊機制下人工智能安全治理合作，推動世界範圍內技術成果的普惠共享，確保人類社會共享人工智能發展的紅利。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="401" src="https://oscimg.oschina.net/oscnet/up-3e656b6a8b8754221ca5273024e8dfad42e.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372324</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372324</guid>
      <pubDate>Sat, 13 Sep 2025 09:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​Cursor 升級 Tab 模型，實時強化學習提升開發者建議精準度</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cursor 是一款基於人工智能的編程平台，最近宣佈對其 Tab 模型進行了升級。Tab 模型是為開發者提供自動補全建議的系統。此次升級顯著減少了低質量建議的數量，提高了建議的準確性。具體來説，新的 Tab 模型相比於之前的版本，建議數量減少了 21%，而接受率提高了 28%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="303" src="https://oscimg.oschina.net/oscnet/up-5f8f2f76b53766cb4cfaec598400aa74c36.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cursor 在其博客中表示，實現高接受率不僅僅是讓模型變得更智能，還需要懂得何時提供建議、何時不提供。為了應對這一挑戰，Cursor 考慮了訓練一個單獨的模型，用於預測某個建議是否會被接受。該公司引用了一項 2022 年的研究，指出這種方法在 GitHub Copilot 中取得了成功。研究中採用了邏輯迴歸過濾器，分析編程語言、最近的接受歷史和訓練字符等特徵，將那些得分較低的建議隱藏起來。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，Cursor 認為這種解決方案雖然可以預測用戶接受建議的概率，但希望有一個更通用的機制，能夠重用 Tab 模型學到的強大代碼表示。Cursor 希望通過改變 Tab 模型的結構，避免在最初就產生低質量建議，而不是後續再進行過濾。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;因此，Cursor 採用了策略梯度方法，這是一種強化學習的方法。當用戶接受建議時，模型會得到獎勵;當建議被拒絕時，模型會受到懲罰;而在選擇保持沉默時則不會得到任何反饋。此方法需要 「在線」 數據，即從當前使用的模型收集的反饋。Cursor 通過每天多次向用戶部署新的檢查點，並迅速基於新交互對模型進行再訓練，來解決這一問題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cursor 表示，當前從部署檢查點到收集數據的過程僅需 1.5 到 2 小時，這在 AI 行業中已經算是較快，但仍有進一步加速的空間。該公司的 Tab 模型每天處理超過 4 億個請求，Cursor 希望這一改進能夠提升開發者的編碼體驗，並計劃在未來進一步開發這些方法。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在線強化學習是該領域最令人興奮的方向之一，一位在 OpenAI 從事後訓練的工程師在社交媒體上對此表示讚賞，稱 Cursor 似乎是&lt;span&gt;第一&lt;/span&gt;個成功在大規模上實施該技術的公司。&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不久前，Cursor 的母公司 Anysphere 宣佈融資 9 億美元，估值達 99 億美元，並推出了一項月費 200 美元的 「超值」 計劃，承諾提供 20 倍於 20 美元月費 「專業版」 的使用量。此外，Cursor 還在同月進行了平台更新，新增了自動代碼審查、記憶功能和一鍵設置模型上下文協議服務器的功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372315</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372315</guid>
      <pubDate>Sat, 13 Sep 2025 08:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Genspark AI 瀏覽器正式發佈，支持本地運行開源模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Genspark AI 瀏覽器正式發佈，官方稱其&lt;strong&gt;為世界首個支持本地運行開源模型的 AI 瀏覽器&lt;/strong&gt;。使用大模型無需聯網，可在本地設備離線運行 169 款開源模型，包括 GPT-OSS、Gemma3 等，響應速度極快且完全免費，並集成了全能智能體、廣告攔截等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-205a66f89555bba425f98420cd70b1a0e86.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1636" src="https://static.oschina.net/uploads/space/2025/0915/164241_hahS_2720166.png" width="2988" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下載地址：&lt;em&gt;https://www.genspark.ai/browser&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;除端側 AI 大模型外，Genspark AI 瀏覽器集成全能智能體，可在任意網頁實時比價、分析評論、尋找最優交易；購物站點一鍵「Find best deal」即可鎖定最低價格。Autopilot 模式允許 AI 自主瀏覽並收集信息；內置 MCP 商店供用戶擴展功能；系統級廣告攔截提供無廣告純淨體驗。目前提供 Windows 版本下載，官網已開放獲取。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372311</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372311</guid>
      <pubDate>Sat, 13 Sep 2025 08:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達違反反壟斷法，市場監管總局依法決定實施進一步調查</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;國家市場監管總局發佈公告稱，&lt;span style="background-color:#ffffff; color:#222222"&gt;近日，經初步調查，英偉達公司違反《中華人民共和國反壟斷法》和《市場監管總局關於附加限制性條件批准英偉達公司收購邁絡思科技有限公司股權案反壟斷審查決定的公告》，市場監管總局依法決定對其實施進一步調查。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-05819d861c5fa6b672979b892bc20198c1c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372305</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372305</guid>
      <pubDate>Sat, 13 Sep 2025 08:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程工具 Cursor 升級 Tab 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程工具 Cursor&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fblog%2Ftab-rl" target="_blank"&gt;宣佈&lt;/a&gt;對其代碼自動補全系統 Tab 模型進行重大升級。此次升級聚焦於減少低質量建議，顯著提升準確性。據 Cursor 稱，新模型提供的建議數量比舊版減少 21%，但接受率提高了 28%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7d38fa82207b8f8398156bf34ea4383041e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為解決此前模型存在的問題，Cursor 最初考慮訓練單獨模型預測建議接受度，參考 2022 年 GitHub Copilot 相關研究，採用邏輯迴歸過濾技術。但 Cursor 期望更通用機制，最終利用強化學習中的策略梯度方法，使模型因建議被接受獲獎勵，被拒則受懲罰。該方法需「在線策略」數據，Cursor 通過每日多次向用戶部署新檢查點，並依據最新交互快速重新訓練模型來實現。&lt;/p&gt; 
&lt;p&gt;Cursor 希望實現不只是事後過濾失敗建議，而是讓主模型本身在建議生成階段就儘量避免「壞建議」。他們用 policy gradient 方法來訓練 Tab 模型，讓模型在做出建議 vs 不建議的決策上，最大化一個定義好的 reward 函數。這個 reward 重在：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;鼓勵建議被接受（accept suggestions）&lt;/li&gt; 
 &lt;li&gt;懲罰建議被拒絕&lt;/li&gt; 
 &lt;li&gt;不建議（show nothing）在模型判斷不確定或建議被低接收率預計的情況下也給予中性或某種 reward。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;舉例來説，如果模型估計建議被接受的機會至少 25%，顯示建議會有正 reward；如果低於，則建議不被顯示以避免 negative reward。&lt;/p&gt; 
&lt;p&gt;目前，Tab 模型在平台上響應用戶每一次操作，每日處理超 4 億次請求。業內對此次升級反響積極，有 OpenAI 工程師稱讚 Cursor 在前沿技術規模化應用方面的領先嚐試。&lt;/p&gt; 
&lt;p&gt;今年 6 月，Cursor 母公司 Anysphere 融資 9 億美元，估值達 99 億美元，並推出高端訂閲計劃，同時平台更新了自動代碼審查等功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372303</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372303</guid>
      <pubDate>Sat, 13 Sep 2025 08:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 董事會主席承認 AI 泡沫：有人會血賺也有人會血虧</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;AI 領域的狂熱情緒正引發一場關於「泡沫」的激烈辯論，而 OpenAI 董事會主席 Bret Taylor 對此給出了一個明確但複雜的答案：我們確實身處泡沫之中，但這並不妨礙 AI 最終創造巨大的經濟價值。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt;
 近日，在接受媒體 The Verge 採訪時，Bret Taylor 贊同了
 &lt;span&gt;OpenAI 首席執行官 Sam Altman 先前的觀點&lt;/span&gt;，承認「我們正處於 AI 泡沫中，有人將損失一大筆錢」。
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 警告稱，&lt;strong&gt;與任何顛覆性技術浪潮一樣，這一過程將不可避免地產生巨大的贏家，同時也會讓許多人損失慘重。&lt;/strong&gt;他同時認為，AI 將改變經濟格局並創造巨大價值，這與市場存在泡沫，是兩個可以同時成立的事實。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 將當前的 AI 熱潮與上世紀 90 年代末的互聯網泡沫進行了直接比較。他指出，&lt;strong&gt;儘管當時無數公司在泡沫破裂中倒下，但從長遠來看，「1999 年的那些人（對互聯網未來的判斷）在某種程度上是正確的」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;如今，亞馬遜和谷歌等誕生於那個時代的公司已成為全球市值最高的企業之一，證明瞭泡沫下的遠見最終能夠兌現：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;「實際上，如果你看看世界的 GDP，互聯網的存在實際上創造了多少或影響了互聯網？有人可能會説，1999 年的所有人都是對的。它對幾乎所有指標都有同樣的影響。」&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;關鍵在於區分泡沫的「方向性」&lt;/strong&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 詳細闡述了他對 AI 泡沫與互聯網泡沫的類比。他認為，&lt;strong&gt;關鍵在於區分方向的正確性與具體投資標的的成功率。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;互聯網泡沫時期，許多商業模式如 Webvan（網上生鮮配送）最終失敗，但其核心理念在互聯網基礎設施成熟後，由 Instacart 和 DoorDash 等公司成功實現。這表明，即便最初的嘗試失敗，其背後的趨勢和需求是真實存在的。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;同樣，在互聯網早期，大量投資光纖網絡的公司破產，但這些基礎設施最終被後來者利用，支撐了整個數字經濟的繁榮。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 表示，「AI 將改變經濟」和「很多人會虧錢」這兩個論斷可以同時為真：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;「我認為 AI 將改變經濟是事實，我認為它將像互聯網一樣，在未來創造巨大的經濟價值。同時我認為我們也處於泡沫之中，很多人會損失很多錢。&lt;strong&gt;我認為兩者同時是絕對正確的，而且這兩件事同時發生的歷史先例很多。」&lt;/strong&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;這意味着當前的鉅額投資，無論最終流向哪家公司，都在為下一代 AI 應用鋪平道路，但並非所有參與者都能分享到最後的果實。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;AI 如此「燒錢」的原因：市場尚不成熟&lt;/strong&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 並不同意「模型迭代已顯著放緩」的觀點，他以編碼任務為例，指出新模型在特定領域的性能仍有「階躍式」提升。但他同時認為，隨着模型能力的成熟和普及，對於許多任務而言，模型已達到「足夠好」的水平。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;他預測，未來構建 AI 應用將更像是「如何使用數據庫」，而非「如何編寫數據庫」。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;對於市場上關於 AI 投入產出比的質疑，例如一份 MIT 報告指出許多企業 AI 支出未見成效，Taylor 認為，&lt;strong&gt;這主要是因為市場尚不成熟。&lt;/strong&gt;許多公司正在進行「AI 觀光」（AI tourism），試圖自己構建解決方案，其過程複雜且容易失敗。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;他相信，正確的路徑是購買像 Sierra（用於客服）或 Harvey（用於法律）這樣專注於特定領域的成熟 AI 解決方案。隨着更多「應用型 AI 公司」的出現，企業將能更直接地購買到解決其痛點 AI 代理，從而真正實現 AI 的價值。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;「我認為我們正處於 AI 的早期階段，還沒有一個出色的供應商來解決您業務中遇到的每個問題。因此，您要麼必須等待，要麼必須自己構建它。」&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372298</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372298</guid>
      <pubDate>Sat, 13 Sep 2025 07:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 發佈 LLM Agent 工具編寫指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 官方博客近日發佈了一份詳細指南&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fengineering%2Fwriting-tools-for-agents" target="_blank"&gt;&lt;em&gt;《Writing effective tools for LLM agents—using LLM agents》&lt;/em&gt;&lt;/a&gt;，闡述如何利用 Model Context Protocol（MCP）為 LLM Agent 設計高效工具，並提出了「原型-評估-協作」三步迭代流程，歸納了五大設計原則。&lt;/p&gt; 
&lt;p&gt;1. 謹慎選擇工具&lt;br&gt; 2. 清晰的命名空間&lt;br&gt; 3. 讓工具返回更具意義的上下文&lt;br&gt; 4. 優化返回信息的 Token 效率&lt;br&gt; 5. 通過提示工程提升工具説明的質量&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-54ceebb7c490a4f1d803e1a0d17a5f1bf5f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;文章指出，工具是「確定性系統與非確定性 Agent 之間的合約」，開發者需跳出傳統 API 思維，面向 Agent 的上下文限制與策略多樣性重新設計接口。&lt;/p&gt; 
&lt;p&gt;作者透露，文中多數結論由 Claude Code 反覆分析評估腳本、重構工具描述與模式後自動得出，且仍在通過保留測試集防止過擬合。Anthropic 已同步開源工具評估 Cookbook，並預告未來 MCP 協議與底層 LLM 升級時，同樣方法可讓工具能力隨 Agent 同步演進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372294/anthropic-writing-tools-for-agents</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372294/anthropic-writing-tools-for-agents</guid>
      <pubDate>Sat, 13 Sep 2025 07:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里 Qoder 新升級，Repo Wiki 支持共享、編輯和導出</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;過去兩年雖有眾多 AI 編程工具湧現，但在真實軟件開發中仍面臨諸多挑戰，如工程複雜度高、不確定性強和知識無沉澱傳承等，現有工具難以滿足開發需要，Qoder 正是為解決這些問題而推出。Qoder 是阿里巴巴發佈的一款全新的 Agentic 編程平台，它集成了全球頂尖的編程模型，提供最強的上下文工程能力，可一次檢索 10 萬個代碼文件。基於強大的編程智能體，可實現 AI 自主研發，大幅提升真實軟件的開發效率。&lt;/p&gt; 
&lt;p&gt;據官方披露，Qoder 上線 5 天用戶規模突破 10 萬，&lt;strong&gt;其中 Repo Wiki 功能受到開發者廣泛好評。&lt;/strong&gt; Repo Wiki 能基於代碼自動為工程生成結構化的文檔，涵蓋工程架構、引用關係圖譜、技術文檔等內容，並持續跟蹤代碼與文檔的變更，把知識沉澱為可複用的工程資產。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6d025ed54bfc027f70832d07af8b3f21d11.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;舉例來説，&lt;strong&gt;在新項目開始時&lt;/strong&gt; ，Repo Wiki 可以根據工程代碼自動生成架構圖譜、模塊文檔、API 手冊以及依賴關係文檔，幫助團隊搭建工程框架，讓成員快速瞭解工程結構。&lt;strong&gt;對於遺留系統研發&lt;/strong&gt; ，Repo Wiki 能快速分析工程結構，幫助開發者理解代碼邏輯，解決遺留工程文檔缺失或過時的問題。更為重要的是，&lt;strong&gt;工程中存在許多隱性知識&lt;/strong&gt; ，如設計決策考量、模塊之間深層依賴關係等，這些知識通常散落在文檔、郵件或口頭交流中，難以被有效獲取。Repo Wiki 能夠將這些隱性知識顯性化，以結構化的形式存儲和呈現，方便開發者和智能體更全面、準確地理解代碼工程。同時 Repo Wiki 對於&lt;strong&gt;軟件代碼的學習和傳承&lt;/strong&gt;大有幫助，讓開發者更快地理解陌生代碼庫，提高開發、學習和交接效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;今天， Repo Wiki 正式上線新功能：支持 Wiki 共享、編輯和導出。&lt;/strong&gt; 為了讓知識更好地在團隊中流轉，Qoder 提供了 Wiki 共享能力。當用戶在本地生成 Wiki 時，會自動在代碼庫中創建一個專屬目錄，只需將該目錄推送至代碼倉庫，即可將生成的文檔輕鬆共享給團隊成員，實現協作共建。&lt;/p&gt; 
&lt;p&gt;此外，為確保 Wiki 與代碼始終保持一致，Qoder 內置了自動檢測機制。當發現代碼變更導致文檔滯後時，系統會及時提醒更新 Wiki。同時為了支持靈活自定義，開發者可以直接修改 Wiki 內容， 實現手工維護。&lt;/p&gt; 
&lt;p&gt;Qoder 目前在公測期，歡迎免費下載體驗：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqoder.com%2F" target="_blank"&gt;https://qoder.com/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18691841</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18691841</guid>
      <pubDate>Sat, 13 Sep 2025 07:22:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>螞蟻開源發佈《大模型開源開發生態全景與趨勢》報告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻開源聯合 Inclusion AI&amp;nbsp;發佈了一份大模型開發生態下的開源項目全景圖，和一份對生態趨勢的洞察報告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0915/151228_jv6C_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://antoss-landscape.my.canva.site/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;據悉，這是報告 5 月首次發佈後的 2.0 版本，不僅全面揭示了人工智能開源領域的發展現狀和未來趨勢，還納入了百餘天內開源社區的新動向，為行業發展提供重要參考。&lt;/p&gt; 
&lt;p&gt;報告最初起源於螞蟻集團內部的技術趨勢洞察，其中的數據全部來源於開源社區，通過對 GitHub 全平台項目的分析，使用 OpenRank 算法對項目進行篩選和排名。&lt;/p&gt; 
&lt;p&gt;具體來看，本次發佈的大模型開源開發生態全景圖共收錄了分佈在 22 個技術領域的 114 個最受關注的開源項目，分為 AI Agent 和 AI Infra 兩大技術方向。&lt;/p&gt; 
&lt;p&gt;據報告顯示，在參與全景圖項目開發的約 36 萬全球開發者中，統計到美國開發者佔比 24%，中國開發者佔比 18%，其次是印度（8%）、德國（6%）和英國（5%）。中美兩國合計貢獻超四成核心力量。更值得關注的是，在大模型開源策略上，中國廠商更傾向於開放權重的開源模型路線，而美國頭部廠商則多采用閉源模式。&lt;/p&gt; 
&lt;p&gt;和全景圖一同發佈的還有一份詳盡的洞察報告《從社區數據出發，再看大模型開源開發生態全景與趨勢》。該報告指出，62% 的大模型生態下的開源項目誕生於 2022 年 10 月「GPT 時刻」之後，平均「年齡」僅 30 個月，這反映出 AI 開源生態的高速迭代特性。&lt;/p&gt; 
&lt;p&gt;另外，AI 編程工具的爆發式增長也成為了矚目的趨勢。數據顯示，2025 年新出現的 Coding 工具平均獲得 3 萬以上開發者 Star 關注，其中 Gemini CLI 開源僅 3 個月，星標數已突破 6 萬，成為增長最快的項目之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372284</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372284</guid>
      <pubDate>Sat, 13 Sep 2025 07:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>火山引擎發佈命令行 AI Agent：veCLI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-UTsE4yDf2XRrbpP3TqOww" target="_blank"&gt;宣佈&lt;/a&gt;推出命令行 AI Agent：veCLI，無縫集成豆包大模型 1.6，veCLI 通過將大模型 AI 能力整合到命令行界面，讓開發者能夠在熟悉的環境中獲得智能助手的全方位支持，為開發者提供更智能、更高效的開發體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4f862d843b686e87e6ce50cfbbc0423f4f4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.volcengine.com/product/vecli&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ccc5e33323ef3899349dbac8ac9ecd86ef8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在技術架構上，veCLI 採用了「思考-行動」循環機制（ReAct），使 AI 助手能夠像經驗豐富的開發者一樣進行多步推理和問題解決。veCLI 不僅和豆包大模型無縫調用，還集成了 Kimi-K2、DeepSeek v3.1 等三方模型供用戶選擇，確保在複雜開發場景下的準確理解和高效響應。同時，還集成火山引擎 MCP Server 等，幫助用戶從構建到部署都更便捷調用火山引擎雲服務，提升雲上 AI 應用開發的效率。&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372278</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372278</guid>
      <pubDate>Sat, 13 Sep 2025 07:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
