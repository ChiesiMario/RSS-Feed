<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Tue, 19 Aug 2025 16:58:34 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>DeepSeek 剛剛更新線上模型版本至 V3.1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 在官方社羣宣佈，其線上模型版本已升級至 V3.1，上下文長度拓展至 128k。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0819/193913_BlOM_2720166.png" width="1196" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;歡迎前往官方網頁、APP、小程序測試，API 接口調用方式保持不變。&lt;/p&gt; 
&lt;p&gt;接口信息：https://platform.deepseek.com/usage&lt;/p&gt; 
&lt;p&gt;近日市場再度傳出深度求索下一代 AI 大模型 DeepSeek-R2 的發佈消息，預計時間窗口為 8 月 15 日至 30 日。對此，接近 DeepSeek 人士表示，該消息不實，並確認 DeepSeek-R2 在 8 月內並無發佈計劃。 &lt;/p&gt; 
&lt;p&gt;DeepSeek 創始人梁文鋒在內部表示，他對 R2 取得的進展並不滿意，並一直在竭力投入更多的時間來研發一款能夠讓該公司在 AI 領域保持領先地位的先進模型。&lt;/p&gt; 
&lt;p&gt;梁文峯要求模型達到更出色的結果才批准發佈，R2 的發佈還因更新版模型的數據標註時間超出預期而被推遲。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367254</guid>
      <pubDate>Mon, 18 Aug 2025 11:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 總裁透露 OpenAI 的 AGI 之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在最新一期的《Latent Space》訪談中，OpenAI 總裁 Greg Brockman 深入闡述了公司邁向 AGI 的整體路線圖，核心可概括為「三個轉向」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技術轉向：從「一次性預訓練」到「強化學習推理」&lt;/li&gt; 
 &lt;li&gt;資源轉向：把「算力」視為唯一稀缺資源&lt;/li&gt; 
 &lt;li&gt;落地轉向：從「科研樣品」到「可審計的生產 Agent」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7470bcfe83cc59abb3b2fd2b11145f80512.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Greg Brockman 透露，GPT-4 發佈之後，團隊內部覆盤「它為何還不是 AGI」，結論是僅靠大規模預訓練無法解決可靠性不足的問題，必須讓模型在與真實世界的交互中「試錯—反饋—再訓練」。因此 GPT-5 首次引入強化學習驅動的「動態推理」範式：模型邊使用邊生成數據，再用這些數據進行再訓練，逼近人類「邊做邊學」的循環。&lt;/p&gt; 
&lt;p&gt;他將這種「推理-重訓」飛輪稱為「超臨界學習」（supercritical learning）：當算力放大 10× 乃至 10 000× 時，模型不僅能掌握任務本身，還能推演出二階、三階後果，從而快速逼近 AGI。&lt;/p&gt; 
&lt;p&gt;Greg Brockman 還把「算力」視為唯一稀缺資源，他認為算法壁壘往往可通過堆算力解決；AGI 進度條幾乎與可用計算量線性相關。OpenAI 已把「持續投入大規模計算」寫入長期資源策略，並認為未來 AGI 的形態會是「一個模型管理器」——本地小模型按需調用雲端大算力，實現自適應計算。&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;總的來説，OpenAI 的 AGI 路線圖可概括為「用強化學習把模型放進真實世界，用算力把反饋循環推到極致，用安全可控的 Agent 形態把能力嵌入千行百業」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367248</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367248</guid>
      <pubDate>Mon, 18 Aug 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 143 被發現不適用於某些舊 Windows 10 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在舊版 Windows 10 上運行 Firefox 瀏覽器的用戶即將迎來很大困擾。目前在 Nightly 頻道提供的最新版本 Firefox 143 已不再適用於 1803 之前的版本。&lt;/p&gt; 
&lt;p&gt;在 Windows 10 1703、1709 或 2015 LTSB 等老版本上啓動該瀏覽器時，用戶會收到以下錯誤：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由於未找到 api-ms-win-core-console-11-2-0.dll，代碼無法繼續執行。重新安裝程序或許可以解決此問題。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0700df38d95ae0494d0de12f07efb1ce47d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FTheBobPony%2Fstatus%2F1955740560292999460" target="_blank"&gt;這一發現&lt;/a&gt;迅速引發了用戶的討論（他們已經對 Mozilla 向瀏覽器添加不必要的、耗費資源的內容&lt;a href="https://www.oschina.net/news/366029" target="_blank"&gt;感到不滿&lt;/a&gt;），他們要求 Mozilla 放棄舊版 Windows 10，這並非罕見之舉。儘管 Windows 10 總體上仍然受支持，但許多應用程序已無法在舊的版本上運行。&lt;/p&gt; 
&lt;p&gt;儘管如此，考慮到 Mozilla 瀏覽器仍然支持 Windows 7，放棄對部分 Windows 10 市場份額的支持卻令人意外，不過某些舊版本（例如 2015 LTSB 和 2016 LTSC）仍然受支持。Windows&amp;nbsp;10 2015 LTSB 版本將於 2025 年 10 月停止支持，而 2016 LTSC 版本將繼續獲得更新，直到 2016 年 10 月。&lt;/p&gt; 
&lt;p&gt;然而事實證明，Mozilla 並沒有在 1803 之前的 Windows 10 版本上淘汰 Firefox。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ffirefox%2Fcomments%2F1mph4ra%2Fstarting_with_firefox_143_it_will_now_only%2F" target="_blank"&gt;Mozilla 工程師在 Reddit 上&lt;/a&gt;迅速處理了此事，並確認 Firefox 143 Nightly 無法在舊版 Windows 10 上運行的問題只是一個 bug，而非故意為之。因此，該問題應該很快就會得到修復。您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1983020" target="_blank"&gt;在 Bugzilla 官方網站上&lt;/a&gt;跟蹤發現的 bug 。&lt;/p&gt; 
&lt;p&gt;與此同時，用戶創建了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faubymori%2FFirefox-OldWindows%252010-Fix" target="_blank"&gt;一個臨時解決方案&lt;/a&gt;，讓瀏覽器在 Firefox 軟件工程師準備永久修復程序期間能夠正常運行。這也可以提醒大家不要依賴 Nightly 版本，因為這些版本的更改有時可能會導致瀏覽器完全崩潰。&lt;/p&gt; 
&lt;p&gt;Mozilla 尚未宣佈終止 Windows 10 支持的計劃。不過，由於 Windows 7 仍受支持，因此可以預期開發人員將在相當長的一段時間內繼續在 Windows 10 上更新 Firefox。另一方面，微軟近日透露，Edge 瀏覽器在 2025 年 10 月主流支持結束後，仍將在 Windows 10 上繼續支持三年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367246</guid>
      <pubDate>Mon, 18 Aug 2025 11:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claudia —— 基於 Tauri 2 的 Claude Code 桌面客戶端</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Claudia 是一款強大的桌面應用程序，作為 Claude Code 的圖形化命令中心，為 AI 輔助開發工作流程提供了直觀的界面。該應用基於 Tauri 2、React 和 TypeScript 構建，填補了 Claude Code CLI 與開發者全面視覺體驗之間的空白。&lt;/p&gt;

&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/181014_4hpz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;Claudia 通過提供功能豐富的圖形用戶界面（GUI），改變了開發者與 Claude Code 的交互方式，提升了生產力並簡化了 AI 輔助開發流程。該應用程序基於您現有的 Claude Code 安裝，自動檢測您的&lt;code&gt;~/.claude&lt;/code&gt;目錄，併為項目、會話和自定義 AI 代理提供可視化界面。&lt;/p&gt;

&lt;p&gt;Claudia 為存儲在&lt;code&gt;~/.claude/projects/&lt;/code&gt;中的所有 Claude Code 項目提供了可視化瀏覽器。您可以：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通過用戶友好的界面瀏覽項目&lt;/li&gt;
&lt;li&gt;查看並恢復帶有完整上下文的過往編碼會話&lt;/li&gt;
&lt;li&gt;搜索特定項目和會話&lt;/li&gt;
&lt;li&gt;查看會話元數據，包括首次消息和時間戳&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;該應用程序自動檢測正在運行的 Claude Code 會話，並允許您從中央界面進行管理。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/claudia-code</link>
      <guid isPermaLink="false">https://www.oschina.net/p/claudia-code</guid>
      <pubDate>Mon, 18 Aug 2025 10:39:00 GMT</pubDate>
    </item>
    <item>
      <title>XZ Utils 後門仍然潛伏在 Docker 鏡像中</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;安全研究公司 Binarly &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.binarly.io%2Fblog%2Fpersistent-risk-xz-utils-backdoor-still-lurking-in-docker-images" target="_blank"&gt;發佈報告稱&lt;/a&gt;，曾在 2024 年曝光的 &lt;strong&gt;XZ Utils 後門&lt;/strong&gt;仍在部分 Docker 鏡像中潛伏，提醒開發者和運維人員容器供應鏈的潛在風險仍未徹底消除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;xz-utils&lt;/code&gt; 軟件包曾在 2024 年被發現存在嚴重後門（CVE‑2024‑3094，CVSS 10.0 分）。該後門通過 &lt;code&gt;liblzma.so&lt;/code&gt; 對 OpenSSH 函數加鈎子，實現繞過 SSH 認證和遠程執行權限操作。&lt;/p&gt; 
&lt;p&gt;儘管該漏洞在公開後迅速修復，但 Binarly 團隊最新掃描顯示，&lt;strong&gt;截至 2025 年 8 月，仍有 12 個 Debian 官方基礎鏡像直接包含該後門&lt;/strong&gt;，並且通過依賴關係，至少有 &lt;strong&gt;35 個鏡像存在潛在傳播風險&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/183442_zItb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;針對該情況，Debian 維護者回應稱，這些鏡像屬於過時開發版，主要保留歷史記錄，因此選擇不移除。Binarly 則提醒，即便利用條件苛刻，這些帶網絡觸發能力的後門鏡像仍可能被自動化構建或無意拉取帶入生產環境，存在潛在安全威脅。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367240</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367240</guid>
      <pubDate>Mon, 18 Aug 2025 10:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>達夢數據：公司董事兼總經理被留置</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;達夢數據發佈公告稱，公司於近期收到湖北省應城市監察委員會下發的《立案通知書》及《留置通知書》，對公司董事兼總經理皮宇立案調查並實施留置措施。&lt;/p&gt; 
&lt;p&gt;目前，公司已對相關工作進行妥善安排，預計該事項不會對公司生產經營產生重大影響。其他董事、監事和高級管理人員均正常履職，公司及子公司日常經營情況正常，各項業務穩步推進。&lt;/p&gt; 
&lt;p&gt;&lt;img height="532" src="https://oscimg.oschina.net/oscnet/up-3b66d352d66b8255335b97b879b6b195785.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367239</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367239</guid>
      <pubDate>Mon, 18 Aug 2025 10:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>歐洲 AI 創企發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;歐洲知名 AI 初創公司 Multiverse Computing 近日發佈了兩款極其微小的 AI 模型，小到可以用雞腦和蠅腦來命名。該公司聲稱這是全球最小但仍保持高性能的模型，能夠處理聊天、語音識別，其中一款甚至具備推理能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這些超小型模型專為物聯網設備設計，同時可以在智能手機、平板電腦和個人電腦上本地運行。公司創始人羅曼·奧魯斯向 TechCrunch 表示："我們可以將模型壓縮到如此程度，使其能夠適配各種設備。你可以在本地運行它們，直接在 iPhone 上，甚至在 Apple Watch 上。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Multiverse Computing 總部位於西班牙多諾斯蒂亞，在全球設有辦公室，員工約 100 人，是一家備受關注的歐洲 AI 初創公司。該公司由歐洲頂級量子計算和物理學教授羅曼·奧魯斯、量子計算專家塞繆爾·穆格爾和前 Unnim 銀行副首席執行官恩裏克·利薩索·奧爾莫斯共同創立。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-994e0870ab2f0680c22e597e4d0461fe9b9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;今年 6 月，該公司憑藉名為"CompactifAI"的模型壓縮技術成功融資 1.89 億歐元（約 2.15 億美元）。自 2019 年成立以來，公司累計融資約 2.5 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;CompactifAI 是一種量子啓發的壓縮算法，能夠在不犧牲模型性能的前提下減小現有 AI 模型的體積。奧魯斯解釋説:"我們擁有的壓縮技術不是計算機科學或機器學習領域人員會採用的典型壓縮技術，因為我們來自量子物理學背景。這是一種更加精妙和精細的壓縮算法。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;該公司已經發布了大量開源模型的壓縮版本，特別是流行的小型模型如 Llama4Scout 或 Mistral Small3.1，並剛剛推出了 OpenAI 兩個新開源模型的壓縮版本。公司還壓縮了一些大型模型，比如提供 DeepSeek R1Slim 版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;專注於模型小型化的 Multiverse 將額外精力投入到創造儘可能小但功能強大的模型上。其兩款新模型小到足以為幾乎任何物聯網設備帶來聊天 AI 功能，並且無需互聯網連接。公司幽默地稱這個系列為"模型動物園"，因為產品是根據動物大腦尺寸命名的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;名為 SuperFly 的模型是 Hugging Face 開源模型 SmolLM2-135 的壓縮版本。原始模型有 1.35 億個參數，專為設備端使用開發。SuperFly 壓縮至 9400 萬個參數，奧魯斯將其比作蠅腦的大小。他説："這就像擁有一隻蒼蠅，但稍微聰明一點。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;SuperFly 專為在極其受限的數據上進行訓練而設計，比如設備操作數據。Multiverse 設想將其嵌入家用電器中，讓用戶能夠通過語音命令操作設備，如對洗衣機説"開始快洗"，或詢問故障排除問題。通過少量處理能力（如 Arduino），該模型就能處理語音界面，公司向 TechCrunch 進行了現場演示。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;另一款名為 ChickBrain 的模型更大，有 32 億個參數，但功能也更強大，具備推理能力。Multiverse 表示這是 Meta Llama3.18B 模型的壓縮版本，但小到足以在 MacBook 上運行，無需互聯網連接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更重要的是，奧魯斯表示 ChickBrain 在多個標準基準測試中實際上略微超越了原始模型，包括語言技能基準 MMLU-Pro、數學技能基準 Math500 和 GSM8K，以及通用知識基準 GPQA Diamond。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;需要注意的是，Multiverse 並未聲稱其模型動物園會在這些基準測試中擊敗最大的最先進模型，動物園的性能甚至可能不會出現在排行榜上。關鍵在於該公司的技術能夠在不影響性能的情況下縮小模型尺寸。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;奧魯斯表示，公司已在與所有領先的設備和家電製造商進行洽談。他説:"我們正在與蘋果洽談，也在與三星、索尼和惠普對話。惠普在最後一輪融資中作為投資者參與進來。"這輪融資由知名歐洲風投公司 Bullhound Capital 領投，包括 HP Tech Ventures 和東芝在內的多家機構參與。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這家初創公司還為其他形式的機器學習提供壓縮技術，如圖像識別，在六年時間裏已獲得巴斯夫、Ally、穆迪、博世等客戶。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了直接向主要設備製造商銷售模型外，Multiverse 還通過託管在 AWS 上的 API 提供壓縮模型，任何開發者都可以使用，通常比競爭對手收取更低的 token 費用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367238</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367238</guid>
      <pubDate>Mon, 18 Aug 2025 10:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小米 Q2 淨利潤同比增長 75.4%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;小米集團公佈 Q2 財報，數據顯示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;小米集團第二季度營收 1159.6 億元人民幣，同比增長 30.5%，創歷史新高。預估 1149.4 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;調整後淨利潤 108.3 億元人民幣，同比增長 75.4%，同樣創下歷史新高。預估 102.3 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;營業利潤 134.4 億元人民幣，預估 104.3 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;研發支出 77.6 億元人民幣，同比增長 41.2%。預估 71.8 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;智能電動汽車及 AI 等創新業務分部收入達到人民幣 213 億元，其中汽車業務貢獻了 206 億元。該分部的毛利率高達 26.4%，遠高於去年同期的 15.4%。財報將其歸因於核心零部件成本下降、單位製造成本降低，以及高 ASP（平均售價）的 Xiaomi SU7 Ultra 交付。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="217" src="https://oscimg.oschina.net/oscnet/up-7c457b8deb1369b766421cd8022a09bb76f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心業務進展：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能電動汽車：&lt;/strong&gt;已成為絕對的增長引擎。本季度收入達 213 億元，交付 81,302 輛新車。毛利率高達 26.4%，遠超市場預期，顯示出強大的成本控制和高端車型交付能力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;IoT 與生活消費產品：&lt;/strong&gt;表現亮眼，收入 387 億元，同比猛增 44.7%，毛利率提升至 22.5%。智能大家電（空調、冰箱、洗衣機）是主要增長動力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能手機：&lt;/strong&gt;儘管出貨量微增 0.6% 至 4240 萬台，但收入同比下滑 2.1% 至 455 億元，毛利率從 12.1% 降至 11.5%，主要受境外市場競爭及國內促銷活動影響。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;互聯網服務：&lt;/strong&gt;收入穩定增長至 91 億元，同比增長 10.1%，但毛利率從 78.3% 微降至 75.4%。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;小米集團表示，2025 年第二季度，智能大家電的收入創歷史新高，同比增長達 66.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="2551" src="https://static.oschina.net/uploads/space/2025/0819/175808_cTEa_4252687.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367233</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367233</guid>
      <pubDate>Mon, 18 Aug 2025 09:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌工程師提交補丁：Linux 內核首次支持 OOM 策略可編程</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 內核正迎來一項可能改變內存管理方式的新提案。來自谷歌的內存管理專家 Roman Gushchin 提交了一組補丁，計劃允許通過 BPF（eBPF）直接定製系統在 &lt;strong&gt;內存溢出（OOM, Out-of-Memory）&lt;/strong&gt; 時的處理邏輯。這意味着，長期以來依賴內核默認 OOM killer 或用戶空間工具（如 systemd-oomd）的侷限性，或將被更靈活、可編程的機製取代。&lt;/p&gt; 
&lt;p&gt;&lt;img height="712" src="https://static.oschina.net/uploads/space/2025/0819/174242_BTqv_2720166.png" width="1082" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lore.kernel.org/lkml/20250818170136.209169-1-roman.gushchin@linux.dev/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;該方案的核心思路是在內核觸發 OOM killer 之前，先調用 BPF 程序。運維人員或雲平台可以藉此決定是終止某個特定進程、清理某個內存 cgroup，甚至通過刪除 tmpfs 文件來釋放內存，而不必一刀切地依賴內核默認策略。同時，新的補丁還引入基於 PSI（Pressure Stall Information） 的 OOM 觸發機制，更好地判斷何時真正進入「內存壓力」狀態，從而避免系統假死或誤殺關鍵進程。&lt;/p&gt; 
&lt;p&gt;在實現上，這些補丁增加了新的 BPF 輔助函數，例如顯式殺死指定進程的 &lt;code&gt;bpf_oom_kill_process()&lt;/code&gt;，以及獲取內存 cgroup 根節點的 &lt;code&gt;bpf_get_root_mem_cgroup()&lt;/code&gt;，為內核空間提供了更強的可編程接口。&lt;/p&gt; 
&lt;p&gt;如果最終被合入主線，Linux 將首次賦予開發者和運維團隊在內核層面 &lt;strong&gt;「編寫自己的 OOM 策略」&lt;/strong&gt; 的能力，這對數據中心、雲計算平台以及對內存敏感的服務部署而言，都可能帶來深遠影響。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367232</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367232</guid>
      <pubDate>Mon, 18 Aug 2025 09:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gemini API 支持抓取 URL</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌宣佈其 Gemini API 中的 URL Context 工具&lt;strong&gt;已正式支持直接抓取 URL 內容&lt;/strong&gt;，無需額外腳本或中間步驟。&lt;/p&gt; 
&lt;p&gt;&lt;img height="765" src="https://static.oschina.net/uploads/space/2025/0819/172728_9w7A_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini API 提供了 &lt;strong&gt;URL Context 功能&lt;/strong&gt;，允許你在請求中直接嵌入網頁鏈接，模型會自動訪問並解析網頁內容。支持的內容類型包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文本網頁（HTML、JSON、TXT 等）&lt;/li&gt; 
 &lt;li&gt;PDF 文件&lt;/li&gt; 
 &lt;li&gt;圖片（PNG、JPEG、WebP 等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不支持的內容：YouTube 視頻、Google Docs、付費牆內容等。&lt;/p&gt; 
&lt;p&gt;✅ 使用示例（Python SDK）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
  model="gemini-2.5-flash",
  contents=[
      "總結這篇文章的內容：",
      types.Part.from_uri(
        uri="https://example.com/article",
        mime_type='text/html'
      )
  ]
)
print(response.text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;使用限制&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;每次最多支持 &lt;strong&gt;20 個 URL&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;單個 URL 內容大小上限為 &lt;strong&gt;34MB&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;抓取內容會計入 &lt;strong&gt;輸入 Tokens 費用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用 &lt;strong&gt;Gemini CLI&lt;/strong&gt;，也可以通過 &lt;code&gt;web_fetch&lt;/code&gt; 工具快速抓取網頁，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gemini-cli web-fetch --prompt "總結 https://example.com/article 的主要內容"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該工具會自動識別提示中的 URL 並調用 Gemini API 抓取內容。&lt;/p&gt; 
&lt;p&gt;如你正在開發基於 Gemini 的應用，&lt;strong&gt;URL Context 功能&lt;/strong&gt;已足夠替代傳統的爬蟲或 HTML 解析器，大幅提升開發效率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關鏈接&lt;/p&gt; 
&lt;p&gt;https://ai.google.dev/gemini-api/docs/url-context&lt;br&gt; https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#url-context&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367231/gemini-api-url-context</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367231/gemini-api-url-context</guid>
      <pubDate>Mon, 18 Aug 2025 09:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>淘寶「AI 萬能搜」功能灰度測試</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;淘寶正在灰度測試一項名為「AI 萬能搜」的新功能，旨在通過大模型技術重構電商搜索體驗。該功能位於淘寶搜索頁的「AI 萬能搜」標籤頁，標誌着 AI 技術在電商領域的應用正從企業端（B 端）營銷，加速滲透至消費者端 (C 端) 的實用階段。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「AI 萬能搜」是一款基於大模型的 AI 問答產品，能夠理解用戶的自然語言提問並進行深度思考。用戶提問後，AI 會生成一份融合文字、商品、視頻和圖片的「答案報告」，以解決用戶在購物過程中遇到的各種消費難題，例如購物攻略、口碑評測和優惠諮詢等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;據瞭解，目前「AI 萬能搜」主要聚焦於四大核心場景:穿搭指南、送禮清單、選購攻略和問口碑。該功能的一大亮點在於，用戶可以清晰地看到 AI 的思考過程，其思考邏輯主要分為三個步驟:獲取信息、查詢需求和分析總結。儘管目前尚不清楚其底層大模型是否只使用了「千問」，但這一功能已經展現出 AI 在提升消費者購物決策效率上的巨大潛力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="649" src="https://oscimg.oschina.net/oscnet/up-ea057aa8125432f67b68af7319fc597d9e8.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367229</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367229</guid>
      <pubDate>Mon, 18 Aug 2025 09:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Abogen - 文本轉語音工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Abogen 是一款功能強大的文本轉語音工具，可輕鬆將 ePub、PDF 或文本文件在幾秒鐘內轉換為帶有匹配字幕的高質量音頻。可以使用&lt;a href="https://huggingface.co/hexgrad/Kokoro-82M"&gt;Kokoro-82M&lt;/a&gt;將其用於有聲讀物、Instagram、YouTube、TikTok 的配音，或任何需要自然語音的文本轉語音項目。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151846_7vpx_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151903_hNpV_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/abogen</link>
      <guid isPermaLink="false">https://www.oschina.net/p/abogen</guid>
      <pubDate>Mon, 18 Aug 2025 09:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Vercel 旗下 AI 前端開發工具 v0 推出 iOS 應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vercel 旗下 AI 前端開發工具 v0&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fv0%2Fstatus%2F1957487790205325760"&gt;宣佈&lt;/a&gt;即將推出其 iOS 應用程序，目前已開放候補名單註冊。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0819/164508_7TkM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;http://v0.app/ios&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;根據官方發佈的信息，其宣傳語為 「Anything. Anyone. Anywhere.」。用戶現在可以通過官方鏈接加入等待列表。&lt;/p&gt; 
&lt;p&gt;Vercel v0 是一個利用自然語言提示生成全棧 web 應用的 AI 工具，其核心優勢在於通過簡單的文本描述即可快速生成高質量的用戶界面和代碼。自 2023 年首次推出以來，v0 憑藉其在前端 UI 生成上的卓越表現，特別是在 React 和 Next.js 框架中的應用，贏得了開發者和企業的廣泛認可。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367213</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367213</guid>
      <pubDate>Mon, 18 Aug 2025 08:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中山大學聯合美團打造 X-SAM 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中山大學、鵬城實驗室與美團三方聯合研發的 X-SAM 圖像分割模型近期正式發佈，這款多模態大模型在圖像分割領域實現了重要突破，將傳統的"分割萬物"能力升級為"任意分割"，顯著提升了模型的適應性和應用範圍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;傳統的 Segment Anything Model（SAM）雖然在生成密集分割掩碼方面表現出色，但其只能接受單一視覺提示輸入的設計侷限性明顯。針對這一技術瓶頸，研究團隊創新性地提出了視覺定位分割 (Visual Grounded Segmentation， VGS) 任務框架，通過交互式視覺提示實現對所有實例對象的精確分割，為多模態大語言模型提供了像素級的理解能力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的技術架構採用了多項創新設計。模型支持統一的輸入格式和輸出表示，能夠處理多種類型的視覺和文本查詢輸入。其核心的雙編碼器架構確保了對圖像內容和分割特徵的深度理解，而分割連接器則提供多尺度信息融合，大幅提升分割精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="432" src="https://oscimg.oschina.net/oscnet/up-17e3fd0c4916165c034f2f1fecd344dd8e9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最值得關注的是，X-SAM 集成了&lt;span&gt;最新&lt;/span&gt;的 Mask2Former 架構作為分割解碼器，這使得模型能夠在單次操作中同時分割多個目標對象，徹底突破了傳統 SAM 只能處理單一對象的技術限制。這一改進不僅提高了處理效率，也為複雜場景下的批量分割任務提供了可能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在模型訓練方面，研究團隊採用了三階段漸進式訓練策略，通過逐步增強的學習過程確保模型性能的穩定提升。經過在 20 多個主流分割數據集上的全面測試，X-SAM 在對話生成分割任務和圖文理解任務中均取得了領先的性能表現，驗證了其技術方案的有效性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的發佈為圖像分割技術發展指明瞭新方向，也為構建更加智能的通用視覺理解系統提供了重要的技術基礎。研究團隊表示，下一步將重點探索該技術在視頻領域的應用拓展，推動圖像與視頻分割技術的統一化發展，進一步提升機器視覺理解能力的邊界。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這項研究成果不僅在學術層面具有重要意義，其在自動駕駛、醫療影像、工業檢測等實際應用場景中的潛力也值得期待。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367209</guid>
      <pubDate>Mon, 18 Aug 2025 08:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ElevenLabs 上線 Eleven Music API，首款商用 AI 音樂生成接口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ElevenLabs&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Felevenlabs.io%2Fblog%2Feleven-music-now-available-in-the-api" target="_blank"&gt;宣佈推出 Eleven Music API&lt;/a&gt;，這是首款基於全授權數據訓練、專為開發者打造的商用 AI 音樂生成接口。自 2024 年推出以來，創作者已通過該工具生成超 75 萬首歌曲，印證市場強勁需求。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;使用文檔：https://elevenlabs.io/docs/cookbooks/music/quickstart&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77a672de334942fafedf640d6297bfa4453.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，該 API 突破性解決了 AI 音樂領域的版權痛點，其模型基於百萬小時授權音頻數據訓練，採用類 GPT 的 Transformer 架構，可通過文本提示實時生成多風格、多情緒的原創音樂，徹底規避未授權數據引發的法律風險，為遊戲、廣告、內容創作等行業提供合規解決方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367208/eleven-music-now-available-in-the-api</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367208/eleven-music-now-available-in-the-api</guid>
      <pubDate>Mon, 18 Aug 2025 08:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達最新研究：SLM（小型語言模型）才是 Agentic AI 的未來</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;英偉達與佐治亞理工學院研究人員聯合發佈《Small Language Models are the Future of Agentic AI》論文，提出了一個極具顛覆性的觀點：SLM（小型語言模型）才是智能代理（Agentic AI）的未來。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1054" src="https://static.oschina.net/uploads/space/2025/0819/161145_Gy8G_2720166.png" width="1760" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/pdf/2506.02153&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;論文核心觀點總結：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;能力與需求匹配：&lt;/strong&gt;當前主流的 AI 代理系統（如 AutoGPT、Open Interpreter 等）普遍採用 &lt;strong&gt;大型語言模型（LLM）&lt;/strong&gt; 作為「大腦」，但這些代理的任務場景往往高度結構化、重複性強。&lt;br&gt; 英偉達指出，&lt;strong&gt;7B 級別的 SLM 在代理任務上的表現已接近 70B+ 的 LLM&lt;/strong&gt;，而資源消耗卻低得多。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;經濟性與可持續性：&lt;/strong&gt;使用 LLM 構建代理系統的&lt;strong&gt;成本是 SLM 的 10-30 倍&lt;/strong&gt;，且能耗巨大。SLM 的輕量級特性使其更適合邊緣設備、本地部署，推動 AI 從「展示品」走向「生產力工具」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;系統架構優化：&lt;/strong&gt;論文提出一種 &lt;strong&gt;「混合型代理架構」&lt;/strong&gt;，即由多個小型專用模型（SLM）分工協作，必要時再調用 LLM 處理複雜任務，避免「殺雞用牛刀」的資源浪費。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;研究人員在文中表示，與業界普遍追捧的大型語言模型（LLMs）相比，SLMs 不僅在特定任務上已具備足夠的處理能力，其固有的經濟性和適用性也更為出色，為構建高效、可持續的 AI Agent 奠定了基礎。&lt;/p&gt; 
&lt;p&gt;而據研究團隊透露，儘管 LLMs 在處理通用和複雜任務上取得了突破，但此類模型在許多 Agent 的專用場景中存在明顯的資源冗餘問題，未能達到理想的成本效益標準。&lt;/p&gt; 
&lt;p&gt;而通過將重心轉向 SLMs，研究者發現模型在執行重複性、專業化的任務時表現卻更加高效，並極大地降低了運算和部署成本。&lt;/p&gt; 
&lt;p&gt;論文作者強調，經濟性是推動 AI 從展示品邁向生產力工具必不可少的因素，而 AI Agent 的規模化應用依賴於更精細的成本與效能的平衡。&lt;/p&gt; 
&lt;p&gt;此外，該論文還提到，從 LLM 到 SLM 的轉變背後，是整個行業對 AI 資源有效利用的戰略性思考。提出這一觀點不僅是為了推動技術路線的演進，更旨在確保整個行業對 AI 發展的經濟現實有更清醒的認識，幫助我們在性能和成本之間找到最佳平衡點。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367198</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367198</guid>
      <pubDate>Mon, 18 Aug 2025 08:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中國 GPU 廠商天數智芯擬赴港 IPO，募資或達 3-4 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據報道，上海天數智芯半導體股份有限公司正考慮在香港進行首次公開募股 (IPO)，計劃募資 3 億至 4 億美元。知情人士透露，目前相關討論仍處於初步階段，IPO 規模及其他細節尚未敲定。天數智芯未回應置評請求。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1840422874854322002%26wfr%3Dspider%26for%3Dpc" target="_blank"&gt;《科創板日報》報道稱&lt;/a&gt;，有接近天數智芯的人士表示，IPO 相關消息應該為真，但具體細節仍未確定。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;天數智芯成立於 2015 年，專注於開發用於運行人工智能服務的 GPU 產品，是力圖與英偉達展開競爭並提升中國芯片能力的數家初創企業之一。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;天數智芯是國內第一家通用 GPU 公司，2020 年率先實現了國產通用 GPU 從「0」到「1」的重大突破，2021 年發佈國內首款通用 GPU 產品天垓 100，實現 GPU 產品量產及商用；2022 年發佈面向 AI 推理的智鎧 100 芯片。2022 年，天數智芯曾披露天垓 100 累計銷售訂單已突破 5 億元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367191</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367191</guid>
      <pubDate>Mon, 18 Aug 2025 08:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>蘋果 Xcode 即將原生集成 Claude</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;繼 WWDC2025 上宣佈 ChatGPT 集成後，蘋果正準備為 Xcode 開發環境引入 Anthropic 的 Claude AI 助手，為開發者提供更多 AI 編程選擇。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據 9to5Mac 深入分析 Xcode26beta7 代碼後發現，蘋果已在新"智能"功能中多次提及對 Anthropic 賬戶的內置支持，特別是 Claude Sonnet4.0 和 5 月 14 日發佈的 Claude Opus4 版本。這表明雖然 ChatGPT 目前是&lt;span&gt;唯一&lt;/span&gt;具有&lt;span&gt;第一&lt;/span&gt;方 Xcode 集成的模型，但 Claude 的原生支持基礎設施已經就位。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-fe0e99cfde75612e2271f514a637c4039a8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;蘋果在 WWDC24 上&lt;span&gt;首次&lt;/span&gt;推出 Swift Assist 概念，旨在打造類似 GitHub Copilot 的 AI 編程助手，但一直未正式發佈。如今這一功能終於在 Xcode26 中亮相，功能範圍大幅擴展：支持蘋果自有 AI 模型，原生 ChatGPT 集成（含每日使用限制），支持第三方 AI 提供商 API 接入，兼容本地運行的 AI 模型。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據彭博社今年 5 月報道，蘋果內部已在測試基於 Claude 的 Xcode 版本，並持續評估公開發布的可能性。當時外界僅知蘋果計劃擴展 Swift Assist 功能，而 ChatGPT 是&lt;span&gt;唯一&lt;/span&gt;確定的合作伙伴。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據 9to5Mac 發現的服務器端配置文件顯示，Claude 不僅可能集成到 Xcode 中，還有望作為 Siri 和系統寫作工具的替代選項，為用戶提供更豐富的 AI 服務體驗。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對於偏好 Claude 編程能力的開發者而言，這一集成將提供更流暢的內置體驗，無需繁瑣的 API 配置即可享受被譽為"目前&lt;span&gt;最佳&lt;/span&gt;編碼助手"的服務。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367187</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367187</guid>
      <pubDate>Mon, 18 Aug 2025 07:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 Edge 143 將移除網絡控制枱工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟 Edge 瀏覽器提供了名為「Network Console Tool」的開發者工具，該工具主要用於網絡請求的捕獲和分析，幫助開發者深入查看瀏覽器與服務器之間的通信，讓開發者可以調試和優化網絡請求。&lt;/p&gt; 
&lt;p&gt;根據微軟工程師發佈的 issue，他們計劃從 Edge 143 版開始刪除這個功能，原因是微軟沒有能力繼續維護這個工具，接下來的主要任務是提供穩定功能並改進與 Chrome 的兼容性。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1066" src="https://static.oschina.net/uploads/space/2025/0819/155038_jRTN_2720166.png" width="1850" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/MicrosoftEdge/DevTools/issues/348&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;作為替代方案，微軟建議開發者使用 Microsoft Visual Studio Code 的 REST 客戶端擴展進行 API 開發和測試，微軟 Edge 瀏覽器本身不再提供直接的替代方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367185</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367185</guid>
      <pubDate>Mon, 18 Aug 2025 07:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>基於 TinyMce 富文本編輯器的客服自研知識庫的技術探索和實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、 背景&lt;/h1&gt; 
&lt;p&gt;客服知識庫是一個集中管理和存儲與客服相關的信息和資源的系統，在自研知識庫上線之前，得物採用的承接工具為第三方知識庫系統。伴隨着業務的發展，知識的維護體量、下游系統的使用面臨的問題愈發明顯，而當前的第三方採購系統，已經較難滿足內部系統間高效協作的訴求，基於以上業務訴求，我們自研了一套客服知識庫。&lt;/p&gt; 
&lt;h1&gt;二、富文本編輯器的選型&lt;/h1&gt; 
&lt;p&gt;以下是經過調研後列出的多款富文本編輯器綜合對比情況：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-95da411b390a1e79e0ee649585a37084e43.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;2.1 編輯器的選擇&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;自研知識庫要求富文本編輯器具備表格的編輯能力，由於&lt;strong&gt;Quill&lt;/strong&gt;不支持表格編輯能力（藉助表格插件可以實現該能力，但經過實際驗證，插件提供的表格編輯能力不夠豐富，使用體驗也較差），被首先被排除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;lt;!-- --&amp;gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;wangEditor&lt;/strong&gt;體驗過程中發現標題和列表（有序、無序）列表兩個功能互斥，體驗不太好，而這兩個功能都是自研知識庫剛需功能，也被排除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;lt;!-- --&amp;gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lexical&lt;/strong&gt; 是 facebook 推出的一款編輯器，雖功能很豐富，但相較於&lt;strong&gt;CKEditor&lt;/strong&gt; 和&lt;strong&gt;TinyMCE&lt;/strong&gt; ，文檔不夠完善，社區活躍性較低，插件不成熟，故優先選擇&lt;strong&gt;CKEditor&lt;/strong&gt; 和&lt;strong&gt;TinyMCE&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;CKEditor&lt;/strong&gt; 和&lt;strong&gt;TinyMCE&lt;/strong&gt; 經過對比，由於當前正在使用的第三方知識庫採用的是&lt;strong&gt;TinyMCE&lt;/strong&gt; 編輯器，選擇 TinyMC 在格式兼容上會更友好，對新老知識庫的遷移上更有利。且 TinyMCE 在&lt;strong&gt;功能豐富度上略佔優勢&lt;/strong&gt; ，故最終選擇&lt;strong&gt;TinyMCE 作為本系統文檔知識庫的編輯器&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;2.2 TinyMce 編輯器模式的選擇&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;經典模式（默認模式）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基於表單，使用表單某字段填充內容，編輯器始終作為表單的一部分。內部&lt;strong&gt;採用了 iframe 沙箱隔離&lt;/strong&gt;，將編輯內容與頁面進行隔離。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 優勢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;樣式隔離好。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 劣勢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由於使用 iframe，性能會差點，尤其對於多實例編輯器。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;內聯模式（沉浸模式）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;將編輯視圖與閲讀視圖合二為一，當其被點擊後，元素才會被編輯器替換。而不是編輯器始終可見，不能作為表單項使用。內容會從它嵌入的頁面繼承 CSS 樣式表。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 優勢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;性能相對較好，頁面的編輯視圖與閲讀視圖合二為一，提供了無縫的體驗，實現了真正的所見即所得。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 劣勢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;樣式容易受到頁面樣式的影響。&lt;/p&gt; 
&lt;h1&gt;三、系統總覽&lt;/h1&gt; 
&lt;h2&gt;3.1 知識創建鏈路&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5898f1dcecea69cb87783dd57f7f99e30a1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.2 知識採編&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;結構化段落&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了對知識文檔做更細顆粒度的解析，客服知識庫採用了&lt;strong&gt;結構化段落的設計思想&lt;/strong&gt; ，每個段落都會有一個唯一標誌 &lt;strong&gt;，且支持對文檔的每個段落單獨設置標籤&lt;/strong&gt;，這樣在後期的知識檢索、分類時，便可以精確定位到知識文檔的具體段落，如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b6e4ad183b36ec82c8fd1558b2e9e9fe28c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.3 應用場景&lt;/h2&gt; 
&lt;p&gt;客服知識庫的主要應用場景如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知識檢索&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基於傳統的 ES 檢索能力，用於知識庫的檢索，檢索要使用的知識，且可以直接在工作台打開對應的知識並瀏覽，並可以定位、滾動到具體的知識段落。同時還會&lt;strong&gt;高亮顯示&lt;/strong&gt; 知識文檔中匹配到的&lt;strong&gt;搜索關鍵字&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智能問答&lt;/strong&gt;（基於大模型能力和知識庫底層數據的訓練）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ RAG 出話&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;輔助客服了解用戶的真實意圖，可用於客服作業時的參考。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原理闡述：&lt;/strong&gt; RAG 是一種結合了檢索和生成技術的人工智能系統。它是大型語言模型的一種，但特別強調檢索和生成的結合。RAG 的最主要的工作流程包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;檢索階段：系統會根據用戶的查詢，從&lt;strong&gt;客服知識庫中檢索出相關信息。這些信息可能包括知識庫內容、訂單信息和商品信息等&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;生成階段：RAG 使用檢索到的信息來增強其生成過程。這意味着，生成模型在生成文本時，會考慮到檢索到的相關信息，以生成更準確、更相關的回答。你可以直接將搜索到的內容返回給用戶也可以通過 LLM 模型結合後生成給用戶。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;※ 答案推薦&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以根據用戶搜索內容、上下文場景（如訂單信息、商品信息）輔助客服更高效的獲取答案。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;流程示意：&lt;/strong&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-fcb0d05ee25406dcdf617c673affa27ab55.png" alt="" referrerpolicy="no-referrer"&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-289d81aee36a4f8ae37f0362bdc5958f98e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 聯網搜索&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當 RAG 出話由於拒識沒有結果時，便嘗試進行聯網搜索給出結果，可作為 RAG 能力失效後的補充能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原理闡述：&lt;/strong&gt; 底層使用了第三方提供的&lt;strong&gt;聯網問答 Agent 服務&lt;/strong&gt; 。在進行聯網搜索之前，會對用戶的查詢信息進行&lt;strong&gt;風控校驗&lt;/strong&gt; ，風控校驗通過後，再進行 &lt;strong&gt;【指定意圖清單】過濾&lt;/strong&gt;，僅對符合意圖的查詢才可以進行聯網搜索。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-74a22f9ec745dc39961d0ca9ecec27e0e37.png" alt="" referrerpolicy="no-referrer"&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-f13e784faad46f5e855ec8518dcc35be047.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;四、問題和解決方案&lt;/h1&gt; 
&lt;h2&gt;4.1 解決圖片遷移問題&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在新老知識遷移的過程中，由於老知識庫中的圖片鏈接的域名是老知識庫的域名，必須要有老知識庫的登錄台信息，才能在新知識庫中訪問並渲染。為瞭解決這個問題，我們對用戶粘貼的動作進行了監聽，並對複製內容的圖片鏈接進行了替換。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;時序圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2d03bfb759a3da15c3f8bdd111ad97c8529.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心邏輯&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/**
 * 替換編輯器中的圖片 URL
 * @param content
 * @param editor 編輯器實例
 * @returns 替換後的內容
 */
export const replaceImgUrlOfEditor = (content, editor) =&amp;gt; {
  // 提取出老知識中的圖片訪問鏈接
  const oldImgUrls = extractImgSrc(content);
  // 調用接口獲取替換後的圖片訪問鏈接
  const newImageUrls = await service.getNewImageUrl(oldImgUrls);
  // 將老知識庫的圖片鏈接替換成新的可訪問的鏈接
  newContent = replaceImgSrc(newContent, replacedUrls.imgUrls);
  // 使用新的數據更新編輯器視圖
  editor.updateView(newContent);
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4.2 解決加載大量圖片帶來的頁面卡頓問題&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;知識庫內含有大量的圖片，當我們打開一篇知識時，系統往往因為在短時間內加載、渲染大量的圖片而陷入卡頓當中，無法對頁面進行其他操作。這個問題在老知識庫中尤為嚴重，也是研發新知識庫過程中我們需要重點解決的問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解決方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們對圖片進行了懶加載處理：當打開一篇知識時，只加載和渲染可見視圖以內的圖片，剩餘的圖片只有滾動到可見視圖內才開始加載、渲染。&lt;/p&gt; 
&lt;p&gt;由於我們要渲染的內容的原始數據是一段 html 字符串，一篇知識文檔的&lt;strong&gt;最小可渲染單元是段落&lt;/strong&gt;（結構化段落），而一個段落的內容大小事先是不知道的，因此傳統的滾動加載方式在這裏並不適用：比如當滾動到需要加載下一段落的位置時，如果該段落的內容特別大且包含較多圖片時，依然會存在卡頓的現象。&lt;/p&gt; 
&lt;p&gt;我們採用正則匹配的方式，識別出知識文檔的 html 中所有的 &lt;img src="" alt="" referrerpolicy="no-referrer"&gt; 標籤（將文檔的 html 視作一段字符串），並給 &lt;img src="" alt="" referrerpolicy="no-referrer"&gt; 標籤插入 loading="lazy" 的屬性，具備該屬性的圖片在到達可視視圖內的時候才會加載圖片資源並渲染，從而實現懶加載的效果，大大節省了知識文檔初次渲染的性能開銷。並且該過程處理的是渲染知識文檔前的 html 字符串，而非真實的 dom 操作，所以不會帶來重繪、重排等性能問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知識文檔渲染的完整鏈路&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b5d408d9e6ef53c6f040cdbce9975f13dae.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;4.3 模板縮略圖&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在知識模板列表頁或者在創建新知識選擇模板時，需要展示模板內容的縮略圖，由於每個模板內容都不一樣，同時縮略圖中需要可以看到該模板靠前的內容，以便用戶除了依靠模板標題之外還可以依靠一部分的模板內容選擇合適的模板。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解決方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在保存知識模板前，通過截屏的方式保存一個模板的截圖，上傳截圖到 cdn 並保存 cdn 鏈接，再對截圖進行一定的縮放調整，即可作為模板的縮略圖。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;時序圖&lt;/strong&gt; &lt;img src="https://oscimg.oschina.net/oscnet/up-7fbdb47a4677be9b3fc62ea8bc99c9e47c2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;實際效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;模板列表中縮略圖展示效果：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-62f564d295f0d583928a08266f7ae3a890a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新建知識時縮略圖展示效果：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-60dee5e8fffbeaa691d47880a0e6d636355.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;4.4 全局查找/替換&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;知識庫採用了結構化段落的設計思想，技術實現上，每個段落都是一個獨立的編輯器實例。這樣實現帶來一個弊端：使用編輯器的搜索和替換功能時，查找範圍僅限於當前聚焦的編輯器，無法同時對所有編輯器進行查找和替換，增加了業務方的編輯費力度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解決方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;調研、擴展編輯器的&lt;strong&gt;查找/替換插件的源碼，調度和聯動多編輯器的查找/替換 API&lt;/strong&gt;從而實現全局範圍內的查找/替換。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 插件源碼剖析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過對插件源碼的分析，我們發現插件的查找/替換功能是基於 4 個基本的 API 實現的： find 、 replace 、 next 、 prev 、 done 。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 設計思路&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過在多個編輯器中加入一個調度器來控制編輯器之間的&lt;strong&gt;接力&lt;/strong&gt; 從而實現&lt;strong&gt;全局的查找/替換&lt;/strong&gt; 。同時&lt;strong&gt;擴展插件的 API&lt;/strong&gt; ，&lt;strong&gt;輔助調度器在多編輯器之間進行調度&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 插件源碼 API 擴展&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;hasMatched：&lt;/strong&gt; 判斷當前編輯器是否匹配到關鍵字。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;hasReachTop&lt;/strong&gt;：判斷當前編輯器是否已到達所查找關鍵字的最前一個。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;hasReachBottom&lt;/strong&gt;：判斷當前編輯器是否已到達所查找關鍵字的最後一個。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;current：&lt;/strong&gt; 滾動到編輯器當前匹配到的關鍵字的位置。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;clearCurrentSelection：&lt;/strong&gt; 對編輯器當前匹配到的關鍵字取消高亮效果。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4aba22b768accecbba6b30d1f9d21a8a4fb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;UI 替換&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;屏蔽插件自帶的查找/替換的彈窗，實現一個支持全局操作的查找/替換的彈窗：使用了 react-rnd 組件庫實現可拖拽彈窗，如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2a1afa88b3bf2be0bf7400d1a95490ba73d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「查找」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 期望效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當用戶輸入關鍵字並點擊查找時，需要在文檔中（所有編輯器中）標記出（加上特定的背景色）所有匹配到該關鍵字的文本，並高亮顯示出第一個匹配文本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 流程圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-64776a2ea093b841c58591a39ed8b1aed24.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;「下一個」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 期望效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當用戶點擊「下一個」時，需要高亮顯示下一個匹配結果並滾動到該匹配結果的位置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 流程圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-de6d015d117227125d947877b18856d5b6a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;五、總結&lt;/h1&gt; 
&lt;p&gt;在新版客服知識庫的研發和落地過程中，我們基於&lt;strong&gt;TinyMce 富文本編輯器&lt;/strong&gt; 的基礎上，進行了功能擴展和定製。這期間既有參考過同類產品（飛書文檔、語雀）的方案，也有根據實際應用場景進行了創新。截止目前已完成&lt;strong&gt;1000+老知識庫的順利遷移&lt;/strong&gt;，系統穩定運行。&lt;/p&gt; 
&lt;p&gt;自研過程中我們解決了老版知識庫系統的卡頓和&lt;strong&gt;無法滿足定製化需求的問題&lt;/strong&gt; 。並在這些基本需求得到滿足的情況下，通過優化交互方式和知識文檔的加載、渲染性能等方式&lt;strong&gt;進一步提升了使用體驗&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;後續我們會結合用戶的反饋和實際使用需求進一步優化和擴展客服知識庫的功能，也歡迎有同樣應用場景的同學一起交流想法和意見。&lt;/p&gt; 
&lt;p&gt;&amp;lt;br /&amp;gt;&lt;/p&gt; 
&lt;h2&gt;往期回顧&lt;/h2&gt; 
&lt;p&gt;&lt;a href=""&gt;1.AI 質量專項報告自動分析生成｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;2.Rust 性能提升"最後一公里"：詳解 Profiling 瓶頸定位與優化｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;3.Valkey 單點性能比肩 Redis 集羣了？Valkey8.0 新特性分析｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;4.Java SPI 機制初探｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=""&gt;5.得物向量數據庫落地實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;lt;br /&amp;gt;&lt;/p&gt; 
&lt;p&gt;&amp;lt;br /&amp;gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文 / 煜宸&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18688668</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18688668</guid>
      <pubDate>Mon, 18 Aug 2025 07:49:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
