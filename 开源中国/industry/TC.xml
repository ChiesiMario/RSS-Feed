<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Tue, 12 Aug 2025 22:14:30 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Fedora 43 獲準支持 Hare 編程語言，默認啓用硬鏈接</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Fedora 工程與指導委員會 (FESCo) 本週批准了即將發佈的 Fedora Linux 43 版本的多項新增功能。其中包括獲準發佈 Hare 軟件包，Hare 是一種新的系統編程語言，旨在簡化、穩定和健壯。&lt;/p&gt; 
&lt;p&gt;Hare 本身仍在開發中，但 FESCo 現已批准將 Hare 工具鏈打包併發布到 Fedora 43 的倉庫中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/191447_Wl7H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;FESCo 還批准在 Fedora 43 中發佈即將發佈的 PHP 8.4 版本，這並不令人意外。FESCo 還批准棄用 YASM，轉而使用 NASM。YASM 彙編器目前無人維護，而 NASM 的情況也好多了。&lt;/p&gt; 
&lt;p&gt;作為英特爾 oneAPI 線程構建版本 (TBB) 的最新更新，Threaded Building Blocks 2022.2 也已獲批准發佈。FESCo 本週還批准了默認對 Fedora RPM 軟件包中，相同的 /usr 文件進行硬鏈接的提案。&lt;/p&gt; 
&lt;p&gt;有關 Fedora 43 版本中這些新批准更改的更多詳細信息，&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.fedoraproject.org%2Farchives%2Flist%2Fdevel%40lists.fedoraproject.org%2Fthread%2FMVPWNTBSZUUJINZX6PZQGTYE2BA7NFKL%2F" target="_blank"&gt;請通過此 FESCo 郵件列表帖子獲取&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;，該版本將於今年晚些時候發佈。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365798</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365798</guid>
      <pubDate>Mon, 11 Aug 2025 11:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>One Million Screenshots：收集了超過 100 萬張網站截圖的網站</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;「One Million Screenshots」 是一個專門收集網站截圖的網站，聲稱截圖了超過 100 萬個熱門 Web 主頁。此外還提供了搜索相似網站的功能，以及查看網站截圖的歷史變化。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0812/185333_PgpB_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;https://onemillionscreenshots.com/&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;沒想到 OSCHINA 也榮幸出鏡了：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fonemillionscreenshots.com%2Foschina.net%2Fscreenshot" target="_blank"&gt;https://onemillionscreenshots.com/oschina.net/screenshot&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="6306" src="https://static.oschina.net/uploads/space/2025/0812/185758_Ydik_2720166.png" width="1604" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是關於該網站的常見問題：&lt;/p&gt; 
&lt;p&gt;&lt;img height="2386" src="https://static.oschina.net/uploads/space/2025/0812/185221_4Hkz_2720166.png" width="1514" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365794</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365794</guid>
      <pubDate>Mon, 11 Aug 2025 11:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>人工智能正在降低知識的價值，大學應該重新考慮所教授的內容？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;生成式人工智能，尤其是大型語言模型（LLM）的興起，正以前所未有的速度改變知識獲取的格局。奧克蘭大學商學院教授帕特里克·多德在《對話》(The Conversation) 上撰文指出，隨着 AI 以低成本、高效率的方式提供知識，大學作為傳統知識來源的價值正在受到挑戰。他認為，大學必須重新審視其核心功能，以適應這個由 AI 驅動的新時代。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多德教授分析，大學長期以來奉行「知識稀缺」的原則，通過提供獨家課程和學位證書來證明學生獲取知識的能力。然而，AI 技術的進步已大大降低了獲取專業知識的門檻，LLM 不僅能檢索事實，還能進行解釋、翻譯和總結，使得曾經「稀缺」的知識價值大打折扣。這種變化已經在勞動力市場顯現，自 ChatGPT 問世以來，英國入門級職位空缺減少了約三分之一，美國部分州甚至取消了公共部門職位的學位要求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;然而，多德強調，並非所有知識都同等貶值。雖然基礎知識的價值下降，但&lt;strong&gt;隱性知識&lt;/strong&gt;，如團隊協作、倫理判斷、創造力以及解決複雜問題的能力，仍是 AI 無法取代的稀缺資源。他指出，未來教育的重點應從傳授信息轉向培養這些關鍵的人類技能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;為應對這一挑戰，多德教授為大學提出了四項轉型建議：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;評估轉型&lt;/strong&gt;：將課堂評估重點從單純的知識記憶轉向&lt;strong&gt;判斷和綜合能力&lt;/strong&gt;的考察。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;體驗式學習&lt;/strong&gt;：投入資源開發導師指導項目、模擬現實場景，並利用 AI 作為工具進行倫理決策研究。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;技能微證書&lt;/strong&gt;：創建針對協作、自主學習和倫理判斷等關鍵能力的微證書。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深化產學研合作&lt;/strong&gt;：大學提供專業知識，企業提供真實案例，學生則專注於驗證和完善想法，共同培養適應未來市場的複合型人才。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多德總結道，如果大學想要在未來立於不敗之地，就必須從一個單純的&lt;strong&gt;信息來源&lt;/strong&gt;轉變為一個&lt;strong&gt;判斷力中心&lt;/strong&gt;，教會學生如何與 AI 協同思考，而非與之競爭。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365792</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365792</guid>
      <pubDate>Mon, 11 Aug 2025 10:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源編程字體「Hack」創始人 Christopher Simpkins 去世</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Christopher Eric Simpkins 是知名開源編程字體「Hack」創始人，他於 2025 年 6 月 20 日在新罕布什爾州漢諾威突然&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftypo.social%2F%40Hilary%2F114845913381245488" target="_blank"&gt;去世&lt;/a&gt;，享年 51 歲。&lt;/p&gt; 
&lt;p&gt;&lt;img height="904" src="https://static.oschina.net/uploads/space/2025/0812/175131_lS6n_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Christopher Simpkins 訃告頁面&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.legacy.com%2Fus%2Fobituaries%2Fvnews%2Fname%2Fchristopher-simpkins-obituary%3Fid%3D58856786" target="_blank"&gt;顯示&lt;/a&gt;，他&lt;span&gt;在佐治亞理工學院取得計算機博士學位後先在美軍服役，退役又完成醫學訓練成為一名器官移植外科醫生&lt;/span&gt;。他醫術精湛、待人溫和，被譽為「溫柔的巨人」，拯救了許多生命並屢獲教學獎。&lt;/p&gt; 
&lt;p&gt;後來他轉向科技領域，&lt;span&gt;加入 Google Fonts 團隊任&lt;/span&gt;高級用戶體驗項目經理&lt;span&gt;，&lt;/span&gt;專注字體開發&lt;span&gt;，發起 Codeface 項目為開發者整理並推薦高可讀性的編程字體，持續推動開源字體生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/175331_L0CQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;2015 年，&lt;/span&gt;Christopher Simpkins 創造了&lt;span&gt;開源 Hack 字體，這款基於 DejaVu Sans Mono 重新調校的等寬字體迅速成為程序員最喜愛的編輯器字體之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;谷歌近期發佈的開源字體&lt;/span&gt;&lt;a href="https://www.oschina.net/news/363609/googlesans-code" target="_blank"&gt;&amp;nbsp;Google Sans Code &lt;/a&gt;正是由&amp;nbsp;Christopher Simpkins 負責主導。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1710" src="https://static.oschina.net/uploads/space/2025/0812/180516_SXlX_2720166.png" width="1686" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365788</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365788</guid>
      <pubDate>Mon, 11 Aug 2025 10:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達推出 Cosmos 與 Nemotron 模型，推動物理 AI 與智能體發展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.nvidia.cn%2Fblog%2Fnvidia-opens-portals-to-world-of-robotics-with-new-omniverse-libraries-cosmos-physical-ai-models-and-ai-computing-infrastructure%2F" target="_blank"&gt;據英偉達官方消息&lt;/a&gt;，英偉達在技術領域再推新進展。其推出的 NVIDIA Cosmos 平台，整合前沿生成式世界基礎模型（WFM）、先進分詞器、護欄以及高效數據處理和管理工作流，旨在加速物理 AI 開發。該平台的世界基礎模型經 2000 萬小時真實世界數據訓練，能預測和生成虛擬環境未來狀態，助力開發者構建新一代機器人和自動駕駛汽車。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/174129_nIuV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，英偉達宣佈推出 Nemotron 模型系列。Llama Nemotron 基於熱門開源模型 Llama 構建，經剪枝和訓練，在指令遵循等方面表現出色，能為 AI 智能體開發提供優化基礎模組。Cosmos Nemotron 視覺語言模型（VLM）則可助力開發者構建智能體，使其能分析圖像和視頻並做出響應。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9ddc7846bd0a958a9b0a9772dcf6c6a4e47.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，已有眾多物理 AI 領域的領先者，如機器人公司，以及自動駕駛汽車開發商等開始與 Cosmos 協作，加速模型開發進程。開發者可在 NVIDIA API 目錄預覽相關模型，並從 NGC 目錄和 Hugging Face 下載模型系列與微調框架。&lt;/p&gt; 
&lt;p&gt;https://docs.nvidia.com/cosmos/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365780</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365780</guid>
      <pubDate>Mon, 11 Aug 2025 09:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Altman：計劃在未來 5 個月內將算力集羣擴容一倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;OpenAI CEO 薩姆・奧爾特曼（SamAltman）在社交平台發文上表示，鑑於 GPT-5 帶來的需求激增，該公司計劃在未來幾個月的算力優先分配如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;首先確保當前付費版 ChatGPT 用戶的總可用量比 GPT-5 推出前更多。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;其次優先滿足 API 需求，直至達到當前分配的產能和已對客戶做出的承諾。（粗略估計，以現有產能可在當前基礎上再支持約 30% 的新 API 增長。）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;提升 ChatGPT 免費版的服務質量。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;再優先滿足新的 API 需求。計劃在未來 5 個月內將算力集羣擴容一倍，因此這一情況有望改善。&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="450" src="https://oscimg.oschina.net/oscnet/up-546ae50cc300f2af8894d1b266b905551e4.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365777</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365777</guid>
      <pubDate>Mon, 11 Aug 2025 09:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 發佈面向 GPT-5 的 Prompt 指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 官方寫的 GPT-5 prompt 指南來了，看看官方是怎麼讓 GPT-5 表現更好的。該指南融匯貫通後，還可用於其他 AI 大模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/172857_F753_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1、 明確角色和目標 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;開頭就讓 AI 模型知道它是誰、要做什麼，比如：&lt;/p&gt; 
&lt;p&gt;你是資深前端工程師，請幫我在現有 React 項目裏實現...&lt;/p&gt; 
&lt;p&gt;2、 設定工作方式 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;用分步指令，讓模型按既定節奏走，而非一次性輸出：&lt;/p&gt; 
&lt;p&gt;- 先分析需求和不確定點&lt;br&gt; - 再給執行計劃 &amp;nbsp; &amp;nbsp;&lt;br&gt; - 按計劃分步完成&lt;br&gt; - 每步結束時總結進度&lt;/p&gt; 
&lt;p&gt;3、 控制主動性 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;想要它多動腦，就加：在不確定時自行推斷並執行，完成後再告知用戶。 &amp;nbsp;&lt;br&gt; 想讓它少跑偏，就加：僅按已知信息執行，不額外探索。&lt;/p&gt; 
&lt;p&gt;4、 給出完成標準 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;告訴模型何時算任務完成，比如： &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;當所有代碼改動已在/app/theme 目錄生效，並通過現有測試時，結束任務。&lt;/p&gt; 
&lt;p&gt;5、 嵌入風格與規範 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在提示裏放工程或寫作規範，讓它自動匹配你的需求： &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;變量用駝峯命名，CSS 類名用 BEM 規範，註釋保持英文簡短描述。&lt;/p&gt; 
&lt;p&gt;6、 善用示例 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;給它 1-2 個高質量示例，讓它照着學，比空口説效果好得多。&lt;/p&gt; 
&lt;p&gt;7、 善用「工具前言」&lt;/p&gt; 
&lt;p&gt;工具前言可以寫：先複述目標，再列計劃，執行時簡短説明當前步驟，最後單獨總結成果。&lt;/p&gt; 
&lt;p&gt;8、 清除歧義 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;檢查提示裏是否有前後矛盾或模糊指令，否則 GPT-5 會花大量精力試圖自圓其説，反而降低效率。&lt;/p&gt; 
&lt;p&gt;記住一個公式：角色+目標+步驟+完成標準+風格+示例，如此 GPT-5 才會既有創造力又不跑偏。&lt;/p&gt; 
&lt;p&gt;這本指南還涵蓋了 API 參數具體怎麼調，感興趣的開發者可以看看。&lt;/p&gt; 
&lt;p&gt;地址：cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365773/openai-gpt-5-prompting-guide</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365773/openai-gpt-5-prompting-guide</guid>
      <pubDate>Mon, 11 Aug 2025 09:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動推出視頻字幕無痕擦除方案，基於 DiT 大模型打造</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;字節跳動技術團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKsl_lF8KNwM0vRtsjzWaBA" target="_blank"&gt;宣佈&lt;/a&gt;推出一項創新技術，基於 DiT 大模型與字體級分割的視頻字幕無痕擦除方案，旨在助力短劇等視頻內容的全球化傳播。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在全球化內容製作中，原始視頻的中文字幕對於海外觀眾而言不僅是無效信息，還嚴重影響觀看體驗。傳統的字幕添加或馬賽克、GAN（生成對抗網絡）等字幕擦除方案，往往導致畫面雜亂、模糊或幀間閃爍，無法徹底解決這一問題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;火山引擎視頻點播推出的這一方案，通過兩大核心技術突破和強大的工程能力，重新定義了字幕擦除標準，實現了全片真實自然的「無痕擦除」，並支持多字幕框、指定時間段的精準擦除。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e6a7ee75485165b360e216e57f4f3f2e85f.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該方案的核心在於兩個技術突破：一是 DiT 視頻字幕擦除模型，二是字體級分割模型。DiT 模型通過強魯棒性預訓練基底、擺脫輔助先驗依賴、兩階段訓練策略提升魯棒性與修復精細度，實現了像素級無痕修復。字體級分割模型則通過精準定位目標區域，實現了從「粗放擦除」到「像素級修復」的轉變，有效避免了傳統塊填充導致的背景模糊或紋理重複問題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="143" src="https://oscimg.oschina.net/oscnet/up-dc217440e603a0e87eec97675dbaaf606fc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;火山引擎多媒體實驗室聯合工程團隊構建了兼顧精度與效率的技術體系，經過超萬集視頻數據集驗證，擦除任務成功率達到 100%。創新的視頻分鏡技術結合服務器集羣分佈式計算，顯著提升了視頻處理效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，該方案還支持多語言內容流轉，突破了中英文限制，支持多個小語種字幕擦除，為全球內容流轉提供了雙向通道。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365771</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365771</guid>
      <pubDate>Mon, 11 Aug 2025 09:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌向發現 Chrome 高危漏洞的安全研究員獎勵 25 萬美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;谷歌近日依據漏洞獎勵計劃（VRP）向一名安全研究員&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.chromium.org%2Fissues%2F412578726" target="_blank"&gt;發放 25 萬美元（約合 179.8 萬元人民幣）獎金&lt;/a&gt;，獎勵其發現 Chrome 瀏覽器高危漏洞。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/170559_YQ7o_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;該研究員於 4 月 23 日報告了一個「沙盒逃逸」漏洞，編號為 CVE-2025-4609，存在於 Chrome 內核的 IPCZ 通信系統中。攻擊者可通過誘導用戶訪問惡意網站，利用該漏洞突破瀏覽器沙箱限制，實現遠程代碼執行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;儘管研究員最初將其標記為「中等危害」，但谷歌評估其嚴重性為 S0/S1 級，並列為 P1 優先級修復。 谷歌已於 5 月發佈的 Chrome 更新中修復該漏洞，並在 8 月 12 日公開披露細節。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;根據谷歌「漏洞獵人（&lt;/span&gt;Google Bug Hunters&lt;span&gt;）」計劃，提交包含 RCE 演示的高質量非沙盒進程逃逸或內存損壞漏洞報告，可獲 2.5 萬至 25 萬美元獎勵，此次為頂格獎勵。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365764</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365764</guid>
      <pubDate>Mon, 11 Aug 2025 09:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Actual - 個人理財工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Actual 是一款本地優先的個人理財工具。它 100% 免費開源，使用 NodeJS 編寫，並具備同步功能，方便用戶在不同設備之間輕鬆遷移更改。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="271" src="https://static.oschina.net/uploads/space/2025/0806/154746_TajJ_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/actual</link>
      <guid isPermaLink="false">https://www.oschina.net/p/actual</guid>
      <pubDate>Mon, 11 Aug 2025 08:53:00 GMT</pubDate>
    </item>
    <item>
      <title>360 智腦推出 Light-IF 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;360 智腦團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FnwyQDZxYGFFA5pTmkxn3JQ" target="_blank"&gt;宣佈&lt;/a&gt;推出全新的 Light-IF 系列模型，這一創新框架旨在顯著提升大型語言模型（LLM）在複雜指令遵循方面的能力。隨着人工智能技術的不斷進步，儘管 LLM 在數學、編程等領域已經展現出了卓越的推理能力，但在遵循複雜指令方面仍存在不足。為瞭解決這一問題，360 智腦團隊提出了以預覽-自檢式推理和信息熵控制為核心的 Light-IF 框架。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Light-IF 框架通過五個關鍵環節來提升模型性能:難度感知指令生成、Zero-RL 強化學習、推理模式提取與過濾、熵保持監督冷啓動、熵自適應正則強化學習。這一框架的提出，旨在破解當前推理模型中存在的「懶惰推理」現象，即模型在思考階段僅複述指令而不主動檢查約束是否被滿足，導致指令執行不準確的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="316" src="https://oscimg.oschina.net/oscnet/up-30ae24d430fc7fd7a393ecaf7c48fbadefc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在實驗中，Light-IF 系列模型在 SuperCLUE、IFEval、CFBench 及 IFBench 四個中文和跨語言指令遵循基準上均取得了顯著提升。特別是 32B 版本的 Light-IF-32B，其在 SuperClue 得分達到了 0.575，比下一個最佳模型高出 13.9 個百分點。此外，參數規模僅為 1.7B 的 Light-IF-1.7B 在 SuperClue 和 IFEval 上的表現甚至超過了 Qwen3-235B-A22B 等體量更大的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;360 智腦團隊表示，Light-IF 系列模型的推出，不僅為開源社區提供了一套可復現的完整路線和配套的開源代碼，而且全系模型將陸續開放，供社區使用、對比與復現。同時，訓練中使用的冷啓動數據集也將同步開放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，360 與 SuperCLUE 聯合推出的中文精確指令遵循測評基準 SuperCLUE-CPIFOpen 也將在 Github 上開放，便於研究者評測模型的中文精確指令遵循能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365748</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365748</guid>
      <pubDate>Mon, 11 Aug 2025 08:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 發佈全球首個可交易 Agent Remix Marketplace</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;MiniMax 稀宇科技宣佈推出全球首個 Agent Remix Marketplace，並啓動了一項獎金高達 15 萬美金的全球挑戰賽。這一創新平台旨在將個人的想法轉化為商業價值，讓每個人都能成為「個體 GDP 創造者」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agent Remix Marketplace 是一個允許用戶一鍵提效的工具，用戶可以通過點擊「Remix」對已發佈的成熟作品進行再創作，無需從零開始，從而將效率提升 10 倍。此外，用戶還可以通過發佈自己的 Agent 作品至 Gallery 並允許他人 Remix，每次作品被 Remix 都能獲得 100 積分的收益。這不僅是一個創作和分享的平台，也是一個漲粉和建立個人品牌的利器。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-d064cf16f7166c2be8c20d9ed0ee1bc940e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;MiniMax 強調，這一平台是「Agent 全民經濟」的顛覆性突破，具有四大獨家優勢。用戶可以輕鬆地 Remix 各種模板，如香氛蠟燭電商模板，快速開啓自己的電商創業。此外，用戶還可以定製任何行業或主題的 Daily Newsletter，甚至將 Netflix 和 Bilibili、LinkedIn 和 Tinder 等不同平台的功能進行 Remix，創造出全新的用戶體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技術層面，MiniMax 在研發過程中注重 Agent 的可靠性，包括上下文壓縮總結、API 信息脫敏引擎以及多 Agent 任務路由等技術，以確保用戶數據的安全和隱私。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;全球挑戰賽面向所有人開放，鼓勵參與者用自己的想法挑戰 15 萬美金的獎池。挑戰賽分為原創和 Remix 雙賽道，無論是原創作品還是基於已發佈作品的二創，都有機會獲獎。參與者無需代碼能力，即可參與這一全球智能普惠的活動。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;體驗地址：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fminimax-agent-hackathon.space.minimax.io%2F" target="_blank"&gt;https://minimax-agent-hackathon.space.minimax.io/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365744</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365744</guid>
      <pubDate>Mon, 11 Aug 2025 08:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華為發佈 AI 推理創新技術 UCM：可實現高吞吐、低時延推理體驗，計劃 9 月開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1840229710674780713%26wfr%3Dspider%26for%3Dpc" target="_blank"&gt;根據報道&lt;/a&gt;，華為正式發佈了 AI 推理創新技術 UCM（推理記憶數據管理器）。&lt;/p&gt; 
&lt;p&gt;華為推出的 UCM（推理記憶數據管理器）是一款以 KV Cache 為中心的推理加速套件，融合多類型緩存加速算法工具，通過分級管理推理過程中產生的 KV Cache 記憶數據，擴大推理上下文窗口，實現高吞吐、低時延的推理體驗，，降低每 Token 推理成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0812/160552_0ocB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，華為計劃於 2025 年 9 月正式開源 UCM，屆時將在魔擎社區首發，後續逐步貢獻給業界主流推理引擎社區，並共享給業內所有 Share Everything (共享架構) 存儲廠商和生態夥伴。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365742</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365742</guid>
      <pubDate>Mon, 11 Aug 2025 08:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claude 新增聊天記錄記憶功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 為其 Claude 聊天機器人推出備受期待的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fclaudeai%2Fstatus%2F1954982275453686216" target="_blank"&gt;「記憶」功能&lt;/a&gt;，用戶可讓機器人檢索並參考過往對話內容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/155847_bdCE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該功能支持網頁、桌面及移動端，能區分不同項目和工作區。用戶只需在 「個人資料」 的 「設置」 中開啓 「搜索和查看聊天記錄」，即可使用。&lt;/p&gt; 
&lt;p&gt;目前，Claude 的 Max、Team 和 Enterprise 訂閲層級已率先上線，其他套餐將在近期開放。與 ChatGPT 的持續記憶不同，Claude 的記憶功能為被動觸發模式，僅在用戶明確要求時才檢索過往對話，且不會構建用戶畫像。&lt;/p&gt; 
&lt;p&gt;作為 AI 領域的頭部企業，Anthropic 與 OpenAI 競爭激烈，雙方在語音模式、上下文窗口、訂閲服務等方面不斷角力。此次記憶功能的推出，旨在提升用戶黏性和使用時長。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365741</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365741</guid>
      <pubDate>Mon, 11 Aug 2025 07:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟為 Excel 加入 AI 公式講解，內聯解釋直達單元格</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;微軟&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcommunity.microsoft.com%2Fblog%2Fexcelblog%2Fexplain-formulas-with-copilot%25E2%2580%2594now-on-the-grid%2F4424028" target="_blank"&gt;宣佈&lt;/a&gt;，其電子表格工具 Excel 迎來一項重要更新：由 Copilot 驅動的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;「解釋此公式」（Explain Formula）&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;功能正式上線，旨在幫助用戶快速理解複雜公式，顯著提升數據處理效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該功能的&lt;span&gt;最大&lt;/span&gt;亮點在於操作簡便。用戶無需單獨打開聊天面板，只需點擊包含有效公式的單元格，並在旁邊的 Copilot 圖標中選擇「解釋此公式」，即可在單元格內直接獲得內聯解釋。這些解釋基於當前工作表的上下文生成，比傳統網絡搜索更精準、更貼合實際工作場景。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="225" src="https://oscimg.oschina.net/oscnet/up-68c25bd98edf5ade9b15bb52dea74ff751f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微軟表示，Copilot 能夠分解並逐步講解各種複雜程度的公式，幫助用戶快速掌握其邏輯。默認情況下，解釋會以內聯形式顯示;若 Copilot 聊天面板已開啓，內容將優先在面板中呈現。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，該功能正分階段向 Windows 版和網頁版 Excel 用戶推送。微軟鼓勵用戶在每次使用後通過點贊或點踩反饋，協助優化 AI 解釋效果。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365740</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365740</guid>
      <pubDate>Mon, 11 Aug 2025 07:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「字節跳動靜態資源公共庫」因黑產原因下線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;從 2025 年 6 月份開始，就有諸多站長髮現字節跳動旗下的靜態資源公共庫存在調用問題，包括部分資源連接超時或者直接 HTTP 404，這導致網站無法正常加載內容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;當時測試發現諸如 jQuery 等還可以調用，其他部分資源出現錯誤無法調用，因此並不清楚字節跳動哪裏出問題才會導致部分資源有效、部分資源無效。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/154152_ycjH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://cdn.bytedance.com/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;現在字節跳動已經明確靜態資源公共庫下線，當前所有靜態資源已經全部處於 404 狀態，字節跳動稱是「黑產原因」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365736</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365736</guid>
      <pubDate>Mon, 11 Aug 2025 07:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 亮相首屆世界 RISC-V 日，分享最新 RISC-V 進展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 8 日，由 RISC-V 國際基金會重磅推出的首屆世界 RISC-V 日 (World RISC-V Days) 在北京開源芯片研究院舉行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//3f4075ef6e79ddf2ab5c098c63d555b7.jpg" width="840" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;deepin 社區技術委員會成員、苦芽科技工程師李程&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;參加了此活動，並於會議上帶大家系統回顧了 deepin-ports SIG 的發展歷程，並重點分享了 deepin-ports SIG 在 RISC-V 方向上的最新進展，包括但不限於 deepin RISC-V 生態適配、社區協作模式優化等方面。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//10b8829d40f7888c675d6790b227fb75.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&lt;span&gt;&lt;span&gt;李程，deepin 社區技術委員會成員、苦芽科技工程師&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;deepin 對 RISC-V 架構的支持並非一日之功。自 2022 年 2 月起，deepin 就建立了對應 SIG，開始了 RISC-V 架構的適配工作，現已成功支持了大量主流的 RISC-V 硬件和開發板。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在軟件方面，deepin 也完成了對 RISC-V 開源軟件生態的適配，提供了超過 27,000 個軟件包，併為 RISC-V 開發板提供了內核、GPU、VPU、NPU 等驅動解決方案，確保了這些關鍵組件能夠長期、及時、良好地維護。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//92d10ca4ef881324c89df1a23d1a392e.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;作為中國桌面操作系統的核心力量，deepin 積極響應國家戰略，深度參與「甲辰計劃」，全力投入 RISC-V 開源新生態建設。迄今，deepin 操作系統已成功適配了幾乎所有可公開獲取的桌面級 RISC-V 設備，並提供了關鍵的 GPU、NPU、VPU 等硬件加速支持。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 23&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 穩定版及 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 25 預覽版&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;均已為 RISC-V 平台提供官方鏡像並持續更新。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;通過在硬件適配、軟件生態構建、社區協作及戰略規劃上的不懈努力，deepin 已成為 RISC-V 生態的重要貢獻者，並有力推動着 RISC-V 桌面操作系統的普及與應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//7215a0a6d6d54c51ac5e45faa8fd4f4a.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;李程還介紹到，deepin 作為「甲辰計劃」的重要參與社區之一，為給更多同學提供深入 deepin、RISC-V 等技術項目的機會，將與甲辰計劃聯合提供近 80 個實習 HC。李程先生將作為該實習崗位的首席導師（Principle Mentor），協調實習工作內容，並負責 mentor 的招募和崗前培訓。進一步瞭解：&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA5NzE0Mjg4Ng%3D%3D%26mid%3D2650457142%26idx%3D2%26sn%3D4b83559f9c00f28f1df379af82b1ab5a%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;&lt;span&gt;新增實習機會！RISC-V deepin 操作系統開發實習生正在招募&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;由於時間限制未設置現場問答環節，但與會者還是對技術路線和實習計劃展現出了濃厚興趣，眾多參會者主動拍攝 PPT 關鍵內容頁，期待進一步交流探討。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//cd1393b25b25a0f66f8bf6cc4337cb36.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;附：&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;deepin-ports SIG 主頁：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://github.com/deepin-community/sig-deepin-ports&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365735</guid>
      <pubDate>Mon, 11 Aug 2025 07:39:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>馬斯克：xAI 將對蘋果採取法律行動</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;埃隆·馬斯克當地時間 8 月 11 日在社交平台發文稱，蘋果公司涉嫌通過限制措施，使除美國開放人工智能研究中心（OpenAI）外的任何人工智能公司都無法在其應用商店排行榜中登頂，稱此為「明確的反壟斷違規行為」。馬斯克表示，其旗下 xAI 公司將立即採取法律行動。&lt;/p&gt; 
&lt;p&gt;&lt;img height="272" src="https://oscimg.oschina.net/oscnet/up-77b6ba53d5b9d23dcb776934627a6b8c4cb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管馬斯克的指控引發了廣泛關注，但他並未提供具體證據來支持自己的説法。截至 8 月 12 日，ChatGPT 正佔據美國 App Store 的榜首位置。值得一提的是，OpenAI 和蘋果去年宣佈了一項合作關係，將 ChatGPT 集成到蘋果的智能系統中，以增強圖像和文檔理解等多項功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在馬斯克的指控後，OpenAI 首席執行官山姆・奧特曼也在社交平台上做出了回應。他表示，「這一指控非常引人注目，尤其是在我聽到的關於馬斯克如何操縱 X 以便讓自己及其公司獲益、並損害競爭對手及不喜歡的人的情況下。」 這一爭論進一步加劇了馬斯克與奧特曼之間本已緊張的關係，兩人曾經在 OpenAI 共事。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;奧特曼在文中提到我希望有人能進行反向取證，我們都想知道究竟發生了什麼。不過，OpenAI 將繼續專注於開發優秀的產品。」 與此同時，社交媒體上有許多人質疑馬斯克的説法，指出除了 ChatGPT 外，許多其他人工智能應用程序 App Store 上也曾登上過榜首。例如，來自中國的 DeepSeek 應用一度成為榜首，而自稱與 ChatGPT 競爭的 Perplexity 最近在印度的 App Store 中也取得了&lt;span&gt;第一&lt;/span&gt;的位置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365734</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365734</guid>
      <pubDate>Mon, 11 Aug 2025 07:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Rust 性能提升 「最後一公里」：詳解 Profiling 瓶頸定位與優化</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、Profiling：揭示性能瓶頸的"照妖鏡"&lt;/h1&gt; 
&lt;p&gt;在過去的一年裏，我們團隊完成了一項壯舉：將近萬核的 Java 服務成功遷移到 Rust，並收穫了令人矚目的性能提升。我們的實踐經驗已在《RUST 練習生如何在生產環境構建萬億流量》一文中與大家分享。然而，在這次大規模遷移中，我們觀察到一個有趣的現象：大多數服務在遷移後性能都得到了顯著提升，但有那麼一小部分服務，性能提升卻不盡如人意，僅僅在 10% 左右徘徊。&lt;/p&gt; 
&lt;p&gt;這讓我們感到疑惑。明明已經用上了性能"王者"Rust，為什麼還會遇到瓶頸？為瞭解開這個謎團，我們決定深入剖析這些"低提升"服務。今天，我就來和大家分享，我們是如何利用 &lt;strong&gt;Profiling&lt;/strong&gt; &lt;strong&gt;工具&lt;/strong&gt;，找到並解決寫入過程中的性能瓶頸，最終實現更高性能飛躍的！&lt;/p&gt; 
&lt;p&gt;在性能優化領域，盲目猜測是最大的禁忌。你需要一把鋒利的"手術刀"，精準地找到問題的根源。在 Rust 生態中，雖然不像 Java 社區那樣擁有 VisualVM 或 JProfiler 這類功能強大的成熟工具，但我們依然可以搭建一套高效的性能分析體系。&lt;/p&gt; 
&lt;p&gt;為了在生產環境中實現高效的性能監控，我們引入了 &lt;strong&gt;Jemalloc&lt;/strong&gt; 內存分配器和 &lt;strong&gt;pprof&lt;/strong&gt; CPU 分析器。這套方案不僅支持定時自動生成 Profile 文件，還可以在運行時動態觸發，極大地提升了我們定位問題的能力。&lt;/p&gt; 
&lt;h1&gt;二、配置項目：讓 Profiling"武裝到牙齒"&lt;/h1&gt; 
&lt;p&gt;首先，我們需要在 Cargo.toml 文件中添加必要的依賴，讓我們的 Rust 服務具備 Profiling 的能力。以下是我們的配置，Rust 版本為 1.87.0。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[target.'cfg(all(not(target_env = "msvc"), not(target_os = "windows")))'.dependencies]
# 使用 tikv-jemallocator 作為內存分配器，並啓用性能分析功能
tikv-jemallocator = { version = "0.6", features = ["profiling", "unprefixed_malloc_on_supported_platforms"] }
# 用於在運行時控制和獲取 jemalloc 的統計信息
tikv-jemalloc-ctl = { version = "0.6", features = ["use_std", "stats"] }
# tikv-jemallocator 的底層綁定，同樣啓用性能分析
tikv-jemalloc-sys = { version = "0.6", features = ["profiling"] }
# 用於生成與 pprof 兼容的內存剖析數據，並支持符號化和火焰圖
jemalloc_pprof = { version = "0.7", features = ["symbolize","flamegraph"] }
# 用於生成 CPU 性能剖析數據和火焰圖
pprof = { version = "0.14", features = ["flamegraph", "protobuf-codec"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;簡單來説，這幾個依賴各司其職：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ tikv-jemallocator&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基於 jemalloc 的 Rust 實現，以其高效的內存管理聞名。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ jemalloc_pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;負責將 jemalloc 的內存剖析數據轉換成標準的 pprof 格式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用於 CPU 性能分析，可以生成 pprof 格式的 Profile 文件。&lt;/p&gt; 
&lt;h1&gt;三、 全局配置：啓動 Profiling 開關&lt;/h1&gt; 
&lt;p&gt;接下來，在 main.rs 中進行全局配置，指定 &lt;strong&gt;Jemalloc&lt;/strong&gt; 的 &lt;strong&gt;Profiling&lt;/strong&gt; 參數，並將其設置為默認的全局內存分配器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 配置 Jemalloc 內存分析參數
#[export_name = "malloc_conf"]
pub static malloc_conf: &amp;amp;[u8] = b"prof:true,prof_active:true,lg_prof_sample:16\0";


#[cfg(not(target_env = "msvc"))]
use tikv_jemallocator::Jemalloc;


// 將 Jemalloc 設置為全局內存分配器
#[cfg(not(target_env = "msvc"))]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這段配置中的 lg_prof_sample:16 是一個關鍵參數。&lt;/p&gt; 
&lt;p&gt;它表示 jemalloc 會對大約每 2^16 字節（即 64KB）的內存分配進行一次採樣。這個值越大，採樣頻率越低，內存開銷越小，但精度也越低；反之則精度越高，開銷越大。在生產環境中，我們需要根據實際情況進行權衡。&lt;/p&gt; 
&lt;h1&gt;四、實現 Profile 生成函數：打造你的"數據採集器"&lt;/h1&gt; 
&lt;p&gt;我們將 Profile 文件的生成邏輯封裝成異步函數，這樣就可以在服務的任意時刻按需調用，非常靈活。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;內存 Profile 生成函數&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_memory_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    // 獲取 jemalloc 的 profiling 控制器
    let prof_ctl = jemalloc_pprof::PROF_CTL.as_ref()
        .ok_or_else(|| "Profiling controller not available".to_string())?;


    let mut prof_ctl = prof_ctl.lock().await;
    
    // 檢查 profiling 是否已激活
    if !prof_ctl.activated() {
        return Err("Jemalloc profiling is not activated".to_string());
    }
   
    // 調用 dump_pprof() 方法生成 pprof 數據
    let pprof_data = prof_ctl.dump_pprof()
        .map_err(|e| format!("Failed to dump pprof: {}", e))?;


    // 使用時間戳生成唯一文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("memory_profile_{}.pb", timestamp);


    // 將 pprof 數據寫入本地文件
    std::fs::write(&amp;amp;filename, pprof_data)
        .map_err(|e| format!("Failed to write profile file: {}", e))?;


    info!("Memory profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU Profile 生成函數&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;類似地，我們使用 pprof 庫來實現 CPU &lt;strong&gt;Profile&lt;/strong&gt; 的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_cpu_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    use pprof::ProfilerGuard;
    use pprof::protos::Message;


    info!("Starting CPU profiling for 60 seconds...");


    // 創建 CPU profiler，設置採樣頻率為 100 Hz
    let guard = ProfilerGuard::new(100).map_err(|e| format!("Failed to create profiler: {}", e))?;


    // 持續採樣 60 秒
    tokio::time::sleep(std::time::Duration::from_secs(60)).await;


    // 生成報告
    let report = guard.report().build().map_err(|e| format!("Failed to build report: {}", e))?;


    // 使用時間戳生成文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("cpu_profile_{}.pb", timestamp);


    // 創建文件並寫入 pprof 數據
    let mut file = std::fs::File::create(&amp;amp;filename)
        .map_err(|e| format!("Failed to create file: {}", e))?;


    report.pprof()
        .map_err(|e| format!("Failed to convert to pprof: {}", e))?
        .write_to_writer(&amp;amp;mut file)
        .map_err(|e| format!("Failed to write profile: {}", e))?;


    info!("CPU profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;ProfilerGuard::new() 100 Hz 意味着每秒鐘會隨機中斷程序 &lt;strong&gt;100 次&lt;/strong&gt;，以記錄當前正在執行的函數調用棧&lt;/li&gt; 
 &lt;li&gt;tokio::time::sleep(std::time::Duration::from_secs(60)).await 表示 pprof 將會持續採樣 60 秒鐘&lt;/li&gt; 
 &lt;li&gt;guard.report().build() 這個方法用於將收集到的所有采樣數據進行處理和聚合，最終生成一個 Report 對象。這個 Report 對象包含了所有調用棧的統計信息，但還沒有轉換成特定的文件格式&lt;/li&gt; 
 &lt;li&gt;report.pprof() 這是 Report 對象的一個方法，用於將報告數據轉換成 pprof 格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;五、 觸發和使用 Profiling：隨時隨地捕捉性能數據&lt;/h1&gt; 
&lt;p&gt;有了上述函數，我們實現了兩種靈活的觸發方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 定時自動生成&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過異步定時任務，每隔一段時間自動調用 dump_memory_profile() 和 dump_cpu_profile() 。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn start_profilers() {
    // Memory profiler
    tokio::spawn(async {
        let mut interval = tokio::time::interval(std::time::Duration::from_secs(300));
        loop {
            interval.tick().await;
            #[cfg(not(target_env = "msvc"))]
            {
                info!("Starting memory profiler...");
                match dump_memory_profile().await {
                    Ok(profile_path) =&amp;gt; info!("Memory profile dumped successfully: {}", profile_path),
                    Err(e) =&amp;gt; info!("Failed to dump memory profile: {}", e),
                }
            }
        }
    });
    // 同理可以實現 CPU profiler
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 手動 HTTP 觸發&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過提供 /profile/memory 和 /profile/cpu 兩個 HTTP 接口，可以隨時按需觸發 Profile 文件的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;async fn trigger_memory_profile() -&amp;gt; Result&amp;lt;impl warp::Reply, std::convert::Infallible&amp;gt; {
    #[cfg(not(target_env = "msvc"))]
    {
        info!("HTTP triggered memory profile dump...");
        match dump_memory_profile().await {
            Ok(profile_path) =&amp;gt; Ok(warp::reply::with_status(
                format!("Memory profile dumped successfully: {}", profile_path),
                warp::http::StatusCode::OK,
            )),
            Err(e) =&amp;gt; Ok(warp::reply::with_status(
                format!("Failed to dump memory profile: {}", e),
                warp::http::StatusCode::INTERNAL_SERVER_ERROR,
            )),
        }
    }
}
//同理也可實現 trigger_cpu_profile() 函數

fn profile_routes() -&amp;gt; impl Filter&amp;lt;Extract = impl Reply, Error = warp::Rejection&amp;gt; + Clone {
    let memory_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("memory"))
        .and(warp::path::end())
        .and_then(trigger_memory_profile);
    
    
    let cpu_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("cpu"))
        .and(warp::path::end())
        .and_then(trigger_cpu_profile);
    memory_profile.or(cpu_profile)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;現在，我們就可以通過 curl 命令，隨時在生產環境中採集性能數據了：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:8080/profile/memory
curl -X POST http://localhost:8080/profile/cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;生成的 .pb 文件，我們就可以通過 go tool pprof 工具，啓動一個交互式 Web UI，在瀏覽器中直觀查看調用圖、火焰圖等。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go tool pprof -http=localhost:8080 ./target/debug/otel-storage ./otel_storage_cpu_profile_20250806_032509.pb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;六、性能剖析：火焰圖下的"真相"&lt;/h1&gt; 
&lt;p&gt;通過 go tool pprof 啓動的 Web UI，我們可以看到程序的&lt;strong&gt;火焰圖&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何閲讀火焰圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 頂部：&lt;/strong&gt; 代表程序的根函數。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 向下延伸；&lt;/strong&gt; 子函數調用關係。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 火焰條的寬度：&lt;/strong&gt; 代表該函數在 CPU 上消耗的時間。&lt;strong&gt;寬度越寬，消耗的時間越多，越可能存在性能瓶頸&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8b814e239f61ed1c970231bc444f3896a50.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU Profile&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-55883adfb3cf12d5390b652452d3f883d17.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Memory Profile&lt;/p&gt; 
&lt;p&gt;在我們的 CPU 火焰圖中，一個令人意外的瓶頸浮出水面：&lt;strong&gt;OSS::new&lt;/strong&gt; 佔用了約 19.1% 的 CPU 時間。深入分析後發現， OSS::new 內部的 TlsConnector 在每次新建連接時都會進行 TLS 握手，這是導致 CPU 佔用過高的根本原因。&lt;/p&gt; 
&lt;p&gt;原來，我們的代碼在每次寫入 OSS 時，都會新建一個 OSS 實例，隨之而來的是一個全新的 HTTP 客戶端和一次耗時的 TLS 握手。儘管 oss-rust-sdk 內部有連接池機制，但由於我們每次都創建了新實例，這個連接池根本無法發揮作用！&lt;/p&gt; 
&lt;h1&gt;七、優化方案：從"每次新建"到"共享複用"&lt;/h1&gt; 
&lt;p&gt;問題的核心在於重複創建 OSS 實例。我們的優化思路非常清晰：&lt;strong&gt;複用 OSS 客戶端實例，避免不必要的 TLS 握手開銷&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每次寫入都新建 OSS 客戶端。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn write_oss() {
    // 每次寫入都新建一個 OSS 實例
    let oss_instance = create_oss_client(oss_config.clone());
    tokio::spawn(async move {
        // 獲取寫入偏移量、文件名
        // 構造 OSS 寫入所需資源和頭信息
        // 寫入 OSS
        let result = oss_instance
            .append_object(data, file_name, headers, resources)
            .await;
}
fn create_oss_client(config: OssWriteConfig) -&amp;gt; OSS {
    OSS::new(
    ......
    )
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這種方案在流量較小時可能問題不大，但在萬億流量的生產環境中，頻繁的實例創建會造成巨大的性能浪費。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 共享實例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;讓每個處理任務（ DecodeTask ）持有 Arc 共享智能指針，確保所有寫入操作都使用同一個 OSS 實例。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;let oss_client = Arc::new(create_oss_client(oss_config.clone()));
let oss_instance = self.oss_client.clone(); 
// ...
let result = oss_instance
    .append_object(data, file_name, headers, resources)
    .await;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 自動重建機制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了應對連接失效或網絡問題，我們引入了自動重建機制。當寫入次數達到閾值或發生寫入失敗時，我們會自動創建一個新的 OSS 實例來替換舊實例，從而保證服務的健壯性。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 使用原子操作確保多線程環境下的計數安全
let write_count = self.oss_write_count.load(std::sync::atomic::Ordering::SeqCst);
let failure_count = self.oss_failure_count.load(std::sync::atomic::Ordering::SeqCst);


// 檢查是否需要重建實例...
fn recreate_oss_client(&amp;amp;mut self) {
 
    let new_oss_client = Arc::new(create_oss_client(self.oss_config.clone()));
    self.oss_client = new_oss_client;
    self.oss_write_count.store(0, std::sync::atomic::Ordering::SeqCst);
    self.oss_failure_count.store(0, std::sync::atomic::Ordering::SeqCst);
    // 記錄 OSS 客戶端重建次數指標
    OSS_CLIENT_RECREATE_COUNT
        .with_label_values(&amp;amp;[])
        .inc();
    info!("OSS client recreated");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;八、優化效果：性能數據"一飛沖天"&lt;/h1&gt; 
&lt;p&gt;優化後的服務上線後，我們觀察到了顯著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU 資源使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降約 &lt;strong&gt;20%&lt;/strong&gt; 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-68b2935d6632ee730c0dc6ac3155a4257a4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OSS 寫入耗時&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降約 &lt;strong&gt;17.2%&lt;/strong&gt; ，成為集羣中最短的寫入耗時。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 寫入耗時&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-18a1b33fff58596e3d4317f4035511a8eca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 相關資源只佔千分之一&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f35812df10896bc3430f0020571b4ab2e03.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;內存使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;平均下降 &lt;strong&gt;8.77%&lt;/strong&gt; ，這部分下降可能也得益於我們將內存分配器從 &lt;strong&gt;mimalloc&lt;/strong&gt; 替換為 &lt;strong&gt;jemalloc&lt;/strong&gt; 的綜合效果。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-863bda3bf8f46a11ceeffef27808d64c90d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這次優化不僅解決了特定服務的性能問題，更重要的是，它驗證了在 Rust 中通過 Profiling 工具進行深度性能分析的可行性。即使在已經實現了初步性能提升的 Rust 服務中，仍然存在巨大的優化空間。&lt;/p&gt; 
&lt;p&gt;未來，我們將繼續探索更高效的 Profiling 方案，並深入挖掘其他潛在的性能瓶頸，以在萬億流量的生產環境中實現極致的性能和資源利用率。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;引用&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub - tikv/jemallocator: Rust allocator using jemalloc as a backend&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrates.io%2Fcrates%2Fjemalloc_pprof" target="_blank"&gt;https://crates.io/crates/jemalloc_pprof&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub - google/pprof: pprof is a tool for visualization and analysis of profiling data&lt;/li&gt; 
 &lt;li&gt;Use Case: Heap Profiling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjemalloc.net%2Fjemalloc.3.html%23heap_profile_format" target="_blank"&gt;https://jemalloc.net/jemalloc.3.html#heap_profile_format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.brendangregg.com%2Fflamegraphs.html" target="_blank"&gt;https://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmagiroux.com%2Frust-jemalloc-profiling" target="_blank"&gt;https://magiroux.com/rust-jemalloc-profiling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.Valkey 單點性能比肩 Redis 集羣了？Valkey8.0 新特性分析｜得物技術&lt;/p&gt; 
&lt;p&gt;2.Java volatile 關鍵字到底是什麼｜得物技術&lt;/p&gt; 
&lt;p&gt;3.社區搜索離線回溯系統設計：架構、挑戰與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;4.正品庫拍照 PWA 應用的實現與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;5.得物社區活動：組件化的演進與實踐&lt;/p&gt; 
&lt;p&gt;文 / 炯帆，南風&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18687884</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18687884</guid>
      <pubDate>Mon, 11 Aug 2025 07:22:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Linux Turbostat 工具可顯示 CPU L3 緩存拓撲信息</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 6.17 內核源代碼樹中 Turbostat 工具的更新已完成合並&lt;/p&gt; 
&lt;p&gt;Turbostat 是一款命令行工具，用於顯示 CPU 頻率/空閒/功耗統計信息以及其他相關的處理器信息，主要針對 Intel 和 AMD 處理器。值得注意的是，Linux 6.17 中的 Turbostat 增加了顯示 L3 緩存拓撲信息的支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cf186a887af4b06f2d0a899e1a4af7834c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Turbostat 還新增了對新增計數器（例如累計瓦特和其他計數器）進行平均的功能，修復了對即將推出的英特爾至強 Diamond Rapids 處理器的支持。&lt;/p&gt; 
&lt;p&gt;由於部分型號特定寄存器 (MSR) 的變更，Turbostat 需要進行更多調整，以便正確顯示 Granite Rapids 後續的下一代至強處理器的功耗和性能相關詳細信息。&lt;/p&gt; 
&lt;p&gt;此外，Turbostat 還修復了針對 musl libc 的構建問題以及其他各種修復。更多詳情，請訪問&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAJvTdKmaTvaQiRjgz_Pr6a%2BXEkLzEnedujV%3Dvqwv5thEE63fdg%40mail.gmail.com%2F" target="_blank"&gt;此 pull request&lt;/a&gt;，該請求已合併至 Linux Git。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365725</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365725</guid>
      <pubDate>Mon, 11 Aug 2025 07:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
