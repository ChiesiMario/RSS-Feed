<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Wed, 23 Jul 2025 07:44:51 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>AI 將在五年內成為企業生存的 「基本技能」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;美國科技億萬富翁馬克・庫班最近在接受採訪時表示，人工智能（AI）將在未來五年內成為每個職場人士必備的 「基本技能」，就像電子郵件和 Excel 軟件一樣普及。他強調，企業主如何有效利用人工智能將直接影響他們在未來幾年的競爭力和成功。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="340" src="https://oscimg.oschina.net/oscnet/up-6045b74ea4f19a7984f7137d2b1c96ff8a2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;庫班提到，在接下來的十年內，人工智能助手將極大改變工作模式。他預測，未來會有越來越多的人選擇自己創業，藉助人工智能的幫助，單個創始人將能夠承擔起一個完整團隊的工作。這一變化不僅能夠提升個人的工作效率，還能夠為更多人打開創業的大門。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他指出，企業主在利用人工智能的過程中，必須快速做出決策並行動。他表示:「如果你沒有利用人工智能來更快地決策，你就會落後於競爭對手。」 庫班將人工智能視為企業主可以投資的 「團隊成員」，它能夠協助企業主完成多個角色的工作，包括運營副總裁、銷售代表、數據分析師及法律顧問，而這些角色的工作費用將大幅降低。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，庫班也提醒企業家們，儘管 AI 具有強大的能力，他們在使用人工智能時仍需謹慎。他建議將人工智能視作 「最聰明的實習生」，不僅要提出正確的問題，還要認真審核其提供的答案。他指出，許多企業家在當前環境中面臨的&lt;span&gt;最大&lt;/span&gt;挑戰是 「恐懼和資金」。然而，人工智能代理的出現，將幫助那些由於招聘成本而無法進入某一行業的創業者，打破這一壁壘。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;庫班總結道，人工智能不僅是工具，更是企業家們的強大槓桿。成功的企業家將懂得如何有效利用這一技術，確保在競爭中立於不敗之地。他強調:「最終，人工智能是一個乘數，善用它，但不要被它操控。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361931</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361931</guid>
      <pubDate>Wed, 23 Jul 2025 07:40:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>亞馬遜雲科技上海 AI 研究院解散</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AWS 亞馬遜雲科技上海 AI 研究院的首席應用科學家王敏捷發朋友圈稱，「剛收到通知，AWS 亞馬遜雲科技上海 AI 研究院（也是 AWS 最後一個海外研究院）正式解散。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bf820d1cb694fdf814a9c083a90582b673.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;王敏捷感慨道，「近 6 年帶隊時光，趕上了外企研究院的黃金週期，更得益於張崢老師的細心指導，有幸成為 AWS 亞太地區最年輕的首席應用科學家。」&lt;/p&gt; 
&lt;p&gt;今日，亞馬遜雲科技就上海 AI 研究院解散一事&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1838398566569114998%26wfr%3Dspider%26for%3Dpc"&gt;回應新浪科技稱&lt;/a&gt;：「經過對公司組織、發展重點及未來戰略方向的深入評估，我們決定對亞馬遜雲科技部分團隊進行人員精簡。」&lt;/p&gt; 
&lt;p&gt;亞馬遜雲科技表示，「做出這些決定是非常艱難的，我們將全力支持員工順利過渡，我們做出這些必要的決定，是為了持續投資、優化資源，為客戶帶來更多的創新」。&lt;/p&gt; 
&lt;p&gt;今年以來，已有多家科技巨頭對其在華研發業務進行了調整。&lt;/p&gt; 
&lt;p&gt;2025 年 3 月，IBM 關閉了在中國運營了 32 年的研發部門，另外，有媒體報道微軟也在逐步關閉其上海 AI 實驗室，並將數百名專家搬遷至美國、澳大利亞、愛爾蘭等地。今年 6 月，花旗集團宣佈，作為在全球持續推進的簡化工作的一部分，花旗將精簡位於中國上海和大連的全球技術解決中心，減少約 3500 名技術人員。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361930</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361930</guid>
      <pubDate>Wed, 23 Jul 2025 07:37:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Fedora 考慮放棄 DVD 光盤啓動支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Fedora 項目正在向其用戶和開發者社區徵求反饋，探討是否可能更新其發佈標準，使其不再阻止光盤啓動問題（DVD 映像），以及是否繼續將基於 Intel 的 Mac 的雙啓動問題視為發佈阻礙。&lt;/p&gt; 
&lt;p&gt;提出的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscussion.fedoraproject.org%2Ft%2Fproposal-drop-optical-media-boot-release-criterion%2F160524" target="_blank"&gt;第一項建議&lt;/a&gt;是，是否放棄 Fedora 發佈標準中關於光盤啓動支持的內容。這涉及 Fedora 發行版安裝程序映像，這些映像必須在寫入光盤（DVD）後才能啓動。Fedora 已於 2020 年正式停止測試光盤支持，目前他們正在考慮使其不再阻止任何已報告的問題：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;自 2020 年以來，質量團隊不再被要求測試光學介質，但發現的任何問題仍然可能成為阻礙。我們不太喜歡這個解決方案（阻止我們未測試的內容），但測試光學啓動實在太耗時，而且已經很小眾了。五年後的今天，我們認為是時候放棄整個標準了。光學啓動的重要性早已不復存在，我們認為是時候將其從名為發佈標準的「關鍵功能列表」中移除了。這不會為我們節省太多時間（我不記得過去幾年出現過任何引人注目的光學啓動問題），但它可以稍微簡化我們的測試矩陣（使其更易於閲讀），解決發佈阻止狀態和質量覆蓋範圍之間的矛盾，並且如果發現問題，它可以讓我們丟棄仍然準備好的 DVD 驅動器和介質（但可能已經無法使用了）。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2F%3D%2522https%3A%2F%2Fdiscussion.fedoraproject.org%2Ft%2Fproposal-drop-intel-based-macbook-dual-boot-release-criterion%2F160525%2522" target="_blank"&gt;第二項提案&lt;/a&gt;是關於取消基於 Intel 的 Apple MacBook 雙啓動發佈標準。當前的發佈標準指出，Fedora 安裝程序必須能夠與基於 Intel 的 Mac 電腦上現有的 macOS 安裝一起雙啓動/安裝到可用空間中。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「這個標準正在隨着時間的推移而被淘汰，因為蘋果多年前就停止生產基於英特爾的 Mac（取而代之的是「Apple Silicon」 M* 處理器，目前 Fedora 並不支持這種處理器）。最後幾款可以合理使用 Fedora 的 MacBook 是 2017 年款，它仍然包含 T1 安全芯片（較新的型號有 T2 芯片，並且它們的內部鍵盤和觸摸板不適用於 Fedora 內核）。2017 年款的系統更新支持將於今年結束，老款已經過時。這意味着 2017 年之前款的用戶很可能已經切換到 Fedora，如果他們願意的話，2017 年款的用戶可能會在今年這樣做，而且未來不會有這樣的用戶，因為他們的硬件得不到 Fedora 的良好支持。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這主要涉及 2017 年及更早的 Apple Mac，因為配備 T2 安全芯片的較新 Apple Mac 目前在 Fedora Linux 上運行不佳。這不會影響 Apple Silicon Mac 的任何變更，只會影響 Intel x86_64 系統。&lt;/p&gt; 
&lt;p&gt;由於 Fedora 質量團隊目前對剩餘的 Intel Mac 的訪問權限較少，並且能夠投入較少時間來修復這些老舊系統的任何問題，因此現在的願望是不要將任何 Apple Mac 雙啓動問題視為發佈阻礙。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361929</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361929</guid>
      <pubDate>Wed, 23 Jul 2025 07:31:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>周鴻禕：最近都採購華為芯片，英偉達 H20 性價比不高</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 23 日，360 集團創始人周鴻禕&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yicai.com%2Fnews%2F102737141.html"&gt;對第一財經記者表示&lt;/a&gt;，360 的芯片採購正轉向國產芯片，最近採購的都是華為的產品，未涉及英偉達 H20 芯片。&lt;/p&gt; 
&lt;p&gt;他坦言，儘管國產芯片與英偉達產品存在差距，但必須堅持使用，因為只有通過大量應用，才能推動國產芯片持續改進。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0723/152238_twYV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;H20 是英偉達針對中國市場推出的 H100 簡化版，採用 Hopper 架構和 CoWoS 封裝技術，但性能差距明顯。周鴻禕分析，H20 更適合 AI 推理任務，而推理對芯片要求較低，無需高速互聯和集羣部署。在此領域，國產芯片性價比更高，使得定位中間的 H20 顯得尷尬。當前美國芯片出口限制背景下，華為等企業加大研發，其昇騰系列芯片性能逐步提升，部分領域已超越 H20。360 的選擇既獲性價比優勢，也助力國產芯片產業迭代，實現雙贏。&lt;/p&gt; 
&lt;p&gt;此前，360 已採購約 1000 片華為昇騰 910B AI 芯片，併合作將 AI 框架移植到該芯片上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361928</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361928</guid>
      <pubDate>Wed, 23 Jul 2025 07:24:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深度剖析 TDMQ RabbitMQ 版經典隊列底層存儲機制</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;導語&lt;/h2&gt; 
&lt;p&gt;RabbitMQ 作為開源消息隊列的標杆產品，憑藉靈活的路由機制與高可用設計，支撐着海量業務場景的消息流轉。而經典隊列（Classic Queue） 作為 RabbitMQ 最基礎、應用最廣泛的隊列類型，其底層存儲機制直接決定了消息處理的性能邊界與可用性上限。&lt;/p&gt; 
&lt;p&gt;理解經典隊列的存儲架構，不僅是掌握 RabbitMQ 核心原理的關鍵，更為生產環境的運維優化提供了理論支撐。本文將從文件目錄結構、存儲格式定義、讀寫流程到運維實踐策略，全面解析經典隊列的底層存儲實現邏輯，幫助讀者深入理解其在消息生命週期管理中的核心作用。&lt;/p&gt; 
&lt;h2&gt;經典隊列介紹&lt;/h2&gt; 
&lt;p&gt;RabbitMQ 作為一款歷史悠久的開源消息隊列，被廣泛應用於各個領域。在 RabbitMQ 中，用戶使用虛擬主機（Vhost）隔離資源，交換機負責路由消息，隊列則是消息存儲的最小單元。&lt;/p&gt; 
&lt;p&gt;用戶通過客戶端與 RabbitMQ 的服務端建立連接後，基於通道（Channel）實現消息的高效交互：生產者經過通道將消息發送至交換機，由交換機按綁定規則路由至目標隊列；消費者則通過通道從隊列中拉取消息，完成業務邏輯處理。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-356020c87a4782a64efc9913f5c4615dfea.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在這一過程中，隊列作為消息生命週期的核心載體，衍生出三種差異化實現：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;經典隊列（Classic Queue）&lt;/strong&gt;：採用輕量級索引與共享存儲架構，在單機性能與存儲效率間取得平衡，適用於高吞吐非強一致性場景；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;仲裁隊列（Quorum Queue）&lt;/strong&gt;：基於 Raft 協議實現多副本強一致性，保障關鍵業務數據不丟失，適用於金融交易、訂單管理等關鍵業務；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;流隊列（Stream Queue）&lt;/strong&gt;：以日誌結構存儲消息流，支持回溯消費與持久化流處理，適用於實時數據分析場景。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經典隊列作為使用頻率最高的隊列，瞭解它的存儲機制對於理解其可用性和性能至關重要，接下來將從存儲架構、文件格式、讀寫流程等維度，深入解析經典隊列的底層實現邏輯。&lt;/p&gt; 
&lt;h2&gt;存儲架構解析&lt;/h2&gt; 
&lt;h3&gt;目錄結構&lt;/h3&gt; 
&lt;p&gt;RabbitMQ 通過虛擬主機（Vhost）實現資源隔離，每個 Vhost 有獨立的物理存儲目錄，其典型結構如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;vhost_name/
├── msg_store_persistent/      # 共享存儲目錄，存儲大消息
│   ├── 0.rdq                  # 共享存儲文件
│   └── 1.rdq                  # 支持文件滾動
└── queues/                    # 隊列專屬存儲目錄
    └── queue_name/            # 單個隊列目錄
        ├── queue_name.qi      # 隊列索引文件
        └── queue_name.qs      # 隊列存儲文件
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;msg_store_* 是共享存儲目錄，顧名思義是這個 Vhost 下所有隊列共享的存儲。由於 Exchange 可能會將同一條消息路由到不同的隊列，而將同一條消息存儲多次會增加磁盤空間佔用，因此經典隊列會將大小超過某個閾值的消息存儲在共享存儲下，通過引用計數來管理這部分消息。&lt;/p&gt; 
&lt;p&gt;每個隊列在 queues 目錄下都有屬於自己的目錄，隊列目錄下主要有兩類文件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隊列存儲&lt;/strong&gt;：名稱為 *.qs 的文件，負責存儲這個隊列中消息大小小於這個閾值的消息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隊列索引&lt;/strong&gt;：名稱為 *.qi 的文件，負責存儲消息元數據和消息所在位置。隊列索引存儲了消息的偏移或唯一標識，通過它們可以定位到消息在隊列存儲或共享存儲中的位置，索引文件中的 Entry 和存儲文件中的 Entry 因此在邏輯上構成了一對一的映射關係。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c21a1914865fc33ac57c80f3056a8a6522b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;隊列索引&lt;/h3&gt; 
&lt;p&gt;隊列索引文件由一個 Header 和若干 Entry 組成，Entry 的數量由 classic_queue_index_v2_segment_entry_count 這一參數控制，默認為 4096。Entry 有兩種類型：Publish Entry 和 Ack Entry。&lt;/p&gt; 
&lt;p&gt;生產者將消息成功發送到隊列後會產生一個 Publish Entry，隊列將這條消息投遞給消費者並且得到消費者確認後會使用 Ack Entry 覆蓋原來的 Publish Entry，代表這條消息可以被刪除。&lt;/p&gt; 
&lt;p&gt;Publish Entry 存儲了這條消息的元數據，包括 MsgId、SeqId、存儲位置、消息屬性和是否持久化的標識。&lt;/p&gt; 
&lt;p&gt;MsgId 是 RabbitMQ 為每條消息隨機生成的 GUID，用來確定消息在共享存儲的位置。&lt;/p&gt; 
&lt;p&gt;SeqId 是這條消息在隊列中的序號，用來決定消息在隊列索引和隊列存儲中的位置。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0d7a0133f530ca3140ec9f5eae8f0132f65.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;隊列存儲&lt;/h3&gt; 
&lt;p&gt;隊列存儲文件和索引文件是一對一的關係，當隊列刪除它的索引文件時，也會刪除對應的存儲文件。隊列存儲文件的結構與索引文件類似，也是由 Header 和 Entry 構成。Header 和 Entry 的具體組成如下所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f1cb3f97618cb1b9d332ea7825e2572cb48.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;共享存儲&lt;/h3&gt; 
&lt;p&gt;ETS 是 Erlang 內置的單機 KV 存儲，共享存儲使用 ETS 維護了兩個組件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Index&lt;/strong&gt;：是 MsgId 到消息位置的映射。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FileSummary&lt;/strong&gt;：文件到文件統計信息的映射。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經典隊列在讀取消息時通過索引文件中的 Publish Entry 獲取到 MsgId 後還需要從 Index 中獲取消息的具體位置，包括這條消息所在的文件、偏移以及它的引用計數。相同 MsgId 的多條消息只會被寫入一次，刪除消息時，它的引用計數會被減一。文件統計信息中記錄了文件中有效數據的數量，這在整理文件時會被用到。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0c96ca072a09a3c72ec0b3a9950eed78807.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;共享存儲文件的大小由參數 msg_store_file_size_limit 控制，默認為 16MB。每個文件由若干個 Entry 組成，每個 Entry 的具體組成如下所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c58a84b548a6cf8d3a9adc321ae22d8fe7c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;核心工作流程&lt;/h2&gt; 
&lt;h3&gt;消息寫入&lt;/h3&gt; 
&lt;p&gt;RabbitMQ 根據消息大小決定將消息寫入到哪個存儲。如果消息大小大於或等於某個值（由參數 queue_index_embed_msgs_below 控制，默認為 4KB），RabbitMQ 會將其存於共享存儲中，否則會存於隊列存儲中。&lt;/p&gt; 
&lt;p&gt;將消息寫入存儲時會直接寫到內部緩衝區：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;隊列存儲內部的緩衝區大小由參數 classic_queue_store_v2_max_cache_size 控制，默認為 512KB。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;共享存儲內部的緩衝區大小則固定為 1MB。將消息寫入到共享存儲時除了需要寫入到緩衝區外，還需要更新它內部的 Index 和 FileSummary 組件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;緩衝區大小超過限制後會 Flush 其中的數據，值得注意的是，Flush 時不會調用 Fsync，而是調用 Write 將數據寫入到操作系統的 Page Cache 上。這種方式通過犧牲數據安全性以獲得更低的延遲，如果需要更強的數據安全性應使用仲裁隊列。&lt;/p&gt; 
&lt;p&gt;存儲寫入完成後需要在隊列索引文件中寫入 Publish Entry，此時消息被認為成功寫入了。之後還要更新內存中的消息緩存，以加速消息讀取。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-06d103e2eaab27dd60507d35936ea839341.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;消息讀取&lt;/h2&gt; 
&lt;p&gt;經典隊列在內存中維護了專門的緩存來提升讀取性能，底層存儲會根據隊列的消費速率批量讀取不超過 2048 條消息到緩存中。讀取消息時會先檢查緩存中是否有這條消息，如果有則直接返回，否則會先將消息批量讀取到緩存。&lt;/p&gt; 
&lt;p&gt;將消息從磁盤批量讀取到內存中需要先到隊列索引中讀取元數據，然後分別到隊列存儲和共享存儲中讀取消息體，並將它們組裝到一起。即便緩存中有消息，但是實際的消息體仍然可能不在緩存中，因為過大（&amp;gt;12KB）過少（&amp;lt;10 條）的消息的消息體並不會被讀到緩存裏，需要在投遞消息時逐條去磁盤中讀取消息體。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-62aec5d5efbcb40873a77832b210429310c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;文件整理&lt;/h2&gt; 
&lt;p&gt;共享存儲會定時整理有效數據佔比低於一半的文件以回收空間。整個過程分為三步：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;將文件末尾的有效數據拷貝到文件前面的無效數據處。&lt;/li&gt; 
 &lt;li&gt;更新 Index 組件。&lt;/li&gt; 
 &lt;li&gt;在沒有進程讀取文件後截斷文件。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;RabbitMQ 會將文件中的無效數據置 0，稱為空洞（blank holes）。在文件整理時，RabbitMQ 從最後一條有效消息開始查看其是否能填補前面的空洞，如果可以就將其拷貝到前面，如果它比前面的任何一個空洞都大，那麼這一次的文件整理將無法釋放任何空間，這是為了防止意外覆蓋被移動過的消息。Index 組件中存儲了消息的位置，拷貝完成後需要更新對應消息的位置。在沒有進程讀取文件後就可以截斷這個文件以節省磁盤空間。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-92a86e83dda9f187412ce495b8d272dad17.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;運維實踐&lt;/h2&gt; 
&lt;h3&gt;發送確認&lt;/h3&gt; 
&lt;p&gt;為了提高消息發送的可靠性，我們推薦用戶打開發送確認（Confirm）。RabbitMQ 會在將消息從緩衝區 Flush 到磁盤後向客戶端發送 Confirm，此時生產者可以認為這條消息已經被成功發送到隊列。&lt;/p&gt; 
&lt;h3&gt;消費確認&lt;/h3&gt; 
&lt;p&gt;為了提高消息消費的可靠性，我們推薦用戶打開手動確認（Manual Ack）。RabbitMQ 在收到 Ack 後會寫入 Entry 到隊列索引中，只有在索引文件中的所有 Publish Entry 全部被 Ack 後，才會刪除該文件。如果消費者在發送 Ack 前宕機了，RabbitMQ 會重複投遞這條消息，確保消息能真正被消費掉。未被客戶端 Ack 的消息會堆積在內存中，如果數量過多則可能觸發內存水位限制，甚至導致服務端 OOM。因此在用戶打開手動確認後，我們建議用戶設置一次最多能預取（prefetch count）的消息數量，避免大量消息堆積在客戶端和服務端內存中。&lt;/p&gt; 
&lt;h3&gt;保證隊列儘可能短&lt;/h3&gt; 
&lt;p&gt;保持生產和消費速率一致可以減少消息堆積。RabbitMQ 會在發現索引文件中的消息全部被消費後刪除索引文件和對應的存儲文件，這樣可以減少磁盤空間佔用。隊列的堆積數量少意味着多數讀取都可以從緩存中直接讀取到消息體，從而提升讀取性能。&lt;/p&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p&gt;本文全面探討了 RabbitMQ 經典隊列的底層存儲機制，包括其整體架構、實現原理及運維實踐。經典隊列的底層存儲由隊列索引和消息存儲兩大模塊構成，其中消息存儲又細分為共享存儲和隊列存儲，通過精心設計的文件結構和內存管理策略，實現了高效的消息讀寫與存儲管理。文章詳細解析了隊列索引、消息存儲（包括共享存儲和隊列存儲）的文件結構，介紹了消息讀取與寫入的流程，以及文件整理的邏輯。在運維實踐方面，強調了發送確認、消費確認與保持隊列儘可能短的重要性，並給出了相應的配置建議。希望通過本文的介紹，可以幫助大家深入理解 RabbitMQ 經典隊列的底層存儲機制，為實際應用中的性能優化與故障排查提供有力支持。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4587289/blog/18684804</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4587289/blog/18684804</guid>
      <pubDate>Wed, 23 Jul 2025 07:21:49 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>智元首款四足機器人 D1 ULTRA 已在官網上架</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 23 日，智元機器人官網已上架其首款四足機器人&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhiyuan-robot.com%2Fproducts%2FD1Ultra" target="_blank"&gt;D1 ULTRA&lt;/a&gt;，定位為「行業級小型四足機器人」，隸屬於智元靈犀系列，最高奔跑速度達 3.7 米/秒，最大上下斜坡角度≥30 度，可向前或向上跳躍離地面高度達 35 釐米，支持最高 16 釐米樓梯連續攀爬，適用於特種應用、安防巡檢、科研教育等場景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/150843_zowq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具體參數如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/150938_ID8h_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，智元尚未公佈 D1 ULTRA 的售價。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361922</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361922</guid>
      <pubDate>Wed, 23 Jul 2025 07:10:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>昔日合作伙伴反目成仇，微軟 AI 主管挖角谷歌 20 名核心員工</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;硅谷 AI 人才市場近日掀起了一陣風暴，微軟消費級 AI 戰略負責人穆斯塔法・蘇萊曼（Mustafa Suleyman）開始大規模從其曾創辦的 DeepMind 團隊挖角，已經成功引入超過 20 名核心員工。作為曾經的合作伙伴，蘇萊曼如今卻將目光投向了他的老東家，直接影響到谷歌的 AI 研發力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="325" src="https://oscimg.oschina.net/oscnet/up-f52907ca2cc81233a194ab25b2e460ef981.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在這次人才爭奪戰中，前谷歌 Gemini 聊天機器人工程負責人阿馬爾・蘇布拉馬尼亞（Amar Subramanya）也確認將加入微軟，擔任人工智能副總裁。他在個人社交平台上表示，微軟的文化讓他感到耳目一新，團隊的氛圍既謙遜又雄心勃勃。除了蘇布拉馬尼亞，微軟還成功説服了其他幾位 DeepMind 的核心員工加入，顯示出其對人才的強烈需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據消息人士透露，微軟在過去六個月內已從 DeepMind 吸納了至少 24 名員工。此時，正值各大科技公司加大力度從競爭對手處挖角頂尖&amp;nbsp;AI 研究員和工程師，行業薪酬水平也因而迅速上升。對此，OpenAI 首席執行官薩姆・奧特曼（Sam Altman）曾批評其他公司用高額簽約獎金吸引人才，認為這助長了 「唯利是圖」 的風氣。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;隨着蘇萊曼的挖角行動，微軟不僅獲得了寶貴的專業技術，還可能幹擾到谷歌的研發進程。蘇萊曼於今年 3 月加入微軟，之前曾因其創辦的初創公司 Inflection 被微軟收購而走上現在的職位。他的戰略意圖顯而易見，通過快速組建一支高效團隊，加速微軟在關鍵 AI 領域的佈局。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與此同時，谷歌也因內部人事變動進行重組，以應對日益激烈的競爭。谷歌數據顯示，ChatGPT 的月活躍用戶數已經達到 6 億，而其自家 Gemini 僅為 4 億。更有消息稱，谷歌也從微軟挖走了部分研究人員，表明兩家公司在人才爭奪上的白熱化程度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，科技巨頭們為頂尖&amp;nbsp;AI 人才開出的高薪，反映出行業的巨大矛盾。儘管如此，很多普通員工卻面臨着裁員的壓力。微軟最近裁減了 9100 個職位，企圖通過精簡運營將資源重分配到 AI 轉型上。這種趨勢在整個科技行業中普遍存在，形成了一個新的高薪專家階層，同時擠壓了大批普通員工的生存空間。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361921</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361921</guid>
      <pubDate>Wed, 23 Jul 2025 07:06:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達發佈 OpenReasoning-Nemotron 系列推理模型，專注於數學、科學和代碼</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;NVIDIA 發佈了 OpenReasoning-Nemotron，這是由四個精簡的推理模型組成的集合，參數分別為 15 億、70 億、140 億和 320 億，均源自擁有 671 億參數的 DeepSeek R1 0528。通過將龐大的「老師」模型壓縮成四個基於 Qwen-2.5 的「學生」模型，NVIDIA 使得即使在標準遊戲設備上也能進行高級推理實驗，而無需擔心高昂的 GPU 費用和雲使用量。&lt;/p&gt; 
&lt;p&gt;這些模型在數學、科學和代碼等多個推理基準測試中，均在其各自的規模級別上達到了業界領先水平。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/145755_fzqJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;https://huggingface.co/blog/nvidia/openreasoning-nemotron&lt;br&gt; https://nvidia.github.io/NeMo-Skills/releases/openreasoning/&lt;br&gt; https://huggingface.co/collections/nvidia/openreasoning-nemotron-687730dae0170059860f1f01&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;關鍵不在於複雜的技巧，而在於原始數據。NVIDIA 使用 NeMo Skills 流水線生成了 500 萬個數學、科學和代碼解決方案，然後通過純粹的監督學習對每個解決方案進行微調。目前，320 億參數的模型在 AIME24 上獲得了 89.2 分，在 HMMT 二月競賽中獲得了 73.8 分，而即使是 15 億參數的版本也取得了 55.5 分和 31.5 分的穩定成績。&lt;/p&gt; 
&lt;p&gt;NVIDIA 設想將這些模型打造為強大的研究工具包。所有四個檢查點均可在 Hugging Face 上下載，為探索強化學習驅動的推理或針對特定任務定製模型奠定堅實的基礎。使用 GenSelect 模式（每個問題進行多次迭代），可以生成多個並行生成並選出最佳答案，從而使 32B 模型的性能達到卓越水平，在多個數學和編碼基準測試中堪比甚至超越 OpenAI 的 o3-high 性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ed39ae4f4d16b16bc9163d29c2687756b43.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;由於 NVIDIA 僅使用監督微調訓練這些模型，而未使用強化學習，因此社區擁有清晰、先進的未來強化學習實驗起點。對於遊戲玩家和家庭愛好者來説，如果您擁有更強大的遊戲 GPU，我們將獲得一個完全本地化的模型，該模型可以非常接近最先進的水平。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361915/nvidia-openreasoning-nemotron</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361915/nvidia-openreasoning-nemotron</guid>
      <pubDate>Wed, 23 Jul 2025 07:01:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>jemalloc 作者自述：開發已陷入停滯</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;jemalloc 內存分配器最初於 2004 年初構思，並且現在已公開使用了大約 20 年。由於開源軟件許可的性質，jemalloc 將無限期地保持公開可用。但積極的上游開發已結束。本文簡要描述了 jemalloc 的發展階段，每個階段都有成功/失敗的亮點，隨後是一些回顧性的評論。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;階段 0：Lyken&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2004 年，我在科學計算的背景下開始開發 Lyken 編程語言。Lyken 最終成為了死衚衕，但其手動內存分配器在 2005 年 5 月已經功能完整。（本應利用其功能的垃圾收集器從未完成。）2005 年 9 月，我開始將分配器集成到 FreeBSD 中，並在 2006 年 3 月，為了使用線程特定數據和 dlsym(3) 實現的薄封裝，我從 Lyken 中移除了分配器。&lt;/p&gt; 
&lt;p&gt;在投入了這麼多精力之後，為什麼又要從 Lyken 中移除內存分配器呢？一旦將分配器集成到 FreeBSD 後，就明顯發現系統分配器的唯一缺失功能是跟蹤分配量的機制，以便觸發線程垃圾收集。而這可以通過使用線程特定數據和 dlsym(3) 的薄封裝來實現。有趣的是，多年後，jemalloc 甚至添加了 Lyken 需要的統計收集功能。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;階段 1：FreeBSD&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2005 年，多處理器計算機的轉變正在進行中。FreeBSD 擁有 Poul-Henning Kamp 的出色 phkmalloc 內存分配器，但該分配器沒有並行線程執行的機制。Lyken 的分配器似乎是一個明顯的可擴展性改進，經過朋友和同事的鼓勵，我將它快速集成到了眾所周知的 jemalloc 中。但等等！在集成後不久，就發現 jemalloc 在某些負載下有嚴重的碎片問題，尤其是由 KDE 應用程序引起的。正當我以為已經差不多完成時，這個現實世界的失敗質疑了 jemalloc 的可行性。&lt;/p&gt; 
&lt;p&gt;簡而言之，碎片問題是由於使用了統一的範圍分配方法（即沒有大小類區分）。我從 Doug Lea 的 dlmalloc 獲得了一些基本靈感，但沒有那些複雜的、經過實戰測試的啓發式方法來避免許多最嚴重的碎片問題。隨後進行了大量的研究和實驗。當 jemalloc 成為 FreeBSD 發佈的一部分時，其佈局算法完全改變了，採用了大小分組的區域，如 2006 年 BSDCan 的 jemalloc 論文所述。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;階段 1.5：Firefox&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2007 年 11 月，Mozilla Firefox 3 即將發佈，高碎片化問題仍未解決，尤其是在微軟 Windows 上。於是開始了與 Mozilla 合作的一年內存分配工作。將 jemalloc 移植到 Linux 幾乎微不足道，但 Windows 卻不一樣。當時 jemalloc 的源代碼在 FreeBSD 的 libc 庫中，所以我們基本上對 jemalloc 進行分叉，並添加了可移植性代碼，將任何對 FreeBSD 相關的內容向上遊提交。整個實現仍然在一個文件中，這減少了分叉維護時的摩擦，但該階段的實現複雜性顯然超過了合理範圍。&lt;/p&gt; 
&lt;p&gt;多年後，Mozilla 開發者為了擺脫他們的分叉，對上游的 jemalloc 做出了重大貢獻。不幸的是，Mozilla 的基準測試一直顯示，分叉版本比上游版本表現得更好。我不確定這是因為對局部最優的過度擬合還是性能迴歸的真正跡象，但這是我對 jemalloc 最大的失望之一。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;階段 2：Facebook&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2009 年我加入 Facebook 時，我驚訝地發現，阻礙 jemalloc 在 Facebook 基礎設施中普遍使用的主要障礙是儀器設備。關鍵的內部服務陷入了尷尬的境地，它們依賴 jemalloc 來控制內存碎片，但工程師們需要使用 tcmalloc 和 gperftools 中的 pprof 堆分析工具來調試內存泄漏。pprof 兼容的堆分析功能成為了 jemalloc 1.0.0 發佈的主要亮點。&lt;/p&gt; 
&lt;p&gt;jemalloc 開發遷移到 GitHub，並在接下來的幾年裏隨着問題和機遇的出現而繼續進行。其他開發者也開始做出重要的功能貢獻。3.0.0 版本引入了廣泛的測試基礎設施以及 Valgrind 支持。4.x 版本系列引入了基於衰減的清除功能和 JSON 格式的遙測。5.x 系列從「塊」轉向「範圍」，為更好地與 2 MiB 大頁進行交互做好準備。&lt;/p&gt; 
&lt;p&gt;較為有爭議的是，我在 5.0.0 版本中移除了 Valgrind 支持，因為這是一項重大的維護複雜性問題（在微妙的地方有很多分支），而且在 Facebook 內部未被使用；其他工具如 pprof 和 MemorySanitizer 佔據主導地位。我幾乎沒有收到關於 Valgrind 支持的反饋，因此推斷它未被使用。但回顧起來，這似乎並非如此。特別是，Rust 語言直接將 jemalloc 整合到編譯的程序中，而我認為 Rust 開發者和 Valgrind 開發者之間有某種重疊。人們感到憤怒。jemalloc 可能比自然發展進程更快地被踢出了 Rust 二進制文件。&lt;/p&gt; 
&lt;p&gt;Facebook 的內部遙測非常壯觀，擁有各種服務的性能數據，這對內存分配器的開發是非常寶貴的。我不認為在過去的十年中，最快內存分配器之一（tcmalloc 和 jemalloc）受益於如此數據是巧合。即使是像快速路徑優化這樣的「簡單」事情，當有彙總的 Linux perf 數據可用時，也更容易正確執行。像碎片管理這樣的困難事情仍然困難，但如果數千種不同的工作流表現良好，沒有異常的迴歸，那麼更改可能是安全的。jemalloc 在 Facebook 基礎設施中受益匪淺，從性能、彈性到一致的行為。此外，jemalloc 自身的集成統計數據報告功能正是應對這種普遍遙測環境而直接誕生的，這在實現上花費的精力不多，但對 jemalloc 開發和非 Facebook 應用程序的調優/調試普遍帶來了巨大的好處。&lt;/p&gt; 
&lt;p&gt;在我在 Facebook 的最後一年，我被鼓勵組建一個小的 jemalloc 團隊，以便我們可以解決一些原本令人生畏的重要任務。除了重大的性能改進，我們還獲得了持續集成測試和全面的遙測功能。當我 2017 年離開 Facebook 時，jemalloc 團隊繼續出色地進行開發和維護工作多年，幾乎完全不涉及我的參與，由我尊敬的同事王歧領導，並且從提交歷史來看，也有許多其他人的出色貢獻。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;階段 3：Meta&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Facebook 更名為 Meta 的時期，jemalloc 的開發趨勢明顯發生了變化。Facebook 基礎設施工程減少了核心科技的投資，而是強調投資回報率。這在 jemalloc 的提交歷史中顯而易見。特別是，有原則的巨型頁面分配（HPA）的種子早在 2016 年就已經埋下！HPA 工作持續了幾年，然後在不斷的調整中放緩，並逐漸停滯，因為沒有進行必要的重構來保持代碼庫的健康。這個特徵路線最近崩潰了。對我而言，有些傷心，但我已經多年未密切參與，因此情感上的衝擊被減弱了。但鑑於 Meta 內部近期的變化，我們現在沒有人能推動長期的 jemalloc 開發，注重通用性。&lt;/p&gt; 
&lt;p&gt;我不打算深入討論這些紛爭，但也許值得一提的是，儘管涉及的大多數人都出於善意，但最終 jemalloc 在 Facebook/Meta 手中走向了令人遺憾的結局。企業文化會隨着外部和內部壓力而變化。而人們經常發現自己處於無法解決的困境中，主要的選擇是 1）在極端壓力下做出糟糕的決定，2）在極端壓力下服從，或者 3）被繞開。作為個人，我們有時有足夠的影響力來減緩組織的退化，甚至可能在局部復興，但我們無法阻止不可避免的事情。&lt;/p&gt; 
&lt;p&gt;我仍然非常感激我的前同事在 jemalloc 上的所有優秀工作，以及 Facebook/Meta 對它投入瞭如此多資源、如此長的時間。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;階段 4：停滯&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現在怎麼辦？就我而言，「上游」的 jemalloc 開發已經結束。Meta 的需求早已與外部使用的需求不一致，他們最好做自己的事情。如果我重新參與，第一步至少需要數百小時的重構以償還累積的技術債務。而我對之後可能帶來的東西並不足夠興奮以支付如此高昂的前期成本。也許其他人會創建可行的分支，無論是從 dev 分支還是從 5.3.0 版本（已經三年了！）。&lt;/p&gt; 
&lt;p&gt;在上述部分中，我提到了幾個特定階段的失敗，但還有一些一般性的失敗讓我感到意外，儘管我的職業一直專注於開源開發。&lt;/p&gt; 
&lt;p&gt;如前所述，移除 Valgrind 引起了某些負面情緒。但問題的根本在於對其他使用和需求缺乏意識。如果我早知道它對任何人來説都重要，我可能會與其他人一起保留 Valgrind 支持。另一個例子是，我完全不知道 jemalloc 作為 Android 內存分配器的使用，可能有兩年時間。而且，多年後，直到事後才知道它已被取代。&lt;br&gt; 即使 jemalloc 完全公開在外部（沒有在 Facebook 內部封存），該項目從未吸引到其他組織的主要貢獻者。Mike Hommey 推動 Firefox 遷移到上游 jemalloc 的努力是一個差一點的成功。其他人試圖遷移到基於 CMake 的構建系統也多次失敗，從未完成。我從與 Darwin 硬碰硬的經驗中知道，內部封存的開源項目無法繁榮（HHVM 是一個重複的例子），但 jemalloc 作為一個獨立項目，需要的不只是開放開發。&lt;/p&gt; 
&lt;p&gt;對我而言，jemalloc 是一項奇特的分心，因為我長期以來一直是垃圾收集的堅定支持者，而不是手動內存管理。我個人很高興再次投入到垃圾收集系統中，但 jemalloc 是一個令我非常滿足的項目。感謝所有讓這個項目變得如此有價值的人，包括合作者、支持者和用戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361911</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361911</guid>
      <pubDate>Wed, 23 Jul 2025 06:51:49 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Pika Labs 發佈首款純 AI 社交視頻應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Pika&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fpika_labs%2Fstatus%2F1947427650555023410" target="_blank"&gt;宣佈&lt;/a&gt;了其開發的首款完全基於 AI 的社交視頻應用，並已開放早期訪問，用戶可通過下載&amp;nbsp;iOS&amp;nbsp;應用加入等待名單。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1764" src="https://static.oschina.net/uploads/space/2025/0723/144812_Lkpt_2720166.png" width="1984" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://apps.apple.com/gb/app/pika-social-ai-video/id6744712684&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;Pika &lt;/span&gt;建立在一個「高度表現力的人類視頻模型」之上，&lt;span&gt;主打 AI 生成自拍視頻，用戶僅需一張自拍即可快速生成風格各異的視頻，如一鍵音畫同步（如生成唱歌、説唱、Vlog 等視頻），更換髮色、服裝、環境等外觀，對他人視頻進行混剪，以及 AI 自動生成 Talking Video 腳本等等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;經過幾周的內測後，Pika&amp;nbsp;現已開放早期訪問。用戶可以下載其&amp;nbsp;iOS&amp;nbsp;應用加入等待名單，或通過邀請碼直接獲得訪問權限。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361912</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361912</guid>
      <pubDate>Wed, 23 Jul 2025 06:51:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手聯合上交開源統一多模態生成理解模型 Orthus</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在今年的 ICML 上，快手聯合上海交通大學提出了一種支持圖文交錯生成的統一模型——Orthus，目前已開源。該模型基於自迴歸 Transformer 架構，能夠從文生圖、圖到文等不同任務學習有價值信號。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，僅使用極少的計算資源，Orthus 便在多個圖像理解指標上超越了現有混合理解生成模型 Chameleon 和 Show-o，並在文生圖生成的 GenEval 指標上優於專用擴散模型 SDXL。此外，Orthus 還展現出強大的圖文交錯數據建模能力，在圖像編輯和網頁生成任務中展現出巨大潛力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Orthus 具有以下核心特性：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自迴歸 Transformer 主幹；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;處理離散的文本 token 和連續的圖像 feature；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;基於線性層定義的 language head 和 diffusion MLP 定義的 image head 來分別生成文和圖；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;足夠計算高效。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;如下圖所示，項目團隊利用上述兩個 heads，將圖片細節的擴散建模從 Transformer 主幹中解耦。該設計使得主幹網絡能夠專注於刻畫文本與圖像特徵表示之間的關聯，而將圖像細節信號的恢復任務交由更專業的 diffusion head 完成。這樣解耦既緩解了圖像離散化表示帶來的信息損失，又避免了端到端擴散建模與自迴歸機制之間的分歧。本質上，Orthus 可以看作何愷明在圖像生成領域的工作&lt;/span&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.11838" target="_blank"&gt;MAR&lt;/a&gt;&amp;nbsp;&lt;span style="color:#000000"&gt;向多模態領域上的拓展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="261" src="https://oscimg.oschina.net/oscnet/up-3e5c3c4f44771f1655d2c0e7ac740d7f9c5.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;具體實現上，Orthus 由以下組件構成：一個文本分詞器、一個視覺自編碼器、兩個特定模態的嵌入模塊、一個 Transformer 主幹網絡和兩個特定模態的輸出頭。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;給定文本和圖像，Orthus 會將離散的文本 token（由文本分詞器生成）和連續的圖像特徵（由視覺自編碼器提供）嵌入到統一的表示空間中。在該空間內，自迴歸 Transformer 主幹負責建模模態內部（如文本-文本）及跨模態（文本-圖像）之間的相互依賴關係。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在主幹之上，Orthus 使用兩個模態特定的頭部來分別生成文本和圖像：一個是常規的語言建模線性頭，用於預測離散的文本 token；另一個是擴散 MLP 頭，用來生成連續的圖像特徵。在推理階段，Orthus 根據特殊標記的指示，自迴歸地預測下一個文本 token 或圖像 feature。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;span style="background-color:#ffffff"&gt;實驗結果表明，得益於 Orthus 對圖像的連續表示及擴散建模方法的優勢，Orthus 相較在同樣的數據設定下微調的 Chameleon 表現更佳。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="234" src="https://oscimg.oschina.net/oscnet/up-5842806691a566273a48e8c29c24d728245.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="130" src="https://oscimg.oschina.net/oscnet/up-9c510895543b1e84c96343f3a21dd47efc5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="129" src="https://oscimg.oschina.net/oscnet/up-ead8be4b204a40ca0cd61e1e7e5bdc6c02c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Ftr70YNC6xjXAuvTZO4-0Gw" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361910</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361910</guid>
      <pubDate>Wed, 23 Jul 2025 06:50:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>商湯科技將成立獨立的具身智能公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.leiphone.com%2Fcategory%2Fai%2FXfVFHlE91fPINqJk.html" target="_blank"&gt;根據雷峯網 AI 科技評論的獨家報道&lt;/a&gt;&lt;/u&gt;，商湯科技將成立獨立的具身智能公司，核心班底已經初步搭建起來，包括王曉剛、陶大程等視覺技術大咖，目前正在業內「招兵買馬」。&lt;/p&gt; 
&lt;p&gt;報道稱，商湯科技此前在 2025 技術交流日上展示了基於大裝置 SenseCore 2.0 訓練的具身智能成果——AI 超市「雙機協作」採購場景。活動現場，商湯也同傅利葉、松應科技兩家機器人公司達成了戰略合作。&lt;/p&gt; 
&lt;p&gt;據商湯大裝置事業羣業務人員透露，從 2024 年開始到今年，具身智能機器人領域的增量客戶明顯增多；為機器人本體企業訓練提供模型能力的生態合作成為商湯重要定位，其全流程 AI 研發體系能通過端到端一站式平台支持千機並行仿真訓練，為具身智能提供從開發到驗證的閉環支持。&lt;/p&gt; 
&lt;p&gt;此外，商湯還領投了眾擎機器人的天使輪系列，今年還在繼續參投其 Pre-A 輪。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361907</guid>
      <pubDate>Thu, 17 Jul 2025 06:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>FreeBSD 15.0 計劃提供 KDE 桌面安裝選項</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;致力於增強 FreeBSD 筆記本電腦支持的團隊希望在 FreeBSD 15 的安裝程序中增加一個安裝選項，以便輕鬆提供基於 KDE Plasma 的桌面環境。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1bc26da69e09b20573cb7a36008f563bb2a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，FreeBSD 台式機/筆記本電腦用戶需要進行基礎安裝，然後使用其控制枱啓動 FreeBSD 安裝程序，最後通過包管理系統安裝所需的桌面。&lt;/p&gt; 
&lt;p&gt;FreeBSD 15.0 計劃於今年晚些時候發佈，其希望將桌面選項集成到操作系統的文本安裝程序中，以提供基於 KDE Plasma 的桌面。&lt;/p&gt; 
&lt;p&gt;選擇圖形桌面選項時，KDE Plasma 6 將與 SDDM 顯示管理器一起安裝，以便在新的 FreeBSD 安裝中提供遠勝於現有桌面環境的出色桌面體驗。不過，這不如項目終止前 PC-BSD 和 TrueOS 等系統提供的體驗那麼好。&lt;/p&gt; 
&lt;p&gt;FreeBSD 筆記本電腦團隊在其每月狀態更新中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeBSDFoundation%2Fproj-laptop%2Fblob%2Fmain%2Fmonthly-updates%2F2025-06.md%23kde-desktop-installer-option" target="_blank"&gt;指出：&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;對於 FreeBSD 15.0，我們的目標是擴展 FreeBSD 安裝程序，使其能夠提供基於 KDE 的精簡桌面作為安裝選項。初始概念是採用低交互的安裝流程，安裝完成後，用戶將直接進入 KDE 圖形登錄屏幕。我們&lt;/p&gt; 
 &lt;p&gt;目前正在評估所需的 pkg 依賴項，以便自動選擇合適的顯卡驅動程序。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/143553_lbDx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原型設計希望為 FreeBSD 15.0 提供一個「最低限度」的桌面環境，供那些希望增強 FreeBSD 桌面/筆記本電腦用戶安裝過程的用戶使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361905</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361905</guid>
      <pubDate>Thu, 17 Jul 2025 06:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 為「深度研究」報告增加 docx 文件導出功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1947756508579828097" target="_blank"&gt;宣佈&lt;/a&gt;，用戶現在可以直接將 ChatGPT 生成的深度研究報告導出為 .docx 文件，該功能已在網頁版上線，並即將登陸移動應用。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1736" src="https://static.oschina.net/uploads/space/2025/0723/142623_3QYN_2720166.png" width="1290" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;深度研究（Deep Research）是 OpenAI 於 2025 年 2 月推出的一款 AI 研究代理，基於 o1 推理模型開發，專為處理複雜研究任務設計。該工具能夠自主瀏覽網絡，分析數百個在線來源然後進行信息整合，並在 5 至 30 分鐘內生成詳盡的研究報告，報告內容包含精準引用的網頁或 PDF 段落。與傳統的手動研究相比，這節省了大量時間。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361903</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361903</guid>
      <pubDate>Thu, 17 Jul 2025 06:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claude 移動端將支持「記憶」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 正在為 Claude 的移動端 APP 準備一次重大升級，將此前僅限於網頁版的功能引入其 iOS 應用。其中最引人注目的新增功能是未公開的&lt;strong&gt;跨聊天搜索和記憶（memory &amp;amp; recall）能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-42837ff4193bca74fce930bea993efe51cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與當前的移動版本不同，這項功能將使 Claude 能夠跨會話保留信息並引用之前的對話，這與 ChatGPT 及其他競爭對手中已有的「記憶」實現方式類似。雖然網頁版的 Claude 目前也不支持此功能，但其在 iOS 的代碼暗示着未來可能進行跨平台推廣。&lt;/p&gt; 
&lt;p&gt;這項功能對於依賴長期上下文或重複性任務的用戶，例如研究人員、專業人士和學生。通過記住相關細節，Claude 有可能演變為更可靠的助手，尤其適用於上下文依賴度高的工作流。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361902</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361902</guid>
      <pubDate>Thu, 17 Jul 2025 06:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 與 Oracle 簽下 300 億美元數據中心大單</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據《華爾街日報》的報道，OpenAI 與甲骨文（Oracle）達成了一項價值每年 300 億美元的數據中心服務協議。OpenAI 的首席執行官山姆・奧特曼在社交媒體上確認了這一合同的細節，但沒有透露具體的金額。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這項交易最初在 6 月 30 日由甲骨文在一份證券交易委員會的文件中披露，雖然當時並沒有透露客戶名稱和具體服務內容，但這一消息使甲骨文的股票飆升，創下歷史新高，創始人兼首席技術官拉里・埃裏森一度成為全球第二富豪。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="274" src="https://oscimg.oschina.net/oscnet/up-9080e8a3ccb262f7bb5138b2eaaaa5b874f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在這項交易達成後，外界紛紛猜測，究竟是什麼公司需要如此龐大的數據中心服務。根據甲骨文的財報，2025 財年該公司總共向所有客戶銷售的雲服務總額為 245 億美元。OpenAI 隨後解釋，這項與甲骨文的交易涉及 4.5 千兆瓦的電力容量，這是雙方在 1 月宣佈的價值 5000 億美元的數據中心建設項目 「星際之門」（Stargate）的一部分。值得注意的是，300 億美元的合同並不包括日本軟銀 (SoftBank)。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;《華爾街日報》指出，4.5 千兆瓦的電力容量相當於兩個胡佛水壩的輸出，足夠為約 400 萬家庭提供電力。然而，這並不是甲骨文的簡單勝利，OpenAI 與甲骨文仍需共同建設這一龐大的數據中心，這將是一項耗資巨大且能源消耗極大的工程。建設地點位於德克薩斯州的阿比林（Abilene）。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;與此同時，甲骨文在過去的財年中支出 212 億美元用於資本支出，預計今年將再花費 250 億美元。由此可見，在短短兩年內，甲骨文在數據中心上的支出接近 500 億美元，這一數字並未包含土地購買的費用。需要指出的是，這筆資金也用於支持甲骨文現有客戶的需求，而不僅僅是為了滿足 OpenAI 的要求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;有趣的是，奧特曼最近透露，OpenAI 的年度經常性收入已達到 100 億美元，較去年約 55 億美元的水平有了顯著增長。這一與甲骨文的合同，已是目前 OpenAI 年收入的三倍多，而不包括公司其他開支和現有數據中心的承諾。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361900</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361900</guid>
      <pubDate>Thu, 17 Jul 2025 06:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 贏得商標訴訟，阻止競爭對手使用 Open AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;OpenAI 在與一家名為 Open AI（兩者之間有空格）的公司之間的商標爭議中獲得了勝利。法院裁定，Open AI 在申請商標註冊時存在誤導性行為，意圖混淆消費者，造成與 ChatGPT 的製造商之間的虛假關聯。根據裁定，Open AI 需要停止使用其名稱和互聯網域名 open.ai。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-cbe3bb3b907ab6fd11df1f9a6e137fb2a94.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Open AI 公司在 OpenAI 推出產品之前，就已經提前獲得了 open.ai 的域名。此次裁決不僅僅是對 Open AI 名稱的限制，還意味着它將失去該域名的使用權。法庭認為，OpenAI 在其發展過程中 「漂移」 到了 Open AI 的市場領域，並在品牌形象上造成了一定的重疊。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這一判決對於 OpenAI 來説無疑是個利好消息，進一步鞏固了其在人工智能領域的市場地位。OpenAI 表示，他們將繼續保護自己的商標和品牌，確保消費者能夠清晰地辨別不同公司的產品。OpenAI 的法律團隊強調，商標的獨特性對於公司和消費者都至關重要，而任何模糊或誤導性的名稱都會對市場造成混亂。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次事件也提醒其他科技公司在品牌命名和商標註冊方面需更加謹慎，確保不會侵犯他人的商標權益。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361878</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361878</guid>
      <pubDate>Thu, 17 Jul 2025 03:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2025 年中 CNCF 前 30 個開源項目回顧</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;CNCF 首席技術官 Chris Aniszczyk 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2025%2F07%2F18%2Fa-mid-year-2025-look-at-cncf-linux-foundation-and-the-top-30-open-source-projects%2F" target="_blank"&gt;發佈&lt;/a&gt;了一篇名為「2025 年中展望 CNCF、Linux 基金會和排名前 30 的開源項目」的文章，並分析得出以下一些要點內容：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Kubernetes 仍然是擁有最多貢獻者的項目，體現了其持續成熟和廣泛採用。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;OpenTelemetry 貢獻者數量持續增長，依然是 CNCF 中速度第二快的項目，已成為觀測（o11y）領域的「Kubernetes」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Backstage 解決了開發者體驗的痛點，成為全球最受歡迎的開源內部開發者門戶（IdP）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;GitOps 依然是雲原生生態的重要組成部分，Argo 和 Flux 等項目培育了龐大的社區。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Crossplane 過去一年貢獻者增長超過 20%，顯示了開源控制平面和多雲管理的需求。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Kubeflow 進入了 CNCF 前 30 項目名單，凸顯了 CNCF 項目在支持大規模 AI 基礎設施中的作用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" height="329" src="https://oscimg.oschina.net/oscnet/up-05b106cedab37d27080c40226eadd31ed42.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;em&gt;注：使用了氣泡圖展示三個維度的數據：提交數、貢獻者數和評論/拉取請求數，採用對數-對數座標圖以覆蓋大規模數據。&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;氣泡麪積與貢獻者數量成正比&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Y 軸代表拉取請求和問題的總數&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;X 軸代表提交數&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;span style="color:#000000"&gt;所有&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcncf%2Fvelocity%23current-reports" target="_blank"&gt;&lt;strong&gt;當前&lt;/strong&gt;&lt;/a&gt;和&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcncf%2Fvelocity%23past-reports" target="_blank"&gt;&lt;strong&gt;過去的&lt;/strong&gt;&lt;/a&gt;報告都可以在 GitHub 上找到。所有用於生成此數據的腳本均位於&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcncf%2Fvelocity" target="_blank"&gt;&lt;strong&gt;https://github.com/cncf/velocity&lt;/strong&gt;&lt;/a&gt;（遵循 Apache 2.0&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2017%2F02%2F01%2Fcncf-recommends-aslv2%2F" target="_blank"&gt;&lt;strong&gt;許可&lt;/strong&gt;&lt;/a&gt;）。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361874/a-mid-year-2025-cncf-top-30-open-source-projects</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361874/a-mid-year-2025-cncf-top-30-open-source-projects</guid>
      <pubDate>Thu, 17 Jul 2025 03:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>技術賦能信任合作｜埃塞俄比亞某銀行客戶到訪綠盟科技</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;近日，埃塞俄比亞某銀行客戶代表團深度走進綠盟科技，圍繞 Web 應用防火牆（WAF）與智能安全運營平台（ISOP）開展專項培訓與交流。通過參觀展廳、技術演示與現場互動，代表團系統瞭解了綠盟科技在智能化安全運營與全球服務交付方面的綜合能力。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;此次來訪，不僅加深了客戶對中國網絡安全方案的信任，也為雙方後續的合作奠定了更堅實基礎。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 1.jpg" height="400" src="https://oscimg.oschina.net/oscnet//164649fd1d4c8dfc7cfedccd94e1c99b.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;該銀行已成立三十多年，是埃塞俄比亞重要的金融機構之一，在全國範圍內擁有廣泛的業務網絡，始終以「成為埃塞俄比亞銀行業卓越典範」為願景，致力於通過高效服務滿足客戶不斷變化的需求，在埃塞俄比亞金融領域佔據重要地位。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;客戶代表團首先參觀了綠盟科技總部展廳。國際團隊系統介紹了公司在安全產品體系、服務能力與技術演進方面的整體佈局，重點展示了在安全研究領域的持續投入與關鍵成果，並詳細講解了覆蓋全生命週期的服務能力，如何通過定製化方案，幫助全球客戶應對日益複雜的安全挑戰。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;交流中，國際團隊重點解讀了綠盟科技智慧安全 3.0 理念，深入闡釋「全場景、可信任、實戰化」的安全運營能力。該理念依託威脅情報與大數據、AI 技術的深度融合，結合 SOAR（安全編排自動化與響應）的編排及自動化能力，實現「場景化防護、智能化分析、自動化響應」的防護效果：通過大數據挖掘潛在威脅，藉助 AI 提升檢測與預警精準度，再以 SOAR 推動安全事件的快速響應，形成閉環防護體系。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 2.jpg" height="400" src="https://oscimg.oschina.net/oscnet//4575803f3e3a6ab88cd2891a754755c0.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 3.jpg" height="400" src="https://oscimg.oschina.net/oscnet//199a99669b2ab4297a50d1979da2640e.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;客戶隨後參觀了綠盟科技鷹眼安全運營中心。工程師代表系統展示了在攻擊面監測、威脅檢測響應、情報運營、漏洞預警及應急管理等方面的核心能力，並現場演示了 AI 驅動的自動化安全運營流程。憑藉海量數據採集與實時監控能力，綠盟 SOC 可實現對網絡威脅的快速發現與高效聯動處置，為客戶業務連續性提供有力保障。交流過程中，客戶代表團全神貫注，現場體驗智能安全體系的實戰能力，並對綠盟科技的專業實力給予了高度認可。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 4.jpg" height="450" src="https://oscimg.oschina.net/oscnet//5edfa3ac8f5305967e86590f23614887.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;通過系統培訓，客戶代表團全面掌握了 Web 應用防火牆（WAF）與智能安全運營平台（ISOP）的核心理念與操作技能，並順利通過考覈，獲得培訓證書。此次交流不僅加深了雙方在技術層面的互信，也為後續合作打開了更廣闊的空間。未來，綠盟科技將持續以可靠技術與專業服務，攜手更多國際夥伴，共同應對數字化時代的安全挑戰，推動構建開放、可信、可持續的全球網絡安全生態。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 5.jpg" height="450" src="https://oscimg.oschina.net/oscnet//092c2e3dc844cdb0dcefe41fbd26a18f.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 6.jpg" height="450" src="https://oscimg.oschina.net/oscnet//f613438fbb445f91f222d89c7cba759d.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361873</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361873</guid>
      <pubDate>Thu, 17 Jul 2025 03:05:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>綠盟科技受邀出席 2025 中國聯通合作伙伴大會網絡安全共鏈行動生態論壇</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="text-align:left"&gt;近日，2025 中國聯通合作伙伴大會網絡安全共鏈行動生態論壇在上海召開。本次論壇以「向實同行，共創安全新生態」為主題，旨在通過積極佈局人工智能重點領域，進一步凝聚網絡安全產業鏈共識，共建產業融通生態，推動網絡安全產業高質量發展。作為中國聯通重要合作伙伴，綠盟科技受邀參會，集團副總裁宮智代表出席。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 7.jpg" height="400" src="https://oscimg.oschina.net/oscnet//7ffc70da89f5ad5b600e94fd787ceb5a.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;大會現場，中國聯通與各方代表共同發起「網絡安全現代產業鏈共鏈行動倡議」，期望通過壯大產業鏈力量，共建新機制，共築新基礎，共享新成果，共創新生態，共謀新發展。綠盟科技集團副總裁宮智受邀出席倡議儀式。作為網絡安全領域的深耕者，綠盟科技願與中國聯通及產業鏈合作伙伴攜手前行，凝聚共識，繪製網絡安全產業鏈的發展藍圖，推動網絡安全產業向新發展。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;一直以來，綠盟科技與中國聯通保持着密切的合作關係，雙方在 SAAS 安全、數據安全、態勢感知、漏洞管理、加密流量威脅分析等領域精誠合作，成效顯著。未來，面對數字化浪潮下的安全新挑戰，綠盟科技將在共鏈行動倡議下，進一步深化與中國聯通及其他產業鏈夥伴的合作，持續加大研發投入，積極探索 AI 安全、數據安全、供應鏈安全等前沿技術在網絡安全領域的創新應用，助力提升整個產業鏈的安全防護能力；同時，綠盟科技將積極參與產業鏈生態活動，與各方共享資源，共創價值，為構建更加完善、更加穩固的網絡安全產業生態貢獻力量。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361872</guid>
      <pubDate>Thu, 17 Jul 2025 03:04:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
  </channel>
</rss>
