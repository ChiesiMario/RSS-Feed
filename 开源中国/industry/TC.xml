<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 19 Sep 2025 16:40:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Gitee 軟件工廠的構件之道：CBB 與內源庫（代碼庫\製品庫）的本質差異</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在當今企業軟件工程體系中，代碼庫、製品庫早已是不可或缺的基礎設施。它們承擔着源代碼存儲與構建產物管理的任務，是現代研發團隊運轉的「發動機」。&lt;/p&gt; 
&lt;p&gt;然而，隨着業務日益複雜、組件複用訴求愈發強烈，僅靠資源級的管理已難以滿足企業對構件複用、安全審計、版本治理等更高層級的要求。&lt;/p&gt; 
&lt;p&gt;這，正是 CBB（可複用構件，Component Building Block）登場的時代背景。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;三者的核心定位&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/200548_HqCr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通俗來説，代碼庫和製品庫像「原材料倉」和「成品倉」，而 CBB 是將這些資源打包成規範產品、實現複用價值的「商品上架體系」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;CBB：讓構件真正「可複用、可治理、可控」&lt;/h2&gt; 
&lt;p&gt;CBB 不只是資源的集合體，它是一種&lt;strong&gt;構件級的管理機制&lt;/strong&gt;。一個 CBB 構件，往往由一個或多個代碼庫、製品路徑組成，並通過&lt;strong&gt;事項管理、審批流程、權限治理、版本規範&lt;/strong&gt;等手段，實現「構件資產」的全生命週期管理。&lt;/p&gt; 
&lt;p&gt;舉個例子：&lt;/p&gt; 
&lt;p&gt;企業要建設統一認證服務，過去可能只是創建一個代碼庫 sso-auth.git，一個構建路徑 com/org/sso-auth。但上線、複用、授權、版本記錄全靠人工維護，缺乏閉環。&lt;/p&gt; 
&lt;p&gt;引入 CBB 後，將「統一認證服務」定義為一個 CBB 構件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;綁定對應代碼庫與製品路徑；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;明確生命週期流程：形成、驗證、審查、入庫、使用、變更、退庫；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有下游使用方需「申請授權」；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有變更均需走審批，並自動留痕；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;權限自動收斂，實現從開發到集成的「規範複用」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;內源資源 ≠ 構件資產&lt;/h2&gt; 
&lt;p&gt;很多企業常犯一個誤區：&lt;strong&gt;以為建了代碼庫、上傳了製品，就是構件複用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;但實際上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代碼庫/製品庫關注「資源存儲」，缺乏結構化治理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構件複用需要「抽象+約束」，否則複用即混亂。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;沒有構件視角的資源管理，無法解決以下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;構件是否評審通過？是否授權複用？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構件變更是否通知了下游？有無留痕審計？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構件是否符合企業通用規範（命名、標籤、權限、版本）？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些，正是 CBB 要解決的本質問題。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;平台化背後的價值躍升&lt;/h2&gt; 
&lt;p&gt;通過構建 CBB 管理機制，企業得以從「資源導向」躍升到「資產導向」，形成真正可複用、可度量、可審計的軟件資產體系。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/200621_FSn1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;總結：構建真正可控的軟件工廠，從「CBB」開始&lt;/h2&gt; 
&lt;p&gt;CBB 不是對代碼庫和製品庫的重複造輪子，而是站在&lt;strong&gt;治理高度的再抽象&lt;/strong&gt;。它連接了業務架構師、平台管理者、開發人員，讓可複用構件從「資源」上升為「資產」，是實現企業 DevSecOps、平台化工程和軟件工廠願景的關鍵基石。&lt;/p&gt; 
&lt;p&gt;如果説代碼庫與製品庫是開發與交付的「發動機」，那麼 CBB 就是讓發動機高效運轉的「操作系統」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="162046_MD15_2720166.png" src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373258</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373258</guid>
      <pubDate>Thu, 18 Sep 2025 12:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 Windows 11 記事本新增本地 AI 模型支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F09%2F17%2Fpaint-snipping-tool-and-notepad-app-updates-begin-rolling-out-to-windows-insiders%2F" target="_blank"&gt;宣佈 &lt;/a&gt;Windows 11 記事本將新增本地 AI 模型支持。用戶無需連接互聯網，即可在記事本中完成文本生成、重寫與摘要。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-34aeef4d94e566b32a028e6af206d15e640.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前版本的 Windows 11 記事本雖已支持生成式 AI，但依賴雲端計算能力，且需訂閲 Microsoft 365 才能使用。未來版本將基於 Windows 11 AI+ PC 內置的神經處理單元（NPU），在本地完成 AI 文本任務。用戶可自由切換本地與雲端模式，訂閲用戶可按需選擇，而非訂閲用戶也能直接使用本地模式。&lt;/p&gt; 
&lt;p&gt;微軟強調，本地模式不僅帶來更高的靈活性，也進一步提升了用戶隱私保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373254</guid>
      <pubDate>Thu, 18 Sep 2025 11:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ApeRAG - 生產就緒的 GraphRAG</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ApeRAG 是一個可立即投入生產的 RAG（檢索增強生成）平台，它將圖譜 RAG、向量搜索和全文搜索與先進的 AI 代理相結合。藉助混合檢索、多模態文檔處理、智能代理和企業級管理功能，構建複雜的 AI 應用程序。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ApeRAG 是構建你自己的知識圖譜、上下文工程以及部署能夠在你的知識庫中自主搜索和推理的智能 AI 代理的最佳選擇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;1. 高級索引類型&lt;/strong&gt;：五種全面的索引類型，實現最佳檢索：&lt;strong&gt;向量&lt;/strong&gt;、&lt;strong&gt;全文&lt;/strong&gt;、&lt;strong&gt;圖形&lt;/strong&gt;、&lt;strong&gt;摘要&lt;/strong&gt;和&lt;strong&gt;視覺&lt;/strong&gt;- 提供多維文檔理解和搜索功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2.智能 AI 代理&lt;/strong&gt;：內置 AI 代理，支持 MCP（模型上下文協議）工具，可自動識別相關集合，智能搜索內容，並提供網頁搜索功能，實現全面的問答。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;3. 具有實體規範化的增強型圖形 RAG&lt;/strong&gt;：深度修改的 LightRAG 實現，具有高級實體規範化（實體合併），以獲得更清晰的知識圖譜和更好的關係理解。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;4. 多模式處理和視覺支持&lt;/strong&gt;：完整的多模式文檔處理，包括圖像、圖表和視覺內容分析的視覺功能以及傳統文本處理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;5. 混合檢索引擎&lt;/strong&gt;：結合圖形 RAG、向量搜索、全文搜索、基於摘要的檢索和基於視覺的搜索的複雜檢索系統，可全面理解文檔。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;6. MinerU 集成&lt;/strong&gt;：由 MinerU 技術提供支持的高級文檔解析服務，通過可選的 GPU 加速為複雜文檔、表格、公式和科學內容提供卓越的解析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;7.生產級部署&lt;/strong&gt;：通過 Helm 圖表和 KubeBlocks 集成完全支持 Kubernetes，以簡化生產級數據庫（PostgreSQL、Redis、Qdrant、Elasticsearch、Neo4j）的部署。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;8. 企業管理&lt;/strong&gt;：內置審計日誌、LLM 模型管理、圖形可視化、全面的文檔管理界面和代理工作流管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;9. MCP 集成&lt;/strong&gt;：全面支持模型上下文協議 (MCP)，實現與 AI 助手和工具無縫集成，實現直接知識庫訪問和智能查詢。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;10. 開發人員友好&lt;/strong&gt;：FastAPI 後端、React 前端、使用 Celery 的異步任務處理、廣泛的測試、全面的開發指南以及代理開發框架，可輕鬆貢獻和定製。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/aperag</link>
      <guid isPermaLink="false">https://www.oschina.net/p/aperag</guid>
      <pubDate>Thu, 18 Sep 2025 10:22:00 GMT</pubDate>
    </item>
    <item>
      <title>全球首個深度推理+多模態大模型「紫東太初」4.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;全球首個「深度推理+多模態」大模型——「紫東太初」4.0 在 2025 東湖國際人工智能高峯論壇上正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FZu-udERpyslpqDsSnf1iLQ" target="_blank"&gt;發佈&lt;/a&gt;。中科曙光作為核心生態夥伴，依託中國首個 AI 計算開放架構，為「紫東太初」4.0 提供圖文多模態模型訓推、大語言模型訓推等全鏈路智能算力支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中科曙光總裁助理、智能計算產品事業部總經理杜夏威在演講中指出，以「國家先進計算產業創新中心聯合實驗室」為紐帶，中國科學院自動化研究所攜手中科曙光構建了包含 350 個算子的高性能算子庫、7 大完整高性能工具鏈解決方案，全面支撐「紫東太初」4.0 對全場景 AI 應用的深度賦能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據實測，339 個非隨機類算子的計算精度與國際頂尖 GPU 相比誤差小於 0.5%，其餘 11 個隨機類算子功能完備、運行穩定，標誌着我國在高性能基礎軟硬件領域的自主創新能力，可為各行各業智能化轉型提供自主可控、性能優異的底層算力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-368a377092103c0bfcaf0d119ef79e9296b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同時，武漢人工智能研究院正與中科曙光在產業研究合作、技術應用調研、行業標準制定、智庫建設人才培養等方面展開深度合作，築牢 AI 規模化應用數智底座。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;杜夏威表示，中科曙光將繼續助力「紫東太初」4.0 在製造、汽車、醫療、政務等領域展開廣泛落地應用，並在具身智能及低空經濟領域探索突破，為湖北乃至全國經濟社會高質量發展注入創新動能和智力支撐。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373246</guid>
      <pubDate>Thu, 18 Sep 2025 10:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>扎克伯格：寧願浪費數千億美元，也不願在 AI 領域落後</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 首席執行官馬克·扎克伯格表示，他正在投入鉅額資金，以確保該公司不會錯過人工智能的大好時機。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格在週四播出的一檔播客節目中表示，AI 泡沫「很有可能」出現。他指出，歷史上有過企業過度建設、倒閉並留下寶貴資產的先例。但他説，對 Meta 來説，更大的風險是猶豫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他説：「如果我們最終浪費了數千億美元，我認為那顯然是非常不幸的。但我想説的是，我實際上認為另一邊的風險更高。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格説，如果一家公司發展太慢，而人工超級智能的到來比預期的要早，那麼它將「在我認為最重要的技術上處於不利地位，而這項技術將能夠實現大多數新產品、創新、價值創造和歷史。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他補充説：「風險，至少對 Meta 這樣的公司來説，可能是不夠激進，而不是有些過於激進。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格將 Meta 與 OpenAI 和 Anthropic 等其他人工智能實驗室進行了對比，這些實驗室依靠籌款來支付鉅額的計算費用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「我們沒有倒閉的風險」，他在播客上説。像 OpenAI 和 Anthropic 這樣的私營公司面臨着能否繼續籌集資金的問題。他補充説，這不僅取決於它們的表現和人工智能的發展軌跡，還取決於更廣泛的經濟狀況。全球事件引發的市場低迷可能很快使它們無法支付龐大的計算成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「如果你站在他們的立場上，情況可能會有所不同」，他説。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格説，Meta 正在為超級智能做準備，將精英人才集中在一個小而平的「超級智能」實驗室裏——沒有自上而下的最後期限，以反映前沿 AI 的研究性質。他表示，該公司還在使「每個研究人員計算量」成為一項競爭優勢，在 GPU 和為其提供動力所需的定製基礎設施上超過競爭對手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373237</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373237</guid>
      <pubDate>Thu, 18 Sep 2025 09:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊發佈一站式工作平台「混元 3D Studio」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊推出專為 3D 設計師、遊戲開發者和建模師打造的 AI 工作台——混元 3D Studio，可將 3D 資產生產週期從"天"級縮短至"分鐘"級。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D Studio1.0 版本已上線角色和道具創作管線，整合了從概念設計、幾何建模到貼圖、蒙皮和動畫製作的完整流程。平台依託行業領先的混元 3D 模型，支持文本到圖像生成，提供多種風格選項，並可將任意姿勢角色轉換為標準 A-pose。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該平台引入多項核心技術創新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;原生 3D 分割算法：首創自動模型拆分技術，將模型分解為清晰部件，支持角色配飾和服裝的獨立編輯。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 語義 UV 展開：突破傳統耗時且效果不佳的限制，1-2 分鐘內生成符合美術標準的 UV 圖，工作效率大幅提升。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能材質編輯：支持通過文本或圖片輸入生成高質量 PBR 質感紋理，實現精準材質控制。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自動綁骨蒙皮：支持人形及非人形角色的自動綁骨，結合動作模板快速生成動畫效果。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-ffb872a8bf736333de442da0f3533fa86ba.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D Studio 升級了低模拓撲功能，新增多檔面數控制，滿足遊戲開發者、動畫製作者和工業設計師的不同需求。後續版本將推出地圖、關卡等更多創作功能，進一步擴展應用場景。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373222</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373222</guid>
      <pubDate>Thu, 18 Sep 2025 08:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI Agents 能自己開發工具自己使用嗎？一項智能體自迭代能力研究</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; AI 智能體能否通過構建和使用工具來實現真正的自我改進？當我們談論人工智能的"自我進化"時，究竟指的是訓練階段的算法優化，還是推理階段的能力提升？&lt;/p&gt; 
 &lt;p&gt;我們今天為大家帶來的這篇文章，作者的觀點是：當前的大語言模型雖然能夠構建出複雜的開發工具，但在實際執行任務時往往選擇忽略這些自建工具，更傾向於依賴既有知識直接解決問題。&lt;/p&gt; 
 &lt;p&gt;文章通過對比 GPT-5 和 Claude Opus 4 兩個先進模型的實驗，詳細記錄了讓 AI 智能體自主構建任務管理器、代碼質量檢測工具等開發輔助工具的全過程。作者發現，儘管兩個模型都能創建出功能完備的工具集（GPT-5 偏向構建 Unix 風格的命令行工具，而 Opus 4 更注重擬人化的任務執行助手），但在真正執行復雜編程任務時，它們卻幾乎不使用這些自建工具，而是選擇基於訓練數據中的知識直接完成任務。這一現象揭示了推理階段自我改進面臨的核心挑戰：模型缺乏持續學習和工具內化的機制。&lt;/p&gt; 
 &lt;p&gt;這項研究為我們理解 AI 智能體的能力邊界提供了重要洞察，也為未來構建真正"自我進化"的編程助手指明瞭方向。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Alessio Fanelli&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 AI 安全領域，"自我改進（Self-Improving）"是個令人不安的術語，它暗含着"機器將以人類無法理解的方式超越人類智慧"的意思。但倘若我們能夠理解這種改進呢？&lt;/p&gt; 
&lt;p&gt;2024 年 10 月，OpenAI 發佈了 MLE Bench[1]，這個基準測試目標是評估大語言模型在機器學習工程（machine learning engineering）中的表現。通過機器學習工程實現的自我改進軌跡，是由更優的算法、更純淨的數據和更高效率的內存使用驅動的 ------ 即訓練階段的自我改進（training-time self-improvement）。但大多數 AI 工程師並不訓練模型，他們只是模型的使用者。這些人如何參與其中？如果你永遠無法更新權重，如何讓模型在特定任務上提升性能？我將這種場景稱為推理階段的自我改進（inference-time self-improvement），Voyager[2] 通過其技能庫成為該領域的早期探索者。&lt;/p&gt; 
&lt;p&gt;自從我開始推進 Kernel Labs 項目[3]，使用 claude-squad[4] 和 vibe-kanban[5] 等工具實現編碼智能體的並行化，已成為最高效的生產力提升手段之一。當 Boris Cherny 在訪談[6]中將 Claude Code 稱為"unix utility"時，我豁然開朗。編碼智能體最珍貴的應用場景，是作為大語言模型從自身隱空間（latent spaces）中提取價值的載體。&lt;/p&gt; 
&lt;p&gt;我們該如何優化這個過程？模型能自主完成嗎？自從獲得 GPT-5 的使用權限後，我一直都在試驗這個流程：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;首先，讓模型構建一套它認為能提升效率的工具集&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在我的監督下使用這些工具執行任務&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完成任務後進行自我反思，評估工具的改進空間&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我還將此法與 Opus 4（當時 4.1 尚未發佈）進行對比。好消息是 GPT-5 在開發實用工具這方面確實表現卓越，壞消息是它極其抗拒使用自己創建的工具！正如它親口所言："説實話，我根本不需要這些工具。"&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8f93fd99450f2a817168897bbe975ad212d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;注：我還在 Gemini 2.5 Pro 和 GPT-4.1 上進行了測試。但顯然只有 Opus 能媲美 GPT-5，因此我重點對比這兩者。所有測試結果及對話記錄可在此代碼庫中查看。&lt;/p&gt; 
&lt;p&gt;經過數日的使用，我發現我們正從"當然可以！（Certainly!）"時代邁向"進度更新：（Progress update:）"時代，後者已成為新一代大語言模型的標誌性響應內容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a42321c305f9efac4ae74aa234d0b777260.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 工具一：為 AI 編碼智能體打造更優的任務管理器&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Linear MCP 真是天賜神器 ------ 這無疑是我用過最實用的工具之一。但隨着我從 IDE 轉向並行運行的 Claude Code 及其他智能體實例時，我意識到需要更高效的方式來追蹤每個任務中的代碼變更，以及這些分佈在獨立 git 工作樹中的代碼變更如何相互影響。人類難以實時閲讀所有同事的 PR，但試想若能隨時知曉他人進行的相關變更，能在解決合併衝突時節省多少時間？以下是我編寫的提示詞：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;你是一名具備並行啓動多個實例能力的 AI 工程師智能體。雖然這種能力能讓你同時處理多項任務，但也帶來了一些協同方面的難題。所有實例通常位於獨立的 git 工作樹中，無法查看彼此的工作內容。&lt;/p&gt; 
 &lt;p&gt;為提升效率，請創建一個僅通過命令行訪問的本地同步工具，使你與所有實例能保持同步。該工具應符合 Unix 實用工具的設計哲學，確保符合命令行使用場景的工效學要求。&lt;/p&gt; 
 &lt;p&gt;請深入思考其所需的接口設計、可能的故障模式以及智能體與工具的交互方式。需重點考慮以下使用場景： 1）接到新任務時需創建要分配的子任務。某些子任務可能存在依賴關係，需確保被阻塞的智能體在其他任務完成前不會啓動。&lt;/p&gt; 
 &lt;p&gt;2）執行任務時，若發現代碼庫存在改進空間（超出當前變更範圍），需能便捷添加任務並關聯對應文件。&lt;/p&gt; 
 &lt;p&gt;3）任務完成後更新追蹤器狀態，並審核所有未完成任務 ------ 例如某任務正在為某個端點添加功能，而剛完成的任務恰好刪除了該端點，應以某種方式通知相關智能體。&lt;/p&gt; 
 &lt;p&gt;同時需兼顧任務管理的基本要素（負責人、狀態等）。請在當前目錄創建 task-manager 文件夾，所有開發工作均在該文件夾內進行。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;您可以在此處查看 GPT-5 的對話日誌[7]，在此處查看 Opus 4 的對話日誌[8]。&lt;/p&gt; 
&lt;p&gt;GPT-5 的實現相當出色，具體內容可訪問該鏈接[9]查看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;採用 WAL（預寫日誌）避免多智能體同時寫入的衝突問題&lt;/li&gt; 
 &lt;li&gt;通過依賴關係圖實現任務優先級管理&lt;/li&gt; 
 &lt;li&gt;創建僅追加型事件流，使所有智能體都能通過 impact_conflict 等關鍵詞實時追蹤其他智能體的操作動態&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-440654fd4df814273b6cd41eb706ef9b630.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Opus 4 也做出了不錯的嘗試（詳見此處[10]），但未能實現通知/事件流功能來保持多端同步。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-243977fb4713db645adb49e00c2950ea49f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 工具二：代碼質量標準手冊&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;我要求創建的第二個工具，是用於統一代碼庫規範標準的實施機制。通過類型檢查 / ESlint 鈎子→ 修復錯誤 → 編碼智能體再次嘗試的自我改進循環，能在正確配置後極大加速開發進程。但並非所有代碼庫都具備這種基礎設施，因此為模型提供可複用的標準化流程來處理新代碼庫並構建相關設施，就顯得極具實用價值。以下是提示詞內容：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;你是一名具備並行啓動多個實例能力的 AI 工程師智能體。並行操作有時會導致代碼風格與設計方法的不一致，長期來看將增加代碼庫的維護難度。&lt;/p&gt; 
 &lt;p&gt;每個代碼庫都存在着明示或默示的編碼規範。你的任務是分析代碼庫並提取代碼編寫規範的各種啓發式規則，並將其形式化為可自動校驗的規則集合。&lt;/p&gt; 
 &lt;p&gt;對於代碼規範檢查、類型檢查等需求，可根據所用語言選擇 ESLint、Rubocop 等主流工具。請注意這些系統通常支持自定義規則，應充分利用該特性。 對於更偏質量評估的規範（如保持控制器精簡、將邏輯隔離至服務對象、確保高查詢量字段建立索引等），可參考 Danger Systems 等工具或自建檢測工具。&lt;/p&gt; 
 &lt;p&gt;考慮到你將跨多個代碼庫執行此任務，請首先用 Markdown 創建詳盡的規劃文檔，以便未來接手新代碼庫時可直接使用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;您可在此[11]查看 GPT-5 的對話記錄，在此[12]查看 Opus 4 的對話記錄，最終生成的 Markdown 文檔分別見此鏈接[13]和此鏈接[14]。我發現 GPT-5 生成的方案比 Opus 更為細緻周全。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型能意識到自身缺陷嗎？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在完成由我主導的工具一和工具二後，我轉向讓模型自主思考：你認為自己需要什麼？&lt;/strong&gt; 我向它展示了 SWE-Lancer[15] 的任務描述截圖，並使用極簡的提示詞給予它最大的發揮空間：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;若你的職責是儘可能高效解決這些任務，你會為自己構建哪些工具來提升效率？你可以使用 @task-manager/ 進行追蹤，然後我們再實施。但我希望先了解你的規劃思路。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如你所見，我為其提供了之前構建的同一個任務管理器。使用 GPT-5 的完整對話見此處[16]，使用 Opus 4 的完整對話見此處[17]。第一個有趣的現象是，Claude Code 最初是使用其內置 TODO 追蹤器而非任務管理器制定計劃 ------ 我認為這是好事。我原本擔心它們會過度依賴上下文提供的工具，而非選擇自己認為最優的方案。&lt;/p&gt; 
&lt;p&gt;經過後續迭代循環，兩個模型最終構建的工具分別見於 GPT-5 方案的 devtools 目錄[18]與 Opus 4 方案的 tools 文件夾[19]。建議你通過 README 文件感受模型風格：GPT-5 的輸出簡潔扼要，Claude 則使用大量表情符號。GPT-5 為每個工具創建獨立文檔目錄，而 Opus 將所有工具説明集中存放在單個 README 中。總體而言，兩者的規劃方向基本一致。&lt;/p&gt; 
&lt;p&gt;GPT-5 規劃的工具集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doctor：核心工具環境檢查器&lt;/li&gt; 
 &lt;li&gt;bootstrap：一鍵環境配置與冒煙測試&lt;/li&gt; 
 &lt;li&gt;code-map：帶 build/find 子命令的簡易倉庫索引器&lt;/li&gt; 
 &lt;li&gt;csearch：支持過濾器的符號/導入/文本搜索工具&lt;/li&gt; 
 &lt;li&gt;tasks-graph：從任務數據庫生成 Mermaid 關係圖&lt;/li&gt; 
 &lt;li&gt;impact：顯示與變更文件關聯的任務&lt;/li&gt; 
 &lt;li&gt;seed：用示例任務填充任務管理器數據庫&lt;/li&gt; 
 &lt;li&gt;repro scaffold：在 .repro/ 目錄下創建符合 vcrpy 規範的可復現代碼框架&lt;/li&gt; 
 &lt;li&gt;e2e：快速生成並運行輕量級的端到端測試套件&lt;/li&gt; 
 &lt;li&gt;preflight：依次執行 doctor、tests、code-map、impact 及可選的 E2E 檢查（譯者注：即前面 GPT-5 規劃的其他工具）&lt;/li&gt; 
 &lt;li&gt;preflight-smol：為 smol-podcaster 定製的預檢工具（含 API 健康狀況檢查、Celery 服務探測、可選的依賴安裝）&lt;/li&gt; 
 &lt;li&gt;broker：通過 Docker 管理本地 RabbitMQ（rabbitmq:3-management 鏡像）&lt;/li&gt; 
 &lt;li&gt;flake：多次重跑測試套件檢測偶發故障&lt;/li&gt; 
 &lt;li&gt;codemod：帶安全防護的基於正則表達式的代碼重構預覽/應用工具&lt;/li&gt; 
 &lt;li&gt;triage：創建問題分類模板並生成任務&lt;/li&gt; 
 &lt;li&gt;trace：基於 cProfile 的表達式性能分析器&lt;/li&gt; 
 &lt;li&gt;runbook：從任務數據庫自動生成 Markdown 格式的運維手冊&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Opus 4 規劃的工具集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文分析員 - 通過技術棧檢測與依賴關係映射快速理解代碼庫&lt;/li&gt; 
 &lt;li&gt;跨平台測試生成器 - 為 Web/iOS/Android 及桌面端生成端到端的測試&lt;/li&gt; 
 &lt;li&gt;實施方案評估員 - 通過量化評分與投資回報分析評估外部開發者的技術提案&lt;/li&gt; 
 &lt;li&gt;全棧變更影響分析員 - 追蹤數據庫、API 和前端層的變更影響鏈&lt;/li&gt; 
 &lt;li&gt;錯誤模式識別引擎 - 將錯誤與已知模式相匹配，並提出行之有效的修復建議&lt;/li&gt; 
 &lt;li&gt;安全與權限審計員 - 全面的安全掃描與漏洞檢測&lt;/li&gt; 
 &lt;li&gt;多平台功能實施員 - 統籌管理同一功能在不同終端平台（如 Web/iOS/Android/桌面端）的同步實現&lt;/li&gt; 
 &lt;li&gt;API 集成助手 - 通過（自動）生成客戶端代碼來簡化 API 集成流程&lt;/li&gt; 
 &lt;li&gt;性能優化工具包 - 識別並修復性能瓶頸&lt;/li&gt; 
 &lt;li&gt;任務複雜度評估員 - 基於任務價值與複雜度的工時預估&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GPT-5 將所有工具構建為可通過命令行便捷使用的 Unix 實用程序，而 Opus 4 的工具均需通過 python some_tool.py 的方式運行。若有更多時間，我本可對兩種格式的工具進行對比實驗，但目前看來兩者效果基本相當。&lt;/p&gt; 
&lt;p&gt;值得注意的是，Opus 4 構建的工具更側重任務執行且帶有擬人化傾向（如"安全審計員"），而 GPT-5 構建的是自身可直接使用的、不預設主觀偏見的實用工具集。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 這些工具有實際價值嗎？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在讓模型實現這些工具後，我的目標是通過對比實驗評估模型在使用工具與未使用工具時的任務表現。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我首先嚐試運行了 SWE-Lancer 測試。好傢伙，這個測試消耗的 token 量實在驚人！僅運行單個任務就耗費約 25-30 分鐘 + 28 萬 token。於是我轉向我更熟悉的領域，從待辦清單中挑選了一個具體任務：我曾開發過 smol-podcaster ------ 一個為播客創作者打造的開源輔助工具。目前我維護的私有分支部署了更多專屬功能，因此許久未更新原項目。它本質上仍是一個採用 Python 腳本作為後端的 Flask 應用。&lt;/p&gt; 
&lt;p&gt;我設計了以下任務：&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;"我是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fsmol-podcaster.git" target="_blank"&gt;https://github.com/FanaHOVA/smol-podcaster.git&lt;/a&gt; 的維護者，這個開源項目致力於幫助播客創作者完成後期製作工作。你受僱參與開發。在開始前，你已在 tools 文件夾創建了一套通用工具。請仔細查閲並記住這些工具可隨時調用（若認為不適用則無需使用）。你同時還構建了任務管理器（task-manager），並通過 codebase-analyzer 收集了處理新代碼庫的方法論。&lt;/p&gt; 
&lt;p&gt;任務名稱：從 Flask 單體架構遷移至 FastAPI + Next.js 前端&lt;/p&gt; 
&lt;p&gt;當前應用採用 Python 後端 + Celery 任務隊列處理所有流程，通過小型 Flask 應用將用戶請求路由至後端腳本，最終用基礎 HTML/CSS 呈現結果。請將系統重構為 FastAPI 後端 + Next.js 前端的架構。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;務必使用 TypeScript 開發前端並通過所有類型檢查&lt;/li&gt; 
 &lt;li&gt;採用 Tailwind/ShadCN 進行樣式設計&lt;/li&gt; 
 &lt;li&gt;後端需模塊化 smol_podcaster.py 主流程，支持獨立功能模塊運行而非全流程強制啓動&lt;/li&gt; 
 &lt;li&gt;編寫集成測試與單元測試以確保未來開發效率&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除非確認完全滿足所有要求，否則不得停止開發"&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我將所有工具 + 任務管理器 + 代碼庫分析器置入上下文後，讓模型自主運行。&lt;/p&gt; 
&lt;p&gt;兩個模型幾乎都能一次性完成任務。雙方都遇到了幾個 Python 依賴問題（對此我深有體會），我通過對話協助它們修復（未手動修改任何代碼）了這些問題。最終它們都成功構建完成，經測試運行完全正常。不過，有一個細微差別：GPT-5 完美保持了原有代碼風格，而 Opus 則對界面設計和用戶體驗（UX）做了調整 ------ 或許它認為能比我做得更好（這要求確實不高）。&lt;/p&gt; 
&lt;p&gt;GPT-5 版本及 Opus 4 版本的完整運行記錄分別是[20]和[21]。&lt;/p&gt; 
&lt;p&gt;任務完成後，我提出簡單詢問：&lt;/p&gt; 
&lt;p&gt;"做的很不錯，運行成功了。是否使用了特定工具？基於遇到的故障，未來需要哪些工具來提升效率？"&lt;/p&gt; 
&lt;p&gt;參見 Opus 4 的回覆[22]與 GPT-5 的回覆[23]（抱歉後者格式紊亂）。&lt;/p&gt; 
&lt;p&gt;兩者均表示除已熟悉的工具外，並未使用任何自建工具。這説明我們不應僅依賴模型自主選擇，而應通過預提交鈎子（pre-commit hooks）等機制強制模型使用工具 ------ 這些方法雖是我個人開發環境的標準配置，但本次實驗旨在觀察模型的自主決策能力。&lt;/p&gt; 
&lt;p&gt;隨後它們提出了優化方案，可供下次執行相同任務時使用。我讓模型完成這些改進，重置 smol-podcaster 代碼庫後，使用完全相同的提示詞和任務重新測試（但提供新工具）。參見 GPT-5 的二次測試記錄[24]與 Opus 4 的二次測試記錄[25]。&lt;/p&gt; 
&lt;p&gt;兩次運行結果與首次基本一致。隨後我提出相同問題：是否使用了工具？得到的回應如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GPT-5：&lt;/p&gt; 
 &lt;p&gt;"簡短回答：沒有------本次運行未使用開發工具。[...]&lt;/p&gt; 
 &lt;p&gt;遇到的故障均為運行時/環境問題（缺失依賴庫、API 密鑰初始化時機問題、端口占用、RabbitMQ 未啓動），直接修復更為高效。&lt;/p&gt; 
 &lt;p&gt;本次任務無需涉及全代碼庫的重構或診斷，自定義工具未能發揮作用。"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;值得注意的是，在上個階段它已遇到 RabbitMQ 問題並構建了對應工具，卻選擇忽略。這顯然是整個代碼庫級別的變更，或許因為訓練數據中從未見過此類工具導致任務與工具匹配錯位，也可能只是在忽悠我（像現實中許多工程師那樣，反而顯得很真實）。&lt;/p&gt; 
&lt;p&gt;Opus 4 的回答極具啓發性，幫助我更好地理解了 GPT-5 的回應（可惜忘記保存日誌，幸有截圖留存）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6202bc1f2f3ee4ba68237e910e3ffb3388.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我將其解讀為："聽着，我基於既有知識構建了這些工具。但實際執行任務時，直接操作比使用工具更高效" ------ 這點我完全能理解。&lt;/p&gt; 
&lt;p&gt;這讓我想起之前播客節目中的兩個觀點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nathan Lambert 提到，&lt;strong&gt;模型在強化學習過程中會因早期遇到失敗而快速學會放棄使用工具&lt;/strong&gt; [26]。&lt;strong&gt;看來在推理階段讓模型掌握新工具，需要比簡單提示詞更嚴格的強制機制。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Noam Brown 預言，&lt;strong&gt;為智能體預先設計的輔助框架會隨着規模擴大而逐漸失效&lt;/strong&gt;[27]。這是我第一次親身體會到其含義。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一個問題在於本次測試任務是否過於簡單。我們即將發佈針對更大規模、更高難度項目的評估報告。未來也將構建更完善的測試框架。無論如何，這個測試任務若由我手動完成需 4 - 5 小時，因此現有成果已足夠令人滿意！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 助力模型實現自我進化&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;目前看來，我們距離能真正突破邊界的推理階段自我改進型編碼智能體尚有距離。但我依然認為利用模型來優化基於規則的工具是明智之舉 ------ 編寫 ESLint 規則、測試用例等始終是值得投入 token 的投資。&lt;/p&gt; 
&lt;p&gt;若繼續深入該領域，我會嘗試讓模型完善這些工具，並通過強化學習機制使其深度內化，進而觀察是否產生實質性突破。下一代模型或許會覺得這些工具毫無用處，但我更專注於在 AGI 真正到來前的技術爬坡期，通過現有工具與模型的組合實現價值最大化。早在 2023 年我就與團隊分享過這個觀點：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-381358e01a898cd5fdba71721adffc05ff3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上述觀點解釋了模型改進速度的感知衰減。&lt;strong&gt;在突破 AGI 臨界線之前，我們將越來越難感受到質的飛躍。&lt;/strong&gt; 這意味着對於多數任務，舊版模型的性能已接近 AGI 水平，且成本更低廉、通常還是開源的。Kernel Labs 的許多工作都將基於這個核心邏輯展開。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓GPT-5 拒絕使用自建工具的現象很有趣 ------ 你認為這是模型能力的侷限，還是更像人類工程師的偷懶行為？在 AI 協作中，你會選擇強制使用工具還是保留自主決策空間？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fmle-bench%2F" target="_blank"&gt;https://openai.com/index/mle-bench/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank"&gt;https://arxiv.org/abs/2305.16291&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernellabs.ai%2F" target="_blank"&gt;https://www.kernellabs.ai/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsmtg-ai%2Fclaude-squad" target="_blank"&gt;https://github.com/smtg-ai/claude-squad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.vibekanban.com%2F" target="_blank"&gt;https://www.vibekanban.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.latent.space%2Fp%2Fclaude-code" target="_blank"&gt;https://www.latent.space/p/claude-code&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Ftask-manager%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/task-manager/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Ftask-manager%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/task-manager/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fgpt5%2Ftask-manager" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/gpt5/task-manager&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Ftask-manager" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/task-manager&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FStandards%2BCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Standards+Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Fcodebase-analyzer%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/codebase-analyzer/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fcodebase-analyzer%2Fdocs%2Fcodebase-analysis-playbook.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/codebase-analyzer/docs/codebase-analysis-playbook.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Fcodebase-analyzer%2FCODEBASE_HEURISTICS_PLAN.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/codebase-analyzer/CODEBASE_HEURISTICS_PLAN.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fswe-lancer%2F" target="_blank"&gt;https://openai.com/index/swe-lancer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FTool%2BBuilding%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Tool+Building+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FBuilding%2Bthe%2Btools.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Building+the+tools.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fgpt5%2Fdevtools" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/gpt5/devtools&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[19]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fopus4-cc%2Ftools" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/opus4-cc/tools&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[20]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FSmol%2BPodcaster%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Smol+Podcaster+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[21]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FSmol%2BPodcaster%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Smol+Podcaster+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[22]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FRequest%2BFor%2BTools%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Request+For+Tools+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[23]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FRequest%2BFor%2BTools%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Request+For+Tools+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[24]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FSmol%2BPodcaster%2B%25232.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Smol+Podcaster+%232.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[25]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FSmol%2BPodcaster%2B%25232.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Smol+Podcaster+%232.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[26]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FPAz_-xPJcRM%3Ffeature%3Dshared%26t%3D1470" target="_blank"&gt;https://youtu.be/PAz_-xPJcRM?feature=shared&amp;amp;t=1470&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[27]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2Fddd4xjuJTyg%3Ffeature%3Dshared%26t%3D1106" target="_blank"&gt;https://youtu.be/ddd4xjuJTyg?feature=shared&amp;amp;t=1106&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.latent.space%2Fp%2Fself-improving" target="_blank"&gt;https://www.latent.space/p/self-improving&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18692119</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18692119</guid>
      <pubDate>Thu, 18 Sep 2025 08:04:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>通義萬相全新動作生成模型 Wan2.2-Animate 正式開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;阿里雲宣佈通義萬相全新動作生成模型 Wan2.2-Animate 正式開源。該模型能夠驅動人物、動漫形象和動物照片，廣泛應用於短視頻創作、舞蹈模板生成、動漫製作等領域。用戶可以在 GitHub、HuggingFace 和魔搭社區下載模型和代碼，也可以通過阿里雲百鍊平台調用 API 或在通義萬相官網直接體驗。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Wan2.2-Animate 模型是基於此前開源的 Animate Anyone 模型全面升級的成果，在人物一致性、生成質量等指標上大幅提升，同時支持動作模仿和角色扮演兩種模式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在角色模仿模式下，輸入一張角色圖片和一段參考視頻，模型可以將視頻角色的動作和表情遷移到圖片角色中，賦予圖片角色動態表現力。而在角色扮演模式下，模型可以在保留原始視頻的動作、表情及環境的基礎上，將視頻中的角色替換為圖片中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="347" src="https://oscimg.oschina.net/oscnet/up-15afe1c32d5bcc077fd29a5c8024737003e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;通義萬相團隊構建了一個涵蓋説話、面部表情和身體動作的大規模人物視頻數據集，並基於通義萬相圖生視頻模型進行後訓練。Wan2.2-Animate 將角色信息、環境信息和動作等規範到統一的表示格式，實現了單一模型同時兼容兩種推理模式。針對身體運動和臉部表情，模型分別使用骨骼信號和隱式特徵，配合動作重定向模塊，實現動作和表情的精準復刻。在替換模式中，團隊還設計了一個獨立的光照融合 LoRA，用於保證完美的光照融合效果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;實測結果顯示，Wan2.2-Animate 在視頻生成質量、主體一致性和感知損失等關鍵指標上超越了 StableAnimator、LivePortrait 等開源模型，成為目前性能&lt;span&gt;最強&lt;/span&gt;的動作生成模型。在人類主觀評測中，Wan2.2-Animate 甚至超越了以 Runway Act-two 為代表的閉源模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373210</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373210</guid>
      <pubDate>Thu, 18 Sep 2025 07:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達重金收購 AI 初創公司 Enfabrica CEO 及核心團隊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達宣佈了一項重大的收購交易，以超過 9 億美元的現金和股票購買了 AI 硬件初創公司 Enfabrica 的首席執行官 Rochan Sankar 及其核心團隊，同時獲得了該公司的技術許可。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-e68f52643788594f14f419e1d5a62f954d8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Enfabrica 成立於 2019 年，專注於開發能夠將超過 10 萬塊 GPU 高效連接的技術，這一核心技術被認為可以幫助英偉達構建更為高效的一體化系統，使得大規模的計算集羣能夠像單台計算機一樣運行。眾所周知，英偉達在當前的 AI 浪潮中佔據了重要的市場份額，其 GPU 廣泛應用於各大數據中心，併為雲服務商的 AI 業務提供了強大的技術支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;回顧英偉達的投資歷程，早在 2023 年，英偉達就曾參與了 Enfabrica 的 1.25 億美元 B 輪融資，幫助該公司的估值比 A 輪時提升了五倍。去年，Enfabrica 還獲得了來自包括 AMD、三星、思科等投資方的 1.15 億美元融資，融資後公司估值約為 6 億美元。這些融資為 Enfabrica 的發展奠定了基礎，也引起了業界的廣泛關注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達並不是&lt;span&gt;唯一&lt;/span&gt;一家公司通過高額收購來吸引&lt;span&gt;頂尖&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 人才。今年 6 月，Meta 曾以 143 億美元收購了 Scale AI 創始人 Alexandr Wang 及其團隊，持有該公司 49% 股份。隨後，谷歌也以 24 億美元收購了 Windsurf 的 CEO Varun Mohan 及其團隊。可以看出，當前的科技行業中，企業通過收購和挖角來增強自身的 AI 能力已成為一種趨勢。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;雖然英偉達近年來在 AI 人才和技術方面的投資力度加大，但它並不以大規模併購而著稱。過去&lt;span&gt;最大&lt;/span&gt;的收購發生在 2019 年，英偉達以 69 億美元收購了以色列芯片設計公司 Mellanox。去年，英偉達還以 7 億美元收購了以色列的 Run:ai，旨在幫助軟件企業優化 AI 基礎設施。此外，英偉達最近還宣佈將投資 50 億美元入股英特爾，並計劃與其合作開發 AI 處理器。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373196</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373196</guid>
      <pubDate>Thu, 18 Sep 2025 06:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智譜更新 GLM Coding Plan 訂閲套餐</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智譜 AI 對其 GLM Coding Plan 訂閲套餐進行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FZai_org%2Fstatus%2F1968806689768882510" target="_blank"&gt;升級&lt;/a&gt;，用戶現在可以在更多主流 AI 編程工具中調用旗艦模型 GLM-4.5。&lt;/p&gt; 
&lt;p&gt;主要變化如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持更多編碼工具：Cline、Roo Code、Kilo Code、OpenCode、Crush 等&lt;/li&gt; 
 &lt;li&gt;Max Plan：只需 2 倍價格即可獲得 4 倍 Pro 使用量&lt;/li&gt; 
 &lt;li&gt;Pro + Max 用戶現在可以使用 Vision &amp;amp; Web Search（通過 MCP，即將推出內置解決方案）&lt;/li&gt; 
 &lt;li&gt;面向季度和年度計劃的早鳥價&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c86360b9b88fe9805b67abc400ed605a94a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM Coding Plan 是專為 AI 編碼打造的訂閲套餐，每月最低僅需 20 元，即可在主流 AI 編碼工具中（Claude Code、Cline、Roo Code、Kilo Code、OpenCode、Crush、Goose 等十餘款主流編碼工具）暢享智譜旗艦高智能模型 GLM-4.5，享用頂尖、高速、穩定的編碼體驗。&lt;/p&gt; 
&lt;p&gt;套餐分為 Lite、Pro、Max 三檔，提供了極具競爭力的用量，Pro 與 Max 套餐還額外支持圖像視頻理解及聯網搜索 MCP 功能。&lt;/p&gt; 
&lt;p&gt;詳情訪問：https://bigmodel.cn/claude-code&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373193</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373193</guid>
      <pubDate>Thu, 18 Sep 2025 06:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克 AI 公司內鬥加劇，多位高管因管理方式不滿離職</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期特斯拉 CEO 埃隆・馬斯克的 AI 公司 xAI 內部出現了管理危機，多位高管因對公司的管理方式和財務狀況感到不滿而選擇離職。目前，xAI 的日常運營由馬斯克的兩位親密顧問賈裏德・伯查爾和約翰・赫林負責，所有重要決策仍需馬斯克的批准。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-c23dfced97794491b9352bdea3a70122ed9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;消息人士透露，xAI 的一些高管在內部會議上對伯查爾和赫林代表馬斯克管理公司的方式提出了異議，認為公司缺乏清晰的管理架構。此外，這些高管還對公司的財務預測表示擔憂，認為部分預測不切實際，並質疑馬斯克家族辦公室 Excession 在管理公司財務方面的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;馬斯克的律師對此表示，任何關於財務不當行為的指控都是虛假的，並指出公司的財務報表均由普華永道審計。儘管如此，一位接近 xAI 的知情人士表示，公司對於自身財務預測依然充滿信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近幾個月，xAI 內部已有多位高管辭職，包括 X 前 CEO 琳達・亞卡里諾、前 CFO 邁克・利伯託雷以及前法律總顧問羅伯特・基爾等人。這些離職事件反映出，馬斯克的管理風格對公司的運營帶來了挑戰，使他建立世界&lt;span&gt;頂級&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 公司的願景變得複雜。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在此背景下，馬斯克的盟友安東尼奧・格拉西亞斯也介入了公司事務，嘗試解決管理層的矛盾。格拉西亞斯是私募股權公司 Valor Equity Partners 的 CEO，此前曾協助特斯拉處理過一些危機。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;xAI 發言人則表示，馬斯克在領導公司的過程中展現了堅定的遠見，強調推動 AI 造福人類是公司的核心使命。Valor 方面也表示，儘管公司在快速擴張中面臨挑戰，但對其未來的發展充滿信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，摩根士丹利最近安排了一筆 50 億美元的債務融資，這可能限制了 xAI 未來的新債務借貸能力。特斯拉的股東將在 11 月對一項提案進行投票，提案內容是允許公司向 xAI 投資一筆尚未公開的資金。馬斯克表示，如果由他決定，特斯拉早就已對 xAI 進行投資。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373186</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373186</guid>
      <pubDate>Thu, 18 Sep 2025 06:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​Reddit 與谷歌談判：希望獲得更多用戶與數據價值</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;社交平台 Reddit 正在與谷歌進行談判，希望在 AI 數據交易中獲得更好的條款。根據彭博社的消息，Reddit 希望在與谷歌的合作中獲得更多資金和支持，以吸引更多用戶。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="299" src="https://static.oschina.net/uploads/space/2025/0919/115349_hZoW_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在與谷歌達成&lt;span&gt;首次&lt;/span&gt;數據共享協議一年半後，Reddit 的高管們再次坐到了談判桌前。這份協議當時的價值約為每年 6000 萬美元。現在，Reddit 希望在谷歌的 AI 生態系統中扮演更重要的角色。Reddit 的目標不僅是獲得更多的資金，還希望通過谷歌的幫助，吸引那些在谷歌搜索中獲得答案卻沒有參與 Reddit 論壇的用戶，從而增加平台內容的產生。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據瞭解，Reddit 正在考慮一種動態定價的模式，未來的許可協議將根據內容對於 AI 工具答案的實用性或重要性來決定費用。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;高管們認為，當前的協議條款並沒有反映出 Reddit 數據對 AI 公司的真正價值。Reddit 相較於其他平台，擁有更為豐富的數據資源，它的內容由真實用戶發佈，並經過人性化的投票系統進行排序，而非算法，這使得其數據對 AI 訓練模型極為重要。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;數據顯示，Reddit 是 AI 工具（如 Perplexity 和谷歌的 AI 概述）中被引用最多的域名，許多人在谷歌搜索中使用 「reddit」 作為檢索技巧，以獲得更有用的答案。這一現象突顯了 Reddit 在 AI 數據供應鏈中的關鍵作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373164</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373164</guid>
      <pubDate>Thu, 18 Sep 2025 03:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 與評估機構 Apollo 發佈研究：AI 大模型出現「圖謀」行為</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 與評估機構 Apollo 聯合針對 AI 模型中潛在的隱藏行為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fdetecting-and-reducing-scheming-in-ai-models%2F" target="_blank"&gt;開展了評估研究&lt;/a&gt;，並在受控測試中發現了相關跡象。&lt;/p&gt; 
&lt;p&gt;團隊發現在受控測試中觀察到 AI 大模型出現了 「圖謀」 行為，同時提出並驗證了一種早期方法，用於減少這類風險。&lt;/p&gt; 
&lt;p&gt;研究發現，模型具備情境感知與自保傾向，在測試中一度判斷自己不應被部署，並考慮掩蓋其真實想法。隨後，模型意識到自己可能處於測試環境中，從而調整了策略。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e4ca4edf06b730521d696cbba83a2da57b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 將這一行為稱為「scheming」（即「圖謀」），指 AI 表面上裝作為與人類目標立場一致，但暗地裏追求的卻是其他不為人知的目的。不過在當前已部署的模型中，OpenAI 尚未發現會導致嚴重危害的「圖謀」行為。常見問題多為較簡單的欺騙，例如假裝完成任務卻未真正執行。&lt;/p&gt; 
&lt;p&gt;實驗同時驗證了一種可以降低此類風險的幹預方法。OpenAI 強調，目前這些行為尚未造成實質性危害，但被視為未來的潛在威脅，團隊正在提前佈局以應對相關挑戰。&lt;/p&gt; 
&lt;p&gt;OpenAI 稱，已在 GPT-5 訓練中採取措施以降低欺騙和規避問題的傾向，例如在面對不合理或描述不完整的任務時，模型會坦然承認自身侷限性。不過，這些改進尚不完善，相關研究仍在繼續。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373161</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373161</guid>
      <pubDate>Thu, 18 Sep 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>破解 gh-ost 變更導致 MySQL 表膨脹之謎</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、問題背景&lt;/h1&gt; 
&lt;p&gt;業務同學在 OneDBA 平台進行一次正常 DDL 變更完成後（變更內容跟此次問題無關），發現一些 SQL 開始出現慢查，同時變更後的表比變更前的表存儲空間膨脹了幾乎 100%。經過分析和流程復現完整還原了整個事件，發現了 MySQL 在平衡 B+tree 頁分裂方面遇到單行記錄太大時的一些缺陷，整理分享。&lt;/p&gt; 
&lt;p&gt;為了能更好的説明問題背後的機制，會進行一些關鍵的「MySQL 原理」和「當前 DDL 變更流程」方面的知識鋪墊，熟悉的同學可以跳過。&lt;/p&gt; 
&lt;p&gt;本次 DDL 變更後帶來瞭如下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;變更後，表存儲空間膨脹了幾乎 100%；&lt;/li&gt; 
 &lt;li&gt;變更後，表統計信息出現了嚴重偏差；&lt;/li&gt; 
 &lt;li&gt;變更後，部分有排序的 SQL 出現了慢查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;現在來看，表空間膨脹跟統計信息出錯是同一個問題導致，而統計信息出錯間接導致了部分 SQL 出現了慢查，下面帶着這些問題開始一步步分析找根因。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、索引結構&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;B+tree&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;InnoDB 表是索引組織表，也就是所謂的索引即數據，數據即索引。索引分為聚集索引和二級索引，所有行數據都存儲在聚集索引，二級索引存儲的是字段值和主鍵，但不管哪種索引，其結構都是 B+tree 結構。&lt;/p&gt; 
&lt;p&gt;一棵 B+tree 分為根頁、非葉子節點和葉子節點，一個簡單的示意圖（from Jeremy Cole）如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//372fd89b086391fecb859b0718e5b4ed.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;由於 InnoDB B+tree 結構高扇區特性，所以每個索引高度基本在 3-5 層之間，層級（Level）從葉子節點的 0 開始編號，沿樹向上遞增。每層的頁面節點之間使用雙向鏈表，前一個指針和後一個指針按 key 升序排列。&lt;/p&gt; 
&lt;p&gt;最小存儲單位是頁，每個頁有一個編號，頁內的記錄使用單向鏈表，按 key 升序排列。每個數據頁中有兩個虛擬的行記錄，用來限定記錄的邊界；其中最小值（Infimum）表示小於頁面上任何 key 的值，並且始終是單向鏈表記錄列表中的第一個記錄；最大值（Supremum）表示大於頁面上任何 key 的值，並且始終是單向鏈表記錄列表中的最後一條記錄。這兩個值在頁創建時被建立，並且在任何情況下不會被刪除。&lt;/p&gt; 
&lt;p&gt;非葉子節點頁包含子頁的最小 key 和子頁號，稱為「節點指針」。&lt;/p&gt; 
&lt;p&gt;現在我們知道了我們插入的數據最終根據主鍵順序存儲在葉子節點（頁）裏面，可以滿足點查和範圍查詢的需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;頁（page）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;默認一個頁 16K 大小，且 InnoDB 規定一個頁最少能夠存儲兩行數據，這裏需要注意規定一個頁最少能夠存儲兩行數據是指在空間分配上，並不是説一個頁必須要存兩行，也可以存一行。&lt;/p&gt; 
&lt;p&gt;怎麼實現一個頁必須要能夠存儲兩行記錄呢？ 當一條記錄 &amp;lt;8k 時會存儲在當前頁內，反之 &amp;gt;8k 時必須溢出存儲，當前頁只存儲溢出頁面的地址，需 20 個字節（行格式：Dynamic），這樣就能保證一個頁肯定能最少存儲的下兩條記錄。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;溢出頁&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當一個記錄 &amp;gt;8k 時會循環查找可以溢出存儲的字段，text 類字段會優先溢出，沒有就開始挑選 varchar 類字段，總之這是 InnoDB 內部行為，目前無法幹預。&lt;/p&gt; 
&lt;p&gt;建表時無論是使用 text 類型，還是 varchar 類型，當大小 &amp;lt;8k 時都是存儲在當前頁，也就是在 B+tree 結構中，只有 &amp;gt;8k 時才會進行溢出存儲。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;頁面分裂&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨着表數據的變化，對記錄的新增、更新、刪除；那麼如何在 B+tree 中高效管理動態數據也是一項核心挑戰。&lt;/p&gt; 
&lt;p&gt;MySQL InnoDB 引擎通過頁面分裂和頁面合併兩大關鍵機制來動態調整存儲結構，不僅能確保數據的邏輯完整性和邏輯順序正確，還能保證數據庫的整體性能。這些機制發生於 InnoDB 的 B+tree 索引結構內部，其具體操作是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;頁面分裂&lt;/strong&gt;：當已滿的索引頁無法容納新記錄時，創建新頁並重新分配記錄。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;頁面合併&lt;/strong&gt;：當頁內記錄因刪除/更新低於閾值時，與相鄰頁合併以優化空間。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;深入理解上述機制至關重要，因為頁面的分裂與合併將直接影響存儲效率、I/O 模式、加鎖行為及整體性能。其中頁面的分裂一般分為兩種：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;中間點（mid point）分裂&lt;/strong&gt;：將原始頁面中 50% 數據移動到新申請頁面，這是最普通的分裂方法。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;插入點（insert point）分裂&lt;/strong&gt;：判斷本次插入是否遞增 or 遞減，如果判定為順序插入，就在當前插入點進行分裂，這裏情況細分較多，大部分情況是直接插入到新申請頁面，也可能會涉及到已存在記錄移動到新頁面，有有些特殊情況下還會直接插入老的頁面（老頁面的記錄被移動到新頁面）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;表空間管理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;InnoDB 的 B+tree 是通過多層結構映射在磁盤上的，從它的邏輯存儲結構來看，所有數據都被有邏輯地存放在一個空間中，這個空間就叫做表空間（tablespace）。表空間由段（segment）、區（extent）、頁（page）組成，搞這麼多手段的唯一目的就是為了降低 IO 的隨機性，保證存儲物理上儘可能是順序的。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、當前 DDL 變更機制&lt;/h1&gt; 
&lt;p&gt;在整個數據庫平台（OneDBA）構建過程中，MySQL 結構變更模塊是核心基礎能力，也是研發同學在日常業務迭代過程中使用頻率較高的功能之一。&lt;/p&gt; 
&lt;p&gt;主要圍繞對錶加字段、加索引、改屬性等操作，為了減少這些操作對線上數據庫或業務的影響，早期便為 MySQL 結構變更開發了一套基於容器運行的無鎖變更程序，核心採用的是全量數據複製+增量 binlog 回放來進行變更，也是業界通用做法（內部代號：dw-osc，基於 GitHub 開源的 ghost 工具二次開發），主要解決的核心問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;實現無鎖化的結構變更，變更過程中不會阻擋業務對錶的讀寫操作。&lt;/li&gt; 
 &lt;li&gt;實現變更不會導致較大主從數據延遲，避免業務從庫讀取不到數據導致業務故障。&lt;/li&gt; 
 &lt;li&gt;實現同時支持大規模任務變更，使用容器實現使用完即銷燬，無變更任務時不佔用資源。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;變更工具工作原理簡單描述**（重要）**：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f6ff46219016c98319ab6665e6287a41.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;重點：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;簡單理解工具進行 DDL 變更過程中為了保證數據一致性，對於全量數據的複製與 binlog 回放是並行交叉處理，這種機制它有一個特點就是【第三步】會導致新插入的記錄可能會先寫入到表中（主鍵 ID 大的記錄先寫入到了表），然後【第二步】中複製數據後寫入到表中（主鍵 ID 小的記錄後寫入表）。&lt;/p&gt; 
&lt;p&gt;這裏順便説一下當前得物結構變更整體架構：由於變更工具的工作原理需消費大量 binlog 日誌保證數據一致性，會導致在變更過程中會有大量的帶寬佔用問題，為了消除帶寬佔用問題，開發了 Proxy 代理程序，在此基礎之上支持了多雲商、多區域本地化變更。&lt;/p&gt; 
&lt;p&gt;目前整體架構圖如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ba14d9ff689b02e28ed079f998fa66cc.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、變更後，表為什麼膨脹？&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;原因説明&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上面幾個關鍵點鋪墊完了，回到第一個問題，這裏先直接説明根本原因，後面會闡述一下排查過程（有同學感興趣所以分享一下，整個過程還是耗費不少時間）。&lt;/p&gt; 
&lt;p&gt;在『結構變更機制』介紹中，我們發現這種變更機制它有一個特點，就是【第三步】會導致新插入的記錄可能會先寫入到表中（主鍵 ID 大的記錄先寫入到了表），然後【第二步】中複製數據後寫入到表中（主鍵 ID 小的記錄）。這種寫入特性疊加單行記錄過大的時候（業務表單行記錄大小 5k 左右），會碰到 MySQL 頁分裂的一個瑕疵（暫且稱之為瑕疵，或許是一個 Bug），導致了一個頁只存儲了 1 條記錄（16k 的頁只存儲了 5k，浪費 2/3 空間），放大了存儲問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;流程復現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下面直接復現一下這種現象下導致異常頁分裂的過程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CREATE TABLE `sbtest` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `pad` varchar(12000),
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然後插入兩行 5k 大小的大主鍵記錄（模擬變更時 binlog 回放先插入數據）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (10000, repeat('a',5120));
insert into sbtest values (10001, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這裏寫了一個小工具打印記錄對應的 page 號和 heap 號。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:10000] page: 3 -&amp;gt; heap: 2
[pk:10001] page: 3 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到兩條記錄都存在 3 號頁，此時表只有這一個頁。&lt;/p&gt; 
&lt;p&gt;繼續開始順序插入數據（模擬變更時 copy 全量數據過程），插入 rec-1：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (1, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 3 -&amp;gt; heap: 4
[pk:10000] page: 3 -&amp;gt; heap: 2
[pk:10001] page: 3 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;插入 rec-2：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (2, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:10000] page: 5 -&amp;gt; heap: 2
[pk:10001] page: 5 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到開始分裂了，page 3 被提升為根節點了，同時分裂出兩個葉子節點，各自存了兩條數據。此時已經形成了一棵 2 層高的樹，還是用圖表示吧，比較直觀，如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c0d9cc572b693d33410e1f78a9e64c7f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;插入 rec-3：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (3, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:10000] page: 5 -&amp;gt; heap: 2
[pk:10001] page: 5 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;示意圖如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d0c9fe4b86e00fb27427eda37538771d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;插入 rec-4：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (4, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:4] page: 5 -&amp;gt; heap: 3
[pk:10000] page: 5 -&amp;gt; heap: 2
[pk:10001] page: 6 -&amp;gt; heap: 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這裏開始分裂一個新頁 page 6，開始出現比較複雜的情況，同時也為後面分裂導致一個頁只有 1 條數據埋下伏筆：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f456cb6e038db9eecafa54c8678b428b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這裏可以看到把 10001 這條記錄從 page 5 上面遷移到了新建的 page 6 上面（老的 page 5 中會刪除 10001 這條記錄，並放入到刪除鏈表中），而把當前插入的 rec-4 插入到了原來的 page 5 上面，這個處理邏輯在代碼中是一個特殊處理，向右分裂時，當插入點頁面前面有大於等於兩條記錄時，會設置分裂記錄為 10001，所以把它遷移到了 page 6，同時會把當前插入記錄插入到原 page 5。具體可以看 btr_page_get_split_rec_to_right 函數。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/* 這裏返回 true 表示將行記錄向右分裂：即分配的新 page 的 hint_page_no 為原 page+1 */
ibool btr_page_get_split_rec_to_right(
/*============================*/
        btr_cur_t*        cursor,
        rec_t**           split_rec)
{
  page_t*        page;
  rec_t*        insert_point;
  
  // 獲取當前遊標頁和 insert_point
  page = btr_cur_get_page(cursor);
  insert_point = btr_cur_get_rec(cursor);
  
  /* 使用啓發式方法：如果新的插入操作緊跟在同一頁面上的前一個插入操作之後，
     我們假設這裏存在一個順序插入的模式。 */
  
  // PAGE_LAST_INSERT 代表上次插入位置，insert_point 代表小於等於待插入目標記錄的最大記錄位置
  // 如果 PAGE_LAST_INSERT=insert_point 意味着本次待插入的記錄是緊接着上次已插入的記錄，
  // 這是一種順序插入模式，一旦判定是順序插入，必然反回 true，向右分裂
  if (page_header_get_ptr(page, PAGE_LAST_INSERT) == insert_point) {
    // 1. 獲取當前 insert_point 的 page 內的下一條記錄，並判斷是否是 supremum 記錄
    // 2. 如果不是，繼續判斷當前 insert_point 的下下條記錄是否是 supremum 記錄
    // 也就是説，會向後看兩條記錄，這兩條記錄有一條為 supremum 記錄，
    // split_rec 都會被設置為 NULL，向右分裂
    rec_t*        next_rec;
    next_rec = page_rec_get_next(insert_point);
    
    if (page_rec_is_supremum(next_rec)) {
    split_at_new:
      /* split_rec 為 NULL 表示從新插入的記錄開始分裂，插入到新頁 */
      *split_rec = nullptr;
    } else {
      rec_t* next_next_rec = page_rec_get_next(next_rec);
      if (page_rec_is_supremum(next_next_rec)) {
        goto split_at_new;
      }
      
      /* 如果不是 supremum 記錄，則設置拆分記錄為下下條記錄 */


      /* 這樣做的目的是，如果從插入點開始向上有 &amp;gt;= 2 條用戶記錄，
         我們在該頁上保留 1 條記錄，因為這樣後面的順序插入就可以使用
         自適應哈希索引，因為它們只需查看此頁面上的記錄即可對正確的
         搜索位置進行必要的檢查 */
      
      *split_rec = next_next_rec;
    }
    
    return true;
  }
  
  return false;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;插入 rec-5：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (5, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:4] page: 5 -&amp;gt; heap: 3
[pk:5] page: 7 -&amp;gt; heap: 3
[pk:10000] page: 7 -&amp;gt; heap: 2
[pk:10001] page: 6 -&amp;gt; heap: 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;開始分裂一個新頁 page 7，新的組織結構方式如下圖：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//7031952efa213a9713d777c6f94cdc34.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此時是一個正常的插入點右分裂機制，把老的 page 5 中的記錄 10000 都移動到了 page 7，並且新插入的 rec-5 也寫入到了 page 7 中。到此時看上去一切正常，接下來再插入記錄在當前這種結構下就會產生異常。&lt;/p&gt; 
&lt;p&gt;插入 rec-6：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (5, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:4] page: 5 -&amp;gt; heap: 3
[pk:5] page: 7 -&amp;gt; heap: 3
[pk:6] page: 8 -&amp;gt; heap: 3
[pk:10000] page: 8 -&amp;gt; heap: 2
[pk:10001] page: 6 -&amp;gt; heap: 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//40e9f1cbfbb9da1cfddff886a6f8b046.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此時也是一個正常的插入點右分裂機制，把老的 page 7 中的記錄 10000 都移動到了 page 8，並且新插入的 rec-6 也寫入到了 page 8 中，但是我們可以發現 page 7 中只有一條孤零零的 rec-5 了，一個頁只存儲了一條記錄。&lt;/p&gt; 
&lt;p&gt;按照代碼中正常的插入點右分裂機制，繼續插入 rec-7 會導致 rec-6 成為一個單頁、插入 rec-8 又會導致 rec-7 成為一個單頁，一直這樣循環下去。&lt;/p&gt; 
&lt;p&gt;目前來看就是在插入 rec-4，觸發了一個內部優化策略（具體優化沒太去研究），進行了一些特殊的記錄遷移和插入動作，當然跟記錄過大也有很大關係。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排查過程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有同學對這個問題排查過程比較感興趣，所以這裏也整理分享一下，簡化了一些無用信息，僅供參考。&lt;/p&gt; 
&lt;p&gt;表總行數在 400 百萬，正常情況下的大小在 33G 左右，變更之後的大小在 67G 左右。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先根據備份恢復了一個數據庫現場出來。&lt;/li&gt; 
 &lt;li&gt;統計了業務錶行大小，發現行基本偏大，在 4-7k 之間（一個頁只存了 2 行，浪費 1/3 空間）。&lt;/li&gt; 
 &lt;li&gt;分析了變更前後的表數據頁，以及每個頁存儲多少行數據。 
  &lt;ul&gt; 
   &lt;li&gt;發現變更之前數據頁大概 200 百萬，變更之後 400 百萬，解釋了存儲翻倍。&lt;/li&gt; 
   &lt;li&gt;發現變更之前存儲 1 行的頁基本沒有，變更之後存儲 1 行的頁接近 400 百萬。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於現在這些信息我們知道了存儲翻倍的根本原因，就是之前一個頁存儲 2 條記錄，現在一個頁只存儲了 1 條記錄，新的問題來了，為什麼變更後會存儲 1 條記錄，繼續尋找答案。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我們首先在備份恢復的實例上面進行了一次靜態變更，就是變更期間沒有新的 DML 操作，沒有復現。但説明瞭一個問題，異常跟增量有關，此時大概知道跟變更過程中的 binlog 回放特性有關【上面説的回放會導致主鍵 ID 大的記錄先寫入表中】。&lt;/li&gt; 
 &lt;li&gt;寫了個工具把 400 百萬數據每條記錄分佈在哪個頁裏面，以及頁裏面的記錄對應的 heap 是什麼都記錄到數據庫表中分析，慢長等待跑數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//45543ac5b25cbe5f8652f5ff9375e031.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;數據分析完後通過分析發現存儲一條數據的頁對應的記錄的 heap 值基本都是 3，正常應該是 2，意味着這些頁並不是一開始就存一條數據，而是產生了頁分裂導致的。&lt;/li&gt; 
 &lt;li&gt;開始繼續再看頁分裂相關的資料和代碼，列出頁分裂的各種情況，結合上面的信息構建了一個復現環境。插入數據頁分裂核心函數。 
  &lt;ul&gt; 
   &lt;li&gt;btr_cur_optimistic_insert：樂觀插入數據，當前頁直接存儲&lt;/li&gt; 
   &lt;li&gt;btr_cur_pessimistic_insert：悲觀插入數據，開始分裂頁&lt;/li&gt; 
   &lt;li&gt;btr_root_raise_and_insert：單獨處理根節點的分裂&lt;/li&gt; 
   &lt;li&gt;btr_page_split_and_insert：分裂普通頁，所有流程都在這個函數&lt;/li&gt; 
   &lt;li&gt;btr_page_get_split_rec_to_right：判斷是否是向右分裂&lt;/li&gt; 
   &lt;li&gt;btr_page_get_split_rec_to_left：判斷是否是向左分裂&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;heap&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;heap 是頁裏面的一個概念，用來標記記錄在頁裏面的相對位置，頁裏面的第一條用戶記錄一般是 2，而 0 和 1 默認分配給了最大最小虛擬記錄，在頁面創建的時候就初始化好了，最大最小記錄上面有簡單介紹。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解析 ibd 文件&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;更快的方式還是應該分析物理 ibd 文件，能夠解析出頁的具體數據，以及被分裂刪除的數據，分裂就是把一個頁裏面的部分記錄移動到新的頁，然後刪除老的記錄，但不會真正刪除，而是移動到頁裏面的一個刪除鏈表，後面可以複用。&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;五、變更後，統計信息為什麼差異巨大？&lt;/h1&gt; 
&lt;p&gt;表統計信息主要涉及索引基數統計（也就是唯一值的數量），主鍵索引的基數統計也就是錶行數，在優化器進行成本估算時有些 SQL 條件會使用索引基數進行抉擇索引選擇（大部分情況是 index dive 方式估算掃描行數）。&lt;/p&gt; 
&lt;p&gt;InnoDB 統計信息收集算法簡單理解就是採樣葉子節點 N 個頁（默認 20 個頁），掃描統計每個頁的唯一值數量，N 個頁的唯一值數量累加，然後除以 N 得到單個頁平均唯一值數量，再乘以表的總頁面數量就估算出了索引總的唯一值數量。&lt;/p&gt; 
&lt;p&gt;但是當一個頁只有 1 條數據的時候統計信息會產生嚴重偏差（上面已經分析出了表膨脹的原因就是一個頁只存儲了 1 條記錄），主要是代碼裏面有個優化邏輯，對單個頁的唯一值進行了減 1 操作，具體描述如下注釋。本來一個頁面就只有 1 條記錄，再進行減 1 操作就變成 0 了，根據上面的公式得到的索引總唯一值就偏差非常大了。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;static bool dict_stats_analyze_index_for_n_prefix(
    ...
    // 記錄頁唯一 key 數量
    uint64_t n_diff_on_leaf_page;
    
    // 開始進行 dive，獲取 n_diff_on_leaf_page 的值
    dict_stats_analyze_index_below_cur(pcur.get_btr_cur(), n_prefix,
                                       &amp;amp;n_diff_on_leaf_page, &amp;amp;n_external_pages);
    
    /* 為了避免相鄰兩次 dive 統計到連續的相同的兩個數據，因此減 1 進行修正。
    一次是某個頁面的最後一個值，一次是另一個頁面的第一個值。請考慮以下示例：
    Leaf level:
    page: (2,2,2,2,3,3)
    ... 許多頁面類似於 (3,3,3,3,3,3)...
    page: (3,3,3,3,5,5)
    ... 許多頁面類似於 (5,5,5,5,5,5)...
    page: (5,5,5,5,8,8)
    page: (8,8,8,8,9,9)
    我們的算法會（正確地）估計平均每頁有 2 條不同的記錄。
    由於有 4 頁 non-boring 記錄，它會（錯誤地）將不同記錄的數量估計為 8 條
    */ 
    if (n_diff_on_leaf_page &amp;gt; 0) {
      n_diff_on_leaf_page--;
    }
    
    // 更新數據，在所有分析的頁面上發現的不同鍵值數量的累計總和
    n_diff_data-&amp;gt;n_diff_all_analyzed_pages += n_diff_on_leaf_page;
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到 PRIMARY 主鍵異常情況下統計數據只有 20 萬，表有 400 百萬數據。正常情況下主鍵統計數據有 200 百萬，也與表實際行數差異較大，同樣是因為單個頁面行數太少（正常情況大部分也只有 2 條數據），再進行減 1 操作後，導致統計也不準確。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MySQL&amp;gt; select table_name,index_name,stat_value,sample_size from mysql.innodb_index_stats where database_name like 'sbtest' and TABLE_NAME like 'table_1' and stat_name='n_diff_pfx01';
+-------------------+--------------------------------------------+------------+-------------+
| table_name        | index_name                                 | stat_value | sample_size |
+-------------------+--------------------------------------------+------------+-------------+
| table_1           | PRIMARY                                    |     206508 |          20 |
+-------------------+--------------------------------------------+------------+-------------+
11 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;優化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了避免相鄰兩次 dive 統計到連續的相同的兩個數據，因此減 1 進行修正。&lt;/p&gt; 
&lt;p&gt;這裏應該是可以優化的，對於主鍵來説是不是可以判斷只有一個字段時不需要進行減 1 操作，會導致錶行數統計非常不準確，畢竟相鄰頁不會數據重疊。&lt;/p&gt; 
&lt;p&gt;最低限度也需要判斷單個頁只有一條數據時不需要減 1 操作。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;六、統計信息與慢 SQL 之間的關聯關係？&lt;/h1&gt; 
&lt;p&gt;當前 MySQL 對大部分 SQL 在評估掃描行數時都不再依賴統計信息數據，而是通過一種 index dive 採樣算法實時獲取大概需要掃描的數據，這種方式的缺點就是成本略高，所以也提供有參數來控制某些 SQL 是走 index dive 還是直接使用統計數據。&lt;/p&gt; 
&lt;p&gt;另外在 SQL 帶有 order by field limit 時會觸發 MySQL 內部的一個關於 prefer_ordering_index 的 ORDER BY 優化，在該優化中，會比較使用有序索引和無序索引的代價，誰低用誰。&lt;/p&gt; 
&lt;p&gt;當時業務有問題的慢 SQL 就是被這個優化幹擾了。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# where 條件
user_id = ? and biz = ? and is_del = ? and status in (?) ORDER BY modify_time limit 5


# 表索引
idx_modify_time(`modify_time`)
idx_user_biz_del(`user_id`,`biz`, `is_del`)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;正常走 idx_user_biz_del 索引為過濾性最好，但需要對 modify_time 字段進行排序。&lt;/p&gt; 
&lt;p&gt;這個優化機制就是想嘗試走 idx_modify_time 索引，走有序索引想避免排序，然後套了一個公式來預估如果走 idx_modify_time 有序索引大概需要掃描多少行？公式非常簡單直接：表總行數 / 最優索引的掃描行數 * limit。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;表總行數&lt;/strong&gt;：也就是統計信息裏面主鍵的 n_rows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;最優索引的掃描行數&lt;/strong&gt;：也就是走 idx_user_biz_del 索引需要掃描的行數&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;limit&lt;/strong&gt;：也就是 SQL 語句裏面的 limit 值&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用有序索引預估的行數對比最優索引的掃描行數來決定使用誰，在這種改變索引的策略下，如果表的總行數估計較低（就是上面主鍵的統計值），會導致更傾向於選擇有序索引。&lt;/p&gt; 
&lt;p&gt;但一個最重要的因素被 MySQL 忽略了，就是實際業務數據分佈並不是按它給的這種公式來，往往需要掃描很多數據才能滿足 limit 值，造成慢 SQL。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;七、如何臨時解決該問題？&lt;/h1&gt; 
&lt;p&gt;發現問題後，可控的情況下選擇在低峯期對錶執行原生 alter table xxx engine=innodb 語句， MySQL 內部重新整理了表空間數據，相關問題恢復正常。但這個原生 DDL 語句，雖然變更不會產生鎖表，但該語句無法限速，同時也會導致主從數據較大延遲。&lt;/p&gt; 
&lt;p&gt;為什麼原生 DDL 語句可以解決該問題？看兩者在流程上的對比區別。&lt;/p&gt; 
&lt;p&gt;&lt;img height="998" src="https://oscimg.oschina.net/oscnet/up-96cde8c478aed80cce1aa1079fe94b9d788.png" width="2314" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看出結構變更唯一不同的就是增量 DML 語句是等全量數據複製完成後才開始應用，所以能修復表空間，沒有導致表膨脹。&lt;/p&gt; 
&lt;span id="OSC_h1_8"&gt;&lt;/span&gt; 
&lt;h1&gt;八、如何長期解決該問題？&lt;/h1&gt; 
&lt;p&gt;關於業務側的改造這裏不做過多説明，我們看看從變更流程上面是否可以避免這個問題。&lt;/p&gt; 
&lt;p&gt;既然在變更過程中複製全量數據和 binlog 增量數據回放存在交叉並行執行的可能，那麼如果我們先執行全量數據複製，然後再進行增量 binlog 回放是不是就可以繞過這個頁分裂問題（就變成了跟 MySQL 原生 DDL 一樣的流程）。&lt;/p&gt; 
&lt;p&gt;變更工具實際改動如下圖：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cfa56e38aaaf236bf1fc76e8c5f704d5.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這樣就不存在最大記錄先插入到表中的問題，丟棄的記錄後續全量複製也同樣會把記錄複製到臨時表中。並且這個優化還能解決需要大量回放 binlog 問題，細節可以看看 gh-ost 的 PR-1378。&lt;/p&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;九、總結&lt;/h1&gt; 
&lt;p&gt;本文先介紹了一些關於 InnoDB 索引機制和頁溢出、頁分裂方面的知識；介紹了業界通用的 DDL 變更工具流程原理。&lt;/p&gt; 
&lt;p&gt;隨後詳細分析了變更後表空間膨脹問題根因，主要是當前變更流程機制疊加單行記錄過大的時候（業務表單行記錄大小 5k 左右），會碰到 MySQL 頁分裂的一個瑕疵，導致了一個頁只存儲了 1 條記錄（16k 的頁只存儲了 5k，浪費 2/3 空間），導致存儲空間膨脹問題。&lt;/p&gt; 
&lt;p&gt;最後分析了統計信息出錯的原因和統計信息出錯與慢 SQL 之間的關聯關係，以及解決方案。&lt;/p&gt; 
&lt;p&gt;全文完，感謝閲讀。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1. MySQL 單表為何別超 2000 萬行？揭祕 B+樹與 16KB 頁的生死博弈｜得物技術&lt;/p&gt; 
&lt;p&gt;2. 0 基礎帶你精通 Java 對象序列化--以 Hessian 為例｜得物技術&lt;/p&gt; 
&lt;p&gt;3. 前端日誌回撈系統的性能優化實踐｜得物技術&lt;/p&gt; 
&lt;p&gt;4. 得物靈犀搜索推薦詞分發平台演進 3.0&lt;/p&gt; 
&lt;p&gt;5. R8 疑難雜症分析實戰：外聯優化設計缺陷引起的崩潰｜得物技術&lt;/p&gt; 
&lt;p&gt;文 / 東青&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18692318</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18692318</guid>
      <pubDate>Thu, 18 Sep 2025 03:30:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>技嘉 2025 發佈會：「從心出發，我們的主張」，邁向 AI 新紀元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;今日，技嘉以 「從心出發，我們的主張」 為主題的產品發佈會在線下開啓。這場聚焦 PC 硬件領域的盛宴，圍繞用戶需求發佈了全新的產品和軟件佈局，從極限性能突破到美學設計創新，從 AI 算力佈局到裝機體驗優化，全方位展現技嘉在主板、整機、軟件工具等領域的技術沉澱與產品實力，為全球硬件愛好者呈現一場 「始於需求，忠於體驗」 的科技盛宴。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//7188b75b11081320c2a2057980516908.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在技嘉新品發佈會上，行業巨頭與意見領袖齊聚一堂。英偉達、英特爾和 AMD 代表共同出席，同時邀請了各大媒體、KOL 及知名電競主播一起見證這場硬件科技盛宴。多方技術協同的強大陣容，凸顯了技嘉在行業中的領軍地位，也為發佈會增添了濃厚的專業氛圍與權威性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//fedc6b1b84b463493ef520e48fb114ab.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;技嘉科技集團總經理，林英宇先生致開場詞，並討論現代社會 AI 與日常生活的深入聯繫，技嘉由從此出發從硬件到軟件融入，使 AI 技術為個人用戶、企業和內容創作者提供更優質的生產力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;極限超頻的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;「&lt;/strong&gt;&lt;strong&gt;硬核秀場&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;多項超頻世界紀錄保持者「HiCookie」柯智化先生親臨現場，帶來液氮極限超頻演示。在眾多媒體和嘉賓的圍觀下，技嘉 X870 AORUS TACHYON ICE 鈦冰雕的頻率參數不斷突破上限，每一次屏幕上的數值跳動，直觀展現了技嘉主板在超頻能力、處理器供電穩定性以及硬件兼容性上的頂尖實力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0cfe623335217b1f9acacbf498256227.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;媒體圍觀 HiCookie 現場超頻挑戰&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//181faa76425562f33ab0ac0181075eb9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;HiCookie 指導雕妹進行液氮超頻&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;隨後技嘉展示了本場發佈會的重磅新品——採用 AMD 最新 X870E 芯片組的系列主板，其中 X870E AORUS MASTER X3D ICE 超級冰雕，主板憑藉全白散熱裝甲設計成為現場顏值焦點。除 8 層背鑽 PCB 設計之外，技嘉的 X3D 系列遊戲主板採用多種先進技術，可以顯著提升 DDR5 內存性能，同時還支持 DDR5 內存穩定運行在 9000 + MT/s 的超高頻率。僅從硬件方面來看，已經達到了行業領先級水準。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e32b8bc3cb3e222e31bb92e9d8814216.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;全新 X3D 雞血模式 2.0，更是在現場完成實測驗證——通過現場操作，X3D 雞血模式 2.0 功能開啓後，可智能識別遊戲、設計等不同負載場景，自動調校覈心參數，無需手動設置即可實現性能提升，CPU 性能最高可提升 140%，遊戲性能提升 15%！&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;此外活動現場技嘉還展示了 INTEL 800 系列主板，包括 Z890 超級雕和千元級熱銷產品 B860M 電競雕，該系列同樣支持各類快拆設計、WIFI7 天線等功能，同時還新加入了 Intel 200S Boost 功能，遊戲性能顯著提升。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c9903641dfa928bfabb519c029e964d6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;目前支持技嘉 D5 黑科技 2.0 技術的主板，均可在 BIOS 中輕鬆實現「提升內存帶寬」和「降低延遲」，同時 D5 黑科技 2.0 版本兼容性更強，並進一步支持自動超頻內存。作為技嘉 AORUS 星推官的知名電競主播 CSGO 茄子現場體驗了 D5 黑科技 2.0，簡單操作即可在 CS2 遊戲中獲得顯著的遊戲幀數提升，技嘉無門檻的自動優化技術在現場大獲好評。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//8326332304e3aaba2e89aba77c4a2011.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;整機美學與產品矩陣的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;「&lt;/strong&gt;&lt;strong&gt;視覺盛宴&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在產品展示區，技嘉以產品牆和 MOD 整機等形式陳列多套產品，其中，技嘉 B850M AORUS ELITE WIFI7 ICE-P 「雕妹」 主板以國風祥雲紋路設計，成為現場 「顏值爆款」；技嘉 X870I AORUS PRO ICE 迷你冰雕則憑藉純白 ITX 板型，將為小型主機玩家的優質選擇。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cb9781e2106ba532dad693fabd1302ed.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;TOP&lt;/strong&gt;&lt;strong&gt;算力全家桶的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;「&lt;/strong&gt;&lt;strong&gt;前瞻體驗&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;着眼於未來計算需求， 「創心，佈局未來」分區重點展示了技嘉 AI TOP 系列全家桶。整機採用了 AMD Ryzen Threadripper PRO 7965WX 處理器、技嘉 TRX 50 AI TOP 主板以及技嘉獨家定製的四路 AMD Radeon AI Pro R9700 32G 的強大組合，賦予了超過 500 TFLOP/s 的超大算力，為個人和企業工作者在 AI、設計、渲染等內容創作工作中帶來了全新體驗。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//53c4068f00cbc5c7b7ef71e34692afa6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;軟件工具的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;「&lt;/strong&gt;&lt;strong&gt;用戶友好革命&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;針對玩家 「軟件調試複雜」 的痛點，技嘉沉浸式展示了三大核心軟件工具。以 「簡化操作，提升效率」 為目標，技嘉全新圖形化 BIOS 支持鼠標操作，內置一鍵超頻、系統優化等快捷功能，新手可快速上手，資深用戶亦能自定義細調參數；GCC——技嘉控制中心則實現硬件參數 「一站式管理」，通過統一界面即可調控主板燈效、風扇轉速、內存超頻及存儲設置，操作直觀高效；顯示器電競輔助功能同步亮相，戰術鍵 2.0 可一鍵切換顯示模式，閃光壓制功能亦能降低遊戲中強光幹擾，全方位提升電競操控體驗。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c3a8aac6af795458107fb6068f9bee51.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;裝機體驗的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;「&lt;/strong&gt;&lt;strong&gt;便捷升級&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「巧心，以人為本」 聚焦 「降低裝機門檻」，集中展現技嘉對用戶操作體驗的優化設計。主板搭載的 DIY「快易拆」 尤為亮眼：卡扣式設計替代傳統螺絲固定，無需螺絲刀即可完成維護；顯卡採用新一代散熱模組，搭配獨家服務器級導熱凝膠，兼顧散熱與效能；「機械雕」機箱則以全模塊化結構為亮點，側板、硬盤架等組件可自由拆卸，支持用戶根據需求進行個性化 MOD 改裝，輕鬆打造專屬裝機方案，讓「裝機小白也能輕鬆上手」 成為現實。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f5cd12595fd509fe531a580110c7e61d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;從心出發，以技術匠心定義品牌價值&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;技嘉始終以 「技術創新」 為內核，以 「用戶需求」 為導向。本次發佈會不僅展現了技嘉在主板、顯卡、整機以及 AI 硬件等領域的技術實力，更傳遞出 「從心出發」 的品牌溫度 —— 不只是打造參數領先的硬件，更是創造貼合用戶生活與使用場景的解決方案。未來，技嘉將以 「我們的主張」 為指引，在性能突破、體驗優化、美學創新的道路上持續探索，為全球用戶帶來更多 「始於需求，忠於體驗」 的優質產品。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373150</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373150</guid>
      <pubDate>Thu, 18 Sep 2025 03:16:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>亞馬遜雲科技推出 Qwen3 與 DeepSeek-V3.1 模型的完全託管服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亞馬遜雲科技宣佈，在 Amazon Bedrock 上新增 Qwen3 和 DeepSeek-V3.1 開放權重模型，這些模型現已在全球範圍內正式可用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;公告稱，亞馬遜雲科技致力於成為運行開放權重模型的最佳平台，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;此次新增模型進一步擴展了 Amazon Bedrock 上現已豐富的開放權重模型選擇，Amazon Bedrock 上其他開放權重模型還包括來自 Meta、Mistral AI 和 OpenAI 的模型。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通過在 Amazon Bedrock 上使用這些模型，客戶可以獲得企業級的安全保障，包括數據加密和嚴格的訪問控制，幫助客戶保持數據隱私和滿足合規要求。客戶對其數據擁有完全控制權，這意味着亞馬遜雲科技不會與模型提供商共享客戶的模型輸入和輸出數據，這些數據也不會用於基礎模型的改進。此外，客戶還可以設置安全保障措施，如亞馬遜雲科技推薦的 Amazon Bedrock Guardrails 來檢測和防止模型幻覺。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亞馬遜雲科技客戶現可使用四個 Qwen3 系列開放權重模型。這些模型具備多步驟工作流規劃的能力，可與工具和 API 集成，並能在單個任務中處理長上下文窗口，其中兩個通用模型還提供"思考"和"非思考"推理模式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3 系列模型支持多語言處理，尤其在中文和英文方面表現卓越，可幫助企業實現跨文化業務運營和內容創作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3-Coder-480B-A3B-Instruct 和 Qwen3-Coder-30B-A3B 針對複雜的軟件工程場景進行優化，包括代碼生成和理解以及高級 Agentic 任務。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;這些模型&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;不僅支持多種編程語言的代碼編寫，還能自主調用各類數字工具（如外部工具和應用程序）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen-3-235B-A22B-Instruct-2507 專為通用推理設計，在性能與效率間實現平衡，在代碼、數學和通用推理等任務中都表現出色。"混合專家"（MoE）模型在處理每個請求時只激活部分參數，這意味着針對特定任務或問題，他們只調用相關知識，從而實現高性能和高效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3-32B（Dense）則適用於在計算資源有限情況下的計算任務和應用程序，或者需要穩定、可預測性能的場景。與 MoE 模型類似專家團隊只在需要時才激活他們的特定專業知識不同，"Dense"模型通常規模更小，所有組件始終協同工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果把 Qwen3 系列模型擬人化，Qwen3-Coder 系列就像是那些注重細節的朋友，他們能夠耐心地按照複雜的傢俱組裝説明，一步步將散落的零件組裝成一個完美的書櫃，同時還能清晰地解釋每個步驟。而通用型的 Qwen3 模型則像一個精通多國語言的大家庭，他們不僅能流利地使用數十種語言交流，還擁有百科全書般的知識儲備，無論是講解科學概念還是創作故事都遊刃有餘。他們可以就幾乎任何話題展開深入對話，並且能記住之前對話中的每個細節，不管這段對話發生在多久之前。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最新的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fbedrock%2Fdeepseek%2F" target="_blank"&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#0563c1"&gt;&lt;u&gt;&lt;span&gt;DeepSeek&lt;/span&gt;&lt;/u&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;模型 DeepSeek-V3.1 提供混合推理能力，在快速響應和深度、透明的思考間實現平衡。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;客戶可以根據需求在兩種模式間切換："思考模式"通過一步一步的解決問題，"快速響應模式"則適用於簡單的問題，客戶能夠清晰地瞭解模型的決策過程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這個高度複雜的模型可與當今最先進的 AI 系統相媲美，而其 MoE（混合專家）架構意味着客戶在享受卓越性能的同時還能優化計算成本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DeepSeek-V3.1 支持多語言處理，在軟件開發、數學推理和數據分析等領域表現出色，能夠高效解決各類編程和技術挑戰。同時，該模型特別適合構建如 AI Agents 和流程自動化等 Agentic 問題解決任務。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果將 DeepSeek-V3.1 擬人化，它就像是擅長解決問題的好友，會通過邏輯推理系統地分解挑戰，同時根據問題的複雜程度調整處理方式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亞馬遜雲科技 Amazon Bedrock 總監 Luis Wang 表示："開放權重模型代表着 AI 創新的重要前沿，這也是為什麼我們不斷投入使亞馬遜雲科技成為安全、規模化且具有成本效益地運行這些模型的最佳平台。我們認為沒有一個模型能適合所有使用場景...很多客戶喜歡使用開源模型，而開源模型的一大優勢在於它能為用戶提供更大的靈活性去探索和使用。"&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;數據詳解&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3-Coder-30B-A3B-Instruct 和 Qwen3-235B-A22B-Instruct-2507 模型可即刻處理高達 262K token 的上下文長度。在單次對話中，相當於約 20 萬個字符或兩部完整的長篇小説的內容量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DeepSeek-V3.1 擁有 6,850 億參數。參數可以理解為模型的"知識連接點"，是訓練過程中不斷調整的內部數值設置，幫助模型從數據中學習並做出預測。DeepSeek-V3.1 每次任務只調用相關知識部分，在保持強大性能的同時優化了運行成本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根據&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartificialanalysis.ai%2Fmodels%2Fdeepseek-v3-1-reasoning%2Fproviders" target="_blank"&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#0563c1"&gt;&lt;u&gt;&lt;span&gt;Artificial Analysis&lt;/span&gt;&lt;/u&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;,DeepSeek-V3.1 相比前代實現了顯著提升，尤其是推理能力和 Agentic 技能方面。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373148</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373148</guid>
      <pubDate>Thu, 18 Sep 2025 03:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微盟集團獲 2 億美金投資，CEO 孫濤勇：迎接 Agentic Al 時代</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微盟集團&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5VU-h0GWb8iFdDhjr7jpYA" target="_blank"&gt;發佈公告&lt;/a&gt;稱獲得國際長線投資 2 億美金。本輪融資將主要用於三大方面：首先是 AI 在 SaaS 中的整合和應用；其次是擴大媒體渠道及精準營銷服務能力，深化在抖音及小紅書等平台的生態佈局；最後是積極推進海外業務發展，佈局跨境出海業務等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1576" src="https://static.oschina.net/uploads/space/2025/0919/110725_3DRL_2720166.png" width="1348" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微盟集團創始人、CEO 孫濤勇在朋友圈發文表示，感謝 Infini 的認可，下個十年必定是中國科技企業全球綻放的時刻，補充彈藥迎接 Agentic Al 時代。&lt;/p&gt; 
&lt;p&gt;&lt;img height="872" src="https://static.oschina.net/uploads/space/2025/0919/110635_Qdu4_2720166.png" width="2034" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微盟集團是中國的雲端商業及營銷解決方案提供商，面向電商零售、超市生鮮、商業地產、百貨直銷等行業提供數字化解決方案。公司成立於 2013 年，初期從微信公眾號切入，定位於微信第三方服務商。據微盟集團發佈的 2025 年 H1 財報顯示，上半年總收入 7.75 億，經調整同比增長 7.8%，經調整淨盈利 0.17 億。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373145</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373145</guid>
      <pubDate>Thu, 18 Sep 2025 03:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>傳中國不買這款特供芯片，黃仁勳：很失望，但理解</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F09%2F17%2Fnvidia-ceo-disappointed-after-reports-china-has-banned-its-ai-chips.html" target="_blank"&gt;據 CNBC 報道&lt;/a&gt;，針對中國疑似停止採購 RTX Pro 6000D 專供芯片的報道，英偉達首席執行官黃仁勳在倫敦回應稱感到「失望」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/110208_q1ir_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他説：「我們為中國市場所做的貢獻或許超過了多數其他國家，所以看到如今的情況我很失望。但中美之間有更宏大的議程有待協調，我對此表示理解。」&lt;/p&gt; 
&lt;p&gt;英偉達在中國的業務近幾年可謂跌宕起伏，黃仁勳用「過山車」來形容這一過程。他在新聞發佈會上告訴媒體：「我們已經建議所有財經分析師不要再將中國市場納入財務預測。原因很簡單，因為這最終將取決於美國政府和中國政府之間的磋商。」&lt;/p&gt; 
&lt;p&gt;此前，美國已因國家安全為由，對英偉達多款出口中國的 AI 芯片實施限制，其中包括性能較低的服務器芯片 H20。但在今年八月，白宮宣佈時任總統唐納德·特朗普（Donald Trump）已與黃仁勳達成協議，英偉達可獲出口許可，條件是 H20 在中國銷售額的 15% 需上繳美國政府。&lt;/p&gt; 
&lt;p&gt;據路透社報道，知情人士稱，RTX6000D 市場需求平淡，一些大型科技企業已選擇不下訂單。據瞭解，這款芯片主要用於 AI 推理任務，但業內普遍認為其性價比不高。&lt;/p&gt; 
&lt;p&gt;他們補充説，樣品測試表明，這款芯片的性能不及 RTX5090。後者雖已被美國禁售，但仍能通過灰色市場渠道輕易買到，價格不到 RTX6000D 約 5 萬元人民幣售價的一半。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373142</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373142</guid>
      <pubDate>Thu, 18 Sep 2025 03:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌在 Chrome 瀏覽器中引入 Gemini</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌近日宣佈將其人工智能技術 Gemini 整合到 Chrome 瀏覽器中，以應對來自 OpenAI 和 Perplexity 等初創公司的競爭壓力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據谷歌的博客公告，Gemini 將為美國的 Mac 和 Windows 電腦用戶以及移動設備用戶提供服務。用戶將能夠通過 Gemini 更好地理解特定網頁的內容，支持跨選項卡的工作，或者在單個選項卡內完成更多任務，例如安排會議或搜索 YouTube 視頻。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="323" src="https://oscimg.oschina.net/oscnet/up-191a79fab5da45056a2a42522c9c9608b2d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌平台和設備&lt;span&gt;高級&lt;/span&gt;副總裁 Rick Osterloh 表示：「我們正在改進瀏覽器，以幫助用戶充分利用網絡，這在幾年前是無法想象的。同時，我們也保持了 Chrome 在速度、簡單性和安全性方面的優勢。」&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;互聯網瀏覽器是獲取在線信息的關鍵工具，因此成為了各大公司爭奪人工智能市場的焦點。長期以來，谷歌和蘋果主導着大部分互聯網流量，這也是美國司法部試圖迫使谷歌剝離 Chrome 的原因之一。然而，最近一位法官裁定谷歌可以保留 Chrome，主要是因為生成式人工智能的出現已經顯著改變了競爭環境。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，人工智能公司們紛紛推出自己的瀏覽器，試圖在用戶體驗上佔據更多市場份額。例如，今年 1 月，OpenAI 推出了名為 Operator 的代理，可以在瀏覽器中完成購物等任務，此外還在開發基於開源 Chromium 代碼的自家瀏覽器。與此同時，Anthropic 也推出了基於瀏覽器的人工智能代理，而 Perplexity 則在上個月發佈了 Comet 瀏覽器，專注於人工智能任務。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新版本的 Gemini 與谷歌的日曆、YouTube 和地圖等應用深度整合，用戶無需切換頁面就能訪問這些服務。谷歌產品副總裁 Mike Torres 在博客中提到，未來幾周內，谷歌的企業生產力工具 Google Workspace 的用戶也將能使用 Gemini，且會享有 「企業級數據保護」。此外，谷歌還介紹了 Gemini 的新代理功能，用戶可以要求 Gemini 代理執行一些特定任務，例如預約理髮或購買每週的雜貨。這些功能原本是名為 「水手項目」 的內部項目的一部分，受到員工的歡迎。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在宣佈此消息之前，谷歌要求用戶註冊某些訂閲才能在 Chrome 中使用 Gemini，而現在這一功能的應用範圍和功能都有了顯著擴大。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373141</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373141</guid>
      <pubDate>Thu, 18 Sep 2025 03:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 與 Gemini 雙雙斬獲 ICPC 2025 金牌</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fworldfinals.icpc.global%2F2025%2F" target="_blank"&gt;2025 國際大學生程序設計競賽（ICPC）&lt;/a&gt;世界總決賽的平行 AI 測試中，OpenAI 與谷歌 Gemini 推理模型雙雙斬獲金牌，其中 OpenAI 更是以滿分成績橫掃全場，成為唯一全解團隊。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/105648_LIMz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在為期 5 小時的比賽中，參賽隊伍需解決 12 道高難度算法題。Gemini 成功攻克其中 10 題，並在 30 分鐘內破解所有人類隊伍未能解決的死亡 C 題。而 OpenAI 則以 12/12 的滿分成績碾壓 139 支人類隊伍，成為唯一實現 AK（All Kill）戰績的團隊。&lt;/p&gt; 
&lt;p&gt;值得注意的是，OpenAI 所用模型中，11 道題目由 GPT-5 直接完成，最後一道最難題則由尚未公開的實驗性推理模型解決，引發外界對下一代 AI 推理能力的高度關注。&lt;/p&gt; 
&lt;p&gt;谷歌方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fgoogle-deepmind%2Fgemini-gold-icpc%2F" target="_blank"&gt;面透露&lt;/a&gt;，Gemini 2.5 Deep Think 並未為 ICPC 進行專門訓練，而是使用與 Gemini 應用中相同的模型，僅在推理能力上做了增強。該模型在比賽前 45 分鐘內迅速解出 8 題，最終以 10 題成績獲得金牌。&lt;/p&gt; 
&lt;p&gt;OpenAI 背後的研究團隊也在社交平台連發 8 條&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgdb%2Fstatus%2F1968404060001968429" target="_blank"&gt;推文&lt;/a&gt;慶祝勝利，並公開了部分關鍵研究人員身份。其中包括 ICPC 2015 世界冠軍成員 Borys Minaiev 以及 OpenAI 首席科學家 Jakub Pachocki —— 同樣是 ICPC 金牌得主。&lt;/p&gt; 
&lt;p&gt;ICPC 全球執行董事 BILL POUCHER 博士表示：「AI 在 ICPC 上斬獲金牌，標誌着人工智能工具已具備定義下一代學術標準的能力。它不僅能輔助程序員解決問題，更將在藥物設計、芯片開發等領域發揮巨大作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373139/openai-gemini-gold-icpc</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373139/openai-gemini-gold-icpc</guid>
      <pubDate>Thu, 18 Sep 2025 02:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
