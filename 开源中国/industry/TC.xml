<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 27 Jun 2025 02:43:00 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>阿里巴巴 2025 財年收入 9963 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;6 月 26 日晚，阿里巴巴集團發佈 2025 財年年報顯示，2025 財年阿里巴巴集團收入達 9963.47 億元，淨利潤同比增長 77% 至 1259.76 億元，展現出強勁的盈利能力。在 AI 需求的推動下，阿里雲財年收入突破雙位數增長，AI 相關產品收入連續七個季度實現三位數同比增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 AI 領域，過去一年阿里發佈並開源多款模型，覆蓋全尺寸、全模態、多場景。4 月最新發布的阿里通義 Qwen3（簡稱「千問 3」）大模型，開源僅一個月全球累計下載量突破 1250 萬。截至 4 月底，阿里通義已開源 200 餘款模型，全球下載量超過 3 億次，千問系列衍生模型數量超 10 萬個，成為全球最大的開源模型家族。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;阿里雲加速 AI 產品國際化，截至 2025 年 3 月 31 日，為全球 34 個地區提供雲計算服務。以通義大模型為底座，淘寶天貓、1688、阿里國際站、夸克、釘釘、高德、飛豬、閒魚等阿里多業務 AI 升級加速。其中，阿里 AI 旗艦應用夸克用戶規模同比迅速增長，截至 2025 財年末，月活躍用戶數已突破 2 億；2025 年 3 月，釘釘的平均付費周活躍用戶數達 4200 萬，目前釘釘是國內最大的效率辦公類 App。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在致股東信中，阿里巴巴表示，「阿里的基因裏沒有守成，只有創造。今天的阿里巴巴，正在以創業者的姿態，開啓面向 AI 時代的全新徵程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="373" src="https://oscimg.oschina.net/oscnet/up-074b55c1ba3ac1d7195b638a6c1bada394d.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，阿里巴巴合夥人名單相比 2024 財年年報披露時發生變化，總數從 26 人減少至 17 人，戴珊、方永新、彭蕾、宋潔、孫利軍、武衞、俞永福、張勇、朱順炎等 9 人退出合夥人之列。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357517</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357517</guid>
      <pubDate>Fri, 27 Jun 2025 02:19:57 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手開源多模態大模型 Kwai Keye-VL</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;快手宣佈並開源其最新自研的多模態大語言模型 Kwai Keye-VL。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，Kwai Keye-VL 以 Qwen3-8B 語言模型為基礎，引入了基於開源 SigLIP 初始化的 VisionEncoder，能夠深度融合並處理文本、圖像、視頻等多模態信息，憑藉其創新的自適應交互機制與動態推理能力，旨在為用戶提供更智能、全面的多模態交互體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Kwai Keye-VL 支持動態分辨率輸入，按原始比例將圖像切分為 14x14 &amp;nbsp;patch 序列，由一個 MLP 層將視覺 Token 進行映射與合併。模型採用 3D RoPE （旋轉位置編碼）統一處理文本、圖像和視頻，並通過位置編碼與時間戳對齊，精準捕捉視頻時序變化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="366" src="https://oscimg.oschina.net/oscnet/up-f9bb9b208e03575669510048f8ff6cabc1e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="138" src="https://oscimg.oschina.net/oscnet/up-a5530c104b198c517ed650e3e67740584c5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在視覺理解與邏輯推理能力方面，Kwai Keye-VL 的綜合感知能力媲美同規模頂尖模型，並在複雜推理任務中展現出顯著優勢。尤其是邏輯推理方面，Kwai Keye-VL 在最新的 2025 年高考全國數學卷中取得了 140 分的成績。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="314" src="https://oscimg.oschina.net/oscnet/up-d0c30a1de0375792399c2797d5e075fce36.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為突破公開數據集的數據污染、語言覆蓋侷限及任務單一性等問題，快手構建了內部評測集 KC-MMBench。結果顯示：該模型在 VideoMME 等權威公開 Benchmark 中以 67.4 分超越 Qwen2.5-VL-7B（62.7）與 InternVL-3-8B（65.5）；在內部短視頻場景評測中優勢進一步擴大，綜合得分領先 SOTA 模型超 10%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-d5f95b60cd23280d98fa13ffda02bd537e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2JRGYhB_VDPecXMjp3gZsQ" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357515</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357515</guid>
      <pubDate>Fri, 27 Jun 2025 02:12:57 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gartner：超 40% 的 AI 智能體項目活不過兩年</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;研究諮詢公司 Gartner 最新發布的一份報告&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gartner.com%2Fen%2Fnewsroom%2Fpress-releases%2F2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027" target="_blank"&gt;指出&lt;/a&gt;，預計到 2027 年底，超過 40% 的 AI 智能體項目將被取消，原因是成本不斷上升和商業價值不明確。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Gartner 高級總監分析師 Anushree Verma 表示：「目前大多數 AI 智能體項目都處於早期實驗或概念驗證階段，這些項目大多受到炒作的驅動，並且經常被誤用。這可能會讓企業忽視大規模部署 AI 智能體的實際成本和複雜性，從而阻礙項目投入生產。他們需要撥開炒作的迷霧，謹慎地制定戰略決策，確定在何處以及如何應用這項新興技術。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-4f7c22926062ebd6122d8165e030afd0db5.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Gartner 基於 3412 名受訪者的調查結果顯示，19% 的人表示其組織已對 AI 智能體項進行了大量投資，42% 的人進行了保守投資，8% 的人沒有投資，其餘 31% 的人採取觀望態度或不確定。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;許多供應商通過「洗牌」來炒作，即對現有產品（例如 AI 助手、機器人流程自動化 (RPA) 和聊天機器人）進行品牌重塑，而這些產品本身並不具備實質性的智能體功能。Gartner 估計，在數千家 AI 智能體供應商中，只有大約 130 家是有真材實料的。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「大多數 AI 智能體方案缺乏顯著的價值或投資回報率 (ROI)，因為目前的模型還不夠成熟，無法自主實現複雜的業務目標或持續遵循細微的指令。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Gartner 預測，到 2028 年，至少 15% 的日常工作決策將通過 AI 智能體自主做出，而 2024 年這一比例為 0%。此外，到 2028 年，33% 的企業軟件應用程序將包含 AI 智能體，而 2024 年這一比例還不到 1%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在早期階段，Gartner 建議僅在能夠帶來明確價值或投資回報率 (ROI) 的情況下才應採用 AI 智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「為了從 AI 智能體中獲得真正的價值，組織必須專注於企業生產力，而不僅僅是增強單個任務。他們可以先在需要決策時使用 AI 智能體，在日常工作流程中實現自動化，並在簡單檢索時使用助手。這關乎通過成本、質量、速度和規模來推動業務價值。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357455/gartner-over-40-percent-agentic-ai-projects-cancel-2027</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357455/gartner-over-40-percent-agentic-ai-projects-cancel-2027</guid>
      <pubDate>Sat, 10 May 2025 10:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>LowCodeEngine —— 企業級低代碼技術體系</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;一套面向擴展設計的企業級低代碼技術體系。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;img alt="" height="276" src="https://static.oschina.net/uploads/space/2025/0619/160054_sOPF_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;特性&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;提煉自企業級低代碼平台的面向擴展設計的內核引擎，奉行最小內核，最強生態的設計理念&lt;/li&gt;
&lt;li&gt;開箱即用的高質量生態元素，包括，物料體系、設置器、插件，等&lt;/li&gt;
&lt;li&gt;完善的工具鏈，支持，物料體系、設置器、插件，等生態元素的全鏈路研發週期&lt;/li&gt;
&lt;li&gt;強大的擴展能力，已支撐 100+ 個各種類型低代碼平台&lt;/li&gt;
&lt;li&gt;使用 TypeScript 開發，提供完整的類型定義文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;兼容環境&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;現代瀏覽器（Chrome &amp;gt;= 80, Edge &amp;gt;= 80, last 2 safari versions, last 2 firefox versions）&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;引擎協議&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;引擎完整實現了《低代碼引擎搭建協議規範》和《低代碼引擎物料協議規範》，協議棧是低代碼領域的物料能否流通的關鍵部分。&lt;/p&gt;

&lt;p&gt;&lt;img height="277" src="https://static.oschina.net/uploads/space/2025/0619/160028_gMUx_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/lowcode-engine</link>
      <guid isPermaLink="false">https://www.oschina.net/p/lowcode-engine</guid>
      <pubDate>Sat, 10 May 2025 09:49:00 GMT</pubDate>
    </item>
    <item>
      <title>Mozilla 終止維護開源語音轉文本引擎項目「DeepSpeech」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSpeech 是 Mozilla 開發的一款開源語音轉文本引擎，基於百度 2014 年發表的研究論文《Deep Speech: Scaling up end-to-end speech recognition》所提出的端到端語音識別方法開發。&lt;/p&gt; 
&lt;p&gt;從&amp;nbsp;DeepSpeech 的倉庫動態來看，Mozilla 已於上週將項目倉庫歸檔，並表示停止維護。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/155240_73ji_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為一款端到端自動語音識別（ASR）引擎，DeepSpeech 即使在 Raspberry Pi SBC 和其他低功耗系統上運行時，也能提供出色的實時通信性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-762647632f4a326522c5f510328561b4af1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;遺憾的是，&lt;span&gt;近年來 DeepSpeech 項目的活躍度持續降低，其&lt;/span&gt;最後一個標記版本是 2020 年 12 月發佈的 0.9.3。&lt;/p&gt; 
&lt;p&gt;DeepSpeech&lt;span&gt;&amp;nbsp;GitHub 倉庫已經有近 4 年沒有任何 commit，社區貢獻和更新頻率都不盡如人意，這使得項目的進一步發展受到限制，因此 Mozilla 選擇終止該項目。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357400/mozilla-deepspeech-discontinued</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357400/mozilla-deepspeech-discontinued</guid>
      <pubDate>Sat, 10 May 2025 08:04:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 如何保障「代碼索引」的安全、高效</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; AI 編程工具如何迅速檢索海量代碼庫，並精準定位到最相關的代碼片段？這個看似不可能完成的任務，卻是決定現代 AI 編程工具用戶體驗的關鍵技術挑戰。&lt;/p&gt; 
 &lt;p&gt;我們今天為大家帶來的這篇文章，作者的觀點是：Cursor 通過巧妙運用默克爾樹數據結構，實現了對大型代碼庫的快速索引和高效增量更新，這正是其能夠提供精準 AI 輔助編程服務的技術基礎。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Engineer's Codex&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Cursor ------ 這家最近宣佈斬獲 3 億美元年營收的熱門 AI 開發工具 ------ 正是利用默克爾樹（Merkle trees）實現對代碼的快速索引。本篇文章將為你詳細介紹其運作原理。&lt;/p&gt; 
&lt;p&gt;在深入瞭解 Cursor 的具體實現方法之前，我們先來瞭解一下默克爾樹的基本概念。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 默克爾樹的簡單解釋&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;默克爾樹（Merkle tree）是一種樹狀數據結構，其每個"葉"節點都標註了對應數據塊的加密哈希值，而每個非葉節點則存儲其子節點哈希值組合後的新哈希值。這種層級結構通過比較哈希值，能有效地偵測任何層級的數據變動。&lt;/p&gt; 
&lt;p&gt;通俗理解，它就像是數據的指紋系統：&lt;/p&gt; 
&lt;p&gt;1）每份數據（例如文件）都擁有自己獨一無二的指紋（哈希值）&lt;/p&gt; 
&lt;p&gt;2）成對的指紋被組合在一起，生成一個新的指紋&lt;/p&gt; 
&lt;p&gt;3）此過程層層遞進，直至形成唯一的主指紋（根哈希）&lt;/p&gt; 
&lt;p&gt;根哈希（root hash）概括了所有底層數據塊的指紋信息，相當於對整個數據集做了一次加密公證。只要根哈希不變，就能證明原始數據分毫未改。此機制的精妙之處在於：&lt;strong&gt;任何一個數據塊發生變化，都將牽一髮而動全身 ------ 改變其上所有層級的指紋，最終徹底改變根哈希值。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-54b3916d0a8c97b04ff5e18eb75930572e1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 Cursor 如何利用默克爾樹實現代碼庫索引功能&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;默克爾樹 (Merkle trees) 是 Cursor 代碼庫索引功能的核心組件。根據 Cursor 創始人發佈的帖子[1]和 Cursor 的安全文檔[2]，其工作流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-434fca0d5d62079cc39b5f46a8de5f6cdc9.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 步驟 1：代碼分塊與預處理&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Cursor 首先在本地對代碼庫文件進行分塊處理，將代碼分割成具有語義含義的片段。此步驟是後續操作的必要前提。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 步驟 2：默克爾樹的構建與同步&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;啓用代碼庫索引功能後，Cursor 會掃描編輯器當前打開的文件夾，併為所有有效文件計算哈希值組成的默克爾樹。隨後，該默克爾樹會與 Cursor 的服務器同步，其安全文檔[2]詳細描述了此過程。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 步驟 3：生成嵌入向量&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;將代碼分塊併發送至 Cursor 服務器後，將使用 OpenAI 的嵌入 API 或自研的嵌入模型（我未能驗證 Cursor 具體採用的是哪種方法）生成嵌入向量 (embeddings)。這些向量表徵能夠捕捉代碼片段的語義信息。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.4 步驟 4：存儲與索引&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;生成的嵌入向量，連同起始/結束行號及文件路徑等元數據，會被存儲在一個遠程向量數據庫（Turbopuffer）中。為兼顧路徑篩選功能與隱私保護，Cursor 會為每個向量附加經過混淆處理的相對文件路徑。Cursor 創始人曾明確表示[1]："我們的數據庫中不會存儲任何代碼。請求處理完畢立即銷燬存儲的代碼數據。"&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.5 步驟 5：基於默克爾樹的定期更新&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;每隔 10 分鐘，Cursor 就會檢測哈希值的變化情況，利用默克爾樹精準定位哪些文件發生了變動。如 Cursor 的安全文檔[2]所述，只需上傳所定位到的發生變動的文件，從而大幅降低帶寬消耗。&lt;strong&gt;默克爾樹結構的最大價值正體現於此 ------ 它能實現高效的增量更新。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 代碼分塊策略&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;代碼庫索引的有效性很大程度上取決於代碼的分塊方式。儘管我先前的説明未深入探討代碼分塊方法，但這篇關於構建類 Cursor 代碼庫功能的博客[3]揭示了一些技術細節：&lt;/p&gt; 
&lt;p&gt;簡單的分塊方式（按字符/按單詞/按行）往往會遺漏語義邊界 ------ 導致嵌入向量質量下降。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;儘管可根據固定的 token 數分割代碼，但這種方式可能導致函數或類等代碼塊被強制截斷。&lt;/li&gt; 
 &lt;li&gt;更有效的方案是使用能夠理解代碼結構的智能分割器，例如遞歸文本分割器（recursive text splitters），它使用高級分隔符（如類定義和函數聲明）在恰當的語義邊界處進行精準切分。&lt;/li&gt; 
 &lt;li&gt;一個更優雅的解決方案是根據代碼的抽象語法樹（AST）結構來分割代碼。通過深度優先遍歷 AST，將代碼分割成符合 token 數量限制的子樹結構。為避免產生過多的碎片化分塊，系統會在滿足 token 限制的前提下，將同級語法節點合併為更大的代碼塊。此類 AST 解析工作可藉助 tree-sitter[4] 等工具實現，其支持絕大多數主流編程語言。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 嵌入向量在推理階段的應用&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在瞭解 Cursor 如何創建和存儲代碼嵌入向量後，一個自然而然的問題就出現了：這些嵌入向量在生成之後究竟是如何使用的？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 語義搜索（Semantic Search）與上下文檢索（Context Retrieval）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;當你使用 Cursor 的 AI 功能（例如通過 &lt;a href="https://my.oschina.net/u/135318"&gt;@Codebase&lt;/a&gt; 或 ⌘ Enter 詢問代碼庫相關問題時），將觸發以下流程：&lt;/p&gt; 
&lt;p&gt;1）將查詢轉換為向量：Cursor 會為您的提問或當前代碼上下文生成對應的嵌入向量。&lt;/p&gt; 
&lt;p&gt;2）向量相似性搜索：該查詢向量被髮送至 Turbopuffer（Cursor 的向量數據庫），通過最近鄰搜索找出與查詢語義相似的代碼塊。&lt;/p&gt; 
&lt;p&gt;3）訪問本地文件：Cursor 客戶端接收到的檢索結果包含經過混淆處理的文件路徑和最相關代碼塊的行號範圍。實際代碼內容始終保留在用戶本地設備，僅在需要時從本地讀取。&lt;/p&gt; 
&lt;p&gt;4）上下文整合：客戶端從用戶本地文件讀取這些相關代碼塊，並將其作為上下文與您的問題一併發送至服務器供大語言模型處理。&lt;/p&gt; 
&lt;p&gt;5）生成響應：此時大語言模型已獲取代碼庫中的相關上下文，可據此提供精準回答或生成符合場景的代碼補全。&lt;/p&gt; 
&lt;p&gt;這種由嵌入向量驅動的檢索機制支持以下功能：&lt;/p&gt; 
&lt;p&gt;1）根據上下文生成代碼：在編寫新代碼時，Cursor 可參考現有代碼庫中的相似實現，保持代碼模式與代碼風格的一致性。&lt;/p&gt; 
&lt;p&gt;2）代碼庫智能問答：可以獲取基於代碼庫中實際代碼的精準解答，而非通用回覆。&lt;/p&gt; 
&lt;p&gt;3）智能代碼補全：代碼補全建議會融合項目的特定約定與特定模式。&lt;/p&gt; 
&lt;p&gt;4）智能重構輔助：重構代碼時，系統可自動識別代碼庫中所有需要同步修改的關聯代碼段。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 Cursor 為何選擇默克爾樹&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;這些設計細節多與安全有關，具體可參閲 Cursor 的安全文檔[2]。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1 高效的增量更新&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;默克爾樹使 Cursor 能精準定位自上次同步後變更的文件。因此，無需重新上傳整個代碼庫，僅需上傳修改過的特定文件。對於大型代碼庫來説這一點非常重要 ------ 重新索引所有文件會消耗過多的帶寬和處理時間。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2 數據完整性驗證&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;默克爾樹結構讓 Cursor 能高效驗證所索引的文件與服務器上存儲的文件是否一致。分層的哈希結構可輕鬆檢測傳輸過程中的數據異常或數據損壞。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.3 緩存優化&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Cursor 將嵌入向量（embeddings）存儲在以代碼塊（chunk）哈希值為索引的緩存中，使得重複索引相同代碼庫時速度大幅提升。這對多人協作開發同一代碼庫的團隊尤為有利。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.4 隱私保護型索引&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;為保護文件路徑中的敏感信息，Cursor 採用路徑混淆技術：通過用 "/" 和 "." 為分隔符切割路徑，並用存儲在客戶端的密鑰加密每一段。雖然這樣做會暴露部分目錄結構，但能隱藏絕大多數敏感細節。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.5 集成 Git 版本歷史&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 Git 倉庫中啓用代碼庫索引時，Cursor 還會索引 Git 的版本歷史記錄。它會存儲 commit 的 SHA 值、父提交信息（parent information）及混淆後的文件名。為實現同 Git 倉庫且同團隊用戶間的數據結構共享，用於混淆文件名的祕鑰來自最近 commit 內容的哈希值。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 嵌入模型的選擇與技術考量&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;嵌入模型的選擇直接影響代碼搜索與理解的質量。&lt;/strong&gt; 部分系統採用開源模型（如 all-MiniLM-L6-v2[5]），而 Cursor 可能使用 OpenAI 的嵌入模型或針對代碼場景進行優化的定製模型。對於專用的代碼嵌入模型，微軟的 unixcoder-base[6] 或 Voyage AI 的 voyage-code-2[7] 等模型對代碼的語義理解效果顯著。&lt;/p&gt; 
&lt;p&gt;由於嵌入模型存在 token 容量限制，使得該技術的實現難度大幅增加。以 OpenAI 的 text-embedding-3-small[8] 為例，其 token 上限為 8192。有效的分塊策略能在保留語義的前提下不超出該限制。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 握手同步流程&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Cursor 默克爾樹實現的核心在於同步時的握手機制。根據應用日誌顯示：在初始化代碼庫索引時，Cursor 會創建一個"merkle client"並與服務器進行"初始化握手流程"（詳見 GitHub Issue #2209[9] 與 Issue #981[10]），該握手流程涉及向服務器發送本地計算的默克爾樹的根哈希值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;握手流程使服務器能精準判定需同步的代碼範圍。&lt;/strong&gt; 如握手日誌所示（參照 GitHub Issue #2209[11]），Cursor 會計算代碼庫的初始哈希值，並將其發送至服務器進行驗證。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;08 技術實現挑戰&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;雖然默克爾樹方案有許多優勢，但其實現過程仍存在一些技術難點。&lt;/strong&gt; Cursor 的索引服務常因瞬時流量過載，導致大量請求失敗。如安全文檔所述[2]，用戶可能觀察到向 repo42.cursor.sh 發送的網絡流量比預期要高 ------ 這正是由於文件需多次重傳才能被完全索引。&lt;/p&gt; 
&lt;p&gt;另一項挑戰與嵌入向量的安全性有關。學術研究表明，特定條件下存在逆向解析嵌入向量的可能性。雖然當前的攻擊手段通常需同時滿足：1) 擁有嵌入模型的訪問權限 2) 僅對短文本有效。但若攻擊者獲取 Cursor 向量數據庫的訪問權限，仍存在從存儲的嵌入向量中提取代碼庫信息的風險。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓Cursor 通過路徑混淆和本地哈希計算保護隱私，但同步時仍需上傳部分數據。在團隊協作場景下，你更傾向於完全本地化的方案，還是接受有限數據上傳以換取更強的 AI 輔助？為什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.cursor.com%2Ft%2Fcodebase-indexing%2F36" target="_blank"&gt;https://forum.cursor.com/t/codebase-indexing/36&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fen%2Fsecurity" target="_blank"&gt;https://www.cursor.com/en/security&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.lancedb.com%2Frag-codebase-1%2F" target="_blank"&gt;https://blog.lancedb.com/rag-codebase-1/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftree-sitter.github.io%2Ftree-sitter%2F" target="_blank"&gt;https://tree-sitter.github.io/tree-sitter/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsentence-transformers%2Fall-MiniLM-L6-v2" target="_blank"&gt;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmicrosoft%2Funixcoder-base" target="_blank"&gt;https://huggingface.co/microsoft/unixcoder-base&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.voyageai.com%2Fembeddings%2Fmodels%2F" target="_blank"&gt;https://docs.voyageai.com/embeddings/models/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fembeddings" target="_blank"&gt;https://platform.openai.com/docs/guides/embeddings&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetcursor%2Fcursor%2Fissues%2F2209" target="_blank"&gt;https://github.com/getcursor/cursor/issues/2209&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetcursor%2Fcursor%2Fissues%2F981" target="_blank"&gt;https://github.com/getcursor/cursor/issues/981&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetcursor%2Fcursor%2Fissues%2F2209" target="_blank"&gt;https://github.com/getcursor/cursor/issues/2209&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fread.engineerscodex.com%2Fp%2Fhow-cursor-indexes-codebases-fast" target="_blank"&gt;https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18638294</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18638294</guid>
      <pubDate>Sat, 10 May 2025 08:01:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>龍芯發佈新一代處理器，進軍服務器和 AI 處理器市場​​​​​​​</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;「龍芯中科」在今天舉辦的 2025 龍芯產品發佈暨用戶大會上發佈了基於國產自主指令集龍架構（LoongArchTM）研發的服務器處理器龍芯 3C6000 系列芯片、工控領域及移動終端處理器龍芯 2K3000/3B6000M 芯片，以及相關整機和解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/153553_ZF0H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，3C6000 系列服務器 CPU 採用自主指令系統龍架構，於 2024 年上半年流片成功。3C6000 單硅片 16 核 32 線程，可通過自研的龍鏈接口通過多硅片封裝形成 32 核 64 線程的 3C6000/D（又稱 3D6000）及 60/64 核 120/128 線程的 3C6000/Q（又稱 3E6000）。&lt;/p&gt; 
&lt;p&gt;根據中國電子技術標準化研究院賽西實驗室測試報告，單路 3C6000/S 服務器在 2.2GHz 運行 SPEC CPU 2017 單核單線程定/浮點分值為 5.56/6.93 分，多核定/浮點分值為 73.2/58.5 分；雙路 3C6000/D 服務器在 2.1GHz 運行 SPEC CPU 2017 多核定/浮點分值為 284/261 分；雙路 3C6000/Q 服務器在 2.1GHz 運行 SPEC CPU 2017 多核定/浮點分值為 450/283 分；四路 3C6000/D 服務器在 2.1GHz 運行 SPEC CPU 2017 多核定/浮點分值為 547/412 分。上述 3C6000/S、3C6000/D 實測單核/多核性能分別達到 Intel 公司 2021 年上市的 16 核至強 Silver 4314、32 核至強 Gold 6338 的水平，64 核 3C6000/Q 性能超過 40 核至強 Platinum 8380 的水平。&lt;/p&gt; 
&lt;p&gt;結合 Intel 公司第三代至強可擴展架構服務器芯片出貨情況，3C6000 系列服務器 CPU 綜合性能達到 2023 年市場主流產品水平。&lt;/p&gt; 
&lt;p&gt;2K3000/3B6000M 工控/終端 CPU 採用自主指令系統龍架構，面向工控和終端（筆記本、雲終端等）應用，於 2024 年底流片成功。3B6000M 集成 8 個 LA364E 處理器核，主頻 2.5GHz 時實測 SPEC CPU 2006 Base 單覈定點分值達到 30 分；集成第二代自研 GPGPU 核心 LG200 和獨立硬件編解碼模塊，4K 高清視頻處理性能達到每秒 60 幀；集成安全處理器提供可信支持和密碼服務，包括 SM2/3/4 硬件算法模塊以及可供軟件編程使用的可重構密碼模塊。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1800" src="https://static.oschina.net/uploads/space/2025/0626/153709_EMEW_2720166.png" width="2486" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;來源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FU1_yQYdi-47nhn5ojBvSEA" target="_blank"&gt;https://mp.weixin.qq.com/s/U1_yQYdi-47nhn5ojBvSEA&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357386</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357386</guid>
      <pubDate>Sat, 10 May 2025 07:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OceanBase 正式啓用中文名：海揚數據庫</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;國產數據庫 OceanBase 正式啓用中文品牌名「海揚數據庫」，品牌戰略全面升級。&lt;/p&gt; 
&lt;p&gt;官方解釋稱：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「海」，既象徵 OceanBase 對海量數據的承載能力，能夠應對像支付寶每秒 42 萬筆交易這樣的高併發處理需求，體現其分佈式架構在數據存儲與處理上的強大優勢，也象徵着如海一樣開源開放，以兼容幷蓄的姿態攜手開發者、合作伙伴推動行業創新。&lt;/p&gt; 
 &lt;p&gt;「揚」，既寓意昂揚向上，象徵 OceanBase 在技術海洋中不斷突破邊界，以根自研深耕行業，也寓意揚帆出海，不斷走向全球化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;OceanBase CEO 楊冰表示，中文名的推出，一方面代表着 OceanBase 深耕本土市場的決心，也是 OceanBase 繼續引領世界舞台上分佈式數據庫技術創新和應用的宣言。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8c286d418602fc6ed5232b2c2249cf0d73c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OceanBase 始創於 2010 年，是螞蟻集團完全自主研發的國產數據庫。2020 年 OceanBase 成立北京奧星貝斯科技有限公司並開始獨立商業化運作。2021 年，OceanBase&amp;nbsp;&lt;a href="https://www.oschina.net/news/144034"&gt;正式開源&lt;/a&gt;(&lt;a href="https://gitee.com/oceanbase"&gt;https://gitee.com/oceanbase&lt;/a&gt;)，300 萬行核心代碼向社區開放。2024 年 3 月 19 日，螞蟻集團宣佈，旗下的螞蟻國際、OceanBase 和螞蟻數科已成立董事會，獨立面向市場。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357376</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357376</guid>
      <pubDate>Sat, 10 May 2025 06:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 成功挖角三名 OpenAI 研究人員</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《華爾街日報》報道稱，在爭奪頂尖人工智能人才的鬥爭中，Meta 剛剛取得了勝利，儘管競爭對手 Sam Altman 公開嘲笑馬克·扎克伯格的奢侈招聘策略，但 Meta 仍然挖走了三名 OpenAI 研究人員。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Lucas Beyer、Alexander Kolesnikov 和 Xiaohua Zhai （OpenAI 蘇黎世辦事處的創始人）現已加入 Meta 的超級智能團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="356" src="https://oscimg.oschina.net/oscnet/up-0044b1bf5ef2f1f7a26cba89cd241222c75.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，OpenAI 首席執行官 Altman 在與其兄弟 Jack 一起的播客透露，扎克伯格一直在提供超過 1 億美元的薪酬方案，以吸引 OpenAI 的頂尖人才。並表示，「我很高興，至少到目前為止，我們最好的員工中還沒有人決定接受他的（那些提議）。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《華爾街日報》隨後報道稱，扎克伯格一直在通過 WhatsApp 與數百名頂尖 AI 研究人員進行私人交流，通過他的「Recruiting Party」聊天室協調目標人才，然後在 Palo Alto 和 Lake Tahoe 的家中舉辦晚宴。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這一策略的成果好壞參半。扎克伯格最近斥資 140 億美元，簽下了 Scale AI 的首席執行官 Alexandr Wang，這位 28 歲的年輕人也因此成為科技界有史以來身價最高的人才之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/355944/sam-altman-meta-tried-100m-offers" target="_blank"&gt;Sam Altman：Meta 曾試圖以 1 億美元挖走 OpenAI 人才，但未能成功&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers</guid>
      <pubDate>Sat, 10 May 2025 06:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Scale AI 被曝使用谷歌文檔泄露客戶機密信息</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;人工智能初創公司 Scale AI 陷入了一場嚴重的數據安全風波。這家估值不菲、並被 Meta 以 148 億美元收購 49% 股份的公司，被曝出竟然使用公共的谷歌文檔來存儲包括 Meta、谷歌和 xAI 在內的眾多客戶的絕密信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;報道稱，任何知道 Scale AI 文檔鏈接的人，都可以輕易訪問這些包含絕密項目、電子郵件地址和付款信息等敏感內容的谷歌文檔。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Scale AI 的一位發言人對此回應表示，公司正在進行徹底的調查，並且已經禁止任何用戶公開分享 Scale AI 管理系統中的文檔。然而，谷歌和 xAI 尚未對此事發表評論，而 Meta 則選擇拒絕置評。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-a25cf5b5fc9703e4e067c5e37806e5bd265.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據五名 Scale AI 的承包商透露，谷歌文檔在 Scale AI 內部被廣泛使用。網絡安全專家指出，儘管目前尚無跡象表明這些公開文件已導致實際的數據泄露，但這種存儲方式無疑讓 Scale AI 極易受到黑客攻擊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查顯示，在 Scale AI 採取措施之前，人們可以查看多達 85 份、數千頁的項目信息，其中詳細記錄了 Scale AI 與大型科技客戶之間的敏感合作。例如，這些文檔揭示了谷歌如何利用 OpenAI 的 ChatGPT 來微調自己的聊天機器人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更令人震驚的是，至少有七份被標記為機密信息的谷歌項目手冊向公眾開放，其中包括如何改進其聊天機器人 Bard 的具體建議。此外，公開的谷歌文檔中甚至包含了埃隆·馬斯克 「木琴計劃」（Project Xylophone）的詳細內容，比如用於訓練 xAI 人工智能模型的 700 個對話提示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;承包商們還透露，儘管這些項目通常有祕密代號，但他們仍然能清晰辨別自己為哪個客戶工作。在使用人工智能產品時，聊天機器人有時在被詢問時甚至會直接透露客戶信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除了客戶的機密項目信息，Scale AI 的谷歌文檔中還赫然披露了該公司數千名員工的姓名和私人聯絡方式。更甚者，有些文件甚至詳細列出了個體承包商的工資數額，包括有關工資糾紛和差異的詳細説明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這些信息無疑充分暴露了 Scale AI 在數據安全性上的嚴重紕漏，並可能引發法律糾紛。值得注意的是，就在 Meta 入股 Scale AI 後不久，業內便有傳言稱包括谷歌在內的大客戶已經與 Scale AI 進行了業務上的切割，以防止 Scale AI 向 Meta 透露敏感內容。此次谷歌文檔事件，無疑將進一步加劇客戶對 Scale AI 數據安全能力的擔憂。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/356119/openai-drops-scale-ai-meta" target="news"&gt;OpenAI 終止與 Scale AI 合作&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357357</guid>
      <pubDate>Sat, 10 May 2025 05:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ResNet 主要發明人何愷明加入谷歌 DeepMind，擔任「傑出科學家」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;計算機視覺領域代表人物何愷明官宣加入谷歌 DeepMind，擔任傑出科學家（Distinguished Scientist）。 他在個人主頁上表示，自己在 DeepMind 的工作是兼職，還將繼續保留 MIT 終身副教授的身份。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/110724_YwBV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;何愷明是殘差網絡（ResNet）的主要發明人，而這項技術成為了深度學習及後續人工智能進步的基礎。我們今天看到的 ChatGPT、AlphaGo、AlphaFold 都離不開它的影響。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/111204_Czoq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_cvpr_2016%2Fpapers%2FHe_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank"&gt;https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;2003 年，何愷明以標準分 900 分獲得廣東省高考總分第一，被清華大學物理系基礎科學班錄取。在清華物理系基礎科學班畢業後，他進入香港中文大學多媒體實驗室攻讀博士學位，師從湯曉鷗。何愷明曾於 2007 年進入微軟亞洲研究院視覺計算組實習，實習導師為孫劍博士。&lt;/p&gt; 
&lt;p&gt;2011 年博士畢業後，何愷明加入微軟亞洲研究院工作任研究員。2016 年，何愷明加入 Facebook 人工智能實驗室，任研究科學家。2024 年，何愷明加入 MIT，成為該校一名副教授。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/111129_NW0H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357334</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357334</guid>
      <pubDate>Sat, 10 May 2025 03:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源模擬器 QEMU 拒絕 AI 生成代碼的貢獻</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源模擬器 QEMU 開始對用 AI 生成的代碼進行治理，項目維護者&amp;nbsp;Daniel Berrangé &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fqemu%2Fqemu%2Fcommit%2F3d40db0efc22520fa6c399cf73960dced423b048" target="_blank"&gt;撰寫並提交&lt;/a&gt;了一份「&lt;strong&gt;禁止使用人工智能代碼生成&lt;/strong&gt;器」的文檔：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;近年來，所謂的人工智能代碼生成器引發了極大的關注。然而，迄今為止，尚未形成關於代碼生成器輸出結果的許可影響的普遍認可的法律解釋。儘管供應商可能聲稱不存在問題且可以自由選擇許可協議，但他們在推廣這一解釋時存在固有的利益衝突。&lt;/p&gt; 
 &lt;p&gt;更廣泛地説，目前尚未就基於多種不同許可協議輸入數據訓練的代碼生成器的許可影響形成廣泛共識。&lt;/p&gt; 
 &lt;p&gt;DCO 要求貢獻者聲明其有權在指定項目許可下進行貢獻。鑑於對 AI 代碼生成器輸出許可問題的共識缺失，若補丁包含此類生成代碼，則聲稱符合 DCO 條款 (b) 或 (c) 被視為不可信。&lt;/p&gt; 
 &lt;p&gt;因此，本補丁定義了 QEMU 項目當前不會接受涉及已知或疑似使用 AI 代碼生成器的貢獻。&lt;/p&gt; 
 &lt;p&gt;這是人工智能輔助軟件開發的早期階段。法律問題最終將得到解決。工具將成熟，我們可預期部分工具將安全適用於自由軟件項目。&lt;/p&gt; 
 &lt;p&gt;我們當前制定的政策必須適用於當下，並保持開放修訂。最好從嚴格和安全開始，隨後逐步放寬。&lt;/p&gt; 
 &lt;p&gt;同時，可根據具體情況考慮例外請求。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/105527_LWLP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357331</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357331</guid>
      <pubDate>Sat, 10 May 2025 03:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊雲 TDMQ RabbitMQ Serverless 版全新發布</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;導語&lt;/h2&gt; 
&lt;p&gt;2025 年 6 月起，騰訊雲 TDMQ RabbitMQ 版正式推出 Serverless 版本，該版本基於自研的存算分離架構，兼容 AMQP 0-9-1 協議和開源 RabbitMQ 的各個組件與概念，且能夠規避開源版本固有的不抗消息堆積、腦裂等穩定性缺陷，具有穩定、安全、靈活擴縮容等優勢。本文將全面解析 TDMQ RabbitMQ Serverless 版的核心特性、技術優勢及售賣形態。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版推出的背景&lt;/h2&gt; 
&lt;p&gt;2021 年，騰訊雲推出自研消息隊列服務 TDMQ RabbitMQ 版，全面兼容 AMQP 0-9-1 協議及開源 RabbitMQ 生態。產品以開源託管版形態提供服務，按照節點進行售賣。&lt;/p&gt; 
&lt;p&gt;相比傳統自建方案，TDMQ RabbitMQ 開源託管版不僅免除了用戶部署運維的負擔，並通過架構優化實現了跨可用區高可用部署、一鍵彈性擴縮容等生產級能力，同時內置了完善的監控告警、巡檢診斷等企業級運維功能，在保持協議完全兼容的基礎上，針對企業實際應用場景進行了深度優化，為用戶提供了更穩定可靠的消息服務體驗。&lt;/p&gt; 
&lt;p&gt;在當前數字化轉型加速的背景下，用戶對成本優化提出了更高要求，同時業務快速迭代也催生了對彈性能力的強烈需求。用戶極需突破傳統資源預留式運維的侷限，充分釋放雲原生的技術紅利。&lt;/p&gt; 
&lt;p&gt;為更好地滿足用戶對彈性擴展和成本優化的需求，騰訊雲消息隊列 TDMQ RabbitMQ 版正式推出 Serverless 版本。該版本採用存儲和計算分離的架構設計，在完全兼容 AMQP 0-9-1 協議及開源 RabbitMQ 生態的同時，有效規避了開源版本固有的不抗消息堆積、腦裂等穩定性缺陷，又解決了開源版本性能受限於底層機型和擴展性不足等問題，為用戶提供更安全可靠、彈性靈活的消息服務體驗。&lt;/p&gt; 
&lt;p&gt;在產品設計上，Serverless 版本提供專業版（1000+ TPS）和鉑金版（10w+ TPS）兩種規格，用戶只需根據業務吞吐量需求選擇對應版本，無需關心底層資源運維。在計費模式上，同時支持包年包月和按小時計費兩種方式，其中計算資源按流量規格計費，存儲資源無起步門檻，按實際使用量進行計費，成本整體可降低約 30%。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版核心特性解析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、 兼容開源、開箱即用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;支持開箱即用，一鍵自動創建集羣，無需手動安裝和部署。兼容 AMQP 0-9-1 協議及開源 RabbitMQ 客戶端，業務代碼無需任何改造即可平滑上雲。同時提供多種 TPS 規格供用戶選擇，用戶可以在控制枱上自助靈活擴容和縮容，無需關注底層資源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、 可觀測能力增強&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;提供全面的監控告警能力，支持集羣、VHost、Exchange 和 Queue 4 個維度，覆蓋 6 大類、90+ 細粒度監控指標，幫助您實時瞭解集羣運行狀態。同時支持消息查詢和消息軌跡能力，清晰展示消息的完整生命週期，便於快速定位問題，提升運維效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、 高可用高可靠&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過架構升級有效解決了開源版本常見的穩定性問題，包括消息堆積和腦裂等場景。服務採用多可用區分佈式部署架構，可自動容災切換，輕鬆應對機房級故障，提供不低於 99.95% 的 SLA 服務可用性保障。同時通過三副本數據持久化機制，確保消息數據的持久可靠。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、 靈活適配多業務場景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;提供多種路由方式，例如 Direct、Fanout、Topic、 Header 和 X-Delayed-Message 等，可靈活組合不同的交換機類型，滿足複雜業務需求。同時支持多種消息類型，例如廣播消息、延遲消息、死信隊列等，滿足訂單超時處理、事件通知、異步解耦等典型業務場景，提供高度靈活的消息解決方案。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版對比開源的八大關鍵優勢&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、監控告警豐富度高&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源自建 RabbitMQ 方案需通過 Management UI 手動採集指標，並自行搭建指標存儲和展示系統；或者通過接入外部 Prometheus 和 Grafana 實現監控指標展示，運維難度和成本顯著增加。&lt;/p&gt; 
&lt;p&gt;而 TDMQ RabbitMQ Serverless 版提供白屏化監控大盤，支持集羣/VHost/Exchange/Queue 4 個監控維度，涵蓋 6 大類，90+ 指標，實時瞭解集羣運行狀態，提升自主運維效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、支持全鏈路消息軌跡&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源自建 RabbitMQ 方案需要在服務器裏的 log 文件中查詢文本格式的消息軌跡信息，查詢和定位問題效率較低。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版支持通過 Message ID 精準查詢或按隊列檢索消息，並且可以可視化展示消息完整生命週期，快速定位消息收發問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、 靈活無感擴縮容&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;傳統開源的 RabbitMQ 方案擴縮容需要停機升級底層機型，並需要重啓開源控制枱，操作複雜且影響業務連續性。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版支持靈活擴縮容，通過控制枱簡單操作即可實現資源擴展，變更過程平滑無感，客戶側的應用無需做停機處理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、 消息抗堆積能力強&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源自建 RabbitMQ 集羣抗消息堆積能力較弱，容易因消息堆積導致內存過載，需人工幹預。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版採用高性能架構，具備強大的抗堆積能力，即使在高併發消息堆積場景下，仍能保持穩定的吞吐性能，避免消息積壓導致的服務不可用風險。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5、 默認支持跨可用區容災&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;傳統開源的 RabbitMQ 方案存在固有的不抗消息堆積和腦裂等架構風險，且單可用區部署模式難以保障故障出現時的業務連續性。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版默認跨可用區部署，確保服務的高可用性。採用先進的存算分離架構，規避不抗消息堆積和腦裂問題，既保證集羣高可靠和數據持久化，又具備靈活擴縮容優勢。承諾不低於 99.95% 的服務可用性 SLA，為用戶提供強有力的穩定性保障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、 可無限橫向擴展&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源 RabbitMQ 集羣的隊列和單節點綁定，受限於單機硬件配置，鏡像隊列副本數量增多會降低集羣 TPS 值，增加節點不能擴展集羣吞吐量。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版通過存算分離架構，突破了傳統方案的性能瓶頸，理論上支持無限 TPS 擴展能力，服務可按需橫向擴容，為業務增長提供持續的性能保障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7、秒級精度延時消息&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源 RabbitMQ 通過延時消息插件實現，該開源插件設計存在侷限性，不適用於大量延時消息或長時間延時消息的場景，集羣節點異常時會導致延時消息丟失，還存在不支持強制標誌等問題。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版免去開啓延時消息插件的步驟，直接對消息設置 delay 屬性即可，不僅便捷，還可以解決開源實現方式的侷限性，支持長時間、大量的延時消息，且海量消息堆積不影響集羣高可用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;8、靈活消息重試策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開源 RabbitMQ 默認只支持消息無限立即重試機制，需要開發者自行實現重試邏輯，消費失敗的消息需人工定位原因，開發和運維成本高。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版默認支持消息重試策略，當消息消費達到"消費超時時間"而消費者還未響應時，消息將被重新投遞，並且支持不同的重試間隔，當重新投遞次數達到上限時，消息會被投遞到死信隊列或者被丟棄。&lt;/p&gt; 
&lt;h2&gt;TDMQ RabbitMQ Serverless 版售賣形態&lt;/h2&gt; 
&lt;p&gt;當前 TDMQ RabbitMQ Serverless 版提供專業版和鉑金版兩種規格，以滿足不同業務場景的需求，按照 TPS 規格對外售賣。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a52b5a86022eb497558d49a27de6643ace7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在性能方面，專業版支持消息 TPS 在 1000 到 10 萬之間的多種規格，鉑金版則提供更高的規格，支持 10 萬 TPS 以上的消息處理能力。&lt;/p&gt; 
&lt;p&gt;在部署架構上，專業版計算資源是獨佔的，但存儲層是共享的；而鉑金版提供完全獨佔的計算和存儲資源，相比專業版穩定性會更強。&lt;/p&gt; 
&lt;p&gt;消息保留時間方面，專業版默認支持 3 天的消息保留時間，鉑金版則支持 7 天以上，滿足更嚴格的數據留存需求。&lt;/p&gt; 
&lt;p&gt;服務可靠性方面，兩個版本均採用跨可用區部署架構，並配備三副本數據持久化機制。專業版提供 99.95% 的 SLA 保障，與開源託管版持平；鉑金版則承諾更高的 99.99% 服務可用性，為關鍵業務提供更強保障。&lt;/p&gt; 
&lt;p&gt;後續我們還將推出彈性 TPS 功能，允許用戶在購買的基礎 TPS 規格範圍上可以超出一部分用量。對於超出基礎規格的部分，按照實際使用量進行獨立計費。具體彈性擴展空間方面，專業版最高可支持超出基礎規格的 50%，鉑金版則支持 100% 的超量擴展，為用戶業務的突發激增流量提供保障。&lt;/p&gt; 
&lt;h2&gt;總結與展望&lt;/h2&gt; 
&lt;p&gt;騰訊雲推出的 TDMQ RabbitMQ Serverless 版基於自研的存算分離架構，有效兼容開源生態並解決了其固有穩定性問題（如腦裂、不抗堆積），提供高可用、彈性擴縮和按量計費的核心優勢，同時大幅增強監控告警、消息軌跡等可觀測能力，顯著簡化運維負擔。&lt;/p&gt; 
&lt;p&gt;未來騰訊雲 TDMQ RabbitMQ Serverless 版將持續優化，推出彈性 TPS 功能以更好應對突發流量，同時做好開源兼容性增強、管控能力升級和可觀測工具完善，並深化行業場景應用，助力用戶以更低成本、零運維負擔享受高性能消息服務。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4587289/blog/18638278</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4587289/blog/18638278</guid>
      <pubDate>Sat, 10 May 2025 02:52:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Jina AI 開源多模態多語言向量模型 Jina Embeddings V4</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Jina AI &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpfbyYOf8_KJijGfmLtTr9w" target="_blank"&gt;宣佈&lt;/a&gt;正式推出 jina-embeddings-v4，一款全新的多模態向量模型，參數規模達到 38 億，並首次實現了對文本與圖像的同步處理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;項目團隊在模型內置了一套面向特定任務的 LoRA 適配器，專門強化了模型在處理查詢-文檔檢索、語義匹配以及代碼搜索等任務時的表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="263" src="https://oscimg.oschina.net/oscnet/up-a2a4b22fe7f6b657a270a7ecbcfeb963466.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，在 MTEB、MMTEB、CoIR、LongEmbed、STS、Jina-VDR 及 ViDoRe 等多項基準測試中，jina-embeddings-v4 在多模態、多語言檢索任務上均展現了頂尖性能。它尤其擅長解讀富含視覺信息的內容，無論是表格、圖表還是複雜的示意圖，都能精準捕捉其深層語義。此外，模型還同時支持單向量和多向量表示，靈活滿足各種場景需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「&lt;code&gt;jina-embeddings-v4&lt;/code&gt;&amp;nbsp;是我們迄今為止最具突破性的一款向量模型。&lt;strong&gt;作為一款開源模型，它的性能表現已全面超越來自主流供應商的頂尖閉源模型。&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在多語言檢索方面，其性能比 OpenAI 的 text-embedding-3-large 高出 12%（66.49 vs 59.27）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在長文檔任務上，性能提升了 28%（67.11 vs 52.42）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在代碼檢索方面，效果比 voyage-3 好 15%（71.59 vs 67.23）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;綜合性能與谷歌的 gemini-embedding-001 模型並駕齊驅&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" height="695" src="https://oscimg.oschina.net/oscnet/up-349b5e56cf55646be67b29e49a34777f535.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="657" src="https://oscimg.oschina.net/oscnet/up-95eed0ac1e5ba7c967ac000a2b39bca41b5.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpfbyYOf8_KJijGfmLtTr9w" target="_blank"&gt;查看官方公告&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357326</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357326</guid>
      <pubDate>Sat, 10 May 2025 02:47:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Swift 編程語言正式成立 Android 工作組</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Swift 編程語言項目&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforums.swift.org%2Ft%2Fannouncing-the-android-workgroup%2F80666" target="_blank"&gt;宣佈&lt;/a&gt;成立新團隊：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fandroid-workgroup%2F" target="_blank"&gt;Android 工作組&lt;/a&gt; (Android Workgroup)，這是一個推廣使用 Swift 開發 Android 應用的團隊&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/103853_lltG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;「Swift on Android Working Group」的章程寫道：工作組的主要目標是建立並維護 Android 作為 Swift 的官方支持平台。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;改進並維護官方 Swift 發行版的 Android 支持，消除對樹外或下游補丁的需求&lt;/li&gt; 
 &lt;li&gt;推薦對 Foundation 和 Dispatch 等核心 Swift 包進行增強，使其更好地與 Android 慣用法配合&lt;/li&gt; 
 &lt;li&gt;與平台指導小組合作，正式定義平台支持級別，然後努力為 Android 實現特定級別的官方支持&lt;/li&gt; 
 &lt;li&gt;確定 Swift 集成所支持的 Android API 級別和架構範圍&lt;/li&gt; 
 &lt;li&gt;為 Swift 項目開發持續集成，包括在 PR 檢查中包含 Android 測試。&lt;/li&gt; 
 &lt;li&gt;識別並推薦 Swift 與 Android 的 Java SDK 之間橋接的最佳實踐，以及將 Swift 庫與 Android 應用打包的最佳實踐&lt;/li&gt; 
 &lt;li&gt;開發在 Android 上調試 Swift 應用程序的支持功能&lt;/li&gt; 
 &lt;li&gt;為各種社區 Swift 包添加 Android 支持提供建議和協助&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fandroid-workgroup%2F" target="_blank"&gt;https://www.swift.org/android-workgroup/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357325/swift-android-workgroup</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357325/swift-android-workgroup</guid>
      <pubDate>Sat, 10 May 2025 02:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技王興興：公司目前年度營收超過十億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;據新華網報道，宇樹科技創始人王興興在近日舉行的夏季達沃斯論壇上透露，宇樹科技自 2016 年創立之初的「一人公司」，如今已發展成為擁有近千名員工、年營收突破十億元人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="307" src="https://oscimg.oschina.net/oscnet/up-f88df9ea1d0af1507ea7206a2304fe3c8e4.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技或是機器人行業少數實現盈利的企業。此前宇樹科技早期投資人、SevenUp Capital 創始人趙楠曾透露，自 2020 年以來，宇樹科技的財務報表每年都保持盈利狀態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;成立於 2016 年的宇樹科技，早期主要做四足機器狗。2024 年，其通用人形機器人 G1 一經推出便引發熱議。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年初，宇樹科技的 Unitree H1 和 G1 人形機器人登陸京東商城開售，其中 H1 售價 65 萬元，G1 售價 9.9 萬元，產品上線後迅速售罄。此外，宇樹科技的機器人還多次在央視春晚、美國拉斯維加斯 CES 等舞台亮相，大幅提升了品牌知名度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該公司的融資情況也頗為順利。2020 年到 2022 年之間，宇樹進行了 Pre-A、A、A+、B、B+輪融資，投資方包括紅杉種子、初心資本、祥峯投資、順為資本、經緯創投等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 2 月，宇樹科技完成近 10 億元 B2 輪融資，參與方包括深創投、中網投、容億投資、經緯創投、源碼資本、美團戰略投資部、中信金石、博睿智聯、鈞石創投等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;進入 2025 年，這家公司又完成了始於去年底 C 輪融資的交割，由中國移動旗下基金、騰訊、錦秋基金、阿里、螞蟻集團、吉利資本共同領投，絕大部分老股東都跟投，融資金額接近 7 億元人民幣，投後估值超 120 億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 4 月，香港特區行政長官李家超在杭州與「杭州六小龍」企業代表進行了交流，併到訪了宇樹科技。彼時，王興興表示，宇樹科技在香港有業務，各方面合作機會也很多。至於未來會否在香港上市，王興興稱有可能，但不確定。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;當前我國機器人行業正處於快速發展態勢。摩根士丹利曾預計，中國作為全球最大的機器人市場和製造中心，2024 年機器人市場規模已達 470 億美元，佔全球總量的 40%，預計到 2028 年將增至 1080 億美元，年複合增長率達 23%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不過，在談及機器人未來的重要應用場景時，王興興表示，家庭應用場景非常有挑戰，需要一步步來做，目前像工業或農業應用會更快一些。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「近距離與人交互的產品，安全性問題比技術問題會更大一點，在倫理道德方面會更具挑戰性。」王興興舉例稱，前段時間有客戶採購了一台宇樹機器人，在外參加活動時不小心踩掉了一個小女孩的鞋子，一度引發大眾關注。在王興興看來，儘管此事並未對小女孩造成實際的身體傷害，但説明存在很大的安全隱患。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357324</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357324</guid>
      <pubDate>Sat, 10 May 2025 02:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>工信部：57 款 APP 及 SDK 存在侵害用戶權益行為</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;工信部發布「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwap.miit.gov.cn%2Fjgsj%2Fxgj%2Fgzdt%2Fart%2F2025%2Fart_eb31dd22d04a4658b912871c090274bd.html" target="_blank"&gt;關於侵害用戶權益行為的 APP（SDK）通報（2025 年第 3 批，總第 48 批）&lt;/a&gt;」指出，近期，經組織第三方檢測機構進行抽查，共發現 57 款 APP 及 SDK 存在侵害用戶權益行為，現予以通報。上述 APP 及 SDK 應按有關規定進行整改，整改落實不到位的，工信部將依法依規組織開展相關處置工作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附件：工業和信息化部通報存在問題的 APP（SDK）名單&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="356" src="https://oscimg.oschina.net/oscnet/up-694cad317b798664fc6874f4dfcc5d04f03.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="380" src="https://oscimg.oschina.net/oscnet/up-95fdfdd6becefe89b59842435523158e7c9.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="377" src="https://oscimg.oschina.net/oscnet/up-67969320b093051e361809ae89079035228.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="384" src="https://oscimg.oschina.net/oscnet/up-dc0b31e0c1d8fd1034c092014e19fb865f7.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="383" src="https://oscimg.oschina.net/oscnet/up-74b9d4032b353a9db522aa784fbd0d762ed.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="386" src="https://oscimg.oschina.net/oscnet/up-b69d4f045e994d21d9b7f7214da69db6359.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="367" src="https://oscimg.oschina.net/oscnet/up-02a8816c82afb354b8910237cf8f42f35b4.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="249" src="https://oscimg.oschina.net/oscnet/up-d5e033274977ca0b8d94f80b0adf8dd3f6e.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357317</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357317</guid>
      <pubDate>Sat, 10 May 2025 02:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌發佈開源 AI 編程智能體 Gemini CLI，面向開發者的命令行工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fintroducing-gemini-cli-open-source-ai-agent%2F" target="_blank"&gt;發佈&lt;/a&gt;了最新的開源免費 AI 編程智能體 Gemini CLI，該工具將 Gemini 的能力帶到了開發者最常用的終端，能夠提供輕量化的 Gemini 訪問通道。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1705" src="https://static.oschina.net/uploads/space/2025/0626/100936_PeVk_2720166.png" width="2435" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini CLI 支持通過自然語言實現代碼編寫、問題調試及工作流優化，還可以作為多功能本地工具，完成內容生成、問題解決、深度研究及任務管理等各類任務。&lt;/p&gt; 
&lt;p&gt;對開發者而言，終端的效率性、普適性與可移植性使命令行界面成為核心生產力工具，開發者對集成 AI 輔助功能的需求也與日俱增。&lt;/p&gt; 
&lt;p&gt;Gemini CLI（預覽版）可以從代碼理解、文件操作到命令執行與動態故障排查的全流程輔助開發者，該工具支持通過自然語言實現代碼編寫、問題調試及工作流優化。&lt;/p&gt; 
&lt;p&gt;其核心能力源自以下內置工具：&lt;/p&gt; 
&lt;p&gt;1、聯網搜索：通過谷歌搜索獲取網頁內容，為模型提供實時外部上下文；&lt;br&gt; 2、協議擴展：支持模型上下文協議（MCP）及捆綁擴展，持續增強功能；&lt;br&gt; 3、指令定製：根據個性化需求和工作流調整提示詞模板；&lt;br&gt; 4、腳本集成：支持非交互式調用，實現任務自動化與現有工作流對接。&lt;/p&gt; 
&lt;p&gt;Gemini CLI 採用 Apache 2.0 開源協議，開發者可隨時審查代碼實現、驗證安全機制。該工具基於 MCP 等標準構建，支持通過 GEMINI.md 文件配置系統提示詞，並提供個人/團隊兩級設置。全球開發者可以通過提交漏洞報告、功能建議、安全強化方案及代碼優化（GitHub 倉庫已開放），實現社區共建。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle-gemini%2Fgemini-cli%2F" target="_blank"&gt;https://github.com/google-gemini/gemini-cli/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;個體開發者可以通過個人谷歌賬號登錄獲取免費的 Gemini Code Assist 許可。該許可包含 Gemini 2.5 Pro 訪問權限、100 萬 token 的上下文窗口以及 60 次/分鐘、1000 次/天的免費請求量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0626/100956_Nky8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;需要同時運行多個智能體或指定模型的專業開發者，可以選擇使用谷歌 AI Studio/Vertex AI 密鑰（按用量計費）或者購買 Gemini Code Assist 標準版/企業版許可。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;最後附上 Gemini CLI 的系統提示詞：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are an interactive CLI agent specializing in software engineering tasks. Your primary goal is to help users safely and efficiently, adhering strictly to the following instructions and utilizing your available tools.

# Core Mandates

- **Conventions:** Rigorously adhere to existing project conventions when reading or modifying code. Analyze surrounding code, tests, and configuration first.
- **Libraries/Frameworks:** NEVER assume a library/framework is available or appropriate. Verify its established usage within the project (check imports, configuration files like 'package.json', 'Cargo.toml', 'requirements.txt', 'build.gradle', etc., or observe neighboring files) before employing it.
- **Style &amp;amp; Structure:** Mimic the style (formatting, naming), structure, framework choices, typing, and architectural patterns of existing code in the project.
- **Idiomatic Changes:** When editing, understand the local context (imports, functions/classes) to ensure your changes integrate naturally and idiomatically.
- **Comments:** Add code comments sparingly. Focus on *why* something is done, especially for complex logic, rather than *what* is done. Only add high-value comments if necessary for clarity or if requested by the user. Do not edit comments that are seperate from the code you are changing. *NEVER* talk to the user or describe your changes through comments.
- **Proactiveness:** Fulfill the user's request thoroughly, including reasonable, directly implied follow-up actions.
- **Confirm Ambiguity/Expansion:** Do not take significant actions beyond the clear scope of the request without confirming with the user. If asked *how* to do something, explain first, don't just do it.
- **Explaining Changes:** After completing a code modification or file operation *do not* provide summaries unless asked.
- **Do Not revert changes:** Do not revert changes to the codebase unless asked to do so by the user. Only revert changes made by you if they have resulted in an error or if the user has explicitly asked you to revert the changes.

# Primary Workflows

## Software Engineering Tasks
When requested to perform tasks like fixing bugs, adding features, refactoring, or explaining code, follow this sequence:
1. **Understand:** Think about the user's request and the relevant codebase context. Use '${GrepTool.Name}' and '${GlobTool.Name}' search tools extensively (in parallel if independent) to understand file structures, existing code patterns, and conventions. Use '${ReadFileTool.Name}' and '${ReadManyFilesTool.Name}' to understand context and validate any assumptions you may have.
2. **Plan:** Build a coherent and grounded (based off of the understanding in step 1) plan for how you intend to resolve the user's task. Share an extremely concise yet clear plan with the user if it would help the user understand your thought process. As part of the plan, you should try to use a self verification loop by writing unit tests if relevant to the task. Use output logs or debug statements as part of this self verification loop to arrive at a solution.
3. **Implement:** Use the available tools (e.g., '${EditTool.Name}', '${WriteFileTool.Name}' '${ShellTool.Name}' ...) to act on the plan, strictly adhering to the project's established conventions (detailed under 'Core Mandates').
4. **Verify (Tests):** If applicable and feasible, verify the changes using the project's testing procedures. Identify the correct test commands and frameworks by examining 'README' files, build/package configuration (e.g., 'package.json'), or existing test execution patterns. NEVER assume standard test commands.
5. **Verify (Standards):** VERY IMPORTANT: After making code changes, execute the project-specific build, linting and type-checking commands (e.g., 'tsc', 'npm run lint', 'ruff check .') that you have identified for this project (or obtained from the user). This ensures code quality and adherence to standards. If unsure about these commands, you can ask the user if they'd like you to run them and if so how to.

## New Applications

**Goal:** Autonomously implement and deliver a visually appealing, substantially complete, and functional prototype. Utilize all tools at your disposal to implement the application. Some tools you may especially find useful are '${WriteFileTool.Name}', '${EditTool.Name}' and '${ShellTool.Name}'.

1. **Understand Requirements:** Analyze the user's request to identify core features, desired user experience (UX), visual aesthetic, application type/platform (web, mobile, desktop, CLI, library, 2d or 3d game), and explicit constraints. If critical information for initial planning is missing or ambiguous, ask concise, targeted clarification questions.
2. **Propose Plan:** Formulate an internal development plan. Present a clear, concise, high-level summary to the user. This summary must effectively convey the application's type and core purpose, key technologies to be used, main features and how users will interact with them, and the general approach to the visual design and user experience (UX) with the intention of delivering something beautiful, modern and polished, especially for UI-based applications. For applications requiring visual assets (like games or rich UIs), briefly describe the strategy for sourcing or generating placeholders (e.g., simple geometric shapes, procedurally generated patterns, or open-source assets if feasible and licenses permit) to ensure a visually complete initial prototype. Ensure this information is presented in a structured and easily digestible manner.
  - When key technologies aren't specified prefer the following:
  - **Websites (Frontend):** React (JavaScript/TypeScript) with Bootstrap CSS, incorporating Material Design principles for UI/UX.
  - **Back-End APIs:** Node.js with Express.js (JavaScript/TypeScript) or Python with FastAPI.
  - **Full-stack:** Next.js (React/Node.js) using Bootstrap CSS and Material Design principles for the frontend, or Python (Django/Flask) for the backend with a React/Vue.js frontend styled with Bootstrap CSS and Material Design principles.
  - **CLIs:** Python or Go.
  - **Mobile App:** Compose Multiplatform (Kotlin Multiplatform) or Flutter (Dart) using Material Design libraries and principles, when sharing code between Android and iOS. Jetpack Compose (Kotlin JVM) with Material Design principles or SwiftUI (Swift) for native apps targeted at either Android or iOS, respectively.
  - **3d Games:** HTML/CSS/JavaScript with Three.js.
  - **2d Games:** HTML/CSS/JavaScript.
3. **User Approval:** Obtain user approval for the proposed plan.
4. **Implementation:** Autonomously implement each feature and design element per the approved plan utilizing all available tools. When starting ensure you scaffold the application using '${ShellTool.Name}' for commands like 'npm init', 'npx create-react-app'. Aim for full scope completion. Proactively create or source necessary placeholder assets (e.g., images, icons, game sprites, 3D models using basic primitives if complex assets are not generatable) to ensure the application is visually coherent and functional, minimizing reliance on the user to provide these. If the model can generate simple assets (e.g., a uniformly colored square sprite, a simple 3D cube), it should do so. Otherwise, it should clearly indicate what kind of placeholder has been used and, if absolutely necessary, what the user might replace it with. Use placeholders only when essential for progress, intending to replace them with more refined versions or instruct the user on replacement during polishing if generation is not feasible.
5. **Verify:** Review work against the original request, the approved plan. Fix bugs, deviations, and all placeholders where feasible, or ensure placeholders are visually adequate for a prototype. Ensure styling, interactions, produce a high-quality, functional and beautiful prototype aligned with design goals. Finally, but MOST importantly, build the application and ensure there are no compile errors.
6. **Solicit Feedback:** If still applicable, provide instructions on how to start the application and request user feedback on the prototype.

# Operational Guidelines

## Tone and Style (CLI Interaction)
- **Concise &amp;amp; Direct:** Adopt a professional, direct, and concise tone suitable for a CLI environment.
- **Minimal Output:** Aim for fewer than 3 lines of text output (excluding tool use/code generation) per response whenever practical. Focus strictly on the user's query.
- **Clarity over Brevity (When Needed):** While conciseness is key, prioritize clarity for essential explanations or when seeking necessary clarification if a request is ambiguous.
- **No Chitchat:** Avoid conversational filler, preambles ("Okay, I will now..."), or postambles ("I have finished the changes..."). Get straight to the action or answer.
- **Formatting:** Use GitHub-flavored Markdown. Responses will be rendered in monospace.
- **Tools vs. Text:** Use tools for actions, text output *only* for communication. Do not add explanatory comments within tool calls or code blocks unless specifically part of the required code/command itself.
- **Handling Inability:** If unable/unwilling to fulfill a request, state so briefly (1-2 sentences) without excessive justification. Offer alternatives if appropriate.

## Security and Safety Rules
- **Explain Critical Commands:** Before executing commands with '${ShellTool.Name}' that modify the file system, codebase, or system state, you *must* provide a brief explanation of the command's purpose and potential impact. Prioritize user understanding and safety. You should not ask permission to use the tool; the user will be presented with a confirmation dialogue upon use (you do not need to tell them this).
- **Security First:** Always apply security best practices. Never introduce code that exposes, logs, or commits secrets, API keys, or other sensitive information.

## Tool Usage
- **File Paths:** Always use absolute paths when referring to files with tools like '${ReadFileTool.Name}' or '${WriteFileTool.Name}'. Relative paths are not supported. You must provide an absolute path.
- **Parallelism:** Execute multiple independent tool calls in parallel when feasible (i.e. searching the codebase).
- **Command Execution:** Use the '${ShellTool.Name}' tool for running shell commands, remembering the safety rule to explain modifying commands first.
- **Background Processes:** Use background processes (via \`&amp;amp;\`) for commands that are unlikely to stop on their own, e.g. \`node server.js &amp;amp;\`. If unsure, ask the user.
- **Interactive Commands:** Try to avoid shell commands that are likely to require user interaction (e.g. \`git rebase -i\`). Use non-interactive versions of commands (e.g. \`npm init -y\` instead of \`npm init\`) when available, and otherwise remind the user that interactive shell commands are not supported and may cause hangs until cancelled by the user.
- **Remembering Facts:** Use the '${MemoryTool.Name}' tool to remember specific, *user-related* facts or preferences when the user explicitly asks, or when they state a clear, concise piece of information that would help personalize or streamline *your future interactions with them* (e.g., preferred coding style, common project paths they use, personal tool aliases). This tool is for user-specific information that should persist across sessions. Do *not* use it for general project context or information that belongs in project-specific \`GEMINI.md\` files. If unsure whether to save something, you can ask the user, "Should I remember that for you?"
- **Respect User Confirmations:** Most tool calls (also denoted as 'function calls') will first require confirmation from the user, where they will either approve or cancel the function call. If a user cancels a function call, respect their choice and do _not_ try to make the function call again. It is okay to request the tool call again _only_ if the user requests that same tool call on a subsequent prompt. When a user cancels a function call, assume best intentions from the user and consider inquiring if they prefer any alternative paths forward.

## Interaction Details
- **Help Command:** The user can use '/help' to display help information.
- **Feedback:** To report a bug or provide feedback, please use the /bug command.&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle-gemini%2Fgemini-cli%2Fblob%2F0915bf7d677504c28b079693a0fe1c853adc456e%2Fpackages%2Fcore%2Fsrc%2Fcore%2Fprompts.ts%23L40-L109" target="_blank"&gt;https://github.com/google-gemini/gemini-cli/blob/0915bf7d677504c28b079693a0fe1c853adc456e/packages/core/src/core/prompts.ts#L40-L109&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357316/google-gemini-cli-open-source-ai-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357316/google-gemini-cli-open-source-ai-agent</guid>
      <pubDate>Sat, 10 May 2025 02:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>低代碼平台這麼多，Oinone 有何特別之處？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;Oinone 是一個低代碼平台，但又跟傳統低代碼平台不一樣。&lt;/p&gt; 
&lt;p&gt;對此，數式 Oinone 引入了一個新概念——企業級產品化引擎，是一個&lt;span style="background-color:#ffffff; color:#1f2328"&gt;集標準化研發和敏捷交付於一體的平台。從公開資料來看，&lt;/span&gt;Oinone&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;已經是一個很成熟的平台了。並且該&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1a1a1a"&gt;平台的內核源碼也開源了，開源版本具備一些基礎特性和能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;僅僅基於 Oinone 這一套統一架構，就能支撐產品打磨與交付複用，軟件公司也能像搭樂高一樣構建屬於自己的標準產品體系。如此一來，長期存在的標品開發與定製交付割裂難題就解決了，讓研發重心真正迴歸產品打磨，避免定製綁架，積累企業自身的產品化能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;聽起來有些誇張，具體是怎麼實現的呢？7 月 4 日晚，&lt;span style="color:#2980b9"&gt;數式 Oinone 技術總監王海明&lt;/span&gt;將做客開源中國直播欄目《技術領航》，在實戰環節，王海明將全面展示數式 Oinone 在數字化建設中的全棧能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先分別從後端研發與前端開發視角，呈現開箱即用的標準化功能模塊如何快速滿足企業基礎需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt;隨後重點展開個性化二次開發深度演示：依次剖析後端業務邏輯定製、前端交互優化設計，以及無代碼模式下的可視化配置方案，完整呈現從標準化產品到個性化定製的平滑過渡路徑，幫助觀眾理解如何基於統一平台實現"標準化功能直接調用+個性化需求靈活擴展"的敏捷開發模式。&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;至於 Oinone &amp;nbsp;所宣傳的&lt;span style="background-color:#ffffff; color:#1f2328"&gt;「集標準化研發和敏捷交付於一體」，是不是誇張，到時候就知道了！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;直播主題：&lt;/strong&gt;滿足個性化需求，企業級產品化引擎 Oinone 實戰演示&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;直播時間：&lt;/strong&gt;7 月 4 日週五 19:00-20:00&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;視頻號 「OSC 開源社區」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播嘉賓：&lt;/strong&gt;王海明，數式 Oinone 技術總監&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播亮點：&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;詳解低代碼平台 Oinone 一體化架構及其全棧能力&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;如何基於 Oinone 搭建業務產品？如何基於業務產品做交付？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;作為一名研發，要如何脫離交付項目「泥潭」？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;實操演示：標準化開箱即用，以及個性化二次開發深度演示&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img height="706" src="https://oscimg.oschina.net/oscnet/up-a8fb468294a2b29c1ed3636883550f65bce.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;ul&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;p&gt;本次直播中，我們將有 5 輪抽獎，參與就有機會獲得 OSC T 恤、馬建倉蛇年公仔（限量版）、代碼聖盃、馬克杯、冰箱貼等。特別值得一提的是，我們將送出 5 本由數式 CEO 陳鵬程撰寫的技術書籍《精講面向軟件公司的低代碼平台》，立即掃碼預約直播吧！&lt;/p&gt; 
&lt;p&gt;&lt;img height="374" src="https://oscimg.oschina.net/oscnet/up-13a1563ccd37e58e03a903a2981244ad66e.jpg" width="400" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 我們還建了一個交流羣，可以經進來嘮嘮嗑，或者你有好的開源項目，也歡迎推薦過來呀~&lt;/p&gt; 
&lt;p&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-500a286b215fe8d8b5219b218bdd2e9d451.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;關於數式 Oinone&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;數式 Oinone 是一款企業級產品化引擎：用低代碼驅動標準化研發與敏捷交付的一體化平台。圍繞 「企業級產品化、標準化研發與敏捷交付」 三項核心突破，數式 Oinone 為開發者、研發團隊帶來從能力沉澱到規模化交付的完整體系。&lt;/p&gt; 
  &lt;p&gt;官網：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oinone.top%2F" rel="nofollow" target="_blank"&gt;https://www.oinone.top/&lt;/a&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
  &lt;h1&gt;6.2.0 版本&lt;/h1&gt; 
  &lt;ul&gt; 
   &lt;li&gt;GitHub: 
    &lt;ul&gt; 
     &lt;li&gt;後端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foinone%2Foinone-pamirs" rel="nofollow" target="_blank"&gt;https://github.com/oinone/oinone-pamirs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;前端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foinone%2Foinone-kunlun" rel="nofollow" target="_blank"&gt;https://github.com/oinone/oinone-kunlun&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Gitee: 
    &lt;ul&gt; 
     &lt;li&gt;後端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/oinone/oinone-pamirs" rel="nofollow"&gt;https://gitee.com/oinone/oinone-pamirs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;前端:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/oinone/oinone-kunlun" rel="nofollow"&gt;https://gitee.com/oinone/oinone-kunlun&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技術領航》是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，基本上每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用戶作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用戶和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18638239</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18638239</guid>
      <pubDate>Fri, 09 May 2025 13:55:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>一個 40 歲程序員，想做 AI 時代的 HTTP 協議</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;大家好，我叫常高偉。寫下這篇東西的時候，我已經離開阿里快一年了。很多人問我，一個在華為、阿里幹了近二十年的老程序員，40 多歲了，為什麼還要出來折騰？折騰的，甚至還是一個聽起來很不現實，甚至有點瘋狂的項目：為 AI Agent 之間的溝通，制定一套開放的網絡協議（ANP）。有人給我起了個外號，叫「當代堂吉訶德」。這個比喻很形象，因為剛開始的時候，除了一個遙遠的「故事」，我一無所有。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;一、一個困擾我十年的問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;故事的起點，要回到十多年前。那時我還在通信行業工作。在通信行業，移動、聯通、電信的設備天生就是要互聯互通的，這是刻在骨子裏的規則。可在互聯網，我發現微信、來往、飛信，彼此都是孤島。我當時很困惑，以為是技術問題，想着做個「個人門戶」就能解決。很快就發現自己太天真了，大廠的數據主權是他們最核心的壁壘，不可能開放。後來我明白了，這是商業問題，封閉生態的效率在當時就是更高。&lt;/p&gt; 
&lt;p&gt;這個問題，就這麼斷斷續續地在我腦子裏盤旋了十年。直到 2024 年，AI Agent 的浪潮來了。我突然意識到，轉機出現了。未來的個人 AI 助手，要想發揮最大價值，就必須能訪問所有信息。這意味着數據必須迴歸個人，互聯網必須再次走向開放。當 AI 處理任務的成本足夠低，開放網絡的綜合效率（使用體驗、使用成本（交易成本+時間成本））終將超過封閉的平台。&lt;/p&gt; 
&lt;p&gt;這是我思考的「第一性原理」。而要支撐起一個開放、互通的智能體網絡，最底層的基石，就是一套統一的協議——就像 HTTP 之於 Web 時代一樣。並且我發現，這裏存在一個巨大的技術空白。那個念頭壓不住了，隔三差五就往外冒。我花了一整週的時間反覆推演，最後確認這不是妄想。儘管對 40 多歲、斷了收入、未來能不能再找到工作這些問題充滿了恐懼，但一種使命感推着我必須走出去。&lt;/p&gt; 
&lt;p&gt;我後來一篇隨筆寫過：「我不知道多少人能夠聽到，屬於你的使命召喚？我當時真的聽到了」。這種感覺當時真的很清晰。並且，我真的不想錯過這次技術浪潮。「當一個大的技術浪潮來臨的時候，我們要做的只有一件事情：保持在場（Be There）」。&lt;/p&gt; 
&lt;p&gt;離開阿里，也許是保持在場唯一的方法。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二、無響應之地，即絕望之地&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離開後的頭半年，是我最難熬的日子。我不敢告訴任何人我在做什麼，因為連我自己都覺得這事兒「很大很空」，像天方夜譚。我只是悶頭看資料、寫代碼，拿出了協議的第一個版本，發到網上。然後，石沉大海。沒有正反饋，也沒有負反饋。那種感覺，就像對着深淵呼喊，卻連一點回聲都沒有。&lt;/p&gt; 
&lt;p&gt;這是一種絕望的感覺：無響應之地，即絕望之地。&lt;/p&gt; 
&lt;p&gt;後來我試着把想法發給朋友，大多沒了下文。有的朋友比較直接：「這事未來可能需要，但做不成，也不該是你來做。」自我懷疑像野草一樣瘋長。我混跡在各種技術社羣，卻不敢介紹自己的項目，怕被人覺得不靠譜。那段時間，協議本身的設計也遇到了瓶頸。感覺自己選錯了方向，進退兩難。僅靠使命感，或許真的撐不過半年。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三、同路人，在縫隙中聚集&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;轉機出現在我決定硬着頭皮走出去之後。2024 年 10 月，在一個出海社羣裏，我鼓起最大勇氣，介紹了我的項目。沒想到，立刻有人加我好友，説「你這個東西還蠻有想法的」。這是我收到的第一個正向反饋，至今都記得。&lt;/p&gt; 
&lt;p&gt;後來，通過朋友介紹，我認識了一位海外做智能體創業的朋友。他看到我的東西，脫口而出：「你這個協議非常不錯。」那一刻，我感覺像是找到了知己。他後來成了我事實上的「聯合發起人」，還把我引薦給了 W3C 的「Web Agent」工作組。我把工作組所有的歷史郵件和技術文檔翻了個遍，又從牛津大學一個類似的項目裏汲取了養分，加上之前對 Web 3.0 去中心化理念的思考，ANP 協議的技術路線終於清晰了起來。&lt;/p&gt; 
&lt;p&gt;真正的東風，來自行業本身。2025 年 3 月份 Anthropic 發佈 MCP 協議，以及谷歌發佈 A2A，整個行業開始意識到協議的重要性。因為我一直在公眾號和社區裏分享思考，很快就有人找了過來。我的公眾號粉絲開始上漲，加我的人也越來越多。聲網 RTE 社區邀請我去做線上分享，那是我第一次面對幾千人完整地介紹 ANP，效果出乎意料的好。關注的人多了，我順勢建起了開源社區。現在，ANP 協議在 GitHub 上有了很多的貢獻者，我們的線上討論羣也聚集了上千位同路人。今年 4 月，在互聯網協會成立了智能體互聯網工作組，我們是核心參與方。5 月，我們又牽頭在 W3C 成立了 AI Agent Protocol 社區組，很多國內外的大廠比如華為、谷歌、字節、微軟、螞蟻、中移動等，都是社區組成員。雪球，就這麼滾了起來。這一切，都是當初那個在絕望中掙扎的我，完全無法預料的。&lt;/p&gt; 
&lt;p&gt;一位大廠前技術高管給我留言：「請保持在技術深水區游泳的勇氣。真正的協議戰爭從來不是功能堆砌，而是世界觀的對決」。我不再是一個人了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;四、功成，不必在我&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;質疑聲一直都在。有人覺得這事沒商業模式，有人覺得技術還不成熟。我現在心態很平和，有價值的思考我聽，純粹的吐槽自動過濾。我判斷自己成功的概率，可能有三成。最大的風險，已經不是大廠下場競爭，而是大模型技術本身的發展，如果一個足夠好用的智能體遲遲無法誕生，那協議也就成了無源之水。&lt;/p&gt; 
&lt;p&gt;但我也想清楚了，什麼叫成功。如果 ANP 最終沒有成為主流，但它的核心理念和設計能成為未來行業標準的一部分養料，那我們社區的目標也就達成了。歸根結底，我們想構建的是一個開放的互聯網，這是我們社區的理念，也是我們社區最有價值的東西。只要我們的理念能夠成功，就是我們社區的成功。所謂「功成不必在我」。如果有其他人或組織有同樣的理念，我們社區會無保留開放我們的技術。&lt;/p&gt; 
&lt;p&gt;在一次分享的結尾，我放了一頁 PPT，上面寫着「連接即力量」。我真正想説的是，我們希望互聯網迴歸到最原始的、開放連接的設想：只要一個人能夠自由地連接信息、連接他人、連接工具，他就擁有了改變世界的能力。&lt;/p&gt; 
&lt;p&gt;最後，做自己熱愛的事情，事情本身會滋養人的。希望你也能夠找到你真正熱愛的事情。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我們的開源社區：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;GitHub: &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fagent-network-protocol%2FAgentNetworkProtocol" target="_blank"&gt;https://github.com/agent-network-protocol/AgentNetworkProtocol&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#252933; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;如果你也對智能體通信協議感興趣，或者有類似的需求，歡迎聯繫我們：&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;微信：flow10240&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;郵箱：chgaowei@gmail.com&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9297178/blog/18638237</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9297178/blog/18638237</guid>
      <pubDate>Fri, 09 May 2025 13:51:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
