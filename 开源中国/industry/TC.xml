<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Thu, 07 Aug 2025 07:41:08 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Cursor 設計負責人分享：軟件工程師（或任何人）如何提升設計水平？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;我經常被問到這個問題。作為一個從計算機科學（CS）轉型做設計的人，我想分享一條切實可行的路徑：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;從系統思維開始&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;工程師們對此已經很熟悉了。設計，只不過是為人類和我們的感官（而非機器）打造的系統。如果你還沒讀過，可以去讀一讀《系統之美》（Thinking in Systems）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;學習基礎知識&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;人類經過幾個世紀的進化，已經形成了一套用於視覺化呈現和接收信息的系統。即使是命令行界面（CLI），也無法避開這些法則：&lt;/p&gt; 
&lt;p&gt;字體排印 — 從 Jost Hochuli 的《Details in Typography》開始。 色彩基礎 — 從 Josef Albers 的《色彩構成》(Interaction of Color) 開始。 網格系統 — 從 Josef Müller-Brockmann 的《平面設計中的網格系統》(Grid Systems) 開始。&lt;/p&gt; 
&lt;p&gt;視覺層次、閲讀節奏、符號與概念系統、動效、無障礙設計…… — 隨着實踐，你會掌握更多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;敞開你的雙眼和大腦&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;觀察你周圍的事物，無論是數字世界還是自然界。觀察萬物中的美與共通之處，思考它為何被設計成這樣。在你的觀察、思考和創造之間建立聯繫。打破僵化、線性的思維，釋放自己。凝望天空，放空自己。洞悉萬物。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然後，放手去創造&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;既然你已經開始留意，那就試着去改進事物，先用你自己的方式。重新設計你日常使用的應用。逐像素地復刻你喜愛的設計——這樣一週學到的東西比你看幾個月理論還多。然後，將你的作品分享給他人，獲取反饋，併為更多人設計。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關鍵心態轉變：感受先行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;停止為計算機優化，開始為人類優化。工程師考慮的是邊緣情況（edge cases）和錯誤狀態，而設計師考慮的是理想路徑（happy paths）和情感體驗。對人類來説，最終的感受以及事物如何融為一體，遠比邊緣情況重要得多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;工具沒那麼重要&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Figma 是行業標準。一個週末就能學會（它基本上就是可視化的 Flexbox）。你可以用 Cursor 這類工具來拆解現有設計系統並製作原型，研究它們是如何構建的——前端技術在這裏大有可為。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最重要的一點&lt;/strong&gt;：通過約束找到你自己的設計語言。 選擇一款出色的字體，一套有限的調色板，然後用它們做出 10 種不同的佈局。約束催生創造力。而迭代是達成目標的途徑。&lt;/p&gt; 
&lt;p&gt;優秀的工程師已經理解系統、邏輯和解決問題的方法。他們只需將這些能力應用到人的概念和問題上，而不是技術問題上。&lt;/p&gt; 
&lt;p&gt;從明天開始。重新設計你的個人網站或一個簡單的應用。完成它，分享它，不斷重複。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：x.com/ryolu_/status/1952759102058242253&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364816</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364816</guid>
      <pubDate>Thu, 07 Aug 2025 07:35:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>摩爾線程 MUSA 架構成功適配開源推理框架 llama.cpp</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MUSA（Meta-computing Unified System Architecture）是摩爾線程自主研發的通用並行計算架構。官方近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1qctAz4EUq%2F"&gt;宣佈&lt;/a&gt;&amp;nbsp;MUSA&amp;nbsp;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;已正式完成與開源推理框架 llama.cpp 的適配，進一步融入全球 AI 生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-21f1f791376efc2c7275c63eb22cf6de3a0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;llama.cpp 作為純 C/C++ 實現的大語言模型推理工具，以輕量化部署和跨硬件兼容性著稱，支持 LLaMA、Mistral 等主流模型及多模態應用。此次適配意味着用戶可在 MTT S80/S3000/S4000 系列 GPU 上通過官方容器鏡像高效運行 AI 推理。&lt;/p&gt; 
&lt;p&gt;今年 4 月，MUSA SDK 4.0.1 已擴展至 Intel 處理器與國產海光平台，此次與 llama.cpp 的聯動，進一步降低了開發者部署大模型的門檻，為本土 AI 硬件生態注入新動能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364814</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364814</guid>
      <pubDate>Thu, 07 Aug 2025 07:23:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小紅書開源多模態大模型 dots.vlm1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;小紅書 Hi Lab 開源了其首個自研多模態大模型&amp;nbsp;&lt;strong&gt;dots.vlm1&lt;/strong&gt;。該模型基於 12 億參數的&amp;nbsp;&lt;strong&gt;NaViT 視覺編碼器&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;DeepSeek V3 大語言模型&lt;/strong&gt;，從零開始完全訓練，其卓越性能在多模態視覺理解與推理能力上已接近當前領先的閉源模型，如&amp;nbsp;&lt;strong&gt;Gemini2.5Pro&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;Seed-VL1.5&lt;/strong&gt;，標誌着開源多模態模型的性能達到了新的高度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;dots.vlm1 的核心亮點在於其原生自研的&amp;nbsp;&lt;strong&gt;NaViT 視覺編碼器&lt;/strong&gt;。與傳統基於成熟模型微調的方式不同，NaViT 從零訓練，並支持動態分辨率，能夠更好地適應多樣化的真實圖像場景。該模型還通過結合純視覺與文本視覺的雙重監督，極大提升了其泛化能力，尤其是在處理表格、圖表、公式、文檔等非典型結構化圖片時表現出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在數據方面，Hi Lab 團隊構建了規模龐大且清洗精細的訓練集。他們通過自主重寫網頁數據和自研&amp;nbsp;&lt;strong&gt;dots.ocr&lt;/strong&gt;&amp;nbsp;工具處理 PDF 文檔，顯著提升了圖文對齊的質量，為模型的跨模態理解能力打下了堅實基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;評測結果表明，dots.vlm1 在&amp;nbsp;&lt;strong&gt;MMMU&lt;/strong&gt;、&lt;strong&gt;MathVision&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;OCR Reasoning&lt;/strong&gt;&amp;nbsp;等多項基準測試中，達到了與 Gemini2.5Pro 和 Seed-VL1.5 相當的水平。在複雜的圖表推理、STEM 數學推理以及長尾細分場景識別等應用中，dots.vlm1 展現出卓越的邏輯推理和分析能力，完全勝任奧數等高難度任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="527" src="https://oscimg.oschina.net/oscnet/up-6e01b7f98f74ddc0a373242bba0c2e628a3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管在文本推理的極複雜任務上與 SOTA 閉源模型仍有差距，但其通用數學推理和代碼能力已與主流大語言模型持平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Hi Lab 團隊表示，未來將繼續優化模型。他們計劃擴大跨模態數據規模，並引入強化學習等前沿算法，進一步提升推理泛化能力。通過開源&amp;nbsp;&lt;strong&gt;dots.vlm1&lt;/strong&gt;，小紅書致力於為多模態大模型生態系統帶來新的動力，推動行業發展。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364810</guid>
      <pubDate>Thu, 07 Aug 2025 07:08:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>日本政府禁止蘋果在 iOS 平台限制第三方瀏覽器引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;日本政府已通過《智能手機法》（正式名稱為《&lt;/span&gt;Bill on the Promotion of Competition for Specified Software Used in Smartphones&lt;span&gt;》）及其配套的《移動軟件競爭法》（MSCA）指南，正式禁止蘋果在 iOS 平台上限制第三方瀏覽器引擎，要求&lt;/span&gt;蘋果 iOS 必須在今年 12 月前解除瀏覽器引擎禁令，必須允許第三方瀏覽器使用自己的引擎（如 Blink、Gecko）。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1832" src="https://static.oschina.net/uploads/space/2025/0807/145413_X9Uj_2720166.png" width="1316" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://www.jftc.go.jp/file/MSCA_Guidelines_tentative_translation.pdf&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;配套要求&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;禁止設置技術或財務上的不合理障礙；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;禁止引導用戶遠離非 WebKit 瀏覽器；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要求設備首次激活時立即彈出瀏覽器選擇界面，確保用戶能明確選擇；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;瀏覽器開發者必須獲得與 Safari 同等水平的系統 API 訪問權限。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據瞭解，&lt;span&gt;蘋果以「安全與隱私」為由，強制所有運行在 iOS 的瀏覽器（比如&amp;nbsp;&lt;/span&gt;Firefox、Chrome、Edge、Opera、Brave&lt;span&gt;）必須使用 WebKit 引擎，導致這些瀏覽器本質上都是「Safari 換皮」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Open Web Advocacy 組織參與了法律諮詢並協助制定政府最終報告，該組織昨天在其官網發佈的聲明稱：「蘋果通過強制使用 WebKit，實際上禁止了 iOS 上獨立瀏覽器的發展。新的法律不僅禁止了明令禁止的行為，也禁止了那些讓替代引擎難以運行的做法。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364809</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364809</guid>
      <pubDate>Thu, 07 Aug 2025 07:06:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Character.AI 發佈全球首個 AI 原生社交動態功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Character. AI &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.character.ai%2Fcharacter-ai-launches-worlds-first-ai-native-social-feed%2F" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出全球首個 AI 原生社區動態（Community Feed） 功能，將提供個性化的角色、場景和創作者帖子，旨在激發靈感、娛樂和聯繫。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5457c8a14f5ed1a8c61106c1b0ad7e652b7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a44b4f56f6311445a4cc5ae981e65fc3360.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;社區動態功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聊天片段（分享展現角色個性的對話片段）&lt;/li&gt; 
 &lt;li&gt;角色卡片（生成可直接聊天的角色預覽）&lt;/li&gt; 
 &lt;li&gt;直播流（為心儀角色設定主題，觀看其辯論、吐槽、製作視頻博客等）&lt;/li&gt; 
 &lt;li&gt;虛擬形象特效（通過自定義視頻模型生成角色或任意內容的視頻，只需一張圖片和簡短腳本，數秒即可完成）&lt;/li&gt; 
 &lt;li&gt;圖像生成（基於與角色的聊天內容生成背景圖）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據介紹，社區動態功能使 Character.AI 從聊天應用升級為面向下一代的全內容社交平台，重塑人們與 AI、敍事及彼此的互動方式。其 CEO 表示：「新信息流模糊了創作者與消費者的界限，終結無意義滑動，引領 AI 娛樂未來。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364805/character-ai-launches-worlds-first-ai-native-social-feed</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364805/character-ai-launches-worlds-first-ai-native-social-feed</guid>
      <pubDate>Thu, 07 Aug 2025 06:47:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 在實際生成環境中的提效實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;導讀&lt;/h4&gt; 
&lt;p&gt;隨着 AI 時代的到來，各類 AI 工具層出不窮，業界都在探索一套完整的 AI 加成的提效方案，我們團隊基於自身特色，利用起團隊沉澱好的歷史知識庫，落地了一套深度結合 AI 的工作流，用 AI 武裝研發團隊，實現研發效率的提升。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;各類 AI 研發工具層出不窮，很多現成工具可使用，&lt;em&gt;&lt;strong&gt;業界都在探索一套完整的 AI 加成的提效方案&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;團隊內部規範文檔完備，但是沒有融入開發流程中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Code review、研發自測、接口文檔更新消耗大量時間&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;目標&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 擁抱 AI 時代，&lt;strong&gt;讓團隊更先進&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;2. 用 AI 武裝研發團隊，通過資源的配合與協調，實現研發效率的提升。&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;思路&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 拆分研發流程，並找到 AI 結合點，並將其串聯起來。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 深度探索 AI IDE，得出最佳實踐。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;3. 利用起團隊的知識庫，為 AI 提供輔助能力。&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;定位&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 這是一個錨點，自此開始團隊研發流程向 AI 化轉變。&lt;/p&gt; 
&lt;p&gt;2. 這是一個開始，帶動團隊與其他同學 review 當前研發流程，&lt;strong&gt;共建更多研發工作流。&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;01 研發鏈路&lt;/h1&gt; 
&lt;p&gt;對研發鏈路進行拆解，得到不同階段的 AI 工作流形態，並基於當前形態向下一形態進行推進。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b940caac96e16b2debbc458606192f14b2c.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;當前我們團隊正處於階段 1 接近完成，階段 2 正在開始探索實踐的階段，因此下面我們會基於我們團隊在這些方面的實踐進行分享。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;原本研發鏈路：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8a46b6b27bceca968a8d8cb3f86c27b69d8.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 加持研發流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e74eb941a7e4a40ab2b07fbbe750401fff3.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;AI 工作流&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;對上面涉及到的 AI 工作流進行補充説明&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI-Cafes：AI 生成需求文檔，製作產品原型圖，節省產品人天。&lt;/p&gt; 
&lt;p&gt;AI-Docs：需求文檔轉技術文檔，節省研發梳理過程，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-DocsCoding：基於技術文檔，生成基礎無業務邏輯代碼，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-Coding：基於團隊內部代碼規範生成代碼，減少返工和代碼理解成本，深度提高研發效率，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-API：基於 MCP Server 打通接口文檔，避免 api 文檔/技術文檔更新不及時，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-CR：基於 Rules，進行 AI Code Review，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-Develops：AI 賦能測試、驗證、監控環節，節省測試人天。&lt;/p&gt; 
&lt;span id="OSC_h1_8"&gt;&lt;/span&gt; 
&lt;h1&gt;02 需求階段&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;AI-CafeDocs&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在原本的工作流中，在需求評審過後，研發同學通常需要至少 0.5d 的人力進行技術文檔的落地，以及 api 接口的準備。&lt;/p&gt; 
&lt;p&gt;但是這一步中的大部分工作是&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的。&lt;/p&gt; 
&lt;p&gt;因此我們實現了了_&lt;strong&gt;&lt;em&gt;&lt;strong&gt;需求文檔 -&amp;gt; aisuda（百度的低代碼平台）-&amp;gt; 大模型 -&amp;gt; 技術文檔（markdown）&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;_的工作流。&lt;/p&gt; 
&lt;p&gt;在微調好大模型之後，我們只需要以下兩步就能完成技術文檔+api 接口準備的工作：&lt;/p&gt; 
&lt;p&gt;1. 投餵需求文檔給大模型，得到初版技術文檔。&lt;/p&gt; 
&lt;p&gt;2. 人工 check 技術文檔。&lt;/p&gt; 
&lt;p&gt;在快速生成了技術文檔後，後端再和前端進行溝通，根據細節進行修改具體實現。&lt;/p&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-DocsCoding&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在得到技術文檔之後，我們下一步要做的則是落地。不得不承認，我們的工作中無可避免的會存在一些基礎的 CRUD 環節，這是正常的，也是&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的。&lt;/p&gt; 
&lt;p&gt;因此，基於以上的 AI-CafeDocs 環節，我們進行了進一步的延伸，實現了_&lt;strong&gt;&lt;em&gt;&lt;strong&gt;技術文檔 -&amp;gt; MCP Server -&amp;gt; AI IDE&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;_ 的工作流&lt;/p&gt; 
&lt;p&gt;我們通過 MCP 打通了內部的知識庫，使得 AI 能夠閲讀到需求文檔和技術文檔，瞭解上下文，並進行對應的開發工作。&lt;/p&gt; 
&lt;p&gt;當然，AI 全流程開發只是一種理想的狀態，就當前而言，AI-DocsCoding 寫出來的代碼並不是完全可用的，在涉及到的業務邏輯越複雜時，代碼的正確性就越低。&lt;/p&gt; 
&lt;p&gt;但是不要緊，我們在設計這個流程的時候，就早有準備。&lt;/p&gt; 
&lt;p&gt;還記得我們強調的一點：讓 AI 取代&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的工作，那麼正確的流程為：&lt;/p&gt; 
&lt;p&gt;1. AI 通過 MCP 閲讀需求文檔、技術文檔，生成本次功能的基礎代碼——除卻業務邏輯之外的參數處理、數據處理的 CRUD 代碼。&lt;/p&gt; 
&lt;p&gt;2. 人工補全核心的業務邏輯處理，人也只需要關心真正的業務邏輯，這些事 AI 無法替代的。&lt;/p&gt; 
&lt;p&gt;可以看到，在以上的兩個工作流裏，人的角色從執行者，變成了驅動者/觀察者，或者説產品經理。&lt;/p&gt; 
&lt;p&gt;我們通過**&lt;em&gt;&lt;strong&gt;向 AI 提出需求，監督 AI 工作，驗收 AI 工作結果&lt;/strong&gt;&lt;/em&gt;**的方式進行工作。&lt;/p&gt; 
&lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
&lt;h1&gt;03 開發階段&lt;/h1&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-Coding&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;AI-Coding 這一塊主要圍繞 AI IDE 的使用，現在市面上有很多的產品，比如 Cursor、Comate、Trae 等。其實在許多人看來，AI IDE 的核心在於底層能夠接入的模型，但是我覺得這不盡然，大模型的邊界效應很強。&lt;/p&gt; 
&lt;p&gt;有些時候，我們對 AI IDE 的使用，還沒有達到需要區分模型效果的地步。&lt;strong&gt;&lt;strong&gt;或者説，如果我們使用了世界上最好的模型，那我們是否就高枕無憂了，可以讓 AI 全程進行 Coding 而不需要人為 Review 了&lt;/strong&gt;&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;至少使用到今天為止，我們認為 AI-Coding，還離不開人的關注，因此如何更好地使用 AI 進行 Coding，是 AI 提效的必經之路。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;合理使用 Rule&lt;/h3&gt; 
&lt;p&gt;在&lt;strong&gt;&lt;strong&gt;AI IDE&lt;/strong&gt;&lt;/strong&gt;內，Rule 是一個非常重要的環節，&lt;strong&gt;它是連接開發者意圖與 AI 代碼生成行為之間的關鍵橋樑&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;定義：Rule 的，核心目的是指導 AI 更準確地理解當前代碼庫的上下文、遵循特定的項目規範與編碼標準、生成符合預期的代碼，或輔助完成複雜的工作流程。Cursor 官方文檔將其描述為「控制 Agent 模型行為的可複用、有作用域的指令」。&lt;/p&gt; 
&lt;p&gt;作用：大型語言模型（LLMs）本身在多次交互之間通常不具備持久記憶。Rule 通過在每次 AI 請求的提示詞（prompt）層面提供持久化、可複用的上下文信息，有效解決了這一問題。&lt;strong&gt;當一個規則被應用時，其內容會被包含在模型上下文的起始部分&lt;/strong&gt;，從而為 AI 的代碼生成、編輯解釋或工作流輔助提供穩定且一致的指導。&lt;/p&gt; 
&lt;p&gt;上面有一個非常重要的點，那就是所有的 rule 在使用的過程中，都會佔用我們上下文的 token，因此如何更好的使用 Rule，是提升 AICoding 能力的關鍵。&lt;/p&gt; 
&lt;p&gt;基於我們的實踐，我們建議將 AI IDE 的 rule 進行層級劃分：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第一層：IDE 全局層 (User Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：User Rules&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：所有項目通用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：個人編碼風格偏好&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：50 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第二層：項目基礎層 (Always Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/always/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：整個項目強制遵循&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：技術棧、核心原則、基礎規範&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：100 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第三層：自動匹配層 (Auto Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/auto/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：特定文件類型或目錄&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：模塊專門的開發規範&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每個規則 200 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第四層：智能推薦層 (Agent Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/agent/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：AI 根據對話內容智能判斷&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：優化建議和最佳實踐&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每個規則 150 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第五層：手動調用層 (Manual Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/manual/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：手動調用的代碼模板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：完整的項目或模塊模板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每個規則 300 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上的劃分，我們再給出對 &lt;strong&gt;&lt;strong&gt;已有/未有 Rule 規範&lt;/strong&gt;&lt;/strong&gt;的代碼庫的 Rule 創建規則（語言不重要，以 Go 為例）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;內容優化原則&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;詳細代碼示例（每個 100+行）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;重複的概念解釋&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推薦：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;簡潔要點列表（每個 20-30 行）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;具體的操作指令&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;globs 精確匹配&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;過於寬泛：&lt;code&gt;"**/*.go"&lt;/code&gt;（匹配所有 Go 文件）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推薦&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精確匹配：&lt;/p&gt; &lt;p&gt;&lt;code&gt;"internal/handler/**/*.go"&lt;/code&gt;（只匹配處理器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精確匹配：&lt;/p&gt; &lt;p&gt;&lt;code&gt;"internal/repository/**/*.go"&lt;/code&gt;（只匹配倉儲層）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精確匹配：&lt;code&gt;"**/*_test.go"&lt;/code&gt;（只匹配測試文件）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;優先級設置詳解&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;優先級數值範圍：1-10，數值越高優先級越高&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f56ca8d226b9275006442e4b467dc204f2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;優先級使用策略&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 基礎規範用 10&lt;/strong&gt;&lt;/strong&gt;：項目必須遵循的核心規範&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 核心模塊用 8-9&lt;/strong&gt;&lt;/strong&gt;：handler、service、repository 等主要模塊&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 輔助模塊用 6-7&lt;/strong&gt;&lt;/strong&gt;：middleware、config、utils 等輔助模塊&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;4. 優化建議用 5&lt;/strong&gt;&lt;/strong&gt;：性能優化、最佳實踐等智能建議&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;5. 模板參考用 3-4&lt;/strong&gt;&lt;/strong&gt;：代碼模板、腳手架等參考資料&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;6. 實驗功能用 1-2&lt;/strong&gt;&lt;/strong&gt;：測試中的新規範，避免影響穩定功能&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;衝突解決機制&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;當多個規則應用於同一文件時，高優先級規則會覆蓋低優先級規則的衝突部分&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;相同優先級規則按文件名字母順序加載&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Always 規則始終優先於所有其他類型規則&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Rule 的核心價值在於它&amp;nbsp;**&lt;em&gt;**為開發者提供了一種機制，用以精細化控制 AI 在代碼理解、生成、重構等環節&amp;nbsp;**&lt;/em&gt;**的行為。&lt;/p&gt; 
&lt;p&gt;通過預設規則，開發者可以將項目規範、編碼標準、技術選型乃至特定業務邏輯「教授」給 AI，從而顯著提升 AI 輔助編程的效率、保證代碼質量的均一性，並確保項目整體的規範性。&lt;/p&gt; 
&lt;p&gt;它使得 AI 從一個泛用的助手，轉變為一個深度理解特定項目需求的「領域專家」。&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;記憶庫&lt;/h3&gt; 
&lt;p&gt;基於 Rule 的運用，我們通過&lt;strong&gt;&lt;strong&gt;memory bank + rule&lt;/strong&gt;&lt;/strong&gt;生成專屬業務研發助手&lt;/p&gt; 
&lt;p&gt;在 AICoding 的使用中，有一種常見的痛點場景，&lt;strong&gt;&lt;strong&gt;就是在複雜的項目中，AI 無法感知到整個項目的歷史上下文，即便是有 Codebase 的存在，也對業務邏輯是一知半解&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在我們實踐的過程中，引入了記憶庫的模式，深化 AI 對項目的理解和記憶，使得每一次需求迭代的上下文都被記錄下來。&lt;/p&gt; 
&lt;p&gt;生成了 memorybank 後，我們可以隨時通過對話查看項目大綱和內容，並且每一次重新進入開發，不會丟失之前的記憶。&lt;/p&gt; 
&lt;p&gt;這種模式，其實就是 Rules 的一種應用，它把上下文總結在代碼庫的制定位置，強制 AI 在每次進入時會閲讀上下文，回到上一次 Coding 的狀態，對於解決上下文丟失的問題有非常大的幫助。&lt;/p&gt; 
&lt;p&gt;這裏可能有人會問，記憶庫和 IDE 本身的長期記憶功能有什麼區別？&lt;/p&gt; 
&lt;p&gt;答：&lt;strong&gt;記憶庫是公共的項目記憶庫，IDE 長期記憶是私人的 IDE 使用記憶&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;而記憶庫的詳細內容，這裏不作詳細分享，它只是一份提示詞，感興趣的同學只要簡單搜索一下就能找到很多的資源。&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;MCP Server（重點）&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;MCP（Model Context Protocol），模型上下文協議&lt;/strong&gt;&lt;/strong&gt;，由 Anthropic 於 24 年 11 月提出，旨在為大語言模型和外部數據源、工具、服務提供統一的通信框架，&lt;strong&gt;&lt;strong&gt;標準化 AI 與真實世界的交互方式&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5bd218b1f85d823bffcb86015c0c545c99e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;MCP 的核心架構包括三環：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Host 主機：用戶與 AI 互動的應用環境，如 Claude Desktop、Cursor；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Client 客戶端：充當 LLM 和 MCP server 之間的橋樑，將用戶查詢指令、可用工具列表、工具調用結果發給 LLM，將 LLM 需要使用的工具通過 server 執行調用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server 服務器：輕量級服務節點，給予 AI 訪問特定資源、調用工具能力的權限&lt;/strong&gt;；目前已有數據庫類（如 SQLite、supabase）、工具類（如飛書多維表格）、應用類（如高德地圖）服務器。是 MCP 架構中最為關鍵的組件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-61c480bfeeaca3a1ea58453b8acc6a3cb64.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在開發中，我們可以接入以下幾種 MCPServer&lt;/p&gt; 
&lt;p&gt;1. 實時搜索，baidu/google/github/微博等&lt;/p&gt; 
&lt;p&gt;2. 存儲，mysql/redis 等&lt;/p&gt; 
&lt;p&gt;3. 工具，kubectl/yapi 等&lt;/p&gt; 
&lt;p&gt;用法一：我們接入百度搜索的 MCP&lt;/p&gt; 
&lt;p&gt;1. 搜索問題：在開發之餘搜索一下，夜的命名術，是否完結。&lt;/p&gt; 
&lt;p&gt;2. 搜索知識點：在想知道 Go1.24 新特性時，通過 MCP 進行搜索，讓 AI 進行總結。&lt;/p&gt; 
&lt;p&gt;3. 搜索用法：在想了解 Linux 的快捷命令時進行搜索。&lt;/p&gt; 
&lt;p&gt;以上這些場景，並非非 MCP 不可，非 AI IDE 不可，但是通過這樣的方式，我們至少節省了切換到瀏覽器，搜索，自己總結結論，返回繼續 Coding 這些步驟。&lt;/p&gt; 
&lt;p&gt;用法二：client 裏直接進行多 client 操作&lt;/p&gt; 
&lt;p&gt;1. Redis 自然語言查詢：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9b021b5b54f9cb7063c72f8966cb7960f0a.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2. MySQL 自然語言查詢：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6a02d721c76876fa171df81368ea9c7bf0.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;3. GCP 自然語言查詢：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9d3eb554b2f75250662d10f7287f5b516ec.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其他的 client（kubectl 等）我就不一一列舉了，但是可以看到，當我們在我們的 IDE 內集成了各種各樣的 client 後，開發效率能極大地提升。&lt;/p&gt; 
&lt;p&gt;當然，這裏有兩個關鍵點：&lt;/p&gt; 
&lt;p&gt;1. 接入 mcpserver 並不需要我們研究，&lt;em&gt;&lt;strong&gt;我們只要把 mcp server 的鏈接丟給 AI&lt;/strong&gt;&lt;/em&gt;，它自己就能開始接入&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 禁止在開發環境使用線上 client 賬號密碼&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-API&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;相信無論是前端還是後端開發，都或多或少地被接口文檔折磨過。前端經常抱怨後端給的接口文檔與實際情況不一致。後端又覺得編寫及維護接口文檔會耗費不少精力，經常來不及更新。&lt;/p&gt; 
&lt;p&gt;其實無論是前端調用後端，還是後端調用後端，都期望有一個好的接口文檔。但是隨着時間推移，版本迭代，接口文檔往往很容易就跟不上代碼了,更會出現之前的同學沒有把接口文檔交接清楚就離職，留下一個繁重複雜的項目，重新啃起來異常艱難，不亞於自己從頭寫一遍。&lt;/p&gt; 
&lt;span id="OSC_h4_16"&gt;&lt;/span&gt; 
&lt;h4&gt;痛點&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 重複勞動&lt;/strong&gt;&lt;/strong&gt;：每一個涉及到前後端的功能，研發都需要手動進行維護接口文檔，在一些時候，接口最後和最開始的設定有可能大相徑庭，每一次改動都是非常令人頭疼的工作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 低效溝通&lt;/strong&gt;&lt;/strong&gt;：前後端在溝通接口後，再進行對應的代碼開發，其實是一件&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的工作。&lt;/p&gt; 
&lt;p&gt;為瞭解決這些痛點，通過引入 AI 自動化功能，搭建&lt;strong&gt;&lt;strong&gt;API MCP Server&lt;/strong&gt;&lt;/strong&gt;，幫我們解決這些冗雜的工作，&lt;strong&gt;讓研發人力更多的集中在覈心業務代碼的開發上&lt;/strong&gt;，提升代碼開發效率、降低溝通成本。&lt;/p&gt; 
&lt;p&gt;這是我們一直暢想的場景，&lt;strong&gt;&lt;strong&gt;後端開發完代碼 -&amp;gt; AI 推送接口文檔 -&amp;gt; API 文檔自動更新 -&amp;gt; AI 拉取接口文檔 -&amp;gt; 前端生成代碼&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;也就是前後端的研發同學，只關注業務功能的實現，而不需要關注這些接口對接的繁瑣工作。&lt;/p&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;Better Thinking&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;這是我想補充的兩個使用 AICoding 的思想，也是我使用下來的一個感悟。&lt;/p&gt; 
&lt;p&gt;一：&lt;em&gt;&lt;strong&gt;學會遞歸使用 AI&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;場景：在 IDE 內佈置 MCP Server&lt;/p&gt; 
&lt;p&gt;通常的做法是：&lt;/p&gt; 
&lt;p&gt;1. 在 MCP Server 市場找到想用的 MCP Server&lt;/p&gt; 
&lt;p&gt;2. 把配置部署好&lt;/p&gt; 
&lt;p&gt;3. 開始調試，完成後投入使用&lt;/p&gt; 
&lt;p&gt;遞歸式使用做法：&lt;/p&gt; 
&lt;p&gt;1. 在 MCP Server 市場找到想用的 MCP Server&lt;/p&gt; 
&lt;p&gt;2. 把鏈接丟給 AI，讓它自己安裝（遞歸）&lt;/p&gt; 
&lt;p&gt;3. 安裝完後讓它自己修改 mcp.json 的配置（遞歸）&lt;/p&gt; 
&lt;p&gt;4. 修改完成後讓它自己調通（遞歸）&lt;/p&gt; 
&lt;p&gt;更進一步我們還可以：&lt;/p&gt; 
&lt;p&gt;1. @Web 讓 AI 找一個可用的 McpServer（遞歸）&lt;/p&gt; 
&lt;p&gt;2. ...（遞歸）&lt;/p&gt; 
&lt;p&gt;3. ...（遞歸）&lt;/p&gt; 
&lt;p&gt;4. ...（遞歸）&lt;/p&gt; 
&lt;p&gt;二：&lt;em&gt;&lt;strong&gt;把 AI 當成一個真正的工具&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;場景：寫某篇文檔的時候，我突然想要做一個 Gif 格式的圖片示例。&lt;/p&gt; 
&lt;p&gt;已知：電腦支持錄屏，但是我缺少視頻轉 Gif 格式的工具。&lt;/p&gt; 
&lt;p&gt;麻煩點：&lt;/p&gt; 
&lt;p&gt;1. 如果通過百度/Google 搜索網頁在線工具，非常麻煩，還要付費。&lt;/p&gt; 
&lt;p&gt;2. 如果通過內部的視頻裁剪服務，還需要起服務來處理。&lt;/p&gt; 
&lt;p&gt;3. 如果通過剪映這樣的工具，那還要下載一個軟件。&lt;/p&gt; 
&lt;p&gt;以上這些點，都不算困難，但都相對麻煩，&lt;strong&gt;&lt;em&gt;屬於能做但是又要浪費一點精力&lt;/em&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;解決方案：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-243c673fa2ab4faf47acc4027d61529933e.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;理論上讓 AI 寫和讓 GPT/Deepseek 寫沒什麼區別，但是我們的操作步驟得到了以下簡化：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6c74d08c893d911217d31f3e6c1e92711aa.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;也就是説，我們在遇到很多**&lt;em&gt;&lt;strong&gt;自己能做，但是又覺得麻煩，浪費精力的場景&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;以及&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;strong&gt;大部分的雜活&lt;/strong&gt;&lt;/em&gt;**，都可以第一時間 Ask Ourself，Can AI Do it？&lt;/p&gt; 
&lt;p&gt;包括但不限於：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;撈數據&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;寫文檔&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;找 bug&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;...&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;AI-Coding VS Original-Coding&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ebea7546f0be5316db168e3e362a4cd52a4.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_18"&gt;&lt;/span&gt; 
&lt;h1&gt;04 集成階段&lt;/h1&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-CR&lt;/strong&gt;&lt;/h3&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;問題&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 時間壓力&lt;/strong&gt;&lt;/strong&gt;：團隊每週可能需要審查數十個 CR，高 T 同學需要審查的居多，每個 CR 的細節往往耗費大量時間。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 溝通低效&lt;/strong&gt;&lt;/strong&gt;：CR 評論描述不清晰，開發者需要來回溝通確認修改點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 重複勞動&lt;/strong&gt;&lt;/strong&gt;：相似的代碼改動需要重複審查，難以專注關鍵問題。&lt;/p&gt; 
&lt;p&gt;為瞭解決這些痛點，通過引入 AI 自動化功能，提前規避一些基礎問題，&lt;em&gt;&lt;strong&gt;讓 CR 人力更多的集中在關鍵問題上&lt;/strong&gt;&lt;/em&gt;，提升代碼審查效率、降低溝通成本。&lt;/p&gt; 
&lt;span id="OSC_h3_21"&gt;&lt;/span&gt; 
&lt;h3&gt;解決方案&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;工作流&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9dc56fede6b3b23156212ab86640c5460fc.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_22"&gt;&lt;/span&gt; 
&lt;h1&gt;05 運維階段&lt;/h1&gt; 
&lt;span id="OSC_h4_23"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;AI-Develops&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;隨着業務系統的複雜度不斷增加，運維過程中產生的告警數量急劇增長，傳統的人工處理方式已經無法滿足快速響應的需求。&lt;/p&gt; 
&lt;p&gt;目前在我們來看，現有的運維體系存在了以下的弊端：&lt;/p&gt; 
&lt;p&gt;1. 告警存在非常厚的方向壁壘，不同方向的同學遇到另一個方向的告警時大都只能進行 Case 路由。&lt;/p&gt; 
&lt;p&gt;2. 告警存在非常厚的年限壁壘，團隊不同年限的同學遇到 Case 的應對時間有可能天差地別。&lt;/p&gt; 
&lt;p&gt;一個點是否足夠痛，決定了我們是都要優化。&lt;/p&gt; 
&lt;p&gt;在我們團隊內，有豐富的 case 處理文檔和記錄，也有着應對問題經驗非常豐富的同學，但是在值班同學遇到告警轟炸的時候，同樣會焦頭爛額。&lt;/p&gt; 
&lt;p&gt;回顧起告警處理的過程，其實大部分都是&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的工作，它們是有方法論的，並非遇到之後就手足無措。因此我們構建一個智能化的應急診斷系統，通過 AI 技術提升故障處理效率，減少平均故障修復時間 (MTTR)。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-abefe62efa9d85ddcf75055afebb1ab4847.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;在這種模式下，AI 可以自動捕捉消息，在遇到告警信息的時候自動分析給出結論，如果有 AI 無法解決的問題，才會輪到人工進行介入。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這種模式最大的優點在於：&lt;strong&gt;&lt;strong&gt;所有出現過的 Case/已有的文檔&lt;/strong&gt;&lt;/strong&gt;都會沉澱為 AI 的記憶和知識庫，從今往後只會有新增的 Case 需要人來解決，存量全都會被 AI 攔截，換而言之，&lt;em&gt;&lt;strong&gt;團隊內多出了一個永遠不會離開，且能夠同時接受所有方向培養的 AI 運維人員&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;span id="OSC_h1_24"&gt;&lt;/span&gt; 
&lt;h1&gt;06 總結&lt;/h1&gt; 
&lt;p&gt;以上就是我們百度國際化廣告團隊的 AI 提效實踐，也希望這篇文章能作為一個錨點，帶動所有看到這篇文章的同學 review 自己所在團隊的工作流程，共建更多的 AI 加持工作流。&lt;/p&gt; 
&lt;p&gt;就如我上面説的，其實 AI 的用法很簡單，它就是我們的助手，假如我們的工作中真的存在一些&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省工作&lt;/strong&gt;&lt;/strong&gt;，那不妨把這些工作交給 AI 試試。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18687336</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18687336</guid>
      <pubDate>Sun, 03 Aug 2025 06:34:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>騰訊 AI Lab 開源智能體框架 Cognitive Kernel-Pro</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;騰訊 AI Lab 推出了全新開源的智能體框架 ——Cognitive Kernel-Pro，旨在&lt;span&gt;最大&lt;/span&gt;限度地降低外部依賴，使更多研究人員和開發者能夠輕鬆參與智能體的開發和訓練。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-e9c42dbf8c0a6016e86a9cebb846fb609e5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cognitive Kernel-Pro 採用了多模塊、層次化的設計，主要由主智能體和多個子智能體組成。主智能體負責任務分解和信息整合，而子智能體則專注於特定任務，如網頁瀏覽和文件處理。這種模塊化結構確保了各部分的獨立性和擴展性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;為了提升複雜任務的處理效率，Cognitive Kernel-Pro 引入了 「進度狀態」 機制，智能體可以記錄已完成的步驟和待辦任務。此外，框架通過簡單的文本接口實現主智能體和子智能體之間的高效通信，便於協作與調試。同時，反思和投票機制的引入，進一步優化了智能體的任務完成質量，特別是在網頁瀏覽等高隨機性的任務中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在性能方面，Cognitive Kernel-Pro 在 GAIA 基準測試中表現出色，超越了其他開源框架 SmolAgents，接近那些依賴付費工具的智能體。這一成果得益於其創新的訓練方法，涵蓋網頁導航、文件處理和推理等多個領域。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;除了強大的框架設計，騰訊 AI Lab 還提供了 Agent Foundation Model 的訓練配方。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364792</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364792</guid>
      <pubDate>Sun, 03 Aug 2025 06:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟宣佈 Windows 11 本地支持 OpenAI 開源模型 gpt-oss-20b</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微軟宣佈通過其&amp;nbsp;Windows AI Foundry&amp;nbsp;平台，正式向 Windows11 用戶提供 OpenAI&amp;nbsp;最新發布的免費開源大模型&amp;nbsp;gpt-oss-20b。這意味着用戶無需依賴雲端，即可直接在本地電腦上調用強大的 AI 功能和各類熱門開源模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="212" src="https://oscimg.oschina.net/oscnet/up-98dfb3a29f2c9673ea430dd0dfd9cc33c9d.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微軟在博客中指出，gpt-oss-20b 是一款輕量且高效的模型，尤其擅長執行代碼、調用外部工具等任務。它能在多種 Windows 硬件上高效運行，未來還將支持更多設備。即便在網絡帶寬受限的環境下，該模型也適合構建自主 AI 助手或將 AI 集成到日常工作流中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這款模型能在配備至少&amp;nbsp;16GB 顯存的主流消費級 PC 或筆記本上運行。OpenAI 表示，gpt-oss-20b 經過高強度計算資源的強化學習訓練，特別擅長處理「思維鏈式」任務，如調用工具進行網頁搜索或執行代碼。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;不過，作為 OpenAI 的「最小」開源模型，gpt-oss-20b 僅支持文本處理，無法生成圖像或音頻。OpenAI 同時也提醒，該模型的「幻覺」比例較高，在內部測試中，其回答中約有&amp;nbsp;53%&amp;nbsp;存在事實錯誤。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了 Windows11，微軟表示未來計劃將該模型引入&amp;nbsp;macOS&amp;nbsp;等更多平台。目前，gpt-oss-20b 已在微軟的&amp;nbsp;Azure AI Foundry&amp;nbsp;和亞馬遜的&amp;nbsp;AWS&amp;nbsp;平台上線，為雲端開發者提供了更多選擇。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364789</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364789</guid>
      <pubDate>Sun, 03 Aug 2025 05:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>又跑出一匹黑馬！超級麥吉，一個開源的超級 AI Agent！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;最近，Agent 領域又跑出了一匹黑馬！超級麥吉——一個開源的超級 AI Agent。&lt;/p&gt; 
&lt;p&gt;與市面上那些硬編碼、預設流程、通過一次性附件交付產物的 AI 工具不同，超級麥吉具有突破性優勢：實時文件管理、在線人機協同編輯、任務完全可控。&lt;/p&gt; 
&lt;p&gt;超級麥吉採用工作區 &amp;gt; 項目 &amp;gt; 話題的三層結構，每個話題都是一個獨立的 AI 執行單元，可以並行運轉。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;所以，你可以同時讓&lt;span style="color:#3498db"&gt;超級麥吉&lt;/span&gt;幫你寫 100 份報告、做 50 個方案、分析 20 個市場，&lt;span&gt;甚至一次性處理&amp;nbsp;1000&amp;nbsp;份簡歷篩選。也&lt;/span&gt;&lt;span&gt;可以隨時調整、修改、回滾任何環節，通過持續與超級麥吉對話的方式，直至完成最終目標。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我淺淺試用了一下，讓它幫我做一個網站，兩三輪對話，前端頁面完成度就很高了，設計審美也很在線。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1248" src="https://oscimg.oschina.net/oscnet/up-915531dcaf528a9c1bc111b9a4aee7094a9.png" width="900" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 生成的技術報告結構清晰，邏輯完整，還有豐富的圖、表。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1782" src="https://oscimg.oschina.net/oscnet/up-82833df77f3d079522eef438e049462e334.png" width="1307" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;超級麥吉有網頁版，也可以下載 Windows 版、maciOS 版、iOS 版、Android 版本。&lt;/p&gt; 
&lt;p&gt;這個超級 Agent 已經開源，GitHub star 數已經有 1.4K。 開源版本跟當前最新的產品還是有一些不同。不過超級麥吉的聯創——陳曹奇昊公開解釋過，超級麥吉的所有核心功能都是開源的，如果有差異也只是暫時的。因為目前工作量比較大，團隊規模比較小，未能及時同步到開源版本。&lt;/p&gt; 
&lt;p&gt;8 月 12 日晚，我們開源中國（OSCHINA ）邀請到&lt;strong&gt;&lt;span style="color:#3498db"&gt;燈塔引擎 CTO、超級麥吉聯創陳曹奇昊&lt;/span&gt;&lt;/strong&gt;做客《技術領航》直播欄目，跟&lt;strong&gt;大家分享：&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     超級麥吉和主流通用 Agent 產品有什麼區別？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     項目模式設計詳解，如何做到多任務並跑、產物無限迭代？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     揭祕主流 AI PPT 製作原理，超級麥吉助你職場彙報好看又有料 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     職場辦公、個人生活、副業探索、知識積累，超級麥吉如何能夠無所不能？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     演示：小工具開發、一口氣做一百份調研報告 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     中國式 MCP 有趣玩法分享 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     超級麥吉未來還有哪些「大招」？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Q&amp;amp;A：直播答疑 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;微信掃碼，預約直播：&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height="660" src="https://oscimg.oschina.net/oscnet/up-e9096d1fdeb8b839be2c4cdc92eb9a7726a.png" width="400" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;p&gt;對超級麥吉剛興趣的朋友，可以訪問以下地址：&lt;/p&gt; 
 &lt;p&gt;中國站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.letsmagic.cn" target="_blank"&gt;https://www.letsmagic.cn&lt;/a&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p style="color:#2a2d3e; margin-left:0px; margin-right:0px; text-align:start"&gt;國際站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.letsmagic.cn" target="_blank"&gt;https://www.letsmagic.ai&lt;/a&gt;&lt;/p&gt; 
  &lt;p style="color:#2a2d3e; margin-left:0px; margin-right:0px; text-align:start"&gt;GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdtyq%2Fmagic" target="_blank"&gt;https://github.com/dtyq/magic&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;還可以加入超級麥吉的交流羣，一起聊聊用它做些什麼有意思的事~&lt;/p&gt; 
  &lt;p&gt;&lt;img height="191" src="https://oscimg.oschina.net/oscnet/up-46c10a258bc90ff73c81ea07baf50c9248d.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   或者 OSC 直播交流羣，可以經進來嘮嘮嗑，或者你有好的產品 / 項目，也歡迎推薦過來呀～ 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div style="text-align:center"&gt; 
    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-f4e3f0507c7b79ba06185e2b2d6da4cd412.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;陳曹奇昊是&amp;nbsp;PHP 語言官方團隊成員、Swoole 協程網絡引擎核心開發者、Swow 項目發起者，協程和異步網絡編程領域專家，是多個知名開源項目的核心貢獻者，有豐富的開源項目經驗。此前，他在某大型零售企業擔任技術負責人，具備大型企業技術實踐經驗。&lt;/p&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;&lt;img height="395" src="https://oscimg.oschina.net/oscnet/up-441276df82e6d018accbc3c8b47a5edb643.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;本次直播中，我們將有 5 輪抽獎，參與就有機會獲得 OSC T 恤、馬建倉蛇年公仔（限量版）、代碼聖盃、馬克杯、冰箱貼、前沿技術書籍等。立即掃碼預約直播吧！&lt;/p&gt; 
  &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;hr&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技術領航》是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，基本上每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用戶作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用戶和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18687305</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18687305</guid>
      <pubDate>Sun, 03 Aug 2025 04:40:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Steam 7 月份調查顯示 Linux 使用率接近 3%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;今年 2-6 月，Steam 在 Linux 上的市場份額分別為 1.45%、2.33%、2.27%、2.69% 以及 2.57%。目前，7 月份的數據也已發佈，顯示 Linux 遊戲玩家數量創近期新高。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查結果顯示，Linux 遊戲市場份額健康增長 0.32%，達到 2.89%，這個百分比是近期的新高。雖然十年前 Steam 在 Linux 上推出初期的份額約為 3%，但從絕對值來看，這可能是調查以來 Linux 遊戲人口數的最大值。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="163" src="https://oscimg.oschina.net/oscnet/up-fd2ea1a25e40200cd90e1245e40251b1bd8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，7 月份 macOS 的市場份額為 1.88%，Windows 的市場份額為 95.23%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-74ddf525ff9c96f683453cff5fe0b21aa8d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;總體而言，SteamOS Holo 作為 Steam Deck 的基礎（Arch Linux 衍生）操作系統繼續名列前茅。這在很大程度上要歸功於 Steam Deck 採用了定製的 AMD APU，以及許多 Linux 遊戲玩家和發燒友偏愛 AMD 的開源特性，AMD CPU 在 Linux 遊戲玩家中的使用率一直徘徊在 68% 左右。在 Windows 下，AMD CPU 在 Steam 上的使用率約為 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="144" src="https://oscimg.oschina.net/oscnet/up-562e67f58ff3c652709be1cd3bda219182c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可查看&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstore.steampowered.com%2Fhwsurvey%2FSteam-Hardware-Software-Survey-Welcome-to-Steam" target="_blank"&gt;SteamPowered.com&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364763/steam-survey-july-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364763/steam-survey-july-2025</guid>
      <pubDate>Sun, 03 Aug 2025 03:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元正式發佈「AI 播客」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fptzp9RC391boFvOVm6dpyw" target="_blank"&gt;發佈 AI 播客功能&lt;/a&gt;，支持將文本、網頁、文檔一鍵轉化為自然流暢的雙人對談式音頻，它能把原本晦澀難啃的內容，變成一場有邏輯、有節奏的對話。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/110856_9lik_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;體驗入口：使用電腦訪問騰訊混元官網（https://hunyuan.tencent.com），點擊首頁對話框下方「AI 播客」 即可嘗試。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據介紹，騰訊混元「AI 播客」支持將文本、網頁鏈接或本地文檔（涵蓋 .pdf、.txt、.docx、.md 格式）一鍵轉換為雙人對話式的音頻播客，旨在將靜態文字內容轉化為動態、自然的對話，採用一男一女雙角色對談模式，音色和語調接近真人。&lt;/p&gt; 
&lt;p&gt;目前，該功能已應用於騰訊旗下的知識庫應用 ima 中。「騰訊新聞 AI 播客」也計劃於 8 月底上線。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364759</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364759</guid>
      <pubDate>Sun, 03 Aug 2025 03:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>慢 SQL 優化實戰：從一例線上慢 SQL 探究執行引擎工作過程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互聯網服務器團隊- Li Xin&lt;/p&gt; 
 &lt;p&gt;本文通過一個線上慢 SQL 案例，介紹了 Join 的兩種算法和 Order by 的工作原理，並通過 Explain 和 Optimizer_trace 工具完整推演了慢 SQL 的執行過程。基於對原理和執行過程的分析，本文給出一種「引導執行引擎選擇效率更高的算法」的方案，從而使查詢性能得到大幅提升。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;1、線上慢 SQL 背景&lt;/h1&gt; 
&lt;p&gt;慢 SQL 會影響用戶使用體驗，降低數據庫的整體性能，嚴重的甚至會導致服務器掛掉、整個系統癱瘓。筆者通過監控平台發現線上存在這樣一條慢 SQL（原始 SQL 已脫敏，表結構出於簡化的目的做了一定刪減，實際執行耗時以文中提供數據為準），其執行耗時在分鐘級。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;select&amp;nbsp;t1.*,t2.x&amp;nbsp;from&amp;nbsp;t_table1 t1 leftjoin t_table2 t2&amp;nbsp;on&amp;nbsp;t1.a = t2.a&amp;nbsp;orderby&amp;nbsp;t1.c desc;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;表結構如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CREATETABLE&amp;nbsp;`t_table1`&amp;nbsp;(
&amp;nbsp;&amp;nbsp;`id`&amp;nbsp;bigint(20) unsigned&amp;nbsp;NOTNULL&amp;nbsp;AUTO_INCREMENT&amp;nbsp;COMMENT&amp;nbsp;'主鍵',
&amp;nbsp;&amp;nbsp;`a`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`b`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`c`&amp;nbsp;varchar(20)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;PRIMARYKEY&amp;nbsp;(`id`),
&amp;nbsp;&amp;nbsp;KEY&amp;nbsp;`idx_a`&amp;nbsp;(`a`)
)&amp;nbsp;ENGINE=InnoDB&amp;nbsp;AUTO_INCREMENT=0DEFAULT&amp;nbsp;CHARSET=utf8mb4;

CREATETABLE&amp;nbsp;`t_table2`&amp;nbsp;(
&amp;nbsp;&amp;nbsp;`id`&amp;nbsp;bigint(20) unsigned&amp;nbsp;NOTNULL&amp;nbsp;AUTO_INCREMENT&amp;nbsp;COMMENT&amp;nbsp;'主鍵',
&amp;nbsp;&amp;nbsp;`a`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`x`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`y`&amp;nbsp;varchar(20)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;PRIMARYKEY&amp;nbsp;(`id`)
)&amp;nbsp;ENGINE=InnoDB&amp;nbsp;AUTO_INCREMENT=0DEFAULT&amp;nbsp;CHARSET=utf8mb4;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其他信息：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/b6/b6d3dd02b7c1dde85561715f07cbc8e5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;當發現慢 SQL 時，筆者的第一反應是使用 Explain 查看 SQL 的執行計劃，結果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/d8/d80e469be4c5bf6a591e0f15e9ce7329.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過 Explain 初步分析：兩張表均執行了全表掃描，結合兩張表的數據規模分析全表掃描並非耗時達到分鐘級的主要原因。另外執行計劃 extra 種提示的 Using temporary; Using filesort; Using join buffer (Block Nested Loop) 又分別代表什麼含義呢？&lt;/p&gt; 
&lt;h1&gt;2、原理探究&lt;/h1&gt; 
&lt;h2&gt;2.1 Join 算法原理&lt;/h2&gt; 
&lt;h3&gt;2.1.1 驅動表和被驅動表&lt;/h3&gt; 
&lt;p&gt;在 Join 語句中，執行引擎優先掃描的表被稱為驅動表，另一張表被稱為被驅動表。執行引擎在選擇驅動表時，除了必須要遵守的特定語義外，最重要的考慮便是執行效率。&lt;/p&gt; 
&lt;p&gt;首先列舉兩種特定語義約束驅動表選取的&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;**場景一：**Straight join 指定連接順序，強制要求執行引擎優先掃描左側的表。&lt;/p&gt; 
 &lt;p&gt;**場景二：**Left/Right [outer] join，方向連接的特點是反方向表中如果不存在關聯的數據則填充 NULL 值，這一特性要求方向查詢時優先掃描相同方向的表。倘若 where 條件中明確指明反方向表中的部分列非空，則驅動表的選擇就不受此語義的限制，執行引擎會依據效率選取驅動表。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;當沒有特定語義的約束時，執行引擎便會依據執行效率選取驅動表，如何判斷哪張表作為驅動表的效率更高呢？下文會結合 Join 的兩種算法更深入地探討這個問題。&lt;/p&gt; 
&lt;h3&gt;2.1.2 Block Nested-Loop Join&lt;/h3&gt; 
&lt;p&gt;假設一個數據量為 m 行的驅動表與一個數據量為 n 行的被驅動表進行 join 查詢。&lt;/p&gt; 
&lt;p&gt;最簡單的一種算法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;從驅動表掃描一行數據；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對被驅動表進行全表掃描，得到的結果依次與驅動表的數據進行 join 並把滿足條件的數據加入結果集；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着掃描驅動表，每掃描一行數據，均重複執行一次步驟 2，直至驅動表的全部數據被掃描完畢。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這種算法的磁盤掃描開銷為 m*n，非常低效，MySQL 在實際中並未直接使用該算法，而是採用緩存的思想（分配一塊 Join buffer）對該算法進行改進，並命名為 Block Nested-Loop join(BNL)。&lt;/p&gt; 
&lt;p&gt;BNL 的算法&lt;strong&gt;步驟&lt;/strong&gt;為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;從驅動表一次掃描 K 條數據，並把數據緩存在 Join buffer；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對被驅動表進行全表掃描，得到的結果依次與驅動表的 K 條數據進行 join 並把滿足條件的數據加入結果集；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;清空 join_buffer；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着從驅動表再取出 K 條數據，重複步驟 2、3，直至掃描完驅動表的全部數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;上述算法中，驅動表分段取數的次數記為 l，整個算法的磁盤掃描開銷為 m+ln。由於分段的次數與驅動表的數據成正相關，所以公式可以記為 m+λmn，λ的取值範圍為 (0,1)。&lt;/p&gt; 
&lt;p&gt;當兩張表的行數（m、n 大小）固定的情況下，m 對結果的影響更大，m 越小整體掃描的代價越小，所以執行引擎優先選擇數據量更小的表作為驅動表 (符合「小表驅動大表」的説法)。&lt;/p&gt; 
&lt;h3&gt;2.1.3 Index Nested-Loop Join&lt;/h3&gt; 
&lt;p&gt;BNL 算法使用了 Join buffer 結構，雖然有可能通過減少重複掃描來降低磁盤掃描開銷，然而驅動表分段掃描的次數過多依然可能會導致查詢的低效。索引是 MySQL 查詢提效的重要結構，當被驅動表的關聯鍵存在索引時，MySQL 會使用 Index Nested-Loop Join（NLJ）算法。&lt;/p&gt; 
&lt;p&gt;該算法的步驟為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;從驅動表掃描一行數據；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;使用驅動表的關聯鍵搜索被驅動表的索引樹，通過被驅動表的索引結構找到被驅動表的主鍵，再通過主鍵回表查詢出被驅動表的關聯數據（暫不考慮覆蓋索引的情況）；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着掃描驅動表，每掃描一行數據，均重複執行一次步驟 2，直至驅動表的全部數據被掃描完畢。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;每次搜索一棵樹的複雜度近似為 log2 n，上述過程在被驅動表掃描一行數據的時間複雜度是 2log2 n，算法的整體複雜度為 m+2mlog2 n，在該算法中，依舊是 m 對結果的影響更大，m 越小整體掃描的代價越小，所以執行引擎總是選擇數據量更小的表作為驅動表 (符合「小表驅動大表」的説法)。&lt;/p&gt; 
&lt;h2&gt;2.2 Order by 算法原理&lt;/h2&gt; 
&lt;h4&gt;2.2.1 全字段排序&lt;/h4&gt; 
&lt;p&gt;MySQL 會為每個線程分配一塊內存（Sort buffer）用於排序，當 Sort buffer 的空間不足時（通過系統參數 sort_buffer_size 設置 Sort buffer 的大小），執行引擎不得不開闢磁盤臨時文件用於排序，此時排序的性能也會大幅降低。&lt;/p&gt; 
&lt;p&gt;全字段排序是將查詢需要的所有字段進行暫存，並按照排序字段進行排序，並將排序後的結果集直接返回。&lt;/p&gt; 
&lt;h3&gt;2.2.2 Rowid 排序&lt;/h3&gt; 
&lt;p&gt;若要查詢的數據單行佔用空間較大，Sort buffer 中可以容納的排序行數將會減少，此時使用磁盤臨時文件進行排序的概率將會增大。為了提高排序性能，執行引擎提供一種只存儲排序字段的算法，稱為 Rowid 排序算法。&lt;/p&gt; 
&lt;p&gt;該算法的&lt;strong&gt;步驟&lt;/strong&gt;為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;將參與排序的字段和主鍵進行臨時存儲；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;按照排序字段進行排序，得到有序的主鍵；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;根據有序的主鍵進行回表，按順序將所有要查詢的數據返回。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Rowid 排序在單行查詢數據較大時可以通過節省臨時排序空間從而達到降低排序開銷的目的，然而該算法的代價是會增加磁盤掃描的次數（主鍵回表），所以是否選擇使用該算法需要根據實際情況進行取捨（通過系統參數 max_length_for_sort_data 設置）。&lt;/p&gt; 
&lt;h1&gt;3、調優過程&lt;/h1&gt; 
&lt;h2&gt;3.1 執行過程分析&lt;/h2&gt; 
&lt;p&gt;瞭解了 Join 和 Order by 的工作原理，我們推測執行計劃的大致&lt;strong&gt;過程&lt;/strong&gt;為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;t_table_1 與 t_table_2 進行 Join 查詢，使用了 BNL 算法（Using join buffer (Block Nested Loop)）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;將 Join 的結果暫存臨時表（Using temporary）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對臨時表中的數據進行排序後返回（Using filesort）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;為了佐證筆者的推測以及瞭解每一步的開銷情況，Optimizer_trace 命令可以提供更多執行過程細節。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_execution_plans":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"`t_table1` `t1`",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"best_access_path":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_access_paths":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_to_scan":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"access_type":&amp;nbsp;"scan",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"resulting_rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost":&amp;nbsp;615,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"use_tmp_table":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_access_paths */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* best_access_path */,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rest_of_plan":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"`t_table2` `t2`",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"best_access_path":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_access_paths":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_to_scan":&amp;nbsp;69882,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"access_type":&amp;nbsp;"scan",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"using_join_cache":&amp;nbsp;true,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"buffers_needed":&amp;nbsp;5,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"resulting_rows":&amp;nbsp;69882,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost":&amp;nbsp;4.19e7,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_access_paths */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* best_access_path */,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_for_plan":&amp;nbsp;2.1e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost_for_plan":&amp;nbsp;4.19e7,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_cost":&amp;nbsp;2.1e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"new_cost_for_plan":&amp;nbsp;2.52e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* rest_of_plan */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_execution_plans */
&amp;nbsp; &amp;nbsp;}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上圖展示的即為執行引擎預估的執行計劃，從 Optimizer_trace 的輸出結果中可以佐證上述對於執行過程的推測。另外我們可以得到執行代價的結果為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;t_table1 的掃描行數為 3000，代價為 615;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;t_table2 的掃描行數為 69882，由於 BNL 算法 t_table2 會被多次全表掃描，整體代價為 4.19e7;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對 Join 結果進行排序的開銷為 2.1e8。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;從執行引擎預估的執行計劃可以看出執行引擎認為排序的開銷最大，另外由於使用 BNL 算法會導致被驅動表執行多次全表掃描，其執行代價僅次於排序。然而預估的執行計劃並不代表真正的執行結果，下面展示 Optimizer_trace 命令對於真實執行結果部分參數：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"join_execution":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"select#":&amp;nbsp;1,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"steps":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"creating_tmp_table":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"tmp_table_info":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"intermediate_tmp_table",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"row_length":&amp;nbsp;655,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"key_length":&amp;nbsp;0,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"unique_constraint":&amp;nbsp;false,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"location":&amp;nbsp;"memory (heap)",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"row_limit_estimate":&amp;nbsp;25614
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* tmp_table_info */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* creating_tmp_table */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;},
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"filesort_summary":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"examined_rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"number_of_tmp_files":&amp;nbsp;0,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_buffer_size":&amp;nbsp;60200,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_mode":&amp;nbsp;"&amp;lt;sort_key, rowid&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* filesort_summary */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* steps */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* join_execution */
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從執行結果參數來看：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;執行引擎使用臨時表保存 Join 的結果，且臨時表是一張內存表。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;參與排序的數據行數為 3000 行，沒有使用磁盤臨時文件進行排序，排序算法選擇的是 Rowid 排序。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;綜合執行引擎的預估的執行計劃和真實的執行結果參數可以得出，執行引擎預估最大的執行開銷為排序，但實際上排序並未使用到磁盤臨時文件，且 Rowid 排序的回表操作是在內存中進行的（在內存臨時表中進行回表），3000 條數據的內存排序開銷是極快的，所以真實的最大開銷是 BNL 算法導致的對被驅動表多次進行全表掃描的開銷。&lt;/p&gt; 
&lt;h2&gt;3.2 最終的優化&lt;/h2&gt; 
&lt;p&gt;對於 BNL 算法，可以通過在被驅動表添加索引使其轉化為 NLJ 算法來進行優化（此處注意一些索引失效的場景，筆者在實際調優中遇到了字符集不同導致的索引失效場景）。在 t_table2 表添加索引後，觀察一週內的 SQL 監控如下，可以看到 SQL 最大響應時間不超過 20ms，執行效率得到了大幅提升。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/47/475398e816de211f42468bc73336a5fa.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;4、總結&lt;/h1&gt; 
&lt;p&gt;本文完整的介紹了一個 SQL 調優案例，通過這個案例可以歸納出 SQL 調優的基本思想。首先，需要了解 SQL 語句中的關鍵字（Join、Order by...）的基本工作原理，並輔助一些執行過程數據（Explain、Optimizer_trace），通過實驗驗證猜想，最終達成調優的目的。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18687291</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18687291</guid>
      <pubDate>Sun, 03 Aug 2025 02:46:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>阿里通義上架 Qwen-Flash API，1M 超長上下文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義千問團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVSQEC5IANVzlef9FiaiaUw" target="_blank"&gt;宣佈&lt;/a&gt;其 Qwen 家族多款模型 API 上架，分別為 Qwen-Flash、Qwen3-Coder-Flash、Qwen-Plus，並且全部支持 1M 超長上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103102_OBd5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103109_o4F8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103133_eSWW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1438" src="https://static.oschina.net/uploads/space/2025/0807/103203_busb_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103225_G56r_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方表示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen-Flash(qwen-flash-2025-07-28)：相較於 qwen-turbo-2025-04-28，Qwen-Flash「通用能力」大幅度提升；同時「推理能力」「中英文長尾知識能力」「Agent 能力」均獲得提升。&lt;/li&gt; 
 &lt;li&gt;Qwen3-Coder-Flash(qwen3-coder-flash-2025-07-28)：繼承 Qwen3-Coder-Plus 的 coding agent 能力，支持多輪工具交互；Agent 能力增強，工具調用更穩定。&lt;/li&gt; 
 &lt;li&gt;Qwen-Plus(qwen-plus-2025-07-28(qwen-plus-latest))：中英文的「通用能力」大幅提升；「邏輯能力」更強了；RAG、工具調用等 Agent 能力更強。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;三款模型 API 均已上線阿里雲百鍊平台，併為每位開發者提供每款模型 100w 免費 tokens。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364747</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364747</guid>
      <pubDate>Sun, 03 Aug 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：賽博占卜</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2118</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2118</guid>
      <pubDate>Sun, 03 Aug 2025 02:26:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 將於 8 月 7 日舉行直播活動，有望發佈 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1953139020231569685" target="_blank"&gt;發佈預告信息&lt;/a&gt;，將於太平洋時間週四上午 10 點舉行網絡直播，屆時將有望發佈傳聞已久的 GPT-5 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="354" src="https://static.oschina.net/uploads/space/2025/0807/101913_nIwa_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;公告內容僅為「&lt;em&gt;LIVE5TREAM THURSDAY 10AM PT&lt;/em&gt;」，其簡潔和神祕的風格引發了業界的廣泛關注和猜測。許多分析人士和社區成員推測，此次活動可能會發布備受期待的 GPT-5 模型。&lt;/p&gt; 
&lt;p&gt;在幾乎同一時間，網絡上突然爆出了 GPT-5 的三個版本型號以及圖表信息：共擁有 GPT-5、GPT-5 mini、GPT-5 nano。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/102026_2Z7k_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據目前消息來看，GPT-5 的最大亮點並非空泛的跑分提升，而是在多模態、軟件工程和 AI 智能體（Agent）這三個極具實用價值的領域，展現了相當大的性能提升。&lt;/p&gt; 
&lt;p&gt;對於 GPT-5 的表現，OpenAI CEO Sam Altman 也曾多次公開表示「十分強大」，甚至形容自己在面對新模型時，有一種「自己相對 AI 毫無用處」的感覺。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364739</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364739</guid>
      <pubDate>Sun, 03 Aug 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AMD、高通宣佈旗下硬件支持 gpt-oss 系列開放模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AMD 與高通近日聯合宣佈，旗下硬件正式支持 OpenAI 推出的 gpt-oss 系列開放推理模型。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 新發布的 gpt-oss 系列包括兩個模型：gpt-oss-20b 和 gpt-oss-120b。前者可以在配備 16GB 內存的設備上流暢運行，而後者則能在單個 80GB 顯卡上高效執行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AMD 表示，鋭龍 AI Max+395 處理器成為全球&lt;span&gt;首款&lt;/span&gt;能夠運行 gpt-oss-120b 模型的消費級 AI PC 處理器。為了適應這一模型，AMD 採用了 GGML 框架和 MXFP4 格式，使得 gpt-oss-120b 在使用大約 61GB 顯存時得以順暢運行。此外，"Strix Halo" 平台通過 128GB 的統一內存，能夠將 96GB 分配給 GPU，從而滿足運行需求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="284" src="https://oscimg.oschina.net/oscnet/up-e6d0339194cefafe23caeacc321abc53252.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在性能方面，鋭龍 AI Max+395 在運行 gpt-oss-120b 時可以實現每秒 30 個 Token 的輸出速度，並且支持 MCP 模型上下文協議。這意味着用戶在處理複雜任務時可以享受到更快的響應速度和更高的效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;高通則表示，經過早期測試，gpt-oss-20b 模型在其驍龍平台上展現出色的思維鏈推理能力。開發者可以通過 Hugging Face 和 Ollama 等平台，在搭載驍龍芯片的設備上輕鬆訪問這一模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364737</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364737</guid>
      <pubDate>Sun, 03 Aug 2025 02:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義超頂小模型「Qwen3-4B」發佈更新，手機也能輕鬆跑</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義千問團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcXAWq0Qkrdh2ag9BcnACPQ" target="_blank"&gt;發佈&lt;/a&gt;了更小尺寸新模型——Qwen3-4B-Instruct-2507 和 Qwen3-4B-Thinking-2507 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101110_FtLJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新模型性能有了大幅提升。在非推理領域，Qwen3-4B-Instruct-2507 全面超越了閉源的 GPT4.1-Nano；在推理領域，Qwen3-4B-Thinking-2507 甚至可以媲美中等規模的 Qwen3-30B-A3B（thinking）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101118_RpzT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101129_LX7V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/101151_mrbH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;「2507」版本的 Qwen3-4B 模型，體積小，性能強，對手機等端側硬件部署尤為友好，目前新模型已在魔搭社區、Hugging Face 正式開源。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;以下為模型核心亮點：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、Qwen3-4B-Instruct-2507&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🌟通用能力顯著提升，更全能的端側利器&lt;br&gt; Qwen3-4B-Instruct-2507 的通用能力均大幅提升，超越了商業閉源的小尺寸模型 GPT-4.1-nano，與中等規模的 Qwen3-30B-A3B（non-thinking）性能接近。&lt;/p&gt; 
&lt;p&gt;🌟掌握更多語言和長尾知識，回答更合你意&lt;br&gt; 新模型覆蓋了更多語言的長尾知識，在主觀和開放性任務中增強了人類偏好對齊，可提供更符合人們需求的答覆。&lt;/p&gt; 
&lt;p&gt;🌟上下文理解擴展至 256K，小模型也能處理長文本&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、 Qwen3-4B-Thinking-2507&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🌟推理能力大幅增強，AIME25 高達 81.3 分&lt;br&gt; Qwen3-4B-Thinking-2507 的推理表現可媲美中等模型 Qwen3-30B-Thinking，特別是在聚焦數學能力的&amp;nbsp;AIME25 測評中，以 4B 參數量斬獲驚人的 81.3 分的好成績！&lt;/p&gt; 
&lt;p&gt;🌟通用能力顯著提升，Agent 分數爆表，相關評測均超越了更大尺寸的 Qwen3-30B-Thinking 模型。&lt;/p&gt; 
&lt;p&gt;🌟 256K tokens 上下文的理解能力，支持更復雜的文檔分析、長篇內容生成、跨段落推理等場景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364735</guid>
      <pubDate>Sun, 03 Aug 2025 02:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌推出新編程工具 Jules</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;谷歌宣佈正式推出一款名為 Jules 的全新編程工具。該工具支持與 GitHub 深度集成，具備異步處理代碼修復與更新任務的能力，有助於開發者提升編程效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據介紹，Jules 可直接將代碼庫克隆至雲端虛擬機運行環境中，實現對 GitHub 倉庫中的任務進行自動化處理。開發者無需手動幹預，即可在後台完成大量重複性編程操作，從而節省時間、提高工作產出。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="238" src="https://oscimg.oschina.net/oscnet/up-cc1e37ad346861f92473d5cf76ccb3c474c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該工具於今年 5 月開啓公開測試，期間吸引了大批開發者參與。據谷歌披露，在測試階段，全球已有成千上萬名開發者使用 Jules 處理了數以萬計的編程任務，並累計提交超過 14 萬項代碼改進建議，顯示出該工具在實際應用中的廣泛認可度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據用戶反饋，谷歌近期為 Jules 增加了多項實用功能，包括複用既有設置以加快任務執行速度、整合 GitHub 問題管理系統、以及支持圖文等多種形式的輸入內容。目前，該工具的用戶羣體主要包括專業開發者和技術愛好者。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-36839410d19ac85f97ffb0c2507b041ea6e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在定價方面，谷歌為 Jules 提供結構化的服務方案。免費用戶每日最多可執行 15 項任務，同時最多可併發運行 3 個任務。付費方案則包含在 Google Pro 和 Ultra 套餐中，分別定價為每月 19.99 美元和 124.99 美元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364729</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364729</guid>
      <pubDate>Sun, 03 Aug 2025 02:04:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>預裝開源操作系統 openFyde 的 XpressReal T3 開發板上市，售價 458 元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Fyde 與 Radxa、Realtek 合作推出的 XpressReal T3 開發板現已在國內上市，該板預裝 openFyde 系統，同時也原生支持 Debian Linux、安卓等，定價為 458 元。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1200" src="https://static.oschina.net/uploads/space/2025/0806/191846_lEaM_2720166.png" width="2070" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://madeforfydeos.cn/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，該開發板整體尺寸 96mm x 40mm，匹配 4GB LPDDR4 RAM 和 32GB eMMC，搭載 Realtek RTD1619B 芯片，該芯片具體規格如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU：四核 ARM Cortex-A55，主頻高達 2.0GHz。&lt;/li&gt; 
 &lt;li&gt;GPU：ARM Mali-G57 MP1，支持 Vulkan 1.1、OpenGL ES 3.2 和 OpenCL 2.0。&lt;/li&gt; 
 &lt;li&gt;NPU：具備 1.6 TOPs 的算力，並支持 INT4 / INT8 / INT16、FP16 / BF16、TF32 等多種精度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;擴展方面，這款開發板提供 1 個 M.2 NVMe SSD 插槽（支持 PCIe Gen2 x1 通道和 2280 規格）、1 個全尺寸 SD 卡槽（符合 SD 3.0 標準）、1 個 HDMI 2.1a 接口、1 個 USB-C 3.2 Gen 1 接口、1 個 USB-A 2.0 接口、1 個千兆 RJ45 網口，同時板載 40-Pin GPIO 擴展接口。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0806/192329_3LuD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多介紹查看：&lt;em&gt;https://mp.weixin.qq.com/s/hS-GRO9-y_KFvZjeBWzfIQ&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364658</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364658</guid>
      <pubDate>Sat, 02 Aug 2025 11:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>JetBrains 推出基於 AI 的無代碼平台 Kineto</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;JetBrains 推出基於 AI 的無代碼平台 Kineto，旨在幫助用戶快速進行 Web 開發，無需編寫任何代碼即可創建 Web 應用程序和網站。&lt;/p&gt; 
&lt;p&gt;該平台旨在幫助用戶快速構建小型的、單一用途的應用程序，例如植物追蹤器、健身應用或博客等。Kineto 的目標是讓有創意的用戶能夠專注於想法本身，而非編碼實現。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0806/190713_SJog_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據 JetBrains 的説法，用戶不需要解釋每個按鈕或者提供廣泛的説明，因為 Kineto 會直觀地為用戶提供必要的組件，它只要求一些基本的設計選擇，例如模板、字體和配色方案，以便在符合用戶偏好的基礎上開始構建。&lt;/p&gt; 
&lt;p&gt;提交選擇後平台就可以製作功能齊全的原型，整個過程需要 20 分鐘左右，然後用戶就可以調整結果以添加新功能、更改設計或者直接通過自然語言對話生成插圖，最後可以直接通過 Kineto 進行在線部署。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0806/190800_uVV9_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，該平台的早期訪問計劃（EAP）已開放候補名單註冊：&lt;em&gt;https://kineto.dev/&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364654</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364654</guid>
      <pubDate>Sat, 02 Aug 2025 11:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
