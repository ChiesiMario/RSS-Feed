<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Wed, 20 Aug 2025 02:51:56 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>DeepSeek V3.1-Base 開源發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 最新開源模型 V3.1-Base 已上架 HuggingFace，相關信息如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型參數為 685B&lt;/li&gt; 
 &lt;li&gt;基座模型（Base），用於微調和二次開發&lt;/li&gt; 
 &lt;li&gt;基於 DeepSeek V3 架構，包含自定義代碼實現&lt;/li&gt; 
 &lt;li&gt;混合精度設計，支持 BF16、FP8（E4M3）、FP32 張量類型&lt;/li&gt; 
 &lt;li&gt;支持 FP8 量化，提升推理效率&lt;/li&gt; 
 &lt;li&gt;採用 Safetensors 安全張量格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1240" src="https://static.oschina.net/uploads/space/2025/0820/104516_2Mto_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104605_duz9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104713_pqfx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3.1-Base" target="_blank"&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Base&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367323</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367323</guid>
      <pubDate>Wed, 20 Aug 2025 02:47:53 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>再獲國際權威機構認可｜綠盟抗 D 解決方案斬獲業界首個 Frost &amp; Sullivan 競爭戰略領導獎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;近日，綠盟科技憑藉在抗 DDoS 領域的深厚積累與全球戰略佈局，一舉斬獲國際權威機構 Frost &amp;amp; Sullivan 頒發的 2025 年度競爭戰略領導獎（2025 Competitive Strategy Leader）。這一重磅獎項不僅彰顯了權威機構的高度認可，同時也標誌着綠盟抗 D 解決方案正在持續向全球安全行業展現強勁的技術創新力與市場領導力。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 1.jpg" height="400" src="https://oscimg.oschina.net/oscnet//68c662dce7d7be9538563f3bd0e5ae88.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 2.jpg" height="785" src="https://oscimg.oschina.net/oscnet//c77b2f3fbb86054cf4ed258924ce184a.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;Frost &amp;amp; Sullivan 分析師 Iqra Azam 表示：「在全球市場，綠盟抗 D 以智能、敏捷、以客戶為核心的解決方案脫穎而出。面對愈發複雜的大規模 DDoS 威脅，綠盟科技以創新驅動戰略，已經成為國際市場中不可忽視的競爭力量。更重要的是憑藉抗 D 設備+平台的智能增值運營方案，不僅為客戶帶來了實打實的價值轉化，更幫助企業釋放了新的商業增長潛能。」&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;從國際競爭力的視角來看，綠盟抗 D 解決方案近年來在亞太、拉美等重點新興市場持續深耕，成功服務於多個國家級運營商、金融機構及關鍵基礎設施客戶，其中最受海外客戶關注的正是三位一體抗 D 增值運營解決方案：&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;方案組件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;綠盟抗拒絕服務攻擊系統-ADS&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;ADS 融合了機器學習建模、交互式動態防護算法、行為模式分析以及動態指紋識別等先進技術，提供高效的多層（L3-L7）DDoS 攻擊流量清洗能力，在高效阻斷各類 DDoS 惡意報文的同時快速放行合法業務流量，同時支持基於業務特點進行策略隔離，讓防護更加靈活化。ADS 防護流程全程透明可視，統計展示各防護策略結果，並支持在線抓包和在線查看報文關鍵特性，幫助用戶快速分析攻擊細節與業務特徵，真正實現可視、可控、可驗證的主動防護體驗。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;綠盟網絡流量分析系-NTA&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;NTA 專注於流量異常監測及 DDoS 攻擊快速告警，提供基於 FLOW（深度流檢測）或者基於 DPI（深度包檢測）雙模監測模型，可靈活適配不同規模網絡、不同流量及重點業務精細化分析等不同業務場景。藉助基於機器學習建模的動態流量基線能力，NTA 可自動生成告警閾值，有效降低漏報與誤報，減輕運維負擔。設備搭配雲端實時檢測規則，能快速識別新興威脅，顯著提升防護響應效率。此外 NTA 支持聯動綠盟威脅情報，實時識別礦機、礦池、殭屍網絡等威脅信息，可通過 flowspec 實現精細化阻斷。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;綠盟流量清洗業務運營系統-ADBOS&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;致力於為運營商、金融、跨國企業及網絡服務提供商賦能基於抗 D 雲清洗、流量分析、MSS 等雲上安全服務，助力客戶構建多層次的運營體系。平台支持跨地域、跨廠商的態勢可視化與策略管理，助力用戶實現抗 D 資源的統一調度與高效運維。平台搭載抗 D 專家策略庫和自適應策略調整模塊，配合探針的自學習建模、基於劇本編排的自動化處置，讓用戶體驗一站式運營管理和全託管式運維，輕鬆降低運營複雜度的同時還能提供增值運營的快速變現。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="圖片 3.jpg" height="210" src="https://oscimg.oschina.net/oscnet//e1def71af4771d74670ec4ab7e2ce7f8.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;三位一體的抗 D 增值運營解決方案，依託 ADBOS 平台接入 ADS/NTA，構建高性能、可擴展的抗 D 清洗與檢測資源池，並通過分權分域的集中管理，實現跨地域、跨廠商設備的統一資源調度與數據融合，做到最大化設備利用率與投資回報率。平台集成客戶管理、售賣規格、費用套餐等一站式增值運營功能幫助用戶輕鬆上線增值抗 D 服務，實現從防護能力到商業變現的無縫銜接。在服務體驗方面，平台提供包括自助門戶與移動端 APP 在內的多種自助服務方式，讓最終用戶可以隨時隨地掌握業務狀態、靈活配置防護策略，並生成自定義、多維度的業務與防護報表，全面提升操作便捷性與服務可視化，顯著增強用戶粘性與滿意度。該方案形成了從精準流量檢測，智能資源調度，高效 DDoS 清洗形成完整業務閉環，全面滿足服務提供商對精細化運營和差異化服務的核心訴求。結合 MSS 可管理安全服務訂閲，客戶可一站式享受從攻擊監控、快速響應、威脅分析、事件處置到全流程報告的無感知式託管防護，真正實現高效、省心的智能化運營。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;未來，綠盟抗 D 產品將持續突破技術邊界，迭代產品能力和服務質量，打造更具前瞻性、智能化的防護體系，持續為全球客戶提供強有力的抗 D 支撐，護航關鍵業務穩健前行。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367321</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367321</guid>
      <pubDate>Wed, 20 Aug 2025 02:39:53 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>小米集團基於 Apache Doris + Apache Paimon 實現 6 倍性能飛躍</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;企業在數據驅動的道路上，始終面臨一對核心矛盾：既需要低成本、可擴展的存儲方案來承載海量結構化、半結構化乃至非結構化數據（這正是數據湖的強項），又渴望實時、低延遲的分析能力來支撐業務決策（這是分析型數據庫的核心優勢）。&lt;/p&gt; 
&lt;p&gt;然而現實是，單獨的解決方案往往難以兩全：以 Apache Paimon 為代表的數據湖技術，雖憑藉開放格式、彈性擴展和低成本存儲成為企業數據中台的基石，但在低延遲響應上存在天然短板；而以 Apache Doris 為代表的分析型數據庫，雖能提供高效的查詢性能，卻缺乏數據湖的存儲靈活性與開放性。&lt;/p&gt; 
&lt;p&gt;本文的核心觀點是："架起數據庫與數據湖的橋樑" 並非趨勢，而是破局的關鍵。小米通過將 Apache Doris（數據庫）與 Apache Paimon（數據湖）深度融合，不僅解決了數據湖分析的性能瓶頸，更實現了 "1+1&amp;gt;2" 的協同效應。&lt;/p&gt; 
&lt;h2&gt;數據庫與數據湖的互補之力&lt;/h2&gt; 
&lt;p&gt;"橋接數據庫與數據湖"的核心價值，在於構建"&lt;strong&gt;存儲靈活、計算高效、格式協同&lt;/strong&gt; "的一體化架構------不僅是存儲與計算能力的分工互補，更包含&lt;strong&gt;數據格式層面的深度協同&lt;/strong&gt;，讓兩者的技術特性形成疊加效應。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 數據湖倉的分工定位&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;從基礎能力來看，兩者的分工已形成天然互補：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Apache Paimon 作為數據湖，核心優勢體現在存儲層：其開放格式（兼容 Spark、Flink、Trino 等多引擎）、基於對象存儲（S3、HDFS）的 PB 級彈性擴展能力，以及對事務、Schema 演進的原生支持，使其成為海量異構數據的"統一存儲基座"，兼顧低成本與兼容性。&lt;/li&gt; 
 &lt;li&gt;Apache Doris 作為分析型數據庫，核心優勢體現在計算層：分佈式並行引擎、向量化執行框架、以及針對複雜聚合場景的算子優化，使其能提供毫秒至秒級的低延遲查詢響應，成為數據價值挖掘的"高效計算引擎"。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;2. 數據格式的特性互補&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;更深層的協同點，在於數據格式的特性互補：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;數據湖格式（如 Paimon）為適配多引擎讀寫與大規模存儲場景，在設計上以通用性為優先，雖能滿足跨引擎兼容需求，但在高頻查詢、複雜計算場景下，其通用格式的解析效率、IO 開銷難以進一步優化；&lt;/li&gt; 
 &lt;li&gt;而數據庫（如 Doris）則擁有專為查詢性能設計的 &lt;strong&gt;高效內部存儲格式&lt;/strong&gt;------例如基於列存的分層存儲結構、自適應編碼壓縮算法（如字典編碼、RLE 壓縮）、原生索引（如前綴索引、 bloom filter）等，這些格式通過深度耦合計算引擎的執行邏輯，可最大限度減少數據掃描量與 IO 消耗，實現亞秒級查詢響應。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;3. 橋接架構的雙向賦能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;橋接架構下，數據湖倉可實現&lt;strong&gt;雙向賦能&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;海量冷數據、全量歷史數據以 Paimon 格式存儲於數據湖，保持低成本與多引擎兼容性；&lt;/li&gt; 
 &lt;li&gt;高頻訪問的熱數據、需複雜聚合的核心指標，則通過 Doris 的物化視圖、本地緩存等機制，轉換為 Doris 高效內部格式存儲，藉助其原生存儲與計算的協同優化，實現極致查詢性能。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;這種模式既避免了單一數據湖格式在查詢性能上的瓶頸，又解決了單一數據庫格式在存儲成本與擴展性上的侷限。唯有通過"橋接"，才能讓數據湖的通用存儲優勢與數據庫的高效格式特性形成合力，實現"存儲成本可控、查詢性能最優"的理想狀態。&lt;/p&gt; 
&lt;h2&gt;Apache Doris &amp;amp; Paimon 在小米的實踐與挑戰&lt;/h2&gt; 
&lt;p&gt;Apache Paimon 是一款優秀的開放數據湖格式，其流批一體的設計很好的滿足了湖上數據的實時處理需求。&lt;/p&gt; 
&lt;p&gt;Doris 在 2.1 版本開始支持 Paimon Catalog，可以直接訪問 Paimon 數據並加速 Paimon 數據分析。在 Paimon TPC-DS 1TB 測試集上，Doris 的總體查詢性能是 Trino 的 5 倍。&lt;/p&gt; 
&lt;p&gt;從 2.1 版本到 3.0、3.1 版本，Doris 在持續針對 Paimon 格式進行功能更新和性能增強，包括但不限於以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;通過元信息對 Paimon 數據進行分區、分桶裁剪和謂詞下推，優化查詢效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Deletion Vector 讀取，利用向量化 C++ 引擎加速 Paimon 更新數據的讀取。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 數據的本地文件緩存，充分利用本地高速磁盤提升熱點數據的查詢效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 時間旅行、增量數據讀取、Branch/Tag 數據讀取，方便用戶進行 Paimon 數據的多版本管理。&lt;/li&gt; 
 &lt;li&gt;支持基於 Paimon 的物化視圖，包括分區級別的增量物化視圖構建，以及本文後續將要介紹的基於快照級別的增量構建，同時支持強一致的物化視圖透明改寫能力，將湖和倉的能力深度結合。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Rest Catalog（DLF），方便雲上用戶接入 Paimon 生態，實現統一元數據管理。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在本文中，我們將重點介紹小米如何基於 Doris + Paimon 構建統一湖倉平台，以及在項目開發過程中的功能貢獻和優化思路。&lt;/p&gt; 
&lt;h2&gt;01 化繁為簡：基於 Doris + Paimon 的統一湖倉平台建設&lt;/h2&gt; 
&lt;p&gt;作為一家業務覆蓋汽車、IoT、手機、互聯網服務等多個領域的大型企業，小米集團對 OLAP 系統和湖倉平台提出瞭如下關鍵需求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多維度分析&lt;/strong&gt;：支持高併發、低延遲的多維聚合分析（如用戶行為、設備狀態、運營監控等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多源接入&lt;/strong&gt;：需要打通 Flink、Spark、Flink CDC 等流批框架的輸入，覆蓋離線、實時全鏈路數據處理場景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;統一數據訪問&lt;/strong&gt;：支持跨引擎、多格式的數據消費需求（如 Doris、Paimon、Iceberg 等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;降低平台複雜度&lt;/strong&gt;：減少技術棧分裂，統一數據建模與管控，提升數據平台運維效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;當前架構的挑戰與瓶頸&lt;/h3&gt; 
&lt;p&gt;儘管已有較成熟的數據平台體系，但小米的 OLAP 湖倉架構長期存在如下"繁雜、割裂"的結構問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;存儲多源異構，數據重複堆疊&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;為滿足不同業務對數據的不同時效性需求，需要按照分鐘、小時、天級別的時效性要求，將數據存儲在不同的數據系統中（Iceberg、Paimon、Druid、Doris），導致數據冗餘、不一致等問題&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;湖倉割裂，缺乏統一接口&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需要同時使用不同的引擎進行數據查詢，（如 Presto、Druid、Doris、Spark 等）。各系統有獨立的數據建模、運維和權限控制邏輯，平台治理成本高，入口不統一，使用方式不統一。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//54a06d5419f01bd3f147603a3e36c475.png" alt="化繁為簡：基於 Doris + Paimon 的統一湖倉平台建設.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這些問題不僅增加了平台負擔，也制約了 OLAP 架構在大規模實時應用場景下的穩定性和擴展性。&lt;/p&gt; 
&lt;h3&gt;統一引擎 + 統一存儲&lt;/h3&gt; 
&lt;p&gt;為應對上述挑戰，小米構建了基於 &lt;strong&gt;Apache Doris + Apache Paimon&lt;/strong&gt; 的統一湖倉一體化架構，作為未來 OLAP 平台的核心形態。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;統一計算引擎：Apache Doris + Spark&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;採用 Doris + Spark 的計算引擎組合。Doris 負責實時數據和交互式數據分析，以及高併發查詢場景。Spark 負責離線批處理場景。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;統一數據湖存儲：Apache Paimon&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;以 Apache Paimon 作為統一數據存儲格式。Paimon 的設計非常適合流、批數據一體化存儲。實現批流一體、湖倉一體的數據管理。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4523b53882f118d0fe114ba1b214b893.png" alt="統一引擎 + 統一存儲.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過這一架構轉型，極大地簡化了系統架構：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算引擎：Presto、Druid、Doris、Spark -&amp;gt; Doris、Spark&lt;/li&gt; 
 &lt;li&gt;存儲格式：Iceberg、Paimon、Doris、Druid -&amp;gt; Doris、Paimon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02 深度融合：基於 Doris + Paimon 查詢加速實踐&lt;/h2&gt; 
&lt;p&gt;小米在引入 Apache Paimon 構建湖倉平台後，雖解決了海量數據的存儲問題，卻在實際業務中遭遇了三大關鍵瓶頸，直接影響了數據價值的釋放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聚合性能不足&lt;/strong&gt;：Doris 在讀取 Paimon 的 Merge-on-Read 表時，受限於 Paimon SDK（Java）單線程處理多文件的排序與合併，在高併發場景下完全無法滿足業務對 "秒級響應" 的需求。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;物化視圖更新代價高昂&lt;/strong&gt;：分區級增量更新機制粒度在某些場景下可以滿足用戶的增量更新需求。但對於非分區表，或者單分區數據量較大的表，依然有較高的更新成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HDFS 讀取延遲不穩定&lt;/strong&gt;：HDFS 多副本讀取時，默認 60 秒的超時閾值和網絡抖動，導致查詢延遲波動極大，業務方難以依賴數據結果快速做出決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些問題並非單純的技術瑕疵 ------ 它們直接拖慢了業務決策速度，同時因資源浪費和低效運行增加了企業成本。&lt;/p&gt; 
&lt;p&gt;針對上述瓶頸，小米通過深度整合 Apache Doris 與 Apache Paimon 的特性，打造了&lt;strong&gt;三大 "橋接" 方案&lt;/strong&gt;，實現了從 "問題" 到 "解決方案" 的精準突破。&lt;/p&gt; 
&lt;h3&gt;方案一：用 Doris 計算引擎加速 Paimon 聚合能力&lt;/h3&gt; 
&lt;p&gt;Doris 本身擁有強大的數據聚合計算能力，同時支持 Aggregate Key 聚合表模型，該模型在應用場景上和 Paimon 聚合表非常類似，因此可以作為 Paimon 聚合表很好的補充。&lt;/p&gt; 
&lt;p&gt;針對原先 Doris 讀取 Paimon 聚合表性能不足的問題，小米採用了將文件合併與排序邏輯 "上移" 至 Doris 的查詢引擎的方案，利用 Doris 的分佈式並行計算與向量化執行能力，替代 Paimon SDK 的單線程處理模式。具體而言：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;放棄 JNI 調用 Paimon Java SDK 的方式，改用 Doris 原生 Parquet Reader 直接讀取 Paimon 數據文件；&lt;/li&gt; 
 &lt;li&gt;藉助 Doris 的 Hash 算子實現分佈式聚合（無需排序步驟），充分發揮 C++ 引擎的性能優勢。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2e1dbabcb52805e9fb9c1bbdabf4dcec.png" alt="方案一：用 Doris 計算引擎加速 Paimon 聚合能力.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;經過此方案改造，聚合表的查詢時長&lt;strong&gt;從 40 秒縮短至 8 秒，性能提升近 5 倍。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案二：快照級增量物化視圖實現高效更新&lt;/h3&gt; 
&lt;p&gt;Doris 支持 Paimon、Iceberg 等數據湖表格式的異步物化視圖構建，並且支持分區級別的增量物化視圖刷新與查詢透明改寫。物化視圖作為數據庫與數據湖的直接橋樑，對查詢加速起到了至關重要的作用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//46574d04066c2797c966cd797925a8f0.png" alt="方案二：快照級增量物化視圖實現高效更新.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了進一步提高物化視圖的時效性，並降低物化視圖的更新開銷。小米進一步研發了基於快照級別的物化視圖增量刷新能力，並且貢獻到了 Apache Doris 社區。&lt;/p&gt; 
&lt;p&gt;首先，小米開發了 Paimon 表的快照級別的增量讀取能力，如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;SELECT * FROM paimon_table@incr('startSnapshotId'='0', 'endSnapshotId'='5')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該功能可以僅讀取指定 snapshot 區間的增量數據。&lt;/p&gt; 
&lt;p&gt;基於該功能，小米進一步開發了基於快照級別的增量物化視圖功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;在 Paimon 中創建一張聚合表&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;CREATE TABLE paimon_aggregate_table (
  dt bigint,
  k1 bigint
  k2 string,
  v1 int,
  v2 double
)
USING paimon
PARTITIONED BY (dt)
TBLPROPERTIES (
  'bucket' = '2',
  'bucket-key' = 'k1,k2',
  'fields.v1.aggregate-function' = 'sum',
  'fields.v2.aggregate-function' = 'max',
  'merge-engine' = 'aggregation',
  'primary-key' = 'dt,k1,k2'
);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Doris 中創建對應的物化視圖&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;  CREATE MATERIALIZED VIEW paimon_aggregate_table_mv
  BUILD DEFERRED
  REFRESH INCREMENTAL
  PARTITION BY (dt)
  DISTRIBUTED BY RANDOM BUCKETS 2
  AS 
  SELECT dt, k1, SUM(a1) AS a1
  FROM paimon_aggregate_table
  GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Doris 的異步物化視圖框架會在後台定時執行如下語句：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;INSERT INTO paimon_aggregate_table_mv
SELECT dt, k1, SUM(a1) AS a1
paimon_aggregate_table@INCR('startSnapshotId'='1', 'endSnapshotId'='2')
GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;利用快照讀取功能和 Doris 聚合功能，準實時的更新物化視圖，避免全量計算。&lt;/p&gt; 
&lt;p&gt;通過此方案，&lt;strong&gt;更新成本顯著降低，數據時效性大幅提升，且得益於 Doris 優化的 SQL 透明改寫能力，用戶無需修改 SQL 即可自動享受物化視圖的加速效果。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案三：HDFS 讀取長尾優化與緩存機制&lt;/h3&gt; 
&lt;p&gt;針對 HDFS 讀取延時不穩定的問題，小米採用瞭如下兩方面措施：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. HDFS 快速超時與重試&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;HDFS 在讀取數據時，會利用多副本機制，當一個副本的讀取時間超過閾值後，會切換到另一個副本嘗試讀取。超市閾值由參數 &lt;code&gt;dfs.client.socket-timeout&lt;/code&gt;控制，默認是 60 秒。這導致首次讀取的超時時間過長，在 HDFS 抖動或負載較高的情況下，會導致查詢延遲顯著增加。我們通過將該閾值降低到 100 毫秒，讓讀取情況進行快速的超時重試，顯著降低了查詢長尾，&lt;strong&gt;P99 性能提升 1 倍，總體性能提升 10%。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e3d184f7c8d525920cddc271ac838bcf.png" alt="方案三：HDFS 讀取長尾優化與緩存機制.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Doris 數據緩存&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;針對高併發查詢場景，單純的降低 HDFS 的重試超時時間，無法徹底的解決 HDFS 查詢延遲高的問題。因此，我們利用 Doris 的數據緩存能力，將熱點數據緩存在本地高速磁盤上，完美解決了高併發場景的查詢延遲問題。在開啓緩存的情況下，從 5 併發到 80 併發，查詢延遲可以&lt;strong&gt;降低&lt;/strong&gt; &lt;strong&gt;25% 到 300%。&lt;/strong&gt; 同時，得益於數據剪枝能力、高性能的算子，&lt;strong&gt;Doris 的整體查詢併發能力是 Presto 的 5 倍。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//29901c93faeb0f8dfc37da040b805da1.png" alt="2. Doris 數據緩存.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;總結與展望&lt;/h2&gt; 
&lt;p&gt;小米在 Apache Doris 和 Paimon 上的深度融合實踐，是典型的數據庫與數據湖的互補增效的體現。在這些實踐下，小米在湖倉數據分析場景下獲得了可觀的業務收益：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;查詢平均延遲從 60 秒降至 10 秒，性能提升 6 倍；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高併發場景下（5 併發提高至 80 併發），查詢延遲降低 25% 到 300%；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;整體查詢併發能力達到 Presto 的 5 倍，有效減少了計算資源。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;目前，這些能力已經全部回饋到了 Apache Doris 社區。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在未來，小米將繼續探索和拓展 Apache Doris 在數據湖倉上的能力和場景，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 Doris 全流量替換 Presto 集羣實現降本增效。&lt;/li&gt; 
 &lt;li&gt;進一步加強針對 Paimon、Iceberg 湖格式增量物化視圖的能力。&lt;/li&gt; 
 &lt;li&gt;Doris 湖倉架構容器化以滿足更靈活的部署方式。&lt;/li&gt; 
 &lt;li&gt;基於 Doris 的 Compute Group 虛擬計算組能力實現多業務間的資源隔離，提高資源利用率，降低維護成本。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/selectdb/blog/18688781</link>
      <guid isPermaLink="false">https://my.oschina.net/selectdb/blog/18688781</guid>
      <pubDate>Wed, 20 Aug 2025 02:35:53 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>英偉達正開發新款「中國特供」 AI 芯片，性能強於 H20</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fworld%2Fchina%2Fnvidia-working-new-ai-chip-china-that-outperforms-h20-sources-say-2025-08-19%2F" target="_blank"&gt;據路透社援引知情人士透露&lt;/a&gt;，英偉達正在研發面向中國市場的新型 AI 芯片 B30A，其性能超越當前獲準銷售的 H20 芯片，並計劃最快於 2025 年 9 月向中國客戶提供測試樣品。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/103840_kcWl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，該芯片採用單芯片設計，預計其算力約為旗艦級 B300 加速卡雙芯片配置的一半。此外，該芯片將配備高帶寬內存（HBM）和 NVLink 技術，以提升處理器間的數據傳輸效率。&lt;/p&gt; 
&lt;p&gt;單芯片設計指所有主要電路都製作在同一塊連續的硅晶圓上，而不是分散在多個芯片上。消息人士表示，目前芯片最終規格還沒完全敲定，但 NVIDIA 希望最快下個月向中國客戶提供樣品進行測試。&lt;/p&gt; 
&lt;p&gt;根據相關曝光的信息，B30A 很可能是基於同樣單芯片設計的 Blackwell B300A 修改而來。通過單芯片集成核心電路，B30A 在保持 Blackwell 架構先進性的同時，降低了被認定為「高性能計算設備」的風險，從而規避更嚴格的出口審查。&lt;/p&gt; 
&lt;p&gt;該芯片基於最新 Blackwell 架構、其核心戰略定位在於，在滿足美國商務部出口管制條例（EAR）的前提下，提供超越上一代特供芯片 H20 的性能，以應對中國市場日益增長的 AI 算力需求和本土廠商的競爭。&lt;/p&gt; 
&lt;p&gt;此前，有消息稱，美國政府與 NVIDIA、AMD 達成協議，將在中國銷售芯片的 15% 營收上繳給美國政府，以取得半導體出口許可。與此同時，中國官媒指控 NVIDIA 芯片存在安全風險，並警告中國科技公司謹慎購買 H20。&lt;/p&gt; 
&lt;p&gt;此外，據知情人士透露，NVIDIA 也正準備推出另一款針對中國市場的新芯片，同樣基於最新 Blackwell 架構，主要用於 AI 推理任務。該芯片暫名 RTX6000D，售價將低於 H20，其規格較弱且製造需求更簡單。該芯片設計是為了落在美國政府設定的門檻之下，採用傳統 GDDR 內存，內存帶寬為 1398 GB/s，計劃 9 月提供少量產品給中國客戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367317</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367317</guid>
      <pubDate>Wed, 20 Aug 2025 02:31:53 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動否認自研 AI 手機</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;針對近日市場上有關字節跳動正在研發「豆包手機」的傳言，字節跳動相關負責人明確回應稱，該消息不實，豆包目前並無推出自有手機產品的計劃。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據介紹，豆包始終致力於將自身 AI 能力向包括手機廠商在內的各類硬件廠商開放。在此過程中，雖會與部分合作夥伴共同開展完整解決方案的嘗試，但所有合作均不涉及自有手機產品的研發與推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="339" src="https://oscimg.oschina.net/oscnet/up-70f77e4956e520cdce2146bdfaa4e1c28a6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據瞭解，2019 年 1 月，字節跳動收購錘子科技部分專利使用權，當時便引發市場對於字節將進入手機市場的猜測。此後，原堅果手機團隊在字節跳動內部以「新石實驗室」為名開展工作，定位為集團硬件中台，探索智能手機及教育硬件等智能硬件產品。不過，2021 年 1 月，「新石實驗室」併入由 Musical.ly 原創始人陽陸育負責的教育硬件團隊，合併後的團隊專注於教育領域，不再研發堅果手機、TNT 顯示器等其他無關產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年以來，類似傳聞亦多次出現。1 月，有消息稱字節跳動選擇與努比亞合作開發 AI 手機，字節跳動回應稱消息不實；2 月，關於榮耀前 CEO 趙明將加盟字節跳動並負責手機業務的傳言，字節跳動同樣表示信息不實。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;豆包大模型作為字節跳動旗下重要的 AI 產品，數據顯示，其 2024 年累計用戶規模已超 1.6 億，11 月平均每日新增下載用戶達 80 萬，單日活躍用戶近 900 萬。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技術應用方面，2025 年 7 月 30 日，火山引擎宣佈豆包·圖像編輯模型 SeedEdit 3.0 正式登陸火山方舟；8 月 1 日，小米瀏覽器升級「AI 搜索」功能，通過接入豆包大模型及火山方舟高代碼智能體產品，進一步提升了 AI 搜索的效率與服務豐富度。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367315</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367315</guid>
      <pubDate>Wed, 20 Aug 2025 02:20:53 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 計劃通過股權出售成為全球最有價值私營公司，估值達 5000 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 正在考慮進行一輪價值 60 億美元的股權出售，這將使其估值達到 5000 億美元，超越目前全球最有價值的私人公司 SpaceX（估值 3500 億美元）。這次股權出售的股份將主要由現有和前員工出售。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-6a3f4b40ac1c67918c3c1507155d1ac2163.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;過去一年，OpenAI 經歷了迅猛的增長，微軟和軟銀等投資者已經為該公司投入了至少 400 億美元，使其在 2023 年 3 月的估值達到了 3000 億美元。而在 2022 年 10 月，OpenAI 的估值僅為 1570 億美元。如果此次股權出售成功，OpenAI 將成為全球估值&lt;span&gt;最高&lt;/span&gt;的私人公司。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;當前，參與此次股權出售談判的投資者包括已經對 OpenAI 投資的三家機構:軟銀、Dragoneer 投資集團和 Thrive 資本。根據彭博社的報道，相關談判仍處於早期階段，最終的數字可能會有所變動。OpenAI 對此未作出評論。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在人工智能領域，OpenAI 正處於激烈的競爭之中。全球多家科技巨頭，包括 Meta、谷歌、亞馬遜和微軟，正在大力投入人工智能研發， hiring engineers and building data centers。僅在 2025 年，這四家公司在人工智能領域的投入就超過了 1550 億美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管自 2022 年發佈 ChatGPT 以來，人工智能技術有了顯著提升，但 OpenAI 在本月發佈的&lt;span&gt;最新&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 模型 GPT-5 的表現卻並未得到熱烈反響。用戶反饋稱，該版本的寫作質量不如之前的版本，且缺乏以往的個性化特徵。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 首席執行官山姆・奧特曼表示，雖然公司追求的是 「通用人工智能」，即能在大多數任務上超越人類的 AI，但他在最近的發佈會上表示，GPT-5 是 「普遍智能」 的，但尚未能夠 「持續學習」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367312</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367312</guid>
      <pubDate>Wed, 20 Aug 2025 02:02:53 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 剛剛更新線上模型版本至 V3.1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 在官方社羣宣佈，其線上模型版本已升級至 V3.1，上下文長度拓展至 128k。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0819/193913_BlOM_2720166.png" width="1196" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;歡迎前往官方網頁、APP、小程序測試，API 接口調用方式保持不變。&lt;/p&gt; 
&lt;p&gt;接口信息：https://platform.deepseek.com/usage&lt;/p&gt; 
&lt;p&gt;近日市場再度傳出深度求索下一代 AI 大模型 DeepSeek-R2 的發佈消息，預計時間窗口為 8 月 15 日至 30 日。對此，接近 DeepSeek 人士表示，該消息不實，並確認 DeepSeek-R2 在 8 月內並無發佈計劃。 &lt;/p&gt; 
&lt;p&gt;DeepSeek 創始人梁文鋒在內部表示，他對 R2 取得的進展並不滿意，並一直在竭力投入更多的時間來研發一款能夠讓該公司在 AI 領域保持領先地位的先進模型。&lt;/p&gt; 
&lt;p&gt;梁文峯要求模型達到更出色的結果才批准發佈，R2 的發佈還因更新版模型的數據標註時間超出預期而被推遲。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367254</guid>
      <pubDate>Mon, 18 Aug 2025 11:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 總裁透露 OpenAI 的 AGI 之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在最新一期的《Latent Space》訪談中，OpenAI 總裁 Greg Brockman 深入闡述了公司邁向 AGI 的整體路線圖，核心可概括為「三個轉向」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技術轉向：從「一次性預訓練」到「強化學習推理」&lt;/li&gt; 
 &lt;li&gt;資源轉向：把「算力」視為唯一稀缺資源&lt;/li&gt; 
 &lt;li&gt;落地轉向：從「科研樣品」到「可審計的生產 Agent」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7470bcfe83cc59abb3b2fd2b11145f80512.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Greg Brockman 透露，GPT-4 發佈之後，團隊內部覆盤「它為何還不是 AGI」，結論是僅靠大規模預訓練無法解決可靠性不足的問題，必須讓模型在與真實世界的交互中「試錯—反饋—再訓練」。因此 GPT-5 首次引入強化學習驅動的「動態推理」範式：模型邊使用邊生成數據，再用這些數據進行再訓練，逼近人類「邊做邊學」的循環。&lt;/p&gt; 
&lt;p&gt;他將這種「推理-重訓」飛輪稱為「超臨界學習」（supercritical learning）：當算力放大 10× 乃至 10 000× 時，模型不僅能掌握任務本身，還能推演出二階、三階後果，從而快速逼近 AGI。&lt;/p&gt; 
&lt;p&gt;Greg Brockman 還把「算力」視為唯一稀缺資源，他認為算法壁壘往往可通過堆算力解決；AGI 進度條幾乎與可用計算量線性相關。OpenAI 已把「持續投入大規模計算」寫入長期資源策略，並認為未來 AGI 的形態會是「一個模型管理器」——本地小模型按需調用雲端大算力，實現自適應計算。&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;總的來説，OpenAI 的 AGI 路線圖可概括為「用強化學習把模型放進真實世界，用算力把反饋循環推到極致，用安全可控的 Agent 形態把能力嵌入千行百業」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367248</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367248</guid>
      <pubDate>Mon, 18 Aug 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 143 被發現不適用於某些舊 Windows 10 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在舊版 Windows 10 上運行 Firefox 瀏覽器的用戶即將迎來很大困擾。目前在 Nightly 頻道提供的最新版本 Firefox 143 已不再適用於 1803 之前的版本。&lt;/p&gt; 
&lt;p&gt;在 Windows 10 1703、1709 或 2015 LTSB 等老版本上啓動該瀏覽器時，用戶會收到以下錯誤：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由於未找到 api-ms-win-core-console-11-2-0.dll，代碼無法繼續執行。重新安裝程序或許可以解決此問題。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0700df38d95ae0494d0de12f07efb1ce47d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FTheBobPony%2Fstatus%2F1955740560292999460" target="_blank"&gt;這一發現&lt;/a&gt;迅速引發了用戶的討論（他們已經對 Mozilla 向瀏覽器添加不必要的、耗費資源的內容&lt;a href="https://www.oschina.net/news/366029" target="_blank"&gt;感到不滿&lt;/a&gt;），他們要求 Mozilla 放棄舊版 Windows 10，這並非罕見之舉。儘管 Windows 10 總體上仍然受支持，但許多應用程序已無法在舊的版本上運行。&lt;/p&gt; 
&lt;p&gt;儘管如此，考慮到 Mozilla 瀏覽器仍然支持 Windows 7，放棄對部分 Windows 10 市場份額的支持卻令人意外，不過某些舊版本（例如 2015 LTSB 和 2016 LTSC）仍然受支持。Windows&amp;nbsp;10 2015 LTSB 版本將於 2025 年 10 月停止支持，而 2016 LTSC 版本將繼續獲得更新，直到 2016 年 10 月。&lt;/p&gt; 
&lt;p&gt;然而事實證明，Mozilla 並沒有在 1803 之前的 Windows 10 版本上淘汰 Firefox。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ffirefox%2Fcomments%2F1mph4ra%2Fstarting_with_firefox_143_it_will_now_only%2F" target="_blank"&gt;Mozilla 工程師在 Reddit 上&lt;/a&gt;迅速處理了此事，並確認 Firefox 143 Nightly 無法在舊版 Windows 10 上運行的問題只是一個 bug，而非故意為之。因此，該問題應該很快就會得到修復。您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1983020" target="_blank"&gt;在 Bugzilla 官方網站上&lt;/a&gt;跟蹤發現的 bug 。&lt;/p&gt; 
&lt;p&gt;與此同時，用戶創建了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faubymori%2FFirefox-OldWindows%252010-Fix" target="_blank"&gt;一個臨時解決方案&lt;/a&gt;，讓瀏覽器在 Firefox 軟件工程師準備永久修復程序期間能夠正常運行。這也可以提醒大家不要依賴 Nightly 版本，因為這些版本的更改有時可能會導致瀏覽器完全崩潰。&lt;/p&gt; 
&lt;p&gt;Mozilla 尚未宣佈終止 Windows 10 支持的計劃。不過，由於 Windows 7 仍受支持，因此可以預期開發人員將在相當長的一段時間內繼續在 Windows 10 上更新 Firefox。另一方面，微軟近日透露，Edge 瀏覽器在 2025 年 10 月主流支持結束後，仍將在 Windows 10 上繼續支持三年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367246</guid>
      <pubDate>Mon, 18 Aug 2025 11:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claudia —— 基於 Tauri 2 的 Claude Code 桌面客戶端</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Claudia 是一款強大的桌面應用程序，作為 Claude Code 的圖形化命令中心，為 AI 輔助開發工作流程提供了直觀的界面。該應用基於 Tauri 2、React 和 TypeScript 構建，填補了 Claude Code CLI 與開發者全面視覺體驗之間的空白。&lt;/p&gt;

&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/181014_4hpz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;Claudia 通過提供功能豐富的圖形用戶界面（GUI），改變了開發者與 Claude Code 的交互方式，提升了生產力並簡化了 AI 輔助開發流程。該應用程序基於您現有的 Claude Code 安裝，自動檢測您的&lt;code&gt;~/.claude&lt;/code&gt;目錄，併為項目、會話和自定義 AI 代理提供可視化界面。&lt;/p&gt;

&lt;p&gt;Claudia 為存儲在&lt;code&gt;~/.claude/projects/&lt;/code&gt;中的所有 Claude Code 項目提供了可視化瀏覽器。您可以：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通過用戶友好的界面瀏覽項目&lt;/li&gt;
&lt;li&gt;查看並恢復帶有完整上下文的過往編碼會話&lt;/li&gt;
&lt;li&gt;搜索特定項目和會話&lt;/li&gt;
&lt;li&gt;查看會話元數據，包括首次消息和時間戳&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;該應用程序自動檢測正在運行的 Claude Code 會話，並允許您從中央界面進行管理。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/claudia-code</link>
      <guid isPermaLink="false">https://www.oschina.net/p/claudia-code</guid>
      <pubDate>Mon, 18 Aug 2025 10:39:00 GMT</pubDate>
    </item>
    <item>
      <title>XZ Utils 後門仍然潛伏在 Docker 鏡像中</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;安全研究公司 Binarly &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.binarly.io%2Fblog%2Fpersistent-risk-xz-utils-backdoor-still-lurking-in-docker-images" target="_blank"&gt;發佈報告稱&lt;/a&gt;，曾在 2024 年曝光的 &lt;strong&gt;XZ Utils 後門&lt;/strong&gt;仍在部分 Docker 鏡像中潛伏，提醒開發者和運維人員容器供應鏈的潛在風險仍未徹底消除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;xz-utils&lt;/code&gt; 軟件包曾在 2024 年被發現存在嚴重後門（CVE‑2024‑3094，CVSS 10.0 分）。該後門通過 &lt;code&gt;liblzma.so&lt;/code&gt; 對 OpenSSH 函數加鈎子，實現繞過 SSH 認證和遠程執行權限操作。&lt;/p&gt; 
&lt;p&gt;儘管該漏洞在公開後迅速修復，但 Binarly 團隊最新掃描顯示，&lt;strong&gt;截至 2025 年 8 月，仍有 12 個 Debian 官方基礎鏡像直接包含該後門&lt;/strong&gt;，並且通過依賴關係，至少有 &lt;strong&gt;35 個鏡像存在潛在傳播風險&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/183442_zItb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;針對該情況，Debian 維護者回應稱，這些鏡像屬於過時開發版，主要保留歷史記錄，因此選擇不移除。Binarly 則提醒，即便利用條件苛刻，這些帶網絡觸發能力的後門鏡像仍可能被自動化構建或無意拉取帶入生產環境，存在潛在安全威脅。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367240</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367240</guid>
      <pubDate>Mon, 18 Aug 2025 10:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>達夢數據：公司董事兼總經理被留置</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;達夢數據發佈公告稱，公司於近期收到湖北省應城市監察委員會下發的《立案通知書》及《留置通知書》，對公司董事兼總經理皮宇立案調查並實施留置措施。&lt;/p&gt; 
&lt;p&gt;目前，公司已對相關工作進行妥善安排，預計該事項不會對公司生產經營產生重大影響。其他董事、監事和高級管理人員均正常履職，公司及子公司日常經營情況正常，各項業務穩步推進。&lt;/p&gt; 
&lt;p&gt;&lt;img height="532" src="https://oscimg.oschina.net/oscnet/up-3b66d352d66b8255335b97b879b6b195785.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367239</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367239</guid>
      <pubDate>Mon, 18 Aug 2025 10:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>歐洲 AI 創企發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;歐洲知名 AI 初創公司 Multiverse Computing 近日發佈了兩款極其微小的 AI 模型，小到可以用雞腦和蠅腦來命名。該公司聲稱這是全球最小但仍保持高性能的模型，能夠處理聊天、語音識別，其中一款甚至具備推理能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這些超小型模型專為物聯網設備設計，同時可以在智能手機、平板電腦和個人電腦上本地運行。公司創始人羅曼·奧魯斯向 TechCrunch 表示："我們可以將模型壓縮到如此程度，使其能夠適配各種設備。你可以在本地運行它們，直接在 iPhone 上，甚至在 Apple Watch 上。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Multiverse Computing 總部位於西班牙多諾斯蒂亞，在全球設有辦公室，員工約 100 人，是一家備受關注的歐洲 AI 初創公司。該公司由歐洲頂級量子計算和物理學教授羅曼·奧魯斯、量子計算專家塞繆爾·穆格爾和前 Unnim 銀行副首席執行官恩裏克·利薩索·奧爾莫斯共同創立。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-994e0870ab2f0680c22e597e4d0461fe9b9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;今年 6 月，該公司憑藉名為"CompactifAI"的模型壓縮技術成功融資 1.89 億歐元（約 2.15 億美元）。自 2019 年成立以來，公司累計融資約 2.5 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;CompactifAI 是一種量子啓發的壓縮算法，能夠在不犧牲模型性能的前提下減小現有 AI 模型的體積。奧魯斯解釋説:"我們擁有的壓縮技術不是計算機科學或機器學習領域人員會採用的典型壓縮技術，因為我們來自量子物理學背景。這是一種更加精妙和精細的壓縮算法。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;該公司已經發布了大量開源模型的壓縮版本，特別是流行的小型模型如 Llama4Scout 或 Mistral Small3.1，並剛剛推出了 OpenAI 兩個新開源模型的壓縮版本。公司還壓縮了一些大型模型，比如提供 DeepSeek R1Slim 版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;專注於模型小型化的 Multiverse 將額外精力投入到創造儘可能小但功能強大的模型上。其兩款新模型小到足以為幾乎任何物聯網設備帶來聊天 AI 功能，並且無需互聯網連接。公司幽默地稱這個系列為"模型動物園"，因為產品是根據動物大腦尺寸命名的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;名為 SuperFly 的模型是 Hugging Face 開源模型 SmolLM2-135 的壓縮版本。原始模型有 1.35 億個參數，專為設備端使用開發。SuperFly 壓縮至 9400 萬個參數，奧魯斯將其比作蠅腦的大小。他説："這就像擁有一隻蒼蠅，但稍微聰明一點。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;SuperFly 專為在極其受限的數據上進行訓練而設計，比如設備操作數據。Multiverse 設想將其嵌入家用電器中，讓用戶能夠通過語音命令操作設備，如對洗衣機説"開始快洗"，或詢問故障排除問題。通過少量處理能力（如 Arduino），該模型就能處理語音界面，公司向 TechCrunch 進行了現場演示。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;另一款名為 ChickBrain 的模型更大，有 32 億個參數，但功能也更強大，具備推理能力。Multiverse 表示這是 Meta Llama3.18B 模型的壓縮版本，但小到足以在 MacBook 上運行，無需互聯網連接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更重要的是，奧魯斯表示 ChickBrain 在多個標準基準測試中實際上略微超越了原始模型，包括語言技能基準 MMLU-Pro、數學技能基準 Math500 和 GSM8K，以及通用知識基準 GPQA Diamond。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;需要注意的是，Multiverse 並未聲稱其模型動物園會在這些基準測試中擊敗最大的最先進模型，動物園的性能甚至可能不會出現在排行榜上。關鍵在於該公司的技術能夠在不影響性能的情況下縮小模型尺寸。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;奧魯斯表示，公司已在與所有領先的設備和家電製造商進行洽談。他説:"我們正在與蘋果洽談，也在與三星、索尼和惠普對話。惠普在最後一輪融資中作為投資者參與進來。"這輪融資由知名歐洲風投公司 Bullhound Capital 領投，包括 HP Tech Ventures 和東芝在內的多家機構參與。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這家初創公司還為其他形式的機器學習提供壓縮技術，如圖像識別，在六年時間裏已獲得巴斯夫、Ally、穆迪、博世等客戶。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了直接向主要設備製造商銷售模型外，Multiverse 還通過託管在 AWS 上的 API 提供壓縮模型，任何開發者都可以使用，通常比競爭對手收取更低的 token 費用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367238</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367238</guid>
      <pubDate>Mon, 18 Aug 2025 10:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小米 Q2 淨利潤同比增長 75.4%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;小米集團公佈 Q2 財報，數據顯示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;小米集團第二季度營收 1159.6 億元人民幣，同比增長 30.5%，創歷史新高。預估 1149.4 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;調整後淨利潤 108.3 億元人民幣，同比增長 75.4%，同樣創下歷史新高。預估 102.3 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;營業利潤 134.4 億元人民幣，預估 104.3 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;研發支出 77.6 億元人民幣，同比增長 41.2%。預估 71.8 億元人民幣。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;智能電動汽車及 AI 等創新業務分部收入達到人民幣 213 億元，其中汽車業務貢獻了 206 億元。該分部的毛利率高達 26.4%，遠高於去年同期的 15.4%。財報將其歸因於核心零部件成本下降、單位製造成本降低，以及高 ASP（平均售價）的 Xiaomi SU7 Ultra 交付。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="217" src="https://oscimg.oschina.net/oscnet/up-7c457b8deb1369b766421cd8022a09bb76f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心業務進展：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能電動汽車：&lt;/strong&gt;已成為絕對的增長引擎。本季度收入達 213 億元，交付 81,302 輛新車。毛利率高達 26.4%，遠超市場預期，顯示出強大的成本控制和高端車型交付能力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;IoT 與生活消費產品：&lt;/strong&gt;表現亮眼，收入 387 億元，同比猛增 44.7%，毛利率提升至 22.5%。智能大家電（空調、冰箱、洗衣機）是主要增長動力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能手機：&lt;/strong&gt;儘管出貨量微增 0.6% 至 4240 萬台，但收入同比下滑 2.1% 至 455 億元，毛利率從 12.1% 降至 11.5%，主要受境外市場競爭及國內促銷活動影響。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;互聯網服務：&lt;/strong&gt;收入穩定增長至 91 億元，同比增長 10.1%，但毛利率從 78.3% 微降至 75.4%。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;小米集團表示，2025 年第二季度，智能大家電的收入創歷史新高，同比增長達 66.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="2551" src="https://static.oschina.net/uploads/space/2025/0819/175808_cTEa_4252687.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367233</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367233</guid>
      <pubDate>Mon, 18 Aug 2025 09:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌工程師提交補丁：Linux 內核首次支持 OOM 策略可編程</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 內核正迎來一項可能改變內存管理方式的新提案。來自谷歌的內存管理專家 Roman Gushchin 提交了一組補丁，計劃允許通過 BPF（eBPF）直接定製系統在 &lt;strong&gt;內存溢出（OOM, Out-of-Memory）&lt;/strong&gt; 時的處理邏輯。這意味着，長期以來依賴內核默認 OOM killer 或用戶空間工具（如 systemd-oomd）的侷限性，或將被更靈活、可編程的機製取代。&lt;/p&gt; 
&lt;p&gt;&lt;img height="712" src="https://static.oschina.net/uploads/space/2025/0819/174242_BTqv_2720166.png" width="1082" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lore.kernel.org/lkml/20250818170136.209169-1-roman.gushchin@linux.dev/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;該方案的核心思路是在內核觸發 OOM killer 之前，先調用 BPF 程序。運維人員或雲平台可以藉此決定是終止某個特定進程、清理某個內存 cgroup，甚至通過刪除 tmpfs 文件來釋放內存，而不必一刀切地依賴內核默認策略。同時，新的補丁還引入基於 PSI（Pressure Stall Information） 的 OOM 觸發機制，更好地判斷何時真正進入「內存壓力」狀態，從而避免系統假死或誤殺關鍵進程。&lt;/p&gt; 
&lt;p&gt;在實現上，這些補丁增加了新的 BPF 輔助函數，例如顯式殺死指定進程的 &lt;code&gt;bpf_oom_kill_process()&lt;/code&gt;，以及獲取內存 cgroup 根節點的 &lt;code&gt;bpf_get_root_mem_cgroup()&lt;/code&gt;，為內核空間提供了更強的可編程接口。&lt;/p&gt; 
&lt;p&gt;如果最終被合入主線，Linux 將首次賦予開發者和運維團隊在內核層面 &lt;strong&gt;「編寫自己的 OOM 策略」&lt;/strong&gt; 的能力，這對數據中心、雲計算平台以及對內存敏感的服務部署而言，都可能帶來深遠影響。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367232</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367232</guid>
      <pubDate>Mon, 18 Aug 2025 09:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gemini API 支持抓取 URL</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌宣佈其 Gemini API 中的 URL Context 工具&lt;strong&gt;已正式支持直接抓取 URL 內容&lt;/strong&gt;，無需額外腳本或中間步驟。&lt;/p&gt; 
&lt;p&gt;&lt;img height="765" src="https://static.oschina.net/uploads/space/2025/0819/172728_9w7A_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini API 提供了 &lt;strong&gt;URL Context 功能&lt;/strong&gt;，允許你在請求中直接嵌入網頁鏈接，模型會自動訪問並解析網頁內容。支持的內容類型包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文本網頁（HTML、JSON、TXT 等）&lt;/li&gt; 
 &lt;li&gt;PDF 文件&lt;/li&gt; 
 &lt;li&gt;圖片（PNG、JPEG、WebP 等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不支持的內容：YouTube 視頻、Google Docs、付費牆內容等。&lt;/p&gt; 
&lt;p&gt;✅ 使用示例（Python SDK）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
  model="gemini-2.5-flash",
  contents=[
      "總結這篇文章的內容：",
      types.Part.from_uri(
        uri="https://example.com/article",
        mime_type='text/html'
      )
  ]
)
print(response.text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;使用限制&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;每次最多支持 &lt;strong&gt;20 個 URL&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;單個 URL 內容大小上限為 &lt;strong&gt;34MB&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;抓取內容會計入 &lt;strong&gt;輸入 Tokens 費用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用 &lt;strong&gt;Gemini CLI&lt;/strong&gt;，也可以通過 &lt;code&gt;web_fetch&lt;/code&gt; 工具快速抓取網頁，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gemini-cli web-fetch --prompt "總結 https://example.com/article 的主要內容"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該工具會自動識別提示中的 URL 並調用 Gemini API 抓取內容。&lt;/p&gt; 
&lt;p&gt;如你正在開發基於 Gemini 的應用，&lt;strong&gt;URL Context 功能&lt;/strong&gt;已足夠替代傳統的爬蟲或 HTML 解析器，大幅提升開發效率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關鏈接&lt;/p&gt; 
&lt;p&gt;https://ai.google.dev/gemini-api/docs/url-context&lt;br&gt; https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#url-context&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367231/gemini-api-url-context</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367231/gemini-api-url-context</guid>
      <pubDate>Mon, 18 Aug 2025 09:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>淘寶「AI 萬能搜」功能灰度測試</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;淘寶正在灰度測試一項名為「AI 萬能搜」的新功能，旨在通過大模型技術重構電商搜索體驗。該功能位於淘寶搜索頁的「AI 萬能搜」標籤頁，標誌着 AI 技術在電商領域的應用正從企業端（B 端）營銷，加速滲透至消費者端 (C 端) 的實用階段。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「AI 萬能搜」是一款基於大模型的 AI 問答產品，能夠理解用戶的自然語言提問並進行深度思考。用戶提問後，AI 會生成一份融合文字、商品、視頻和圖片的「答案報告」，以解決用戶在購物過程中遇到的各種消費難題，例如購物攻略、口碑評測和優惠諮詢等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;據瞭解，目前「AI 萬能搜」主要聚焦於四大核心場景:穿搭指南、送禮清單、選購攻略和問口碑。該功能的一大亮點在於，用戶可以清晰地看到 AI 的思考過程，其思考邏輯主要分為三個步驟:獲取信息、查詢需求和分析總結。儘管目前尚不清楚其底層大模型是否只使用了「千問」，但這一功能已經展現出 AI 在提升消費者購物決策效率上的巨大潛力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="649" src="https://oscimg.oschina.net/oscnet/up-ea057aa8125432f67b68af7319fc597d9e8.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367229</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367229</guid>
      <pubDate>Mon, 18 Aug 2025 09:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Abogen - 文本轉語音工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Abogen 是一款功能強大的文本轉語音工具，可輕鬆將 ePub、PDF 或文本文件在幾秒鐘內轉換為帶有匹配字幕的高質量音頻。可以使用&lt;a href="https://huggingface.co/hexgrad/Kokoro-82M"&gt;Kokoro-82M&lt;/a&gt;將其用於有聲讀物、Instagram、YouTube、TikTok 的配音，或任何需要自然語音的文本轉語音項目。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151846_7vpx_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151903_hNpV_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/abogen</link>
      <guid isPermaLink="false">https://www.oschina.net/p/abogen</guid>
      <pubDate>Mon, 18 Aug 2025 09:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Vercel 旗下 AI 前端開發工具 v0 推出 iOS 應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vercel 旗下 AI 前端開發工具 v0&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fv0%2Fstatus%2F1957487790205325760"&gt;宣佈&lt;/a&gt;即將推出其 iOS 應用程序，目前已開放候補名單註冊。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0819/164508_7TkM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;http://v0.app/ios&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;根據官方發佈的信息，其宣傳語為 「Anything. Anyone. Anywhere.」。用戶現在可以通過官方鏈接加入等待列表。&lt;/p&gt; 
&lt;p&gt;Vercel v0 是一個利用自然語言提示生成全棧 web 應用的 AI 工具，其核心優勢在於通過簡單的文本描述即可快速生成高質量的用戶界面和代碼。自 2023 年首次推出以來，v0 憑藉其在前端 UI 生成上的卓越表現，特別是在 React 和 Next.js 框架中的應用，贏得了開發者和企業的廣泛認可。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367213</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367213</guid>
      <pubDate>Mon, 18 Aug 2025 08:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中山大學聯合美團打造 X-SAM 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中山大學、鵬城實驗室與美團三方聯合研發的 X-SAM 圖像分割模型近期正式發佈，這款多模態大模型在圖像分割領域實現了重要突破，將傳統的"分割萬物"能力升級為"任意分割"，顯著提升了模型的適應性和應用範圍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;傳統的 Segment Anything Model（SAM）雖然在生成密集分割掩碼方面表現出色，但其只能接受單一視覺提示輸入的設計侷限性明顯。針對這一技術瓶頸，研究團隊創新性地提出了視覺定位分割 (Visual Grounded Segmentation， VGS) 任務框架，通過交互式視覺提示實現對所有實例對象的精確分割，為多模態大語言模型提供了像素級的理解能力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的技術架構採用了多項創新設計。模型支持統一的輸入格式和輸出表示，能夠處理多種類型的視覺和文本查詢輸入。其核心的雙編碼器架構確保了對圖像內容和分割特徵的深度理解，而分割連接器則提供多尺度信息融合，大幅提升分割精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="432" src="https://oscimg.oschina.net/oscnet/up-17e3fd0c4916165c034f2f1fecd344dd8e9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最值得關注的是，X-SAM 集成了&lt;span&gt;最新&lt;/span&gt;的 Mask2Former 架構作為分割解碼器，這使得模型能夠在單次操作中同時分割多個目標對象，徹底突破了傳統 SAM 只能處理單一對象的技術限制。這一改進不僅提高了處理效率，也為複雜場景下的批量分割任務提供了可能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在模型訓練方面，研究團隊採用了三階段漸進式訓練策略，通過逐步增強的學習過程確保模型性能的穩定提升。經過在 20 多個主流分割數據集上的全面測試，X-SAM 在對話生成分割任務和圖文理解任務中均取得了領先的性能表現，驗證了其技術方案的有效性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的發佈為圖像分割技術發展指明瞭新方向，也為構建更加智能的通用視覺理解系統提供了重要的技術基礎。研究團隊表示，下一步將重點探索該技術在視頻領域的應用拓展，推動圖像與視頻分割技術的統一化發展，進一步提升機器視覺理解能力的邊界。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這項研究成果不僅在學術層面具有重要意義，其在自動駕駛、醫療影像、工業檢測等實際應用場景中的潛力也值得期待。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367209</guid>
      <pubDate>Mon, 18 Aug 2025 08:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
