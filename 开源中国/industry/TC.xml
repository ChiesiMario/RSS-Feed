<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 19 Feb 2025 07:36:12 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>百度 Q4 業績會實錄：DeepSeek 讓我們明白要將最優秀的模型開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度昨天&lt;a href=&quot;https://www.oschina.net/news/334611&quot;&gt;發佈&lt;/a&gt;了截至 12 月 31 日的 2024 年第四季度及全年財報。第四季度，營收為 341 億元，同比下滑 2%。屬於百度的淨利潤為 52 億元。不按美國通用會計準則，歸屬於百度的淨利潤為 67 億元。整個 2024 年，總營收為 1331 億元，同比下滑 1%。歸屬於百度的淨利潤為 238 億元。不按美國通用會計準則，歸屬於百度的淨利潤為 270 億元。&lt;/p&gt; 
&lt;p&gt;財報發佈後，百度董事長兼 CEO 李彥宏，移動生態事業羣總裁羅戎，智能雲事業羣總裁沈抖，代理 CFO 何俊傑等高管出席隨後召開的財報電話會議，解讀財報要點並回答分析師提問。&lt;/p&gt; 
&lt;p&gt;以下是分析是問答環節主要內容：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;花旗銀行分析師 Alicia Yap&lt;/strong&gt;：DeepSeek 最近備受關注，百度也宣佈即將開源文心大模型 4.5 系列，並且將免費提供使用。請問管理層，此舉背後的戰略考量是什麼？另外，我們如何看待當前基礎模型領域的競爭格局？百度計劃如何在這個不斷演變的市場中保持領先地位？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李彥宏&lt;/strong&gt;：生成式人工智能和基礎模型市場仍處於初期階段，但發展速度極快，DeepSeek 的成功案例肯定會加快基礎模型的應用速度。隨着基礎模型變得更容易獲取且成本降低，我們正進入一個真正的變革階段，我們會看到新的人工智能應用和使用案例在數量上呈爆發式增長，這將為所有人帶來巨大的機遇，並拓展人工智能的邊界，增加更多可能性。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;從 DeepSeek 我們學到一點，那就是將最為優秀的模型開源供所有人使用，將可以極大地推動其應用，因為大家出於好奇自然會想去嘗試開源模型，進而推動其更廣泛的應用。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;文心大模型 4.5 早期版本將是我們有史以來最出色的模型，我們希望用戶和客戶試用起來能比以往更容易，更輕鬆。我們決定將 4.5 早期系列進行開源，也源於對自身技術領先地位的堅定信心，這種信心源自我們數十年在研發方面的持續投入、不斷的技術創新，以及我們作為全球為數不多具備全棧人工智能能力公司之一的獨特地位。&lt;/p&gt; 
&lt;p&gt;文心一言已經展現出強大的市場吸引力，日 API 調用量在短短一年內從 5000 萬激增至 16.5 億。通過開源，我們相信更多開發者和用戶將認識到文心一言的真正價值，推動其更廣泛應用，並擴大其在更多場景中的影響力。&lt;/p&gt; 
&lt;p&gt;同樣，將文心一言機器人免費提供使用，能讓更多用戶在同等條件下將我們的基礎模型與其他模型進行比較，尤其是其他模型收費而我們不收費的情況。我們上次對文心大模型進行重大升級是在 2023 年 10 月，距今已有很長時間，所以，未來幾個月大家敬請期待文心大模型的 4.5 版本。&lt;/p&gt; 
&lt;p&gt;話説回來，我也想強調一個關鍵的重點。無論開源還是閉源，基礎模型只有在能夠大規模有效解決現實世界問題時才真正有價值，我們致力於以應用為導向，持續迭代文心大模型。秉持這種理念，自推出以來，我們一邊利用文心大模型升級內部產品，一邊服務企業客戶。&lt;/p&gt; 
&lt;p&gt;藉助文心大模型成功改造了百度面向消費者的產品，如百度搜索和百度文庫；此外，通過千帆平台，我們正在提升企業客戶的模型和應用開發體驗。文心一言在指令遵循、先進的檢索增強生成技術（該技術將幻覺問題降至最低）等方面的行業領先能力，使其在各種場景中得到廣泛應用。千帆平台的綜合工具鏈讓我們的客戶能夠針對自身應用場景定製任何模型。展望未來，我們將瞄準性能提升和成本削減的潛力，加快文心大模型的迭代，繼續在對現實世界影響潛力最大的領域對其進行開發。我們對人工智能發展的新篇章感到興奮，期待看到人工智能技術帶來更多具有開創性且對社會有持久價值的應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;高盛分析師 Lincoln Kong&lt;/strong&gt;：我有一個關於公司搜索業務的問題。在經歷了最近幾個季度的搜索改版後，我們應該如何看待未來的調整或變化？目前生成式人工智能結果在搜索結果中的佔比是多少，我們的目標佔比又是多少？另外，隨着人工智能整合的不斷深入，鑑於像 Deepseek 和豆包這樣的人工智能聊天機器人也具備搜索功能，能否分享更多關於用戶指標方面的信息？您如何看待百度搜索與這些人工智能聊天機器人之間的競爭態勢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;羅戎&lt;/strong&gt;：目前，約 22% 的搜索結果頁面包含人工智能生成的內容，但幕後還有更多的工作在進行，我們正在從根本上對搜索服務進行了變革，使其比以往任何時候都更強大、更高效。就像李彥宏在事先準備好的發言中提到的，藉助文心一言，我們將搜索範圍從文本和鏈接擴展到提供多樣化的內容形式，包括短視頻、直播、智能助理筆記和商品展示。這些不同的形式可以動態組合，創造出個性化的搜索體驗。在持續改革搜索產品的過程中，我們也在開發能實現更深度個性化的功能，以適應每位用戶的習慣和偏好。&lt;/p&gt; 
&lt;p&gt;我們的努力帶來了更好的用戶使用效果，包括在每月使用百度進行搜索的活躍用戶中，83% 的用戶會與生成式人工智能進行內容互動。更令我們倍受鼓舞的是，12 月百度應用上每位用戶的搜索查詢量同比增長了 2%。我們專注於不斷提升用戶體驗，考慮到用戶參與度日益積極，我們也會擴大人工智能的作用。&lt;/p&gt; 
&lt;p&gt;在此基礎上，我可以同大家分享一個文心一言智能助理如何在剛剛過去的春節假期為我們的廣告客戶創造價值的案例。春節期間，許多中小企業放假一週，但某些行業的客戶需求卻達到高峯。我們的文心一言智能助理有效地彌補了這一缺口。例如，一家助聽器公司因為家庭團聚，子女關心年邁父母的健康需求，諮詢量有所增加，但該公司的客服團隊因放假不在崗。通過文心一言智能助理，該公司有效地識別並篩選出高度相關的銷售線索，使其即便在假期人員減少的情況下，也能高效跟進並無縫服務客戶。&lt;/p&gt; 
&lt;p&gt;關於你提到的人工智能聊天機器人與搜索的問題，我們認為，由基礎模型驅動的人工智能革命仍處於非常早期的階段。無論是像 Deepseek 這樣原生的人工智能工具，還是我們基於人工智能的產品，這些努力都代表了探索人工智能潛力的不同方式。作為擁有數億用戶的中國搜索市場領導者，我們通過採用最優秀的創新成果並融入真正創新的人工智能功能，保持靈活性和全面的市場視野。百度將繼續引領人工智能變革，為我們龐大的用戶羣體提升搜索體驗。&lt;/p&gt; 
&lt;p&gt;此外，搜索本質上深深紮根於語言和文本理解，這與大語言模型的能力完美契合，使我們能夠在人工智能賦能的搜索變革中佔據領先地位。我們相信，搜索正在演變成一個集成平台，它超越了人工智能驅動的探索階段，不僅能提供智能答案，還能引導用戶完成整個流程，從尋找答案、進行深入分析、完成任務，最終提供全面的服務和解決方案。&lt;/p&gt; 
&lt;p&gt;雖然人工智能驅動的探索是人工智能應用開發的一個重要但仍處於早期發展的階段，目前尚未出現具有決定性影響力的應用程序，而對我們來説，關鍵是要保持這種快速且堅定的發展態勢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;摩根大通分析師 Alex Yao&lt;/strong&gt;：能否請管理層談談 2025 年第一季度和 2025 年全年核心廣告業務的增長前景？支撐這些預測的宏觀假設是什麼？我們看到業務在 2024 年第四季度觸底並開始復甦。最後一個問題是，生成式人工智能搜索的潛在盈利機會有哪些，預計何時能實現盈利？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;羅戎&lt;/strong&gt;：過去幾個月，我們看到各類支持政策相繼出台，比如貨幣寬鬆政策、財政政策以及貿易政策。我們相信這些舉措最終會推動經濟增長，但它們需要時間才能產生效果。鑑於百度的廣告業務與中小企業高度相關，而中小企業對宏觀經濟狀況尤為敏感，再加上競爭環境持續嚴峻，儘管短期內可能面臨壓力，我們還會繼續利用基礎模型對搜索進行變革，這些工作正在穩步推進。正如我們在事先準備的發言稿中提到的，相信這種人工智能變革將持續提升用戶體驗，並創造新的可能性。&lt;/p&gt; 
&lt;p&gt;本季度，我們進一步深化了搜索在人工智能方向的變革，用戶指標也出現了令人鼓舞的改善。我們認為這將推動收入增長，並在長期內開啓新的盈利機會。此外，我們尚未大規模實現人工智能生成搜索結果的盈利，目前這類結果約佔總查詢量的 22%，而一旦我們的人工智能驅動搜索功能得到充分優化，我們將憑藉更高質量的用戶產品推進盈利進程。基於這些因素，我們看到了未來增長的機會，判斷我們的廣告業務正在觸底。我們預計業務未來將逐步改善，今年上半年的表現會好於第四季度，下半年相比上半年會有進一步提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;摩根士丹利分析師 Gary Yu&lt;/strong&gt;：我的問題是關於人工智能雲服務的。鑑於公司人工智能雲業務增長強勁，我們能否期待該業務能夠在 2025 年繼續保持良好的發展態勢？在收入和盈利能力方面，其主要驅動因素是什麼？另外，管理層能否分享一下對 2025 年人工智能雲市場的展望？我們應如何看待企業雲服務需求？人工智能又給這一領域帶來了哪些新增機會？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;沈抖&lt;/strong&gt;：正如李彥宏前面提到的，我們人工智能雲業務的收入在 2024 年第四季度同比增長加速至 26% ，推動 2024 年全年收入增長 17%。值得注意的是，2024 年與生成式人工智能相關的收入同比增長近兩倍，這一增長得益於對文心一言和人工智能基礎設施的需求不斷上升，以及市場對百度在技術方面的領導力高度認可。因此，我們成功吸引了多樣化的客戶羣體，並建立了強大的潛在業務渠道。&lt;/p&gt; 
&lt;p&gt;在人工智能基礎設施方面，我們已與多個行業建立合作關係，涵蓋互聯網、汽車、智能設備、製造業、能源、金融、公用事業以及眾多人工智能生成內容初創企業。我們的客戶羣體持續健康增長，在大中型客戶中均取得顯著進展，這表明我們在中國雲市場的份額正在不斷擴大。&lt;/p&gt; 
&lt;p&gt;通過千帆大模型平台，我們為市場提供具有行業領先性價比的全面基礎模型。我們推出了從旗艦版到輕量版的文心大模型系列，旨在滿足各種不同的需求。除了文心大模型，我們還提供廣泛的優質第三方基礎模型，包括 DeepSeek V3 和 R1 模型。得益於百度的全棧人工智能能力和端到端優化，我們能夠確保平台上託管的任何模型都具備最佳性能和穩定性，同時保持極具競爭力的價格。此外，我們還提供一整套用於微調模型和構建原生人工智能應用程序的工具，客戶能夠輕鬆制定滿足自身特定需求的解決方案。&lt;/p&gt; 
&lt;p&gt;關於人工智能雲市場展望的問題，我們認為未來將迅速增長。一方面，在最近的春節假期期間，大語言模型成為了廣泛討論的話題，這不僅進一步提高了公眾對基礎模型的認知度，還促使更多人深入思考如何利用這些模型來提升自身業務。另一方面，我們相信基礎模型的性能將不斷提升，而成本會穩步下降，這無疑將進一步降低使用這些模型的門檻。因此，我們認為更多企業會將基礎模型整合到從研發到生產的業務運營各個環節，從而推動 API 調用量的顯著增長。&lt;/p&gt; 
&lt;p&gt;我們也預計百度人工智能雲服務的支出將會增加，因為過去我們已經觀察到一個明顯的趨勢：通過千帆大模型平台的 API 調用而使用基礎模型的客戶，也傾向於增加在我們人工智能雲服務上的支出。在利潤方面，由於我們專注於符合戰略重點的高價值機會，推動了穩健的可持續增長，我們 2024 年第四季度非通用會計準則下的運營利潤率持續同比擴大。展望 2025 年，我們有信心人工智能雲業務收入增長將保持強勁勢頭，同時繼續產生正的運營利潤。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;瑞銀證券分析師 Wei Xiong&lt;/strong&gt;：我想問一下利潤率趨勢的問題。鑑於核心廣告業務近期面臨的壓力以及雲業務收入佔比的不斷增加，我們應該如何看待 2025 年第一季度和全年的核心利潤率水平？在運營效率方面還有進一步優化的空間嗎？另外，公司全年有哪些投資計劃？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何俊傑&lt;/strong&gt;：儘管面臨短期壓力，但對於人工智能領域的戰略投資將產生更為可持續的影響方面，我們仍然非常樂觀。我們始終專注於提升業務運營各方面的韌性，並且在各項業務中都看到了令人鼓舞的進展。&lt;/p&gt; 
&lt;p&gt;首先，對於我們的在線營銷業務，預計受到人工智能生成搜索結果和技術變現計劃的推動，以及百度在捕捉增長機遇方面的準備和市場宏觀環境的改善，我們的廣告收入將逐步提升。其次，我們的人工智能雲業務已經展現出強勁的增長，隨着市場份額的不斷擴大，以及我們在自主研發獨特全層級人工智能架構和全棧人工智能能力方面的競爭優勢，利潤率得到持續改善，因此，我們有信心在未來保持這一強勁勢頭。第三，對於我們的智能駕駛業務，尤其是蘿蔔快跑，我們將繼續致力於通過提高運營效率和改善單位經濟效益來縮小虧損，我們也在探索創新的運營模式，包括輕資產模式。&lt;/p&gt; 
&lt;p&gt;關於你問到 2025 年的投資與優化情況，我們將保持對高增長機遇的最優資源配置，同時與我們的長期戰略保持一致。我們的投資將繼續聚焦於那些既擁有巨大未來機遇，又具備強大投資回報率潛力的項目，包括進一步提升盈利能⼒、深化搜索業務的人工智能轉型、增強我們的人工智能雲產品，以及拓展我們的自動駕駛項目。在推進這些項目的過程中，我們將繼續致力於提高運營效率，促進各業務集團之間的協同效應，以最大限度地發揮這些戰略投資的影響力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;美銀美林分析師 Miranda Zhuang&lt;/strong&gt;：我有一個關於蘿蔔快跑業務的問題。管理層能否介紹一下 2025 年該業務的進展情況，包括車隊規模目標、能夠貢獻哪些獨特的經濟效益，以及業務的價值主張是什麼？管理層認為行業目前處於什麼階段？我們是否正在接近一個轉折點？鑑於國內自動駕駛出租車市場上的競爭對手正在與汽車製造商和打車平台合作，採用生態系統戰略，管理層對於接下來該行業的競爭態勢有何看法？請問百度的競爭和規模化策略是什麼？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李彥宏&lt;/strong&gt;：我們在自動駕駛技術領域已經投入了十多年，通過蘿蔔快跑，我們將宏偉願景變為了現實，確立了公司在自動駕駛技術領域的全球領先地位。中國的自動駕駛市場環境是非常具有挑戰性的，由於中國人口眾多、路況多樣、交通場景動態變化以及城市佈局繁複，其交通狀況是非常複雜的，而在中國乘坐自動駕駛出租車的價格約為美國的七分之一。因此，我們在中國的成功運營展示了百度卓越的技術和運營能力，包括我們所設計的全新第六代量產無人車 RT6，是世界上有史以來最具成本效益的自動駕駛出租車。憑藉我們的這些優勢，這一商業模式得到成功驗證，併為進一步規模化發展和全球擴張奠定了堅實基礎。&lt;/p&gt; 
&lt;p&gt;在第四季度，蘿蔔快跑在全國範圍內提供了約 110 萬次出行服務，同比增長 36%。到 1 月份，向公眾提供的累計出行服務次數已超過 900 萬次。此外，正如我之前提到的，我們在中國實現了 100% 完全無人駕駛運營，這意味着車輛上不再配備安全員，這是一個新的行業標杆，鞏固了我們在該領域的領先地位。正如我之前提到的，去年 11 月，自動駕駛業務獲得批准在香港開始開放道路測試，這是非常重要的一步，因為香港是我們首個右舵駕駛和靠左行駛的交通市場。這表明我們有能力使自動駕駛技術適應不同的交通系統，為拓展到其他具有類似駕駛設置的市場打開了大門。&lt;/p&gt; 
&lt;p&gt;今年對我們的業務拓展至關重要，隨着業務的推進，預計車隊規模和出行服務量的增長速度將超過以往任何時候。同時，我們也在積極尋找合作機會，我們已經確定了各種潛在合作伙伴，包括出行服務提供商、當地出租車公司、第三方車隊運營商以及其他潛在合作伙伴，這種輕資產模式將使我們能夠高效擴大規模，同時保持靈活性。通過與不同類型的合作伙伴合作，我們旨在加強市場地位，讓更多人體驗到自動駕駛服務。從更廣闊的市場來看，正如我在上次財報電話會議中提到的，由於市場仍處於起步階段，競爭實際上有助於加速市場發展，並營造更有利於創新的監管環境。在這個不斷增長的市場中，我們的使命始終明確，那就是為更多用戶提供更安全、便捷和舒適的出行體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;傑富瑞分析師 Thomas Chong&lt;/strong&gt;：展望 2025 年，百度業務投資的戰略重點會是什麼？具體而言，資源將如何在搜索、自動駕駛、雲服務和基礎模型之間分配？此外，管理層對 2025 年全年的資本支出以及股東回報有何展望？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何俊傑&lt;/strong&gt;：在評估 2025 年的資本配置選項時，我們的方法基於以下戰略考量。我們將繼續把提升人工智能能力作為長期戰略重點進行投資。在此基礎上，我們將進一步深化全產品線的人工智能轉型，尤其是搜索業務。在人工智能雲業務方面，我們旨在推動企業客戶採用我們的人工智能基礎設施、飛槳（PaddlePaddle）深度學習平台以及文心一言，滿足他們對人工智能產品和解決方案以及人工智能雲服務日益增長的需求。在智能駕駛方面，我們專注於擴大國內業務規模，探索創新運營模式，並拓展國際業務。&lt;/p&gt; 
&lt;p&gt;在確保嚴格的投資回報率管理和有效控制資本支出損失的同時，有兩個關鍵優先事項驅動我們的決策，那就是強化我們的技術領先地位，以及加速人工智能產品和人工智能雲服務在不同行業的應用。至於你問到的股東回報，自 2024 年初以來，我們的股票回購金額已超過 10 億美元，這顯著高於 2023 年全年的回購總額。對於截至 2025 年 12 月，規模為 50 億美元的股票回購計劃，我們總計已回購 17 億美元。展望未來，作為持續回報股東長期信任的舉措之一，我們計劃加快股票回購計劃的推進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334727</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334727</guid>
            <pubDate>Wed, 19 Feb 2025 07:17:09 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技申請春晚機器人圖形商標</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，2 月 5 日，杭州宇樹科技有限公司申請註冊一枚「春晚機器人」樣式圖形商標，國際分類為廚房潔具，當前商標狀態為等待實質審查。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;269&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bc4fda9d3052fe48a476a7f163206880819.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;杭州宇樹科技有限公司成立於 2016 年 8 月，法定代表人為王興興，註冊資本約 259 萬人民幣，並已於 2024 年完成了 C 輪，交易金額數億人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;經營範圍包括智能機器人的研發、智能機器人銷售、工業機器人制造、工業機器人銷售等，由王興興、漢海信息技術（上海）有限公司、寧波紅杉科盛股權投資合夥企業（有限合夥）等共同持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，宇樹科技有四足機器狗和通用人形機器人兩大系列產品。在創業早期，宇樹科技以四足機器狗起家，第一款產品為 XDog。隨後，Laikago、AlienGo、A1、Go1、B1 等一系列機器狗產品相繼研發問世，推出市場。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334724</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334724</guid>
            <pubDate>Wed, 19 Feb 2025 07:15:09 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Omdia：2029 年電信 IT 人工智能軟件市場達 50 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究機構 Omdia 最新發布了一份《電信 IT 人工智能市場預測》報告，展示了 Omdia 對於在跟蹤的電信 IT 軟件的五個主要產品類別中 AI 所佔價值的估算。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Omdia 觀點：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們估計，2023 年，電信 IT 軟件中 AI 的價值為 18 億美元，而且我們預測，到 2024 年底，其價值會達到 23 億美元。從 2024 年至 2029 年，整體價值會以 17% 的複合年增長率（CAGR）增長，達到 50 億美元。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;233&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-175f0c5940f60ad73ea3821a680982bf8f1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;預測性 AI 將佔整個預測期中大部分價值，於 2029 年達到總價值的 76%。在預測期期間，預測性 AI 將以 13% 的 CAGR 增長。然而，生成式 AI 會增長得更快，CAGR 為 37%，到 2029 年佔電信 IT 軟件中 AI 價值的 24%。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本預測的前幾年將由自動化和相關用例驅動，相比於預計到預測期末會更普遍的推薦和預測用例，這些用例相對價值更低。消費者互動和網絡管理將佔大部分的增長，因為 AI 已經在這些細分市場獲得關注，也正在推動運營效率提升，CSP 可以在此基礎上再接再厲。在沒有 AI 益處的情況下，分析已經能夠完成很多任務，所以其增長會稍慢一點。目前 AI 對於創收和服務管理的作用更加受限，並且我們預測，在預測期期間這些細分市場的增長最低。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334718</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334718</guid>
            <pubDate>Wed, 19 Feb 2025 06:54:09 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 年中國在開源人工智能模型領域的崛起和變革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;報告地址：&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
&lt;p&gt;在第二章《TOP 101-2024 大模型觀點》中，Hugging Face 工程師 &lt;strong&gt;Tiezhen&lt;/strong&gt;、Hugging Face 中文社區項目經理 &lt;strong&gt;Adina &lt;/strong&gt;以及 Hugging Face Fellow &lt;strong&gt;Lu Cheng&lt;/strong&gt;，從崛起與變革兩個維度，探討中國開源模型在 2024 年取得的重大成就和未來展望：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國在開源人工智能模型領域從 「追隨者」 到 「引領者」 轉變，體現技術實力且反映人工智能生態系統快速完善。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國學術界和產業界推進自主研發，在技術創新和模型能力上飛躍，多款自主研發模型在國內外評測表現卓越。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen 系列因多尺寸選項、多語言支持及友好授權功能獲高度評價；DeepSeek 引入 MLA 技術實現性能成本突破；智譜 CogVideoX 系列成全球首批開源文生視頻模型之一。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源模型從質疑中崛起獲廣泛認可，其成功得益於政府支持與行業鉅額投入，中國人工智能生態體系迅速完善，未來可能在全球佔更核心地位。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隨着開源模型影響力提高，中國開源社區活躍度提升，企業、研究機構、個體開發者積極參與，如 Qwen 系列被廣泛集成促進交流協作，智源研究院等機構建立協作機制貢獻基礎工作和資源。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國開源社區湧現高質量自發研究成果，如 MAP 團隊的 Map Neo、InstantX 團隊的 InstantID，為中國模型贏得國際認可。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國在推動人工智能技術發展同時建立完善透明治理機制，如《人工智能示範法 2.0（專家建議稿）》《生成式人工智能服務管理暫行辦法》，為開源模型發展提供穩定政策環境並確保技術應用符合社會價值導向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;端上模型興起，中國 AI 社區推出多款移動友好型模型，如 Qwen2 - 1.5B 等，雖有挑戰但代表 AI 技術隱私保護和成本優化未來方向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源社區在邏輯推理領域推出創新項目，如 Macro - o1、QwQ 等，通過開源策略分享研究細節，推動小模型推理能力提升與行業技術進步。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源模型發展從 「百模大戰」 邁向多元化和深度細分，發佈大量高質量開源模型，涵蓋多模態理解與生成等多個領域，模型競爭轉向應用場景細化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/135245_kWl7_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;完整全文：&lt;a href=&quot;https://my.oschina.net/u/3859945/blog/17503717&quot; target=&quot;_blank&quot;&gt;https://my.oschina.net/u/3859945/blog/17503717&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334705</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334705</guid>
            <pubDate>Sat, 08 Feb 2025 05:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 將在 4 月底舉辦首屆 AI 開發者大會 LlamaCon</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Meta&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llama.com%2Fevents%2Fllamacon%2Fsignup%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;將在今年 4 月 29 日舉行首屆 LlamaCon——專門面向生成式人工智能的開發者大會。大會的名字源於 Meta 的開源 AI 模型 Llama 系列。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-26ace593ef0174eac7b8b3e6bcbe581ade6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Meta&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.meta.com%2Fblog%2Ffuture-of-ai-built-with-llama%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，隨着開源 Llama 模型和工具集合的空前增長和發展勢頭強勁，公司決定於 4 月 29 日舉行首屆專門面向 AI 領域的開發者大會 LlamaCon。他們將&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;在大會上分享開源 AI 發展的最新動態，來幫助開發者構建「令人驚歎的應用和產品」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;在接下來的幾周裏，Meta 也將公佈更多與 LlamaCon 有關的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在 1 月底的財報説明會上，扎克伯格曾表示，Llama 4 的目標是引領（市場），具備原生的多模態能力。他當時也暗示 Llama 4 最早也要到今年二季度才會發佈，所以 4 月 29 日會是一個較為合適的日期。&lt;/p&gt; 
&lt;p&gt;留出兩個月的時間，也給 Meta 公司帶來了不確定性。目前 OpenAI 已經確認會在近期發佈 GPT-4.5、Anthropic 也被爆料將在「數週內」發佈混合 AI 模型 Claude 4。&lt;/p&gt; 
&lt;p&gt;最令 Meta 忌憚的是，DeepSeek 是否會在未來兩個月裏搞出更多的「大新聞」。&lt;/p&gt; 
&lt;p&gt;據報道，在 DeepSeek 發佈 R1 模型之後，Meta 迅速組建了四個「戰情室」，核心憂慮是 DeepSeek 的最新大模型可能會比 Llama AI 的下一代版本更強。&lt;/p&gt; 
&lt;p&gt;知情員工透露，四個「戰情室」中有兩個負責研究 DeepSeek 如何降低訓練和運行 AI 模型的成本，並將心得用於訓練 Llama。另外兩個團隊，負責嘗試找出 DeepSeek 用於訓練的數據，以及如何將中國 AI 的先進訓練方法用於重構 Meta 自己的產品。&lt;/p&gt; 
&lt;p&gt;在分析師電話會議上，扎克伯格曾表示：「他們（DeepSeek）做了一些新穎的事情，我認為我們仍在消化中。他們取得的一些進展，我們希望在我們的系統中應用，這就是開源世界運作的本質。」&lt;/p&gt; 
&lt;p&gt;與此同時，扎克伯格也已經宣佈，今年將在人工智能相關的項目上投資 600-650 億美元，包括建設一個超大型數據中心和更多的人才招聘。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334689/meta-llamacon-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334689/meta-llamacon-2025</guid>
            <pubDate>Sat, 08 Feb 2025 04:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 前 CTO 官宣新創業 AI 公司，團隊成員多來自 OpenAI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 前 CTO Mira Murati 今天凌晨&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmiramurati%2Fstatus%2F1891918876029616494&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;創立了新的 AI 公司 Thinking Machines Lab（思維機器實驗室）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d07fc6d37ca4e1534888a3ca6098802c5d2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthinkingmachines.ai%2F&quot; target=&quot;_blank&quot;&gt;官網寫道&lt;/a&gt;，公司將專注於構建人工智能（AI）模型和產品，以支持更多、跨工作領域的「人類-AI 協作」，「雖然當前的系統擅長編程和數學，但我們正在構建能夠適應人類所有專業知識並實現更廣泛應用的人工智能。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;他們還強調這會是一家重視研究開放的公司，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fthinkymachines%2Fstatus%2F1891919141151572094&quot; target=&quot;_blank&quot;&gt;其推文中承諾&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我們致力於通過論文發表和代碼發佈來開放科學，同時會重點關注應用於不同領域的人機協作。我們的方法包括共同設計研究和產品，以便從實際部署和快速迭代中學習。這項工作需要三個核心基礎：&lt;strong&gt;SOTA 的模型智能、高質量的基礎設施和先進的多模態能力&lt;/strong&gt;。我們致力於構建處於能力領先的模型來兌現這一承諾。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該公司官方網站對這三核心基礎進行了展開説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;模型智能是基石。除了強調人機協作和定製之外，模型智能也至關重要，我們正為科學和編程等領域構建前沿能力模型。最終，最先進的模型將解鎖最具變革性的應用和優勢，例如實現新穎的科學發現和工程突破。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基礎設施質量是重中之重。研究生產力至關重要，在很大程度上取決於基礎設施的可靠性、效率和易用性。我們的目標是長期正確地構建事物，以最大限度地提高生產力和安全性，而不是走捷徑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;先進的多模態能力。我們認為多模態對於實現更自然、更高效的通信、保存更多信息、更好地捕捉意圖以及支持與現實環境的更深入集成至關重要。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;官網貼出了公司 29 人團隊名單，其中超過 20 人有在 OpenAI 供職的經驗。其中較為知名的有 OpenAI 聯合創始人約翰·舒爾曼（John Schulman），他正擔任新公司的首席科學家。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334684</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334684</guid>
            <pubDate>Sat, 08 Feb 2025 03:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>沒有所謂的 1875 紀元，美國 150 多歲老人領社保福利不是 COBOL 語言的鍋</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期，一位美國政府官員曾宣稱：「我們這裏有些人看起來都已經 150 歲了」，並指出這些人正在領取社會保障福利。由此，有人開始流傳這樣一種説法：社會保障局（SSA）在存儲日期時使用了一個 1875 年的紀元，把那些未知出生年份的記錄存為 0，從而默認顯示為 1875 年。&lt;/p&gt; 
&lt;p&gt;這種觀點的起源可以追溯到某個帖子，帖子中有人調侃道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「看起來埃隆那羣天才程序員根本就不懂 COBOL 的工作原理。社會保障系統正是運行在 COBOL 上，而 COBOL 並沒有專門的日期或時間類型。於是日期就以數字形式存儲，按照 ISO 8601 標準計算，紀元定在了 150 年前（1875 年）——也就是米制標準的開始。結果如果不知道某個日期，就會存儲成 0，而在 COBOL 中這就會默認解析為 1875 年，也就是 150 年前。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;1668&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/112214_BPqK_3820517.png&quot; width=&quot;1198&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然而，筆者對此並不認同，主要基於以下幾點理由：&lt;/p&gt; 
&lt;h2&gt;數據庫中存在 1875 年前的出生年份&lt;/h2&gt; 
&lt;p&gt;2007 年，社會保障局曾發佈過一份數據集，該數據集包含了在 2007 年 1 月之前發放的社會保障號碼持有者的收入記錄（約佔全部數據的 1%）。在這份數據集中，他們明確説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;移除了出生年份早於 1870 年的 5,935 條記錄&lt;/li&gt; 
 &lt;li&gt;移除了出生年份等於 2007 的 1,096 條記錄&lt;/li&gt; 
 &lt;li&gt;以及少數缺失出生年份的記錄&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這表明，SSA 的數據庫中確實保存了 1875 年前（甚至 1869 年及更早）的出生年份數據，並非將未知年份一律默認為 1875。&lt;/p&gt; 
&lt;h2&gt;數據中沒有 1875 年出生人數激增的異常&lt;/h2&gt; 
&lt;p&gt;如果系統將所有未知出生年份的記錄默認轉換為 1875 年，那麼在統計數據中，1875 年的出生人數應該會異常增多。但實際上，從公開數據來看，並不存在這樣一個「高峯」。（注：該數據集只是 1% 的樣本，若存在默認值問題，趨勢應當更加明顯。）&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;698&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/112303_XwHt_3820517.png&quot; width=&quot;1174&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;社會保障局並未使用 ISO 8601 標準存儲日期&lt;/h2&gt; 
&lt;p&gt;負責跟蹤社會保障福利支付的主記錄（Master Beneficiary Record, MBR）建立於 1962 年，這遠早於 ISO 8601 標準於 1988 年的發佈。即便是其前身 ISO 2016 標準也在 1976 年發佈，並且並沒有任何依據指向 1875 年。實際上，有研究論文基於 SSA 數據指出，SSA 對生日等信息的存儲採用的是固定寬度格式，而不是 ISO 8601 標準的日期字符串格式。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;The data abstracted from the MBR consisted of a 26-character record for each deceased individual. The four data items on each record were… the month and year of death&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ISO 8601 標準本身並不涉及紀元概念&lt;/h2&gt; 
&lt;p&gt;ISO 8601 僅僅是一種用於表示日期和時間的字符串格式，其本質並不是基於數字計算時間流逝，因此根本無需設定一個「紀元」。雖然 ISO 8601:2004 版曾固定引用 1875 年 5 月 20 日——即《米制公約》在巴黎簽署的那一天——作為參考日期，但這一引用在 ISO 8601-1:2019 版中已被移除。換句話説，這個日期僅用於定義格里高利曆，並非作為一個時間計數的起點。&lt;/p&gt; 
&lt;h2&gt;沒有任何證據顯示 1875 年被用作時間計算的起點&lt;/h2&gt; 
&lt;p&gt;經過查找，筆者沒有發現任何系統或標準會將 1875 年作為時間紀元。尤其在 COBOL 語言中，也沒有這樣的約定或實踐。所有跡象都表明，所謂的「1875 紀元」只是個誤解。&lt;/p&gt; 
&lt;p&gt;總的來説，從 SSA 的數據實踐、存儲方式以及國際標準的角度來看，都沒有任何證據支持「1875 紀元」這一説法。該觀點看似有趣，但實際上缺乏堅實的依據。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fiter.ca%2Fpost%2F1875-epoch%2F&quot; target=&quot;_blank&quot;&gt;https://iter.ca/post/1875-epoch&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334682/1875-epoch-cobol-150-american</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334682/1875-epoch-cobol-150-american</guid>
            <pubDate>Sat, 08 Feb 2025 03:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>沒有處理過遺留項目，別自稱資深工程師</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家都不喜歡維護遺留項目，我也不例外。命運總愛跟人開玩笑，最近一個遺留項目正好落到了我手上。雖然在這個項目上工作的經歷並沒有減少我對遺留系統的厭惡，反而讓我對當下所採用的流程與實踐有了更深刻的認識。&lt;/p&gt; 
&lt;p&gt;我為自己所在的團隊感到自豪，因為我們遵循了許多業界最佳實踐：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;編寫簡潔且易維護的代碼，並配以自動化測試&lt;/li&gt; 
 &lt;li&gt;積極參與代碼合併請求和任務評審&lt;/li&gt; 
 &lt;li&gt;合併到主分支後，當天就能將應用推向生產環境&lt;/li&gt; 
 &lt;li&gt;高度採用敏捷開發模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;當然，一切並非盡善盡美。合併請求中偶爾會出現一些無關痛癢的建議和討論；運維團隊有時也會搞砸一些事情（至少在我們開發人員看來是這樣）；而產品負責人也時不時催促我們加快推出某些「簡單」的新功能……總的來説，情況還算不錯。&lt;/p&gt; 
&lt;h2&gt;穿越回 Ant 時代&lt;/h2&gt; 
&lt;p&gt;由於團隊表現出色，公司決定將我們的開發效率借調給另一個由其他部門負責的產品。令我們略感失望的是，這個項目不僅使用的是較老版本的 Java，其代碼風格也與我們的習慣大相徑庭。&lt;/p&gt; 
&lt;p&gt;任務要求我們添加幾個簡單的監控指標，比如應用是否正常運行、運行時長、數據處理是否足夠迅速等。由於項目正處於維護模式，已經有段時間沒有添加新功能了。按理説，添加這些指標對我們來説應該是小菜一碟。&lt;/p&gt; 
&lt;p&gt;然而，當我們捲起袖子開始工作時，首先發現這個項目竟然使用了一種非常古老的構建方式——Ant 構建文件。那是一種龐大的 XML 文件，詳細描述瞭如何構建整個項目：從編譯、測試到打包，每個環節都必須顯式配置，包括源碼路徑、目標路徑以及資源位置。過去，這種做法在許多編程語言中都很常見：寫好一個構建文件，複製到每個新項目中，再不斷調整直至適應新項目需求。&lt;/p&gt; 
&lt;p&gt;例如，一個簡單的「Hello World」項目的 Ant 構建文件可能如下所示：&lt;/p&gt; 
&lt;pre&gt;&amp;lt;project&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;clean&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;delete dir=&quot;build&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;compile&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;mkdir dir=&quot;build/classes&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;javac srcdir=&quot;src&quot; destdir=&quot;build/classes&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;jar&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;mkdir dir=&quot;build/jar&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;jar destfile=&quot;build/jar/HelloWorld.jar&quot; basedir=&quot;build/classes&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;manifest&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;attribute name=&quot;Main-Class&quot; value=&quot;oata.HelloWorld&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;/manifest&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;/jar&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;run&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;java jar=&quot;build/jar/HelloWorld.jar&quot; fork=&quot;true&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/pre&gt; 
&lt;p&gt;難道就沒有更便捷的方式嗎？正因如此，「約定優於配置」的理念應運而生。這一理念主張：開發者只需關心那些偏離約定的特殊情況，而現代構建工具正是基於這一思想，通過提供可覆蓋的默認配置，免去了重複配置的麻煩。正因為如此，大多數 Java 源碼統一存放在 &lt;code&gt;src/main/java&lt;/code&gt; 目錄下，而編譯後的文件則放在 &lt;code&gt;target&lt;/code&gt; 目錄中，避免了繁瑣的重複設置。&lt;/p&gt; 
&lt;p&gt;這一發現啓發了我們：或許同樣的原則也能應用到我們當前項目中的應用配置上。面對一個龐大且大部分數值雷同（如應用端口）的配置文件，採用默認值機制無疑能讓配置文件變得更精簡。&lt;/p&gt; 
&lt;h2&gt;被我們視為理所當然的事情&lt;/h2&gt; 
&lt;p&gt;回到遺留項目，我們順利構建並打包了應用！那枯燥的部分終於過去，可以安心開始編碼了。但問題隨之而來：如何將我們負責監控的指標組件嵌入到這套老舊的代碼庫中？在我們的常規開發框架中，這一切通常是自動處理的，因此我們一度認為這毫不費事。&lt;/p&gt; 
&lt;p&gt;但實際上，將指標組件「注入」到遺留代碼的各個角落，最佳方案是什麼呢？初看起來，單例模式似乎是最簡單的選擇；不過，開發社區普遍認為單例是一種反模式。為什麼呢？畢竟，我們鍾愛的某某框架不也依賴單例嗎？如果不是，那它到底採用了什麼機制？依賴注入究竟是什麼？其底層又是如何運作的？&lt;/p&gt; 
&lt;p&gt;這一連串問題促使我們重新審視那些一直視為理所當然的基本概念。雖然在這種情況下使用單例並非最糟，因為代碼大部分缺乏單元測試，但要讓我們心安理得，代碼必須經得起推敲。經過嘗試，我們最終採用了一種不同的方案，寫出了既簡潔又清晰的代碼——既沒有依賴單例，也未引入多餘的抽象層。&lt;/p&gt; 
&lt;h2&gt;開發者角色的侷限性&lt;/h2&gt; 
&lt;p&gt;項目的最後一步是部署，只有部署成功後才能進行測試。但問題來了——這一次，我們既不負責部署，也不負責測試。部署工作由運維團隊完成，而測試則交由專門的測試團隊。為什麼開發者就不能全程掌控，從開發到上線，而要先提交工單，再等待其他團隊的配合呢？&lt;/p&gt; 
&lt;p&gt;首先，由於代碼測試覆蓋率不足，手動測試不可避免；其次，公司的基礎設施也不允許我們自行部署應用。&lt;/p&gt; 
&lt;p&gt;這一系列經歷使我們開始思考職責分離的原因，以及現行模式為何更為合理。事實證明，這個項目的任務交付時間和迭代週期遠遠超過平時（通常幾天就能交付的工作，此次竟拖延了數週），這無疑驗證了分工合作的必要性。&lt;/p&gt; 
&lt;h2&gt;通過舊實踐理解現代方法&lt;/h2&gt; 
&lt;p&gt;到了月底，我們的監控指標終於在生產環境中順利運行。雖然我對遺留項目的看法依舊——我仍然討厭它們，也不奢望你會因此改變看法——但這段經歷給了我們寶貴的啓示。&lt;/p&gt; 
&lt;p&gt;我們無法選擇所分配到的項目，但我們可以調整對待遺留系統的態度。與其心存無奈，不如把它當作一個提問、學習與成長的機會。通過瞭解過去的做法及其侷限，我們不僅掌握了當下的最佳實踐，更獲得了背後歷史的寶貴經驗。&lt;/p&gt; 
&lt;p&gt;一旦你積累了這種深厚的知識，其他開發者自然會認可並信賴你的專業能力。如果你希望成為這樣的人，就得勇於鑽研那些看似繁瑣的遺留項目。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infobip.com%2Fdevelopers%2Fblog%2Fseniors-working-on-a-legacy-project&quot; target=&quot;_blank&quot;&gt;https://www.infobip.com/developers/blog/seniors-working-on-a-legacy-project&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;作者：Alen Kosanovic&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334678/seniors-working-on-a-legacy-project</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334678/seniors-working-on-a-legacy-project</guid>
            <pubDate>Sat, 08 Feb 2025 03:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Grok 3 是否意味着大力出奇跡的大模型法則仍然成立？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文轉載自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F24609799526&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/24609799526&lt;/a&gt;&lt;br&gt; 作者：張俊林（中科院軟件所，博士）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;媒體風向變化太快，讓人目不暇接。早上還在誇 Deepseek 成本低，性價比高，預訓練 Scaling Law 死了，不需要太多機器和 GPU 卡，性價比優先，英偉達休矣；中午 Grok 3 一出來，説是用了 10 萬張英偉達 H100 卡，效果力壓 OpenAIo3 mini 和 Deepseek R1，就轉向説 Scaling law 還成立，還需要大量的卡，英偉達股價有救了，還是要大力出奇跡……&lt;/p&gt; 
&lt;p&gt;這兩個觀點明顯對立，有一真必有一假，那事實的真相到底是啥呢？我們來推一推。&lt;/p&gt; 
&lt;h2&gt;一、預訓練階段的 Scaling Law 是否仍然成立&lt;/h2&gt; 
&lt;p&gt;-預訓練階段的 Scaling Law 成立嗎？當然是成立的，所謂「Scaling Law 撞牆」，大家普遍遇到的問題是數據不夠了，沒有大量新數據，導致預訓練階段的 Scaling Law 走勢趨緩，注意是趨緩但不是停頓，預訓練階段的 Scaling Law 並沒到天花板。按照 Chinchilla Scaling Law 推斷，即使沒有新數據，也並不意味着模型效果提不上去了，很簡單，只要增加基座模型尺寸，效果仍然會提高，只是從付出的算力和獲得的效果提升來説很不合算，性價比過低，這是為何大家轉到 RL Scaling Law 和 Test Time Scaling Law 的原因，是因為付出同樣的算力，在後面兩個階段大模型智商提升更明顯，就是性價比高。&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;目前可以提高模型效果的 Scaling 方法，按照性價比由高到低排序的話: Test time Scaling Law&amp;gt; RL Scaling Law&amp;gt;預訓練階段 Scaling Law(數據不夠了，只能推大模型尺寸)&lt;/strong&gt;，有性價比高的 Scaling，當然優先做這種，性價比低的 Scaling，只有在沒有性價比更高的情況下才會採用。這跟購物一個道理，有性價比高的當然不會去買性價比低的商品。&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;如果哪天 RL Scaling Law 和 Test Time Scaling Law 到了天花板，又沒有找到新的性價比更合算的 Scaling law，也不是説模型效果就提不上去了，大家仍然可以迴歸預訓練階段的 Scaling Law，沒有新數據也沒關係，推大模型尺寸規模就可以，效果仍然會上升&lt;/strong&gt;。但這基本是最後的選擇，沒辦法的辦法，只要有性價比高的方法就不會走這條路。&lt;/p&gt; 
&lt;p&gt;-有人問了：那按照你的意思，囤那麼多 GPU 算力，其實對訓最好的模型也沒啥用？要是按照上面的理論，那確實是沒有太大必要，比如 Deepseek 2000 卡也可以作出最好的模型不是。但是卡多有個好處，就是能壓縮實驗新想法和訓練大模型基座的時間週期。比如你總得探索一些不同的算法、參數或數據配比的模型進行各種實驗，你有 10 個新想法，如果只有 2000 張卡，可能得跑 5 天才能得出結論，要是有幾萬張卡，可能 1 天就能得出結論，所以卡多對於探索效率是有極大幫助的。卡多創新多，這點肯定成立。&lt;/p&gt; 
&lt;h2&gt;二、Grok 3 基座模型（對標 Deepseek V3，非 R1 這種邏輯推理模型）&lt;/h2&gt; 
&lt;p&gt;-為何 Grok 3 作為通用基座模型，它的評測指標只有數學、科學和代碼數據集？沒有通用能力比如最常用的 MMLU 指標的對比，這是不太規範的對比模式。推斷可能 Grok 3 的通用能力相對 OpenAI 和 Deepseek 的模型沒有大幅提升，所以不拿出來比？&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;如果想要提升基座模型的數學、科學和代碼能力，無論從方法還是從成本角度來講，難度並不大，目前比較標準的做法是類似 Deepseek V3 從 Deepseek R1 蒸餾數學、代碼等邏輯題的長 COT 數據，即深度思考過程數據，就是説把深度思考長 COT 數據引入基座的 Post-Training 階段、甚至前置到預訓練階段（所謂大模型「左腳（Deepseek 基座）踩右腳（Deepseek R1）自我飛昇」的模式），這樣就能大幅提升基座模型在數學和代碼方面相關的能力，也就是 Grok3 宣傳具備的「有思維鏈推理和自我糾錯機制」，評測指標看着會比較好看，而且蒸餾的數據總量也不會太大（幾百 B 級別應該夠了），成本很低，對算力要求不高。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;-OpenAI 很快會發布的非邏輯推理模型 GPT 4.5，大概也應是類似的思路，從 o3 模型蒸餾 COT 數據，用深度思考數據來提升 GPT 4.5 基座模型的智商，大模型「左腳踩右腳自我飛昇」大法，這會是之後基座模型提升能力的主要手段。&lt;/p&gt; 
&lt;p&gt;-Grok 3 的算力消耗是 Grok 2 的 10 倍，如果遵照 Chinchilla Scaling Law，最佳做法是 Grok 3 的訓練數據量比 Grok 2 增加 3 倍，模型大小同時比 Grok 2 增加 3 倍（但是目前的趨勢是減小模型大小，增大數據量[就是説「小模型大數據」的模式]，儘管這樣不滿足訓練最優原則，但因為模型尺寸小了，所以這種模型更適合在線推理服務，降低服務成本）。&lt;/p&gt; 
&lt;p&gt;-如果像發佈會宣稱的，Grok 3 耗費算力是 Grok 2 的 10 倍消息為真的話，那有兩種可能。一種是數據量增長極大，這樣只能是增加了大量多模態數據，比如數據量從 10T 增長到 30T（目前文本模型使用的數據量，最多到 18T 到 20T 之間，基本到頂，再多沒有了，要大幅增加只能加多模態數據，但是增加多模態數據對提升大模型智商幫助不大，所以這個增量按理説不應該太大），如果這樣推算，Grok3 的模型規模增長 3 倍左右；第二種可能是訓練數據量比 20T 增加的不多，如果這樣可以推出 Grok3 模型尺寸比 Grok 2 要大很多，至少 4 到 5 倍起步（若新增數據不多，那隻能靠增加模型尺寸來消耗新增算力）。不論是哪種可能，Grok 3 的模型大小肯定比 Grok 2 大了很多，而 Grok 2 模型本身可能就不小（Grok 2 發佈網頁評測效果超過 Llama 3.1405B，所以無論數據還是模型大小，都不會太小，要是 Dense 模型， 70B 是最小的估計了），&lt;strong&gt;所以 Grok 3 的尺寸規模很可能不是一般的大&lt;/strong&gt;（感覺在 200B 到 500B 之間）。&lt;/p&gt; 
&lt;p&gt;-很明顯，Grok 3 仍然在採取推大基座模型尺寸的「傳統」做法，也就是上面「Scaling Law」部分分析的預訓練階段增大模型尺寸的方法來提升基座模型能力，上面分析過，這種做法是性價比很低的。比較時髦的做法是把訓練重心放在 RL Scaling 方面，性價比會高太多。但是為啥他要做這種賠本買賣呢？在後面會給出一個可能的解釋。&lt;/p&gt; 
&lt;h2&gt;三、Grok 3 邏輯推理版本 (深度思考版本，對標 Deepseek R1)&lt;/h2&gt; 
&lt;p&gt;-Grok 3 的深度思考版本，不説體驗，單從評測指標看，達到或者超過了 o3 mini，確實是目前效果最好的，或者説最好的之一沒有什麼問題。&lt;/p&gt; 
&lt;p&gt;-説回上面提到的問題，為啥明知靠推大預訓練階段模型尺寸規模性價比低，Grok 3 還要用這種模式呢？很可能內在的原因在於（推斷無證據）：&lt;strong&gt;Post-Training 階段採取 RL Scaling，其效果可能跟基座模型的大小是有正相關關係的，就是説，同樣的 RL 階段的算力消耗，如果基座模型尺寸更大，則 RL 階段的 Scaling 效果越好。&lt;/strong&gt;只有這樣，才有在預訓練階段儘量把模型規模推大的必要性。而我們可以假設，Grok 3 之所以採取這種過於耗費算力，看着性價比不高的方式，是希望通過加大基座，把深度思考版本的能力明顯提起來。&lt;/p&gt; 
&lt;p&gt;-貌似 Deepseek R1 效果很好又開源，獲得一片好評，但大家想要實際用起來，會發現基座太大，部署難度和消耗資源太高，對下游應用不太友好。那為啥 Deepseek 非得推這種對下游應用來説明顯過大的模型呢？（小點的蒸餾模型看着指標很好，但是實際應用效果貌似差不少），是否也是因為基座模型如果不夠大，深度思考模型效果就沒那麼好的原因？&lt;/p&gt; 
&lt;p&gt;-如果上述假設成立，那意味着：&lt;strong&gt;三個 Scaling Law(Pre-train、RL 、Test Time)，從提高大模型智商的性價比來説，由高到低是：Test Time &amp;gt; RL &amp;gt; Pre-Train，這個是之前的結論。但如果上述假設成立，説明 Test Time Scaling 的天花板最低，它的天花板依賴於 RL 階段的 Scaling 能力，而 RL 階段 Scaling 天花板次低，它的天花板依賴於預訓練階段 Pre-Train 的 Scaling？&lt;/strong&gt;如果這樣，如果有一天當 RL 和 Test Time 天花板到頂，意味着我們可以再啓動一輪，去推大基座模型的模型尺寸，RL 階段 Scaling 的天花板隨之升高，然後可以再去 Scale RL 和 Test Time，就進一步得到智商更高的大模型。如果這成立，那意味着 AGI 的解決方案已經完整了？其實不需要新的 Scaling Law 存在就夠？&lt;/p&gt; 
&lt;p&gt;-上述推論，是在一個前提成立的條件下的推出來的，這個前提是：Grok 3 耗費這麼大算力推大模型規模，這是個深思熟慮或小規模實驗的結果，而不是僅僅受到之前老觀念（預訓練階段算力越高效果越好）影響下的決策。&lt;/p&gt; 
&lt;p&gt;如果這個前提不成立，則上述推論不成立。總之，一切責任在馬斯克，Over。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334674</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334674</guid>
            <pubDate>Sat, 08 Feb 2025 03:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 提出新的注意力機制：原生稀疏注意力 (NSA)，創始人親自提交論文</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 18 日，DeepSeek 官方發文公佈了一篇新的論文，&lt;strong&gt;論文提出了一種新的注意力機制「NSA」&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-adf24ce9b3e5ac8760a1ec13688871f61ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2502.11089v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2502.11089v1&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據 DeepSeek 介紹，&lt;strong&gt;&lt;span&gt;「原生稀疏注意力 (Native Sparse Attention, NSA) 」&lt;/span&gt;&lt;/strong&gt;是一個用於超快長上下文訓練和推斷的本地可訓練的稀疏注意力機制，並且還具有與硬件對齊的特點。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;論文摘要：&lt;/p&gt; 
 &lt;p&gt;長文本建模對下一代語言模型來説至關重要，但標準注意力機制的高計算成本帶來了顯著的計算挑戰。稀疏注意力為提高效率同時保持模型能力提供了一個有前景的方向。我們提出了 NSA（原生稀疏注意力），這是一個將算法創新與硬件對齊優化相結合的、原生可訓練的稀疏注意力機制，用於實現高效的長文本建模。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d43b8ad2a0cb2e2f280f11b7d2d96a63fba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NSA 核心組件包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;動態分層稀疏策略&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;粗粒度 token 壓縮&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;細粒度 token 選擇&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;研究通過對現實世界語言語料庫的綜合實驗來評估 NSA。其中作者評估了 NSA 在通用語言評估、長上下文評估和鏈式推理評估中的表現。實驗結果表明，NSA 實現了與 Full Attention 基線相當或更優的性能，同時優於現有的稀疏注意力方法。&lt;/p&gt; 
&lt;p&gt;此外，與 Full Attention 相比，NSA 在解碼、前向和後向階段提供了明顯的加速，且加速比隨着序列長度的增加而增加。這些結果驗證了分層稀疏注意力設計有效地平衡了模型能力和計算效率。&lt;/p&gt; 
&lt;p&gt;另外，有網友發現，arXiv 上 NSA 這篇論文的提交記錄顯示，它於 2 月 16 日提交，提交者正是梁文鋒本人，他也是這篇論文的合著者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-521d0ee94e504b1caa033cbf984b6fde938.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334671/deepseek-nsa</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334671/deepseek-nsa</guid>
            <pubDate>Sat, 08 Feb 2025 02:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Linus Torvalds 將不顧維護者反對合並 Rust 內核代碼</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 &lt;a href=&quot;https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead&quot;&gt;Asahi Linux 創始人宣佈辭去項目負責人職務&lt;/a&gt;之後，圍繞 Linux 內核中 Rust 代碼的爭議還在繼續。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DMA 映射助手及內核其他多個領域的維護者 Christoph Hellwig 一直對 Linux 內核中的 Rust 代碼及其長期可維護性持批評態度，他在最新發布的一封郵件列表帖子中指出， Linus Torvalds 私下提到將推翻維護者對內核中 Rust 代碼的否決權。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;409&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-84071f688bda1ac854a0ee922963f204016.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;考慮到最近幾天的討論，我決定發佈此頁面，其中包含我們的理解：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frust-for-linux.com%2Frust-kernel-policy&quot; target=&quot;_blank&quot;&gt;https://rust-for-linux.com/rust-kernel-policy&lt;/a&gt;……&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Linus 私下表示，他絕對會不顧維護者的反對合並 Rust 代碼。因此，從現在開始，作為 Linux 開發者或維護者，無論你是否願意，都必須處理 Rust。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這裏的 Rust 代碼不僅僅是指 Rust 代碼——這些綁定看起來一點也不像地道的 Rust 代碼，它們是一種完全不同的存在，試圖彌合巨大的語義鴻溝。而且它們在某些地方並沒有做到這一點，因為它們現在被塞進了每個小子系統和庫中。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，這些綁定會像癌症一樣蔓延到各處，並迅速從一個允許並追求全局改進的軟件項目，轉向日益增加的隔離化。這將使 Linux 變成一個用多種語言編寫的項目，而沒有明確的指南説明在何處使用何種語言。即使在綁定之外，由於內核數據結構（如無處不在的鏈表）的侵入性和自引用特性，許多代碼也不會是非常地道的 Rust。我們是否既對不起那些試圖將現有代碼庫帶入更安全空間的人，也對不起那些用 Rust 進行系統編程的人？&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我曾經在類似的代碼庫上工作過，它們是我最糟糕的噩夢，因為由於原因 X，不斷有部分代碼從語言 A 重寫為語言 B，然後又由於原因 Z 重寫回去。而這還沒有算上 Linux 維護者之間常見的‘創造性’內鬥。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我想了解這個 Rust ‘實驗’的目標是什麼：如果我們想解決現有的內存安全問題，我們需要針對現有代碼進行修復，並找到改進的方法。最近在這方面做了很多工作，我們還需要更多。但這也表明，核心維護者對諸如檢查整數溢出或編譯器強制同步（如 clang hread sanitizer)）等瑣碎事情感到厭煩。我們如何彌合內核中一部分甚至不接受相對簡單的安全改進規則，而另一部分卻強制執行更嚴格規則之間的差距？&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;如果我們只是想使編寫驅動程序更容易，那麼引入一種新語言只會增加更多工作，並加重已經超負荷工作的核心基礎設施維護者的負擔。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，我認為這份政策文件沒有太大用處。目前的規則是，Linus 可以強迫你做任何他想要的事情，我認為他需要非常清楚地闡明這一點，包括對貢獻者的期望。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;就我個人而言，我可以很好地處理 Rust 本身，我很樂意將內核帶入一個更安全的內存世界，但處理一個不受控制的多語言代碼庫肯定會讓我把業餘時間花在其他事情上。我聽到其他一些人嘀咕類似的話，但並不是每個人都像我這樣直言不諱。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Frust-for-linux%2FZ7SwcnUzjZYfuJ4-%40infradead.org%2F&quot; target=&quot;_blank&quot;&gt;查看郵件列表&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334666/linus-torvalds-rust-code</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334666/linus-torvalds-rust-code</guid>
            <pubDate>Sat, 08 Feb 2025 02:34:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中軟國際被曝不協商直接降薪，有人直降 35%，引發員工抗議</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7884923627%2FPeQTeBEot&quot; target=&quot;_blank&quot;&gt;有網友爆料&lt;/a&gt;，華為外包大廠中軟國際員工在公司樓下聚集維權，抗議公司未提前協商突然降薪操作，疑似降薪幅度 10%-35%，甚至還有傳出 0 元工資的極端情況，引發員工強烈不滿。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/102639_R1Xq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/102923_eWur_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，目前 IT 中心產品部確認降薪，其他受影響部門暫不清楚。有員工反映，公司在降薪的同時還在大力拓展新業務，高層薪資福利卻絲毫未減，這讓員工心裏很不平衡。&lt;/p&gt; 
&lt;p&gt;據透露，中軟國際提供了三種選擇：一是按照薪資比例摺合 13 個月+的薪資，多出來的月份按照績效年終發放；第二種方案為直接降薪 18%；或者選擇在 3 月底主動離職。三種方案任選其一，且沒有書面形式，只是口頭通知。更讓員工難以接受的是，此次降薪並未明確説明原因，且強制執行。&lt;/p&gt; 
&lt;p&gt;面對員工的質疑，截至目前，該外包大廠派了一個所謂的辦事員前來收集員工的訴求，並承諾將與高層協商解決。「他們只是來聽我們説話，卻沒有給出任何實質性的答覆。」一位參與溝通的員工表示，「感覺就像是走過場，根本沒有解決問題的誠意。」&lt;/p&gt; 
&lt;p&gt;值得注意的是，據員工爆料，中軟國際的郵箱讓員工可以收到郵件，但是員工發送郵件出去，發件箱和發件記錄是空的，「這是怕員工留痕特意設置的。」該員工表示。更有網友爆料，甲方開價不低，到手的錢卻層層縮水，之前就有裁員 2.2 萬人的先例，現在又不協商直接降薪。&lt;/p&gt; 
&lt;p&gt;資料顯示，中國軟件外包市場規模已突破 4454 億元，年增速超 10%，而該公司作為在岸外包龍頭，客戶包括瞭如華為等互聯網大廠。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334665</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334665</guid>
            <pubDate>Sat, 08 Feb 2025 02:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>李彥宏：文心大模型 4.5 系列將開源，是最強大的文心大模</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在百度 2024 年 Q4 及全年財報電話會上，百度創始人、董事長兼首席執行官李彥宏透露，文心大模型 4.5 將開源，4.5 將是百度有史以來最強大的大模型，「希望客戶和用戶能比之前更方便地體驗這款模型」。&lt;/p&gt; 
&lt;p&gt;他表示，開源 4.5 系列的決策源自於對技術領先地位的堅定信心，開源將進一步促進文心大模型的廣泛應用，並在更多場景中擴大其影響力，「但我想強調的是，無論開源閉源，基礎模型只有在大規模解決現實問題時，才具備真實價值」。未來，百度將加速推動文心大模型的性能升級與成本降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;400&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f76b9accbca6162153bf21f08d99a59ecc.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，李彥宏還在業績會上表示，2025 年是蘿蔔快跑重要的擴張之年。他透露，百度將尋求與移動服務運營商、出租車公司及第三方車隊運營方等合作，以加速業務擴展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334659</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334659</guid>
            <pubDate>Sat, 08 Feb 2025 02:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>天天 AI-20250218</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;DeepSeek 加持，北大通院幾何模型達 IMO 金牌水平！32 個 CPU 核心和 1 塊 4090 就能實現滿血解題&lt;/h3&gt; 
&lt;p&gt;北大通院的 TongGeometry 模型在 DeepSeek 的加持下，達到了國際數學奧林匹克競賽（IMO）金牌水平。該模型不僅能夠解決 IMO-AG-30 數據集中的所有 30 題，還在 IMO-AG-50 數據集上解決了 42 題，超越了人類金牌選手的平均水平。TongGeometry 通過使用歸納數據庫方法（DD）、構造對稱圖形、利用策略網絡和價值網絡聯合搜索等技術，實現了高效解題。此外，該模型還具備出題能力，其生成的題目已被權威數學競賽收錄。值得注意的是，TongGeometry 僅需 32 個 CPU 核心和 1 塊 4090 顯卡即可實現滿血解題，展現了極高的效率。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Feswmr-dcYx_oeYrKJwX0qQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;6 個 DeepSeek 指令，讓 AI 成為你的超級助手！掌握這些，效率翻倍！&lt;/h3&gt; 
&lt;p&gt;在信息爆炸的時代，高效處理複雜信息、全面分析問題、精準預測趨勢已成為現代人必備的技能。而 DeepSeek，作為一款強大的 AI 工具，憑藉其獨特的指令功能，能夠幫助你輕鬆應對這些挑戰。今天，我們就來揭祕 DeepSeek 的 6 個神奇指令，讓你在內容傳播和推廣中如虎添翼！&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIBow-N4IFbwNKEQGmuWdNQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;大決戰！OpenAI 可能發佈 GPT-4.5，狙擊馬斯克 Gork3&lt;/h3&gt; 
&lt;p&gt;OpenAI 首席執行官 Sam Altman 透露，GPT-4.5 已進入測試階段，可能在近期發佈。這一消息正值馬斯克宣佈發佈「地球最聰明的 AI」——Gork3 之際，引發了行業的廣泛關注。GPT-4.5 被認為是對抗 Gork3 的有力武器，OpenAI 團隊甚至計劃在 Gork3 發佈後決定是否推出 GPT-4.5。這一競爭不僅展示了 AI 領域的激烈競爭，也預示着未來 AI 技術的快速發展。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX33kBcSq3ieMSfPx-gnW_Q&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;10W+爆款 AI 流水線：Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版&lt;/h3&gt; 
&lt;p&gt;熬夜趕稿、追熱點到頭禿、爆文全靠運氣……這些是不是你創作路上的「噩夢」？別急，這裏有個祕密武器，能讓你輕鬆告別這些煩惱，甚至讓爆款內容像印鈔機一樣源源不斷！想知道是什麼「黑科技」嗎？往下看，解鎖 15 分鐘生成爆款的神奇公式！&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSA9KUAscPemgXMnwDssHyw&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;深圳上線 70 名「AI 員工」，滿足 240 個政務場景&lt;/h3&gt; 
&lt;p&gt;深圳福田區上線了基於 DeepSeek 開發的「AI 數智員工」，覆蓋政務服務全鏈條 240 個場景。這些「AI 員工」能夠處理公文、提供民生服務、支持應急管理等任務。福田區政務大模型 2.0 版以 DeepSeek R1 為核心，通過混合專家架構（MoE）和強化學習技術，實現了高效、精準的政務服務。該模型不僅提升了公文處理和審核效率，還為招商引資、執法文書生成等場景提供了強大支持。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcRalKSPJxLYgzsApONMTUw&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Adobe 發佈全新生成式 AI 應用 Firefly，進軍商業化&lt;/h3&gt; 
&lt;p&gt;Adobe 推出了生成式 AI 應用 Firefly，集成了圖像、矢量圖形和視頻生成功能。Firefly 支持從文本提示生成高質量視頻，並提供多種語言翻譯功能，能夠將音頻翻譯成 20 多種語言。該應用還與 Adobe 全家桶深度集成，支持無縫切換和創作流程優化。Firefly 的推出標誌着 Adobe 在生成式 AI 領域的商業化佈局，為創意產業帶來了革命性體驗。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-AiIZ08-vk1-xWOPt7a97A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;搞定 DeepSeek R1 部署，這個開源項目有點東西！&lt;/h3&gt; 
&lt;p&gt;開源項目 GPUStack 為 DeepSeek R1 的部署提供了高效解決方案。該項目支持 Windows、Linux 和 macOS，能夠自動處理資源分配，支持多機協同計算和異構硬件適配。GPUStack 通過分佈式推理技術，解決了單機資源不足的問題，使 DeepSeek R1 能夠在各種硬件環境下穩定運行。此外，GPUStack 還支持模型管理、高可用性、監控與可視化等功能，為 AI 模型的部署和管理提供了全面支持。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FQmbVjWXO2tGNPFHIjwfa3A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;清華最新綜述解讀，大模型推理能力的進化之路！&lt;/h3&gt; 
&lt;p&gt;清華大學發佈了一篇關於大模型推理能力發展的綜述論文，全面梳理了 LLM 推理能力的進化路徑。論文指出，大模型的推理能力建立在預訓練、微調和對齊三個關鍵階段之上。高質量的推理數據和先進的訓練方法（如強化學習）是提升模型推理能力的關鍵。此外，論文還探討了測試時優化技術（如樹搜索和集束搜索）對提升推理能力的作用。該綜述為理解大模型推理能力的發展提供了重要參考。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FY_bmJUObwyoD0AI6yCqYIQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;微信也接不住 DeepSeek 的流量？&lt;/h3&gt; 
&lt;p&gt;微信開始灰度測試接入 DeepSeek R1，用戶可以在微信搜索中體驗 AI 搜索功能。這一舉措不僅是微信對 AI 技術的積極探索，也反映了騰訊對流量變現的佈局。儘管 DeepSeek 的接入帶來了高昂的算力成本，但微信希望通過 AI 技術提升用戶體驗，吸引更多用戶。此外，騰訊旗下的多個產品也在持續接入 DeepSeek，顯示出騰訊在 AI 領域的全面佈局。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJ9XMqSdz00x_TFsMXRZbfg&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;DeepSeek 顛覆了什麼？學習不靠「人盯」，AI 自己「卷」自己&lt;/h3&gt; 
&lt;p&gt;DeepSeek 通過純強化學習路線，顛覆了傳統 AI 訓練模式。其 R1 模型證明瞭無需過程監督，僅通過結果控制即可訓練出優秀的推理模型。DeepSeek 的 Zero 研究展示了模型自主生成思維鏈的能力，為 AI 的平民化鋪平了道路。此外，DeepSeek 在語言文字創作和風格模仿方面也取得了顯著突破，進一步拓展了 AI 的應用範圍。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsYRgyuGy7rE5sfMjzHsWlA&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;比亞迪掀起「全民智駕」風暴：接入 DeepSeek，7 萬級車型標配高階智駕&lt;/h3&gt; 
&lt;p&gt;比亞迪發佈了「天神之眼」高階智能駕駛系統，將高階智駕功能推廣至 7 萬級車型。該系統由比亞迪全棧自研，能夠實現全程高速自動駕駛和城區穩定駕駛。比亞迪還宣佈將接入 DeepSeek R1 大模型，進一步提升車輛的智能化水平。這一舉措標誌着智能駕駛技術的普及化，為未來交通帶來了新的可能性。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6hNhK_NmeKCsAcE0QnS80A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;馬斯克用程序員和 AI 算法「整頓」華盛頓，此刻已亂成一鍋粥&lt;/h3&gt; 
&lt;p&gt;馬斯克領導的 DOGE（政府效率部）正在通過 AI 技術和高強度工作模式對美國聯邦政府機構進行「現代化改造」。DOGE 團隊由一羣年輕工程師組成，他們被賦予極高權限，直接接入財政部、教育部等核心部門的數據庫，利用 AI 算法審查開支、識別欺詐行為，並推動自動化流程。馬斯克甚至聲稱，AI 已發現財政部每年有高達 500 億美元的可疑支出。此外，DOGE 還計劃開發名為「GSAi」的生成式 AI 聊天機器人，用於梳理政府合同和採購數據。然而，這一系列激進措施引發了爭議，許多聯邦機構員工面臨裁員，部分項目被暫停，甚至引發了多起法律訴訟。批評者認為，馬斯克的團隊缺乏透明度和問責機制，可能對公共服務造成負面影響。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5Co4_4bNFiZCc9x7opxuvA&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;DeepSeek 衝擊之下，大模型六小強如何「回應」？&lt;/h3&gt; 
&lt;p&gt;DeepSeek 的出現對全球大模型市場產生了巨大沖擊。國內六家獨角獸大模型公司（零一萬物、百川智能、階躍星辰、智譜華章、月之暗面、MiniMax）紛紛採取行動應對。零一萬物與蘇州高新區合作，成立產業大模型基地，聚焦垂直產業解決方案；百川智能發佈全場景推理大模型 Baichuan-M1-preview，並推出「AI 兒科醫生」；階躍星辰發佈多款新模型，並在應用中接入 DeepSeek；智譜華章繼續與三星合作，推動大模型在手機端的應用；月之暗面發佈 Kimi k1.5 多模態思考模型；MiniMax 開源 MiniMax-01 系列模型，推動技術進化。這些動作表明，大模型公司正在通過技術創新和產業合作來應對 DeepSeek 帶來的挑戰。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FfdbEWhQekN1w3WvI_vCg7A&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1100 萬人都在玩的 AI 視頻神器，三步把你 P 進任何名場面&lt;/h3&gt; 
&lt;p&gt;Pika 是一款 AI 視頻工具，最近推出了 Pikaddition 功能，允許用戶通過簡單的三步操作將任何圖片融入視頻中。用戶只需上傳視頻和圖片，並輸入提示詞，Pika 就能生成融合效果。該功能支持多種創意玩法，例如將人物融入影視名場面、製作表情包等。儘管 Pika 的特效可能不是專業級，但其低門檻和高趣味性吸引了大量用戶，註冊用戶已突破 1100 萬。此外，Pika 還推出了 Pikamemes 功能，一鍵生成表情包，進一步降低了 AI 視頻創作的門檻。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjcUdGPLBYHV6TT5zuOhK7Q&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;政務雲，DeepSeek 下一個風口？&lt;/h3&gt; 
&lt;p&gt;多地政務系統開始接入 DeepSeek 大模型，推動政務數字化轉型。山東煙台、蘇州、廣州、深圳、無錫等地已部署 DeepSeek 模型，用於提升政務服務效率、優化數據管理和降低錯誤率。例如，深圳市的「AI 公務員」錯誤率控制在 5% 以內，顯著提升了政務處理效率。相關研報指出，DeepSeek 的開源特性為雲服務廠商提供了低門檻部署世界級 AI 應用的機會，政務雲作為重要細分領域有望加速發展。&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeAlm4IVXiqpJXRizqMCywQ&quot; target=&quot;_blank&quot;&gt;來源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;🔥 熱門文章推薦（2AGI.NET）&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250218%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250218&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 18 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250217%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250217&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 17 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2F10w-plus-hit-ai-pipeline-coze-depth-writing-deepseek-algorithm-insight-html-fast-typesetting%2F&quot; target=&quot;_blank&quot;&gt;10W+爆款 AI 流水線：Coze 深度寫作×DeepSeek 算法洞察×HTML 極速排版&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 16 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fexploring-the-secrets-of-world-models%2F&quot; target=&quot;_blank&quot;&gt;探索世界模型奧祕&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 16 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Funderstanding-intelligent-emergence%2F&quot; target=&quot;_blank&quot;&gt;如何理解智能湧現（emergence）&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 15 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250214%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250214&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 14 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250213%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250213&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 13 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250212%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250212&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 12 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20250211%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20250211&lt;/a&gt; &lt;p&gt;作者：2AGI&lt;/p&gt; 2025 年 2 月 11 日&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;掃碼加入社羣，參與討論&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img alt=&quot;2AGI 技術社區，歡迎掃碼加入&quot; height=&quot;558&quot; src=&quot;https://oscimg.oschina.net/oscnet//88cbcd3a747ff3c416c80d739b5a3a82.png&quot; width=&quot;1180&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#212121; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fagi%2F&quot; target=&quot;_blank&quot;&gt;AGI&lt;span&gt;(102)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-agent%2F&quot; target=&quot;_blank&quot;&gt;AI Agent&lt;span&gt;(3)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-app%2F&quot; target=&quot;_blank&quot;&gt;AI App&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-celebrity%2F&quot; target=&quot;_blank&quot;&gt;AI Celebrity&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Faigc%2F&quot; target=&quot;_blank&quot;&gt;AIGC&lt;span&gt;(126)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e5%2590%258d%25e4%25ba%25ba%25e5%25a0%2582%2F&quot; target=&quot;_blank&quot;&gt;AI 名人堂&lt;span&gt;(9)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e6%2590%259c%25e7%25b4%25a2%2F&quot; target=&quot;_blank&quot;&gt;AI 搜索&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai%25e6%2595%2599%25e7%25a8%258b%2F&quot; target=&quot;_blank&quot;&gt;AI 教程&lt;span&gt;(7)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai-%25e6%2595%2599%25e7%25a8%258b%2F&quot; target=&quot;_blank&quot;&gt;AI 教程&lt;span&gt;(2)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai%25e7%2594%259f%25e4%25ba%25a7%25e5%258a%259b%25e5%25b9%25b3%25e5%258f%25b0%2F&quot; target=&quot;_blank&quot;&gt;AI 生產力平台&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fai%25e7%2594%25b5%25e5%25bd%25b1%25e5%2588%25b6%25e4%25bd%259c%2F&quot; target=&quot;_blank&quot;&gt;AI 電影製作&lt;span&gt;(2)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fclaude%2F&quot; target=&quot;_blank&quot;&gt;Claude&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fclaude-3-5-sonnet%2F&quot; target=&quot;_blank&quot;&gt;claude 3.5 sonnet&lt;span&gt;(1)&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Ftag%2Fcoze%2F&quot; target=&quot;_blank&quot;&gt;Coze&lt;span&gt;(2)&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334648</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334648</guid>
            <pubDate>Sat, 08 Feb 2025 01:11:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>百度 2024 年總營收 1331 億元，對 AI 投資充滿信心</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度剛剛發佈了 2024 年 Q4 及全年財報：全年總營收 1331 億元，歸屬百度核心淨利潤達 234 億元，同比增長 21%。&lt;/p&gt; 
&lt;p&gt;百度聯合創始人兼 CEO 李彥宏表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年是百度從以互聯網為中心向以 AI 為先轉型的關鍵一年。我們的全棧 AI 能力得到了市場的廣泛認可，從而推動了人工智能雲的發展勢頭。在移動生態系統方面，我們堅定不移地推進 AI 轉型，使搜索更接近原生 AI 能力，從而提供更好的用戶體驗。&lt;/p&gt; 
 &lt;p&gt;Apollo Go 經過多年的投入也充分驗證了其商業模式，為全球擴張和可擴展的輕資產戰略鋪平了道路。隨着我們的戰略遠見逐漸得到驗證，我們預計我們的 AI 投資將在 2025 年取得更顯著的成果。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;1440&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0218/184432_hRLQ_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;受 AI 驅動，百度智能雲呈高速增長，四季度收入同比增長達 26%。近期，百度智能雲成功點亮崑崙芯三代萬卡集羣，未來還將進一步點亮三萬卡集羣。&lt;/p&gt; 
&lt;p&gt;12 月，文心大模型日均調用量達 16.5 億次，一年增長 33 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1440&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0218/184634_17th_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334611</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334611</guid>
            <pubDate>Fri, 07 Feb 2025 10:47:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源策略是大模型最好的競爭策略</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;報告地址：&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
&lt;p&gt;在第二章《TOP 101-2024 大模型觀點》中，資深開發者社區運營專家&lt;strong&gt;顧鈞&lt;/strong&gt;直言，開源策略是大模型最好的競爭策略，並分享了諸多思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;大模型是一項較新技術，賽道的主要玩家在技術和商業化上有差距但未到無法翻盤程度，該賽道涵蓋模型訓練與服務，市場化程度高，商業化場景覆蓋 2B 與 2C。&lt;/li&gt; 
 &lt;li&gt;大模型賽道在海外是 「一超多強」，國內是 「多頭並舉」，元素豐富，為分析開源策略重要性提供素材。&lt;/li&gt; 
 &lt;li&gt;大模型競爭賽點包括技術先進性、C 端用戶基數、依賴軟件的生態系統大小等，但技術先進性目前更多用於公關宣傳，大模型商業化還處於摸索階段。&lt;/li&gt; 
 &lt;li&gt;C 端用戶沒有忠誠度且難以產生獨特粘性，大模型廠商維繫 C 端流量成本可能很高，且大模型賽道內卷，普通用戶使用隨意性強、準確性要求不高。&lt;/li&gt; 
 &lt;li&gt;大模型生態系統大小是評價其能否勝出的關鍵指標，構建開發者生態有提供 API 雲服務和 「開源」 兩種方法，閉源大模型多采用前者，開源模型採用後者。&lt;/li&gt; 
 &lt;li&gt;拋開成本和易用性空談技術先進性是常見錯誤，大模型領域開源更有優勢，因為大模型賽道核心制約條件是成本太高，開源可省去拓展開發者生態的大模型運行成本。&lt;/li&gt; 
 &lt;li&gt;閉源大模型廠商維持雲資源、工程師資源支撐開發者調試需求，投入產出可能算不過來，且大模型對開發者粘性有限。&lt;/li&gt; 
 &lt;li&gt;大模型 API 雲服務接口簡單且高度一致，開發者構建應用時與具體大模型難形成強綁定，主動權在開發者。&lt;/li&gt; 
 &lt;li&gt;開源策略目標是以最小代價消耗閉源對手資源與心氣，是 &lt;strong&gt;「先為不可勝，以待敵之可勝」&lt;/strong&gt; 的策略。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1920&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0218/175851_PK73_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;完整全文：&lt;a href=&quot;https://my.oschina.net/u/3859945/blog/17503844&quot; target=&quot;_blank&quot;&gt;https://my.oschina.net/u/3859945/blog/17503844&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334605</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334605</guid>
            <pubDate>Fri, 07 Feb 2025 10:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>KubeSphere 產品生命週期管理政策公告正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;親愛的 KubeSphere 用戶：&lt;/p&gt; 
&lt;p&gt;在雲原生技術飛速發展的今天，KubeSphere 始終以技術創新和用戶價值為核心，持續優化產品與服務。為更好地服務全球用戶、保障業務連續性，基於多年的技術積累與用戶反饋，我們正式對外公開發布 &lt;strong&gt;《KubeSphere 產品生命週期管理政策》&lt;/strong&gt;。通過清晰的支持策略與版本管理，助力用戶高效規劃升級，規避潛在風險，實現業務可持續發展。&lt;/p&gt; 
&lt;h2&gt;KubeSphere 產品生命週期管理政策公告&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;文件版本&lt;/strong&gt;: v1.0 &lt;strong&gt;更新時間&lt;/strong&gt;: 2025.02.14&lt;/p&gt; 
&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;在快速變化的市場環境中，青雲科技針對 KubeSphere 雲原生產品與服務推出了產品生命週期管理政策。該政策旨在及時調整和終止不再符合市場需求的產品，以確保我們的產品始終滿足客戶期望。通過清晰的產品終止方案，我們將為客戶提供必要的支持與指導，降低業務風險，提升客戶信任與滿意度。我們致力於推動技術創新，實現持續的業務發展，為客戶創造更大的價值。&lt;/p&gt; 
&lt;h2&gt;適用範圍&lt;/h2&gt; 
&lt;p&gt;本文中描述的 KubeSphere 產品生命週期終止政策適用於以下 KubeSphere 雲原生產品與服務：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KubeSphere 開源版。涉及 v1、v2、v3 及 v4 版本。&lt;/li&gt; 
 &lt;li&gt;KubeSphere 企業版（包含更名前的青雲 QKCP）。涉及 v1、v2、v3 及 v4 版本。&lt;/li&gt; 
 &lt;li&gt;青雲容器平台（可信版）。涉及所有產品版本。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;KubeSphere 產品版本定義&lt;/h2&gt; 
&lt;p&gt;在 KubeSphere 產品版本控制中，軟件版本號通常用來表示其代表的發佈階段與更新內容。其中，版本號格式包括主版本號 (Major Version)、次版本號 (Minor Version)、補丁版本號 (Patch Version) 和熱修復版本號 (HotFix)。以下是這些術語的詳細説明：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 主版本 (Major Version)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主版本號的設置通常表示軟件有重大更新或變化，這可能包括全新的產品架構、功能模塊、操作體驗或與舊版本不再兼容的變更。&lt;/li&gt; 
 &lt;li&gt;主版本號的設置通常意味着版本號的其他部分（如：次版本號、補丁版本號）重置為零。例如，產品版本從 v3.4.1 升級到 v4.0.0。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 次版本 (Minor Version)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;次版本號的設置表示軟件有一般的更新或改進，這可能包括新增功能模塊、性能改善、安全性強化或兼容性增強等。&lt;/li&gt; 
 &lt;li&gt;次版本號的設置通常意味着補丁版本號重置為零，但主版本號保持不變。例如，產品版本從 v4.1.2 升級到 v4.2.0。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 補丁版本 (Patch Version)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;補丁版本號的設置表示軟件有較小的修復或優化，這通常用於修復錯誤、改進穩定性、或優化產品體驗等。&lt;/li&gt; 
 &lt;li&gt;補丁版本不會開啓新的產品生命週期。例如，KSE v4.1.3 將共享 KSE v4.1 的生命週期。&lt;/li&gt; 
 &lt;li&gt;補丁版本號的設置不會影響主版本號和次版本號。例如，產品版本從 v4.1.2 升級到 v4.1.3。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4. 熱修復 (HotFix)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;熱修復是指對軟件進行的緊急修復，其通常用於解決如無法繼續的阻塞或嚴重的安全隱患導致客戶業務停滯或沒有臨時方案的問題。&lt;/li&gt; 
 &lt;li&gt;熱修復僅就對應發現的嚴重問題進行修復和針對性測試，不會像上述三類正式產品版本一樣進行全量的測試驗證，是解決緊急問題的臨時性處置措施。最佳方案依然是升級至後續正式產品版本。&lt;/li&gt; 
 &lt;li&gt;熱修復通常不改變產品版本號的主要部分，僅在現有版本上立即應用。例如，如果產品版本 v3.5.0 存在嚴重錯誤，可能會發佈一個熱修復版本 3.5.0-hotfix-version-number。&lt;/li&gt; 
 &lt;li&gt;熱修復可能會在下一個補丁版本或次版本中被正式包含。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;KubeSphere 服務與支持等級定義&lt;/h2&gt; 
&lt;p&gt;在 KubeSphere 雲原生產品與服務中，通常會涉及到以下多種類型的服務與支持。根據等級的劃定，可分為：FS（Full Support，全面服務與支持）與 ES（Extended Support，延長服務與支持）。下方表格中」Y」表示」YES」，即支持；」N」表示」NO」，即不支持。表格中的數字標識表示有進一步的文字説明，詳見下方對應標號的內容。&lt;/p&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere 服務與支持等級表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;服務與支持類型&lt;/th&gt; 
   &lt;th&gt;FS&lt;/th&gt; 
   &lt;th&gt;ES&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;服務與支持時長 (Duration: Months)&lt;/td&gt; 
   &lt;td&gt;12-36&lt;/td&gt; 
   &lt;td&gt;06-24&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;問題分析 (Root-Cause Analysis)&amp;lt;sup&amp;gt;(1)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;產品新特性 (Features)&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;產品版本升級 (Upgrade)&amp;lt;sup&amp;gt;(2), (3)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&amp;lt;sup&amp;gt;(2)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;功能與體驗優化 (Enhancements)&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;普通缺陷修復 (General BugFix)&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;嚴重缺陷修復 (Critical BugFix)&amp;lt;sup&amp;gt;(4)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;嚴重安全漏洞修復 (Critical Security Fix)&amp;lt;sup&amp;gt;(5)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;兼容性支持 (Compatibility Support)&amp;lt;sup&amp;gt;(6)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;N&amp;lt;sup&amp;gt;(7)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;遷移協助 (Migration Support)&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1) 「問題分析」是指對非產品自身、從外部引入的第三方軟硬件帶來的問題進行分析與支持。如客戶自己開發的業務系統、自採購硬件設備、自行部署的第三方軟件等，青雲科技僅承諾協助性分析與支持，不承諾能定位或解決此類非青雲科技提供的產品的問題。&lt;/li&gt; 
 &lt;li&gt;(2) 產品版本升級主要包括提供主版本、次版本、補丁版本或熱修復的升級。ES 等級下，僅針對「嚴重缺陷修復」與「嚴重安全漏洞修復」提供」熱修復「升級。&lt;/li&gt; 
 &lt;li&gt;(3) 一般情況下，產品不支持跳過任意主和次版本進行升級，需按版本號順序依次遞進升級。若遇不確定情況，請聯繫青雲科技客服人員或售後服務團隊，諮詢並評估專屬的產品升級方案。&lt;/li&gt; 
 &lt;li&gt;(4) 「嚴重缺陷」是指客戶、產品經理、測試經理、產品技術負責人、技術支持工程師及項目經理等多方共同認定下，明確影響到客戶業務連續性、穩定性、可靠性等的問題。&lt;/li&gt; 
 &lt;li&gt;(5) 「嚴重安全漏洞」是指 CVSS 大於等於 7 的安全漏洞問題。&lt;/li&gt; 
 &lt;li&gt;(6) 兼容性支持主要包括兼容 Kubernetes 新版本、新的 CPU 架構、新的 OS 類型或架構、OS 的新版本等。&lt;/li&gt; 
 &lt;li&gt;(7) 兼容性支持取決於軟件主版本、次版本發佈時的適配兼容情況，在後續的產品生命週期中不再改變。FS 不再新增兼容適配。&lt;/li&gt; 
 &lt;li&gt;(8) FS、ES 僅針對青雲科技的商業產品。ES 可視為 FS 的延續，不一定每個版本都可以額外訂閲 ES。ES 在經過青雲科技確認並同意的前提下最多允許訂閲兩次即兩年，之後不再提供續訂。若有需要，請聯繫青雲科技客服人員或售後服務團隊諮詢詳情。&lt;/li&gt; 
 &lt;li&gt;(9) FS、ES 默認通過如維保工單支持平台、遠程桌面、電話、微信、企業微信等遠程方式提供服務與支持。現場或駐場類型的服務與支持不在 FS、ES 範圍內，若有需要，請聯繫青雲科技客服人員或售後服務團隊諮詢詳情。&lt;/li&gt; 
 &lt;li&gt;(10) 青雲科技 KubeSphere 雲原生產品與服務的具體服務與支持範圍，可參考青雲科技售後服務團隊出具的 SLA 聲明。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;KubeSphere 產品生命週期説明&lt;/h2&gt; 
&lt;h3&gt;1. Standard 類型產品版本説明&lt;/h3&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere Standard 類型產品版本説明表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;里程碑階段&lt;/th&gt; 
   &lt;th&gt;GA&lt;/th&gt; 
   &lt;th&gt;EoFS&lt;/th&gt; 
   &lt;th&gt;EoES&lt;/th&gt; 
   &lt;th&gt;EoL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;中英文名稱&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;General Availability, 一般可獲得性，即批量銷售日。&lt;/td&gt; 
   &lt;td&gt;End of Full Support，停止全面服務與支持。&lt;/td&gt; 
   &lt;td&gt;End of Extended Support，停止延長服務與支持。&lt;/td&gt; 
   &lt;td&gt;End of Life，生命週期完全終止。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;定義&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GA 是產品生命週期開啓的日期。該日期表明該產品版本正式開始售賣，並可按需、批量交付到客戶生產環境使用。&lt;/td&gt; 
   &lt;td&gt;EoFS 是產品停止全面服務與支持的日期。產品停止提供補丁版本，僅針對「嚴重缺陷」與「嚴重安全漏洞」提供「熱修復」。同時，該日期表明產品（主版本、次版本）已不再銷售。&lt;/td&gt; 
   &lt;td&gt;EoES 是產品停止延長服務與支持的日期。產品不再修復嚴重缺陷與嚴重安全漏洞。&lt;/td&gt; 
   &lt;td&gt;EoL 是產品生命週期完全終止的日期。完全停止此產品（版本）的一切活動，包括商業售賣、版本升級（含熱修復）、各種等級的服務與支持等。青雲科技將不再為此產品（版本）上產生的任何問題負責。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;服務與支持等級&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;FS（產品 GA 之後，根據客戶的產品授權與維保訂閲情況提供）&lt;/td&gt; 
   &lt;td&gt;ES（產品 EoFS 之後，產品不再提供標準的 FS。客戶額外訂閲 ES 的情況後提供延長服務與支持）&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;客戶影響&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;(1) 不建議客戶使用已經 EoFS 的版本進行新建或擴容；&amp;lt;br&amp;gt;(2) 客戶無法得到新的產品補丁版本；&amp;lt;br&amp;gt;(3) 推薦客戶儘快升級使用全新 GA 的版本；&amp;lt;br&amp;gt;(4) 客戶可在訂閲 ES 後享受對應等級服務與支持。&lt;/td&gt; 
   &lt;td&gt;(1) 客戶無法得到新的產品熱修復；&amp;lt;br&amp;gt;(2) 若繼續使用，客戶必須進行版本升級；&amp;lt;br&amp;gt;(3) 對應產品（版本）官方文檔很快將無法查看；&amp;lt;br&amp;gt;(4) 對應產品（版本）安裝、升級等程序（鏡像 Chart 等）很快將無法使用。&lt;/td&gt; 
   &lt;td&gt;(1) 客戶無法查看對應產品（版本）官方文檔；&amp;lt;br&amp;gt;(2) 客戶無法使用安裝、升級等程序（鏡像 Chart 等）；&amp;lt;br&amp;gt;(3) 客戶無法獲得針對該產品（版本）的任何服務；&amp;lt;br&amp;gt;(4) 客戶需自行維護或遷移業務環境，客戶需考慮購買新的產品（版本）。&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Preview 類型產品及擴展組件版本説明&lt;/h3&gt; 
&lt;p&gt;KubeSphere 雲原生產品與服務中，Preview 類型產品版本及擴展組件版本非售賣，不支持商用，僅供實驗室、開發測試等非正式生產環境體驗使用，不提供 SLA 與 EOS 商業保障。通常情況下，Preview 類型產品版本及擴展組件版本生命週期為 6 個月。&lt;/p&gt; 
&lt;h2&gt;KubeSphere 產品生命週期時間表&lt;/h2&gt; 
&lt;h3&gt;1. KubeSphere 企業版（包含更名前的青雲 QKCP、青雲容器平台（可信版））&lt;/h3&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere 企業版產品生命週期時間表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;版本號&lt;/th&gt; 
   &lt;th&gt;版本類型&lt;/th&gt; 
   &lt;th&gt;GA&lt;/th&gt; 
   &lt;th&gt;EoFS&lt;/th&gt; 
   &lt;th&gt;EoES&lt;/th&gt; 
   &lt;th&gt;EoL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v4.2&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v4.1&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2024 年 04 月 16 日&lt;/td&gt; 
   &lt;td&gt;2027 年 04 月 16 日&lt;/td&gt; 
   &lt;td&gt;2028 年 10 月 16 日&lt;/td&gt; 
   &lt;td&gt;2028 年 12 月 16 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v4.0&lt;/td&gt; 
   &lt;td&gt;Preview&lt;/td&gt; 
   &lt;td&gt;2023 年 08 月 16 日&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2024 年 06 月 28 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.5&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2023 年 10 月 13 日&lt;/td&gt; 
   &lt;td&gt;2025 年 07 月 13 日&lt;/td&gt; 
   &lt;td&gt;2026 年 01 月 13 日&lt;/td&gt; 
   &lt;td&gt;2026 年 03 月 13 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.4&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2023 年 04 月 25 日&lt;/td&gt; 
   &lt;td&gt;2025 年 05 月 25 日&lt;/td&gt; 
   &lt;td&gt;2025 年 11 月 25 日&lt;/td&gt; 
   &lt;td&gt;2025 年 12 月 25 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.3&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 03 月 31 日&lt;/td&gt; 
   &lt;td&gt;2025 年 09 月 30 日&lt;/td&gt; 
   &lt;td&gt;2025 年 10 月 31 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.2 及之前版本&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 03 月 31 日&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;青雲容器平台（可信版）請參考 KubeSphere 企業版與青雲 QKCP 對應版本號的產品生命週期情況。&lt;/li&gt; 
 &lt;li&gt;KubeSphere 企業版 v4.2 之後，各擴展組件可能出現獨立發版、迭代的情況，但其產品生命週期不單獨設立，仍與 KubeSphere 企業版產品生命週期一致。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. KubeSphere 開源版&lt;/h3&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere 開源版產品生命週期時間表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;版本號&lt;/th&gt; 
   &lt;th&gt;版本類型&lt;/th&gt; 
   &lt;th&gt;GA&lt;/th&gt; 
   &lt;th&gt;EoL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v4.2&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v4.1&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2024 年 09 月 12 日&lt;/td&gt; 
   &lt;td&gt;2027 年 09 月 12 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v3.4&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 12 月 25 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v3.3 及之前版本&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 10 月 31 日&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;補充説明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 KubeSphere 企業版/開源版 v4 版本中，可能存在一些來自第三方合作伙伴的生態擴展組件。針對這些擴展組件，其產品生命週期管理策略請查看產品的相關説明文檔或聯繫對應產品提供商。&lt;/li&gt; 
 &lt;li&gt;因產品軟著與軟件採購退稅等政策性原因，青雲科技銷售目錄與合同中所列舉的產品版本可能與實際交付部署的產品版本不一致。若出現該情況，一切都以客戶首次採購、實際交付部署並頒發許可證授權的產品版本為準。&lt;/li&gt; 
 &lt;li&gt;在 KubeSphere 雲原生產品與服務的銷售中，當出現採購產品永久授權與多年 FS/ES 的場景時，其適用的版本可能不是採購當時的產品版本。此時以當前實際交付部署並頒發許可證授權的產品版本為準。&lt;/li&gt; 
 &lt;li&gt;上方「KubeSphere 產品生命週期時間表」中展示的時間，為各里程碑階段承諾服務與支持的最短時間。我們可能會基於產品版本質量、安裝部署人數、新產品（版本）研發情況等進行動態調整 EoFS/EoES/EoL 的時間。若有調整，我們將另行公告，歡迎關注。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;注意事項&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;第三方擴展組件：生命週期策略請以提供商文檔為準。&lt;/li&gt; 
 &lt;li&gt;版本交付一致性：實際授權版本以首次交付並頒發許可證的版本為準。&lt;/li&gt; 
 &lt;li&gt;動態調整説明：如遇產品迭代或用戶需求變化，生命週期時間可能調整，請持續關注官方公告。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;完整聲明全文&lt;/h3&gt; 
&lt;p&gt;中英雙語全文請參見 KubeSphere 官網：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;全球站：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fnews%2Fkubesphere-product-lifecycle-policy%2F&quot; target=&quot;_blank&quot;&gt;KubeSphere Product Lifecycle Policy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;中文站：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fnews%2Fkubesphere-product-lifecycle-policy%2F&quot; target=&quot;_blank&quot;&gt;KubeSphere 產品生命週期管理政策公告&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;關於 KubeSphere&lt;/h3&gt; 
&lt;p&gt;KubeSphere （&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%EF%BC%89%E6%98%AF%E5%9C%A8&quot; target=&quot;_blank&quot;&gt;https://kubesphere.io）是在&lt;/a&gt; Kubernetes 之上構建的開源容器平台，提供全棧的 IT 自動化運維的能力，簡化企業的 DevOps 工作流。&lt;/p&gt; 
&lt;p&gt;KubeSphere 已被 Aqara 智能家居、本來生活、東方通信、微宏科技、東軟、華雲、新浪、三一重工、華夏銀行、四川航空、國藥集團、微眾銀行、紫金保險、去哪兒網、中通、中國人民銀行、中國銀行、中國人保壽險、中國太平保險、中國移動、中國聯通、中國電信、天翼雲、中移金科、Radore、ZaloPay 等海內外數萬家企業採用。KubeSphere 提供了開發者友好的嚮導式操作界面和豐富的企業級功能，包括 Kubernetes 多雲與多集羣管理、DevOps (CI/CD)、應用生命週期管理、邊緣計算、微服務治理 (Service Mesh)、多租戶管理、可觀測性、存儲與網絡管理、GPU support 等功能，幫助企業快速構建一個強大和功能豐富的容器雲平台。&lt;/p&gt; 
&lt;p&gt;&amp;gt; 本文由博客一文多發平台 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom&quot; target=&quot;_blank&quot;&gt;OpenWrite&lt;/a&gt; 發佈！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4197945/blog/17646180</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/17646180</guid>
            <pubDate>Fri, 07 Feb 2025 09:37:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>阿里巴巴在上海成立智信普惠科技公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 App 顯示，上海智信普惠科技有限公司於 2025 年 2 月 17 日成立，位於上海市，是一家以從事軟件和信息技術服務業為主的企業。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;法定代表人為餘志乾，企業註冊資本 1000 萬人民幣。經營範圍含計算機軟硬件及輔助設備零售、網絡技術服務、信息技術諮詢服務、數字內容製作服務、數據處理服務、人工智能通用應用系統、人工智能應用軟件開發、互聯網信息服務等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;股東信息顯示，該公司由阿里巴巴旗下廣州大魚快樂信息技術有限公司全資持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;189&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-50d477f860fc194e7c26bfc25727db08669.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334598</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334598</guid>
            <pubDate>Fri, 07 Feb 2025 09:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Stanford 團隊展現 RWKV 多智能體優勢，UVa 團隊突破 RWKV 端側性能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日 RWKV 生態新增來自海外名校的兩項工作：Stanford（斯坦福大學）團隊的 RWKV 多智能體研究，和 UVa（弗吉尼亞大學） 團隊的 RWKV 端側優化研究。&lt;/p&gt; 
&lt;h2&gt;RWKV 多智能體強化學習&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;開源項目地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsocialdeductionllm.github.io%2F&quot; target=&quot;_blank&quot;&gt;https://socialdeductionllm.github.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;論文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.06060&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.06060&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;四名斯坦福大學研究人員共同發佈了《Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning》論文，研究&lt;strong&gt;使用多智能體強化學習&lt;/strong&gt;（multi-agent reinforcement learning）訓練 RWKV 模型，使其能&lt;strong&gt;通過自然語言交流&lt;/strong&gt;完成**《Among Us》遊戲**的推理過程並贏下游戲。&lt;/p&gt; 
&lt;p&gt;論文已被 AAMAS 2025 主會（口頭報告）接收，論文作者在 RWKV Discord 頻道分享了這一消息，並分享了「&lt;strong&gt;為什麼使用 RWKV-4-World 模型&lt;/strong&gt;」。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;為何選擇 RWKV 而非 Transformer？&lt;/strong&gt; 因為 RWKV 的顯存佔用恆定、理論上支持無限上下文長度。Among Us 遊戲單局軌跡可達數萬 token，Transformer 模型顯存佔用過高，而 RWKV 的循環結構通過 T-BPTT 實現無限上下文訓練，單 GPU 即可完成訓練（論文的實驗基於一張 48G 顯存的 A40 顯卡）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;為何使用 RWKV-4，而非性能更好的 RWKV-5/6/7 模型？&lt;/strong&gt; 研究在 2023 年夏季啓動，當時 RWKV-4 是唯一可用版本。團隊通過修改 RWKV-4 的 CUDA 內核優化計算效率，沒有時間適配 RWKV 新架構。未來計劃適配 RWKV-7，進一步提升模型性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-02983c1404f33542f90159bef9c5fdf2346.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;接下來我們一起看看該工作的創新點，以及 RWKV 模型在論文中表現出來的強大性能：&lt;/p&gt; 
&lt;h3&gt;遊戲規則&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;《Among Us》是類似於狼人殺/鴨鵝殺的社交推理遊戲。&lt;/p&gt; 
 &lt;p&gt;遊戲規則：在一輛宇宙飛船上有&lt;strong&gt;船員&lt;/strong&gt;（Crewmates）和&lt;strong&gt;內鬼&lt;/strong&gt;（Impostors）兩種角色。內鬼的目標是暗中破壞飛船設施、殺死船員，並&lt;strong&gt;在討論時偽裝成普通船員&lt;/strong&gt;以避免被發現，船員的目標則是&lt;strong&gt;通過討論進行邏輯推理，然後投票淘汰內鬼&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0b88f3704e3b60ed6f4133f07c8ad866e18.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下圖是論文中智能體在《Among Us》遊戲的循環示意圖，遊戲開始時同時向所有智能體發送觀察結果，然後在每個時間步從一組有效的行動中收集標記化的行動歷史。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c38fda38f6c099df315a41dec73b26848b5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;無需人工數據，純 Self-Play&lt;/h3&gt; 
&lt;p&gt;這項工作創新的地方在於&lt;strong&gt;完全不依賴人工標註數據&lt;/strong&gt;，而是通過&lt;strong&gt;純自我對抗學習（Self-Play）&lt;/strong&gt; 如環境反饋（投票結果、任務進度）和智能體（Agent）間交互來訓練 AI 的語言交流能力。AI 智能體通過多輪博弈，逐步學習如何在討論中提取關鍵信息，並形成自己的投票策略。&lt;/p&gt; 
&lt;p&gt;完整的訓練框架引入了 &lt;strong&gt;RL + 聽説雙重訓練機制&lt;/strong&gt;。先通過強化學習（RL），使得 AI 在沒有人工數據示例的情況下學會如何行動。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以下是用於優化 AI 長期遊戲勝率的&lt;strong&gt;強化學習損失函數&lt;/strong&gt;，同時使用 &lt;strong&gt;KL 約束&lt;/strong&gt; 限制 AI 不能偏離自然語言分佈。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1bb307c78419f8a009bcef196d0887c397e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，研究團隊引入了一種新的&lt;strong&gt;聽/説雙重獎勵機制&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聽力獎勵（Listening Reward）&lt;/strong&gt;：聽力的損失函數：&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7fc4544ddeccf7c24fb8efec492c74509f0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; ，用於訓練 AI 通過討論預測環境信息，從而預測誰是內鬼。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;融合聽力獎勵後，強化學習的損失函數如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-576c520ddcf32c888d2379a877c54178f71.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;表達獎勵（Speaking Reward）&lt;/strong&gt;：獎勵 AI 生成&lt;strong&gt;能影響隊友決策&lt;/strong&gt;的消息，好的發言會獲得更高的獎勵&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c2a008d036b28c097870a2f5bda300801f6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;融合了 RL + 聽説雙重獎勵後，用於訓練智能體的強化學習損失函數如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5d895b7a72f4c08f0ea1364b96b6d292b4a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;但&lt;strong&gt;RL 算法非常善於 Hack 規則的漏洞&lt;/strong&gt;。如果不加幹預，智能體可能會&lt;strong&gt;抓住 Among Us 遊戲規則的漏洞來「作弊」並進入失效模式（Failure Modes）&lt;/strong&gt;，比如船員們使用非自然語言來「對暗號」（非自然語言交流），或者在討論階段集體沉默等內鬼説話（作弊合作）等。&lt;/p&gt; 
&lt;h3&gt;失效模式與解決方案&lt;/h3&gt; 
&lt;p&gt;為了避免模型偏離自然語言的軌道或偏離任務目標，作者團隊採取了一些巧妙的解決方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;KL 約束&lt;/strong&gt;：為了避免模型在討論過程中「跑偏」，團隊在訓練中加入了 KL 約束，強制模型始終保持使用自然語言進行交流&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;凍結部分智能體&lt;/strong&gt;：為了防止模型在訓練過程中學會不自然的策略（比如大家都不發言，只等內鬼發言），研究團隊選擇凍結部分智能體，讓它不參與策略調整，從而避免了「集體擺爛」的現象&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;世界建模損失（World Modeling Loss）&lt;/strong&gt;：為了確保模型在每次討論時都能記住重要的上下文信息，論文引入了世界建模損失：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ab0ff0c1f9563ddec1fc4028d4f477870f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;世界建模損失用於幫助智能體&lt;strong&gt;學習更長期、更合理的策略&lt;/strong&gt;，避免出現像&lt;strong&gt;等待策略&lt;/strong&gt;（Waiting Strategy，智能體一直待在起始房間不動，然後投票淘汰移動過的玩家）等退化現象。這些策略雖然在短期內有效，但嚴重破壞了遊戲的真實性和挑戰性。&lt;/p&gt; 
&lt;p&gt;最終，&lt;strong&gt;完整的損失函數&lt;/strong&gt;結合了&lt;strong&gt;強化學習（RL）、聽力（Listening）、表達（Speaking）、世界建模（WM）&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a294cb582f4032308a32934f5867d528edc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過新穎的「聽説獎勵」 結合 KL 約束和世界建模損失等優化，斯坦福團隊的研究突破了 RL 傳統上的侷限，訓練出來的 $\text {RWKV}_{RL + L + S}$ 模型在社交推理任務中展現出了&lt;strong&gt;更接近人類的行為模式&lt;/strong&gt;，為多智能體協作和複雜場景下的語言模型訓練提供了新範式。&lt;/p&gt; 
&lt;h3&gt;RWKV 模型：勝率碾壓 + 類人行為湧現&lt;/h3&gt; 
&lt;p&gt;論文選擇 RWKV-4-World 模型作為語言模型基座，實驗結果驗證了其強大性能：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 勝率碾壓&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;完整訓練框架（RL + 聽説）的 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b4c7cc6029197805d2a1990e222c0876327.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 模型（RWKV-4-World-1.5B）， &lt;strong&gt;Among US 遊戲勝率是傳統強化學習模型的 2 倍&lt;/strong&gt;，&lt;strong&gt;且優於 4 倍參數量的 RWKV 基底模型（RWKV-4-World-7B）&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-65d89373722bae0d1baa0845b81a2c8516e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;上圖：不同算法訓練的模型在基礎環境（2 × 2 網格，每名隊員 4 項任務，共 5 名玩家）中的勝率，經過完整框架訓練的 RWKV 模型（橙色）勝率大幅領先傳統 RL 模型（淺灰色）。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在未訓練過的環境配置中（如不同地圖佈局、任務數量），RWKV 模型仍能保持高勝率，展現了強大的泛化能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-37b7ac0067fd82298bcbd9f8e9653fcfd9d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;上圖：使用不同算法訓練的 AI 船員，在不同環境配置下的獲勝率，環境修改包括更改遊戲地圖形狀、任務數量和玩家數量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;2. 類人行為湧現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI 學會指控嫌疑人（如「Player Green 在屍體房間離開」），會提供證據支持自己的觀點。甚至會編造謊言，試圖誤導隊友（類似人類玩家策略）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. 強適應能力&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，遊戲裏的內鬼也是特別強化（反指控、轉移焦點等）過的，其損失函數：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-53e0a4041e0bdd1e07d38ec3634d7acb668.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然而，面對自適應訓練的內鬼，RWKV 船員仍能保持 50% 以上勝率，展現了強大的抗幹擾能力。&lt;/p&gt; 
&lt;p&gt;實驗數據驗證了 RWKV 在&lt;strong&gt;多智能體社交推理&lt;/strong&gt;中的卓越性能，更揭示了 RWKV 在&lt;strong&gt;輕量化部署與長序列決策場景&lt;/strong&gt;的獨特優勢。&lt;/p&gt; 
&lt;h3&gt;未來工作&lt;/h3&gt; 
&lt;p&gt;論文作者表示後續將開展更多 RWKV 相關研究，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;訓練 RWKV 模型去&lt;strong&gt;塑造其他 LLM 智能體的行為和邏輯&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;訓練 RWKV &lt;strong&gt;向人類解釋多智能體的團隊決策邏輯&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高效的世界建模&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;利用 RWKV 長序列處理能力&lt;strong&gt;分析市場數據&lt;/strong&gt;，實現金融時序預測&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RWKV 4/5/6/7 的純 Jax 實現&lt;/strong&gt;，實現更高效訓練和推理&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，作者認為 &lt;strong&gt;RWKV 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2FRWKV-Fine-Tuning%2FState-Tuning&quot; target=&quot;_blank&quot;&gt;state tuning&lt;/a&gt; 在多智能體的研究上擁有極大的優勢。&lt;/strong&gt; 通過切換 state 來改變智能體的「基因」，遠比切換模型、切換 LoRA 等方式更方便、更無縫。&lt;/p&gt; 
&lt;h2&gt;RWKV 端側部署優化&lt;/h2&gt; 
&lt;p&gt;UVa（弗吉尼亞大學） 團隊提出了 &lt;strong&gt;RWKV-Lite&lt;/strong&gt;，一套從模型架構優化到後訓練壓縮的&lt;strong&gt;高效 RWKV 模型壓縮技術&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在保持&lt;strong&gt;模型準確率&lt;/strong&gt;基本不變的情況下，RWKV-Lite 將內存佔用降低了 &lt;strong&gt;3.4 – 5 倍&lt;/strong&gt;；若結合量化，整體內存需求甚至可降低 &lt;strong&gt;10&lt;/strong&gt; 倍。與此同時，該方法帶來的計算開銷微乎其微，非常適合邊緣部署。&lt;/p&gt; 
&lt;p&gt;該論文已被機器學習頂會 ICML 2024 收錄。論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fhtml%2F2412.10856v3&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/html/2412.10856v3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f08360bb6b5f456bbe5d984a3838d621393.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-Lite 的壓縮方向大致有以下三點：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;低秩近似（Low-Rank Approximation）&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;針對 RWKV 塊中的投影權重矩陣（如 &lt;code&gt;channel-mix&lt;/code&gt; 和 &lt;code&gt;time-mix&lt;/code&gt; 層），通過 &lt;strong&gt;奇異值分解（SVD）&lt;/strong&gt; 將大型矩陣拆分為兩個低秩矩陣，減少參數量的同時保留關鍵信息。&lt;/p&gt; 
&lt;p&gt;實驗顯示，低秩壓縮可實現 4 倍參數壓縮，且可以通過持續訓練（Continual Training）恢復精度損失。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;稀疏性利用（Sparsity Exploitation）&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;發現 RWKV 的 FFN 層存在顯著稀疏性（67%-83% 的神經元激活率為零），提出混合預測器（MLP + 1-bit 量化）動態加載關鍵神經元權重，減少推理時內存佔用。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;嵌入緩存與分層分類頭&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;嵌入緩存：通過緩存高頻詞嵌入，減少對大型嵌入層的依賴&lt;/li&gt; 
 &lt;li&gt;分層分類頭：將詞彙表聚類，僅加載與當前預測相關的詞權重&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下圖是論文演示在一個可穿戴設備上運行壓縮後的 RWKV 模型（帶可視化屏幕），開發板型號為 Orange Pi Zero 2W，板載 CPU 1.5GHz 4x Cortex-A53，內存 4GB 。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2fa17ed229ff21b66bd05d7600daba391fc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;歡迎開展 RWKV 學術研究&lt;/h2&gt; 
&lt;p&gt;我們歡迎大家基於最新最強的 RWKV-7 架構開展學術研究！&lt;/p&gt; 
&lt;p&gt;最新發布的 RWKV-7 2.9B 模型在各類評測中表現出色，其英文和多語言能力顯著超越所有同尺寸模型（英文評測 71.1%，多語言評測 62.3%），超越了包括 Llama 3.2 3B（英文評測 68.7%，多語言評測 57.3%）、Qwen2.5 3B（英文評測 68.6%，多語言評測 57.0%）等知名優秀開源模型。&lt;/p&gt; 
&lt;p&gt;此外，我們為 RWKV 學術研究&lt;strong&gt;提供全面的支持和激勵&lt;/strong&gt;，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;力所能及的&lt;strong&gt;技術支持&lt;/strong&gt;和&lt;strong&gt;算力支持&lt;/strong&gt;，具體支持請在公眾號內發消息聯繫我們溝通&lt;/li&gt; 
 &lt;li&gt;對 RWKV 學術研究提供&lt;strong&gt;生態獎金&lt;/strong&gt;，詳情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生態內容徵集大賽 &lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;微軟已經將 RWKV 全面引入 Windows 10/11 系統&lt;/strong&gt;，足以證明 RWKV 的端側優勢。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a4517caf796e82678e9381efeae1b07dd15.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334597</guid>
            <pubDate>Fri, 07 Feb 2025 09:31:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>2025 年 xbatis 誕生了，它是一款超級好用的基於 mybatis 的 ORM 框架，沒有之一！！！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;h1&gt;官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn&quot; target=&quot;_blank&quot;&gt;https://xbatis.cn&lt;/a&gt;&lt;/h1&gt; 
 &lt;h1&gt;xbatis 是什麼&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23xbatis-%25E6%2598%25AF%25E4%25BB%2580%25E4%25B9%2588&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h1&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;xbatis 是一款基於 mybatis 的 ORM 框架，ORM 程度非常高，幾乎不需要再寫 SQL;&lt;br&gt; &lt;br&gt; 同時內置多種&lt;strong&gt;數據庫函數&lt;/strong&gt;,具有良好的不同數據庫遷移能力,注意它可以&lt;strong&gt;同時支持多種數據庫！！！&lt;/strong&gt;，一款真正意義上的 ORM 框架&lt;br&gt; &lt;br&gt; xbatis 具有良好程序設計，非常穩定（經過 testcase 驗證）；優雅的 API、簡而易懂的方法操作，讓你寫代碼和寫 SQL 幾乎一樣，學習成本幾乎為零。&lt;br&gt; &lt;br&gt; 功能強大，支持&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;多表/子查詢,自動分頁，優雅的 XML 自動分頁&lt;/strong&gt;等眾多功能！！&lt;/p&gt; 
 &lt;h1&gt;特徵&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23%25E7%2589%25B9%25E5%25BE%2581&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h1&gt; 
 &lt;h2&gt;1、很輕量,非常輕量&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23_1%25E3%2580%2581%25E5%25BE%2588%25E8%25BD%25BB%25E9%2587%258F-%25E9%259D%259E%25E5%25B8%25B8%25E8%25BD%25BB%25E9%2587%258F&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;輕量級封裝 mybatis。 其他框架都比較深度修改了 mybatis 源碼。&lt;/p&gt; 
 &lt;h2&gt;2、高性能&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23_2%25E3%2580%2581%25E9%25AB%2598%25E6%2580%25A7%25E8%2583%25BD&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;對比其他 mybatis 框架，性能不差，接近最優。&lt;/p&gt; 
 &lt;h2&gt;3、靈活方便&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23_3%25E3%2580%2581%25E7%2581%25B5%25E6%25B4%25BB%25E6%2596%25B9%25E4%25BE%25BF&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;高度實現 ORM，查詢 API 零學習成本。&lt;/p&gt; 
 &lt;h2&gt;4、高可用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23_4%25E3%2580%2581%25E9%25AB%2598%25E5%258F%25AF%25E7%2594%25A8&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;可應付 90% 的 SQL 需求。&lt;/p&gt; 
 &lt;h2&gt;5、可靠，安全&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23_5%25E3%2580%2581%25E5%258F%25AF%25E9%259D%25A0-%25E5%25AE%2589%25E5%2585%25A8&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;沒有過於複雜的設計，但是 API 卻很豐富，足夠使用！&lt;br&gt; 其他框架或多或少設計的過於複雜，反而容易出現各種問題。&lt;/p&gt; 
 &lt;h2&gt;6、優秀的分頁和 SQL 優化能力&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23_6%25E3%2580%2581%25E4%25BC%2598%25E7%25A7%2580%25E7%259A%2584%25E5%2588%2586%25E9%25A1%25B5%25E5%2592%258Csql%25E4%25BC%2598%25E5%258C%2596%25E8%2583%25BD%25E5%258A%259B&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;/h2&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;自動過濾多餘的 left join 、count 查詢，自動去除 order by ，無效的 left join&lt;br&gt; 以及 select 部分替換成 select count(&lt;em&gt;) 或 select 1 後，在 select count(&lt;/em&gt;)&lt;br&gt; &lt;br&gt; 內置分頁功能，超級牛逼！&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334593</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334593</guid>
            <pubDate>Fri, 07 Feb 2025 09:14:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
    </channel>
</rss>