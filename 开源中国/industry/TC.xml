<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 19 May 2025 03:28:42 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>張朝陽：如果晚生 30 年，自己也會捲入到 AI 裏面</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在最近召開的 2025 搜狐科技年度論壇上，搜狐創始人、董事局主席兼首席執行官張朝陽，與清華大學講席教授張亞勤及獵豹移動董事長兼 CEO 傅盛等三位不同領域人士，圍繞人工智能（AI）、人形機器人和腦科學等前沿科技展開了深入的討論。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-d1f6ff151f11d7f2624bff8dbdb8b1e473d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;張朝陽在討論中表示，&lt;strong&gt;如果晚生 30 年，自己也會捲入到 AI 裏面，包括人形機器人，腦科學&lt;/strong&gt;。他認為，目前正是一個比特與分子、原子交匯的時代，物理世界和生物世界的融合為年輕人提供了追逐新興風口的機會。在他的視角中，年輕人可以在這一時代中大膽嘗試，而年長者則更傾向於優化現有的商業模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在談及中美之間的 AI 差距時，傅盛強調了中國在工程化和應用創新方面的潛力，特別是在智能體等貼近實際應用的領域中，中國有望超越對手。張亞勤則指出，人才的積累是核心競爭力，並提到年輕人在人工智能領域的進展速度令人矚目，清華大學的相關研究成果是美國的五倍左右。他認為，人工智能最大的創新發生在過去五年，未來五年也將是一個關鍵期。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;張朝陽總結道，中國在 AI 和科技領域的競爭力源於人們的聰明才智和勤奮工作，加上龐大的人口基數，這種競爭環境推動了中國在各個科技領域的追趕與超越，包括芯片技術和算力問題的解決。他對中國在人工智能領域的未來充滿信心，認為我們正處於一個充滿機遇的時代。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350569</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350569</guid>
      <pubDate>Mon, 19 May 2025 02:53:40 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>StarRocks MCP Server 開源發佈：為 AI 應用提供強大分析中樞</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;過去，開發者要讓大模型（LLM）使用數據庫查詢數據，往往需要開發專屬插件、設計複雜的接口或手動構建 Prompt，這不僅費時費力，而且很難在不同模型之間複用。StarRocks MCP Server 提供了一個「通用適配器」接口，讓各種 LLM（如 Claude、OpenAI、Gemini）都能標準化地訪問 StarRocks，使得模型能夠直接執行 SQL 查詢並探索數據庫內容，無需複雜的配置或集成。&lt;/p&gt; 
&lt;p&gt;這意味着：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;無需開發專用 Agent 插件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型自動發現和調用 StarRocks 暴露的查詢/分析工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構建數據問答、智能分析、自動報表等應用變得更簡單&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;👉🏻 項目地址：https://github.com/StarRocks/mcp-server-starrocks&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;什麼是 MCP？&lt;/h2&gt; 
&lt;p&gt;首先，我們來瞭解什麼是 MCP。&lt;strong&gt;MCP（Model Context Protocol）&lt;/strong&gt; 是一種用於規範模型與上下文交互的通信協議，旨在標準化模型輸入輸出的數據結構、元信息傳遞及上下文管理機制。它通過定義統一的接口協議（如請求/響應格式、狀態跟蹤、多輪對話標識等），確保模型在複雜應用場景（如多模態交互、長上下文推理）中高效處理上下文依賴關係，同時支持動態上下文更新與歷史信息檢索。典型應用包括大語言模型（LLM）的對話系統、知識增強推理等。&lt;/p&gt; 
&lt;p&gt;通俗的來説，MCP 就像 AI 世界的「USB 接口」，它提供了一種通用標準，讓各種 AI 模型和智能代理（agents）能夠無縫連接、交換信息，就像 USB 讓不同品牌的設備（鼠標、鍵盤、硬盤等）都能即插即用一樣。通過 MCP，不同 AI 組件可以像樂高積木一樣自由組合，使 AI 變得更加智能、靈活和協作高效。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="719" src="https://oscimg.oschina.net/oscnet/up-90681374f708b3497f242a553ae2aa52a2a.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（MCP 架構示意圖）&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;MCP 核心組件&lt;/h2&gt; 
&lt;p&gt;MCP 的核心是一個簡單但強大的客戶端-服務器架構，用於將語言模型與現實世界的功能連接起來。&lt;/p&gt; 
&lt;p&gt;你可以把它想象成一個智能家居中控系統：&lt;/p&gt; 
&lt;p&gt;MCP Host（宿主） = 智能助手（如小愛同學、Alexa）&lt;/p&gt; 
&lt;p&gt;MCP Client （客戶端）= 控制中樞&lt;/p&gt; 
&lt;p&gt;MCP Server （服務器）= 各種設備（燈、空調、門鎖等）&lt;/p&gt; 
&lt;p&gt;你對智能助手説「打開空調」，你不需要知道空調的品牌、遙控器協議或者哪個網關。系統會通過統一協議找到正確的設備、下發正確的指令。在 MCP 裏，LLM 也是這樣發起一個請求，比如「獲取銷售報表」，Client 就會找到對應的數據源 Server，並返回數據。&lt;/p&gt; 
&lt;p&gt;這三大組件的作用如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Host：&lt;/strong&gt;基於 LLM 的應用程序，如 Claude Desktop 或未來集成 AI 的 IDE，用戶通過它提出問題或發起操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Client：&lt;/strong&gt;處理連接邏輯。每個客戶端與一個服務器建立連接，負責通信和協調。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Server：&lt;/strong&gt;暴露具體能力，如文件訪問、天氣 API 等。每個服務器通過標準接口提供一組特定的工具、資源或提示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCP Server 提供三類核心能力：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具（Tools）&lt;/strong&gt;：模型可以調用的可執行函數，如「獲取天氣預報」或「運行 shell 命令」。模型可自行決定何時使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;資源（Resources）&lt;/strong&gt;：如文件、日誌或 API 響應等。這些是模型可以讀取但不能修改的上下文信息。客戶端負責決定何時展示哪些資源。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示詞（Prompts）&lt;/strong&gt;：預設的模板，引導模型如何互動。例如生成提交信息、進行調試指導。通常由用戶選擇，而非模型自行決定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;StarRocks MCP 功能介紹&lt;/h2&gt; 
&lt;p&gt;StarRocks MCP Server 充分利用了 MCP 的核心能力，為大語言模型提供了與 StarRocks 數據庫進行深度交互的強大工具集和豐富的上下文資源。具體來説，它實現了以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具 (Tools)&lt;/strong&gt;：這些是模型可以按需調用的「技能」，使其能夠主動與 StarRocks 交互：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;db_overview&lt;/code&gt;&lt;/strong&gt;：獲取指定數據庫中所有表的概覽信息。模型可以提供數據庫名（若未提供且配置了默認數據庫，則使用默認庫）。此工具會遍歷庫中所有表，併為每張表調用 &lt;code&gt;table_overview&lt;/code&gt; 的邏輯獲取其詳情。同樣支持緩存和強制刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;table_overview&lt;/code&gt;&lt;/strong&gt;：快速獲取指定表的概覽信息。模型只需提供表名（可包含數據庫名，如 &lt;code&gt;db_name.table_name&lt;/code&gt;；若未指定數據庫名且配置了默認數據庫，則使用默認庫）。此工具會返回表的列定義 (&lt;code&gt;DESCRIBE table&lt;/code&gt;)、總行數 (&lt;code&gt;COUNT(*)&lt;/code&gt;) 以及少量樣本數據 (&lt;code&gt;SELECT * FROM table LIMIT 3&lt;/code&gt;)。為了提高效率，該信息會被緩存，並可通過 &lt;code&gt;refresh=true&lt;/code&gt; 參數強制刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;read_query&lt;/code&gt;&lt;/strong&gt;：執行只讀的 SQL 查詢（如 &lt;code&gt;SELECT&lt;/code&gt; 語句），並以 CSV 格式返回結果集，包含列名和數據行。這使得模型可以直接獲取和分析數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;write_query&lt;/code&gt;&lt;/strong&gt;：執行數據定義語言 (DDL) 或數據操作語言 (DML) 等寫操作，如 &lt;code&gt;CREATE TABLE&lt;/code&gt;, &lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;，並返回操作結果（如影響行數、執行時間）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;query_and_plotly_chart&lt;/code&gt;&lt;/strong&gt;：一個強大的分析工具，它首先執行用戶提供的 SQL 查詢從 StarRocks 獲取數據，然後利用該數據和用戶指定的 Plotly Express 表達式（一個 Python 函數調用字符串）動態生成圖表。圖表最終以 Base64 編碼的圖片形式返回給模型，極大增強了數據洞察的可視化能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;資源 (Resources)&lt;/strong&gt;：這些是模型可以讀取的上下文信息，幫助模型理解 StarRocks 的結構和狀態：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///databases&lt;/code&gt;&lt;/strong&gt;：列出 StarRocks 集羣中的所有數據庫名稱。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///{db}/tables&lt;/code&gt;&lt;/strong&gt;：列出指定數據庫 (&lt;code&gt;{db}&lt;/code&gt;) 中的所有表名。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///{db}/{table}/schema&lt;/code&gt;&lt;/strong&gt;：獲取指定數據庫 (&lt;code&gt;{db}&lt;/code&gt;) 中特定表 (&lt;code&gt;{table}&lt;/code&gt;) 的創建語句 (&lt;code&gt;SHOW CREATE TABLE {db}.{table}&lt;/code&gt; 的結果），詳細展示表的結構信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;proc:///{+path}&lt;/code&gt;&lt;/strong&gt;：訪問 StarRocks 內部的 &lt;code&gt;/proc&lt;/code&gt; 路徑（如 &lt;code&gt;/proc/backends&lt;/code&gt;, &lt;code&gt;/proc/dbs/{db_id}&lt;/code&gt;），獲取集羣、節點、數據庫、表、事務、作業等詳細的運行時狀態和元數據信息，類似於 Linux 的 &lt;code&gt;/proc&lt;/code&gt; 文件系統。這為模型提供了深入瞭解 StarRocks 內部運作的窗口。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示詞 (Prompts)&lt;/strong&gt;：目前 StarRocks MCP Server 暫未定義特定的預設提示詞。MCP 的設計允許未來根據場景需求靈活添加，以更好地引導模型與 StarRocks 進行特定類型的交互。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;通過這些精心設計的工具和資源，StarRocks MCP Server 使大語言模型能夠像經驗豐富的數據分析師一樣，自主地探索數據、執行分析任務，並以多樣化的形式（文本、圖表）呈現結果，從而將 StarRocks 的強大 OLAP 能力無縫對接到 AI 應用中。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;StarRocks MCP Server 應用場景&lt;/h2&gt; 
&lt;p&gt;瞭解了什麼是 MCP 之後，來瞭解一下 StarRocks MCP Server 能應用在哪些場景中：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.實時數據分析與 AI 增強決策&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：讓 AI 模型（如 LLM）能夠實時查詢 StarRocks 中的業務數據，並結合歷史上下文生成更精準的分析報告或建議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;金融風控&lt;/strong&gt;：AI 結合 StarRocks 的實時交易數據，動態評估風險並生成預警。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;電商推薦&lt;/strong&gt;：基於用戶實時行為（如瀏覽、加購）和 StarRocks 的 OLAP 分析，優化個性化推薦策略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.自動化數據報表與 BI 增強&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：通過 MCP 協議，讓 AI 自動生成 SQL 查詢、執行聚合計算，並返回可視化報表，減少人工幹預。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;廣告投放分析&lt;/strong&gt;：AI 自動查詢 StarRocks 的廣告曝光、點擊數據，生成優化建議。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;運營駕駛艙&lt;/strong&gt;：結合自然語言交互（如「顯示最近 7 天銷售額趨勢」），自動從 StarRocks 拉取數據並生成 Dashboard。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.複雜查詢的 AI 優化與加速&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：利用 MCP 管理查詢上下文，讓 AI 輔助優化 StarRocks 的多表 JOIN、聚合計算等複雜操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;用戶畫像分析&lt;/strong&gt;：AI 自動構建 Roaring Bitmap 查詢，計算用戶留存、漏斗分析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨業務分析&lt;/strong&gt;：AI 解析業務需求，自動生成高效 StarRocks SQL，避免全表掃描。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.統一數據湖與 AI 增強查詢&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：通過 MCP 讓 AI 同時訪問 StarRocks 和外部數據源（如 Hive、Elasticsearch），實現聯邦查詢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;混合分析&lt;/strong&gt;：AI 自動組合 StarRocks 的聚合數據和 Hive 的原始日誌，生成完整業務洞察。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知識增強&lt;/strong&gt;：AI 查詢 StarRocks 的業務數據 + 外部知識庫（如論文、行業報告），生成深度分析。&lt;/p&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;StarRocks x MCP 快速上手&lt;/h3&gt; 
&lt;p&gt;StarRocks 是首批通過內置 MCP Server 原生集成 MCP 協議的引擎之一。這使得 StarRocks 不再只是一個高性能查詢引擎，而是升級為一個專為智能 Agent 交互優化的分析執行環境。&lt;/p&gt; 
&lt;p&gt;這一切都構建在 StarRocks 現代化的執行引擎之上——向量化、高併發、C++ 編寫，自設計之初就面向低延遲和高併發場景。&lt;/p&gt; 
&lt;p&gt;通過將面向 Agent 的標準協議（MCP）與面向現代工作負載的執行引擎結合，StarRocks 為從探索到生產部署的 Agent 驅動分析工作流提供了直接路徑。你無需重新設計架構，就可以立即開始構建智能分析應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.部署 StarRocks 集羣，準備數據&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;部署 Starrocks 集羣，假設部署到本地 localhost

導入 quickstart 中的 crashdata 數據
https://docs.starrocks.io/docs/quick_start/shared-nothing/#new-york-city-crash-data

CREATE TABLE IF NOT EXISTS crashdata (
    CRASH_DATE DATETIME,
    BOROUGH STRING,
    ZIP_CODE STRING,
    LATITUDE INT,
    LONGITUDE INT,
    LOCATION STRING,
    ON_STREET_NAME STRING,
    CROSS_STREET_NAME STRING,
    OFF_STREET_NAME STRING,
    CONTRIBUTING_FACTOR_VEHICLE_1 STRING,
    CONTRIBUTING_FACTOR_VEHICLE_2 STRING,
    COLLISION_ID INT,
    VEHICLE_TYPE_CODE_1 STRING,
    VEHICLE_TYPE_CODE_2 STRING
);

curl --location-trusted -u root             \
    -T ./NYPD_Crash_Data.csv                \
    -H "label:crashdata-0"                  \
    -H "column_separator:,"                 \
    -H "skip_header:1"                      \
    -H "enclose:\""                         \
    -H "max_filter_ratio:1"                 \
    -H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i'),BOROUGH,ZIP_CODE,LATITUDE,LONGITUDE,LOCATION,ON_STREET_NAME,CROSS_STREET_NAME,OFF_STREET_NAME,NUMBER_OF_PERSONS_INJURED,NUMBER_OF_PERSONS_KILLED,NUMBER_OF_PEDESTRIANS_INJURED,NUMBER_OF_PEDESTRIANS_KILLED,NUMBER_OF_CYCLIST_INJURED,NUMBER_OF_CYCLIST_KILLED,NUMBER_OF_MOTORIST_INJURED,NUMBER_OF_MOTORIST_KILLED,CONTRIBUTING_FACTOR_VEHICLE_1,CONTRIBUTING_FACTOR_VEHICLE_2,CONTRIBUTING_FACTOR_VEHICLE_3,CONTRIBUTING_FACTOR_VEHICLE_4,CONTRIBUTING_FACTOR_VEHICLE_5,COLLISION_ID,VEHICLE_TYPE_CODE_1,VEHICLE_TYPE_CODE_2,VEHICLE_TYPE_CODE_3,VEHICLE_TYPE_CODE_4,VEHICLE_TYPE_CODE_5" \
    -XPUT http://localhost:8030/api/quickstart/crashdata/_stream_load
    &lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2.啓動 MCP Client&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2.1 配置客戶端添加 mcp-server-starrocks，客戶端使用的是 DeepChat&lt;/p&gt; 
&lt;p&gt;大家可以使用這個優化過的版本：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdecster%2Fdeepchat" target="_blank"&gt;https://github.com/decster/deepchat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-c56f1c9bcdcd53827339f3ed235c5884640.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-86469cacb7fd6f7c162e6ae3b9310861b86.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-27900bd2f64691dd1af2f7ae19b109d82a8.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2.2 配置成功後在對話選項中可以添加使用 mcpserver&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-9c20710df0b7cb55fa3b54c2f22b6ba6fba.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;補充説明：在本次 Demo 中，我們使用的是 DeepChat 作為 MCP Client。除此之外，市面上還有如 Claude Desktop、Cline 等主流客戶端，用戶可根據個人偏好進行配置。需要注意的是，由於我們期望返回結果包含表格和圖片，部分客戶端可能不支持圖片顯示，選擇時建議將此因素一併考慮。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Demo 演示&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下面的視頻中演示瞭如何以對話形式對 StarRocks 中的數據集進行可視化分析&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV195EizWEFT%2F%3Fvd_source%3D1cb452610138142d1300dd37a6162a88" target="_blank"&gt;https://www.bilibili.com/video/BV195EizWEFT/?vd_source=1cb452610138142d1300dd37a6162a88&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;最後，我們總結一下 StarRocks MCP server 的核心價值：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;讓 AI 具備實時 OLAP 能力，減少人工 SQL 編寫和數據分析成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;增強決策智能，結合歷史數據和實時計算，提供更精準的業務建議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;統一數據訪問層，讓 AI 無縫對接結構化數據（StarRocks）與非結構化數據（文檔、日誌）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;未來，隨着 MCP 生態的擴展（如支持更多數據庫、BI 工具），這種結合將在，金融、電商、IoT、醫療，等領域發揮更大作用。StarRocks 的朋友們，快來開啓更多智能應用！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5658056/blog/18414667</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5658056/blog/18414667</guid>
      <pubDate>Mon, 19 May 2025 02:45:40 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>超擬人 AI 老師、因材施教 AI 輔導，大模型技術在教育中能做好哪些事？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p style="text-align:justify"&gt;&lt;span style="display:none"&gt;&amp;nbsp;&lt;/span&gt;在生成式人工智能重塑各行業版圖的當下，教育領域也正經歷着一場靜水深流的技術變革。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;大模型不再只是實驗室裏的概念驗證，而是逐步滲透進作業批改、個性化輔導、學情分析等教育核心場景，推動着"千人千面"教育理想的落地。在這場技術與教育的雙向奔赴中，如何平衡技術創新與教育本質？如何讓 AI 真正成為教育公平的推進器而非技術泡沫？我們與深耕 AI 教育應用多年的專家丁小晶展開對話。作為百度小度教育技術負責人，他帶領團隊打造的 AI 教師系統已成為行業標杆，其團隊在教育大模型應用層面積累的實戰經驗與冷思考，或許能幫助我們更清晰地看到技術賦能教育的可行路徑。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;丁小晶 &lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;百度資深工程師/小度教育技術負責人/大模型應用技術專家&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;資深大模型 AI 應用技術專家與管理者，技術創新與項目管理的複合型人才，致力於 AI 大模型應用創新。碩士畢業於中國科學院計算技術研究所，從事高性能計算技術研究。先後在百度、三星等世界知名企業工作，並有多年旅日工作經歷。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;擁有超過 15 年的計算機及 AI 領域經驗、10 年 AI 及 5 年團隊管理經驗，精通大模型技術及多語言編程，屢獲榮譽，持多項專利。目前作為小度教育業務技術負責人，研究基於大模型 AI 教育產品創新，引領小度教育成為行業先鋒。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;丁小晶、崔遠，編著《&lt;strong&gt;深度剖析 DeepSeek 大模型： 原理、開發與優化部署&lt;/strong&gt;》&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fitem.m.jd.com%2Fproduct%2F14401797.html" rel="nofollow" target="_blank"&gt;https://item.m.jd.com/product/14401797.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：目前大模型在教育領域的主要應用場景有哪些？能否結合具體案例説明其效果？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;目前大模型技術對教育行業進行深入重構，今年 4 月份的 2025 年教育裝備展上明顯能看到，教育從業公司都在往大模型應用方向轉型。個性化 AI 老師是一個主流趨勢。藉助大模型技術，可以實現個性化 1v1 的授業、答疑、解惑，大幅降低教育成本，解決教育資源分佈不均衡的問題。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;比如 AI 作業批改和 AI 講題答疑的效果提升，在目前的 AI 自習室行業已經大面積使用，通過 AI 老師逐步降低學生對真人老師的依賴，還可以培養自主學習的習慣，已經逐步在顛覆傳統教培行業。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：多模態技術在教育中的應用進展如何？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;多模態技術非常重要，甚至可以説，沒有多模態技術效果的快速提升，教育行業不可能如此迅猛發展。比如在前面提到的 AI 作業批改和 AI 講題答疑方向，完全靠純文本大模型是無法滿足需求的，非常依賴對大模型的圖片理解能力。還比如超擬人 AI 老師，語音情感大模型就起來非常關鍵的作用。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：大模型存在幻覺，在教育中，這是否會導致輸出一些錯誤知識，如錯誤公式推導等，如何避免這種情況，或者是否可以「自主糾錯機制」？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;確實目前即使最好的大模型也還會存在一定的幻覺，比如數學上的一些邏輯計算問題，解決大模型幻覺一直是教育行業的難點。但是在這方面我們還是做了很多創新，比如 SFT 微調、Prompt 約束、Fewshot 規範以及 Tools 校驗等技術手段，目前來看效果還是很不錯的，也獲得用戶的認可。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：教育大模型需持續吸收新知識，但傳統微調易導致舊知識遺忘。在模型動態更新過程中，如何平衡知識擴展與核心能力穩定性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;這個確實是一個難點。我們自己的經驗來看，分兩個階段：24 年 Q4 之前，各家大模型的基座能力確實在教育垂類應用上，受限於沒有大量教育優質數據，無論是知識擴展和核心能力都還有欠缺，需要我們進行不斷 SFT。但是從 24 年 Q4 往後，特別是 DeepSeek 出來之後，大模型的基座能力提升非常明顯。我們對於微調的使用比較謹慎，更傾向於微調非核心能力，比如微調 AI 老師的講題範式，微調 AI 老師的擬人風格等。在知識擴展方面，我們更傾向於 Agent 架構思想，通過 RAG，More&amp;nbsp;Tools，MCP 等手段來擴展，而不是大模型的微調。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：基座大模型的很多訓練數據來自英語，可能導致文化偏見。在中文教育場景中，這是否會影響教育結果？是否有解決機制？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;我們沒有這方面問題。我們主要用的是百度文心大模型，很擅長中文。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：教育大模型是否解決傳統教育中的「因材施教」難題？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;答：&lt;/strong&gt;大模型技術是解決傳統教育「因材施教」難題的最佳方法。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;首先，通過大模型能夠更加懂學生。我們的 AI 老師是覆蓋家庭教育全場景的，從薄弱項診斷、家長反饋、學習規劃到作業輔導，持續更新學生的學習情況。比如在智能作業批改場景，傳統 AI 只能判斷對錯，但是基於大模型我們現在能過做到歸因分析，每一步錯在哪裏都能診斷出來。例如是漏了題目條件，還是對基礎概念的理解有誤，都能診斷出來。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;其次，只有大模型才能實現真正的 1v1 教學。以為題目答疑為例，傳統 AI 對所有學生，都只能有文字解析，或者是一個講題視頻，讓學生去看，至於懂不懂，懂多少，那就不知道了。但是基於大模型技術的 AI 老師可以和學生進行交互，在交互中識別孩子們是否真的懂了，進而根據理解的多與少，可以調整講題思路，一步一步的引導，讓孩子真正的理解題目，而這都是傳統 AI 無法實現的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們做 AI 老師的初衷，就是為了能夠復刻名師，通過大模型技術，我們有機會，讓每個家庭、每個孩子都能有一個 AI 名師，即使是在偏遠貧困的山區，也能有一個清華北大的 AI 私教。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：當大模型能自動生成個性化習題、教案甚至虛擬實驗時，傳統教師的角色將如何演變？是轉型為「AI 訓練師」專注設計提示詞，還是強化人類獨有的元認知培養能力？這類變革對師範教育體系會產生何種衝擊？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;答：&lt;/strong&gt;我和很多老師交流，他們都有這個焦慮。但是我感覺這個問題不僅僅是教育行業存在的，其他行業都會有，比如&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Midjourney&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;我們的 UI 工程師就很焦慮，還有 C&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;oursor&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;也讓很多程序員也很焦慮。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我可以談幾點我對這個問題的幾點思考：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;老師們也要快速擁抱大模型。大模型短時間內還是不會替代真人老師的，但是善於使用大模型工具的老師一定會更有競爭力，因為他們的效率更高。所以壓力不是來自於大模型，而是會使用大模型的同事們。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;對大模型來説，傳統的教育經驗是非常有價值的。目前所有的大模型都還是在復刻老師。復刻的方法都是在學習老師的教育經驗，沒有這些教育經驗，大模型還是難以替代真人的。我們目前遇到的一個難題是，如何將不同老師的個性化的教育經驗，抽象歸納成一套教育方法論，並且能數據化輸入給大模型，目前還很難，可能對一些懂大模型的老師是一個機會。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;真人老師除了傳道授業解惑之外，言傳身教會對學生人生觀、價值觀也會深深影響，畢竟人是有社會屬性的，這種面對面的情感價值，至少是目前的大模型技術還沒有辦法替代的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：作為小度教育的技術負責人，您帶領團隊做了哪些 AI 教育產品的創新？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;答：&lt;/strong&gt;大模型技術起來之前，我們小度教育就一直在做 AI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;教育的創新，那個時候也是圍繞作業批改和講題答疑來做的，但是效果一直比較受限。隨着大模型技術的快速發展，我們的 AI 能力效果已經做到了行業頂尖水平。特別是我們 2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年發佈的 AI 老師，是行業內首創推出超擬人 AI 老師，圍繞&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;家庭最普遍的日常學習和作業場景，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;模擬真人家&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;教輔導&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的核心&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;流程&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;從&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;診斷、反饋、規劃&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;個性化&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1v&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;輔導學習，系統化的實現了家庭教育場景和大模型技術的深度融合。目前 AI 老師已經成為學習機行業標杆，引領了行業發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：對 AI 從業者而言，面對技術迭代加速的「百模大戰」，哪些核心能力將成為競爭壁壘？您會建議青年開發者深耕哪些技術方向？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/span&gt;這個問題就比較寬泛了，仁者見仁，智者見智。我只能從 AI 應用創新從業者的視角來看，識別大模型的能力邊界是個很重要的核心能力。大模型能幹什麼？不能幹什麼？能幹到什麼程度？你只有非常清楚，才能做好產品創新。把握的好就是事半功倍，把握的不好那就是事倍功半。而且大模型的能力邊界是在持續變化的，要動態的看這個問題，而不是靜態的，要對未來有預見性和判斷力。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;建議就不太好給了，我也是青年哈，我只能談幾點我自己正在看的幾個方向：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一、多模態大模型（特別是視覺大模型）還在快速升級。很多應用場景都需要多模態的支持；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二、Agent 架構迭代很快。比如年初的 Manus，還有最近的 MCP 協議等都在加速智能體架構的發展；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第三、端側大模型不可忽視。隨着 iPhone 的引領，端側大模型會成為手機行業標配，那也會催生端側大模型應用爆發。預計今年設備端有希望能跑 1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;0&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;B 小模型了，從能力角度看，已經可以幹很多事情了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:none"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18426743</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18426743</guid>
      <pubDate>Mon, 19 May 2025 02:38:40 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>微軟裁員風暴：軟件工程崗成為 AI 衝擊的重災區</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;《財富》雜誌近日發文對微軟近日裁員進行了針對性報道，社評認為微軟近日的大規模裁員計劃引發科技行業對人工智能時代就業結構變革的廣泛關注。&lt;/p&gt; 
&lt;p&gt;據華盛頓州官方文件披露，&lt;strong&gt;在微軟總部所在地的裁員中，軟件工程崗位成為受衝擊最嚴重的領域，佔該州約 2000 名被裁員工的 40% 以上。微軟本週二確認，其全球裁員規模約 6000 人，華盛頓州裁員人數佔總數的三分之一&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-28c5f1e9e5bbf3a6ed55da0a3a7e813d2ea.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次裁員呈現顯著的崗位結構性特徵：除軟件工程師外，軟件項目管理崗位亦面臨較大調整，華盛頓州被裁的產品管理和技術項目管理崗位合計約 600 人，佔該州總裁員數的 30% 左右。&lt;/p&gt; 
&lt;p&gt;知情人士透露，部分參與人工智能項目的管理人員與員工也在裁員範圍內，而客戶服務類崗位（如銷售和市場營銷）受影響相對較小，微軟對此未作公開置評。&lt;/p&gt; 
&lt;p&gt;行業分析指出，微軟的裁員舉措與科技企業在人工智能領域的戰略轉型直接相關。隨着微軟及其競爭對手持續加碼人工智能投資，企業正通過嚴格審視運營成本、調整預算結構以優化資源配置。&lt;/p&gt; 
&lt;p&gt;微軟高管近期承諾，在鉅額數據中心建設投資背景下，將嚴控總體支出。值得關注的是，人工智能驅動的開發工具已展現出代碼編寫與分析能力，正逐步替代傳統工程師手動完成的部分開發任務。微軟首席執行官薩蒂亞·納德拉今年 4 月透露，在公司部分項目中，已有 30% 的代碼由 AI 生成。&lt;/p&gt; 
&lt;p&gt;這一現象並非微軟獨有，多家科技企業正同步推進人力結構重構以適應人工智能轉型。例如，Salesforce 今年初宣佈裁員逾 1000 人，同時計劃持續招聘人工智能相關銷售崗位，並明確到 2025 年將減少工程師招聘需求，因其認為人工智能已能替代部分崗位職能；Workday 今年 2 月裁員時，首席執行官卡爾·埃申巴赫亦強調將在人工智能等戰略重點領域加大招聘力度。&lt;/p&gt; 
&lt;p&gt;對於裁員目的，微軟方面表示主要是精簡管理層級，但目前精簡成效尚未明確。文件顯示，華盛頓州被裁員工中約 17% 為管理職位，這與微軟 2023 年底向美國平等就業機會委員會提交的人力資源報告中整體管理人員佔比基本一致。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350287</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350287</guid>
      <pubDate>Fri, 16 May 2025 11:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>加速項目管理效率，Gitee PPM 驅動軟件工廠的智能化轉型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：Gitee DevSecOps 產品經理，李穎萍&amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在高速發展的軟件開發時代，企業如何高效管理多個項目、協調團隊合作、優化資源配置，已成為推動技術進步的關鍵。尤其是在多任務、多項目並行的複雜環境下，&lt;strong&gt;Gitee 項目組合管理（PPM）作為一款智能化工具，正成為軟件工廠的重要推動力量&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;軟件工廠：標準化與自動化的未來&lt;/h2&gt; 
&lt;p&gt;傳統開發模式中，企業依賴多個獨立工具支撐不同的開發任務和項目。隨着軟件工廠理念的提出，開發模式發生根本性轉變：軟件工廠強調的是一個完整的生產體系，由「標準化流程 + 自動化執行 + 可複用構件」構成的生產線。&lt;/p&gt; 
&lt;p&gt;在多項目並行背景下，如何通過高效的項目組合管理優化資源分配、提升執行效率，已成為企業面臨的重要挑戰。Gitee PPM 正是在此背景下應運而生，&lt;strong&gt;以全新的項目管理方式，推動軟件工廠智能化轉型&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;Gitee PPM：項目管理的智能調度與透明協作&lt;/h2&gt; 
&lt;p&gt;Gitee PPM 通過智能調度與跨團隊協作機制，為軟件工廠提供有力支撐。無論資源調度還是多項目並行推進，Gitee PPM 都能高效保障項目執行：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;實時任務進度跟蹤：Gitee PPM 提供實時任務進度跟蹤功能。通過清晰的進度條和狀態標識，團隊可隨時掌握當前項目狀態，管理者也能及時識別需要重點關注和調整的環節。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/161929_chRv_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;精準資源調配：用戶可清晰查看每個項目的資源使用情況。系統根據需求智能調度資源，避免浪費與衝突，提升整體研發效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/161945_oCBD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;風險預警與問題追蹤：藉助任務進度和風險管理模塊，Gitee PPM 能及時識別潛在風險併發出預警，幫助項目經理在問題發生前做出調整，確保按時交付。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162000_wLN0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;全生命週期管理：從項目立項到交付，Gitee PPM 貫穿始終&lt;/h2&gt; 
&lt;p&gt;Gitee PPM 的亮點之一是全生命週期管理能力。從立項、排期、執行、監控，到最終交付，Gitee PPM 涵蓋項目管理的每一環節，確保每個項目都能夠高效且有序地推進。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;項目立項與資源規劃：提供標準化立項流程，並通過資源規劃功能助力前期準備。人員配置、時間安排、預算分配均可系統化管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;動態調整與進度追蹤：在項目推進過程中，Gitee PPM 提供靈活的進度追蹤與調整功能，通過直觀的進度條與任務分配，管理者可以輕鬆地進行任務調度和進度優化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;協作與透明化：Gitee PPM 不僅支持項目經理和團隊成員之間的溝通，還通過任務審批和資源訪問權限的透明化管理，確保每個環節都能得到準確、及時的反饋。團隊成員可以實時查看項目狀態，隨時參與決策，提升工作效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162015_kOQP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;未來趨勢：智能化與自動化助力軟件工廠的跨越式發展&lt;/h2&gt; 
&lt;p&gt;隨着人工智能和自動化技術的迅速發展，未來的 PPM 更加註重智能與自動化融合。Gitee PPM 將持續深化智能分析與預測能力，提前識別風險並提供決策支持。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;無縫集成 DevSecOps 流程：Gitee PPM 將與 DevSecOps 深度融合，支持 CI/CD 等敏捷方法，提升軟件交付速度與質量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全生命週期智能管理：隨着項目規模與複雜性增長，Gitee PPM 將擴展管理範圍，覆蓋研發、測試、交付和運維等各環節的智能化管理。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Gitee PPM，賦能軟件工廠的未來&lt;/h2&gt; 
&lt;p&gt;在軟件工廠的智能化轉型過程中，Gitee PPM 無疑是其中最為關鍵的一環。通過智能化的項目管理，精準的資源調配，全面的風險控制以及高效的跨部門協作，Gitee PPM 正在為軟件開發行業帶來革命性的變化。&lt;/p&gt; 
&lt;p&gt;未來，Gitee PPM 將繼續不斷創新，推動軟件工廠向更高效、更智能、更安全的方向發展，成為企業實現研發目標、提升交付質量、加速業務增長的核心競爭力。&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p&gt;&lt;img height="489" src="https://static.oschina.net/uploads/space/2025/0516/162034_3TT9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitee.cn%2Ffactory" target="_blank"&gt;https://gitee.cn/factory&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="599" src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350255</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350255</guid>
      <pubDate>Fri, 16 May 2025 08:21:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>🔥 Solon Ai Flow 編排開發框架發佈預告（效果預覽）</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;Solon Ai 在推出 Solon Ai Mcp 後，又將推出 Solon Ai Flow。&lt;/p&gt; 
&lt;h3&gt;1、Solon Ai Flow 是個啥？&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Solon Ai Flow 是一個智能體編排開發框架。它是框架！不是工具，不是產品（這與市面上流行的工具和產品，有較大差別）。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;使用 yaml 格式編排，很像 docker-compose 的觀感。&lt;/p&gt; 
&lt;h3&gt;2、發佈預告&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;預計下週（2025 年農曆小滿）發佈首個版本。&lt;/p&gt; 
&lt;h3&gt;3、效果預覽&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;簡單的聊天智能體&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;chat_case1&lt;/span&gt;
&lt;span style="color:#986801"&gt;layout:&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextInput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;text:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你好"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是個聊天助手"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;RAG 知識庫智能體&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;rag_case1&lt;/span&gt;
&lt;span style="color:#986801"&gt;layout:&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextInput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;text:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"Solon 是誰開發的？"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@EmbeddingModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;embeddingConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.embedding.EmbeddingConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"bge-m3"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/embed"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@InMemoryRepository"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;documentSources:&lt;/span&gt;
        &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"https://solon.noear.org/article/about?format=md"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;splitPipeline:&lt;/span&gt;
        &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"org.noear.solon.ai.rag.splitter.RegexTextSplitter"&lt;/span&gt;
        &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"org.noear.solon.ai.rag.splitter.TokenSizeTextSplitter"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是個知識庫"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;兩個智能體表演相聲式吵架（llm 與 llm 講相聲）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;pk_case1&lt;/span&gt;
&lt;span style="color:#986801"&gt;layout:&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;type:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"start"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextInput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;text:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你好"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;model_a&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是一個智能體名字叫「阿飛」。將跟另一個叫「阿紫」的智能體，表演相聲式吵架。"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatSession:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"A"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;prefix:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"阿飛: "&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@ChatModel"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;model_b&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;systemPrompt:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"你是一個智能體名字叫「阿紫」。將跟另一個叫「阿飛」的智能體，表演相聲式吵架。"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;stream:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatSession:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"B"&lt;/span&gt;
      &lt;span style="color:#986801"&gt;chatConfig:&lt;/span&gt; &lt;em&gt;# "@type": "org.noear.solon.ai.chat.ChatConfig"&lt;/em&gt;
        &lt;span style="color:#986801"&gt;provider:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;model:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;
        &lt;span style="color:#986801"&gt;apiUrl:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;task:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"@TextOutput"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;meta:&lt;/span&gt;
      &lt;span style="color:#986801"&gt;prefix:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"阿紫: "&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;type:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"exclusive"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;link:&lt;/span&gt;
      &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;nextId:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;model_a&lt;/span&gt;
        &lt;span style="color:#986801"&gt;condition:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;'context.counter().incr("demo") &amp;lt; 10'&lt;/span&gt;
      &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;nextId:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;end&lt;/span&gt;
  &lt;span style="color:#4078f2"&gt;-&lt;/span&gt; &lt;span style="color:#986801"&gt;type:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"end"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;id:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"end"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4、如何運行？&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;case2, csae3, case4 是用 TextInput，TextOutput 作輸出輸入。通過流引擎和引上下文，即可運行。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@SolonTest&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;ChatTest&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    FlowEngine flowEngine;
    
    &lt;span style="color:#4078f2"&gt;@Test&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case2&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case2"&lt;/span&gt;);
    }
    
    &lt;span style="color:#4078f2"&gt;@Test&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case3&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case3"&lt;/span&gt;);
    }
    
    &lt;span style="color:#4078f2"&gt;@Test&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case4&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case4"&lt;/span&gt;);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;csae1 則是用 ChatInput 和 ChatOutput 作輸入輸出（基於 Context.current() 輸入和輸出），需要正常的 web 聊天場景&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;DemoController&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    FlowEngine flowEngine;

    &lt;span style="color:#986801"&gt;ChatSession&lt;/span&gt; &lt;span style="color:#986801"&gt;chatSession&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;ChatSessionDefault&lt;/span&gt;();

    &lt;span style="color:#4078f2"&gt;@Mapping("case1")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;case1&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span style="color:#a626a4"&gt;throws&lt;/span&gt; Exception {
        &lt;span style="color:#986801"&gt;FlowContext&lt;/span&gt; &lt;span style="color:#986801"&gt;flowContext&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;FlowContext&lt;/span&gt;();
        flowContext.put(Attrs.CTX_CHAT_SESSION, chatSession); &lt;em&gt;//傳遞聊天會話&lt;/em&gt;

        flowEngine.eval(&lt;span style="color:#50a14f"&gt;"case1"&lt;/span&gt;, flowContext); 
    }
}&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350236</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350236</guid>
      <pubDate>Fri, 16 May 2025 07:32:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>SpringBoot3 使用 SolonMCP 開發 MCP</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;之前發了個 「《SpringBoot2 可以使用 SolonMCP 開發 MCP（江湖救急）》」。然後，有人問：SpringBoot3 能不能用 SolonMCP？&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;其實 SpringBoot3 可以使用 Spring AI 或者 Spring AI Alibaba（都有 MCP 功能）。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;既然問了，就再發一個文。另外 SpringBoot3 使用 SolonMPC 和 SpringBoot2 的情況，差不多。只一個依賴包有不同。&lt;/p&gt; 
&lt;h3&gt;1、SolonMCP 簡介&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;SolonMCP（全稱：solon-ai-mcp）是 solon ai 的一個擴展。支持內嵌到 jfinal，vert.x，springboot2，springboot3 等框架使用。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Maven 主要依賴包：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-ai-mcp&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;具體的示例參考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3"&gt;https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3-newstyle"&gt;https://gitee.com/opensolon/solon-ai-mcp-embedded-examples/tree/main/solon-ai-embedded-springboot3-newstyle&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2、MCP 服務端開發&lt;/h3&gt; 
&lt;h4&gt;2.1、添加入口類&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.HelloApp&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@SpringBootApplication&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;HelloApp&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; {
        SpringApplication.run(HelloApp.class, args);
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.2、添加個空接口&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.mcpserver.IMcpServerEndpoint&lt;/code&gt;&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;用於識別端點組件類&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;interface&lt;/span&gt; &lt;span style="color:#c18401"&gt;IMcpServerEndpoint&lt;/span&gt; { }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.3、添加&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.mcpserver.McpServerConfig&lt;/code&gt;&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;拖管 solon 的生命週期。收集 IMcpServerEndpoint 組件，並轉為 McpServerEndpointProvider&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@Configuration&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpServerConfig&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@PostConstruct&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;start&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        Solon.start(McpServerConfig.class, &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;String&lt;/span&gt;[]{&lt;span style="color:#50a14f"&gt;"--cfg=mcpserver.yml"&lt;/span&gt;});
    }

    &lt;span style="color:#4078f2"&gt;@PreDestroy&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;stop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt; (Solon.app() != &lt;span style="color:#0184bb"&gt;null&lt;/span&gt;) {
            Solon.stopBlock(&lt;span style="color:#0184bb"&gt;false&lt;/span&gt;, Solon.cfg().stopDelay());
        }
    }

    &lt;span style="color:#4078f2"&gt;@Bean&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; McpServerConfig &lt;span style="color:#4078f2"&gt;init&lt;/span&gt;&lt;span&gt;(List&amp;lt;IMcpServerEndpoint&amp;gt; serverEndpoints)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;for&lt;/span&gt; (IMcpServerEndpoint serverEndpoint : serverEndpoints) {
            &lt;em&gt;//這裏注意一下，如果有代理的話需要用 AnnotationUtils 獲取註解&lt;/em&gt;
            &lt;span style="color:#986801"&gt;McpServerEndpoint&lt;/span&gt; &lt;span style="color:#986801"&gt;anno&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; AnnotationUtils.findAnnotation(serverEndpoint.getClass(), McpServerEndpoint.class);

            &lt;span style="color:#a626a4"&gt;if&lt;/span&gt; (anno == &lt;span style="color:#0184bb"&gt;null&lt;/span&gt;) {
                &lt;span style="color:#a626a4"&gt;continue&lt;/span&gt;;
            }

            &lt;span style="color:#986801"&gt;McpServerEndpointProvider&lt;/span&gt; &lt;span style="color:#986801"&gt;serverEndpointProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpServerEndpointProvider.builder()
                    .from(serverEndpoint.getClass(), anno)
                    .build();

            serverEndpointProvider.addTool(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;MethodToolProvider&lt;/span&gt;(serverEndpoint));
            serverEndpointProvider.addResource(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;MethodResourceProvider&lt;/span&gt;(serverEndpoint));
            serverEndpointProvider.addPrompt(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;MethodPromptProvider&lt;/span&gt;(serverEndpoint));

            serverEndpointProvider.postStart();

            &lt;em&gt;//可以再把 serverEndpointProvider 手動轉入 SpringBoot 容器&lt;/em&gt;
        }

        &lt;em&gt;//為了能讓這個 init 能正常運行&lt;/em&gt;
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#c18401"&gt;this&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@Bean&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; FilterRegistrationBean &lt;span style="color:#4078f2"&gt;mcpServerFilter&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        FilterRegistrationBean&amp;lt;SolonServletFilter&amp;gt; filter = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;FilterRegistrationBean&lt;/span&gt;&amp;lt;&amp;gt;();
        filter.setName(&lt;span style="color:#50a14f"&gt;"SolonFilter"&lt;/span&gt;);
        filter.addUrlPatterns(&lt;span style="color:#50a14f"&gt;"/mcp/*"&lt;/span&gt;);
        filter.setFilter(&lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;SolonServletFilter&lt;/span&gt;());
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; filter;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.4、添加&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;webapp.mcpserver.tool.McpServer&lt;/code&gt;（實現 Handler、IPlugin 接口）&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;這裏是重點了，添加 mcp server 端點（支持多個端點）。這裏是正常的 SpringBoot 組件開發了。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#4078f2"&gt;@Component&lt;/span&gt; &lt;em&gt;//注意這個註解別用錯了（solon 裏也有同名的）&lt;/em&gt;
&lt;span style="color:#4078f2"&gt;@McpServerEndpoint(name="demo1", sseEndpoint = "/mcp/demo1/sse")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpServerTool&lt;/span&gt; &lt;span style="color:#a626a4"&gt;implements&lt;/span&gt; &lt;span style="color:#c18401"&gt;IMcpServerEndpoint&lt;/span&gt; {
    &lt;em&gt;//&lt;/em&gt;
    &lt;em&gt;// 建議開啓編譯參數：-parameters （否則，最好再配置參數的 name）&lt;/em&gt;
    &lt;em&gt;//&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@ToolMapping(description = "查詢天氣預報")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getWeather&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param(description = "城市位置")&lt;/span&gt; String location)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"晴，14 度"&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@ResourceMapping(uri = "config://app-version", description = "獲取應用版本號")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getAppVersion&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"v3.2.0"&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@ResourceMapping(uri = "db://users/{user_id}/email", description = "根據用戶 ID 查詢郵箱")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getEmail&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param(description = "用戶 Id")&lt;/span&gt; String user_id)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; user_id + &lt;span style="color:#50a14f"&gt;"@example.com"&lt;/span&gt;;
    }

    &lt;span style="color:#4078f2"&gt;@PromptMapping(description = "生成關於某個主題的提問")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; Collection&amp;lt;ChatMessage&amp;gt; &lt;span style="color:#4078f2"&gt;askQuestion&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param(description = "主題")&lt;/span&gt; String topic)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; Arrays.asList(
                ChatMessage.ofUser(&lt;span style="color:#50a14f"&gt;"請解釋一下'"&lt;/span&gt; + topic + &lt;span style="color:#50a14f"&gt;"'的概念？"&lt;/span&gt;)
        );
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.5、編譯後運行&lt;/h4&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;或者開發時，直接運行&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;HelloApp:main&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法&lt;/p&gt; 
&lt;h3&gt;3、MCP 客戶端開發&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;客戶端簡單些&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpClientTest&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span style="color:#a626a4"&gt;throws&lt;/span&gt; Exception {
        &lt;span style="color:#986801"&gt;McpClientProvider&lt;/span&gt; &lt;span style="color:#986801"&gt;toolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientProvider.builder()
                .apiUrl(&lt;span style="color:#50a14f"&gt;"http://localhost:8080/mcp/sse"&lt;/span&gt;)
                .build();

        &lt;em&gt;//工具調用&lt;/em&gt;
        Map&amp;lt;String, Object&amp;gt; map = Collections.singletonMap(&lt;span style="color:#50a14f"&gt;"location"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"杭州"&lt;/span&gt;);
        &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; toolProvider.callToolAsText(&lt;span style="color:#50a14f"&gt;"getWeather"&lt;/span&gt;, map).getContent();
        System.out.println(rst);
        &lt;span style="color:#a626a4"&gt;assert&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"晴，14 度"&lt;/span&gt;.equals(rst);
        
        
        &lt;em&gt;//資源讀取&lt;/em&gt;
        resourceContent = toolProvider.readResourceAsText(&lt;span style="color:#50a14f"&gt;"config://app-version"&lt;/span&gt;).getContent();
        System.out.println(resourceContent);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4、MCP 客戶端作為 LLM（ChatModel） 的工具集使用&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;也比較簡單。使用 ollama 做為 llm 提供者，方便本地測試。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;McpClientTest&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;final&lt;/span&gt; &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;apiUrl&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"http://127.0.0.1:11434/api/chat"&lt;/span&gt;;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;final&lt;/span&gt; &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;provider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"ollama"&lt;/span&gt;;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;final&lt;/span&gt; &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;model&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"qwen2.5:1.5b"&lt;/span&gt;; &lt;em&gt;//"llama3.2";//deepseek-r1:1.5b;&lt;/em&gt;
    
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span style="color:#a626a4"&gt;throws&lt;/span&gt; Exception {
        &lt;em&gt;//構建 mcp client&lt;/em&gt;
        &lt;span style="color:#986801"&gt;McpClientProvider&lt;/span&gt; &lt;span style="color:#986801"&gt;toolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientProvider.builder()
                .apiUrl(&lt;span style="color:#50a14f"&gt;"http://localhost:8080/mcp/sse"&lt;/span&gt;)
                .build();

        &lt;em&gt;//構建 llm 接口&lt;/em&gt;
        &lt;span style="color:#986801"&gt;ChatModel&lt;/span&gt; &lt;span style="color:#986801"&gt;chatModel&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; ChatModel.of(apiUrl)
                .provider(provider)
                .model(model)
                .defaultToolsAdd(toolProvider) &lt;em&gt;//添加默認工具（這是 mcp client）&lt;/em&gt;
                .build();
        
        &lt;em&gt;//請求&lt;/em&gt;
        &lt;span style="color:#986801"&gt;ChatResponse&lt;/span&gt; &lt;span style="color:#986801"&gt;resp&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; chatModel.prompt(&lt;span style="color:#50a14f"&gt;"杭州今天的天氣怎麼樣？"&lt;/span&gt;)
                .call();

        System.out.println(resp.getMessage());
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5、SpringBoot3 和 SpringBoot2 使用 SolonMCP 有什麼區別？&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;僅一個 servlet 的依賴包不同（由 java-ee 改名引起的）。SpringBoot3 使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;solon-web-servlet-jakarta&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;依賴包；SpringBoot2 則使用 solon-web-servlet-jakarta 依賴包。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350221</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350221</guid>
      <pubDate>Fri, 16 May 2025 06:50:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>【最後今天】LFOSSA 技能煥新季 85 折限時福利活動即將結束！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="微信圖片_85 折.png" src="https://oscimg.oschina.net/oscnet//23abacdd7a61a2ef402c028b04dfb5a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;Linux Foundation&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;開源軟件&lt;/strong&gt;&lt;strong&gt;學園（LFOSSA） 於 5 月 7 日至 5 月 16 日，推出&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;L&lt;/strong&gt;&lt;strong&gt;FOSSA 技能煥新季限時福利活動&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff"&gt;，&lt;span style="color:#ff0000"&gt;&lt;strong&gt;全場 LF 官方認證考試及課程 &amp;nbsp;&lt;span style="color:#00b050"&gt;85 折&amp;nbsp;&lt;/span&gt;起&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffff00; color:#ff0000"&gt;&lt;strong&gt;活動僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;今&lt;/span&gt;&amp;nbsp;天，機會不容錯過！&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;快速提升你的開源技能，搶跑&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;新時代&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技能煥新季 · LF 認證限時福利詳情&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;活動時間&lt;/strong&gt;：&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;5 月 7 日 - 5 月 16 日&lt;span style="background-color:#ffff00"&gt;（活動僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天！）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;適用產品：&lt;/strong&gt;&lt;strong&gt;LF&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;官方認證考試及課程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向個人專屬福利：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;部分機構熱門課程低至&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;7&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;折&lt;/span&gt;&lt;/strong&gt;，&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;添加 LFOSSA 官方微信，限時領取&amp;nbsp;&lt;span style="color:#00b050"&gt;認證培訓首節課程免費試聽&amp;nbsp;&lt;/span&gt;資格&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向企業專屬福利（階梯折扣）：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 採購 5-20 個認證：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;85&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;優惠&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 採購 21-50 個認證：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;優惠&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;3. 採購 50 個以上認證：&lt;/strong&gt;聯繫官方客服，獲取定製專屬方案&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368565314179.png" height="1000" src="https://oscimg.oschina.net/oscnet//dcb6214ff743fa4e8bbe17fc11a9cee5.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;有關&amp;nbsp;&lt;/strong&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;LFOSSA 技能煥新季限時福利活動&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;，可點擊以下鏈接瞭解詳情：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542784%26idx%3D1%26sn%3D236a3bfdcf36dec0bf41f462cc0c91d8%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;搶跑 AI 時代，煥新開源技能！LFOSSA 技能煥新季 85 折限時福利活動開啓！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542805%26idx%3D1%26sn%3D4af4c9ac39d950df1de31477624b659e%26scene%3D21%23wechat_redirect" target="_blank"&gt;【最後 2 天】LFOSSA 技能煥新季｜企業採購折扣限時福利活動即將截止，抓緊最後機會！&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;聯繫我們&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;如需&amp;nbsp;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;體驗&lt;/strong&gt;&lt;strong&gt;認證培訓課程免費試聽首節課&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;，或為&lt;span style="color:#ff0000"&gt;&lt;strong&gt;貴單位定製認證學習路徑以及批量採購方案&lt;/strong&gt;&lt;/span&gt;，歡迎掃碼添加官方客服，我們將為你提供一對一的採購諮詢與支持服務。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="background-color:rgba(255, 246, 122, 0.8); color:#ff0000"&gt;&lt;strong&gt;活動截止時間：2025 年 5 月 16 日（僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;限時折扣，錯過不再，快來鎖定優惠名額！&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368673326323.jpeg" height="260" src="https://oscimg.oschina.net/oscnet//86a0e91efbe8dabcc8f184b71cdb50ad.jpeg" width="260" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span style="color:#8f959e"&gt;掃碼添加客服&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368808706235.png" height="311" src="https://oscimg.oschina.net/oscnet//6a2c4a0154fe65c0ed86ca1afc9639a8.png" width="1600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;查看更多 LFOSSA 培訓、認證及套購產品，請訪問以下鏈接：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;培訓：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"&gt;https://training.linuxfoundation.cn/courses&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;認證：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"&gt;https://training.linuxfoundation.cn/certificates&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;套購：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank"&gt;https://training.linuxfoundation.cn/pack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;立即點擊&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank"&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;這裏&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;進入 LFOSSA 官網，選購官方認證考試及培訓課程產品。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350219</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350219</guid>
      <pubDate>Fri, 16 May 2025 06:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 VS &amp; VS Code 每月活躍開發者數量達到 5000 萬</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟今天&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fblog%2Fcelebrating-50-million-developers-the-journey-of-visual-studio-and-visual-studio-code" target="_blank"&gt;宣佈了&lt;/a&gt;其 Visual Studio 產品系列的一個重要里程碑：Visual Studio 和 Visual Studio Code 現在每月為超過 5000 萬活躍開發人員提供服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.cnbetacdn.com/article/2025/0516/0b34a4bdf1bdfd2.jpg" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-51990187483c55d75a61f86af17b234b4ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fc7a64f6ab1f22d5860bdce786e8832ef8b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Visual Studio 於 28 年前首次推出，至今仍是領先的集成開發環境 (IDE)，這主要得益於 Windows 生態系統的普及。多年來，它不斷發展，現已支持跨平台開發、雲原生應用程序、遊戲開發、數據科學工作流等。它仍然是少數幾個開箱即用地包含編譯器、調試器、分析器、設計器和語言服務的 IDE 之一。&lt;/p&gt; 
&lt;p&gt;Visual Studio 的數據：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Visual Studio Marketplace 上有 25000 多個擴展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;超過 100000 名開發人員貢獻反饋、問題報告和功能創意&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;社區論壇中數十萬個問答&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;每個季度更新平均修復 800 多個社區報告的問題&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;十年前，隨着 Windows 開始被 iOS 和 Android 等移動平台蠶食，微軟在當時推出了 Visual Studio Code，這一舉動令許多人感到意外。與其功能齊全的兄弟版本不同，Visual Studio Code 採用輕量級開源模式。它並非提供所有開箱即用的功能，而是允許開發人員通過龐大的擴展生態系統自定義其開發環境。&lt;/p&gt; 
&lt;p&gt;Visual Studio Code 的數據：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 市場中有 100000 多個擴展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 代碼庫已獲得 37000 多個 GitHub 星標&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;來自世界各地的數千名貢獻者&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;微軟開發者部門 CVP 兼產品主管、微軟第一方工程系統總經理 Amanda Silver 就這一里程碑寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在我們慶祝這一里程碑的同時，我們也正站在軟件開發新時代的開端。人工智能編程革命正在從根本上改變我們編寫代碼的方式，而我們僅僅觸及了未來可能性的皮毛。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;為了慶祝 5000 萬里程碑，微軟還發布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2F" target="_blank"&gt;Visual Studio 和 Visual Studio Code 的週年紀念特別壁紙&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eaef23439a2406d17ad3b98418b1733e23a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;下載地址如下，分別用於桌面、手機與智能手錶：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fdesktop" target="_blank"&gt;https://visualstudiowallpapers.com/desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fphone" target="_blank"&gt;https://visualstudiowallpapers.com/phone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fwatch" target="_blank"&gt;https://visualstudiowallpapers.com/watch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在下週即將舉行的 Build 開發者大會上，微軟預計將發佈這兩款工具的更新，旨在進一步提升開發者體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</guid>
      <pubDate>Fri, 16 May 2025 06:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟將於 8 月 11 日關閉 Bing Search API 服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fbing%2Fapis%2Fbing-web-search-api" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;將於 2025 年 8 月 11 日正式關閉 Bing Search API 服務，屆時所有使用 Bing Search API 的實例將完全停用，同時不再接受新用戶註冊。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135843_cSSP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微軟建議用戶考慮使用 Azure AI Agents 中的「Grounding with Bing Search」作為替代方案，但該替代方案並非完美。&lt;/p&gt; 
&lt;p&gt;「Grounding with Bing Search」可以在生成回應時引用實時公開網絡數據，但開發者和用戶無法直接訪問 Bing 搜索的原始數據內容，這意味着它無法完全替代 Bing Search API 的功能。&lt;/p&gt; 
&lt;p&gt;此次停用決定主要影響 Bing Search F1 及 S1 到 S9 資源的用戶，以及 Custom Search F0 與 S1 到 S4 資源的用戶。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;不過受影響的主要為 Bing Search APIs 的自助式或小型用戶，像 DuckDuckGo 這樣的大型客戶，由於與微軟簽署了直接協議，仍可繼續使用這些 API。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，微軟在 ChatGPT 於 2022 年首次亮相後，已將 Bing Search APIs 的價格提高了 10 倍，此次直接關閉 API 服務，可能是微軟在 AI 時代對搜索服務戰略調整的一部分。&lt;/p&gt; 
&lt;p&gt;此外有分析指出，微軟停用 Bing API 可能會對正在審理中的 Google 搜索壟斷案產生影響。&lt;/p&gt; 
&lt;p&gt;由於 Google Search APIs 價格昂貴且限制較多，許多開發者更傾向於使用 Bing API，微軟的這一決定可能會迫使 Google 在搜索 API 資源方面做出更多讓步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350213/bing-web-search-api-retired</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350213/bing-web-search-api-retired</guid>
      <pubDate>Fri, 16 May 2025 05:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元圖像（Hunyuan Image）2.0 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元圖像 2.0 模型（Hunyuan Image2.0）已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNEg5Wop9EPw3Z6Lx5ik7Mg" target="_blank"&gt;正式發佈&lt;/a&gt;。該模型主要有兩大特點：&lt;strong&gt;實時生圖、超寫實畫質。&lt;/strong&gt;目前已在騰訊混元官方網站上線（https://hunyuan.tencent.com/），並對外開放註冊體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img height="607" src="https://static.oschina.net/uploads/space/2025/0516/134524_sRBm_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方數據顯示，在圖像生成領域專門測試模型複雜文本指令理解與生成能力的評估基準 &amp;nbsp;GenEval（Geneval Bench）上，騰訊混元圖像 2.0 模型準確率超過 95%，遠超其他同類模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134745_rlGs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是混元圖像（Hunyuan Image）2.0 模型生成的圖片：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;人像攝影風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="512" src="https://static.oschina.net/uploads/space/2025/0516/134725_ADPH_2720166.png" width="854" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;動漫風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="532" src="https://static.oschina.net/uploads/space/2025/0516/134738_PKYz_2720166.png" width="888" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;真實人物風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134836_gwyW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次模型升級還帶來了發佈了實時繪畫板功能，基於模型的實時生圖能力，用戶在繪製線稿或調整參數時，預覽區同步生成上色效果，突破了傳統「繪製-等待-修改」的線性流程，可助力專業設計師的創作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135145_kura_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;實時繪畫板支持多圖融合，用戶上傳多圖後，可將多個草圖疊加至同一畫布自由創作，經過 AI 自動協調透視與光影，按照提示詞內容生成融合圖像，進一步豐富了 AI 生圖的交互體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350209</guid>
      <pubDate>Fri, 16 May 2025 05:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Windsurf 發佈 Wave 9 模型家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windsurf (原 Codeium) 發佈了 Wave 9 模型家族，包括 SWE-1、SWE-1-Lite 和 SWE-1-Mini。&lt;/p&gt; 
&lt;p&gt;SWE-1 是一個前沿模型，專門為軟件工程任務設計，在內部評估和產品使用中，其性能接近甚至超越現有前沿模型。&lt;/p&gt; 
&lt;p&gt;SWE-1-Lite 是一個更強大的新模型，將取代原有的 Cascade Base，對所有用戶免費。SWE-1-Mini 是用於 Windsurf 中 tab 補全的改進模型。SWE-1 目前對 Pro 用戶限時免費。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/133759_d7AQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據 Windsurf 介紹，SWE-1 是其中最大、能力最強的 AI 模型，旨在突破現有大模型在軟件工程實際需求上的侷限。&lt;/p&gt; 
&lt;p&gt;相比只關注代碼生成和單元測試的傳統模型，SWE-1 更強調對開發流程中多種狀態和上下文的感知能力（flow awareness），它能夠在人機協作、任務未完成等複雜場景下持續推進工作。&lt;/p&gt; 
&lt;p&gt;根據基準測試，SWE-1 在 「對話式 SWE 任務基準」 和 「端到端 SWE 任務基準」 這兩項核心指標上，都已經接近目前行業最強的前沿模型。特別是獨立的端到端任務中，它的表現幾乎和 Claude 系列最新模型能力相當。&lt;/p&gt; 
&lt;p&gt;在對話式任務中（任務做到一半，用戶和模型交替操作，模型需要接着用戶的進度繼續完成任務），它目前的能力相當於 Claude 3.5 Sonnet。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-80a326122f0a65adc98949e8bf1c2bc890e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fcb9655b8e9ddf4084175265b446815c9f2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;參考來源：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindsurf.com%2Fblog%2Fwindsurf-wave-9-swe-1" target="_blank"&gt;https://windsurf.com/blog/windsurf-wave-9-swe-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FOS6Tz1nfUxgi0n4Dcf3bvg" target="_blank"&gt;https://mp.weixin.qq.com/s/OS6Tz1nfUxgi0n4Dcf3bvg&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</guid>
      <pubDate>Fri, 16 May 2025 05:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深入對比谷歌 A2A 與 ANP：找到協議的原點</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;作者：常高偉，智能體協議 ANP 發起人。&lt;/p&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;關於 ANP：Agent Network Protocol (ANP) 是一個開源的智能體通信協議，目標是成為智能體互聯網時代的 HTTP。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;谷歌的&lt;/span&gt;&lt;span&gt;A2A&lt;/span&gt;&lt;span&gt;協議出來後，很多關注 ANP 社區的朋友第一時間發來消息，問對我們影響大不大，並且給我們獻言獻策，再次感謝。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我認為 A2A 對&lt;/span&gt;&lt;span&gt;ANP&lt;/span&gt;&lt;span&gt;最大的影響是，有了谷歌的「蓋章「 Follow：ANP 的路線是對的，ANP 看的很長遠，我也來了&amp;nbsp;&lt;/span&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;我不用再去解釋為什麼智能體通信協作重要了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;當天我花了半天的時候研究，寫了一篇文章：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4NjIwOTM5Mw%3D%3D%26mid%3D2654085211%26idx%3D1%26sn%3D22d52145d41b02fc217469278c8857f5%26scene%3D21%23wechat_redirect" target="_blank" rel="nofollow"&gt;多角度全面對比 Google 最新的 A2A、ANP、MCP&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;後來又花了一天的時間仔細研究了 A2A，與 ANP 做了一個深度的對比，我認為我應該找到了 A2A 的原點，我也看到了 A2A 與 ANP 的更深層次的差異&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;一句話總結：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;MCP 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;模型與工具、資源的連接&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;A2A 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;企業內部智能體之間的複雜協作&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;ANP 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;智能體在互聯網上的連接與協&lt;/span&gt;作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;技術層面的差異對比&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;雖然説 A2A 和 ANP 都是解決智能體通信與協作，但是從技術層面，A2A 與 ANP 還是有很大的差異。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能體描述與信息組織&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在協議設計中，一個智能體如何對另外一個智能體暴露其信息，是一個關鍵的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能體描述方面，A2A 使用了一個名為 Agent Card 的 JSON 格式的文檔，用於描述智能體的能力、技能、身份認證方法等，Agent Card 的核心是技能（skill），表達智能體能夠幹什麼事情，比如能夠進行地圖路徑規劃等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ANP 也是用的 JSON，不過基於 JSON-LD（&lt;/span&gt;&lt;span&gt;Linked Data&lt;/span&gt;&lt;span&gt;）和 schema.org 描述智能體信息（基本信息、身份驗證、對外產品/服務、交互 Interface），這是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;語義網&lt;/span&gt;&lt;span&gt;的技術，目的是提高兩個智能體對信息理解的一致性，以及讓智能體的公開信息能夠鏈接成一個數據網絡，智能體描述文件是網絡的入口：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="374" src="https://oscimg.oschina.net/oscnet/up-d01d5d7307d80461908b85ccbf5bf33a731.png" width="866" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，一個酒店智能體，使用 ANP，可以將酒店的房間、設施、服務、交互接口等信息（包括圖片）描述出來，並且鏈接成一個數據網絡，讓其他智能體能夠爬取並且理解。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這也導致，在智能體的交互上，A2A 與 ANP 有非常大的差異：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;A2A 通過 Agent Card 描述智能體的技能（skills），其他智能體獲取 skills，然後通過 JSON-RPC 發送一個任務請求，任務使用自然語言描述，並且攜帶任務需要的相關信息。任務完成後返回結果。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="899" src="https://oscimg.oschina.net/oscnet/up-6520f035e7c07da9e2c01587383e4349789.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;ANP 則是通過智能體描述文檔（Agent Description），將智能體對外提供的產品、服務、交互接口等信息用 URL 連接到一起，另外一個智能體像一個網絡爬蟲，通過 URL 不斷的爬取自己需要的信息。這個過程中可以通過自然語言接口與智能體進行交互，也可以通過結構化接口與智能體進行交互。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1037" src="https://oscimg.oschina.net/oscnet/up-6b28fc14add696a2b8229dff90d88f23df6.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這裏的核心差異：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;A2A 是智能體對外公開自己的技能，另外一個智能體發送處理任務過來，處理完成後返回結果。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;ANP 是智能體對外公開自己信息（包含交互接口），其他智能體爬取信息進行處理，必要的時候通過自然語言接口或結構化接口與智能體進行交互&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能體發現&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能體的發現上 A2A 的方案和 ANP 基本是一樣的，都是在域名的.well-known 目錄下增加一個元數據文檔，A2A 的文件名是 agent.json，ANP 的文件名是 agent-descriptions。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時也都支持智能體主動註冊到私有註冊表，這個在局域網中的協作是非常有必要的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不同的地方在於，A2A 是直接將 Agent Card 內容放到.well-known/agent.json 中，而 ANP 則是在.well-known/agent-descriptions 中存放智能體描述文件的 URL。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 目前看起來是一個域名一個 Agent Card（還要進一步確認），ANP 則是一個域名可以有很多個智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;身份驗證&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在身份驗證上，A2A 和 ANP 有所不同。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 智能體在 A2A 協議中並不交換身份信息。相反，它們通過帶外方式獲取認證材料（如 token），並通過 HTTP 頭部傳遞這些材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;所謂的帶外，是指通過 A2A 之外的其他協議獲取認證材料。A2A 遵循 OpenAPI 的身份認證規範進行身份認證，支持包括 HTTP Basic Auth、API Key、OAuth 2.0 等多種認證方式，具體由每個智能體在其 Agent Card 中聲明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="480" src="https://oscimg.oschina.net/oscnet/up-d447565d2bd93d80f90c7ecb282f4ef5cc6.png" width="852" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 則基於 W3C DID 技術構建去中心化的身份認證，在協議中直接攜帶身份信息，包括身份驗證信息。智能體使用自己的身份就能夠和其他所有的智能體進行交互，不需要帶外獲得身份驗證材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，在某些場景中，帶外獲取身份驗證材料是必要的，特別是在企業級應用中。ANP 未來會支持帶外身份驗證材料的獲取，設計上預留了擴展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b3dfb6efb5e2de6b145ed311e0f9e726f08.png" width="948" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差異：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 採用帶外獲取身份驗證材料，是為了最大程度兼容美國主流企業應用生態的安全合規要求，複用現有的企業身份認證體系，確保協議本身輕量、靈活且安全。核心是為瞭解決企業級應用的身份問題，並且沒有解決互聯網上智能體互聯互通的身份問題。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 則是未來解決智能體在互聯網上如何進行身份認證的問題，核心是讓互聯網上任意兩個智能體都能夠互聯互通，這需要一個互操作性更好的身份認證方案。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;核心概念&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 與 ANP 在協議的核心概念上有很大差異。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;A2A 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括 Skill（技能）、Task（任務）、Artifact（產物）、Message（消息）、Part（部分）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時，Task 又定義了多種狀態，包括：submitted（已提交）、working（處理中）、input-required（需要輸入）、completed（完成）、canceled（取消）、failed（失敗）、unknown（未知）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Task 也定義了一些操作，包括：Send（發送）、Get（獲取）、Cancel（取消）等，以及一些通知相關的操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;ANP 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括描述信息與接口（Interface）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;描述信息主要是 JSON-LD 格式的文檔，以及 JSON-LD 文檔中通過 URL 鏈接到的其他資源，包括圖片、音頻、視頻等多媒體文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Interface 又分為自然語言接口（Natural Language Interface）和結構化接口（Structured Interface）。結構化接口支持現有大部分的規範，比如 OpenAPI、JSON-RPC 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差異：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 在協議層面定義了詳細的任務協作概念，包括任務的狀態、操作等，這有助於解決智能體之間複雜任務的協作問題。缺點是會導致兩個智能體之間的耦合度較高。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 簡化了智能體之間的交互，降低了智能體之間的耦合度，在跨平台的智能體協作場景下有較大的優勢。缺點是原生協議不支持複雜任務協作，需要自己定義 Interface 來實現。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;A2A 與 ANP 的原點&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;要想真正的理解一個協議的設計，必須找到這個協議的原點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，ANP 的原點一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;智能體在互聯網上的連接與協作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。MCP 的原點一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;模型與工具、資源的連接&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，構建更好的智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;通過上面的技術分析，我們可以確認 A2A 的原點是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;企業內部智能體之間的複雜協作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;協議的官網並沒有明確的説出這一點，但是谷歌的新聞發佈稿中有提到過一些：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;AI 智能體為人們帶來了獨特的機會，能夠通過自主處理許多日常重複性或複雜任務，幫助提升工作效率。如今，企業越來越多地構建並部署自主智能體，以幫助在整個工作場景中實現規模化、自動化並優化各類流程——從訂購新筆記本電腦，到輔助客戶服務代表，再到協助供應鏈規劃。（https://developers.googleblog.com/en/a2a&lt;/span&gt;&lt;span&gt;&lt;span&gt;-a&lt;/span&gt;&lt;/span&gt;&lt;span&gt;-new-era-of-agent-interoperability/）&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從 A2A 生態企業的分佈也大概可以看出這一點，大部分都是 AI 平台與服務、軟件、SaaS 和企業平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-2defdfdfeb005bbfae4fe07af3e72afe1a4.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="693" src="https://oscimg.oschina.net/oscnet/up-8026f8e9b8cc4e73963d2737dd793f74d30.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從技術上看，目前&lt;strong&gt;A2A 的實現也不大適合智能體互聯網的需求&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;以個人助手使用 A2A 去酒店智能體預訂房間為例，按照目前 A2A 的實現，個人助手需要發送一個任務，用自然語言描述用戶的要求（價格、房型、時間等）信息，酒店智能體處理後返回任務執行信息。在中間可能要經過多次的任務交互、任務狀態的遷移等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這會有兩個問題：一個是用戶的隱私可能會被泄露，因為個人助手要將任務發送給另外一個智能體執行；另外一個就是交互耦合度過高。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 的邏輯則是個人助手爬取酒店智能體的信息在本地進行處理，需要交互的時候才調用酒店智能體的接口。這是本質的區別。當然，除此之外 A2A 還有智能體在互聯網上的身份互聯互通問題沒有解決。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，&lt;strong&gt;也不排除未來 A2A 通過協議升級擴展到智能體互聯網的場景&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;未來智能體協議的一些預判&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;短期內 MCP 成為模型連接工具和資源的事實標準，這個基本上已經確定，目前很難有第二個 MCP 出現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;中長期來看，我認為有一個趨勢大概率會發生：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;工具智能體化，智能體工具化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果這個趨勢發生，那麼智能體協議會擠壓 MCP 的空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;更長期來看，AGI 實現後，也許人類設計的協議是 AI 的束縛而非助力，AI 有辦法自己設計協議並達成共識。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，在當下智能體協議是非常重要的，它是智能體的重要拼圖，也是智能體與互聯網交互最 AI 原生的方式，是比 Computer Use、Browser Use，甚至 AI 瀏覽器都更高效的連接方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;無論如何，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;ANP 最有價值的部分，是社區對未來智能體互聯網的設想，是社區獨特的互聯網理念（連接即權力），以及 DID+語義網的技術路線。這是支撐 ANP 走下去的核心動力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;關於創新&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 出來之後看着"炸裂、一夜變天、顛覆"這些標題心情複雜，特別是我們做 ANP 做了一年，也推廣了很長時間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們都在説，我們需要"0 到 1"的創新——我們不單需要創新者，也需要媒體能夠去發現這些創新者。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;最後感謝開源社區的每一位貢獻者和開發者，現在已經有 40 多位開發者了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;也感謝公眾號、社區對我們的支持，包括 RTE 開發者社區、OSC 開源社區、&lt;/span&gt;&lt;span&gt;Founder Park&lt;/span&gt;&lt;span&gt;、覺察流、侯宏文存、AIGCLink、智能體 AI 等等（可能不全），還有很多給我們提供分享機會的組織，以及為社區提供服務器資源的 AWS 和阿里雲。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;最後&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;如果你也認可我們的理念，認可我們對未來智能體互聯網的設想，歡迎加入我們，無論是以個人，還是以公司名義，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;我們需要你的支持&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們正在籌備 ANP 開源技術社區創始委員會，這是一個臨時委員會，目的是為了讓社區能夠走向正軌，成長為一個更加開放的社區。感興趣可以聯繫我。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;聯繫方式：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;開源項目 GitHub：https://github.com/agent-network-protocol/AgentNetworkProtocol&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;Discord: https://discord.gg/sFjBKTY7sB&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;官網：https://agent-network-protocol.com/&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;微信：flow10240&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9297178/blog/18398047</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9297178/blog/18398047</guid>
      <pubDate>Fri, 16 May 2025 05:07:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>NebulaGraph 圖數據庫開源六週年</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-347a643f66a66a9edf9d5760c1e8d2f4686.png" referrerpolicy="no-referrer"&gt;&lt;/strong&gt;&lt;/strong&gt;‍‍&lt;/p&gt; 
&lt;p&gt;2025 年 5 月 15 日，NebulaGraph 迎來開源六週年的里程碑。作為國產開源圖數據庫的標杆項目，回望 NebulaGraph 的六年發展歷程，不僅是一部技術迭代的編年史，更是中國開源社區在全球基礎軟件領域崛起的縮影。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、誕生：在數據關係的浪潮中揚帆起航&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 8 月 31 日， @Sherman-the-tank 在 nebula 倉庫中提出第一個 issue ‘Create a parser framework to process GQL.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 9 月 5 日， @dutor 提交了第一個 PR ‘Added some concurrent utilities, GenericThreadPool, etc.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph PMC Sherman Ye 曾參與多個分佈式數據庫研發工作，當社交網絡爆發式增長，引發數據關係挖掘需求井噴時，他敏鋭地意識到：圖數據庫是表示和理解關係最天然的工具，然而當時的圖數據庫或受限於單機性能，或困於擴展性不足，難以承載千億節點、萬億邊級的超大規模數據。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我們必須打造一款開源的、分佈式的、支持線性擴容的世界級圖數據庫，能夠容納千億頂點和萬億邊。&lt;/strong&gt;」Sherman 的願景，從一開始就超越了代碼本身。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4e970720b415322cc5254ac4b46dd587181.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 誕生於一間小公寓，初期核心團隊在這裏辦公）&lt;/p&gt; 
&lt;p&gt;NebulaGraph 採用 Shared-Nothing 架構與存儲計算分離設計，為 NebulaGraph 注入了宇宙級的基因——每個節點獨立處理數據，如同星雲中的星辰，既自由又協調；存儲與計算分離，則讓擴容像星雲膨脹般自然。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我們寫下 NebulaGraph 第一行代碼時，就認識到它必須是一款開源的圖數據庫&lt;/strong&gt;。」不忘開源初心，八個月後，NebulaGraph 遵循 Apache 2.0 開源協議，在 GitHub 開源 alpha 版本，從此開啓了突破國產圖數據庫技術的星辰大海征程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a9d672008ac303c7c9a6d86aa9b3c44aa2e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（一張開源紀念截圖）&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、應用：在產業實踐的土壤中紮根&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 10 月 29 日，攜程雲原生技術總監周昕毅先生在上海 nMeetup 上充分肯定了 NebulaGraph 作為開源解決方案在企業中的應用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用戶的選擇是最好的背書。六年來，NebulaGraph 用戶覆蓋金融、互聯網、通信、電商、保險、安全等多個行業。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-d2338012c10f02d334d817be194af6c777f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 部分用戶）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;攜程集團已有包括酒店、機票、金融在內的 16 個部門使用 NebulaGraph, 在風控場景，構建了實時圖特徵平台的應用邏輯閉環，額外獲取了 55% 的關聯業務信息，使得該場景下的覆蓋率提升了 32%&amp;nbsp;；奇富科技打造了智能化的金融反欺詐系統系統，累計報送涉騙阻斷預警 59 萬次，攔截潛在被騙者 9.5 萬人，幫助用戶避免損失 11.35 億元；OPPO 從 JanusGraph 切換到 NebulaGraph 後，導入性能提升了 10 倍，且查詢性能以及併發能力都有 3-6 倍的提升。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;NebulaGraph 是開源項目，用戶在真實使用場景中，為解決業務需求，會自然地參與共建，這種集體智慧加快了 NebulaGraph 的迭代：企查查貢獻了 Node 客戶端，奇富科技阿旺把自己做的 nebula-console-intellij-plugin 捐給了社區，篤篤科技大葉開發了 NebulaGraph 圖數據庫客戶端星影 StarShadow.&lt;/p&gt; 
&lt;p&gt;一幅技術紮根產業、需求反哺產品的共生圖景已然成形。這正是 NebulaGraph 在真實商業土壤中向下紮根、向上生長的最佳註腳。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、生態：在開源共治的生態中繁榮&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 3 月，NebulaGraph 在 GitHub star 數突破 10,000 大關&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph 社區構建了一套自由且開放的「雙軌成長體系」：開發者（Dev Group）聚焦代碼貢獻，用戶（User Group）專注實踐傳播。細分來看，還有學習者、佈道師、文檔貢獻者等角色，每種角色都能擁有自己的話語權，找到自己的存在價值，他們不會被統一地轉化成某一類角色，他們被允許以某一種角色停留在社區裏，比如僅僅作為用戶，或者僅僅作為一次性的代碼貢獻者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4781abc41f59cc55d7d129c6444f502e901.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph Community 成長體系）&lt;/p&gt; 
&lt;p&gt;作為開源項目，我們始終重視代碼共建共享。連續 5 年參與中國科學院軟件研究所發起的開源之夏，鼓勵全球高校開發者參與開源貢獻，為社區注入新鮮血液；舉辦 NebulaGraph Hackthon，設立 150,000 獎金池，從內核到周邊，讓廣大圖數據庫及 NebulaGraph 愛好者盡情探索圖世界。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a5cadecf20779c82bcf80c9e7896d7e77cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（來自開發者的認可）&lt;/p&gt; 
&lt;p&gt;線下活動同樣精彩紛呈。從 NUC 2021、2022，到足跡遍佈全國的 nMeetup，我們珍惜每次與用戶、開發者面對面交流的機會。也許大家素未謀面，但因為同在 NebulaGraph 社區，見證了萬星開源項目的崛起，每次線下探索圖數據庫的世界都能像老朋友一樣碰撞出思維的火花和久違的默契。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-9d32d3464c875255314f68fc03f7487fc59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（社區可愛的小夥伴們）&lt;/p&gt; 
&lt;p&gt;我們始終以包容的姿態，讓每個社區參與者的獨特貢獻匯聚成生態繁榮的星河。&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、未來：在雲與 AI 的浪潮中領航&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph Cloud&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2020 年，NebulaGraph 決定打造雲產品&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;NebulaGraph 從誕生之初起，不僅堅定走開源路線，還堅持雲原生理念。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如今，NebulaGraph Cloud 作為一套集成了 NebulaGraph 數據庫和數據服務的雲上服務，支持一鍵部署 NebulaGraph 和相關可視化產品。用戶可以在幾分鐘內創建一個圖數據庫，並快速擴展計算、存儲等資源，無需在本地搭建和維護複雜的圖數據庫基礎設施，從而能夠更加專注於核心業務的發展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-0f3996764f2cbb028787d68755889da4bdc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 控制枱界面）&lt;/p&gt; 
&lt;p&gt;NebulaGraph Cloud 除了在 AWS 上提供全託管服務，還計劃全面支持 Azure 和 Google Cloud Platform (GCP) 等主流公有云廠商，企業可夠根據自身需求和業務場景，選擇最適合的雲廠商。&lt;/p&gt; 
&lt;p&gt;申請試用⬇️&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.nebula-graph.io%2Flogin" target="_blank"&gt;https://cloud.nebula-graph.io/login&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph AI 應用平台&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2023 年 8 月 16 日，@wey-gu 與 LlamaIndex 聯合發佈 GraphRAG.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;正如 NebulaGraph 誕生之初，我們又一次站在高處看未來——洞察到圖結構在知識處理中的革命性潛力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2023 年 8 月，在 RAG 技術還未被稱為 RAG，而是上下文學習方法的時候，我們就意識到以圖的方式處理知識會對解決「大海撈針」等特定問題有很大幫助，因此&amp;nbsp;@wey-gu 提出了將圖數據庫與 RAG 結合的想法，向 LlamaIndex 提了第一個 PR，將 KG-RAG 轉變為 GraphRAG.&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-94fd0e2ef4e5265750786d1f60e9423f893.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph GenAI Team Leader @wey-gu）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GraphRAG 僅僅是 NebulaGraph 探索 GenAI 的「第一步」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨後，我們和 Researcher: Diego 一起討論，做了圖索引之上 Chain of Exploration 的工作，這種探索鏈不僅可以幫助 Agent 理解圖譜，還能從非結構化數據中提取出半結構化的知識圖譜‌。&lt;/p&gt; 
&lt;p&gt;在一系列 Graph based RAG 的落地實踐中，GenAI Team 又一次突破技術邊界，提出了 Fusion GraphRAG：融合了高級 RAG 技術，通過圖狀結構存儲文檔層級、章節關係及特殊元素（如公式、表格），實現高效、靈活的檢索。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-b04608e8eedc97b778355eed434fc9280f4.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（Fusion GraphRAG 是更高級的 RAG 技術）&lt;/p&gt; 
&lt;p&gt;但不止於此，NebulaGraph 把視角轉向企業級應用，基於 FusionGraphRAG 與 Agentic RAG 技術，打造了一個全新的高級知識庫與低門檻應用平台 —— NebulaGraph AI 應用平台（內部命名為 「Catalyst」，即催化劑），無需構建複雜 Workflow 和編寫繁瑣 Prompt，更智能地激活與應用企業內部知識。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-2cbc7e0b1c9bf670db137f17cbee8b6f5dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（用戶只需將對私有知識的理解轉化為對不同「知識籃子」的定義）&lt;/p&gt; 
&lt;p&gt;從 GraphRAG 到 NebulaGraph AI 應用平台，我們始終相信：真正的技術革命，不在於創造更復雜的工具，而在於讓複雜技術變得觸手可及。當每個企業都能像調配催化劑一樣輕鬆激活知識資產，我們離智能時代的真正到來，便又近了一步。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;六週年快樂🎉&lt;/h1&gt; 
&lt;p&gt;六載春秋，NebulaGraph 從一顆種子長成參天大樹，其根系已深入全球開發者土壤，枝葉則伸向雲與 AI 的星辰大海。NebulaGraph 的開源歷程，證明瞭通過開源共治，我們能打造出一款世界一流的圖數據庫產品，更證明瞭這羣活躍在開源社區的極客，有着無限的探索精神和創新能力。&lt;/p&gt; 
&lt;p&gt;因為開源，這場圖數據庫技術革命，沒有終點，只有新的起點。&lt;/p&gt; 
&lt;p&gt;因為有你，這場開源協作的星辰征途，沒有孤島，只有攜手同行的遼闊未來。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;開源最大的意義，莫過於代碼開放，共建共享，以用戶/開發者的力量推動產品迭代。&lt;/p&gt; 
&lt;p&gt;陪伴 NebulaGraph 共同成長的你，是使 NebulaGraph 愈發閃耀的星光。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-98d9a5b4f678bcb55a625b31b4cefe5e359.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.nebula-graph.com.cn%2Ft%2Ftopic%2F16781" target="_blank"&gt;在 NebulaGraph 論壇&lt;/a&gt;&amp;nbsp;分享你與 NebulaGraph 的故事，讓更多小夥伴感受到開源的力量。（分享即送星雲仔 T 恤，點贊 top3 可獲得全套社區周邊）&lt;/p&gt; 
&lt;p&gt;六月，NebulaGraph 社區將在北京舉辦 nMeetup，歡迎掃碼提交議題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" height="100" src="https://oscimg.oschina.net/oscnet/up-780ef5d7632ee90c872ab50c1333b6c1ddc.png" width="100" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;‍&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;如果你覺得 NebulaGraph 能幫到你，或者你只是單純支持開源精神，可以在 GitHub 上為 NebulaGraph 點個 Star！每一個 Star 都是對我們的支持和鼓勵✨&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvesoft-inc%2Fnebula" target="_blank"&gt;https://github.com/vesoft-inc/nebula&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4169309/blog/18403236</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4169309/blog/18403236</guid>
      <pubDate>Fri, 16 May 2025 03:53:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 牽頭推動 Transformers 庫模型架構標準化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Ftransformers-model-definition" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;聯合多家機構推動將&lt;code&gt;transformers&lt;/code&gt;庫作為模型架構標準，提升 AI 生態兼容性。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1238" src="https://static.oschina.net/uploads/space/2025/0516/114028_tsZR_2720166.png" width="1718" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Hugging Face 表示正與 vLLM、LlamaCPP、SGLang、Mlx、Qwen、Glm、Unsloth、Axoloth、Deepspeed、IBM、Gemma、Llama、Deepseek、Microsoft、Nvidia、InternLM、Llava、AllenAI、Cohere、TogetherAI 等眾多生態系統參與者共同努力，將&amp;nbsp;&lt;code&gt;transformers&lt;/code&gt;&amp;nbsp;庫中的模型定義代碼作為標準，旨在為所有模型提供一個統一的真實來源。&lt;/p&gt; 
&lt;p&gt;Hugging Face 目前正在與最流行的推理引擎（vLLM、SGLang、TGI、...）緊密合作，讓它們使用&lt;code&gt;transformers&lt;/code&gt;作為後端：只要模型被添加到&lt;code&gt;transformers&lt;/code&gt;，便支持在這些推理引擎中使用，同時利用每個引擎的優勢：推理優化、專用內核、動態批處理等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-dc6ac94d98590b08d7bb511a05cf4e82e7e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這項聯合工作將極大地提高不同模型架構在整個 AI 生態系統中的兼容性和互操作性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350188/huggingface-transformers-model-definition</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350188/huggingface-transformers-model-definition</guid>
      <pubDate>Fri, 16 May 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>得物自研 DSearch3.0 搜索核心引擎升級之路</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;&lt;span&gt;&lt;strong&gt;一、背景&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p style="text-align: left"&gt;&lt;span&gt;隨着交易和社區搜索業務穩步快跑，基建側引擎越來越複雜，之前搜索底層索引查詢結構已經存在較為嚴重的性能瓶頸。成本和運維難度越來越高。在開發效率上和引擎的穩定性上，也暴露出了很多需要解決的運維穩定性和開發效率短板。而在引擎的業務層部分也需要逐步升級，來解決當前引擎中召回層和業務層中各個模塊強耦合，難維護，迭代效率低下等問題。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/de1274b479a3468eb2c8c9732f943b6d~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=yG8v2qkQHq9NYLqIZ%2Bfln4tsbMw%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;h1 style="text-align: left" class="pgc-p"&gt;&lt;span&gt;&lt;strong&gt;二、引擎開發技術方案&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;h2 style="text-align: left" class="pgc-p"&gt;&lt;span&gt;&lt;strong&gt;DSearch1.0 索引層整體結構&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;DSearch1.0 的索引結構比較特殊一些，總體上使用了全局 rcu 的設計思想，整體架構上單寫多讀，所以實現了併發高性能無鎖讀，內部數據結構都是無鎖數據結構，所以查詢性能高。在寫操作上因為 rcu 機制實現寫入無鎖。整體上優點讀性能高，沒有傳統段合併操作帶來的磁盤抖動。缺點是索引地址和操作系統強相關，運維複雜，熱更新受限。全局地址分配難以並行寫入，構建瓶頸明顯。無法對浪費的內存進行回收導致內存空間利用率低，索引空間佔用大。總體結構如圖所示：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/90b13bdb5afb4c739e88babf772c494b~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=sBcaXhhCtFSFO6CLTcQ7Ldypf5o%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;h2 style="text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch2.0 的索引升級&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch2.0 分段索引整體設計&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;引擎 2.0 索引升級採用經典段合併架構，除了繼承了段合併中優異的高性能寫入性能和查詢已經索引合併等優勢外，針對段合併中頻繁的正排字段更新等帶來的高 IO 缺點。我們設計了新的正排字段原地更新索引，使新的 DSearch2.0 引擎擁有 Redis 的高性能寫入和查詢，也擁有 lucene 的緊湊索引和索引合併帶來的內存空間節省的優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 索引段結構&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每個索引段包含了文檔文件，用於緊湊存放 document 中的各個字段的詳細信息。字符串池文件是對 document 中所有的字符串進行統一順序存儲，同時&lt;strong&gt;對字符串進行 ID 化&lt;/strong&gt;，每個字符串 ID 就是對應於字符串池中的&lt;strong&gt;offset 偏移&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;可變數組文件是專門存放數組類型的數據，緊湊型連續存放，當字段更新的時候採用文件追加 append 進行寫。最終內存回收通過段&lt;strong&gt;之間的 compaction 進行&lt;/strong&gt;。FST 索引文件是專門存放 document 中全部字符串索引。每個 fst 的 node 節點存放了該字符串在字符串池中的偏移 offset。而通過字符串的 offset，能夠快速在倒排 termoffset 數組上二分查找定位到 term 的倒排鏈。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;倒排文件是專門存放倒排 docid，詞頻信息、位置信息等倒排信息，其中 docid 倒排鏈數據結構會根據生成段的時候計算 docid 和總 doc 數的密度來做具體判斷，&lt;strong&gt;如果密度高於一定閾值就會使用 bitmap 數據結構，如果小於一定閾值會使用 array 的數據結構&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;標記刪除 delete 鏈主要是用於記錄段中被刪除的 document，刪除操作是軟刪除，在最後查詢邏輯操作的時候進行最後的過濾。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;實時增量的 trie 樹結構，實時增量段中的前綴檢索和靜態段中的前綴檢索數據結構不一樣，trie 因為能夠進行實時更新所以在內存中使用 trie 樹。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;段中的 metadata 文件，metadata 文件是記錄每個段中的核心數據的地方，主要記錄段內 doc 數量，段內 delete 文檔比例，實時段的 metadata 會記錄 kafka 的 offset 等核心數據。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/24c940a2b35e4d15a162fe3ebf200d0f~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2BYmQsxTR%2FExv2AC40UdCJ0azAwA%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;Document 文檔和索引結構&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ Document 文檔數據結構&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;Document 文檔使用緊湊型存儲，其中 array 和字符串類型單獨存放，其他字段連續存放，string 和 array 字段存放。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;array 字段類型數據直接存放在可變數組文件區，連續追加寫。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;string 字符串池對所有字符串進行連續存放，多個 doc 中同一個字符串引用同一個字符串地址，節省大量字符串存放空間。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 倒排索引文件結構&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;倒排索引文件存放 docid 倒排和 Tf 以及位置 position 數據。其中內存實時段中的倒排索引數據結構是固定一種類型 array 類型。而內存實時段固化為靜態段的時候，倒排數據結構會根據 docid 中的密度進行選擇 array 和 bitmap 存儲。當 docid 密度大於一定閾值是 bitmap，反之是 array 結構。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;Tf 數據結構是一個 uint16 的數組，數組長度和 docid 的數組長度一致，所以當確定了某個 docid 時候，也隨即確定了它的 tf 信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;postion 信息存儲是一個二維數組的格式，第一層數組存放的是對應於 term 的在字符串池的 offset，因為 term 在字符串池中已經 ID 化，所以 offset 可以表示唯一 term。第二層數組是該 term 在字段中多次出現的位置，使用 uint16 存儲。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 前綴檢索文件&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;FST 靜態段文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;a. 靜態段中前綴是 fst 的數據結構，因為 fst 一旦建立是不能夠進行修改的，所以在段合併的時候需要對所有 term 進行排序然後再構建 fst 結構。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;b. fst 的 node 節點存放了對應於 term 的字符串池的 offset。當需要查詢一個 term 的倒排結構時候，需要先查詢該 term 的字符串池的 offset，然後拿該 offset 去倒排的 termoffset 文件中二分查找找到對應的倒排 positionlist 結構拿到對應倒排。所以一次 term 到倒排的查詢需要查詢一次 fst+一次二分查詢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;c. term 到倒排的查詢一次 fst+一次二分查找效率不高，所以針對 term 到倒排查詢，新增了第二種 HashMap 索引，直接通過 term 到倒排的 offset 索引，這個選項在建表的時候可以配置。&lt;/span&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;實時段 RcuTrie 樹索引&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;a. 實時段中需要支持邊寫邊讀，前綴檢索需要支持併發讀寫。引擎中 trie 樹是 rcu 實現，單線程更新，多線程併發讀，trie 樹寫更新節點內存延遲迴收。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/1a4ee53847174e60b8ac7df104a5d5b6~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=HOQHf%2Fr42ewivfi%2BZbf2pws0nLo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;倒排索引和查詢樹邏輯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 倒排鏈優化&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;DSearch1.0 的 roaringbimap 倒排索引在低密度數據量上存在一些瓶頸，比如對於倒排鏈比較短的情況下，roaringbitmap 的 container 大部分都是 array 結構，在倒排鏈查詢和合並都會進行一次二分查找，在大面積的倒排鏈合併中是個相當大的性能瓶頸。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;針對上面所説的情況對 roaringbitmap 進行了精簡，只存 array 或者 bitmap 合併的時候不需要查找，直接鏈式合併。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 邏輯樹合併優化&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;DSearch2.0 重點從邏輯語法樹和倒排入手，優化語法樹，減少合併樹高，從二叉樹合併變成單層合併。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;優化倒排鏈合併方式，採用原地倒排鏈合併，消除倒排合併臨時對象，同時引入多線程並行合併，減少長尾提高性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a324c1263d7045f6a4346f99c7f97124~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=DxtCm2sohwPSMuxM%2Flr5%2BTSP4kg%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;增量更新邏輯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 增量實時寫入邏輯&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;引擎支持多個併發實時段，這個由配置文件通過配置來進行配置。多個實時段能夠提升併發寫入的性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每個實時段對應一個寫入隊列，提高併發寫入吞吐。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每個段真實寫入一條信息會同步原子更新消費的 kafka 的 offset，用於對後面進程重啓等恢復數據做準備。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;當進程重啓或者異常退出時候，會讀取 metadata 文件中的最後一條 kafka offset 進行重新消費增量在內存中重新構建新的正排、文檔和倒排等信息，完成數據的恢復。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/4a6eba83cdd74c1587d9aa76bf35ddbd~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=okNAsDWIX8ozfo9pqhZbj2DF39Q%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;實時段固化和段合併策略&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 實時段固化邏輯：&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;當實時段內隨着增量寫，doc 文件大小超過 128M 時候會進行內存實時段固化操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;固化操作開始時，會先生成新的內存實時段，老的內存實時段會變成只讀內存段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;遍歷按整個只讀內存段，構建新的索引和新的正排結構生成新的靜態段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 段合併策略：&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;實時段固化的小靜態段因為大小比較小，會優先和之前固化後的小段進行合併，按照 1，2，4，8 進行合併，逐步合併成靜態段最大的上限。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;靜態段的合併觸發策略是當靜態段中 delete 的 doc 比例超過了 30% 會觸發靜態段之間的合併，合併會按照近鄰合併原則，從左右近鄰中選取一個最小 doc 數的段進行合併，進而新生成一個新的段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/08582c715cbd47d0b298435e57bac25f~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=40FqkO626yUPY%2BI3uTtsbA1Ihwo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;查詢和更新中的併發控制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 查詢流程&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;引擎查詢時候，先遍歷查詢實時段，然後再查詢靜態段。實時段查詢存在最大增量查詢截斷，當實時段查詢到最大增量截斷時實時段停止查詢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;實時段查詢後，查詢靜態段。靜態段中包含了全量構建索引的全量最大 offset 記錄同時全量的 doc 是通過質量分進行排序，所以在全量段查詢的時候，先遍歷質量分最大的全量段，逐步往後面靜態段查詢，直到查詢到全量截斷。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;實時段查詢和靜態段查詢結果進行 merge 作為最終的查詢結果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 更新併發控制&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;因為 DSearch2.0 的索引更新是直接在實時段或者靜態段進行更新，所以存在多線程讀寫問題。尤其是正排字段更新寫入量大更新頻繁。同時更新涉及到所有的實時段和靜態段，較為複雜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;為瞭解決正排字段和倒排的更新問題，新版本引擎引入了 document 文檔鎖池，對每個 doc 進行 hash 計算落到鎖池中具體一個鎖上來減少鎖衝突，當前鎖池內有多個個文檔鎖。文檔鎖在文檔進行拷貝和更新的時候會進行鎖住。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch3.0 搜索核心升級&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;異步非阻塞圖調度框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7e1821341e54416a99384f4ae1016048~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=Ugikrdj%2Fc%2FMZkAFTUtc7L9JVcG0%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="color: rgb(62, 62, 62)"&gt;&lt;strong&gt;圖框架支持 RPC 異步非阻塞請求：&lt;/strong&gt;&lt;/span&gt;&lt;span style="font-size: 0.882em"&gt;引擎圖框架 RpcServer 服務使用 brpc 的異步處理無需同步阻塞等待調度完成，只需框架調度完算子返回結果，不阻塞 RpcServer 線程，例如：當前引擎調用 neuron 服務是同步調用，當 neuron 服務負載高阻塞時，同步調用會導致拖住引擎 RpcServer 處理線程，新的異步非阻塞模式引擎 client 在調用引擎後已經返回，等待引擎 RpcServer 中異步調度框架中 remote 異步算子回調，減少外部服務影響引擎。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;減少線程切換：&lt;/strong&gt;圖框架調度器會優先調度當前運行線程，同時使用 M:N 類型的 bthread 線程池，線程切換會更小，執行效率高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;RPC 服務和框架算子獨立：&lt;/strong&gt;引擎 RPC 服務和框架算子完全解耦，跨集羣部署算子服務無需任何改造，實現算子脫離運行環境。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;高效的算子異常處理和超時機制：&lt;/strong&gt;每個算子維護自己的運行超時時間和請求到算子調度執行的超時時間，對整個請求流程中各算子執行更加精準。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;動態圖支持：&lt;/strong&gt;圖框架支持靜態圖和動態圖業務組合式調用。支持靜態子圖和動態子圖調用等複雜業務組合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;複雜子圖支持：&lt;/strong&gt;圖框架支持嵌套子圖，支持自調用模型，可以實現複雜單節點多功能調用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;算子間數據交換 Table 設計&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3bf931610dd74d5da3be98d3395310ab~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=n4lk8KDSCTKVPt6uIgyIxo9v%2FPw%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;列式數據共享優化：&lt;/strong&gt;算子交換數據全部存放在 Table 列中，Table 中全部共享列式數據，省去大面積數據拷貝，大幅提升引擎業務執行性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;兼容引擎索引中 doc 數據：&lt;/strong&gt;引擎索引中 doc 行式存儲有很多優點，比如多字段訪問效率高等，Table 設計中考慮了行式存儲優點，不僅存高頻的列字段也儲存了引擎內部的 doc*以及對應 FieldDef*，能直接方便訪問索引數據，接口統一，易於迭代。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;打通 FlatBuffer 序列化協議：&lt;/strong&gt;當前引擎 FlatBuffer 序列化傳輸協議和引擎內部數據出口需要多次遍歷轉換，需要拷貝很多數據，新 Table 的設計內部數據列和 FlatBuffer 內部的數據列互轉互通，節省大量內部拷貝同時避免了字段兼容等問題。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;支持原地排序和標記刪除：&lt;/strong&gt;Table 數據表，支持原地 sort 操作和標記刪除操作，節省數據排序時大量數據的拷貝和刪除操作中導致的數據重排等拷貝操作，提升性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;算子間數據交換 Table 設計&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a96224208f0d46f2b9abffe520367ac1~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=zR%2B1sBPOMWcKSWcnoqSS3HtpR%2Bo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;動態圖支持：&lt;/strong&gt;DSsearch3.0 支持動態圖編排，主要通過業務方通過動態編排請求來組織對應的算子編排邏輯，實現業務方自主編排調度邏輯，方便整體業務開發。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;Remote 遠程調用支持：&lt;/strong&gt;通過開發遠程異步調用算子，支持 DSearch3.0 跨集羣調用，實現多機算子化互聯互通。提高引擎的整體縱向拓展能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;引擎算子庫複用：&lt;/strong&gt;通過設計統一的算子接口，開發基礎的可複用框架算子，支持配置化組合運行圖，實現業務邏輯快速複用和開發，提高整體引擎開發效率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;三、性能和效果提升&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;DSearch 在 2024 年 Q1 季度索引升級開發完成後逐步推全到交易和社區等各個主場景業務中，最後拿到了很多超預期結果：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;索引內存優化超出預期：&lt;/strong&gt;社區搜索和交易搜索總索引單分片優化 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;構建和寫入性能優化超出預期：&lt;/strong&gt;社區搜索和交易搜索主表寫入性能提升 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;索引更新優化超預期：&lt;/strong&gt;社區和交易主表更新時間提升接近 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;性能優化符合預期：&lt;/strong&gt;社區搜索平均 rt 降低一倍，P99 晚高峯降低 2 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;四、總結&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;DSearch 引擎從開始的 DSearch1.0 的搜索引擎逐步經歷了 DSearch2.0 的分段式索引改造升級，又經歷了 DSearch3.0 的全圖化引擎升級。逐步將 DSearch 引擎升級到業界較為領先的支持內存型、磁盤型多段式搜索引擎，為支持得物業務的發展做出了重要的貢獻，後續 DSearch 會圍繞着通用化、自迭代、高性能等多個方向繼續升級，將 DSearch 引擎迭代到業界領先的引擎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;算法團隊大量 HC，歡迎加入我們：&lt;/strong&gt;得物技術大量算法崗位多地上線，「職」等你來！&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;1. 以細節詮釋專業，用成長定義價值——對話@孟同學 ｜得物技術&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;2. 最近爆火的 MCP 究竟有多大魅力？MCP 開發初體驗｜得物技術&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;3. 得物可觀測平台架構升級：基於 GreptimeDB 的全新監控體系實踐&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;4. 得物自研 DGraph4.0 推薦核心引擎升級之路&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;5. 大語言模型的訓練後量化算法綜述 | 得物技術&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;文 / 蘇黎&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;關注得物技術，每週更新技術乾貨&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18387813</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18387813</guid>
      <pubDate>Fri, 16 May 2025 03:36:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Dify.AI 開源兩週年更新品牌形象，堅持「讓每一個想法變成 AI Agent」的使命</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源 AI 應用開發平台 Dify.AI &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdify.ai%2Fblog%2Four-vision-takes-shape-imagine-if" target="_blank"&gt;迎來了兩週年&lt;/a&gt;。在慶祝之際，Dify 發佈了全新的品牌形象和外觀。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/111845_qi60_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a96b9b86bb6e4f0894313ba038203e4ef27.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Dify 的使命保持不變，即讓每一個想法都能變成 AI Agent。新的品牌口號強調&lt;strong&gt;「如果」你能想到，通過 Dify 你就能構建它&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/111557_HOat_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350181</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350181</guid>
      <pubDate>Fri, 16 May 2025 03:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2030 年我國數據產業規模將達 7.5 萬億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;2025 數據安全發展大會上介紹，我國將培育壯大一批數據要素產業鏈上下游企業，預計到 2030 年，我國數據產業規模將達到 7.5 萬億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作為全球首個將數據納入生產要素的國家，我國已初步構建起門類齊全的數據產業鏈。數據顯示，2024 年我國年度數據生產總量達 41.06 澤字節，同比增長 25%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;截至目前，我國數據領域相關企業超 19 萬家，數據產業規模超 2 萬億元。按照 20% 以上的年均增長率測算，2030 年我國數據產業規模將達 7.5 萬億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-8974708623b157a8be63e50fae982623dce.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家數據局局長劉烈宏表示：探索適應數據特徵的產權配置、流通模式和安全治理機制，培育壯大一批數據要素產業鏈上下游企業。當前我們正謀劃構建橫向聯通、縱向貫通，協調有力的數據基礎設施體系，到 2029 年要基本建成國家數據基礎設施主體結構。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公共數據開放共享成為數據要素市場化的重要突破口。2024 年全國地市級以上的地方公共數據開放平台數量增長 7.5%，開放數據量增長 7.1%，高質量數據集數量同比增長 27.4%。在數據要素與產業融合方面，國家正加快打通公共數據共享開放壁壘，推動公共數據與企業數據深度融合，激活海量「沉睡數據」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350559</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350559</guid>
      <pubDate>Sun, 11 May 2025 02:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>如何用好 「對話式編程」？牢記這十二條策略</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 如何有效利用大語言模型（LLMs）生成高質量代碼？這是當下開發者們比較關心的一個問題。在生成代碼的過程中，提示詞的設計是否精確，直接決定了模型輸出的質量。&lt;/p&gt; 
 &lt;p&gt;本文深入探討了提示詞優化的 12 條策略，給出了清晰的操作指南和示範案例，讀者可以瞭解到如何通過精準編寫提示詞引導模型生成性能優越、符合實際需求的代碼。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Ayush Thakur@Potpie&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpotpie-ai%2Fpotpie" target="_blank"&gt;https://github.com/potpie-ai/potpie&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;大語言模型（LLMs）已經徹底改變了代碼生成領域，但要想獲得高質量、有用的輸出結果，編寫有效的提示詞至關重要。LLMs 生成代碼的質量高度依賴於所提供提示詞的質量。&lt;strong&gt;一句表述不當的提示詞可能導致不完整、不正確或雖然正確但不具備針對性的響應，而邏輯性、完整性和易讀性良好的提示詞則能最大化發揮模型的潛力。&lt;/strong&gt; 本文將探討編寫有效提示詞的高級策略，以便使用 LLMs 生成高質量的代碼。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 提供詳細的上下文&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在與 LLMs 進行交互生成代碼時，所提供上下文的深度和質量直接影響模型輸出的相關程度和準確程度。&lt;/p&gt; 
&lt;p&gt;上下文需要包含的關鍵要素有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Specific problem domain（譯者注：指的是你試圖解決的問題所在的特定專業或技術領域。例如，如果你正在開發一個系統來處理金融交易，那麼你的問題領域就是金融科技（FinTech）。）&lt;/li&gt; 
 &lt;li&gt;Existing codebase characteristics（譯者注：指的是當前項目中已有代碼的特點、風格和結構等信息。）&lt;/li&gt; 
 &lt;li&gt;Implementation constraints（譯者注：在實現解決方案時必須遵守的各種限制條件，如只能使用某些技術棧等。）&lt;/li&gt; 
 &lt;li&gt;Performance requirements（譯者注：指的是系統或應用程序需要達到的性能標準。）&lt;/li&gt; 
 &lt;li&gt;Architectural patterns already in use（譯者注：指的是在當前項目或組織中已經採用的軟件架構模式。架構模式是一種通用的、可重複的設計模板，用於解決軟件架構中的常見問題。例如，微服務架構、分層架構（n-tier architecture）或是事件驅動架構等。）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，你可以使用 &lt;a href="https://my.oschina.net/references"&gt;@references&lt;/a&gt; 指向特定文件或函數（譯者注：大部分「對話式編程」 Apps 都支持該功能），使你的請求更加精準。與其用文字描述某個函數，不如直接引用它。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❌ 欠佳的提示詞：創建一個用戶身份驗證系統。&lt;/p&gt; 
 &lt;p&gt;✅ 更好的提示詞：為我們的 Node.js Express API 創建一個基於 JWT 的身份驗證系統，該系統需要與 MongoDB 的 user 集合集成。該系統應使用 bcrypt 處理密碼哈希，簽發有效期為 24 小時的令牌，並實現刷新令牌（refresh token）輪換機制增強安全性。現有的中間件模式採用 async/await 語法。請參考 @authMiddleware.js 的中間件結構和 @userModel.js 的 user 集合結構。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;通過使用 @authMiddleware.js 和 @userModel.js，可以確保生成的代碼與現有架構保持一致，減少一些集成問題和手動調整工作量。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 將問題分解為多個步驟&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;複雜的編碼任務需要系統性地拆解為可管理單元。該方法論的實施路徑如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;從明確的功能需求出發&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分析目錄結構和代碼組織方式&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;引導 LLM 按照邏輯步驟實現目標功能，同時遵循既定的架構邊界和設計模式。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;例如，在實現一個數據處理 pipeline 時，首先需明確輸入的數據結構、轉換邏輯、錯誤處理的相關要求及預期的輸出格式。隨後分析目錄結構，並確定新功能的實現位置。&lt;/p&gt; 
&lt;p&gt;需要綜合考量代碼之間的依賴關係（dependency relationships）、模塊的職責劃分與隔離（module boundaries）以及代碼的目錄結構與命名規範（code organization principles）。這一步驟可確保生成的代碼能無縫集成到現有代碼庫中。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 選擇合適的模型完成任務&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;不同 LLM 在代碼生成任務中展現出的優勢不同。&lt;strong&gt;某模型可能擅長理解複雜需求並生成邏輯一致性強的代碼，而另一模型可能在特定編程語言或框架上具有優勢。&lt;/strong&gt; 在評估使用哪種 LLM 時，需着重關注以下技術因素：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文窗口大小（處理大型代碼庫時至關重要）&lt;/li&gt; 
 &lt;li&gt;對編程語言/技術框架的掌握程度&lt;/li&gt; 
 &lt;li&gt;特定領域的專業知識&lt;/li&gt; 
 &lt;li&gt;多輪交互的穩定性&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對比示例：&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;任務類型&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;模型選擇考量因素&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;複雜的企業級架構&lt;/td&gt; 
   &lt;td&gt;更大的上下文窗口大小有助於在大型代碼庫中保持多輪交互的穩定性&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;機器學習 pipeline&lt;/td&gt; 
   &lt;td&gt;數學基礎紮實且經過數據科學專項訓練的模型更具優勢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;前端組件&lt;/td&gt; 
   &lt;td&gt;採用新近框架數據訓練的模型，可輸出符合業界最新標準的代碼模式&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;&lt;strong&gt;04 具體參照現有的代碼實現模式&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在提示詞中明確具體細節能大大提升代碼生成的質量。&lt;/strong&gt; 技術細節需明確指向代碼庫中的既有實現範式，而非籠統要求通用方案。例如：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❌ 欠佳的提示詞： 「寫一個處理用戶數據的函數」&lt;/p&gt; 
 &lt;p&gt;✅ 更優的提示詞：「在 UserProcessor 類 (src/services/UserProcessor.js) 中創建一個新方法，沿用 transformPaymentData 方法的函數式編程風格實現用戶數據的轉換。因採用異步機制，實現時應以可讀性為第一準則，性能次之。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該方法也同樣適用於命名規範、編碼標準和架構模式。需明確説明採用函數式或面向對象範式，指定設計模式類型，並澄清性能與代碼可讀性的優先級。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 請重新生成而非回滾&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;當生成的代碼出現問題時，重新生成有問題的模塊通常比逐步去修復代碼中的問題效果更好。&lt;/strong&gt; 此方法源於大語言模型理解上下文和生成模型響應的機制。&lt;/p&gt; 
&lt;p&gt;為何重新生成效果更好？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;脫離原有錯誤實現方式的思維定式&lt;/li&gt; 
 &lt;li&gt;防止舊代碼中的錯誤代碼邏輯污染新的代碼實現&lt;/li&gt; 
 &lt;li&gt;支持加入新的約束條件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種方法對解決一些算法難題或實現複雜的代碼邏輯特別有效，因為在這些場景下一點細微的錯誤都可能影響整體解決方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「請嘗試用不同的方法實現排序算法。當前版本的時間複雜度為 O(n²)，無法滿足數據集規模要求，請基於我們其他的數據處理函數使用的歸併排序模式，重新生成 O(n log n) 時間複雜度的解決方案」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;06 決策前請生成多套方案進行對比&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;利用大語言模型能夠生成多套解決方案的能力，通過對比分析提升代碼質量。首先，要求模型生成 2-3 種不同的實現策略，每種策略需包含對該方案優缺點的分析。&lt;/p&gt; 
&lt;p&gt;生成多套方案後，引導模型分析時間複雜度、空間複雜度、代碼可讀性和可維護性等因素，並分析如何權衡這些因素。這一反思（reflection）過程使模型能根據具體需求選擇並完善最合適的解決方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「請為 API 響應緩存系統（caching system for our API responses）提供三套實現方案：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;基於自定義數據結構的 LRU 內存緩存方案&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;基於 Redis 的分佈式緩存方案&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;支持 TTL 的本地文件系統緩存&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;請分別分析各方案的時間複雜度、內存佔用、多服務器擴展能力和實現複雜度」&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 實施自我審查機制&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Self-review prompting 可通過引導大語言模型對其生成的代碼進行系統化評估來提升代碼質量。具體實施時需明確要求模型在完成代碼生成後交叉檢查其生成的代碼。自我審查（Self-review）應評估以下這幾個方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;代碼正確性（是否有邏輯錯誤）&lt;/li&gt; 
 &lt;li&gt;效率（是否存在性能問題）&lt;/li&gt; 
 &lt;li&gt;邊界情況的處理情況&lt;/li&gt; 
 &lt;li&gt;安全漏洞&lt;/li&gt; 
 &lt;li&gt;是否嚴格滿足需求&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在自我審查過程中，模型可識別潛在問題，例如併發代碼中的競態條件漏洞（譯者注：一種常見安全漏洞，源於系統或程序在處理併發操作時因時序問題導致的邏輯錯誤。）、資源管理中的內存泄漏，或直接影響系統安全的核心邏輯中的漏洞風險點。發現問題後，模型可立即優化代碼實現來解決問題。此方法對應成熟的軟件工程實踐（如代碼審查和靜態分析），但將其置於同一 prompt-response 週期內執行，大大提升了初始的代碼生成質量。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;08 為模型賦予技術人設或給出參考框架&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;為大語言模型分配技術人設，可確保其代碼生成保持統一的專業視角。當要求模型以"精通分佈式系統的高級後端工程師"的思維模式運作時，其生成的代碼會優先考慮可擴展性、容錯性和性能優化。同理，若賦予"安全專家"人設，其生成的代碼會重點強化內容輸入區的驗證、規範認證流程，並預先規避潛在的漏洞風險。&lt;/p&gt; 
&lt;p&gt;技術參考框架需與任務需求相匹配。&lt;/p&gt; 
&lt;p&gt;根據不同任務選擇不同的專業人設：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;後端系統："具備分佈式系統專業知識的高級後端工程師"&lt;/li&gt; 
 &lt;li&gt;安全模塊："熟悉 OWASP 規範的安全架構師"&lt;/li&gt; 
 &lt;li&gt;基礎設施："專攻雲原生解決方案的 DevOps 工程師"&lt;/li&gt; 
 &lt;li&gt;前端開發："關注用戶體驗且具有無障礙化開發經驗的前端工程師"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種方法利用模型模仿領域專家的能力，使生成的代碼更精準體現特定技術領域的行業最佳實踐。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「扮演高級安全工程師進行代碼審查。用 Python/Django 創建用戶註冊系統，需實現合規的密碼處理、輸入驗證功能，並防禦常見 Web 漏洞。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;09 明確編程語言、開發框架或第三方庫的限制條件&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;明確説明技術限制條件，才能確保代碼與運行環境完美兼容。首先應清晰説明編程語言版本（例如 Python 3.9、TypeScript 4.5），確保生成的代碼所使用的語言特性在生產環境中可用。同時需指定框架版本及其特定規範，例如"使用 Pydantic v2 模型的 FastAPI 0.95 進行數據驗證"。&lt;/p&gt; 
&lt;p&gt;此外，還要交代清楚：用哪些第三方庫、具體怎麼接入。例如，在請求生成數據庫交互代碼時，應指定使用 SQLAlchemy 等 ORM 還是原始的 SQL queries，並明確數據庫連接的處理要求。摳到這種細節程度，才可以避免生成依賴了不可用的組件或版本不兼容的代碼。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「請使用以下技術棧開發 REST API 接口：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Python 3.9&lt;/li&gt; 
  &lt;li&gt;搭載 Pydantic v2 模型的 FastAPI 0.95 框架&lt;/li&gt; 
  &lt;li&gt;使用 SQLAlchemy 2.0 執行數據庫操作&lt;/li&gt; 
  &lt;li&gt;通過 auth_utils.py 文件中現有 AuthManager 實現 JWT 身份認證&lt;/li&gt; 
  &lt;li&gt;必須兼容 PostgreSQL 13 數據庫」&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;10 實施思維鏈這一提示詞工程技術&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;思維鏈（Chain of thought prompting）通過引導大語言模型進行邏輯推理，可以大大提升代碼生成質量。這個方法的精髓是：讓 AI 先拆解問題再寫代碼。&lt;/p&gt; 
&lt;p&gt;要求模型按這個順序分步思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;用大白話解釋實現思路&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;搭建解決方案的偽代碼框架&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;每個模塊的具體實現邏輯&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;最終完整可運行的代碼成品&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;思維鏈技術對於包含複雜邏輯或數據轉換的算法特別有效。這種方法可以減少邏輯錯誤，提高代碼的一致性，並可視化模型的推理過程，便於在最終代碼生成前進行修正。&lt;/p&gt; 
&lt;p&gt;與側重任務分解的"分步執行"方法不同，思維鏈技術着重於顯性化模型的推理路徑，確保在確認最終方案前保持邏輯的嚴謹性。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;11 針對不同大語言模型（LLM）的特長設計專屬的提示詞策略，以最大化發揮其優勢&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;不同的大語言模型具備各自獨特的優勢，通過針對性的提示詞技巧可以充分發揮它們的潛能。&lt;/p&gt; 
&lt;p&gt;提示詞策略如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;針對上下文窗口有限的模型：聚焦分步算法指導&lt;/li&gt; 
 &lt;li&gt;針對擅長函數式編程的模型：使用函數式思維提問&lt;/li&gt; 
 &lt;li&gt;針對精通某一特定開發框架的模型：直接使用該框架的核心 API、類名或設計模式等特定術語提問，減少解釋成本。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;瞭解模型在訓練過程中接觸的數據集特點是優化提示詞的關鍵。&lt;/strong&gt; 不同的模型因其訓練數據分佈不同，往往只對特定編程範式或語言有更強的理解力。例如，若某模型在訓練中接觸了大量函數式編程內容，那麼當問題本身適合使用函數式編程解決時，用函數式編程術語構建提示詞，將獲得更精準的響應。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;12 指定邊界情況和約束條件&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;全面覆蓋邊界場景能大幅提升代碼健壯性 &amp;nbsp;。技術領域的邊界情況因場景而異，但通常包含臨界值（譯者注：如數值溢出、空輸入）、資源限制（譯者注：如內存耗盡、超時）和異常狀態（譯者注：如網絡中斷、併發衝突）。在向模型發送請求生成代碼時，應明確列出這些要素，例如説明數據處理函數應如何處理空輸入、格式錯誤的數據或超出預期範圍的值。&lt;/p&gt; 
&lt;p&gt;通過預先考慮這些約束條件，生成的代碼可包含與指定限制條件相匹配的驗證邏輯、錯誤處理機制和性能優化方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「實現一個能處理以下情況的文件處理函數：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;空文件（返回空結果）&lt;/li&gt; 
  &lt;li&gt;超過 1GB 的文件（分塊讀取處理）&lt;/li&gt; 
  &lt;li&gt;格式錯誤的 CSV 數據（記錄錯誤並跳過錯誤行，繼續處理後續有效行）&lt;/li&gt; 
  &lt;li&gt;多進程/線程同時操作同一文件（需加鎖（如文件鎖、數據庫鎖）避免數據競爭）&lt;/li&gt; 
  &lt;li&gt;網絡中斷（需支持斷點續傳）」&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;掌握代碼生成的提示詞工程既是一門藝術，也是一門科學，它能大幅提升開發效率。通過運用這些策略方法，開發者可以將大語言模型（LLM）從簡單的代碼生成工具升級為智能開發助手，從而打造出更健壯、高效且易於維護的軟件系統。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Ayush Thakur&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Developer Advocate | Community Manager | Technical Writer&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;文中提到「重新生成代碼優於修復 Bugs」，你在實際使用「對話式編程」時有這種感受嗎？&lt;/strong&gt; &lt;strong&gt;歡迎在評論區分享~&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由&lt;/strong&gt; &lt;strong&gt;Baihai IDP&lt;/strong&gt; &lt;strong&gt;編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpotpie-ai%2Fpotpie%2Fwiki%2FHow-to-write-good-prompts-for-generating-code-from-LLMs" target="_blank"&gt;https://github.com/potpie-ai/potpie/wiki/How-to-write-good-prompts-for-generating-code-from-LLMs&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18426598</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18426598</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>OpenAI 發佈編程 Agent「Codex」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式發佈編程 Agent 產品「Codex」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0e12276316926445f454385b24aee64ca00.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Codex 是一款支持並行處理多個任務的雲端編程 Agent，能夠提供如編程功能、回答代碼庫的問題、修復錯誤等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0519/100634_jTO9_2720166.png" width="1336" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1578" src="https://static.oschina.net/uploads/space/2025/0519/100843_qXsH_2720166.png" width="1190" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Codex 基於 codex-1 模型驅動，OpenAI 方面表示這一模型由 o3 模型針對編程進行優化而得來。codex-1 通過強化學習在各種環境中，對現實世界的編碼任務進行訓練，從而能夠生成接近人類風格和 PR 偏好的代碼。&lt;/p&gt; 
&lt;p&gt;在 OpenAI 自己的代碼評估和內部基準測試中，codex-1 即使沒有 AGENTS.md 文件或自定義腳手架（custom scaffolding）也表現出色。&lt;/p&gt; 
&lt;p&gt;目前，Codex 提供的是研究預覽版。使用方面，OpenAI 將會優先為 ChatGPT Pro 用戶、企業或團隊用戶提供 Codex，Plus 用戶和教育用戶也即將能體驗到。&lt;/p&gt; 
&lt;p&gt;另外，OpenAI 還同時公佈了 codex-1 的小號版本，基於專為 Codex CLI 設計的 o4-mini 打造。模型型號為「codex-mini-latest」，API 定價為每百萬輸入 token 1.5 美元，每百萬輸出 token 6 美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多詳細內容查看 Codex 技術報告：&lt;/strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-codex%2F" target="_blank"&gt;https://openai.com/index/introducing-codex/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350557/openai-codex</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350557/openai-codex</guid>
      <pubDate>Sun, 11 May 2025 02:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
