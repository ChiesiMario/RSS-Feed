<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 15 Jul 2025 21:41:10 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>北京人形發佈高保真鉸接物體數字資產 ArtVIP</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;隨着具身智能訓練對數據需求的不斷放大，通過仿真&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;合成數據&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;彌補數據缺口已成為行業當前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;共識和&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;重要課題。近日，北京人形機器人創新中心（後稱北京人形）與北京市建築設計研究院（後稱北京建院）聯合打造的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;高保真&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;鉸接物體數字資產數據集&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP（Articulated-object digital assets with Visual realism, modular Interaction, and Physical fidelity）正式發佈，該數據集實現了對高複雜度鉸接物品的高精度仿真，在還原物品視覺外觀的同時，以高保真度復現了物品物理特性，並且開源了 6 個支持全場景交互的虛擬機器人訓練場。除開源已有場景提升行業模型訓練效果外，北京人形同時可針對不同場景不同物品提供定製化建模服務，為具身智能快速落地提供平台支撐。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;&lt;span&gt;項目主頁：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://x-humanoid-artvip.github.io/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span&gt;&lt;span&gt;huggingface：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://huggingface.co/datasets/x-humanoid-robomind/ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;隨着具身操作訓練的快速進展，機器人&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在執行精準抓取拿放等動作方面已經有了長足進步&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，行業攻堅的重點轉向了針對複雜物體的靈巧操作。但在此前，主流開源仿真資產數據集如&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;PartNet-Mobility、BEHAVIOR-1K&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;等在物體&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;複雜度上難以達到要求，特別是針對轉椅、抽屜、冰箱等帶有可活動關節的物體，始終缺乏成熟方法生成或製作此類數字資產，導致模型由仿真走向現實的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Sim2Real&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;訓練和部署&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;存在巨大鴻溝。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;為解決該問題，北京人形與北京建院共同合作，將雙方的機器人仿真經驗與數字化建模能力相結合，由前沿的具身智能需求作為牽引，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;讓現實物品在數字世界中重新覺醒&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP 構建了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;全球最&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;精細&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;複雜鉸接物體庫，包括 26 類共 206 種高精度可動物件，實現了對櫥櫃、&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;烤箱&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、摺疊椅、抽屜、電風扇、剪刀等不同特性鉸接結構狀態的精準仿真。通過海量高複雜度物品覆蓋，支持訓練具身智能模型獲得處理機械結構變異性的泛化能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-d5858e5619af59c5b4e81d91d5f50c8d041.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;針對物理參數的細節參數調整，讓&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;實現了高物理一致性，能夠充分參考物品的剛度&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;阻尼&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、摩擦力、質量、轉動慣量、碰撞體積等參數，模擬不同物品的在被操作或運轉時的物理特性。如辦公轉椅受側向力時，各輪組會依據地面摩擦係數差異自動形成轉向序列差；具備阻尼或彈簧特性的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;烤箱&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;開口打開至特定角度，在仿真場景內操作或受力後的反饋與現實中完全一致，甚至冰箱門也與現實中一樣在關門時有&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;相應&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的磁吸效果。高精度動力學還原使&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;具身智能算法&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;能夠&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;習得符合現實的力控制策略，為開門、推椅等需精細力覺反饋的任務提供可靠訓練環境。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-18ec00e6bbebf4c5de95ab767fccc7e62b9.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-12767b0507fd61d770101480c0761ae0d7e.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;除常見的有固定形態的剛性物體外，北京人形&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;構建的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;數字資產平台&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;支持行業領先的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;剛體&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;流體&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;-柔性體全&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;物質形態&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;仿真&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。冰塊在水杯中因水流改變漂動方向，衣物等柔性物體的摺疊與褶皺，甚至衣物在洗衣機滾筒內的旋轉翻轉&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;均可被仿真復現&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，助力&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;機器人訓練液態容器搬運、柔性物體整理等傳統仿真無法支持的高階任務，大幅擴展具身智能操作邊界。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-812c250e960a3f0f56246760b85ee0e5d5a.gif" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99ffcaf546b2fb1ce543fb8e498204dc2bf.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-3e76fcc2392c4e2736e5dc686373e0805c3.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;不同於常見仿真資產僅支持簡單場景，ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;開放 6 大數字孿生機器人訓練場，方便用户直接進行使用，包括中式客廳、廚房、卧室、起居室等常見環境，以精準建模完全還原真實場景內的全部物體以及視覺氛圍感，充分考慮光照及材質等不同條件，如實木地板的深淺木紋在自然光下呈現差異化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;漫反射&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，電視屏幕鏡面反射隨角度實時變化，顯著提升視覺感知訓練的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;真實性&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;對具身訓練更重要的是，ArtVIP 場景內所有物品均支持交互，實現環境級物理-視覺聯動機制，構建閉環交互生態。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-2d78c6514083b54f885865c7e3b7be67c9d.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;例如，在仿真環境內點按電燈開關後，基於&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;光線追蹤&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;技術，系統實時計算全場景光學響應，根據光源方向及角度調整環境可見度。該機制可在具身智能模型訓練中建立「操作-環境反饋」的因果認知，顯著提升複雜場景下的連續決策能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-120c2e084cda3f306ddf3bddd94076eaad0.gif" width="426" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;根據&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;同期公開的論文&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;《ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning》，通過 CLIP 空間可視化顯示，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;相比於其他主流仿真數字資產，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;中數據分佈與真實世界對齊度提升了 47%。僅靠&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;仿真數據訓練的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Diffusion Policy&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;模型，直接操控真實&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Franka&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;機械臂&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;以零樣本遷移方式在物理世界中&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;完成關門任務，成功率&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;即可達到&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;30%&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;當混合&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;少量&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;真機數據訓練&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;後&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，開門任務成功率&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;迅速大幅躍&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;升至 80%&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。實驗結果&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;證明瞭&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;作為數字資產，可支撐具身模型完成高複雜度物體的交互訓練，為具身智能大規模訓練建立全新&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;範式&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;當前 ArtVIP 已在 Hugging Face 開源，面向高校、研究機構以及行業研究者提供支持。除已有的數字資產內容，團隊還開源了包含建模流程、關節參數調優方法在內的數字資產建模流程，且支持無縫接入仿真軟件 Isaac Sim。開發者可直接基於已有環境訓練，也可基於標準化流程快速生成新鉸接物體資產，持續擴展高質量仿真訓練環境。通過統一行業仿真資產標準，激發社區共建數字孿生庫，徹底改變傳統仿真資產&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;碎片化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;現狀，推動具身智能訓練從「作坊式開發」邁向「工業化協作」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;面向應用落地，團隊還將提供可針對不同場景不同物品提供定製化建模服務，支持工業產線、物流園區、特種作業等不同場景的精準數字化復現。該服務使人形機器人在實際應用部署前能在仿真環境中預演精密裝配、高危設備操作等任務，將產線停機試錯成本降低 80%，為&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;智能製造&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;智慧物流&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;等場景的高效落地提供基礎。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;ArtVIP 的發佈，將極大改善困擾具身智能訓練的 Sim2Real 問題。通過向全球研究者和開發者提供了一套高質量、標準化、可複用的鉸接物體數字資產庫，以及一套成熟的生產建模服務，改變此前仿真資產匱乏且低質的現狀。通過低成本、高擬真的仿真資產，ArtVIP 將顯著改善具身智能模型訓練缺乏數據的問題，並同時降低人形機器人等&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;智能體&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在訓練真實環境部署時的風險和試錯成本，助力其在工業、服務等高價值或高危場景的安全高效落地。未來，北京人形機器人創新中心將持續推進此類共性技術平台建設，為我國人形機器人產業的核心技術攻關與規模應用提供堅實支撐。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;&lt;strong&gt;獲取 ArtVIP：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;數字資產：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://huggingface.co/datasets/x-humanoid-robomind/ArtVIP&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;項目主頁：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://x-humanoid-artvip.github.io/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9021515/blog/18684644</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9021515/blog/18684644</guid>
      <pubDate>Mon, 14 Jul 2025 10:09:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Blender Studio 發佈 Dogwalk：基於開源引擎 Godot 的免費遊戲</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Blender Studio 發佈了一款名為「Dogwalk」的免費遊戲，旨在演示開源 3D 建模軟件 Blender 和開源遊戲引擎 Godot 的協同工作流程，展現完全使用開源軟件的可能性 。&lt;/p&gt; 
&lt;p&gt;該遊戲是一款短小、温和的單人遊戲，玩家扮演一隻可愛的小狗，帶着小孩在冬日景色中探索，尋找堆雪人的材料 。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在短暫的旅程中，你要探索雪林、冰凍的池塘和幽靜的小徑。您的目標非常簡單：找到散落的物品來堆雪人。但如何到達目的地才是整個體驗的重點。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/164502_DQMM_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;https://store.steampowered.com/app/3775050/DOGWALK/&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;玩家在評論中明確表示，遊戲運行時間短，僅有 20 分鐘左右，下載大小適中，約為 300MB，因此更容易上手。一位玩家指出，衝刺速度過快會導致孩子在你身後翻滾。其他許多玩家則稱讚這款遊戲節奏輕鬆，並將其描述為一種治療性的逃避遊戲。&lt;/p&gt; 
&lt;p&gt;整個項目的資產、動畫和代碼均由 Blender 和 Godot 完成，Godot 作為完全開源的引擎，不要求開發者支付版税或許可費，適合小型工作室和獨立開發者。&lt;/p&gt; 
&lt;p&gt;遊戲於 7 月 11 日首次在 Steam 上線，100% 免費，玩家也可選擇購買 4.99 美元的 「支持者包」 以示支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360473</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360473</guid>
      <pubDate>Mon, 14 Jul 2025 08:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>K2 編譯器熱點：2025.1 中的高採用率、更少的 Bug 和重大改進</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/news/351989"&gt;IntelliJ IDEA 2025.1 默認採用 K2 編譯器&lt;/a&gt;，本文將概要介紹 K2 編譯器的當前狀態，分享其採用指標，重點介紹 2025.1 中的改進，並預告下一步的計劃。&lt;/p&gt; 
&lt;p&gt;以下內容來自：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fidea%2F2025%2F07%2Fk2-mode-takes-off-high-adoption-fewer-bugs-and-major-improvements-in-2025-1%2F" target="_blank"&gt;K2 模式熱點：2025.1 中的高採用率、更少的 Bug 和重大改進&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我們建議您更新到最新的 IntelliJ IDEA 版本，享受最佳的 K2 模式體驗。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;採用&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;目前採用 K2 模式的用户數量已經非常高，並且還在持續增長。 在 IntelliJ IDEA 2025.1 用户中，&lt;strong&gt;95% 的 Ultimate 開發者和 9% &lt;/strong&gt;的 Community Edition 開發者使用 K2 模式。&lt;/p&gt; 
&lt;p&gt;大多數用户都會在新版本發佈後的幾個月內更新 IDE，因此我們也跟蹤了 2024.3 和 2025.1 版本的綜合使用情況。 即使算上 2024.3 版的用户，K2 模式的採用率也已超過&amp;nbsp;&lt;strong&gt;76%&lt;/strong&gt;，並且這一數字每週都在穩步增長。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fc89ef43f0cffd0a6ebe37585aabe334f13.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;感謝您的反饋&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您的反饋是我們所有改進和增強的驅動力。&lt;/p&gt; 
&lt;p&gt;我們通過&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2FnewIssue%3FdraftId%3D25-6414130" target="_blank"&gt;YouTrack 問題&lt;/a&gt;、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.slack.com%2Farchives%2FC0B8H786P" target="_blank"&gt;Slack 消息&lt;/a&gt;、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fintellijidea" target="_blank"&gt;討論帖&lt;/a&gt;以及各種會議和聚會上的無數次面對面交流獲得了寶貴的意見和建議，這些都直接影響了 Kotlin 支持的發展。&lt;/p&gt; 
&lt;p&gt;我們的專屬支持團隊每天都會審查和監控 YouTrack 報告，確保您提出的問題成功傳達和解決。&lt;/p&gt; 
&lt;p&gt;您的反饋不僅能幫助我們解決問題，還將幫助我們塑造 Kotlin 工具的未來。 感謝您持續分享！&lt;/p&gt; 
&lt;h3&gt;Bug 報告&lt;/h3&gt; 
&lt;p&gt;這個最新版本發佈後的前 3-4 周內提交的 bug 報告數量與 2024.3 版本發佈後的數量相當。&lt;/p&gt; 
&lt;p&gt;其他反饋渠道也顯示負面提及數量顯著下降，總體情緒比預期更積極。&lt;/p&gt; 
&lt;p&gt;一些用户在 2024.3 和 2024.2 版本中使用 K2 模式。 我們強烈建議您更新到最新版本的 IntelliJ IDEA，因為 2025.1 版本在質量和功能完整性方面都為 K2 模式帶來了巨大的改進。&lt;/p&gt; 
&lt;p&gt;我們來看看哪些內容有所更新。&lt;/p&gt; 
&lt;h3&gt;2025.1 中的修正和改進：&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;穩定性得到提高，意味着崩潰和凍結更少。&lt;/li&gt; 
 &lt;li&gt;超過 100 項檢查和意圖已得到改進並從 K1 模式遷移到 K2 模式。&lt;/li&gt; 
 &lt;li&gt;臨時文件和腳本現在獲得了更好的支持 (&lt;code&gt;.kts&lt;/code&gt;)。&lt;/li&gt; 
 &lt;li&gt;錯誤報告中的誤報（例如_Constructor expected_（應為構造函數）和_Unknown symbol_（未知符號））已被修正。&lt;/li&gt; 
 &lt;li&gt;應為&lt;code&gt;String?&lt;/code&gt;但實際為&lt;code&gt;String&lt;/code&gt;類型的錯誤不再錯誤顯示。&lt;/li&gt; 
 &lt;li&gt;未使用的函數或屬性現在獲得一項檢查。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.serializer()&lt;/code&gt;獲得高亮顯示支持。&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Create member from usage&lt;/em&gt;（從用法創建成員）快速修復現在可以按預期工作。&lt;/li&gt; 
 &lt;li&gt;頻繁重新索引觸發器已減少。&lt;/li&gt; 
 &lt;li&gt;項目切換緩存問題已解決。&lt;/li&gt; 
 &lt;li&gt;所有外部和內部主要插件現在都支持 K2 模式。&lt;/li&gt; 
 &lt;li&gt;JetBrains Academy 集成功能齊全。&lt;/li&gt; 
 &lt;li&gt;多種 Spring 支持改進已經實現。&lt;/li&gt; 
 &lt;li&gt;K2 模式調試器已與其 K1 模式對等功能達到同等水平。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們還改進了 K2 模式的許多其他方面。 查看我們的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FIDEA-A-2100662435%2FIntelliJ-IDEA-2025.2-EAP-1-252.13776.59-build-Release-Notes" target="_blank"&gt;版本説明&lt;/a&gt;獲取完整列表。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;em&gt;Move&lt;/em&gt;（移動）重構&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在 K2 模式中，我們重寫了_Move_（移動）重構的運作方式。 現在，它更加可靠和可預測。 邊緣情況會得到正確處理，生成的代碼也更加清晰和準確。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2025.2 最新變化：&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;常規代碼補全改進。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com.cn%2Fhelp%2Fidea%2Fauto-completing-code.html%23smart_type_matching_completion" target="_blank"&gt;類型匹配智能補全&lt;/a&gt;支持。&lt;/li&gt; 
 &lt;li&gt;Spring 支持與 K1 模式相當。&lt;/li&gt; 
 &lt;li&gt;重構，例如針對文件和函數的_Convert Enum to Sealed Class_（將枚舉轉換為密封類）、&lt;em&gt;Extract Interface&lt;/em&gt;（提取接口）、&lt;em&gt;Create test / Navigate to test&lt;/em&gt;（創建測試/導航到測試）、&lt;em&gt;Rearrange Code&lt;/em&gt;（重新排列代碼）。&lt;/li&gt; 
 &lt;li&gt;針對迴歸高亮顯示的修正，包括 DSL、註解和 Kotlin 特定語法的一致行為。&lt;/li&gt; 
 &lt;li&gt;針對_Constructor expected_（應為構造函數）和_Unknown symbol_（未知符號）等誤報錯誤的修正。&lt;/li&gt; 
 &lt;li&gt;Kotlin 腳本更可靠的執行，包括獨立文件和&lt;code&gt;Gradle .kts&lt;/code&gt;文件。&lt;/li&gt; 
 &lt;li&gt;腳本定義的正確加載和項目特定符號的正確解析。&lt;/li&gt; 
 &lt;li&gt;對使用&lt;code&gt;@DslMarker&lt;/code&gt;註解的函數的正確識別和高亮顯示。&lt;/li&gt; 
 &lt;li&gt;所有項目配置中更可靠的_Extract Interface_（提取接口）重構。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;還有更多變化，敬請期待！&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;協程檢查&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;協程是我們最受歡迎也最常被提及的功能之一，但要正確使用可能並不簡單，特別是對於新手來説。&lt;/p&gt; 
&lt;p&gt;我們正在設法使它們更易使用，並且已經引入不斷增加的協程檢查集。 它們可以捕捉常見問題、提供實用建議，並指導您更順暢、更自信地編寫正確且慣用的協程代碼。 以下是我們通過這一舉措解決的一些工單：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;關於在掛起函數中調用&lt;code&gt;runBlocking&lt;/code&gt;的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-32417" target="_blank"&gt;警告&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;儘可能將 &lt;code&gt;_kotlin.coroutine.coroutineContext_&lt;/code&gt; 訪問替換為 &lt;code&gt;_kotlinx.coroutines.currentCoroutineContext_&lt;/code&gt; 調用的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-34526" target="_blank"&gt;檢查&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;未使用來自_kotlin.coroutines_的流時的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-17625" target="_blank"&gt;檢查&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;在 ‘&lt;em&gt;Deferred&lt;/em&gt;’ 對象集合上替換 ‘&lt;em&gt;map { it.await() }’ with ‘awaitAll()&lt;/em&gt;’ 的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-34236" target="_blank"&gt;檢查&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;在 ‘&lt;em&gt;Job&lt;/em&gt;’ 對象集合上替換 ‘&lt;em&gt;forEach { it.join() }’ with ‘joinAll()&lt;/em&gt;’ 的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FKTIJ-34346" target="_blank"&gt;檢查&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;對 Kotlin 2.2 功能預覽的支持&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Kotlin 2.2 將帶來多種在 K2 模式下具有 IDE 支持的精彩新功能，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;when、多美元內插以及非局部_break_和_continue_中的保護條件。&lt;/li&gt; 
 &lt;li&gt;嵌套類型別名。&lt;/li&gt; 
 &lt;li&gt;對 Kotlin 中註解的使用場所默認值的改進。&lt;/li&gt; 
 &lt;li&gt;上下文形參（不穩定）。&lt;/li&gt; 
 &lt;li&gt;將具有內聯類的函數暴露給 Java（不穩定）。&lt;/li&gt; 
 &lt;li&gt;上下文相關解析的原型（不穩定）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;性能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;2025.1 版本帶來了顯著的性能改進，2025.2 則在此基礎上帶來了進一步改進。&lt;/p&gt; 
&lt;p&gt;在 2025.1 中，高亮顯示和_Find Usages_（查找用法）等操作變得更快、更靈敏。 為了準備 2025.2 版本，我們還提升了補全速度和內存使用情況，使日常編輯更加順暢和高效。&lt;/p&gt; 
&lt;p&gt;這些更新是我們不斷使 K2 模式更加強大的一部分。 我們將繼續跟蹤這些更改的影響，並在今年晚些時候分享更詳細的指標。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360461</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360461</guid>
      <pubDate>Mon, 14 Jul 2025 08:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>APKLab —— VS Code 的 Android 逆向工程工作台</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1d2d35"&gt;APKLab 是一款開源 Android 逆向工程和惡意軟件分析工具。它是 VS Code 的擴展，使用 TypeScript 編寫。APKLab 旨在集成該領域現有的開源工具，併為常見的逆向工程任務提供更簡潔的用户體驗。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;APKLab 將最好的開源工具：&lt;a href="https://github.com/quark-engine/quark-engine"&gt;Quark-Engine&lt;/a&gt;、&lt;a href="https://github.com/ibotpeaches/apktool/"&gt;Apktool&lt;/a&gt;、&lt;a href="https://github.com/skylot/jadx"&gt;Jadx&lt;/a&gt;、&lt;a href="https://github.com/patrickfav/uber-apk-signer"&gt;uber-apk-signer&lt;/a&gt;、&lt;a href="https://github.com/shroudedcode/apk-mitm/"&gt;apk-mitm&lt;/a&gt;等無縫集成到優秀的 VS Code 中，因此你可以專注於應用程序分析，而無需離開 IDE 即可完成。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解碼 APK 中的所有資源&lt;/li&gt;
&lt;li&gt;將 APK 反彙編為 Dalvik 字節碼，又名 Smali&lt;/li&gt;
&lt;li&gt;將 APK 反編譯為 Java 源代碼&lt;/li&gt;
&lt;li&gt;交互式惡意軟件分析報告&lt;/li&gt;
&lt;li&gt;將項目目錄初始化為 Git repo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LoyieKing/Smalise"&gt;&lt;strong&gt;Smalise&lt;/strong&gt;&lt;/a&gt;提供出色的 Smali 語言支持&lt;/li&gt;
&lt;li&gt;使用功能豐富的 VS Code 進行有效分析和破解&lt;/li&gt;
&lt;li&gt;應用 MITM 補丁進行 HTTPS 檢查&lt;/li&gt;
&lt;li&gt;使用 Smali 和資源構建 APK&lt;/li&gt;
&lt;li&gt;在調試模式下重建 APK 以進行動態分析&lt;/li&gt;
&lt;li&gt;在構建過程中無縫地對 APK 進行簽名&lt;/li&gt;
&lt;li&gt;直接從 VS Code 安裝 APK&lt;/li&gt;
&lt;li&gt;支持 Apktool 風格的項目（&lt;code&gt;apktool.yml&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;支持大多數 Apktool CLI 參數&lt;/li&gt;
&lt;li&gt;Android 資源框架管理（即將推出！）&lt;/li&gt;
&lt;li&gt;支持用户提供的密鑰庫進行 APK 簽名&lt;/li&gt;
&lt;li&gt;下載並配置缺少的依賴項&lt;/li&gt;
&lt;li&gt;支持 Linux、Windows 和 Mac&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/apklab</link>
      <guid isPermaLink="false">https://www.oschina.net/p/apklab</guid>
      <pubDate>Mon, 14 Jul 2025 07:52:00 GMT</pubDate>
    </item>
    <item>
      <title>PHP 社區正在討論變更許可證</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;PHP 社區近日就變更許可證&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.php.net%2Frfc%2Fphp_license_update" target="_blank"&gt;發起了提案&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;PHP 在自定義開源許可證方面有着長期的混淆、擔憂和爭議，而涵蓋 Zend/ 目錄中源代碼的 Zend Engine 許可證，加劇了這種混淆並進一步複雜化了問題，因為它不是 Open Source Initiative 批准的許可證。&lt;/p&gt; 
 &lt;p&gt;本 RFC 提議對 PHP 許可證進行務實的簡化，以消除這種混淆，保留所有 PHP 貢獻者擁有的版權，並授予用户與原始許可證相同的權利。&lt;/p&gt; 
 &lt;p&gt;為達成此目的而提出的許可證是修正版 BSD 許可證，通常稱為 3-clause BSD 許可證。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/153907_Klzo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;1. &lt;strong&gt;背景&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHP 當前使用的自定義開源許可證（PHP License 3.01 和 Zend Engine License 2.00）存在以下問題： 
  &lt;ul&gt; 
   &lt;li&gt;不被 OSI（Open Source Initiative）完全認可；&lt;/li&gt; 
   &lt;li&gt;與 GPL 不兼容；&lt;/li&gt; 
   &lt;li&gt;存在品牌控制條款（如「不得使用 PHP 名稱」）；&lt;/li&gt; 
   &lt;li&gt;多個許可證並存，造成混淆；&lt;/li&gt; 
   &lt;li&gt;Debian 等發行版曾因條款模糊而拒絕使用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. &lt;strong&gt;解決方案&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;統一許可證&lt;/strong&gt;：將 PHP 和 Zend Engine 的許可證都改為 &lt;strong&gt;BSD 3-Clause License&lt;/strong&gt;（SPDX: &lt;code&gt;BSD-3-Clause&lt;/code&gt;）。 
  &lt;ul&gt; 
   &lt;li&gt;該許可證被 OSI 和 FSF 認可；&lt;/li&gt; 
   &lt;li&gt;與 GPL 兼容；&lt;/li&gt; 
   &lt;li&gt;簡潔、廣泛使用、無歧義。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3. &lt;strong&gt;具體變更&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;發佈新的許可證版本： 
  &lt;ul&gt; 
   &lt;li&gt;PHP License 版本 4；&lt;/li&gt; 
   &lt;li&gt;Zend Engine License 版本 3；&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;刪除舊許可證文件；&lt;/li&gt; 
 &lt;li&gt;替換所有源碼文件頭部的許可證聲明；&lt;/li&gt; 
 &lt;li&gt;更新官網和文檔；&lt;/li&gt; 
 &lt;li&gt;舊代碼可選擇繼續使用舊許可證或遷移到新許可證。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;4. &lt;strong&gt;是否需要所有貢獻者同意？&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;不需要&lt;/strong&gt;。因為 BSD 3-Clause 與原許可證在權利授予上無實質差異；&lt;/li&gt; 
 &lt;li&gt;但出於禮貌，將開放至少 6 個月的社區討論期。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;5. &lt;strong&gt;是否需要 PHP Group 和 Perforce 同意？&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;需要&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;PHP Group（代表 PHP 項目）；&lt;/li&gt; 
   &lt;li&gt;Perforce Software（Zend Technologies 的母公司，擁有 Zend Engine 版權）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;6. &lt;strong&gt;投票機制&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHP 社區將通過 RFC 投票決定是否採納該變更；&lt;/li&gt; 
 &lt;li&gt;投票選項：是否同意採用 BSD-3-Clause 作為 PHP License v4 和 Zend License v3。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;7. &lt;strong&gt;時間線&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;提案版本：PHP 9.0；&lt;/li&gt; 
 &lt;li&gt;當前狀態：草案&lt;/li&gt; 
 &lt;li&gt;實施前將開放討論期 ≥6 個月。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h3&gt;✅ 總結一句話：&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;PHP 社區計劃將 PHP 和 Zend Engine 的許可證統一為 BSD 3-Clause License，以解決歷史遺留的兼容性和法律歧義問題，推動 PHP 更加標準化和開源友好。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360454/php-license-update-rfc</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360454/php-license-update-rfc</guid>
      <pubDate>Mon, 14 Jul 2025 07:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>亞馬遜發佈全新 AI IDE「Kiro」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;亞馬遜宣佈推出 AI 編程工具&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkiro.dev%2F" target="_blank"&gt;Kiro&lt;/a&gt;，這是一款集成開發環境（IDE），旨在通過「規範驅動開發」（Spec-Driven Development）革新軟件開發模式，解決「氛圍編碼」（Vibe Coding）帶來的混亂和低效問題 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5ce71ce1cd37882ab5707f2d549d0b3b8fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kiro 藉助 AI 智能體與開發者協作，在編寫代碼前自動生成需求文檔、系統設計圖和任務清單，並基於這些規範生成代碼、測試用例和文檔，實現「從氛圍編碼到可用代碼」的轉變 。&lt;/p&gt; 
&lt;p&gt;此外，&lt;strong&gt;Kiro 引入「鈎子」（Agent Hooks）機制&lt;/strong&gt;，在代碼保存或提交時觸發自動化任務（如更新測試文件、文檔、安全掃描等），確保代碼與規範同步 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/152736_Ykvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前 Kiro 預覽版免費，支持 macOS、Windows 和 Linux 系統，後續將推出免費版（月限 50 次交互）、專業版（19 美元/月，支持 1000 次交互）和專業增強版（39 美元/月，支持 3000 次交互）三種定價層級 。&lt;/p&gt; 
&lt;p&gt;亞馬遜 CEO 安迪·傑西（Andy Jassy）表示，Kiro「有機會徹底改變開發者構建軟件的方式」 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360450</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360450</guid>
      <pubDate>Mon, 14 Jul 2025 07:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>YouTrack 自 2025 年 10 月起開始實行新價格</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;JetBrains 宣佈將對 YouTrack 價格做出一些調整，新價格將於 2025 年 10 月 1 日生效。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;保持不變的方面&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;YouTrack 對最多 10 個用户的團隊仍然免費。&lt;/li&gt; 
 &lt;li&gt;幫助台項目對最多 3 位支持人員的團隊仍然免費，報告者數量不受限制。&lt;/li&gt; 
 &lt;li&gt;YouTrack 訂閲將繼續免費提供全套功能、支持和 AI 輔助。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;發生改變的方面&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;所有有效的升級和支持訂閲將繼續有效，直至到期日期。&lt;/li&gt; 
 &lt;li&gt;2025 年 10 月 1 日之前，您可以按當前價格續訂。&lt;/li&gt; 
 &lt;li&gt;10 月 1 日之後，任何續訂或用户/支持人員添加都將按照新價格執行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-70e827f2f16141b0a60bf93255589c0bf32.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下文將詳細説明此次變動的原因、您應如何準備，以及這對 YouTrack Cloud 和 Server 客户意味着什麼。&lt;/p&gt; 
&lt;h2&gt;我們為什麼要做出這一改變？&lt;/h2&gt; 
&lt;p&gt;我們的當前定價自 2020 年以來一直沒有變化。 事實上，許多長期客户一直以十多年前推出的舊定價使用 YouTrack，並完全享受所有功能。&lt;/p&gt; 
&lt;p&gt;幾年過去，我們已經做出了大量增值改進，包括知識庫、幫助台功能、AI 輔助、應用等。 新價格反應了這些增強以及我們對 YouTrack 的持續投入。&lt;/p&gt; 
&lt;p&gt;我們對多年來選擇 YouTrack 的團隊表示感謝。 此次更新將幫助我們繼續改進 YouTrack Cloud 和 Server，使其既適用於小型團隊，也適用於大型企業。&lt;/p&gt; 
&lt;h2&gt;如何準備&lt;/h2&gt; 
&lt;p&gt;以下是許可證管理員需要了解的信息，以便提前做好規劃：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您現有的 Cloud 或 Server 訂閲將以當前價格保持有效，直至到期日期。 您不需要立即採取任何行動。&lt;/li&gt; 
 &lt;li&gt;不過，您可以按當前價格&lt;strong&gt;提前續訂&lt;/strong&gt;。 這是 2025 年 10 月 1 日之前的最後機會。&lt;/li&gt; 
 &lt;li&gt;在此日期之後，所有續訂和用户/支持人員添加都將按照&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2168%2F" target="_blank"&gt;新價格&lt;/a&gt;執行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以下是根據您的訂閲類型提供的詳細信息。&lt;/p&gt; 
&lt;h2&gt;針對 YouTrack Cloud 客户的更新&lt;/h2&gt; 
&lt;h3&gt;YouTrack Cloud 按用户訂閲&lt;/h3&gt; 
&lt;p&gt;如果您是在 2020 年或之後開始使用 YouTrack Cloud，您很可能擁有按用户訂閲。 以下是價格變化對您的團隊的影響。&lt;/p&gt; 
&lt;p&gt;YouTrack 將繼續向最多 10 個用户的團隊免費提供，這一點沒有改變。&lt;/p&gt; 
&lt;p&gt;如果您的團隊有超過 10 個用户，訂閲價格將從 2025 年 10 月 1 日起進行調整。 對於包月方案，新定價為&lt;strong&gt;每個用户每月 5.40 美元&lt;/strong&gt;起。 如果您喜歡包年訂閲，您將獲得兩個月的免費使用時間，新的起始價格為&lt;strong&gt;每個用户每月 4.50 美元&lt;/strong&gt;。 您的團隊越大，價格就越低，因為隨着您添加用户，折扣也會增加。 您可以在我們的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2169%2F" target="_blank"&gt;常見問題解答&lt;/a&gt;中探索更新後的定價示例。&lt;/p&gt; 
&lt;p&gt;幫助台功能仍然完全包含在您的訂閲中。 它對最多包含 3 位支持人員的團隊免費，報告者數量不受限制。 對於 4 位或更多支持人員的團隊，將採用新定價：包月方案&lt;strong&gt;每位支持人員每月 6 美元&lt;/strong&gt;，包年方案&lt;strong&gt;每位支持人員每月 5.50 美元&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;所有功能，包括 AI 輔助和支持，都將繼續作為訂閲的一部分，不收取額外費用。 我們還將保留面向創業公司、非營利組織、教育機構和開源項目的所有折扣。&lt;/p&gt; 
&lt;h3&gt;YouTrack Cloud 舊用户包訂閲&lt;/h3&gt; 
&lt;p&gt;如果您從 2020 年之前就開始使用 YouTrack Cloud，並且還沒有切換到按用户結算模式，那麼您可能仍在使用帶有用户包的舊版方案。&lt;/p&gt; 
&lt;p&gt;即使在 2025 年 10 月 1 日之後，這些訂閲仍將照常有效，直至到期日期。 您不需要立即採取任何行動。&lt;/p&gt; 
&lt;p&gt;不過，這將是您以當前價格續訂的最後一次機會。 您只能在&lt;strong&gt;2025 年 10 月 1 日&lt;/strong&gt;前按照舊條款再次續訂。 此後，續訂將切換到新的按用户定價。&lt;/p&gt; 
&lt;p&gt;為了方便過渡，當您切換到包年按用户訂閲時，我們將&lt;strong&gt;免費提供三個月的額外時長&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;與舊方案相比，這個方案可以為您帶來更多的靈活性和功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您可以按需添加或移除用户，沒有固定大小的用户包。&lt;/li&gt; 
 &lt;li&gt;您還將獲得更多雲存儲空間，每個用户 3 GB。&lt;/li&gt; 
 &lt;li&gt;您可以使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com.cn%2Fyoutrack%2Fhelpdesk%2F" target="_blank"&gt;幫助台&lt;/a&gt;項目，3 位支持人員免費，報告者數量不受限制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新的按用户定價將於&lt;strong&gt;2025 年 10 月 1 日&lt;/strong&gt;生效。 此後，包月方案起價為&lt;strong&gt;每個用户 5.40 美元&lt;/strong&gt;，包年方案起價為&lt;strong&gt;每個用户 4.50 美元&lt;/strong&gt;，隨着團隊人數增加，折扣也會增加。 您可以查看我們的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2170%2F" target="_blank"&gt;常見問題解答&lt;/a&gt;獲取示例來估算您的成本。&lt;/p&gt; 
&lt;p&gt;與往常一樣，全套功能、支持和 AI 輔助均免費提供。 面向創業公司、教育和非營利組織以及開源項目的折扣將繼續有效。&lt;/p&gt; 
&lt;h2&gt;針對 YouTrack Server 客户的更新&lt;/h2&gt; 
&lt;p&gt;如果您正在使用 YouTrack Server，以下是從 2025 年 10 月 1 日起將會改變和保持不變的方面。&lt;/p&gt; 
&lt;h3&gt;保持不變的方面&lt;/h3&gt; 
&lt;p&gt;YouTrack Server 對最多 10 個用户的團隊仍然免費，這一點沒有改變。&lt;/p&gt; 
&lt;p&gt;如果您購買了許可證，您仍然擁有它：所有現有 YouTrack Server 許可證都是永久的，並且將繼續有效。 您當前的升級和支持訂閲也將一直有效，直至到期日期。&lt;/p&gt; 
&lt;p&gt;與往常一樣，每個有效訂閲都包含全套功能、支持和 AI 輔助，沒有額外費用。 面向創業公司、非營利和教育機構以及開源項目的折扣保持不變。&lt;/p&gt; 
&lt;h3&gt;發生改變的方面&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;2025 年 10 月 1 日&lt;/strong&gt;之前，您可以按當前價格續訂。 此後，所有續訂和新用户或支持人員的添加都只能按新價格執行。&lt;/p&gt; 
&lt;p&gt;我們將繼續提供靈活的用户包選項，從 15 個用户開始，然後擴展到 25、50、100、250、500、750、1,000、1,500、2,000 及更多。 2025 年 10 月 1 日之後，這些產品將僅按&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Farticles%2FSUPPORT-A-2116%2F" target="_blank"&gt;新價格&lt;/a&gt;提供。&lt;/p&gt; 
&lt;p&gt;如果您的團隊規模超過 2,000 人，請隨時&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack-support.jetbrains.com%2Fhc%2Fen-us%2Frequests%2Fnew%3Fticket_form_id%3D66282" target="_blank"&gt;聯繫&lt;/a&gt;YouTrack 團隊獲取定製報價。&lt;/p&gt; 
&lt;h3&gt;續訂並節省 50%&lt;/h3&gt; 
&lt;p&gt;如果您的支持訂閲仍然有效，或者已過期不到 12 個月，您可以按&lt;strong&gt;新許可證價格的 50% 續訂&lt;/strong&gt;。 今後，我們將繼續提供這種續訂折扣。&lt;/p&gt; 
&lt;p&gt;如果您的訂閲過期已超過一年，則折扣不再適用，但您仍然可以購買新許可證繼續使用 YouTrack Server，您的數據將完整保留。&lt;/p&gt; 
&lt;h3&gt;幫助台價格&lt;/h3&gt; 
&lt;p&gt;幫助台項目對 3 位支持人員和無限數量的報告者免費。&lt;/p&gt; 
&lt;p&gt;自 2025 年 10 月 1 日起，對於擁有 4 位或更多支持人員的團隊，價格為每位支持人員每年 72 美元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360443/new-youtrack-pricing-starting-october-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360443/new-youtrack-pricing-starting-october-2025</guid>
      <pubDate>Mon, 14 Jul 2025 07:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 宣佈全球首個 1GW+ 能耗超級計算機集羣即將上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 首席執行官馬克·扎克伯格通過社交媒體宣佈，公司正加速推進人工智能基礎設施建設，計劃上線全球首個功耗超過 1 吉瓦（GW）的超級計算機集羣「Prometheus」，預計於 2026 年投入使用。同時，Meta 正在規劃另一個名為「Hyperion」的超大規模集羣，未來幾年內功耗將達到 5GW，規模堪比曼哈頓。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="372" src="https://oscimg.oschina.net/oscnet/up-e27761cb0d17660586425b83510ac2df335.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 的「Prometheus」超級計算機集羣被定位為全球首個功耗超過 1 吉瓦的 AI 算力基礎設施。這一集羣將搭載約 130 萬塊 NVIDIA H100GPU，預計提供超過 2 艾克薩（exaflops）的混合精度算力，遠超 Meta 此前於 2022 年推出的 AI Research SuperCluster(RSC，約 5exaflops)。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Prometheus 專為訓練下一代大語言模型（如 Llama4）及通用人工智能（AGI）設計，目標是支持多模態 AI 任務，包括實時語音翻譯、增強現實 (AR) 應用及元宇宙相關技術。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與傳統超級計算機不同，Prometheus 採用 NVIDIA Quantum2InfiniBand 網絡架構和 Grand Teton 硬件平台（Meta 貢獻給開放計算項目 OCP 的設計），優化了 GPU 間的通信效率和數據中心能效。社交媒體上，開發者對 Prometheus 的規模表示震撼，稱其「重新定義了 AI 算力的上限」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了 Prometheus，Meta 還透露正在規劃「Hyperion」集羣，預計功耗高達 5GW，規模堪比一座小型城市。這一集羣將進一步擴展 Meta 的 AI 基礎設施，目標是支持更復雜的模型訓練和推理任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;有分析指出，Hyperion 的能耗相當於 xAI 30 萬張 GPU 集羣的 20 倍。xAI 近期宣佈其 Memphis&amp;nbsp;超級計算機集羣（約 30 萬塊 GPU）功耗在 200-300 兆瓦，而微軟與 OpenAI 合作的 Stargate 項目計劃投資超 5000 億美元建設 AI 數據中心。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Hyperion 的具體細節尚未完全公開，但 Meta 表示，該集羣將採用液冷技術和高性能網絡架構，以應對大規模 AI 訓練的散熱和通信需求。此外，Meta 計劃在 2025 年投資 600-650 億美元用於數據中心建設和 AI 團隊擴張，以確保算力與人才儲備的同步增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 強調，Prometheus 和 Hyperion 將延續其在開放計算（Open Compute Project）和 PyTorch 等開源生態中的承諾。集羣設計基於 Grand Teton 平台，支持 RoCE 和 InfiniBand 兩種網絡架構，展示了 Meta 在硬件靈活性和可擴展性上的探索。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Meta 承諾在數據隱私方面採取嚴格措施，集羣將與互聯網隔離，數據傳輸全程加密，以保護用户數據安全。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;開發者對 Meta 的開源策略表示歡迎，認為這將進一步降低 AI 開發門檻。然而，也有用户指出，如此大規模的算力部署可能需要更透明的能源使用和碳排放報告，以回應公眾對可持續性的關注。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360422</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360422</guid>
      <pubDate>Mon, 14 Jul 2025 06:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>特朗普將宣佈 700 億美元 AI 與能源投資計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;美國總統特朗普將於本週二在賓夕法尼亞州匹茲堡郊區宣佈一項高達 700 億美元的人工智能與能源領域投資計劃。據一位不願透露姓名的政府官員透露，該投資涉及數據中心建設、電力基礎設施升級、AI 人才培訓與學徒項目，來自多傢俬營企業的支持也將共同推動該戰略落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據計劃，投資項目包括多個新建數據中心、電力生產擴張與電網基礎設施現代化，同時涵蓋 AI 培訓課程和技術學徒機制，旨在打造一個能量充沛、技術領先的人才生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;特朗普將與共和黨參議員 David McCormick 一同出席此次活動，McCormick 也將主持在卡內基梅隆大學舉行的首屆「賓夕法尼亞能源與創新峯會」。預計將有多達 60 位能源與 AI 領域高管出席，包括貝萊德 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FBLK.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;BLK.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO 拉里·芬克，Palantir(&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FPLTR.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;PLTR.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO Alex Karp，Anthropic 聯合創始人 Dario Amodei，埃克森美孚 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FXOM.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;XOM.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO Darren Woods 以及雪佛龍 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCVX.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;CVX.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;)CEO Mike Wirth。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;本次宣佈的投資項目是特朗普第二任期內，兑現其「確保美國在 AI 領域全球領先」承諾的最新行動。上任以來，他採取了放寬監管、加速許可審批、吸引私營部門資本等多元策略，積極推動美國科技創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年早些時候，特朗普已宣佈一項 1000 億美元的 AI 數據中心投資，涉及軟銀、OpenAI 與甲骨文 (&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FORCL.US" target="_blank"&gt;&lt;span style="color:#000000"&gt;ORCL.US&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;) 等科技巨頭。同時，其政府還取消了拜登時期對 AI 芯片出口的限制措施，意在提升盟友科技能力、打擊技術「脱鈎」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為保障能源基礎，特朗普政府主張恢復並擴大煤炭、天然氣與核電的使用，認為這是避免未來電力短缺和 AI 系統運行中斷的關鍵。美國能源部已動用緊急授權令，延遲兩座本應關閉的發電廠停運，並表示未來可能會有更多聯邦介入措施。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360406</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360406</guid>
      <pubDate>Mon, 14 Jul 2025 03:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>高併發系統的藝術：如何在流量洪峯中游刃有餘</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們常説的三高，高併發、高可用、高性能，這些技術是構建現代互聯網應用程序所必需的。對於京東 618 備戰來説，所有的中台系統服務，無疑都是圍繞着三高來展開的。而對於京東龐大的客户羣體，高併發的要求尤為重要。用户對在線服務的需求和期望不斷提高，系統的併發處理能力成為衡量其性能和用户體驗的關鍵指標之一。高併發系統不僅僅是大型互聯網企業的專利，對於任何希望在市場中佔據一席之地的公司來説，能夠處理大量併發請求的能力都是至關重要的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;高併發系統的設計和實現是一個複雜且多層次的過程，涉及到硬件資源的合理利用、系統架構的精心設計、併發控制技術的應用以及性能調優等多個方面。無論是電商平台在大促期間應對突發流量，還是社交媒體在熱點事件發生時的流量激增，抑或是金融系統在交易高峯期的平穩運行，都需要一個高效、穩定、可擴展的高併發系統作為支撐。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接下來我通過一張思維導圖展開我的分享，幫大家梳理一下一個高併發系統所需要考慮的技術點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img alt="" src="https://oscimg.oschina.net/oscnet//01cbd4401f15d148b559f5bd9ef49a3b.png" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;單機維度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在單機維度上， 我們一般分為硬件維度和代碼維度兩個方向考慮。硬件維度比較簡單，就是提升單機的硬件性能和網絡帶寬。而代碼維度，則是在高併發系統架構設計時，最容易被大家忽視的，尤其是大量的脱離一線研發並進化成 PPT 架構師的今天，單機維度基本不在考量範圍。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但不積跬步無以至千里，有的時候單機接口的的性能優化，會帶來很高的經濟成本價值。在代碼維度，我這裏重點介紹一種情況，關於多線程和異步方法。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;a. 多線程和異步方法的誤區&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;關於多線程和異步方法的概念，我再面試候選人的時候，發現很多人對此都有誤區。在此，我先詳細的一下他倆的概念：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多線程：多線程是指在一個進程中可以同時運行多個線程，每個線程執行不同的任務。Java 通過 java.lang.Thread 類和 java.util.concurrent 包提供了多線程編程的支持。多線程的主要目的是為了充分利用 CPU 資源，提高程序的執行效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;異步方法：異步方法是指在調用某個方法時，不需要等待該方法執行完成即可繼續執行後續代碼。Java 通過 CompletableFuture 和異步回調機制提供了異步編程的支持。異步方法的主要目的是為了提高系統的響應能力和資源利用率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;b. 多線程能夠解決高併發場景麼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當大家瞭解了多線程和異步方法的概念後，那麼我們就可以認真思考一下，多線程一定能提升系統的併發能力麼？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的結論是：多線程可以提升部分服務的併發能力，但並不能顯著提高性能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先我們先了解，Tomcat 的 Servlet 機制是基於多線程實現的，而如果你在單次請求中在此開闢線程池進行多線程處理，在一定的併發情況下，你可能只是改善了單次請求的 TP99，但無法有效提升系統的併發能力。因為多線程的性能提升與 CPU 核心數密切相關。如果系統只有一個 CPU 核心，那麼多個線程只能在該核心上輪流執行，無法實現真正的並行處理。而我們的宿主機一般也就是 8C 或者 16C，在面單機上千的 QPS 請求時，多線程只會增加 CPU 上下文切換的負擔。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;舉個簡單並且常見的例子，批量下單接口。我們常見的做法就是在批量下單接口中開闢線程池，然後建個多個下單在線程池中並行處理。這樣做的結果是，在請求量低的情況下，效果還是可以的，單次請求的 QPS 也會很低，但如果單機面臨每秒上千次的下單請求，這種實現方式就會出現問題。最直觀的觀察，可以通過 TP99 的監控曲線發現，就是請求量跟 TP99 呈現嚴重的正相關性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而真正有效的提升下單接口的併發能力，是通過異步方式實現。但異步方式又會增加系統的設計複雜度，比如下單失敗，異步回調設計和數據一致性設計等等，也在考量範圍之內，這裏就不詳細展開説明。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;c. 小結&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多線程和異步方法是 Java 開發中兩種重要的併發處理技術，它們在提高系統性能和響應能力方面各有優勢。多線程通過並行處理任務，充分利用 CPU 資源，適用於 CPU 密集型任務和需要並行處理的場景。異步方法通過非阻塞 I/O 操作和異步回調機制，提高系統的響應能力和資源利用率，適用於 I/O 密集型任務和事件驅動架構。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外當然還有大家經常樂於討論的 JVM 調優問題，基於 JVM 調優，包括垃圾回收器的選擇，參數的合理優化，當然，還有一點，其實大家平時關注不多，就是採用更高版本的 JDK 和更新的 Spring 框架，因為高版本的框架會對性能本身有不錯的優化。關於這點，我在另一篇文章中有重點介紹：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F25214%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;性能加速包: SpringBoot 2.7&amp;amp;JDK 17,你敢嘗一嘗嗎&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;多機維度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在多機維度考慮系統的高併發性能，應該是大家最長能夠想到的場景了，也是架構師們最熱衷討論的點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先是對系統的拆分角度來説，第一個是單體應用的水平擴展問題，就是我們所説的負載均衡集羣，換成我們經常聽到的一個詞： 擴容。擴容一般針對負載均衡集羣進行水平擴展，用於解決單機無法承載高併發的情況，這也是互聯網公司解決高併發場景的最常用手段，就比如每次雙十一或者 618 前夕，我們都會成倍的擴容我們的服務實例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對系統的另一個拆分角度，叫做垂直拆分，也就是我們常見的分佈式系統。比如按照領域劃分，我們將一個大的單體服務，拆分成不同的子領域系統，然後每個子領域系統單獨承擔各自的流量，而不會相互影響。還比如説長江的 CQRS 設計架構，翻譯過來是指令查詢分離的設計方式，通過查詢和指令服務拆分，來講高併發的查詢場景單獨拆分出來進行設計。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;既然採用了分佈式的微服務架構，那麼分佈式系統的一些常見痛點也是高併發要考慮的，比如熔斷，降級，限流，超時等設計，這些本身是為了增強分佈式系統的魯棒性，從而間接的增強系統的高併發承載能力。關於微服務架構，在此處不再贅述，有興趣的，可以看我的另一篇文章:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F11328%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;【實踐篇】教你玩轉微服務--基於 DDD 的微服務架構落地實踐之路&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;垂直維度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所謂垂直維度，是為了區分於單機維度和多機維度的，垂直的意思是針對一個業務系統在系統層級的垂直劃分，包括業務應用和數據庫。要知道，很多高併發場景，不管是寫場景還是讀場景，當數據庫維度出現瓶頸，擴容就不想業務應用服務那麼簡單了，所以要區分來説。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;a. 業務應用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;唯物辯證法中有一個重要概念，就是一切從實際出發，具體問題具體分析。對於高併發系統的構建，雖然有通用的手段和方法論，但沒有統一的落地方案，必須根據具體的業務應用場景進行分析和設計。比如你的系統是高併發讀還是高併發寫，處理思路也是完全不一樣的。當然常見的手段和方法論核心包括兩點：緩存和異步。但具體到相應的業務，需要仔細思考緩存邏輯怎麼設計，異步流程怎麼設計，如何保證數據一致性等等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;這塊我有一個項目案例，就是在 SAAS 商城中秒殺場景下，如何設計高性能庫存扣減邏輯，我將這塊內容寫在了我另一篇文章裏： &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F35227%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高併發場景下的庫存管理，理論與實戰能否兼得？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;b. 數據庫&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在存儲媒介這塊其實高併發是不好設計的。比如關係型數據庫 MySQL, 在進行擴展要比業務應用複雜不少，涉及到的就是數據庫的分庫分表邏輯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這塊可以參考之前我寫過的一篇文章：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F12678%3FshareId%3D8087%26isHideShareButton%3D1" target="_blank" rel="nofollow"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;分而治之--淺談分庫分表及實踐之路&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而對於讀場景下的高併發請求，還有一種最常見的處理手段，就是異構存儲介質，實現讀寫分離，最常見的就是 MySQL 關係型數據庫負責寫，ES 這種文檔類數據庫負責讀。而他的技術難點則在於數據的同步和數據一致性上。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;總結&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以上我分享的是一個思維導圖，它描述的是當你遇到一個高併發場景時，你需要經歷的思考過程。但做好以上這些也並不能説明你的系統一定能承載高併發了。還是那句話，具體問題具體分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;構建高併發系統的核心在於如何高效地處理大量同時發生的請求，保證系統的穩定性、性能和可擴展性。這裏涉及到合理的業務架構設計，以及高效的併發編程模型。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此之外，也要考慮到數據一致性和事務管理，配合合理的監控和自動化運維，保證及時出現系統資源緊張和崩潰時，可以快速反應和解決問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18682939</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18682939</guid>
      <pubDate>Mon, 14 Jul 2025 03:26:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Kimi K2 在 OpenRouter 的市場份額超越 xAI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;來自中國初創公司 Moonshot AI 的開源大語言模型 Kimi K2 在 OpenRouter 平台的 token 消耗量（市場份額指標）上迅速攀升，超越 xAI 的 Grok4 和 OpenAI 的 GPT-4.1，成為近期 AI 領域的焦點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#242424"&gt;OpenRouter 作為一個統一 API 平台，允許開發者訪問包括 Kimi K2、Grok4 和 GPT-4.1 在內的 400 多個模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="445" src="https://oscimg.oschina.net/oscnet/up-f9c10971955440402f4be24e32485a5fc6e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Kimi K2 是一款基於混合專家（MoE）架構的大語言模型，擁有 1 萬億總參數和 320 億活躍參數，專為代理智能 (agentic intelligence) 優化，支持高級工具使用、推理和代碼生成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;發佈僅數天，Kimi K2 在 OpenRouter 平台的 token 消耗量已達到 1.5%，超越了 xAI 的 Grok4 和 GPT-4.1，位列排行榜前列。社交媒體數據顯示，截至 7 月 14 日，Kimi K2 的排名已升至 OpenRouter 的第 13 位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這種快速增長得益於 Kimi K2 的開源策略和低成本定價。OpenRouter 平台上，Kimi K2 的輸入 token 價格為每百萬 0.15 美元（緩存命中）和 0.60 美元 (緩存未命中)，輸出 token 為每百萬 2.50 美元，遠低於 Claude4Sonnet 和 GPT-4.1 的推理成本。這種價格優勢吸引了大量開發者嘗試和集成 Kimi K2，推動其市場份額迅速擴大。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360398</guid>
      <pubDate>Mon, 14 Jul 2025 02:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌計劃將 ChromeOS 整合到 Android，成為統一平台</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Android 生態系統總裁 Sameer Samat 近期在回答記者的採訪時表示，公司計劃&lt;strong&gt;將 ChromeOS 合併到 Android，整合為統一平台&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-51dd4c07514e139b94a2701461bd9f1dfa5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Sameer Samat 在採訪中透露，合併工作已啓動，將耗時多年。預計短期內（如 8 月 Pixel 10 發佈會）不會有重大發布，完整落地仍需數年時間。合併後，Chromebook 等設備將直接運行基於 Android 的統一系統，帶來更強的 Android 應用兼容性、跨設備協同能力以及桌面級多窗口體驗。&lt;/p&gt; 
&lt;p&gt;2024 年早些時候谷歌曾&lt;u&gt;&lt;a href="https://www.oschina.net/news/297021/chromeos-android-under-the-hood"&gt;宣佈&lt;/a&gt;&lt;/u&gt;將 Android 內核的部分合併到 ChromeOS 中，而現在谷歌似乎正在基於該基礎，將 ChromeOS 完全整合到 Android 上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360389/google-says-chromeos-will-merge-into-android</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360389/google-says-chromeos-will-merge-into-android</guid>
      <pubDate>Mon, 14 Jul 2025 02:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 或將放棄開源理念，轉向閉源 AI 模型開發</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;《紐約時報》援引消息人士報道，Meta 公司新成立的&lt;span&gt;超級&lt;/span&gt;智能實驗室高層成員正在討論一項重大戰略轉變，放棄公司強大的下一代開源人工智能模型 Behemoth，轉而開發一個封閉模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據悉，Meta 已完成 Behemoth 模型的訓練，但因內部性能測試不佳而推遲發佈，其測試工作在新實驗室啓動後也已暫停。若 Meta 最終選擇放棄 Behemoth 並優先發展閉源模型，將標誌着其核心 AI 理念的重大轉變。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對此，Meta 發言人向媒體表示，公司對開源 AI 的立場「沒有改變」，並計劃繼續發佈領先的開源模型，但未來會混合訓練開放和封閉兩種模型。該發言人並未就 Behemoth 可能被放棄一事發表評論。任何戰略變更仍需 CEO 馬克·扎克伯格的最終批准。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-ca858a0d41f7edf5fbd3c0579adcc15a0e2.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;扎克伯格曾高調地將 Llama 系列的開放性作為區別於 OpenAI 等競爭對手的核心戰略。然而，隨着 Meta 在 AI 領域投入數十億美元（包括支付鉅額薪酬招募&lt;span&gt;頂尖&lt;/span&gt;人才和興建數據中心），公司正面臨廣告業務以外巨大的盈利壓力。儘管擁有&lt;span&gt;頂尖&lt;/span&gt;的 AI 研究實驗室，Meta 在 AI 商業化方面仍落後於 OpenAI、谷歌 DeepMind 等對手。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;轉向封閉模式將賦予 Meta 對其技術更多的控制權和更清晰的盈利路徑。扎克伯格本人過去也曾表態，雖支持開源，但如果某項技術強大到開源「不負責任」，就不會開源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360384</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360384</guid>
      <pubDate>Mon, 14 Jul 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程智能體 Devin 開發商宣佈收購 Windsurf</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 14 日，AI 編程智能體 Devin 開發商 Cognition&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcognition_labs%2Fstatus%2F1944819486538023138"&gt;宣佈&lt;/a&gt;簽署最終協議，收購 AI 編程初創公司 Windsurf，包括其知識產權（如 AI 驅動的集成開發環境 IDE）、產品、商標、品牌及剩餘約 250 名員工。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0715/100601_pCAH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前谷歌以 24 億美元「反向收購」&lt;a href="https://www.oschina.net/news/360297"&gt;挖走&lt;/a&gt;了 Windsurf 的 CEO Varun Mohan、聯合創始人 Douglas Chen 及核心研究團隊，而 OpenAI 的 30 億美元收購要約則因知識產權共享問題於幾天前過期 。&lt;/p&gt; 
&lt;p&gt;Cognition 沒有透露收購的具體價格，但表示 Windsurf 年經常性收入（ARR）已達 8200 萬美元，其中企業客户 ARR 環比翻番，擁有 350 多家企業客户，日活躍用户數十萬。&lt;/p&gt; 
&lt;p&gt;最讓人點讚的是 Cognition 對員工的態度，與谷歌只照顧高層的做法形成了鮮明對比，公告中明確表示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% 的員工都能在此次收購中獲得經濟層面的參與機會，也就是可能通過股權、現金等形式分享收購帶來的收益。&lt;/li&gt; 
 &lt;li&gt;免除所有人的股權歸屬懸崖期（vesting cliffs），無需再等待該期限即可獲得對應權益。&lt;/li&gt; 
 &lt;li&gt;所有員工截至目前工作對應的股權將全部加速歸屬，原本可能需要分階段、長時間獲得的股權，現在可在短期內完全獲得。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0715/101009_dpR1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對於用户來説也有好消息，Cognition 還與 Anthropic 達成協議，Windsurf 現在將再次獲得 Claude AI 模型的完全訪問權限。&lt;/p&gt; 
&lt;p&gt;短期內，兩個團隊將繼續獨立運作：Windsurf 團隊繼續開發其 AI 驅動的 IDE，Cognition 則專注於其 AI 編碼代理 Devin。最終兩者的技術將進行整合，打造更強大的 AI 編程工具。&lt;/p&gt; 
&lt;p&gt;未來，Cognition 計劃將 Windsurf 的技術與 Devin 整合，使開發者能在單一界面中規劃任務、並行委託多個 Devin 實例處理代碼，並藉助自動補全完成高影響力任務 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf</guid>
      <pubDate>Mon, 14 Jul 2025 02:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里 Qwen 團隊提醒 Qwen3-embedding GGUF 模型使用注意事項</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里巴巴 Qwen 團隊提醒開發者，在使用 Qwen3-embedding GGUF 模型時需在末尾添加特殊 token&amp;lt;|endoftext|&amp;gt; 以保證精度，並預告將發佈自動處理此問題的更新版本。&lt;/p&gt; 
&lt;p&gt;阿里巴巴 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAlibaba_Qwen%2Fstatus%2F1944425668235977146" target="_blank"&gt;表示&lt;/a&gt;，他們在社區討論中注意到，部分開發者在使用 Qwen3-embedding 的 GGUF 模型時，未在上下文末尾附加特殊 token&amp;lt;|endoftext|&amp;gt;，這可能會嚴重影響模型精度。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen3-Embedding-0.6B-GGUF" target="_blank"&gt;詳細信息可查閲其 Hugging Face 模型卡&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0714/183758_kDLs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;團隊表示，llama.cpp 在轉換 GGUF 文件時已支持自動添加此 token。他們將很快發佈一個更新的 GGUF 模型包，屆時開發者將無需再手動處理此問題。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360312</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360312</guid>
      <pubDate>Sun, 13 Jul 2025 10:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>PaddleOCR 3.1 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.0 自 5 月 20 日發佈以來，受到業界的廣泛關注，同時我們也收到了眾多寶貴意見。我們積極響應、快速升級迭代，並在近日發佈了 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1&lt;/strong&gt;，帶來了&lt;strong&gt;3 個新升級：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;■ &lt;strong&gt;三大升級&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增 PP-OCRv5 多語種文本識別模型。支持法語、西班牙語、葡萄牙語、俄語、韓語等 37 種語言，平均識別精度提升超過 30%。同時依託文心 4.5 多模態能力，實現了數據的自動高質量標註，有效解決了多語種數據稀缺和標註成本高的問題，進一步提升了模型在多語言、多場景下的識別能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增文檔翻譯 PP-DocTranslation 產線。PP-DocTranslation 基於文檔解析 PP-StructureV3 和文心 4.5 大模型，支持對 Markdown、PDF 和圖片三種格式的文檔數據進行翻譯，同時支持本地傳入專業術語對照表，實現關鍵詞彙的精細化多語言翻譯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 MCP 服務器。用户可通過簡單的步驟搭建 MCP 服務器，將通過本地 Python 庫、雲服務、自託管服務等多種方式運行的 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 核心能力統一集成到下游 AI 應用中，實現更靈活高效的應用構建。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;30+語種文字識別精度躍升 30%&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨着世界各地交流合作的加深，多語種文本識別正成為智能應用領域的重要需求。為提升多語種場景下的文字識別能力，我們通過融合文心大模型的視覺和文本理解能力，實現了高效、高質量的訓練數據獲取，升級 PP-OCRv5 在 37 種語言文字的識別能力，包括韓文、西班牙文、法文、葡萄牙文、德文、意大利文、俄羅斯文等。與前代多語種文字識別模型相比，PP-OCRv5 在多語言場景文字&lt;strong&gt;識別準確率提升超過 30%。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a8707e8f4e09c855f8c0316f4b50560e2a4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-3ae5ee285df36995e695478a78702967ca8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-393c007aadc93cc04eff6538c720d504618.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-71116717dd646f973c9f97918ec28a609ec.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-faa32420f433405c6817bc1c4ec7902d074.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a5ce05bbee27068f72ea88ccea577ddc826.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-6ccc329e2cbe51bb431e31f36da7250a1bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-c2e4263d331578c92954d9cf161df0b773a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 關鍵步驟——文心 4.5 助力多語種文字高質量數據構建&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;自動文本行檢測與裁剪：利用 PP-OCRv5 檢測模型，自動定位並裁剪圖像中的每一行文本，快速、高效地獲取標準化的文本行圖片。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高置信度文本內容識別：依託文心 4.5 強大的視覺和文本理解能力，對每個文本行圖像進行多次獨立識別，篩選出識別結果一致的樣本。不僅顯著提升標註數據的準確性，還有效規避了人工標註的主觀誤差，確保數據高質量和高可靠性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-b38cde483c65f6abb66d7f9562517e5336c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 模型精度對比&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-f19e38a90dd3436d78b4fb6f216ba9d16c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;注：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;為更全面評估多語種模型能力，本次模型研發過程中重新收集了大量來自真實場景的高難度評估數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;拉丁字母文字涵蓋西班牙文、葡萄牙文、法文等 33 種語言文本。東斯拉夫語言涵蓋俄文、烏克蘭文、白俄羅斯文。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;▎ PP-OCRv5 多語種文字識別命令行使用方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以通過在命令行中使用--lang 參數，來進行指定語種的文本識別模型推理：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 通過 `--lang` 參數指定使用法語的識別模型

paddleocrocr-ihttps://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_french01.png \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--langfr \ # 此處為法語，剛多請參閲文檔

&amp;nbsp; &amp;nbsp;&amp;nbsp;--use_doc_orientation_classifyFalse \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--use_doc_unwarpingFalse \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--use_textline_orientationFalse \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--save_path ./output \

&amp;nbsp; &amp;nbsp;&amp;nbsp;--devicegpu:0

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述命令行的其他參數説明請參考通用 OCR 產線的&lt;strong&gt;命令行使用方式。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PP-StructureV3+文心大模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;複雜文檔翻譯更簡單&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在全球化和信息化加速發展的背景下，文檔翻譯在現代社會中已成為一種不可或缺的需求，企業和個人需要高效、準確地翻譯各類複雜文檔。為此，我們結合 &lt;strong&gt;PP-StructureV3 和文心大模型&lt;/strong&gt;，推出了&lt;strong&gt;複雜文檔翻譯工具 PP-DocTranslation&lt;/strong&gt;。PP-StructureV3 具備強大的複雜文檔解析能力，能夠輕鬆應對很多複雜佈局的 PDF 文檔及文檔圖片，並高效地將其轉換為 Markdown 格式輸出。我們在此基礎上，融合了文心大模型強大的文本理解和語義分析能力，對生成的 Markdown 結果進行進一步處理，&lt;strong&gt;實現了對相關文檔的高質量多語言翻譯。&lt;strong&gt;此外，為了更好地服務於各類專業領域對精準翻譯的需求，該工具特別增加了用&lt;/strong&gt;户自定義詞表功能&lt;/strong&gt;，用户可以根據自身業務或領域的專業術語，自定義詞彙表，從而實現特定場景下更加準確、專業的翻譯結果。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 效果展示&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-e362b2b43e56cbaef67a4ee6b734f10255e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-5d59816b55e1500001a12db71417a24dbb0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 文心 4.5 助力多語言翻譯&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;精準翻譯：依託文心 4.5 對多語言的理解，能夠實現更為精準、地道的目標語言翻譯效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多語言支持：藉助文心 4.5 的多語言處理能力，滿足多樣化多語言的翻譯需求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-e099b39899578a925c90895450d0b1c1e25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;▎ PP-DocTranslation 的 CLI 體驗方式：&lt;/p&gt; 
&lt;p&gt;可以通過在命令行中使用--target_language 參數，來進行指定要翻譯的目標語言：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;paddleocr pp_doctranslation -i&amp;nbsp;vehicle_certificate-1.png&amp;nbsp;--target_language&amp;nbsp;en&amp;nbsp;--qianfan_api_key&amp;nbsp;your_api_key﻿

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持 MCP 服務器，輕鬆連接大模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;發揮 OCR 的無限想象空間&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MCP 是一種開放協議，用於規範應用程序向大語言模型提供上下文信息的方式。可以將 MCP 類比為 AI 應用中的 USB 接口。正如 USB 為設備與各種外設和配件之間的連接提供了標準化方式，MCP 同樣為 AI 模型與不同數據源和工具之間的連接提供了統一規範。通過支持實時調用數據或 API，MCP 能有效拓展應用場景、降低開發門檻，並提升系統安全性。如今，MCP 正逐漸成為推動 AI 生態落地的關鍵連接橋樑。&lt;/p&gt; 
&lt;p&gt;為了更便捷地將 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 能力集成至各類 AI 應用中，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1 版本支持用户通過幾步簡單操作，即可搭建 MCP 服務器。具體而言，根據 MCP 協議，AI 應用（作為 MCP 主機）通過 MCP 客户端與 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 的 MCP 服務器進行通信。&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 的 MCP 服務器則通過 Python API 或服務請求等方式調用其核心能力，並將這些能力標準化後提供給下游的 AI 應用使用。下圖展示了 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 核心功能、&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器以及 AI 應用之間的關係：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-f28229dbd08038a27d3d3c4cb8f8a06db40.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;當前，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器支持以下能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;文字識別：對圖像和 PDF 文件進行文本檢測與識別，返包含文字座標和文字內容的 JSON 文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文檔解析：從圖像或 PDF 中識別和提取文本塊、標題、段落、圖片、表格等版面元素，並將內容結構化輸出為 Markdown 文檔和 JSON 文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;根據 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 的運行方式，&lt;strong&gt;MCP 服務器支持以下工作模式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;本地 Python 庫：在本地直接運行 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;星河社區服務：調用託管在&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;飛槳&lt;/a&gt;星河社區的服務。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自託管服務：連接用户自行部署的 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 服務。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同時，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器支持 stdio 和 Streamable HTTP 兩種傳輸機制，用户既可以本地部署服務實現快速集成，也可以遠程調用服務，滿足不同場景的使用需求。&lt;/p&gt; 
&lt;p&gt;同時，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器支持 stdio 和 Streamable HTTP 兩種傳輸機制，用户既可以本地部署服務實現快速集成，也可以遠程調用服務，滿足不同場景的使用需求。&lt;/p&gt; 
&lt;p&gt;搭建 MCP 服務器並集成到 AI 應用中，僅需幾個簡單步驟。下面以「星河社區服務」模式為例，介紹如何在 Claude for Desktop 中使用 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器提供的工具。&lt;/p&gt; 
&lt;p&gt;1.參考 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 官方文檔，在星河社區部署推理服務&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 官方文檔：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpaddlepaddle.github.io%2FPaddleOCR%2Fv3.1.0%2Fversion3.x%2Fdeployment%2Fmcp_server.html" target="_blank"&gt;https://paddlepaddle.github.io/PaddleOCR/v3.1.0/version3.x/deployment/mcp_server.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;星河社區：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faistudio.baidu.com%2Fpipeline%2Fmine" target="_blank"&gt;https://aistudio.baidu.com/pipeline/mine&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;2.將 Claude for Desktop 配置文件 claude_desktop_config.json 修改如下（需安裝 uv）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"paddleocr-ocr": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"command":&amp;nbsp;"uvx",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"args": [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"--from",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"paddleocr-mcp@https://paddle-model-ecology.bj.bcebos.com/paddlex/PaddleX3.0/mcp/paddleocr_mcp/releases/v0.1.0/paddleocr_mcp-0.1.0-py3-none-any.whl",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"paddleocr_mcp"
&amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"env": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_PIPELINE":&amp;nbsp;"OCR",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_PPOCR_SOURCE":&amp;nbsp;"aistudio",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_SERVER_URL":&amp;nbsp;"&amp;lt;替換為服務基礎 URL&amp;gt;",&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"PADDLEOCR_MCP_AISTUDIO_ACCESS_TOKEN":&amp;nbsp;"&amp;lt;替換為星河社區訪問令牌&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}﻿

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3.重啓 Claude for Desktop。新的 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;paddle&lt;/a&gt;ocr-ocr 工具現在應該可以在應用中使用了，如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-fe758a76c5bedaedd2af8279774434e5274.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果希望使用 PP-StructureV3 的文檔解析能力，只需參考上述步驟，在星河社區部署文檔版面解析 V3 產線，並在配置文件中替換對應的服務基礎 URL 即可。除了基本配置外，&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器還提供&lt;strong&gt;豐富的可調參數&lt;/strong&gt;，用户可根據需求靈活調整，例如替換為自訓練的文本識別模型、關閉不需要的功能模塊等。&lt;/p&gt; 
&lt;p&gt;關於更多詳細用法，請參考官方文檔：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpaddlepaddle.github.io%2FPaddleOCR%2Fv3.1.0%2Fversion3.x%2Fdeployment%2Fmcp_server.html" target="_blank"&gt;https://paddlepaddle.github.io/PaddleOCR/v3.1.0/version3.x/deployment/mcp_server.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;▎ 創新案例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下展示了使用 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器結合其他工具搭建的創意案例：&lt;/p&gt; 
&lt;p&gt;Demo 1：在 Claude for Desktop 中，提取圖像中的手寫內容，並存到筆記軟件 Notion。&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器從圖像中提取了文字、公式等信息，並保留了文檔的結構。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;除 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器外，此 demo 還使用 Notion MCP 服務器（&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.notion.com%2Fdocs%2Fmcp" target="_blank"&gt;https://developers.notion.com/docs/mcp&lt;/a&gt;&lt;/em&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Demo 2：在 VSCode 中，根據手寫思路或偽代碼一鍵轉換為可運行並符合項目代碼風格規範的 Python 腳本，並將其上傳到 GitHub 倉庫中。&lt;strong&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器從圖像中高準確率地提取手寫代碼供後續步驟使用。&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;除 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器外，此 demo 還使用 filesystem MCP 服務器（&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers%2Ftree%2Fmain%2Fsrc%2Ffilesystem" target="_blank"&gt;https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem&lt;/a&gt;&lt;/em&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Demo 3：在 Claude for Desktop 中，&lt;strong&gt;將含有複雜表格、公式、手寫文字等內容的 PDF 文檔或圖片轉存為本地可編輯文件。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;PDF 轉為 Word 可編輯格式&lt;/p&gt; 
&lt;p&gt;圖片轉為 Excel 可編輯格式：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-c7e8d117935384082bf2c28f1e7eec1d79f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4bc497f7fba3d8291718fb8d282eeb48b60.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4561eb49759832b5f52951d2edc59fbf26f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR MCP 服務器外，此 demo 還使用 filesystem MCP 服務器（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers%2Ftree%2Fmain%2Fsrc%2Ffilesystem%25EF%25BC%2589%25E3%2580%2582" target="_blank"&gt;https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem）。&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;■ &lt;strong&gt;結語&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.0 發佈以來，我們收到了大量關於多語種識別和 MCP 支持的需求反饋。為此，我們近期推出了升級版 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1。歡迎各位開發者、研究者和行業用户下載體驗 &lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;Paddle&lt;/a&gt;OCR 3.1，並積極提出寶貴建議和反饋。大家的支持和參與將持續助力我們打造更加優質、開放和強大的 OCR 生態！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;開源地址：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FPaddlePaddle%2FPaddleOCR" target="_blank"&gt;https://github.com/PaddlePaddle/PaddleOCR&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18684322</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18684322</guid>
      <pubDate>Sun, 13 Jul 2025 10:30:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>蘋果考慮收購法國 AI 初創公司 Mistral AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據彭博社&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2025-07-13%2Fis-apple-going-to-replace-ceo-tim-cook-who-is-the-next-ceo-of-apple-ternus-md1mhrj4" target="_blank"&gt;報道&lt;/a&gt;，蘋果將 Mistral 視為潛在的收購對象，以彌補其在生成式 AI 領域（如 Siri）的不足 。&lt;/p&gt; 
&lt;p&gt;Mistral AI 是歐洲估值最高的 AI 初創企業，目前估值約€5.8 億（約$6.2 億），已融資約€1.1 億（約$1.2 億），並正在洽談新一輪高達$1 億的融資 。該公司以高效的模型和 OCR 功能聞名，其聊天機器人「Le Chat」也因快速響應受到用户好評 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8746a30a13ddc9aefb1c7186d4ee14a441c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;蘋果的 AI 生態系統近年來受到批評，Siri 的升級也因內部問題被推遲至 2026 年，同時蘋果近期失去了如 Ruoming Pang（基礎模型團隊負責人）和 Tom Gunter（資深研究員）等關鍵 AI 人才 。&lt;/p&gt; 
&lt;p&gt;此次收購若成行，將遠超蘋果 2014 年收購 Beats 的$30 億記錄，成為其史上最大併購案，但也可能面臨歐盟監管阻力，因為 Mistral AI 被視為歐洲 AI 領域的重要資產 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360305</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360305</guid>
      <pubDate>Sun, 13 Jul 2025 10:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深謀科技重磅發佈真正為人類服務的新一代人形機器人核心技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;聲波傳感&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;·&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;意念&lt;/strong&gt;&lt;strong&gt;控制 ·&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;高精視覺 · 類腦智能&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;2025 世界人工智能大會（WAIC）將於 7 月 26 日至 29 日舉行。作為本屆大會的精英合作伙伴，深謀科技亮相 H3 館 D710 展位。秉承「人形機器人應擺脱 ‘跑跑跳跳，圖個熱鬧’ 的怪圈，真正滿足人類需要、為人類服務，最終成為人類社會一員」 的理念，深謀將憑藉全能感知、先進控制、類腦智能等一系列面向新一代人形機器人的核心技術點燃具身智能新的變革。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;2025 年，深謀自研全尺寸人形機器人「美猴王」尚未正式亮相，便已榮獲德國紅點大獎與美國 MUSE 金獎，成為首個同時摘得這兩項國際頂級設計殊榮的人形機器人。儘管「美猴王」在設計上獨樹一幟，但深謀關注的從不只是單項突破，而是貫穿感知、控制與決策的一體化能力，構建具身智能要改變人類生活方式所需的全域系統閉環，實現對複雜現實與人類意圖的深度適配與響應。深謀科技將在 WAIC 發佈真正為人類創造價值的新一代人形機器人核心技術。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//caa0be4755bae97d2570fe9b265a9958.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;一、業界獨創 | 基於 SAW 聲表面波的人形機器人多物理量智能感知系統「&lt;/strong&gt;&lt;strong&gt;OmniSense&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深謀科技獨創基於聲表面波（SAW）的人形機器人傳感系統「OmniSense」，構建出一整套類人感官網絡，覆蓋環境、生理、運動三大維度：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;環境感知：&lt;/strong&gt;單芯片方案可同步感知温濕度、有害氣體與化學物質，適配工業與家庭場景，實現多級智能預警；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;體表監測:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;系統可感受脈搏、分析人類汗液、呼氣生物成分，輔助血糖、血壓等健康評估、乃至酒精、疾病檢測與康養照護，實現從外部感知走向內在理解。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;運動控制:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;SAW 傳感器嵌入機器人軀幹，實現高靈敏度的角速度和加速度測量，嵌入機器人關節，利用聲磁耦合，進行高精度的位置檢測，支撐高速動態下的平衡控制與姿態校準。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;整套系統可根據不同 SAW 頻率擾動，實現温度、濕度、氣體、壓力、磁、生物信息、六軸 IMU 等不同物理量的智能傳感，結合神經網絡人工智能分類識別算法，具備 MHz 級高頻響應、強抗幹擾、無線無源結構與生物兼容性，在提升感知靈敏度的同時顯著降低功耗，為人形機器人帶來更輕盈、更持久的智能感知能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;二、腦電驅動 | 人形機器人+腦電感知與控制方案「&lt;/strong&gt;&lt;strong&gt;Mindmover&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;MindMover 是深謀首創的人形機器人閉環腦機交互系統，融合多項前沿腦電感知與智能控制技術，包含「如意」SSVEP 意圖識別模塊與「觀心」專注度檢測模塊，首次實現「意圖識別+ 狀態反饋」的雙向腦機交互閉環。前端 SSVEP 模塊支持校準/免校準雙模式，2 秒內完成指令反饋，信息傳輸率最高可達 37.4 bits/min；後端注意力檢測模塊基於 2 通道腦電輸入，結合時頻聯合特徵與 3 分鐘個性化建模，準確率達 85%，ITR 約 22.5 bits/min。系統採用多時頻尺度分析與空頻增強機制，具備優異的抗噪能力與跨時段穩定性，適用於便攜式場景下的沉浸式人機協同任務。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;藉助深謀腦機技術的賦能，「美猴王」可實現「意念控制」和「感知人類思維」的功能，無需語音或肢體輸入，即可高效適配語言或行動障礙人羣，在醫療輔助、教育陪護和特種作業等高要求場景中展現出獨特而不可替代的價值。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;三、&lt;/strong&gt;&lt;strong&gt;力覺先鋒&lt;/strong&gt;&lt;strong&gt;｜國內首個壓電式六維力傳感器「彈起」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在「手腕」這一最複雜、最精密的人形接口上，深謀科技率先推出國內首款壓電式動態六維力傳感器「彈起」。區別於傳統應變式方案，我們採用石英晶體為核心力敏元件，配合小型化智能信號解耦裝置，構建出一套高帶寬、高分辨率、高魯棒性的下一代力覺系統。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;三大技術優勢，讓機器真正擁有觸覺與判斷力：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;快｜毫秒級響應：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;快速捕捉高頻動態力，實時應對老人摔倒預警、康復訓練反饋、手術刀下刀力控。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;準｜微小力分辨：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;對微小力精準響應，敏鋭感知芯片鍵合、病變組織切割、易碎物品抓取等複雜任務中的細微變化，做到「下手如繡花」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;狠｜超強抗幹擾：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在強電磁場（如電機驅動環境）中仍能穩定工作，有效過濾肢體擺動中的低頻幹擾，實現精準監測。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深謀壓電式六維力傳感器亦可應用於:&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;醫療&lt;/strong&gt;：用於遠程及微創手術，其傳感器高靈敏、低延遲、抗幹擾，提供穩定力反饋，提升醫生感知，保障安全與精度。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;航空航天&lt;/strong&gt;：可開展飛行器風洞測試等，能在極端温度和真空下工作，高可靠、高靈敏。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;工業&lt;/strong&gt;：實時反饋用於精密裝配等流程，保障精準度與質量，尤適用於鑄造、鍛造等高温高振閉環力控。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;四、原始創新 | 具備類人動態視覺理解能力的 6D 姿態視覺伺服系統&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在機器人動態視覺伺服領域，深謀科技構建起獲多項發明專利、自成體系的技術優勢，自主研發基於立方包擬合的 6D 姿態估計算法，突破傳統特徵點與模板匹配的侷限，可針對目標三軸姿態賦予差異化權重——系統能夠識別並強化對動態目標關鍵方向（如長軸）的跟蹤與擬合，顯著提升在動態環境中的操控穩定性與抓取成功率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;不僅如此，深謀進一步打通了 3D 模型投影與實例分割的耦合路徑，實現幾何形態與姿態信息的聯合估計，讓機器人不僅「看到」目標，更能「理解」其結構與空間狀態。在此基礎上，系統還能提取顏色、紋理、文字、標識等語義信息，構建完整的多模態認知鏈條，使視覺識別更精準、更具可解釋性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;尤為關鍵的是，深謀動態視覺伺服系統針對動態任務場景進行了專項強化：通過穩健的目標跟蹤機制與連續姿態更新能力，系統可在目標快速移動、遮擋或形變的情況下，實時捕捉關鍵特徵並同步調整伺服策略，實現從動態感知到運動控制的閉環響應。不止是「看見」動態，更能在「看見中控制」，在變化中持續修正跟蹤路徑。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深謀科技以全鏈路技術佈局推動視覺伺服從靜態識別走向動態交互，使人形機器人真正具備「理解視覺、實時反應、精準控制」的動態伺服能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;五、&lt;/strong&gt;&lt;strong&gt;自主構建｜軟硬件全&lt;/strong&gt;&lt;strong&gt;棧&lt;/strong&gt;&lt;strong&gt;自&lt;/strong&gt;&lt;strong&gt;研&lt;/strong&gt;&lt;strong&gt;的人形&lt;/strong&gt;&lt;strong&gt;機器人&lt;/strong&gt;&lt;strong&gt;具身智能&lt;/strong&gt;&lt;strong&gt;系統&lt;/strong&gt;&lt;br&gt; &amp;nbsp;深謀科技深知人形機器人未來競爭力在於軟硬件全棧自研，自研範圍覆蓋從關鍵部件到核心算法的全棧技術架構，構建起支撐人形機器人感知與運動等核心功能的智能技術平台。在硬件層面，自主研發了靈巧手、六維力傳感器，在研準直驅關節模組，為機器人本體提供高性能的多模態感知與執行能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在算法層面，規劃與控制軟件融合了模型驅動的 MPC（模型預測控制）和數據驅動的 RL(強化學習）及具身智能大模型 (VLA)，結合 ADRC（主動抗擾控制）機制、運動控制策略與動態協調系統，構建起機器人感知、決策、規劃、動作的智能閉環與精準響應能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;深謀科技｜打造類&lt;/strong&gt;&lt;strong&gt;腦具身&lt;/strong&gt;&lt;strong&gt;智能新範式&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在打造人形機器人「大腦」的路徑上，深謀科技又與眾不同地選擇了一條有別於行業主流的獨立方向。認為當前依賴海量數據與無限參數的大模型，雖在語言、文本和視覺方面取得成功，也展現出一定的推理能力，但其高能耗、低效率的學習特性，與人類所具備的高效、可泛化的高級智能仍存在很大差距。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深謀科技正進行基於能量 (Energy-Based)、具備生物合理性（biologically plausible），借鑑腦科學機制的世界模型研究，將於明年發佈能分時間維度提取因果關係和物理規律的通用具身智能世界模型。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&lt;strong&gt;WAIC 見 · 來 H3-D710，&lt;/strong&gt;&lt;strong&gt;深&lt;/strong&gt;&lt;strong&gt;謀科技&lt;/strong&gt;&lt;strong&gt;獨家展示兼具&lt;/strong&gt;&lt;strong&gt;技術鋒芒與美學張力的&lt;/strong&gt;&lt;strong&gt;陸上&lt;/strong&gt;&lt;strong&gt;具身&lt;/strong&gt;&lt;strong&gt;智能&lt;/strong&gt;&lt;strong&gt;人形「美猴王」 和&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;空中具身&lt;/strong&gt;&lt;strong&gt;智能巨獸「星漢一號」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ab88f2d3c375dde9e7e68cc772534ac8.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360301</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360301</guid>
      <pubDate>Sun, 13 Jul 2025 10:03:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>飛書開源「RTV」富文本組件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;飛書近日正式將其自研的富文本組件庫 RichTextVista（RTV）開源，並上線 OpenHarmony 三方庫中心倉。它是鴻蒙生態首個深度集成「屬性字符串」（StyledString）方案的富文本組件，兼顧性能、開放性和易用性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「該組件以領先的性能、流暢的渲染體驗與高度的開放性，為鴻蒙生態提供了更高效的富文本解決方案。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-2eb284d37904c2121362a99a8cc887778ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;流暢性能：基於屬性字符串，打破滑動瓶頸&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;RTV 在架構上摒棄傳統基於 Component 的實現路徑，採用輕量級的「屬性字符串」（StyledString）渲染方案，顯著減少視圖層級。實測顯示，即便在萬級消息長列表等場景下，仍可保持 120FPS 的流暢滑動，為用户帶來絲滑的交互體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;超高開放性：支持「自定義樣式注入」&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;現有開源的富文本倉庫均缺乏集成自定義樣式的能力，只能使用預製的樣式。RTV 是社區中唯一支持用户注入自定義樣式的文本渲染器。開發者可以通過其完善的開放樣式 API，輕鬆實現@人、自定義表情、業務組件等元素的集成與渲染，讓富文本真正服務於業務創新，而不是成為創新的掣肘。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;廣泛兼容與輕鬆接入：歷經大型應用驗證&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;RTV 支持包括 HTML、Markdown、Protobuf 實體在內的多種標準化數據源，開發者無需為格式轉換耗費心力。同時，它提供了「開箱即用」的接入體驗，包含清晰的文檔、豐富的示例和預覽工具，最簡單的 Demo 僅需不到 10 行代碼即可渲染，告別複雜的性能調優與兼容性適配工作。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，該組件已在飛書的 IM、日曆、雲文檔、視頻會議等 8 個核心業務模塊中穩定運行超過半年。據飛書內部估算，RTV 的落地應用，已累計為飛書相關業務節省了超過 300 天的時間及人力開發成本，成為名副其實的「效率槓桿」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360299</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360299</guid>
      <pubDate>Sun, 13 Jul 2025 10:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌「截胡」 OpenAI，AI 編程創企 Windsurf 核心成員加入 DeepMind 團隊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windsurf 原名 Codeium，2021 年由麻省理工學院校友創立，2025 年 4 月更名，年度經常性收入超 1 億美元，用户增長強勁。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0714/175102_k9UJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2025 年 7 月 12 日，OpenAI 以 30 億美元收購 AI 編程初創公司 Windsurf 的交易失敗（&lt;strong&gt;收購協議排他性期限到期未續簽&lt;/strong&gt;&amp;nbsp;），谷歌 DeepMind 迅速 「截胡」，宣佈聘請 Windsurf 創始人兼首席執行官 Varun Mohan、聯合創始人 Douglas Chen 及部分研發人員加入谷歌 DeepMind 團隊，專注於以 Gemini 為核心的 AI 編程（智能體編碼）項目開發 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0714/175117_I0TI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;谷歌未收購 Windsurf 股權或控制權，但獲得其部分技術的非獨家許可（&lt;strong&gt;彭博社稱相關花費約 24 億美元&lt;/strong&gt;&amp;nbsp;）。&lt;/p&gt; 
&lt;p&gt;Windsurf 任命業務主管 Jeff Wang 為臨時 CEO，全球銷售副總裁 Graham Moreno 為新總裁，維持獨立運營 。&lt;/p&gt; 
&lt;p&gt;科技媒體 The Verge 從谷歌發言人 Chris Pappas 那裏得到了一份聲明，其中寫道：「Gemini 是目前最好的模型之一，我們一直在投資為其開發先進的開發者功能。我們非常高興地歡迎 Windsurf 團隊的頂尖 AI 編程人才加入谷歌 DeepMind，以推進我們在智能體編程方面的工作。」&lt;/p&gt; 
&lt;p&gt;擔任臨時 CEO 的 Jeff Wang 在𝕏發佈了一份長文聲明，寫道：Windsurf 「一流」 團隊的大部分成員將繼續為企業打造 Windsurf 產品，並幫助我們的客户最大限度地利用這項技術。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0714/175149_lsXk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360297</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360297</guid>
      <pubDate>Sun, 13 Jul 2025 09:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
