<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Mon, 28 Jul 2025 07:44:43 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>一次線上生產庫的全流程切換完整方案</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一、現狀梳理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#1b1b1b"&gt;本篇介紹了一次數據庫遷移的完整方案。 本次需要改造的系統為一個較為陳舊的技術棧系統，其中 MongoDB 作為核心數據存儲中間件，承擔着存儲全部核心數據的重要任務。該系統目前的配置為 1 主 1 副本模式，涉及 1 個數據庫和 2 張表，服務於 7 個不同的應用。儘管系統架構相對簡單，但其在日常運營中發揮着不可或缺的作用。目前需要將 MongoDB 存儲在其它介質中，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;如何能夠保障在不影響線上使用的情況下，平滑切流到新庫，是本文主要探討的問題。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;二、遷移方案&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.1 遷移節奏&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;整體節奏分為 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.梳理範圍，因為系統內不僅有 mongo 還同時有 mysql 數據源，需要梳理出使用 mongo 的所有業務範圍&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.確定好原有的數據，應該存儲在哪個介質中，確定好存儲標準，需要能夠 cover 住原有的所有業務，包括讀寫性能&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.對原有數據結構的 DAO 層進行改造&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.需要對數據進行雙寫並進行數據遷移&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5.R2 流量驗證/測試迴歸/數據比對，進行驗證&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6.切量:放量節奏&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//9c521ae700f248187c51d3a8d671c1b2.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.2 代碼改造/數據異構&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;採用裝飾器模式，統一控制雙寫邏輯（主寫，輔寫），統一控制切量邏輯，下線邏輯，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;抽取代碼中原有的直接調用底層 mongodb API 的代碼，將其不改業務邏輯的情況下遷移到 Dao 層。這樣做的目的是為了後續做切流適配邏輯。不改邏輯及出入參的目的是為了避免對當前業務造成影響。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;選用數據源的依據為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;table style="width:auto"&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特性&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;JimKV&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HBase&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;優勢&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 支持多存儲引擎（SSD、AEP）- 基於 Raft 協議的強一致性和多機房容災&amp;lt;br&amp;gt;- 完善的運維監控和彈性伸縮能力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 支持 PB 級別的存儲容量- 雲原生架構，支持單集羣和主備集羣&amp;lt;br&amp;gt;- 高吞吐性能，適合寫密集型應用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;劣勢&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 由於 Raft 協議，寫性能低於 JimDB&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 故障恢復時間較長，約 1—2 分鐘&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;適用場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 數據一致性和可靠性要求高- 數據存儲量大- 讀流量大於寫流量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 存儲量非常大（PB 級別）- 寫密集且性能要求高的場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技術選型推薦理由&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- JimKV 滿足存儲量和吞吐量要求- 數據一致性和可靠性優於 HBase&amp;lt;br&amp;gt;- 適合讀流量大於寫流量的應用場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;- 適用於存儲量極大的場景，但對一致性要求較高的場景不如 JimKV 適合&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基於以上原則,我們選用 JImKV(京東自研中間件)，Mysql 和 ES 作為 MongoDB 的替換的數據源，數據源切換 Dao 層的改造方式如下:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//6ff6bf2db84b30c9647b44e6897c3ac4.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.3 存量數據遷移&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;table style="width:auto"&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style="border-right-width:3px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;方案 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td style="border-right-width:3px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是否可實現 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td style="border-right-width:3px"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;難度 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用大數據抽數任務 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;易 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用代碼異步任務的方式 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;易 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DRC 同步 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從 mongo 到數據庫不支持 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;略 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;考慮整體的數據量並不大單表 300w，通過大數據離線表的方式效率並不高，通過代碼更加的靈活，可以隨時調整速度和範圍存量數據分了兩部分 1、已經審核通過，申請單不會在有任何變更，可以隨時遷移，比對 2、申請單處於過程中的數據，數據隨時會變更。凌晨遷移，打開雙寫&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//91a580b4c7abb945ed8ae09b7f133e05.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2.4 增量數據同步&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;創建申請單和更新不包含狀態字段時的操作&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;先寫 mongo 再寫 mysql，以 mongo 寫入成功為準，寫 mysql 失敗，mq 異步補償&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//679cdd023e610819ec4e401dacf3fc3f.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//d3c5ff84534b7d9e63485fe3d2d44ff1.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;三、上線三板斧 (灰度/監控/回滾)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本章節主要探討在進行數據遷移和代碼改造這些基礎工作完成之後，如何保障上線沒有線上問題，如何保障平滑切流和聽寫，工作主要聚焦於上線三板斧，可灰度，可回滾，可監控等方面，具體工作如下:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.1 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可監控 (數據對比讀邏輯)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;增量數據比對&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;雙寫數據完成後發送 MQ，消息裏面查詢新庫，老庫的數據進行實時比對，不一致數據記錄不一致字段，關鍵字業務報警，寫入日誌文件，導出分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;存量數據比對&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;遍歷全量老庫數據，與新庫查出數據，轉換成相同對象對比數據一致性，異常數據寫入日誌文件分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//323083f471a4d392ba9790f91ec33d9c.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.2 可監控 (對比讀邏輯)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對比邏輯，引入 R2 流量回放對比，提高對比速度，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//1c840436e0907bc578b21dba45f08b9e.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.3 可灰度 (灰度切量讀)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;讀切流，按照供應商和採銷白名單+百分比來切流&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//0c6295902850262dbf5645c3587ab417.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;切流時，由於需要根據 pin 對流量分散，但是不在同一線程內，使用 threadlocal 對商户信息進行設置和讀取&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//afb0c666bda5295ebd776e317bdc9b2e.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.4 可回滾 (灰度切量寫)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;寫切流，分為四步&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.首先驗證，寫新庫沒問題，相當於對新加代碼進行灰度，如果有問題，進行回切&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.當驗證寫新庫沒問題，需要補齊數據庫數據&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.當數據補齊後，轉換為主寫新庫&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.後續如果讀寫新庫都沒問題，可以徹底下線舊庫存&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//640fe93d584fd444cf2dc85e46c6935e.jpg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;四、總結&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#24292f"&gt;本文詳細梳理了線上生產環境的全流程，包括遷移和切換的灰度方案對比。在數據源選型方面，根據實際業務需求選擇合適的中間件是整個工作的基石。在代碼改造和數據異構方面，選擇恰當的設計模式和合理的架構方案是關鍵所在。存量數據遷移和增量數據同步是不可或缺的步驟。上線過程中，確保系統具備可監控、可回滾和可灰度的能力，是實現平滑切換的保障。歡迎各位同學與我交流探討。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18685920</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18685920</guid>
      <pubDate>Mon, 28 Jul 2025 07:35:41 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>WAIC 首日 | RWKV-7s 新型高效大模型架構正式亮相</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 26 日，RWKV 攜全球領先的大模型架構 RWKV-7 亮相 2025 世界人工智能大會暨人工智能全球治理高級別會議（以下簡稱 " WAIC 2025"），並首次公開了 RWKV-7s 架構。元始智能作為企業代表向國務院總理李強、上海市委書記陳吉寧介紹 RWKV 架構、生態和產業化近況。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="元始智能 COO&amp;amp;Co-Founder 羅璇向總理介紹 RWKV" src="https://oscimg.oschina.net/oscnet/up-45e836f5402788bffce489a460ee6b3d3db.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV 系列是全球領先的 RNN 大模型架構。其中 RWKV-7 在 RNN 架構中效率和效果世界領先。在大會首日，我們，公開了系列首個混合架構 ------ RWKV-7s。&lt;/p&gt; 
&lt;p&gt;RWKV-7s 是承接 RWKV-7 優勢的 RNN + DEA（獨創的 DeepEmbedAttention）新型高效大模型架構，KV cache 僅為 MLA 的 1/9 大小，兼具高效計算與強長文本性能，可適配多模態、智能體等多種應用場景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6093fc2663a245aa49e3f9e392d74cc2be8.jpg" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e6724a19136a358f0e45e7a6be8d4e63eec.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在瞭解 RWKV 架構作為底層技術的創新性及可為人工智能行業帶來的新機遇後，李強總理給予了寶貴的指導意見，並鼓勵更多 AI 從業者關注底層技術，解決更多的基礎問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="李強總理親臨 RWKV 展位指導" src="https://oscimg.oschina.net/oscnet/up-4cd734102525efae518e5c422c4f656bcea.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最後預告，純 RNN 的 RWKV7-G0 7B 已經可以解決一些 AIME（美國數學競賽）題，我們稍後會發布詳細測試結果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math" src="https://oscimg.oschina.net/oscnet/up-378ee71ccfc10efe46f40849c447a30d72e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不僅如此，修改後的題目也能做對（將原題的 3(n+3) 修改為 2(n+3)）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math" src="https://oscimg.oschina.net/oscnet/up-a9f2f1025f4451640b8545d0ceb14baf43c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;WAIC 展覽還有三天，歡迎大家在 7 月 27 日至 29 日親臨 RWKV 展位，與我們共同探討人工智能行業發展的更多可能！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;地點：上海世博展覽館&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主展位：1 樓中庭，H2-2 門前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展位一：H3-D701&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展位二：H4-FT305&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362721</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362721</guid>
      <pubDate>Mon, 28 Jul 2025 07:24:41 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>​三星與特斯拉達成 165 億美元 AI 芯片供應協議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;韓國科技巨頭三星電子宣佈與電動車製造商特斯拉達成了一項重大的合作協議，成為其 AI 芯片的主要供應商。這項價值高達 165 億美元的交易，是三星與單一客户之間最大的訂單。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="405" src="https://oscimg.oschina.net/oscnet/up-cce85318480efbbe05ec700e087771c01f4.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;隨着人工智能技術的迅速發展，對高性能芯片的需求也不斷增加。特斯拉在自動駕駛和智能汽車領域的佈局，需要先進的 AI 芯片來提升其車輛的智能化水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;三星近年來一直在努力扭轉其合同芯片製造業務的下滑趨勢。通過與特斯拉的合作，三星不僅可以獲得穩定的訂單，還能進一步鞏固在全球半導體市場的地位。這一協議的簽署，預計將為三星帶來可觀的收入，並幫助公司在技術研發方面進行更多投資。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;特斯拉與三星的合作不僅侷限於芯片供應，雙方還計劃在未來的研發中進行更深層次的技術交流。特斯拉希望藉助三星的技術優勢，加速其在電動汽車和智能駕駛領域的創新步伐。同時，三星也希望通過這次合作，獲取特斯拉在汽車領域的最新需求和技術趨勢，以提升自身產品的市場競爭力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這一合作協議對雙方來説都具有重要的戰略意義。特斯拉在 AI 技術領域的進步，將會依賴於三星提供的高效能芯片，而三星則能借此機會重塑自身在半導體行業的形象，迎接未來更大的挑戰。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362720</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362720</guid>
      <pubDate>Mon, 28 Jul 2025 07:20:41 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>京東將大模型品牌正式升級為 JoyAI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;京東集團正式宣佈將其大模型品牌升級為 JoyAI。此次升級的 JoyAI 大模型體系支持 3B 到 750B 全尺寸模型，具備語言、語音、圖像、視頻、數字人等多模態交互能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;通過動態分層蒸餾、跨領域數據治理等技術，其推理效率平均提升 30%，訓練成本降低 70%。在零售領域，京東立影「秒搭」平台可 3 分鐘生成 3D 內容，京點點 AIGC 平台實現商品圖、文案、視頻的快速生成；推出的高商業可用數字人具備逼真形象與自然動作，情感表達與場景適配能力超越 80% 真人主播，支持 24 小時不間斷直播，成本僅為真人直播的十分之一，目前已有 20000 餘個品牌採用其進行直播帶貨。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="443" src="https://oscimg.oschina.net/oscnet/up-12fa4d7a1eca57443933396144af5111c04.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;京東同步推出附身智能品牌 JoyInside，通過接入 JoyAI 大模型為機器人、玩具等終端設備註入高情商交互能力，支持角色定製與多場景應用。該品牌已與十餘家頭部機器人、AI 玩具品牌合作，產品涵蓋快遞機器人、機器狗、AI 潮玩及兒童陪伴 AI 夥伴等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，京東雲正式開源行業首個 100% 企業級智能體 JoyAgent，其融合多智能體協同引擎與大小模型優勢，支持高效協作與動態任務執行，具備高可用性、高性能及靈活適配特性。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362716</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362716</guid>
      <pubDate>Mon, 28 Jul 2025 07:08:41 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>WAIC 2025 速覽：史上最大規模、學術頂流參會、具身智能&amp;機器人成熱門版塊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;剛剛過去的週六，史上最盛大的一屆世界人工智能大會（WAIC 2025）正式開幕！&lt;/p&gt; 
&lt;p&gt;今年大會不僅把重量級學術大佬「深度學習三巨頭」之一、2018 年圖靈獎得主、2024 年諾貝爾物理學獎得主傑弗裏·辛頓都請到開幕式做演講，連展會都是前所未有的爆場。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0728/150438_LvlE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是 WAIC 2025 亮點速覽：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;史上最大規模：7 萬㎡展區、800+企業、40+大模型、50+AI 終端、60+機器人、80+全球首發/中國首秀。&lt;/li&gt; 
 &lt;li&gt;學術頂流：圖靈獎&amp;amp;諾獎雙料得主 Geoffrey Hinton 開幕式演講。&lt;/li&gt; 
 &lt;li&gt;門票爆火：168 元單日票被炒至 2000+。&lt;/li&gt; 
 &lt;li&gt;主題關鍵詞：應用為王——全部可上手、可互動、可落地。&lt;/li&gt; 
 &lt;li&gt;參展方陣 
  &lt;ul&gt; 
   &lt;li&gt;國內大廠：華為、騰訊、阿里、螞蟻、百度、聯想、京東、快手、網易、中興、三大運營商、理想、吉利等。&lt;/li&gt; 
   &lt;li&gt;國際巨頭：谷歌、AWS、特斯拉、西門子、施耐德、希捷、思科等。&lt;/li&gt; 
   &lt;li&gt;AI 明星公司：商湯、訊飛、第四範式、階躍星辰、MiniMax、智譜、月之暗面 Kimi、面壁智能等。&lt;/li&gt; 
   &lt;li&gt;缺席：字節跳動（豆包等）、百川、零一萬物。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;三大熱門板塊 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;具身智能&amp;amp;機器人&lt;/strong&gt;：特斯拉 Bot、宇樹拳擊秀、智元/雲深處等 20+ 新品；H3 館單館展出 63 款機器人、208 台人形/輪式、56 條機器狗。&lt;br&gt; &lt;br&gt; &lt;img src="https://static.oschina.net/uploads/space/2025/0728/150232_l7FK_2720166.png" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;智能硬件&lt;/strong&gt;：阿里夸克 AI 眼鏡、中興「麻薯」AI 萌寵、XREAL/Rokid 等旗艦 AR 眼鏡、聯想/訊飛 AI PC。&lt;br&gt; &lt;br&gt; &lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0728/150158_naTS_2720166.png" width="1000" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;AI 基礎設施&lt;/strong&gt;：華為昇騰 384 超節點領銜，20+ 國產 AI 芯片公司（摩爾線程、燧原、曦智等）及聯想、浪潮、新華三等智算廠商同台，玻色量子、國盾量子等量子計算企業也亮相。&lt;br&gt; &lt;br&gt; &lt;img src="https://static.oschina.net/uploads/space/2025/0728/150354_lqDc_2720166.png" referrerpolicy="no-referrer"&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt;彩蛋展區：H2 館「中國 AI 產業創新成果展」——中國 5170 家 AI 企業佔全球 15%，獨角獸 71 家佔 26%，並展出全球大模型演進圖及國產 AI 芯片/加速卡全景。&lt;br&gt; &lt;br&gt; &lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0728/150126_yNkU_2720166.png" width="1000" referrerpolicy="no-referrer"&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;來源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoeyURi8YKLxud2t_BV9Jyg" target="_blank"&gt;https://mp.weixin.qq.com/s/oeyURi8YKLxud2t_BV9Jyg&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362714</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362714</guid>
      <pubDate>Mon, 28 Jul 2025 07:05:41 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟即將發佈 Visual Studio 重大升級，應對 AI 編程工具激烈競爭</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;儘管微軟向客户提供了 Visual Studio Code 這款輕量級但功能強大的開源代碼編輯器，但其旗艦開發環境實際上是原生版 Visual Studio。這是一個功能齊全的集成開發環境 (IDE)，具有 .NET 集成和其他功能，使其更適合複雜的項目管理。現在，一份新報告顯示，微軟正計劃對 Visual Studio 進行重大升級。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/194445_SAV6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;媒體&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-plans-major-update-visual-studio-coding-service-ai-2025-7" target="_blank"&gt;Business Insider&lt;/a&gt;&amp;nbsp;看到了一份微軟內部備忘錄，其中詳細介紹了該公司計劃發佈 Visual Studio 的重大升級。不出所料，此次更新將重點關注人工智能 (AI)，這對於與亞馬遜 Kiro 等其他競爭對手競爭至關重要，亞馬遜 Kiro 被譽為基於 AI 的 IDE。&lt;/p&gt; 
&lt;p&gt;這份備忘錄由傑伊·帕裏克（Jay Parikh）於今年 4 月撰寫，他加入微軟不到一年，擔任執行副總裁（EVP）。帕裏克領導着公司的 CoreAI 部門，該部門負責開發人員工具，因此 Visual Studio 恰好屬於這位高管的職責範圍。&lt;/p&gt; 
&lt;p&gt;Parikh 的備忘錄將這次主要版本稱為「Visual Studio 18」，考慮到 Visual Studio 目前使用的是 17 版，這頗具趣味。該 IDE 上個月發佈了更新，允許開發人員訪問更強大的 AI 模型，同時靈活地管理計費。值得注意的是，Visual Studio 的上一次重大更新是在 2021 年，當時微軟發佈了 Visual Studio 2022 和 .NET 6，因此再次發佈主要版本也是合情合理的。&lt;/p&gt; 
&lt;p&gt;話雖如此，雖然 Visual Studio 的下一次重大升級有可能在今年推出，但目前尚未公佈具體的時間表。備忘錄還指出，這個由人工智能驅動的 IDE 版本目前正處於「早期內部測試」階段，這意味着微軟自己的員工正在積極地使用它進行測試。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362407</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362407</guid>
      <pubDate>Fri, 25 Jul 2025 11:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌短鏈接服務「goo.gl」將於下個月正式停用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Google 將於下個月正式棄用其網址縮短工具生成的鏈接。自 2025 年 8 月 25 日起，所有「&lt;span style="color:#2980b9"&gt;&lt;em&gt;https://goo.gl/*&lt;/em&gt;&lt;/span&gt;」格式的鏈接將不再有效，並返回 404 錯誤信息。&lt;/p&gt; 
&lt;p&gt;Google 於 2019 年關閉了其網址縮短服務，理由是「我們發現人們在互聯網上查找內容的方式發生了變化」。此後，使用該工具創建的鏈接仍然有效，但 Google 去年宣佈，隨着縮短網址流量的下降，將開始棄用這些服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3de2e977a212c4b76a27a10e76c003b1a75.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Google 在其&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F" target="_blank"&gt;2024 年 7 月的博客文章&lt;/a&gt;中表示：「事實上，超過 99% 的縮短網址在過去一個月內沒有任何活動。」&lt;/p&gt; 
&lt;p&gt;當時，Google 還開始在用户點擊縮短的網址時顯示一個警告頁面，提示「此鏈接近期將不再有效」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bd067dfa47ef36f85743afb32cf6824b04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;距離「goo.gl」鏈接關閉僅剩一個月時間，如果您還沒有將網址轉換到其他縮短服務，現在正是轉換的好時機。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362402</guid>
      <pubDate>Fri, 25 Jul 2025 11:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV7-G0 7.2B 發佈，最強純 RNN 推理模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 22 日， &lt;strong&gt;RWKV7-G0 7.2B 推理模型&lt;/strong&gt;（Reasoning Model）正式開源發佈，它很可能是迄今為止人類訓練過的最強純 RNN 語言模型。&lt;/p&gt; 
&lt;p&gt;RWKV7-G0 7.2B 是在 RWKV6-World-V3-7.6B 的基礎上訓練 2T tokens 的純預訓練模型，但在預訓練加入了大量指令/對話/推理數據，可以解決各種推理問題。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果需要後訓練和對齊，最適合 RNN 的方式是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fadvanced%2FFine-Tune%2FRWKV-PEFT%2FState-Tuning" target="_blank"&gt;state-tuning&lt;/a&gt;，直接微調 RNN 的初始狀態，相當於終極 context engineering。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型客觀指標評測&lt;/h2&gt; 
&lt;h3&gt;英語和多語言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的基礎英語和多語言能力&lt;strong&gt;均強於同規模的開源模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval" src="https://oscimg.oschina.net/oscnet/up-3961b82f0302bbedafaae3e26ce721fe159.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;得益於架構和數據的提升，RWKV7-G0 7.2B 的 MMLU 準確度為 62.7%，顯著超過 RWKV6-World-V3-7.6B 的 54.2%。後續我們會發布訓練 8T tokens 的滿血 RWKV7-G1 7.2B，目標是 MMLU 達到 70%，看齊前沿模型。&lt;/p&gt; 
&lt;h3&gt;無法作弊的評測&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval" target="_blank"&gt;Uncheatable Eval&lt;/a&gt; 是"無法作弊的評測"，它使用最新的論文和新聞文章等實時數據，評估開源大語言模型的真實建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的 Uncheatable Eval 同樣顯著提升，滿血 8T tokens 預計超越 Llama3 8B（這裏測試 2024-07 數據，後續會測新數據，並對比 Qwen2.5、Qwen3）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="uncheatable-eval" src="https://oscimg.oschina.net/oscnet/up-00ee915e6a6642e230984bbad95c7adda04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;模型實戰：解數學題&lt;/h2&gt; 
&lt;p&gt;我們發現，RWKV7-G0 7.2B 解數學題可使用 &lt;code&gt;temperature top_p penalty&lt;/code&gt; 解碼參數都為 0 的純貪心解碼，且無限復讀現象較少。&lt;/p&gt; 
&lt;p&gt;但貪心解碼會導致推理過程探索度不足，因此可引入隨機性，例如 &lt;code&gt;temperature=0.3 top_p=0.3 penalty=0&lt;/code&gt;。模型會自動進行多輪驗算（類似 rollout），並可以自我糾錯。&lt;/p&gt; 
&lt;p&gt;那麼 &lt;code&gt;temperature=0.6 top_p=0.6 penalty=0&lt;/code&gt; 等隨機性更高的參數是否更好，後續我們會通過參數掃描實驗評估。&lt;/p&gt; 
&lt;p&gt;例子，第一題：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math1" src="https://oscimg.oschina.net/oscnet/up-0cd8d78f631ee7405c4bbca2340892aa1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改題目表述，模型換了種做法：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math2" src="https://oscimg.oschina.net/oscnet/up-dc97d5561c78acbb5117c3b214de082e7da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第二題，故意將原題的 99 改為 99.1，模型一開始看錯，後來成功糾正了自己：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math3" src="https://oscimg.oschina.net/oscnet/up-e607d6ca88eb49ab4caf0e417262eb39b2b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第三題，原題是計算 1 的冪，改為計算 i 的冪，增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math4" src="https://oscimg.oschina.net/oscnet/up-8d5d4f106fec7c3c72836c057b1de89bddd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第四題，原題是 2^8 = 4^x，改為 8^x 增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math5" src="https://oscimg.oschina.net/oscnet/up-4d801cfa9f331b3dca71d086a3c05004e6c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第五題，原題的概率是 1/5，改為 1/4 測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math6" src="https://oscimg.oschina.net/oscnet/up-39c45f49e2a398f59a7dc87fde27cf46756.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第六題，原題是 one hat，改為 two hat（故意不加 s 複數形式）測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math7" src="https://oscimg.oschina.net/oscnet/up-2d56afb40928ffd13d17308fc41c6e56369.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第七題，模型有點懵，但反覆驗算多次後，成功確認了正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math8" src="https://oscimg.oschina.net/oscnet/up-7730c44785334a3421428c0e7dd153ed6ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;結論：【純 RNN + 純預訓練】可以得到推理模型，而且它理解了一些解題方法，可以用不同方法解決修改過的題目。&lt;/p&gt; 
&lt;h2&gt;模型實戰：寫代碼&lt;/h2&gt; 
&lt;p&gt;在此我們測試用户喜聞樂見的圖像輸出。生成一個有一隻貓的 SVG 的網頁：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code" src="https://oscimg.oschina.net/oscnet/up-06f4dbd1a7c9e178ed8408f93d7bb939c4d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用 Three.js 創建一個旋轉的 3D 紅色立方體（完整代碼在文末的附錄中）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code-1" src="https://oscimg.oschina.net/oscnet/up-5965c8a859ccc3bcc7f9db0d86caeb5f612.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;考慮到這是【純 RNN + 純預訓練 + 只訓練 2T tokens】，表現合理。後續更多數據的滿血版會顯著更強。&lt;/p&gt; 
&lt;h2&gt;RNN 的抗幹擾能力&lt;/h2&gt; 
&lt;p&gt;最新論文 &lt;code&gt;Inverse Scaling in Test-Time Compute&lt;/code&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.14417%25EF%25BC%2589%25E5%258F%2591%25E7%258E%25B0%25E5%2589%258D%25E6%25B2%25BF%25E6%25A8%25A1%25E5%259E%258B%25E5%259C%25A8%25E2%2580%259C%25E6%2581%25B6%25E6%2584%258F%25E9%2597%25AE%25E9%25A2%2598%25E2%2580%259D%25EF%25BC%2588%25E4%25BE%258B%25E5%25A6%2582%25E5%25B8%25A6%25E5%25B9%25B2%25E6%2589%25B0%25E9%25A1%25B9%25E7%259A%2584%25E8%25AE%25A1%25E6%2595%25B0%25E3%2580%2581%25E5%25B8%25A6%25E8%2599%259A%25E5%2581%2587%25E7%2589%25B9%25E5%25BE%2581%25E7%259A%2584%25E5%259B%259E%25E5%25BD%2592%25E9%25A2%2584%25E6%25B5%258B%25EF%25BC%258C%25E7%25AD%2589%25E7%25AD%2589%25EF%25BC%2589%25E4%25BC%259A%25E5%2587%25BA%25E7%258E%25B0%25E8%25B6%258A%25E6%2583%25B3%25E8%25B6%258A%25E5%25B7%25AE%25E7%259A%2584%25E6%2583%2585%25E5%2586%25B5%25EF%25BC%259A" target="_blank"&gt;https://arxiv.org/abs/2507.14417）發現前沿模型在「惡意問題」（例如帶幹擾項的計數、帶虛假特徵的迴歸預測，等等）會出現越想越差的情況：&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Inverse Scaling in Test-Time Compute" src="https://oscimg.oschina.net/oscnet/up-6ae323b74fd47a196c5d2c1f9fa0e6eba61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們發現 RWKV7-G0 7.2B 可以克服幹擾，得到正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test" src="https://oscimg.oschina.net/oscnet/up-ae61d209ca82eea02e344618caff2afca92.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;繼續測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-1" src="https://oscimg.oschina.net/oscnet/up-514174dd1deab6244d08e752e541b0fd36e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改數字再測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-2" src="https://oscimg.oschina.net/oscnet/up-203991398541247ca9e64b89fa8da85280d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可見 attention 會導致 transformer 更易受前文幹擾，而 RNN 在此有優勢。而且 RNN 的思考過程永遠勻速，不會越想越慢。我們未來訓練更大的 RNN 會更有趣。&lt;/p&gt; 
&lt;h2&gt;模型下載&lt;/h2&gt; 
&lt;p&gt;下載 RWKV7-G0 7.2B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain" target="_blank"&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社區：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles" target="_blank"&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile" target="_blank"&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何使用 RWKV 模型&lt;/h2&gt; 
&lt;h3&gt;在線 demo（續寫模式）&lt;/h3&gt; 
&lt;p&gt;可以在 RWKV 官方 Gradio 中試用 RWKV7-G0 7.2B 模型（為避免排隊，這裏限制了輸入和輸出長度）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank"&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Hugging Face Gradio 是續寫模式，使用時需要遵循 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fbasic%2FPrompt-Format" target="_blank"&gt;RWKV 的 prompt 格式&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B &lt;strong&gt;不思考模式&lt;/strong&gt;的 QA prompt 格式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如需開啓&lt;strong&gt;思考模式&lt;/strong&gt;，可在 QA prompt 的基礎上添加 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 標籤：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant: &amp;lt;think&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;本地部署 RWKV 模型&lt;/h3&gt; 
&lt;p&gt;可以使用 RWKV Runner、Ai00、RWKV pip 等推理工具本地部署 RWKV 模型。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 模型也適配了 llama.cpp、ollama 等熱門的模型推理工具。&lt;/p&gt; 
&lt;p&gt;由於 RWKV7-G0 7.2B 是新模型，目前建議使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate%2FRWKV-Runner%2FIntroduction" target="_blank"&gt;RWKV Runner&lt;/a&gt; 以保證得到正確結果。&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate" target="_blank"&gt;RWKV 官網 - 模型推理教程&lt;/a&gt;中查看上述推理工具的使用教程。&lt;/p&gt; 
&lt;h2&gt;未來訓練計劃&lt;/h2&gt; 
&lt;p&gt;我們也正在訓練 RWKV7-G0 13.3B 模型，以及使用更多 tokens、使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;DEA&lt;/a&gt; 技術的 RWKV-7s 模型。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;歡迎大家基於 RWKV-7 進行創業、科研，我們也會為基於 RWKV 的項目提供技術支持。&lt;/p&gt; 
 &lt;p&gt;如果您的團隊正在基於 RWKV 創業或開展研究，請聯繫我們！（在「RWKV 元始智能」微信公眾號留言您的聯繫方式，或發送郵件到「contact@rwkvos.com」。）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;附錄：旋轉的紅色立方體&lt;/h2&gt; 
&lt;p&gt;將以下代碼保存為 &lt;code&gt;3d.html&lt;/code&gt; 並雙擊運行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang="en"&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;meta charset="UTF-8"&amp;gt;
    &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&amp;gt;
    &amp;lt;title&amp;gt;Rotating Red Box&amp;lt;/title&amp;gt;
    &amp;lt;style&amp;gt;
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script&amp;gt;
        // Create scene
        const scene = new THREE.Scene();
        
        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;
        
        // Create renderer
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
        // Create box geometry and material
        const geometry = new THREE.BoxGeometry(1, 1, 1);
        const material = new THREE.MeshBasicMaterial({ color: 0xff0000 }); // Red color
        
        // Create box mesh
        const box = new THREE.Mesh(geometry, material);
        
        // Add lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(0, 0, 10);
        scene.add(light);
        
        // Add box to scene
        scene.add(box);
        
        // Animation loop
        let angleX = 0;
        let angleY = 0;
        
        function animate() {
            requestAnimationFrame(animate);
            
            // Update rotation angles
            angleX += 0.01;
            angleY += 0.01;
            
            // Update box rotation
            box.rotation.x = angleX;
            box.rotation.y = angleY;
            
            // Render scene
            renderer.render(scene, camera);
        }
        
        animate();
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362400</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362400</guid>
      <pubDate>Fri, 25 Jul 2025 10:54:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>谷歌 DeepMind 新架構 MoR 有望成為「Transformer 殺手」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 DeepMind 團隊發表論文《Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation》，&lt;strong&gt;提出新 Transformer 架構 Mixture-of-Recursions（MoR）&lt;/strong&gt;，旨在同時實現參數共享和自適應計算，以解決大型語言模型訓練和部署中的計算與內存開銷問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-17000d1f4f6bc815b75098237c70778d99f.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c76175988abdc82ca877e5b51ccc663dba8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/abs/2507.10524&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;MoR 的核心創新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;參數效率&lt;/strong&gt;：通過共享層堆棧在不同遞歸步驟中複用參數，減少參數量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;動態計算&lt;/strong&gt;：輕量級路由器為每個 token 動態分配遞歸深度，複雜 token 可深入處理，簡單 token 可提前退出，從而將計算資源精準分配 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;內存優化&lt;/strong&gt;：採用遞歸級鍵值（KV）緩存機制，僅緩存活躍 token 的 KV 對，顯著降低內存帶寬壓力並提升推理吞吐量 。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實驗結果顯示，在 135M 到 1.7B 參數規模的模型中，MoR 在相同訓練計算量下，驗證困惑度更低、少樣本準確率更高，推理吞吐量相比傳統 Transformer 和現有遞歸基線提升至多 2.18 倍，同時降低內存佔用和推理延遲。&lt;/p&gt; 
&lt;p&gt;因此，MoR 被認為可能在無需承擔大模型成本的情況下實現大模型質量，甚至被稱為「Transformer 殺手」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362399</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362399</guid>
      <pubDate>Fri, 25 Jul 2025 10:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>三分之一美國人藉助 AI 工具尋求職業轉型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據東南俄克拉荷馬大學（SOU）&lt;span&gt;最新&lt;/span&gt;發佈的一項報告，約三分之一的美國人已開始使用 AI 工具，如 ChatGPT，來幫助他們進行職業轉型。該報告基於對 1000 名來自四個不同世代的美國人的調查，旨在瞭解 AI 在當前美國勞動市場劇烈變化中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;調查顯示，超過一半的受訪者表示，他們正在積極考慮換工作或職業轉型，其中以 Z 世代的 57% 比例&lt;span&gt;最高&lt;/span&gt;，隨後是千禧一代的 55%，X 世代的 50%，以及僅 12% 的嬰兒潮一代。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在那些表示 AI 對他們的職業轉型有所幫助的受訪者中，43% 的人使用 AI 工具撰寫簡歷和求職信，47% 的人則利用 AI 進行新工作機會的研究，包括尋找薪資更高的職位。值得注意的是，近五分之一的受訪者（18%）表示，AI 建議了他們之前未曾考慮過的全新職業路徑。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，儘管有不少人依賴 AI 來提供職業建議，調查也顯示大多數受訪者對 AI 提供的信息持謹慎態度。60% 的受訪者表示，他們更傾向於相信人類職業顧問的意見，而只有 7% 的人選擇相信 AI。一部分人（17%）甚至選擇遵循 AI 的建議，即使這些建議與他們之前從人類顧問那裏得到的意見相悖。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在各年齡層中，受訪者主要關注的職業機會集中在技術領域，其次是醫療和金融。隨着 AI 技術的不斷發展，許多人認為這可能導致大量白領職位的消失。例如，Anthropic 的首席執行官達裏奧・阿莫德伊預測，AI 將在未來五年內消除一半的白領工作。而亞馬遜首席執行官安迪・賈西也表示，AI 驅動的自動化將取代一些人類工作，同時使其他職位變得更加 「有趣」，並創造出全新的崗位。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技術公司招聘方面的數據也表明，隨着 AI 工具開始接管許多原本由年輕、經驗較少的員工完成的日常任務，科技公司對新近計算機科學畢業生的招聘數量有所減少。此外，在硅谷的激烈人才爭奪戰中，企業之間的競爭愈發激烈，特別是在人工智能研究方面的&lt;span&gt;頂尖&lt;/span&gt;人才更是稀缺。許多公司都願意為此支付高額薪資，以吸引那些能夠在技術突破中發揮關鍵作用的優秀研究人員。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362398</guid>
      <pubDate>Fri, 25 Jul 2025 10:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>階躍星辰發佈最強開源多模態推理模型 Step3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;階躍星辰宣佈發佈新一代基礎大模型 Step3，主打多模態推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，這是階躍星辰首個全尺寸、原生多模態推理模型。在國產芯片 32K 上下文推理效率最高可達 DeepSeek R1 的 300%，在英偉達 H800 芯片將推理效率提升了 70% 以上。該模型將於 7 月 31 日向全球開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e93e689dafce5406835a7db40fe0043af4b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，階躍星辰宣佈與上海國有資本投資有限公司達成深度戰略合作，並透露上海國投將參與階躍星辰的新一輪融資。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;階躍星辰創始人、CEO 姜大昕表示，階躍的商業化的成果體現在了收入數字上，基於上半年的高速增長，公司將全年的衝刺目標定在 10 億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;會上，階躍還將聯合近 10 家芯片廠商和算力平台成立模新生態創新聯盟。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362393</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362393</guid>
      <pubDate>Fri, 25 Jul 2025 10:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻數科發佈金融推理大模型 Agentar-Fin-R1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;螞蟻數科已正式發佈金融推理大模型 Agentar-Fin-R1。該模型基於 Qwen3 研發，在 FinEval1.0、FinanceIQ 等權威金融評測基準上表現優異，超越同尺寸開源通用大模型及金融大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「通用大模型和產業之間仍存在知識鴻溝，尤其在金融領域。」螞蟻數科 CEO 趙聞飆在大會上表示，構建專業金融大模型，是推動金融智能體真正落地的必由之路。這不僅是科技挑戰，更直接關係金融機構在未來的智能競爭中是否擁有核心抓手。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研發團隊為其構建了一套業內極為全面和專業的金融數據語料。一個覆蓋了銀行、證券、保險、基金、信託等全場景的金融任務體系，包含 6 大類、66 個細分場景，構成了業內最系統、最真實的金融數據集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;訓練中還引入「原則類合成數據」，讓模型天然遵守金融監管紅線，比如數據合規、身份校驗、反洗錢等細節。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-8d7c354e371db0062d5a9f25d7135f76029.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agentar-Fin-R1 採用了創新的加權訓練算法，這就像一個聰明的學習方法，能夠動態地發現模型的薄弱環節並針對性地進行強化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這樣做的好處是，在後續的業務應用中，可以顯著減少二次微調所需的數據和算力，有效降低了企業部署大模型的門檻和成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;評測結果顯示，Agentar-Fin-R1 在金融基準測試中均取得最高評分。螞蟻數科構建了全面的金融任務數據體系，覆蓋銀行、證券等全場景，通過可信數據合成技術顯著提升模型處理複雜任務的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="231" src="https://oscimg.oschina.net/oscnet/up-a22dbbe5f4527d0a3bb44a2f3049557f6da.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-9f2fab555918f31a036c29c55510abeffde.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，Agentar-Fin-R1 推出了 32B 和 8B 兩種參數版本，此外還有基於百靈大模型的 MOE 架構模型以及 14B 和 72B 的非推理版本，以滿足不同機構和場景的部署需求。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362703</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362703</guid>
      <pubDate>Thu, 17 Jul 2025 06:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 中國版宣佈停止服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 27 日，由北京謀智火狐信息技術有限公司運營的 Firefox 中國版網站發佈&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com.cn%2Ffarewell%2F" target="_blank"&gt;公告&lt;/a&gt;稱，將於 2025 年 9 月 29 日後正式終止與 Mozilla 及 Firefox 瀏覽器相關的中國大陸運營。Firefox 瀏覽器將在中國大陸繼續可用並保持全部功能。&lt;/p&gt; 
&lt;p&gt;根據公告中的背景説明，北京火狐原在中國大陸負責部分 Firefox 瀏覽器相關業務。2025 年 5 月 8 日，Mozilla 與北京火狐達成一致，北京火狐將不再運營 Firefox 瀏覽器及任何與 Firefox 有關的中國大陸業務。北京火狐將停止使用 Mozilla 授權的商標、版權及域名。同時，北京火狐將全力配合 Mozilla 確保用户的平穩過渡。後續 Mozilla 將自行或通過授權的第三方，繼續在中國大陸負責 Firefox 瀏覽器及 Firefox 社區的相關運營。&lt;/p&gt; 
&lt;p&gt;公告稱，自即日起，Firefox 火狐中文官方網站將不再提供 Firefox 瀏覽器的下載；中國專版的火狐通行證、火狐社區將不再接受新用户註冊。自 9 月 29 日晚 24:00 起，火狐中文官方網站、火狐社區網站、火狐通行證賬户服務及，火狐主頁將正式停止運營，所有功能將終止。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img height="3258" src="https://static.oschina.net/uploads/space/2025/0728/112233_GG4l_2720166.png" width="1548" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362681/firefox-com-cn-farewell</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362681/firefox-com-cn-farewell</guid>
      <pubDate>Thu, 17 Jul 2025 03:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>無問芯穹發佈終端本徵大模型 Megrez 2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;無問芯穹聯合上海創智學院（上海交通大學背景）正式發佈終端本徵智能大模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fws8N9Gov8MT65JFumcGZpQ" target="_blank"&gt;&lt;strong&gt;Megrez 2.0&lt;/strong&gt;&lt;/a&gt;（Megrez-2-3x7B-A3B-Preview）。&lt;/p&gt; 
&lt;p&gt;該模型通過終端本徵架構，突破端側「能效-空間-智能」不可能三角，在實現 &lt;strong&gt;21B&lt;/strong&gt; 參數（雲端級智能水平）的同時，將實際計算量控制在 &lt;strong&gt;3B&lt;/strong&gt;、內存佔用控制在 &lt;strong&gt;7B&lt;/strong&gt; 規模（INT4 量化下不足 4G 內存佔用），適配各類終端設備 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-aa0ceca67088dab4c9dfe052153582592bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模型鏈接：https://www.modelscope.cn/models/InfiniAI/Megrez2-3x7B-A3B-Preview/summary&lt;/p&gt; 
&lt;p&gt;Megrez 2.0 採用重參數機制，將相鄰 MoE 層分組複用專家參數，將總參數量從 21B 降至 7B，同時保持 21B 專家池空間，實現更高能效、更低內存和更強智能，其速度比同內存佔用模型快 50%，精度比同尺寸稠密模型提升 36%，內存比同精度模型節約 75% 。&lt;/p&gt; 
&lt;p&gt;此外，Megrez 2.0 支持終端設備在「休眠時段」無感知地持續創造價值（如整理會議紀要），實現端側級算力撬動雲端級智能，推動 AI 智能體等應用在終端釋放更大能動性 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362679</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362679</guid>
      <pubDate>Thu, 17 Jul 2025 03:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊公開 AI 產品應用全景圖，開源 3D 世界模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊宣佈首次公開 AI 產品應用全景圖，包括 1+3+N 多項成果：混元 3D 世界模型、雙智能體開發平台、具身智能開放平台等，覆蓋 ToB-ToC-機器人多場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="226" src="https://oscimg.oschina.net/oscnet/up-2a518afecfb3fd34b432863c074a91586b1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與此同時，混元正式發佈並開源了業界首個 3D 世界生成模型——混元 3D 世界模型 1.0。根據介紹，混元 3D 世界模型 1.0 融合了全景視覺生成與分層 3D 重建技術，能夠接受文字和圖片作為輸入，快速生成高質量、風格多樣的可漫遊 3D 場景。這一技術突破極大地簡化了 3D 場景的構建流程，過去需要專業建模團隊數週才能完成的工作，現在通過簡單的文字指令或圖片上傳，幾分鐘內即可實現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對於遊戲開發者而言，該模型能夠迅速生成包含建築、地形、植被等元素的完整 3D 場景，輸出的 Mesh 文件可直接用於遊戲原型搭建或關卡設計，同時支持前景物體調整和天空背景更換，滿足個性化創作需求。即便是沒有建模經驗的普通用户，也能通過混元 3D 創作引擎，輕鬆生成 360°沉浸式視覺空間，並無縫導入 Vision Pro 等虛擬頭顯設備，享受沉浸式體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="293" src="https://oscimg.oschina.net/oscnet/up-e397af148c8e4065009e800578c020c6773.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D 世界模型 1.0 的核心優勢在於其創新的「語意層次化 3D 場景表徵及生成算法」。該算法將複雜的 3D 世界解構為不同語意層級，實現前景與背景、地面與天空的智能分離，不僅生成視覺效果逼真的整體場景，還能輸出標準化的 3D Mesh 資產，兼容 Unity、Unreal Engine、Blender 等主流工具，便於用户對場景內元素進行獨立編輯或物理仿真，實現了 AIGC 技術與傳統 CG 工作流的無縫銜接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#222222"&gt;混元大模型的最新進展：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-f2e1d93b044490b121dc73e763a7d7f36d8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkaISOjFXhne5g9IG5P7ahg" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362675</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362675</guid>
      <pubDate>Thu, 17 Jul 2025 02:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中國政府倡議成立世界人工智能合作組織</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中國政府 26 日倡議成立世界人工智能合作組織，初步考慮總部設在上海。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="218" src="https://oscimg.oschina.net/oscnet/up-d0df9652b4e7e21e9148ac6f456ef0f67af.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;記者獲悉，這是中方堅持踐行多邊主義、推動共商共建共享全球治理的重要舉措，也是中方響應全球南方呼聲、助力彌合數字和智能鴻溝、促進人工智能向善普惠發展的實際行動。中方期待世界人工智能合作組織作為重要的國際公共產品，實現以下目標：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;一是深化創新合作，釋放智能紅利。中方願同各國分享中國式現代化帶來的廣闊機遇，將世界人工智能合作組織打造成供需對接平台，破除妨礙世界各國間生產要素流動的壁壘，促進中國同各國以及各國之間的人工智能務實合作，讓人工智能的無限潛力充分釋放，實現共同發展、共同繁榮。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;二是推動普惠發展，彌合智能鴻溝。中方將以世界人工智能合作組織為平台，持續推進落實「加強人工智能能力建設國際合作」聯大決議和《人工智能能力建設普惠計劃》，幫助全球南方國家加強能力建設、培育人工智能創新生態，確保發展中國家在智能化浪潮中平等受益，推動落實聯合國 2030 年可持續發展議程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;三是加強協同共治，確保智能向善。中方將依託世界人工智能合作組織，加強各國之間發展戰略、治理規則、技術標準的對接協調，在充分尊重各國政策和實踐差異性的基礎上，逐步形成具有廣泛共識的人工智能全球治理框架和標準規範，確保人工智能始終沿着人類文明進步的方向發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方倡議成立世界人工智能合作組織旨在加強人工智能領域的國際合作。中方初步考慮該組織總部設在上海，希望利用中國特別是上海人工智能先發優勢，凝聚國際共識，促進務實合作，讓人工智能真正造福全人類。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方將秉持共商共建共享的理念，同有意願加入的國家共同探討相關安排。包括尊重主權原則，堅持平等相待，支持各國結合自身國情開展人工智能合作。遵循聯合國憲章宗旨和原則，支持聯合國發揮人工智能治理主渠道作用，為聯合國及其相關機構的努力提供有益補充。採取開放包容的態度，踐行真正的多邊主義，通過世界人工智能合作組織進一步凝聚共識、促進合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;中方熱忱歡迎有誠意、有意願的國家積極參與世界人工智能合作組織的籌備工作，共同推進人工智能全球治理和國際合作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362669</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362669</guid>
      <pubDate>Thu, 17 Jul 2025 02:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>基於模型蒸餾的大模型文案生成最佳實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;大語言模型在生成高質量文案方面表現優異，然而其巨大的計算資源消耗和存儲需求，使得實際應用尤其是在資源受限場景中的應用充滿挑戰。企業在尋求高效的文案生成時，常常面臨着在性能和資源之間權衡的困境。在這種背景下，模型蒸餾技術為解決這一問題提供了新的思路。模型蒸餾是一種優化技術，旨在通過將知識從大型複雜模型中提取並轉移到更小、計算更高效的模型中，使得這些小型模型能夠在保留大多數性能優勢的情況下顯著降低資源需求。這一技術在大模型文案生成領域的應用，不僅能夠保持生成質量接近原有大模型，還極大地減少了計算成本和部署難度。本文介紹如何使用 EasyDistill 算法框架以及 PAI 產品，實現基於模型蒸餾的大模型文案生成，通過這種方式節省人力成本，同時提高用户體驗，推動業務的可持續增長。&lt;/p&gt; 
&lt;h2&gt;部署教師大語言模型&lt;/h2&gt; 
&lt;h3&gt;部署模型服務&lt;/h3&gt; 
&lt;p&gt;您可以按照以下操作步驟，部署教師大語言模型生成對應回覆。&lt;/p&gt; 
&lt;p&gt;在 PAI-Model Gallery 選擇 DeepSeek-V3 模型或者其他教師大模型，在模型部署區域，系統已默認配置了模型服務信息和資源部署信息，您也可以根據需要進行修改，參數配置完成後單擊部署按鈕。以 DeepSeek-V3 為例，其模型卡片如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-28df44d9861762bd4497b14e096e764f133.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;模型部署和調用&lt;/h3&gt; 
&lt;p&gt;PAI 提供的 DeepSeek-V3 預置了模型的部署配置信息，可以選擇 SGLang 部署/vLLM 部署/Transformers 部署，用户僅需提供推理服務的名稱以及部署配置使用的資源信息即可將模型部署到 PAI-EAS 推理服務平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cd9de19c221b06b8a1068309ddcb1fd7c0e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推理服務同樣支持以 OpenAI API 兼容的方式調用，調用示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

models = client.models.list()
model = models.data[0].id
print(model)

def main():
    stream = True
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "你好，介紹一下你自己，越詳細越好。",
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=stream,
    )
    if stream:
        for chunk in chat_completion:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion.choices[0].message.content
        print(result)


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多細節可以參考"一鍵部署 DeepSeek-V3、DeepSeek-R1 模型"。&lt;/p&gt; 
&lt;h2&gt;構建訓練數據&lt;/h2&gt; 
&lt;h3&gt;構建 SFT 訓練數據&lt;/h3&gt; 
&lt;p&gt;您可以按照以下操作步驟，構建 SFT 訓練數據。用户可以根據如下輸入數據批量調用教師大模型，輸入數據格式如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "instruction": "xxx"
  },
  {
    "instruction": "xxx"
  },
  {
    "instruction": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，instruction 為調用大模型的 prompt，由任務模版和實際輸入數據組成。這裏，我們給出一個任務模版供您參考，實際內容可以根據業務場景和數據特徵進行調整：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;你是短視頻文案生成專家，專注於根據視頻原始標題、視頻內容，生成文案的標題和內容。
你的任務是確保文案與視頻核心內容高度匹配，並且吸引用户點擊。

要求
1: 信息匹配度：確保文案准確反映視頻核心看點，禁止出現視頻中未呈現的虛構內容。
2. 情緒契合度：文案情緒需與視頻內容保持一致。嚴肅悲傷類內容不要使用搞笑戲謔風格。
3. 內容規範度：確保句意表達清晰、完整、通順、連貫，沒有出現無意義字符。
4. 嚴格按照 JSON 格式輸出：
{
   "title": "",
   "body": ""
}

避免出現情況
1. 標題要求在 10 個漢字以內。
2. 內容要求在 30 個漢字以內。
3. 禁止標題黨，和過度誇張的表述。
4. 不得出現高敏感內容，或者低俗用語。

請嚴格按照 JSON 格式輸出內容，不要在輸出中加入解析和説明等其他內容。

視頻原始標題和視頻內容分別如下所示：
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;給定上述輸入數據，我們可以批量調用教師大模型生成回覆，示例代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import json
from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# 獲取模型
models = client.models.list()
model = models.data[0].id
print(model)

# 讀取輸入數據
def read_input_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

# 調用大模型獲取輸出
def get_model_output(instruction):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": instruction,
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=False,
    )
    return chat_completion.choices[0].message.content

# 處理輸入數據並生成輸出
def process_data(input_data):
    results = []
    for item in input_data:
        instruction = item.get("instruction")
        output = get_model_output(instruction)
        results.append({
            "instruction": instruction,
            "output": output
        })
    return results

# 保存輸出數據到文件
def save_output_data(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump(data, file, ensure_ascii=False, indent=2)

def main(input_file_path, output_file_path):
    input_data = read_input_data(input_file_path)
    output_data = process_data(input_data)
    save_output_data(output_file_path, output_data)
    print("Data processing complete.")

if __name__ == "__main__":
    # 指定你的輸入和輸出文件路徑
    input_file_path = "input.json"
    output_file_path = "output.json"
    main(input_file_path, output_file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;當運行完上述代碼後，我們得到構造好的 SFT 訓練數據，格式如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "instruction": "xxx",
    "output": "xxx"
  },
  {
    "instruction": "xxx",
    "output": "xxx"
  },
  {
    "instruction": "xxx",
    "output": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了保證 SFT 訓練數據集的高質量，我們建議採用如下設置：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練數據量至少應在 3000 條以上，而且需要儘可能覆蓋輸入視頻的各種主題；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成文案的任務模版可以按照實際業務需求進行修改，需要根據明確的業務需求，用自然語言精確描述生成的文案要求達到的效果和避免出現的情況；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為了保證生成文案的高質量，使用的教師大模型底座參數量需要儘可能高，例如使用滿血版的 DeepSeek-V3，一般不需要使用深度思考的模型，例如 DeepSeek-R1 或 QwQ-32B；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在輸入中，視頻的內容可以通過 OCR、ASR 等多種途徑從原始視頻中抽取出來，需要保證抽取出來的內容具有較高的準確性；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建議在生成 SFT 訓練數據集後人工抽樣進行質量校驗，並且根據校驗結果，反覆調整調用大模型的任務模版，以達到滿意的效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;構建 DPO 訓練數據&lt;/h2&gt; 
&lt;p&gt;如果您需要通過 DPO 算法繼續優化較小的學生模型，則需要構造用於 DPO 算法訓練的數據集。我們可以基於構造好的 SFT 訓練數據進行繼續構造流程。其中，DPO 數據格式示例如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  },
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  },
  {
    "prompt": "xxx",
    "chosen": "xxx",
    "rejected": "xxx"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，prompt 對應 SFT 訓練數據集的 instruction，chosen 可以使用 SFT 訓練數據集的 output 字段，rejected 為 DPO 算法中提供的低質量文案。在 DPO 算法的訓練過程中，我們鼓勵大模型生成高質量的 chosen 文案，懲罰大模型生成類似 rejected 的文案。因此，我們需要額外生成 rejected 文案。我們可以同樣採用教師大模型生成 rejected 文案，利用 SFT 訓練數據集作為輸入，我們需要改變上文使用的任務模版。這裏我們給出一個示例供您參考：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;你是視頻文案生成初學者，嘗試根據視頻原始標題、視頻內容生成不夠吸引人的文案標題和內容。
目標是生成邏輯不清、可能誤導、不夠吸引用户點擊的文案。

要求
1. 信息匹配度：不要求準確反映視頻核心看點，甚至可以與視頻內容無關。
2. 情緒契合度：文案情緒可以與視頻內容不一致。
3. 內容規範度：表達可以不清晰、不完整、不通順、不連貫，可以出現無意義字符。
4. 可不用嚴格按照 JSON 格式輸出。

視頻原始標題和視頻內容分別如下所示：
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我們同樣給出一個批量推理的腳本，生成上述數據，我們假設輸入數據格式與 SFT 訓練數據集相同，但是 instruction 字段採用上文生成低質量文案的任務模版：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import json
from openai import OpenAI

##### API 配置 #####
openai_api_key = "&amp;lt;EAS API KEY&amp;gt;"
openai_api_base = "&amp;lt;EAS API Endpoint&amp;gt;/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# 獲取模型
models = client.models.list()
model = models.data[0].id
print(model)

# 讀取輸入數據
def read_input_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

# 調用大模型獲取低質量文案
def get_rejected_output(instruction):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": instruction,
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=False,
    )
    return chat_completion.choices[0].message.content

# 處理輸入數據並生成輸出
def process_data(input_data):
    results = []
    for item in input_data:
        instruction = item.get("instruction")
        chosen = item.get("output")
        rejected = get_rejected_output(instruction)
        results.append({
            "prompt": instruction,
            "chosen": chosen,
            "rejected": rejected
        })
    return results

# 保存輸出數據到文件
def save_output_data(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump([data], file, ensure_ascii=False, indent=2)

def main(input_file_path, output_file_path):
    input_data = read_input_data(input_file_path)
    output_data = process_data(input_data)
    save_output_data(output_file_path, output_data)
    print("Data processing complete.")

if __name__ == "__main__":
    # 指定你的輸入和輸出文件路徑
    input_file_path = "input.json"
    output_file_path = "output.json"
    main(input_file_path, output_file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了保證 DPO 訓練數據集的高質量，我們建議採用如下設置：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練數據量至少應在 1000 條以上，而且需要儘可能覆蓋輸入視頻的各種主題；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;生成 rejected 文案的任務模版可以按照實際業務需求進行修改，需要和 chosen 文案在質量上有明顯的差距，特別可以注重生成 chosen 文案中避免出現的情況（即負向樣本）；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為了保證生成文案質量滿足要求，使用的教師大模型底座參數量需要儘可能高，例如使用滿血版的 DeepSeek-V3，一般不需要使用深度思考的模型，例如 DeepSeek-R1 或 QwQ-32B；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在輸入中，視頻的內容可以通過 OCR、ASR 等多種途徑從原始視頻中抽取出來，需要保證抽取出來的內容具有較高的準確性；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建議在生成 DPO 訓練數據集後人工抽樣進行質量校驗，並且根據校驗結果，反覆調整調用大模型的任務模版，以達到滿意的效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;通過 SFT 算法蒸餾訓練較小的學生模型&lt;/h2&gt; 
&lt;p&gt;接下來我們使用 EasyDistill 算法框架，利用準備好的訓練數據，訓練學生模型。在 PAI-DSW 中，根據"&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1664823" title="阿里雲人工智能平台 PAI 開源 EasyDistill 框架助力大語言模型輕鬆瘦身" target="_blank"&gt;阿里雲人工智能平台 PAI 開源 EasyDistill 框架助力大語言模型輕鬆瘦身&lt;/a&gt;"一文安裝 EasyDistill 算法包後使用如下命令進行 SFT 模型訓練：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python easydistill/kd/train.py --config=sft.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，sft.json 為 SFT 蒸餾訓練的配置文件，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
  "job_type": "kd_black_box_api",
  "dataset": {
    "labeled_path": "sft_train.json",
    "template" : "chat_template_kd.jinja",
    "seed": 42
  },
  "models": {
    "student": "model/Qwen/Qwen2.5-0.5B-Instruct/"
  },
  "training": {
    "output_dir": "result_sft/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "save_steps": 1000,
    "logging_steps": 1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
} 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，sft_train.json 為 SFT 訓練數據集，model/Qwen/Qwen2.5-0.5B-Instruct/為學生模型路徑，這裏以 Qwen2.5-0.5B-Instruct 為示例，result_sft/為模型輸出路徑。您可以根據實際需要，在 training 字段中調整訓練使用的超參數。&lt;/p&gt; 
&lt;h2&gt;通過 DPO 算法繼續優化較小的學生模型&lt;/h2&gt; 
&lt;p&gt;由於 SFT 訓練過程中提供給學生模型唯一的正確答案，因此這種訓練存在兩個限制條件：一為模型的泛化能力有限，二為缺乏更加細粒度的模型對齊。DPO 算法通過提供 chosen 和 rejected 的模型回覆，進一步提升模型的對齊能力。根據準備好的 DPO 訓練數據，我們在 SFT 訓練完的模型 Checkpoint 基礎上，使用 EasyDistill 的如下命令，進行 DPO 模型訓練：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python easydistill/rank/train.py --config=dpo.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，dpo.json 為 DPO 蒸餾訓練的配置文件，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-{"&gt;  "job_type": "rank_dpo_api",
  "dataset": {
    "labeled_path": "dpo_train.json",
    "template" : "chat_template_kd.jinja",
    "seed": 42
  },
  "models": {
    "student": "result_sft/"
  },
  "training": {
    "output_dir": "result_dpo/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "save_steps": 1000,
    "logging_steps": 1,
    "beta": 0.1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中，dpo_train.json 為 SFT 訓練數據集，result_sft/為 SFT 訓練之後的學生模型路徑，result_dpo/為模型輸出路徑。您可以根據實際需要，在 training 字段中調整訓練使用的超參數。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5583868/blog/18685835</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18685835</guid>
      <pubDate>Thu, 17 Jul 2025 02:25:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>字節跳動 AI Agent 平台釦子擁抱開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;字節跳動旗下 AI Agent 開發平台釦子（Coze）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6jGoaE29S2oOrywCAB8zMg" target="_blank"&gt;宣佈&lt;/a&gt;正式擁抱開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;釦子旗下共有四款子產品：「釦子空間」、「釦子開發平台」、「釦子羅盤」 及 Eino。目前，釦子開發平台 （Coze Studio）與釦子羅盤 （Coze Loop）已在 Apache 2.0 許可證下開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="214" src="https://oscimg.oschina.net/oscnet/up-7117b00b0aec66eedb8cac42206d8cab2fa.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Coze Studio 是一個一站式的 AI Agent 可視化開發工具，此次開源的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;完整的工作流（Workflow）引擎：只需拖拽節點，就能輕鬆編排出複雜的業務邏輯。無論是簡單的問答機器人，還是需要執行多步任務的 Agent，都能輕鬆實現。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;插件（Plugin）核心框架：開放了插件的定義、調用與管理機制。你可以便捷地將任何第三方 API 或私有能力封裝成插件，無限擴展 Agent 的能力邊界。還提供了官方開源插件作為參考，讓用户立刻上手。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;開箱即用的開發環境： 你只需一鍵部署，即可獲得一個功能完備的 Agent 開發平台，包括創建、調試、版本管理等全套界面，讓你專注於創造本身。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Coze Loop 聚焦於 Agent 從開發到運維的全鏈路管理，此次開源的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Prompt 開發： 提供從編寫、調試、一鍵優化到版本管理的強大能力，讓你的 Prompt 工程化、系統化。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多維度評測：AI 的效果好壞不再憑感覺。Coze Loop 提供系統化的評測能力，能從準確性、簡潔性、合規性等多個維度，自動化地評估 Prompt 和 Agent 的輸出質量。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;全鏈路可觀測性：Agent 的每一次執行過程都盡在掌握。提供覆蓋全過程的可視化觀測能力，詳細記錄每個環節的處理細節與狀態，讓 Debug 不再是大海撈針。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362658</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362658</guid>
      <pubDate>Thu, 17 Jul 2025 02:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>我國大模型數量超 1500 個</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;世界人工智能大會的最新數據顯示，目前全球已發佈的大模型總數達 3755 個，其中中國企業貢獻了 1509 個，位居全球首位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="1124" src="https://oscimg.oschina.net/oscnet/up-76a22434fb01383b49199810b0ee2c20962.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;從中國互聯網絡信息中心發佈的第 56 次報告中可以看出，2025 年上半年，我國的生成式人工智能在技術與應用層面均取得了全面進步，相關產品的數量也在快速增長，應用場景不斷擴展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在用户方面，截至 6 月，使用生成式人工智能產品回答問題的比例高達 80.9%。從產業層面來看，預計到 2024 年，我國的人工智能產業規模將突破 7000 億元，並且連續多年保持 20% 以上的增長率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362654</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362654</guid>
      <pubDate>Thu, 17 Jul 2025 02:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Solon 整合 LiteFlow 規則引擎：概念與實戰</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;一、引言&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在現代軟件開發中，規則引擎允許我們以聲明式的方式定義業務邏輯和決策路徑。LiteFlow 是一個輕量級、易於使用的組件式規則引擎，它可以與 Solon 應用無縫整合。本文將介紹如何在 Solon 項目中引入 LiteFlow，實現靈活的業務流程管理。&lt;/p&gt; 
&lt;h2&gt;二、LiteFlow 的核心概念&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;LiteFlow 簡介&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;LiteFlow 是一個基於 Java 的輕量級流程引擎，專為簡化複雜業務邏輯處理設計。通過將業務流程抽象為一系列的節點（components），LiteFlow 提供了一種清晰和可維護的方法來編排業務邏輯。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主要特點&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;組件化設計：業務邏輯分解為獨立的組件，每個組件執行特定的功能。 靈活的流程控制：支持同步和異步執行，以及條件分支、循環等控制結構。 易於配置：使用 XML、YAML 或程序式配置定義流程。&lt;/p&gt; 
&lt;h2&gt;三、實戰演示：在 Solon 中使用 LiteFlow&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;環境準備&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;確保你的開發環境已經安裝了 JDK 1.8 或以上版本，並且項目是基於 Solon 構建的。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加依賴&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在項目的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;pom.xml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件中添加 LiteFlow 的 Maven 依賴：&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;xml 複製代碼&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.yomahub&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;liteflow-solon-plugin&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;最新版本號&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;配置 LiteFlow&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;app.yml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件中配置 LiteFlow 的規則文件路徑：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;liteflow:&lt;/span&gt;
  &lt;span style="color:#986801"&gt;rule-source:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;classpath:liteflow-rules.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;定義組件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;創建組件類，每個類對應一個處理步驟：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; com.yomahub.liteflow.core.NodeComponent;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Component;

&lt;span style="color:#4078f2"&gt;@Component("componentA")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;ComponentA&lt;/span&gt; &lt;span style="color:#a626a4"&gt;extends&lt;/span&gt; &lt;span style="color:#c18401"&gt;NodeComponent&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;process&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        System.out.println(&lt;span style="color:#50a14f"&gt;"執行組件 A 的邏輯"&lt;/span&gt;);
        &lt;em&gt;// 添加業務邏輯代碼&lt;/em&gt;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;定義流程&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;liteflow-rules.xml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中定義業務流程，指定組件的執行順序：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;flow&lt;/span&gt; &lt;span style="color:#986801"&gt;id&lt;/span&gt;=&lt;span style="color:#50a14f"&gt;"chain1"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;then&lt;/span&gt; &lt;span style="color:#986801"&gt;value&lt;/span&gt;=&lt;span style="color:#50a14f"&gt;"componentA,componentB,componentC"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;flow&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;觸發流程執行&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在 Solon 應用中通過 LiteFlow 的 API 觸發流程執行：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; com.yomahub.liteflow.flow.FlowExecutor;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;FlowController&lt;/span&gt; {

    &lt;span style="color:#4078f2"&gt;@Inject&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;private&lt;/span&gt; FlowExecutor flowExecutor;

    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/runFlow")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;runFlow&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;try&lt;/span&gt; {
            flowExecutor.execute2Resp(&lt;span style="color:#50a14f"&gt;"chain1"&lt;/span&gt;);
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"流程執行成功"&lt;/span&gt;;
        } &lt;span style="color:#a626a4"&gt;catch&lt;/span&gt; (Exception e) {
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"流程執行失敗: "&lt;/span&gt; + e.getMessage();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;測試與驗證&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;啓動 Solon 應用並訪問&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/runFlow&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;路徑，檢查控制枱輸出以驗證流程是否按預期執行。&lt;/p&gt; 
&lt;h2&gt;結論&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;通過整合 LiteFlow 規則引擎，Solon 應用可以更加靈活地處理複雜的業務流程。LiteFlow 的組件化和易配置性使得管理和維護業務邏輯變得更簡單。此外，藉助 LiteFlow 的強大功能，開發者可以構建出更加動態和可擴展的應用系統，滿足不斷變化的業務需求。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362560</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362560</guid>
      <pubDate>Wed, 16 Jul 2025 05:11:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
  </channel>
</rss>
