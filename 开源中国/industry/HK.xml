<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 12 Jun 2025 12:41:53 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Stalwart —— 一體化郵件和協作服務器</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Stalwart&lt;/strong&gt;是一款開源郵件和協作服務器，支持 JMAP、IMAP4、POP3、SMTP、CalDAV、CardDAV 和 WebDAV，並具備豐富的現代功能。它採用 Rust 編寫，安全、快速、健壯且可擴展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特點：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;具有完整協議支持的&amp;nbsp;&lt;strong&gt;電子郵件服務器：&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;JMAP：
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8621"&gt;JMAP 用於郵件&lt;/a&gt;服務器。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ietf.org/archive/id/draft-ietf-jmap-sieve-22.html"&gt;用於 Sieve 腳本的 JMAP&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8887"&gt;WebSocket&lt;/a&gt;、&lt;a href="https://www.rfc-editor.org/rfc/rfc9404.html"&gt;Blob 管理&lt;/a&gt;和&lt;a href="https://www.rfc-editor.org/rfc/rfc9425.html"&gt;配額&lt;/a&gt;擴展。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IMAP：
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9051"&gt;IMAP4rev2&lt;/a&gt;和&lt;a href="https://datatracker.ietf.org/doc/html/rfc3501"&gt;IMAP4rev1&lt;/a&gt;服務器。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc5804"&gt;ManageSieve&lt;/a&gt;服務器。&lt;/li&gt;
&lt;li&gt;支持多種&lt;a href="https://stalw.art/docs/development/rfcs#imap4-and-extensions"&gt;擴展&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;POP3：
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc1939"&gt;POP3&lt;/a&gt;&amp;nbsp;服務器。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc2595"&gt;STLS&lt;/a&gt;和&lt;a href="https://datatracker.ietf.org/doc/html/rfc5034"&gt;SASL&lt;/a&gt;支持以及其他&lt;a href="https://datatracker.ietf.org/doc/html/rfc2449"&gt;擴展&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SMTP：
&lt;ul&gt;
&lt;li&gt;SMTP 服務器內置&lt;a href="https://datatracker.ietf.org/doc/html/rfc7489"&gt;DMARC&lt;/a&gt;、&lt;a href="https://datatracker.ietf.org/doc/html/rfc6376"&gt;DKIM&lt;/a&gt;、&lt;a href="https://datatracker.ietf.org/doc/html/rfc7208"&gt;SPF&lt;/a&gt;和&lt;a href="https://datatracker.ietf.org/doc/html/rfc8617"&gt;ARC&lt;/a&gt;支持消息認證。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc6698"&gt;通過 DANE&lt;/a&gt;、&lt;a href="https://datatracker.ietf.org/doc/html/rfc8461"&gt;MTA-STS&lt;/a&gt;和&lt;a href="https://datatracker.ietf.org/doc/html/rfc8460"&gt;SMTP TLS&lt;/a&gt;報告實現強大的傳輸安全性。&lt;/li&gt;
&lt;li&gt;通過細粒度的配置規則、篩選腳本、MTA 掛鈎和 milter 集成進行入站限制和過濾。&lt;/li&gt;
&lt;li&gt;具有延遲傳送、優先傳送、配額、路由規則和節流支持的分佈式虛擬隊列。&lt;/li&gt;
&lt;li&gt;信封重寫和消息修改。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;協作&lt;/strong&gt;服務器：
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4791"&gt;使用 CalDAV&lt;/a&gt;進行日曆和日程安排。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc6352"&gt;使用 CardDAV&lt;/a&gt;進行聯繫人管理。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4918"&gt;使用 WebDAV&lt;/a&gt;進行文件存儲和共享。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;垃圾郵件&lt;/strong&gt;和&lt;strong&gt;網絡釣魚&lt;/strong&gt;內置過濾器：
&lt;ul&gt;
&lt;li&gt;與流行解決方案相當的一套全面的過濾&lt;strong&gt;規則。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;LLM 驅動的垃圾郵件過濾和消息分析。&lt;/li&gt;
&lt;li&gt;具有自動訓練功能和地址簿集成的統計&lt;strong&gt;垃圾郵件分類器。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;DNS 黑名單 (&amp;nbsp;&lt;strong&gt;DNSBL&lt;/strong&gt;&amp;nbsp;) 檢查 IP 地址、域和哈希。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用 Pyzor&lt;/strong&gt;進行基於協作摘要的垃圾郵件過濾。&lt;/li&gt;
&lt;li&gt;針對同形異義 URL 攻擊、發件人欺騙和其他技術的網絡&lt;strong&gt;釣魚保護。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;可信&lt;strong&gt;回覆&lt;/strong&gt;跟蹤，用於識別和優先處理真實的電子郵件回覆。&lt;/li&gt;
&lt;li&gt;通過 IP 地址、ASN、域和電子郵件地址監控發件人&lt;strong&gt;信譽。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灰名單&lt;/strong&gt;可暫時延遲未知發件人。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;垃圾郵件陷阱&lt;/strong&gt;用於設置誘餌電子郵件地址來捕獲和分析垃圾郵件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;靈活的&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;可插入存儲後端，支持&lt;strong&gt;RocksDB&lt;/strong&gt;、&lt;strong&gt;FoundationDB&lt;/strong&gt;、&lt;strong&gt;PostgreSQL&lt;/strong&gt;、&lt;strong&gt;mySQL&lt;/strong&gt;、&lt;strong&gt;SQLite&lt;/strong&gt;、&lt;strong&gt;S3-Compatible&lt;/strong&gt;、&lt;strong&gt;Azure&lt;/strong&gt;、&lt;strong&gt;Redis&lt;/strong&gt;和&lt;strong&gt;ElasticSearch&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;提供 17 種語言的全文搜索。&lt;/li&gt;
&lt;li&gt;Sieve 腳本語言支持所有&lt;a href="https://www.iana.org/assignments/sieve-extensions/sieve-extensions.xhtml"&gt;註冊的擴展&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;電子郵件別名、郵件列表、子地址和全部地址支持。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ietf.org/id/draft-bucksch-autoconfig-02.html"&gt;使用 autoconfig&lt;/a&gt;和&lt;a href="https://learn.microsoft.com/en-us/exchange/architecture/client-access/autodiscover?view=exchserver-2019"&gt;autodiscover&lt;/a&gt;自動配置和發現帳户。&lt;/li&gt;
&lt;li&gt;通過域和租户隔離實現多租户支持。&lt;/li&gt;
&lt;li&gt;每個用户和租户的磁盤配額。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安全且強大&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;使用 S/MIME&lt;/strong&gt;或&lt;strong&gt;OpenPGP&lt;/strong&gt;進行靜態加密。&lt;/li&gt;
&lt;li&gt;使用、或挑戰通過&lt;a href="https://datatracker.ietf.org/doc/html/rfc8555"&gt;ACME&lt;/a&gt;自動配置 TLS 證書。&lt;code&gt;TLS-ALPN-01&lt;/code&gt;&lt;code&gt;DNS-01&lt;/code&gt;&lt;code&gt;HTTP-01&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;自動阻止攻擊、濫用或掃描服務器漏洞的 IP 地址。&lt;/li&gt;
&lt;li&gt;速率限制。&lt;/li&gt;
&lt;li&gt;安全審計（閲讀&lt;a href="https://stalw.art/blog/security-audit"&gt;報告&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;內存安全（感謝 Rust）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可擴展且容錯&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;設計用於無縫處理增長，從小型設置到數千個節點的大規模部署。&lt;/li&gt;
&lt;li&gt;構建時考慮了&lt;strong&gt;容錯&lt;/strong&gt;和&lt;strong&gt;高可用性&lt;/strong&gt;，可以從硬件或軟件故障中恢復，同時最大程度地減少對操作的影響。&lt;/li&gt;
&lt;li&gt;對等集羣協調或與&lt;strong&gt;Kafka&lt;/strong&gt;、&lt;strong&gt;Redpanda&lt;/strong&gt;、&lt;strong&gt;NATS&lt;/strong&gt;或&lt;strong&gt;Redis&lt;/strong&gt;協調。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;、&lt;strong&gt;Apache Mesos&lt;/strong&gt;和&lt;strong&gt;Docker Swarm&lt;/strong&gt;支持自動擴展和容器編排。&lt;/li&gt;
&lt;li&gt;讀取副本、分片 Blob 存儲和內存數據存儲，實現高性能和低延遲。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;身份驗證和授權&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OpenID Connect&lt;/strong&gt;身份驗證。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.rfc-editor.org/rfc/rfc8628"&gt;帶有授權碼&lt;/a&gt;和&lt;a href="https://www.rfc-editor.org/rfc/rfc8628"&gt;設備授權&lt;/a&gt;流程的 OAuth 2.0 授權。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LDAP&lt;/strong&gt;、&lt;strong&gt;OIDC&lt;/strong&gt;、&lt;strong&gt;SQL&lt;/strong&gt;或內置身份驗證後端支持。&lt;/li&gt;
&lt;li&gt;使用基於時間的一次性密碼進行雙因素身份驗證（&lt;code&gt;2FA-TOTP&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;應用程序密碼（App Passwords）。&lt;/li&gt;
&lt;li&gt;角色和權限。&lt;/li&gt;
&lt;li&gt;訪問控制列表 (ACL)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可觀察性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;使用 OpenTelemetry&lt;/strong&gt;、journald、日誌文件和控制枱支持進行日誌記錄和跟蹤。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;具有 OpenTelemetry&lt;/strong&gt;和&lt;strong&gt;Prometheus&lt;/strong&gt;集成的指標。&lt;/li&gt;
&lt;li&gt;用於事件驅動自動化的 Webhook。&lt;/li&gt;
&lt;li&gt;通過電子郵件和 webhook 通知發出警報。&lt;/li&gt;
&lt;li&gt;實時追蹤和指標。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基於 Web 的管理&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;具有實時統計和監控功能的儀錶板。&lt;/li&gt;
&lt;li&gt;帳户、域、組和郵件列表管理。&lt;/li&gt;
&lt;li&gt;用於消息和出站 DMARC 和 TLS 報告的 SMTP 隊列管理。&lt;/li&gt;
&lt;li&gt;用於接收 DMARC、TLS-RPT 和故障（ARF）報告的報告可視化界面。&lt;/li&gt;
&lt;li&gt;郵件服務器各個方面的配置。&lt;/li&gt;
&lt;li&gt;具有搜索和過濾功能的日誌查看器。&lt;/li&gt;
&lt;li&gt;用於密碼重置和靜態加密密鑰管理的自助服務門户。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;截圖&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="299" src="https://static.oschina.net/uploads/space/2025/0528/141541_x6Xx_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/stalwart</link>
      <guid isPermaLink="false">https://www.oschina.net/p/stalwart</guid>
      <pubDate>Sun, 11 May 2025 10:20:00 GMT</pubDate>
    </item>
    <item>
      <title>Hugging Face 發佈 ScreenSuite：開源 GUI 智能體評測套件</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Hugging Face&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fscreensuite" target="_blank"&gt;&amp;nbsp;開源&lt;/a&gt;&lt;/u&gt;了專用於評估 GUI 智能體的綜合測試套件&amp;nbsp;ScreenSuite。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b8a681e7b26b82daaa084cba75737cf15d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;什麼是 GUI Agent？簡單説，就是「能像人一樣操作屏幕」的 AI！它能識別界面內容、點擊按鈕、輸入文字、滾動頁面……實現真實的「虛擬助手」體驗。&lt;/p&gt; 
&lt;p&gt;現在，Hugging Face 推出了全新的開源工具 ScreenSuite，幫助開發者和研究者評估這類視覺語言模型的實際操作能力！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ScreenSuite 能做什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;它整合了 13 個評測集，覆蓋：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;屏幕感知與 UI 定位&lt;/li&gt; 
 &lt;li&gt;單步操作指令執行&lt;/li&gt; 
 &lt;li&gt;多步驟任務規劃與完成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ScreenSuite 已在多個主流 VLM 上完成評測，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen2.5-VL 系列（3B~72B）&lt;/li&gt; 
 &lt;li&gt;UI-TARS、Holo1 等優秀開源模型&lt;/li&gt; 
 &lt;li&gt;GPT-4o 等閉源模型&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ScreenSuite 支持 Ubuntu、Android、Windows 多平台評測，結合虛擬機環境還原真實交互場景，適用於科研評估與模型迭代。與其他評測不同的是，ScreenSuite 完全基於視覺輸入，不依賴 DOM 或輔助樹，更貼近人類的使用方式，挑戰也更真實。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355075/huggingface-screensuite</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355075/huggingface-screensuite</guid>
      <pubDate>Sun, 11 May 2025 10:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里發佈開源數字人框架 Mnn3dAvatar</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;阿里開源了名為「Mnn3dAvatar」的數字人框架，項目可以做到實時面捕然後映射到 3D 虛擬角色臉上（注意不是 Live2D 的，是 3D 的），甚至還能幫助創建一個 3D 虛擬角色。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-752d4b90686f31d92cffa705f0a4666ba61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/alibaba/MNN/blob/master/apps/Android/Mnn3dAvatar/README.md&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Mnn3dAvatar 是基於自研 3D 高斯濺射技術的 3D 數字人實時面捕方案，通過 AI 驅動實現高精度面部動作捕捉與實時渲染，支持語音、表情、手勢等多模態驅動，可在手機、AR 設備等終端以 90FPS 幀率流暢運行。&lt;/p&gt; 
&lt;p&gt;其核心優勢在於將影視級數字人效果落地到消費級硬件，僅需普通手機攝像頭即可替代傳統動捕設備，顯著降低直播場景的部署門檻與成本，製作週期縮短至一週內，成本僅為傳統 CG 方案的 1/30。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355070</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355070</guid>
      <pubDate>Sun, 11 May 2025 09:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 發佈強化學習框架 LlamaRL</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Meta 發佈了 LlamaRL 強化學習框架，基於 PyTorch 構建全異步分佈式架構，通過獨立執行器並行處理生成、訓練和評分任務，並整合 DDMA 和 NVLink 技術實現高效數據傳輸。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/174259_0GLJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;實測顯示，該框架在 4050 億參數模型中，將強化學習步驟耗時從 635.8 秒縮減至 59.5 秒，效率提升 10.7 倍，80 億、700 億參數模型訓練時間分別縮短至 8.90 秒、20.67 秒。其突破內存瓶頸與 GPU 利用率難題，同時在 MATH 和 GSM8K 等標準測試中模型表現穩定甚至增強，為未來更大規模模型訓練提供可擴展解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-586f91769fd68bac924768946985aabdcfc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;論文地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.24034" target="_blank"&gt;https://arxiv.org/abs/2505.24034&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355068</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355068</guid>
      <pubDate>Sun, 11 May 2025 09:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌發佈高效運行語言模型的 C++ 庫：LiteRT-LM</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌發佈了 LiteRT-LM 早期版本，這是一個 C++庫，用於在邊緣平台上高效運行語言模型。&lt;/p&gt; 
&lt;p&gt;LiteRT-LM 支持跨平台高效運行 Gemma-3N 系列模型，支持 2B 和 4B 參數模型，適用於桌面環境（Mac/Windows/Linux）及物聯網設備。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/173748_cLZX_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;LiteRT-LM 的 README 寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;語言模型不再是一個單一模型，而是一個由多個模型和組件協同工作的流水線。LiteRT-LM 基於 LiteRT 構建，以支持這些流水線，包括：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;C++ API 高效運行語言模型&lt;/li&gt; 
  &lt;li&gt;跨平台支持，通過便攜式 C++實現廣泛部署場景&lt;/li&gt; 
  &lt;li&gt;靈活可定製，滿足您的特定功能需求&lt;/li&gt; 
  &lt;li&gt;硬件加速，釋放設備硬件的全部潛能&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;開源地址&lt;/p&gt; 
&lt;p&gt;https://github.com/google-ai-edge/LiteRT-LM&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/google/gemma-3n-E2B-it-litert-lm-preview&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355066/google-litert-lm-preview</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355066/google-litert-lm-preview</guid>
      <pubDate>Sun, 11 May 2025 09:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>通用型 AI 智能體 Manus 推出全新的聊天模式</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Manus AI &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FManusAI_HQ%2Fstatus%2F1932862389717995710" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出全新的聊天模式，並面向所有的用户免費開放。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/165305_UkfX_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可通過簡潔界面進行即時問答，覆蓋日常諮詢、知識查詢等場景，並可無縫切換至代理模式，執行網頁設計、數據分析等複雜任務。&lt;/p&gt; 
&lt;p&gt;&lt;img height="580" src="https://static.oschina.net/uploads/space/2025/0612/165427_PwLc_2720166.png" width="1496" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="662" src="https://static.oschina.net/uploads/space/2025/0612/165349_LikS_2720166.png" width="1126" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前，代理模式需訂閲或消耗點數，而此次更新後，用户無需付費即可體驗基礎功能，顯著降低使用門檻。&lt;/p&gt; 
&lt;p&gt;自 2025 年 3 月上線以來，Manus 已吸引超 200 萬用户註冊，而在今年 5 月，還獲得 Benchmark Capital 和紅杉中國 7500 萬美元融資，估值達 5 億美元。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/353537/manus-video-generation" target="news"&gt;通用型 AI 智能體 Manus 新增「文字生成視頻」功能&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/349561" target="news"&gt;Manus 開放註冊，用户每天可免費執行一項任務&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355049/manus-chat-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355049/manus-chat-mode</guid>
      <pubDate>Sun, 11 May 2025 08:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Android「 閉源」進度更新：Google 不再提供 Pixel 固件編譯</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;「愛範兒」昨日發文介紹了 Android 閉源進度更新，稱 Google 最新放出的 AOSP 代碼當中，沒有像往年那樣一併提供 Pixel 設備的 vendor binary，也即必要驅動程序等文件。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/161620_QpYg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;原文：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ifanr.com%2F1626765" target="_blank"&gt;Android 閉源進度更新：Google 不再提供 Pixel 固件編譯&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下文為該報道的總結：&lt;/p&gt; 
&lt;p&gt;Google 在發佈 Android 16 版本 AOSP 代碼時未提供 Pixel 設備的 vendor binary。&lt;/p&gt; 
&lt;p&gt;目前 Pixel 設備驅動程序二進制文件停留在 Android 15.0.0 版本，且此次提供的 Android 16 版本 AOSP 代碼只能構建為通用系統映像，用於硬件兼容性驗證，非完整系統。&lt;/p&gt; 
&lt;p&gt;這一變化對第三方操作系統開發造成障礙，過去 Google 會同時提供 Pixel 設備 vendor binary，方便 ROM 開發者打包，而從 Android 16 開始，開發者無法自行修改 AOSP 代碼打包成固件安裝到 Pixel 設備上，只能通過逆向工程拆解 Pixel 升級包做適配，且每款 Pixel 手機都要逆向工程一次，限制第三方 ROM 適配範圍和市場表現。&lt;/p&gt; 
&lt;p&gt;只有與 Google 簽訂 GMS 協議的 OEM 合作伙伴能第一時間獲得全量 AOSP 代碼，這意味着基於 AOSP 開發的 ROM 很難開發 Android 16 版本，除非開發團隊與 Google 簽訂授權協議或從已簽約 OEM 獲取代碼。&lt;/p&gt; 
&lt;p&gt;知名 ROM 團隊 GrapheneOS 確認了這一情況，其因無法第一時間拿到完整 AOSP 代碼，開發進度受阻，需大量逆向工程且移植工作變得困難。&lt;/p&gt; 
&lt;p&gt;Google 這樣做的原因可能是為了節約開支和增加收入，減少對不能帶來利益的第三方 ROM、非認證 Android 設備等市場的免費支持。&lt;/p&gt; 
&lt;p&gt;Google 早在 2025 年初就有了收窄 Android 開源屬性的想法，策略執行將延續數年，直至 AOSP 徹底失去開源屬性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355037</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355037</guid>
      <pubDate>Sun, 11 May 2025 08:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節 Trae 宣佈月活突破 100 萬，交付超 60 億行代碼</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;由字節跳動開發的 AI 原生集成開發環境（IDE）Trae 迎來重要里程碑：截至 2025 年 5 月，月活躍用户已達 100 萬，累計幫助開發者交付超過 60 億行代碼。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Trae 於 2025 年 1 月正式推出，3 月推出國內版本，集成了豆包 1.5-pro 及 DeepSeek R1 和 V3 等先進模型，為中國開發者提供定製化支持。Trae 的多模態功能尤為突出，能夠根據 Figma 設計文件或手繪草圖生成前端代碼，代碼生成準確率高達 91%，複雜系統（如電子商務平台）的開發效率提升高達 400%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="344" src="https://oscimg.oschina.net/oscnet/up-e841ba3308d0602d72ac4e45d0a1c2c3980.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Trae 成功的核心在於其高效生成和管理海量代碼的能力。平台已助力開發者交付超 60 億行代碼，充分展示了其強大的自動化功能和與現代開發流程的無縫整合。Trae 的 Builder 模式支持用户通過自然語言提示生成完整的項目框架，例如輸入「構建一個帶有 Redis 緩存和 JWT 認證的購物車系統」，即可自動生成包含 Dockerfile 和 CI/CD 腳本的完整項目。此外，Chat 模式提供實時代碼調試和優化功能，進一步提升了開發體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月，Trae 推出國際付費訂閲計劃，首月定價 3 美元，隨後每月 10 美元，為用户提供更快訪問高級模型和無限代碼補全等高級功能。支持支付寶的訂閲模式進一步推動了國際用户的增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/336617" target="_blank"&gt;中國首款 AI IDE：Trae 國內版發佈&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/352294/trae-pro-plan" target="news"&gt;Trae IDE 海外版上線付費訂閲服務，Pro 版每月 10 美金&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355035</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355035</guid>
      <pubDate>Sun, 11 May 2025 08:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>vivo Pulsar 萬億級消息處理實踐（1）- 數據發送原理解析和性能調優</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網大數據團隊- Quan Limin&lt;/p&gt; 
 &lt;p&gt;本文是 vivo 互聯網大數據團隊《vivo Pulsar 萬億級消息處理實踐》系列文章第 1 篇。&lt;/p&gt; 
 &lt;p&gt;文章以 Pulsar client 模塊中的 Producer 為解析對象，通過對 Producer 數據發送原理進行逐層分析，以及分享參數調優實戰案例，幫助讀者理解與使用好 Producer，並體會到 Producer 對消息中間件系統穩定性以及處理性能所起到的關鍵作用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;一、Pulsar 簡要介紹&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/fb/fbcab3bc275f1a6943f142e8a110d07c.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar 是新一代的雲原生消息中間件，由 Apache 軟件基金會孵化和開源。它的設計目的是為了滿足現代數據處理和計算應用程序對可擴展性、可靠性和高性能的需求，具備存儲與計算分離、節點對等、獨立擴展、實時均衡、節點故障快速恢復等特性。&lt;/p&gt; 
&lt;p&gt;Pulsar 由四個核心模塊組成：broker、bookKeeper 和 client（Producer 和 Consumer）、zk（元數據管理和節點協調）。broker 接受來自 Producer 的消息，將消息路由到對應的 topic；bookKeeper 用於數據持久化存儲和數據複製；Consumer 消費 topic 上的數據。Pulsar 支持多種編程語言和協議（如 Java、C++、Go、Python 等），可以運行在雲、本地和混合環境中，擴展性好，支持多租户和跨數據中心複製等特性。因此，Pulsar 被廣泛應用於雲計算、大數據、物聯網等領域的實時消息傳遞和處理應用中。&lt;/p&gt; 
&lt;h1&gt;二、Pulsar Producer 解析&lt;/h1&gt; 
&lt;p&gt;首先需要了解 Producer 的數據發送流程，這裏以「開啓壓縮、batch 發送消息給 partitioned topic「這樣的一個線上常規場景為例，解析數據的發送的關鍵環節。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;tips：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Pulsar 中有無分區（Non-Partitioned）Topic 和有分區 (Partitioned) 的 Topic 之分，Partitioned topic 最小分區數為 1，為滿足任務的拓展性，在線上一般使用 Partitioned topic。&lt;/p&gt; 
&lt;h2&gt;2.1 消息生產與發送的詳細流程&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/66/6663c40abe8c2e1562b1ef8e8393a55d.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Producer 發送數據主要分為&lt;strong&gt;12 個步驟：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① 創建 Producer：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;partitioned topic 創建的是一個 Partitioned-&lt;/p&gt; 
&lt;p&gt;ProducerImpl 對象，該對象包含了所有分區及其對應的 ProducerImpl 對象，ProducerImpl 對象負責所對應分區數據的維護和發送。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 構造消息：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一條消息被髮送前首先會被封裝成為一個 Message 對象，對象中包含了所發送的 topic name、消息體、消息大小、schema 類型、metadata（是否指定 key 等）等信息。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;③ 確定目標分區：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在發送消息前需要通過路由策略決定發往哪一個分區，選擇對應分區的 ProducerImpl 對象進行進一步處理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;④ 攔截器：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Producer 可以設置自定義的攔截器，攔截器需要實現 producerInterceptor 接口，在消息發送前可對消息進行攔截修改。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑤ 消息堆積控制：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Producer 可以處理的消息是有限的，接收新的消息時會分別進行信號量和內存使用率校驗，控制接收消息的速率，防止消息無限在本地堆積。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑥ batch 容器管理：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;默認情況下分好區的消息不是直接被髮送，而是放入了生產者的一個 batch 緩存容器中裏面。在這個緩存裏面，多條消息會被封裝成為一個批次（batch）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑦ 消息序列化：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;Pulsar 的消息需要從客户端傳到服務端，涉及到網絡傳輸，因此 Producer 將 batch 緩衝區中的所有消息逐一進行序列化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑧ 壓縮：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar 內置了多種壓縮算法，在發送前會根據所選擇的壓縮算法對 batch 整體進行壓縮，這將優化網絡傳輸以提高 Pulsar 消息傳輸的性能。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑨ 構建消息發送對象：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;無論是開啓 batch 的批次消息，還是關閉 batch 的單條消息，都會被包裝為一個 OpSendMsg 對象，OpSendMsg 也是 Producer 發送和 pulsar broker 接收處理的最小單位。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑩ pending 隊列：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;所有構建好的 OpSendMsg 在發送前都會被放入 pendingMessages 隊列中，消息處理完成後才會從隊列中移除。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑪&amp;nbsp;消息傳輸：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar 使用 netty 將消息異步的從客户端發送到服務端，Broker 節點將在收到消息後對其進行確認，並將其存儲在指定主題的持久存儲中。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⑫ 響應處理：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar Broker 在收到消息時會返回一個響應，如果寫入成功，消息將會從 pendingMessages 隊列中移除。如果寫入失敗，會返回一個錯誤，生產者在收到可重試錯誤之後會嘗試重新發送消息，直到重試成功或超時。&lt;/p&gt; 
&lt;h2&gt;2.2 關鍵環節原理分析&lt;/h2&gt; 
&lt;p&gt;接下來會對上述流程中關鍵環節的設計和原理作進一步的剖析，幫助讀者更好的理解 Producer。&lt;/p&gt; 
&lt;h3&gt;2.2.1 創建 Producer&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/e5/e52d9588e782f913a00d092f1cdd80f5.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 Pulsar 中，PartitionedProducerImpl 用於將多個 ProducerImpl 對象包裝成為一個邏輯生產者，以便向 Partitioned Topic 發送消息時能夠批量操作。其中，PartitionedProducerImpl.producers 成員變量維護了每個分區及其對應的 ProducerImpl 對象，該設計主要有以下&lt;strong&gt;3 個好處：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① 每個分區對應一個單獨的生產者：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Pulsar 中，Partitioned Topic 按照分區（Partition）將多個 ProducerImpl 對象進行分配，以便能夠同時發往多個 Broker 節點，因此對於每個分區，需要擁有一個單獨的生產者以便進行發送操作。在 PartitionedProducerImpl 類中，需要為每個分區維護一個 ProducerImpl 對象，以便在消息被分配好「目標分區」後可以調用對應的 ProducerImpl 進行處理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;②簡化代碼邏輯：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 PartitionedProducerImpl 中，將每個分區及其對應的 ProducerImpl 對象維護在一個 HashMap 中，能夠更加方便的維護並管理不同分區的生產者，使得代碼邏輯更加清晰簡明。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;③ 提高容錯性：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當某個分區的 ProducerImpl 對象無法工作時，可以選擇其他可用的 ProducerImpl 對象，從而保證系統整體的可用性。由於將不同分區的 ProducerImpl 對象分別進行維護，因此具備更加靈活的容錯處理策略。&lt;/p&gt; 
&lt;p&gt;在線上實踐中我們也基於該設計，在 PartitionedProducerImpl 層做了進一步優化，通過感知下一層每個 ProducerImpl 的阻塞狀態（信號量的使用情況）來決定新的消息發送，避免將消息持續發往阻塞較為嚴重的分區，規避了 topic 被某一個分區阻塞而影響到整體發送性能的情況，也提高了線上系統的穩定性，具體的實現可以詳見這篇文章《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247494958%26idx%3D3%26sn%3Db2f02d545627a1457958289d8f623af3%26scene%3D21%23wechat_redirect" target="_blank"&gt;構建下一代萬億級雲原生消息架構：Apache Pulsar 在 vivo 的探索與實踐&lt;/a&gt;》。&lt;/p&gt; 
&lt;p&gt;關鍵代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;//對每一個分區都創建一個 ProducerImpl 對象
  private void start(List&amp;lt;Integer&amp;gt; indexList) {
        AtomicReference&amp;lt;Throwable&amp;gt; createFail = new AtomicReference&amp;lt;Throwable&amp;gt;();
        AtomicInteger completed = new AtomicInteger();
 
        for (int partitionIndex : indexList) {
            createProducer(partitionIndex).producerCreatedFuture().handle((prod, createException) -&amp;gt; {
.......
            });
        }
    }
 
    private ProducerImpl&amp;lt;T&amp;gt; createProducer(final int partitionIndex) {
        return producers.computeIfAbsent(partitionIndex, (idx) -&amp;gt; {
            String partitionName = TopicName.get(topic).getPartition(idx).toString();
            return client.newProducerImpl(partitionName, idx,
                    conf, schema, interceptors, new CompletableFuture&amp;lt;&amp;gt;());
        });
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2.2 確定目標分區&lt;/h3&gt; 
&lt;p&gt;在發送消息前需要決定發往哪一個分區，確定好分區後便調用對應分區的 ProducerImpl 對象進一步處理，目標分區的確定主要跟「路由策略」和「是否指定 key」有關：&lt;/p&gt; 
&lt;p&gt;**（1）如果消息沒有指定 key：**則按照三種路由策略的效果選擇分區進行發送，三種路由策略如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;SinglePartition：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;如果消息沒有指定 Key，Producer 會隨機選擇一個 Partition，然後把所有的消息都發送到這個 Partition 上。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;RoundRobinPartition：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;生產者將以輪詢方式在所有 Partition 之間發佈消息，以實現最大吞吐量。需要注意的是如果開啓了 batch 發送，則輪詢將會以批為單位進行消息發送，批次發送時每隔 partitionSwitchMs 會輪詢一個 Partition。如果關閉了批量發送，那麼每條消息發送都會輪詢一個 Partition。（partitionSwitchMs 至少為一個 batchingMaxPublishDelay 時間）。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;CustomPartition：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;使用用户自定義的消息路由實現，根據自定義的 Router 實現決定消息要發往哪個分區。用户自定義的 Router 可以通過 messageRoute 參數設置。自定義的 Router 需要實現 MessageRouter 接口的 choosePartition 方法。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;**（2）如果消息指定 key：**則會對 Key 做哈希處理,然後找到對應的 Partition，把 key 所對應的消息都發送到同一個分區：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;對消息的 Key 進行哈希處理後如何找到對應的 Partition 的？即使用 Key 的哈希值對總的 Partition 數取模：N=(Key 的哈希值% 總的 Partition 數)，得到的 N 就是第 N 個 Partition，Producer 可以通過設置 hashingscheme 來使用不同的哈希算法 ，現在已經支持 JavastringHash 和 Murmur3_32Hash 兩種哈希算法，前者直接調用 String.hash.Code()，後者使用 Murmur3。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;路由策略的關鍵代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;//SinglePartition 路由策略：
public int choosePartition(Message&amp;lt;?&amp;gt; msg, TopicMetadata metadata) {
    // If the message has a key, it supersedes the single partition routing policy
    if (msg.hasKey()) {
        return signSafeMod(hash.makeHash(msg.getKey()), metadata.numPartitions());
    }
 
    return partitionIndex;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;//RoundRobin 路由策略：
public int choosePartition(Message&amp;lt;?&amp;gt; msg, TopicMetadata topicMetadata) {
    // If the message has a key, it supersedes the round robin routing policy
    if (msg.hasKey()) {
        return signSafeMod(hash.makeHash(msg.getKey()), topicMetadata.numPartitions());
    }
 
    if (isBatchingEnabled) { // if batching is enabled, choose partition on `partitionSwitchMs` boundary.
        long currentMs = clock.millis();
        return signSafeMod(currentMs / partitionSwitchMs + startPtnIdx, topicMetadata.numPartitions());
    } else {
        return signSafeMod(PARTITION_INDEX_UPDATER.getAndIncrement(this), topicMetadata.numPartitions());
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2.3 消息堆積控制&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/2f/2fe4f4750d448407920510d97421b11b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Producer 不可能無限接收新的消息，如果某些分區數據發送較慢，消息就會堆積在 Prouducer 緩存中，導致已經阻塞的分區堆積大量的消息，又無法重新發往其他分區，同時也可能因為無限堆積的消息佔用了大量的內存，使得任務頻繁 GC 甚至 OOM。&lt;/p&gt; 
&lt;p&gt;在 Pulsar 提供了兩個核心的速率限制策略和一個阻塞時的消息處理策略：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;消息數量限制：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;maxPendingMessages 控制每個分區某一時刻最大可處理消息數量，通過信號量的方式控制「新進入的消息」的信號量分配和「處理完成消息「的信號量釋放，防止某個分區的消息嚴重堆積。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;消息佔用內存大小限制：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;memoryLimit 控制整個 Pulsar client 的消息最大佔用內存大小，通過計數器方式控制「新進入的消息」有效載荷的內存分配和「處理完成消息「有效載荷的內存釋放，這裏需要特殊説明的是 memoryLimit 是 client 的參數，針對的是該 client 對象下的所有 topic，因此並不建議一個 Pulsar client 對象 new 多個 Producer topic ，因為很容易出現某一個 topic 佔用內存過多，導致另一個 topic 無空間可分配的情況。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;阻塞處理策略：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;由 blockIfQueueFull 進行控制，當 blockIfQueueFull 為 true 時，代表阻塞等待，Producer 會等待獲取信號量；當 blockIfQueueFull 為 false 時，一旦獲取不到信號量，就會立刻失敗，需要注意的是如果 blockIfQueueFull 為 false，業務需要處理好消息失敗後的回調策略，否則會導致數據在 Producer 上「丟失」。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;關鍵代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public void sendAsync(Message&amp;lt;?&amp;gt; message, SendCallback callback) {
......
        MessageImpl&amp;lt;?&amp;gt; msg = (MessageImpl&amp;lt;?&amp;gt;) message;
        MessageMetadata msgMetadata = msg.getMessageBuilder();
        ByteBuf payload = msg.getDataBuffer();
        int uncompressedSize = payload.readableBytes();
        //對發送隊列大小以及 client memory 進行判斷是否有空間放入新的消息
        if (!canEnqueueRequest(callback, message.getSequenceId(), uncompressedSize)) {
            return;
        }
......
    }
 
    private boolean canEnqueueRequest(SendCallback callback, long sequenceId, int payloadSize) {
        try {
            if (conf.isBlockIfQueueFull()) {
                //當 blockIfQueueFull 為 true 時，等待獲取信號量
                if (semaphore.isPresent()) {
                    semaphore.get().acquire();
                }
                //分配消息有效載荷所需要的內存空間
                client.getMemoryLimitController().reserveMemory(payloadSize);
            } else {
                //當 blockIfQueueFull 為 false 時，如果無法獲取到信號量，則快速失敗
                if (!semaphore.map(Semaphore::tryAcquire).orElse(true)) {
                    callback.sendComplete(new PulsarClientException.ProducerQueueIsFullError("Producer send queue is full", sequenceId));
                    return false;
                }
                //如果沒有如何的內存空間用於消息分配，則報錯
                if (!client.getMemoryLimitController().tryReserveMemory(payloadSize)) {
                    semaphore.ifPresent(Semaphore::release);
                    callback.sendComplete(new PulsarClientException.MemoryBufferIsFullError("Client memory buffer is full", sequenceId));
                    return false;
                }
            }
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            callback.sendComplete(new PulsarClientException(e, sequenceId));
            return false;
        }
 
        return true;
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2.4 消息 batch 容器打包&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/57/57e8428ca0b0093978799d8411231e60.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）batch 關鍵組成信息&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Messages:&lt;/strong&gt; 保存消息的 list，保存跟這個 batch 相關所有的 MessageImpl 對象。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;**Metadata：**保存 batch 相關的元數據，如批量消息的序列號、消息發送的時間戳等信息。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;**Callback：**保存消息回調邏輯的集合，記錄了每一條消息對應的 callback 策略，在 batch 消息發送並等到服務端響應後，依次對消息的回調進行處理。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;（2）batch 打包條件&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;batch 打包條件的三個關鍵參數：滿足其一數據就會被打包發送出去。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;**批次大小：**batchingMaxBytes&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;**批次條數：**batchingMaxMessages&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;批次延遲發送時間：&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;batchingMaxPublishDelay&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Pulsar 使用兩個模塊設計來實現上面的參數控制：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;**accumulator：**在 BatchMessage-&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ContainerImpl 中通過計數器的方式去控制 batch 的大小和條數，numMessages-&lt;/p&gt; 
 &lt;p&gt;InBatch 記錄已經緩存的消息數量，currentBatchSizeBytes 用於記錄已緩存的消息的大小。當這些變量達到閾值時，BatchMessageContainerImpl 將會觸發批量消息的發送。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;**batchTimerTask：**當生產者使用批量消息發送模式時，Producer 將會創建一個定時器任務（batchTimerTask），並通過計時器的方式定時將 BatchMessageContainer 容器中的消息進行批量發送。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2.2.5 消息壓縮&lt;/h3&gt; 
&lt;p&gt;如果開啓了消息壓縮，在發送前都需要進行壓縮處理。對於單條消息發送的場景，是對每一條消息進行單獨壓縮後進行發送；而如果開啓了 batch 則是對整個 batch 進行壓縮後再整個進行發送。&lt;/p&gt; 
&lt;p&gt;在線上實踐中，推薦在不影響業務延遲的情況下 batch 越大越好，主要有&lt;strong&gt;兩個理由&lt;/strong&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;可以優化網絡 IO 降低 CPU 負載：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;不論 Producer 發送的是一條消息還是一批消息，在 pulsar 客户端都會被構建為一個 OpSendMsg 對象，同時 pulsar broker 接收到消息進行寫入處理時，也是按照 OpSendMsg 為一個處理單位將消息寫入磁盤，因此當消息數量一定時，batch 越大，則代表需要處理的 OpSendMsg 越少。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;batch 越大「壓縮效果則越好」：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;壓縮算法對應的壓縮率並不固定，它通常取決於所要壓縮的數據對象的內容和壓縮算法本身，壓縮的本質在於通過消除或利用數據中存在的冗餘來實現數據的壓縮和重構。而 Pulsar 是以 batch 來進行打包的，batch 越大，壓縮的目標包體越大壓縮效果則可能越好，同時也能夠儘可能避免單條消息因為包體較小導致越壓縮後包體越大的情況出現。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;以下是開啓了 batch 情況下，構建發送消息和壓縮的關鍵代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    public OpSendMsg createOpSendMsg() throws IOException {
        //對數據進行壓縮、加密等操作
        ByteBuf encryptedPayload = producer.encryptMessage(messageMetadata, getCompressedBatchMetadataAndPayload());
......
 
        ByteBufPair cmd = producer.sendMessage(producer.producerId, messageMetadata.getSequenceId(),
                messageMetadata.getHighestSequenceId(), numMessagesInBatch, messageMetadata, encryptedPayload);
        //對整個 batch 構建一個 OpSendMsg
        OpSendMsg op = OpSendMsg.create(messages, cmd, messageMetadata.getSequenceId(),
                messageMetadata.getHighestSequenceId(), firstCallback);
......
        return op;
    }
 
    //對 batch 進行壓縮，並將壓縮後信息更新到 messageMetadata 中
    private ByteBuf getCompressedBatchMetadataAndPayload() {
......
        int uncompressedSize = batchedMessageMetadataAndPayload.readableBytes();
        ByteBuf compressedPayload = compressor.encode(batchedMessageMetadataAndPayload);
        batchedMessageMetadataAndPayload.release();
......
        return compressedPayload;
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2.6 pending 隊列&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/64/6470193ab1e788eb19b49948423a9665.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar 中的 pendingMessages 隊列是客户端用來暫存「未處理完成的消息」的一個緩存隊列。用於存儲當 Producer 連接到 Broker 服務器後，還未發送或尚未得到 Broker 系統的 ACK 確認的所有生產者（Producer）的消息。在發送消息之前，Producer 首先會將消息緩存到 pendingMessages 隊列中，並記錄保存緩存消息的 OpSendMsg 對象，直到它被成功發送到了 Broker 端並收到 Broker 發送的 ACK 確認之後，相關的元信息和消息信息才會從隊列中移除。&lt;/p&gt; 
&lt;p&gt;需要注意的是：&lt;strong&gt;pending 隊列的本質是一個回調處理隊列，而不是發送隊列&lt;/strong&gt;，消息在放入 pending 隊列的同時就被異步發送到服務端了，所以這裏需要重點理解什麼是「未處理完成的消息」。&lt;/p&gt; 
&lt;p&gt;pendingMessages 隊列的&lt;strong&gt;作用在於&lt;/strong&gt;：對於已經發送但尚未收到 ACK 確認的消息，防止在連接出現異常時丟失消息。當連接中斷時，緩存在 pendingMessages 隊列中的未確認消息將被認為是需要重發的，當連接恢復時，緩存的消息將重新發送到 Broker 端，以確保生產者生產的消息不會丟失。&lt;/p&gt; 
&lt;p&gt;**總的來説，**pendingMessages 隊列是 Pulsar 客户端保證消息可靠性和一致性的關鍵功能組件，在 Pulsar 的生產者（Producer）和消息確認的機制中擔任着非常重要的角色。&lt;/p&gt; 
&lt;p&gt;關鍵代碼如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;add() 方法用於在追加消息時將指定元素插入隊列中的隊尾，remove() 用於消息在完成後移除隊列頭部的元素。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;    protected void processOpSendMsg(OpSendMsg op) {
        if (op == null) {
            return;
        }
        try {
            if (op.msg != null &amp;amp;&amp;amp; isBatchMessagingEnabled()) {
                batchMessageAndSend();
            }
            //將消息放入「待處理消息隊列」
            pendingMessages.add(op);
......
                // If we do have a connection, the message is sent immediately, otherwise we'll try again once a new
                // connection is established
                op.cmd.retain();
                cnx.ctx().channel().eventLoop().execute(WriteInEventLoopCallback.create(this, cnx, op));
                stats.updateNumMsgsSent(op.numMessagesInBatch, op.batchSizeByte);
...... 
    }
 
       //添加消息到 pendingMessages 隊列
       public boolean add(OpSendMsg o) {
            // postpone adding to the queue while forEach iteration is in progress
            //batch 的計數是按照 batch 中消息的總量進行計數
            messagesCount.addAndGet(o.numMessagesInBatch);
            if (forEachDepth &amp;gt; 0) {
                if (postponedOpSendMgs == null) {
                    postponedOpSendMgs = new ArrayList&amp;lt;&amp;gt;();
                }
                return postponedOpSendMgs.add(o);
            } else {
                return delegate.add(o);
            }
        }
        //將消息從 pendingMessages 隊列移除
        public void remove() {
            OpSendMsg op = delegate.remove();
            if (op != null) {
                messagesCount.addAndGet(-op.numMessagesInBatch);
            }
        }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2.7 消息傳輸&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/2d/2d4bd56bfcbf7bbe62118828ee858a69.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Producer 和 broker 都維護了分區維度的 pending 隊列來保證消息處理的順序性，以及實現消息重新發送、重新寫入持久化存儲的能力。在 Producer 端，消息被順序追加到 pending 隊列並異步發送到服務端，服務端的 pending 隊列在接收到消息後，按照順序追加到隊列中，並按照順序將數據寫入 bookie 進行持久化處理，處理完成後按照順序返回響應 Producer，並將消息從 broker pending 和 producer pending 隊列中移除。&lt;/p&gt; 
&lt;p&gt;另外在數據傳輸過程中，無論是使用 Pulsar Producer 的同步發送還是異步發送，在消息傳輸環節本質上都是使用 netty 將消息異步的從客户端發送到服務端，區別在於 send() 方法封裝了 sendAsync() 方法，使其可以在向服務器發送 Pulsar 消息時阻塞等待 Broker 的響應，直到確認消息已經被 Broker 成功處理後才會返回，常規情況下，建議使用異步的方式發送 Pulsar 消息，因為同步方式必須在 Broker 端成功接收到消息之後才會返回，因此會帶來較大的性能損耗和延遲。但是在部分場景下，需要使用同步方式來保證可靠性，以防 Broker 端接收失敗，可以考慮使用 send() 方法實現同步方式的方式發送 Pulsar 消息。&lt;/p&gt; 
&lt;p&gt;使用 netty 執行的代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    private static final class WriteInEventLoopCallback implements Runnable {  
......
        @Override
        public void run() {
            if (log.isDebugEnabled()) {
                log.debug("[{}] [{}] Sending message cnx {}, sequenceId {}", producer.topic, producer.producerName, cnx,
                        sequenceId);
            }
 
            try {
                cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());
                op.updateSentTimestamp();
            } finally {
                recycle();
            }
        }
......
    
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.2.8 處理響應&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/28/28dd6d8c28f93ecae7372ea40b5c372b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar Producer 使用「ACK 跟蹤機制」來實現對 Broker 返回的 ACK 確認消息的處理，用於檢測和處理到達生產者的全部消息狀態信息。&lt;/p&gt; 
&lt;p&gt;對於 Producer 發送的消息，Pulsar 會對每個消息分配一個唯一的 sequenceId 序號，並記錄該消息的創建時間（createdAt）等元數據信息。當 Broker 確認收到某個消息時，Producer 會依據返回的 ACK 序號和 Broker 返回的確認時間來判斷當前 ACK 是否有效，並從已緩存的 pendingMessages 隊列中找到對應的消息元數據信息，以進行確認處理，在 Broker 確認消息接收成功時，Producer 將從等待確認的消息隊列中刪除對應的消息元數據信息，如果 Broker 返回的 ACK 消息不符合生產者預期的消息狀態信息，Producer 將會重發消息，直到重試成功或多次重試失敗後拋出異常後再從隊列中移除對應消息元數據信息並釋放對應內存、信號量等資源。&lt;/p&gt; 
&lt;p&gt;消息重發的關鍵代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    private void resendMessages(ClientCnx cnx, long expectedEpoch) {
        cnx.ctx().channel().eventLoop().execute(() -&amp;gt; {
            synchronized (this) {
                //判斷連接狀態：當連接正在關閉或者已經關閉則不進行重發
                if (getState() == State.Closing || getState() == State.Closed) {
                    // Producer was closed while reconnecting, close the connection to make sure the broker
                    // drops the producer on its side
                    cnx.channel().close();
                    return;
                }
......
                //調用重發消息方法
                recoverProcessOpSendMsgFrom(cnx, null, expectedEpoch);
            }
        });
    }
 
 
   // Must acquire a lock on ProducerImpl.this before calling method.
    private void recoverProcessOpSendMsgFrom(ClientCnx cnx, MessageImpl from, long expectedEpoch) {
......
        final boolean stripChecksum = cnx.getRemoteEndpointProtocolVersion() &amp;lt; brokerChecksumSupportedVersion();
        Iterator&amp;lt;OpSendMsg&amp;gt; msgIterator = pendingMessages.iterator();
        OpSendMsg pendingRegisteringOp = null;
        while (msgIterator.hasNext()) {
            OpSendMsg op = msgIterator.next();
......
            op.cmd.retain();
            if (log.isDebugEnabled()) {
                log.debug("[{}] [{}] Re-Sending message in cnx {}, sequenceId {}", topic, producerName,
                          cnx.channel(), op.sequenceId);
            }
            //發送消息
            cnx.ctx().write(op.cmd, cnx.ctx().voidPromise());
            op.updateSentTimestamp();
            stats.updateNumMsgsSent(op.numMessagesInBatch, op.batchSizeByte);
        }
        cnx.ctx().flush();
......
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;三、Pulsar 數據發送端參數調優實踐&lt;/h1&gt; 
&lt;p&gt;根據以上對原理解析，我們對 Producer 已經有了一個大致理解，下面通過一個 Producer 參數調優實踐案例來幫助讀者基於原理進一步理解客户端參數之間的聯繫。&lt;/p&gt; 
&lt;h2&gt;3.1 調優目的&lt;/h2&gt; 
&lt;p&gt;首先要清楚為什麼要進行參數調優，有以下兩個目的：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;降低參數使用門檻：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Pulsar client 和 Producer 的幾十個配置參數，參數多且聯繫緊密，需要花費較多的時間成本去理解，同時參數之間存在協同生效互相影響的情況，對普通使用者而言場景複雜理解門檻高，我們希望能夠有一套較為通用的參數配置，或有公式化的參數配置方法論。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;提升單機處理性能：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;站在客户端的角度，相同時間內處理的數據量越多，則認為單機處理性能更強。作為中間件系統的提供者，我們經常認為性能提升是服務端的事情，想盡辦法在 pulsar 的 broker 和 bookie 上去提升單機處理性能，但 pulsar client 作為整個消息中間件系統的核心組件，它能否發送好一份數據，對整個消息中間件系統的性能和穩定性也發揮着至關重要的作用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;3.2 調優實踐&lt;/h2&gt; 
&lt;p&gt;下面就圍繞「參數通用模版化」和「提升單機處理性能」兩個目的出發並結合上述講解的數據發送原理，來分享一些實踐經驗。&lt;/p&gt; 
&lt;h3&gt;3.2.1 關聯與場景相關的重點參數&lt;/h3&gt; 
&lt;p&gt;Pulsar 客户端參數雖多但都提供了默認值，不需要一一調整。只需要對業務場景相關的針對性的去調整即可，如我們本次的參數調優目的是提升單機處理性能，則重點關注哪些場景哪些參數可以提升客户端的發送速率、降低服務端的壓力，讓服務端可以處理更多的數據，有以下四點最為關鍵：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;batch 打包發送：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;消息多條批次發送，在降低客户端和服務端網絡 IO 的同時也降低了兩者的 cpu 的負載。這裏需強調的是我們希望 batch 是一個均勻的、「完整」的包，如 pending 隊列被打滿，batch 只能空等到延遲發送時間過後被髮送，沒有構建出預期中的 batch，那麼可以認為這個 batch 是一個不完整的包，這種 batch 包含的數據量少，對發送效率有着極大的影響。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;數據壓縮：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Pulsar 是 IO 密集型系統，常規情況下磁盤是系統的主要瓶頸，開啓壓縮可以有效降低網絡 I/O，提升處理相同數據量下的讀寫能力。由於壓縮是針對 batch 的，在發送時間一定的情況下，batch 越大其壓縮效果也越好，代表着處理的消息量也更多。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;RoundRobin 發送：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;將數據均勻地分配到多個分區中。它的基本思想是輪詢將新的數據寫入到不同的分區中，以均衡地分散負載。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;消息堆積控制：&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;maxPendingMessages 信號量和 memoryLimit 限制不直接提升發送速率，但它能夠有效保障我們客户端的穩定，也是控制或限制發送效率的重要參數之一。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;涉及的客户端關鍵參數以及默認值和我們線上調優後設置的數值如下表：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/fa/fa59c582553e31ab2ecc8027cdce5f13.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.2.2 結合 Producer 發送原理分析參數的效果&lt;/h3&gt; 
&lt;p&gt;接下來我們以參數的效用角度來描述一條消息從構建到發送的過程，進一步解釋參數如此設置的意義：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）選擇分區&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;構建消息後，通過 messageRoutingMode 參數所設置的路由策略來選擇分區，這裏以 RoundRobinPartition 為路由策略，開啓 batch 時則每間隔 partitionSwitchMs 時間換一個分區進行數據發送，partitionSwitchMs 的值為「batchingPartitionSwitchFrequencyByPublish&lt;/p&gt; 
&lt;p&gt;-Delay、batchingMaxPublishDelayMicros」這兩個 Producer 參數之積，也就是每 batchingPartition&lt;/p&gt; 
&lt;p&gt;-SwitchFrequencyByPublishDelay 個 batch 的最大打包時間，消息就會輪換一個分區發送。&lt;/p&gt; 
&lt;p&gt;為了能在 batchingMaxPublishDelayMicros 內得到一個較大的包，我們希望這個 batch 接收的消息是連續的，因此 batchingPartitionSwitchFrequency-&lt;/p&gt; 
&lt;p&gt;ByPublishDelay 不能小於 1，同時也希望一個分區之間數據是較為均勻的，所以 batchingPartition-&lt;/p&gt; 
&lt;p&gt;SwitchFrequencyByPublishDelay 也要儘量小，否則分區對應的信號量 maxPendingMessages 耗盡還沒有切換分區，就會導致 batch 必須等待一個 batchingMaxPublishDelayMicros 時間。因此將 batchingPartitionSwitchFrequencyByPublishDelay 修改成了 1，保證打包了一個 batch 之後就切換分區，這也極大的避免了分區信號量耗盡，出現發送阻塞。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）消息堆積控制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;maxPendingMessages 作為分區的信號量，也是「pending 隊列」的大小，代表着每個分區能夠同時處理的最大消息上限，而 maxPendingMessages-&lt;/p&gt; 
&lt;p&gt;AcrossPartitions 則是針對整個 topic 生效的，maxPendingMessages=min( maxPending-&lt;/p&gt; 
&lt;p&gt;Messages,maxPendingMessagesAcrossPartitions/Partition），由於線上分區可能會變化，有不確定性，因此就使用上而言除非有特殊的使用場景，建議將 maxPendingMessagesAcrossPartitions 設置的比較大，讓 maxPendingMessages 生效即可。&lt;/p&gt; 
&lt;p&gt;除了 maxPendingMessages 以外，消息能否接收被放入 pending 隊列中，還要看當前正在處理的消息體大小總和是否超過了 memoryLimit 參數的限制，memoryLimit 控制了消息待處理隊列中未壓縮前的消息有效荷載總和，可以避免在消息有效荷載非常大時，還未觸發 maxPendingMessages 限制，就導致內存佔用過多出現頻繁 GC 和 oom 的問題。由於 memoryLimit 是 client 級別的策略，因此也建議一個 client 對應一個 Poducer。&lt;/p&gt; 
&lt;p&gt;總而言之 maxPendingMessages 控制了每個分區可以處理消息數量的上限，memoryLimit 控制了所有分區可以消息佔用內存的上限，兩者相輔相成。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（3）消息 batch 容器打包&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;決定一個 batch 是否打包完成有三個條件控制，batchingMaxBytes、batchingMaxMessages、batchingMaxPublishDelayMicros 滿足其一即可，根據這三個參數的含義去設置值看似是容易的，但容易忽略的是 batch 中用來打包的消息也是受 memoryLimit 和 maxPendingMessages 制約的，應該避免出現 batch 中消息的數量超過 memoryLimit 和 maxPendingMessages 導致 batch 打包效率受影響。舉個例子，當 maxPendingMessages 設置為 500，而 batchingMaxMessages 設置 1000 時，batch 就永遠無法滿足消息條數達到 1000 的條件，只能空等 batchingMaxPublishDelayMicros 或者 batchingMaxBytes 兩者生效。&lt;/p&gt; 
&lt;h3&gt;3.2.3 公式化模版&lt;/h3&gt; 
&lt;p&gt;通過上述分析，大致瞭解了關鍵參數的生效效果，且彼此相互關聯，根據這些關係就能夠輸出一個較為簡單的參數調優模版。&lt;/p&gt; 
&lt;p&gt;假設我們發送的單條消息大小為：messageByte；分區數量為：partitionNum。&lt;/p&gt; 
&lt;p&gt;那麼對應參數調整公式如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;//業務發送速率越大，這裏設置的值越大
maxPendingMessages：一般 1000-2000 之間
 
//這裏值也可以設置大一些，讓 maxPendingMessages 生效即可
maxPendingMessagesAcrossPartitions = maxPendingMessages * partitionNum
 
//memoryLimit 的值就是打算阻塞總消息大小，這與消息體和 maxPendingMessages 有關
memoryLimit=(maxPendingMessages * partitionNum * messageByte)
 
//batch 的條數不超過「待處理消息隊列」大小的一半
batchingMaxMessages=maxPendingMessages/2，這樣可以保證在消息發送等待 ack 的時候，該分區剩下一半的空間還能用來構建一個 batch
 
//batch 大小同理，batch 大小不超過「待處理消息隊列」消息大小的一半
batchingMaxBytes= Math.min(memoryLimit * 1024 * 1024 /partitionNum/2,1048576)
 
//業務能夠接受的延遲大小，一般延遲時間越大，batch 越大
batchingMaxPublishDelayMicros=1ms-100m 皆可
 
//每構建一個 batch 就轉換一個分區
batchingPartitionSwitchFrequencyByPublishDelay=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到根據上面的分析，參數之間是有一個模版化的公式，但這也不是唯一的，讀者可以根據自己的業務場景進行調整。在真實使用過程中線上的消息大小以及分區數量實際上是會變化的，因此真正的參數設置還需要根據實際情況來確定，比如我們線上通常的做法是根據機器配置將 memoryLimit 直接設置為 64M-256M，分區數量我們線上不會超過 1000，那麼這裏就假設為 1000，確定了這兩個參數，其他的參數的值也就確定了。&lt;/p&gt; 
&lt;h3&gt;3.2.4 效果對比&lt;/h3&gt; 
&lt;p&gt;以線上一個業務參數調優為例，前後都開啓壓縮的情況下調整上述參數後的一個效果。&lt;/p&gt; 
&lt;p&gt;服務端（Pulsar）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/c4/c45ed239c62c651c39708935958c9416.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/3c/3c0534426c68d4af315d6d436ea2fcdc.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優化前後對比數據：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/3b/3bf425c9885d7cb1c6c6f50f6afde351.jpeg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相同的寫入速率，Pulsar 服務端網卡流量縮減約 50%（batch 包體增加，壓縮效果提升），cpu 負載降低約 90%，Pulsar 服務端總體成本相較優化前至少可降低 50% 以上，客户端也有一定程度的負載降低。&lt;/p&gt; 
&lt;p&gt;參數調整後，CPU 負載得到明顯降低，一定程度上避免了 CPU 成為系統的瓶頸，同時由於壓縮效果的提升，Pulsar 的磁盤 IO 負載得到顯著降低，可以用更少的機器處理更多的數據。&lt;/p&gt; 
&lt;h1&gt;四、總結&lt;/h1&gt; 
&lt;p&gt;理解 Producer 發送原理以及核心參數是寫好數據發送程序最為有效的手段，最簡單的客户端參數優化反而隱藏了巨大的收益。本文通過對 Producer 原理進行剖析、對消息的流轉過程中參數效用進行講解，並配合參數調優實踐案例，介紹了具體的分析思路和調優的方法，在實際使用過程中通過對核心的幾個上游系統進行調優，服務端單機處理能力至少提升了一倍以上，成本得到了極大的降低。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;參考文章：&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpulsar.apache.org%2Fdocs%2F4.0.x%2Fconcepts-overview%2F" target="_blank"&gt;https://pulsar.apache.org/docs/4.0.x/concepts-overview/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18619282</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18619282</guid>
      <pubDate>Sun, 11 May 2025 07:17:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>《智能體網絡協議技術報告》發佈</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;W3C&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA3OTY5NDI0OA%3D%3D%26mid%3D2247489930%26idx%3D1%26sn%3Dc3c4ed0e725c88f03e2e6cb6c82c13dc%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;strong&gt;AI Agent Protocol 社區組&lt;/strong&gt;&lt;/a&gt;於今年 5 月成立，致力於孵化下一代智能體之間的交互協議，讓智能體能夠在互聯網上使用協議進行高效的連接與協作，推動智能體在 Web 上的安全、高效、可信連接與協作。&lt;/p&gt; 
&lt;p&gt;小組現發佈《智能體網絡協議技術報告》：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fw3c-cg.github.io%2Fai-agent-protocol%2F" target="_blank"&gt;https://w3c-cg.github.io/ai-agent-protocol/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;另見該報告的中文翻譯參考：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fw3c-cg.github.io%2Fai-agent-protocol%2Findex_cn.html" target="_blank"&gt;https://w3c-cg.github.io/ai-agent-protocol/index_cn.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/145659_Z93C_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/145939_LjvL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;這份報告探討了從語義網（Semantic Web）的未竟願景到智能體網絡（Agentic Web）的演進歷程，並分析了構建標準化智能體網絡協議的必要性。&lt;/p&gt; 
&lt;p&gt;儘管二十年前提出的語義網構想極具前瞻性，但受限於當時人工智能技術的能力不足，未能充分實現。隨着大型語言模型（LLMs）等現代 AI 技術的飛速發展，智能體已具備自主執行任務、進行復雜推理和解決多步驟問題的能力，從而催生了 Agentic Web 的出現。&lt;/p&gt; 
&lt;p&gt;通過系統分析，該報告給出智能體網絡的&lt;strong&gt;四大核心趨勢&lt;/strong&gt;：&lt;strong&gt;智能體取代傳統軟件成為互聯網基礎設施&lt;/strong&gt;、&lt;strong&gt;智能體間實現普遍互聯互通&lt;/strong&gt;、&lt;strong&gt;基於協議的原生連接模式&lt;/strong&gt;、以及&lt;strong&gt;智能體的自主組織與協作能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;同時，研究揭示了當前互聯網架構對 Agentic Web 發展的&lt;strong&gt;三大挑戰&lt;/strong&gt;：&lt;strong&gt;數據孤島限制智能體決策質量、人機界面阻礙智能體交互效率、以及標準協議缺失阻礙智能體協作&lt;/strong&gt;。針對這些挑戰，報告詳細闡述了智能體網絡協議的設計原則與核心需求，並對當前主要智能體網絡協議倡議（MCP、A2A、ACP、ANP 等）進行了系統比較與分析。&lt;/p&gt; 
&lt;p&gt;報告強調，建立標準化智能體網絡協議對於打破數據孤島、實現異構智能體協作、構建 AI 原生數據網絡，以及最終實現開放、高效的 Agentic Web 具有關鍵作用，並呼籲各利益相關方積極參與 W3C 的標準化進程。這是一個塑造未來網絡的機會：一個更智能、更協作、更賦能的網絡，建立在開放和可信的基礎之上。一個精心設計的 Agentic Web 具有巨大的變革潛力，而現在正是為其奠定堅實基礎的關鍵時刻。&lt;/p&gt; 
&lt;p&gt;歡迎參與 AI Agent Protocol 社區組，共同定義 AI Agent 的 Web 通信標準，攜手構建可信、安全的智能體互聯網生態！&lt;/p&gt; 
&lt;p&gt;參與方式詳見：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.w3.org%2Fcommunity%2Fagentprotocol%2Fjoin" target="_blank"&gt;https://www.w3.org/community/agentprotocol/join&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關於 W3C 社區組&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;W3C 通過社區組（Community Groups）為全球社區提供一個廣泛交流 Web 技術進而探索孵化未來新標準的開放平台，從而滿足日益增長的各方 Web 參與者的技術交流需求。W3C 社區組面向公眾開放，任何感興趣的單位及個人均可參與。&lt;/p&gt; 
&lt;p&gt;W3C 目前設有 144 個社區組：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.w3.org%2Fgroups%2Fcg%2F" target="_blank"&gt;https://www.w3.org/groups/cg/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;歡迎瞭解如何參與社區組討論（中文指南）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chinaw3c.org%2Fhowtocg.html" target="_blank"&gt;https://www.chinaw3c.org/howtocg.html&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;來源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlSPl8HprLBPuGmkJYvEuBA" target="_blank"&gt;https://mp.weixin.qq.com/s/lSPl8HprLBPuGmkJYvEuBA&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355009/w3-org-agent-network-protocol-whiter-paper</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355009/w3-org-agent-network-protocol-whiter-paper</guid>
      <pubDate>Sun, 11 May 2025 07:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>黃仁勳論 AI 與量子技術驅動新浪潮，微美全息正加速量子計算產業化融合</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;北京時間 6 月 12 日，英偉達 CEO 黃仁勳在法國巴黎召開的 VivaTech2025 上表示，對量子計算越來越看好。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;「量子計算正迎來拐點，我們即將能夠在一些有趣的領域應用量子計算。」黃仁勳在在本次演講中表示，英偉達會以多種方式與世界各地的量子計算公司合作。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//95030e6360550155a4bc4588318030aa.png" width="719" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;此前，在 GTC 2025 大會上，英偉達舉辦了首個「量子日」活動，黃仁勳公開表示，「對時間表判斷錯誤」，並宣佈設立量子研究中心，旨在幫助量子計算公司利用英偉達硬件助力其工作。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;現如今，黃仁勳稱，未來幾年或至少下一代超級計算機中，它們中的每一個都將擁有連接到 GPU 的 QPU（量子處理器），QPU 將進行量子計算，而 GPU 將用於預處理、控制、糾錯、後處理。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//2723d8c890a73ac2a0a84317244e87dc.png" width="719" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;更重要的是，黃仁勳在開場中還表示，GB200 NVL72 系統將加速量子計算產業發展。英偉達正藉助 GB200 NVL72 平台與 CUDA-Q 軟件棧，推動 AI 與量子計算的協同發展。比如，GB200 NVL72 輸出量子訓練數據的速度比基於 CPU 的技術快 4000 倍，有助於將最新的 AI 進展引入量子計算。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;事實上，量子計算機是利用量子力學定律，解決對經典計算機來説過於複雜的問題的機器，其目的是處理更多的數據量，以促進醫學、科學和金融等領域的突破。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//e6c8dec8e124671c4d3a31f832222047.png" width="719" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &lt;span&gt;&lt;span&gt;業內人士分析，過去 5 年，人工智能技術特別是生成式 AI 的爆發，看到計算模式出現了很多顛覆性的發展。未來 5 年，量子計算很可能從實驗室走向應用，所以，人工智能與量子計算的融合有望成為必然趨勢。&lt;/span&gt;&lt;/span&gt;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;顯然，越來越多的企業在加入開拓「量子計算」未來產業新賽道的行列，資料顯示，量子計算概念股微美全息（WIMI.US），積極推動量子計算融入 AI 生態，正加速「量子+AI」技術落地，通過構建 AI 平台基礎設施、佈局技術研究中心及推進量子技術融合，以全棧式佈局加碼量子計算+人工智能市場。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;當前，微美全息深刻認識到人工智能是底座，量子科技是躍遷力，而兩者的融合正是搶佔未來產業、未來話語權的關鍵路徑。因此，微美全息以人工智能為基座，聚焦量子技術、人形機器人、人工智能三大風口，擴展布局量子產業前沿領域，未來，將重點關注量子算法加速 AI 訓練、神經擬態計算等融合賽道，讓更多成果湧現。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;整體而言，量子計算與經典計算的融合將成為未來技術發展的重要方向，許多企業在這一領域的佈局顯示了其對前沿技術的敏鋭洞察。不過也要意識到一點，目前量子計算的產業格局仍處於早期階段，格局尚未成型，全球量子計算機數量較少，量子計算芯片將是整個領域未來發展的重點和難點。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355008</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355008</guid>
      <pubDate>Sun, 11 May 2025 06:56:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Meta 發佈開源世界模型 V-JEPA 2</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Meta 發佈了最新的開源世界模型&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.meta.com%2Fblog%2Fv-jepa-2-world-model-benchmarks%2F" target="_blank"&gt;V-JEPA 2&lt;/a&gt;，稱其在物理世界中實現了最先進的視覺理解和預測，從而提高了 AI agents 的物理推理能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height="559" src="https://static.oschina.net/uploads/space/2025/0612/144127_0qiP_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;開源地址：https://github.com/facebookresearch/vjepa2&lt;/em&gt;&lt;br&gt; &lt;em&gt;官網地址&lt;/em&gt;&lt;em&gt;：https://ai.meta.com/vjepa/&lt;br&gt; 論文地址：https://ai.meta.com/research/publications/v-jepa-2-self-supervised-video-models-enable-understanding-prediction-and-planning/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;V-JEPA 2 是一種&lt;strong&gt;聯合嵌入預測架構&lt;/strong&gt;（&lt;strong&gt;Joint Embedding Predictive Architecture&lt;/strong&gt;）模型，這也是「JEPA」的名稱由來。&lt;/p&gt; 
&lt;p&gt;模型包括兩個主要組成部分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;一個編碼器，負責接收原始視頻，並輸出包含對於觀察世界狀態語義上有用的內容的嵌入（embeddings）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="597" src="https://static.oschina.net/uploads/space/2025/0612/150421_f1zo_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;一個預測器，負責接收視頻嵌入和關於要預測的額外內容，並輸出預測的嵌入。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/150628_SYFp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;V-JEPA 2 跟傳統預測像素的生成式模型有很大性能差異，根據 Meta 測試數據，V-JEPA 2 執行任務時每個步驟的規劃用時縮短至 Cosmos 模型的三十分之一，不僅用時短，V-JEPA 2 的成功率還更高。&lt;/p&gt; 
&lt;p&gt;V-JEPA 2 的能力對現實世界 agents 理解複雜運動和時間動態（temporal dynamics），以及根據上下文線索預測動作都非常關鍵。基於這種預測能力，世界模型對於規劃給定目標的動作順序非常有用，比如從一個杯子在桌子上的狀態到杯子在桌子邊上的狀態，中間要經歷怎樣的動作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0612/150646_SoAo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，V-JEPA 2 的核心架構是一個自監督學習框架，通過互聯網規模的視頻數據來訓練模型，使其能夠學習到視頻中的動態和靜態信息。預訓練階段使用了超過 100 萬小時的視頻和 100 萬張圖像，這些數據涵蓋了各種動作和場景。預訓練的目標是讓模型能夠通過觀察學習到世界的背景知識，而無需依賴於大量的標註數據。&lt;/p&gt; 
&lt;p&gt;值得一提的是，圖靈獎獲得者、Meta 首席科學家楊立昆（Yann LeCun）參與了該模型的開發，這在 Meta 開源的眾多大模型中很罕見。他在官方視頻中提到，在世界模型的幫助下，AI 不再需要數百萬次的訓練才能掌握一項新的能力，世界模型直接告訴了 AI 世界是怎樣運行的，這可以極大提升效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355002/meta-vjepa-2-world-model</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355002/meta-vjepa-2-world-model</guid>
      <pubDate>Sun, 11 May 2025 06:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Liquid Glass React —— 「液態玻璃」的 React 實現</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Liquid Glass React 是蘋果「液態玻璃（Liquid Glass）」設計語言的 React 實現。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-09f93126aa8a24944a023d1e74e2ab9d9a5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f90f27edf2a257be2d13ededab62bc276f0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;良好的邊緣彎曲和折射&lt;/li&gt;
&lt;li&gt;多種折射模式&lt;/li&gt;
&lt;li&gt;可配置的冰霜級別&lt;/li&gt;
&lt;li&gt;支持任意子元素&lt;/li&gt;
&lt;li&gt;配置的填充&lt;/li&gt;
&lt;li&gt;修正懸停和點擊效果&lt;/li&gt;
&lt;li&gt;邊緣和高亮會像蘋果一樣呈現底層光線&lt;/li&gt;
&lt;li&gt;可配置的色差&lt;/li&gt;
&lt;li&gt;可配置的彈性參數，以模仿蘋果的"液體"觸感&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/liquid-glass-react</link>
      <guid isPermaLink="false">https://www.oschina.net/p/liquid-glass-react</guid>
      <pubDate>Sun, 11 May 2025 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>小紅書、B 站等平台清理違規 AI 產品營銷信息</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;網信上海微信公號&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fqmfe8tiUlXJDnt525ucA-Q" target="_blank"&gt;發文稱&lt;/a&gt;，為貫徹落實中央網信辦「清朗·整治 AI 技術濫用」工作部署，4 月下旬以來，上海市委網信辦聚焦 6 類突出問題深入開展第一階段專項行動。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="329" src="https://oscimg.oschina.net/oscnet/up-11e6dea0c86ec77bcd50df467bb75257ff6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上海市委網信辦指導小紅書、嗶哩嗶哩、拼多多等 15 家重點網站平台，集中清理「一鍵脱衣」、未經授權的人臉或人聲克隆編輯、未備案等違規 AI 產品、商品及相關營銷、炒作、推廣、教程信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;小紅書、嗶哩嗶哩主動發佈專項行動治理公告，開通了有害 AI 內容的舉報受理處置渠道；星野開展智能體全面排查清理。各重點網站和 AI 平台共攔截清理相關違法違規信息 82 萬餘條，處置違規賬號 1400 餘個，下線違規智能體 2700 餘個。經整治，網絡違規 AI 信息顯著減少。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，上海市已完成 82 款大模型備案，87 款應用登記。對 3 款未履行備案或登記程序提供服務且存在風險的應用，上海市委網信辦依法約談並給予行政處罰。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354996</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354996</guid>
      <pubDate>Sun, 11 May 2025 06:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>10+ PG 國際大咖助陣！IvorySQL 生態大會 6.27 開啓</title>
      <description>IvorySQL 2025 生態大會將於 6 月 27 日在濟南開幕，彙集來自開源和 PostgreSQL 社區的採用者和國內外技術專家。本次大會將以 PostgreSQL 技術生態為核心，聚焦全球數據庫技術發展趨勢、開源創新與行...</description>
      <link>https://howconf.cn/</link>
      <guid isPermaLink="false">https://howconf.cn/</guid>
      <pubDate>Sun, 11 May 2025 05:52:00 GMT</pubDate>
    </item>
    <item>
      <title>蘋果高管回應「個性化版 Siri」延期：技術架構限制導致未達到預期標準</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;在今年的 WWDC25 主題演講中，蘋果的 AI 智能助手 Siri 顯然沒有佔據重要位置。蘋果僅簡要提到它，並重申了開發進展比預期更慢，集成蘋果智能（Apple Intelligence）需要更長時間，預計將在 「明年」 推出。&lt;/p&gt; 
&lt;p&gt;演講結束後，蘋果軟件工程高級副總裁克雷格・費德里吉（Craig Federighi）和全球營銷副總裁格雷格・喬斯維亞克（Greg Joswiak）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tomsguide.com%2Fai%2Fapple-intelligence%2Fwwdc-interview-apples-craig-federighi-and-greg-joswiak-on-siri-delay-voice-ai-as-therapist-and-whats-next-for-apple-intelligence"&gt;進行了深度對話&lt;/a&gt;，解釋了蘋果在 Apple Intelligence、Siri 和 AI 領域的戰略思考。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fcd007add07610a84ea1a7e78288a2d830c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;蘋果曾承諾在 2024 年底發佈集成 Apple Intelligence 的 Siri 更新，但最終未能如期交付，並在 2025 年春季承認該功能還需要更多時間。至於原因，外界一直未能搞清楚，而蘋果一向不會展示那些無法按時交付的技術或產品。&lt;/p&gt; 
&lt;p&gt;訪談中，費德里吉詳細解釋了問題的所在，並説明瞭蘋果如何繼續推進這一計劃。&lt;/p&gt; 
&lt;p&gt;費德里吉提到在開發過程中意識到可以&lt;strong&gt;基於設備端的大語言模型、私人云計算基礎設施和設備端的語義索引技術提升 Siri 的智能化水平&lt;/strong&gt;，&lt;strong&gt;並設想通過 V1 架構協調應用意圖來觸發設備上的更多操作&lt;/strong&gt;，讓 Siri 執行更多任務。例如，利用語義索引中的個人知識，當用户詢問特定問題時，Siri 能從消息或郵件中找到相關內容，並通過應用意圖執行相關操作。但這些功能在 V1 架構下尚未完全交付。&lt;/p&gt; 
&lt;p&gt;在蘋果致力於開發 Siri 架構 V1 的同時，它也在打造 V2 架構 —— 費德里吉稱其為 「&lt;strong&gt;更深層次的端到端架構&lt;/strong&gt;，我們知道這才是最終要實現的架構，是讓 Siri 具備完整功能的架構。」&lt;/p&gt; 
&lt;p&gt;費德里吉説道：「我們花了幾個月的時間，不斷優化 V1 架構在更多應用意圖和搜索功能方面的表現。但從根本上看，我們發現該架構的侷限性沒有辦法達到客户所期望的質量水平。因此，我們決定轉向 V2 架構。但當我們意識到這一點時，已經是春季了，於是我們向外界説明，無法按計劃發佈，並將繼續轉向新架構。」&lt;/p&gt; 
&lt;p&gt;費德里吉進一步表示，即便採用第二代架構，蘋果仍在不斷優化 Siri 功能，確保其達到最佳狀態。&lt;/p&gt; 
&lt;p&gt;蘋果市場負責人 Greg Joswiak 在訪談中確認，「未來一年」 指向 2026 年，科技媒體 MacRumors 推測個性化 Siri 功能很可能隨 iOS 26.4 版本於 2026 年春季面世。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/337918/apple-says-some-ai-improvements-siri-delayed" target="news"&gt;蘋果推遲上線 Siri 中的 AI 相關功能&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354969/apples-on-siri-delay</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354969/apples-on-siri-delay</guid>
      <pubDate>Sun, 11 May 2025 03:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里蔡崇信：被 DeepSeek 逼急，工程師春節徹夜留守搞研發</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;彭博社報道稱，DeepSeek 在，今年 1 月推出低成本、功能強大的人工智能模型震驚全球科技行業後，也給阿里巴巴帶來了巨大的緊迫感。為迅速追趕這一技術突破，阿里巴巴的工程師們甚至取消了最重要的中國傳統節日——春節的休假，徹夜留守公司，全力投入 AI 研發。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="325" src="https://oscimg.oschina.net/oscnet/up-a5dcc123152fe1c8b0935e049dda3c97f2b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;阿里巴巴董事長蔡崇信在本週三舉行的巴黎 VivaTech 科技大會上，生動地講述了這段「爭分奪秒」的經歷。他表示，當 DeepSeek 發佈 R1 模型時，阿里巴巴內部意識到自身在 AI 領域已然落後。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面對這一挑戰，公司的工程負責人當機立斷，決定取消春節假期，要求所有工程師留在公司，甚至睡在辦公室裏，以最快的速度進行開發。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「幾周之內，我們推出了自己的版本——通義（Qwen）系列模型，表現相當不錯，競爭力很強。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此後，阿里巴巴推出了一系列新的 AI 模型，並將公司的業務重心進一步轉向人工智能和通用人工智能（AGI）。為支撐這一戰略轉型，阿里巴巴還承諾在未來三年內投入超過 3800 億元人民幣 (約合 530 億美元)，用於建設包括數據中心在內的 AI 基礎設施。今年早些時候，阿里巴巴還與蘋果公司達成合作協議，為 iPhone 提供 AI 技術支持。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354967</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354967</guid>
      <pubDate>Sun, 11 May 2025 03:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>可觀測性第四大支柱：配置數據的監控</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p style="color:#333333; text-align:left"&gt;業內經常講可觀測性有三大支柱：指標、日誌、鏈路追蹤，本文作者認為，還有第四大支柱：那就是配置類數據。配置類數據的變更也會影響系統的穩定性，也值得被監控，方便我們快速排查問題。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#333333"&gt;&lt;span&gt;原文鏈接：https://www.cloudquery.io/blog/fourth-lost-pillar-of-observability-config-data-monitoring&lt;/span&gt;&lt;br&gt; &lt;span&gt;原文作者：Yevgeny Pats&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#333333; text-align:left"&gt;很多關於日誌、指標和跟蹤的內容已經被廣泛討論，因為它們確實是可觀測性、應用程序和系統監控的關鍵組成部分。然而，經常被忽視的是配置數據及其可觀測性。在這篇博客中，我們將探討什麼是配置數據，它與日誌、指標和跟蹤有何不同，並討論需要什麼樣的架構來存儲這種類型的數據以及在哪些場景中它具有價值。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;日誌、指標和鏈路追蹤的快速回顧&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;對於那些對可觀測性的三大支柱還不太瞭解的人來説，讓我們快速回顧一下：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;&lt;img height="738" src="https://oscimg.oschina.net/oscnet/up-58f95ee676e13fe3a0619f3d3d0f956e34d.png" width="1316" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;日誌：系統內發生事件的詳細記錄。它們提供了關於特定事件的信息，包括時間戳、錯誤消息和其他相關細節。日誌有助於調試和故障分析。&lt;/li&gt; 
 &lt;li&gt;指標：定期收集的數值測量。它們有助於監控系統健康狀況、性能和隨時間的行為。示例包括 CPU 使用率、請求速率、錯誤率和響應時間。&lt;/li&gt; 
 &lt;li&gt;跟蹤：記錄請求在分佈式系統中通過不同服務的流程。跟蹤提供請求流程的可見性，有助於識別瓶頸並理解依賴關係。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:left"&gt;這些技術的後端通常是某種時間序列數據庫，數據類型通常是低基數數據（可以是高基數，但通常會變得昂貴且不建議這樣做）。另一個關鍵方面是，要獲取這些指標，通常需要對系統進行插樁，即，您需要訪問應用程序或基礎設施，以便部署 agent 或添加 Prometheus Exporter。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;配置數據：第四支柱&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;基礎設施不僅限於 AWS EC2 實例，還包括 IAM 用户、安全工具配置、SaaS 應用程序等。這些配置數據在幾個重要方面與傳統的可觀測性數據不同：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;無法直接監控：這些系統無法直接進行監控，但它們通過 API 暴露其配置。&lt;/li&gt; 
 &lt;li&gt;高基數和關係型：數據通常具有高基數，並且高度關係型。它也不像服務器上的磁盤 I/O 指標那樣頻繁變化，而是更側重於配置狀態。&lt;/li&gt; 
 &lt;li&gt;較低頻率，更高細節：我們在這裏想要做的權衡是較少的採集頻率，但具有更高的基數和細節。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;為什麼配置數據很重要&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;配置數據監控填補了您可觀測性策略中的關鍵空白：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;安全態勢監控：跟蹤 IAM 權限、安全組規則、加密設置以及其他影響您安全態勢的配置項。&lt;/li&gt; 
 &lt;li&gt;合規性跟蹤：監控配置以符合內部政策或外部合規要求（SOC2、HIPAA、PCI-DSS 等）。&lt;/li&gt; 
 &lt;li&gt;成本優化：識別導致不必要的成本的配置錯誤，例如過大實例或未使用的資源。&lt;/li&gt; 
 &lt;li&gt;變更管理：檢測並跟蹤環境中的配置變更，提供誰在何時變更了什麼的可見性。&lt;/li&gt; 
 &lt;li&gt;漂移檢測：識別資源何時偏離其預期或期望的配置。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;配置數據監控架構&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;讓我們來看看我們在 CQ（指的是 CLoudQuery，作者所在公司） 處理配置數據時做出的一些關鍵架構決策：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;&lt;img height="858" src="https://oscimg.oschina.net/oscnet/up-b79c63c47f59349231edbdaef7a8e21ed94.png" width="1200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;數據攝取&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;首先，數據提取的挑戰是不同的問題。我們無法對這些系統進行監控，因此需要創建提取器（或 ETL 腳本），主要挑戰是維護這些連接器。任何希望解決這一需求的系統都必須維護高質量的數據源連接器。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;收集頻率通常為每日一次，但根據配置的重要性，有時可能需要將其配置為更高的頻率。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#333333"&gt;譯者注：如果頻率這麼低，從監控的角度感覺是不夠用的。真的發生了故障，黃花菜都涼了。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;存儲&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;由於從 API 獲取的數據具有高度相關性，我們使用了一個 SQL 數據庫，可以在其中創建複雜的連接。NoSQL 數據庫或時間序列數據庫並不適合這種用例。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;在這裏，頻率和基數之間的權衡可能是按日分區。一些提取器可能會運行得更頻繁，但快照操作通常仍然會按日運行；否則，數據量會爆炸。&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;生成洞察&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;這與可觀測性平台解決「空白頁面綜合徵」（即「我有數據，現在我要監控什麼？」）的方式有些類似。我們提供了大量的開箱即用的洞察，但我們也認識到每個組織的需求略有不同，並且在雲治理方面沒有一刀切的規則。因此，客户可以訪問原始查詢並對其進行修改，也可以添加新的自定義數據源。&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;關係和物化視圖&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;將配置數據存儲在關係數據庫中的一個顯著優勢是能夠建模和查詢不同配置項之間的關係。例如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;哪個 IAM 角色可以訪問哪些 S3 桶？&lt;/li&gt; 
 &lt;li&gt;哪些安全組與哪些實例相關聯？&lt;/li&gt; 
 &lt;li&gt;您的 Kubernetes RBAC 設置與雲 IAM 權限有何關係？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:left"&gt;Materialized views 可以用於預先計算常見的關係查詢，從而提高經常性請求的性能。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;與傳統可觀測性集成&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;當配置數據作為第四支柱時，其真正的力量在於與傳統可觀測性數據集成後展現出來：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-fc821dc2087372e43f3f7c246362363b506.png" width="818" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;根本原因分析：當發生故障時，將指標、日誌和跟蹤與配置更改相關聯可以迅速識別根本原因。&lt;/li&gt; 
 &lt;li&gt;上下文增強：通過配置上下文增強指標和日誌（例如，「此錯誤峯值發生在對負載均衡器進行配置更改之後」）。&lt;/li&gt; 
 &lt;li&gt;主動監控：在這些配置變化影響您的指標之前，檢測可能導致未來性能問題或中斷的配置變化。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;挑戰與考慮&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;實施配置數據監控自身也伴隨着一系列挑戰：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;API 速率限制：許多服務對他們的 API 設定了速率限制，這可能會限制你收集配置數據的頻率。&lt;/li&gt; 
 &lt;li&gt;認證和授權：管理眾多系統的憑據和權限需要仔細考慮安全問題。&lt;/li&gt; 
 &lt;li&gt;數據體積管理：即使採集頻率較低，配置數據的高基數也可能導致顯著的存儲需求。&lt;/li&gt; 
 &lt;li&gt;Schema 遷移：API 隨時間發生變化，需要適應您的數據提取和存儲機制。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;日誌、指標和跟蹤仍然是可觀測性的關鍵組成部分，而配置數據代表了第四根支柱，提供了對您系統獨特見解。通過實施全面的配置數據監控，組織可以增強其安全態勢、確保合規性、優化成本，並更深入地瞭解其基礎設施。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;隨着系統變得越來越複雜和分佈式，配置數據監控的價值將只會增加。那些認識到這一第四支柱並將其納入其可觀測性策略中的組織，將更好地處於理解、排查故障和優化其日益複雜基礎設施的有利位置。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;譯者注：原文作者這個觀點值得借鑑，但是對於故障定位等場景真的那麼有用嗎？也未可知。具體實施時，建議先從 ROI 高的方面着手，從那些你覺得最重要的配置數據開始。Google SRE 統計生產環境 70% 故障是變更導致的，譯者建議您先把變更事件收集起來，對於排障還是蠻有用的。我們在 Flashcat 裏專門做了一個「事件牆」的產品，就是用來收集變更事件的。如果生產環境發生故障，從故障時間點往前看一個小時，該時間段內的變更事件，很可能就是故障的罪魁禍首。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/morflameblog/blog/18332409</link>
      <guid isPermaLink="false">https://my.oschina.net/morflameblog/blog/18332409</guid>
      <pubDate>Sun, 11 May 2025 02:59:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>香橙派開發板成功適配開源鴻蒙 OpenHarmony 5.0</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;香橙派&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FBDc9PFNAbhNS9HiX-3Bg4A"&gt;宣佈&lt;/a&gt;完成 OrangePi RV2 與開源鴻蒙 OpenHarmony5.0 的適配工作，&lt;/p&gt; 
&lt;p&gt;據介紹，OrangePi RV2 是香橙派在 RISC-V 佈局的一個標誌性產品，其採用開芯微首款 8 核 64 位 RISC-V AI CPU Ky X1。它以 RISC-V 開源指令集為基礎，提供快速、高效、易用的處理器平台，釋放算力潛能。OrangePi RV2 精緻小巧，尺寸僅為 89mmX56mmX1.6mm，功能強大，可廣泛應用於 NAS、商用電子產品、智慧機器人、智慧家居、工業控制、邊緣計算等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0612/104611_2b3H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;除了適配 OpenHarmony 5.0&amp;nbsp;之外，OrangePi RV2 還具有以下亮點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;以 CPU 方式提供 AI 算力，在無需獨立 NPU 模塊的情況下，實現 2TOPS@INT8 的 AI 能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持雙 M.2 SSD&amp;nbsp;擴展，支持 Wi-Fi5.0 和藍牙 5.0，擴展有 HDMI 2.0、三個 USB3.0、雙千兆 LAN、USB-C&amp;nbsp;供電接口。此外，還有兩個&amp;nbsp;MIPI-CSI&amp;nbsp;攝像頭接口（四通道），以及 26Pin GPIO&amp;nbsp;等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持本地部署 Deepseek-R1 蒸餾模型，通過在邊緣進行離線部署。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OrangePi RV2 售價 231 元起。香橙派已在官網放出開發板的&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.orangepi.cn%2Fhtml%2FhardWare%2FcomputerAndMicrocontrollers%2Fservice-and-support%2FOrange-Pi-RV2.html"&gt;Orange Pi OS（OH）鏡像&lt;/a&gt;，Orange Pi OS（OH）是以 OpenHarmony 為主要技術路線，結合 Linux 技術積累構建的多端融合操作系統。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/337094" target="news"&gt;香橙派首款高性能開源 RISC-V 開發板 (OrangePi RV) 即將開售，229 元起&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/263519" target="news"&gt;香橙派 Orange Pi OS (OH) 即將發佈，開源鴻蒙 PC 端&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354959</guid>
      <pubDate>Sun, 11 May 2025 02:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>特朗普政府新 AI 計劃「AI.gov」在 GitHub 上被泄露</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farchive.is%2Fhfl2Z"&gt;根據相關備份資料&lt;/a&gt;，美國總務管理局（GSA）在 GitHub 上發佈的一個早期版本的網站和代碼顯示，該聯邦政府正在開發一個名為 「ai.gov」 的網站和 API，旨在 「用 AI 加速政府創新」，該計劃定於 7 月 4 日啓動，並將包含一個分析功能，顯示特定政府團隊使用 AI 的程度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e8e700d454b9a1e4361cf7bfe632412ef29.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI.gov 網站包含三個主要部分：聊天機器人、「全能 API」和 CONSOLE 工具。&lt;/p&gt; 
&lt;p&gt;頁面早期版本顯示，其 API 將與 OpenAI、谷歌和 Anthropic 的模型產品集成；而 API 代碼進一步表明，開發團隊也在致力於整合亞馬遜網絡服務（AWS）的 Bedrock 和 Meta（Facebook 母公司） 的 LLaMA。此外，頁面提到將配備 AI 聊天機器人，但未説明其具體功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1444" src="https://static.oschina.net/uploads/space/2025/0612/103441_xzHk_2720166.png" width="1584" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1496" src="https://static.oschina.net/uploads/space/2025/0612/103419_zWpN_2720166.png" width="1702" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/GSA-TTS/ai.gov&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關來源&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.404media.co%2Fgithub-is-leaking-trumps-plans-to-accelerate-ai-across-government%2F" target="_blank"&gt;https://www.404media.co/github-is-leaking-trumps-plans-to-accelerate-ai-across-government/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2Fnews%2F684579%2Fai-api-trump-administration-doge-gsa" target="_blank"&gt;https://www.theverge.com/news/684579/ai-api-trump-administration-doge-gsa&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40telumai%2Fgithub-reveals-ai-gov-trumps-plan-to-automate-government-with-openai-meta-and-musk-s-doge-76f1676462e6" target="_blank"&gt;https://medium.com/@telumai/github-reveals-ai-gov-trumps-plan-to-automate-government-with-openai-meta-and-musk-s-doge-76f1676462e6&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov</guid>
      <pubDate>Sun, 11 May 2025 02:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
