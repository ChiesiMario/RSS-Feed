<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 29 Jul 2025 16:46:10 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>馬斯克宣佈 Grok 推出新 UI，引入「Auto 模式」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;馬斯克&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1948992239071326244" target="_blank"&gt;宣佈&lt;/a&gt;，Grok&amp;nbsp;已推出新的用户界面。該更新目前已在網頁端上線，並將很快推廣至移動端 APP。&lt;/p&gt; 
&lt;p&gt;新界面增加了一個新的模型選擇器功能。該功能引入了 Auto 模式，允許應用自動選擇合適的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1613" src="https://static.oschina.net/uploads/space/2025/0729/192206_0PZn_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前已經用户體驗到了新版的移動端 APP，並表示有「兩個版本」：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-87130b778bb6fac752a16c5287206709ff7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b88733bc4bda21493906af15dda98f02539.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363022</guid>
      <pubDate>Wed, 16 Jul 2025 11:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源項目 Kapitano 作者無端遭遇人身攻擊，心灰意冷之下宣佈停止維護</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，Linux 開源社區發生了一起令人遺憾的事件，開發者 zynequ 宣佈，由於遭遇無端的人身攻擊，他決定停止維護其開源項目 Kapitano。&lt;/p&gt; 
&lt;p&gt;Kapitano 是一個為命令行殺毒工具 ClamAV 提供圖形界面的應用程序，可幫助 Linux 用户更方便地使用 ClamAV 進行病毒掃描。&lt;/p&gt; 
&lt;p&gt;起因是一位用户在 Kapitano 的 Codeberg 頁面上創建了一個問題，聲稱該軟件在其 Linux Mint 系統上產生了誤報，檢測到 24 個與 Windows 漏洞和木馬相關的陽性結果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-da7edb2fb2aa6ca9655d630c2e2b8a6933a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該用户聲稱所有被標記的文件都與 Kapitano Flatpak 本身有關，並且以一種較為激進的方式警告其他用户不要下載該程序。&lt;/p&gt; 
&lt;p&gt;該用户甚至表示：「程序沒有任何評論，應該保持這種狀態，直到源代碼被獨立來源驗證。」&lt;/p&gt; 
&lt;p&gt;zynequ 在回應中冷靜地指出，問題並不是他的應用程序，Kapitano 並不參與具體的病毒判斷邏輯。&lt;/p&gt; 
&lt;p&gt;他還提供了相關代碼的鏈接，證明 Kapitano 只是調用了 ClamAV 的 clamscan 和 freshclam 命令。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ada62c2d3c6bf63d9f8dd27f293bb5a7110.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;然而事情並沒有就此結束，用户隨後創建了重複的問題，並聲稱 zynequ 是惡意行為者，要求將他這個「惡意軟件傳播者」封鎖。&lt;/p&gt; 
&lt;p&gt;經過激烈的爭論後，用户表示：「你的項目已經從我的筆記本硬盤中刪除了。讓它安息吧。再見。」&lt;/p&gt; 
&lt;p&gt;最終 zynequ 發佈終止維護聲明，他指出，Kapitano 是一個純粹的愛好項目，沒有得到任何經濟支持，而這種無端的人身攻擊讓他很難保持開發的動力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-011febf1266dc370c06a3c74915c45686a5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;zynequ 宣佈，Kapitano 的代碼現在已發佈到公共領域，採用無許可證（The Unlicense），這意味着任何人都可以分叉並隨意使用它。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363019</guid>
      <pubDate>Wed, 16 Jul 2025 11:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>新研究提出 AI 自主架構發現系統 ASI-Arch</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;上海創智學院領銜的團隊發佈了 AI&amp;nbsp;超智能系統：ASI-Arch，其成功設計徹底顛覆了這一認知。該系統基於先進的大模型技術，構建了高度自主的多智能體研究框架，能夠完全獨立地進行從問題識別、假設生成、實驗設計到結果驗證的完整科學研究流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/184132_dCXe_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文標題: AlphaGo Moment for Model Architecture Discovery&lt;/li&gt; 
 &lt;li&gt;系統開源: https://github.com/GAIR-NLP/&lt;/li&gt; 
 &lt;li&gt;ASI-Arch 網站地址: https://gair-nlp.github.io/ASI-Arch/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據介紹，在長達數月的自主研究過程中，ASI-Arch 系統展現出了令人震撼的研究能力。系統共進行了 1,773 次獨立實驗，累計消耗超過 20,000 GPU 小時的計算資源，在無人幹預的情況下，ASI-ARCH 自主發現了 106 個新穎且性能卓越的線性注意力架構，這些架構在多個基準測試中超越瞭如 Mamba2 和 Gated DeltaNet 等強大的基線模型。&lt;/p&gt; 
&lt;p&gt;這一研究規模和效率遠超傳統人類研究團隊的能力範圍。&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0729/184123_2g16_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖：AI 自主進行了 1,773 次科研探索&lt;/p&gt; 
&lt;p&gt;ASI-ARCH 系統成功發現了 106 個全新的線性注意力機制架構，每一個在性能指標上都顯著超越了現有的人類設計方案。這些發現的重要性不僅在於性能提升，更在於設計理念的創新。系統提出的許多架構設計原理和優化策略，即使是該領域的頂級專家也承認此前從未考慮過。這表明 AI 系統已經具備了超越人類認知邊界的創新能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363014</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363014</guid>
      <pubDate>Wed, 16 Jul 2025 10:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 AI 編程工具 Gemini CLI 定為每週三發佈更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;為提高更新流程的有序性，Gemini CLI 的發佈週期將調整為每週三定期更新。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1404" src="https://static.oschina.net/uploads/space/2025/0729/182925_0lMy_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini CLI 維護團隊成員宣佈將對其 Gemini CLI 的更新發布計劃進行調整。從現在開始，Gemini CLI 的更新將在每週三定期發佈，以使更新流程更有序、更有計劃性。&lt;/p&gt; 
&lt;p&gt;Gemini CLI 是谷歌開源的免費 AI 編程工具，該工具將 Gemini 的能力帶到了開發者最常用的終端，能夠提供輕量化的 Gemini 訪問通道。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363011</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363011</guid>
      <pubDate>Wed, 16 Jul 2025 10:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 首席科學家楊立昆回應另一位首席科學家的加入</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 近日宣佈清華校友趙晟佳（Shengjia Zhao）將&lt;a href="https://www.oschina.net/news/362754"&gt;正式&lt;/a&gt;擔任其超級智能實驗室（ MSL）首席科學家。&lt;/p&gt; 
&lt;p&gt;而 Meta 中的另一個 AI 團隊部門——FAIR 團隊，雖然在 Meta 的整體戰略中逐漸邊緣化，但 65 歲的圖靈獎得主 Yann LeCun（楊立昆）的職位未發生變化。扎克伯格也特別強調，&lt;strong&gt;楊立昆將繼續擔任 FAIR 的首席科學家&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-10f48ab6c9358abcb6969b367b7a7b9619d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與 MSL 不同，FAIR 專注於長期 AI 研究——即可能在五到十年後使用的技術。而對於扎克伯格的任命宣佈，Yann Lecun 也回應表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我作為 FAIR 首席科學家的角色一直專注於長期的人工智能研究和構建下一代人工智能範式。我期待與趙晟佳合作，加速將新研究成果整合到我們最先進的模型中。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363007</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363007</guid>
      <pubDate>Wed, 16 Jul 2025 10:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 招聘硬件系統產品設計師，打造「下一代全球最具創新移動設備」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正在招聘多個消費硬件相關職位，引發外界對其佈局新品的猜測。其中，硬件系統產品設計師崗位旨在打造「下一代全球最具創新的移動設備」。&lt;/p&gt; 
&lt;p&gt;在硬件系統產品設計師的&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fjobs%2Fview%2Fhardware-systems-product-designer-at-openai-4263584294%2F" target="_blank"&gt;職位描述中&lt;/a&gt;&lt;/u&gt;，OpenAI 表示該職位要求應聘者具備強大的機械設計技能，以及製造性設計（DFM）、裝配性設計（DFA）、公差與尺寸設計等領域的專業知識。此外，還需要具備組件模塊的經驗，包括 OLED / LCD 顯示屏、電池、聲學、攝像頭模塊，以及蜂窩和 GPS 系統等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1650" src="https://static.oschina.net/uploads/space/2025/0729/180234_vwbc_2720166.png" width="1410" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，OpenAI 也在招募電氣工程師，以「設計和優化高性能硬件產品的下一代充電技術」，涉及電路設計與充電技術優化，可能為未來設備構建無線充電平台。有用户推測，該設備或類似智能手錶或 Humane AI 別針，具備攝像頭、屏幕和麥克風等功能。&lt;/p&gt; 
&lt;p&gt;一位用户在 X 社交平台上&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fliminalsunset_%2Fstatus%2F1949642969914778016" target="_blank"&gt;猜測&lt;/a&gt;&lt;/u&gt;：「這看起來像是他們正在為 io 設備招聘，可能包含攝像頭、小屏幕和麥克風。」這位用户推測這可能是智能手錶或類似 Humane AI 別針的設備。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363005/hardware-systems-product-designer-at-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363005/hardware-systems-product-designer-at-openai</guid>
      <pubDate>Wed, 16 Jul 2025 09:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全新高效模型架構！RWKV-7s 閃耀 WAIC</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 26-29 日，&lt;strong&gt;RWKV 團隊受邀參加 2025 世界人工智能大會（WAIC 2025）&lt;/strong&gt;, 並在大會公開了 RWKV 最新的高效大模型架構：RWKV-7s，吸引了來自產業界、學術界及媒體的廣泛關注與討論。&lt;/p&gt; 
&lt;h2&gt;戰略合作，廣泛落地&lt;/h2&gt; 
&lt;p&gt;7 月 26 日，&lt;strong&gt;移遠通信宣佈與 RWKV 公司建立全面合作關係&lt;/strong&gt;，雙方將依託移遠的算力平台，優化並支持 RWKV 最新模型架構，共同推動大模型在端側設備的低資源佔用部署。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV x 移遠通信" src="https://oscimg.oschina.net/oscnet/up-ec04d5001a459b4a33964c1c2478645def2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUk6xlo-MQ09vS9JFwf35NA" target="_blank"&gt;端側大模型迎來「輕」革命！移遠通信 × RWKV 打造「輕量 AI 大腦」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;憑藉 RWKV 架構「資源佔用和推理速度恆定」的特性，RWKV 系列模型在端側部署具有天然優勢。&lt;strong&gt;現在，RWKV 已與多家芯片廠商、具身智能廠商合作將 RWKV 模型部署在芯片及機器人上&lt;/strong&gt;，如：高通、聯發科、Intel、AMD、英偉達、地平線機器人、有鹿機器人等等。&lt;/p&gt; 
&lt;h2&gt;全新技術，全面領先&lt;/h2&gt; 
&lt;p&gt;WAIC 大會首日，承接 RWKV-7 優勢的 RWKV-7s 新型高效大模型架構正式發佈。憑藉其原創的 DeepEmbed 和 DeepEmbedAttention 技術，成為現場焦點並 &lt;strong&gt;榮獲 WAIC「鎮館之寶-未來之星」稱號&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="WAIC-Award" src="https://oscimg.oschina.net/oscnet/up-e03b0a22f02ad601b832cf7790bf0bd78e8.jpg" referrerpolicy="no-referrer"&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhH7y37AcYP4GWOIjhNHz7g" target="_blank"&gt;鎮館之寶｜WAIC 2025 鎮館之寶及系列獎項名單公佈&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-7s 是 RNN+DeepEmbedAttention 混合架構，兼具高效計算與強長文本性能，其設計創新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;原創 DeepEmbed 技術，大稀疏模型只需小顯存，比 MoE 顯著更適合端側！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;原創 DeepEmbedAttention (DEA) 技術，長文本性能看齊 Attention，而 KV cache 僅為 MLA 的 1/9，更快更省！&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="DeepEmbed" src="https://oscimg.oschina.net/oscnet/up-78a8be5b2720c3b1b8ac934f907d2e6d5cf.png" referrerpolicy="no-referrer"&gt; &lt;img alt="DeepEmbedAttention" src="https://oscimg.oschina.net/oscnet/up-8c057eabf3fdcda0299f303d25e8433b8a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-7s 架構支持適配大語言模型、多模態、智能體等多種應用場景，憑藉廣泛的適配性吸引了現場各領域有智能化發展需求的企業關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eb5cd7552cfc42ce0e5ca61d787880e5ceb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;多場深度分享&lt;/h2&gt; 
&lt;p&gt;大會期間，&lt;strong&gt;RWKV 聯合創始人 &amp;amp; COO 羅璇及 RWKV-PEFT 與 WorldRWKV 作者康嘉樂受邀參與多場技術論壇與專題活動&lt;/strong&gt;，圍繞 RWKV-7s 混合架構、AGI 演進路徑及端側部署趨勢等話題展開深度分享。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="mohe" src="https://oscimg.oschina.net/oscnet/up-9bcdda5f376377dfa999b9685d793452f65.png" referrerpolicy="no-referrer"&gt; &lt;img alt="open_talk" src="https://oscimg.oschina.net/oscnet/up-3a8aebd93474fb31316773da624d59feaa3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;端側 Demo&lt;/h2&gt; 
&lt;p&gt;展會現場，&lt;strong&gt;RWKV 展台同步展出了五款 RWKV 自研的端側離線應用&lt;/strong&gt;。憑藉對多模態場景的廣泛覆蓋，收穫了現場觀眾的熱烈反響。&lt;/p&gt; 
&lt;p&gt;其中，&lt;strong&gt;RWKV 作曲家&lt;/strong&gt;升級全新輸入方式。除原有的虛擬鍵盤和藍牙 MIDI 鍵盤輸入以外，&lt;strong&gt;新增哼唱識別樂譜輸入功能，大幅降低使用門檻，便捷不同用户使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV 作曲家" src="https://oscimg.oschina.net/oscnet/up-7d3a18337b7b4cc8bab88df444b0e5fafd3.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV Chat 內置 RWKV7-G1 推理模型，&lt;strong&gt;無需聯網即可實現推理、深度對話與文本續寫。其中的 RWKV7-G1 2.9B 模型在高通手機平台的速度可達 30 token/s&lt;/strong&gt;，且由於 RWKV 架構無需 KV cache，在超長推理後仍然可以速度恆定，內存佔用恆定。&lt;/p&gt; 
&lt;p&gt;本次展示，RWKV Chat 全面優化 UI 界面，&lt;strong&gt;新增 Agent 陪聊與文本續寫功能，開發團隊還同步推出新手、高級、專家三種應用模式&lt;/strong&gt;，以滿足不同技術背景用户的需求為核心，為用户帶來更個性化的體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV Chat" src="https://oscimg.oschina.net/oscnet/up-4953f6c241e03a59b465a5b2bfbda1ba2af.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，RWKV 展位還演示了端側離線部署的圖像多模態應用 &lt;strong&gt;RWKV See&lt;/strong&gt;；超長 CoT 解決複雜數獨的 &lt;strong&gt;RWKV 數獨&lt;/strong&gt;；以及語音多模態應用 &lt;strong&gt;RWKV Talk&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV 數獨" src="https://oscimg.oschina.net/oscnet/up-7403589cfd4c77f004366bd59184897e350.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV See" src="https://oscimg.oschina.net/oscnet/up-7164d710aae30a7840955bd661f1b2001d2.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV Talk" src="https://oscimg.oschina.net/oscnet/up-99d0220761f728cfb0db51908d13a2fd81a.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV— 面向未來的高效 AI 大模型架構&lt;/h2&gt; 
&lt;p&gt;感謝每一位在 WAIC 2025 與 RWKV 相遇的朋友。未來，RWKV 期待深度參與社區技術交流與資源整合，攜手夥伴共同推動普惠開放的 AI 未來。目前，下一代核心架構 RWKV-8 的研發已在加速籌備中，預計於今年內發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8409a5f7ed66ea3012c851458bdf076b2de.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多 RWKV 技術動態、產品進展及社區合作信息，敬請持續關注 RWKV 官方公眾號。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363004</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363004</guid>
      <pubDate>Wed, 16 Jul 2025 09:53:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>​Mistral AI 發佈人工智能模型環境影響分析</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Mistral AI 對其一款大型語言模型進行了全面的生命週期分析，旨在評估人工智能技術的環境影響。這項研究由 Mistral 與可持續發展諮詢公司 Carbone4 及法國生態轉型機構共同開展，分析結果還經過了環境諮詢公司 Resilio 和 Hubblo 的同行評審。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#000000"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-9d2866802c4667241df914db00df7739dfa.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;該分析主要聚焦於 Mistral AI Large2 模型的整個生命週期，評估了其在温室氣體排放、水資源使用和材料消耗等三個關鍵領域的影響。研究發現，人工智能模型的訓練和推理階段是環境影響最大的環節，Mistral 表示，該模型 85.5% 的温室氣體排放和 91% 的水消耗都發生在模型的開發和用户交互過程中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;截至 2025 年 1 月，Mistral 的 Large2 模型在運行 18 個月後已產生 20.4 千噸的二氧化碳排放量，並消耗了 28.1 萬立方米的水資源。研究還估算了推理的邊際影響，通過用户與 「Le Chat」 聊天機器人進行 400 個令牌的交互，預計每次交互會產生約 1.14 克的二氧化碳排放和 45 毫升的水消耗。這些數據表明，單次查詢的環境影響雖然微小，但在數百萬乃至數十億用户長期交互下，整體的環境挑戰是不可忽視的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Mistral 也承認其研究存在一些侷限性，特別是在準確量化大型語言模型工作負載對 GPU 和數據中心基礎設施造成的硬件性能下降方面。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管如此，該報告中的數據與其他機構對人工智能環境影響的評估基本一致。Mistral 表示，未來將更新環境報告，呼籲整個人工智能行業提升透明度，致力於實現全球氣候目標。公司指出，目前的一些政策與這些目標存在背道而馳的現象。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362993</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362993</guid>
      <pubDate>Wed, 16 Jul 2025 09:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>opencode —— 為終端打造的 AI 編碼代理</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;a href="https://opencode.ai/"&gt;opencode&lt;/a&gt;&amp;nbsp;是為終端打造的 AI 編碼代理。&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;&lt;strong&gt;原生 TUI&lt;/strong&gt;：響應迅速、原生、可主題化的終端 UI。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSP 已啓用&lt;/strong&gt;：自動為 LLM 加載正確的 LSP。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多會話&lt;/strong&gt;：在同一個項目上並行啓動多個代理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可共享鏈接&lt;/strong&gt;：共享任何會話的鏈接以供參考或調試。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Claude Pro&lt;/strong&gt;：通過 Anthropic 登錄以使用你的 Claude Pro 或 Max 帳户。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用任何模型：通過&lt;/strong&gt;&lt;a href="https://models.dev/"&gt;Models.dev&lt;/a&gt;支持 75 多個 LLM 提供商，包括本地模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="366" src="https://static.oschina.net/uploads/space/2025/0725/145221_a1Fv_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/opencode</link>
      <guid isPermaLink="false">https://www.oschina.net/p/opencode</guid>
      <pubDate>Wed, 16 Jul 2025 08:59:00 GMT</pubDate>
    </item>
    <item>
      <title>統信 Windows 應用兼容引擎官網上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;統信 Windows 應用兼容引擎官網已於近日正式上線，「&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#3f3f3f"&gt;標誌着兼容技術從工具迭代邁向生態共建的新階段&lt;/span&gt;&lt;span style="color:#000000"&gt;」。官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLicvwV1XgGFgG_GKdHzImw" target="_blank"&gt;發文&lt;/a&gt;詳細介紹了統信 Windows 應用兼容引擎的演進歷程、核心功能與生態共建新起點。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;前期探索&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;wine 助手與 UOS 應用遷移助手&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2014 年，deepin-wine 團隊以「讓 Linux 系統流暢運行 Windows 應用」為目標，持續向 wine 上游社區提交 200 餘個補丁，十餘年間團隊從技術驗證走向產品化，產品也在不斷升級演進。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;2021 年：首次嘗試 wine 技術應用化&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2021 年，團隊首次嘗試將 wine 技術應用化，推出了「wine 助手」，實現了在 deepin 上雙擊直接安裝運行 Windows exe 程序，讓普通用户無需複雜操作即可使用 Windows 應用，大幅降低了 wine 技術的使用門檻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="248" src="https://oscimg.oschina.net/oscnet/up-29ad2fa7bd2709449d99883d318532ea5b0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;2024 年：UOS 應用遷移助手聚焦專業場景&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年，推出與 wine 助手定位差異化的「UOS 應用遷移助手」，聚焦更多專業場景，主打將 exe 程序打包為 deb 包，支持綠色軟件打包、ARM 架構運行等特性，滿足運維人員、技術工程師及應用開發者的專業需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-59821dc6d3b3bc43207d6072947b4234f52.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;統信 Windows 應用兼容引擎&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;功能升級與定位革新&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 11 月，UOS 應用遷移助手正式更名為「統信 Windows 應用兼容引擎」，並於 12 月迭代至 V3.0.4 版本，實現功能與定位的雙重升級：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;軟件功能重構&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從「打包工具」轉向「全場景兼容引擎」，支持直接雙擊運行 Windows exe 程序；打包功能整合至應用管理菜單，成為兼容成功後的延伸能力，優先保障 wine 應用的運行成功率。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;覆蓋多元用户需求&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向普通用户提供「一鍵運行」便利，為技術發燒友、軟件廠商提供圖形化遷移工具，助力 Windows 程序快速適配 deepin 與統信 UOS，滿足多架構、多場景的生態需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="335" src="https://oscimg.oschina.net/oscnet/up-c8e50fba3fe4eed53c9ee23e7fae68c4f86.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年，統信 Windows 應用兼容引擎持續迭代，現已更新至 V3.3.1 版本，進一步提升技術實力與生態覆蓋。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Proton 支持與架構適配&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;3&amp;nbsp;月成功適配 Proton 技術，支持在 deepin 25 中選擇「ge-proton」版本運行遊戲，大幅提升遊戲運行成功率與性能；新增與 Steam 版本對齊的穩定版 Proton，增加對 wow64 的支持，實現純 64 位系統運行多數 32 位遊戲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="269" src="https://oscimg.oschina.net/oscnet/up-93effbf36f9e47fd70fbe255d4b322344ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;應用清單與版本標準化&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;5 月 V3.3.0 版本新增 「全部應用」 模塊，整合 deepin-wine 團隊驗證通過的可兼容應用清單，為用户提供清晰的適配參考；默認 wine 版本升級為 deepin-wine10-stable，統一容器運行標準，減少適配衝突。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="382" src="https://oscimg.oschina.net/oscnet/up-6024ea1bea8099cb9b6ab2da98e7a666c43.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;wine 應用內存佔用下降 90%&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;6 月 V3.3.1 版本&lt;/strong&gt;解決了 wine 應用在 Linux 下的內存開銷過大問題，針對 64 位 Electron 框架的應用優化最為明顯，實測可以減少 90% 內存開銷，趨近於其在原生 Windows 平台上的實際使用量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-b95aae66980222fd322f3775f265b8b3b1a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;官網上線&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;打造協同共建新平台&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;統信 Windows 應用兼容引擎官網地址：&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#3f3f3f"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwine.deepin.org%2F" target="_blank"&gt;https://wine.deepin.org/&lt;/a&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;提供詳細使用教程、開發文檔與論壇交流入口等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-030f9331200776bda96ead8151501f87a9d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362978</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362978</guid>
      <pubDate>Wed, 16 Jul 2025 08:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包 App 視覺推理能力升級，圖片分析支持深度思考</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;豆包 App 在視覺推理領域迎來重大升級，其圖片分析功能現已支持深度思考模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;用户只需在深度思考模式下拍攝或上傳一張圖片，豆包便能迅速對圖片進行放大、裁剪等精細處理，並支持圖片搜索功能，實現邊想邊搜，從而進一步提升搜索結果的準確性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-0abd984fd925aba9f9e2f8f34b62cce318d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在圖片分析過程中，豆包展現出強大的信息處理能力。它能夠根據圖片中的細節信息，對比歷史檔案，檢索出相似圖片，並梳理出圖片的演變脈絡。通過這一系列操作，豆包能夠最終確定圖片的年代範圍，為用户提供更為精準的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，豆包還能對圖片進行深入分析，根據地形景觀、建築風格以及窗户細節等特徵，對照地理和人文特徵進行綜合判斷。經過這一系列複雜的分析過程，豆包能夠準確確定圖片所展示的具體方位，甚至最終確定城市名稱，為用户提供更加全面、準確的圖片解讀服務。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362977</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362977</guid>
      <pubDate>Wed, 16 Jul 2025 07:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻 inclusionAI 團隊發佈 Ming-lite-omni v1.5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻集團 inclusionAI 團隊發佈了全面升級版的全模態模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finclusionai.github.io%2Fzh%2Fblog%2Fming-lite-omni-1_5%2F" target="_blank"&gt;&lt;strong&gt;Ming-Lite-Omni v1.5&lt;/strong&gt;&lt;/a&gt;，基於 &lt;strong&gt;Ling-lite-1.5&lt;/strong&gt; 構建，總參數量為 &lt;strong&gt;203 億&lt;/strong&gt;（其中 MoE 部分活躍參數為 &lt;strong&gt;30 億&lt;/strong&gt;），在圖像-文本理解、文檔理解、視頻理解、語音理解與合成、圖像生成與編輯等全模態能力上顯著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95012b461af8180f5480bac2f4c85b95949.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ming-lite-omni v1.5 模型架構如下，主題參考了 Ming-lite-omni v1 版本的結構，區別在於為了增強圖像編輯人物和場景一致性，升級 Vision head 支持參考圖特徵輸入。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6c48bdf68ea2bcdfc0e8deb440f605297fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關鍵優化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;增強視頻理解&lt;/strong&gt;：通過 &lt;strong&gt;MRoPE 3D 時空編碼&lt;/strong&gt; 和針對長視頻的 &lt;strong&gt;課程學習策略&lt;/strong&gt;，顯著提升對複雜視覺序列的理解能力 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;優化多模態生成&lt;/strong&gt;：採用雙分支圖像生成（ID 與場景一致性損失）和新的音頻解碼器及 BPE 編碼，提升生成一致性與感知控制，實現高質量實時語音合成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據全面升級&lt;/strong&gt;：新增結構化文本數據、高質量產品信息及包括方言（如普通話、粵語、四川話等）在內的精細化視覺與語音感知數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;性能表現&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 &lt;strong&gt;MMVet&lt;/strong&gt;、&lt;strong&gt;MathVista&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt; 等數據集上表現突出，文檔理解任務（如 &lt;strong&gt;ChartQA&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt;）取得 10B 以下參數模型中的 &lt;strong&gt;SOTA&lt;/strong&gt; 成績。&lt;/li&gt; 
 &lt;li&gt;視頻理解、語音理解與生成（支持多種方言）及圖像生成（保持人物 ID 一致性編輯）均處於行業領先地位。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該模型已在 &lt;strong&gt;Hugging Face&lt;/strong&gt; 和 &lt;strong&gt;ModelScope&lt;/strong&gt; 上開放下載，並提供詳細安裝指南、代碼示例和 &lt;strong&gt;Gradio&lt;/strong&gt; 演示。&lt;/p&gt; 
&lt;p&gt;Hugging Face: https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5&lt;br&gt; ModelScope: https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362971</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362971</guid>
      <pubDate>Wed, 16 Jul 2025 07:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>eBPF 助力 NAS 分鐘級別 Pod 實例溯源</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;雲存儲 NAS 產品是一個可共享訪問、彈性擴展、高可靠、高性能的分佈式文件系統。 NAS 兼容了 POSIX 文件接口，可支持數千台計算節點共享訪問，可掛載到彈性計算 ECS、容器實例等計算業務上，提供高性能的共享存儲服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;鑑於多主機間共享的便利性和高性能， NAS 在得物的算法訓練、應用構建等場景中均成為了基礎支撐。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/36/36274710c18533ce5fc246ee82e640c2.jpeg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在多業務共享的場景中，單個業務流量異常容易引發全局故障。目前，異常發生後需依賴&lt;strong&gt;雲服務廠商 NAS &lt;/strong&gt;的溯源能力，&lt;strong&gt;但只能定位到主機級別，無法識別具體異常服務&lt;/strong&gt;。要定位到服務級別，仍需依賴所有使用方協同排查，並由 SRE 多輪統計分析，&lt;strong&gt;效率低下&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6a6a6a"&gt;（若服務實例發生遷移或重建，排查難度進一步增加）&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;為避免因 NAS 異常或帶寬佔滿導致模型訓練任務受阻&lt;/strong&gt;，因此需構建支持服務級流量監控、快速溯源及 NAS 異常實時感知的能力，以提升問題定位效率並減少業務中斷。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、流量溯源方案調研和驗證&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;NAS 工作原理&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 本地掛載原理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux 平台上，NAS 的產品底層是基於標準網絡文件系統 NFS（Network File System），通過將遠端文件系統掛載到本地，實現用户對遠端文件的透明訪問。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NFS 協議（主要支持 NFS v3 和 v4，通常以 v3 為主）允許將遠端服務掛載到本地，使用户能夠像訪問本地文件目錄一樣操作遠端文件。文件訪問請求通過 RPC 協議發送到遠端進行處理，其整體流程如下：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="465" src="https://oscimg.oschina.net/oscnet/up-3f3abf4fce2a08639688cf370284cf62cdd.png" width="620" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;文件系統訪問時的數據流向示意&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="552" src="https://oscimg.oschina.net/oscnet/up-a5b7a533fbca51c726053b4598e79c9786f.jpg" width="507" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;Linux 內核中 NFS 文件系統&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NFS 文件系統讀/寫流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux NFS 文件系統的實現中，文件操作接口由 nfs_file_operations 結構體定義，其讀取操作對應的函數為:&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;//NFS 文件系統的 VFS 層實現的函數如下所示：
const&amp;nbsp;struct&amp;nbsp;file_operations nfs_file_operations = {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .llseek &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_llseek,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .read_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;= nfs_file_read,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .write_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_write,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
};&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;針對 NFS 文件系統的讀操作涉及到 2 個階段（寫流程類似，只是函數名字有所差異，本文僅以讀取為例介紹）。由於文件讀取涉及到網絡操作因此這兩個階段涉及為異步操作：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 兩個階段&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;讀取請求階段：&lt;/strong&gt;當應用程序針對 NFS 文件系統發起 read() 讀操作時，內核會在 VFS 層調用 nfs_file_read 函數，然後調用 NFS 層的 nfs_initiate_read 函數，通過 RPC 的 rpc_task_begin 函數將讀請求發送到 NFS Server，至此向 NFS Server 發起的請求工作完成。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;讀響應階段：&lt;/strong&gt;在 NFS Server 返回消息後，會調用 rpc_task_end 和 nfs_page_read_done 等函數，將數據返回到用户空間的應用程序。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="415" src="https://oscimg.oschina.net/oscnet/up-fd2c800299c65096f8d6eba7de108c0581f.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在瞭解 NFS 文件系統的讀流程後，我們回顧一下 NFS Server 為什麼無法區分單機訪問的容器實例或進程實例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;這是因為 NFS 文件系統的讀寫操作是在內核空間實現的。當容器 A/B 和主機上的進程 C 發起讀請求時，這些請求在進入內核空間後，統一使用主機 IP（如 192.168.1.2）作為客户端 IP 地址。因此，NFS Server 端的統計信息只能定位到主機維度，無法進一步區分主機內具體的容器或進程。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-91366119d285327518f226735b34227dddd.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;內核空間實現示意&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;方案調研和驗證&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;進程對應容器上下文信息關聯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;內核中進程以 PID 作為唯一編號，與此同時，內核會建立一個 struct task_struct 對象與之關聯，在 struct task_struct 結構會保存進程對應的上下文信息。如實現 PID 信息與用户空間容器上下文的對應（進程 PID 1000 的進程屬於哪個 Pod 哪個 Container 容器實例），我們需基於內核 task_struct 結構獲取到容器相關的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過分析內核代碼和資料確認，發現可以通過 task_struct 結構中對應的 cgroup 信息獲取到進程對應的 cgroup_name 的信息，而該信息中包含了容器 ID 信息，例如&lt;strong&gt; docker-2b3b0ba12e92...983.scope &lt;/strong&gt;，完整路徑較長，使用 .... 省略。基於容器 ID 信息，我們可進一步管理到進程所歸屬的 Pod 信息，如 Pod NameSpace 、 Pod Name 、 Container Name 等元信息，最終完成進程 PID 與容器上下文信息元數據關聯。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;struct&amp;nbsp;task_struct&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;css_set&amp;nbsp;__rcu &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;*cgroups;
}


struct&amp;nbsp;css_set&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;*subsys[CGROUP_SUBSYS_COUNT];
}


struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup&amp;nbsp;*cgroup;
}


struct&amp;nbsp;cgroup&amp;nbsp;{
&amp;nbsp;&amp;nbsp;struct&amp;nbsp;kernfs_node&amp;nbsp;*kn; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;/* cgroup kernfs entry */
}


struct&amp;nbsp;kernfs_node&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; *name; &amp;nbsp;// docker-2b3b0ba12e92...983.scope
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以某容器進程為例，該進程在 Docker 容器環境中的 cgroup 路徑完整為 /sys/fs/cgroup/cpu/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podefeb3229_4ecb_413a_8715_5300a427db26.slice/docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;經驗證，我們在內核中讀取 task-&amp;gt;cgroups-&amp;gt;subsys[0]-&amp;gt;kn-&amp;gt;name 的值為 docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/92/92735ea140e6e0021584e2c7cc21b0b4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;其中容器 ID 字段為 docker- 與 .scope 間的字段信息，在 Docker 環境中一般取前 12 個字符作為短 ID，如 2b3b0ba12e92 ，可通過 docker 命令進行驗證，結果如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;docker&amp;nbsp;ps -a|grep&amp;nbsp;2b3b0ba
2b3b0ba12e92&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; registry-cn-hangzhou-vpc.ack.aliyuncs.com/acs/pause:3.5&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 上下文信息關聯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NAS 產品的訪問通過掛載命令完成本地文件路徑的掛載。我們可以通過 mount 命令將 NAS 手工掛載到本地文件系統中。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;mount&amp;nbsp;-t nfs -o vers=3,nolock,proto=tcp,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport \
&amp;nbsp;&amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test /mnt/nas&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;執行上述掛載命令成功後，通過 mount 命令則可查詢到類似的掛載記錄：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;5368 47 0:660 / /mnt/nas rw,relatime shared:1175 \
&amp;nbsp; &amp;nbsp; &amp;nbsp;- nfs 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test \ &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp;rw,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,nolock,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;noresvport,proto=tcp,timeo=600,retrans=2,sec=sys, \
&amp;nbsp; &amp;nbsp; &amp;nbsp;mountaddr=192.168.0.91,mountvers=3,mountport=2049,mountproto=tcp,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;local_lock=all,addr=192.168.0.92&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;核心信息分析如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# 掛載點，父掛載點，掛載設備號 &amp;nbsp; 目錄 &amp;nbsp; &amp;nbsp; 掛載到本機目錄 &amp;nbsp;協議 &amp;nbsp; NAS 地址
5368&amp;nbsp; &amp;nbsp; &amp;nbsp;47&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0:660&amp;nbsp; &amp;nbsp; &amp;nbsp;/ &amp;nbsp; &amp;nbsp; &amp;nbsp; /mnt/nas &amp;nbsp; &amp;nbsp; nfs &amp;nbsp; &amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;maror:minor&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;掛載記錄中的&lt;/span&gt;&lt;span style="color:#d92142"&gt;&lt;strong&gt; 0:660 &lt;/strong&gt;&lt;/span&gt;為本地設備編號，格式為 major:minor ， 0 為 major 編號， 660 為 minor 編號，系統主要以 minor 為主。在系統的 NFS 跟蹤點 nfs_initiate_read 的信息中的 dev 字段則為在掛載記錄中的 minor 編號。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;cat /sys/kernel/debug/tracing/events/nfs/nfs_initiate_read/format
format:
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:dev_t dev; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:8; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:u32 count; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:32; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過用户空間 mount 信息和跟蹤點中 dev_id 信息，則可實現內核空間設備編號與 NAS 詳情的關聯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;內核空間信息獲取&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如容器中進程針對掛載到本地的目錄 /mnt/nas 下的文件讀取時，會調用到 nfs_file_read() 和 nfs_initiate_read 函數。通過 nfs_initiate_read 跟蹤點我們可以實現進程容器信息和訪問 NFS 服務器的信息關聯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過編寫 eBPF 程序針對跟蹤點 tracepoint/nfs/nfs_initiate_read 觸發事件進行數據獲取，我們可獲取到訪問進程所對應的 cgroup_name 信息和訪問 NFS Server 在本機的設備 dev_id 編號。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="673" src="https://oscimg.oschina.net/oscnet/up-b7e2eac3eeba85b51ed94f7a84d28a096ea.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;獲取 cgroup_name 信息&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;進程容器上下文獲取：&lt;/strong&gt; 通過 cgroup_name 信息，如樣例中的 docker-2b3b0ba12e92...983.scope ，後續可以基於 container_id 查詢到容器對應的 Pod NameSpace 、 Pod Name 和 Container Name 等信息，從而定位到訪問進程關聯的 Pod 信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;NAS 上下文信息獲取：&lt;/strong&gt; 通過 dev 信息，樣例中的 660 ，通過掛載到本地的記錄，可以通過 660 查詢到對應的 NAS 產品的地址，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com 。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;用户空間元信息緩存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/aa/aa252b079e6ce3cb1e52e02ab5b4052a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在用户空間中，可以通過解析掛載記錄來獲取 DEV 信息，並將其與 NAS 信息關聯，從而建立以 DevID 為索引的查詢緩存。如此，後續便可以基於內核獲取到 dev_id 進行關聯，進一步補全 NAS 地址及相關詳細信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;對於本地容器上下文的信息獲取，最直接的方式是通過 K8s kube-apiserver 通過 list-watch 方法進行訪問。然而，這種方式會在每個節點上啓動一個客户端與 kube-apiserver 通信，顯著增加 K8s 管控面的負擔。因此，我們選擇通過本地容器引擎進行訪問，直接在本地獲取主機的容器詳情。通過解析容器註解中的 Pod 信息，可以建立容器實例緩存。後續在處理指標數據時，則可以通過 container-id 實現信息的關聯與補全。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;三、架構設計和實現&lt;/h1&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;整體架構設計&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;內核空間的信息採集採用 Linux eBPF 技術實現，這是一種安全且高效的內核數據採集方式。簡單來説，eBPF 的原理是在內核中基於事件運行用户自定義程序，並通過內置的 map 和 perf 等機制實現用户空間與內核空間之間的雙向數據交換。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NFS 和 RPC 調用事件觸發的基礎上，可以通過編寫內核空間的 eBPF 程序來獲取必要的原始信息。當用户空間程序蒐集到內核指標數據後，會對這些原始信息進行二次處理，並在用户空間的採集程序中補充容器進程信息（如 NameSpace、Pod 和 Container 名稱）以及 NFS 地址信息（包括 NFS 遠端地址）。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/c6/c687b3f4df8a2ce5d0ab5cd9f287dfd4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;內核 eBPF 程序流程&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 NFS 文件讀為例，通過編寫 eBPF 程序跟蹤 nfs_initiate_read / rpc_task_begin / rpc_task_end / nfs_page_read_done 等關鍵鏈路上的函數，用於獲取到 NFS 讀取的數據量和延時數據，並將訪問鏈路中的進程上下文等信息保存到內核中的指標緩存中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="471" src="https://oscimg.oschina.net/oscnet/up-f854a1a8cdf429eff044e715772dc96dfb6.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如上圖所示， nfs_initate_read 和 rpc_task_begin 發生在同一進程上下文中，而 rpc_task_begin 與 rpc_task_end 是異步操作，儘管兩者不處於同一進程上下文，但可以通過 task_id 進行關聯。同時， page_read_done 和 rpc_task_end 則發生在同一進程上下文中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="627" src="https://oscimg.oschina.net/oscnet/up-70f989400d6710f021cfa7577375a709030.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;nfs_initiate_read 函數調用觸發的 eBPF 代碼示例如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;

SEC("tracepoint/nfs/nfs_initiate_read")
int&amp;nbsp;tp_nfs_init_read(struct&amp;nbsp;trace_event_raw_nfs_initiate_read *ctx)
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步驟 1 獲取到 nfs 訪問的設備號信息，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com
&amp;nbsp; &amp;nbsp;&amp;nbsp;// dev_id 則為： 660&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;dev_t&amp;nbsp;dev_id =&amp;nbsp;BPF_CORE_READ(ctx, dev);
&amp;nbsp; &amp;nbsp; u64 file_id =&amp;nbsp;BPF_CORE_READ(ctx, fileid);
&amp;nbsp; &amp;nbsp; u32 count =&amp;nbsp;BPF_CORE_READ(ctx, count);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;task_struct&amp;nbsp;*task = (struct&amp;nbsp;task_struct *)bpf_get_current_task();


&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步驟 2 獲取進程上下文所在的容器 cgroup_name 信息
&amp;nbsp; &amp;nbsp;&amp;nbsp;// docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp;*cname =&amp;nbsp;BPF_CORE_READ(task, cgroups, subsys[0], cgroup, kn, name);
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(cname)
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_core_read_str(&amp;amp;info.container, MAX_PATH_LEN, cname);
&amp;nbsp; &amp;nbsp; }


&amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_map_update_elem(&amp;amp;link_begin, &amp;amp;tid, &amp;amp;info, BPF_ANY);
}


SEC("tracepoint/nfs/nfs_readpage_done")
int&amp;nbsp;tp_nfs_read_done(struct&amp;nbsp;trace_event_raw_nfs_readpage_done *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_begin")
int&amp;nbsp;tp_rpc_task_begin(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;&amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_end")
int&amp;nbsp;tp_rpc_task_done(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;用户空間程序架構&lt;/span&gt;&lt;/h2&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b9cf6d19b68dcceaa9f6f459645264baaa8.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;元數據緩存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ NAS 掛載信息緩存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過解析掛載記錄，可以獲取 DEV 信息與 NAS 信息的關聯關係。以下是實現該功能的關鍵代碼詳情：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;scanner := bufio.NewScanner(mountInfoFile)
count :=&amp;nbsp;0
for&amp;nbsp;scanner.Scan() {
&amp;nbsp; &amp;nbsp; line := scanner.Text()
&amp;nbsp; &amp;nbsp; devID,remoteDir, localDir, NASAddr = parseMountInfo(line)


&amp;nbsp; &amp;nbsp; mountInfo := MountInfo{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;DevID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; devID,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;RemoteDir: &amp;nbsp; &amp;nbsp; remoteDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;LocalMountDir: localDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NASAddr： NASAddr,
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; mountInfos =&amp;nbsp;append(mountInfos, mountInfo)

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 容器元信息緩存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過 Docker 或 Containerd 客户端，從本地讀取單機的容器實例信息，並將容器的上下文數據保存到本地緩存中，以便後續查詢使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;podInfo := PodInfo{
&amp;nbsp; &amp;nbsp; NameSpace: &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.namespace"],
&amp;nbsp; &amp;nbsp; PodName: &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.name"],
&amp;nbsp; &amp;nbsp; ContainerName: labels["io.kubernetes.container.name"],
&amp;nbsp; &amp;nbsp; UID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.uid"],
&amp;nbsp; &amp;nbsp; ContainerID: &amp;nbsp; conShortID,
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;數據處置流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;用户空間程序的主要任務是持續讀取內核 eBPF 程序生成的指標數據，並對讀取到的原始數據進行處理，提取訪問設備的 dev_id 和 container_id 。隨後，通過查詢已建立的元數據緩存，分別獲取 NAS 信息和容器 Pod 的上下文數據。最終，經過數據合併與處理，生成指標數據緩存供後續使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;func&amp;nbsp;(m *BPFEventMgr)&amp;nbsp;ProcessIOMetric() {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; events := m.ioMetricMap
&amp;nbsp; &amp;nbsp; iter := events.Iterate()


&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;iter.Next(&amp;amp;nextKey, &amp;amp;event) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ① 讀取到的 dev_id 轉化為對應的完整 NAS 信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;devId := nextKey.DevId
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;mountInfo, ok := m.mountMgr.Find(int(devId))


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ② 讀取 containerID 格式化並查詢對應的 Pod 上下文信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;containerId := getContainerID(nextKey.Container)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;podInfo, ok = m.criMgr.Find(containerId)
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ③ 基於事件信息、NAS 掛載信息和 Pod 上下文信息，生成指標數據緩存&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;metricKey, metricValue := formatMetricData(nextKey， mountInfo, podInfo)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;value, loaded := metricCache.LoadOrStore(metricKey, metricValue)
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ④ 指標數據緩存，生成最終的 Metrics 指標並更新&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;var&amp;nbsp;ioMetrics []metric.Counter
&amp;nbsp; &amp;nbsp; metricCache.Range(func(key, value&amp;nbsp;interface{})&amp;nbsp;bool&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;k := key.(metric.IOKey)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;v := value.(metric.IOValue)


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ioMetrics =&amp;nbsp;append(ioMetrics, metric.Counter{"read_count",&amp;nbsp;float64(v.ReadCount),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[]string{k.NfsServer, v.NameSpace, v.Pod, v.Container})
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&amp;nbsp;true
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; m.metricMgr.UpdateIOStat(ioMetrics)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;啓動 Goroutine 處理指標數據：通過啓動一個 Goroutine，循環讀取內核存儲的指標數據，並對數據進行處理和信息補齊，最終生成符合導出格式的 Metrics 指標。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 具體步驟&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;獲取 NAS 信息：&lt;/strong&gt;從讀取的原始數據中提取 dev_id ，並通過 dev_id 查詢掛載的 NAS 信息，例如遠端訪問地址等相關數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;查詢 Pod 上下文：&lt;/strong&gt;對 containerID 進行格式化處理，並查詢對應的容器 Pod 上下文信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成指標數據緩存：&lt;/strong&gt;基於事件數據、NAS 掛載信息和 Pod 上下文信息，生成指標數據緩存。此過程主要包括對相同容器上下文的數據進行合併和累加。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;導出 Metrics 指標：&lt;/strong&gt;根據指標數據緩存，生成最終的 Metrics 指標，並更新到指標管理器。隨後，通過自定義的 Collector 接口對外導出數據。當 Prometheus 拉取數據時，指標會被轉換為最終的 Metrics 格式。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過上述步驟，用户空間能夠高效地處理內核 eBPF 程序生成的原始數據，並結合 NAS 掛載信息和容器上下文信息，生成符合 Prometheus 標準的 Metrics 指標，為後續的監控和分析提供了可靠的數據基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自定義指標導出器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在導出指標的場景中，我們需要基於保存在 Go 語言中的 map 結構中的動態數據實時生成，因此需要實現自定義的 Collector 接口。自定義 Collector 接口需要實現元數據描述函數 Describe() 和指標蒐集的函數 Collect() ，其中 Collect() 函數可以併發拉取，因此需要通過加鎖實現線程安全。該接口需要實現以下兩個核心函數：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Describe() ：用於定義指標的元數據描述，向 Prometheus 註冊指標的基本信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Collect() ：用於蒐集指標數據，該函數支持併發拉取，因此需要通過加鎖機制確保線程安全。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;type&amp;nbsp;Collector&amp;nbsp;interface&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 指標的定義描述符
&amp;nbsp; &amp;nbsp; Describe(chan&amp;lt;- *Desc)
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 並將收集的數據傳遞到 Channel 中返回
&amp;nbsp; &amp;nbsp; Collect(chan&amp;lt;- Metric)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;我們在指標管理器中實現 Collector 接口， 部分實現代碼，如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;nfsIOMetric := prometheus.NewDesc(
&amp;nbsp; &amp;nbsp; prometheus.BuildFQName(prometheusNamespace,&amp;nbsp;"",&amp;nbsp;"io_metric"),
&amp;nbsp; &amp;nbsp;&amp;nbsp;"nfs io metrics by cgroup",
&amp;nbsp; &amp;nbsp; []string{"nfs_server",&amp;nbsp;"ns",&amp;nbsp;"pod",&amp;nbsp;"container",&amp;nbsp;"op",&amp;nbsp;"type"},
&amp;nbsp; &amp;nbsp;&amp;nbsp;nil,
)


// Describe and Collect implement prometheus collect interface
func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Describe(ch&amp;nbsp;chan&amp;lt;- *prometheus.Desc) {
&amp;nbsp; &amp;nbsp; ch &amp;lt;- m.nfsIOMetric
}


func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Collect(ch&amp;nbsp;chan&amp;lt;- prometheus.Metric) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// Note：加鎖保障線程併發安全
&amp;nbsp; &amp;nbsp; m.activeMutex.Lock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;defer&amp;nbsp;m.activeMutex.Unlock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;_, v :=&amp;nbsp;range&amp;nbsp;m.ioMetricCounters {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ch &amp;lt;- prometheus.MustNewConstMetric(m.nfsIOMetric, prometheus.GaugeValue, v.Count, v.Labels...)
&amp;nbsp; &amp;nbsp; }

&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;四、總結&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;當前 NAS 溯源能力已正式上線，以下是主要功能和視圖介紹：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 單 NAS 實例整體趨勢&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;支持基於環境和 NAS 訪問地址過濾，展示 NAS 產品的讀寫 IOPS 和吞吐趨勢圖。同時，基於內核空間統計的延時數據，提供 P95 讀寫延時指標，用於判斷讀寫延時情況，輔助問題分析和定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/14/14577d6fe8b2876ca7f5138680fc3667.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/9c/9c091aeaecc284956b851416de5d313a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NAS 流量溯源方面，我們結合業務場景設計了基於任務和 Pod 實例維度的流量分析視圖：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 任務維度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過聚合具有共同屬性的一組 Pod 實例，展示任務級別的整體流量情況。該視圖支持快速定位任務級別的流量分佈，幫助用户進行流量溯源和多任務錯峯使用的依據。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/0a/0a504606b05345b52061d2f754c15b51.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Pod 實例維度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 Pod 為單位進行流量分析和彙總，提供 Pod NameSpace 和 Name 信息，支持快速定位和分析實例級別的流量趨勢，幫助細粒度監控和異常流量的精準定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/90/90765c51493906beaf530c64494abc6a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在整體能力建設完成後，我們成功構建了 NAS 實例級別的 IOPS、吞吐和讀寫延時數據監控大盤。通過該能力，進一步實現了 NAS 實例的 IOPS 和吞吐可以快速溯源到任務級別和 Pod 實例級別，流量溯源時效從小時級別縮短至分鐘級別，有效提升了異常問題定位與解決的效率。同時，基於任務流量視圖，我們為後續帶寬錯峯複用提供了直觀的數據支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;1.&lt;/span&gt;正品庫拍照 PWA 應用的實現與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;2.&lt;/span&gt;匯金資損防控體系建設及實踐 | 得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;3.&lt;/span&gt;一致性框架：供應鏈分佈式事務問題解決方案｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;4.&lt;/span&gt;得物社區活動：組件化的演進與實踐&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;5.&lt;/span&gt;從 CPU 冒煙到絲滑體驗：算法 SRE 性能優化實戰全揭秘｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;文 / 泊明&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;關注得物技術，每週更新技術乾貨&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18683994</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18683994</guid>
      <pubDate>Wed, 16 Jul 2025 07:35:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>英偉達開源 Llama-3.3-Nemotron-Super-49B-v1.5 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;英偉達發佈了 Llama-3.3-Nemotron-Super-49B-v1.5，這是一款專為推理和 Agentic 任務優化的開源模型，在單個 H100 GPU 上實現高吞吐量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1eb8efcbf4188aaa81c53fbda0c23259d86.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型介紹&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Llama Nemotron Super v1.5 是 Llama-3.3-Nemotron-Super-49B-V1.5 的簡稱。它是 Llama-3.3-Nemotron-Super-49B-V1 的升級版本（該模型是 Meta 的 Llama-3.3-70B-Instruct 的衍生模型），專為複雜推理和智能體任務設計，支持 128K tokens 的上下文長度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型架構&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Llama Nemotron Super v1.5 採用神經架構搜索（Neural Architecture Search，NAS），使該模型在準確率和效率之間實現了良好的平衡，將吞吐量的提升有效轉化為更低的運行成本。&lt;/p&gt; 
&lt;p&gt;（注：NAS 的目標是通過搜索算法從大量的可能架構中找到最優的神經網絡結構，利用自動化方法替代人工設計神經網絡架構，從而提高模型的性能和效率。）&lt;/p&gt; 
&lt;p&gt;模型經過了多階段後訓練，包括針對數學、代碼、科學和工具調用的監督微調 (SFT)，以及用於聊天對齊的獎勵感知偏好優化 (RPO)、用於推理的帶可驗證獎勵的強化學習 (RLVR) 和用於工具調用能力增強的迭代直接偏好優化 (DPO)。&lt;/p&gt; 
&lt;p&gt;在多個基準測試中，該模型表現出色。例如，在 MATH500 上 pass@1 達到 97.4，在 AIME 2024 上達到 87.5，在 GPQA 上達到 71.97。模型支持 Reasoning On/Off 模式，用户可通過在系統提示中設置 /no_think 來關閉推理模式。官方推薦在推理開啓時使用 temperature=0.6 和 Top P=0.95，在關閉時使用貪心解碼。&lt;/p&gt; 
&lt;p&gt;該模型已準備好用於商業用途，遵循 NVIDIA Open Model License 和 Llama 3.3 社區許可協議。開發者可以通過 NVIDIA build.nvidia.com 或 Hugging Face 下載和試用該模型，並可使用 vLLM（推薦 v0.9.2）進行部署，官方倉庫中提供了支持工具調用的解析器插件。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362966</guid>
      <pubDate>Wed, 16 Jul 2025 07:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Julius AI 完成 1000 萬美元種子輪融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自稱為「AI 數據分析師」的初創公司 Julius AI 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjulius.ai%2Farticles%2Ffunding-announcement" target="_blank"&gt;宣佈&lt;/a&gt;，已成功完成 1000 萬美元種子輪融資，本輪融資由知名風投機構 Bessemer Venture Partners 領投。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此輪融資吸引了眾多知名投資者參與，包括 Horizon VC、8VC、Y Combinator、AI Grant 加速器，以及 Perplexity 首席執行官 Aravind Srinivas、Vercel 首席執行官 Guillermo Rauch 和 Twilio 聯合創始人 Jeff Lawson 等多位知名天使投資人。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="265" src="https://oscimg.oschina.net/oscnet/up-fa76ef8ea19caf7593f5d21fe0c268005aa.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Julius AI 由創始人 Rahul Sonwalkar 於 2022 年從 Y Combinator 畢業後創立。Sonwalkar 在加速器期間曾創立一家物流初創公司，但最終選擇放棄並全身心投入到 Julius AI 的開發中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Julius AI 旨在像數據科學家一樣，通過分析和可視化海量數據集，並根據自然語言提示進行預測建模。儘管其功能與 ChatGPT、Anthropic 的 Claude 和谷歌的 Gemini 等基礎模型公司有所類似，但 Julius AI 成功開闢了自己的市場。公司透露，目前已擁有超過 200 萬用户，並生成了超過 1000 萬份可視化作品。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Rahul Sonwalkar 在接受 TechCrunch 採訪時表示：「使用 Julius 最簡單的方法就是跟它對話。你可以像跟團隊分析師對話一樣跟 AI 對話，然後 AI 會像人類一樣，為你運行代碼並進行分析。」&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;去年，Julius 在數據科學領域的專業能力甚至引起了哈佛商學院 （HBS） 教授 Iavor Bojinov 的關注。Bojinov 對 Julius 印象深刻，並邀請 Sonwalkar 專門修改其設計，以適應哈佛商學院的新必修課程——「領導者的數據科學與人工智能」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362957</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362957</guid>
      <pubDate>Wed, 16 Jul 2025 07:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 出現大範圍服務中斷：目前已全部恢復，影響超 8 小時</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;代碼託管平台 GitHub 從 2025 年 7 月 28 日 16:50 UTC（北京時間 7 月 29 日 00:50）起突發&lt;strong&gt;大規模服務中斷&lt;/strong&gt;，受影響服務包括 Git 操作、API 請求、Pull 請求和 Issues 跟蹤等核心功能 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/150643_ZtSu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;儘管 GitHub 工程團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.githubstatus.com%2Fincidents%2Fs6d4x8c6cvv5" target="_blank"&gt;嘗試了多種修復措施&lt;/a&gt;（如增設服務器容量、調整限流措施），初期效果不佳，直到北京時間 &lt;strong&gt;7 月 29 日 9:23 左右&lt;/strong&gt; 才取得實質性進展。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1416" src="https://static.oschina.net/uploads/space/2025/0729/150606_wHAe_2720166.png" width="1890" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最終，相關問題已逐步解決，截至目前，API 請求、Pull 請求等服務已全面恢復，整體中斷時間超過 &lt;strong&gt;8 小時&lt;/strong&gt;。GitHub 官方表示正在深入調查具體原因，後續將發佈詳細技術分析報告。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.githubstatus.com/history&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362956</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362956</guid>
      <pubDate>Wed, 16 Jul 2025 07:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中國移動「九天」3.0 發佈，多項核心技術同步開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;中國移動發佈了其自主研發的 「九天」基礎大模型 3.0。根據介紹，「九天眾擎語言大模型」實現了架構上的突破性創新，採用可擴展至萬億級的&amp;nbsp;&lt;strong&gt;MoE 架構&lt;/strong&gt;。通過 15T token 的多階段配比預訓練數據與全流程治理體系，其推理能力得到顯著強化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該模型還創新構建了 113 域 ×53 能力的二維分級後訓練框架，結合動態強化學習策略，使複雜推理能力提升了&amp;nbsp;&lt;strong&gt;35%&lt;/strong&gt;。測評結果顯示，「九天」語言大模型：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;GPQA-Diamond&lt;/strong&gt;&amp;nbsp;評測中，以&amp;nbsp;&lt;strong&gt;77.67 分&lt;/strong&gt;斬獲全球第二，超越 DeepSeekR1 和 Qwen3。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;ArenaHard V1.0&lt;/strong&gt;&amp;nbsp;中，以&amp;nbsp;&lt;strong&gt;67.2 分&lt;/strong&gt;位居全球第一。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;BFCL V3&lt;/strong&gt;&amp;nbsp;評測中，達到&amp;nbsp;&lt;strong&gt;68 分&lt;/strong&gt;。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在性能大幅躍升的同時，模型進一步強化了可控生成能力，通過精確流程內置等技術細節，實現了專業場景下的&lt;strong&gt;零幻覺&lt;/strong&gt;，破解了沉浸式角色演繹難題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基於最新的語言大模型，中國移動還同步推出了多個專項模型:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;九天代碼大模型：&lt;/strong&gt;採用兩階段持續訓練技術，支持代碼生成、註釋生成、單元測試生成、代碼智能問答等任務，覆蓋 Python、Java、JS、TS、Go、C++ 等 10 餘種主流編程語言。在 EvalPlus、MHPP、LivecodeBenchv6 等多個代碼生成榜單上表現領先。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;九天數學大模型：&lt;/strong&gt;在短思考、長思考模式下均達到業界 SOTA 水平，多項指標超越 Qwen2.5Math、Qwen3、DeepSeek Math、DeepSeek R1-Distill 等同參數量級模型。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「九天善智多模態大模型」引入複雜時空建模、流匹配圖片視頻漸進式聯合訓練、端到端局部可控注意力機制等創新技術。同時，通過融合多模態理解信息和聯合圖文交織數據訓練，顯著提升了模型對文本指令和輸入條件圖像視頻的感知能力。這意味着模型不僅能生成高質量的圖像視頻，還能進行多輪對話式高可控精確編輯操作，大幅提升了視覺生成的靈活便利性。例如，在圖片生成方面可支持多輪精準局部修改，如修改文字、修改背景、增加元素等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;模型的圖理解和視頻理解性能也得到了全面提升：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖理解方面：&lt;/strong&gt;在 MMStar、HallusionBench 和 OCRBench 等圖理解任務中，九天模型分別獲得了&amp;nbsp;&lt;strong&gt;82.2、64.3 和 94.9 的高分&lt;/strong&gt;，處於業界領先水平。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;視頻理解方面：&lt;/strong&gt;在 Videomme 和 MVbench 兩個任務中均表現領先，超越 Qwen2-VL 和 InternVideo2。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;目前，中國移動已將多項模型及核心技術進行開源：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;開源九天數童結構化數據大模型&lt;/strong&gt;：包括 JT-DA-8B 模型及後續演進版本，支持下載模型權重、微調代碼、推理代碼等。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;開源九天數學大模型&lt;/strong&gt;：包括 JT-Math-8B 系列模型，支持下載模型權重、推理代碼、技術報告。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;開源九天代碼大模型&lt;/strong&gt;：包括 JT-Coder-8B 系列模型，支持下載模型權重、推理代碼、技術報告。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;開源業界首創的結構化數據模型評測數據及 TReB 評測體系&lt;/strong&gt;：涵蓋 6 大任務、34 個能力，包括高質量、全面的數據、推理模式及評價指標，支持下載評測數據集、測試代碼。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;開源 CCR-Bench 行業場景複雜指令遵循評測數據集&lt;/strong&gt;：包含 174 條高質量、多樣化、高難度複雜指令數據，高度模擬健康專家、智能客服、醫療助手等典型工業場景，支持下載數據集。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362949</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362949</guid>
      <pubDate>Wed, 16 Jul 2025 06:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>特斯拉與三星簽訂 165 億美元 AI 芯片製造協議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 28 日，三星電子在提交給監管機構的文件中表示，三星電子與一家全球大型公司簽署了價值 22.8 萬億韓元（注：現匯率約合 1181.72 億元人民幣，約合 165 億美元）的芯片製造協議，但未透露具體客户名稱。&lt;/p&gt; 
&lt;p&gt;據消息人士透露，特斯拉正是這家客户，該公司目前與三星的合同芯片製造部門已有業務往來。&lt;/p&gt; 
&lt;p&gt;有外媒表示，三星電子公司將就新達成的 165 億美元協議，為特斯拉公司生產半導體，這將為其表現不佳的晶圓代工部門提供助力。該合作的合同期 2025 年 7 月 24 日-2033 年 12 月 31 日。&lt;/p&gt; 
&lt;p&gt;對此，特斯拉 CEO 埃隆・馬斯克確認了合作爆料，三星在美國得克薩斯州新建的巨型工廠將專門用於生產特斯拉的下一代 AI6 芯片（注：特斯拉汽車智駕芯片），並稱「其戰略重要性毋庸置疑」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99e430011e2ff79c31d84adca382c598c73.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;馬斯克還稱，三星目前正在生產 AI4 芯片。台積電將首先在中國台灣地區生產剛剛完成設計的 AI5 芯片，然後在美國亞利桑那州生產。&lt;/p&gt; 
&lt;p&gt;根據外媒今年 6 月報道，台積電在全球第三方晶圓代工市場的市佔比為 67%，而排名第二的三星則僅佔 11%。另外，有消息人士稱，三星電子 2025 上半年晶圓代工部門獲零獎金。此前，外媒援引供應鏈消息稱，三星已啓動「精選和聚焦」戰略，集中資源提升 2nm 工藝良率，希望通過產量和成本優勢來挑戰台積電。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362947</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362947</guid>
      <pubDate>Wed, 16 Jul 2025 06:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>端側原生大模型 SmallThinker 正式開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;上海交通大學 IPADS 研究所、上海交通大學人工智能學院聯合初創公司本智激活（Zenergize AI），發佈了開源端側原生大模型 SmallThinker。&lt;/p&gt; 
&lt;p&gt;該系列模型採用為端側算力、內存、存儲特性而原生設計的模型架構，並從零開始預訓練，具體包含兩個尺寸的稀疏模型，分別是 SmallThinker-4B-A0.6B 和 SmallThinker-21B-A3B。&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt; 
&lt;p&gt;SmallThinker 專為低成本硬件設計，可在百元級國產開發板（如瑞芯微 RK3588）上流暢運行百億參數模型，旨在為資源受限的個人設備帶來強大、私密且低延遲的 AI 能力，無需依賴雲端。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1578" src="https://static.oschina.net/uploads/space/2025/0729/143436_ewWq_2720166.png" width="2044" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以通過 Transformers（版本需 &amp;gt;= 4.53.3）或 ModelScope 來運行該模型。官方 GitHub 倉庫提供了詳細的設置、模型轉換和運行指南。官方提示，模型使用了稀疏的 lm_head，可能會導致一定的精度損失，但用户可以手動修改代碼禁用此特性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct&lt;/li&gt; 
 &lt;li&gt;https://github.com/SJTU-IPADS/PowerInfer/tree/main/smallthinker&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362945</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362945</guid>
      <pubDate>Wed, 16 Jul 2025 06:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：AnyShake Project 開源地震監測系統</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2112</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2112</guid>
      <pubDate>Wed, 16 Jul 2025 06:18:00 GMT</pubDate>
    </item>
  </channel>
</rss>
