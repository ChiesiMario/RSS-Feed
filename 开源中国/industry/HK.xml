<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 18 Sep 2025 12:43:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>法國 AI 公司 H Company 開源 Holo1.5 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;法國 AI 公司 H Company 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.hcompany.ai%2Fblog%2Fholo-1-5" target="_blank"&gt;發佈並開源&lt;/a&gt;了 Holo1.5 系列視覺語言模型，該系列專為 Computer Use (CU) Agent 設計。&lt;/p&gt; 
&lt;p&gt;新系列在 UI 元素定位與界面問答任務上全面超越了前代 Holo1，平均準確率提升超過 10%，並在 Web、桌面、移動跨平台基準測試中刷新了開源模型的紀錄。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-219e3deebf5dcddb8a7f01c5f6247a79289.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0fd9afd5fa18f87cdbae72ae07c86ca4b28.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Holo1.5 基於 Qwen2.5-VL 基座模型，採用高分辨率原生輸入（最高支持 3840×2160），通過大規模監督微調與在線強化學習（GRPO）兩階段進行訓練，融合了開源數據、合成數據與人工標註數據。&lt;/p&gt; 
&lt;p&gt;該系列提供了三種不同規模的模型，並採用不同的開源許可：&lt;/p&gt; 
&lt;p&gt;模型規模&amp;nbsp;&amp;nbsp; &amp;nbsp;開源許可&amp;nbsp;&amp;nbsp; &amp;nbsp;商業用途&lt;br&gt; 3B&amp;nbsp;&amp;nbsp; &amp;nbsp;Qwen 許可&amp;nbsp;&amp;nbsp; &amp;nbsp;遵循原許可&lt;br&gt; 7B&amp;nbsp;&amp;nbsp; &amp;nbsp;Apache 2.0&amp;nbsp;&amp;nbsp; &amp;nbsp;完全開放&lt;br&gt; 72B&amp;nbsp;&amp;nbsp; &amp;nbsp;僅限學術研究&amp;nbsp;&amp;nbsp; &amp;nbsp;需單獨授權&lt;/p&gt; 
&lt;p&gt;目前，模型已上線 HuggingFace，提供了開放權重、演示空間與本地推理腳本，支持開發者構建能夠操縱真實應用的 CU Agent。H Company 表示，未來數週還將發佈基於 Holo 系列的新工具與完整的 Agent 方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373033</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373033</guid>
      <pubDate>Thu, 18 Sep 2025 11:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>《Anthropic 經濟指數》報告發布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fresearch%2Feconomic-index-geography" target="_blank"&gt;發佈&lt;/a&gt;了《Anthropic Economic Index》報告，首次披露了美國及全球 AI 使用的地理圖譜。該報告基於 2024 年 12 月至 2025 年 8 月期間 Claude.ai 的匿名對話與 API 調用記錄，並同步上線了交互式數據網站與開放數據集。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-71f68a68f3af83a15c28e454af5f36a1ea8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;報告顯示，AI 的使用在地域、行業和模式上存在明顯差異。計算機與數學任務仍佔據核心地位（37–40%），教育與科研類任務顯著增長，而管理運營類任務則有所下降。&lt;/p&gt; 
&lt;p&gt;值得注意的是，自動化對話的佔比首次超過了增強協作（49.1% vs 47%），其中企業用户更傾向於自動化（77%），而消費者則維持均衡。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-26aabfe98a2ed7cc7ad59939d8557ae367f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;研究還發現，高收入和知識密集型地區更早採用 AI。企業更看重 AI 能力帶來的價值而非成本，這預示着勞動力市場可能將迎來深度調整。&lt;/p&gt; 
&lt;p&gt;報告附帶的開放數據與交互網站可供公眾查詢使用：&lt;em&gt;https://huggingface.co/datasets/Anthropic/EconomicIndex&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373030/anthropic-economic-index-geography</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373030/anthropic-economic-index-geography</guid>
      <pubDate>Thu, 18 Sep 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>法國 AI 公司 Mistral 開源推理模型 Magistral Small 1.2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;法國 AI 公司&amp;nbsp;Mistral AI&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmistralai%2FMagistral-Small-2509" target="_blank"&gt;&amp;nbsp;推出&lt;/a&gt;了 Magistral 系列最新的開源推理模型 Magistral Small 1.2。該模型擁有 24B 參數，採用 Apache 2.0 許可，支持 128k 上下文、多語言及視覺輸入，並引入了創新的 [THINK]...[/THINK] 特殊 token 以包裹推理過程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0918/191800_wOvi_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相比 1.1 版，新版本增加了視覺編碼器，並引入了 [THINK]...[/THINK] 特殊 token 來包裹模型的推理過程。系統提示中內置了推理模板，支持 vLLM、Transformers、llama.cpp 等框架即開即用，同時提供了 GGUF 量化版本與 Unsloth 微調示例。&lt;/p&gt; 
&lt;p&gt;企業版 Magistral Medium 1.2 也同步升級，繼續通過 Le Chat 提供對話服務，其 API 已上線 La Plateforme 平台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373029</guid>
      <pubDate>Thu, 18 Sep 2025 11:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手旗下可靈 AI 數字人上線公測</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手旗下可靈 AI 數字人已於近日上線公測。該功能通過多模態技術，實現了從「對口型」到「會表演」的突破，支持用户上傳圖片或音頻，生成 1080p/48fps、最長 1 分鐘的數字人視頻，具備精準口型同步、情緒動作控制、多角色同屏等功能，且支持中、英、日、韓等多語種。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-07ea3d588b535e3ffb9b60946dce753e6fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可通過可靈 AI 官網（https://app.klingai.com/cn/）體驗，目前處於逐步放量階段。&lt;/p&gt; 
&lt;p&gt;據瞭解，可靈 AI 數字人基於多模態理解與視頻生成模型的深度結合，實現了口型精準同步以及情緒動作的精細控制。其採用的基於 Transformer 的 DiT 架構，在處理時序信息和細粒度控制方面具有獨特優勢，能夠精準解析面部特徵、理解音頻語義，並根據語音內容推斷合適的面部表情和微動作，從而確保生成的數字人在視頻全程保持角色一致性。&lt;/p&gt; 
&lt;p&gt;在角色和語言支持方面，可靈 AI 數字人功能表現出色。其支持多種角色類型，包括真人、動畫角色甚至動物形象，同時涵蓋中、英、日、韓等多語種，能夠滿足不同用户的多樣化需求。在價格策略上，結合會員優惠，可靈 AI 數字人的使用成本最低為 0.12 元 / 秒。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373025</guid>
      <pubDate>Thu, 18 Sep 2025 11:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 Visual Studio Code 引入自動 AI 模型選擇功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟正在為其 Visual Studio Code 編輯器引入自動 AI 模型選擇功能，將根據「最佳性能」自動挑選 AI 模型。&lt;/p&gt; 
&lt;p&gt;此功能會在 GitHub Copilot 免費用户之間切換 Claude Sonnet 4、GPT-5、GPT-5 mini 及其他模型，而付費用户則「主要依賴 Claude Sonnet 4」模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fb40cb72cb7f78b338a2a8465189b5e88b5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這一變化實際上表明，微軟在編程和開發領域比起 OpenAI 最新的 GPT-5 模型，更傾向於使用 Anthropic 的 AI 模型。據熟悉微軟開發業務的消息人士透露，微軟近幾個月來也在內部要求開發人員優先使用 Claude Sonnet 4。&lt;/p&gt; 
&lt;p&gt;微軟開發者事業部負責人 Julia Liuson 在今年 6 月的一封內部郵件中曾表示：「根據內部基準測試，Claude Sonnet 4 是我們為 GitHub Copilot 推薦的模型。」而這一指導意見是在 GPT-5 發佈之前提出的，據悉，目前微軟對此的推薦依然沒有改變。&lt;/p&gt; 
&lt;p&gt;微軟方面還表示，公司正對自家 AI 模型的訓練進行「重大投入」。微軟 AI 業務負責人 Mustafa Suleyman 在上週的一場員工專屬會議上提到：「我們也將在自有集羣上做重大投資。目前 MAI-1-preview 僅使用了 1.5 萬張 H100 顯卡進行訓練，從整體規模看還非常小。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373021</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373021</guid>
      <pubDate>Thu, 18 Sep 2025 10:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>發展大模型要摒棄短視冒進</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;一段時間以來，關於 DeepSeek 的消息層出不窮，下載量大跌、用户規模縮減……引發社會上一些對其發展前景和技術路線的質疑。然而，這背後折射出的是對大模型發展規律認知的偏差。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在人工智能時代，大模型的價值絕非簡單以使用率和流量來評判，而是依託於技術沉澱的厚度以及生態協作的深度，對技術的極致追求與秉持戰略耐心，才是立足大模型時代的關鍵所在。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從「流量為王」到「技術制勝」，人工智能時代的邏輯已發生轉變。互聯網時代的產品競爭遵循「快魚吃慢魚」法則——由於技術代差較小，搶佔用户注意力、積累流量池成為決勝關鍵，「使用率」標準應運而生。就像一款社交軟件可能憑藉界面優化或運營活動在短時間內吸引百萬用户，即便功能尚未完善，也能通過快速迭代留住他們。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;但大模型競爭截然不同。這是硬科技的角力場，技術指標和模型性能是實打實的，即使用户數多，如果性能不過硬，也會在技術競爭浪潮中掉隊。以 DeepSeek-R1 為例，其發佈之初使用率的飆增，根源在於算法架構的創新與訓練數據的深度優化，而非依賴用户規模。大模型的價值如同精密儀器，參數精度、響應速度、多模態能力等硬指標才是衡量其競爭力的核心要素。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從「流量壟斷」到「生態賦能」，底層思維也有了變化。當人們將目光聚焦使用率時，卻忽視了其作為 AI 應用底層生態的深遠戰略價值。如今，阿里雲、騰訊雲等雲服務商，諸多搜索平台、智能終端以及行業應用，還有廣大用户羣體，都不同程度接入 DeepSeek，形成龐大生態網絡。這得益於 DeepSeek 開放 API 接口與訓練框架，不搞流量分成或數據壟斷，讓開發者能快速構建垂直領域應用，實現多方共贏，眾多 AI 應用也得以大量湧現，走進各行各業。本質上，DeepSeek 打造的是人工智能時代的「高速公路」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從「單點突破」到「系統攻堅」，大模型跨越式發展的條件正日趨成熟。DeepSeek-R2 醖釀之際，其團隊已在論文中闡述下一代人工智能系統的創新藍圖——「模型+硬件」的協同優化設計，意味着大模型發展不再單純依靠算力堆砌或算法單一創新，而是軟硬件並行研發的「集團軍作戰」。當下，像華為昇騰 384 超節點、上海 AILab 系統平台的相關突破，都為大模型新發展築牢了基礎，也讓我們堅信下一代人工智能系統的推出只是時間問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;互聯網思維碰上人工智能時代，「流量焦慮」「爆款心態」已成創新枷鎖。在這個算力成本高昂、技術迭代迅速、計算量極大的時代，急功近利的冒進易引發系統性風險。唯有摒棄短視觀念，專注技術深耕與生態共建，才能在這場關乎國家競爭力的科技競賽中取得最終勝利。（經濟日報，鍾梓濱）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373019</guid>
      <pubDate>Thu, 18 Sep 2025 10:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華為公佈昇騰 AI 芯片三年發展路線圖，明年 Q1 推出 Ascend 950PR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在華為全聯接大會 2025 上，華為副董事長、輪值董事長徐直軍登台發表演講，首次對外公佈了昇騰 AI 芯片未來三年的產品迭代路線圖，同時明確表示 2026 年一季度發佈的新產品將採用華為自研 HBM（高帶寬內存）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/182257_S72G_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時他還分享了昇騰芯片的後續規劃：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ascend 950PR：2026 年 Q1&lt;/li&gt; 
 &lt;li&gt;Ascend 950DT：2026 年 Q4&lt;/li&gt; 
 &lt;li&gt;Ascend 960：2027 年 Q4&lt;/li&gt; 
 &lt;li&gt;Ascend 970：2028 年 Q4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其中，950 芯片採用華為自研 HBM，新增支持低精度數據格式、提升向量算力、提升互聯帶寬 2.5 倍。&lt;/p&gt; 
&lt;p&gt;據報道，華為 Ascend 910C 在今年一季度量產，將兩顆昇騰 910B 芯片通過先進封裝技術整合在一起，採用相對成熟的封裝方案，在性能和成本間做了平衡。其 FP16 精度算力約 800 TFLOPS，內存帶寬約 3.2 TB/s，性能大概能達到 NVIDIA H100 的 80%。&lt;/p&gt; 
&lt;p&gt;據悉，阿里巴巴、百度、騰訊等互聯網巨頭都是 Ascend 910C 的首批客户，他們過往都採購了大量的 NVIDIA GPU 加速器，華為昇騰對 NVIDIA 造成了巨大沖擊。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373016</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373016</guid>
      <pubDate>Thu, 18 Sep 2025 10:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Brush - 人人皆可進行 3D 重建</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 是一個使用高斯分佈的 3D 重建引擎。它適用於多種系統：macOS/windows/linux、AMD/Nvidia/Intel 顯卡、Android 以及瀏覽器。為此，它使用了 WebGPU 兼容技術和&amp;nbsp;&lt;a href="https://github.com/tracel-ai/burn"&gt;Burn&lt;/a&gt;&amp;nbsp;機器學習框架。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;機器學習在實時渲染方面潛力巨大，但大多數機器學習工具都無法很好地支持它：渲染需要實時交互，通常涉及動態形狀和計算，無法在大多數平台上運行，而且發佈包含大量 CUDA 依賴的應用程序會非常繁瑣。而 Brush 則能生成簡單的無依賴二進制文件，幾乎可以在所有設備上運行，無需任何設置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://arthurbrussee.github.io/brush-demo"&gt;試用網頁演示版&amp;nbsp;&lt;/a&gt;（注意：僅適用於 Chrome 和 Edge。）&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 接收 COLMAP 數據或 Nerfstudio 格式的數據集。訓練在移動設備和瀏覽器中均得到原生支持。訓練期間，您可以與場景互動，實時查看訓練動態，並在訓練過程中將當前渲染與輸入視圖進行比較。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;它還支持遮罩圖像：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;具有透明度的圖像。這將強制最終的 splat 與輸入的透明度匹配。&lt;/li&gt;
&lt;li&gt;一個名為「masks」的圖像文件夾。這會忽略圖像中被遮罩的部分。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 也可用作 splat &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;viewer&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，包括在 Web 上。它可以加載 .ply 和 .compressed.ply 文件。您可以從 URL 中流式傳輸數據（對於 Web 應用，只需在 URL 後附加&lt;code&gt;?url=&lt;/code&gt;）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 還可以加載 splat 文件的 .zip 以將其顯示為動畫，或包含增量幀的特殊層（參見&lt;a href="https://cat-4d.github.io/"&gt;cat-4D&lt;/a&gt;和&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://felixtaubner.github.io/cap4d/"&gt;Cap4D&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;!&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Brush 可以用作命令行界面 (CLI)。運行&lt;code&gt;brush --help&lt;/code&gt;即可查看概覽。所有命令行命令均可配合&lt;code&gt;--with-viewer&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用，並可打開用户界面 (UI)，方便調試。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/brush</link>
      <guid isPermaLink="false">https://www.oschina.net/p/brush</guid>
      <pubDate>Thu, 18 Sep 2025 10:08:00 GMT</pubDate>
    </item>
    <item>
      <title>用 Python 代碼給微信「去重瘦身」？工程師回應：非常粗暴，可能導致文件打不開</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日有網友分享了一段能幫助微信「去重瘦身」的 Python 代碼，專門針對微信「每一次轉發都會重新保存一份」的情況，刪除重複的文件，稱能搞定微信這個易胖體質。&lt;/p&gt; 
&lt;p&gt;微信員工 @客村小蔣，今日轉發了該消息，並表示「非常不建議這麼做，沒用，而且可能帶來不好的後果」。&lt;/p&gt; 
&lt;p&gt;1）微信並沒有對多次轉發的同一個文件重複存儲，電腦裏看到的同文件名加 (1)、(2)，是硬鏈接，實際只有一份真實存儲；&lt;/p&gt; 
&lt;p&gt;2）這裏的代碼，是通過名字重複來判斷，非常粗暴，刪除之後，可能導致原來消息打不開，還存在誤刪可能性&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-19b42cb87229a8efd6ceef9f6b84997cea4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373013</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373013</guid>
      <pubDate>Thu, 18 Sep 2025 10:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度 PaddleOCR 累計下載量突破 900 萬，被超 5.9k 開源項目使用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日，百度在海外官方賬號介紹了最新輕量級文字識別模型 PP-OCRv5。該模型僅 0.07B 參數，以千分之一參數量實現與 700 億參數大模型相媲美的 OCR 精度。在多項 OCR 場景測試中，PP-OCRv5 的表現超越 GPT-4o、Qwen2.5-VL-72B 等通用視覺大模型。最新信息顯示，飛槳團隊發佈的技術 Blog 已連續一週登頂 Hugging Face 博客熱度榜首，受到開發者社區的廣泛關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;img height="1576" src="https://static.oschina.net/uploads/space/2025/0918/173354_EC7R_3820517.png" width="1580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;據瞭解，2025 年 5 月，飛槳團隊推出 PaddleOCR 3.0 版本，文字識別方案 PP-OCRv5 與通用文檔解析方案 PP-StructureV3，以及原生支持文心大模型 4.5 的智能文檔理解方案 PP-ChatOCRv4 共同構成其三大特色能力。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;自 2020 年開源以來，PaddleOCR 累計下載量突破 900 萬，被超過 5.9k 開源項目直接或間接使用，是 GitHub 社區中唯一一個 Star 數超過 50k 的中國 OCR 項目。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;img height="998" src="https://static.oschina.net/uploads/space/2025/0918/173417_2NkS_3820517.png" width="1516" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373008/paddleocr-news-59k-star</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373008/paddleocr-news-59k-star</guid>
      <pubDate>Thu, 18 Sep 2025 09:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>中文互聯網基礎語料 3.0 發佈，數據量高達 120GB</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中文互聯網基礎語料 3.0 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcorpus.cybersac.cn%2F%3Fhome%23%2FdataSetDetail%3FdataSetId%3D399" target="_blank"&gt;發佈&lt;/a&gt;。這一新版本的數據量達到了驚人的 120GB，旨在為大模型訓練和人工智能的進一步發展提供可靠的數據支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中文互聯網基礎語料 3.0 的發佈，是在中央網信辦的指導下，由中國網絡空間安全協會與國家互聯網應急中心等單位協同合作的成果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="217" src="https://oscimg.oschina.net/oscnet/up-54c09b578c1c75e35f0d48e63448b668c10.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此次語料的開發與構建，得益於企業、高校和科研單位之間的緊密合作，充分利用了網安協會人工智能安全治理專委會建立的語料共建共享機制。與前兩版相比，3.0 版本在信源範圍上進行了擴大，進一步提升了數據的質量。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在數據處理方面，語料 3.0 經過了嚴格的信源篩選、內容過濾和數據去重等一系列細緻的加工處理措施。這些措施確保了發佈的數據更加可信，有助於過濾掉違法和不良信息，為人工智能的研究和應用提供一個更為健康的環境。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;用户可以通過登錄中國網絡空間安全協會網站，點擊 「中文互聯網語料資源平台」 鏈接，註冊並認證後下載相關語料。該負責人表示，中文互聯網基礎語料 3.0 的推出標誌着各界對高質量中文語料的共同努力與成果，未來還將繼續加強中文互聯網基礎語料的建設，以支撐人工智能技術的創新與產業發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373007</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373007</guid>
      <pubDate>Thu, 18 Sep 2025 09:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>工信部通報：29 款 APP 存在侵害用户權益行為</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工信部發布「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCCItP6cdGEq05uzR4zQwsA" target="_blank"&gt;關於侵害用户權益行為的 APP 通報（2025 年第 5 批，總第 50 批）&lt;/a&gt;」指出，近期，經組織第三方檢測機構進行抽查，共發現 29 款 APP 存在侵害用户權益行為，現予以通報。上述 APP 應按有關規定進行整改，整改落實不到位的，將依法依規組織開展相關處置工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;附件：工業和信息化部通報存在問題的 APP 名單&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;img alt="" height="1200" src="https://oscimg.oschina.net/oscnet/up-7ac3883f810c1bcd70bae9b44ea0e5a6a00.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372997</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372997</guid>
      <pubDate>Thu, 18 Sep 2025 09:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 數據標註團隊大幅裁員，休學大學生臨危接管核心業務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fafrica.businessinsider.com%2Fnews%2Felon-musks-xai-put-a-college-student-in-charge-of-the-team-training-grok-amid%2Fj80f9tm" target="_blank"&gt;根據 Business Insider 的報道&lt;/a&gt;，xAI 正在經歷人事變動。9 月以來，埃隆・馬斯克旗下 AI 公司 xAI 的 Grok 訓練數據標註團隊經歷重大人事震盪：上週至少 9 名高管被停用 Slack 賬號，&lt;a href="https://www.oschina.net/news/372229" target="_blank"&gt;9 月 12 日超 500 名員工遭裁員&lt;/a&gt;，團隊規模從 1500 人鋭減至約 900 人。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0918/170155_oEAu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;年僅 21 歲、仍處於大學休學狀態的 Diego Pasini 於 1 月通過黑客馬拉松加入 xAI，如今臨危受命接管該團隊。這位 2023 年高中畢業生在 9 月 15 日全員會議中承諾停止裁員，但隨後又有超 100 人被解僱。目前其團隊正開展一對一工作彙報，並通過測試重新定崗。&lt;/p&gt; 
&lt;p&gt;Pasini 的任命引發內部爭議：有員工質疑其資歷，相關發言在數小時內被停用賬號。據悉，他曾就讀於賓夕法尼亞大學計算機科學專業，在機器人領域有研究經歷，9 月初獲馬斯克關注。此次人事調整凸顯 xAI 在快速擴張中面臨的管理挑戰，也折射出馬斯克對年輕技術人才的破格任用策略。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372995</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372995</guid>
      <pubDate>Thu, 18 Sep 2025 09:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>透視 AI「魔改」視頻爭議：創意還是惡搞？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;（新華社）唐僧和孫悟空爭當「話事人」、《甄嬛傳》變成「槍戰片」、《人民的名義》中沙瑞金和高育良開展魔法攻擊……近段時間，一些 AI「魔改」內容在短視頻平台上引發爭議。&lt;/p&gt; 
&lt;p&gt;所謂 AI「魔改」，是指利用人工智能技術對原作品進行顛覆性改編的行為，常見於短視頻、視覺創作等領域。&lt;/p&gt; 
&lt;p&gt;AI「魔改」是創意還是惡搞？邊界到底在哪兒？如何更好規範治理，讓 AI 技術更多「賦能」而非「跑偏」？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;備受爭議的「魔改」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「家人們，看着五指山壓的是誰？如來老兒。當年壓我 500 年，現在必須壓他 1000 年。」孫悟空手舉相機「現場直播」，在他身後，如來佛祖被壓在山下……&lt;/p&gt; 
&lt;p&gt;看着短視頻平台推送的內容，青海西寧市民李女士着實嚇了一跳。「我和孩子一起刷短視頻，看到這個視頻畫面流暢、人物説話嘴型絲毫不差，不仔細分辨，還以為是電視劇原有的畫面。」&lt;/p&gt; 
&lt;p&gt;隨着 AI 技術普及，一些視頻博主將其變成獵取流量的工具，選取電視劇經典片段，剪輯成天馬行空的劇情，以獵奇的畫面、誇張的台詞激發觀眾興趣。&lt;/p&gt; 
&lt;p&gt;在一些短視頻平台上，此類「魔改」短視頻數據火爆，有的點贊量高達數萬。部分賬號起號半個多月，粉絲就已漲到 10 萬多。不少做此類內容的賬號，還會在視頻裏推薦 AI 網站、賣課，通過接廣告商單、知識變現、創作者分成計劃等方式獲取收益。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI「魔改」究竟是創意還是惡搞？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;部分公眾認為，一些「魔改」視頻新奇好玩，是創意表達；但也有人強調，經典承載文化記憶，娛樂化改編應有底線。一些「魔改」行為未經授權，破壞了原作品的完整性和藝術價值，一代觀眾的集體記憶也有可能變得混沌。&lt;/p&gt; 
&lt;p&gt;「我家孩子只有 12 歲，正處於價值觀建立的關鍵期，看太多這類視頻，三觀容易被帶偏。」李女士説。蘭州大學新聞與傳播學院副教授譚澤明認為，AI「魔改」視頻製造大量非真實信息，加劇了信息繭房效應。&lt;/p&gt; 
&lt;p&gt;有青年劇作家認為，影視經典既是一代人的共同記憶，也是文化傳承的載體。如果《三國演義》張飛等人物形象被肆意扭曲，甚至被「魔改」成與原著精神內核相悖的形象，是對經典的褻瀆。&lt;/p&gt; 
&lt;p&gt;2025 年 4 月，浙江省高級人民法院公佈一起「奧特曼形象 AI 生成侵權案」。浙江省杭州市中級人民法院審理認為，AI 的發展導致可能出現針對經典 IP 進行「魔改」的不良行為，過度或不當的「魔改」可能扭曲歷史記憶、文化遺產以及社會共識。&lt;/p&gt; 
&lt;p&gt;2024 年 12 月，國家廣播電視總局網絡視聽節目管理司也發佈管理提示指出，AI「魔改」視頻為博流量，毫無邊界褻瀆經典 IP，衝擊傳統文化認知，與原著精神內核相悖，且涉嫌構成侵權行為。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;走熱背後：門檻低、獲利高&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;利用 AI 技術改編生成內容的技術門檻和經濟成本並不高。記者試用多款軟件發現，AI 視頻剪輯可以通過文本描述內容、上傳圖片與視頻等多種方式生成。&lt;/p&gt; 
&lt;p&gt;隨機打開一款 AI 生成軟件，根據提示內容輸入「根據西遊記形象，讓孫悟空和唐僧持槍互相攻擊」，在「對口型」中選擇「猴哥」……數十秒後，一條視頻便生成出來。內容不僅流暢生動，人物形象和聲音也與電視劇版無異。&lt;/p&gt; 
&lt;p&gt;此類 AI 生成軟件大多需要付費，會員費用從幾十元到一兩百元不等。&lt;/p&gt; 
&lt;p&gt;記者看到，一款 AI 生成軟件花費 129 元就能成為永久會員，可解鎖文生視頻、圖生視頻、AI 繪畫等功能。另一款應用只需 98 元就可成為永久會員，同樣有口播視頻、圖生視頻、照片跳舞等功能，已有一百餘萬次下載。&lt;/p&gt; 
&lt;p&gt;譚澤明認為，AI「魔改」頻發背後，既有人工智能技術驅動的因素，也有平台算法的隱蔽驅動。&lt;/p&gt; 
&lt;p&gt;業內人士告訴記者，AI「魔改」視頻會給發佈者帶來流量曝光、粉絲增長、廣告收入等效益。&lt;/p&gt; 
&lt;p&gt;一名博主在短視頻平台發佈了一條唐僧唱歌的 AI 視頻，斬獲近 200 萬次轉贊評，粉絲量迅速突破 32 萬。「相比辛辛苦苦做原創，AI 改編的視頻流量會大很多，粉絲轉化率也高出好幾倍。」一名短視頻博主透露説，一些短視頻平台推出 AIGC 內容激勵計劃，進一步提升了博主的創作熱情。&lt;/p&gt; 
&lt;p&gt;記者調查發現，短視頻平台上還有不少以「投入低迴報高」「低成本開副業」「不上班在家做視頻就能賺錢」為噱頭的博主，宣傳提供 AI 生成視頻、AI 短劇製作相關培訓，「短時間就能上手，少則幾分鐘、多則三小時即可成片，月薪一萬起步」。&lt;/p&gt; 
&lt;p&gt;根據著作權法規定，未經著作權人許可，以改編、翻譯、註釋等方式使用作品的構成侵權行為。「不少 AI‘魔改’視頻的目的是為引流賺錢，已超出‘合理使用’範疇。」青海師範大學法學與社會學學院院長馬旭東教授説。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何加強治理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;針對 AI「魔改」亂象，國家廣播電視總局網絡視聽節目管理司督促短視頻平台排查清理 AI「魔改」影視劇的短視頻，並要求對在平台上使用、傳播的各類相關技術產品嚴格准入和監管，對 AI 生成內容做出顯著提示。&lt;/p&gt; 
&lt;p&gt;記者調查發現，相較之前，短視頻平台 AI「魔改」現象有一定改善。&lt;/p&gt; 
&lt;p&gt;抖音相繼發佈《關於人工智能生成內容的平台規範暨行業倡議》《關於不當利用 AI 生成虛擬人物的治理公告》，明確表示不鼓勵利用 AI 生成虛擬人物開展低質創作活動。在平台內相關視頻下方會明確註明「作者聲明：內容由 AI 生成」。&lt;/p&gt; 
&lt;p&gt;「流量思維驅動下，相關治理工作不可能一蹴而就。」譚澤明認為，針對利用 AI「魔改」博取流量現象，短視頻平台應切實承擔起把關責任，對於涉及侵權甚至包含暴力、低俗惡搞等元素的不良內容進行限流或下架、封號。&lt;/p&gt; 
&lt;p&gt;「既不能阻斷創作內容的創新，也要對相關著作權人的權利進行保護。」馬旭東建議，相關行業協會也應發揮建設性作用，加強網絡公益宣傳，不斷提高用户的媒介素養和對 AI 相關產品使用的法律意識；同時引導短視頻平台技術向善，推出更多優質、健康的內容。&lt;/p&gt; 
&lt;p&gt;清華大學新聞與傳播學院教授瀋陽説，鑑於 AI 技術的複雜性和應用的廣泛性，AI 治理需要實現跨領域的協同。例如，AI 生成音視頻內容時，可與身份驗證、行為分析等技術共同協作，以增強 AI 應用的合規性。科技公司、法律監管部門和倫理委員會等共同組成「技術共治聯盟」，制定更全面、細化的治理準則。&lt;/p&gt; 
&lt;p&gt;中國政法大學傳播法研究中心副主任朱巍認為，在 AI 技術飛速發展的今天，更需明確創新邊界，重視知識產權保護，注重審美培育和文化尊重，讓 AI 技術成為推動文化發展的新動力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372991</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372991</guid>
      <pubDate>Thu, 18 Sep 2025 08:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2024 年全社會研發投入超 3.6 萬億元，較 2020 年增長 48%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;國務院新聞辦公室今天（9 月 18 日）下午舉行 「高質量完成‘十四五’規劃」系列主題新聞發佈會，科技部負責人介紹「十四五」時期科技創新發展成就。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據介紹，「十四五」時期，我國科技投入持續增加，2024 年全社會研發投入超 3.6 萬億元，較 2020 年增長 48%；研發投入強度達到 2.68%，超過歐盟國家平均水平；研發人員總量世界第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基礎研究水平進一步提升。基礎研究經費達 2497 億元，較 2020 年增長超 70%，在量子科技、生命科學、物質科學、空間科學等領域取得一批重大原創成果，高水平國際期刊論文數量和國際專利申請量連續 5 年世界第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家戰略科技力量不斷壯大。國家實驗室體系建設穩步推進，國家科研機構、高水平研究型大學科研能力不斷提升，科技領軍企業加快培育成長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;區域科技創新呈現良好態勢。北京、上海、粵港澳大灣區國際科創中心支撐引領和輻射帶動作用不斷增強，深圳-香港-廣州躍居全球百強創新集羣榜首。成渝、武漢、西安區域科創中心建設加快推進。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家綜合創新能力排名由 2020 年的第 14 位提升至 2024 年的第 10 位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="771" src="https://oscimg.oschina.net/oscnet/up-44f21c70fb0f720c57bbf8586c1929ed685.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372983</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372983</guid>
      <pubDate>Thu, 18 Sep 2025 08:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里雲爆款雲服務器 68 元/年，2 核 2G 限時秒殺，超高性價比，立即搶購！</title>
      <description>覆蓋 90%+通用業務場景，組合購買「專享活動價」。</description>
      <link>https://click.aliyun.com/m/1000406832/</link>
      <guid isPermaLink="false">https://click.aliyun.com/m/1000406832/</guid>
      <pubDate>Thu, 18 Sep 2025 07:32:00 GMT</pubDate>
    </item>
    <item>
      <title>螞蟻百靈大模型團隊開源高性能推理 MoE 模型 Ring-mini-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻百靈大模型團隊正式發佈 Ring-mini-2.0，一款基於 Ling-mini-2.0 架構深度優化的高性能推理型 MoE 模型（Thinking model）。&lt;/p&gt; 
&lt;p&gt;它在總參數量 16B、僅激活 1.4B 參數的情況下，即可達到 10B 級別以下 dense 模型的綜合推理能力，尤其在邏輯推理、代碼與數學任務中表現卓越，並支持 128K 長上下文及 300+ token/s 的高速生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="550" src="https://static.oschina.net/uploads/space/2025/0918/151311_MTTi_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 以 Ling-mini-2.0-base 為基礎繼續訓練，經過 Long-COT SFT、更穩定持續的大規模 RLVR 以及 RLHF 聯合優化，顯著提升了複雜推理的穩定性與泛化性。在多項高難度基準（LiveCodeBench、AIME 2025、GPQA、ARC-AGI-v1 等）中，在輸出長度相當的情況下，性能顯著超越 10B 以下 dense 模型，甚至媲美更大參數量的 MoE 模型（如 gpt-oss-20B-medium），在邏輯推理方面尤為突出。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/151413_jqOH_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 已全面開源，模型權重、訓練策略與數據配方將全部開放。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ring-mini-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ring-mini-2.0&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372966</guid>
      <pubDate>Thu, 18 Sep 2025 07:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻百靈大模型團隊開源 MoE 大模型 Ling-flash-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻百靈大模型團隊正式開源其最新 MoE 大模型 ——Ling-flash-2.0。&lt;/p&gt; 
&lt;p&gt;作為 Ling 2.0 架構系列的第三款模型，Ling-flash-2.0 以總參數 100B、激活僅 6.1B（non-embedding 激活 4.8B）的輕量級配置，在多個權威評測中展現出媲美甚至超越 40B 級別 Dense 模型和更大 MoE 模型的卓越性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150130_epe3_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="634" src="https://static.oschina.net/uploads/space/2025/0918/150203_ryAo_2720166.jpg" width="1000" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Ling-flash-2.0 在僅激活 6.1B 參數的前提下，實現了對 40B Dense 模型的性能超越，&lt;strong&gt;用最小激活參數，撬動最大任務性能&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;為此，團隊在多個維度上 「做減法」 也 「做加法」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;1/32 激活比例：每次推理僅激活 6.1B 參數，計算量遠低於同性能 Dense 模型&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;專家粒度調優：細化專家分工，減少冗餘激活&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;共享專家機制：提升通用知識複用率&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sigmoid 路由 + aux-loss free 策略：實現專家負載均衡，避免傳統 MoE 的訓練震盪&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MTP 層、QK-Norm、half-RoPE：在建模目標、注意力機制、位置編碼等細節上實現經驗最優&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150338_KdT0_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最終結果是：6.1B 激活參數，帶來約 40B Dense 模型的等效性能，實現 7 倍以上的性能槓桿。&lt;/p&gt; 
&lt;p&gt;Ling-flash-2.0 基礎版與對話版模型已同步上架 Hugging Face 與 ModelScope，採用 MIT 協議可商用。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ling-flash-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ling-flash-2.0&lt;br&gt; GitHub：https://github.com/inclusionAI/Ling-V2&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372964</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372964</guid>
      <pubDate>Thu, 18 Sep 2025 07:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>擁抱新一代 Web 3D 引擎，Three.js 項目快速升級 Galacean 指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互聯網前端團隊- Su Ning&lt;/p&gt; 
 &lt;p&gt;本文從多個維度對比 Galacean 和 Three.js 兩款 Web3D 引擎的差異，並介紹擬我形象項目從 Three.js 切換到 Galacean 以後帶來的提升以及項目遷移的心得，為其他 Three.js 項目升級到 Galacean 提供參考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;1 分鐘看圖掌握核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-844825cdee521dcf0dd15502276e842fe65.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;Web 3D 技術的發展日新月異，為我們帶來了前所未有的沉浸式體驗。從虛擬展示到遊戲開發，從建築可視化到教育模擬，Web 3D 技術的應用場景愈發廣泛。而在這一領域，Three.js 作為一款廣受歡迎的 JavaScript 3D 庫，憑藉其簡潔易用的 API 和豐富的功能，幫助眾多開發者實現了精彩的 3D 項目。&lt;/p&gt; 
&lt;p&gt;然而，隨着項目複雜度的不斷提升，以及用户對性能和體驗要求的日益苛刻，Three.js 逐漸顯露出一些侷限性。比如在處理重負載時，很容易遇到性能瓶頸，出現卡頓、掉幀等問題。這就如同一位經驗豐富的車手，駕駛着一輛曾經性能卓越的賽車，但在面對愈發複雜的賽道和激烈的競爭時，卻發現車輛的動力和操控性漸漸力不從心。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、Galacean：新一代 Web 3D 引擎&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 業務簡介&lt;/h2&gt; 
&lt;p&gt;擬我形象是 vivo 賬號中的一個 3D 數字人功能，提供一種代表自由、個性、創新和時尚的虛擬形象，為用户提供更加生動、直觀、有趣的交流方式。採用 Native+H5 混合的開發方式，其中 3D 渲染的部分基於 Three.js 進行開發。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 技術挑戰與痛點&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能瓶頸：&lt;/strong&gt;人物模型包含大量形態鍵以實現多樣化面部特徵，導致模型加載解析耗時過長。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;線程阻塞：&lt;/strong&gt;受限於 JS 單線程特性，模型解析過程會造成頁面短暫無響應。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模型渲染：&lt;/strong&gt;套裝切換等場景下，多個模型同時渲染時性能問題尤為突出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;陰影優化：&lt;/strong&gt;Three.js 的陰影渲染性能消耗大，不得不通過局部陰影和限制捕捉範圍等折中方案來平衡畫質與性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Galacean 引擎核心優勢&lt;/h2&gt; 
&lt;p&gt;Galacean 是一款開源的 Web 遊戲引擎，致力於打造一個開放、易用、高效的遊戲開發工具，可以通過在線編輯器或者純代碼的形式進行使用。&lt;/p&gt; 
&lt;p&gt;針對現存的技術挑戰與痛點，Galacean 做了深度優化：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;多線程處理：&lt;/strong&gt;採用 Worker 避免主線程阻塞。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;移動端適配：&lt;/strong&gt;對大量常量進行近似取值優化，完美適配移動端。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能突破：&lt;/strong&gt;優化數據傳輸鏈路，創新緩存設計，顯著降低重負載場景下的卡頓現象。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7e8fd35268a9e4e6807d7a59d98c296eab.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對比視頻 1：加載速度&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-b7b3c633bc729e87048a7e7cbbd4c6374b4.gif" width="240" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對比視頻 2：套裝切換&lt;/p&gt; 
&lt;p&gt;此外，Galacean 基於 EC（Entity-Component）架構設計，而非 Three.js 的面向對象，大幅提升了開發的靈活性。&lt;/p&gt; 
&lt;p&gt;近期我們將渲染引擎由 Three.js 切換為 Galacean。這一舉措不僅解決了頁面卡頓問題，還提升了瀏覽器兼容性（可支持到 chrome82），幀率表現更出色，畫面質感也得到顯著改善。整體切換過程較為平滑，但也遇到了一些問題。接下來，將與大家分享此次整體升級的相關經驗。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;三、調優過程&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;任務拆解：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;作為一個數字人項目，涉及到引擎升級的模塊大致有&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;①環境初始化&lt;/strong&gt;（場景、相機、光線、引擎設置）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 模型加載&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;骨架獲取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;材質獲取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;動畫獲取&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;③妝容、穿搭還原&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;形態鍵修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;貼圖、顏色修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型替換&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;頭像（靜態頭像、動態頭像）導出&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;壁紙（靜態壁紙、動態壁紙、視差壁紙）導出&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經過梳理，可以大致分為四類：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;初始化&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;模型加載&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;素材替換&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;動畫狀態&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;接下來我們對這幾個部分進行分別的處理&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 初始化&lt;/h2&gt; 
&lt;p&gt;有別於 Three.js 的渲染器創建，Galacean 的 engine 初始化是異步方法，所以後續用到用到 engine 的地方需要考慮加載的時序，以及 engine 存在狀態的判斷。另外，Three.js 中 renderer 的渲染行為需要手動調用，一般是使用 requestAnimationFrame 循環調用，而 Galacean 則不需要，引擎開始渲染只需要調用一次 engine.run 即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;renderer=new&amp;nbsp;THREE.WebGLRenderer({
&amp;nbsp;&amp;nbsp;alpha:&amp;nbsp;true,
&amp;nbsp;&amp;nbsp;antialias:&amp;nbsp;true,
})
document.body.appendChild(renderer.domElement)
const&amp;nbsp;scene =&amp;nbsp;new&amp;nbsp;THREE.Scene()
const&amp;nbsp;camera =&amp;nbsp;new&amp;nbsp;THREE.PerspectiveCamera(15,&amp;nbsp;window.innerWidth/window.innerHeight,&amp;nbsp;0.1,&amp;nbsp;100)
requestAnimationFrame(function&amp;nbsp;render() {
&amp;nbsp; renderer.render(scene, camera)
&amp;nbsp;&amp;nbsp;requestAnimationFrame(render)
})&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;engine =&amp;nbsp;await&amp;nbsp;WebGLEngine.create({
&amp;nbsp; canvas,
&amp;nbsp;&amp;nbsp;physics:&amp;nbsp;new&amp;nbsp;LitePhysics()
})
engine.run()&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中，尺寸單位統一以米為基準，無需額外進行特殊處理。不過在角度單位的使用上存在差異：Three.js 裏，僅相機的 fov（視場角）採用角度單位，其他涉及角度的參數均以弧度計量；而 Galacean 則採用更為統一的設定，所有角度相關單位均為角度。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
camera.fov =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&amp;nbsp;* Math.PI/180

/** Galacean */
camera.fieldOfView =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中顏色的設置更加靈活，可以使用 16 進制或者 RGB 值來進行賦值，但是在 Galacean 中只能通過 RGB 來進行賦值，且有別於 0-255 的取值範圍，Galacean 中的顏色範圍是 0-1。從 Galacean1.5 版本開始，默認的色彩空間改為線性，在代碼中需要手動轉換一下。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
directLight.color=0xffffff
directLight.intensity=0.9

/** Galacean */
const&amp;nbsp;color =&amp;nbsp;new&amp;nbsp;Color(0.9,&amp;nbsp;0.9,&amp;nbsp;0.9,&amp;nbsp;1)
color.toLinear(color)
directLight.color = color&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 模型加載&lt;/h2&gt; 
&lt;p&gt;對於包含大量形態鍵和動畫的模型，將模型打成 zip 包可以有效的壓縮模型的體積，不論是 Three.js 還是 Galacean 都不支持加載 zip 包，但是我們可以自行擴展模型加載的鏈路，將 zip 下載後解壓出的模型獲取 ObjectUrl 再放到各自的加載器中加載，這樣加載進度的獲取也可以進行自定義，不需要進行額外的改造。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;exportclassModelLoader {
&amp;nbsp;&amp;nbsp;engine:&amp;nbsp;WebGLEngine
&amp;nbsp;&amp;nbsp;constructor(engine: WebGLEngine){
&amp;nbsp; &amp;nbsp;&amp;nbsp;this.engine&amp;nbsp;= engine
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;async&amp;nbsp;load(src:&amp;nbsp;string) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;url =&amp;nbsp;await&amp;nbsp;fileLoader(src)
&amp;nbsp; &amp;nbsp; returnthis.engine.resourceManager.load&amp;lt;GLTFResource&amp;gt;({
&amp;nbsp; &amp;nbsp; &amp;nbsp; url,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;type:&amp;nbsp;AssetType.GLTF
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Three.js 解析 glTF 模型輸出的數據結構較為簡單，主要使用模型的場景和動畫片段。由於後續需針對特定材質進行替換，所以要根據節點名獲取特定節點，再取出節點中的材質信息，模型的骨架也通過這種方式獲取。而 Galacean 輸出的數據更為全面，除動畫片段和實體信息外，模型中使用的材質、貼圖、蒙皮和網格信息也會分門別類展示，需要對應內容時直接獲取即可，相比 Three.js 更加方便。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 素材替換&lt;/h2&gt; 
&lt;p&gt;素材替換如上文總結分為四種，分別是顏色、貼圖、形態鍵和模型的替換，顏色設置我們在初始化中已經講解，而模型加載和展示也沒有特別的內容，無非是節點/實體的添加和移除，這裏我們講下貼圖和形態鍵修改的一些 tips。&lt;/p&gt; 
&lt;p&gt;在 Three.js 中修改材質貼圖 map 可以直接直接使用 canvas 或者 image，修改後需要將材質 needsUpdate 屬性設置為 true。而在 Galacean 需要先將圖片加載為 texture，再進行賦值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
material.map=canvas
material.needsUpdate =&amp;nbsp;true

/** Galacean */
const&amp;nbsp;texture: Texture2D = await engine.resourceManager.load({
&amp;nbsp; url,
&amp;nbsp;&amp;nbsp;type: AssetType.Texture2D
})
material.baseTexture = texture&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中修改形態鍵，可以先通過網格中的 morphTargetDictionary 屬性獲取到需要修改的形態鍵的索引，然後修改 morphTargetInfluences 中對應索引的值即可。&lt;/p&gt; 
&lt;p&gt;在 Galacean 中網格渲染器中沒有存儲形態鍵的索引信息，而是存儲在 MeshRenderer 下的 mesh 屬性下的 blendShapes 屬性中，通過獲取對應名稱的形態鍵在數組中的索引，修改網格渲染器中 blendShapeWeights 屬性對應下標的值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
const&amp;nbsp;index = morphTargetDictionary[keyName]

if&amp;nbsp;(index !==&amp;nbsp;undefined) {
&amp;nbsp; mesh.morphTargetInfluences[index] = value
}

/** Galacean */
const&amp;nbsp;blendShapes = skinMeshRenderer.mesh.blendShapes
const&amp;nbsp;index = blendShapes.findIndex(i=&amp;gt;i.name===keyName)
if&amp;nbsp;(index &amp;gt; -1){
&amp;nbsp; skinMeshRenderer.blendShapeWeights[index] = value
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;3.4 動畫&lt;/h2&gt; 
&lt;p&gt;相較於 Three.js 的 AnimationMixer 和 AnimationClip，Galacean 擁有更加完善的面向組件的動畫系統，支持，狀態機、混合動畫、時長壓縮等，不同動畫之間的切換與播放更加簡單易維護。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js 播放動畫片段 */
const&amp;nbsp;mixer =&amp;nbsp;new&amp;nbsp;THREE.AnimationMixer(scene)
const&amp;nbsp;action=mixer.clipAction(avatarClip)
action.play()
ticker.addEvent(delta =&amp;gt; {
&amp;nbsp; mixer.update(delta)
})

/** Galacean 添加狀態機，播放完成回到待機狀態 */
const&amp;nbsp;animationState = animator.findAnimatorState('action')
const&amp;nbsp;idleStatle = animator.findAnimatorState('idle')
const&amp;nbsp;transition =&amp;nbsp;new&amp;nbsp;AnimatorStateTransition()
transition.duration =&amp;nbsp;1
transition.offset =&amp;nbsp;0
transition.exitTime =&amp;nbsp;1
transition.destinationState = idleStatle
animationState.addTransition(transition)
animator.play('action')&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_11"&gt;&lt;/span&gt; 
&lt;h1&gt;四、結語&lt;/h1&gt; 
&lt;p&gt;Galacean 的出現，無疑為 Web 3D 開發領域帶來了新的活力。它不僅解決了 Three.js 等傳統技術在性能和功能上的諸多痛點，還以其卓越的性能、豐富的功能和易用性，為開發者打開了一扇通往更廣闊創意空間的大門。&lt;/p&gt; 
&lt;p&gt;需要注意的是，Galacean 不同版本之間的 API 差異較大，需要進行甄別，同時開發文檔及相關的案例也需要進一步完善。&lt;/p&gt; 
&lt;p&gt;對於全新的項目，Galacean 提供編碼或在線編輯器兩種方式保障創意的高效落地，詳細的文檔和案例也便於接觸 Web3D 開發的新人快速上手。&lt;/p&gt; 
&lt;p&gt;對於存量的項目，Galacean 的遷移成本不高，且整個過程平滑可控，能夠有效提升現有項目的畫面表現和性能。為未來複雜度更高的需求提供性能保障。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18692286</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18692286</guid>
      <pubDate>Thu, 18 Sep 2025 07:06:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>華為發佈全球首個通算超節點</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在華為全聯接大會 2025 上，華為輪值董事長徐直軍正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huawei.com%2Fcn%2Fnews%2F2025%2F9%2Fhc-lingqu-ai-superpod" target="_blank"&gt;發佈&lt;/a&gt;了全球首個通算超節點華為 Taishan 950 SuperPoD，計劃 2026 年一季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直軍稱，其將能夠徹底取代各種應用場景的大型機和小型機以及 Exadata 數據庫一體機，將成為各類大型機、小型機的終結者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-24f09fe6e041b3140f61e7f0fa4a12dc091.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直軍指出：「算力過去是，未來也將繼續是人工智能的關鍵，更是中國人工智能的關鍵」。他認為，超節點在物理上由多台機器組成，但邏輯上以一台機器學習、思考、推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，華為發佈的最新超節點產品 Atlas 950 SuperPoD，算力規模 8192 卡，預計於 2026 年四季度上市。Atlas 960 SuperPoD 算力規模 15488 卡，預計 2027 年四季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基於超節點，華為同時發佈了全球最強超節點集羣，分別是 Atlas 950 SuperCluster 和 Atlas 960 SuperCluster，算力規模分別超過 50 萬卡和達到百萬卡。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372960</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372960</guid>
      <pubDate>Thu, 18 Sep 2025 06:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
