<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 18 Mar 2025 21:43:04 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>拼多多上線用户和商家視頻通話功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbjXsabyYPkkNl12e9XFk6g&quot; target=&quot;_blank&quot;&gt;據電商派 Pro 昨日報道&lt;/a&gt;，拼多多面向用户和商家上線了視頻通話功能，方便進行產品使用講解。商家只需登錄商家後台，在多多客服功能中找到客服工具，即可開通語音通話服務。&lt;/p&gt; 
&lt;p&gt;商家需選擇語音通話賬號，設置可視頻接待的賬號，點擊下一步後，再選擇是否在 23:00 至次日 8:00 期間接聽，最後點擊確認即可完成設置。&lt;/p&gt; 
&lt;p&gt;開通該功能後，商家在與消費者的聊天界面中可以向消費者發送「視頻講解邀請」卡片。消費者點擊進入後，商家側即會彈起視頻通話界面。&lt;/p&gt; 
&lt;p&gt;值得注意的是，視頻接通後，消費者攝像頭默認關閉，需消費者手動開啓，且開啓後默認使用後置攝像頭。&lt;/p&gt; 
&lt;p&gt;此外，平台方面還建議商家在配置語音通話賬號後，儘量不要關閉商家 App，保持其前台運行狀態。若商家連續兩天接聽率較低，系統會暫停通話功能 3 天，之後需商家重新開啓。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339647</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339647</guid>
            <pubDate>Wed, 05 Mar 2025 11:20:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>使用 DeepSeek 拯救數據中台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;在數字化轉型浪潮中，數據中台作為企業核心資產的&quot;樞紐站&quot;，卻長期面臨&quot;建而難用&quot;的尷尬境地——業務團隊抱怨數據獲取門檻高、技術團隊困於複雜的數據治理任務，如何打通數據價值落地的&quot;最後一公里&quot;始終是行業痛點。&lt;/p&gt; 
 &lt;p&gt;PowerData 社區主理人李奇峯給出了一個充滿技術想象力的答案：通過深度結合 DeepSeek 大模型的邏輯推理與結構化數據處理能力，重構數據中台的技術棧。&lt;/p&gt; 
 &lt;p&gt;3 月 22 日，PowerData 社區主理人李奇峯將出席 OSC 源創會南京站，並發表《使用 DeepSeek 拯救數據中台》主題分享，探討如何藉助大模型通用化與生成式的數據處理能力，結合數據中台中的落地痛難點，對其進行針對性的優化改造。&lt;/p&gt; 
 &lt;p&gt;在活動正式開始前，我們也和李奇峯聊了聊一些「入門級」問題，感興趣的開發者可週六到活動現場，與李奇峯交流探討關於數據中台的建設問題。報名鏈接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;800&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e193f9982c2bb3fe9fad5193d51273ce545.jpg&quot; width=&quot;552&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在眾多大模型中為何選擇 DeepSeek 作為數據中台改造的核心技術？與其他開源模型相比，DeepSeek 在數據處理場景下有哪些優勢？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;我作為一個數據中台的從業者，核心訴求還是提升數據中台本身的能力。對於大模型的瞭解並不深入，其只是我的一個工具而已。所以從工具的屬性來説，我選擇 deepseek 主要有以下幾點原因：&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;成本：無論是訓練成本、還是推理成本，相較於其他模型都有顯著降低。同時支持國產化硬件，在合規性方面也有保證。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;熱度：在風口到來的時候，不説乘風而飛，但是至少還是需要蹭一下的。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;能力：DeepSeek R1 是 LMSYS Chinese 榜單最強的 from China 的模型，V3 是上面榜單中開源的最強非 Reasoner 模型，基礎能力優越。同時相較於其他模型，DeepSeek 在邏輯推理+結構化數據解析處理的能力優秀，同時其支持的上下文窗口較大，在數據血緣解析、數據分類分級、數據質量治理等任務中，其準確性較其他模型都有顯著提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;開發者最關心的部署成本問題：在私有化部署場景下，DeepSeek 模型針對數據中台做了哪些輕量化改造？是否支持量化壓縮後的模型在常規 GPU 服務器集羣運行？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;Deepseek 不會為企業應用場景訓練各種量化模型的，市面上的量化模型都是社區和開發者上傳的。如果為了降低部署成本，採購算力服務器之前先測試各個量化模型的能力能否滿足應用場景，確定好使用哪版量化模型後，根據顯存去採購性價比最高算力服務器，推理服務器建議買 Nvdia 遊戲卡。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;能否用具體代碼片段説明 DeepSeek 如何與數據中台組件集成？例如如何通過 API 調用實現&quot;自然語言轉數據服務接口&quot;這類典型場景，過程中需要哪些中間件做適配？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;下面是一個非常簡單的通過大模型進行數據自動標註的代碼：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import openai
import pandas as pd
import json
from typing import List, Dict

class MetadataAutoTagger:
    def __init__(self, api_key: str, business_context: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.business_context = business_context  # 公司業務背景説明
        
    def generate_prompt(self, table_name: str, columns: List[str]) -&amp;gt; str:
        &quot;&quot;&quot;構造大模型提示詞&quot;&quot;&quot;
        return f&quot;&quot;&quot;
        # 任務説明
        根據提供的元數據和業務背景，生成數據資產的業務標註信息，要求：
        1. 業務名稱：體現數據在業務中的核心作用
        2. 業務類型：交易型/分析型/主數據/日誌型...
        3. 業務實體：對應業務對象（客户/訂單/產品...）
        4. 分類分級：按公司數據分類分級標準
        5. 字段説明：用業務語言解釋字段含義

        # 業務背景
        {self.business_context}

        # 待標註元數據
        表名：{table_name}
        字段列表：{&#39;, &#39;.join(columns)}

        請用 JSON 格式返回結果，結構如下：
        {{
            &quot;table_name&quot;: &quot;{table_name}&quot;,
            &quot;business_name&quot;: &quot;&quot;,
            &quot;business_type&quot;: &quot;&quot;,
            &quot;business_entity&quot;: &quot;&quot;,
            &quot;data_classification&quot;: &quot;&quot;,
            &quot;columns&quot;: {{
                &quot;column1&quot;: &quot;業務説明&quot;,
                &quot;column2&quot;: &quot;業務説明&quot;
            }}
        }}
        &quot;&quot;&quot;

    def tag_metadata(self, metadata_df: pd.DataFrame) -&amp;gt; pd.DataFrame:
        &quot;&quot;&quot;批量處理元數據&quot;&quot;&quot;
        results = []
        for _, row in metadata_df.iterrows():
            response = self._call_llm(row[&#39;table_name&#39;], row[&#39;columns&#39;])
            if response:
                results.append(response)
        return pd.DataFrame(results)

    def _call_llm(self, table_name: str, columns: List[str]) -&amp;gt; Dict:
        &quot;&quot;&quot;調用大模型 API&quot;&quot;&quot;
        try:
            prompt = self.generate_prompt(table_name, columns)
            response = self.client.chat.completions.create(
                model=&quot;gpt-4&quot;,
                messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
                temperature=0.2,
                response_format={&quot;type&quot;: &quot;json_object&quot;}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f&quot;Error processing {table_name}: {str(e)}&quot;)
            return None

# 示例用法
if __name__ == &quot;__main__&quot;:
    # 初始化配置
    config = {
        &quot;api_key&quot;: &quot;your_openai_key&quot;,
        &quot;business_context&quot;: &quot;某電商公司，主要業務包含商品交易、用户畫像、訂單履約等...&quot;
    }

    # 示例元數據（實際從數據庫或文件讀取）
    sample_data = {
        &quot;table_name&quot;: [&quot;user_info&quot;, &quot;order_detail&quot;],
        &quot;columns&quot;: [
            [&quot;user_id&quot;, &quot;registration_date&quot;, &quot;last_login&quot;],
            [&quot;order_id&quot;, &quot;product_sku&quot;, &quot;payment_amount&quot;]
        ]
    }
    metadata_df = pd.DataFrame(sample_data)

    # 執行自動標註
    tagger = MetadataAutoTagger(**config)
    result_df = tagger.tag_metadata(metadata_df)
    
    # 保存結果
    result_df.to_csv(&quot;tagged_metadata.csv&quot;, index=False)
    print(&quot;標註結果示例：&quot;)
    print(result_df.head())
典型輸出結果如下：
{
    &quot;table_name&quot;: &quot;user_info&quot;,
    &quot;business_name&quot;: &quot;用户基本信息表&quot;,
    &quot;business_type&quot;: &quot;主數據&quot;,
    &quot;business_entity&quot;: &quot;用户&quot;,
    &quot;data_classification&quot;: &quot;PII/LEVEL-2&quot;,
    &quot;columns&quot;: {
        &quot;user_id&quot;: &quot;用户唯一標識符，用於跨系統用户識別&quot;,
        &quot;registration_date&quot;: &quot;用户註冊電商平台的具體日期&quot;,
        &quot;last_login&quot;: &quot;記錄用户最近一次登錄平台的時間&quot;
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在處理非結構化數據場景中（如日誌解析/圖片 OCR），DeepSeek 與傳統 ETL 工具的結合方案是怎樣的？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;非結構化數據基本用不上 Deepseek，月更好的選擇，圖片用多模態 LLM 可以總結，圖片類型的文檔用 OCR，OCR 一般用百度&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot;&gt;paddle&lt;/a&gt;，表格解析有開源的讀光模型。這些都是數據處理，處理完才是抽取-轉換-加載（Sqoop、Flume、Cannel、DataX）到下游。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在數據關係複雜的中台環境，如何通過 prompt engineering 確保大模型輸出的 SQL/SHELL 腳本符合安全規範？是否有開發自定義的語法校驗中間件？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;提示詞來確保大模型輸出的 SQL/SHELL 腳本符合安全規範，是有問題的。LLM 是用來理解和處理自然語言的，更多的是交互上的提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;推薦使用 sqlcheck 和 shellcheck 這種工具，腳本安全做的還可以。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;遇到模型&quot;幻覺&quot;導致的數據質量問題，是否有設計技術兜底方案？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;可以通過 RAG + 外掛知識庫的方式優化幻覺問題。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;PowerData 社區在構建 DeepSeek 插件生態方面有哪些規劃？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;後續會實現一些 MCP 接口。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;對想參與數據中台智能化改造的開發者，建議從哪些具體模塊入手貢獻？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;可以先嚐試進行 text to sql 的功能開發，具體入門教程可參考此篇文章：https://mp.weixin.qq.com/s/Wk9OmB80JC7NFG2T7VjNRA&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在 Data+AI 的架構演進中，您認為未來 3 年數據中台的核心組件會發生哪些顛覆性變化？傳統數據倉庫工程師需要優先補充哪些 AI 工程化能力？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;顛覆性變化談不上，數據中台的核心還是數據資產化、服務化，一切的功能目標都是往這個方向走。隨着大模型的快速進化與深度結合，數據中台可能會在以下能力進行進化：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;自然語言交互：大模型出色的自然語言交互能力可準確理解用户意圖，大幅提升數，據查詢分析的便利性，提升用户體驗&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;智能洞察分析：大模型可分析文本、圖表等多維數據，智能歸因、預測、總結，降，低員工利用數據、分析數據的門檻&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;集成大模型服務鏈路：集成 LangChain、向量檢索、finetune 等大模型應用所，需技術組件，提升企業調試、使用大模型的效率&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;傳統數倉需要補充哪些 AI 工程化能力？這個我們社區之前內部討論過，工程化能力談不上，更多的還是把 AI 當成一個全能小助手，幫助自己解決問題和提效吧。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;10567&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9b99625d6dd601dfc15f3189cd7c0bdf40c.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17938519</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17938519</guid>
            <pubDate>Wed, 05 Mar 2025 09:57:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Bolt.new 創始人：軟件世界運行着萬億美元的市場，重寫軟件世界秩序的機會是巨大的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Bolt.new 創始人的勵志故事：我們如何從即將倒閉，到成為史上增長最快的 AI 編碼工具，並保持不到 20 名員工的規模。&lt;/p&gt; 
&lt;p&gt;本文整理自 Bolt.new 創始人 Eric Simons 的完整採訪。他説：&quot;軟件世界運行着萬億美元的市場，重寫軟件世界秩序的機會是巨大的。&quot;&lt;/p&gt; 
&lt;p&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FPiG719cda&quot; target=&quot;_blank&quot;&gt;https://weibo.com/1233486457/PiG719cda&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;一、從零到爆發：Bolt 的驚人增長軌跡&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Lenny 最近對 StackBlitz 的創始人兼 CEO Eric Simons 進行了一次深入採訪，揭示了這個產品如何在短短几個月內從零到每年 4000 萬美元的經常性收入 (ARR)，成為史上增長最快的產品之一。&lt;/p&gt; 
&lt;p&gt;StackBlitz 是一家已經存在了七年的公司，專注於基於網絡的開發環境技術。然而，就在公司即將倒閉之際，他們推出了 Bolt - 一款 AI 驅動的文本到應用程序 (text-to-app) 工具，徹底改變了公司的命運。&lt;/p&gt; 
&lt;p&gt;&quot;公司在我們推出 Bolt 時幾乎要倒閉了，&quot;Simons 回憶道。&quot;我們想，如果這能在未來幾個月增加 10 萬美元的 ARR，那就太棒了。結果在前兩個月，我們從零增長到了 2000 萬美元的 ARR。&quot;&lt;/p&gt; 
&lt;p&gt;現在，僅僅 5 個月後，Bolt 已經達到了 3000 萬美元的 ARR，即將跨越 4000 萬美元的門檻，擁有 300 萬註冊用户和約 100 萬月活躍用户。更令人驚訝的是，StackBlitz 只有 15-20 名員工。這種爆炸性增長甚至讓經驗豐富的創業者和投資者都感到震驚，因為很少有公司能以這樣的速度擴張。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;二、WebContainer 技術：七年錘鍊的核心競爭力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功並非一蹴而就，而是建立在七年技術積累的基礎上。StackBlitz 的核心技術是 WebContainer - 一種可以在瀏覽器中運行的操作系統，它能在 100 毫秒內啓動並運行完整的開發工具鏈。&lt;/p&gt; 
&lt;p&gt;與市場上其他類似產品不同，Bolt 不依賴雲服務器來運行應用程序。當用户使用其他&quot;文本到應用程序&quot;工具時，通常需要等待雲虛擬機啓動，這可能需要幾分鐘時間，並且經常出現問題。而 Bolt 的 WebContainer 技術利用用户自己的 CPU 和內存在瀏覽器中本地運行應用程序，使得整個過程更快、更可靠。&lt;/p&gt; 
&lt;p&gt;&quot;這就是為什麼我們可以有一個非常寬鬆的免費層級，而且它極其快速和可靠，&quot;Simons 解釋道。&quot;我們的 AI Agent 與這個操作系統有雙向通信。它編寫代碼，運行開發服務器，使整個過程快速而流暢。&quot;&lt;/p&gt; 
&lt;p&gt;這種技術路線是 StackBlitz 團隊經過深思熟慮的結果，受到了像 Figma 這樣的成功產品的啓發。Simons 指出：&quot;如果你看看其他在網絡上真正成功的生產力應用程序，它們都採用這種計算模型。Figma、Google Docs - 這是唯一一種擴展到十億用户的模型。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;三、Bolt 實戰：一分鐘內從文本到功能性應用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示了 Bolt 的強大功能。他只是簡單地在一個文本框中輸入&quot;製作一個 Spotify 克隆&quot;，然後點擊回車。在不到一分鐘的時間內，Bolt 在瀏覽器中生成了一個功能完整、視覺上令人印象深刻的 Spotify 克隆應用。&lt;/p&gt; 
&lt;p&gt;&quot;這是在瀏覽器中運行的完整開發環境，這是在我的瀏覽器中運行的真實操作系統，&quot;Simons 展示道。&quot;我可以在上面運行命令等，真正令人印象深刻的是，所有這些都是在 60 秒內完成的。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，用户可以立即部署他們的應用程序。通過集成 Netlify 等生產級託管提供商，用户可以一鍵獲得一個實時 URL，甚至可以附加自己的域名。這使得整個過程從創建到部署變得無縫銜接。&lt;/p&gt; 
&lt;p&gt;Simons 強調説：&quot;這是有史以來構建網絡應用最簡單的方式。&quot;對比傳統工具，他指出：&quot;那些東西（如 Wix 或 Squarespace）使用起來非常複雜。我不知道你是否見過這些工具的 UI，但它們非常複雜。而那只是為了構建一個靜態網站，你根本無法用它們構建功能性應用。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;四、移動應用開發的革命：實時預覽與測試&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 最近的一項重大更新是與 Expo 的合作，使用户能夠創建原生移動應用。Expo 是一家專注於 React Native 工具的公司，使開發者能夠更輕鬆地構建漂亮的應用並將其上傳到應用商店。&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示瞭如何使用 Bolt 和 Expo 構建一個移動版 Spotify 克隆應用。用户只需掃描二維碼，就能在自己的手機上實時查看和測試應用程序。當用户繼續通過提示改進應用程序時，這些更改會實時反映在他們的設備上。&lt;/p&gt; 
&lt;p&gt;&quot;這是第一次，你不需要成為技術人員就能製作生產級的網絡、全棧網絡和移動應用，&quot;Simons 解釋道。他指出，Bolt 的用户羣體中有 67% 的人不是開發者，而是產品經理、設計師和企業家。&quot;這些人一直都很擅長構建產品，但以前，他們唯一能將想法轉化為代碼軟件的方式是通過開發者的手指。現在他們可以自己處理。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;五、七年磨一劍：從技術挑戰到市場突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功不僅僅是一個技術故事，更是一個關於毅力和堅持的故事。StackBlitz 在七年的時間裏專注於構建 WebContainer 技術，經歷了無數挑戰和失敗。&lt;/p&gt; 
&lt;p&gt;&quot;我們在技術第一，然後尋找問題來解決，這往往是人們告訴你不應該做的事情，&quot;Simons 承認。他的聯合創始人 Albert 和他從 13 歲就開始一起編寫代碼，並從那時起一直在構建產品。&lt;/p&gt; 
&lt;p&gt;他們的靈感部分來自於早期的 Figma，Figma 最初是作為一個基於瀏覽器的深度技術項目起步的。Simons 解釋説：&quot;很少有人知道 Figma 也是一個基於瀏覽器的深度技術項目。他們第一個 Figma 演示不是設計工具，而是在瀏覽器標籤中展示一個 3D 球體掉入水中的效果。&quot;&lt;/p&gt; 
&lt;p&gt;類似地，StackBlitz 團隊看到了瀏覽器技術（如 WebAssembly、共享內存和 Service Workers）的進步，並意識到可以構建一個運行在瀏覽器中的操作系統。他們花了大約五年時間來構建 WebContainer，然後又花了幾年時間嘗試找到合適的產品應用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;六、在死亡邊緣找到轉機：一條推文改變一切&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在公司即將耗盡資金的關鍵時刻，StackBlitz 團隊認識到他們的 WebContainer 技術非常適合構建基於瀏覽器的 AI 產品。&lt;/p&gt; 
&lt;p&gt;&quot;我們與 Anthropic 合作，獲得了對 Sonnet 模型的預覽，&quot;Simons 回憶道。&quot;我們意識到這可能是我們的機會。我們以前嘗試過構建類似 Bolt 的東西，但當時的模型不夠好，代碼輸出不夠可靠。但 Sonnet 改變了這一切。&quot;&lt;/p&gt; 
&lt;p&gt;2023 年 6 月，當 Anthropic 發佈 Claude 3.5 Sonnet 模型時，StackBlitz 團隊看到了機會。他們重新拾起之前擱置的項目，並通過一條簡單的推文推出了 Bolt。結果超出了他們最瘋狂的期望。&lt;/p&gt; 
&lt;p&gt;&quot;這就像是一個七年磨一劍的&#39;一夜成名&#39;故事，&quot;Simons 表示。StackBlitz 的生存策略也起到了關鍵作用，他們在整個過程中保持了極低的支出和精簡的團隊。&quot;我和我的聯合創始人以前曾經引導一家公司直至被收購，所以我們知道如何使每一美元發揮超出任何人認為合理或可能的價值。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;七、小團隊實現高速增長的秘訣&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;儘管 Bolt 正在以前所未有的速度增長，但 StackBlitz 仍然是一個只有 15-20 人的小團隊。當被問及如何管理這種增長時，Simons 強調了兩個關鍵因素：技術和人員。&lt;/p&gt; 
&lt;p&gt;&quot;我們團隊中有大約 5-7 人已經在這裏工作了五年多，這在初創公司中相當罕見，&quot;Simons 指出。&quot;我們的策略一直是減少人員，增加每人的背景知識。每個人在公司裏都瞭解其他所有事情，這樣他們可以獨立做出準確的決策。&quot;&lt;/p&gt; 
&lt;p&gt;StackBlitz 採用了每天召開全公司會議的做法，使每個人都瞭解正在發生的一切。儘管這聽起來可能效率低下，但 Simons 辯解説：&quot;當你處於極端增長期時，你希望溝通損失接近於零。雖然這不是我們永遠會做的事情，但在目前的階段，它非常有效。&quot;&lt;/p&gt; 
&lt;p&gt;在工具方面，團隊使用 Linear 進行工程任務，使用 Notion 進行產品路線圖，使用 Figma 進行設計。有趣的是，他們現在也在使用 Bolt 進行許多設計和原型製作工作，因為它比傳統工具更快。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;八、Anthropic 的 Sonnet 模型：AI 編碼的臨界點突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在訪談中一個令人驚訝的發現是，Anthropic 的 Claude 3.5 Sonnet 模型在 Bolt 的成功中起到了關鍵作用。Simons 稱之為 AI 生成可靠代碼的&quot;臨界點&quot;。&lt;/p&gt; 
&lt;p&gt;&quot;在 Sonnet 之前，我們嘗試過構建類似的東西，但它就是不起作用，代碼輸出不夠可靠，應用程序要麼損壞，要麼看起來很醜，&quot;Simons 解釋道。&quot;但當我們在 2023 年 5 月看到 Sonnet 的預覽時，我們知道我們應該重新啓動項目，因為這可能就是機會。&quot;&lt;/p&gt; 
&lt;p&gt;這一見解揭示了為什麼自 Sonnet 發佈以來，&quot;文本到應用程序&quot;工具的快速增長。Simons 指出，軟件是確定性的，使其成為 AI 訓練的理想領域：&quot;當你編寫代碼並點擊運行時，它要麼運行，要麼不運行。這使得訓練數據的創建和強化學習變得更加可靠。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，這些成功是基於 2023 年 6 月發佈的模型，自那以來 Anthropic 還沒有發佈新模型。&quot;這是 AI 編碼可能達到的最差狀態，而且已經這麼好了。下一個模型將使這一切變得更好，而且很快就會到來。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;九、AI 時代的職業前景：產品經理的黃金時代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;當討論到 AI 對軟件開發角色的影響時，Simons 提出了一個與許多流行觀點相反的看法。他認為產品經理 (PM)，而非工程師，可能是 AI 編碼革命的最大受益者。&lt;/p&gt; 
&lt;p&gt;&quot;當 Bolt 開始增長時，我們發現大多數用户不是開發者，而是產品經理、設計師和非技術企業家。這真正改變了一切，&quot;Simons 解釋道。&quot;整個軟件世界秩序將被重寫，因為組織構建軟件的方式將完全改變。&quot;&lt;/p&gt; 
&lt;p&gt;Simons 認為，產品經理精通定義範圍並幫助開發者調試問題，這與成功使用 AI 開發代理所需的技能高度重合。&quot;如果你快進 1-5 年，PM 將不再只是寫 JIRA 工單然後等待開發者完成，他們將能夠自己進行更改。&quot;&lt;/p&gt; 
&lt;p&gt;工程師仍然很重要，但他們將專注於 LLM 不適合的智力挑戰任務。&quot;這對每個人都是好事，&quot;Simons 強調。&quot;工程師可以專注於困難的挑戰，而不是製作另一個 CRUD（增刪改查）應用程序，而 PM 和設計師可以直接將他們的願景轉化為軟件。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十、未來功能與願景：與 Figma 和 Slack 的集成&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;展望未來，Bolt 正在開發幾個令人興奮的新功能。一個主要的即將推出的集成是與 Figma 的深度連接。用户只需在 Figma URL 前添加&quot;bolt.new&quot;並按回車，就能將設計導入 Bolt 並轉換為全棧應用或移動應用。&lt;/p&gt; 
&lt;p&gt;&quot;這將是瘋狂的，&quot;Simons 興奮地説。&quot;從 Figma 到全棧應用，只需一次點擊，字面意思。當你是開發者、設計師或其他角色時，將設計轉化為實際的編碼應用並能繼續從那裏提示，這真的很有趣。&quot;&lt;/p&gt; 
&lt;p&gt;另一個即將推出的功能是與 Slack 的集成，這將使團隊能夠直接在他們的通信中使用 Bolt。&quot;我們正在創建一個 Slack 機器人，其工作是基本上像你團隊中的開發者一樣行動，&quot;Simons 解釋道。&quot;你可以在一個線程中説&#39;嘿，我認為我們應該添加一個主頁&#39;，然後@Bolt&#39;你能快速做出這個嗎？&#39;它會獲取對話歷史，理解需求，並生成應用程序。&quot;&lt;/p&gt; 
&lt;p&gt;這些集成反映了 Simons 對 AI 如何改變產品開發的更廣泛願景，使非技術人員能夠直接創建他們想象的產品。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十一、使用 Bolt 的建議：像與開發者交流一樣與 AI 交流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;當被問及給新 Bolt 用户的建議時，Simons 提供了一個簡單但有力的建議：&quot;像寫線程工單或 JIRA 工單一樣與它交流。將它視為你團隊中的開發者。&quot;&lt;/p&gt; 
&lt;p&gt;他解釋説，這意味着在重要的事情上要具體，但也要允許 AI 在適當的領域發揮創意。&quot;你可以只告訴它&#39;讓它更漂亮&#39;，它會做得很好。事實上，它做得非常好。&quot;&lt;/p&gt; 
&lt;p&gt;對於初次使用的人，Simons 建議從個人網站開始：&quot;這有一種魔力。你複製粘貼你的 LinkedIn 簡歷，説&#39;我需要一個網站。我的名字是某某。這是我的 LinkedIn 歷史。我喜歡藍色和狗。&#39;點擊回車，然後你可以部署它。如果你還沒有.com 域名，現在你可以擁有一個真正的個人網站。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十二、從 AOL 總部蹭住到建立價值數千萬的公司&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在採訪的最後，Simons 分享了他早年在硅谷的一段驚人經歷。2012 年，19 歲的他參加了一個教育科技孵化器項目，該項目位於 AOL 總部。當資金耗盡時，他注意到這個辦公室有沙發、食物、健身房，甚至還有淋浴和洗衣設施。&lt;/p&gt; 
&lt;p&gt;&quot;我想，也許在弄清楚這一切的同時，我可以住在這裏，&quot;Simons 回憶道。&quot;所以我最終在這裏住了四五個月。&quot;他通過在夜間編碼來避開保安，白天和夜間輪班的保安以為他只是一個工作非常努力的員工。&lt;/p&gt; 
&lt;p&gt;生活費用？&quot;當時我的花費是每天一美元。那是麥當勞還有一美元菜單的時候。&quot;最終，一名保安發現了他並將他趕了出去，但這段經歷展示了他早期的創業精神和生存能力。&lt;/p&gt; 
&lt;p&gt;Simons 的故事，從 AOL 總部蹭住到建立一家在幾個月內達到 4000 萬美元 ARR 的公司，展示了他一直以來的堅韌和創新精神。正如他所説：&quot;這一切都是關於保持活力，並採取儘可能多的嘗試。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;結論：AI 編碼的未來與更廣泛的影響&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的故事不僅是關於一個成功的產品，還是關於技術進步如何徹底改變我們構建軟件的方式。從這次採訪中，我們可以看到幾個關鍵趨勢：&lt;/p&gt; 
&lt;p&gt;1. 文本到應用程序技術正在迅速成熟，使非技術人員能夠創建以前需要專業開發團隊的應用程序。&lt;/p&gt; 
&lt;p&gt;2. 基於瀏覽器的計算正在獲得新的重要性，提供比基於雲的替代方案更快、更可靠的體驗。&lt;/p&gt; 
&lt;p&gt;3. AI 編碼工具正在重塑公司的組織結構，可能導致產品和設計角色的重要性增加。&lt;/p&gt; 
&lt;p&gt;4. 我們可能正處於一場軟件開發革命的邊緣，這場革命將使創建功能全面的應用程序變得像使用文字處理器一樣容易&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339630</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339630</guid>
            <pubDate>Wed, 05 Mar 2025 09:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>小米汽車模型訓練專利公佈，可解決資源消耗較大等技術問題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查知識產權信息顯示，小米汽車科技有限公司申請的「模型訓練方法、使用方法、裝置、設備及存儲介質」專利公佈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要顯示，其中所述模型訓練方法包括：將第一物理參數和第一性能數據輸入第一模型，得到所述第一物理參數和所述第一性能數據的多個關聯關係；將所述第一物理參數輸入到取值模塊，得到第二物理參數，所述取值模塊基於所述第一物理參數計算出目標取值集合，在所述目標取值集合中選取所述第二物理參數；將所述第二物理參數輸入所述第一模型，得到多個第二性能數據；基於所述多個第二性能數據，更新所述第一模型，得到第二模型。這樣，能解決相關技術中存在的模型訓練的精度和效率較低、資源消耗較大等技術問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-72b7dc543a47a38cd1a8d9a37c54723f663.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339627</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339627</guid>
            <pubDate>Wed, 05 Mar 2025 09:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AgentOps —— AI 代理的可觀察性和 DevTool 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;AgentOps 是一個幫助開發人員&lt;/span&gt;測試、調試和部署 AI 代理和 LLM 應用程序的平台&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;。與大多數 LLM 和代理框架集成，包括 OpenAI Agents SDK、CrewAI、Langchain、Autogen、AG2 和 CamelAI。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Replay Analytics 和 Debugging&lt;/strong&gt; 代理逐步執行圖&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM 成本管理&lt;/strong&gt; 跟蹤 LLM 基礎模型提供商的支出&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代理基準測試&lt;/strong&gt; 根據 1,000 多個評估測試您的代理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合規性和安全性&lt;/strong&gt; 檢測常見的即時注入和數據泄露漏洞&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;框架集成&lt;/strong&gt; 與 CrewAI、AG2 (AutoGen)、Camel AI 和 LangChain 的原生集成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;237&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/182656_cKyN_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/agentops</link>
            <guid isPermaLink="false">https://www.oschina.net/p/agentops</guid>
            <pubDate>Wed, 05 Mar 2025 09:09:00 GMT</pubDate>
        </item>
        <item>
            <title>崑崙萬維開源 R1V 視覺思維鏈推理模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;崑崙萬維宣佈正式開源首款工業界多模態思維鏈推理模型 Skywork R1V，即日起開源模型權重和技術報告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，Skywork R1V 具備超強的視覺理解和推理能力。「無論是日常繁瑣的工作任務、複雜的數據分析、難以解答的學術問題，還是前所未見的陌生場景，都可以交給 Skywork R1V 進行高效處理。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Reasoning 推理能力方面，Skywork R1V 實現了模型的頂尖邏輯推理與數學分析能力。在權威的 MATH500 和 AIME 基準測試中，Skywork R1V 分別取得了 94.0 和 72.0 的高分，明顯領先於行業內眾多主流模型。Skywork R1V 在純文本複雜推理任務中展現出卓越性能，使其在邏輯推理和數學問題求解領域展現出人類專家級別的水準。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Vision 視覺理解能力方面，Skywork R1V 成功地將其強大的文本推理與思維鏈推導能力高效遷移到視覺任務中。憑藉創新的跨模態遷移技術與推理優化框架，Skywork R1V 能夠高效解決需要多步視覺推理的問題，在 MMMU 與 MathVista 等視覺推理基準中分別取得了 69 和 67.5 的優異成績。這些結果不僅明顯超越了多個近似大小的開源競爭模型，更達到與規模更大的閉源模型媲美的水準，充分證實了 Skywork R1V 在需要視覺思維鏈推理的跨模態任務中的領先優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Skywork R1V 通過視覺與文本能力的深度融合和視覺思維鏈推理能力的突破，推動了多模態推理模型的進一步發展，標誌着人工智能領域的又一重大進步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Skywork R1V 已全面開源。和開源同規模或更大規模模型的對比，Skywork R1V 38B 體現出行業顯著優異的推理能力，以及領先的多模態視覺理解能力。如下圖，與開源同規模或更大規模模型的對比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e032223e7b259303f6e6f7cce7dde417a6f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;與閉源頭部模型性能對比，R1V 38B 模型性能媲美甚至超越更大開源模型以及主流閉源模型。如下圖，與開源大尺寸模型與閉源專有模型的對比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;332&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-673a31430f860afa0908dd05aeaa3ad9c22.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339599</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339599</guid>
            <pubDate>Wed, 05 Mar 2025 07:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>理想汽車發佈下一代自動駕駛架構 MindVLA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 18 日，在 NVIDIA GTC 2025 上，理想汽車發佈了下一代自動駕駛架構 MindVLA。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ee07e92de4f6f16747c4c6b166e3b3f2f7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;理想汽車自動駕駛技術研發負責人賈鵬發表了主題演講《VLA：邁向自動駕駛物理智能體的關鍵一步》，分享了理想汽車對於下一代自動駕駛技術 MindVLA 的最新思考和進展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b55c3282e8382e3f4257e15bbf23fee737f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;賈鵬表示：「MindVLA 是機器人大模型，它成功整合了空間智能、語言智能和行為智能，一旦跑通物理世界和數字世界結合的範式後，將有望賦能更多行業。MindVLA 將把汽車從單純的運輸工具轉變為貼心的專職司機，它能聽得懂、看得見、找得到。我們希望 MindVLA 能為汽車賦予類似人類的認知和適應能力，將其轉變為能夠思考的智能體。」&lt;/p&gt; 
&lt;p&gt;理想汽車 CEO 李想&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1243861097%2FPj5JY3Gsr%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;介紹稱&lt;/a&gt;&lt;/u&gt;：「&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;MindVLA 是一個視覺-語言-行為大模型，但我們更願意將其稱為‘機器人大模型’，它將空間智能、語言智能和行為智能統一在一個模型裏，讓自動駕駛擁有感知、思考和適應環境的能力，是我們通往 L4 路上最重要的一步。&lt;/strong&gt;&lt;/span&gt;」&lt;/p&gt; 
&lt;p&gt;李想還表示：「MindVLA 能為自動駕駛賦予類似人類的駕駛能力，就像 iPhone 4 重新定義了手機，MindVLA 也將重新定義自動駕駛。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339597</guid>
            <pubDate>Wed, 05 Mar 2025 07:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟量子計算機研發曾遭 CEO 納德拉否定</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微軟上月&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot;&gt;宣佈&lt;/a&gt;了一項重大科研進展，聲稱已成功製造出能夠產生馬約拉納費米子的芯片，這一成果被視為量子計算領域的一大突破。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0220/104630_5Gkb_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微軟方面表示，這一技術突破有望將量子設備的問世時間大幅提前，從原本預估的幾十年縮短至幾年之內。儘管這一消息在科技界引起了廣泛關注，但並非所有物理學家都對微軟的説法表示完全信服。&lt;/p&gt; 
&lt;p&gt;然而，微軟 CEO 薩蒂亞·納德拉卻對此成果顯得頗為滿意。據悉，微軟每年在量子研究上的投入高達 3 億美元，儘管與人工智能等領域的投資相比，這一數字顯得微不足道，但微軟在量子領域的持續投入已累積近二十年，如今終於取得了階段性成果。&lt;/p&gt; 
&lt;p&gt;值得注意的是，微軟在量子計算領域的進展並非一帆風順。據知情人士透露，七年前，納德拉曾在公司內部對微軟的量子研究表示懷疑，認為其缺乏商業潛力。然而，隨着谷歌和 D-WaveQuantum 等競爭對手在量子計算方面取得進展，微軟的科學家們也意識到自己正處於一場激烈的競賽之中。&lt;/p&gt; 
&lt;p&gt;儘管如此，微軟方面仍對自身的科研成果充滿信心。負責監督相關團隊的高管賈森·贊德表示，公司正準備發表《自然》論文的後續研究，並已邀請一組獨立研究人員對其進行評審。&lt;/p&gt; 
&lt;p&gt;同時，微軟發言人強調，公司會秉持最高的學術道德標準，確保研究成果的真實性和可靠性。&lt;/p&gt; 
&lt;p&gt;閲讀更多：&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot; target=&quot;news&quot;&gt;微軟發佈首款量子計算芯片「Majorana 1」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339592</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339592</guid>
            <pubDate>Wed, 05 Mar 2025 07:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 首席 AI 科學家楊立昆評價人形機器人：演示驚豔、實際很蠢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;圖靈獎得主、Meta 首席 AI 科學家楊立昆近日在一檔播客節目中對人形機器人發表了「鋭評」，他表示：「&lt;strong&gt;很多人形機器人演示令人印象深刻，但實際很蠢，不少機器人公司都在豪賭未來 3 到 5 年 AI 會突飛猛進。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/151624_dBd1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;楊立昆認為，目前我們仍然沒有家用機器人，也沒有能夠完成貓或狗所能完成任務的機器人，更沒有完全自主的 L5 級自動駕駛汽車。他強調，&lt;strong&gt;我們所欠缺的是如何訓練一個系統來理解像視覺這樣複雜的感官輸入&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;楊立昆進一步指出，如果我們能夠構建出理解物理世界、擁有持久記憶、能夠推理和規劃的 AI 系統，那我們就有了為機器人提供動力的 AI 基礎。這樣的機器人會比我們現有的機器人靈活得多。他提到，過去一兩年裏，成立了很多機器人公司，他們製造人形機器人和類似的技術。雖然所有的演示都令人印象深刻，但這些機器人實際上都很蠢。它們不能做人類能做的事情，不是因為它們缺乏身體能力，而是因為它們根本不夠聰明，無法駕馭現實世界的複雜性。&lt;/p&gt; 
&lt;p&gt;楊立昆還提出，很多這樣的公司都寄希望於 AI 在未來 3 到 5 年內會取得快速進展。他們預計到他們準備好大規模生產和銷售這些機器人時，AI 的進步將使它們足夠智能。&lt;/p&gt; 
&lt;p&gt;然而，楊立昆認為這是一場豪賭，他無法確定這是否能在三至五年內實現。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339582</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339582</guid>
            <pubDate>Wed, 05 Mar 2025 07:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>澳門即將全面結束 3G 時代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;澳門特區政府於 2022 年向澳門四間流動電信服務營運商延長 3G 牌照兩年，&lt;strong&gt;該牌照將於 2025 年 6 月 4 日屆滿，澳門 3G 移動電信網絡及服務將隨着牌照屆滿而終止&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-952129e924f58e0fc3e136e05bebebc548b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;針對上述情況，澳門已敦促各運營商為 3G 退網做好準備工作。&lt;/p&gt; 
&lt;p&gt;澳門郵電局呼籲使用 3G 服務的市民及商户，請儘早聯絡相關電信營運商，瞭解轉換到 4G 或 5G 服務的條件，選擇最適合自身需求的服務。此外，市民及商户亦應留意手機或其他終端設備是否支持 4G 或 5G 制式，如需語音通話，有關設備更需支持 4G 語音通話功能（VoLTE），用户可按自身需要適時更換設備，確保能繼續享用電信服務。&lt;/p&gt; 
&lt;p&gt;澳門郵電局局長劉惠明日前表示，隨着通信業的發展進程，3G 流動電信網絡及服務將於 6 月隨着牌照屆滿而終止。劉惠明稱，目前仍有約 1 萬多名用户，有一部分是非活躍用户。局方正敦促營運商與合作伙伴處理有關問題，並要求營運商加強宣傳推廣 3G 在 6 月退場的訊息。&lt;/p&gt; 
&lt;p&gt;澳門電訊 CTM 也稱，將於 2025 年 6 月起正式與 3G 網絡服務告別。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-22f36d1bf91bacce6a45e473812d8130769.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;澳門電訊會通過短信通知仍使用 3G 服務的客户，及時更新服務計劃及設備。客户亦可通過撥打 #183# 查詢設備是否支持 4G / 5G 網絡以及 VoLTE 話音功能。如有任何疑問或需協助，可親臨任何一間 CTM 門市或致電 CTM 服務第一熱線：1000 查詢。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339576</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339576</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「RdbStore」上線開源鴻蒙社區，助力鴻蒙應用數據訪問效率大幅提升</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，由夥伴參與共建的鴻蒙關係映射數據庫「RdbStore」正式上線 OpenHarmony 社區，為鴻蒙生態開發者提供了簡單高效的關係映射數據庫方案選擇。該數據庫性能和功能強大，可支持數據庫自動升級、品質調優、全鏈路運維等，能夠有效提升應用啓動和訪問速度，助力應用高效開發和性能提升。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;性能強大：數據訪問和初始化耗時大幅優化&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;在應用開發過程中，數據訪問的效率直接影響應用的啓動和訪問速度，「RdbStore」的推出讓鴻蒙應用數據訪問更加高效便捷。相比於其他關係映射數據庫，「RdbStore」在性能方面做了諸多優化，包括：簡化 DB 構建方式，優化核心框架架構；隔離同庫中各表的解析創建，縮短各表的初始化耗時；抽象 SQL 語句書寫方式，避免魔法值、SQL 語句方式訪問 DB，便捷進行復雜 DB 操作；提升反序列化能力，優化 ResultSet 到 DTO 的構建過程，避免對象深拷貝導致的耗時。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;通過這些優化，「RdbStore」能夠顯著提升數據訪問性能，單元測試 20 張數據表結構下，數據庫訪問耗時減少 76%[1]，確保數據高效讀寫，加速應用響應，提升用户體驗。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;功能豐富：自動升級，便捷監測運行狀態&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;「RdbStore」不僅具備卓越的性能，還提供了豐富的功能支持，大大降低了數據庫維護成本。其具備數據庫自動升級功能，可在運行時動態計算不同版本的表結構差異，自動生成遷移語句，開發者無需維護複雜易錯的升級邏輯。同時支持品質調優 API，可調整日誌模式、頁大小等關鍵參數，使開發者能夠靈活優化數據庫性能。此外，「RdbStore」還具備全鏈路日誌與打點功能，能夠採集數據庫運行時的品質數據，構建完善的數據庫指標體系，幫助開發者實時監測數據庫狀態並進行優化調整，從而確保數據庫的高效穩定運行。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;在實際應用中，「RdbStore」也展現了卓越的性能表現。運用「RdbStore」進行開發之後，該鴻蒙應用數據庫加載首刷耗時 86ms，相比 Android 版 294ms 的首刷耗時，優化幅度高達 70%[2]，顯著提升了應用的冷啓動速度。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;無論是性能優化還是功能增強，「RdbStore」都展現了強大的技術實力，助力開發者打造更流暢、更穩定的鴻蒙應用。目前，「RdbStore」已在 OpenHarmony 社區正式上線並開源，希望更多應用廠商下載使用，並參與到共建行列，共同推進這一項目的持續優化和完善。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;歡迎更多夥伴和開發者們一起加入鴻蒙生態，貢獻更多智慧與活力。未來華為也將持續攜手生態夥伴共建創新，面向底座技術、通用能力、垂類行業等場景推出系列開發者場景化解決方案，不斷提升鴻蒙應用的創新體驗和開發效率，與廣大開發者共建繁榮的鴻蒙生態。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;更多關於「RdbStore」的詳細信息和使用指南，請訪問「OpenHarmony 官網」，點擊「開發者」——&amp;gt;「三方庫中心倉」——&amp;gt;搜索「RdbStore」。&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;[1]數據來源：廠商測試所得數據&lt;/p&gt; 
&lt;p style=&quot;color:#555555; margin-left:0; margin-right:0; text-align:left&quot;&gt;[2]數據來源：廠商測試所得數據&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339575</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339575</guid>
            <pubDate>Wed, 05 Mar 2025 07:04:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>華科大研發領先的「玻璃光盤」技術：理論容量最高 360TB、成本僅 1/10</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FroBVlcZaikjurKymBpvpYQ&quot; target=&quot;_blank&quot;&gt;《長江日報》報道稱&lt;/a&gt;&lt;/u&gt;，武漢光電國家研究中心信息存儲系統教育部重點實驗室研發出了一種「玻璃光盤」，存儲容量目前是普通光盤的 10 倍，理論容量最高 360TB，而且幾乎可以永久保存。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;921&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/145326_59D9_2720166.png&quot; width=&quot;1235&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;一塊普通的玻璃如何讓它有記憶的功能，報道介紹稱，首先要在玻璃中產生結構，引起玻璃的化學性質變化，而完成這個任務的便是飛秒激光，類似於光刻，過去家用光刻機只能刻一層，而華科大團隊能刻 400 層。製作成的玻璃存儲介質從表面看只增加了一層淺灰色，而在顯微鏡下玻璃表面呈現出的是三維立體結構。如何把結構又快又好寫進玻璃裏，工藝是關鍵。&lt;/p&gt; 
&lt;p&gt;該技術被稱之為「巨量信息低成本超長壽命玻璃多維存儲技術」，目前華科大在該項技術上全球領先，國內也是獨有的。相比於幾年前，玻璃存儲介質讀寫速度較過去快了 3 個數量級，單位體積的存儲容量也提升了 2 個數量級，成本則下降了 1 個數量級。現在 1GB 的介質成本需要約 1 元，而玻璃存儲介質 1TB 也才幾十元，只有其他存儲介質十分之一的成本。&lt;/p&gt; 
&lt;p&gt;目前，製造玻璃介質存儲的設備已生產出原型樣機，今年將推出產品樣機，產品也將很快走向市場。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339573</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339573</guid>
            <pubDate>Wed, 05 Mar 2025 06:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 3FS 與 JuiceFS：架構與特性比較</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;近期，DeepSeek 開源了其文件系統 Fire-Flyer File System (3FS)，使得文件系統這一有着 70 多年曆時的&quot;古老&quot;的技術，又獲得了各方的關注。在 AI 業務中，企業需要處理大量的文本、圖像、視頻等非結構化數據，還需要應對數據量的爆炸式增長，分佈式文件系統因此成為 AI 訓練的關鍵存儲技術。&lt;/p&gt; 
&lt;p&gt;本文旨在通過深入分析 3FS 的實現機制，並與 JuiceFS 進行對比，以幫助用户理解兩種文件系統的區別及其適用場景。同時，我們將探討 3FS 中的值得借鑑的創新技術點。&lt;/p&gt; 
&lt;h2&gt;01 架構對比&lt;/h2&gt; 
&lt;h3&gt;3FS&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2F3FS&quot; target=&quot;_blank&quot;&gt;3FS&lt;/a&gt; (Fire-Flyer File System) 是一款高性能的分佈式文件系統，專為解決 AI 訓練和推理工作負載而設計，該系統使用高性能的 NVMe 和 RDMA 網絡提供共享存儲層。3FS 由 DeepSeek 在 2025 年 2 月開源。 3FS 主要包括以下模塊：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集羣管理服務（Cluster Manager）&lt;/li&gt; 
 &lt;li&gt;元數據服務（Metadata Service）&lt;/li&gt; 
 &lt;li&gt;存儲服務（Storage Service）&lt;/li&gt; 
 &lt;li&gt;客户端 （FUSE Client、Native Client）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-96308079c12c6210e0436722cad35b7c636.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所有模塊通過 RDMA 網絡通信。元數據服務和存儲服務向集羣管理服務發送心跳信號。集羣管理服務負責處理成員變更，並將集羣配置分發給其他服務和客户端。為了提高系統的可靠性和避免單點故障，會部署多個集羣管理服務，其中一個被選為主節點。當主節點發生故障時，另一個管理器會被提升為主節點。集羣配置通常存儲在可靠的分佈式服務中，例如 ZooKeeper 或 etcd。&lt;/p&gt; 
&lt;p&gt;當進行文件元數據操作（例如打開或創建文件/目錄），請求被髮送到元數據服務，以實現文件系統語義。元數據服務有多個，並且是無狀態的，它們不直接存儲文件元數據，而是依賴支持事務的鍵值數據庫 FoundationDB 來存儲這些數據。因此，客户端可以靈活地連接到任意元數據服務。這種設計使得元數據服務可以在沒有狀態信息的情況下獨立運作，進而增強了系統的可伸縮性和可靠性。&lt;/p&gt; 
&lt;p&gt;每個存儲服務管理若干本地 SSD，並提供 chunk 存儲接口。存儲服務採用 CRAQ （ Chain Replication with Apportioned Queries）來確保強一致性。3FS 中存儲的文件被拆分為默認 512K 大小相等的塊，並在多個 SSD 上進行復制，從而提高數據的可靠性和訪問速度。&lt;/p&gt; 
&lt;p&gt;3FS 客户端提供兩種接入方式： FUSE Client 和 Native Client。 FUSE Client 提供常見 POSIX 接口的支持，簡單易用。Native Client 提供更高的性能，但是用户需要調用客户端 API ，具有一定的侵入性，下文我們還將對此作更詳盡的解析。&lt;/p&gt; 
&lt;h3&gt;JuiceFS&lt;/h3&gt; 
&lt;p&gt;JuiceFS 是一個雲原生分佈式文件系統，其數據存儲在對象存儲中。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjuicedata%2Fjuicefs&quot; target=&quot;_blank&quot;&gt;社區版&lt;/a&gt;可與多種元數據服務集成，適用場景廣泛，於 2021 年在 GitHub 開源。企業版專為高性能場景設計，廣泛應用於大規模 AI 任務，涵蓋生成式 AI、自動駕駛、量化金融和生物科技等。 JuiceFS 文件系統包括三部分組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;元數據引擎：用於存儲文件元數據，包括常規文件系統的元數據和文件數據的索引。&lt;/li&gt; 
 &lt;li&gt;數據存儲：一般是對象存儲服務，可以是公有云的對象存儲也可以是私有部署的對象存儲服務。&lt;/li&gt; 
 &lt;li&gt;JuiceFS 客户端：提供 POSIX（FUSE）、Hadoop SDK、CSI Driver、S3 網關等不同的接入方式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bed8225b825f4a839eca178b415fc4b67db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;架構差異&lt;/h3&gt; 
&lt;p&gt;從模塊劃分上看兩個文件系統差異不大，都採用了元數據與數據分離的設計，各個模塊功能也較類似。不同於 3FS 和 JuiceFS 企業版，JuiceFS 社區版兼容多種開源數據庫存儲元數據，對元數據的操作都封裝在客户端，用户不需要再單獨運維一個無狀態的元數據服務。&lt;/p&gt; 
&lt;h4&gt;存儲模塊&lt;/h4&gt; 
&lt;p&gt;3FS 使用大量本地 SSD 進行數據存儲，為了保證數據存儲的一致性，3FS 使用 CRAQ 這一簡潔的數據一致性算法 。幾個副本被組成一個 Chain，寫請求從 Chain 的 Head 開始，一直到達 Chain 的 Tail 時返回寫成功應答。讀請求可以發送到 Chain 的所有副本，如果讀到髒節點的數據，該節點會聯繫 Tail 節點檢查狀態。如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4b03df1057d9942ff363f034bee15053b6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;數據的寫入是按順序逐節點傳遞，因此會帶來比較高的延時。如果 Chain 當中的某個副本不可用， 3FS 會把這個副本移到 Chain 的末尾，等副本可用的時候再做恢復。恢復的時候需要把整個 Chunk 的內容複製到這個副本，而非使用不可用期間的增量數據。如果要做到同步寫所有副本和增量恢復數據，那寫的邏輯會複雜非常多，比如 Ceph 使用 pg log 保證數據一致性。儘管 3FS 這種設計會導致寫延遲，但是對於以讀為主的 AI 應用場景，影響不大。&lt;/p&gt; 
&lt;p&gt;JuiceFS 利用對象存儲作為數據存儲解決方案，從而可享有對象存儲帶來的若干優勢，如數據可靠性、一致性等。存儲模塊提供了一組用於對象操作的接口，包括 GET/PUT/HEAD/LIST 等，用户可以根據自己的需求對接具體的存儲系統。比如不同雲廠商的對象存儲，也可以選擇私有部署的對象存儲比如 MinIO、Ceph RADOS 等系統。社區版 JuiceFS 提供本地緩存來應對 AI 場景下的帶寬需求，JuiceFS 企業版使用分佈式緩存滿足更大的聚合讀帶寬的需求。&lt;/p&gt; 
&lt;h4&gt;元數據模塊&lt;/h4&gt; 
&lt;p&gt;在 3FS 中，文件的屬性以 KV 的形式存儲在元數據服務中。該服務是一個無狀態的高可用服務，依靠 FoundationDB 做支撐。FoundationDB 是 Apple 開源的優秀分佈式 KV 數據庫，具有很高的穩定性。FoundationDB 所有鍵值使用 Key 做全局排序，然後均勻拆分到不同的節點上。&lt;/p&gt; 
&lt;p&gt;為了優化 list 目錄的效率，3FS 使用字符 &quot;DENT&quot; 前綴加父目錄 inode 號和名字作為 dentry 的 Key。Inode 的 Key 是通過將 &quot;INOD&quot; 前綴與 inode ID 連接而構造的，其中 inode ID 採用小端字節序編碼，以便將 inodes 分佈到多個 FoundationDB 節點上。這個設計與 JuiceFS 使用的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Finternals%2F%23tkv&quot; target=&quot;_blank&quot;&gt;TKV（Transactional Key-Value Database）&lt;/a&gt; 進行元數據服務的存儲方式類似。&lt;/p&gt; 
&lt;p&gt;JuiceFS 社區版的元數據模塊，與存儲模塊類似也提供一組操作元數據的接口，可以接入不同的元數據服務，比如 Redis，TiKV 等 KV 數據庫，MySQL，PostgreSQL 等關係型數據庫，也可以使用 FoundationDB。JuiceFS 企業版使用自研高性能元數據服務，可根據負載情況來平衡數據和熱點操作，以避免大規模訓練中元數據服務熱點集中在某些節點的問題（比如因為頻繁操作臨近目錄文件的元數據引起）。&lt;/p&gt; 
&lt;h4&gt;客户端&lt;/h4&gt; 
&lt;p&gt;3FS 的客户端除了提供 FUSE 操作外，還提供了一組 API 用於繞過 FUSE 直接操作數據，也就是 Native Client，接口的調用方式有點類似於 Linux AIO。這組 API 的作用是避免使用 FUSE 模塊帶來的數據拷貝，從而減少 I/O 延遲和對內存帶寬的佔用。下面將詳細解析這組 API 如何實現用户進程與 FUSE 進程之間的零拷貝通信。&lt;/p&gt; 
&lt;p&gt;3FS 通過 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存共享內存的大小，地址和其他一些屬性，使用 &lt;code&gt;IoRing&lt;/code&gt; 在兩個進程間通信。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-abcb70acca194a50f90a6a422695f8d89db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當用户調用接口，創建 &lt;code&gt;hf3fs_iov&lt;/code&gt; 時，會在 &lt;code&gt;/dev/shm&lt;/code&gt; 上分配內存,並創建一個指向這個共享內存的軟鏈接，軟鏈接的地址位於 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt;,這是個虛擬目錄。3FS FUSE 進程收到創建軟鏈接請求，並且發現它的地址位於上述虛擬目錄後，就會根據軟鏈接的名字解析出這塊共享內存的相關參數，並將內存的地址註冊到所有 RDMA 設備（除了 &lt;code&gt;IORing&lt;/code&gt; ）。&lt;code&gt;ibv_reg_mr&lt;/code&gt; 返回的結果被存在 &lt;code&gt;RDMABuf::Inner&lt;/code&gt; 數據結構中，用於後續發送 RDMA 請求。&lt;/p&gt; 
&lt;p&gt;同時，&lt;code&gt;IORing&lt;/code&gt; 的內存也使用 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存，只是在創建對應的軟鏈接時，文件名中會有更多的 &lt;code&gt;IORing&lt;/code&gt; 相關的信息。如果 FUSE 進程發現這個內存是用於創建 &lt;code&gt;IORing&lt;/code&gt;，也會在它的進程內創建對應的 &lt;code&gt;IORing&lt;/code&gt;。這樣設置之後，用户進程和 FUSE 進程就可以訪問相同的 &lt;code&gt;IORing&lt;/code&gt; 了。&lt;/p&gt; 
&lt;p&gt;進程間協作方面，3FS 在 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt; 目錄中創建 3 個不同的虛擬文件用於共享 3 個不同優先級的提交信號量 （submit sem ），用户進程將請求放到 &lt;code&gt;IORing&lt;/code&gt; 後使用這些信號量通知 FUSE 進程有新的請求。 &lt;code&gt;IORing&lt;/code&gt; 尾部包含請求完成信號量，FUSE 進程通過調用 &lt;code&gt;sem_post&lt;/code&gt; 通知用户進程 &lt;code&gt;IORing&lt;/code&gt; 上有新的請求完成。以上整個機制確保了兩個進程間的高效數據通信和操作同步。&lt;/p&gt; 
&lt;p&gt;3FS 的 FUSE 客户端實現了文件和目錄的基本操作，而 JuiceFS FUSE 客户端的實現更加全面。比如，在 3FS 文件系統中文件的長度是最終一致的，這意味着在寫的過程中用户可能訪問到不正確的文件長度。而 JuiceFS 在每次成功上傳對象後會立即更新文件長度。此外，JuiceFS 還提供了以下這些常用的高級文件系統功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 BSD 鎖（flock）和 POSIX 鎖（fcntl）&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;file_copy_range&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;readdirplus&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;fallocate&lt;/code&gt; 接口&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除了 FUSE 客户端，JuiceFS 還提供 Java SDK，S3 Gateway，CSI Driver 等接入方式。企業版還提供 Python SDK，Python SDK 將 JuiceFS 客户端在用户進程中運行，避免了通過 FUSE 導致的額外性能開銷。具體見文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcloud%2Fdeployment%2Fpython-sdk%2F&quot; target=&quot;_blank&quot;&gt;Python SDK&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;02 文件分佈對比&lt;/h2&gt; 
&lt;h3&gt;3FS 文件分佈&lt;/h3&gt; 
&lt;p&gt;3FS 將每個文件分成固定長度的 chunk，每個 chunk 位於一個上文提到的鏈上（ CRAQ 算法）。用户使用 3FS 提供的一個腳本，生成一個 chain table。然後將這個表提交到元數據服務。創建新文件時，系統會從表中選取特定數量的 chain （數量由 stripe 定義），並將這些 chain 的信息存入文件的元數據中。&lt;/p&gt; 
&lt;p&gt;因為 3FS 中的 chunk 是固定的，客户端只需要獲取一次 inode 的 chain 信息，就可以根據文件 inode 和 I/O 請求，的 offset，length 計算出這個請求位於哪些 chunk 上，從而避免了每個 I/O 都從數據庫查詢的需求。可以通過 &lt;code&gt;offset/chunk_size&lt;/code&gt; 得到 chunk 的索引。 而 chunk 所在的 chain 的索引就是 &lt;code&gt;chunk_id%stripe&lt;/code&gt;。有了 chain 的索引就可以得到 chain 的詳細信息（比如這個 chain 由哪些 target 組成）。然後，客户端根據路由信息將 I/O 請求發送到相應的存儲服務。存儲服務收到寫請求後以 copy-on-write （COW）的方式將數據寫入新的位置。原來的數據在引用數據清零前仍然是可讀的。&lt;/p&gt; 
&lt;p&gt;為了應對數據不平衡問題，每個文件的第一個 chain 按照輪詢（ round roubin） 的方式選擇。比如當 stripe 為 3 時，創建一個文件，其選擇的 chain 為：chain0，chain1，chain2。那麼下一個文件的 chain 為：chain1，chain2 和 chain3。系統會將選擇的 3 個 chain 做隨機排序，然後存儲到元數據中。下圖為 stripe 為 3 時一個文件的分佈示例，chain 隨機排序後的順序是：1，3，2。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cf9e25c0851f3f04955915e8e7ea4ffd658.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;JuiceFS 文件分佈&lt;/h3&gt; 
&lt;p&gt;JuiceFS 按照 Chunk、Slice、Block 的規則進行數據塊管理。每個 Chunk 的大小固定為 64M，主要用於優化數據的查找和定位。實際的文件寫入操作則在 Slice 上執行，每個 Slice 代表一次連續的寫入過程，屬於特定的 Chunk，並且不會跨越 Chunk 的邊界，因此長度不超過 64M。Chunk 和 Slice 主要是邏輯上的劃分，而 Block（默認大小為 4M）則是物理存儲的基本單位，用於在對象存儲和磁盤緩存中實現數據的最終存儲。更多細節可以參考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Farchitecture&quot; target=&quot;_blank&quot;&gt;官網介紹&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-db8518e62e6de3e60bb23e2080a1ee55222.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS 中的 Slice 是在他文件系統中不常見的一個結構。主要功能是記錄文件的寫入操作，並在對象存儲中進行持久化。對象存儲不支持原地文件修改，因此，JuiceFS 通過引入 Slice 結構允許更新文件內容，而無需重寫整個文件。這與 Journal File System 有些類似，其中寫入操作僅創建新對象，而不是覆蓋現有對象。修改文件時，系統會創建新的 Slice，並在該 Slice 上傳完畢後更新元數據，從而將文件內容指向新的 Slice。被覆蓋的 Slice 內容隨後通過異步壓縮過程從對象存儲中刪除，導致在某些時刻對象存儲的使用量會暫時超過文件系統實際使用量。&lt;/p&gt; 
&lt;p&gt;此外，JuiceFS 的所有 Slice 均為一次性寫入，這減少了對底層對象存儲一致性的依賴，並大大簡化了緩存系統的複雜度，使數據一致性更易於保證。這種設計還為實現文件系統的零拷貝語義提供了便利，支持如 copy_file_range 和 clone 等操作。&lt;/p&gt; 
&lt;h2&gt;03 3FS RPC (Remote Procedure Call) 框架&lt;/h2&gt; 
&lt;p&gt;3FS 使用 RDMA 作為底層網絡通信協議，目前 JuiceFS 尚未支持，下面對此做一些分析。&lt;/p&gt; 
&lt;p&gt;3FS 通過實現一個 RPC 框架，來完成對底層 IB 網絡的操作。除了網絡操作外，RPC 框架還提供序列化，小包合併等能力。因為 C++ 不具有反射能力，所以 3FS 還通過模版實現了一個反射庫，用於序列化 RPC 使用的 request、response 等數據結構。需要被序列化的數據結構只需要使用特定的宏定義需要序列化的屬性。RPC 調用都是異步完成的，所以序列化後的數據只能從堆上分配，等待調用完成後再釋放。為了提高內存的分配和釋放速度，分配對象都使用了緩存。3FS 的緩存有兩部份組成，一個 TLS 隊列和一個全局隊列。 從 TLS 隊列獲取緩存時不需要加鎖；當 TLS 緩存為空時就得加鎖，從全局隊列中獲取緩存。所以在最優情況下，獲取緩存是不需要加鎖的。&lt;/p&gt; 
&lt;p&gt;與 I/O 請求的負載不同，緩存對象的內存都未註冊到 RDMA 設備中。因此，當數據到達 IBSocket 後，會被拷貝到一個在 IB 設備註冊過的緩衝區中。多個 RPC 請求可能被合併為一個 IB 請求發送到對端。下圖為 FUSE Client 調用 Meta 服務的 RPC 過程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//58e38641fd7da6914308fa2198428dc9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;04 特性對比&lt;/h2&gt; 
&lt;p&gt;| 對比項 | 3FS | JuiceFS 社區版 | JuiceFS 企業版 | |--------------------|-------------------------------|----------------------------------|----------------------------------------------| | 元數據 | 無狀態元數據服務+FoundationDB | 獨立數據庫服務 | 自研高性能分佈式元數據引擎（可橫向擴展） | | 數據存儲 | 自主管理 | 使用對象存儲 | 使用對象存儲 | | 冗餘保護 | 多副本 | 對象存儲提供 | 對象存儲提供 | | 數據緩存 | 無緩存 | 本地緩存 | 自研高性能多副本分佈式緩存 | | 數據加密 | 不支持 | 支持 | 支持 | | 數據壓縮 | 不支持 | 支持 | 支持 | | 配額管理 | 不支持 | 支持 | 支持 | | 網絡協議 | RDMA | TCP | TCP | | 快照 | 不支持 | 支持克隆 | 支持克隆 | | POSIX ACL | 不支持 | 支持 | 支持 | | POSIX 兼容性 | 少量子集 | 完全兼容 | 完全兼容 | | CSI 驅動 | 沒有官方支持 | 支持 | 支持 | | 客户端 | FUSE + Native Client | POSIX（FUSE）、Java SDK、S3 網關 | POSIX（FUSE）、Java SDK、S3 網關、Python SDK | | 多雲鏡像 | 不支持 | 不支持 | 支持 | | 跨雲和跨區數據複製 | 不支持 | 不支持 | 支持 | | 主要維護者 | DeepSeek | Juicedata | Juicedata | | 開發語言 | C++, Rust (本地存儲引擎) | Go | Go | | 開源協議 | MIT | Apache License 2.0 | 商業軟件 |&lt;/p&gt; 
&lt;h2&gt;05 總結&lt;/h2&gt; 
&lt;p&gt;大規模 AI 訓練中最主要的需求是高讀帶寬，為此 3FS 採用了性能優先的設計策略，將數據存儲在高速磁盤上，並且用户需要自行管理底層數據存儲。這種方法提升了性能，但成本較高，維護也更繁重。此外，為了充分發揮底層硬件的性能，其架構實現了客户端到網卡的零拷貝，利用共享內存和信號量減少 I/O 延遲和內存帶寬佔用。此外，通過帶 TLS 的 I/O buffer pool 和合併網絡請求，3FS 增強了小 I/O 和文件元數據操作的能力，並引入了性能更優的 RDMA 技術。我們將繼續關注 3FS 在性能優化方面的進展，並探索如何將這些技術應用於我們的場景中。&lt;/p&gt; 
&lt;p&gt;JuiceFS 使用對象存儲作為底層數據存儲，用户因此可大幅降低存儲成本並簡化維護工作。為了滿足 AI 場景的對讀性能的需求，JuiceFS 企業版引入了分佈式緩存、分佈式元數據服務和 Python SDK，從而提高文件系統的性能和擴展能力，並同時兼顧低存儲成本。在接下來發布的 v5.2 企業版中，在 TCP 網絡中實現了零拷貝，進一步提升數據傳輸效率。&lt;/p&gt; 
&lt;p&gt;JuiceFS 提供完整的 POSIX 兼容性和成熟活躍的開源生態，適應更廣泛的使用場景，並支持 Kubernetes CSI，極大簡化了雲平台的部署和運維工作。此外，JuiceFS 還提供了 Quota、安全管理和數據災備等多項企業級管理功能，讓企業可以更便捷地在生產環境中部署和應用 JuiceFS。&lt;/p&gt; 
&lt;p&gt;希望這篇內容能夠對你有一些幫助，如果有其他疑問歡迎加入 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2F&quot; target=&quot;_blank&quot;&gt;JuiceFS 社區&lt;/a&gt;與大家共同交流。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5389802/blog/17937022</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/17937022</guid>
            <pubDate>Wed, 05 Mar 2025 06:54:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Roblox 公佈生成式 AI 模型 Roblox Cube</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 17 日，Roblox 公佈了自己的生成式 AI 模型 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcorp.roblox.com%2Fnewsroom%2F2025%2F03%2Fintroducing-roblox-cube&quot; target=&quot;_blank&quot;&gt;Roblox Cube&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;926&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/144726_7BvT_2720166.png&quot; width=&quot;1618&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;遊戲公司 Roblox 曾於去年宣佈將建立一個開源的三維基礎模型，用於在 Roblox 中創建三維物體與場景。&lt;/p&gt; 
&lt;p&gt;本週，Roblox 將開源名為 Cube 3D 的模型首個版本，任何人都可以在 Roblox 平台內外使用。同時發佈的還有網格生成 API 的 beta 版。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1906054f0606ef1676bb4e26ab93a24aed.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;官方示例提示詞：A red buggy with knobby tires（裝有凸高花紋越野胎的紅色越野車）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Cube 3D 可以從文字直接生成 3D 模型與環境，未來還將支持以圖生模型。Roblox 期望最終模型能完成加入物體-環境-人互動維度的 4D 創造。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339570/oblox-cube</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339570/oblox-cube</guid>
            <pubDate>Wed, 05 Mar 2025 06:48:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>在 RISC-V 上構建 AI 應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;當開源指令集 RISC-V 遇上 AI 大模型，會碰撞出怎樣的未來圖景？&lt;/p&gt; 
&lt;p&gt;中國科學院軟件研究所工程師張旭陽和他所在的團隊正在研究 AI 大模型在 RISC-V 架構上的多項應用與實踐。&lt;/p&gt; 
&lt;p&gt;3 月 22 日，張旭陽將出席 OSC 源創會南京站活動，發表《RISC-V 上 AI 應用與實踐》，通過自主研發的 AI 助手展示如何藉助 RISC-V 架構構建高效、靈活的 AI 助手，實現智能交互與數據處理。&lt;/p&gt; 
&lt;p&gt;同時張旭陽還將分享 Qwen、DeepSeek、LLama 和 Stable Diffusion 等知名模型在 RISC-V 上應用的最新進展。&lt;/p&gt; 
&lt;p&gt;在活動開始前，我們和張旭陽簡單聊了聊 RISC-V + AI 的技術創新與生態構建，歡迎想了解具體如何在 RISC-V 上構建 AI 應用的開發者到現場交流，報名鏈接：&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1014&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-015bbdaaa23e8ca63a6d14af2bc8f95c1a0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 對 AI 來説，是「樂高積木」還是「瑞士軍刀」？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;我覺得更像是樂高積木吧，因為 RISC-V 的架構更加開發，所以非常易於針對不同場景進行定製。用户根據不同的場景需要，定製化的設計芯片，可以擴展指令集，可以在 Soc 上集成各種類型的處理器。同時因為 RISC-V 的特性，做同樣的工作，相比 x86 和 arm 來説，功耗更低。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;把 Qwen、DeepSeek 這些「大胖子」模型塞進 RISC-V，需要先幫它們「瘦身」嗎？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;我們都知道 Qwen 是阿里推出的一系列優秀的開源模型，Qwen 的優點就是，模型參數覆蓋比較廣，最小的模型參數只有 1.5b 。我們目前成功在基於 TH1520 的 RUYIBOOK 上跑通了 Qwen2.0-1.5B 的小模型，以及 DeepSeek-R1-Distill-Qwen-1.5B 模型。同時在算能 SG2042 和 SG2044 的環境上，跑通了 DeepSeek-R1-Distill-Qwen-1.5B，DeepSeek-R1-Distill-Qwen-7B 等模型，藉助於 TPU 的算力，這些精簡的模型也可以跑出相對不錯的性能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 架構上的自研 AI 助手突出優勢是什麼？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;我們自研的 AI 助手，可以説是 RISC-V 的原住民，也是首款基於 RISC-V 桌面生態環境的原生開發的 AI 助手，它可以原生運行在我們的自研的開源 RISC-V 筆記本 RUYIBOOK 甲辰版上，除了基礎的文字問答功能之外，還有圖片理解，文生圖，語音合成等多模態功能。同時藉助大模型的能力，可以通過文字或者語音的方式直接對操作系統做一些基礎的控制。比如説調節音量，調節屏幕亮度，打開關閉應用，搜索文件並打開等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;Stable Diffusion 在 RISC-V 上畫圖，實測生成一張圖要多久？效果如何？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;目前基於算能 SG2044 的測試情況，在 TPU 加速情況下，StableDiffusionV1.5 模型生成一張圖大約 5-6s，StableDiffusionXL 模型生成一張圖大約是 40-50s。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;開發者最怕「從入門到放棄」，有沒有開箱即用的工具包？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;可以關注一下中科院軟件所 PLCT 實驗室所出的 RuyiSDK 開發工具集。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;RISC-V 開發板鏡像相關信息以及下載、安裝教程，便於開發者獲取相關鏡像（換而言之提供一個鏡像站），其中涵蓋多種操作系統（如基於 Debian 的 RevyOS、openEuler RISC-V 等）提供給開發者使用。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;提供 RISC-V 開發板對應的演示程序、開發資料和相關工具（含適用的編譯工具鏈、模擬器等）的信息維護和下載，方便 RISC-V 開發者快速上手。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;在集成開發環境中增加 RISC-V 設備專有嚮導頁面、實現開發環境和運行環境的文件傳輸、支持在 RISC-V 設備上調試應用程序等。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;玩轉 RISC-V + AI 需要點亮哪些技能樹？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;其實如果感興趣的話，完全可以自己買一個開發板先玩起來，因為技能是可以在實踐的過程中逐步去學習的。無論是 AI 相關的，還是 RISC-V 相關的。只要你有一定的計算機專業基礎，然後又會一兩門開發語言，比如 C,C++,python 等。那麼就可以自己利用開發板來做一些研究和學習。咱們的大部分普通人的目的可能並不在於搞出一個 DeepSeek，而是看看能利用 DeepSeek 做些什麼。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;預言時間：RISC-V + AI 組合拳，3 年內能 KO 傳統架構嗎？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;這個時間點我不好預估，因為無論是 AI 軟件棧，還是 RISC-V 都在快速發展中，他們都還沒有達到一個成熟期。但是呢，我認為在開源開放，合作共贏的生態下，RISC-V 和 AI 未來一定可以拿出一些標杆級的應用，可以在某些應用場景下落地生根。我們和傳統的指令集架構，很長時間都是共生共存的關係。並不是説要 KO 掉誰。但我們因為靈活擴展等特性，可能未來在 AI 領域比傳統指令集更加容易去開拓。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;即刻報名&lt;/strong&gt;，現場探智能體設計與使用問題&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🔥報名鏈接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;⏰時間：03-22 14:00 至 18:00&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🚗地點：南京瑞瀾庭院酒店（南京秦淮區瑞金路街道解放路 46 號）&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;2367&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7a57781b43c33abfad271e2d16b2f1eca4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17937477</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17937477</guid>
            <pubDate>Wed, 05 Mar 2025 06:46:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>摩爾線程開源兩大 AI 框架：MT-MegatronLM 和 MT-TransformerEngine</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摩爾線程近日宣佈正式開源 MT-MegatronLM 與 MT-TransformerEngine 兩大 AI 框架。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，通過深度融合 FP8 混合訓練策略和高性能算子庫，這兩大框架在國產全功能 GPU 上實現了高效的混合並行訓練和推理，顯著提升了訓練效率與穩定性。此次開源不僅為 AI 訓練和推理提供了全新的國產化解決方案，更對推動國產 GPU 在 AI 大模型領域的應用具有重要意義。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MT-MegatronLM 是面向全功能 GPU 的開源混合並行訓練框架，支持 dense 模型、多模態模型及 MoE（混合專家）模型的高效訓練。該框架利用全功能 GPU 支持 FP8 混合精度策略、高性能算子庫 muDNN 與集合通信庫 MCCL，可以顯著提升國產全功能 GPU 集羣的算力利用率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MT-TransformerEngine 主要用於 Transformer 模型的高效訓練與推理優化，通過算子融合、並行加速策略等技術，充分釋放摩爾線程全功能 GPU 高密度計算的潛力和 memory bound 算子的效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;兩大框架的技術突破集中體現在硬件適配與算法創新的深度協同：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;混合並行訓練：支持 Dense、多模態及 MoE 模型的混合並行訓練，可靈活應對不同模型架構的複雜運算場景；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;FP8 混合訓練策略：結合摩爾線程 GPU 原生支持的 FP8 混合精度訓練策略，能夠有效提升訓練效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;高性能算子庫：通過高性能算子庫 muDNN 與通信庫 MCCL 的深度集成，系統性優化了計算密集型任務與多卡協同的通信開銷；同時結合摩爾線程開源 Simumax 庫，可自動進行並行策略搜索，並針對不同模型和加速環境 spec 最大化並行訓練性能；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;異常訓練處理：框架內置的 rewind 異常恢復機制，可自動回滾至最近穩定節點繼續訓練，大幅提升大規模訓練的穩定性；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;完整的兼容性：兩個框架兼容 GPU 主流生態，既保障了現有生態的平滑遷移，也為開發者構建自有的 AI 技術棧提供了底層支撐。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;實際應用效果&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;高效訓練：&lt;/strong&gt;在全功能 GPU 集羣上，Llama3 8B 模型的訓練任務，可以利用 FP8 在 loss 幾乎無損的情況下 MFU 達到 90% 以上；（如下圖所示）&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;508&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e522512f7751e81f2884a5adceedd07045.webp&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;圖注：利用摩爾線程 FP8 混合精度加速技術在 loss 無損的情況下得到 28% 的加速&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;復現 DeepSeek 滿血版訓練：&lt;/strong&gt;摩爾線程已深度集成並開源對 DeepSeek 並行算法 DualPipe 的高效支持，MT-DualPipe 可以完整接入 MT-Megatron 框架和 MT-TransformerEngine 框架，成功實現 DeepSeek V3 訓練流程的完整復現，支持 MLA、MTP 及多種專家平衡策略；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;性能大幅優化：&lt;/strong&gt;通過多種 Transformer 算子融合技術，顯著提升了內存帶寬利用率，有效緩解 memory bound 瓶頸，進一步釋放國產 GPU 的硬件潛力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;摩爾線程方面表示，接下來將持續優化 MT-MegatronLM 與 MT-TransformerEngine 框架，並引入一系列創新功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;Dual Pipe/ZeroBubble 並行策略：&lt;/strong&gt;進一步降低氣泡率，提升並行訓練效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;多種 FP8 優化策略：&lt;/strong&gt;獨創的 FP8 優化策略，提高訓練的性能和穩定性；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;異步 checkpoint 策略：&lt;/strong&gt;提高訓練過程中的容錯能力和效率；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;優化後的重計算策略：&lt;/strong&gt;減少計算和顯存開銷，提高訓練速度；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;容錯訓練策略：&lt;/strong&gt;獨創的容錯訓練算法，增強訓練過程中的容錯能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;集成摩爾線程 FlashMLA 和 DeepGemm 庫：&lt;/strong&gt;進一步釋放摩爾線程 GPU 的算力和 FP8 計算能力，提升計算性能和效率。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339567</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339567</guid>
            <pubDate>Wed, 05 Mar 2025 06:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Cursor 發佈 Claude 3.7 Max</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Cursor 剛剛&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.cursor.com%2Ft%2Fclaude-3-7-max-out-now%2F65698&quot; target=&quot;_blank&quot;&gt;發佈了最新的 AI 模型——Claude Max&lt;/a&gt;！它可不是一般的小升級，而是一次徹底的進化，強大到你難以想象！&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;核心大腦：&lt;/strong&gt;&amp;nbsp;搭載 Claude 3.7 Thinking 模型&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;超大視野：&lt;/strong&gt;&amp;nbsp;完整&amp;nbsp;&lt;strong&gt;200k 上下文窗口&lt;/strong&gt;，代碼理解能力直接拉滿！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具狂魔：&lt;/strong&gt;&amp;nbsp;超高工具調用限制，一次性搞定複雜操作！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;代碼速讀：&lt;/strong&gt;&amp;nbsp;瞬間消化海量代碼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;價格注意：&lt;/strong&gt;&amp;nbsp;按用量付費，每 prompt 和 tool call 均為 $0.05 美元。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;受眾明確：&lt;/strong&gt;&amp;nbsp;不適合日常輕度用户，硬核玩家專屬！&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/143434_w22S_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面帶你快速瞭解一下它的核心優勢：&lt;/p&gt; 
&lt;p&gt;🧠&lt;strong&gt; 1. 核心更聰明，創意更強大！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Claude Max 搭載了最新的 Claude 3.7 大腦，不只是智能，更具有超強的創造力。&lt;br&gt; 它不按常規套路出牌，能在其他模型失靈時脱穎而出，解決更復雜、更精妙的任務。&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;2. 一口氣處理 20 萬字上下文！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;過去 AI 模型總是卡在「上下文長度」上，代碼量一多就開始變傻？&lt;br&gt; Claude Max 一次可加載，整整 20 萬字的上下文，讓你整個項目代碼一次性輸入，無需拆分。&lt;br&gt; 首次實現上下文越大，模型表現越好！&lt;/p&gt; 
&lt;p&gt;🛠️ &lt;strong&gt;3. 工具調用猛增到 200 次！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Claude Max 一次性可以調用多達 200 次工具調用，效率簡直爆表！&lt;br&gt; 它能一口氣編輯、分析、優化你的整個代碼庫，徹底擺脱過去 AI「小步慢走」的尷尬。&lt;/p&gt; 
&lt;p&gt;🔍&lt;strong&gt; 4. 一次讀懂大量代碼！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Claude Max 一次性閲讀代碼的量比過去大大增加，&lt;br&gt; 理解更深入、動作更少、更精準。不再浪費多餘的工具調用，更加高效省時。&lt;/p&gt; 
&lt;p&gt;💰 &lt;strong&gt;5. 性能超強，但價格也超「感人」！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;注意啦，Claude Max 並非普通用户的日常選擇，因為它採用了按使用量計費的方式：&lt;/p&gt; 
&lt;p&gt;- 每次請求（prompt）收費：0.05 美元&lt;br&gt; - 每次工具調用收費：0.05 美元&lt;/p&gt; 
&lt;p&gt;⚠️ 舉個例子：&lt;br&gt; 如果你不小心讓 Claude Max 用滿 200 次工具調用，一次操作下來可能會花掉整整 10 美元。&lt;/p&gt; 
&lt;p&gt;因此，我們並不建議普通用户隨便用 Claude Max。&lt;br&gt; 它更適合專業人士、資深程序員或對費用不敏感的用户。&lt;/p&gt; 
&lt;p&gt;💪&lt;strong&gt; 6. 誰最適合用 Claude Max？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;- 要一次完成超大規模複雜項目的開發者；&lt;br&gt; - 面對高難度、精細化代碼編輯的高級用户；&lt;br&gt; - 想體驗目前最先進 AI 模型能力，且預算充足的用户。&lt;/p&gt; 
&lt;p&gt;超過 90% 的日常代碼編輯任務，用 Cursor 現有的普通模型已經綽綽有餘，無需額外投入。&lt;/p&gt; 
&lt;p&gt;🚩 使用前務必注意：&lt;/p&gt; 
&lt;p&gt;Claude Max 不包含在 Cursor 的基礎 Pro 套餐，中，必須額外開啓「按量計費模式」才能使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339566/claude-3-7-max</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339566/claude-3-7-max</guid>
            <pubDate>Wed, 05 Mar 2025 06:34:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊混元推出 5 個開源 3D 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;騰訊混元宣佈推出 5 個全新 3D 生成模型，並全部開源。這些基於 Hunyuan3D-2.0 打造的模型具有更快的生成速度、更豐富的細節和更逼真的材質表達。同時，騰訊自研的 3D AI 創作引擎也進行了升級，現已向 C 端用户全面開放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;285&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-142e80908d4b94f1fe229da4677ce363137.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在這些新模型中，Turbo 系列模型通過騰訊混元提出的 3D 生成加速框架 FlashVDM，實現了數十倍的加速，將生成過程縮短至 30 秒內完成。多視圖版本模型 Hunyuan3D-2-MV 能更好地捕捉細節，生成符合用户預期的 3D 資產。輕量級 mini 系列模型通過架構優化降低了算力需求，可部署在 4080 顯卡甚至蘋果 M1Pro 芯片上。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;升級後的騰訊混元 3D AI 創作引擎支持多視圖輸入，用户只需上傳 2-4 張標準視角圖片，即可快速生成高質量 3D 模型，大幅降低遊戲製作、3D UGC 創作等場景的製作成本。引擎的 3D 智能減面能力可自適應生成幾百至數千面的三角面，提升幾何邊緣平滑度，在低面片基礎上最大化體現模型細節。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在材質表現方面，此次升級實現了 PBR（基於物理渲染技術）的材質生成效果提升，通過物理特性模擬技術賦予模型更真實的顏色與材質表達。兼容性上，除通用 OBJ、GLB、FBX 外，還可輸出 STL、USDZ 及 MP4 等主流格式，無縫連接 3D 打印工具，支持模型快速預覽及移動端實時交互。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;據悉，騰訊混元 3D 生成模型已應用於 UGC、商品素材合成、遊戲 3D 資產生成等場景。在遊戲業務中，大模型生成的 3D 模型已能滿足部分遊戲 3D 資產標準，包括幾何佈線合理性、貼圖準確性與骨骼蒙皮合理性等要求。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339557</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339557</guid>
            <pubDate>Wed, 05 Mar 2025 06:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘇州：做強 AI 芯片骨幹核心企業</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;《蘇州市加快發展 AI 芯片產業的若干措施（徵求意見稿）》公開徵求意見。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中提到，充分用好人工智能產業專項母基金，重點投向本土擁有關鍵核心技術、發展潛力大的 AI 芯片創新型企業，撬動社會資本投向 AI 芯片領域，支持 AI 芯片企業原始創新和成果轉化。加強與國家、省集成電路產業投資基金對接，爭取各級基金資源支持蘇州市 AI 芯片產業發展。重點支持 AI 芯片領域專精特新企業、高新技術企業進入上市後備企業庫，實施重點培育。積極落實集成電路企業税收優惠政策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中提到，做強骨幹核心企業。聚焦 GPU 通用型芯片、ASIC 專用型芯片、FPGA 半定製化芯片、存算一體芯片、硅光芯片等重點方向，加大招商力度，加快引育一批帶動性強的優質項目、頭部企業，對重點項目在空間保障、場地建設、人才引進等方面予以綜合支持。推動 AI 芯片企業通過兼併重組等方式提升資源整合能力，向產業鏈上下游佈局拓展業務，對優質 AI 芯片企業開展併購重組，鼓勵縣級市（區）對企業實施兼併重組給予獎勵。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;228&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-41c7faa9ce5f67f92cbd0c08e8362ea840e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;蘇州市加快發展 AI 芯片產業的若干措施&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;（徵求意見稿）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;為搶抓人工智能技術快速迭代發展機遇期，充分發揮我市半導體與集成電路產業基礎優勢，加快推動 AI（人工智能）芯片產業創新突破、集聚成勢，結合我市產業發展實際，制定本措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;一、做強骨幹核心企業。&lt;/strong&gt;聚焦 GPU 通用型芯片、ASIC 專用型芯片、FPGA 半定製化芯片、存算一體芯片、硅光芯片等重點方向，加大招商力度，加快引育一批帶動性強的優質項目、頭部企業，對重點項目在空間保障、場地建設、人才引進等方面予以綜合支持。推動 AI 芯片企業通過兼併重組等方式提升資源整合能力，向產業鏈上下游佈局拓展業務，對優質 AI 芯片企業開展併購重組，鼓勵縣級市（區）對企業實施兼併重組給予獎勵。對 AI 芯片企業獲評製造業單項冠軍、國家專精特新「小巨人」，分別給予 100 萬元、40 萬元獎勵。對獲得認定的 AI 芯片高新技術企業，給予最高 100 萬元支持。（責任單位：市工信局、市科技局、市發改委、市委人才辦，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;二、佈局建設創新平台。&lt;/strong&gt;圍繞 AI 芯片重點方向，加快構建龍頭企業牽頭、高校院所支撐、各創新主體相互協同的創新聯合體，給予最高 200 萬元運營經費支持。鼓勵圍繞 AI 芯片技術研發、成果轉化等關鍵環節，建設 AI 芯片科技公共技術服務平台，對新建平台按總投資的 20% 給予最高 2000 萬元支持。對為 AI 芯片設計企業提供 EDA 工具、系統級芯片（SoC）設計服務、多項目晶圓（MPW）、功能模擬、測試驗證、「芯機」聯動、快速封測、人才培訓等專業化服務的平台，按照平台為本地企業提供服務收入的 20%，給予最高 300 萬元獎勵。（責任單位：市科技局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;三、集聚高端芯片人才。&lt;/strong&gt;聚焦 AI 芯片領域，大力引進培養處於人工智能領域科技前沿和國際一流水平，掌握關鍵核心技術，能夠帶來重大影響、重大突破的海內外人才，給予 3000 萬元～1 億元項目資助和 300 萬元～1000 萬元購房補貼。在蘇州創新創業領軍人才計劃中，每年專設 100 個左右「人工智能專項」名額，特別優秀的可突破學歷、來蘇州時間等限制，給予 100 萬元～500 萬元項目資助和 100 萬元～200 萬元購房補貼。對入選蘇州市重點產業緊缺人才計劃的人才，給予最高 30 萬元薪酬補貼。推動建設集教育、培訓及研究為一體的產學研融合協同的集成電路產業人才公共實訓基地，在 AI 芯片領域打造全產業鏈高技能人才團隊。（責任部門：市委人才辦、市科技局、市人社局、市教育局、市工信局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;四、實現關鍵技術突破。&lt;/strong&gt;梳理編制 AI 芯片關鍵核心技術清單，鼓勵企業開展芯片架構、製程工藝、計算加速、異質集成、數據中心光模塊等技術研究，對關鍵核心技術攻關項目給予最高 1000 萬元支持。支持 AI 芯片設計企業開展擁有自主知識產權的工程流片驗證，對首次流片、光罩製作以及測試驗證等費用給予最高 50% 支持，工藝製程 12nm 以上的產品最高支持 500 萬元，12nm 及以下的產品最高支持 1000 萬元，鼓勵有條件的縣級市（區）給予聯動支持。鼓勵 AI 芯片企業提出技術需求，吸引國內外創新主體揭榜攻關，加快突破制約產業發展的技術瓶頸。（責任單位：市科技局、市工信局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;五、支持開展標準研製。&lt;/strong&gt;健全 AI 領域技術創新、專利保護與標準化互動支撐機制，推動創新成果的知識產權化和技術標準化，為 AI 芯片技術專利申請、軟件著作權登記提供便利化服務。發揮行業協會和標準化機構作用，支持 AI 芯片龍頭企業、重點院校、科研機構主導和參與 AI 芯片行業標準制定（修訂），經主管部門認定後，按相應政策給予支持。支持組建芯片領域高價值專利培育中心，對成效明顯的給予獎勵。（責任部門：市市場監管局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;六、推進重點產品量產。&lt;/strong&gt;圍繞數據中心、計算機視覺、智能網聯車、智能機器人、智能語音等主要應用領域，結合關鍵技術清單，鼓勵創新主體通過產學研合作等方式推進重點產品規模化批量生產。對 AI 芯片 IDM（垂直整合製造模式）企業開發創新產品列入省重點推廣應用新技術新產品目錄的，給予一次性獎勵 50 萬元。在蘇州市科技成果轉化專項中對 AI 芯片企業給予傾斜支持，加快 AI 芯片重大創新產品培育，每個項目給予最高 2000 萬元支持。鼓勵支持保險機構探索 AI 芯片定製化保險產品，為企業研發、生產、銷售等各環節提供保險保障。（責任單位：市工信局、市科技局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;七、加快產業協同聯動。&lt;/strong&gt;鼓勵 AI 芯片設計企業與製造企業開展合作，支持封測企業擴大 AI 芯片產品佈局。對為蘇州市 AI 芯片設計企業自主研發產品提供生產線產能，並生產符合一定條件產品的集成電路製造、封測企業，按每款產品訂單實際生產費用的 10% 最高給予 300 萬元獎勵。對使用本地企業 AI 芯片產品的終端廠商、系統方案集成商、算力中心，按當年使用金額的 10% 給予獎勵，單個企業最高獎勵 100 萬元。對認定為省級、蘇錫常首台（套）重大裝備的半導體設備企業，分別給予 80 萬元、50 萬元獎勵。對首年度生產銷售重點新材料首批次應用示範指導目錄內同品種、同技術參數的半導體新材料產品企業給予 50 萬元獎勵。組織開展「芯片—整機」「芯片—材料設備」等產業鏈上下游供需聯動和產業對接，增強產業鏈協作能力。（責任單位：市工信局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;八、開放規模應用場景。&lt;/strong&gt;鼓勵政府機關、企事業單位開放應用場景，支持 AI 芯片企業積極參與政務服務、交通、環衞、公共安全、教育、醫療健康等領域應用，加快 AI 芯片產品新技術迭代、新產品應用、新場景落地，培育打造具有典型意義的標杆案例。構建芯片測評標準和適配認證體系，加速 AI 芯片在智算中心訓練、推理等場景的規模化應用。鼓勵 AI 芯片企業整合行業資源和高質量數據，針對場景需求開展 AI 芯片產品開發，形成可複製可推廣的解決方案。（責任單位：市數據局、市交通局、市城管局、市公安局、市教育局、市衞健委、市工信局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;九、着力強化金融支撐。&lt;/strong&gt;充分用好人工智能產業專項母基金，重點投向本土擁有關鍵核心技術、發展潛力大的 AI 芯片創新型企業，撬動社會資本投向 AI 芯片領域，支持 AI 芯片企業原始創新和成果轉化。加強與國家、省集成電路產業投資基金對接，爭取各級基金資源支持我市 AI 芯片產業發展。重點支持 AI 芯片領域專精特新企業、高新技術企業進入上市後備企業庫，實施重點培育。積極落實集成電路企業税收優惠政策。（責任單位：市委金融辦、市財政局、國家金融監管總局蘇州分局、蘇創投，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;十、打造多元產業生態。&lt;/strong&gt;發揮「人工智能+」城市政策牽引作用，加快構建 AI 芯片設計企業、大模型推理及訓練企業、智算及數據中心及終端應用企業深度合作生態。支持龍頭企業牽頭組建 AI 芯片行業生態聯盟，舉辦產業鏈上下游對接交流活動，為企業搭建溝通平台。鼓勵 AI 芯片領域行業聯盟、行業協會、智庫單位等行業組織加強能力建設，為行業提供專業化服務。搭建高層次交流合作平台，鼓勵開放創新與全球合作，支持打造 AI 芯片領域品牌展會和論壇等活動。（責任單位：市發改委、市科技局、市工信局、市商務局，各縣級市&amp;lt;區&amp;gt;人民政府&amp;lt;管委會&amp;gt;）&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;本文件所指 AI 芯片企業是在蘇州依法登記註冊，以 AI（人工智能）芯片設計、製造、封測等為主營業務的企業。本文件由蘇州市人民政府負責解釋，具體解釋工作由市工業和信息化局會同相關部門承擔。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;本文件自 2025 年 X 月 X 日起施行，有效期至 2027 年 12 月 31 日。各部門政策所涉及資金按原渠道和財政體制要求落實。同一事項或項目符合市級財政多個支持政策的，均按照「就高、不重複」原則予以支持，不得重複申報。執行期間如遇上級有關政策規定調整的，從其規定。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339556</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339556</guid>
            <pubDate>Wed, 05 Mar 2025 06:10:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>MCP 有望引入新的數據傳輸方式：Streamable HTTP</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;MCP (Model Context Protocol) 是 Anthropic 開源的&amp;nbsp;「模型上下文協議」，該協議支持將大模型直接連接至數據源，官方介紹稱 「可無縫集成 LLM 應用程序和外部數據源」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/115746_nnq5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;近日，開發者在 MCP 的 GitHub 倉庫提交了一個希望採用&quot;Streamable HTTP&quot;傳輸代替「HTTP+SSE」的 PR，以解決當前遠程 Model Context Protocol (MCP) 傳輸方式的關鍵限制，同時保留其優勢。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1584&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/115359_va3x_2720166.png&quot; width=&quot;2476&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fspecification%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/specification/pull/206&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;簡單來説，&lt;strong&gt;Streamable HTTP&amp;nbsp;改變了 MCP 的數據傳輸方式&lt;/strong&gt;，讓協議變得：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更靈活&lt;/strong&gt;（支持流式傳輸，但不強制）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更易用&lt;/strong&gt;（支持無狀態服務器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更兼容&lt;/strong&gt;（適用於標準 HTTP 基礎設施）&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;💡 &lt;strong&gt;簡單比喻&lt;/strong&gt;： 原來的 MCP 傳輸方式就像是&lt;strong&gt;你和客服通話時必須一直保持在線&lt;/strong&gt;（SSE 需要長連接），而新的方式更像是&lt;strong&gt;你隨時可以發消息，然後等回覆&lt;/strong&gt;（普通 HTTP 請求，但可以流式傳輸）。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;主要變更&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 /sse 端點&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器不再單獨維護 SSE（Server-Sent Events）端點。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;所有客户端 → 服務器的消息都通過 /message 端點&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任何數據傳輸都通過 &lt;strong&gt;/message&lt;/strong&gt; 進行，不再依賴 /sse。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;服務器可以選擇升級請求為 SSE&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器可以根據需要&lt;strong&gt;動態升級 HTTP 請求為 SSE 流&lt;/strong&gt;，用於發送通知或請求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;客户端通過 Header 提供 Mcp-Session-Id&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器可選是否需要存儲 Session 信息，但客户端始終發送 Mcp-Session-Id 頭部信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持無狀態（Stateless）服務器&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服務器可選擇完全無狀態運行，不再需要維持長期連接。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;變更的動機&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;當前的 &lt;strong&gt;HTTP+SSE 傳輸&lt;/strong&gt; 存在以下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;不支持可恢復性&lt;/strong&gt;（Resumability）：連接斷開後，客户端必須重新開始整個會話。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;服務器需要維持長期連接&lt;/strong&gt;（High Availability Requirement）：服務器必須保持高可用性，以支持持續的 SSE 連接。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SSE 僅支持服務器 → 客户端消息&lt;/strong&gt;，無法靈活進行雙向通信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新的「Streamable HTTP」傳輸方式解決了這些問題，並增強了系統的可擴展性和靈活性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339546/mcp-streamable-http-transport</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339546/mcp-streamable-http-transport</guid>
            <pubDate>Wed, 05 Mar 2025 04:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>