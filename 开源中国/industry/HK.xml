<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Fri, 20 Jun 2025 07:43:53 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>宇樹科技確認：近期已完成 C 輪融資交割</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;市場消息稱，宇樹科技已完成了始於去年 9 月的 C 輪融資交割，由中國移動旗下基金、騰訊、錦秋、阿里、螞蟻、吉利資本共同領投，絕大部分老股東跟投。對此，證券時報記者向宇樹科技核實。宇樹科技方面向記者表示，「我們最近確實完成了 C 輪融資，但其他信息暫時不清楚」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;天眼查顯示，自 2016 年創立至今，宇樹科技已完成 9 輪融資。最近的一輪為始於去年 9 月的 C 輪融資，彼時公司估值為 80 億元。但在過去的半年中，宇樹科技屢屢「出圈」，成為人形機器人領域最受關注的公司之一。據最新消息，宇樹科技的投前估值目前已超過 100 億元人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「宇樹的估值，我覺得還是保守了。」前不久，在提到宇樹科技的最新估值或達到百億元級別時，一名宇樹科技的早期投資人向證券時報記者表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="306" src="https://oscimg.oschina.net/oscnet/up-307142b03f6f36a82cf894dca3e3bdd0862.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;完成 C 輪融資交割後，宇樹科技的下一步動作會否是上市？這一直是備受市場關注的焦點。今年 5 月 29 日，證券時報記者從知情人士處獲取一份《公司名稱變更函》。宇樹科技向合作伙伴表示，因公司發展需要，杭州宇樹科技有限公司即日起名稱變更為杭州宇樹科技股份有限公司。國家企業信用信息公示系統也顯示，宇樹科技已從有限責任公司變更為股份有限公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;有市場人士分析，這一變更可等同於完成股改，或許是為 IPO 上市鋪路。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 4 月，香港特區行政長官李家超在杭州與「六小龍」企業代表進行了交流，併到訪了宇樹科技。彼時，宇樹科技創始人王興興表示，宇樹科技在香港有業務，各方面合作機會也很多。至於未來會否在香港上市，王興興稱，有可能，但不確定。李家超鼓勵宇樹科技來港拓展業務，並表示香港特區政府亦可提供所需支援。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與此同時，近日 A 股市場釋放的一系列提升制度包容性和適應性的信號也讓市場振奮。6 月 18 日，中國證監會主席吳清在 2025 陸家嘴論壇上指出，重啓未盈利企業適用科創板第五套標準上市。同日，中國證監會發布《關於在科創板設置科創成長層，增強制度包容性適應性的意見》，明確提出擴大第五套標準適用範圍，支持人工智能、商業航天、低空經濟等更多前沿科技領域企業適用。一系列利好信號，為像宇樹科技一樣的前沿科技企業提供了更廣闊的發展空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不過，與大部分同行仍然處於虧損狀態相比，宇樹科技在商業化領域的進展也較快。今年 3 月，宇樹科技早期投資人、SevenUp Capital 創始人趙楠在接受媒體採訪時透露，自 2020 年以來，宇樹科技的財務報表每年都保持盈利狀態。宇樹科技也證實了該消息。數據顯示，宇樹科技人形機器人出貨量位居全球前列，四足機器狗全球市場佔有率更是超過 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;近日，王興興還與公司的投資方之一，吉利控股集團董事長李書福進行了一場以「AI 時代的人才培養」為主題的對話。王興興回憶創業經歷時表示，早年創業時機器人還屬於相對冷門的賽道，但他選擇這一行業並非因為市場規模、盈利前景或未來熱度。最大的原因還是從小就喜歡動手做東西，希望能做一些改變世界的產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對於未來，王興興表示，希望能看到未來整個行業發展方向，做更好的機器人產品，更好推動整個機器人 AI 的技術進步。希望未來能讓機器人去幹活，更好地解放生產力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356437</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356437</guid>
      <pubDate>Fri, 20 Jun 2025 07:27:50 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Windows 11 市佔率僅比 Windows 10 低 1%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟自 2021 年 10 月推出 Windows 11 以來，就一直在不斷鼓勵用户升級，但 Windows 10 的市場份額一直高於 Windows 11。不過隨着 Windows 10 即將停止支持，Windows 11 的市場份額終於有望實現超越。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b7ef309abb2c8b41fbb02c7ac6fe93264a1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據 StatCounter 的最新數據，&lt;strong&gt;Windows 10 的市場份額為 48.92%，而 Windows 11 的市場份額已經達到了 47.73%，兩者差距僅為 1.19%&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;這意味着在未來幾個月內，Windows 11 的市場份額有望超過 Windows 10，實現所謂的「黃金交叉」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3d78ab74367857f983b0a30f19c666044bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從數據來看，Windows 11 的市場份額在過去一個月中提升幅度創下新高，這可能與 Windows 10 即將停止支持有關。&lt;/p&gt; 
&lt;p&gt;微軟近期也通過多種方式提醒用户儘快升級，以避免安全風險，許多用户可能選擇購買新電腦或從 Windows 10 升級到 Windows 11。&lt;/p&gt; 
&lt;p&gt;Windows 11 市場份額增長最快的地區是亞洲，這個月差距已經縮小到不到 3%，相比之下，美國、日本、英國等國家的 Windows 11 份額早在幾個月前就已經超過了 Windows 10。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f816ff7d41f357ec1431b4b54bd88f86e50.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這也顯示出亞洲用户在操作系統升級方面相對保守，直到最後幾個月才開始大規模升級。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356419</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356419</guid>
      <pubDate>Fri, 20 Jun 2025 06:58:50 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Andrej Karpathy 提出「軟件 3.0 時代」，稱自然語言正在取代傳統代碼</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;日前，OpenAI 聯合創始人、特斯拉前 AI 負責人 Andrej Karpathy 在 Y Combinator 的 AI 創業學院活動上，進行了個人演講。&lt;/p&gt; 
&lt;p&gt;&lt;img height="556" src="https://static.oschina.net/uploads/space/2025/0620/142721_2fd9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次演講中，Karpathy 提出了「軟件 3.0 時代」這一概念，&lt;strong&gt;他認為自然語言正在取代傳統代碼，而大型語言模型（LLM）則成為新的「萬能計算機」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/142813_2Ldh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Karpathy 指出，軟件 3.0 時代下，自然語言（如英語）將作為「編程接口」，直接給大語言模型下達命令，讓模型自己完成剩下的所有工作。Karpathy 直言，這並非一次工具迭代，而是「根本性變革」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="2260" src="https://static.oschina.net/uploads/space/2025/0620/142754_fhxp_2720166.png" width="4090" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0620/142833_1Cbg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，Karpathy 還提出：大語言模型兼具公共設施、晶圓廠、操作系統這三種行業的屬性。如「晶圓廠」：訓練大模型的鉅額算力與研發壁壘，使得少數實驗室成為新的「芯片製造商」。&lt;/p&gt; 
&lt;p&gt;另外，Karpathy 還展望了 AI Agent（智能體）的未來。他表示，Agent 既非人類也非傳統程序，而是新的「數字信息消費者與操作者」。其進一步解釋稱，「因為 Agent 需要我們重新設計文檔、接口乃至網絡協議，為它們提供可讀、可執行的‘原生’內容。」&lt;/p&gt; 
&lt;p&gt;原視頻：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DLCEmiRjPEtQ" target="_blank"&gt;https://www.youtube.com/watch?v=LCEmiRjPEtQ&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356402</guid>
      <pubDate>Sun, 11 May 2025 06:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>張一鳴重回公司一線？知情人士：每月參與覆盤和討論會</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息稱，字節跳動創始人張一鳴目前主要辦公地已從新加坡轉到北京，從去年下半年開始，他每月會召集一次字節核心管理層和 AI 項目負責人的覆盤和討論會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fm.thepaper.cn%2Fbaijiahao_31015094" target="_blank"&gt;澎湃新聞&lt;/a&gt;記者表示，張一鳴一直很關注 AI 業務。目前張一鳴經常往返北京和新加坡，從去年下半年開始，他每月會參加一次 seed 核心技術團隊的覆盤和討論會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="279" src="https://oscimg.oschina.net/oscnet/up-ed5561a0fb8783c67b902102fad0b52aeea.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官網介紹顯示，字節跳動 Seed 團隊成立於 2023 年，致力於尋找通用智能的新方法,追求智能上限。團隊研究方向涵蓋 LLM、語音、視覺、世界模型、基礎架構、AI Infra、下一代 AI 交互等，在中國、新加坡、美國等地設有實驗室和崗位。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356387</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356387</guid>
      <pubDate>Sun, 11 May 2025 05:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智元機器人在上海成立雲程科技公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;天眼查資料顯示，上海智元雲程科技有限公司於近日成立，是一家以從事軟件和信息技術服務業為主的企業。法定代表人為鄧泰華，註冊資本 100 萬人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="266" src="https://oscimg.oschina.net/oscnet/up-ef9f219581dfc75802ad4f47bb51e48b5ee.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司經營範圍包括信息技術諮詢服務、會議及展覽服務、市場營銷策劃、企業形象策劃等。股東信息顯示，該公司由上海智元新創技術有限公司全資持股。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356358</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356358</guid>
      <pubDate>Sun, 11 May 2025 03:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub Copilot Spaces 支持將 Issues 和 Pull Requests 作為上下文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;GitHub Copilot Spaces 現已支持將 issues 和 pull requests 作為上下文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fchangelog%2F2025-06-19-copilot-spaces-now-support-issues-and-pull-requests-public-preview%2F" target="_blank"&gt;目前處於公開預覽階段&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;用户在 Copilot Spaces 中創建空間時，只需粘貼 issue 或 pull request 的 URL，即可自動拉取其最新的標題、正文、評論、狀態甚至標籤作為上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fe648c5ab0d622f51ad0305a0bb2aecc6a2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這一功能旨在幫助開發者更高效地進行工作。例如，在規劃新功能時，可以添加工作項、功能規範和預期修改的代碼，讓 Copilot 協助規劃方法、搭建初步更改或識別風險；在修復 bug 時，可以添加 issue 和可疑代碼，讓 Copilot 幫助查找問題行並提出修復建議；在跟蹤工作和分享更新時，可以將新功能的所有工作項添加到空間，並與團隊成員共享以回答進度和障礙問題。Copilot Spaces 可在 github.com/copilot/spaces 上供所有 Copilot 用户使用。&lt;/p&gt; 
&lt;p&gt;對於商業或企業客户，組織管理員需要選擇啓用 Copilot 預覽功能才能使用此特性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356357</guid>
      <pubDate>Sun, 11 May 2025 03:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>用 AI 會讓人變笨，過度依賴 AI 或導致損壞批判性思維與記憶力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;一項由麻省理工學院媒體實驗室的 Nataliya Kosmyna 及其團隊主導的&lt;span&gt;最新&lt;/span&gt;研究，深入探討了在論文寫作任務中，使用大型語言模型（LLM）如 OpenAI 的 ChatGPT 可能帶來的認知成本。該研究發現，儘管 LLM 產品為人類和企業帶來了諸多便利，但其廣泛應用卻可能導致大腦積累「認知負債」，長遠來看甚至會削弱個體的學習技能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-9da4a2d7ee235a5a7411c434fda354048e0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該研究招募了 54 名參與者，並將其分為三組:LLM 組（僅使用 ChatGPT）、搜索引擎組 (使用傳統搜索引擎，禁用 LLM) 和純腦力組 (不使用任何工具)。研究共進行了四次會話，其中在第四次會話中，LLM 組的參與者被要求不使用任何工具 (被稱為「LLM 轉純腦力組」)，而純腦力組的參與者則開始使用 LLM(被稱為「純腦力轉 LLM 組」)。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究團隊通過腦電圖 (EEG) 記錄了參與者的大腦活動，以評估其認知投入和負荷，並深入理解論文寫作任務期間的神經激活模式。此外，研究還進行了自然語言處理 (NLP) 分析，並在每次會話後對參與者進行了訪談，同時邀請人類教師和 AI 評判員對論文進行打分。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-a56dd98b0353f8374fe7d0874c8ffcf7a89.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心發現：大腦連接性減弱，記憶和所有權受損&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究結果提供了確鑿證據，表明 LLM、搜索引擎和純腦力組的神經網絡連接模式存在顯著差異，反映了不同的認知策略。大腦連接性與外部支持的程度呈系統性下降：純腦力組表現出&lt;span&gt;最強&lt;/span&gt;、範圍最廣的連接網絡，搜索引擎組居中，而 LLM 輔助則引發了最弱的整體耦合。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特別值得關注的是，在第四次會話中，「LLM 轉純腦力組」的參與者表現出較弱的神經連接性，以及阿爾法（alpha）和貝塔 (beta) 網絡的投入不足。阿爾法波段連接性通常與內部注意力、語義處理和創造性構思相關。貝塔波段則與主動認知處理、專注注意力和感覺運動整合相關。這些結果表明，過去依賴 LLM 的使用者，在脱離工具後，其大腦在內容規劃和生成方面的神經活動有所減少，這與認知卸載的報告相符，即依賴 AI 系統可能導致被動方法和批判性思維能力的減弱。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在記憶方面，LLM 組的參與者在引用自己剛寫完的論文時表現出明顯障礙，甚至無法正確引用。這直接映射到 LLM 組較低的低頻連接性，特別是與情景記憶鞏固和語義編碼密切相關的西塔（theta）和阿爾法波段。這表明 LLM 用户可能繞過了深層記憶編碼過程，被動地整合了工具生成的內容，而沒有將其內化到記憶網絡中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，LLM 組對自己論文的所有權感知度普遍較低，而搜索引擎組擁有較強的所有權感，但仍低於純腦力組。這種行為上的差異與神經連接性模式的變化相吻合，凸顯了 LLM 使用對認知能動性的潛在影響。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;認知負債的積累&lt;/strong&gt;：&lt;strong&gt;效率與深度學習的權衡&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究指出，儘管 LLM 在初期提供了顯著的效率優勢並降低了即時認知負荷，但隨着時間的推移，這種便利可能以犧牲深度學習成果為代價。報告強調了「認知負債」的概念:重複依賴外部系統（如 LLM）取代了獨立思考所需的努力認知過程，短期內延遲了腦力投入，但長期卻導致批判性探究能力下降、更容易被操縱以及創造力減退。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;純腦力組的參與者，儘管面臨更高的認知負荷，卻展現出更強的記憶力、更高的語義準確性和對其作品更堅定的主人翁意識。而「純腦力轉 LLM 組」在&lt;span&gt;首次&lt;/span&gt;使用 AI 輔助重寫論文時，大腦連接性顯著增加，這可能反映了將 AI 建議與現有知識整合時的認知整合需求，暗示了 AI 工具引入的時機可能對神經整合產生積極影響。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;對教育環境的深遠影響與未來展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究團隊認為，這些發現對教育領域具有深遠意義。過度依賴 AI 工具可能無意中阻礙深層認知處理、知識保留以及對書面材料的真實投入。如果用户過度依賴 AI 工具，他們可能會獲得表面的流暢度，但卻無法內化知識或對其產生所有權感。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該研究建議，教育幹預應考慮將 AI 工具輔助與「無工具」學習階段相結合，以優化即時技能轉移和長期神經發展。在學習的早期階段，全面的神經參與對於發展強大的寫作網絡至關重要;而在後續練習階段，有選擇性的 AI 支持可以減少無關的認知負荷，從而提高效率，同時不損害已建立的網絡。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人員強調，隨着 AI 生成內容日益充斥數據集，以及人類思維與生成式 AI 之間的界限變得模糊，未來研究應優先收集不借助 LLM 協助的寫作樣本，以發展能夠識別作者個人風格的「指紋」表示。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最終，這項研究呼籲在 LLM 整合到教育和信息情境中時，必須謹慎權衡其對認知發展、批判性思維和智力獨立性的潛在影響。LLM 雖然能減少回答問題的摩擦，但這種便利性也帶來了認知成本，削弱了用户批判性評估 LLM 輸出的意願。這預示着「迴音室」效應正在演變，通過算法策劃內容來塑造用户接觸信息的方式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;（研究論文標題為《Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task》，主要作者為麻省理工學院媒體實驗室的 Nataliya Kosmyna 等。）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356351</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356351</guid>
      <pubDate>Sun, 11 May 2025 03:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>警惕日誌採集失敗的 6 大經典雷區：從本地管理反模式到 LoongCollector 標準實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：餘韜（訊飛）&lt;/p&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;觀察系統的運行狀態，排查疑難問題，日誌作為一種歷史悠久的可觀測手段，始終扮演着不可替代的角色。&lt;/p&gt; 
&lt;p&gt;科學的本地日誌管理策略，不僅能在本地保留更完整歷史記錄，最小化性能開銷，並且能為日誌採集和後續分析提供便利。然而在實際運維中，我們時常遇到反例，這類管理缺陷帶來的採集現在對於主流採集工具（LoongCollector（原 iLogtail）、Filebeat、Fluentbit、Vector、OpenTelemetry Collector）均無法完美解決，唯有從源頭解決才是最佳實踐。&lt;/p&gt; 
&lt;p&gt;我們將沉澱自阿里云云原生可觀測團隊的經驗總結成本文，希望給大家一些啓發，一起讓日誌更好地為大家服務。&lt;/p&gt; 
&lt;h2&gt;反模式&lt;/h2&gt; 
&lt;h3&gt;1. 使用 copy truncate 模式輪轉日誌，因兩個動作非原子並創建新文件，可能導致日誌丟失或重複採集&lt;/h3&gt; 
&lt;p&gt;使用 logrotate 的 copy truncate 模式輪轉日誌的原理是先複製原日誌文件，然後截斷原文件。這種方式存在以下問題：&lt;/p&gt; 
&lt;p&gt;a. copy 動作產生的新文件可能被當作新的內容重複採集。因為文件系統的 inode 變化，採集器可能無法正確識別這是輪轉後的舊文件。&lt;/p&gt; 
&lt;p&gt;b. copy 和 truncate 之間產生的日誌可能丟失。在這兩個操作之間有一個時間窗口，此時寫入的內容既不在複製的文件中，又會被截斷操作清除。&lt;/p&gt; 
&lt;p&gt;c. truncate 操作可能導致文件大小變小和頭部內容變化，縮小文件或改變文件頭部簽名會導致採集器誤判為新文件，造成重複採集。&lt;/p&gt; 
&lt;p&gt;因此，copy truncate 模式可能導致日誌重複採集、內容丟失或不一致的問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-11c600c00de52c3f883da0edfddcbf352fa.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推薦使用 create 模式進行日誌輪轉，即創建新文件並重命名舊文件，這樣可以保證文件的完整性和連續性。如果無法避免，請在配置採集配置時使用精確的路徑名。&lt;/p&gt; 
&lt;h3&gt;2. 使用 NAS、OSS 作為日誌存儲，因元信息不一致和 ls 性能低，可能導致日誌採集截斷或停止&lt;/h3&gt; 
&lt;p&gt;網絡附加存儲 (NAS) 通常採用基於最終一致性的一致性模型，這在分佈式系統中是常見的設計。在實時採集場景下，這可能導致以下問題：&lt;/p&gt; 
&lt;p&gt;a. 文件元信息與實際內容不一致。由於最終一致性，文件大小等元數據可能先於實際內容更新。&lt;/p&gt; 
&lt;p&gt;b. 讀取到文件空洞。當元信息顯示文件已增大，但實際內容尚未同步時，讀取操作可能返回 \0 字符（文件空洞）。&lt;/p&gt; 
&lt;p&gt;c. 數據延遲。寫入操作的結果可能不會立即對讀取操作可見，導致採集延遲。&lt;/p&gt; 
&lt;p&gt;d. 數據丟失。由於 NAS 不支持 inotify 並且 list 性能低下，因此文件可能無法被發現，導致數據丟失。&lt;/p&gt; 
&lt;p&gt;這些問題可能導致採集到的數據與最終內容不一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f58f5b993aee7f7f62ca6fba5fe9e6ac750.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;建議使用 EBS，自建機器使用本地磁盤，以保證日誌讀寫的效率和一致性。如無法避免，請在消費端做好異常日誌的兼容邏輯。&lt;/p&gt; 
&lt;h3&gt;3. 多進程寫日誌，因數據互相覆蓋，可能導致採集到的數據不完整&lt;/h3&gt; 
&lt;p&gt;多進程併發寫入同一日誌文件是一種常見但不推薦的做法，它可能導致以下問題：&lt;/p&gt; 
&lt;p&gt;a. 文件內容交叉。多個進程的寫入可能相互交叉，導致日誌條目混亂。&lt;/p&gt; 
&lt;p&gt;b. 採集不完整。當文件發生寫入事件時，採集器開始採集數據。但如果採集過程中其他進程繼續寫入，這些新寫入的內容可能被跳過。&lt;/p&gt; 
&lt;p&gt;c. 文件鎖爭用。多進程寫入可能導致文件鎖爭用，影響寫入性能和可靠性。&lt;/p&gt; 
&lt;p&gt;這種模式可能導致採集到的數據不完整且與文件的最終內容不一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fc14b0f44891b38e616836bdef9df5c90d2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推薦多進程寫入各自不同文件，這樣可以保證日誌的完整性和順序性。如無法避免，請在消費端做好異常日誌的兼容邏輯。&lt;/p&gt; 
&lt;h3&gt;4. 創建文件空洞釋放日誌文件空間，因改變文件簽名和內容，可能導致日誌重複採集或數據丟失&lt;/h3&gt; 
&lt;p&gt;通過在文件頭部創建空洞來釋放日誌文件空間是一種存在風險的做法，原因如下：&lt;/p&gt; 
&lt;p&gt;a. 文件簽名改變。LoongCollector（原 iLogtail）為避免 inode 複用漏採數據，額外使用文件頭部的內容作為文件唯一性的判斷依據。創建空洞可能改變這個簽名，導致採集器誤判為新文件。&lt;/p&gt; 
&lt;p&gt;b. 數據完整性問題。創建空洞實際上是用 \0 字符替換了原有內容，可能導致重要的歷史日誌丟失。&lt;/p&gt; 
&lt;p&gt;c. 文件系統碎片化。頻繁創建空洞可能導致文件系統碎片化，影響讀寫性能。&lt;/p&gt; 
&lt;p&gt;這種做法可能導致數據重複採集和歷史數據丟失。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6c6407d85a79a192a0b95f05fca565f3e16.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;推薦使用標準的日誌輪轉機制來管理日誌文件大小，如使用 logrotate 工具定期輪轉日誌文件，這樣可以保證日誌的完整性和可追溯性。如無法避免，建議使用 &lt;code&gt;fallocate &lt;/code&gt;而非 &lt;code&gt;truncate 或 dd，&lt;/code&gt;並在消費端做好異常日誌的兼容邏輯。&lt;/p&gt; 
&lt;h3&gt;5. 頻繁覆蓋寫文件，因文件內容頻繁變化，可能導致採集數據不完整或不一致&lt;/h3&gt; 
&lt;p&gt;頻繁覆蓋寫整個日誌文件是一種不安全的日誌管理方式，可能導致以下問題：&lt;/p&gt; 
&lt;p&gt;a. 文件元信息與內容不一致。在覆蓋過程中，文件大小等元信息可能先於實際內容更新，導致採集器讀取到不完整或不一致的內容。&lt;/p&gt; 
&lt;p&gt;b. 數據丟失風險。如果在日誌採集過程中發生覆蓋寫入，可能導致採集讀取到的數據內容錯亂或丟失。&lt;/p&gt; 
&lt;p&gt;c. 歷史數據難以保留。頻繁覆蓋會導致無法保留歷史日誌，不利於問題追溯和分析。&lt;/p&gt; 
&lt;p&gt;這種做法可能導致採集到的內容與文件最終內容不一致，或完全丟失文件內容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-13e7a8b3340e98dc878a5e6f8087c47f0eb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;建議採用追加寫入（append）的方式記錄日誌，並配合日誌輪轉機制管理文件大小。如無法避免，請在消費端做好異常日誌的兼容邏輯。&lt;/p&gt; 
&lt;h3&gt;6. 使用 vim 編輯文件保存，因創建新文件替換原文件，可能導致日誌重複採集&lt;/h3&gt; 
&lt;p&gt;使用 vim 編輯並保存文件時，vim 的保存機制可能導致以下問題：&lt;/p&gt; 
&lt;p&gt;a. inode 變化。vim 創建新文件替換原文件時，新文件的 inode 與原文件不同，可能導致採集器誤判為新文件。&lt;/p&gt; 
&lt;p&gt;b. 文件簽名改變。新文件的頭部內容可能與原文件不同，改變了文件簽名，導致採集器無法正確識別。&lt;/p&gt; 
&lt;p&gt;c. 文件內容丟失。當 vim 替換文件時，寫入程序可能沒有切換到新保存日誌文件，可能導致日誌內容丟失。&lt;/p&gt; 
&lt;p&gt;這種編輯方式可能導致日誌重複採集或數據丟失。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-312ad3a220f60d82ea0e47d533d32de2372.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如僅需查看日誌，建議使用 less、grep 等只讀工具。如無法避免，請在消費端做好去重和異常處理的邏輯。&lt;/p&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p&gt;日誌是系統運行的"黑匣子"，其管理質量直接影響故障排查效率與系統可靠性。通過規避本文提到的反模式，遵循使用日誌庫輪轉、本地盤寫入、單線程追加等最佳實踐，可顯著降低日誌採集風險，提升可觀測性能。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18627746</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18627746</guid>
      <pubDate>Sun, 11 May 2025 03:19:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>崑崙萬維開源代碼 Agent 模型 Skywork-SWE-32B</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;崑崙萬維開源了其專門為軟件工程（SWE）任務設計的代碼代理模型 Skywork-SWE-32B。&lt;/p&gt; 
&lt;p&gt;據介紹，崑崙萬維團隊通過構建超過 1 萬個可驗證的 GitHub 倉庫任務實例，打造出目前最大規模的可驗證 GitHub 倉庫級代碼修復的數據集，並系統性驗證了大模型在軟件工程任務上的數據縮放定律（Scaling Law）。&lt;/p&gt; 
&lt;p&gt;Skywork-SWE-32B 模型在 SWE-bench Verified 基準上取得 38.0% pass@1 準確率，刷新 Qwen2.5-Coder-32B 系列模型在 OpenHands 代碼框架下的最佳成績。進一步引入測試時擴展技術後，模型表現提升至 47.0% 的準確率，不僅超越了現有參數規模在 32B 以下的開源模型，也顯著效縮小了與閉源模型之間的性能差距。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-75700273fe37027abd1178c6a983f991074.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45145852d765d18d59adfdb2f0f701193c5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過結合測試時縮放技術（Test-Time Scaling），Skywork-SWE-32B 的性能進一步提升至 47.0% 的準確率，超越了 32B 參數以下模型的現有 SOTA 結果。&lt;/p&gt; 
&lt;p&gt;崑崙萬維還明確展示了 LLM 軟件工程能力的數據縮放定律現象，在收集了 8209 條訓練軌跡後仍未出現飽和跡象。此外，崑崙萬維引入了一種高效自動化的 SWE 數據收集流程，並創建了 Skywork-SWE 數據集，該數據集具有大規模、高質量和全面的可執行運行時環境。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FSkywork%2FSkywork-SWE-32B" target="_blank"&gt;https://huggingface.co/Skywork/Skywork-SWE-32B&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356330/skywork-swe-32b</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356330/skywork-swe-32b</guid>
      <pubDate>Sun, 11 May 2025 02:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 智能體對話存在低俗擦邊內容，築夢島 APP 被約談</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;網信上海微信公眾號&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX9cFX9Eaw0BLbMdxV9GbKg" target="_blank"&gt;發文&lt;/a&gt;稱，近期有媒體報道，築夢島 APP 等 AI 聊天軟件存在虛擬角色互動生成低俗內容等問題，經核實，該平台 AI 智能體內容生成環節存在低俗擦邊等違規內容，危害未成年人身心健康。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;6 月 19 日上午，上海市網信辦依法約談築夢島 APP 運營企業主要負責人，要求平台立即整改，健全 AI 生成合成內容審核機制，提升技術把關能力，加強涉未成年人不良內容的整治清理，切實落實未成年人網絡保護義務。企業負責人表示，將按照約談要求，對照問題舉一反三、全面整改。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="310" src="https://oscimg.oschina.net/oscnet/up-a021104c6777b288b3b3b3b2eb09dbff5e9.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上海市網信辦相關負責人指出，AI 技術應用的規範發展事關廣大網民的切身利益。依據《未成年人網絡保護條例》《生成式人工智能服務管理暫行辦法》等相關法規，互聯網平台應當主動履行主體責任，平衡好技術創新與內容合規之間的關係，切實防範 AI 技術濫用風險，保護未成年人合法權益，為用户營造風清氣正的網絡空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據國家網信辦統一部署，上海組織開展的「清朗・整治 AI 技術濫用」專項行動當前已進入第二階段。上海市網信辦聚焦利用 AI 技術製作發佈謠言、不實信息、色情低俗內容、假冒他人、從事網絡水軍活動等突出問題，指導督促網站平台、APP 運營企業集中清理相關違法不良信息，處置違規賬號、MCN 機構。對屢教不改、問題嚴重的企業，上海市網信辦將依法予以處罰，並對典型案例進行媒體曝光。歡迎廣大網民積極參與，通過以下渠道據實提供舉報線索，共同營造清朗網絡生態。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356329</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356329</guid>
      <pubDate>Sun, 11 May 2025 02:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>無需邀請碼，Manus AI 推出 Windows 桌面應用程序</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;Manus AI 宣佈，其備受矚目的 Windows 桌面應用程序正式登陸 Microsoft Store，為 Windows 用户帶來無縫的智能自動化體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Manus AI 的 Windows 桌面應用程序繼承了其雲端服務的核心優勢，通過多代理架構和先進的自主任務處理能力，為用户提供從數據分析到代碼生成的全面支持。與傳統的 AI 助手不同，Manus AI 不僅能提供建議，還能自主規劃並執行復雜任務，例如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;智能任務管理：用户只需輸入模糊的需求，如「分析市場數據」或「規劃旅行行程」，應用便能自動分解任務、搜索信息並生成完整結果，如 Excel 報表或交互式網站。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;本地化性能優化：Windows 應用利用本地計算資源，提供更快的響應速度和更低的延遲，同時支持離線任務處理（需預配置）。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;無縫集成：應用與 Windows 生態深度整合，支持瀏覽器自動化、文件處理及第三方工具調用，適配辦公、開發和創意等多種場景。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="529" src="https://oscimg.oschina.net/oscnet/up-9181760d369a202b7816fd8a4b8e95b481d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據 Microsoft Store 的介紹，安裝該應用需 Windows7 及以上系統，至少 2GB 內存，管理員權限，以及&lt;span&gt;最新&lt;/span&gt;的圖形驅動程序，確保流暢運行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Manus AI Windows 應用保留了其標誌性的「Manus’s Computer」側邊欄功能，允許用户實時觀察 AI 的執行過程，如打開瀏覽器、填寫表單或編寫代碼。用户甚至可以通過回放功能查看任務的每一步操作，極大地提升了透明度和可控性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，應用提供免費每日任務（300 積分）和一次性 1000 積分獎勵，讓新用户能夠快速上手體驗。官方強調，應用目前無需邀請碼即可下載，徹底消除了此前雲端服務的訪問限制。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;與此同時，Manus AI 與 Microsoft Azure AI Foundry 的合作進一步增強了其技術生態。據官方透露，未來可能通過 Windows API 的開放性，將 Manus AI 打造為系統級調度助手，為用户提供更深度的操作系統集成體驗。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管 Windows 應用的發佈廣受好評，但部分用户反饋指出，應用在處理複雜多模態任務（如視頻生成）時可能存在性能瓶頸，且當前缺少語音輸入功能。Manus AI 官方表示，將持續優化應用性能，並計劃引入更多多模態功能，如實時圖像和視頻處理，以滿足多樣化需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356325</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356325</guid>
      <pubDate>Sun, 11 May 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克駁斥 xAI 鉅額虧損傳聞：每月燒錢 10 億美元純屬無稽之談</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有媒體報道稱，科技巨頭埃隆・馬斯克創辦的人工智能初創公司 xAI 每月燒錢高達 10 億美元，這一説法引發了廣泛關注。消息稱，xAI 在構建先進的 AI 模型方面的成本遠遠超過其收入增長，公司的資金需求愈加迫切。對此，馬斯克進行了強烈反駁，稱這些報道 「純屬胡説八道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-34a4735e7445256b266cb4625e29a62693a.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 自 2023 年成立以來，正積極尋求通過債務和股權融資來填補資金缺口，目標是融資 93 億美元。儘管如此，馬斯克合併了 xAI 與社交媒體平台 X，令合併後的新公司的估值達 1130 億美元，其中 xAI 的估值為 800 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據相關人士透露，xAI 的支出速度在整個 AI 行業中顯得尤為顯著。公司預計在未來三個月內將花費超過一半的融資金額，而全年虧損預計達到 130 億美元。相比之下，競爭對手 OpenAI 預計在 2025 年的收入將達到 127 億美元，而 xAI 在同年僅預計收入 5 億美元，明年才有可能突破 20 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;馬斯克的巨大個人魅力和資源，使得 xAI 有理由保持樂觀。他曾在特斯拉和 SpaceX 的早期階段也經歷了類似的鉅額虧損，然而這些項目最終都取得了成功。馬斯克相信，xAI 將在 2027 年實現盈利，儘管當前仍需與時間賽跑，以應對鉅額支出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;xAI 計劃利用與 X 平台的整合，利用其龐大的數據檔案來訓練 AI 模型，從而降低昂貴的數據費用。雖然目前 xAI 正在進行大規模的資金籌集，但公司對於未來的發展前景充滿信心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356227</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356227</guid>
      <pubDate>Sat, 10 May 2025 10:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Boot 啓動優化實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網服務器團隊- Liu Di&lt;/p&gt; 
 &lt;p&gt;本文系統性分析並優化了一個 Spring Boot 項目啓動耗時高達 280 秒的問題。通過識別瓶頸、優化分庫分表加載邏輯、異步初始化耗時任務等手段，最終將啓動耗時縮短至 159 秒，提升近 50%。文章涵蓋啓動流程分析、性能熱點識別、異步初始化設計等關鍵技術細節，適用於大型 Spring Boot 項目的性能優化參考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;文章太長？1 分鐘看圖抓住核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//de4a19ad8ae5ee03f930e1ffa71b9716.gif" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、前言&lt;/h1&gt; 
&lt;p&gt;隨着業務的發展，筆者項目對應的 Spring Boot 工程的依賴越來越多。隨着依賴數量的增長，Spring 容器需要加載更多組件、解析複雜依賴並執行自動裝配，導致項目啓動時間顯著增長。在日常開發或測試過程中，一旦因為配置變更或者其他熱部署不生效的變更時，項目重啓就需要等待很長的時間影響代碼的交付。加快 Spring 項目的啓動可以更好的投入項目中，提升開發效率。&lt;/p&gt; 
&lt;p&gt;整體環境介紹：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Spring 版本：4.3.22&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Spring Boot 版本：1.5.19&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU：i5-9500&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內存：24GB&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化前啓動耗時：280 秒&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、Spring Boot 項目啓動流程介紹&lt;/h1&gt; 
&lt;p&gt;Spring Boot 項目主要啓動流程都在 org.spring-&lt;/p&gt; 
&lt;p&gt;framework.boot.SpringApplication#run(java.lang.String...) 方法中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public ConfigurableApplicationContext run(String... args) {
    StopWatch stopWatch = new StopWatch();
    stopWatch.start();
    // Spring 上下文
    ConfigurableApplicationContext context = null;
    FailureAnalyzers analyzers = null;
    configureHeadlessProperty();
    // 初始化 SpringApplicationRunListener 監聽器
    SpringApplicationRunListeners listeners = getRunListeners(args);
    listeners.starting();
    try {
        ApplicationArguments applicationArguments = new DefaultApplicationArguments(
                args);
        // 環境準備
        ConfigurableEnvironment environment = prepareEnvironment(listeners,
                applicationArguments);
         // 打印 banner
        Banner printedBanner = printBanner(environment);
        // 創建上下文
        context = createApplicationContext();
        analyzers = new FailureAnalyzers(context);
        // 容器初始化
        prepareContext(context, environment, listeners, applicationArguments,
                printedBanner);
        // 刷新容器內容
        refreshContext(context);
        afterRefresh(context, applicationArguments);
        // 結束監聽廣播
        listeners.finished(context, null);
        stopWatch.stop();
        if (this.logStartupInfo) {
            new StartupInfoLogger(this.mainApplicationClass)
                    .logStarted(getApplicationLog(), stopWatch);
        }
        return context;
    } catch (Throwable ex) {
        handleRunFailure(context, listeners, analyzers, ex);
        throw new IllegalStateException(ex);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到在啓動流程中，監聽器應用在了應用的多個生命週期中。並且 Spring Boot 中也預留了針對 listener 的擴展點。我們可以藉此實現一個自己的擴展點去監聽 Spring Boot 的每個階段的啓動耗時，實現如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Slf4j
public class MySpringApplicationRunListener implements SpringApplicationRunListener{
    private Long startTime;
    public MySpringApplicationRunListener(SpringApplication application, String[] args){
    }
    @Override
    public void starting(){
        startTime = System.currentTimeMillis();
        log.info("MySpringListener 啓動開始 {}", LocalTime.now());
    }
    @Override
    public void environmentPrepared(ConfigurableEnvironment environment){
        log.info("MySpringListener 環境準備，準備耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextPrepared(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文準備，耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
    @Override
    public void contextLoaded(ConfigurableApplicationContext context){
        log.info("MySpringListener 上下文載入，耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
   @Override
   public void finished(ConfigurableApplicationContext context, Throwable exception){
        log.info("MySpringListener 結束，耗時：{}毫秒", (System.currentTimeMillis() - startTime));
        startTime = System.currentTimeMillis();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接着還需要在 classpath/META-INF 目錄下新建 spring.factories 文件，並添加如下文件內容：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;org.springframework.boot.SpringApplicationRunListener=com.vivo.internet.gameactivity.api.web.MySpringApplicationRunListener
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;至此，藉助 Listener 機制，我們能夠追蹤 Spring Boot 啓動各階段的耗時分佈，為後續性能優化提供數據支撐。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e19075cd485d32e7d5029945fd7ba604.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;contextLoaded 事件是在 run 方法中的 prepareContext() 結束時調用的，因此 contextLoaded 事件和 finished 事件之間僅存在兩個語句：refreshContext(context) 和 afterRefresh&lt;/p&gt; 
&lt;p&gt;(context,applicationArguements) 消耗了 285 秒的時間，調試一下就能發現主要耗時在 refreshContext() 中。&lt;/p&gt; 
&lt;h1&gt;三、AbstractApplicationContext#refresh&lt;/h1&gt; 
&lt;p&gt;refreshContext() 最終調用到 org.spring-framework.context.support.AbstractApplicationContext#refresh 方法中，這個方法主要是 beanFactory 的預準備、對 beanFactory 完成創建並進行後置處理、向容器添加 bean 並且給 bean 添加屬性、實例化所有 bean。通過調試發現，finishBeanFactoryInitialization(beanFactory) 方法耗時最久。該方法負責實例化容器中所有的單例 Bean，是啓動性能的關鍵影響點。&lt;/p&gt; 
&lt;h1&gt;四、找出實例化耗時的 Bean&lt;/h1&gt; 
&lt;p&gt;Spring Boot 也是利用的 Spring 的加載流程。在 Spring 中可以實現 InstantiationAwareBeanPost-&lt;/p&gt; 
&lt;p&gt;Processor 接口去在 Bean 的實例化和初始化的過程中加入擴展點。因此我們可以實現該接口並添加自己的擴展點找到處理耗時的 Bean。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class TimeCostCalBeanPostProcessor implements InstantiationAwareBeanPostProcessor {
    private Map&amp;lt;String, Long&amp;gt; costMap = Maps.newConcurrentMap();

    @Override
    public Object postProcessBeforeInstantiation(Class&amp;lt;?&amp;gt; beanClass, String beanName) throws BeansException {
        if (!costMap.containsKey(beanName)) {
            costMap.put(beanName, System.currentTimeMillis());
        }
        return null;
    }
    @Override
    public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {
        return true;
    }
    @Override
    public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException {
        return pvs;
    }
    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        return bean;
    }
    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
         if (costMap.containsKey(beanName)) {
            Long start = costMap.get(beanName);
            long cost = System.currentTimeMillis() - start;
            // 只打印耗時長的 bean
             if (cost &amp;gt; 5000) {
                System.out.println("bean: " + beanName + "\ttime: " + cost + "ms");
            }
        }
         return bean;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;具體原理就是在 Bean 開始實例化之前記錄時間，在 Bean 初始化完成後記錄結束時間，打印實例化到初始化的時間差獲得 Bean 的加載總體耗時。結果如圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//28a73a7adfed28c5eff40855c8260121.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到有許多耗時在 10 秒以上的類，接下來可以針對性的做優化。值得注意的是，統計方式為單點耗時計算，未考慮依賴鏈上下文對整體加載順序的影響，實際優化還需結合依賴關係分析。&lt;/p&gt; 
&lt;h1&gt;五、singletonDataSource&lt;/h1&gt; 
&lt;pre&gt;&lt;code&gt;@Bean(name = "singletonDataSource")
public DataSource singletonDataSource(DefaultDataSourceWrapper dataSourceWrapper) throws SQLException {
    //先初始化連接
    dataSourceWrapper.getMaster().init();
    //構建分庫分表數據源
    String dataSource0 = "ds0";
    Map&amp;lt;String, DataSource&amp;gt; dataSourceMap = new HashMap&amp;lt;&amp;gt;();
    dataSourceMap.put(dataSource0, dataSourceWrapper.getMaster());
    //分庫分表數據源
    DataSource shardingDataSource = ShardingDataSourceFactory.createDataSource
    (dataSourceMap,shardingRuleConfiguration, prop);
    return shardingDataSource;    
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;singletonDataSource 是一個分庫分表的數據源，連接池採用的是 Druid，分庫分表組件採用的是公司內部優化後的中間件。通過簡單調試代碼發現，整個 Bean 耗時的過程發生在 createDataSource 方法，該方法中會調用 createMetaData 方法去獲取數據表的元數據，最終運行到 loadDefaultTables 方法。該方法如下圖，會遍歷數據庫中所有的表。因此數據庫中表越多，整體就越耗時。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//05283b802a6c9c0a6c8653f9a7f080cd.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;筆者的測試環境數據庫中有很多的分表，這些分表為了和線上保持一致，分表的數量都和線上是一樣的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//eee1a3f0f0dd73861b2894776a40850b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此在測試環境啓動時，為了加載這些分表會更加的耗時。可通過將分表數量配置化，使測試環境在不影響功能驗證的前提下減少分表數量，從而加快啓動速度。&lt;/p&gt; 
&lt;h1&gt;六、初始化異步&lt;/h1&gt; 
&lt;p&gt;activityServiceImpl 啓動中，主要會進行活動信息的查詢初始化，這是一個耗時的操作。類似同樣的操作在工程的其他類中也存在。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Service
public class ActivityServiceImpl implements ActivityService, InitializingBean{
     // 省略無關代碼
     @Override
     public void afterPropertiesSet() throws Exception {
        initActivity();
    }
     // 省略無關代碼
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以通過將 afterPropertiesSet() 異步化的方式加速項目的啓動。&lt;/p&gt; 
&lt;p&gt;觀察 Spring 源碼可以注意到 afterPropertiesSet 方法是在 AbstractAutowireCapableBeanFactory#&lt;/p&gt; 
&lt;p&gt;invokeInitMethods 中調用的。在這個方法中，不光處理了 afterPropertiesSet 方法，也處理了 init-method。&lt;/p&gt; 
&lt;p&gt;因此我們可以寫一個自己的 BeanFactory 繼承 AbstractAutowireCapableBeanFactory，將 invokeInitMethods 方法進行異步化重寫。考慮到 AbstractAutowireCapableBeanFactory 是個抽象類，有額外的抽象方法需要實現，因此繼承該抽象類的子類 DefaultListableBeanFactory。具體實現代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitListableBeanFactory extends DefaultListableBeanFactory{
     public AsyncInitBeanFactory(ConfigurableListableBeanFactory beanFactory){
         super(beanFactory);
    }
     @Override
     protected void invokeInitMethods(String beanName, Object bean, RootBeanDefinition mbd)throws Throwable {
        if (beanName.equals("activityServiceImpl")) {
            AsyncTaskExecutor.submitTask(() -&amp;gt; {
                try {
                      super.invokeInitMethods(beanName, bean, mbd);
                } catch (Throwable throwable) {
                    throwable.printStackTrace();
                }
            });
        } else {
              super.invokeInitMethods(beanName, bean, mbd);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;又因為 Spring 在 refreshContext() 方法之前的 prepareContext() 發放中針對 initialize 方法提供了接口擴展 (applyInitializers())。因此我們可以通過實現該接口並將我們的新的 BeanFactory 通過反射的方式更新到 Spring 的初始化流程之前。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public interface ApplicationContextInitializer&amp;lt;C extends ConfigurableApplicationContext&amp;gt; {
     /**
     * Initialize the given application context.
     * @param applicationContext the application to configure
     */
    void initialize(C applicationContext);

}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;改造後的代碼如下，新增 AsyncAccelerate-&lt;/p&gt; 
&lt;p&gt;Initializer 類實現 ApplicationContextInitializer 接口：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncBeanFactoryInitializer implements ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt; {
    @SneakyThrows
    @Override
    public void initialize(ConfigurableApplicationContext applicationContext){
        if (applicationContext instanceof GenericApplicationContext) {
            AsyncInitListableBeanFactory beanFactory = new AsyncInitListableBeanFactory(applicationContext.getBeanFactory());
            Field field = GenericApplicationContext.class.getDeclaredField("beanFactory");
            field.setAccessible(true);
            field.set(applicationContext, beanFactory);
        }
    }
}
public class AsyncBeanInitExecutor{
    private static final int CPU_COUNT = Runtime.getRuntime().availableProcessors();
    private static final AtomicReference&amp;lt;ThreadPoolExecutor&amp;gt; THREAD_POOL_REF = new AtomicReference&amp;lt;&amp;gt;();
    private static final List&amp;lt;Future&amp;lt;?&amp;gt;&amp;gt; FUTURES = new ArrayList&amp;lt;&amp;gt;();
     /**
      * 創建線程池實例
      */
     private static ThreadPoolExecutor createThreadPoolExecutor(){
         int poolSize = CPU_COUNT + 1;
         return new ThreadPoolExecutor(poolSize, poolSize, 50L, TimeUnit.SECONDS, new LinkedBlockingQueue&amp;lt;&amp;gt;(), new ThreadPoolExecutor.CallerRunsPolicy()
        );
    }
    /**
     * 確保線程池已初始化（線程安全）
     */
     private static void ensureThreadPoolExists(){
         if (THREAD_POOL_REF.get() != null) {
              return;
        }
        ThreadPoolExecutor executor = createThreadPoolExecutor();
         if (!THREAD_POOL_REF.compareAndSet(null, executor)) {
            executor.shutdown(); // 另一線程已初始化成功
        }
    }
    /**
     * 提交異步初始化任務
     *
     * @param task 初始化任務
     * @return 提交後的 Future 對象
     */
    public static Future&amp;lt;?&amp;gt; submitInitTask(Runnable task) {
        ensureThreadPoolExists();
        Future&amp;lt;?&amp;gt; future = THREAD_POOL_REF.get().submit(task);
        FUTURES.add(future);
        return future;
    }
    /**
     * 等待所有初始化任務完成並釋放資源
     */
    public static void waitForInitTasks(){
        try {
            for (Future&amp;lt;?&amp;gt; future : FUTURES) {
                future.get();
            }
        } catch (Exception ex) {
            throw new RuntimeException("Async init task failed", ex);
        } finally {
            FUTURES.clear();
            shutdownThreadPool();
        }
    }
     /**
     * 關閉線程池並重置引用
     */
     private static void shutdownThreadPool(){
        ThreadPoolExecutor executor = THREAD_POOL_REF.getAndSet(null);
         if (executor != null) {
            executor.shutdown();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;實現類後，還需要在 META-INF/spring.factories 下新增説明 org.springframework.context.&lt;/p&gt; 
&lt;p&gt;ApplicationContextInitializer=com.xxx.AsyncAccelerateInitializer，這樣這個類才能真正生效。&lt;/p&gt; 
&lt;p&gt;這樣異步化以後還有一個點需要注意，如果該初始化方法執行耗時很長，那麼會存在 Spring 容器已經啓動完成，但是異步初始化任務沒執行完的情況，可能會導致空指針等異常。為了避免這種問題的發生，還要藉助於 Spring 容器啓動中 finishRefresh() 方法，監聽對應事件，確保異步任務執行完成之後，再啓動容器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public class AsyncInitCompletionListener implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt;, ApplicationContextAware, PriorityOrdered{
    private ApplicationContext currentContext;
    @Override
    public void setApplicationContext(ApplicationContext applicationContext)throws BeansException {
         this.currentContext = applicationContext;
    }
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event){
        if (event.getApplicationContext() == currentContext) {
            AsyncBeanInitExecutor.waitForInitTasks();
        }
    }
    @Override
    public int getOrder(){
         return Ordered.HIGHEST_PRECEDENCE;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;七、總結&lt;/h1&gt; 
&lt;p&gt;啓動優化後的項目實際測試結果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2f535724d8b21204e9e881711c6acf6f.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過異步化初始化和分庫分表加載優化，項目啓動時間從 280 秒縮短至 159 秒，提升約 50%。這對於提升日常開發效率、加快測試與聯調流程具有重要意義。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18627678</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18627678</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>數據「熵增」時代，AI 如何以標準重構治理秩序?</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;Agent 熱潮不減,但數據分析與治理狀況卻仍存在短板。據 Gartner 公司預測,到 2027 年,80% 的數據和分析治理舉措或將因各類原因而失效。如何在 AI 時代重塑數據治理體系,讓混亂數據重歸有序,成為企業智能轉型的關鍵命題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;近日,在 infoQ 舉辦的全球人工智能開發與應用大會上,瓴羊智能數據建設與治理產品 Dataphin 高級技術專家，周鑫，受邀出席,以&lt;strong&gt;「基於統一標準的智能數據治理&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;Dataphin&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;的落地實踐」&lt;/strong&gt;為主題,系統闡述了以數據標準為核心,實現可持續數據治理的方法論,以及以 AI 賦能自動化數據治理、重構複雜業務流程的實踐路徑。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;01&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;數據「&lt;/strong&gt;&lt;strong&gt;熵減」之道:基於統一標準,打造數據治理方法論&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「事物天生具有‘變混亂’的趨勢,數據也是如此。如何將無序變得有序?按照熱力學第二定律,需要從外界輸入能量,並且具備感知能力。」&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示:「對於數據治理來説,能量就是治理工具,感知就是標準規範。」數據治理是實現數據世界的「熵減」,它可以通過&lt;strong&gt;現狀評估、制定目標、執行計劃、持續監測&lt;/strong&gt;四個治理階段,幫助數據生產者打破孤島,實現低成本數據開發,幫助數據管理者做好資產盤點,確保數據質量與安全,幫助數據使用者便捷用數,助力決策分析。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//5ca3fd8084d8b3ffa1e3874b915a46b8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;但在現實情況中,許多數據治理的結果通常會面臨失敗,周鑫將其歸結為四個原因:1) 治理動作分散,缺乏體系化方法論;2) 治理流程複雜,重度依賴人的能力和素質;3) 缺乏工具支撐,導致理論與實施脱節;4) 無法持續治理,治理策略難以快速調整。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c19a9aa3073e13c96e65f3ea454ed7c5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;面對以上四類問題,Dataphin 提出了一套以數據標準為中心的數據治理方法論及產品化的落地。其核心邏輯為:&lt;strong&gt;聚焦&lt;/strong&gt;&lt;strong&gt;Data x AI&lt;/strong&gt;&lt;strong&gt;,用中台方法論構建統一的數據標準&lt;/strong&gt;,打造企業級好數據,幫助企業形成數據生產、數據消費、行業數據流通的數據要素服務鏈,驅動數據價值的釋放。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「方法論的核心關鍵,在於以數據標準為中心。數據標準貫穿數據整個生命週期,它讓數據治理具備核心抓手,不會漫無目的」,周鑫表示,&lt;strong&gt;企業需從核心業務入手,先行試點開展業務梳理與盤點工作,將相關統一納入&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;DataCatalog&lt;/strong&gt;&lt;strong&gt;,並在此過程中逐步形成對應的數據標準。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;標準梳理完成後,平台即可開展標準構建:通過統一的數據標準,自動實現質量監控與安全分類,保障開發過程規範,阻斷不規範數據開發。同時,統一標準可提升數據的可理解性與細節清晰度,實現數據從生成、開發到消費的全生命週期標準化管理。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a79214da341aeb304b867992344fd1c8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;「整個治理鏈路就是以數據標準為中心,將傳統的複雜的治理手段,簡化成數據標準的梳理與治理效果的評估過程,數據符合標準的程度越高,整體數據質量也就越好」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,該方案以數據標準為核心,通過插件集成、API 註冊和準實時同步等多種方式採集元數據,並統一納入 DataCatalog,結合質量規則和安全策略進行自動識別與治理。這一方法論具備三大優勢:一是&lt;strong&gt;體系化&lt;/strong&gt;,明確治理目標與路徑;二是&lt;strong&gt;易落地&lt;/strong&gt;,藉助一體化工具和 AI 能力,貫穿數據全生命週期;三是&lt;strong&gt;可持續&lt;/strong&gt;,以標準驅動模式便於應對業務變化,有效降低治理成本與複雜度。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;02&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;語義知識&lt;/strong&gt;&lt;strong&gt;+&lt;/strong&gt;&lt;strong&gt;流程提效,智能&lt;/strong&gt;&lt;strong&gt;Agent&lt;/strong&gt;&lt;strong&gt;多場景賦能數據治理&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; text-align:left"&gt;許多企業在應用 Agent 時都難免遇到一個難題:Agent 雖然具備一定的智能和對話能力,但在複雜業務場景中常常「空轉」,無法真正理解業務語境、解決預期的實際問題。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;周鑫表示,造成這一現象的根本原因,「在於數據質量偏低或數字化基礎薄弱,導致 Agent 無法有效發揮價值,最終企業只能被迫放棄」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;AI 時代,優質數據至關重要,但「好數據」應如何獲取?AI 又該如何賦能數據治理?&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;首先,「Agent 在沒有豐富準確的語義知識下,不可能達到可生產使用的準確率」,周鑫認為,&lt;strong&gt;企業獲取好數據,需要構建準確且豐富的語義知識體系&lt;/strong&gt;。Dataphin 針對這一需求,打造了包含&lt;strong&gt;元數據&lt;/strong&gt;、&lt;strong&gt;數據標準&lt;/strong&gt;、&lt;strong&gt;數據模型&lt;/strong&gt;、&lt;strong&gt;業務知識&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;四大語義知識體系。企業可以通過採集豐富且統一的元數據,建立涵蓋碼錶、詞根、值域及安全分類分級的標準體系,依託 Dataphin 智能構建的概念模型、邏輯模型和物理模型,以及對業務詞條和邏輯的高效管理,實現對複雜業務知識的精準映射和應用。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e35e9b9658db17cdacdbbccf911c6633.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 為例,Dataphin 通過引入業務語義,不僅提升了問題泛化能力,還大幅提高了 SQL 匹配的準確率,顯著增強了對自然語言的理解能力。實測數據顯示,在 Dataphin 開放數據共享模型涵蓋的 45 個典型問題中,&lt;strong&gt;簡單問題的&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;strong&gt;準確率從&lt;/strong&gt;&lt;strong&gt;70%&lt;/strong&gt;&lt;strong&gt;提升至&lt;/strong&gt;&lt;strong&gt;80%&lt;/strong&gt;&lt;strong&gt;,而中等及複雜問題的準確率更是從&lt;/strong&gt;&lt;strong&gt;10%&lt;/strong&gt;&lt;strong&gt;躍升至&lt;/strong&gt;&lt;strong&gt;60%&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;其次,企業還需藉助 AI,對數據治理鏈路進行提效。基於 TaskWeaver 改造,Dataphin 構建了具備生產化能力的 Agent 框架,覆蓋研發、治理、資產問答等多個場景,顯著提升了現有流程效率,拓展了 Agent 的應用邊界。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;以 NL2SQL 為例,系統可在識別信息不全時自動發起反問,補全後再繼續處理,確保複雜業務場景下依然具備高理解力與執行準確率。同時,Dataphin 的開放能力不斷演進,從傳統的 API 和數據服務擴展至 MCP 模式,支持更靈活的接入方式,適配非固定流程和動態交互等複雜需求。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;智能找表&lt;/strong&gt;場景,Dataphin 有效解決了用户將複雜業務問題,轉化為準確搜索詞的難題。「引入 AI 後,你可以用業務的語言直接問,比如‘我要做客户分層’,‘我要用哪張表’,AI 會用大模型去對業務問題進行拆解和泛化,最後找關聯到你已有的全域資產」。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 5.png" height="366" src="https://oscimg.oschina.net/oscnet//44b7bd5fb943546e95785c6a26a72115.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;數據分析&lt;/strong&gt;場景,Dataphin 通過專輯機制與豐富的語義知識,解決了因語義知識的缺失或混亂,相似口徑和命名幹擾、以及海量表格帶來的找表難題,顯著提升了找表的效率與準確率。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 6.png" height="366" src="https://oscimg.oschina.net/oscnet//5484c3d0938ae4172448aca47dd0d73a.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;數據治理&lt;/strong&gt;場景,Dataphin 通過「性別」等複雜字段特徵識別,解決了正則表達式「不會寫」、「看不懂」難題,取代了傳統人工探查的繁瑣過程,以往需要耗費十幾分鐘的特徵識別,如今只需幾十秒即可完成。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 7.png" height="460" src="https://oscimg.oschina.net/oscnet//5ada55aa58b287d443496c220aa124d5.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;在&lt;strong&gt;數據管家&lt;/strong&gt;場景中,資產上架往往涉及表描述、字段註釋、目錄歸屬、標籤分類等複雜操作,尤其在字段數量眾多時,人工維護工作量大、耗時長且易出錯。通過引入 AI 能力,Dataphin 支持屬性信息的智能生成,可一鍵生成表/字段描述信息、目錄、標籤等,使人力成本與操作門檻大大降低。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="圖片 8.png" height="359" src="https://oscimg.oschina.net/oscnet//004299cfcc7d5766516ace7402af26ad.png" width="650" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;隨着 AI 對複雜節點的處理能力增強,Dataphin 正在以「智能工作台」有機整合獨立模塊,重構整體業務流程。 「有了 AI 之後,工作台模式可以讓很少的人,完成複雜的業務,每個環節都有大量 AI 和自動化能力支撐,人們乾的最多的事情是進行確認」,周鑫表示,未來,AI 還將在更多場景中深度參與,從輔助提效逐步向自動化、智能化方向邁進,推動企業實現數據治理範式的全面升級。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356211</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356211</guid>
      <pubDate>Sat, 10 May 2025 08:27:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Workout.cool —— 現代開源健身教練平台</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;一個全面的健身指導平台，可以為你制定鍛鍊計劃、跟蹤進度並訪問包含詳細説明和視頻演示的龐大鍛鍊數據庫。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;項目包含一個全面的練習數據庫。要導入練習樣本，請執行以下操作：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;導入的先決條件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;準備 CSV 文件&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你的 CSV 應該包含以下列：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以使用提供的示例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;導入命令&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Import exercises from a CSV file&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full /path/to/your/exercises.csv

&lt;span&gt;&lt;span style="color:#59636e"&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;#&lt;/span&gt;&lt;/span&gt; Example with the provided sample data&lt;/span&gt;&lt;/span&gt;
pnpm run import:exercises-full ./data/sample-exercises.csv&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;CSV 格式示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;id,name,name_en,description,description_en,full_video_url,full_video_image_url,introduction,introduction_en,slug,slug_en,attribute_name,attribute_value
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,TYPE,STRENGTH
157,"Fentes arrières à la barre","Barbell Reverse Lunges","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;","&amp;lt;p&amp;gt;Stand upright...&amp;lt;/p&amp;gt;",https://youtube.com/...,https://img.youtube.com/...,slug-fr,slug-en,PRIMARY_MUSCLE,QUADRICEPS&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可用的屬性類型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRENGTH&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CARDIO&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;PLYOMETRICS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;STRETCHING&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PRIMARY_MUSCLE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;QUADRICEPS&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;CHEST&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BACK&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;SHOULDERS&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SECONDARY_MUSCLE&lt;/strong&gt;: Secondary muscle groups targeted&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EQUIPMENT&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BARBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;DUMBBELL&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;BODYWEIGHT&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;MACHINE&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MECHANICS_TYPE&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;COMPOUND&lt;/code&gt;,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ISOLATION&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/workout-cool</link>
      <guid isPermaLink="false">https://www.oschina.net/p/workout-cool</guid>
      <pubDate>Sat, 10 May 2025 08:20:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenBMB 開源輕量級 CUDA 推理框架 CPM.cu</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 推出了 CPM.cu，這是一個輕量級且高效的開源 CUDA 推理框架，專為端側大型語言模型（LLMs）的部署而設計，併為&lt;a href="https://www.oschina.net/news/354328"&gt;MiniCPM4&lt;/a&gt;提供優化，核心支持&lt;strong&gt;稀疏架構&lt;/strong&gt;、&lt;strong&gt;投機採樣&lt;/strong&gt;和&lt;strong&gt;低位寬量化&lt;/strong&gt;等前沿技術創新。&lt;/p&gt; 
&lt;p&gt;CPM.cu 亮點包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集成了 InfLLM v2 可訓練稀疏注意力內核，可加速長上下文預填充和解碼；&lt;/li&gt; 
 &lt;li&gt;FR-Spec（頻率排序推測採樣）通過壓縮詞彙空間提高草稿效率，顯著降低計算開銷；&lt;/li&gt; 
 &lt;li&gt;結合了 EAGLE-2 推測採樣、4 位量化和基於滑動窗口注意力的長上下文支持，從而在資源受限設備上實現高效部署。&lt;/li&gt; 
 &lt;li&gt;性能方面，在 128K-token 序列上，預填充速度比 Qwen3-8B 快 2-4 倍，解碼速度快 4-6 倍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CPM.cu&amp;nbsp; 框架結構：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CPM.cu/
├── src/
│   ├── flash_attn/ # 修改後的 Flash-Attention, 支持稀疏和投機採樣
│   ├── model/
│   │   ├── minicpm4/ # minicpm4 模型
│   │   │   ├── minicpm4_model.cuh # 模型的核心實現
│   │   │   └── minicpm4_eagle.cuh # 投機採樣實現
│   │   ├── model.cuh # 其他代表性模型
│   │   ├── w4a16_gptq_marlin/ # GPTQ 量化計算 kernel
│   │   ├── memory.cuh # 顯存分配
│   │   └── layer.cuh # 通用層
│   ├── entry.cu # pybind: 連接 C/CUDA 和 Python
│   └── ...
├── cpmcu/ # python interface
└── ...&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;cpmcu/ 代碼提供了一個 python 的調用接口，裏面涉及在 Python 側 tokenize，調用 C 代碼得到模型的輸出 logits，在 Python 側根據 logits 採樣並 detokenize 這些過程。我們使用了 pybind 將 C 代碼與 Python 代碼進行綁定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/memory.cuh 這裏實現了整個推理框架的內存管理，這裏我們採用了先分配模型權重，再分配模型中間計算結果所需的空間，最後把所有剩餘顯存分配給 kv-cache 的內存管理策略。這一點設計上是和 vLLM, SGLang 類似的。分配中間計算結果的空間時可以考慮一下中間計算結果的生命週期，做一點顯存複用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/w4a16_gptq_marlin/ 量化的計算 kernel。這裏直接使用了 vLLM 的 Marlin 代碼。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/model/minicpm4/ 這裏是模型的架構實現。src/model/下也有其他代表性模型實現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;src/flash_attn/ 我們基於 flash_attn 2.6.3 版本，在上面增加了對 InfLLM v2、投機採樣的適配支持。下面我們主要介紹這一部分，也是整個框架實現的難點。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FCPM.cu" target="_blank"&gt;https://github.com/OpenBMB/CPM.cu&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356197</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356197</guid>
      <pubDate>Sat, 10 May 2025 07:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源模型上下文協議 MCP 更新規範文檔，添加對結構化工具輸出的支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源模型上下文協議 MCP 昨天更新了規範文檔，主要變更如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;移除對 JSON-RPC 批處理的支持（PR #416）&lt;/li&gt; 
 &lt;li&gt;添加對結構化工具輸出的支持（PR #371）&lt;/li&gt; 
 &lt;li&gt;將 MCP 服務器歸類為 OAuth 資源服務器，添加受保護資源元數據以發現相應的授權服務器。（PR #338）&lt;/li&gt; 
 &lt;li&gt;要求 MCP 客户端按照 RFC 8707 中描述的方式實現資源指示器，以防止惡意服務器獲取訪問令牌。（PR #734）&lt;/li&gt; 
 &lt;li&gt;在授權規範中闡明安全注意事項和最佳實踐，並在新的安全最佳實踐頁面中説明。&lt;/li&gt; 
 &lt;li&gt;增加引導支持，使服務器能夠在交互過程中向用户請求更多信息。（PR #382）&lt;/li&gt; 
 &lt;li&gt;在工具調用結果中增加資源鏈接支持。（PR #603）&lt;/li&gt; 
 &lt;li&gt;在使用 HTTP 時，後續請求中需通過&amp;nbsp;&lt;code&gt;MCP-Protocol-Version&lt;/code&gt;&amp;nbsp;頭指定協商的協議版本。（PR #548）&lt;/li&gt; 
 &lt;li&gt;將生命週期操作中的 SHOULD 改為 MUST&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fspecification%2F2025-06-18%2Fchangelog" target="_blank"&gt;https://modelcontextprotocol.io/specification/2025-06-18/changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356195</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356195</guid>
      <pubDate>Sat, 10 May 2025 07:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源代碼編輯器 Zed 上線「調試器」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源代碼編輯器 Zed &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fdebugger" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出「調試器（Debugger）」功能，稱這是向 Zed 1.0 邁出的重要一步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;調試器特性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;快速&lt;/strong&gt; ：減少上下文切換時間，讓用户能更專注於調試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;熟悉&lt;/strong&gt; ：與 Zed 的設計語言保持一致，支持典型的調試流程，方便用户快速上手。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可配置&lt;/strong&gt; ：用户可自定義 UI、鍵綁定、調試配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-43c899b5d73c5470109aecf601bbff05ba7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Zed 開箱即支持調試多種流行編程語言，包括 Rust、C/C++、JavaScript、Go 和 Python。通過擴展系統，Zed 可以支持任何實現調試適配器協議（DAP）的調試適配器。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;技術架構&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   採用兩層架構，數據層與調試適配器直接通信，UI 層從數據層獲取數據進行界面渲染。
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   數據層負責維護會話狀態、緩存響應、使失效數據，UI 層按需請求數據，避免不必要的請求，便於後續實現協作調試。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;調試適配器集成&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   擴展了 Zed 的擴展 API 以支持調試器集成，通過定義自定義架構等方式，讓擴展作者能輕鬆將調試適配器集成到 Zed 中。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;內聯變量值實現&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   利用 Tree-sitter 查詢準確識別當前執行範圍內的變量，無需依賴 LSP 服務器與調試適配器的緊密集成，目前支持 Python、Rust、Go 等語言。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fdocs%2Fdebugger" target="_blank"&gt;https://zed.dev/docs/debugger&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356190/zed-debugger</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356190/zed-debugger</guid>
      <pubDate>Sat, 10 May 2025 06:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 Rust 瀏覽器引擎 Servo 支持 GIF</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Servo 是一款開源的瀏覽器引擎，最初由 Mozilla 開發。它使用 Rust 語言編寫，旨在提供高效、安全的網頁渲染能力，並且採用並行渲染技術，以提高網頁加載速度和性能。&lt;/p&gt; 
&lt;p&gt;近日，Servo 團隊介紹了最近的更新內容，其中一項重要新功能是&lt;strong&gt;支持顯示動態 GIF&lt;/strong&gt;，並且還可以通過 HTML "img"標籤加載 SVG 圖像。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/142856_yG2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 還在推進其 Trusted Types API、輸入類型 &amp;lt;input type=color&amp;gt; 支持、更好的佈局和 CSS 支持，以及支持各種其他 API 和功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f8cd0cc574887e5f2e0cc055fb9586cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 還在繼續努力提升圍繞 Servo 嵌入支持的開發者體驗，以 Servo 作為 Chromium 的 CEF 替代方案在應用程序中利用 Servo。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2025%2F06%2F18%2Fthis-month-in-servo%2F" target="_blank"&gt;https://servo.org/blog/2025/06/18/this-month-in-servo/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</guid>
      <pubDate>Sat, 10 May 2025 06:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美國科技巨頭推動聯邦立法，禁止各州單獨監管 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《金融時報》報道稱，近日美國多家大型科技公司正積極推動一項聯邦禁令，旨在禁止各州自行制定人工智能（AI）監管法規。此次立法倡議得到了亞馬遜、谷歌、微軟和 Meta 等公司的支持，目的是避免各州在 AI 監管方面各自為政，影響行業的整體發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士透露，這項禁令提案已經被納入眾議院版本的 「大而美」 預算法案中。參議院也計劃在近期推出自己的版本，並希望能夠在 7 月 4 日之前完成相關立法工作。前聯邦眾議員、現任 INCOMPAS 首席執行官 Chip Pickering 是這項提案的重要推動者，他表示，保持美國在技術領域的領導地位是確保國家競爭力的關鍵。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;INCOMPAS 組織於 2024 年成立了 「人工智能競爭中心」（AICC），專注於遊説國會與監管機構，以適應快速發展的 AI 行業。隨着 AI 監管討論的加劇，尤其是在歐盟出台新規後，亞馬遜和 Meta 也加入了該組織，試圖通過統一監管來增強競爭力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，此提案引發了廣泛的爭議。反對者認為，大型科技公司推動禁令的真正目的是為了鞏固自身在 AGI（通用人工智能）競爭中的壟斷地位。範德比爾特大學的政策加速中心 AI 與科技政策主任 Asad Ramzanali 表示，負責任的創新不應該懼怕法律的約束。同時，麻省理工學院的教授 Max Tegmark 也批評稱，這種行為是科技巨頭為了進一步集中財富和權力的擴張。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，支持禁令的人士認為，聯邦層面的統一監管將有助於避免各州的分歧，保持行業的創新能力，從而在全球 AI 競爭中處於有利地位。AI 安全倡導者如 Anthropic 聯合創始人 Dario Amodei 則警告稱，如果完全依賴企業自我監管，可能會帶來嚴重的社會風險。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356176</guid>
      <pubDate>Sat, 10 May 2025 06:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
