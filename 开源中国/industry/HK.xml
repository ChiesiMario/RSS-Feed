<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 09 Sep 2025 02:40:35 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>字節 Seedream 4.0 圖像創作模型正式發佈</title>
      <description/>
      <link>https://www.oschina.net/news/371058</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371058</guid>
      <pubDate>Tue, 09 Sep 2025 02:38:32 GMT</pubDate>
    </item>
    <item>
      <title>知名 Android 第三方桌面 Nova Launcher 將停止維護</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;知名 Android 第三方桌面&lt;span&gt;啓動器 Nova Launcher 創始人和原始開發者 Kevin Barry 宣佈，他已經離開收購 Nova Launcher 的分析公司 Branch，並不再參與該項目。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1658" src="https://static.oschina.net/uploads/space/2025/0909/103239_Hnwx_2720166.png" width="1502" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://teslacoilapps.com/nova/solong.html&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據悉，Nova Launcher 由 Kevin Barry 帶隊開發，於 2022 年被 Branch 收購。當時，Branch 承諾不會將 Nova Launcher 變為訂閲式付費、帶有廣告的普通 Android 桌面啓動器。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d68adf6667956ed5f537c0b8b93ebbb0b93.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據 Kevin Barry 透露，其在過去幾個月不斷為 Nova Launcher 的開源進行付出。其表示，雖然 Branch 曾在收購 Nova Launcher 時承諾，其若離職，Nova Launcher 最終則會開源，但 Barry 現被要求停止開發 Nova Launcher 和終止進行開源工作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371057</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371057</guid>
      <pubDate>Tue, 09 Sep 2025 02:35:32 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義發佈語音識別模型 Qwen3-ASR-Flash</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通義千問系列最新的語音識別模型 Qwen3-ASR-Flash 已正式發佈，它基於 Qwen3 基座模型，經海量多模態數據以及千萬⼩時規模的 ASR（自動語音識別）數據訓練構建而成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101857_EGZg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 實現了⾼精度⾼魯棒性的語⾳識別性能，⽀持 11 種語⾔和多種⼝⾳。與眾不同的是，Qwen3-ASR-Flash⽀持⽤户以任意格式提供⽂本上下⽂，從⽽獲得定製化的 ASR 結果，同時還⽀持歌聲識別。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101903_kNR1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="664" src="https://static.oschina.net/uploads/space/2025/0909/101933_MOCR_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1395" src="https://static.oschina.net/uploads/space/2025/0909/101944_O6J2_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 單模型支持多種語言、方言和口音的精準轉錄：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中文：包括普通話以及四川話、閩南語、吳語、粵語等主要方言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;英語：支持英式、美式及多種其他地區口音。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;其他支持語言：法語、德語、俄語、意大利語、西班牙語、葡萄牙語、日語、韓語和阿拉伯語。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Qwen3-ASR-Flash 的核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;領先的識別準確率：Qwen3-ASR-Flash 在多箇中英文，多語種 benchmark 測試中表現最優。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;驚豔的歌聲識別能力：支持歌唱識別,包括清唱與帶 bgm 的整歌識別，實測錯誤率低於 8%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定製化識別：用户可以以任意格式 (如詞彙表、段落或完整文檔) 提供背景文本，模型能智能利用該上下文識別並匹配命名實體和其他關鍵術語，輸出定製化的識別結果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;語種識別與非人聲拒識：模型能精確分辨語音的語種，自動過濾非語音片段，包括靜音和背景噪聲。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;魯棒性：面對長難句、句中語言切換和重複詞語等困難文本模式，以及在複雜的聲學環境中，模型仍能保持高準確率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;體驗方式：&lt;/p&gt; 
&lt;p&gt;ModelScope&lt;strong&gt;：&lt;/strong&gt;https://modelscope.cn/studios/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;HuggingFace:&amp;nbsp;https://huggingface.co/spaces/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;阿里雲百鍊 API&lt;strong&gt;：&lt;/strong&gt;https://bailian.console.aliyun.com/?tab=doc#/doc/?type=model&amp;amp;url=2979031&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371054</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371054</guid>
      <pubDate>Tue, 09 Sep 2025 02:21:32 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Databricks 融資 10 億美元，估值超 1000 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Databricks &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.databricks.com%2Fcompany%2Fnewsroom%2Fpress-releases%2Fdatabricks-surpasses-4b-revenue-run-rate-exceeding-1b-ai-revenue" target="_blank"&gt;宣佈&lt;/a&gt;即將完成 10 億美元的 K 輪融資，對應估值超過 1000 億美元。此輪融資由 Andreessen Horowitz、Insight Partners、MGX、Thrive Capital 和 WCM Investment Management 共同領投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 表示，將利用這筆新資金加速其 AI 戰略——擴展 Agent Bricks，推出全新 Lakebase 產品線，並推動全球增長。以及支持 Databricks 未來的 AI 收購，並深化 AI 研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="245" src="https://oscimg.oschina.net/oscnet/up-ba2a1094a2ce8345cb7359294aa377ea3d0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在公告中，Databricks 還透露了部分財務狀況，披露其第二季度的年收入運行率超過 40 億美元，同比增長 50%，並在過去 12 個月中實現了正自由現金流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該公司還表示，其人工智能產品的年營收運行率近期已超過 10 億美元，淨留存率超過 140%，目前有超過 650 家客户使用 Databricks 的產品，年收入超過 100 萬美元。目前，共有超過 2 萬家企業和組織在使用其軟件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 聯合創始人兼首席執行官 Ali Ghodsi 在公告中表示：「我們的團隊正在構建企業未來幾十年將依賴的數據和 AI 基礎設施，從而取得這些成果。有了這筆新資金，我們將能夠加快 Agent Bricks 的發展步伐，幫助各行各業的客户將其數據轉化為生產級 AI 代理，並在創建新的 Lakebase 類別、為 AI 代理重塑數據庫的過程中獲得更大的發展動力。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 還指出，在前兩個季度中，該公司已與微軟、谷歌雲、Anthropic、SAP 和 Palantir 建立或擴大了合作伙伴關係。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371049</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371049</guid>
      <pubDate>Tue, 09 Sep 2025 02:08:32 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥造物分享：流浪地球 550W（MOSS）小智 AI 生態中樞</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2186</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2186</guid>
      <pubDate>Tue, 09 Sep 2025 01:49:32 GMT</pubDate>
    </item>
    <item>
      <title>李彥宏頒發「百度最高獎」：心流團隊獲 100 萬美元獎勵</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，百度創始人李彥宏在內部活動上為技術團隊頒發「百度最高獎」，獲獎團隊得到 100 萬美元獎勵，合人民幣超 700 萬元。「百度最高獎」已歷經 15 屆，語音識別、深度學習平台、大模型等大量 AI 技術均曾獲獎，獎金總金額將近 4 億元人民幣。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-322339010570111171fc427256170f32b22.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，「百度最高獎」於 2010 年 7 月設立，鼓勵「小團隊做出大事業」，是百度公司最高級別的獎項，給予每個獲獎團隊 100 萬美元獎勵。獎項評選需滿足三項條件：項目意義重大；成果遠超預期；團隊足夠小，必須是小於等於 10 人。&lt;/p&gt; 
&lt;p&gt;本次百度最高獎的獲獎團隊為「心流」團隊。據介紹，「心流」團隊率先實現了端到端的多模態內容理解與序列生成技術。李彥宏在頒獎時表示，到今天，模型發展已經非常接近臨界點，很快就會有各種有價值的應用被創造出來，「我們生活在一個非常令人興奮、非常令人期待的環境當中」。&lt;/p&gt; 
&lt;p&gt;李彥宏稱，百度搜索已有近 70% 結果含有 AI 生成內容，且通過「百看」帶來富媒體形式，是全球所有的搜索引擎當中改造最激進的，這也代表搜索引擎的未來。&lt;/p&gt; 
&lt;p&gt;同時，百度慧博星數字人已達到「以假亂真」的地步，「很多人看不出是數字人還是真人」；百度蘿蔔快跑已覆蓋全球 16 座城市，代表着最新一代的無人駕駛技術。&lt;/p&gt; 
&lt;p&gt;頒獎典禮現場，李彥宏在談及 AI 發展時指出，「AI 大模型發展到今天，其實已接近了臨界點，很快就會有各種各樣非常有價值的應用能夠創造出來，我們正生活在一個非常令人興奮、非常令人期待的市場環境當中。」&lt;/p&gt; 
&lt;p&gt;「我們所從事的每一項工作都代表着未來，我也希望大家和我一起去期待，去迎接、去奮鬥出一個創新在 C 位的社會。」李彥宏表示。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370987</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370987</guid>
      <pubDate>Sat, 06 Sep 2025 11:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「AI 教父」辛頓竟然被前女友竟用 ChatGPT 提分手</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，被譽為「AI 教父」 的 Geoffrey Hinton 在接受採訪時&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F31feb335-4945-475e-baaa-3b880d9cf8ce" target="_blank"&gt;透露&lt;/a&gt;，他的前女友曾用 ChatGPT 給他發送分手信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1776" src="https://static.oschina.net/uploads/space/2025/0908/192243_YVS9_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Hinton 作為人工智能領域的先驅，其在 1980 年代的工作為機器學習和人工神經網絡奠定了基礎，去年還獲得了諾貝爾物理學獎。&lt;/p&gt; 
&lt;p&gt;這位 AI 領域的權威人士卻未能預料到自己會被 AI 工具所「傷害」，他的前女友用 ChatGPT 告訴他他有多糟糕，讓他非常驚訝。「她用聊天機器人説出我的缺點，再傳給我。」不過辛頓自認沒有聊天機器人説的那麼糟，所以也沒有太難過。&lt;/p&gt; 
&lt;p&gt;事實上，讓像 ChatGPT 這樣的聊天機器人撰寫分手短信等似乎並不是什麼新鮮事，畢竟越來越多的人就一系列問題向 AI 諮詢。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370985</guid>
      <pubDate>Sat, 06 Sep 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Agent Client Protocol —— 代碼編輯器與 Agent 的通信協議</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Agent Client Protocol (ACP) 是用於連接代碼編輯器和 Agent 的協議，對代碼編輯器（用於查看和編輯源代碼的交互式程序）與編碼 Agent（使用生成式 AI 自主修改代碼的程序）之間的通信進行了標準化。&lt;/p&gt;

&lt;p&gt;這一協議讓開發者可以在編輯器中自由接入任意第三方智能體（Agent），無需依賴官方內置工具。其理念類似於語言服務器協議（LSP），通過解耦編輯器與 Agent 的交互方式，提供更靈活的擴展能力。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2f621ad18024ec580d997b820ea9139346e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;ACP 協議已經以 Apache 開源許可證發佈，任何開發者都可基於它集成自己的 AI Agent。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/agent-client-protocol</link>
      <guid isPermaLink="false">https://www.oschina.net/p/agent-client-protocol</guid>
      <pubDate>Sat, 06 Sep 2025 11:18:00 GMT</pubDate>
    </item>
    <item>
      <title>商湯日日新為 Claude API 用户提供「搬家」大禮包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 5 日，Anthropic 宣佈將禁止中資控股超過 50% 的公司使用 Claude 服務，並限制企業通過海外雲服務、第三方平台等方式間接使用。&lt;/p&gt; 
&lt;p&gt;即日起，商湯日日新大模型 SenseNova 將為 Claude 用户提供「搬家」服務，幫助客户繼續享受高質量的模型能力和服務。&lt;/p&gt; 
&lt;p&gt;相關模型詳情可訪問 platform.sensenova.cn 註冊。&lt;/p&gt; 
&lt;p&gt;商湯將為從 Claude 遷移到「日日新」的新用户贈送 5000 萬 Tokens 體驗包；同時為用户提供專屬搬家顧問，提供遷移系列培訓，讓新用户入駐新家舒適順利。相關模型詳情可訪問 platform.sensenova.cn 註冊。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/185753_qsE0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;商湯還提供最新交互模型——日日新 SenseNova V6.5 Omni API 的免費接入測試。用户也可在應用商店下載「商量 APP」免費體驗！&lt;/p&gt; 
&lt;p&gt;另外，針對用户對高質量的編程和 Agent 工具的需求，商湯小浣熊還將提供 300,000 元會員權益，所有用户均可掃描文末二維碼領取。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370978</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370978</guid>
      <pubDate>Sat, 06 Sep 2025 10:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達推出通用深度研究（UDR）系統</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達&lt;span&gt;最新&lt;/span&gt;發佈另外一個通用深度研究（UDR）系統，目前仍處於原型階段。該系統不僅可以與任何大語言模型 (LLM) 兼容，更為用户提供了高度定製的深度研究策略，徹底改變了以往研究智能體的工作方式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據英偉達的&lt;span&gt;最新&lt;/span&gt;論文，UDR 系統的核心優勢在於其極強的靈活性。過去，深度研究智能體往往依賴硬編碼的方式，用户只能使用固定的工具和策略進行研究，無法進行個性化調整。而 UDR 系統的推出，意味着用户可以隨心所欲地創建、編輯和優化自己的研究策略，甚至無需進行額外的模型訓練。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-7461c3da8a2ceb3b17c20d0c5f84c7d2fba.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;UDR 系統配備了一個用户友好的界面，方便用户輸入研究提示，隨時更新進度並查看最終報告。與傳統的對話式 LLM 不同，UDR 能夠在研究過程中持續向用户反饋進展，極大提升了研究效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得一提的是，UDR 系統在設計上將研究邏輯與語言模型解耦，使開發者能夠靈活選擇&lt;span&gt;最先&lt;/span&gt;進的 AI 模型，並將其與量身定製的研究方案結合使用。這種創新的組合方式，讓用户能夠創造出更強大、更具適應性的深度研究工具。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管 UDR 系統具有諸多優點，但仍存在一些需要改進的地方。系統的準確性依賴於底層 AI 模型生成代碼的質量，同時用户設計的研究策略必須合理可行，否則可能導致生成的報告質量低下。此外，當前版本在執行過程中缺乏用户幹預的能力，所有決策都需在研究開始前預設，限制了靈活性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人員已提出了進一步的改進方案，包括提供可修改的策略庫和更靈活的用户控制功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370976</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370976</guid>
      <pubDate>Sat, 06 Sep 2025 10:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>rainfrog - 命令行數據庫工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Rainfrog 的目標是提供一個輕量級的、基於終端的數據庫交互工具。該項目目前處於測試階段。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通過類似 vim 的鍵綁定和鼠標控制實現高效導航&lt;/li&gt;
&lt;li&gt;具有關鍵字高亮顯示、會話歷史記錄和收藏夾的查詢編輯器&lt;/li&gt;
&lt;li&gt;快速複製數據、過濾表以及在模式之間切換&lt;/li&gt;
&lt;li&gt;查看錶元數據和屬性的快捷方式&lt;/li&gt;
&lt;li&gt;跨平台（macOS、linux、windows、android 通過 termux）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt="" height="278" src="https://static.oschina.net/uploads/space/2025/0905/115915_L0YY_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/rainfrog</link>
      <guid isPermaLink="false">https://www.oschina.net/p/rainfrog</guid>
      <pubDate>Sat, 06 Sep 2025 10:11:00 GMT</pubDate>
    </item>
    <item>
      <title>騰訊混元翻譯模型 Hunyuan-MT-7B 登頂開源熱榜</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F19W9SEUxq7nuYQvVJz8faA" target="_blank"&gt;宣佈&lt;/a&gt;，混元翻譯模型 Hunyuan-MT-7B 登頂 Hugging Face 模型趨勢榜第一位。官方表示，該模型和混元世界模型家族最新成員 HunyunWorld-Voyager 一起，拿下前三中的兩席。&lt;/p&gt; 
&lt;p&gt;Hunyuan-MT-7B 於 9 月 1 日開源，其總參數量僅 7B，支持 33 個語種、5 種民漢語言/方言互譯，是一個能力全面的輕量級翻譯模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1506" src="https://static.oschina.net/uploads/space/2025/0908/175938_Dkn8_2720166.png" width="1216" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 8 月底結束的國際計算語言學協會（ACL）WMT2025 比賽中，Hunyuan-MT-7B（參賽名稱：Shy-hunyuan-MT）拿下了全部 31 個語種比賽中的 30 個第 1 名，處於絕對領先地位。&lt;/p&gt; 
&lt;p&gt;這 31 個語種除了中文、英語、日語等常見語種，也包含捷克語、馬拉地語、愛沙尼亞語、冰島語等小語種。&lt;/p&gt; 
&lt;p&gt;騰訊混元表示，在業界常用的翻譯能力測評數據集 Flores200 上，騰訊混元 Hunyuan-MT-7B 模型也有卓越的效果表現，明顯領先於同尺寸模型，與超大尺寸模型效果對比也不遜色。&lt;/p&gt; 
&lt;p&gt;針對翻譯場景，騰訊混元提出了一個完整的翻譯模型訓練範式，覆蓋從預訓練、到 CPT 再到監督調參、翻譯強化和集成強化全鏈條，使得模型的翻譯效果達到業界最優。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370969</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370969</guid>
      <pubDate>Sat, 06 Sep 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>上海發佈 AI 廣告扶持政策：最高 500 萬補貼大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;上海市近日發佈了《上海市支持人工智能賦能廣告業創新發展的若干措施》，旨在通過一系列具體的扶持政策，推動人工智能技術在廣告行業的深度應用和發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心扶持措施概覽&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新政策的核心在於「AI+數字廣告」生產要素的強化支持，具體措施包括:&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;大模型私有化部署補貼:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;對於採用第三方大模型進行私有化部署，並將其應用於廣告垂類領域的數字廣告企業，上海市將提供&lt;span&gt;最高&lt;/span&gt;可達核定合同額&lt;strong&gt;50%&lt;/strong&gt;，&lt;span&gt;最高&lt;/span&gt;&lt;strong&gt;500 萬元&lt;/strong&gt;的補貼。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;語料研發與應用補貼:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;鼓勵企業購買非關聯方的語料進行廣告垂類應用和「智能體」等研發。對於此類投入，企業可獲得&lt;span&gt;最高&lt;/span&gt;核定合同額&lt;strong&gt;30%&lt;/strong&gt;，&lt;span&gt;最高&lt;/span&gt;&lt;strong&gt;500 萬元&lt;/strong&gt;的補貼。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;算力租用支持:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;此外，有條件的區政府還將對租用算力的數字廣告企業提供支持，按實際投入的&lt;strong&gt;30%&lt;strong&gt;比例，給予單個主體年度&lt;span&gt;最高&lt;/span&gt;&lt;/strong&gt;2000 萬元&lt;/strong&gt;的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這一系列政策的出台，不僅體現了上海市搶佔「AI+廣告」產業制高點的決心，也旨在通過真金白銀的投入，降低企業在技術研發和部署上的成本，激發市場的創新活力。通過支持大模型私有化部署、語料研發和算力投入，上海正着力打造一個集技術、數據和算力於一體的完整 AI 廣告生態系統。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這些措施預計將吸引更多 AI 技術公司和傳統廣告企業在上海落地和發展，加速人工智能在廣告創意、內容生成、精準投放等環節的深度融合，從而推動整個廣告行業的數字化和智能化轉型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370959</guid>
      <pubDate>Sat, 06 Sep 2025 09:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>HuggingFace 開源 FinePDFs 與 FineVision 數據集</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face 開源了兩個大規模數據集 FinePDFs 和 FineVision，前者是目前最大的公開 PDF 語料庫，後者則專為視覺-語言模型訓練設計，旨在顯著提升開源模型的能力。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/datasets/HuggingFaceFW/finepdfs&lt;br&gt; https://huggingface.co/datasets/HuggingFaceM4/FineVision&lt;/p&gt; 
&lt;p&gt;FinePDFs 是目前最大的公開 PDF 語料庫，完全由 PDF 文件構建，包含約 3 萬億 tokens，覆蓋 4.75 億份文檔、1733 種語言，數據量 3.65TB。&lt;/p&gt; 
&lt;p&gt;語料來自 105 個 CommonCrawl 快照（2013 夏—2025 年 2 月），經 datatrove 庫去重、過濾與 PII 匿名化，採用 ODC-By 1.0 許可證。文檔平均長度接近 HTML 數據集的兩倍，長於 10 萬，字符的樣本顯著，可用於提升開源 LLM 的長上下文能力。&lt;/p&gt; 
&lt;p&gt;數據集已按語言-腳本對劃分，978 種語言超 100 萬 tokens，66 種語言超 10 億 tokens。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7cbae8687f50206187cf62b7ba1d65da7be.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;FineVision 面向視覺-語言模型訓練，整合 200 餘個來源，含 1730 萬張圖像、2430 萬樣本、8890 萬輪對話、95 億回答 tokens，支持 GUI 導航、指向、計數等新能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-945829421e543e2f159fb676f6f537bbadb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方稱在 10 項基準上帶來 20% 以上提升，可顯著增強開源 VLM 性能。數據已轉為 Parquet，總量約 4.48 TB，支持流式加載。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370951</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370951</guid>
      <pubDate>Sat, 06 Sep 2025 09:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技衝刺 IPO 將影響機器人產業格局</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;近日，國內機器人領域頭部企業宇樹科技宣佈，預計在 2025 年 10 月份至 12 月份期間向證券交易所提交 IPO 申請文件。這一消息在科技界和資本市場引發了廣泛關注。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作為人形機器人商業化落地的標杆企業，宇樹科技衝刺 IPO，有望成為影響機器人產業格局的關鍵節點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;首先，宇樹科技衝刺 IPO，有望向市場證明其技術商業化的可行性。公司 2024 年營收突破 10 億元，且連續 4 年實現盈利，其中，2024 年四足機器人貢獻了 65% 的收入，驗證了消費級場景的變現能力。若成功上市，通過完整披露研發數據、客户結構及成本模型，宇樹科技將進一步證明其技術護城河並非只是「實驗室成果」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;機器人企業不僅要注重技術研發，還要重視商業化落地。通過拓展應用場景，開發滿足市場需求的產品，實現技術的商業價值轉化，才能獲得穩定的收入，增強資本吸引力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其次，宇樹科技衝刺 IPO，將成為機器人產業鏈價值重估的催化劑，持續推動上游精密製造、中游系統集成、下游場景運營的全鏈條資本化，形成「技術—資本—產業」正循環，從而進一步優化產業鏈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，宇樹科技已經實現電機、減速器、控制器等核心部件全棧自研，國產化率超 90%。業內預計，宇樹科技或將募資重點投向高扭矩密度電機、輕量化材料等領域，以打破機器人規模化應用的成本瓶頸。上市後，宇樹科技勢必會通過融資擴大產能，相關供應鏈企業有望迎來訂單放量的黃金機遇，上下游協同的良性生態有望加速形成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;最後，宇樹科技選擇 IPO，本質上是資本效率與技術週期的精準匹配。2025 年 6 月份，宇樹科技完成 C 輪融資，投後估值已達 120 億元。該輪融資由中國移動旗下基金、騰訊、錦秋基金、阿里巴巴、螞蟻集團和吉利資本共同領投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技衝刺 IPO，是機器人產業加速資本化的縮影。相信在資本市場與機器人產業的「雙向奔赴」中，中國機器人企業將大幅提升競爭力。（證券日報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370948</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370948</guid>
      <pubDate>Sat, 06 Sep 2025 09:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>未來可能有高達 50% 的入門級工作將被 AI 取代</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;隨着人工智能（AI）的迅速發展，許多公司正在經歷前所未有的變革。曾經的職場成功故事，如 Hewlett Packard Enterprise 的首席執行官安東尼・內裏 (Antonio Neri) 從客服代理晉升為 CEO，正在逐漸被 AI 的興起所取代。分析師預測，未來可能有高達 50% 的入門級工作將被 AI 取代，這意味着許多剛剛步入職場的大學畢業生將面臨前所未有的挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在一項針對公共科技公司和成長中的風險投資企業的研究中，數據顯示，從 2019 年到 2024 年，具有不到一年工作經驗的求職者的就業機會下降了 50%。這一趨勢影響到了銷售、市場營銷、工程、招聘、運營、設計、財務和法律等各個核心職能。這種變化不僅影響了求職者，也讓企業面臨重新培養人才的壓力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管如此，行業專家指出，這種失去入門級崗位的情況可能促使組織內部的人才培養模式發生改變。隨着公司的結構變得更加扁平化，入門級崗位可能會轉變為更高要求的技能角色，要求求職者在進入職場前具備更多的能力。雖然對於即將畢業的學生來説，這意味着他們需要自行掌握這些技能，但也可能成為他們在競爭激烈的求職市場中脱穎而出的優勢。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;各大高校也在積極調整課程，旨在為學生提供與 AI 相關的技能培訓。雖然技術進步可能在短期內對就業率產生影響，但歷史上技術革新在長期內並未導致大規模的失業。專家認為，當前大學畢業生面臨的挑戰，可能在未來幾年內影響他們的職業發展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，儘管有許多未知數，許多經濟學家認為 AI 對勞動市場的長期影響仍然具有高度的不確定性，企業和社會將需要時間來適應這一變化。隨着技術的不斷進步和 AI 的普及，職場的未來可能會迎來全新的模式，而不僅僅是對現有職場階梯的替代。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370944</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370944</guid>
      <pubDate>Sat, 06 Sep 2025 08:47:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達收購 AI 編程初創公司 Solver</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Fbriefings%2Fnvidia-acquires-coding-startup-solver" target="_blank"&gt;據 The Information 報道&lt;/a&gt;，英偉達最近完成了對 AI 編程公司 Solver 的收購，進一步強化其在 AI 全棧生態的佈局。&lt;/p&gt; 
&lt;p&gt;Solver 成立於 2022 年，前身為 Laredo Labs，專注於 AI Coding Agent，其產品能通過自然語言指令管理完整代碼庫（如生成、測試、修復代碼），而非僅代碼補全。公司曾獲 800 萬美元融資，創始團隊包括前 Siri 和三星 Viv Labs 核心成員。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/161953_FkOn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Solver 的技術突破在於學習「超過一億個軟件項目的開發歷史」，理解代碼演進邏輯，可執行復雜任務（如重構模塊、修復系統性漏洞）。其 API 支持多語言（Python、JavaScript 等），並與主流開發工具無縫集成。&lt;/p&gt; 
&lt;p&gt;此次收購是英偉達 2024-2025 年系列收購的關鍵一環，旨在構建「硬件+軟件+雲服務」全棧生態。Solver 將整合至英偉達開發者工具鏈（如 CUDA、NVIDIA AI Enterprise），降低 AI 應用開發門檻，反向驅動 GPU 需求增長。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370938/nvidia-acquires-coding-startup-solver</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370938/nvidia-acquires-coding-startup-solver</guid>
      <pubDate>Sat, 06 Sep 2025 08:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 重組 ChatGPT 「模型行為團隊」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 內部郵件確認，原「模型行為團隊」（Model Behavior）整體併入「後訓練團隊」（Post Training），直接向該團隊負責人 Max Schwarzer 彙報。此舉旨在把 AI 個性、安全與用户體驗研究更深地嵌入核心模型開發流程，為 GPT-5 後續版本提供更快的迭代支持。&lt;/p&gt; 
&lt;p&gt;該團隊原有 14 人，長期負責減少諂媚、平衡政治偏見、定義聊天語氣等「人格化」工作。與此同時，模型行為團隊創始負責人 Joanne Jang 宣佈轉崗，啓動新項目 OAI Labs，探索超越傳統聊天窗口的人機協作界面。Jang 稱，新實驗室將「讓 AI 成為思考、創作、遊戲、學習和連接的工具」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/160802_ml0W_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/160900_9Cth_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;業內分析指出，此次重組反映出 OpenAI 對「模型性格」商業化影響的重視：用户反饋 GPT-5「過於冷淡」或「過度迎合」後，公司已臨時開放舊模型訪問權限，並加速個性調優。同期發表的 OpenAI 研究論文也警告，行業慣用的「應試型」評估可能鼓勵模型幻覺，未來需在評分機制中引入「不確定性誠實」指標。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370934</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370934</guid>
      <pubDate>Sat, 06 Sep 2025 08:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Tilde AI 發佈開源 TildeOpen LLM</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Latvian 語言技術公司 Tilde 發佈了 TildeOpen LLM，這是一個開源的基礎大語言模型（LLM），旨在支持歐洲語言，特別是那些較少被代表的國家和地區語言。這一舉措標誌着歐盟在語言公平和數字主權方面邁出了重要的一步。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="290" src="https://oscimg.oschina.net/oscnet/up-a3afc0c462ebfde5158ba6a9fda49510c9d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TildeOpen LLM 是一個擁有 300 億參數的稠密解碼器模型，採用了 CC-BY-4.0 的寬鬆許可證，能夠支持從拉脱維亞語、立陶宛語到烏克蘭語、土耳其語等多種語言。該模型的訓練是在歐洲的&lt;span&gt;超級&lt;/span&gt;計算機 LUMI（芬蘭）和 JUPITER 上進行的，使用了歐盟委員會的大型人工智能大獎挑戰賽所提供的 200 萬 GPU 小時的計算資源。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技術細節方面，TildeOpen LLM 通過受 EleutherAI 啓發的 GPT-NeoX 腳本進行訓練，共進行了 45 萬次更新，使用了約 2 萬億個令牌。其訓練過程包含三階段採樣：首先在語言間均勻分佈，其次是對高數據量語言的自然分佈進行增強，最後再進行均勻的掃查以確保平衡。模型的超參數包括 60 層、嵌入維度 6144、48 個注意力頭、8192-token 的上下文窗口，以及使用 SwiGLU 激活、RoPE 位置編碼和 RMSNorm 層規範化。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在語言公平和數據主權方面，傳統的主流模型往往側重於英語和其他主要語言，導致在處理波羅的海、斯拉夫及其他較小的歐洲語言時表現不佳，常常出現語法錯誤和奇怪的措辭。而 TildeOpen 通過引入 「公平的標記器」，使得不同語言的文本以相似方式進行表示，從而減少標記數量，提高較少代表語言的推理效率。此外，組織可以選擇在本地數據中心或符合歐盟要求的安全雲中自我託管，確保遵循 GDPR 及其他數據保護法規，從而解決了與美國或亞洲託管模型相關的主權問題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TildeOpen 作為基礎模型，預計會推出更多專門化版本，例如經過指令調優的翻譯模型，這將進一步增強其功能。拉脱維亞通過 Tilde 的努力，期望在全球科技領域佔據一席之地，同時致力於保護語言多樣性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370933</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370933</guid>
      <pubDate>Sat, 06 Sep 2025 08:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>合理選擇任務調度的路由策略，可以幫助降本 50%</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：黃曉萌（學仁）&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="225" src="https://oscimg.oschina.net/oscnet/up-95c58fbed31f7c7be0c1d4fb9dcd324f094.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;有許多的業務場景需要用到短週期的任務，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;訂單異步處理：每分鐘掃描超時未支付的訂單進行訂單處理。&lt;/li&gt; 
 &lt;li&gt;風險監控：每分鐘掃描 metrics 指標，發現異常進行報警。&lt;/li&gt; 
 &lt;li&gt;數據同步：每天晚上同步庫存、門店信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;任務調度系統負責管理這些短週期的任務，通過用户設置的調度時間，週期性的把任務分發給執行器執行。每次任務要分發給哪個執行器執行，就是由路由策略決定的。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfa179d2d832985259fd56c4cb3164f3350.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不同任務處理不同的業務邏輯，有些執行時間長，有些執行時間短，有些消耗資源多，有些消耗資源少。如果選擇的路由策略不合適，可能會導致集羣中執行器負載分配不平均，資源利用率上不去，成本上升，甚至產生穩定性故障。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;輪詢（Round Robin）&lt;/h2&gt; 
&lt;p&gt;輪詢（Round Robin）路由策略是一種簡單且常見的負載均衡方法，其核心原理是按照順序將請求或任務依次分發到後端節點上，從而確保任務的平均分佈，避免資源過度集中在某一節點上。具體實現方式通常是維護一個計數器，記錄當前分配的節點索引。分發請求時，該索引遞增並對節點總數取模，從而實現循環分配。在任務調度系統中，分為任務級別輪詢和應用級別輪詢。&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;任務級別輪詢&lt;/h3&gt; 
&lt;p&gt;代表產品是 XXLJOB &lt;strong&gt;[&lt;/strong&gt; &lt;strong&gt;1]&lt;/strong&gt; ，為每個任務都維護了一個計數器。比如有 ABC 三個執行器。每個任務調度的時候都會按照 A-&amp;gt;B-&amp;gt;C-&amp;gt;A 這個順序輪詢機器。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;如果所有任務的調度時間都一致（比如每小時執行一次），會導致所有任務每次執行都落在同一台後端節點上，負載嚴重不均衡。為瞭解決這個問題，XXL-JOB 初始化每個任務計數器的時候，做了隨機，可以大大降低該問題的概率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;pre style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;code&gt;&lt;span&gt;AtomicInteger count = routeCountEachJob.&lt;span style="color:#ca7d37"&gt;get&lt;/span&gt;(jobId);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&lt;span style="color:#ca7d37"&gt;if&lt;/span&gt;&amp;nbsp;(count ==&amp;nbsp;&lt;span style="color:#0e9ce5"&gt;null&lt;/span&gt;&amp;nbsp;|| count.&lt;span style="color:#ca7d37"&gt;get&lt;/span&gt;() &amp;gt;&amp;nbsp;&lt;span style="color:#0e9ce5"&gt;1000000&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;em&gt;// 初始化時主動 Random 一次，緩解首次壓力&lt;/em&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; count =&amp;nbsp;&lt;span style="color:#ca7d37"&gt;new&lt;/span&gt;&amp;nbsp;AtomicInteger(&lt;span style="color:#ca7d37"&gt;new&lt;/span&gt;&amp;nbsp;Random().nextInt(&lt;span style="color:#0e9ce5"&gt;100&lt;/span&gt;));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&amp;nbsp;&lt;span style="color:#ca7d37"&gt;else&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;em&gt;// count++&lt;/em&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; count.addAndGet(&lt;span style="color:#0e9ce5"&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果任務的調度頻率不一致，因為每個任務都按照自己計數器輪詢，也有可能在某個週期，大部分任務都調度到同一個執行器上，導致負載不均衡。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;應用級別輪詢&lt;/h3&gt; 
&lt;p&gt;整個應用下所有任務共享同一個計數器，每個任務調度的時候，都會讓計數器+1。該算法可以保證所有執行器接收到的任務次數是平均的。如果所有任務負載和執行時間差不多，是負載均衡的，但是如果有大任務和小任務並存，情況又不一樣了。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4d9dff721251ff1fbb2639b630c2867d23c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;有 ABC 三個執行器，job1~job6 一共 6 個任務需要依次調度，其中 job1 和 job4 是大任務。&lt;/li&gt; 
 &lt;li&gt;job1 調度到 A 節點，job2 調度到 B 節點，job3 調度到 C 節點，job4 調度到 A 節點，job5 調度到 B 節點，job6 調度到 C 節點。&lt;/li&gt; 
 &lt;li&gt;job1 和 job4 這 2 個大任務，每次都調度到 A 節點，導致 A 節點負載比其他節點高。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;階段總結&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果所有任務負載和執行時間差不多，建議選擇應用級別輪詢。&lt;/li&gt; 
 &lt;li&gt;如果有大任務和小任務存在，這兩種算法都有可能導致負載不均衡，建議給大任務配置任務級輪詢，防止每次都落到同一台節點上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;隨機&lt;/h2&gt; 
&lt;p&gt;隨機路由策略是一種簡單的負載均衡算法，它通過隨機選擇一個後端服務器來處理每個請求，來達到負載均衡的目的。在任務調度系統中，任務每次調度的時候，隨機選一個執行器執行。&lt;/p&gt; 
&lt;p&gt;隨機路由策略由於算法完全依賴隨機數生成器，負載均衡全憑運氣，如果拉長時間區間（比如看一整天的調度情況）看可能是負載均衡的，但是可能存在短時間負載不均的問題（某些服務器在一定時間段內被選中的概率較高）。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;最近最少使用（LFU）&lt;/h2&gt; 
&lt;p&gt;最近最少使用（LFU，Least Frequently Used）是一種基於訪問頻率的緩存淘汰算法，主要用於內存管理和緩存系統中。其實現機制是為每個數據項維護一個訪問計數器，數據被訪問時計數器加 1，當需要淘汰數據時，選擇計數器值最小的數據項。&lt;/p&gt; 
&lt;p&gt;在任務調度系統中，可以統計執行器的調度次數，優先選擇最近使用次數最少的執行器進行任務調度，從而達到負載均衡的目的。如果所有任務都配置成 LFU 路由策略，該算法最終使用效果，和輪詢算法是差不多的，算法還複雜，沒有太大必要。如果集羣中的任務配置了多種路由策略，不同執行器調度次數不一樣，出現了負載不均衡的情況，給新任務配置 LFU 算法，一定能調度到調度次數最少的執行器上，才能真正發揮它的作用。&lt;/p&gt; 
&lt;p&gt;開源 XXLJOB 具體實現上，使用的是任務級別的 LFU，最終使用效果和任務級別輪詢一致。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;最近最久未使用（LRU）&lt;/h2&gt; 
&lt;p&gt;最近最久未使用 (LRU,Least Recently Used) 是一種基於訪問時間的緩存淘汰算法，主要用於管理有限緩存空間內的內存數據，當緩存已滿時，依據數據最近使用時間，優先移除最近最久未使用的數據。&lt;/p&gt; 
&lt;p&gt;在任務調度系統中，可以統計執行器的調度時間，優先選擇最久未調度的執行器進行任務調度，從而達到負載均衡的目的。因為每次調度的時候，也會更新執行器調度次數，所以該算法最終使用效果，和 LFU 是差不多的。&lt;/p&gt; 
&lt;p&gt;開源 XXLJOB 具體實現上，使用的是任務級別的 LRU，最終使用效果和任務級別輪詢一致。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;一致性哈希&lt;/h2&gt; 
&lt;p&gt;有些業務場景，需要任務每次執行在固定的機器上，比如執行器上有緩存，可以較少下游數據加載、加快任務處理速度。最直接的想法就是使用哈希算法，通過任務 ID（JobId）和執行器數量取 mod，把任務調度到固定的機器上。但是如果某個執行器掛掉了，或者執行器擴容的時候，執行器數量發生了變更，會導致所有任務重新哈希到了不同的機器上，所有緩存全部失效，可能會導致後端流量一下子突增。&lt;/p&gt; 
&lt;p&gt;XXLJOB 提供了一致性哈希路由算法，可以保證執行器掛掉或者擴容的時候，大部分任務調度的執行器不變。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;一致性哈希算法將 2^32 劃分為一個邏輯環，其中每個執行器節點根據哈希值被映射到環上的某個位置。任務通過 JobId 做哈希也映射到環上，然後順時針找到最近的執行器，即為目標執行器。如下圖所示，job1 固定調度到執行器 A，job2 和 job3 固定調度到執行器 B，job4 固定調度到執行器 C：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0ad01a71277a9f227ced3b876fa4a2360dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;如果添加一個執行器 D，通過哈希值映射到了 job2 和 job3 中。如下圖所示，job2 會調度到執行器 D 上，其他任務調度的機器保持不變：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-19e2de7321e73d275cb09c27e427f7a4793.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;如果執行器 C 突然掛掉了，如下圖所示，job4 會調度到執行器 A 上，其他任務調度的機器保持不變：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-49f2dd8255ad7f43faeb56e5e0a37506e9f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果執行器節點不多，直接映射到哈希環上的時候，有可能無法平均分佈，導致任務分配不均。為瞭解決這個問題，可以引入虛擬節點（XXLJOB 引入了 100 個虛擬節點），將虛擬節點平均分佈在哈希環上，然後物理節點映射虛擬節點。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0af27b26f0bd8673df6d331804136865584.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，一共有 3 個執行器 ABC，每個執行器分配 4 個虛擬節點，保證所有虛擬節點平均分佈在哈希環上，這樣所有任務調度就基本上負載均衡了。&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;負載最低路由策略&lt;/h2&gt; 
&lt;p&gt;上面提到的路由策略都沒法解決一個問題，就是應用下同時存在大任務和小任務，導致執行器負載不均衡。那麼我們是否可以採集所有執行器的負載，每次調度的時候按照負載最低優先調度呢？確實有些調度系統是這樣做的，代表產品是 Kubernets &lt;strong&gt;[&lt;/strong&gt; &lt;strong&gt;2]&lt;/strong&gt; 。Kubernetes 使用 kube-scheduler 進行調度，本質上是把 Pod 調度到合適的 Node 上，默認策略就是調度到負載最低的 Node 上。在容器服務中，每個 Pod 都會預製佔用 cpu 和內存，kube-scheduler 每調度一個 Pod，就能實時更新所有 Node 的負載，該算法沒有問題。&lt;/p&gt; 
&lt;p&gt;但是在傳統的任務調度系統中（比如 XXLJOB），一般都是通過線程運行任務的，沒法提前知道每個任務會佔用多少資源。任務調度到執行器上，也不是馬上導致執行節點負載上升，通常會有滯後性。甚至有些邏輯複雜的任務，可能好幾分鐘後才會有大量的 IO 操作，導致該執行節點好幾分鐘後才能明顯負載上升。舉個例子，有 AB 兩個執行節點：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A 節點上當前有 1 個任務在運行，A 節點負載 20%，B 節點當前沒有任務運行，負載 0%。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-be10f131d25815e10c703a6b56b4c79afaf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;這個時候有 job2~job5 一共 4 個任務要調度，都選擇了當時負載最低的執行器 B。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4c2a38d0bbec16b75d051f38e62fe5263d3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;4 個任務都發送到執行器 B 後，過了一會，執行器 B 負載上升到 100%，執行器 A 還是 5%，導致負載不均衡。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;任務權重路由策略&lt;/h2&gt; 
&lt;p&gt;有沒有辦法可以像 kube-scheduler 一樣，調度的時候就預算每個執行節點的負載呢？因為定時任務都是週期性運行的，每次執行的代碼或者腳本是固定的，通過業務邏輯或者歷史執行時間，我們其實是知道哪些是大任務哪些是小任務的。每次任務調度的時候，我們只要知道當前各個執行器上運行了多少個大任務多少個小任務，就能把當前這個任務分發到最合適的執行器上。&lt;/p&gt; 
&lt;p&gt;MSE-XXLJOB &lt;strong&gt;[&lt;/strong&gt; &lt;strong&gt;3]&lt;/strong&gt; 設計並實現了任務權重路由策略，每個任務都可以用户自定義權重（int 值），交互流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0d9160df2b04280c0c7c1f1887c088ecc37.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Scheduler 調度器開始調度任務。&lt;/li&gt; 
 &lt;li&gt;RouteManger 負責路由策略，如果是任務權重路由策略，去 WorkerManger 裏尋找當前權重最小的執行器，並更新該執行器的權重（+當前任務的權重）。&lt;/li&gt; 
 &lt;li&gt;RouteManger 把任務分發給權重最小的執行器執行任務。&lt;/li&gt; 
 &lt;li&gt;執行器運行完任務，更新 WorkerManger，把該執行器的權重減去該任務的權重。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下面以一個詳細的例子來説明。當前有兩個執行器，有 ABCD 4 個任務需要調度，其中 A 是大任務，按照歷史經驗 cpu 會佔用 50%，BCD 是小任務，每個會佔用 cpu 20%。將 A 任務權重設置為 5，BCD 設置為 2。初始化執行器 1 和執行器 2 的權重都是 0。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A 任務調度到執行器 1，執行器 1 的權重變為 5，執行器 2 的權重還是 0。B 任務選擇任務權重最小的機器，調度到執行器 2，執行器 2 的權重變為 2。C 任務選擇任務權重最小的機器，調度到執行器 2，執行器 2 的權重變為 4。D 任務選擇任務權重最小的機器，調度到執行器 2，執行器 2 的權重變為 6。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-294a2873a5488022b9503489236d079c705.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;這個時候，又有個小任務 E 要調度，權重也是 2，選擇當前權重最小的機器 1，則機器 1 的權重變為了 7，如下圖&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0cb6bdad28fca8ad7ad85a7041fd24a8586.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;小任務 B 和 C 執行很快就跑完了，這個時候執行器 2 的權重減去 4，變為了 2，如下圖：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8fbdbf6a298620ffc183e8eb4853863b44.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;這個時候又來個大任務 F，權重是 5，選擇權重最小的機器 2，機器 2 的任務權重變為了 7，如下圖：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d431902415007920bbd5594f3d235dfe1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;可以看到該算法，將每個任務實際消耗的資源映射成任務權重，可以實時統計每個執行器的權重，提前規劃不同權重的任務分配到哪個執行器上去執行，達到全局最優解。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p&gt;在真實生產環境下，不同的任務處理不同的業務邏輯，如果選錯路由策略，可能會導致集羣中大部分執行節點負載不到 10%，但是個別節點負載會衝高到 100%，雖然平均負載不高，但是也無法減少規格，可能還需要增大規格防止出穩定性問題。但是如果選對了路由策略，集羣所有節點負載均衡，就可以減少節點規格，成本降低 50% 以上。下面以一個表格詳細介紹不同路由算法的場景：&lt;/p&gt; 
&lt;p&gt;&lt;img height="352" src="https://oscimg.oschina.net/oscnet/up-135f88cb4ca465c1c8dfa02b9b2f2522ea3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1] XXLJOB&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxuxueli%2Fxxl-job" target="_blank"&gt;https://github.com/xuxueli/xxl-job&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;[2] Kubernets&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.csdn.net%2Fjy02268879%2Farticle%2Fdetails%2F148855464" target="_blank"&gt;https://blog.csdn.net/jy02268879/article/details/148855464&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;[3] MSE-XXLJOB&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fschedulerx%2Fschedulerx-xxljob%2Fgetting-started%2Fcreate-and-deploy-a-xxljob-job-in-a-container-in-10-minutes" target="_blank"&gt;https://help.aliyun.com/zh/schedulerx/schedulerx-xxljob/getting-started/create-and-deploy-a-xxljob-job-in-a-container-in-10-minutes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18689928</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18689928</guid>
      <pubDate>Sat, 06 Sep 2025 07:55:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
