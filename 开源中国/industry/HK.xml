<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 19 Jun 2025 07:44:31 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>開源模型上下文協議 MCP 更新規範文檔，添加對結構化工具輸出的支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源模型上下文協議 MCP 昨天更新了規範文檔，主要變更如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;移除對 JSON-RPC 批處理的支持（PR #416）&lt;/li&gt; 
 &lt;li&gt;添加對結構化工具輸出的支持（PR #371）&lt;/li&gt; 
 &lt;li&gt;將 MCP 服務器歸類為 OAuth 資源服務器，添加受保護資源元數據以發現相應的授權服務器。（PR #338）&lt;/li&gt; 
 &lt;li&gt;要求 MCP 客户端按照 RFC 8707 中描述的方式實現資源指示器，以防止惡意服務器獲取訪問令牌。（PR #734）&lt;/li&gt; 
 &lt;li&gt;在授權規範中闡明安全注意事項和最佳實踐，並在新的安全最佳實踐頁面中説明。&lt;/li&gt; 
 &lt;li&gt;增加引導支持，使服務器能夠在交互過程中向用户請求更多信息。（PR #382）&lt;/li&gt; 
 &lt;li&gt;在工具調用結果中增加資源鏈接支持。（PR #603）&lt;/li&gt; 
 &lt;li&gt;在使用 HTTP 時，後續請求中需通過&amp;nbsp;&lt;code&gt;MCP-Protocol-Version&lt;/code&gt;&amp;nbsp;頭指定協商的協議版本。（PR #548）&lt;/li&gt; 
 &lt;li&gt;將生命週期操作中的 SHOULD 改為 MUST&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fspecification%2F2025-06-18%2Fchangelog" target="_blank"&gt;https://modelcontextprotocol.io/specification/2025-06-18/changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356195</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356195</guid>
      <pubDate>Thu, 19 Jun 2025 07:33:28 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源代碼編輯器 Zed 上線「調試器」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源代碼編輯器 Zed &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fdebugger" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出「調試器（Debugger）」功能，稱這是向 Zed 1.0 邁出的重要一步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;調試器特性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;快速&lt;/strong&gt; ：減少上下文切換時間，讓用户能更專注於調試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;熟悉&lt;/strong&gt; ：與 Zed 的設計語言保持一致，支持典型的調試流程，方便用户快速上手。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可配置&lt;/strong&gt; ：用户可自定義 UI、鍵綁定、調試配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-43c899b5d73c5470109aecf601bbff05ba7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Zed 開箱即支持調試多種流行編程語言，包括 Rust、C/C++、JavaScript、Go 和 Python。通過擴展系統，Zed 可以支持任何實現調試適配器協議（DAP）的調試適配器。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;技術架構&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   採用兩層架構，數據層與調試適配器直接通信，UI 層從數據層獲取數據進行界面渲染。
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   數據層負責維護會話狀態、緩存響應、使失效數據，UI 層按需請求數據，避免不必要的請求，便於後續實現協作調試。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;調試適配器集成&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   擴展了 Zed 的擴展 API 以支持調試器集成，通過定義自定義架構等方式，讓擴展作者能輕鬆將調試適配器集成到 Zed 中。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;內聯變量值實現&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   利用 Tree-sitter 查詢準確識別當前執行範圍內的變量，無需依賴 LSP 服務器與調試適配器的緊密集成，目前支持 Python、Rust、Go 等語言。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fdocs%2Fdebugger" target="_blank"&gt;https://zed.dev/docs/debugger&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356190/zed-debugger</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356190/zed-debugger</guid>
      <pubDate>Thu, 19 Jun 2025 06:59:28 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 Rust 瀏覽器引擎 Servo 支持 GIF</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Servo 是一款開源的瀏覽器引擎，最初由 Mozilla 開發。它使用 Rust 語言編寫，旨在提供高效、安全的網頁渲染能力，並且採用並行渲染技術，以提高網頁加載速度和性能。&lt;/p&gt; 
&lt;p&gt;近日，Servo 團隊介紹了最近的更新內容，其中一項重要新功能是&lt;strong&gt;支持顯示動態 GIF&lt;/strong&gt;，並且還可以通過 HTML "img"標籤加載 SVG 圖像。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/142856_yG2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 還在推進其 Trusted Types API、輸入類型 &amp;lt;input type=color&amp;gt; 支持、更好的佈局和 CSS 支持，以及支持各種其他 API 和功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f8cd0cc574887e5f2e0cc055fb9586cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 還在繼續努力提升圍繞 Servo 嵌入支持的開發者體驗，以 Servo 作為 Chromium 的 CEF 替代方案在應用程序中利用 Servo。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2025%2F06%2F18%2Fthis-month-in-servo%2F" target="_blank"&gt;https://servo.org/blog/2025/06/18/this-month-in-servo/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</guid>
      <pubDate>Sun, 11 May 2025 06:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美國科技巨頭推動聯邦立法，禁止各州單獨監管 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《金融時報》報道稱，近日美國多家大型科技公司正積極推動一項聯邦禁令，旨在禁止各州自行制定人工智能（AI）監管法規。此次立法倡議得到了亞馬遜、谷歌、微軟和 Meta 等公司的支持，目的是避免各州在 AI 監管方面各自為政，影響行業的整體發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士透露，這項禁令提案已經被納入眾議院版本的 「大而美」 預算法案中。參議院也計劃在近期推出自己的版本，並希望能夠在 7 月 4 日之前完成相關立法工作。前聯邦眾議員、現任 INCOMPAS 首席執行官 Chip Pickering 是這項提案的重要推動者，他表示，保持美國在技術領域的領導地位是確保國家競爭力的關鍵。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;INCOMPAS 組織於 2024 年成立了 「人工智能競爭中心」（AICC），專注於遊説國會與監管機構，以適應快速發展的 AI 行業。隨着 AI 監管討論的加劇，尤其是在歐盟出台新規後，亞馬遜和 Meta 也加入了該組織，試圖通過統一監管來增強競爭力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，此提案引發了廣泛的爭議。反對者認為，大型科技公司推動禁令的真正目的是為了鞏固自身在 AGI（通用人工智能）競爭中的壟斷地位。範德比爾特大學的政策加速中心 AI 與科技政策主任 Asad Ramzanali 表示，負責任的創新不應該懼怕法律的約束。同時，麻省理工學院的教授 Max Tegmark 也批評稱，這種行為是科技巨頭為了進一步集中財富和權力的擴張。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，支持禁令的人士認為，聯邦層面的統一監管將有助於避免各州的分歧，保持行業的創新能力，從而在全球 AI 競爭中處於有利地位。AI 安全倡導者如 Anthropic 聯合創始人 Dario Amodei 則警告稱，如果完全依賴企業自我監管，可能會帶來嚴重的社會風險。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356176</guid>
      <pubDate>Sun, 11 May 2025 06:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度垂搜數據管理系統彈性調度優化實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;百度垂直搜索系統將搜索核心能力賦能阿拉丁（百度搜索特型結果）、垂直領域搜索、應用內搜索等場景，支撐了數百個檢索場景、百億級內容數據的檢索。隨着接入業務數量和數據量不斷增長，系統在海量數據管理與調度上遭遇新的挑戰，通過垂搜數據管理系統彈性調度優化實踐來滿足業務增長需求。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 簡介&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;百度垂搜架構的召回引擎經過歷史架構演進確定了&lt;strong&gt;&lt;strong&gt;異構&lt;/strong&gt;&lt;/strong&gt;部署的架構模型，相較於同構部署在容量自動調整、數據按需存儲等方面更具效率與成本的優勢，同時在海量數據和海量檢索方面也實現了高可用和高性能。目前系統已承接 80+業務，全機房部署了數百個檢索服務，數千個索引庫，共計數百億文檔收錄。隨着接入新業務數量的增加，以及存量業務的深入迭代，我們遇到了更加複雜多樣的場景，進而對系統提出更高的要求。本文主要介紹我們的系統在海量數據管理與調度上面臨的問題， 以及各項優化工作落地後在系統擴展性、穩定性等方面取得的效果。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&amp;nbsp;當前數據管理架構存在的問題&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此前我們的系統設計了彈性伸縮機制應對流量和數據量的上漲，冷熱分離機制實現了資源按需部署。隨着接入業務的增加，系統逐漸暴露出一些新的問題，主要體現在以下幾點:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;元信息管理瓶頸。系統使用 ETCD 進行服務發現和心跳管理， 然而所有業務實例&lt;strong&gt;&lt;strong&gt;直連 ETCD&lt;/strong&gt;&lt;/strong&gt;存在嚴重讀寫放大問題， 導致 ETCD 負載超發出現&lt;strong&gt;&lt;strong&gt;單點瓶頸&lt;/strong&gt;&lt;/strong&gt;, 限制集羣規模進一步增長。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依靠人工評估資源。新業務的接入或者一些大事件運營保障依賴人工估算所需資源，&lt;strong&gt;&lt;strong&gt;不僅耗費人力，而且不夠準確&lt;/strong&gt;&lt;/strong&gt;，估算過高，服務長期處於低負載會造成資源浪費，估算過低，服務容易過載，進而導致穩定性問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據量增長瓶頸。 當前的架構可以在無需重新建庫的情況下原地擴分片，但是分片數只能倍數擴展，並且&lt;strong&gt;&lt;strong&gt;分片數量有限制&lt;/strong&gt;&lt;/strong&gt;，大庫場景容易觸發上限，進而導致數據量無法繼續增長。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;02 檢索系統與數據管理系統架構&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1&amp;nbsp;檢索系統架構概覽&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先簡單介紹下垂搜檢索系統的各模塊，如下圖所示:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6fa6c464ffb4e6ea05cb47989be85fcbaf.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;RANK。檢索精排模塊，負責 query 理解、請求構造、多隊列拆分、正排數據獲取、策略因子計算、算分排序、返回結果組裝等流程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS。檢索召回引擎，負責基礎召回/粗排，根據基礎相關性等權重因子進行數據的粗篩，支持基於 term 倒排拉鍊和 ANN 向量基礎召回。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BUILD。數據建庫模塊，負責數據處理、切詞、生成正排/倒排/向量/摘要等功能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;每個垂類 (業務) 擁有一套獨立的上述檢索系統服務，數據管理系統為每個業務的檢索系統提供&lt;strong&gt;&lt;strong&gt;實例調度、容量管理、服務發現、心跳管理、路由控制&lt;/strong&gt;&lt;/strong&gt;等能力，數據管理系統面向的核心管理對象是召回引擎 (BS)。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1&amp;nbsp;垂搜召回引擎&lt;/h3&gt; 
&lt;p&gt;如下圖所示，百度垂搜的召回引擎是一個&lt;strong&gt;&lt;strong&gt;流式、多分片、異構、有狀態的倒排+向量&lt;/strong&gt;&lt;/strong&gt;索引引擎:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6a59f451eae4330c4d002228c9ca5d20b51.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;流式。業務經過離線建庫環節產出建庫包並生效到 Kafka 中，召回引擎再從 Kafka 消費，數據從建庫到檢索可實現&lt;strong&gt;&lt;strong&gt;秒級生效&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多分片。業務數據量超過單機存儲上限，會被拆分成多個分片 (slice)，每個分片由 PaaS 層面實例承載，並對應 Kafka 的一段 partition 區間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;異構。單個業務的若干個資源號 (resource) 之間支持獨佔或者混部，一般根據服務負載設置不同副本數，根據數據量設置不同分片數。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;有狀態。每個實例承載一個或多個分片數據，週期性彙報心跳，消費分片由中控服務統一調度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;名詞解釋:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;resource(資源號): 一類或者一個場景的數據集合，即一個&lt;strong&gt;&lt;strong&gt;索引庫&lt;/strong&gt;&lt;/strong&gt;，一個業務通常包含多個資源號 (如圖中 mobile_game，pc_game， game_video 等)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slice(分片):數據調度基本單位，一個 resource 根據數據量可能會拆分成多個 slice(mobile_game 有三個 slice, pc_game 和 game_video1 個)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slot:數據劃分的基本單位，一個 slice 下有若干個 slot， 與 Kafka 的 partition 一一對應，在業務接入時根據數據量級確定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;pod:PaaS 層面實際的物理存儲容器，一個 pod 會承載一個或多個 slice，由中控服務統一調度。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&amp;nbsp;動態化數據管理系統&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;動態化數據管理系統負責召回引擎的每個實例從建庫到檢索，從部署到下線的全生命週期管理。經過&lt;strong&gt;&lt;strong&gt;服務重構、架構升級、新功能建設&lt;/strong&gt;&lt;/strong&gt;等方面的優化工作，形成了包括中控服務，心跳服務 (HeartbeatService), 名字服務 (NamingService), 存儲 ETCD 等模塊的現有系統架構:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-da1b5525954986be5194f44d536e0d8d45b.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1&amp;nbsp;中控服務&lt;/h3&gt; 
&lt;p&gt;整個動態化數據管理系統的核心模塊，負責各類調度任務的發起、控制等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;資源號接入/下線。新增資源號 (索引庫)，為每個資源號根據副本數、資源號之間部署關係等調度實例；下線資源號， 對應資源號的數據發起清理以及實例回收。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;副本保活。每個資源號實際副本數可能由於擴縮副本或 PaaS 層面遷移，導致與目標副本數不一致，中控服務負責定期輪訓所有資源號 (分片)，維持副本數與目標一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;容量管理。自動擴縮容服務/人工基於負載調整資源號的副本數，並通過副本保活生效，基於數據量調整資源號分片數，通過任務控制器生效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可用度控制。上線重啓需要保證分片維度的可用度，變更由 PaaS 發起，每個實例重啓前需要請求中控服務的探針，中控服務根據當前分片可用度決定實例是否可以重啓。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2&amp;nbsp;名字服務 NamingService&lt;/h3&gt; 
&lt;p&gt;提供服務發現，實例屏蔽，建庫路由控制等能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;服務發現。週期性加載並更新全量業務的資源號檢索路由拓撲信息，對每個分片過濾心跳丟失、未消費完成、重啓中等暫不可用實例。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實例屏蔽。支持異常實例的分片維度/App 維度屏蔽，線上快速止損，並保留現場便於後續問題追查。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建庫路由控制。提供離線建庫側全量業務資源號與 Kafka partition 映射關係查詢，資源號倒排索引雙寫控制。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.3&amp;nbsp;心跳服務 HeartbeatService&lt;/h3&gt; 
&lt;p&gt;負責召回引擎 (BS) 實例、分片心跳信息收集並持久化，實例消費區間信息傳遞等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;心跳管理。收集召回引擎實例上報的心跳信息，包括實例自身心跳以及消費分片信息， 並將心跳信息聚合後寫入 ETCD。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實例調度信息傳遞。獲取由中控調度下發的最新消費分片信息，寫入心跳請求 response，實例感知到消費分片發生變化後，清理舊分片數據，並重新消費新分片數據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.4&amp;nbsp;存儲 ETCD&lt;/h3&gt; 
&lt;p&gt;動態化數據管理系統各類元信息持久化存儲:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;實例心跳信息。包括版本號，實例唯一標識，上報時間戳，消費分片等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分片路由拓撲信息。分片下全量副本狀態信息，包括 endpoint，snapshot 版本，上報時間戳，消費狀態等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;業務資源號拓撲信息、建庫路由信息。單業務視角下全量資源號信息，包括版本號，分片數，副本數，對應 Kafka partition 區間，rpc 參數配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;03 彈性調度機制優化實踐&lt;/h1&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1&amp;nbsp;服務發現、心跳管理模塊重構&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.1&amp;nbsp;原有架構&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f12910e29c40a1a821609e09c774e7296d.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到在原有架構，業務 RANK 和 BS 實例都是直連 ETCD，隨着業務接入數量的增加逐漸暴露出一些問題:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;讀流量放大。同業務的不同 RANK 實例會各自訪問 ETCD 獲取相同的路由拓撲，導致讀流量放大，對於 RANK 實例數多的業務放大現象愈發明顯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;寫流量放大。每個分片含有多個副本，在進行更新時，一輪週期內同一個分片會被寫入多次，導致寫流量放大，對於副本數多的分片寫競爭愈發激烈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;升級改造困難。路由篩選策略、心跳上報策略均內嵌在 sched-lib 中, 進行升級需要給每個業務 RANK/BS 上線，人力成本巨大。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為瞭解決上述問題，我們對心跳管理和服務發現模塊進行了微服務拆分，新增心跳服務 (以下簡稱 HS) 和名字服務 (以下簡稱 NS) 避免了業務實例直連 ETCD，同時引入了 Prometheus，對心跳上報狀態和路由獲取狀態等信息進行監控和可視化展示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bb9efb9826cf2b2ebe1bae522ce0df14546.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.2&amp;nbsp;NS(NamingService) 設計&lt;/h3&gt; 
&lt;p&gt;我們對 NS 的定位是作為 ETCD 的 cache，採用 Read-Through 的模式，對全量業務的 RANK 提供拓撲信息查詢，RANK 不再直接訪問 ETCD:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;NS 本身設計為一個&lt;strong&gt;&lt;strong&gt;無狀態服務&lt;/strong&gt;&lt;/strong&gt;， RANK 可以訪問任意一台 NS 獲取拓撲，NS 實例之間拓撲路由&lt;strong&gt;&lt;strong&gt;保證最終一致性&lt;/strong&gt;&lt;/strong&gt;，NS 在拓撲變更時返回拓撲信息+MD5(拓撲)+更新時間戳，未變更時僅返回 MD5 和時間戳， RANK 基於 MD5 和時間戳自行判斷是否需要更新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;拓撲更新策略下沉到 NS 中，RANK 獲取到的拓撲即為直接可用拓撲，針對不同業務提供不同的控制策略並且後續升級改造只需上線 NS，成本大幅降低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;單機房 3 台 NS 實例即可支撐全部業務拓撲查詢，重構前後 ETCD 讀流量比例為 M:3，M 為平均每個業務 RANK 實例數，假設 N 取 30，則讀流量下降 90%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-93ea29c3774379e1a2cabf37f1ed095a248.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.3&amp;nbsp;HS(HeartbeatService) 設計&lt;/h3&gt; 
&lt;p&gt;HS 負責收集 BS 實例本身的心跳以及實例消費的分片的心跳，週期性&lt;strong&gt;&lt;strong&gt;聚合寫入&lt;/strong&gt;&lt;/strong&gt;ETCD，並且向 BS 實例返回其最新的消費分片信息:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;HS 採用無主節點設計，也支持任意水平擴展。同一個業務的不同 BS 實例通過&lt;strong&gt;&lt;strong&gt;一致性 hash&lt;/strong&gt;&lt;/strong&gt;方式請求同一台 HS 實例, 便於 HS 進行分片維度的信息聚合，這樣在大部分時間，每個分片無論有多少個副本一個週期內只會被寫入一次，實例本身的心跳採用批量更新形式，寫競爭大幅降低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 在上報心跳的同時會從 HS 的 response 中獲取自身消費的最新分片信息，如果分片信息變化，則清理老分片數據，消費新分片數據，後續只上報新分片狀態信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;單機房 3 台 NS 實例即可支撐全部業務心跳更新，重構前後 ETCD 寫流量比例為 N:1，N 為平均每個分片副本數，假設 N 取 5，則寫流量下降 80%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f141ad59566f2bbe45c04a1a0dac2046805.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_17"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;自動擴縮容&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1&amp;nbsp;當前現狀&lt;/h3&gt; 
&lt;p&gt;BS 是一個&lt;strong&gt;&lt;strong&gt;多分片、異構&lt;/strong&gt;&lt;/strong&gt;服務，即每個 App 內通常部署了多個資源號，各業務 App 在 PasS 層面隔離部署，在資源利用率、擴縮容管理等方面我們遇到以下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;整體資源利用率低。全機房擁有上百個 BS 業務 App、上千個資源號，PaaS 層面的整體平均峯值 CPU 利用率低於平均水平，峯值 CPU 超過 70% 的資源號佔比不足 20%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依賴人工進行資源號副本數調整。一般上線前通過人工壓測評估放量後所需的資源然後進行申請，有時候通過壓測難以估算真實的資源，並且後續業務迭代或者流量變化也會引起資源使用的變化，如果負載超發，服務穩定性難以保障，如果負載太過空閒，也會造成資源浪費。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無法直接接入 PaaS 層面自動擴縮容能力。一方面 PaaS 無法感知每個 App 內資源號維度負載信息，另一方面每個實例承載分片信息只能由中控服務調度，因此無法直接服用 PaaS 層面自動擴縮容能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-05f53f5b84434e08c78529d148cd54a6dcb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2&amp;nbsp;自動擴縮容實現&lt;/h3&gt; 
&lt;p&gt;為了實現容量自適應調整，我們開發了一個自動擴縮容服務，對全量資源號進行容量管理。自動擴縮容服務週期性計算資源號維度負載，根據負載情況，觸發中控服務進行資源號副本數調整，或者 PaaS 層面實例數調整。對於擴容，優先調度存量資源池中實例，如果存量實例不足則觸發 PaaS 擴容；對於縮容，先將空閒副本數回收至空閒資源池，再觸發 PaaS 縮容。對於自動擴縮容服務的設計我們主要考慮了以下幾點:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-53d9ad28a3b34ec0ecb4706a0bc8f9316eb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;負載指標選取&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;垂搜系統大部分業務 BS 為純內存版本，且幾乎沒有下游網絡請求，屬於典型的計算密集型業務， 因此我們選擇 CPU 作為負載計算參考指標，另外資源號混部場景進一步結合 QPS 和 Latency 進行判斷。此前我們已經實現了基於 Prometheus 採集實分片維度 CPU、MEM、QPS、Latency、建庫數據量等指標全量業務覆蓋，因此可以低成本的獲取到全量&lt;strong&gt;&lt;strong&gt;資源號維度&lt;/strong&gt;&lt;/strong&gt;的負載數據。&lt;/p&gt; 
&lt;span id="OSC_h4_21"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;負載狀態流轉&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;每個資源號從擴容到縮容，共定義如下 7 種狀態：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;enum LoadStatus { LOAD_STATUS_LOAD_OK = 0; //正常負載 LOAD_STATUS_OVERLOAD = 1; //超負載 LOAD_STATUS_IDLELOAD = 2; //低負載 LOAD_STATUS_BS_ADD_REPLICA = 3; //bs 擴副本中 LOAD_STATUS_BS_REMOVE_REPLICA = 4; // bs 縮副本中 LOAD_STATUS_TRIGGER_PAAS_EXPENSION = 5; // PaaS 擴容中 LOAD_STATUS_TRIGGER_PAAS_SHRINK = 6; // PaaS 縮容中 }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;每個資源號根據負載情況在上述狀態之間流轉:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8fa2f7581ed63466a8f24640ad7258bba52.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_22"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;擴縮容執行流程&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;擴副本&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;優先調度 App 內空閒實例，不足則觸發 PaaS 層面實例數擴容，循環執行直到負載恢復正常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-edfbd8b326a5709833d414a5fb013f357ed.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;縮容&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;先將資源號多餘副本釋放為空閒實例，再觸發 PaaS 層面縮容，循環執行直到資源號負載以及空閒實例數回到正常水平。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-504ce96574f2dc384b323509ab32bd78022.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3&amp;nbsp;&lt;strong&gt;資源號擴分片進階&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;每個資源號隨着數據量級不斷增長，分片數也需要動態擴展，否則會出現分片內存超發的情況。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.1&amp;nbsp;&lt;strong&gt;當前擴分片方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;每個資源號按 resource-&amp;gt;slice-&amp;gt;slot 的層級劃分，slot 是數據劃分最小單位與 kafka partion 一一對應，在業務接入時每個資源號 slot(partion) 的數量已經確定。擴層時，資源號的 slot 數量不變，&lt;strong&gt;&lt;strong&gt;分片數變成原來 2 倍， 每個分片的 slot 數則為原來的 1/2&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8db852d84d0b6a8d63c9bac9fed576d9490.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;原有的擴分片方案可以在無需重新建庫的情況下實現業務無感的原地分片擴縮操作，然而依舊存在兩個問題:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;分片數按指數增長，當分片數超過一定數值，將帶來不容忽視的資源成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果初始分配 slot 數太少，當 slice:slot=1:1 時，無法再擴層，數據增長出現瓶頸。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.2&amp;nbsp;&lt;strong&gt;進階擴展方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;對於分片無法繼續擴展但是依舊需要繼續建庫的情況，先前的方案只能是重建一個新的資源號，需要業務、架構共同介入，歷史上我們使用原方案遷移一個資源號，前後&lt;strong&gt;&lt;strong&gt;投入近 3 周時間&lt;/strong&gt;&lt;/strong&gt;，耗費成本巨大，因此我們需要一個成本更低的方案。通過分析，當前分片的擴展瓶頸主要有以下三個限制條件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;每個資源號的 slots 是一段連續的區間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 的 slot 與 Kafka 的 partition 一一對應。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始分配 slot 數太少，且後續不支持調整。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;只需要打破其中任意一個條件，則可以消除瓶頸。綜合考慮改造成本、擴展靈活性、實現難度等因素，我們選擇從條件三入手，在新的 partition 區間重建分片，分片數和 slot 數根據數據量設置，將舊分片的數據全量複製到新的分片上，再將新分片替換舊分片，如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1534a9d4b6b75072160e0a0470563a1c8c8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_26"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;整體實現&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;對於一個流式建庫系統，業務可能時刻都在進行數據建庫，我們希望做到遷移過程中業務依舊可以持續建庫，並且保證數據不丟失、時序不錯亂。我們的方案是將數據分為存量數據 (老分片中的全量數據) 和增量數據 (實時寫入的新數據)，對於增量數據可以通過雙寫機制，同時寫入新舊分片，存量數據則通過構建 snapshot 的方法遷移至新分片，新分片數據 ready 後，再由服務發現層將檢索流量切換至新分片，整體流程如下:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;離線側開啓雙寫，保證增量倒排索引數據同時寫入新舊分片，正排和摘要部分數據無需變化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基於舊分片構建新分片 snapshot, 並記錄構建時間點。將該時間點前舊分片所有數據進行 resharding 構建新分片 snapshot。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新分片的 BS 實例加載構建好的 snapshot，然後每個 partition 的消費 offset&lt;strong&gt;&lt;strong&gt;回退到 snapshot 構建時間點開始重新消費&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;服務發現層將資源號到 slot 區間映射切換到新分片上，檢索流量從老分片遷移至新分片。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;將舊分片 BS 實例回收，並關閉雙寫。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2cc22fbbf1492e639ef2bf5cbd76b4f8c3a.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_27"&gt;&lt;/span&gt; 
&lt;h1&gt;04 總結與展望&lt;/h1&gt; 
&lt;span id="OSC_h2_28"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1&amp;nbsp;&lt;strong&gt;總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本文介紹了百度垂搜檢索數據管理架構在彈性機制建設上的一系列優化工作，並且在擴展性、穩定性、以及成本效率等方面均取得了預期成果:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;擴展性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 負載下降一個量級，單機房 BS、RANK 集羣規模提升兩個量級， 單分片副本數上限提升至 5000+。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;分片擴展數量不再受限，解決了部分存量業務無法擴展分片導致的內存超發問題，並支持搜索創新業務數據量從百萬級逐步增加至數十億量級。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;穩定性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;存量調度問題被修復，新增多種路由調度策略以應對不同場景，分片可用度不足幹預時間從小時級縮短至分鐘級。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 負載不再超發，慢查詢基本消失，穩定性風險基本消除，心跳上報、拓撲獲取狀態建立監控，異常情況及時感知。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成本效率&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;全機房 BS 接入自動擴縮容，實現容量自適應調整，整體峯值 CPU 利用率提升了 15%+，同時相比之前減少了 80% 人工介入容量調整的情況出現。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;部分業務通過分片合併，最終使用存儲資源為下降至原來的 20%，並且檢索 97 分位耗時降低了 20ms，業務側效果與先前打平。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_29"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2&amp;nbsp;&lt;strong&gt;展望&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;目前索引庫的自動擴縮容機制實現了副本數隨負載 (CPU) 的自動調整，後續將實現分片數隨數據量的自動調整。另外，在大庫場景將持續建設流批一體機制，以追求用更低的存儲成本實現更高的檢索性能。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18627327</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18627327</guid>
      <pubDate>Sun, 11 May 2025 03:11:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Sam Altman 透露將在今年夏季發佈 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 發佈了其聯合創始人兼首席執行官 Sam Altman 的 40 分鐘深度專訪。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/105636_pUBl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1935357512011890815" target="_blank"&gt;透露&lt;/a&gt;&lt;/u&gt;，備受矚目的 GPT-5 預計將於今年夏天推出，不過具體發佈日期尚未確定。&lt;/p&gt; 
&lt;p&gt;據報道，GPT-5 性能將遠超 GPT-4，測試者表示其在多方面有顯著進步。據悉，這款新模型將整合 OpenAI 的核心技術，融合 GPT-4o 自然語言處理的靈活性與 o3 在代碼及科學推理方面的優勢，打造更強大的統一系統。&lt;/p&gt; 
&lt;p&gt;Altman 暗示，GPT-5 或許不僅是性能上的升級，更可能是 OpenAI 邁向統一、類似代理模型的重要一步，使其向人工通用智能（AGI）目標更進一步。&lt;/p&gt; 
&lt;p&gt;此外，據 AI 工程師 Tibor Blaho 和投資者「Chris（chatgpt21）」消息透露，OpenAI 或將在 7 月發佈一個大規模模型，而該模型有望為 GPT-5。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/354761" target="news"&gt;OpenAI 推遲開源模型的發佈時間&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356142</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356142</guid>
      <pubDate>Sun, 11 May 2025 02:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 終止與 Scale AI 合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 發言人當地時間週三向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-18%2Fopenai-is-phasing-out-its-work-with-scale-ai-after-meta-deal" target="_blank"&gt;彭博社&lt;/a&gt;透露，在 Meta 與 Scale AI 達成交易後，OpenAI 將逐步停止與 Scale AI 的合作，並切斷與該數據供應商的聯繫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 表示，早在 Meta 上週宣佈向這家初創公司投資數十億美元並任命 Alexandr Wang 擔任首席執行官之前，該公司就已開始逐步結束與 Scale AI 的合作。OpenAI 一直在尋找其他供應商來獲取更專業的數據，以開發日益先進的 AI 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="336" src="https://oscimg.oschina.net/oscnet/up-77faf9c892257b37289b5ccb5a6d4304d54.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 斷絕關係的決定引發了人們對 Scale AI 核心數據標籤業務的質疑。上週，路透社報道稱，谷歌也在討論放棄 Scale AI 作為數據提供商的計劃。隨着 Meta 與 Scale AI 達成合作，Scale AI 的一些競爭對手錶示，他們收到了大量尋求「中立」合作伙伴的 AI 模型供應商的興趣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在週三發佈的一篇博客文章中，Scale AI 的總法律顧問試圖駁斥 Meta 將在此次交易後獲得優待的説法。Scale AI 的高管表示，公司不會與 Meta 分享其他客户的機密信息，並且新任首席執行官 Wang 不會直接參與公司的日常運營。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在週三發佈的另一篇博客文章中，Scale AI 的臨時首席執行官 Jason Droege 則表示，公司將「加倍投入」其應用程序業務，其中包括為政府和企業構建定製的 AI 應用程序。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</guid>
      <pubDate>Sun, 11 May 2025 02:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Midjourney 發佈首個 AI 視頻生成模型 V1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 初創公司 Midjourney &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1935377193733079452" target="_blank"&gt;宣佈&lt;/a&gt;推出其備受期待的首款 AI 視頻生成模型 V1，支持圖像到視頻的生成，並可實現從文本直接生成視頻。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1216" src="https://static.oschina.net/uploads/space/2025/0619/102551_SwUy_2720166.png" width="1286" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;V1 目前僅通過 Discord 平台的網頁端提供服務，基礎訂閲費為每月 10 美元。&lt;/p&gt; 
&lt;p&gt;根據 Midjourney 的官方介紹，V1 基於此前的圖像模型生態進行打造。&lt;/p&gt; 
&lt;p&gt;Midjourney V1 操作分為自動和手動兩種模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自動模式下，平台會根據用户生成的圖片，自動創建「動作提示詞」並讓畫面運動起來；&lt;/li&gt; 
 &lt;li&gt;手動模式則是由用户提供提示詞。同時，Midjourney V1 也分為「低動態」和「高動態」兩種運動模式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;V1 的發佈讓 Midjourney 加入與 OpenAI 的 Sora、Runway 的 Gen 4 等 AI 視頻模型的競爭。其目標不止於為好萊塢或廣告業生成素材，公司 CEO David Holz 稱這是邁向 「實時開放世界模擬」 AI 模型的一步，後續還計劃開發 3D 渲染和實時 AI 模型。 &amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 考慮赴港 IPO？知情人士：屬實，仍處於初步籌備階段</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息稱，AI 獨角獸稀宇科技 (MiniMax) 正考慮在香港進行首次公開募股（IPO）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對此，有接近 MiniMax 的知情人士向澎湃新聞記者表示，MiniMax 內部確實有類似想法，但目前仍處於初步籌備階段。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-1c8fdc630a51d77c2dbbdb3ff2131f20e68.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官網介紹顯示，MiniMax 是全球領先的通用人工智能科技公司。自 2022 年初成立以來，以「與所有人共創智能」為使命，致力於推動人工智能科技前沿發展，實現通用人工智能 (AGI）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，MiniMax 已自主研發了一系列多模態通用大模型，包括 MiniMax M1、Hailuo-02、Speech-02 和 Music-01，具備超長上下文處理能力，能夠理解、生成並整合包括文本、音頻、圖像、視頻和音樂在內的多種模態。並基於這些自研模型推出一系列 AI 原生產品，包括 MiniMax、海螺 AI、MiniMax Audio、星野等，以及面向企業和開發者的開放平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 3 月，MiniMax 獲 6 億美元 A 輪融資，投後估值 25 億美元，由阿里巴巴領投，此前融資的投資方也包括騰訊等。據媒體報道稱，MiniMax 的實際估值目前已經超過 2024 年所報道過的「25 億美元」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356108</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>融雲 AI 機器人上線，獨家直連 AI 平台，加速落地創新探索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 技術的爆發為各行各業帶來了前所未有的機遇，各類創新應用如雨後春筍般湧現——從圖像生成、視頻創作，到智能搜索引擎、代碼助手，AI 正在重塑人們的工作與生活方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;而在這一波浪潮中，ChatBot 類產品及其衍生形態——如虛擬角色、智能客服和 AI 助理——作為 AI 普及的「OG」，始終佔據着核心地位。無論是全球科技巨頭的佈局，還是創業團隊的創新嘗試，這一領域依然活力十足，不斷有優秀的新產品嶄露頭角。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;深度整合 IM 對話與 AI 能力，融雲 AI 機器人正式上線。&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;獨立的機器人用户類型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，擁有&lt;/span&gt;&lt;strong&gt;&lt;span&gt;詳細的事件回調能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，&lt;strong&gt;獨家直連 AI 平台&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，大幅降低開發者落地 AI 社交、智能回覆等業務的成本，給開發者的創新探索加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;無論是以全新產品角逐市場，還是在現有產品中增加附加玩法。融雲 AI 機器人都可以&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效縮短業務上線週期，助力開發者快速探索充滿潛力的 AI 賽道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;無論是以全新產品角逐市場，還是在現有產品中增加附加玩法。融雲 AI 機器人都可以&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效縮短業務上線週期，助力開發者快速探索充滿潛力的 AI 賽道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;場景豐富，響應穩定&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融雲 AI 機器人支持基於指定機器人的詳細事件回調，方便開發者精準掌握用户與機器人的互動，如單聊消息、羣聊@指令等，並基於不同事件進行定製化處理，靈活響應各類業務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;無論是自動回覆、任務觸發，還是羣聊助手，都可以藉助融雲 AI 機器人輕鬆實現更智能、更豐富的交互，&lt;/span&gt;&lt;span&gt;&lt;span&gt;提升產品的用户體驗及業務運營效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;以單聊和羣聊兩種主要對話場景來看：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在單聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通過與機器人對話，可觸發多輪智能對話、內容生成等功能，支持流式或非流式輸出，適用於&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 陪伴、角色扮演&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等社交場景&lt;/span&gt;&lt;span&gt;&lt;span&gt;及&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 知識問答、智能客服&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等商務社交場景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="636" src="https://oscimg.oschina.net/oscnet/up-faa3c43ddca6e7fdc989dafeddb8f0d1286.png" width="585" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;除了穩定高效的多輪對話支持外，還可以實現智能任務執行功能，響應用户發起的智能操作請求，如「生成北京出行計劃」、&lt;span&gt;「寫一封郵件」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;等；或&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;查詢個人事務，如「我今天還有哪些未完成的任務」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在羣聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通過 @ 機器人，觸發與 AI 機器人的溝通或智能業務處理流程，如：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;FAQ 問答：解析用户意圖並自動回覆；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;工單創建：識別需求並提交至工單系統；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;日程提醒：識別時間表達並添加到日曆服務。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;快速上線，降本增效&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;提供獨立的機器人類型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;融雲 IM 提供獨立的機器人服務，自帶區別於真實用户類型的業務邏輯，大幅降低開發者在 AI 對話類業務實現時針對機器人的特殊處理邏輯，從底層能力上滿足開發者靈活創新的 AI 對話需求，極具拓展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;獨家直連&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;&amp;nbsp;AI 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;融雲 AI 機器人業內獨家實現了與第三方 AI 平台的對接，開發者無需進行繁瑣的中間處理，即可快速接入 AI Agent 創建調試及大模型推理服務，顯著降低開發難度，為開發者的 AI 社交、智能客服等業務落地打開了一個「綠色極速通道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;此前，開發者若想借助 AI 平台賦能自身的 AI 對話類業務，需要自行實現中間的需求中轉和消息流轉，鏈路長、問題多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通過融雲 AI 機器人，開發者可在簡單調用接口後實現對 AI 平台能力的關聯，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;鏈路穩定、響應高效&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，並可以在融雲&lt;/span&gt;&lt;strong&gt;&lt;span&gt;流式消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等底層能力和&lt;/span&gt;&lt;strong&gt;&lt;span&gt;內容審核&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等周邊服務的配套支持下實現靈活的業務需求。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;接入便捷，靈活搭建&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融雲 AI 機器人支持 Webhook 回調、Dify 平台對接，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方便開發者根據自身的業務情況選擇對接方式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;設置 Webhook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可通過 Webhook 回調，將用户向機器人發送的消息同步到自己的業務服務器，由業務服務器自由對接自研或私有大模型自建服務（&lt;em&gt;如私有部署的 LLM、LangChain、RAG 檢索系統等&lt;/em&gt;）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通過這一方式可以實現靈活的消息接入、參數定製、響應策略，&lt;/span&gt;&lt;span&gt;&lt;span&gt;適合有高度定製化、私有化部署、安全隔離等要求的業務場景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;對接 AI Agent 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;支持對接已&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;接入 OpenAI、Claude、Gemini 等多種大模型的 Dify 平台。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可在 Dify 平台上創建一個自己的 AI Agent（&lt;/span&gt;&lt;em&gt;&lt;span&gt;如：聊天機器人&lt;/span&gt;&lt;/em&gt;&lt;span&gt;），同時在融雲服務端創建一個機器人，並將該機器人通過配置直接與 Dify 平台創建的 AI Agent 進行對接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;這樣，&lt;/span&gt;&lt;span&gt;&lt;span&gt;無需自行搭建模型服務，就可以實現多輪 AI 對話、知識庫問答、RPA 流程（&lt;em&gt;機器人流程自動化&lt;/em&gt;）等&lt;/span&gt;&lt;span&gt;&lt;span&gt;高級功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="148" src="https://oscimg.oschina.net/oscnet/up-7518cc39e9922c3ad838434add534928cc3.png" width="580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;快速搭建 AI 陪伴應用示例&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;以 AI 陪伴應用為例，融雲提供從 AI 角色配置、Prompt 預設到 IM 對接的全鏈路服務，&lt;/span&gt;&lt;span&gt;&lt;span&gt;快速搭建 AI 陪伴應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在 Dify 中創建和調試 AI Agent&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪創建聊天助手&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪填寫人設&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪設置 LLM 和參數&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪配置開場白&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在融雲服務端創建機器人並完成關聯&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通過 Server API 創建機器人&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通過&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;Agent 地址&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;設置機器人的回調配置信息，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;關聯 AI Agent&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑在客户端集成 IM SDK， AI 角色便可出現在 App 中，提供&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能破冰、AI 陪伴等能力，助力應用提升用户粘性和商業價值。&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;詳細接入流程可見本期推文次條&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;更多詳情見&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;em&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.rongcloud.cn%2Fplatform-chat-api%2Fbot%2Foverview" target="_blank"&gt;開發者文檔&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356103</guid>
      <pubDate>Sun, 11 May 2025 02:01:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Firefox 139 測試內置 Perplexity AI 搜索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;負責 Firefox 搜索的產品經理&amp;nbsp;Gayatri &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconnect.mozilla.org%2Ft5%2Fdiscussions%2Ftry-out-perplexity-ai-search-in-firefox-139%2Ftd-p%2F98352" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;團隊正在與 Perplexity 合作，將&amp;nbsp;Perplexity AI 搜索內置到 Firefox 139 中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db094748597759caee52fd4a82e08cdcb33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0618/191849_B1yu_2720166.png" width="1390" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Perplexity 是一個 AI 驅動的搜索引擎，能直接以對話形式回答你的問題——無需翻閲大量搜索結果。它特別適用於以下情況：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅&amp;nbsp;需要快速簡潔的答案，避免在多個信息源中迷失&lt;/li&gt; 
 &lt;li&gt;📚&amp;nbsp;在研究或學習時需要準確且引用充分的資料&lt;/li&gt; 
 &lt;li&gt;✍️&amp;nbsp;在創作或處理技術內容，如博客文章或代碼片段&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Firefox 團隊表示，這是他們更廣泛目標的組成部分，即在使用搜索方式以及信任哪些工具來幫助他們完成任務方面為用户提供更多選擇。如果體驗良好，可能會考慮在未來支持更多 AI 回答或搜索選項。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepEP —— 開源 EP 通信庫</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;DeepEP 是專為&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Mixture-of-Experts (MoE)&lt;/span&gt;&amp;nbsp;和 &lt;span style="background-color:#ffffff; color:#1f2328"&gt;expert parallelism (EP)&lt;/span&gt;&amp;nbsp;定製的通信庫。它提供高吞吐量和低延遲的&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;all-to-all&lt;/span&gt;&amp;nbsp;GPU 內核，也就是所謂的 MoE 調度和組合。該庫還支持低精度操作，包括 FP8。&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;為了與 DeepSeek-V3&amp;nbsp;論文中提出的 group-limited gating algorithm 保持一致，DeepEP 提供了一組針對非對稱域帶寬轉發（例如將數據從 NVLink 域轉發到 RDMA 域）進行優化的內核。這些內核提供高吞吐量，使其適合訓練和推理預填充任務。此外，它們還支持 SM (Streaming Multiprocessors)&amp;nbsp;數量控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對於延遲敏感的推理解碼，DeepEP 包含一組具有純 RDMA 的低延遲內核，以最大限度地減少延遲。該庫還引入了一種 hook-based 通信計算重疊方法，該方法不佔用任何 SM 資源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;要求&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;Hopper GPU（以後可能支持更多架構或設備）&lt;/li&gt;
&lt;li style="text-align:start"&gt;Python 3.8 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;CUDA 12.3 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;PyTorch 2.1 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;用於節點內通信的 NVLink&lt;/li&gt;
&lt;li style="text-align:start"&gt;用於節點內通信的 RDMA 網絡&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepep</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepep</guid>
      <pubDate>Sat, 10 May 2025 10:35:00 GMT</pubDate>
    </item>
    <item>
      <title>Gitee MCP 現已支持遠程訪問：無需本地部署，AI 助手即插即用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今年三月，&lt;a href="https://www.oschina.net/news/338794/gitee-mcp-server"&gt;Gitee 正式發佈了官方 MCP Server&lt;/a&gt;，讓 AI 助手深度參與代碼倉庫的管理，助力開發者更高效地工作。&lt;/p&gt; 
&lt;p&gt;今天，Gitee MCP 正式支持遠程訪問，上線了&lt;code&gt;Remote mcp-gitee&lt;/code&gt;：無需安裝、即開即用，讓 AI 助手可以遠程、安全地與 Gitee 交互，真正做到「即連即用」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源地址：&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;什麼是 Remote mcp-gitee？&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;是 Gitee 推出的遠程版 MCP Server，無需本地部署，默認運行在雲端，同時也擁有全面的接口能力，支持倉庫、文件、Issue、PR、用户信息獲取、評論等眾多操作，滿足常見開發協作需求。&lt;/p&gt; 
&lt;p&gt;你可以通過簡單配置直接將其接入任意支持 MCP Streamable HTTP 協議的客户端，&lt;strong&gt;無需安裝依賴、編譯構建，也無需配置本地環境&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;與此前的本地部署方式不同，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;將服務完全託管在雲端，為用户提供了開箱即用、跨平台、跨設備的一致使用體驗。&lt;/p&gt; 
&lt;h2&gt;遠程 MCP 有哪些使用場景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI 驅動的協作&lt;/strong&gt;：通過&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手能夠自動創建 Issue、提取任務、拆解子任務、發起/合併 PR，減輕日常操作負擔。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;低門檻接入&lt;/strong&gt;：無需本地搭建或安裝依賴，企業或個人團隊只需配置一次，即可將 MCP 能力集成至工作流中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨團隊標準化流程&lt;/strong&gt;：所有操作通過遠端 MCP 接入，統一管理權限、審計、日誌，便於追蹤和審查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;無需部署即可讀寫代碼倉庫&lt;/h2&gt; 
&lt;p&gt;藉助&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手將具備完整的上下文訪問能力，能夠直接調用 Gitee 接口，獲取倉庫結構、讀取文件內容、創建 Issue、生成 PR，甚至合併代碼、發佈版本。&lt;/p&gt; 
&lt;p&gt;你只需要準備一個 Gitee 訪問令牌，並將其配置在客户端中，即可激活整個智能協作流程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"gitee": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"https://api.gitee.com/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"headers": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Authorization":&amp;nbsp;"Bearer &amp;lt;YOUR PERSONAL ACCESS TOKEN&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;本方法適用於 Cursor、Trae 等多種主流客户端，配置完畢後，即可直接連接 Remote mcp-gitee。&lt;/p&gt; 
&lt;h3&gt;在 Cursor 中連接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;進入 Cursor 設置頁面，選擇&lt;code&gt;Tools &amp;amp; Integrations&lt;/code&gt;，新建一個 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182420_lanO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;將配置信息複製到文件中，填入 Gitee 賬號的私人令牌，保存即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182431_KJ6X_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;返回設置頁面，可以看到 mcp-gitee server 已正常連接。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182440_lOSn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;在 Trae 中連接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;選擇任意一種方式進入 MCP 設置頁面。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182451_sEtI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;搜索 Gitee 並添加。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182501_L5XD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;將配置信息複製到文件中，填入 Gitee 賬號的私人令牌（Trae 暫時未支持遠程連接，需手動複製遠程連接的配置信息）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182511_Y51c_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;確認後，mcp-gitee server 已成功連接至 Trae。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="360" src="https://static.oschina.net/uploads/space/2025/0618/182521_D6Qz_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182549_TvrI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;同時，開發者也可選擇自行部署 Remote mcp-gitee 至本地，具體流程可訪問項目倉庫查看：&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;即插即用的智能協作，就在 Gitee&lt;/h2&gt; 
&lt;p&gt;Gitee 始終致力於在 AI 時代持續探索智能開發的邊界。無論是底層協議支持，還是工具鏈能力拓展，我們都希望為開發者&lt;strong&gt;提供更開放、更易用、更高效、更先進的基礎設施&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;讓 Gitee MCP 能力以即插即用的方式走進開發者日常。無需安裝、無需配置環境，只需一段 JSON 與私人令牌，就能讓 AI 真正參與項目開發的各個環節。&lt;/p&gt; 
&lt;p&gt;現在，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;已全面開放使用，歡迎體驗輕量、流暢的智能協作能力，歡迎訪問項目倉庫瞭解更多信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee" target="_blank"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356026</guid>
      <pubDate>Sat, 10 May 2025 10:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>國家互聯網信息辦公室：中國已有 433 款大模型完成備案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 上海世界移動通信大會（MWC 上海 2025）開幕式上，國家互聯網信息辦公室副主任王京濤在致辭中指出，截至目前，中國已經有 433 款大模型完成備案，上線提供服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京濤表示，目前中國已成為全球最大的互聯網市場，擁有全球最多的網民和移動互聯網的用户，以及最活躍的數字技術和應用創新生態，建成了全球規模最大、技術領先、性能優越的網絡基礎設施。在追求自身發展的同時，中國也積極地推進各國共享互聯網發展機遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向未來，中國要堅持發展與安全並重研究，加強發展戰略、治理規則和技術標準的對接協調，推動人工智能朝着有益、安全、公平的方向健康、有序發展。要尊重各國網絡主權，尊重各國的互聯網發展道路和治理模式，共同構築和平、開放、安全、合作、有序的網絡空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京濤還表示，以人工智能為代表的新的數字技術，給人類生產生活帶來前所未有的機遇的同時，不同地區、國家、羣體間享受數字紅利的差距依然較大。對此，他建議，秉持人類共同體理念，廣泛開展人工智能國際合作，幫助發展中國家加強能力建設，提高人工智能的技術的可及性，彌合全球智能鴻溝，釋放更多的智能紅利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356024</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356024</guid>
      <pubDate>Sat, 10 May 2025 10:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「最火 AI 編程軟件」 Cursor 備受風投公司青睞，公司估值超過 180 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-17%2Fai-startup-anysphere-fields-vc-offers-at-over-18-billion-valuation"&gt;據彭博援引知情人士報道&lt;/a&gt;，近幾周來，投資者已與 Cursor 開發商 Anysphere 接洽，商討一項融資協議，該協議將使這家初創公司的估值達到 180 至 200 億美元。該提議是在這家 AI 初創公司年收入超過 5 億美元后不久提出的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/180654_RHv6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;知情人士透露，該公司並未主動尋求新一輪融資，而是投資者主動接洽。&lt;/p&gt; 
&lt;p&gt;Anysphere 首席執行官 Michael Truell 此前透露，超過半數財富 500 強企業使用 Cursor，日活用户超過 100 萬人。OpenAI、Spotify、美國職業棒球大聯盟和 Instacart 等知名公司均為其用户。&lt;/p&gt; 
&lt;p&gt;這家成立於 2023 年的公司年化收入已突破 5 億美元，被硅谷投資者譽為 「史上收入增長最快的初創公司」。雖然公司目前並不缺乏現金，但考慮到有利的融資條件，Anysphere 可能會選擇增加更多資本儲備。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356022</guid>
      <pubDate>Sat, 10 May 2025 10:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>bzip2 的 crate 包已完全從 C 遷移到 Rust</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;bzip2 0.6.0&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrifectatech.org%2Fblog%2Fbzip2-crate-switches-from-c-to-rust%2F" target="_blank"&gt; 已發佈&lt;/a&gt;，團隊稱新版本默認採用他們實現的 bzip2 算法 libbz2-rs-sys，bzip2 的 crate 包也已完全從 C 遷移到 Rust，bzip2&amp;nbsp;庫現在編譯更快、跨編譯更簡單。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/173858_3xAW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;儘管現在 bzip2 的使用不如以前廣泛，但許多協議和庫仍需支持它以滿足規範要求。團隊借鑑了在 zlib-rs 項目中的經驗，對 bzip2 的實現進行了更新。&lt;/p&gt; 
&lt;p&gt;在性能方面，Rust 實現通常優於 C 實現，儘管在某些情況下兩者性能相當。壓縮性能測試顯示，Rust 實現的壓縮速度比 C 實現快 14% 左右。在解壓縮方面，Rust 實現也帶來了顯著的速度提升，測試結果顯示平均速度快了 5%-10%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/173936_x7TO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;移除 C 語言依賴後，Rust 項目在交叉編譯時的複雜性大大降低，編譯為 WebAssembly 等平台的問題也得到了解決。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/256102/sudo-rs-0-2-0-first-stable" target="news"&gt;sudo-rs 發佈首個穩定版 0.2.0：內存安全、用 Rust 重寫的 sudo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356012/bzip2-crate-switches-from-c-to-rust</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356012/bzip2-crate-switches-from-c-to-rust</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​字節跳動 Seedance 1.0 模型評測結果超越谷歌 Veo 3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在近期的人工智能視頻生成領域，字節跳動悄然發佈了一款名為 Seedance1.0 的新模型，該模型在獨立的評測中已經超越了谷歌最新推出的 Veo3。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Seedance1.0 的研究論文中詳細介紹了該模型的創新之處。字節跳動的團隊通過對空間和時間層的解耦，結合了多模態位置編碼，從而使得該模型能夠同時處理文本到視頻和圖像到視頻的生成任務。這樣的方法支持複雜的場景切換和多鏡頭敍事，保持了一致的主題表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="185" src="https://oscimg.oschina.net/oscnet/up-cdfc14b924c4930f690c558ca675747c61e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Seedance1.0 的性能離不開字節跳動強大的數據管道。團隊精心構建了一個大規模、多來源的數據集，配有詳細的雙語註釋和豐富的動作與靜態特徵標註，確保生成內容的準確性。同時，採用了一種新穎的強化學習設置，結合了三個獎勵模型，重點關注基礎對齊、動作質量和美觀度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-3b8266677daa9731bb02990119d48c53102.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在評測中，Seedance1.0 在多個維度上超過了 Veo3。在與電影導演合作開發的 SeedVideoBench 基準測試中，該模型在遵循提示和動作真實感方面取得了更高的分數。在圖像到視頻的任務中，Seedance 保持了輸入幀的視覺一致性，而 Veo3 則在某些情況下出現了光照和紋理的變化。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="293" src="https://oscimg.oschina.net/oscnet/up-47383f948234dcb7e6170c1e5457953697d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在推理性能方面，Seedance1.0 也表現出色。該模型能夠在 41.4 秒內生成一段 1080p 的五秒視頻，這一速度遠超其他競爭對手，如 Sora、Runway Gen-4 和 Veo3。字節跳動還表示，他們在降低成本和延遲方面取得了重大進展，使得視頻生成向實時應用的目標邁進了一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Seedance1.0 計劃於 2025 年 6 月集成到 Doubao 和 Jimeng 等平台，旨在顯著改善專業工作流程和常規創作任務。雖然 Veo3 因首次結合了真實視頻與環境音效和對話而備受矚目，但 Seedance1.0 在視覺保真度、運動穩定性和敍事連貫性方面表現更為出色，雖然在音頻能力上有所欠缺。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356005</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356005</guid>
      <pubDate>Sat, 10 May 2025 09:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>通過 AIOps、生成式 AI 和機器學習，實現更智能的可觀測性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;雲與 AI 成為基礎設施與平台的當下，運維團隊正面臨多重挑戰：指標、日誌、跟蹤數據割裂形成的「數據孤島」，被動響應機制導致的平均修復時間攀升，傳統監控在動態微服務架構中的失效等等。&lt;/p&gt; 
 &lt;p&gt;而在現代應用開發的背景下，可觀測性可以從各種來源收集和分析數據：日誌、指標和追蹤 —— 以深入瞭解在你環境中運行的應用程序的行為。而通過可觀測性方案 + AI，也能為現代 IT 系統實現更加智能的可觀測性。&lt;/p&gt; 
 &lt;p&gt;本週六，第 114 期 OSC 源創會將在北京舉辦，以「AI 運維「開掛」指南」為主題。Elastic 社區首席佈道師劉曉國將出席活動，並發表《通過 AIOps、生成式 AI 和機器學習，實現更智能的可觀測性》主題演講。在活動正式開始前，先來簡單瞭解下可觀測方案。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="1440" src="https://oscimg.oschina.net/oscnet/up-499956c715242acc73d6281d0bffbe0ce6b.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：您提到現代系統需從「被動響應轉向主動防禦」，當前企業在可觀測性實踐中面臨的最大痛點是什麼？傳統監控方案為何難以應對雲原生環境下的複雜性？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;數據量大，存儲成本高、海量數據處理壓力大，很多企業的可觀測性數據（指標，日誌及跟蹤）存在於不同的數據庫中，從而造成數據孤島，手動關連它們或通過一些工具進行轉化比較困難。當真正的事件發生後，很難找到真正的原因。另外人工分析這些數據幾乎是不可能的，特別是想從被動響應轉向主動防禦。 &lt;strong&gt;Elastic 的全面可觀測性方案&lt;/strong&gt;可以採用機器學習的方法來對實時數據進行分析，並查看異常事件，從而完成從被動響應轉向主動防禦的需求。這些異常的事件可以結合通知/告警的方式以不同的形式發送給運維人員。雲原生環境中的服務頻繁啓動，停止和擴展，傳統的監控很難實時地跟蹤這些變化。另外，傳統監控難以在雲環境中捕獲服務的調用鏈和依賴關係。Elastic 的服務圖可以很方便地顯示各個服務之間的調用關係，並在圖上以不同的顏色顯示該服務的健康狀態。我們可以結合機器學習及大模型來進一步解釋及提供修正的方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：Elastic 可觀測性方案的優勢是什麼？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Elastic 可觀測性方案把指標，日誌，跟蹤及通用分析數據保存於同一個數據庫中，儘管存在於同一個平台的不同索引裏。Elastic 使用 ECS (Elastic Common Schema) 語義語法來定義統一的字段名稱。這樣不同的索引還是可以通過一些字段進行關聯。當一個事件發生時（比如響應緩慢可以在跟蹤視圖可見），我們可以同時同時在一個平台查看日誌，指標，從而找出真正的事件原因。Elastic 全觀測性方案可以更快地位 IT 團隊找出根因，而不用在各個不同的平台裏進行手動關聯，或通過一種轉換的方式來進行操作。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：在您遇到的案例中，是否有某個問題通過傳統監控完全無法捕捉，卻因 Universal Profiling 的‘全棧可見性’意外暴露？當時團隊如何反應？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Elastic Universal Profiling™ 是一種全系統、始終在線、連續的分析解決方案，無需代碼檢測、重新編譯、主機上調試符號或服務重新啓動。 通用分析利用 &lt;span style="color:#6425d0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Febpf.io%2F" target="_blank"&gt;eBPF&lt;/a&gt;&lt;/span&gt; 在 Linux 內核空間內運行，以不引人注目的方式以最小的開銷僅捕獲所需的數據。它可以幫我們定位消耗時間最多的函數以及這些函數的調用情況，並以火焰圖的形式表達出來。它可以幫我們瞭解整個基礎架構中哪些代碼行始終消耗 CPU 資·源。我們可以通過 Universal Profiling 工具來優化我們的代碼設計。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; Assistant 生成的操作建議需要人工複核嗎？在您經歷的案例中，運維團隊對 AI 建議的信任度如何建立？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;我們的 AI Assistant 是基於 LLM RAG 基礎之上的智能助手。我們可以建立自己的知識庫，從而消除人工智能在推理時產生的幻覺。這些知識庫存在於 Elastic 自己的索引裏，是可以由運維人員自己創建的，或者直接有運營手冊直接導入的。這些知識庫可以來自 github，runbook， playbook 等。另外 Elasticsearch 的文檔非常全面，很多大模型對 Elasticsearch 的文檔進行了充分的訓練。通常來説，產生幻覺的機會還是蠻少的。我們將來甚至可以推出自己的大模型。針對有些敏感的操作，我們可以在助手裏做出相應的選擇。在 AI 進行回答問題之前，通常會查看自己的知識庫得到最相近的答案。如果 AI 提供的推理是建立在自己的知識庫之上，或者我們在自己平時積累的解決方案之上，那麼 AI 推理提出的解決方案還是相當可以接受的。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：您認為 &lt;/strong&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;strong&gt;+Observability 的結合會催生哪些新&lt;/strong&gt;&lt;strong&gt;範式&lt;/strong&gt;&lt;strong&gt;？未來是否可能出現「自主修復系統」？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;是的，這種完全可能。目前在 Elastic 的可觀測性方案中，我們使用 AIOps 來針對可觀測性提供解決方案。由於 LLM 具有良好的推理及總結功能，甚至它還可以幫我們關聯不同索引裏的數據。結合私有知識庫，LLM+Observability 為我們的可觀測性提供良好的解決方案。Elastic 的可觀測性其實還有一個叫做 AutoOps 的解決方案。其實主要是針對集羣的運行及查詢，攝入的監控，並提出相應的解決方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：對於資源有限的中小團隊，部署智能可觀測性最應規避的‘過度設計’陷阱是什麼？能否分享一個最小可行方案的搭建路徑？」&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;我覺得儘量採用通用標準，比如 OpenTelemetry 從而規避鎖定廠商。另外，儘量避免工具氾濫，膨脹。工具多了，維護的成本也會增加，帶來的問題也會很多。如把需要的數據採集到一個數據庫中，而不是分散到不同的平台中。還有最好採用一下比較成熟的解決方案，而不是一些未經得到證實的方案。Elastic 其實已經提供了一個比較簡介的部署方案，從數據攝取，處理，展示，搜索，及到事件的捕獲，通知/告警。在同一個平台即可搞定所有的事。我們還可以結合人工智能來幫助我們攝取，優化，推理，並提供解決方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：開發者需掌握哪些新技能來駕馭智能運維時代？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;日誌，指標及跟蹤的數據採集，處理及分析技能（Elastic Stack, OpenTelemetry 等）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;數據整合的能力，比如數據採集，清洗，豐富等&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;熟悉 Kafka, Spark, Flink, Logstash, Beats, Elastic Agents 等數據處理框架。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AI/ML 能力。Elastic 中使用 ML 來監測異常事件。雖然開發者不需要掌握很深的 ML 能力，但是知道其作用並如何使用即可。。如果使用 LLMs 來幫助我們分析文件，解決問題。在海量的數據裏找到洞察。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;具有使用一些構建易用，直觀的運維可視化界面能力（比如 Kibana, Grafana 等）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;通知及告警&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AI agents&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：Elastic 近年從&lt;/strong&gt;&lt;strong&gt;搜索引擎&lt;/strong&gt;&lt;strong&gt;擴展到可觀測性、安全甚至&lt;/strong&gt;&lt;strong&gt;生成式 AI&lt;/strong&gt;&lt;strong&gt;領域，這種跨界拓展背後的核心邏輯是什麼？在您看來，未來 3 年 Elastic 最可能顛覆的 「下一個生態位」 會是什麼？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;劉曉國：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;其實 Elastic 在很多年前已經進入到可觀測性及安全領域。早期我們還有企業搜索。這些構成了 Elastic 的三大技術方案。目前企業搜索已經退出，更多地集成到我們的 Search 解決方案裏。Elastic 在過去的三年裏大量投入到 AI 領域。我們的向量搜索庫 Elasticsearch 是世界上下載最多的數據庫。在未來，我們將圍繞 AI 打造智能解決方案。LLMs 為這些提供了良好的基礎。我們結合 MCP 這種 AI agents 通過自然語言的方式對我們的數據進行查詢，分析，並提出解決方案。AI 智能體在未來肯定會越來越聰明，併為我們的可觀測性帶來自動處理的能力！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="10252" src="https://oscimg.oschina.net/oscnet/up-c40d45614995bacbd788286afa1eafa1aa4.png" width="3125" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18627539</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18627539</guid>
      <pubDate>Sat, 10 May 2025 08:48:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Docker Desktop 4.42 發佈，集成 MCP 工具包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Docker Desktop&amp;nbsp;4.42 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-desktop-4-42-native-ipv6-built-in-mcp-and-better-model-packaging%2F" target="_blank"&gt;已發佈&lt;/a&gt;&lt;/u&gt;，新增原生支持 IPv6 網絡，智能 DNS 解析、集成 Docker MCP Toolkit、增強 AI 相關功能等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b35f142c42d62e4321cd5c076947810288e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在網絡功能方面，Docker Desktop 4.42 為滿足多樣化的企業網絡需求，引入了原生 IPv6 網絡支持，開發者可靈活選擇 IPv4 / IPv6 雙棧（默認）、IPv4 專用或 IPv6 專用模式。&lt;/p&gt; 
&lt;p&gt;新版本還新增智能 DNS 解析功能，能夠檢測主機的網絡堆棧，並過濾不支持的 DNS 記錄類型，有效減少 IPv4 或 IPv6 限制環境下的連接問題。&lt;/p&gt; 
&lt;p&gt;這些網絡設置可在 Docker Desktop 的「Settings」 &amp;gt; 「Resources」 &amp;gt; 「Network」中調整，並支持團隊集中管理和強制執行，從而提升複雜網絡配置的可靠性。&lt;/p&gt; 
&lt;p&gt;在工具方面，Docker Desktop 4.42 集成 Docker MCP Toolkit，開發者無需額外安裝，可以直接使用 GitHub、MongoDB 和 HashiCorp 等熱門 MCP 服務器，並可將其連接至 Claude Desktop、Cursor 等客户端或 Docker 自家 AI 代理 Gordon。此外還新增 docker mcp 命令，支持通過命令行管理服務器、客户端及配置。&lt;/p&gt; 
&lt;p&gt;Docker 正致力於成為一個全面的 AI 解決方案，&lt;a href="https://www.oschina.net/news/340579/docker-model-runner-run-llms-natively"&gt;此前已內置 LLM 模型運行器&lt;/a&gt;，使得基於 llama.cpp 的服務器模型部署更加便捷。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-desktop-4-42-native-ipv6-built-in-mcp-and-better-model-packaging%2F" target="_blank"&gt;詳情查看發佈公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355998/docker-desktop-4-42-native-ipv6-built-in-mcp</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355998/docker-desktop-4-42-native-ipv6-built-in-mcp</guid>
      <pubDate>Sat, 10 May 2025 08:47:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>【視頻】Solon Flow vs Drools - 業務規則應用對比</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索視頻：&lt;/p&gt; 
&lt;p&gt;&lt;iframe height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114703174993573&amp;amp;bvid=BV1FfNjz1EzQ&amp;amp;cid=30560947818&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355985</guid>
      <pubDate>Sat, 10 May 2025 07:53:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
  </channel>
</rss>
