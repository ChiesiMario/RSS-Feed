<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Sun, 01 Jun 2025 12:41:16 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Reactor Kafka 項目將被終止維護</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;簡要説明&lt;/strong&gt;：我們已決定停止 Reactor Kafka 項目的未來維護，並在 Spring 生態系統中廢棄相關組件。&lt;/p&gt; 
&lt;p&gt;我們的團隊始終以長期可持續性為目標來評估項目組合。當某個項目的用户羣體減少時，我們會慎重考慮退役，以便集中精力滿足社區的主要需求。根據對用户採用情況、下載趨勢、項目活動以及 Reactor Kafka 在整體戰略中的作用的評估，我們決定終止該項目的維護和集成。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這對用户意味着什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Freactor%2Freactor-kafka" target="_blank"&gt;Reactor Kafka&lt;/a&gt; 將從所有未來版本的 Reactor BOM 中移除。&lt;/li&gt; 
 &lt;li&gt;Reactor Kafka 1.3 將是最後一個次要版本，我們僅會提供必要的更新和修復，直至&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprojectreactor.io%2Fsupport" target="_blank"&gt;開源及商業支持&lt;/a&gt;期限結束。&lt;/li&gt; 
 &lt;li&gt;Spring Cloud Stream - &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-cloud%2Fspring-cloud-stream%2Ftree%2Fmain%2Fbinders%2Fkafka-binder%2Fspring-cloud-stream-binder-kafka-reactive" target="_blank"&gt;Reactor Kafka Binder&lt;/a&gt; 將被廢棄，並計劃在未來移除。&lt;/li&gt; 
 &lt;li&gt;Spring for Apache Kafka 的響應式模板將被廢棄，並計劃在未來移除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們仍然致力於 Reactor 生態系統的持續發展，包括 Reactor Core、Reactor Netty 等項目。&lt;/p&gt; 
&lt;p&gt;我們衷心感謝多年來所有為 Reactor Kafka 項目成功作出貢獻的用户。如果您有任何問題或疑慮，請隨時通過相關 GitHub 代碼庫聯繫，或在下方留言。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;感謝您，&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Project Reactor 團隊&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352970/reactor-kafka-discontinued</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352970/reactor-kafka-discontinued</guid>
      <pubDate>Sat, 10 May 2025 14:40:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Agentic AI，拼完技術拼生態</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;最近 Agentic AI 一詞常出現在大眾視野裏，很多人還沒玩轉 Agent，又要開始瞭解 Agentic AI，這是不是新瓶裝舊酒，又造沒必要的概念？&lt;/p&gt; 
&lt;p&gt;還真不是。Agentic AI 的核心能力很好理解——接到任務後，先思考規劃，然後自動調用、組合一切可以使用的工具，幫你完成任務。&lt;/p&gt; 
&lt;p&gt;和對話式、生成式的 GenAI 相比，Agentic AI 具備自主決策與行動的能力。&lt;/p&gt; 
&lt;p&gt;和單個的 Agent 相比，Agentic AI 則是能同時調動多個 Agent 或者其他工具，完成更復雜的系統性任務。&lt;/p&gt; 
&lt;p&gt;&lt;img height="822" src="https://oscimg.oschina.net/oscnet/up-2819d862530fc01ca480c99b76c748fe102.png" width="1234" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;乍一看會感覺功能上的進步並沒有多亮眼，實際上，這可能是大模型時代從拼技術，到拼生態的關鍵一環。百模大戰已暫告一段落，市場向頭部模型靠近，開源也加速了 AI 普惠。在許多應用場景中，很難從大模型技術能力層面拉開太大的差距。那麼下一步，拼的必然是生態，誰能聚合更多應用，完成更復雜的任務，才能引得用户駐足。而 Agentic AI 恰恰是一個帶着生態性質的智能系統。&lt;/p&gt; 
&lt;p&gt;可以看一個簡單的案例——上個月剛剛升級的扣子空間，也符合 Agentic AI 系統的定義。&lt;/p&gt; 
&lt;p&gt;先提出一個初始要求：「2025 端午節馬上就要到了，我要從深圳出發，去周邊度假 3 天，請你結合實際情況做一個旅遊規劃，並且用文檔呈現給我。」&lt;/p&gt; 
&lt;p&gt;下圖是釦子空間給出的反饋：可以看出，釦子空間的思考過程劃分了明確的任務步驟，首先找合適的地點，然後使用搜索工具檢索信息，繼而做出規劃，根據規劃查詢細節，最後整理成了 Markdown 格式返回給我。最終的 Markdown 文件可以直接在釦子空間中打開。&lt;/p&gt; 
&lt;p&gt;&lt;img height="746" src="https://oscimg.oschina.net/oscnet/up-e91b9dd7d4a6cb1feb5580b01a35bab52de.png" width="2184" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1142" src="https://oscimg.oschina.net/oscnet/up-35727c6e636cfdaae3ce0aa2dae231fcd75.png" width="1938" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;釦子空間目前並沒有選擇底層模型的按鈕，使用的是豆包大模型，同樣的問題給到豆包大模型，就可以對比出不同：豆包沒有展示詳細的思考過程，最終也無法直接生成一個文檔，只是在對話框裏給了文字信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1160" src="https://oscimg.oschina.net/oscnet/up-840c0158a254c84c43baeebaf7462ddac68.png" width="1934" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，更核心的區別在於，Agentic AI 中，還具備調用各類內外部工具的能力。在釦子空間的頁面，點擊擴展，即可添加外部工具組件，比如在這次對話中選擇墨跡天氣、高德地圖、飛書雲文檔，然後提出修改的要求：「生成一份飛書文檔，並結合實際天氣預報和路線，完善這份旅遊攻略。」&lt;/p&gt; 
&lt;p&gt;同樣按照前文思考、工具調用、完成任務的步驟，釦子空間給了我一個飛書雲文檔的鏈接，打開之後，更新的旅遊攻略裏有了非常詳細的交通行車規劃，以及天氣預報。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1108" src="https://oscimg.oschina.net/oscnet/up-53ec07f1cae7be7d30e4d024e894fb04d54.png" width="1938" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;還沒完，目前釦子空間提供的外部擴展組件只有 10 多個，但是它支持通過 MCP 協議配置，這樣一來，開發者就可以自定義更多功能。（不瞭解 MCP 的同學可以看這篇：&lt;a href="https://my.oschina.net/u/4489239/blog/17989059" target="_blank" rel="nofollow"&gt;MCP 協議：LLM 應用開發的 「Type-C」&lt;/a&gt;）從這個角度看，也就解釋了為什麼去年很多廠商在做多智能體協作的產品，但今年卻被 Agentic AI 搶了風頭——MCP 協議方便大模型調用各個成熟的產品、工具，同時開發一個 MCP Sever 也很簡單，所以自然比幾個智能體協作更有市場。&lt;/p&gt; 
&lt;p&gt;&lt;img height="834" src="https://oscimg.oschina.net/oscnet/up-1fdae16c050676c35af0d14b4f3387f0f87.png" width="1934" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;誰在做？&lt;/h3&gt; 
&lt;p&gt;目前市場上，符合 Agentic AI 定義的產品正呈現多點開花的態勢。其中最典型的落地場景當屬開發者工具領域——各類 Code Agent 可以自主思考、動態調試、具備全局視角、能根據需求自主調用工具。比如字節海外版 Trae 支持 Agent 模式下的全流程開發；Copilot 上線了名為 "Project Padawan" 的自主 Agent；通義靈碼宣佈全面支持 Qwen3，上線了編程智能體等等。感興趣的讀者可以查看此前關於 Code Agent 的詳細報道 &lt;a href="https://my.oschina.net/u/4489239/blog/18348629" rel="nofollow"&gt;Code Agent 都用過了嗎，能打幾分？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;今年廠商的戰略佈局正從單一工具向系統工程演進，許多廠商發佈的滿足 Agentic AI 定義的相關的產品錨定在更加工程化的場景中。&lt;/p&gt; 
&lt;p&gt;上個月，亞馬遜成立了一個專注於 Agentic AI 的新部門。5 月 22 日，亞馬遜雲科技推出 Amazon Transform，定位是「基於 Agentic AI 的現代化遷移服務」，從技術架構上看，Amazon Transform 融合了多種亞馬遜雲科技已有能力：包括 Amazon Q（對話界面）、Amazon Bedrock（模型支撐）、圖神經網絡（依賴建模）、Amazon Q Developer（代碼生成）、以及雲原生部署平台（ECS/Fargate）。但對開發者而言，它最有意義的地方，是能把遷移過程變成一段工程閉環流程，而非一個無頭緒的技術債項目。&lt;/p&gt; 
&lt;p&gt;3 月，智譜發佈了 AutoGLM 沉思模型，核心支持 research 場景。據介紹，該模型是一個集深度研究與實際操作能力於一體的 Agent 產品。後續，智譜還將搭建 Agentic LLM 平台，助力生態合作伙伴利用智譜模型與智能體的能力，構建行業、地域與場景深度融合的智能體應用。智譜 CEO 張鵬表示，2025 年無疑是 AI Agent 的爆發之年，智譜將戰略聚焦 Agentic GLM 的研發，以推動智能體技術的快速發展。&lt;/p&gt; 
&lt;p&gt;北京大學發佈了開源研究項目 Agentic RAG-R1，旨在推動語言模型在自主檢索與推理能力方面的能力邊界。該項目通過引入強化學習策略（GRPO），構建了一個可自我規劃、檢索、推理與總結的智能體式 RAG 系統，具備模型自主、工具自選、推理自洽核心能力。&lt;/p&gt; 
&lt;p&gt;NVIDIA 和微軟也在合作推進 Agentic AI 應用從雲端到 PC 的發展。在 5 月的 Microsoft Build 大會上，微軟發佈了可擴展平台 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fblog%2Ftransforming-rd-with-agentic-ai-introducing-microsoft-discovery%2F" rel="nofollow" target="_blank"&gt;Microsoft Discovery&lt;/a&gt;，旨在賦能研究人員利用 Agentic AI) 變革整個發現流程，幫助各行各業的研發部門加快新產品的上市時間，並加速和擴展所有科學家的端到端發現流程。Microsoft Discovery 將集成 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.nvidia.com%2Fblog%2Falchemi-nim%2F" rel="nofollow" target="_blank"&gt;NVIDIA ALCHEMI NIM 微服務&lt;/a&gt;，微服務可用於優化化學模擬的 AI 推理，並通過屬性預測和候選材料推薦來加速材料科學研究。&lt;/p&gt; 
&lt;p&gt;此外，研究機構對 Agentic AI 的評價與期待也很高。&lt;/p&gt; 
&lt;p&gt;Gartner 的《2025 年主要戰略技術趨勢研究報告》。第一大趨勢便是 Agentic AI（智能代理 AI）趨勢背景：智能代理 AI 是能夠自主決策並採取行動以實現特定目標的軟件程序。該技術結合了多種 AI 技術，具備記憶、規劃、感知環境、使用工具並遵循安全準則等功能，旨在使 AI 系統具備更強的自主性。&lt;/p&gt; 
&lt;p&gt;趨勢重要性體現在智能代理 AI 可以大幅提升企業的生產力，並在 2028 年前讓至少 15% 的日常工作決策實現自動化。它能夠幫助員工完成更復雜的任務，推動技術項目的發展，並改善企業的決策效率。應用場景指向客户體驗自動化、數據分析中的高級決策、複雜項目的自主規劃等。&lt;/p&gt; 
&lt;p&gt;康奈爾大學最新發布的論文也認為 AI Agent 和 Agentic AI 本質上是兩個完全不同的技術範式，後者代表一種由多個 AI 代理組成的系統，這些代理可以協同工作，解決複雜的多步驟任務。它不僅擁有更高層次的自主性，還能在多個任務和環境中進行學習與適應。其典型應用包括供應鏈管理、流程優化和虛擬項目管理，體現出系統級的智能協作與協調能力。而這種演進標誌着從「功能性智能」向「系統性智能」的躍遷。&lt;/p&gt; 
&lt;p&gt;&lt;img height="680" src="https://oscimg.oschina.net/oscnet/up-b64e2ca7d2c7e06ec5bdc0f9a4ce29b6ac4.png" width="1800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;怎麼做？&lt;/h3&gt; 
&lt;p&gt;從技術層面來説，整合一個 Agentic AI 不算難，結合 MCP，或是通過開放平台構建工具集市，打通自定義工具的調用接口就能實現。但技術可行性只是商業化的起點，當科技巨頭們爭相佈局 Agentic AI 時，兩條截然不同的演進路線浮出水面。&lt;/p&gt; 
&lt;p&gt;Salesforce 選擇漸進式改造：將 Agentic AI 嵌入現有 SaaS，比如在 CRM 裏內置智能銷售助手，自動生成客户畫像和跟進策略等。&lt;/p&gt; 
&lt;p&gt;典型案例是 Salesforce 的 Agentforce 系統，Agentforce 與整個 Salesforce Customer 360 系統原生集成。從銷售與服務到商務與市場營銷，客服人員可以使用 CRM 應用程序中的完整客户上下文，比如客服人員可以利用互動數據來識別追加銷售機會，並向潛在客户生成個性化電子郵件。這種「自下而上」的策略，既保留企業原有數據架構，又降低了轉型成本。&lt;/p&gt; 
&lt;p&gt;微軟比較激進，微軟 CEO Satya Nadella 曾高調宣稱：「我們所知的 SaaS 時代即將結束……Agent 將成為核心驅動力」。 Nadella 認為，這是一場從「App Stack」到「Agent Stack」的根本性變革。過去，我們依賴前端 UI 驅動的應用形態，每一個業務場景都被拆分為獨立的 App，用户通過操作完成任務。未來，主導者將是 Agent，它能感知用户意圖，基於數據、模型和推理鏈條，完成決策和自動執行。結合前不久 Microsoft Discovery 的發佈動作，Nadella 暢想的這幅關於 Agent 的未來畫面顯然是符合 Agentic AI 的範疇。&lt;/p&gt; 
&lt;p&gt;在這種架構轉變下，當前的 SaaS 等應用因為其本質上是嵌入商業邏輯的數據庫，未來這些邏輯會被 Agent 接管，由 Agent 去做增刪改查，在多個數據庫之間工作，所有的邏輯都會轉移到 AI 層。而一旦 AI 層成為主導，背後的數據庫最終也會開始被替代。&lt;/p&gt; 
&lt;p&gt;從本質上講，Agentic AI 是一種以自主性為核心的 AI。這意味着它可以做出決策、採取行動，甚至自主學習以實現特定目標。它就像一個虛擬助手，能夠思考、推理，並適應不斷變化的環境，而無需持續的指令。&lt;/p&gt; 
&lt;p&gt;從系統的角度看，Agentic AI 既可以融入企業的現有架構中，也能另起爐灶。下一步，Agentic AI 的成敗或許就要看，誰能接入更多工具，誰能打破邊界絲滑融入更多的生態。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18514357</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18514357</guid>
      <pubDate>Fri, 09 May 2025 10:29:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>打造智能化軟件工廠：Gitee Insight 的 DevSecOps 度量實踐</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：Gitee DevSecOps 團隊-李穎萍，紀文靜，徐烈&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;隨着數字化轉型的深入，軟件正逐步成為企業的核心競爭力。越來越多的企業採用「軟件工廠」建設模式，期望實現軟件研發的規模化、自動化和智能化。&lt;/p&gt; 
&lt;p&gt;傳統的軟件研發管理面臨諸多挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;工具和系統的多樣化導致數據孤島，無法實現全局洞察和協同優化；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;度量體系缺失，企業難以掌握研發效能、質量、成本、風險等核心指標，也無法對標行業水平；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能化水平有限，AI、數據分析等技術尚未充分融入研發過程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為瞭解決這些挑戰，Gitee Insight 應運而生。作為 Gitee 平台推出的面向軟件工廠的度量與智能中樞，Gitee Insight 基於 DevSecOps 方法論，&lt;strong&gt;為企業提供「可視、可度量、可優化」的研發治理能力&lt;/strong&gt;，覆蓋從立項到交付的全生命週期，真正實現數據驅動下的智能研發決策支持，有效提升軟件交付質量與組織研發效能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;做軟件工廠的中樞神經系統&lt;/h2&gt; 
&lt;p&gt;作為軟件工廠的核心能力模塊，Gitee Insight 貫穿全流程，負責全面的軟件度量工作。通過打通代碼、測試、部署等環節的核心數據，平台構建了完善的度量體系，支撐以下價值實現：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;效能提升：依託多維數據分析引擎，深入剖析任務流轉效率、資源使用情況及版本迭代節奏，精準識別瓶頸並持續優化交付流程；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;風險防控：集成 20 多個風險監測維度，涵蓋安全漏洞、技術債務、延期風險等，實時識別研發活動中的潛在風險併發出預警。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;平台還提供了高度可視化的交互式工程儀錶板，結合趨勢圖、對比圖等組件，幫助管理者實時掌握研發動態，從全景視角洞察項目進展與質量態勢，推動管理科學化與決策精準化。&lt;/p&gt; 
&lt;p&gt;Gitee Insight 不僅是軟件工廠的「度量大腦」，還是 DevSecOps 戰略落地的關鍵支撐，引領企業構建安全、透明、高效的一體化軟件交付體系。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;研發效能透視引擎&lt;/h2&gt; 
&lt;p&gt;在軟件工廠體系下，Gitee Insight 致力於打造一套貫穿全生命週期、覆蓋全角色的研發效能度量模型，實現研發過程的透明化、可觀測與可優化。該模型覆蓋從需求提出、架構設計、編碼開發、測試驗證到部署上線的全流程，全面支撐 DevSecOps 理念下的閉環度量與治理。&lt;/p&gt; 
&lt;h3&gt;產能分析&lt;/h3&gt; 
&lt;p&gt;作為 Gitee Insight 研發效能透視引擎的核心能力之一，產能分析為管理者提供直觀、全面的效率分析視圖，主要包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;代碼提交頻率&lt;/strong&gt;：實時監測開發活躍度與代碼投產節奏，洞察研發產出情況；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;流水線阻塞點分析&lt;/strong&gt;：聚焦構建時長、測試通過率、部署失敗率等核心指標，定位 CI/CD 流程中的潛在瓶頸；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;任務流轉效率&lt;/strong&gt;：對接需求管理與任務看板系統，分析任務從創建到完成的各階段流轉效率，揭示流程中存在的待辦積壓與中斷點；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工作負載分佈&lt;/strong&gt;：評估團隊成員的任務負載均衡性，識別超載或資源空轉，為任務調度與人員配置提供決策支撐。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="494" src="https://static.oschina.net/uploads/space/2025/0530/182050_muy1_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0530/182119_0ekW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;效能基準動態對標&lt;/h3&gt; 
&lt;p&gt;作為 Gitee Insight 中的戰略級功能，效能基準動態對標通過構建多維、可持續演進的效能評估體系，幫助組織系統化提升研發能力，形成可複製、可推廣的卓越實踐。&lt;/p&gt; 
&lt;p&gt;該功能支持將當前項目效能與企業歷史數據、不同團隊、乃至行業標杆進行對比分析，構建覆蓋多維度的動態對標體系，包括但不限於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需求變更響應週期：評估團隊對需求波動的響應效率，推動更快的反饋閉環；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代碼評審效率：衡量代碼從提交到評審完成的平均週期，促進代碼質量與協作效率的雙提升；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺陷關閉週期：追蹤從缺陷發現到關閉的時間跨度，反映組織在產品質量治理上的執行力；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付節奏穩定性：監測版本迭代的規律性與穩定性，助力高頻、小步、穩定的交付策略。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;平台可自動聚合歷史項目數據，生成組織內部的效能基準樣本，並支持引入行業公共指標，幫助定位短板、明確優化方向。Gitee Insight 不僅提供數據視角，更推動數據驅動的組織進化，讓效能提升從感性認知走向理性改進。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0530/182135_HWz6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;代碼質量防護體系&lt;/h2&gt; 
&lt;p&gt;在 DevSecOps 理念下，質量管理不再是研發末端的補救措施，而是貫穿全流程的內嵌機制。Gitee Insight 深度集成代碼質量檢測能力，覆蓋提交、構建、審核到發佈等各環節。核心能力包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;靜態掃描引擎&lt;/strong&gt;：自動檢測超 20 類代碼質量指標，包括圈複雜度、重複代碼率、潛在死循環、異常處理缺失等，同時支持主流語言的語法安全分析，全面掃描潛在漏洞風險；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OWASP Top 10 漏洞看板&lt;/strong&gt;：可視化展示漏洞分佈與修復進度，支持跨版本對比、問題追蹤與整改閉環。平台還能針對質量短板，預測技術債還款週期、評估技術風險沉積，為架構演進和重構提供量化決策支撐。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過全面的質量數據採集與趨勢分析，Gitee Insight 實現從「問題感知」到「根因洞察」，建立一套可度量、可治理的質量管理體系，成為軟件工廠落地 DevSecOps 安全要求的核心基座。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0530/182150_bLUJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;風險預警中心&lt;/h2&gt; 
&lt;p&gt;平台構建了&lt;strong&gt;涵蓋超 20 個風險維度的數字畫像體系&lt;/strong&gt;，大幅提升研發過程的透明度與前瞻性，讓風險防控真正從「事後響應」邁向「事前治理」，是實現 DevSecOps 安全左移、質量前置的關鍵能力之一。&lt;/p&gt; 
&lt;p&gt;覆蓋場景包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;安全漏洞監測：結合靜態掃描與漏洞庫比對，實時捕捉潛在安全隱患；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;部署概況分析：識別部署失敗率等指標，洞察交付鏈路的穩定性與健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;軟件工廠靈活化模塊適配&lt;/h2&gt; 
&lt;p&gt;為實現研發全流程的全面感知與精準度量，Gitee Insight 構建了靈活強大的數據接入體系，支持多種結構化與非結構化數據源的無縫對接，實現從「數據孤島」到「數據協同」的躍遷。目前，平台支持秒級接入 12 種主流數據庫，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;關係型數據庫：MySQL、PostgreSQL、Oracle、SQL Server、MariaDB 等；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;NoSQL 數據庫：MongoDB、Cassandra、Redis、InfluxDB 等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;藉助多源數據的統一接入與標準化處理，Gitee Insight 能快速搭建跨系統指標體系與行為鏈路，支撐研發活動的實時度量、質量追蹤、風險監控與效能分析。這一能力為軟件工廠提供了高度開放的治理底座，確保數據可聯通、分析可落地、治理有依據，是推動 DevSecOps 精準化落地的關鍵支撐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee Insight 可視化治理體系&lt;/h2&gt; 
&lt;p&gt;在軟件工廠的可視化治理中，指標的價值不僅在於採集，更在於如何呈現與解讀。Gitee Insight 內置強大的可視化能力，支持圍繞業務關注點構建多維、可交互的度量視圖，為研發管理提供從戰略決策到戰術執行的全景式數據支撐。&lt;/p&gt; 
&lt;p&gt;平台&lt;strong&gt;預置 8 大主題域、超 80 個原子指標庫&lt;/strong&gt;，覆蓋研發效能、代碼質量、安全風險、部署監控、漏洞追蹤、人力資源等關鍵領域。用户可根據業務角色和分析目標，靈活組合視圖與分析組件，搭建個性化的數字化儀表盤。&lt;/p&gt; 
&lt;p&gt;核心能力包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;拖放式組件編排：支持圖表、指標、趨勢、對比、下鑽等模塊的自由組合，所見即所得，快速搭建分析視圖；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多場景看板模板：預置「需求響應力分析」「技術債務健康度評估」「安全合規性追蹤」等看板模板，適配項目執行、團隊運營、安全治理等多元場景。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過將海量研發數據轉化為結構清晰、語義明確的可視化洞察，Gitee Insight 實現從「數據展示」到「業務驅動」的躍遷，幫助企業在戰略、戰術、執行各層面建立統一視角與協同認知，加速軟件工廠的數據化治理進程。&lt;/p&gt; 
&lt;p&gt;在軟件工廠的生產範式中，實現研發過程的可度量、可追蹤、可優化，必須依託覆蓋全鏈條的系統性度量體系。Gitee Insight 基於研發效能透視引擎，構建了一套覆蓋全生命週期的立體化度量體系，貫穿需求、設計、開發、測試、部署、運維等關鍵環節。&lt;/p&gt; 
&lt;p&gt;該體系深度整合 Gitee 平台核心模塊的指標數據，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Code（代碼質量）：提交頻次、代碼複雜度、評審效率、質量門禁通過率等；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Team（協作效率）：任務流轉時長、成員參與度、計劃完成率等；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Pipe（持續交付）：構建成功率、流水線耗時、部署穩定性等；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scan（安全檢測）：靜態掃描結果、安全漏洞分佈、修復進度等；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;One（一體化管理）：項目進度、資源投入、交付節奏等宏觀治理數據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過統一建模與語義整合，&lt;strong&gt;Gitee Insight 構建出貫穿需求規劃、研發實施、交付上線、運維反饋的完整數據資產圖譜&lt;/strong&gt;，為研發流程提供可信、實時、結構化的可視化支撐。&lt;/p&gt; 
&lt;p&gt;這一全生命週期度量能力，使軟件工廠從「工具支撐」邁向「數據驅動」，成為 DevSecOps 戰略落地與數字化治理的關鍵基礎設施。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitee.cn%2Ffactory" target="_blank"&gt;https://gitee.cn/factory&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352829</guid>
      <pubDate>Fri, 09 May 2025 10:23:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>人工智能能耗有望在 2025 年底超越比特幣挖礦</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據一項新的分析，人工智能的電力消耗預計將在 2025 年底前接近全球數據中心總電力消耗的一半，這意味着人工智能的能耗將很快超越比特幣挖礦。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該分析由阿姆斯特丹自由大學環境研究所的博士生 Alex de Vries-Gao 進行，他曾跟蹤研究過加密貨幣的電力消耗及其環境影響，並在他的網站 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdigiconomist.net%2Fai-power-demand-rapidly-escalating%2F" target="_blank"&gt;Digiconomist&lt;/a&gt; 上發佈了相關數據。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="368" src="https://oscimg.oschina.net/oscnet/up-0a6be3f3922d984c57959e12a5e7829a1de.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，人工智能已經佔據了數據中心電力消耗的高達五分之一。儘管這一數據難以精確確定，因為大型科技公司並未具體披露其人工智能模型所消耗的能源，但 de Vries-Gao 通過專門用於人工智能的計算芯片的供應鏈進行了預測。儘管技術的效率有所提升，但研究人員發現，人工智能的電力需求仍在快速增長，亟需更多關注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;de Vries-Gao 原本認為，在以太坊等替代比特幣的加密貨幣轉向低能耗技術後，他的研究工作可能會逐漸結束。然而，隨着 「ChatGPT」 等大型人工智能技術的出現，他意識到這又是一個通常耗能較大的技術，尤其是在競爭激烈的市場中。「我當時在想，天哪，這又來了」， 他如是説。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在對人工智能能耗的評估中，de Vries-Gao 指出，當前人工智能的發展正在引發更廣泛的關注。隨着這一領域的不斷擴大，理解其能源需求的重要性日益凸顯。儘管技術在不斷進步，但如何在能源消耗和可持續發展之間找到平衡，將是未來必須面對的重要課題。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352827</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352827</guid>
      <pubDate>Fri, 09 May 2025 09:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>面向開源愛好者的英國紙質雜誌《Linux Format》宣佈停刊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;科技媒體 linuxiac 報道，英國知名雜誌《Linux Format》將在第 329 期後正式停刊，結束其 25 年來記錄開源軟件發展的使命。該雜誌自 2000 年創刊以來，以每年 13 期的頻率為 Linux 和開源愛好者提供新聞、評測、教程及行業訪談等內容。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d5e102e905b7358289c7356049818b51e7d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第 329 期作為最終刊於 2025 年 5 月 27 日發行，內容聚焦 Debian 服務器搭建、Windows 用户轉向 Linux 的發行版推薦，並探討 Linux 在超級計算機中的應用。&lt;/p&gt; 
&lt;p&gt;此外，雜誌還開放部分早期刊物的數字版下載，包括創刊號 LXF001 的 PDF 文件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e925311661d7314ee729c4607fb65bf3e99.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flinuxformat.com%2Flinux-format-001.html" target="_blank"&gt;https://linuxformat.com/linux-format-001.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;儘管停刊原因未明確説明，但數字化轉型對傳統紙媒的衝擊被認為是重要因素。《Linux Format》的謝幕，標誌着開源文化傳播方式的一次時代更迭。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352825</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352825</guid>
      <pubDate>Fri, 09 May 2025 09:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Onlook —— 面向設計師的開源 Cursor</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;面向設計師的開源 Cursor。直接在實時 React 應用中進行設計，並將更改發佈到代碼中。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="color:#000000"&gt;與任何在 React + TailwindCSS 上運行的網站或 Web 應用無縫集成，並直接在瀏覽器 DOM 中進行實時編輯。自定義你的設計，控制你的代碼庫，不折不扣地推送你的變更。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="282" src="https://static.oschina.net/uploads/space/2025/0213/153046_miqw_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="315" src="https://static.oschina.net/uploads/space/2025/0213/152443_PvR5_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/onlook</link>
      <guid isPermaLink="false">https://www.oschina.net/p/onlook</guid>
      <pubDate>Fri, 09 May 2025 09:39:00 GMT</pubDate>
    </item>
    <item>
      <title>前 4 個月我國軟件業務收入 42582 億元，同比增長 10.8%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;工業和信息化部運行監測協調局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_bc256c8ceebc4130a24fb6fc5af1c6ed.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;，&lt;/span&gt;&lt;span style="color:#000000"&gt;2025 年前 4 個月，我國軟件和信息技術服務業（以下簡稱「軟件業」）運行態勢良好，軟件業務收入穩健增長，利潤總額&lt;/span&gt;&lt;span style="color:#000000"&gt;保持兩位數增長，軟件業務出口穩定增長。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="266" src="https://oscimg.oschina.net/oscnet/up-c8abf7cf47ec6c99b9bcb624452c9b7fa1c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;一、總體運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;軟件業務收&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;入穩健增長&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，我國軟件業務收入 42582 億元，同比增長 10.8%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;利潤&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;總額增速&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;保持兩位數增長&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，軟件業利潤總額 5075 億元，同比增長 14.2%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;軟件業務&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;出口穩定增長&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，軟件業務出口 172.6 億美元，同比增長 3.5%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;二、分領域運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;軟件產品收入&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;穩定&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;增長。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，軟件產品收入 9933 億元，同比增長 9.6%，佔全行業收入的比重為 23.3%。其中，基礎軟件收入 536 億元，同比增長 8.6%；工業軟件產品收入 913 億元，同比增長 6.3%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;信息技術服務收入&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;保持&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;兩位數增長。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，信息技術服務收入 28415 億元，同比增長 11.5%，佔全行業收入的 66.7%。其中，雲計算、大數據服務共實現收入 4658 億元，同比增長 11.4%，佔信息技術服務收入的 16.4%；集成電路設計收入 1210 億元，同比增長 18.0%；電子商務平台技術服務收入 3341 億元，同比增長 8.1%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;信息安全收入&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;平穩增長。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，信息安全產品和服務收入 601 億元，同比增長 8.4%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;嵌入式系統軟件收入&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;增勢回落。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，嵌入式系統軟件收入 3634 億元，同比增長 8.9%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;三、分地區運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#070707"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;前 4 個月，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;東部地區、中部地區、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;西部地區和東北地區分別&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同比增長&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;10.7%、11.3%、10.9% 和 10.9%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;東部地區佔&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;全國軟件業務總收入的 84.0%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;京津冀地區軟件業務收入同比增長 11.9%，長三角地區軟件業務收入同比增長 10.8%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;北京、廣東、江蘇、山東、上海軟件業務收入居全國前 5，同比分別增長 12.0%、8.6%、11.1%、11.9% 和 14.0%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352817</guid>
      <pubDate>Fri, 09 May 2025 09:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>從公益初心到商業化探索，開源中國助推中國開源生態之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;我們懷揣夢想、堅持不懈在做一件很多人認為是很「傻」的事情，之間也走過不少的彎路，但最終還是回到「傻」的路上。哪位牛人説過，傻的事情堅持做到極致，就會很牛。&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;而我們離牛還有十萬八千里，沒有筋斗雲，但不缺意志和情懷，再加上有你的支持，夢想終將實現。&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;—— 開源中國創始人紅薯，2013.08.31&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;中國開源，從使用者到扛把子&lt;/h1&gt; 
&lt;p&gt;2025 年春節，來自中國的開源大模型 DeepSeek-R1 引爆全球，這一模型在數學、推理等多項基準測試中已追平甚至超越國際一線閉源模型，迅速佔領了全球技術頭條。&lt;/p&gt; 
&lt;p&gt;這一「DeepSeek 時刻」不僅打破了美國對 AI 技術話語權的壟斷，也為全球 AI 生態注入了開放、多元的新動能；它也標誌着中國開源生態在底層模型研發和開放協作方面已具備世界級競爭力。&lt;/p&gt; 
&lt;p&gt;而這背後，是又一次深刻有力的印證：&lt;strong&gt;在全球開源格局中，中國正以前所未有的速度完成從「大量使用」到「深度共建」、從「跟隨者」到「領跑者」的華麗轉身。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在全球開源舞台上，&lt;strong&gt;中國開發者與社區正從「採納者」向「主導者」轉變&lt;/strong&gt;，報告顯示，自 2013 年以來，中國貢獻持續位列全球前五且增速領先，貢獻了大量倉庫、PR 和 Issue。&lt;/p&gt; 
&lt;p&gt;國內層面，&lt;strong&gt;政策與基礎設施的深度&lt;strong&gt;&lt;strong&gt;耦合&lt;/strong&gt;&lt;/strong&gt;為開源生態築牢根基&lt;/strong&gt;，「十四五」規劃出台、獨立開源託管平台建設、MulanPSL v2 開源協議問世與開放原子開源基金會成立等，為生態保駕護航。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;開源商業化方面則形成了較成熟的「開源核心＋增值服務」範式&lt;/strong&gt;，通過企業版授權、雲託管、培訓和定製開發實現穩定營收，頭部廠商的成功範式又反哺中小廠商，推動生態良性循環與持續創新。&lt;/p&gt; 
&lt;p&gt;DeepSeek 的現象級突破，僅僅是中國開源生態邁向世界舞台的重要里程碑之一。在巨量開發者的持續貢獻、企業與基金會的深度參與、政策與平台的制度保障以及商業化模式的不斷探索下，中國已由「開源使用強國」加速躋身「開源扛把子」，並將繼續以開放協作的姿態，引領全球技術創新與產業升級。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;開源中國，從公益初心到生態基座&lt;/h1&gt; 
&lt;p&gt;2005 年，Linux 之父 Linus Torvalds 推出了分佈式版本控制系統 Git，再一次改變了世界。2008 年，基於 Git 的 GitHub 上線，它的出現，推動了軟件開發協作方式和效率的變革，極大地影響了全球開發者和開源生態。時至今日，代碼託管和協作開發已經深入人心，開源社區化運作發展也成為主流。&lt;/p&gt; 
&lt;p&gt;而在中國，「開源」在當時仍是一個陌生的詞語，開源理念尚未得到廣泛傳播，開源知識與信息寥寥無幾，開源社區發展分散且缺乏系統化支撐，代碼託管、版本管理、社區協作等關鍵環節，一片凋敝。&lt;/p&gt; 
&lt;p&gt;正是在這樣的背景下，開源中國社區上線了，從此，中國開源生態有了一個從底層不斷快速生長的基座。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;開源知識傳播、開源項目推薦、開源專家孵化、開源人才培育、開源商業化優質資源整合；提供招聘平台，讓企業與開源人才精準對接、打造&lt;strong&gt;&lt;strong&gt;眾包&lt;/strong&gt;&lt;/strong&gt;平台，串聯開源甲乙方商單高效閉環、構建一站式&lt;strong&gt;&lt;strong&gt;軟件工程&lt;/strong&gt;&lt;/strong&gt;解決方案工具，加速開源項目落地……&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於開源生態有所收益的事情，開源中國從未停止探索與嘗試，自創立起開源中國就秉持公益初心，以「讓開源真正在中國落地」為使命，持續推動本土開源生態繁榮。&lt;/p&gt; 
&lt;p&gt;這樣的開源中國可以由衷地承認，中國開源乃至全球開源生態的發展有其十餘年的堅定助力。説辭流於空虛，此處僅以幾個開發者耳熟能詳的事項舉例：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Gitee SaaS 代碼託管及相關能力自 2013 年上線後就一直免費，包括私有倉庫，至今&lt;strong&gt;免費服務超過 1350 萬開發者&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;免費使用 Gitee 的用户中包括 &lt;strong&gt;2000 多家高等院校（涵蓋所有 985、211 高校），在教學與科研中推動學生走近真實項目&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2016 年，開源中國首創開源項目打賞功能，旨在為開源開發者提供實質性的經濟支持，&lt;strong&gt;激勵開源可持續創作&lt;/strong&gt;。這一公益性創新舉措不僅回應了開發者的現實需求，也成為後來開源圈廣泛效仿的範式，推動了本土開源生態的正向循環；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2020 年，開源中國發起開源百科聯合編寫計劃「開源指北」，&lt;strong&gt;為國內百萬開發者進行了一次系統性定向科普&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2023 年開源中國發布 OSS Compass 開源指南針項目，針對開源社區的健康情況開展度量與分析，&lt;strong&gt;為構建可持續健康發展的開源生態提供支持&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;開源中國至今舉辦過 10 場超大型開源軟件評選活動，&lt;strong&gt;為數千國內優秀開源項目進行強效影響力傳播，累計帶來 10 億傳播量、100 萬+ 開發者參與&lt;strong&gt;&lt;strong&gt;投票&lt;/strong&gt;&lt;/strong&gt;、分享&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Gitee 上已經生長了 1500 萬公開倉庫，其中平台精心推薦優秀的開源項目超過 10 萬個，&lt;strong&gt;用數量與質量，讓中國開發者感知技術與創新新動態&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;開源中國線下源創會技術沙龍，已成功舉辦 113 期、覆蓋 21 座城市，&lt;strong&gt;免費向開發者、創業者、學生及社會公眾開放，現場參會人數超過 1.5 萬，線上的知識傳播超過千萬&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;……&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以上種種，&lt;strong&gt;並不以追求直接商業利益為出發點，但卻構建了堅實的中國開源生態基礎&lt;/strong&gt;。從技術入門到項目治理、從教育培訓到社區服務，開源中國以無償分享和公益服務，激發了本土開發者的熱情和創新力，為中國開源生態的可持續發展注入持久動力。從操作系統到數據庫，從中間件到編譯工具鏈，開源中國見證了無數國產開源軟件的成長，也助推了國產技術體系的構建。&lt;/p&gt; 
&lt;p&gt;中國開源生態的土壤，孕育了 DeepSeek 的碩果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d61dff4351a6d04ab3d9d63c6b2eb364ac7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-36e8f8a9e16456c3c87748746a2e54ef27a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;圖片截選自 2020 年開源中國 12 週年開源人寄語&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;路漫漫其修遠兮，吾將上下而求索&lt;/h1&gt; 
&lt;p&gt;理想之外，總需現實支撐。維持如此體量的社區、平台與運營，光靠公益難以持續。公益的背後是成本，帶寬費用、服務器維護、人力成本、活動組織、技術支持……同時，商業模式的不確定、團隊資源的平衡問題、外界質疑的聲音，都幾度讓開源中國這條路舉步維艱。&lt;/p&gt; 
&lt;p&gt;但開源中國始終堅信：&lt;strong&gt;真正屬於中國的開源生態，不能僅靠海外平台託底，更不能只做「公益樣板」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;於是，開源中國開始嘗試商業化探索，試圖找到一條「反哺」的可持續之路。&lt;/p&gt; 
&lt;p&gt;從技術廣告、人才服務，到面向企業的代碼管理解決方案，再到如今的模力方舟大模型平台、DevOps 工具鏈、AI 創造力平台……開源中國不斷尋找開源生態資產與企業需求之間的連接點，打造兼具商業價值與技術深度的產品矩陣，提供解決企業軟件研發管理與過程痛點的服務。&lt;/p&gt; 
&lt;p&gt;然而，這一路走來並不容易。&lt;/p&gt; 
&lt;p&gt;增值服務：針對企業用户推出私有化部署、定製化技術支持與運維服務。雖然在技術實力與交付效率上獲得了認可，但如何平衡付費與免費用户的體驗差異，一度成為難題。&lt;/p&gt; 
&lt;p&gt;廣告與贊助：引入精準廣告、技術廠商贊助及冠名合作，為社區帶來穩定收入。然廣告與公益精神的邊界並非易察，過度商業化可能侵蝕用户體驗，也讓我們在理想與現實間反覆斟酌。&lt;/p&gt; 
&lt;p&gt;培訓與認證：聯合行業導師、學術機構開展企業內訓與開源認證考試。培訓項目獲得了政府與企業的關注，卻也面臨師資、課程體系不斷迭代的壓力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;每一次嘗試都伴隨着質疑與爭議，有人擔憂開源中國商業化會削弱開源本質，也有人質疑我們的服務是否值得付費。正是在各種考驗中，我們不斷修正航向，力求在公益與經營中找到最佳平衡點。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2025 年戰略部署會上，開源中國正式公佈了未來核心增長路徑 —— &lt;strong&gt;錨定 AGI 發展趨勢，基於自身十餘年沉澱之開源與開發者生態&lt;/strong&gt;，以&lt;strong&gt;模力方舟&lt;/strong&gt;為 AI 技術基座，通過 &lt;strong&gt;AI 工具、AI 教育與 AI 應用市場&lt;/strong&gt;三大業務矩陣協同發力，構建從底層能力支撐到場景化落地的全棧生態體系。&lt;/p&gt; 
&lt;p&gt;作為戰略核心的模力方舟，定位為 AI 模型即服務（MaaS）平台，為三大業務線提供通用 AI 能力支持。在此基座上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;AI 工具板塊以 Gitee SaaS 與私有化部署為雙引擎，將軟件工程全面升級為 AI 增強（AI Enhance）開發範式，實現項目管理、代碼生成、智能測試、自動化運維的全鏈路提效；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 教育依託 OSCHINA 社區、Gitee 平台與教育培訓體系的深度融合，從 K12 少年培養到企業數字化人才賦能，貫穿技術普及、實踐訓練與認證輸出的全生命週期；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 應用市場聚焦打通 AI 技術到產業場景的 「最後一公里」，通過匯聚開發者生態與企業需求，構建 AI 應用的部署與交易平台。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這一戰略架構以技術普惠為核心邏輯，模力方舟作為底層能力基座，通過標準化 AI 模型接口與開發工具鏈，降低技術應用門檻；AI 教育從內容生態、人才儲備到技術認證，為行業輸送適配 AI 時代的技術人才；AI 工具與 AI 應用市場則分別從生產力工具革新和場景化解決方案落地兩端，形成 「能力輸出 - 需求匹配 - 價值閉環」 的商業化鏈路。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-06a01cc7c89390263d8b6685da244be57eb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開源中國經歷了從開源社區到代碼託管平台，再到 DevOps 研發效能平台的演進，從公益起家，到探索商業模式，發展歷程充滿了艱辛和堅持，如今完成了從流量聚合到商業化閉環的蜕變。這一歷程中，不僅為中國開源生態注入了活力，更推動了企業研發效能的規模化提升，驗證了開源技術商業化的可行路徑。&lt;/p&gt; 
&lt;p&gt;如今，開源中國正式邁向 「&lt;strong&gt;AI&lt;/strong&gt; &lt;strong&gt;驅動型技術服務商&lt;/strong&gt;」 的新階段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;縱向貫通&lt;/strong&gt;：以教育培育生態、以工具提升效率、以市場兑現價值，形成從人才儲備到技術落地的完整閉環。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;橫向聯動&lt;/strong&gt;：三大業務線數據互通、資源協同 —— 社區教育為工具平台輸送人才，AI 市場反哺開發者生態，工具迭代驅動教育內容升級，構建自循環的增長飛輪。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;社會價值&lt;/strong&gt;：通過降低 AI 使用門檻，助力中小企業與製造業、金融等傳統行業實現智能化轉型；以國產信創技術築牢安全底座，推動自主可控的 AI 基礎設施在政務、金融等關鍵領域落地，保障國家信息安全與產業鏈韌性，踐行 「技術普惠」 初心的同時，扛起守護數字主權的時代責任。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b40aa033333177220c600602030d2f65768.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;無論平台規模如何擴大，開源中國始終強調初心未改：相信開源技術的力量、肩負國家戰略責任，為開發者和社會創造價值。從推動每一行代碼的創造力，到賦能千行百業的數字化轉型，開源中國正以 AI 為槓桿，撬動技術商業化與產業智能化的雙重革命。這一進程，正在悄然重塑中國技術生態的未來圖景。&lt;/p&gt; 
&lt;p&gt;回首，望月，獨酌。2013 年開源中國五週年之際，創始人紅薯寫下的那份「迷茫與堅定」，與君共勉：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#27ae60"&gt;2008 年 8 月 31 日，開源中國上線，到今天剛好是 5 週年的日子。5 年來我們懷揣夢想、堅持不懈在做一件很多人認為是很「傻」的事情，之間也走過不少的彎路，但最終還是回到「傻」的路上。哪位牛人説過，傻的事情堅持做到極致，就會很牛。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#27ae60"&gt;而我們離牛還有十萬八千里，沒有筋斗雲，但不缺意志和情懷，再加上有你的支持，夢想終將實現。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352812</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352812</guid>
      <pubDate>Fri, 09 May 2025 08:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華為發佈準萬億模型盤古 Ultra MoE</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;華為推出參數規模 7180 億的新模型——盤古 Ultra MoE，這是一個全流程在昇騰 AI 計算平台上訓練的準萬億 MoE 模型。主要的架構和訓練特性如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;超大規模和超高稀疏比：採用 256 個路由專家，每個 token 激活 8 個專家，模型總參數量 718B，激活量 39B。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;MLA 注意力機制：引入 MLA（Multi-head Latent Attention），有效壓縮 KV Cache 空間，緩解推理階段的內存帶寬瓶頸，優於傳統 GQA 方案。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;MTP 多頭擴展：採用單頭 MTP 進行訓練，後續複用 MTP 參數擴展至多頭結構，實現多 Token 投機推理，加速整體推理過程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Dropless 訓練：採用 Dropless 訓練可以避免 Drop&amp;amp;Pad 訓推不一致問題，並且提升訓練的數據效率。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;RL 訓練：採用迭代難例挖掘與多能力項均衡的獎勵函數，並參考 GRPO 算法，提升了模型的訓練效率與最終推理性能。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;華為同時發佈盤古 Ultra MoE 模型架構和訓練方法的技術報告。在訓練方法上，華為首次披露在昇騰 CloudMatrix 384 超節點上，打通大稀疏比 MoE 強化學習（RL）後訓練框架的關鍵技術，使 RL 後訓練進入超節點集羣時代。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="259" src="https://oscimg.oschina.net/oscnet/up-7b9f1ffdf190c5090e951e17d2e2fc2e3e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，近期發佈的盤古 Pro MoE 大模型，在參數量為 720 億，激活 160 億參數量的情況下，在大模型榜單 SuperCLUE 的 2025 年 5 月排行榜上，位居千億參數量以內大模型排行並列國內第一。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352810</guid>
      <pubDate>Fri, 09 May 2025 08:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV 社區五月動態：多篇高質量論文、RWKV-8 第一個新特性公佈！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;歡迎大家收看《RWKV 社區最新動態》，本期內容收錄了 RWKV 社區 2025 年 5 月的最新動態。&lt;/p&gt; 
&lt;p&gt;只需 3 分鐘，快速瞭解 RWKV 社區 5 月都有哪些新鮮事！&lt;/p&gt; 
&lt;h2&gt;5 月動態省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 學術研究動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新論文：Multi-View Learning with Context-Guided Receptance for Image Denoising（RWKV 圖像去噪，已被 &lt;strong&gt;IJCAI 主會接收&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization（RWKV 模型量化，已&lt;strong&gt;入選 ICML2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：QuantumRWKV：Quantum-Enhanced Channel Mixing in RWKV Models for Time Series Forecasting（RWKV 量子增強時序預測）&lt;/li&gt; 
   &lt;li&gt;新論文：DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor（基於 RWKV-7 的圖像和文本壓縮）&lt;/li&gt; 
   &lt;li&gt;新論文：Maximizing Asynchronicity in Event-based Neural Networks（基於 RWKV-6 的事件相機異常檢測）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKV-X: A Linear Complexity Hybrid Language Model（RWKV 混合模型架構）&lt;/li&gt; 
   &lt;li&gt;新論文：Multiple Span Bidirectional RWKV Network for Infrared Image Super-Resolution（RWKV 紅外圖像超分）&lt;/li&gt; 
   &lt;li&gt;新論文：RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale（RWKV 模型轉換）&lt;/li&gt; 
   &lt;li&gt;新論文：Spatio-Temporal Weighted Graph Reason Learning for Multivariate Time-Series Anomaly Detection（RWKV 時序異常檢測）&lt;/li&gt; 
   &lt;li&gt;新論文：ModRWKV:Transformer Multimodality in Linear Time（多模態的 RWKV）&lt;/li&gt; 
   &lt;li&gt;新論文：RainRWKV:a deep RWKV model for video deraining（基於 RWKV 的視頻去雨）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新聞動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV7 G1 2.9B 發佈，同參數量全面登頂&lt;/li&gt; 
   &lt;li&gt;RWKV-8 "Heron" 第一個新特性發布&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區活動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 亮相澳門和深圳雙展&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區項目動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;rwkv7-g1-1.5b-Lonely-Neko：基於 RWKV-7 G1 1.5B 微調的對話模型，角色十分可愛。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 學術研究動態&lt;/h2&gt; 
&lt;p&gt;RWKV 學術研究包括 &lt;strong&gt;基於 RWKV 架構的新論文&lt;/strong&gt; 或 &lt;strong&gt;RWKV 社區參加的學術研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Multi-View Learning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Multi-View Learning with Context-Guided Receptance for Image Denoising&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.02705" target="_blank"&gt;https://arxiv.org/abs/2505.02705&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該論文基於 RWKV 模型提出 CRWKV 架構，通過引入雙向 BiWKV 機制突破因果約束，實現線性複雜度的像素序列交互。結合 Context-guided Token Shift (CTS) 機制增強噪聲分佈建模，並通過 Frequency Mix 模塊整合頻域特徵，在圖像去噪任務中取得 SOTA 效果，推理時間減少 40%。&lt;/p&gt; 
&lt;p&gt;該論文因其在圖像去噪任務中的優秀性能，已被 &lt;strong&gt;IJCAI 主會&lt;/strong&gt;接收&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250505-CRWKV" src="https://oscimg.oschina.net/oscnet/up-229703c0bda82e3a13ed08c135eb94044f5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKVQuant&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.03803" target="_blank"&gt;https://arxiv.org/abs/2505.03803&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-02&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 RWKVQuant，一種專門針對 RWKV 模型的訓練後量化框架。通過結合標量量化和向量量化技術，並設計基於信息熵的代理策略與碼本優化算法，該框架成功將 RWKV-14B 模型壓縮至約 3 位寬，在精度損失小於 1% 的同時實現 2.14 倍加速。&lt;/p&gt; 
&lt;p&gt;實驗證明瞭該方法在語言和視覺任務上的有效性，是首個針對 RWKV 家族的完整量化解決方案。&lt;/p&gt; 
&lt;p&gt;憑藉優秀的模型壓縮技術，論文成功入選 &lt;strong&gt;ICML2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250502-RWKVQuant" src="https://oscimg.oschina.net/oscnet/up-58830cf70ab2eb692dfe3a0c61630d68a77.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;QuantumRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Quantum-Enhanced Channel Mixing in RWKV Models for Time Series Forecasting&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.13524" target="_blank"&gt;https://arxiv.org/abs/2505.13524&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 QuantumRWKV 模型，將 RWKV 模型中的前饋網絡部分替換為變分量子電路，以增強非線性表示能力。&lt;/p&gt; 
&lt;p&gt;實驗證明，該模型在處理非線性或混沌動力學的時間序列任務中表現更優。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250518-QuantumRWKV" src="https://oscimg.oschina.net/oscnet/up-f2ee4a0f44d9f4da2f4fff1435397d8c76b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DualComp&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.16256" target="_blank"&gt;https://arxiv.org/abs/2505.16256&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-22&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 DualComp，一種 RWKV-7 的統一雙模態無損壓縮器，首次實現了圖像和文本數據的統一無損壓縮。&lt;/p&gt; 
&lt;p&gt;DualComp 在圖像和文本數據集上的壓縮性能實現 SOTA，且參數更少，支持桌面 CPU 上的近實時推理。其單模態變體在 Kodak 數據集上以僅 1.2% 的模型大小超越了之前的最佳圖像壓縮器約 9%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="2025-05-30-DualComp" src="https://oscimg.oschina.net/oscnet/up-990732815cf759d045f10da3ac395229c03.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Maximizing Asynchronicity&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱： Maximizing Asynchronicity in Event-based Neural Networks&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.11165" target="_blank"&gt;https://arxiv.org/abs/2505.11165&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種新的異步到同步框架 EVA，用於實時事件相機數據處理。&lt;/p&gt; 
&lt;p&gt;該框架基於 RWKV-6 構建了高效的異步編碼器，實現了逐事件的表示更新，並採用自監督學習方法獲得具有高度泛化能力的事件表示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250516-Maximizing Asynchronicity in Event-based Neural Networks" src="https://oscimg.oschina.net/oscnet/up-8ebaa25e8f5f1b314c0c1223d0b2f0c7e08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-X&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：RWKV-X: A Linear Complexity Hybrid Language Model&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2504.21463" target="_blank"&gt;https://arxiv.org/abs/2504.21463&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-04-30&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 RWKV-X 混合語言模型，通過將 RWKV 的短程建模效率與新型稀疏注意力機制結合，顯著提升了長上下文處理能力。&lt;/p&gt; 
&lt;p&gt;該模型在 64K token 序列上持續預訓練後，在長上下文基準測試中超越前期 RWKV-7 模型，同時保持線性訓練時間複雜度和恆定推理解碼複雜度，支持百萬級 token 序列解碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250430-RWKV-X ALinear Complexity Hybrid Language Model" src="https://oscimg.oschina.net/oscnet/up-ddce43b585415759724a7eb31efff3221af.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Multiple Span Bidirectional RWKV Network&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Multiple Span Bidirectional RWKV Network for Infrared Image Super-Resolution&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs13042-025-02644-7" target="_blank"&gt;https://link.springer.com/article/10.1007/s13042-025-02644-7&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-04-30&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種基於 RWKV 模型的多跨度雙向 MSB-RWKV 網絡用於紅外圖像超分辨率。&lt;/p&gt; 
&lt;p&gt;通過改進 RWKV 的注意力機制，設計了 MSB-WKV 線性複雜度全局注意力模塊和 Wide Shift 局部特徵增強層，實現了紅外圖像長程依賴建模與局部細節恢復的高效平衡。&lt;/p&gt; 
&lt;p&gt;實驗表明該方法在紅外圖像超分辨率任務中優於現有技術。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250430-Multiple Span Bidirectional RWKV Network" src="https://oscimg.oschina.net/oscnet/up-5ac04a911ee6ef5e1817f6f68c773bf5a81.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RADLADS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.03005" target="_blank"&gt;https://arxiv.org/abs/2505.03005&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出 RADLADS 框架，通過注意力蒸餾將傳統 softmax attention 的 Transformer 高效轉換為線性注意力模型。&lt;/p&gt; 
&lt;p&gt;基於 RWKV 架構開發了兩種新型變體 RAD-RWKV6 和 RAD-RWKV7，顯著改善了現有 RWKV 架構在模型轉換中的兼容性問題，並在 7B 至 72B 參數量級上實現了接近原模型的推理質量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250505-RADLADS" src="https://oscimg.oschina.net/oscnet/up-2bc7c79ab77dc710884f64ea38bb2c62682.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;STWGRL&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Spatio-Temporal Weighted Graph Reason Learning for Multivariate Time-Series Anomaly Detection&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11002535" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11002535&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-12&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了 STWGRL 框架，用於多元時間序列異常檢測。其核心貢獻包括基於 D-RWKV 模塊高效捕獲長期序列信息，結合 TaGAA 模塊自適應聚合信號特徵.&lt;/p&gt; 
&lt;p&gt;平衡了檢測精度、時間成本和可靠性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250512-Spatio-Temporal Weighted Graph Reason Learning" src="https://oscimg.oschina.net/oscnet/up-13f594016700c48cec9f111982f6580bbc8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;ModRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：ModRWKV:Transformer Multimodality in Linear Time&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.14505" target="_blank"&gt;https://arxiv.org/abs/2505.14505&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-20&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種基於 RWKV-7 架構的 ModRWKV 框架，探索了現代 RNN 架構在多模態場景下的應用。&lt;/p&gt; 
&lt;p&gt;ModRWKV 通過動態自適應的異構模態編碼器實現多源信息融合，並通過廣泛的實驗確定了性能與計算效率之間的最佳平衡。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250520-ModRWKV Transformer Multimodality in Linear Time" src="https://oscimg.oschina.net/oscnet/up-0ba1e789c2d58fed12110549cf9bddf3953.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RainRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：RainRWKV:a deep RWKV model for video deraining&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs00371-025-03965-y" target="_blank"&gt;https://link.springer.com/article/10.1007/s00371-025-03965-y&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種基於 RWKV 模型的 RainRWKV 框架，用於視頻去雨任務。通過引入小波變換移位機制和管狀嵌入機制，分別增強了模型對低頻特徵和高頻細節的捕捉能力。&lt;/p&gt; 
&lt;p&gt;在視頻去雨任務中實現了卓越的性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250524-RainRWKV a deep RWKV model for video deraining" src="https://oscimg.oschina.net/oscnet/up-3ed80af638e58aeadb73e9a2ac31f0d2bbf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型新聞動態&lt;/h2&gt; 
&lt;h3&gt;RWKV7-G1 2.9B 發佈&lt;/h3&gt; 
&lt;p&gt;2025 年 5 月 20 日，RWKV 基金會開源發佈了 RWKV7-G1 2.9B 推理模型（Reasoning Model）。RWKV7-G1 2.9B 相較於之前的所有版本模型均有很大提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV-G1 2.9B MMLU" src="https://oscimg.oschina.net/oscnet/up-456ff4b2c554edb382d7ce756d4b276abdb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJN-InNN0UgELLgYpwoTfLA" target="_blank"&gt;RWKV7-G1 2.9B 推理模型開源發佈，展示數學/代碼/全球語言能力，已適配手機 app&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-8 "Heron" 新特性&lt;/h3&gt; 
&lt;p&gt;2025 年 5 月 26 日，RWKV 的作者彭博上傳了 RWKV-8 "Heron" 的第一個新特性；&lt;/p&gt; 
&lt;p&gt;RWKV-8 "Heron" 是 RWKV 的下一代架構，具有多個全新技術。在此首先公佈的是 DeepEmbed 技術，它可以實現類似 MoE 的優秀推理性能，同時無需佔用顯存，甚至無需佔用內存，可以讓稀疏的大模型真正部署到所有端側設備。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV-8 &amp;quot;Heron&amp;quot; DeepEmbed" src="https://oscimg.oschina.net/oscnet/up-576de10644681dd5c253a5eea81be69f6d4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 預覽之 DeepEmbed：對端側友好的稀疏設計，解決 MoE 顯存佔用&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;社區活動&lt;/h2&gt; 
&lt;h3&gt;RWKV 亮相雙展&lt;/h3&gt; 
&lt;p&gt;5 月 22 至 24 日，元始智能同時參加了澳門 BEYOND EXPO 以及 2025 全球人工智能終端展，並首次公開展示基於 RWKV-7 模型的 5 款端側 AI 應用 demo，呈現人工智能模型在離線環境下的技術突破。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV-in-BEYOND_EXPO" src="https://oscimg.oschina.net/oscnet/up-a1ff63c29537cc62c8e05fddbd5c87f756e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;詳細報道&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F24XV1zv0pFohGS5KXSE5tw" target="_blank"&gt;RWKV-7 新 app 亮相雙展：聚焦端側推理及多模態&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;社區項目動態&lt;/h2&gt; 
&lt;h3&gt;rwkv7-g1-1.5b-Lonely-Neko&lt;/h3&gt; 
&lt;p&gt;基於 RWKV--G1-1.5B 的單角色推理模型，擁有較為優秀的單角色 rp 能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="lonly-cat" src="https://oscimg.oschina.net/oscnet/up-8f201c0d2aa449202664f2228e49c88f178.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;rwkv7-g1-1.5b-Lonely-Neko 模型地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FSeikaijyu%2Frwkv7-g1-1.5b-Lonely-Neko" target="_blank"&gt;https://huggingface.co/Seikaijyu/rwkv7-g1-1.5b-Lonely-Neko&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352796</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352796</guid>
      <pubDate>Fri, 09 May 2025 08:21:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Yandex 發佈全球最大事件數據集，助力推薦系統發展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;推出了當前可用的全球最大的推薦系統數據集，推動全球範圍內的研究與開發工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;該開放數據集包含通過&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;音樂流媒體服務歷時&lt;/span&gt;&lt;span&gt; 10 &lt;/span&gt;&lt;span&gt;個月收集的&lt;/span&gt;&lt;span&gt; 47.9 &lt;/span&gt;&lt;span&gt;億條匿名的用户交互數據（收聽、喜歡、不喜歡）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;該數據集包含匿名的音頻嵌入向量&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:white"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#444746"&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;自然交互標記和精確時間戳，支持用於真實行為分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;引入全局時間分割&lt;/span&gt;&lt;span&gt; (GTS) &lt;/span&gt;&lt;span&gt;評估方法保持事件序列，並配套基線算法作為參考。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;該數據集在&lt;/span&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fyandex%2Fyambda" target="_blank"&gt;&lt;span&gt;&lt;span style="color:#1155cc"&gt;Hugging Face&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;平台提供三種規模：&lt;/span&gt;&lt;span&gt;50 &lt;/span&gt;&lt;span&gt;億、&lt;/span&gt;&lt;span&gt;5 &lt;/span&gt;&lt;span&gt;億和&lt;/span&gt;&lt;span&gt; 5000 &lt;/span&gt;&lt;span&gt;萬事件量級，滿足多樣化研發需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;發佈了&lt;/span&gt;&lt;span&gt; Yambda&lt;/span&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;Yandex Music Billion-Interactions Dataset&lt;/span&gt;&lt;span&gt;，即&lt;/span&gt;&lt;span&gt; Yandex Music &lt;/span&gt;&lt;span&gt;十億級交互數據集），這是全球最大的推薦系統開放數據集，包含近&lt;/span&gt;&lt;span&gt; 50 &lt;/span&gt;&lt;span&gt;億條來自其音樂流媒體平台&lt;/span&gt;&lt;span&gt; Yandex Music &lt;/span&gt;&lt;span&gt;的用户與音軌的匿名交互數據。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" height="675" src="https://oscimg.oschina.net/oscnet/up-614d00c695553af44b3275a2fb0c8b551c8.png" width="1200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yambda, &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;全球最大的推薦系統開放數據集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yambda &lt;/span&gt;&lt;span&gt;可作為通用基準來測試推薦系統的新方法和算法，適用於電子商務、社交網絡和短視頻平台等所有使用推薦系統的領域。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;研究人員可藉助該數據集基於其基線模型開發和測試新的推薦算法，從而加速創新進程。數據資源有限的初創企業可以先利用&lt;/span&gt;&lt;span&gt; Yambda &lt;/span&gt;&lt;span&gt;數據集構建和測試系統，然後再擴展規模。這有助於在全球範圍內加快特定於業務需求的先進技術開發進程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彌合研究與產業的鴻溝&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;訓練數據的質量與規模對於流媒體服務、社交網絡、短視頻應用和電商等平台提供相關的推薦內容而言至關重要。然而，推薦系統領域的研究已落後於大語言模型等迅速發展的領域，其主要原因便是缺乏大規模數據集。效果良好的推薦模型需要&lt;/span&gt;&lt;span&gt; TB &lt;/span&gt;&lt;span&gt;級的行為數據，商業平台雖然擁有這些數據但卻極少公開分享。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" height="711" src="https://oscimg.oschina.net/oscnet/up-b1d269d239695e6fe89e17e2484712d2ddf.png" width="1560" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集統計的軌跡分佈&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;研究人員通常只能獲得規模較小且過時的數據集，難以反映現代使用場景的複雜性：&lt;/span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Spotify &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;的百萬歌單&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;數據集對於商業級推薦系統而言規模過小。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Netflix Prize&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;數據集包含約&lt;/span&gt;&lt;span&gt; 17,000 &lt;/span&gt;&lt;span&gt;個項目且時間戳僅包含日期，限制了時序建模和大規模研究。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Criteo 1TB &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;點擊日誌&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;數據集缺乏合適的文檔和標識符，且只關注廣告點擊。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:white"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:black"&gt;「推薦系統天生與敏感數據緊密相關。企業只有在進行充分的匿名化處理後才能公開發布推薦系統數據集，這一過程會耗費大量資源，減緩了開放創新的步伐。」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="color:black"&gt;Yandex &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="color:black"&gt;推薦系統負責人&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="color:black"&gt; Nikolai Savushkin &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="color:black"&gt;解釋道。&lt;/span&gt;&lt;/span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據短缺導致了落差的出現：學術表現優異的模型在現實應用中往往表現不佳。將推薦系統與先進架構加以整合的工作也因缺乏合適的訓練數據而受限。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yambda &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集簡介&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yambda &lt;/span&gt;&lt;span&gt;提供的海量匿名數據集來自其月活用户約&lt;/span&gt;&lt;span&gt; 2800 &lt;/span&gt;&lt;span&gt;萬的音樂流媒體服務，解決了推薦系統面臨的挑戰。&lt;/span&gt;&amp;nbsp; &lt;span&gt;該數據集揭示了用户與&lt;/span&gt;&lt;span&gt; Yandex Music &lt;/span&gt;&lt;span&gt;平台內容的交互方式，該平台以其先進的&lt;/span&gt;&lt;span&gt; &lt;em&gt;My Wave&lt;/em&gt; &lt;/span&gt;&lt;span&gt;推薦系統著稱，能夠根據每位用户的品味定製收聽體驗。為保護隱私，所有用户和音軌數據均已匿名化，採用數字標識符以符合隱私標準。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" height="1369" src="https://oscimg.oschina.net/oscnet/up-a9033463c19a195492b478c4e79cf2df9e8.png" width="1560" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集統計的用户內容交互歷史&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集主要特性：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;歷時&lt;/span&gt;&lt;span&gt; 10 &lt;/span&gt;&lt;span&gt;個月收集的&lt;/span&gt;&lt;span&gt; 47.9 &lt;/span&gt;&lt;span&gt;億條匿名的用户交互數據。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;來自&lt;/span&gt;&lt;span&gt; 100 &lt;/span&gt;&lt;span&gt;萬用户的數據以及&lt;/span&gt;&lt;span&gt; 939 &lt;/span&gt;&lt;span&gt;萬條音軌的匿名描述符。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;包含兩種反饋類型：隱式交互（收聽）和顯式交互（喜歡、不喜歡及其撤銷）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供音頻嵌入向量（通過卷積神經網絡生成的向量表示）及音軌的匿名信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;設有「&lt;/span&gt;&lt;span&gt;is_organic&lt;/span&gt;&lt;span&gt;」標記，區分用户是自主發現音軌還是通過推薦發現，便於進行更深入的行為分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所有事件均帶有時間戳，從而支持對用户行為的時序分析，使模型能夠在更接近真實使用場景的條件下接受評估。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集以&lt;/span&gt;&lt;span&gt; Apache Parquet &lt;/span&gt;&lt;span&gt;格式發佈，兼容&lt;/span&gt;&lt;span&gt; Spark&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Hadoop &lt;/span&gt;&lt;span&gt;等分佈式處理系統和&lt;/span&gt;&lt;span&gt; Pandas&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Polars &lt;/span&gt;&lt;span&gt;等分析庫。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;Yambda &lt;/span&gt;&lt;span&gt;讓研究人員能驗證創新性假設，讓企業能構建更智能的推薦系統。最終，用户將會受益，能夠輕鬆找到符合需求的的歌曲、商品或服務。」&lt;/span&gt;&lt;span&gt;Nikolai Savushkin &lt;/span&gt;&lt;span&gt;補充説道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集版本與評估&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yambda &lt;/span&gt;&lt;span&gt;數據集提供三種規模：約&lt;/span&gt;&lt;span&gt; 50 &lt;/span&gt;&lt;span&gt;億、&lt;/span&gt;&lt;span&gt;5 &lt;/span&gt;&lt;span&gt;億和&lt;/span&gt;&lt;span&gt; 5000 &lt;/span&gt;&lt;span&gt;萬事件量級，滿足需求和算力資源條件不同的研究人員與開發者。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;數據集的不同規模&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:solid windowtext 1.0pt"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:black; border-style:solid; border-width:1.0pt; vertical-align:top; width:99.0pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;數據集&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:black; border-left:none; border-style:solid; border-width:1.0pt; vertical-align:top; width:55.7pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;用户數&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:black; border-left:none; border-style:solid; border-width:1.0pt; vertical-align:top; width:77.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;項目數&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:black; border-left:none; border-style:solid; border-width:1.0pt; vertical-align:top; width:80.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;收聽數&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:black; border-left:none; border-style:solid; border-width:1.0pt; vertical-align:top; width:77.65pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;喜歡數&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:black; border-left:none; border-style:solid; border-width:1.0pt; vertical-align:top; width:77.35pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;不喜歡數&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:black; border-style:solid; border-top:none; border-width:1.0pt; vertical-align:top; width:99.0pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yambda-50M&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:55.7pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;10,000&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;934,057&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:80.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;46,467,212&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.65pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;881,456&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.35pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;107,776&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:black; border-style:solid; border-top:none; border-width:1.0pt; vertical-align:top; width:99.0pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yambda-500M&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:55.7pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;100,000&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3,004,578&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:80.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;466,512,103&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.65pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;9,033,960&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.35pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1,128,113&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:black; border-style:solid; border-top:none; border-width:1.0pt; vertical-align:top; width:99.0pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yambda-5B&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:55.7pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1,000,000&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;9,390,623&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:80.4pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;4,649,567,411&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.65pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;89,334,605&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom:solid windowtext 1.0pt; border-left:none; border-right:solid windowtext 1.0pt; border-top:none; vertical-align:top; width:77.35pt"&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;11,579,143&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據集採用全局時間分割&lt;/span&gt;&lt;span&gt; (GTS) &lt;/span&gt;&lt;span&gt;進行評估，該方法按時間戳劃分數據以保持事件序列。與留一法&lt;/span&gt;&lt;span&gt; (Leave-One-Out) &lt;/span&gt;&lt;span&gt;從每個用户的歷史記錄中移除最後一次正向交互以用於測試的做法不同，&lt;/span&gt;&lt;span&gt;GTS &lt;/span&gt;&lt;span&gt;避免破壞訓練集和測試集之間的時序依賴，模擬了未來數據不可用的現實條件，讓模型測試更為真實。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" height="935" src="https://oscimg.oschina.net/oscnet/up-0793b6fba6944cacf478f47e21eebb0f5b5.png" width="1560" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;採用全局時間分割&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; (GTS) &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的評估方案&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基線實現包括&lt;/span&gt;&lt;span&gt; MostPop&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;DecayPop&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;ItemKNN&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;iALS&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;BPR&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;SANSA &lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt; SASRec&lt;/span&gt;&lt;span&gt;，為比較新推薦系統方法提供基準。這些基線通過標準指標進行評估，包括：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;NDCG@k&lt;/span&gt;&lt;span&gt;（排序質量）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Recall@k&lt;/span&gt;&lt;span&gt;（檢索效果）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Coverage@k&lt;/span&gt;&lt;span&gt;（目錄多樣性）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「當行業領袖共享寶貴的工具和數據時，所有人都會從中受益：研究人員獲得真實的基準，初創企業獲得原本只屬於科技巨頭的資源，全球用户得以享受更優質的個性化體驗。」&lt;/span&gt;&lt;span&gt;Nikolay Savushkin &lt;/span&gt;&lt;span&gt;補充説道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yambda&lt;/span&gt;&lt;span&gt;，全球最大的推薦系統開放數據集，現已在&lt;/span&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fyandex%2Fyambda" target="_blank"&gt;&lt;span&gt;&lt;span style="color:#1155cc"&gt;Hugging Face&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;發佈。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;簡介&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;是一家全球性的科技公司，專注於打造由機器學習驅動的智能產品與服務。公司宗旨為幫助消費者和企業更好地應對線上與線下世界的挑戰。自&lt;/span&gt;&lt;span&gt; 1997 &lt;/span&gt;&lt;span&gt;年以來，&lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;持續提供世界級、本地化的搜索與信息服務，併為全球數百萬消費者開發了市場領先的按需出行服務、導航產品及其他移動應用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;My Wave &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;簡介&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;My Wave &lt;/span&gt;&lt;span&gt;是集成於用户規模達數百萬的音樂流媒體服務&lt;/span&gt;&lt;span&gt; Yandex Music &lt;/span&gt;&lt;span&gt;中的個性化推薦系統，採用深度神經模型和&lt;/span&gt;&lt;span&gt; AI &lt;/span&gt;&lt;span&gt;算法分析千餘項因素，包括用户交互、可定製的情緒&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;語言設置，以及對聲譜圖、頻率範圍、節奏、聲調和流派等的實時音樂分析。通過處理收聽歷史記錄和音軌序列來動態適應用户偏好、識別音頻相似性並預測音樂品味，從而提供量身定製的推薦內容&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352793</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352793</guid>
      <pubDate>Fri, 09 May 2025 08:14:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>大白話聊一聊：AI 下半場，Agent 的本質與變革</title>
      <description/>
      <link>https://my.oschina.net/u/9379757/blog_beta/18497991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9379757/blog_beta/18497991</guid>
      <pubDate>Fri, 09 May 2025 08:07:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic CEO：未來五年 AI 可能取代一半入門級白領工作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在最近的一次採訪中，Anthropic 公司的首席執行官 Dario Amodei 發出了一個引人注目的警告。他表示，隨着人工智能 (AI) 技術的快速發展，未來五年內，可能會有一半的入門級白領工作被取代，而失業率則可能飆升至 10% 到 20%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Amodei 強調，許多工人並沒有意識到這種變化即將到來，很多人對此感到難以置信。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="306" src="https://oscimg.oschina.net/oscnet/up-ad5abb6f041838a751dcd5a4689af5eb0e6.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Amodei 指出，AI 技術的進步將使得很多工作從輔助人類轉變為完全自動化。他預測，這種轉變可能在未來兩年內開始顯現。隨着越來越多的工作被 AI 取代，社會將面臨更大的經濟不平等，普通人創造經濟價值的能力下降將威脅到民主和財富的平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管前景嚴峻，Amodei 依然對 AI 的潛力抱有希望。他提到，AI 不僅可能取代工作，還能在其他領域取得顯著進展，例如醫療行業。Amodei 表示，未來可能出現 「治癒癌症、經濟增長 10%、預算平衡，但 20% 的人沒有工作」 的局面。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;為了應對即將到來的變化，Amodei 提出了一些建議，包括提高公眾對 AI 發展的認識，以幫助人們更好地規劃自己的職業路徑。他還強調了 AI 素養的重要性，呼籲人們學習如何利用 AI 來增強自己的工作能力，以便適應未來的職業環境。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Amodei 還呼籲政策制定者更加重視 AI 發展對經濟的影響，思考在超智能經濟背景下的政策解決方案。他認為，隨着數字化轉型的推進，雖然某些工作會被取代，但也會創造出新的就業機會。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352775</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352775</guid>
      <pubDate>Fri, 09 May 2025 07:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Hugging Face 發佈兩款開源人形機器人，最低僅售 250 美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;AI 開發平台 Hugging Face 發佈了&amp;nbsp;HopeJR 和 Reachy Mini 兩款開源人形機器人。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="756" src="https://static.oschina.net/uploads/space/2025/0530/144447_jYDa_2720166.png" width="579" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;HopeJR&amp;nbsp;是全尺寸人形機器人，具備&amp;nbsp;66&amp;nbsp;個驅動自由度（即&amp;nbsp;66&amp;nbsp;個獨立動作），包括行走和手臂運動能力。Reachy Mini&amp;nbsp;則是桌面版機器人，能夠轉動頭部、説話、聆聽，並可用於測試&amp;nbsp;AI&amp;nbsp;應用。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0530/144531_7p8m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Hugging Face&amp;nbsp;尚未公佈這兩款機器人的具體發貨時間表。公司聯合創始人兼 CEO&amp;nbsp;Clem Delangue&amp;nbsp;表示，預計今年年底前至少能交付首批產品，目前等候名單已開放註冊。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;據 Hugging Face 估算，HopeJR 單價約為 3000 美元，Reachy Mini 價格區間在 250 至 300 美元之間，具體取決於關税政策。"關鍵在於這些機器人是開源的，任何人都能組裝、重構、理解其運作原理，同時價格親民，這樣機器人技術就不會被少數掌握危險黑箱系統的大公司壟斷。"Delangue 強調。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;此次機器人發佈部分得益於公司對仿人機器人初創企業 Pollen Robotics 的收購——據 Delangue 透露，該收購於四月公佈。他補充説，Pollen 團隊為 Hugging Face 提供了開發這些機器人所需的"新能力"。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/344615/hugging-face-buys-a-humanoid-robotics-startup-pollen-robotics"&gt;開源 AI 平台 Hugging Face 收購法國開源機器人公司 Pollen Robotics&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352772/hugging-face-unveils-two-new-humanoid-robots</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352772/hugging-face-unveils-two-new-humanoid-robots</guid>
      <pubDate>Fri, 09 May 2025 06:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里雲人工智能平台 PAI 開源 EasyDistill 框架助力大語言模型輕鬆瘦身</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：汪誠愚（熊兮）、嚴俊冰（玖燭）、蔡文睿（清素）、嶽元浩（顧城）、黃俊（臨在）&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;前言&lt;/h1&gt; 
&lt;p&gt;隨着大型語言模型（LLM）的複雜性和規模不斷增長，對於許多研究人員和企業而言，如何有效地利用這些龐大的模型變得愈發重要。然而，巨大的計算需求和訓練成本為模型的廣泛應用設置了障礙。知識蒸餾是一種將大模型的知識轉移到小模型的方法，其核心思想是在不顯著降低性能的前提下，通過訓練將複雜的模型轉化為更小、更高效的版本。通過這種方式，知識蒸餾不僅能夠有效降低計算成本，還能夠提高模型在資源受限環境中的適應性，從而為大規模應用提供可能。在此背景下，阿里雲人工智能平台（PAI）推出了一款新的開源工具包——EasyDistill（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelscope%2Feasydistill" target="_blank"&gt;https://github.com/modelscope/easydistill&lt;/a&gt;），旨在簡化大型語言模型的知識蒸餾過程，助力參數量更小但性能卓越的大模型的實際應用。除了 EasyDistill 本身，這一框架還包括了蒸餾大模型 DistilQwen 系列以及相應的開源數據集，供用户使用，其中包括一百萬條通用指令遵循數據和兩百萬條思維鏈推理數據。尤其是， DistilQwen 系列最新的變長思維鏈推理蒸餾模型 DistilQwen-ThoughtX 能夠根據任務難度輸出變長思維鏈，其 32B 版本推理能力超越了 DeepSeek 官方蒸餾模型。&lt;/p&gt; 
&lt;p&gt;在下文中，我們詳細描述 EasyDistill 的框架功能，包括對應的 DistilQwen 模型以及其對應開源數據集。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;1. EasyDistill 框架功能&lt;/h1&gt; 
&lt;p&gt;在本節中，我們將深入討論 EasyDistill 的功能模塊及其在知識蒸餾中的各類應用細節。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;1.1 基本架構和功能簡介&lt;/h2&gt; 
&lt;p&gt;EasyDistill 的基礎架構如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img height="394" src="https://static.oschina.net/uploads/space/2025/0530/140055_1Z8q_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;1.2 數據合成&lt;/h3&gt; 
&lt;p&gt;在訓練大語言模型過程中，合成數據起着至關重要的作用。尤其在知識蒸餾階段，種子數據集的規模通常有限，使合成數據的使用顯得尤為必要。我們在 EasyDistill 框架中集成了多種數據合成和增強操作，這些操作利用了專有和開源的教師模型，使訓練集不僅在數量上增加，還在任務、主題或領域的多樣性方面得到了提升。&lt;/p&gt; 
&lt;p&gt;EasyDistill 支持的第一組操作專注於合成各種 NLP 任務的指令數據。框架引入了多項功能，包括指令擴展、指令優化，以及從原始文本中自動生成指令-響應對等。具體而言，指令擴展通過增加指令數據集的數量，使模型能夠獲取更加豐富的上下文信息，從而提升訓練集的知識覆蓋率；指令優化則涉及去除冗餘信息並提高指令的明確性，確保模型回覆質量更高；自動生成指令-響應對的功能使得模型能夠從非結構化文本中提取知識，為訓練數據集註入更多的多樣性。&lt;/p&gt; 
&lt;p&gt;EasyDistill 框架的第二組操作專注于思維鏈，這是蒸餾大規模推理模型的重要組成部分。除生成思維鏈的算子外，我們進一步整合了用於簡化和擴展思維鏈的算子。思維鏈簡化算子通過減少模型推理的複雜性，使思維鏈更加清晰和連貫，提升模型在推理過程中的效率。思維鏈擴展算子則能夠在複雜問題上提供更多詳細步驟和邏輯鏈，從而增強模型解決複雜問題的能力。&lt;/p&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;1.3 基礎蒸餾訓練&lt;/h3&gt; 
&lt;p&gt;在基礎蒸餾訓練模塊中，EasyDistill 提供了黑盒化和白盒化的模型蒸餾訓練功能。對於專有的閉源大語言模型，由於只能訪問模型的輸出，其黑盒化知識蒸餾主要依賴於監督微調（SFT），將這些輸出視為學生模型的真實值進行訓練。這種方法操作簡單，但在數據有限的情況下，其效果可能受到限制。值得注意的是，EasyDistill 框架支持所有符合 OpenAI 格式的閉源模型 API，例如 OpenAI、DashScope、PAI-EAS 等。&lt;/p&gt; 
&lt;p&gt;針對開源的教師語言模型，EasyDistill 訓練層提供了一種更為精細的白盒化訓練策略。除了進行 SFT 之外，我們還利用教師模型的隱藏知識進行指導。這種方式能夠顯著提升效果。具體而言，我們從教師模型獲取 token 級別的 logits，通過最小化教師模型與學生模型 logits 分佈之間的差異來優化訓練表現。為此，EasyDistill 框架採用了包括 Kullback–Leibler 散度（KLD）和反向 KLD 在內的多種損失函數。根據我們的研究，模型的前 10 個概率最大的 token 的概率之和幾乎為 1。因此，EasyDistill 允許用户選擇僅使用教師模型中前 top-k 的 token logits，並與學生模型的對應 logits 進行匹配。隨後，在計算損失函數時，我們僅考慮這 k 個選定的 logits 進行近似計算。這種策略不僅降低了計算時間，而且加快了 logits 的存儲和讀取速度。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;1.4 進階蒸餾訓練&lt;/h3&gt; 
&lt;p&gt;上述黑盒化和白盒化模型蒸餾訓練的核心原則在於讓學生模型模仿教師模型的行為。然而，這種方法可能導致學生模型"過擬合"教師模型的輸出，從而限制其泛化能力的提升。為解決這一問題，EasyDistill 框架在訓練層引入了基於強化學習（RL）和偏好優化的方法，通過教師模型的反饋來訓練學生模型。&lt;/p&gt; 
&lt;p&gt;在強化學習中，決定模型優化上限的一個核心因素是高質量的獎勵模型（Reward Model）。EasyDistill 支持的首項功能是利用教師模型的反饋來訓練獎勵模型，這類似於從 AI 反饋中進行強化學習（RLAIF）框架。具體而言，我們使用教師模型生成的選擇和拒絕回覆作為偏好數據，並利用這些數據訓練獎勵模型。一旦獎勵模型建立，便可通過各種強化學習算法優化學生模型。為此，EasyDistill 集成了多種流行算法用於訓練學生模型，特別是對通用大語言模型的近端策略優化（Proximal Policy Optimization，PPO）和用於優化推理模型的羣體相對策略優化（Group Relative Policy Optimization，GRPO）。&lt;/p&gt; 
&lt;p&gt;然而，RL 算法的一個潛在缺點是訓練過程中的不穩定性。為此，EasyDistill 還引入了偏好優化的方法，將偏好直接融入大模型中以實現更穩定的訓練過程。在這一框架下，我們集成了直接偏好優化（Direct Preference Optimization，DPO）算法，直接利用選擇和拒絕的回覆作為偏好數據來優化學生模型。對於推理模型，蒸餾後的小模型一般具有與大模型不同的認知能力。為此，EasyDistill 引入了我們提出的認知偏好優化（CogPO）算法，通過與模型的認知能力對齊，進一步增強小模型的推理能力。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;2. 初步體驗 EasyDistill&lt;/h2&gt; 
&lt;p&gt;為了適應不同的使用需求，EasyDistill 採用了模塊化設計。用户可以依據具體的任務場景選擇適合的模塊進行組合和應用。我們也提供了簡潔的命令行接口使得用户能夠方便地運行各種知識蒸餾算法。以下是使用 EasyDistill 的一些基本步驟。&lt;/p&gt; 
&lt;p&gt;2.1 克隆代碼庫：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/modelscope/easydistill
cd EasyDistill
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.2 安裝必要的依賴：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python setup.py install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.3 通過命令行界面探索 EasyDistill 的使用：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-plain"&gt;easydistill --config &amp;lt;config-file-path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;配置文件可為不同的知識蒸餾任務設定具體的參數和路徑，如下提供了一個黑盒化蒸餾訓練的配置示例：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "job_type": "kd_black_box_local",
  "dataset": {
    "instruction_path": "train.json",
    "labeled_path": "train_labeled.json",
    "template" : "chat_template/chat_template_kd.jinja",
    "seed": 42
  },
  "inference":{
    "enable_chunked_prefill": true,
    "seed": 777,
    "gpu_memory_utilization": 0.9,
    "temperature": 0.8,
    "trust_remote_code": true,
    "enforce_eager": false,
    "max_model_len": 4096,
    "max_new_tokens": 512
  },
  "models": {
    "teacher": "teacher/Qwen/Qwen2.5-7B-Instruct/",
    "student": "student/Qwen/Qwen2.5-0.5B-Instruct/"
  },
  "training": {
    "output_dir": "./result/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "max_length":512,
    "save_steps": 1000,
    "logging_steps": 1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;教師模型也可以使用閉源的 API 進行配置，示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "job_type": "kd_black_box_api",
  "dataset": {
    "instruction_path": "train.json",
    "labeled_path": "train_labeled.json",
    "template" : "./chat_template/chat_template_kd.jinja",
    "seed": 42
  },
  "inference":{
    "base_url": "ENDPOINT",
    "api_key": "TOKEN",
    "stream": true,
    "system_prompt" : "You are a helpful assistant.",
    "max_new_tokens": 512
  },
  "models": {
    "student": "student/Qwen/Qwen2.5-0.5B-Instruct/"
  },
  "training": {
    "output_dir": "./result/",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "max_length":512,
    "save_steps": 1000,
    "logging_steps": 1,
    "learning_rate": 2e-5,
    "weight_decay": 0.05,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "cosine"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;用户只需要指定大模型對應的 base_url 和 api_key 即可，無需配置其他教師大模型的信息。&lt;/p&gt; 
&lt;span id="OSC_h1_8"&gt;&lt;/span&gt; 
&lt;h1&gt;3. DistilQwen：基於 EasyDistill 的蒸餾開源模型家族&lt;/h1&gt; 
&lt;p&gt;在 EasyDistill 的支持下，我們開發了一系列基於通義千問開源框架的蒸餾語言模型，稱為 DistilQwen。這些模型充分利用知識蒸餾的方法，能夠在減少模型參數量的同時保持高性能表現。這些蒸餾模型特別適用於資源受限的環境。同時，我們在 EasyDistill 框架的 Recipes 模塊中提供了這些蒸餾算法的使用指引。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 DistilQwen 之 System 1 模型&lt;/h2&gt; 
&lt;p&gt;在大語言模型框架中，System 1 模型使用直覺型的任務解決機制來回答用户的指令。由於這些模型的輸出 token 量較少，其推理速度更快。在 DistilQwen 系列中，我們開源了 DistilQwen2 和 DistilQwen2.5 兩個模型系列。其中，DistilQwen2 是 Qwen2 模型的增強版本，具備改進的指令跟隨能力，以適應各種自然語言處理任務。我們使用 GPT-4 和 Qwen-max 作為教師模型來生成高質量的回覆，同時平衡輸入指令的任務分佈。在蒸餾訓練過程中，我們首先採用 SFT 訓練，之後通過 DPO 算法進行偏好優化，以增強學生模型與教師模型之間的對齊。&lt;/p&gt; 
&lt;p&gt;DistilQwen2.5 系列模型是 DistilQwen2 的升級版本，以 Qwen2.5 模型作為底座，使用黑盒和白盒知識蒸餾算法的結合進行訓練。我們首先使用與 DistilQwen2 相同的指令數據處理和黑盒 SFT 訓練過程。隨後，我們進一步採用白盒化的 logitis 優化對齊訓練，以完善學生對教師模型中複雜知識的獲取。這裏，我們使用 Qwen2.5-72B-Instruct 作為開源教師模型。下表展示了 DistilQwen2 和 DistilQwen2.5 與原始模型性能表現的對比。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5ee4284859a3d30ed6f13daabc0365c5344.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 DistilQwen 之 System 2 模型&lt;/h2&gt; 
&lt;p&gt;與 System 1 模型不同，System 2 模型使用慢思考模式，對複雜問題的解決首先輸出思維鏈，其次給出問題的解答，從而顯著提升了模型的深度推理能力，在 DistilQwen 系列中，我們首先推出 DistilQwen2.5-R1 系列模型，使用 DeepSeek-R1 作為教師模型。為了使更小的蒸餾模型在推理能力上與其內在的認知能力相匹配，我們進一步使用提出的 CogPO 算法對思維鏈進行精細化處理。&lt;/p&gt; 
&lt;p&gt;此外，我們將 DeepSeek-V3-0324 的快思維推理能力轉移到 DistilQwen2.5-DS3-0324 模型中。為了縮短推理過程，我們使用 CoT 簡化算子來減少 DistilQwen2.5-R1 訓練數據中的 token。結合重寫的 CoT 數據集，以及 DeepSeek-V3-0324 的 CoT 蒸餾數據，我們訓練了 DistilQwen2.5-DS3-0324 系列模型。下圖展示了 DistilQwen2.5-R1 和 DistilQwen2.5-DS3-0324 的性能表現。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-39eafd1fb8a6e36e26f873e11875f03f196.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 DistilQwen 最新發布：變長思維鏈推理模型 DistilQwen-ThoughtX&lt;/h2&gt; 
&lt;p&gt;深度推理模型的一個問題是，他們對於各種輸入問題都輸出較長的思維鏈進行推理；然而，不適合的思維鏈可能反而使得模型推理能力下降。因此，提升模型推理能力的關鍵是模型根據問題難度和自身能力，實現自適應的變長思維鏈推理。最新的 DistilQwen 系列是 DistilQwen-ThoughtX，與之前的 DistilQwen 模型以及其他開源蒸餾模型相比，它具有更強的推理能力，並可以生成了長度更為優化的推理鏈。這一模型系列的訓練集為我們推出的具有兩百萬條思維鏈的 OmniThought 開源數據集，我們對於每條思維鏈數據都進行推理冗餘度（Reasoning Verbosity，RV）和認知難度（Cognitive Difficulty，CD）評分，確保模型獲得高質量的思維鏈訓練數據。DistilQwen-ThoughtX 在開源社區中表現甚至優於 DeepSeek 官方採用閉源數據集蒸餾的模型。下表展示了 DistilQwen-ThoughtX 的性能表現：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-535aab891ce37611535192ba2f7ee68183a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DistilQwen 所有模型均可以 HuggingFace 和 ModelScope 開源社區中進行下載。&lt;/p&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;4. 開源數據集&lt;/h1&gt; 
&lt;p&gt;本章介紹基於 EasyDistill 框架的開源數據集，這些數據集集用於訓練 DistilQwen 系列模型，分為兩個系列：指令遵循系列和思維鏈推理系列。&lt;/p&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 指令遵循數據集&lt;/h2&gt; 
&lt;p&gt;社區開發者在微調 DistilQwen 模型時，容易發生災難性遺忘的現象。為了緩解這一問題，我們開源了用於訓練 DistilQwen2 和 DistilQwen2.5 系列模型的兩個子集：DistilQwen_100K 和 DistilQwen_1M。這些數據集也可以用於提升其他類似大型語言模型在指令遵循方面的能力。這些數據集涵蓋了數學、代碼、基於知識的問答以及創造性生成等內容，總數據集規模分別為 10 萬和 100 萬。用户可以在模型微調過程中將 DistilQwen_100K 和 DistilQwen_1M 或其子集與自己的數據結合使用，以提升模型在下游任務的效果。&lt;/p&gt; 
&lt;span id="OSC_h2_14"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 思維鏈推理數據集&lt;/h2&gt; 
&lt;p&gt;OmniThought 是用於訓練 DistilQwen-ThoughtX 的大規模思維鏈推理數據集。我們從開源社區蒐集大量推理問題以及對應的思維鏈，並且使用 DeepSeek-R1 和 QwQ-32B 生成更多的思維鏈，對於每條思維鏈，我們也使用上述模型驗證其正確性，總共獲得了 200 萬條思維鏈。對於 OmniThought 的每一個思維鏈，我們都給出提出的推理冗餘度（RV）和認知難度（CD）評分，這些評分描述了 CoT 冗長程度和模型對於上述思維鏈的認知難度等級。因此，在蒸餾推理小模型時，可以根據上述評分篩選出更優的思維鏈子集進行訓練。在前文中，我們也展示了，訓練出的 DistilQwen-ThoughtX 的表現甚至優於 DeepSeek 官方採用閉源數據集蒸餾的模型。&lt;/p&gt; 
&lt;p&gt;所有這些數據集都可以在 HuggingFace 和 ModelScope 上公開下載，彙總如下表。&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;數據集&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;類別&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;數據量&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;下載鏈接&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DistilQwen_100K&lt;/td&gt; 
   &lt;td&gt;指令遵循&lt;/td&gt; 
   &lt;td&gt;10 萬&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Falibaba-pai%2FDistilQwen_100k" target="_blank"&gt;下載鏈接&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DistilQwen_1M&lt;/td&gt; 
   &lt;td&gt;指令遵循&lt;/td&gt; 
   &lt;td&gt;100 萬&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Falibaba-pai%2FDistilQwen_1M" target="_blank"&gt;下載鏈接&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OmniThought&lt;/td&gt; 
   &lt;td&gt;思維鏈推理&lt;/td&gt; 
   &lt;td&gt;200 萬&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Falibaba-pai%2FOmniThought" target="_blank"&gt;下載鏈接&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id="OSC_h1_15"&gt;&lt;/span&gt; 
&lt;h1&gt;5. 本文小結&lt;/h1&gt; 
&lt;p&gt;本文介紹了阿里雲人工智能平台 PAI 推出的開源工具包 EasyDistill。隨着大語言模型的複雜性和規模增長，它們面臨計算需求和訓練成本的障礙。知識蒸餾旨在不顯著降低性能的前提下，將大模型轉化為更小、更高效的版本以降低訓練和推理成本。EasyDistill 框架簡化了知識蒸餾過程，其具備多種功能模塊，包括數據合成、基礎和進階蒸餾訓練。通過數據合成，豐富訓練集的多樣性；基礎和進階蒸餾訓練則涵蓋黑盒和白盒知識轉移策略、強化學習及偏好優化，從而提升小模型的性能。&lt;/p&gt; 
&lt;p&gt;基於 EasyDistill 框架，我們進一步開源了 DistilQwen 模型系列，並且提供了蒸餾技術的實際應用案例 EasyDistill-Recipes。特別地，DistilQwen 模型系列的最新版本額 DistilQwen-ThoughtX 實現了變長思維鏈輸出，其推理能力超越了其他開源蒸餾模型。此外，本文還介紹了 EasyDistill 框架的開源數據集，包括 100 萬條指令遵循和 200 萬條思維鏈推理數據集，以支持社區開發者的使用和進一步提升模型性能。所有數據集均可在 HuggingFace 和 ModelScope 平台獲取。&lt;/p&gt; 
&lt;p&gt;在未來，我們將進一步擴展 EasyDistill 框架的功能，開源更多 DistilQwen 模型系列和相應資源。歡迎大家加入我們，一起交流大模型蒸餾技術！&lt;/p&gt; 
&lt;span id="OSC_h1_16"&gt;&lt;/span&gt; 
&lt;h1&gt;6. 參考工作&lt;/h1&gt; 
&lt;p&gt;相關論文&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chengyu Wang, Junbing Yan, Wenrui Cai, Yuanhao Yue, Jun Huang. EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models. arXiv preprint&lt;/li&gt; 
 &lt;li&gt;Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang. Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations. arXiv preprint&lt;/li&gt; 
 &lt;li&gt;Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang. Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv preprint&lt;/li&gt; 
 &lt;li&gt;Chengyu Wang, Junbing Yan, Yuanhao Yue, Jun Huang. DistilQwen2.5: Industrial Practices of Training Distilled Open Lightweight Language Models. &lt;strong&gt;ACL 2025&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. &lt;strong&gt;COLING 2025&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. &lt;strong&gt;EMNLP 2024&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;技術介紹&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882" target="_blank"&gt;DistilQwen2：通義千問大模型的知識蒸餾實踐&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842" target="_blank"&gt;DistilQwen2.5 發佈：通義千問蒸餾小模型再升級&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1659288" target="_blank"&gt;DistilQwen2.5-R1 發佈：知識蒸餾助推小模型深度思考&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1661734" target="_blank"&gt;人工智能平台 PAI DistilQwen2.5-DS3-0324 發佈：知識蒸餾+快思考=更高效解決推理難題&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1635146" target="_blank"&gt;基於多輪課程學習的大語言模型蒸餾算法 TAPIR&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;歡迎大家在評論區互動留言哦！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5583868/blog/18507743</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18507743</guid>
      <pubDate>Fri, 09 May 2025 06:15:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>通義靈碼 AI IDE 正式上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;阿里雲&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FfZHEZDeTza1P1Df8Lqk73A" target="_blank"&gt;發佈&lt;/a&gt;旗下首個 AI 原生的開發環境工具通義靈碼 AI IDE，適配了最新的千問 3 大模型，全面集成通義靈碼插件能力，具備編程智能體、行間建議預測、行間會話等功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不僅可以輔助寫代碼、修 BUG，還擁有自主決策、MCP 工具調用、工程感知、記憶感知等能力，可幫助開發者完成複雜編程任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="395" src="https://oscimg.oschina.net/oscnet/up-19d9f95ddcd54f5f6b8bb3701d266105cd6.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;核心亮點&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;支持最強開源模型千問 3，其代碼能力達到業界領先水平，同時支持 MCP 協議，具備強大的工具調用能力，可以幫助開發者快速開發智能體應用。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;全面集成通義靈碼智能編碼助手（即通義靈碼插件）的能力，無需安裝插件開箱即用，直接體驗高效、智能的編程體驗。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自帶編程智能體模式，開發者只需描述編碼任務，通義靈碼便可以自主地進行工程感知、代碼檢索、執行終端、調用 MCP 工具等，端到端地幫助開發者完成編碼任務。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;全面支持長期記憶、行間建議預測（NES - Next Edit Suggestion）、行間會話（Inline Chat）等能力，為開發者帶來更絲滑、更智能的編程體驗。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;即日起用户可在通義靈碼官網免費下載開箱即用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352750</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352750</guid>
      <pubDate>Fri, 09 May 2025 05:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源鴻蒙開發者大會 2025 | 大屏生態分論壇：共建共享，共贏未來</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;5 月 24 日，開源鴻蒙開發者大會 2025（OHDC.2025）在深圳成功舉辦。在主論壇上隆重舉行了「開源鴻蒙 TV SIG」成立儀式，開源鴻蒙 TV SIG 旨在攜手產業夥伴，基於開源鴻蒙社區，構建 TV 關鍵技術能力、推動產業標準制定和落地、加強生態合作，促進大屏生態繁榮。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748243791996.jpg" height="397" src="https://oscimg.oschina.net/oscnet//f08a7f65f01594e4772bc1a8dbf5fe18.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;開源鴻蒙 TV SIG 成立儀式&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;大會期間，同步舉辦了以「共建共享，共贏未來」為主題的大屏生態分論壇，與會者圍繞開源鴻蒙 TV SIG 技術規劃、大屏應用、系統、產品、芯片及配件等關鍵技術的突破等 11 個熱點議題進行分享與交流，並就未來的發展方向進行了深入探討，全方位展示基於開源鴻蒙操作系統的大屏生態在創新實踐和落地應用方面的成果。本次論壇由開源鴻蒙 TV SIG 組長、華為終端 BG OpenHarmony 使能部大屏生態總監汪曙光擔任出品人。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748095725340.jpg" height="400" src="https://oscimg.oschina.net/oscnet//f95aca616e27866108c8f09233de0194.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;大屏生態分論壇圓滿舉辦&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;華為終端 BG OpenHarmony 使能部副部長李彥舉發表開幕致辭，向所有參與開源鴻蒙大屏生態共建的開發者及企業致謝，並高度評價了開源鴻蒙大屏建設所取得的階段性成果。基於對大屏行業的深度洞察與開源鴻蒙技術的演進趨勢，他指出：「開源鴻蒙大屏產業近年來取得了顯著的階段性成果，已進入高速發展期。」同時，他呼籲更多夥伴和開發者加入生態共建，加速推進大屏生態從技術驗證向規模商用的關鍵跨越，共同把握智慧顯示終端的時代機遇。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094733792.jpg" height="400" src="https://oscimg.oschina.net/oscnet//4c07280c955c0272410ab886b88a4d75.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;華為終端 BG OpenHarmony 使能部副部長李彥舉&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 組長汪曙光發表題為《開源鴻蒙 TV SIG 整體規劃及最新共建進展》的主題演講。他表示，TV SIG 將以「建能力、立標準、促生態、廣複製」為目標，攜手 SIG 成員及廣大生態夥伴，搭建社區大屏公共軟硬件平台，進行技術的孵化和生態的推動，並展示了 SIG 組的技術全景圖以及路標規劃。在演講中，汪曙光詳細介紹了大屏生態已取得的成果：完善了 10 多個系統應用和專有能力，推出了 9 個第三方應用（涵蓋應用市場、影音娛樂、工具遊戲等多個領域）和 4 顆媒體 SoC 主芯片（適用於 TV、商顯、盒子等多種設備）。在演講最後他提到，基於開源鴻蒙的大屏北向三方應用預計將於今年下半年取得階段性進展，SIG 組也將支撐夥伴孵化出更多商用產品。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094523003.jpg" height="400" src="https://oscimg.oschina.net/oscnet//a7e359acc75fe3a0f6b8ec4ee6247b0f.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;華為終端 BG OpenHarmony 使能部大屏生態總監汪曙光&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 副組長、北京風行在線技術有限公司高級技術專家韓超在論壇上做了《風行面向開源鴻蒙的大屏應用市場進展分享》的主題演講。作為內容運營服務商，風行始終致力於讓內容流動更簡單，併為數億用户提供了優質的數字文娛服務。韓超詳細介紹了風行在應用開發方面的技術方案和成功實踐，並將應用框架源碼開源至社區，幫助行業夥伴縮短開發週期。截止目前，風行已推出多款開源鴻蒙大屏應用，其中「橙子市場」作為開源鴻蒙大屏端首個應用市場，旨在為生態夥伴提供內容及應用分發服務，當前已上架的應用涵蓋了影視、遊戲、教育等多個品類。未來，風行將繼續攜手行業夥伴，鼓勵更多優質應用入駐，持續豐富應用種類，滿足用户多樣化需求。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748096718379.jpg" height="400" src="https://oscimg.oschina.net/oscnet//b36e555a2564efc5ea695920f223d0f8.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;北京風行在線技術有限公司高級技術專家韓超&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 副組長、華為終端 BG 智慧交互軟件開發部技術專家華紅寧帶來《面向開源鴻蒙的大屏 TV 子系統共建進展分享》議題演講。他詳細介紹了華為智慧屏的業務、產品願景及使命，並表達了通過共建共享，與開源鴻蒙生態夥伴攜手推動傳統大屏產業升級的期望。與此同時，他還分享了開源鴻蒙 TV 子系統的架構、業務分層以及核心業務的邏輯，並同步了最新的開發進展和後續規劃：通過開源共建，TV 子系統已取得顯著進展，預計上半年將完成核心功能開發，並將在下半年持續進行功能迭代與完善，後續版本也已規劃一系列新特性。他誠邀行業夥伴共同參與代碼共建，提升未來產品競爭力。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094429559.jpg" height="400" src="https://oscimg.oschina.net/oscnet//64b1c0ffb0c05af2188e54f4bd44a487.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;華為終端 BG 智慧交互軟件開發部技術專家華紅寧&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 副組長、四川長虹電子控股集團有限公司操作系統高級技術專家張帥做《長虹面向開源鴻蒙的大屏實踐分享和後續展望》議題分享，展示了長虹積極擁抱開源鴻蒙的堅定態度。他指出，長虹雲計算與大數據研究中心長期深度參與開源鴻蒙大屏社區共建，推動開源鴻蒙在智慧顯示終端領域的生態完善。作為重要共建單位，長虹積極貢獻遙控器拾音、分佈式白板應用等關鍵技術架構，完善了社區的技術能力。未來，長虹將持續深化與開源鴻蒙社區的合作，聚焦於開源鴻蒙教育大屏、開源鴻蒙 TV 等有屏設備以及工業智能終端、工業機器人等方向，推動開源鴻蒙能力平台與產業落地深度融合，為構建智能終端操作系統生態貢獻力量。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094348933.jpg" height="400" src="https://oscimg.oschina.net/oscnet//d0f9501b1f789e37dd1b7f5fa9617aa3.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;四川長虹電子控股集團有限公司操作系統高級技術專家張帥&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 副組長、海思技術有限公司產品規劃總監陳超帶來《上海海思媒體領域面向開源鴻蒙的探索與實踐》主題分享。他詳細介紹了上海海思全面擁抱開源鴻蒙的策略，強調了開源鴻蒙與上海海思芯片深度融合的整體解決方案優勢。他表述，開源鴻蒙與星閃技術的強強聯合，將有力推動 IoT、輕智能、泛媒體等領域智能化升級。在泛媒體終端領域，上海海思已有多款媒體類模組/開發板通過開源鴻蒙認證，涵蓋了會議平板、閨蜜機、直播機、智慧大屏等多種產品形態。上海海思正全面支持產業產品的創新發展，助力開源鴻蒙生態繁榮壯大。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094222303.jpg" height="400" src="https://oscimg.oschina.net/oscnet//a909faaeaf6fde97e87d16364f66f646.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;海思技術有限公司產品規劃總監陳超&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 成員、未來電視有限公司高級技術專家李欣做了《聚力開源鴻蒙，共啓央視頻 TV 未來》議題分享，詳細介紹了未來電視在 TV 端大屏應用——央視頻 TV 的發展歷程、平台架構演進，以及開源鴻蒙版本的開發與迭代計劃。未來，央視頻 TV 將在其開源鴻蒙版本中逐步集成靈犀觸控、互動卡片等創新功能，持續優化用户互動操控體驗。此外，央視頻 TV 將依託開源鴻蒙的人臉識別技術，在確保用户隱私安全的基礎上為不同用户羣體提供個性化的內容推薦和事件推送等陪伴功能，共同構建「有温度」的客廳場景。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094198385.jpg" height="400" src="https://oscimg.oschina.net/oscnet//79494ba3411ec64562368299d79375b0.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;未來電視有限公司高級技術專家李欣&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 成員、湖南國科微電子股份有限公司資深系統架構師劉傑兵帶來《國科微基於開源鴻蒙的芯片平台介紹》議題分享。他指出，基於開源鴻蒙行業發行版的芯片適配是點亮億級行業設備的關鍵。作為國內領先的集成電路設計企業，國科微在大型 SoC 及解決方案開發方面積累了豐富的實踐經驗，並積極推進開源鴻蒙芯片適配工作，為開源鴻蒙生態建設注入強勁動力。截至目前，國科微已獲得 5 張兼容性測評證書，涵蓋機頂盒、電視、商顯、攝像頭等多個應用場景，實現多個業內首款「開源鴻蒙認證」。未來，國科微將持續提速國科芯開源鴻蒙適配工作，並將於 2025 年第三季度和第四季度推出基於開源鴻蒙的 5.0 和 5.1 商用版本。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748094030027.jpg" height="400" src="https://oscimg.oschina.net/oscnet//5559f927312e65d35b7d709d0042a0b4.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;湖南國科微電子股份有限公司資深系統架構師劉傑兵&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 成員、上海視九信息科技有限公司總裁周雲龍發表《面向開源鴻蒙的大屏小程序平台介紹》主題演講。他介紹了公司研發的 JsView 引擎，其核心價值在於能為開源鴻蒙生態快速引入豐富的大屏小程序應用。作為在國內主流 OTT、IPTV 設備穩定運行多年的成熟引擎，JsView 以開發週期短、部署升級快、頁面流暢、特效豐富等優勢，成為行業開發標杆。目前，JsView 引擎已完成開源鴻蒙系統適配，基於該平台開發的央視國學苑、唱吧 K 歌等數十家頭部內容的小程序版本，可直接上線開源鴻蒙大屏設備。全新的內容或應用，也可經由該引擎快速開發融入開源鴻蒙生態。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748093944317.jpg" height="400" src="https://oscimg.oschina.net/oscnet//a898f363257fe799592ce06543915fdf.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;上海視九信息科技有限公司總裁周雲龍&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 成員、廣東辰奕智能科技股份有限公司研究院院長嚴開雲帶來《面向開源鴻蒙的大屏配件生態解決方案介紹》，並現場發佈首款基於開源鴻蒙的指向語音遙控器及生態配件產品。作為開源鴻蒙 TV 生態的亮點創新成果，該遙控器具備隔空觸控、智慧觸摸、近場語音及靈活批註等功能，兼容多類南向應用，靈活適配家庭娛樂場景需求，為用户帶來更智能、便捷的交互體驗。該產品的發佈，充分彰顯了開源鴻蒙在智能硬件領域的應用潛力。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748093884330.jpg" height="355" src="https://oscimg.oschina.net/oscnet//ddce8ae85d9bf552c25051f2be6dc184.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;span&gt;廣東辰奕智能科技&lt;/span&gt;&lt;span&gt;股份有限公司研究院院長嚴開雲&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 成員、鴻湖萬聯（江蘇）科技發展有限公司 PC 及大屏產品總監袁傑做《基於開源鴻蒙的教育及會議大屏產品實踐分享》主題分享。據介紹，軟通動力充分融合子公司鴻湖萬聯在開源鴻蒙領域的創新突破以及軟通計算機（原同方計算機）的硬件優勢，率先推出搭載 SwanLinkOS 天鴻操作系統的開源鴻蒙智能交互大屏產品，並完成跨系統跨終端形態的多屏協同、集成 DeepSeek 大模型應用、以及教育應用軟件的開源鴻蒙移植工作，為行業客户提供軟硬一體端到端的產品及服務能力。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="image_1748093734048.jpg" height="400" src="https://oscimg.oschina.net/oscnet//2aa19be11afd190576f6cfd3b6c1ccc2.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;鴻湖萬聯（江蘇）科技發展有限公司 PC 及大屏產品總監袁傑&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;開源鴻蒙 TV SIG 成員、江蘇潤開鴻數字科技有限公司開源鴻蒙應用架構師傅康帶來《基於開源鴻蒙文件管理器與 DeepSeek 的大屏開發實踐》議題分享，深入介紹文件管理器和 DeepSeek 在開源鴻蒙大屏上的實現方案及核心功能點，並針對大屏設備的交互特點，適配了遙控器走焦、靈犀操控功能。基於 DeepSeek 的語音助手還支持藍牙遙控器語音以及 ASR 語音轉文字等功能，顯著提升用户操控體驗的同時，也賦予大屏如家庭管家、家庭醫生和家庭教師等更多角色。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="420" src="https://oscimg.oschina.net/oscnet/up-09164b94d47d7cdd343f56dcd4c01cda5f4.png" width="632" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0px; margin-right:0px; text-align:center"&gt;江蘇潤開鴻數字科技有限公司開源鴻蒙應用架構師傅康&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;本次大屏生態分論壇內容豐富，活動現場人氣火爆，充分彰顯了大屏行業夥伴對開源鴻蒙大屏技術發展、生態進展的高度關注與殷切期待。同時，也印證了開源鴻蒙在大屏產業中擁有廣闊的發展前景，具備廣泛應用與行業創新的巨大潛力。誠摯歡迎更多開發者和企業加入開源鴻蒙 TV SIG 組，一起「共建共享，共贏未來」！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352735</guid>
      <pubDate>Fri, 09 May 2025 04:42:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>阿里巴巴開源 WebAgent：自主搜索 AI 智能體</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里巴巴開源了名為「WebAgent」的自主搜索 AI Agent 項目，包含兩部分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlibaba-NLP%2FWebAgent%2Fblob%2Fmain%2FWebDancer" target="_blank"&gt;&lt;strong&gt;WebDancer&lt;/strong&gt;&lt;/a&gt;：端到端智能體訓練框架，旨在增強基於網絡的 AI 智能體的多步驟信息搜索能力&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlibaba-NLP%2FWebAgent%2Fblob%2Fmain%2FWebWalker" target="_blank"&gt;&lt;strong&gt;WebWalker&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;：用於「Web 遍歷中的 LLM 基準測試」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9a799f9c85e59a1999e680b6812f85ed9cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;WebAgent 具備端到端的自主信息檢索與多步推理能力，就像人類一樣在網絡環境中主動感知、決策和行動，例如，當用户想了解某個特定領域的最新研究成果時，WebAgent 能夠主動搜索多個學術數據庫，篩選出最相關的文獻，並根據用户的需求進行深入分析和總結。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6e8c992c6702162b18ba98f97406ff76aed.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，WebAgent 不僅能識別文獻中的關鍵信息，還能通過多步推理將不同文獻中的觀點進行整合，最終為用户提供一份全面且精準的研究報告。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;WebAgent 開源地址：&lt;/p&gt; 
&lt;p&gt;Github：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlibaba-NLP%2FWebAgent" target="_blank"&gt;https://github.com/Alibaba-NLP/WebAgent&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WebDancer&amp;nbsp;論文：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2505.22648" target="_blank"&gt;https://arxiv.org/pdf/2505.22648&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WebWalker&amp;nbsp;論文：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2501.07572" target="_blank"&gt;https://arxiv.org/pdf/2501.07572&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352726/alibaba-nlp-web-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352726/alibaba-nlp-web-agent</guid>
      <pubDate>Fri, 09 May 2025 04:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>純前端實現圖片偽 3D 視差效果</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網前端團隊- Su Ning&lt;/p&gt; 
 &lt;p&gt;本文通過 depth-anything 獲取圖片的深度圖，同時基於 pixi.js，通過着色器編程，實現了通過深度圖驅動的偽 3D 效果。該方案支持鼠標/手勢與手機陀螺儀雙模式交互，在保證性能的同時，為不同終端用户提供沉浸式的視覺體驗。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本文提供配套演示代碼，可下載體驗：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvivo%2FBlueSnippets%2Ftree%2Fmain%2Fdemos%2Fparallax" target="_blank"&gt;Github | vivo-parallax&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;一、引言&lt;/h1&gt; 
&lt;p&gt;在當今的網頁設計與交互中，3D 效果能極大地提升用户的視覺體驗和沉浸感。但是 3D 的物料設計成本依然很高，不僅需要專門的設計師掌握專業的建模工具，而且高精度模型帶來的渲染壓力也使移動端適配變得困難。&lt;/p&gt; 
&lt;p&gt;在這樣的背景下，利用 2D 圖片實現偽 3D 的效果，就展現出獨特的價值。開發者能以極低的資源消耗，在常規圖片素材上構建出具有空間縱深的交互效果。這種技術路徑不僅規避了傳統 3D 內容生產的複雜性，同時實現了視覺效果與性能消耗的平衡。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9567e396aff3d86d2c93c6f4cff301b1.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;二、實現思路&lt;/h1&gt; 
&lt;p&gt;相比二維平面，三維物體多了一個 z 軸作為深度信息。要讓 2D 平面呈現 3D 縱深感，關鍵在於隨着視角偏移時，畫面中的物體產生不同程度的位移，從而營造前後視差，實現偽 3D 效果。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-90ddcc1a408f2b244f27f4ffd5d20ae38ae.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為此，我們可以通過深度圖來獲取圖片的深度信息，根據這些信息對圖片進行分層。當視角改變時，通過調整不同層的偏移來實現視差效果。&lt;/p&gt; 
&lt;h1&gt;三、獲取深度圖&lt;/h1&gt; 
&lt;p&gt;在前端獲取深度圖可以藉助現有的預訓練模型。例如使用 @huggingface/transformers 庫，指定任務類型為 'depth-estimation'，並選擇合適的預訓練模型，目前的深度圖推理模型尺寸普遍比較大，綜合效果和模型尺寸最終選擇了 'Xenova/depth-anything-small-hf'，量化後的模型尺寸為 27.5mb。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import { pipeline } from '@huggingface/transformers';
export async function depthEstimator(url) {
  const depth_estimator = await pipeline('depth-estimation', 'Xenova/depth-anything-small-hf');
  const output = await depth_estimator(url);
  const blob=await output.depth.toBlob()
  return URL.createObjectURL(blob)
}



&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;四、視差效果的實現&lt;/h1&gt; 
&lt;p&gt;若想借助深度圖實現圖片分層，可依據深度區間進行劃分。假設深度圖中純白的色值為 0，純黑色值為 1，若將圖片切分為兩層，那麼第一層的色值範圍為 0 - 0.5，第二層則是 0.5 - 1。為使畫面過渡更自然，可適當增加分層的數量。當鏡頭偏移時，層數越小的圖片位移幅度越大，層數越大的圖片位移幅度越小，藉此便能實現視差效果。&lt;/p&gt; 
&lt;p&gt;然而，簡單的分層會引發一個問題：不同層的位移可能導致上層的部分區域遮擋背景圖案，而另一側則會出現空白。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c0305e558112356ce847d32022d1a23c.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;針對空白部分，可採用光線步進算法進行顏色採樣。&lt;/p&gt; 
&lt;p&gt;在此，我們選用 Pixi.js 來實現這一效果。作為一款輕量級的 2D 渲染引擎，Pixi.js 在跨平台 2D 動畫、遊戲及圖形界面開發領域表現出色。其精靈支持自定義渲染管線，通過定製圖片片段着色器，能夠輕鬆實現視差效果。&lt;/p&gt; 
&lt;h2&gt;4.1 光線步進算法 (Ray Marching)&lt;/h2&gt; 
&lt;p&gt;首先我們獲取到需要採樣顏色的座標 ray_origin，並根據用户的交互事件（鼠標，觸摸，陀螺儀）增加鏡頭偏移 offset。得到光線發射的起始座標。&lt;/p&gt; 
&lt;p&gt;設置採樣步數 step，設置光線的偏移向量 ray_direction，每一步將光線增加 ray_direction/step 的座標。獲取到當前深度圖座標的深度信息，由於顏色越淺數值越大，要對深度值進行反轉，比對此時光線的 z 軸是否大於深度的反轉值，如果滿足條件則挑出循環，取此時光線座標圖片的顏色。&lt;/p&gt; 
&lt;p&gt;由於每一步增加的偏移值可能跨度比較大，即使滿足 z 軸大於深度反轉值的條件，但是二者值的差距依然過大，我們還需要做一個二分搜索來優化採樣結果。即偏移值大於深度值，但二者的差值大於閾值的時候，回退一步光線，並將步進值再除以 2，可以顯著提升採樣的精度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//54767b356af2c1b4fa087f8d93fbfb39.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;代碼實現&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;varying vec2 vTextureCoord;
uniform sampler2D depthMap;
uniform sampler2D uSampler;
uniform vec3 offset;
const float enlarge = 1.06;

vec3 perspective(vec2 uv) {
  const int step_count = 5;
  
  vec3 ray_origin = vec3(uv - 0.5, 0);
  ray_origin.xy -= offset.xy;
  
  vec3 ray_direction = vec3(0, 0, 1);
  ray_direction.xy += offset.xy;
  ray_direction /= float(step_count);
  
  const float hit_threshold = 0.01;
  vec4 color = vec4(0.0);
  for (int i = 0; i &amp;lt; step_count; i++) {
    ray_origin += ray_direction;
    float scene_z = 1.0 - texture2D(depthMap, ray_origin.xy + 0.5).x;
    if (ray_origin.z &amp;gt; scene_z) {
      if (ray_origin.z - scene_z &amp;lt; hit_threshold) {
        break;
      }
    ray_origin -= ray_direction;
    ray_direction /= 2.0;
    }
  }
  color = texture2D(uSampler, ray_origin.xy + 0.5);
  return color.rgb;
}

void main(void ) {
  vec2 uv = (vTextureCoord - vec2(0.5)) / vec2(enlarge) + vec2(0.5);
  gl_FragColor = vec4(
    perspective(uv),
    1.0
  );
}



&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;五、深度圖膨脹&lt;/h1&gt; 
&lt;p&gt;邊緣膨脹操作主要用於處理深度圖，通過對每個像素鄰域內的深度值進行分析和處理，增強圖像的邊緣，可以使視差圖的邊緣更加平滑。這裏使用一個簡單的膨脹函數實現。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//8c26cdb94e5befa90dd742e95f27223b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;varying vec2 vFilterCoord;
varying vec2 vTextureCoord;
uniform float widthPx;
uniform float heightPx;
uniform float dilation;
uniform sampler2D uSampler;
const int MAX_RADIUS = 10;

float dilate(vec2 uv, vec2 px) {
  float maxValue = 0.0;
  float minValue = 1.0;
  for (int x = -MAX\_RADIUS; x &amp;lt;= +MAX_RADIUS; x++) {
    for (int y = -MAX\_RADIUS; y &amp;lt;= +MAX_RADIUS; y++) {
      vec2 offset = vec2(float(x), float(y));
      if (length(offset) &amp;gt; float(MAX_RADIUS)) continue;
      offset *= px;
      vec2 uv2 = uv + offset;
      float val = texture2D(uSampler, uv2).x;
      maxValue = max(val, maxValue);
      minValue = min(val, minValue);
    }
  }
  
  return dilation &amp;lt; 0.0
  ? minValue
  : maxValue;
}

  

void main(void ) {
  const float dilationScale = 1.26;
  float dilationStep = abs(dilationScale * dilation) / float(MAX_RADIUS);
  float aspect = widthPx / heightPx;
  vec2 px =
    widthPx &amp;gt; heightPx
      ? vec2(dilationStep / aspect, dilationStep)
      : vec2(dilationStep, dilationStep * aspect);
  gl_FragColor = vec4(vec3(dilate(vTextureCoord, px)), 1.0);

}



&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;六、總結&lt;/h1&gt; 
&lt;p&gt;綜上所述，我們先利用預訓練模型生成圖片的深度圖，再借助 Pixi.js 與光線步進算法達成視差效果，最終通過對深度圖進行膨脹處理，實現邊緣的平滑過渡。&lt;/p&gt; 
&lt;p&gt;通過上面的操作，我們成功實現了圖片的偽 3D 效果，為用户帶來了更具沉浸感的視覺體驗。&lt;/p&gt; 
&lt;p&gt;在實際應用過程中，我們觀察到，當視角偏移幅度過大時畫面會出現採樣失真現象。為解決這一問題，後續可考慮採用動態調整光線步進參數的方法，根據視角變化實時優化光線傳播路徑，從而減少採樣誤差；或者引入屏幕空間遮擋關係，通過精準模擬物體間的遮擋效果，增強畫面的真實感與層次感。隨着 WebGPU 技術的逐步普及，這一方案還有極大的優化空間。我們可藉助計算着色器強大的並行計算能力，對複雜的 3D 計算任務進行高效處理，進一步提升計算性能，為網頁端 3D 交互開闢更多可能性，打造更加流暢、逼真的 3D 交互場景。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18506522</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18506522</guid>
      <pubDate>Fri, 09 May 2025 03:45:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Ubuntu 優化發版機制：每月發佈快照更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Ubuntu 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fsupercharging-ubuntu-releases-monthly-snapshots-automation%2F61876" target="_blank"&gt;宣佈&lt;/a&gt;其發版機制引入一項新變化：從 5 月份開始，他們將會每月發佈測試版 Ubuntu 快照 (Monthly Snapshots)。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0530/111832_awMb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這一機制並非取代現有的每六個月一次的常規發佈，而是通過現代發佈工程實踐，在保持穩定性的同時優化測試與構建流程。&lt;/p&gt; 
&lt;p&gt;月度快照作為開發預覽，被定義為「精心策劃的可測試里程碑」，有助於減少人為幹預並增加自動化測試，從而提升發佈透明度與效率。Canonical 工程師 Jon Seager 表示，該機制將幫助 Ubuntu 在保留核心優勢的基礎上，更好地應對軟件開發中的新挑戰。&lt;/p&gt; 
&lt;p&gt;首個快照以「Ubuntu 25.10 Snapshot 1」形式命名，&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fquesting-snapshot-1-released%2F61889" target="_blank"&gt;已於 5 月 29 日發佈&lt;/a&gt;&lt;/u&gt;，並在後續幾個月持續更新，最終於 10 月 9 日推出穩定版本。這標誌着 Ubuntu 在靈活性與穩定性之間邁出了重要一步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/352709/ubuntu-releases-monthly-snapshots-automation</link>
      <guid isPermaLink="false">https://www.oschina.net/news/352709/ubuntu-releases-monthly-snapshots-automation</guid>
      <pubDate>Fri, 09 May 2025 03:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
