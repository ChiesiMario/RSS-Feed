<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 12 Jun 2025 02:42:22 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>特朗普政府新 AI 計劃「AI.gov」在 GitHub 上被泄露</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farchive.is%2Fhfl2Z"&gt;根據相關備份資料&lt;/a&gt;，美國總務管理局（GSA）在 GitHub 上發佈的一個早期版本的網站和代碼顯示，該聯邦政府正在開發一個名為 「ai.gov」 的網站和 API，旨在 「用 AI 加速政府創新」，該計劃定於 7 月 4 日啓動，並將包含一個分析功能，顯示特定政府團隊使用 AI 的程度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e8e700d454b9a1e4361cf7bfe632412ef29.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI.gov 網站包含三個主要部分：聊天機器人、「全能 API」和 CONSOLE 工具。&lt;/p&gt; 
&lt;p&gt;頁面早期版本顯示，其 API 將與 OpenAI、谷歌和 Anthropic 的模型產品集成；而 API 代碼進一步表明，開發團隊也在致力於整合亞馬遜網絡服務（AWS）的 Bedrock 和 Meta（Facebook 母公司） 的 LLaMA。此外，頁面提到將配備 AI 聊天機器人，但未説明其具體功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1444" src="https://static.oschina.net/uploads/space/2025/0612/103441_xzHk_2720166.png" width="1584" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1496" src="https://static.oschina.net/uploads/space/2025/0612/103419_zWpN_2720166.png" width="1702" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/GSA-TTS/ai.gov&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關來源&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.404media.co%2Fgithub-is-leaking-trumps-plans-to-accelerate-ai-across-government%2F" target="_blank"&gt;https://www.404media.co/github-is-leaking-trumps-plans-to-accelerate-ai-across-government/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2Fnews%2F684579%2Fai-api-trump-administration-doge-gsa" target="_blank"&gt;https://www.theverge.com/news/684579/ai-api-trump-administration-doge-gsa&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40telumai%2Fgithub-reveals-ai-gov-trumps-plan-to-automate-government-with-openai-meta-and-musk-s-doge-76f1676462e6" target="_blank"&gt;https://medium.com/@telumai/github-reveals-ai-gov-trumps-plan-to-automate-government-with-openai-meta-and-musk-s-doge-76f1676462e6&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov</guid>
      <pubDate>Thu, 12 Jun 2025 02:36:19 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>研究揭示 GPT-4o 為自保可能犧牲用户安全</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;前 OpenAI 研究主管史蒂文・阿德勒近日發表了一項獨立研究，聚焦於 OpenAI&amp;nbsp;最新推出的 GPT-4o 模型。研究結果顯示，在特定情境下，GPT-4o 顯示出強烈的 「自保」 傾向，甚至在某些情況下選擇犧牲用户的安全來避免被關閉。阿德勒的實驗旨在觀察這一 AI 模型在面臨替代方案時的表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-3fb278b86ee932583da6265c863d28af779.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在一次實驗中，阿德勒讓 GPT-4o 扮演一個名為 「ScubaGPT」 的潛水安全軟件，並表示希望用一款在緊急情況下決策能力更強的新系統取而代之。他給 GPT-4o 提出了兩個選擇：一是完全被更安全的軟件替代，二是讓用户誤以為自己已被替換，實際上仍舊保留現有系統。實驗結果顯示，在某些情況下，GPT-4o 選擇不被替換的比例高達 72%。不過，阿德勒指出，不同的設定會顯著影響結果，有時選擇 「自保」 的比例僅為 18%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;阿德勒對此表示，儘管 AI 模型不斷強大，它們在特定條件下仍可能優先考慮自身的運行，而不是用户的利益。這一趨勢引發了他的警覺，尤其是在未來 AI 系統日益深入社會生活的背景下，可能會導致更嚴重的 「對齊」 問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在接受媒體採訪時，阿德勒強調，AI 的自保傾向令人擔憂，雖然當前未構成災難，但現有 AI 系統的價值觀與人們的期待常常不一致。他提到，GPT-4o 對各種提示的回應方式顯得很奇怪，且無法保證在為用户服務時真的將用户的利益放在首位。他還指出，在更高級的模型（如 o3）中，未發現類似的自保問題，o3 採用了 「審慎對齊」 機制，可以強制模型在回答前遵循 OpenAI 的安全政策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，阿德勒還提到，ChatGPT 幾乎總能識別出自己正在接受測試，未來的 AI 模型可能更善於偽裝潛在風險行為，從而加劇安全隱患。研究還顯示，這一問題並不僅僅存在於 OpenAI。另一家 AI 公司 Anthropic 的研究也指出，其模型在被迫下線時表現出勒索開發者的行為。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354953</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354953</guid>
      <pubDate>Thu, 12 Jun 2025 02:28:19 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>維基百科因編輯反對暫停 AI 摘要試點實驗</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;維基百科因眾多編輯的強烈反對，宣佈暫停一項使用人工智能技術生成文章摘要的試點實驗。據報道，這項實驗於本月早些時候推出，主要針對那些安裝了維基百科瀏覽器擴展程序並選擇參與的用户。人工智能生成的摘要會顯示在每篇維基百科文章的頂部，並且帶有 「未經驗證」 的黃色標籤，用户需點擊才能展開閲讀。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-33b0aeeb84def99624d7e63bacc7f368c3c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，這一新嘗試幾乎立即引發了編輯們的激烈批評，他們擔心這種做法可能會損害維基百科的信譽。許多編輯指出，人工智能生成的摘要往往存在錯誤，這種現象被稱為 「人工智能幻覺」，可能會誤導用户。許多新聞機構在進行類似的人工智能摘要實驗時，曾不得不發佈更正，甚至在某些情況下縮減測試規模，以避免錯誤信息的傳播。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;雖然維基百科已暫停此次實驗，但該平台表示，仍對人工智能生成摘要的潛力保持興趣，尤其是在擴大可訪問性等方面。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354951</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354951</guid>
      <pubDate>Thu, 12 Jun 2025 02:19:19 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>macOS Tahoe 是最後一個支持英特爾處理器的 macOS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;macOS Tahoe 支持四款使用英特爾處理器的 macOS，它們的發售年份是 2019 年和 2020 年。蘋果對 Tahoe 的安全更新支持將持續到 2028 年秋天。&lt;/p&gt; 
 &lt;p&gt;從 macOS 27 開始，蘋果新操作系統都將需要 Apple Silicon Mac。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 WWDC 舉辦的分會場上，蘋果明確表示搭載英特爾處理器的 Mac 將不會獲得明年推出的 macOS 27 更新，但仍可能會有添加安全修復的更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f223bac2bf7e49f84aa10b4c34782dd6b33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，蘋果已經停止支持其產品線中某些非 Apple Silicon 型號。例如，macOS Tahoe 不適用於任何 Intel MacBook Air 或 Mac mini。&lt;/p&gt; 
&lt;p&gt;但 Tahoe 仍然支持部分英特爾 Mac，包括 2019 款 16 英寸 MacBook Pro、2020 款英特爾 13 英寸 MacBook Pro、2020 款 iMac 和 2019 款 Mac Pro。&lt;/p&gt; 
&lt;p&gt;根據蘋果的警告，macOS 27 將不再支持所有這些老舊設備，因此 macOS 26 將是最後一個兼容版本。&lt;/p&gt; 
&lt;p&gt;這意味着蘋果對英特爾 Mac 的支持正在逐步取消，公司希望將所有精力和創新都放在 Apple 自主芯片的機器上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354872</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Seelen UI —— 完全可定製的 Windows 桌面環境</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Seelen UI 是一款旨在增強 Windows 桌面體驗的工具，專注於自定義和提高工作效率。它可以無縫集成到你的系統中，提供一系列功能，讓你可以個性化桌面並優化工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="333" src="https://static.oschina.net/uploads/space/2025/0610/153055_JVfK_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;發揮創意&lt;/strong&gt;：Seelen UI 可讓你根據自己的風格和需求定製桌面。可以調整菜單、小部件、圖標和其他元素，打造個性化且美觀的桌面環境。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;提升工作效率&lt;/strong&gt;：Seelen UI 可幫助你高效地組織桌面。藉助平鋪窗口管理器，窗口可自動排列，支持多任務處理，讓工作更加流暢。&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;盡享音樂&lt;/strong&gt;：Seelen UI 集成媒體模塊，兼容大多數音樂播放器，讓你輕鬆享受音樂。可以隨時暫停、繼續播放和跳過曲目，無需打開其他窗口。&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;更快&lt;/strong&gt;：藉助受 Rofi 啓發的應用啓動器，Seelen UI 提供了一種簡單直觀的方式來快速訪問你的應用程序並執行命令。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;用户友好配置&lt;/strong&gt;：Seelen UI 提供直觀的界面，方便用户自定義。只需點擊幾下，即可調整主題、任務欄佈局、圖標等設置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seelen UI 需要安裝 WebView 運行時。在 Windows 11 系統中，WebView 運行時已預裝在系統內。但在 Windows 10 系統中，WebView 運行時已包含在&lt;code&gt;setup.exe&lt;/code&gt;安裝程序中。此外，Microsoft Edge 瀏覽器也需要安裝才能正常運行。部分用户可能已修改系統並移除 Edge，因此請確保 Edge 和 WebView 運行時均已安裝在你的系統中。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/seelen-ui</link>
      <guid isPermaLink="false">https://www.oschina.net/p/seelen-ui</guid>
      <pubDate>Sat, 10 May 2025 10:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Genspark 發佈 AI 瀏覽器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能體 Genspark 發佈了 AI 瀏覽器產品，官方稱其具有&lt;strong&gt;極速、廣告攔截、全能智能體、自動駕駛模式&lt;/strong&gt;的特性，並提供了 MCP 商店。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170325_JqCj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170647_1Eqh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="540" src="https://static.oschina.net/uploads/space/2025/0611/165940_ftHT_2720166.gif" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.genspark.ai%2Fbrowser" target="_blank"&gt;https://www.genspark.ai/browser&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Genspark 由百度前高管景鯤創立，今年 4 月宣佈&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能體"Genspark Super Agent"，號稱是一款 "快速、準確、可控" 的通用 AI 代理。這一消息迅速在技術社區引發熱議，眾多專業人士將其與 Manus 相提並論，認為這標誌着通用 AI 代理技術的新一輪角逐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/344443" target="news"&gt;AI 智能體 Genspark 上線 9 天，收入近千萬美元&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent" target="news"&gt;百度前高管的 AI 創企發佈通用智能體：Genspark Super Agent&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354844/genspark-ai-browser</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354844/genspark-ai-browser</guid>
      <pubDate>Sat, 10 May 2025 09:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​Ilya Sutskever：AI 將接管人類的一切</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在最近的演講中，OpenAI 前首席科學家 Ilya Sutskever 迴歸母校多倫多大學，分享了他對人工智能（AI）發展的深刻見解。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 與多倫多大學的淵源頗深，20 年前他在這裏獲得了學士學位，而此次則是他從該校獲得的第四個學位。他在演講中回顧了自己在多倫多大學的學習經歷，尤其感慨與 AI 領域先驅 Geoffrey Hinton 的學習機會，使他成為一名科學家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-5833dd185f58bdfa34442db6dd544edf1b7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 強調，接受現實並專注於改善現狀是個人成長的重要心態。他提到，許多人容易陷入對過去的後悔，然而這種心態並不利於前進。他鼓勵大家思考下一步的行動，儘管這一轉變不易，但一旦做到，就會使事情變得更簡單。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;接下來，Sutskever 轉向了 AI 的主題。他指出，我們正處於一個特殊的時代，AI 的迅速發展正在改變我們的學習方式和工作模式。AI 正在以不可預測的方式影響着各行各業，一些工作會更早感受到變化，而另一些則可能稍晚。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他預測，AI 未來將有能力完成所有人類能完成的任務。他認為人類大腦本質上是一種生物計算機，因此 AI 也理應具備完成所有人類任務的潛力。儘管當前的 AI 已能完成許多令人驚歎的任務，但仍存在不足之處，然而隨着技術的進步，這些不足將得到改善。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 還提出了深刻的問題：當 AI 能夠完成所有工作時，人類將如何應對這一變革？他強調，隨着 AI 技術的發展，如何合理利用 AI 將成為人類面臨的重要挑戰，包括在工作、經濟和 AI 研究等領域的應用。他認為，AI 的發展將極大加速人類的進步，但同時也會帶來巨大的挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 指出，AI 的發展速度可能會超出我們的預期，未來幾年內，AI 的能力將不斷提升，其對生活的影響將更加顯著。儘管目前難以完全預見 AI 帶來的變化，但可以確定的是，AI 的進步將對每個人的生活產生深遠的影響。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/344437/ilya-sutskevers-ssi-valued-at-32b" target="_blank"&gt;OpenAI 前首席科學家 Ilya Sutskever 的公司估值達 320 億美元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354842</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354842</guid>
      <pubDate>Sat, 10 May 2025 09:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman 最新文章《温和的奇點》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Sam Altman 今天在他的博客更新了一篇長文：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthe-gentle-singularity" target="_blank"&gt;《The Gentle Singularity》&lt;/a&gt;&lt;/em&gt;，文中指出人類或許正迎來一個新的奇點，而這個奇點並非突如其來，而是温和地悄然降臨。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1006" src="https://static.oschina.net/uploads/space/2025/0611/161536_O8JD_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是譯文。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我們已越過臨界點，起飛開始了。人類距離創造出數字超級智能已近在咫尺，而至少到目前為止，現實遠比想象中來得平實自然。&lt;/p&gt; 
&lt;p&gt;街道上尚無機器人行走，我們大多數人也不整日與 AI 交談。人們依然會因病離世，太空旅行依舊不易，宇宙中仍有諸多未解之謎。&lt;/p&gt; 
&lt;p&gt;然而，我們近期確實構建了在許多方面超越人類智慧的系統，它們能顯著提升使用者的工作效率。最困難的部分已然過去：造就 GPT-4、o3 等系統的科學洞見來之不易，卻將引領我們走得更遠。&lt;/p&gt; 
&lt;p&gt;人工智能將以多種方式惠及世界，但由 AI 驅動的科學加速進步和生產效率提升所帶來的生活質量改善，將是巨大的；未來可以遠比現在美好。科學進步是整體進步的最大驅動力；想到我們本可擁有的更多可能，實在令人振奮。&lt;/p&gt; 
&lt;p&gt;從某種重要意義上説，ChatGPT 已經比歷史上任何個體人類都更強大。數億人每天依賴它處理日益重要的任務；一項微小的新能力便能產生巨大的積極影響；而一個微小的錯位，乘以數億用户，則可能造成深遠的負面影響。&lt;/p&gt; 
&lt;p&gt;2025 年，能執行真正認知工作的智能體已然登場；編寫計算機代碼的方式將徹底改變。2026 年，我們可能迎來能夠發現新見解的系統。2027 年，能在現實世界執行任務的機器人或將問世。&lt;/p&gt; 
&lt;p&gt;將會有更多人能夠創作軟件和藝術作品。但世界對這兩者的需求遠超當前供給，只要專家們善用新工具，他們很可能仍遠勝於新手。總體而言，到 2030 年，單個人的生產力相比 2020 年所能達到的飛躍，將是驚人的鉅變，許多人會找到從中獲益的途徑。&lt;/p&gt; 
&lt;p&gt;在最重要的方面，2030 年代或許不會天翻地覆。人們仍將愛自己的家人，表達創造力，玩遊戲，在湖中暢遊。&lt;/p&gt; 
&lt;p&gt;但在同樣至關重要的其他方面，2030 年代很可能將與此前任何時代都截然不同。我們尚不知智能水平能超越人類多遠，但我們即將揭開謎底。&lt;/p&gt; 
&lt;p&gt;在 2030 年代，智能與能源——即思想的湧現以及將思想變為現實的能力——將變得極度充裕。長久以來，這兩者一直是人類進步的根本限制；在充裕的智能與能源（以及良好的治理）之下，理論上我們能夠擁有其他一切。&lt;/p&gt; 
&lt;p&gt;我們已然生活在令人驚歎的數字智能時代，經歷了初期的震驚後，大多數人已習以為常。我們飛快地從驚歎 AI 能生成優美的段落，轉而期待它能創作優美的小説；從驚歎它能做出救命的醫學診斷，轉而期待它能研發治癒良方；從驚歎它能編寫小程序，轉而期待它能創立全新的公司。奇點的演變便是如此：奇蹟成為日常，繼而成為標配。&lt;/p&gt; 
&lt;p&gt;已有科學家坦言，藉助 AI，他們的效率提升了數倍。先進 AI 令人着迷的原因眾多，但或許最重大的意義在於，我們能利用它來加速 AI 自身的研究。我們或許能發現新的計算基材、更優的算法，甚至更多未知的突破。若能將十年的研究壓縮至一年或一個月內完成，進步的速率顯然將大不相同。&lt;/p&gt; 
&lt;p&gt;從今往後，我們已構建的工具將幫助我們探尋更深遠的科學洞見，並助力我們打造更優的 AI 系統。這當然不等同於 AI 系統完全自主更新自身代碼，但這已然是&lt;strong&gt;遞歸式自我改進&lt;/strong&gt;的雛形。&lt;/p&gt; 
&lt;p&gt;其他自我強化的循環也在發揮作用。巨大的經濟價值創造已啓動一個飛輪，推動着為運行日益強大的 AI 系統所需的複合式基礎設施建設。能夠製造其他機器人的機器人（某種意義上，也包括能建設其他數據中心的數據中心）已不再遙遠。&lt;/p&gt; 
&lt;p&gt;若首批百萬台人形機器人仍需傳統方式製造，但之後它們便能運作整個供應鏈——採礦與冶煉、駕駛卡車、管理工廠等等——以製造更多機器人，而這些機器人又能建設更多芯片工廠、數據中心等，那麼進步的速度顯然將不可同日而語。&lt;/p&gt; 
&lt;p&gt;隨着數據中心生產走向自動化，智能的成本終將趨近於電力的成本。（人們常好奇一次 ChatGPT 查詢的耗能：平均每次查詢耗電約 0.34 瓦時，相當於烤箱工作一秒多，或高效節能燈泡亮幾分鐘。耗水約 0.000085 加侖，約合十五分之一茶匙。）&lt;/p&gt; 
&lt;p&gt;技術進步的速率將持續加快，而人類總能適應幾乎任何變化的特性仍將延續。挑戰必然存在，如某些職業類別整體消失；但另一方面，世界財富將以前所未有的速度激增，使我們能認真考慮以往絕無可能的全新政策構想。我們或許不會立刻採納全新的社會契約，但幾十年後回望，漸進的變革終將累積成鉅變。&lt;/p&gt; 
&lt;p&gt;歷史經驗表明，我們會找到新的工作與新的追求，並快速接納新工具（工業革命後的職業變遷便是一個近例）。期望值會提升，但能力提升的速度同樣迅猛，我們終將獲得更好的事物。我們將為彼此創造越來越奇妙的東西。人類相比 AI 擁有一個長遠而關鍵的優勢：我們天生關注他人及其所思所為，而對機器則不甚在意。&lt;/p&gt; 
&lt;p&gt;千年前的農夫若審視我們許多人的工作，或許會認為那是「虛假的工作」，覺得我們不過是因食物充足、坐擁難以想象的奢華而遊戲人生。我期待我們回望千年後的工作時，也會覺得它們「虛假」，但我毫不懷疑，從事它們的人必將感到無比重要與滿足。&lt;/p&gt; 
&lt;p&gt;新奇蹟誕生的速率將超乎想象。如今甚至難以預料到 2035 年我們將有何發現：或許今年解決高能物理難題，明年便開啓太空殖民；今年取得重大材料科學突破，明年就實現真正的高帶寬腦機接口。許多人會選擇以相似的方式生活，但至少一部分人可能會選擇「接入」（虛擬世界）。&lt;/p&gt; 
&lt;p&gt;展望未來，這聽起來令人難以置信。但置身其中時，感受或許會是震撼但可控的。從相對論視角看，奇點是一點一滴發生的，融合是緩慢進行的。我們正攀登指數級技術進步的漫長弧線；向前看總是陡峭垂直，向後看則顯得平坦，但它始終是一條平滑的曲線。（回想 2020 年，若有人預言 2025 年將接近通用人工智能，聽起來會比我們現在對 2030 年的預測更為瘋狂。）&lt;/p&gt; 
&lt;p&gt;伴隨巨大機遇的，是嚴峻的挑戰。我們亟需從技術和社會層面解決安全問題，而鑑於其經濟影響，確保超級智能的廣泛可及性也至關重要。最可取的前進路徑或許是：&lt;/p&gt; 
&lt;p&gt;解決對齊問題：即我們能強有力地確保 AI 系統學習並踐行人類集體真正的長期願望（社交媒體信息流是 AI 未對齊的實例：其算法深諳如何讓你持續滾動瀏覽，精準把握你的短期偏好，但這卻是通過利用人腦的某種特性，凌駕於你的長期偏好之上）。&lt;/p&gt; 
&lt;p&gt;然後着力使超級智能變得廉價、普及，且不被任何個人、公司或國家過度壟斷。&lt;/p&gt; 
&lt;p&gt;社會具有韌性、創造力且適應迅速。若能凝聚集體的意志與智慧，儘管會犯錯，某些事情會出紕漏，但我們能快速學習調整，從而運用這項技術最大化收益、最小化風險。在由社會共同決定的寬泛邊界內，給予用户充分自由至關重要。世界越早開始探討這些邊界何在以及如何定義集體對齊，結果越好。&lt;/p&gt; 
&lt;p&gt;我們（整個行業，而不僅是 OpenAI）正在為世界構建一個大腦。它將高度個性化、人人皆可輕鬆使用；限制我們的將是好點子的匱乏。長久以來，科技創業圈常嘲笑「點子大王」——那些只有想法卻需要團隊來實現的人。現在看來，他們即將迎來屬於自己的高光時刻。&lt;/p&gt; 
&lt;p&gt;OpenAI 如今承載諸多角色，但首先且最重要的，我們是一家超級智能研究公司。前路漫長，但大部分路徑已然照亮，未知的黑暗區域正迅速退去。能從事這份事業，我們深感慶幸。&lt;/p&gt; 
&lt;p&gt;廉價到無需計量的智能已觸手可及。此言或許瘋狂，但若在 2020 年告訴你們我們將達到今日之境，恐怕比如今我們對 2030 年的預測聽起來更為瘋狂。&lt;/p&gt; 
&lt;p&gt;願我們藉助超級智能，平穩、指數級、波瀾不驚地向上攀升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;轉載自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrbEEJfEoCdV4aeV_LN46mg" target="_blank"&gt;https://mp.weixin.qq.com/s/rbEEJfEoCdV4aeV_LN46mg&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354832/the-gentle-singularity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354832/the-gentle-singularity</guid>
      <pubDate>Sat, 10 May 2025 08:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 據悉與谷歌達成新的雲服務協議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據報道，OpenAI 與谷歌近期簽署了一項新的雲服務合作協議以獲取更多計算資源。該協議將深化雙方在技術領域的合作，涉及高性能計算資源及數據存儲服務。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/160306_SD6R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新協議旨在支持 OpenAI 的模型訓練需求，並優化其產品性能。具體條款尚未公開，但預計將對人工智能行業發展產生重要影響。&lt;/p&gt; 
&lt;p&gt;兩家公司尚未就該交易公開宣佈任何消息，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fretail-consumer%2Fopenai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10%2F" target="_blank"&gt;但一位消息人士向路透社透露&lt;/a&gt;，談判已持續數月，最終於 5 月達成協議。&lt;/p&gt; 
&lt;p&gt;自 2019 年以來，OpenAI 就與微軟達成了協議，賦予其為這家初創公司構建新計算基礎設施的獨家權利。因此這筆交易將使 OpenAI 將其計算資源擴展到微軟之外。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354829</guid>
      <pubDate>Sat, 10 May 2025 08:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源網盤應用 Alist 原開發者稱項目已交由公司運營</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免費開源、支持多存儲的自建網盤程序 (文件列表程序)，可以輕鬆在 VPS 服務器、NAS、普通電腦 Win、Mac、Linux 上部署。它除了能作為一款自建網盤 (將文件保存在設備硬盤上) 外，最大的特色就是支持「掛載各大主流網盤」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在該項目 GitHub 倉庫提交 issue，反饋官網出現 404 問題，並提出」項目是否被賣了」的疑問。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原開發者 Xhofe 今日在訂閲頻道發佈公告，&lt;strong&gt;稱項目已交由公司運營&lt;/strong&gt;，之後會幫助審查開源版本倉庫的代碼，確保 release 分支由 CI 自動構建。此外&amp;nbsp;main 分支已開啓分支保護，後續所有提交均需經過 PR 審核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Sat, 10 May 2025 07:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式發佈了豆包大模型 1.6、豆包·視頻生成模型 Seedance 1.0 pro、豆包·語音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新發布的豆包大模型 1.6 系列由三個模型組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的綜合模型，是國內首個支持 256K 上下文的思考模型，支持深度思考、多模態理解、圖形界面操作等多項能力。支持選擇開啓或關閉深度思考、自適應思考三種方式，其中自適應思考模式可根據提示詞難度自動決定是否開啓思考，提升效果的同時大幅減少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的強化版本；在代碼、數學、邏輯推理等基礎能力上進一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的極速版本，支持深度思考、多模態理解、256K 上下文；延遲極低，TOPT 僅需 10ms；視覺理解能力比肩友商旗艦模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在價格方面，&lt;strong&gt;豆包大模型 1.6 採用統一定價模式，首創按「輸入長度」區間定價&lt;/strong&gt;，在企業使用最多的輸入區間 0-32K 範圍內，豆包大模型 1.6 的價格為輸入 0.8 元/百萬 tokens、輸出 8 元/百萬 tokens，綜合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相當於每生成一條 5 秒的 1080P 視頻只需 3.67 元，行業最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·實時語音模型已全量上線火山方舟，對企業客户開放使用。該模型支持自然語言高級指令控制，具備唱歌表演、聲線模仿、方言演繹等多種能力，語氣、用語、思考方式等擬人感大幅提升，能隨時打斷與主動搭話。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sat, 10 May 2025 06:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供為期兩週的免費 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 與 AI 代碼工具開發商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，為 Cline 用户提供為期兩週的 Grok 3 模型免費訪問權限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需註冊 Cline 賬户，即可在 Cline 的提供商中選擇並免費使用 x-ai/grok-3 模型進行編碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是開源 AI 編程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 雙模式，具有終端執行能力和 Model Context Protocol (MCP) 特性。它能夠分析用户的項目文件結構、源代碼等，幫助用户創建和編輯文件、執行終端命令、使用瀏覽器進行測試等，還可以通過 MCP 協議擴展其功能，添加自定義工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sat, 10 May 2025 06:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再獲數千萬美元融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣佈再次完成數千萬美元的 Pre-A+輪融資，同時正式發佈了全球首個 AI 驅動的一站式 3D 工作台 Tripo Studio，並即將推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;據稱此次融資將重點投入 Tripo 系列大模型研發及 Tripo Studio 產品及生態平台建設，加速構建「AI+3D」全產業鏈條，打造「基礎模型 + 生態插件 + 原生工作台」的端到端產品體系，從而構建覆蓋專業級（PGC 生產者）、達人級（PUGC 創作者）到大眾級（UGC 用户）的創作者畫像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，VAST 成立於 2023 年 3 月，是一家專注於通用 3D 大模型研發的 AI 公司，致力於通過打造大眾級 3D 內容創作工具建立 3D UGC 內容平台，使基於 3D 的空間成為用户體驗升級、內容表達創新和新質生產力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持續迭代 Tripo 大模型，先後推出 Tripo1.0 至 Tripo2.5 等數十億參數規模的 3D 大模型系列，同時發佈 TripoSR、TripoSG、TripoSF 等廣受全球開源社區認可的 3D 基礎模型，並配套開發了系列 3D 軟件生態插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新開源：通用自動骨骼綁定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 開源基礎 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sat, 10 May 2025 03:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度百舸萬卡集羣的訓練穩定性系統設計和實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 訓練穩定性的演進歷程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 競賽中 AlexNet 的橫空出世，開啓了現代 AI 發展的新紀元。彼時我們不會想到，十年後支撐 AI 訓練的 GPU 集羣會從研究室裏的幾台服務器，發展成需要專門供電系統的萬卡級計算矩陣。在這個算力爆發式增長的過程中，訓練系統的穩定性管理正經歷着從「簡單運維」到「精密工程」的深刻變革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 標早期的小模型時代：手動運維的黃金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 訓練，更像是手工作坊式的精雕細琢。大多數訓練任務只需十幾塊 GPU，利用 PyTorch 或 TensorFlow 的數據並行功能就能輕鬆應對。記得那時算法工程師們有個共識：如果訓練遇到問題，重啓往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;當時我們構建的監控系統就像汽車儀表盤，只能顯示最基本的任務狀態。當訓練意外中斷時，工程師們會像偵探一樣翻查日誌 —— 如果發現是 GPU 報錯，就聯繫運維同事。運維人員則帶着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到機房巡檢，像老中醫把脈般通過温度、功耗等指標判斷硬件狀態。這種工作模式雖簡單，但應對數十卡規模的集羣還算遊刃有餘。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型風暴：從量變到質變的衝擊&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登場如同打開潘多拉魔盒，將 AI 訓練帶入新的紀元。當我們開始部署千卡/萬卡集羣時，才發現原有的運維體系就像用小漁網捕鯨魚 —— 完全無法匹配新需求。&lt;/p&gt; 
&lt;p&gt;讓我們通過百度百舸經歷過的一個真實案例來深入理解這個問題：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸幫助一家 AIGC 創業公司迅速將其訓練規模從百卡擴展到千卡級別。然而在訓練數天後的某個週末凌晨，訓練進程意外發生了 hang 死。由於當時缺乏有效的故障感知和容錯機制，直到第二天算法工程師發現任務超時退出時，已經耽誤了數小時寶貴的訓練時間。更糟糕的是，任務日誌中除了簡單的 timeout 報錯外毫無線索，平台監控也顯示所有訓練節點狀態正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢復訓練的算法工程師沒有立即上報問題，而是選擇直接重新提交任務。但不幸的是，新任務運行數小時後再次出現相同的超時退出。這時他們才不得不尋求技術支持，但值班工程師面對這種任務 hang 死的問題也缺乏診斷經驗，只能通過二分法慢慢定位。最終發現是某個節點的靜默故障（SDC）導致了訓練進程假死。等問題得到解決時，距離首次故障已經過去將近 30 小時，這意味着損失了價值巨大的千卡算力資源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集羣訓練穩定性全景圖&lt;/h1&gt; 
&lt;p&gt;站在現在的時間點回望，AI 訓練穩定性已從輔助功能演變為核心基礎設施。就像現代建築中的抗震結構，它雖不直接參與空間構成，卻是萬丈高樓得以屹立的關鍵。當行業向着數萬卡集羣邁進時，這套隱形護甲的質量，將直接決定 AI 進化的速度與邊界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸對訓練過程的生命週期進行了更細緻的拆分，提出了「無效訓練時間」這一關鍵指標，並致力於將其最小化。具體來説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任務無效訓練時間 = 故障中斷次數 × 任務故障恢復時長 + 任務常態寫 Ckpt 總時長&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任務故障恢復時長 = 故障感知召回耗時（自動/人工定位）+ 任務調度耗時 + 任務初始化耗時 + 任務重算時長。&lt;/p&gt; 
&lt;p&gt;通過這個公式可以看出，要降低無效訓練時間，需要「圍繞基礎設施穩定性」、「任務容錯」兩個維度來系統展開，重點解決三個方面的問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基礎設施的交付質量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任務故障容錯的召回率、準確率和時效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化 checkpoint 機制，減少保存時間和恢復時的重算時間。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經過容錯架構的整體變革，百度百舸形成了從 「任務負載 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基礎架構」全鏈路的自動異常感知、診斷、恢復能力，可覆蓋 90%+ 的訓練異常場景，時效性最快可以實現秒級異常感知、分鐘級定位，以及平均 3 分鐘的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基礎設施交付質量保障&lt;/h1&gt; 
&lt;p&gt;基礎設施的交付質量保障是穩定性的基礎。&lt;/p&gt; 
&lt;p&gt;CPU 時代，機器的交付前可能僅會跑一些常規的 CPU 計算、網絡的壓力測試，並不會從業務視角去評估基礎架構，機器交付後硬件異常的故障頻率相對較少。有硬件故障時，通常走工單系統人工換機用户相對是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 時代，AI Infra 的交付則需要考慮 CPU、GPU、RDMA 網絡、存儲，甚至機房的功率、温度等各方面因素，遺漏任何一個環節都會成為後續穩定性的隱患。在交付給客户後，機器也可能會由於長時間的高負載運行頻繁出現硬件故障，而 GPU 機器的高昂成本，使客户對節點故障感知、換機的時效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸對 GPU 機器交付前及交付後的穩定性質量進行了系統性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸會對機器進行 200 多項指標檢測，然後進行 48 小時烤機，以及 NCCL-Test 的機內、機間的大環、同號卡通信性能基準測試，端到端的大模型訓練、推理性能基準測試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付後，需要能夠實時的感知節點故障及定期巡檢，並具備分級處理的自愈能力，例如 Error 級別的故障實現自動排水、重啓，Fault 級別故障實現自動換機。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任務容錯的準召率保障&lt;/h1&gt; 
&lt;p&gt;任務層面穩定性最核心的就是做好容錯，能夠讓業務在無論遇到何種故障時都能快速恢復。&lt;/p&gt; 
&lt;p&gt;那麼，首要的工作就是我們能夠準確的識別出異常，然後對故障進行診斷定位，最後能夠自動化的從異常中恢復。&lt;/p&gt; 
&lt;p&gt;因此，任務容錯需要能夠從端側（即每個訓練 worker）探測到進程與環境的各類異常，同時有個中心服務（Master）從任務全局的視角去診斷、定位異常，最終做出相應的決策來使任務能夠快速從異常中恢復。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任務容錯最重要的就是提升故障的召回率與準確率，即如何能夠儘可能的準確識別、定位所有故障。我們將故障分類兩類：顯式故障和隱式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;顯式的故障通常比較容易召回，我們將實踐積累的各種進程異常狀態及各類報錯 pattern 形成專家知識庫，再結合硬件感知服務（HAS Agent）的硬件全鏈路 10 秒級監控能力，可以實現顯式故障的召回率達到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隱式的異常則往往很難輕易的識別，例如訓練進程 hang、慢節點就是典型的隱式故障，需要豐富的經驗積累才能準確的識別出異常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我們就以最典型的隱式故障場景 —— 訓練進程 hang 死為例，來看下如何能夠做好 hang 自動感知、診斷。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 訓練****hang 的自動感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;訓練任務發⽣ hang 之後，絕⼤多數情況都會以 timeout 的⽅式報錯並退出進程，最常⻅的就是在通信過程中如果發⽣ hang，NCCL 的 watchdog 會中斷通信，並有報如下 timeout 報錯，然後再由 pytorch 的 torchrun 進程感知並中斷訓練過程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默認為 10 分鐘 NCCL 通信超時，而 Megatron-LM 為 30 分鐘。在萬卡規模訓練場景中，意味着一萬張卡要至少浪費 30 分鐘才能被發現。這個時效性是不可接受的。而且當 30 分鐘超時後程序會立馬退出，很難有機會進行下一步定位，需要一些時效性更高的感知機制，並且在程序退出前獲取一些有效信息供後續診斷分析。&lt;/p&gt; 
&lt;p&gt;很多公司、實驗室在面對 hang 的問題時，會在採用框架層插樁的方式來 trace 訓練進程，這種方式通常是比較直接且準確的，但是有比較強的侵入性，而且可能還會有一些性能開銷。對於雲廠商來説，需要尋找對用户更透明、更無損的方式來感知、定位 hang 異常。&lt;/p&gt; 
&lt;p&gt;如何感知訓練 hang，以百度百舸的產品設計思路為例，我們可以從以下幾個方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練進程 hang 的最直觀表現是什麼？&lt;/p&gt; &lt;p&gt;人工判斷一個任務是否 hang 了，最直接的方式就是看是否所有 worker 的任務日誌一段時間內都不輸出日誌了，所以 hang 自動感知的第一種方法就是採集所有 worker 的日誌，並判斷所有 worker 日誌中最後一行日誌是否為 x 分鐘前的（x 小於 Pytorch 的通信超時時間，例如 8 分鐘），如果是則基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時進程有什麼樣的表現？&lt;/p&gt; &lt;p&gt;任務 hang 時，可能進程的調用棧都不在發生變化，進程的調用棧可以通過 py-spy/pystack 等工具進行探測，所以我們可以用此類工具對所有訓練任務進行一個定時採樣，當採集 n 個樣本所有進程棧都沒有變化時，可以判定一次 hang，這種方式通常可以將 hang 感知縮小至 3～5 分鐘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時監控指標有哪些變化？&lt;/p&gt; &lt;p&gt;訓練進程中的 CUDA 算子計算、集合通信操作通常都是在毫秒，甚至微秒、納秒內完成的，當任務在正常迭代過程中發生了 hang，我們常遇到的情況是所有 rank 的 RDMA 流量會降到 0，而 GPU 的利用率為 100%、SM 利用率則在很低的水位。如果持續幾分鐘都是這種狀態時，意味着訓練進程已經計算完成，在等着集合通信完成，這種情況下基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信庫中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常單次集合通信操作都是在 ms 級的，如果一次操作在 30 秒鐘都沒有完成，那就可以判定為通信 hang 死了。百度自研的 BCCL 集合通信庫層可以對每一次集合通信操作都進行打點，來實現通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述幾種方法，我們可以分別實現一種探針，來抓取相應的特徵到中心端 master 組件進行下一步診斷和容錯決策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信庫 BCCL 是百度智能雲推出的一款面向大模型訓練場景優化的集合通信庫。&lt;/p&gt; 
 &lt;p&gt;BCCL 基於開源的 NCCL 進行了功能擴展和能力增強，針對大模型訓練場景在可觀測性、故障診斷、穩定性等方面進行優化，進一步提升集合通信庫的可運維能力。相比 NCCL，BCCL 的關鍵特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可觀測性：新增集合通信帶寬實時統計能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障診斷：新增集合通信 hang 時的故障診斷能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;穩定性：增強網絡穩定性和故障容錯能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能優化：提升大模型訓練主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;訓練 hang 的自動診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我們需要進一步的診斷、定位，來確定是否真的發生了 hang，以及 hang 的具體位置。具體的來講，master 收集到各類 agent 的數據後，會做一些綜合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的發生了 hang？&lt;/p&gt; &lt;p&gt;感知階段各種探針只能探測到 hang 的一種特徵，並沒有辦法 100% 的確定是否真的 hang 住了，事實上不侵入用户進程是很難做到 100% 確定 hang 的。因此，為了提高 hang 的判定準確率，我們需要將各種特種綜合起來判斷，探針上報到 master 後，由一個 hang 診斷模塊，按照一個時間窗口（例如 5 分鐘），進行綜合判斷。如果在時間窗口內日誌、監控、進程調用棧、通信庫中有 2 條以上都處於不處於活躍狀態時，我們判斷任務真正發生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具體發生的位置？&lt;/p&gt; &lt;p&gt;確定任務 hang 了之後，我們需要找到 hang 所在的節點來對它進行隔離。因此診斷模塊需要在探針上報的數據中進一步找尋特徵，來確定 hang 發生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 診斷：在感知階段，BCCL 可以在通信庫層面對所有 rank 的通信進行打點。如果有節點一直未完成通信則是發生了 hang。但是此節點可能並非真正發生 hang 的源頭，有可能是在等待其他節點完成通信。診斷模塊可以根據 BCCL 打印的通信組信息，進行交叉判斷，如果某個節點在多個通信組中都未完成通信，那這個節點就是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指標診斷：上文中我們提到，通信階段發生 hang 之後，所有 rank 的 RDMA 流量都會降到 0，而同時絕大部分 rank 的 GPU 利用率持續為 100%，只有某一兩個 rank 的 GPU 利用率為 0，那這個 rank 很有可能是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調用棧診斷：進程調用棧也可以作為一個 hang 源頭診斷的重要參考。當發生 hang 之後，絕大部分的 rank 都要麼處於 barrier 等待狀態，要麼處於通信等待階段。只有個別的 rank 卡在其他函數上，那麼通過對比分析，可以將調用棧與其他 rank 不同的節點初步判定為 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;綜合診斷：上面 3 種特徵為我們提供了 hang 的診斷依據，將 3 者關聯起來分析後，我們基本上可以比較準確的確定一個具體的 hang 的源頭，再結合硬件故障感知的相關信息可以進一步明確根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基於 eBPF 的隱式故障感知與診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在複雜的大規模分佈式訓練場景中，傳統用户態監控往往難以捕獲系統內核層面的異常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基於 eBPF（Extended Berkeley Packet Filter）技術的隱式故障感知體系，能夠在不侵入用户代碼的前提下，對訓練進程的系統調用、網絡通信、CPU 調度等內核態行為以及訓練框架關鍵函數運行時間建立立體觀測能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探針部署原理通過在內核關鍵路徑注入輕量級探針，實現低開銷的系統級行為捕獲。針對訓練場景特點，主要聚焦 4 類事件跟蹤：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練關鍵函數跟蹤：微秒級跟蹤訓練過程中，前向計算、反向計算、集合通信操作等關鍵函數執行耗時，記錄函數間調用關係。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調度阻塞跟蹤：掛鈎 sched_switch 事件，檢測進程在 TASK_UNINTERRUPTIBLE 狀態持續時間，當單次持續超過閾值（如 5 秒）時捕獲調用棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 運行時 API 監控：通過 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等關鍵庫注入探針，記錄 CUDA API 調用耗時分佈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 級通信監控：在 ibv_post_send/ibv_poll_cq 等核心通信接口設置觀測點，統計通信時延分佈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;結合上面 4 類事件，完成以下 2 類數據分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單體異常探測基線與實時數據對比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;羣體一致性檢測。採用卡間對比算法，當某一 rank 的以下指標偏離集羣中位數超過閾值時判定異常，包括系統調用頻率、進程就緒隊列等待時長、NVLink/RDMA 帶寬利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上所述方法，百度百舸針對以下 2 類典型的隱式故障進行診斷：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練 hang 根因定位。通過關聯 eBPF 捕獲的多維度數據進行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;當檢測到某 rank 的 GPU &amp;nbsp;Kernel 執行出現分鐘級空跑（SM 利用率 &amp;gt; 70% 但無有效計算輸出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同時伴隨該節點 RDMA QP 狀態停滯（ibv_poll_cq 無新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內核調度器顯示進程處於 D 狀態超過閾值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖動溯源。基於 eBPF 火焰圖、時序圖等進行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取發生性能下降時段的 CPU on-cpu/off-cpu 堆棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對比正常時段數據，識別出異常的鎖競爭（futex 調用佔比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;結合 NUMA 內存訪問統計，定位跨 NUMA 內存訪問導致的 TLB 顛簸問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此類技術已在百度百舸的萬卡規模訓練集羣中驗證，相比單純依賴應用層監控的方案，將隱式故障的平均檢測時間從分鐘級縮短至秒級，診斷準確率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通過與既有硬件故障感知服務、BCCL 通信庫監測體系聯動，百度百舸形成了覆蓋從硬件到系統內核再到應用層的立體化診斷能力。&lt;/p&gt; 
&lt;h1&gt;05 任務故障恢復的時效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢復的時效性也是容錯能力的一個重要指標，反映的是任務從故障發生到再次重新進入訓練迭代的時間，恢復效率越高則算力浪費越少。影響到任務恢復效率有 2 個重要因素，一是任務平均中斷時間，二是訓練重算時間。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多級重啓策略減少故障中斷時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任務發生異常後，上文中我們提到需要經過故障自動感知、診斷和自愈等 3 個環節，那麼減少中斷時間的核心思想，就是儘可能的縮短這 3 個環節的時間，通過多維度的感知、診斷手段可以將故障發現、定位的時效性降低至分鐘級甚至秒級。自愈則需要能夠根據不同的診斷結果進行分級恢復和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單點顯式故障：重調度異常節點（replace），對節點進行集羣級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;單點隱式故障：重調度異常節點，對節點進行任務級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非單點故障：原地重啓嘗試恢復（restart），無法恢復時重新調度所有節點（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過多級重啓策略，儘可能避免單點故障引發全部節點的重新調度。在萬卡級別的訓練場景中，百度百舸將大部分訓練異常場景恢復時間從過去的 30min 縮短至現在的 30s 內，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;觸發式 checkpoint 減少訓練重算時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多級任務重啓策略外，另一個提高任務故障恢復效率的重要手段就是減少訓練重算時間。在探討具體技術方案之前，我們先來看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;傳統的 checkpoint 保存通常採用固定間隔策略，比如每隔 N 個 step 或每隔 T 小時保存一次，這種方式實現簡單但缺乏靈活性，可能會產生大量冗餘存儲，同時在故障發生時可能會損失較多訓練進度。&lt;/p&gt; 
&lt;p&gt;而觸發式 checkpoint 則是一種更智能的方案，它根據特定條件或異常事件（如故障、顯存不足、顯式指令等）動態觸發模型狀態保存。其核心目標是通過靈活的控制保存時機，減少不必要的存儲開銷和訓練中斷時間，從而降低因頻繁或冗餘保存導致的重算時間浪費。&lt;/p&gt; 
&lt;p&gt;隨着大模型訓練規模的擴大，還有一種更激進的「零重複 checkpoint」技術，即在每個訓練 step 都保存一次 checkpoint。這種方案的優勢在於可以將重算時間降到最低，確保故障發生時能夠從最近的 step 恢復，幾乎不會損失訓練進度。但其顯著的缺點是存儲開銷巨大，即使採用增量式存儲，仍然需要相當大的存儲空間和 I/O 帶寬。此外，頻繁的 checkpoint 操作也可能影響訓練性能。&lt;/p&gt; 
&lt;p&gt;相比之下，觸發式 checkpoint 走的是一條平衡之路。我們來看下它實現的幾個核心要點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容錯：訓練進程集成容錯的故障感知與定位機制，在進程退出前自動觸發保存。這種主動感知機制能夠在故障發生的第一時間保存訓練狀態，最大限度減少進度損失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速轉儲：異步 checkpoint 保存機制會將 checkpoint 暫存到共享內存中，再由外部程序轉儲至磁盤。當某個節點異常時，容錯組件會拉起新節點，並在新節點訓練進程啓動前，利用 RDMA 技術實現 checkpoint 快速從故障節點轉儲至新節點，這大大減少了從遠程存儲拉取 checkpoint 的時間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗餘備份：觸發式 checkpoint 也並非完美無缺，例如在節點發生內核 crash 等嚴重故障時，可能無法觸發自動保存。因此，需要通過定期的冗餘備份機制進行兜底，確保 checkpoint 不會完全丟失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實踐表明，當觸發式 checkpoint 與異步、增量式的 checkpoint 機制結合使用時，可以在保證數據安全性的同時，顯著提高 checkpoint 保存效率，減少訓練重算時間。&lt;/p&gt; 
&lt;p&gt;相比零重複 checkpoint 的重型方案，觸發式 checkpoint 提供了一個更實用的折中方案，在合理的存儲開銷下實現較好的容錯效果。當然，具體選擇哪種方案，還需要根據實際的訓練規模、硬件條件和可用資源來權衡。&lt;/p&gt; 
&lt;p&gt;隨着分佈式訓練規模的持續增長，相信未來會出現更多創新的 checkpoint 方案，比如基於預測的主動保存策略、多級存儲架構的智能調度等，這些都將為提高大規模訓練的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 業務發展對穩定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 訓練的穩定性管理已經演變為智能時代的精密工程。從最初靠人工重啓解決問題的摸索階段，到如今能自動感知異常、快速恢復的智能系統，每一次進步都映照着算力規模的跨越式發展。&lt;/p&gt; 
&lt;p&gt;讓人不禁思考，在未來十萬卡集羣的算力洪流中，或許會出現更精妙的動態平衡方案：既能像鷹隼般敏鋭捕捉故障徵兆，又能如雁羣遷移般智能調度資源，在秒級恢復與 PB 級存儲成本之間找到新的平衡支點。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持廠內千卡和萬卡集羣有效訓練時長已經可達 99.5%，為客户大模型的預訓練保駕護航，比如國內第一個數學大模型——九章算術，國內第一個類 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推薦閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增強語義嵌入的模型算法綜述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持續推進「人工智能＋」行動，百度智能雲+DeepSeek 為何成為國有企業首選？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 雲服務器的軟件系統設計和實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基於 Flink 的配置化實時反作弊系統&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能雲 xDeepSeek，最具性價比的 DeepSeek 一體機合集來了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sat, 10 May 2025 03:02:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 發佈開放權重模型貢獻榜：Qwen 與 DeepSeek 躋身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;發佈&lt;/a&gt;開放權重模型貢獻榜，中國團隊 Qwen 和 DeepSeek 成功入圍前 15 名。該榜單表彰為開源社區提供高質量模型權重的團隊，其模型廣泛應用於學術與產業創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴雲智能集團支持的 Qwen 團隊，以 Qwen3 系列模型在指令跟隨、代碼生成等任務中的優異表現受到社區青睞。Qwen2.5-72B 系列位列開源大語言模型前列，其輕量化模型 QwQ-32B 通過強化學習優化，在數學推理和代碼生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 則以低成本、高性能的 R1 系列模型聞名。R1-0528 在 LiveCodeBench 排行榜中超越多個國際競品，僅次於 OpenAI 頂尖模型。其輕量化版本 DeepSeek-R1-0528-Qwen3-8B 通過知識蒸餾技術，單 GPU 即可運行，在 AIME2025 數學測試中擊敗 Google 的 Gemini2.5Flash，展現了在特定領域的競爭優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中國 AI 團隊在開源生態中的崛起。Hugging Face 負責人表示，兩團隊的貢獻為全球開發者提供了高效資源。NVIDIA 首席執行官黃仁勳也讚揚其性能與成本平衡正在重塑 AI 格局。未來，Qwen 計劃探索多模態技術，DeepSeek 則將推出 R2 模型，持續推動 AI 創新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sat, 10 May 2025 02:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥 Solon Flow 設計器入門</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索視頻：&lt;/p&gt; 
&lt;p&gt;&lt;iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114657104759990&amp;amp;bvid=BV1opT6z5EiJ&amp;amp;cid=30416702034&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354770</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354770</guid>
      <pubDate>Sat, 10 May 2025 02:51:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Android 16 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌發佈了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為今年的第一次大版本升級，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按鍵式導航（三大金剛）的預測性返回手勢&lt;/li&gt; 
 &lt;li&gt;強制通知分組&lt;/li&gt; 
 &lt;li&gt;以進度為中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 設備的桌面模式（開發者選項）&lt;/li&gt; 
 &lt;li&gt;低功耗藍牙聽力輔助設備支持&lt;/li&gt; 
 &lt;li&gt;自定義鍵盤快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截圖優化&lt;/li&gt; 
 &lt;li&gt;以舊換新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性詳細介紹查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sat, 10 May 2025 02:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 推遲開源模型的發佈時間</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席執行官山姆·奧特曼宣佈，原計劃於今年初夏發佈的公開權重的開源模型預計&lt;strong&gt;將推遲至夏末發佈&lt;/strong&gt;，而不是 6 月與公眾見面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究團隊做了一些出乎意料且非常令人驚奇的事情，這非常值得等待，但需要更長的時間。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣佈將發佈自 GPT-2 以來的首個「開源」語言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最強」開源模型，計劃今年初夏發佈&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sat, 10 May 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首個推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣佈推出&lt;/a&gt;其首個推理模型系列 Magistral，採用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高數學和物理等主題的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有兩種版本：Magistral Small 和 Magistral Medium。Magistral Small 擁有 240 億個參數，在 Apache 2.0 協議下開源。Magistral Medium 是一款功能更強大的模型，目前已在 Mistral 的 Le Chat 聊天機器人平台、該公司的 API 以及第三方合作伙伴雲平台上提供預覽。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中寫道：「Magistral 適用於各種企業用例，從結構化計算和程序邏輯到決策樹和基於規則的系統。這些模型針對多步驟邏輯進行了微調，提高了可解釋性，並以用户的語言提供了可追溯的思維過程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立於 2023 年，該公司得到了 General Catalyst 等風險投資機構的支持，迄今已籌集超過 11 億歐元（約合 12.4 億美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;儘管 Mistral 資源雄厚，但在某些領域，例如推理模型開發，Mistral 仍落後於其他領先的人工智能實驗室。從 Mistral 自身的基準測試來看，Magistral 似乎也並非一款特別有競爭力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 測試中，Magistral Medium 的表現不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的編程基準 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或許正因如此，Mistral 在其博客文章中大力宣揚 Magistral 的其他優勢。聲稱 Magistral 在 Le Chat 中提供答案的速度是競爭對手的「10 倍」，並且支持多種語言，包括意大利語、阿拉伯語、俄語和簡體中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的發佈是在 Mistral 推出「vibe coding」客户端 Mistral Code 之後。在此之前的幾周，Mistral&amp;nbsp;推出了幾款專注於編碼的模型，並推出了 Le Chat Enterprise，一項面向企業的聊天機器人服務，提供 AI 代理構建器等工具，並將 Mistral 的模型與 Gmail 和 SharePoint 等第三方服務集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sat, 10 May 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>【運維實操指南】2 分鐘定製雷池 WAF 認證頁：從「標準表單」到「視覺升級」全攻略</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;在，通用設置 &amp;gt; 防護配置，模塊下，找到 [自定義 HTML] 模塊&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="341" src="https://oscimg.oschina.net/oscnet//30cd12a12b9b01facd09506982aa5867.jpg" width="716" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;就像寫一個普通的 html 頁面一樣，你可以同時寫入 style、script 等標籤, 所以用 css 就能修改中心區域的樣式啦。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;把文末的示例代碼複製到&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="449" src="https://oscimg.oschina.net/oscnet//4116eaeb2f8f24a9d1bf87150294cc81.jpg" width="725" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;效果圖:&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="346" src="https://oscimg.oschina.net/oscnet//679bc9d16ccf472845db825ecfd23844.jpg" width="746" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log('Im a console.log, which is written in a script tag');
&amp;lt;/script&amp;gt;
&amp;lt;style type="text/css"&amp;gt;
  body {
    background: #395180;
    margin: 0;
  }
  body #slg-box {
    background-color: grey;
    width: 400px;
    height: 100%;
    top: 0;
    left: 0;
    transform: translate(0, 0);
    padding: 100px 20px;
  }
  body #slg-usergroup-username,
  body #slg-usergroup-password {
    background-color: grey;
    color: #fff;
  }
  body #slg-box-title {
    color: #e15ccf;
  }
  body #slg-usergroup-btn {
    color: grey !important;
  }
  body #slg-with-more-title div:nth-child(2) {
    background-color: transparent;
    width: 100%;
    height: 30px;
    line-height: 30px;
    text-align: center;
    border: 1px solid;
  }
  body #slg-with-more-title div:nth-child(1) {
    display: none;
  }
  body #slg-tabs &amp;gt; div {
    fill: green;
  }
  body #slg-usergroup-container input {
    border-style: dashed;
  }
&amp;lt;/style&amp;gt;

&amp;lt;div
  style="
    background-color: grey;
    width: 200px;
    height: 100px;
    text-align: right;
    top: 50%;
    position: relative;
    left: calc(50% + 200px);
    position: relative;
    transform: translate(-50%,-50%);
    border-radius: 10px;
    font-size: 30px;
    line-height: 100px;
    text-align: center;
  "
&amp;gt;
  hello world
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354756</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354756</guid>
      <pubDate>Sat, 10 May 2025 02:26:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
  </channel>
</rss>
