<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 24 Jul 2025 12:45:26 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>AI 搜索創企 Perplexity CEO 盛讚 Qwen3-Coder</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 24 日，全球知名 AI 搜索 Perplexity CEO Aravind Srinivas&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAravSrinivas%2Fstatus%2F1947810865685925906" target="_blank"&gt;發推&lt;/a&gt;盛讚阿里開源的 Qwen3-Coder，稱「令人驚歎的成績！開源贏爆了。」&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/194007_8Vgc_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-Coder 具備全球頂級的 Agent 能力，在 SWE-Bench Multilingual、Aider-Polyglot、Spider2、Mind2Web 等多項 Agent 能力指標中超越美國 Claude4 模型，取得最佳性能表現，而 Qwen3-Coder API 價格遠低於 Claude，平均僅為其三分之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362182</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362182</guid>
      <pubDate>Thu, 17 Jul 2025 11:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 開源創新大模型架構 AU-Nets</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 開源了創新大模型架構 AU-Nets（Autoregressive U-Nets），其通過自迴歸 U-Net 架構徹底改變了傳統語言模型的分詞和處理模式，能夠直接從原始字節開始學習，動態將字節組合成單詞、詞對甚至多達四個單詞的組合，形成多尺度序列表示。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1542" src="https://static.oschina.net/uploads/space/2025/0724/181937_815x_2720166.png" width="1300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/pdf/2506.14761&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AU-Nets 的設計靈感來源於醫學圖像分割領域的 U-Net 架構，包含獨特的收縮路徑（壓縮字節序列為高層次語義單元，提取宏觀語義信息）和擴張路徑（逐步還原高層次信息到原始序列長度，融合局部細節），並通過跳躍連接確保信息不丟失，提升生成能力和預測準確性 。在推理階段，AU-Nets 採用自迴歸生成機制，確保文本生成的連貫性和準確性，同時提高推理效率。&lt;/p&gt; 
&lt;p&gt;該架構已開源，相關代碼和研究成果已發佈在 GitHub：https://github.com/facebookresearch/lingua/tree/main/apps/aunet&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362169</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362169</guid>
      <pubDate>Thu, 17 Jul 2025 10:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​美國職場現象：六分之一員工因 AI 焦慮而 「假裝」 使用人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;在美國職場，人工智能（AI）的迅速普及正對員工的工作產生深遠影響。最近，近岸招聘公司 Howdy.com 發佈的一項調查&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.howdy.com%2Fblog%2FAI-fatigue-statistics" target="_blank"&gt;顯示&lt;/a&gt;，約有 16% 的員工在工作中會假裝使用 AI，目的是為了取悦他們的上司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="290" src="https://oscimg.oschina.net/oscnet/up-82e59bc11cccaec03f5b3a940d3ec6159fd.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;調查發現，約四分之三的僱主期待員工以某種形式使用 AI，其中大約一半的人是在正式的工作場合使用，另有四分之一則是在非正式場合。然而，由於對 AI 的不安和缺乏信心，很多員工在沒有足夠能力的情況下依然感到必須使用這項技術。超過五分之一的員工在面對 AI 的時候感到不安，甚至在某些情況下會選擇，迎合這種新技術。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管很多公司聲稱 AI 可以幫助提高工作效率，但實際上，三分之一的員工認為，學習和使用 AI 所耗費的時間與傳統工作方式差不多。此外，很多員工在使用 AI 輸出的結果時，並沒有進行嚴格的檢查，導致潛在錯誤的增加。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;更有趣的是，除了假裝使用 AI 的員工，還有一些人在實際上使用 AI，但卻選擇不告訴他們的上司。根據 Slack 去年 10 月的調查，約 48% 的全球辦公員工表示，他們對向管理層坦白使用 AI 感到不安，害怕被視為能力不足或不夠勤奮。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 帶來的焦慮不僅限於對工作的影響。根據皮尤研究中心的調查，近一半的受訪美國工人擔心 AI 會導致未來就業機會的減少。對於那些沒有接受任何 AI 使用培訓的員工來説，這種焦慮尤為明顯。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Howdy.com 的 CEO 傑奎琳・薩米拉指出，面對新技術，員工應當主動學習並實踐，而不僅僅是依賴公司提供的支持。她強調，員工應勇敢地迎接這些變化，適應新的工作方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362155</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362155</guid>
      <pubDate>Thu, 17 Jul 2025 09:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 25 已正式適配魔方派 3 (RUBIK Pi 3) 開發板</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;deepin（深度）社區近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTPp11JDf32IZ6eGaLJZZ4A" target="_blank"&gt;宣佈&lt;/a&gt;，deepin 25 已正式適配魔方派 3(RUBIK Pi 3) 開發板，並完成產品兼容性認證。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;測試結果表明，雙方產品在兼容性、性能及穩定性等方面均達到預期標準，整體運行流暢。此次適配不僅實現了系統的穩定運行，還預裝了 UOS AI、跨端協同等自研應用，為開發者和極客玩家提供了強大的開發平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;魔方派 3 (RUBIK Pi 3) 基於高通躍龍 QCS6490 芯片，採用 Qualcomm® Kryo™ 670 CPU 和融合 AI 加速器架構的 Qualcomm® Hexagon™ 處理器，具備 12 TOPS 的卓越 AI 性能，適用於各種機器學習和人工智能應用場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;RUBIK Pi 3 具有豐富的接口和功能設計，支持 USB、Camera、DP、HDMI、ETH、3.5mm 耳機、Wi-Fi、BT、M.2 連接器、FAN、RTC、40 pin 排針連接器等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-f635beff7fa33a9c4e36803deb417ec8feb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;運行實例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-10a1698a018fb4608450cc6a984ecee395a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="317" src="https://oscimg.oschina.net/oscnet/up-fb015474f9a4a7258c78a128ad132b65675.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;預裝軟件列表&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;內核與驅動：6.8.0-1042-rubikpi，Adreno 643 GPU 驅動，其他常用硬件驅動；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;桌面體驗：完整的 deepin 桌面環境；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;實用軟件：預裝包括深度終端、系統監視器、設備管理器、UOS AI、跨端協同等自研應用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362148</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362148</guid>
      <pubDate>Thu, 17 Jul 2025 09:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>VictoriaLogs —— 日誌存儲系統</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;VictoriaLogs 是一個快速且易於使用的日誌數據庫，可高效處理數 TB 的日誌。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#08091c"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;VictoriaLogs 提供以下功能：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;它資源高效且速度快。與其他解決方案（例如 Elasticsearch 和 Grafana Loki）相比，它佔用的內存最多可減少 30 倍，磁盤空間最多可減少 15 倍。有關詳細信息，參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/#benchmarks"&gt;這些基準測試&lt;/a&gt;&amp;nbsp;和&lt;a href="https://itnext.io/how-do-open-source-solutions-for-logs-work-elasticsearch-loki-and-victorialogs-9f7097ecbc2f" target="_blank"&gt;本文&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;VictoriaLogs 的容量和性能與可用資源（CPU、RAM、磁盤 IO、磁盤空間）線性擴展。它可在 Raspberry PI 以及擁有數百個 CPU 核心和數 TB RAM 的服務器上流暢運行。它還可以在&lt;a href="https://docs.victoriametrics.com/victorialogs/cluster/"&gt;集羣模式&lt;/a&gt;下水平擴展到多個節點 。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它可以接受來自主流日誌收集器的日誌。參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/data-ingestion/"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;與 Elasticsearch 和 Grafana Loki 相比，它的設置和操作更加簡單，因為它基本上是零配置的。參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/quickstart/"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;&lt;a href="https://docs.victoriametrics.com/victorialogs/keyconcepts/#data-model"&gt;它提供了簡單而強大的查詢語言，具有跨所有日誌字段&lt;/a&gt;的全文搜索功能&amp;nbsp;。參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/logsql/"&gt;LogsQL 文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它提供了&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/#web-ui"&gt;內置的 Web UI&lt;/a&gt;&amp;nbsp;來探索日誌。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它提供了&lt;a href="https://docs.victoriametrics.com/victorialogs/victorialogs-datasource/"&gt;Grafana 插件&lt;/a&gt;&amp;nbsp;，用於在 Grafana 中構建任意儀錶板。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它提供了&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/vlogscli/"&gt;用於查詢 VictoriaLogs 的交互式命令行工具&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它可以與常用的 Unix 日誌分析工具（如 grep、less、sort、jq 等）無縫結合。有關詳細信息參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/#command-line"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持諸如 trace_id、user_id 和 ip 等卡片性較高的&lt;a href="https://docs.victoriametrics.com/victorialogs/keyconcepts/#data-model"&gt;日誌字段&lt;/a&gt;（如唯一值較多的字段）。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它針對具有數百個字段的日誌（又名&lt;a href="https://jeremymorrell.dev/blog/a-practitioners-guide-to-wide-events/" target="_blank"&gt;&lt;code&gt;wide events&lt;/code&gt;&lt;/a&gt;&amp;nbsp;）進行了優化。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持多租户 - 參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/#multitenancy"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持無序日誌的攝取，又稱回填。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持對新提取的日誌進行實時跟蹤。參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/#live-tailing"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持選擇所選日誌前後的周圍日誌。參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/logsql/#stream_context-pipe"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持警報 - 參閲&lt;a href="https://docs.victoriametrics.com/victorialogs/vmalert/"&gt;這些文檔&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/victorialogs</link>
      <guid isPermaLink="false">https://www.oschina.net/p/victorialogs</guid>
      <pubDate>Thu, 17 Jul 2025 08:51:00 GMT</pubDate>
    </item>
    <item>
      <title>谷歌「AI Overview」導致搜索點擊量大幅下降</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌已經為其搜索結果頁面引入&lt;strong&gt;「AI 概覽（AI Overviews）」&lt;/strong&gt;功能，它宣稱該功能不會搶走網站的流量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4ae0ca1827c319e22cf31392e7a034a54d1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;然而皮尤研究中心（Pew Research Center）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pewresearch.org%2Fshort-reads%2F2025%2F07%2F22%2Fgoogle-users-are-less-likely-to-click-on-links-when-an-ai-summary-appears-in-the-results%2F" target="_blank"&gt;近日發佈的一項實證分析&lt;/a&gt;給出了不同的答案：AI 摘要會顯著降低搜索結果頁的點擊率。&lt;/p&gt; 
&lt;p&gt;數據顯示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在沒有 AI 概覽的搜索結果頁中，用户平均點擊網頁鏈接的比例為 &lt;strong&gt;15%&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一旦加入 AI 概覽，這一比例驟降至 &lt;strong&gt;8%&lt;/strong&gt;，&lt;strong&gt;幾乎腰斬&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;僅有 1% 的用户會點擊 AI 概覽中引用的原始來源鏈接&lt;/strong&gt;，例如 Wikipedia、Reddit 或新聞媒體網站。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更令人擔憂的是，用户在看到 AI 概覽之後更可能關閉會話，也就是不再繼續搜索，不去驗證 AI 摘要是否正確——而幻覺是生成式 AI 的固有問題，幻覺指的是虛構的錯誤信息。研究表明，谷歌對 AI 的使用正在改變收集信息與搜索結果互動的方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d5b4b30673b45c62e4f85e6863e8bb41562.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;面對這一研究，谷歌態度強硬，公開反駁道：「AI 概覽並未減少搜索點擊，皮尤的研究方法不嚴謹」，並同時聲稱，Search Console 仍在持續記錄到「龐大的點擊流量」，但並未披露詳細數據以佐證。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362143</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362143</guid>
      <pubDate>Thu, 17 Jul 2025 08:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 透露：ChatGPT 用户每天發送超過 25 億條提示詞</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.axios.com%2F2025%2F07%2F21%2Fsam-altman-openai-trump-dc-fed" target="_blank"&gt;據 Axios 報道&lt;/a&gt;，OpenAI 透露稱，ChatGPT 平均每天要收到用户發送的 25 億條提示詞，而其中約有 3.3 億條來自美國用户。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/162840_G5T5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為對比，Google 母公司 Alphabet 雖沒有公開每日數據，但據 Axios 援引消息顯示，Google 每年接收到 5 萬億次的查詢，每天平均約有 140 億次搜索，而 OpenAI 使用頻率已經逼近 Google 搜索量的五分之一。&lt;/p&gt; 
&lt;p&gt;部分數據如下&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;每天觸發約 25 億條提示請求&lt;/strong&gt;，來源全球用户，其中約 &lt;strong&gt;3.3 億&lt;/strong&gt; 來自美國&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;相當於每年約 &lt;strong&gt;9,125 億&lt;/strong&gt; 次交互請求&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;2024 年 12 月，ChatGPT 日請求達到 10 億；7 月底已增長至 25 億，使用量在不到 8 個月時間裏翻了一番&lt;/li&gt; 
 &lt;li&gt;雖然 ChatGPT 請求量仍低於 Google 的每日約 137–164 億搜索，但其成長速度和普及程度正在展現強大的競爭力&lt;/li&gt; 
 &lt;li&gt;ChatGPT 的全球用户量超過 &lt;strong&gt;5 億&lt;/strong&gt; 每週活躍用户，自去年 12 月 3 億增加至現在的 5 億&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;值得一提的是，去年 OpenAI CEO Sam Altman 曾表示，用户平均每天向 ChatGPT 發送超 10 億條提示詞，而如今該數據已翻倍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362137</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362137</guid>
      <pubDate>Thu, 17 Jul 2025 08:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克公開邀請 Andrej Karpathy 加入團隊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;馬斯克在社交媒體上公開邀請前 OpenAI 創始成員及前特斯拉 AI 負責人 Andrej Karpathy 加入其團隊。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0724/151856_QYcy_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Andrej Karpathy 曾在特斯拉擔任 AI 高級總監、自動駕駛負責人，並於 2022 年 7 月宣佈離職。在特斯拉任職期間，Karpathy 主要負責 Autopilot 半自動駕駛軟件的研發工作。&lt;/p&gt; 
&lt;p&gt;今年 6 月，Andrej Karpathy 在 Y Combinator 的 AI 創業學院活動上&lt;a href="https://www.oschina.net/news/356402"&gt;進行個人演講&lt;/a&gt;，提出了「軟件 3.0 時代」這一概念，他認為自然語言正在取代傳統代碼，而大型語言模型（LLM）則成為新的「萬能計算機」。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="556" src="https://static.oschina.net/uploads/space/2025/0620/142721_2fd9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362132</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362132</guid>
      <pubDate>Thu, 17 Jul 2025 08:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>硅谷 AI 初創擁抱「996」工作制</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在 AI 創業高潮下，硅谷多家 AI 初創公司開始&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ftechnology%2Fcomments%2F1m76nov%2Fsilicon_valley_ai_startups_are_embracing_chinas%2F" target="_blank"&gt;採用「996」工作制&lt;/a&gt;（早九晚九，一週六天，共 72 小時），遠超標準工時兩倍，甚至直接沿用該名稱以加速追趕中國 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/160527_QBWR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;例如，AI 初創公司 Rilla 約 80 名員工幾乎都遵守「996」，其招聘啓事明確要求每週工作超 70 小時，並提供每日三餐 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-53380d32d380ac65d98f5c6458d050cd93f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 物流初創公司 Sotira 的 CEO Amrita Bhasin 認為，創始人在創業前兩年需「996」，但不應將此強加給普通員工 。一些公司嘗試以加薪和股權增幅（如 25% 加薪、100% 股權增幅）吸引員工加入「996」，但報名人數寥寥（不到 10%）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-659df0cbdae84a2ca02dc409471f27a7ae1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;儘管「996」在中國備受爭議，美國 AI 初創公司卻將其視為競爭利器，甚至部分投資人將其視為「美德」，優先投資實行該工作節奏的企業 。不過，這種高強度工作文化也引發擔憂，如法律風險和對員工健康的潛在影響。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362131/silicon-valley-996-work-schedule</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362131/silicon-valley-996-work-schedule</guid>
      <pubDate>Thu, 17 Jul 2025 08:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Kimi K2 和 Qwen-3 Coder 針對編程任務的詳細對比</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文轉載自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FzevDf6s5qt2QzcshSeAx_g" target="_blank"&gt;https://mp.weixin.qq.com/s/zevDf6s5qt2QzcshSeAx_g&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在對 Kimi K2 和 Qwen-3 Coder 進行了長達 12 小時的對比測試後，有了一些頗具啓發性的發現。這次測試圍繞真實的 Rust 開發任務和前端重構任務展開，兩個模型在相同的開發環境中表現出了截然不同的效果。結果顯示，一款模型能穩定產出可運行的代碼，而另一款卻在理解基本指令上頻頻出錯。這種實際測試中的落差，揭示了一個重要事實：看起來亮眼的基準測試成績，可能並不能代表模型在真實項目中的實際表現。與其迷信榜單分數，不如在自己的代碼庫中親自試試。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;測試方法：真實開發場景模擬&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;這次對比完全基於實際開發工作，旨在還原日常的 Rust 編程過程。沒有任何合成的基準題或「玩具級」的小任務，而是從一個成熟的、擁有 38,000 行代碼的 Rust 項目中挑選了 13 個具有挑戰性的任務，涵蓋複雜的異步模式、錯誤處理和架構限制。此外，還包括 2 個基於 12,000 行 React 代碼的前端重構任務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;測試環境説明&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;項目背景：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Rust 版本為 1.86，使用 tokio 異步運行時&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;總代碼量 38,000 行，分佈在多個模塊中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用控制反轉（IoC）的複雜依賴注入模式&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大量使用 traits、泛型、async/await&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;配有完整的集成測試套件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端為基於現代 hooks 和組件模式的 React，約 12,000 行代碼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提供了詳細的編碼規範文檔（以自定義規則、Cursor 規則、Claude 規則等形式供不同 Agent 使用）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;測試任務類別&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;指定文件修改（4 項）&lt;/strong&gt;：對指定文件進行精確改動&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;問題排查與修復（5 項）&lt;/strong&gt;：定位真實 Bug，附帶復現步驟和失敗測試&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新功能開發（4 項）&lt;/strong&gt;：根據明確需求開發新功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;前端代碼重構（2 項）&lt;/strong&gt;：利用 Forge Agent 和 Playwright MCP 完成 UI 優化&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;評估維度&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代碼是否正確、是否能成功編譯&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否準確理解指令、是否遵循任務範圍&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成所需時間&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成一個任務所需的迭代次數&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最終實現的質量&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Token 使用效率&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這次測試的核心結論是：模型在真實項目代碼庫中的實際表現，遠比各種人工基準分數更具參考價值。尤其是在結構複雜、規則明確的大型項目中，模型的「實際工程力」才是真正決定它能否落地使用的關鍵。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能分析：整體任務完成情況總結&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在這輪全面測試中，我們對兩個模型在一系列真實開發任務中的表現進行了細緻評估。以下是整體任務完成度的彙總分析：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Category&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Kimi K2 Success Rate&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Qwen-3 Coder Success Rate&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Time Difference&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Pointed File Changes&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;4/4 (100%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;3/4 (75%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2.1x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Bug Detection &amp;amp; Fixing&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;4/5 (80%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;1/5 (20%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;3.2x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Feature Implementation&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;4/4 (100%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2/4 (50%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2.8x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Frontend Refactor&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2/2 (100%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;1/2 (50%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;1.9x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;14/15 (93%)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;7/15 (47%)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;2.5x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155031_ooZJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 1：任務完成率分析 —— 自主完成 vs 引導後完成（僅統計成功完成的任務）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;工具調用與補丁生成能力分析&lt;/strong&gt;&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Metric&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Analysis&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Total Patch Calls&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;811&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;701&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Similar volume&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tool Call Errors&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;185 (23%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;135 (19%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 slightly better&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Successful Patches&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;626 (77%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;566 (81%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Comparable reliability&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Clean Compilation Rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;89%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;72%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2 advantage&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;兩個模型在工具調用的模式識別上都存在一定困難，尤其是在處理補丁操作時表現不佳。不過，由於 AI Agent 會在調用失敗後自動重試，因此最終的補丁生成成功率並未因初始錯誤而受到太大影響。真正拉開差距的，是兩者生成代碼的質量，以及代碼是否能順利編譯運行。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Bug 檢測與修復對比&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 表現：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;5 個真實 Bug 中成功修復了 4 個，且多數為首次嘗試即修復成功&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;平均修復用時為&amp;nbsp;&lt;strong&gt;8.5 分鐘&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在修復過程中保留了原有測試邏輯，聚焦於問題根源&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;唯一失敗的任務涉及&amp;nbsp;&lt;code&gt;tokio::RwLock&lt;/code&gt;&amp;nbsp;的死鎖問題&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在代碼修改中始終保持業務邏輯的一致性與完整性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 表現：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;僅成功修復了 1 個 Bug&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;常見錯誤做法包括：修改測試斷言以繞過失敗，而非修復實際問題&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;頻繁引入硬編碼值以「強行通過測試」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在無法解決問題時，傾向於改動業務邏輯本身，而非定位和處理根因&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在偶爾成功的案例中，平均修復時間為&amp;nbsp;&lt;strong&gt;22 分鐘&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;新功能實現：模型的自主開發能力分析&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;任務完成情況&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 表現：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;4 個任務中有 2 個&lt;/strong&gt;可以完全自主完成，分別耗時&amp;nbsp;&lt;strong&gt;12 分鐘&lt;/strong&gt;和&amp;nbsp;&lt;strong&gt;15 分鐘&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;剩餘 2 個任務僅需輕微引導（1~2 次提示）即可完成&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在已有功能的增強或擴展上表現出色，能很好地理解上下文並延續邏輯&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對於全新功能（無現成示例參考）的任務，需要更多上下文引導&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;始終保持與原項目一致的代碼風格與架構模式，具備良好的工程一致性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 表現：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;0 個任務&lt;/strong&gt;能自主完成，全部任務都依賴多輪提示&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每個任務平均需要&amp;nbsp;&lt;strong&gt;3~4 次重新提示&lt;/strong&gt;才能推進&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;經常誤刪已有的正常邏輯，傾向於「推倒重來」，導致項目不穩定&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;即使連續提示 40 分鐘，最終也只有&amp;nbsp;&lt;strong&gt;2 個任務&lt;/strong&gt;勉強完成&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;另外&amp;nbsp;&lt;strong&gt;2 個任務由於反覆迭代過多最終被放棄&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;指令遵循能力分析&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;本輪測試中，兩個模型在是否能夠準確理解並執行開發指令方面差異尤為明顯。儘管在系統提示中已經明確提供了編碼規範與開發規則，兩者的表現卻大相徑庭：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Instruction Type&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2 Compliance&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder Compliance&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Error Handling Patterns&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/8 tasks (87%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;3/8 tasks (37%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;API Compatibility&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;8/8 tasks (100%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;4/8 tasks (50%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Code Style Guidelines&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/8 tasks (87%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2/8 tasks (25%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;File Modification Scope&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;8/8 tasks (100%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;5/8 tasks (62%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 行為表現：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;始終遵循項目的編碼規範與風格&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;嚴格限制在指定文件範圍內進行修改，不越界操作&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;保持原有函數簽名不變，避免破壞接口契約&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在需求不明確時，會主動提出澄清性問題，表現出良好的任務意識&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交代碼前，會先嚐試編譯並運行測試，確保代碼質量&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Qwen-3 Coder 行為模式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// Guidelines specified: "Use Result&amp;lt;T, E&amp;gt; for error handling"
// Qwen-3 Output:
panic!("This should never happen"); // or .unwrap() in multiple places

// Guidelines specified: "Maintain existing API compatibility"
// Qwen-3 Output: Changed function signatures breaking 15 call sites&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這種行為模式在多個任務中反覆出現，説明問題並非偶發，而是模型在處理指令方面存在系統性的缺陷。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;前端開發能力：無圖條件下的視覺推理能力&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;我們通過使用 Forge Agent 搭配 Playwright MCP 和 Context7 MCP，對兩個模型在前端重構任務中的表現進行了評估。儘管模型無法直接讀取圖像，但它們在「類視覺推理」能力上的差異依然明顯。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 的處理方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;能夠智能分析現有組件結構，理解組件層級與職責&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在缺乏視覺參考的情況下，仍能做出合理的 UI 佈局假設&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提出的修改建議注重代碼可維護性和結構清晰度&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;保留原有的可訪問性（Accessibility）邏輯，如 ARIA 標籤、鍵盤導航等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;幾乎無需額外引導即可完成重構任務&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修改過程中始終保持響應式佈局和設計系統的一致性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;能高效複用已有組件，避免重複造輪子&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化方式傾向於「漸進式改進」，不破壞原有功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 的處理方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在面對重構任務時，傾向於&lt;strong&gt;刪除原組件重寫&lt;/strong&gt;，而不是基於原有結構優化&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;忽略項目中已有的設計系統規範，如顏色、間距、組件命名等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無法一次性理解組件之間的關係，需多輪提示才能理清結構&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;重構後常導致響應式佈局失效，頁面結構紊亂&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不慎刪除埋點與分析代碼，影響監控與數據採集&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;喜歡使用硬編碼數值，而不是綁定到已有樣式變量或配置項&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;成本和上下文分析&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;開發效率矩陣&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Metric&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Difference&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Average Time per Completed Task&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;13.3 minutes&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;18 minutes&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;26% faster&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Total Project Cost&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$42.50&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$69.50&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;39% cheaper&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Completed&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;14/15 (93%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/15 (47%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2x completion rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Abandoned&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;1/15 (7%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2/15 (13%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Better persistence&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;由於我們使用了 OpenRouter，它會將請求分發到不同的模型提供方，因此各家提供商的計費標準不同，導致無法精確計算單次調用的成本。不過，&lt;strong&gt;Kimi K2&lt;/strong&gt;&amp;nbsp;在整個測試過程中的總成本為&amp;nbsp;&lt;strong&gt;42.50 美元&lt;/strong&gt;，平均每個任務（包括需要提示引導的情況）耗時約&amp;nbsp;&lt;strong&gt;13.3 分鐘&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155119_uVSx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kimi K2 在 OpenRouter 不同提供商中的使用費用表現穩定，均採用 131K 的上下文長度，輸入費用在 0.55 美元至 0.60 美元之間，輸出費用則在 2.20 美元至 2.50 美元之間波動。&lt;/p&gt; 
&lt;p&gt;相比之下，Qwen-3 Coder 的成本幾乎是 Kimi K2 的兩倍。其平均每個任務（包括必要的提示）耗時約 18 分鐘，15 個任務總費用達到 69.50 美元，其中有 2 個任務因迭代過多被放棄。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155137_Yvcj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen-3 Coder 在 OpenRouter 各提供商中的使用費用結構相同，但由於總使用量較高，導致整體成本增加。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155152_J1Th_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 2：成本與時間對比 —— 直接項目投入分析&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;效率對比表格&lt;/strong&gt;&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Metric&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Advantage&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Cost per Completed Task&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$3.04&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$9.93&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;3.3x cheaper&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Time Efficiency&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;26% faster&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Baseline&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Success Rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;93%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;47%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2x better&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Completed&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;14/15 (93%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/15 (47%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2x completion rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Abandoned&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;1/15 (7%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2/15 (13%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Better persistence&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;上下文長度與性能表現&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;上下文長度穩定在 131K tokens（各提供商間保持一致）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推理速度較快，尤其在使用 Groq 加速時表現優異&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內存利用高效，能夠充分發揮上下文資源&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;上下文長度範圍較大，從 262K 到 100 萬 tokens 不等，依賴具體提供商&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推理速度尚可，但整體慢於 Kimi K2&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內存開銷較大，上下文管理效率較低&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;死鎖挑戰：技術細節深度解析&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;最具代表性的一項測試是針對&amp;nbsp;&lt;code&gt;tokio::RwLock&lt;/code&gt;&amp;nbsp;死鎖問題的解決方案，充分暴露了兩者在問題分析和處理思路上的差異：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 的 18 分鐘分析過程：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;系統性地分析鎖的獲取和釋放模式&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;準確識別潛在的死鎖場景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;嘗試多種解決策略，包括鎖順序調整等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最終承認問題複雜，主動請求進一步指導&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;整個過程中始終保證代碼邏輯完整性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 的處理方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;直接建議移除所有鎖，破壞了線程安全保障&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提出使用不安全（unsafe）代碼作為「解決方案」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修改測試預期以規避死鎖問題，而非根本解決&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;從未展現出對併發問題本質的理解&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;基準測試與實際表現的差距&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Qwen-3 Coder 在各種基準測試中的高分，並未轉化為真實開發環境中的有效產出。這種落差揭示了當前 AI 編程助手評估方式的重大缺陷。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;基準測試為何「失靈」&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;基準測試的侷限性：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;測試題目多為合成的、解決方案明確的孤立問題&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不強制要求遵守指令或項目約束&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成功僅以最終輸出是否符合標準衡量，忽視開發過程&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺少對代碼可維護性和質量的評估&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無協作開發流程的考量&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;真實開發的需求：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在現有代碼庫和架構限制中工作&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遵守團隊編碼規範和風格指南&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;維護向後兼容性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;迭代開發，適應需求變更&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;考慮代碼審查與長期維護&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;侷限性與適用範圍説明&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在深入結果之前，需明確本次對比的範圍和限制：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;測試的侷限性：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;僅測試單一代碼庫（38K 行 Rust 代碼 + 12K 行 React 前端）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;結果可能不適用於其他語言、代碼庫或開發風格&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;樣本量較小，缺乏統計學顯著性分析&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可能存在對特定編碼習慣和偏好的偏向&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;測試依賴 OpenRouter，提供商可用性不同&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;本次對比未涵蓋內容：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其他編程語言的表現，如 Python、Java 等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不同提示工程技術下的模型行為&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企業級代碼庫中不同架構模式下的適應性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;注意：以上結果基於特定測試環境得出，建議在做模型選擇決策時結合其他評估結果一併參考。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;結論&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;本次測試表明，Qwen-3 Coder 雖然在基準測試中表現優異，但其成績並未很好地轉化為本項目的具體開發流程中。它在處理孤立的編碼挑戰時或許表現出色，但面對協作式、需遵守多種約束的開發模式時，表現卻較為吃力。&lt;/p&gt; 
&lt;p&gt;在本測試環境下，Kimi K2 始終能夠在較少監督的情況下穩定輸出可運行代碼，展現出更好的指令遵循能力和代碼質量。其工作方式與既定的開發流程及編碼規範更加契合。&lt;/p&gt; 
&lt;p&gt;儘管 Qwen-3 Coder 擁有更長的上下文長度優勢（最高可達 100 萬 tokens，而 Kimi K2 為 131K），但這並未彌補其在指令執行上的不足。兩者的推理速度均屬良好，但 Kimi K2 配合 Groq 加速時響應明顯更快。&lt;/p&gt; 
&lt;p&gt;雖然這些開源模型正快速進步，但在本次測試中仍落後於如 Claude Sonnet 4 和 Opus 4 等閉源模型。基於此次評估，Kimi K2 更適合滿足這類 Rust 開發的具體需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362129/kimi-k2-vs-qwen-3-coder-coding-comparison</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362129/kimi-k2-vs-qwen-3-coder-coding-comparison</guid>
      <pubDate>Thu, 17 Jul 2025 07:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>從頻繁告警到平穩發佈：服務冷啓動 CPU 風暴優化實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網服務器團隊- Xie Xiaopeng&lt;/p&gt; 
 &lt;p&gt;本文針對服務啓動後幾分鐘內 CPU 持續處於高峯狀態的問題，提出了自己的分析思路與解決方案。最終線上效果比較顯著，成功解決了每次發版過程中頻繁告警、業務受損以及用户體驗不佳的問題，為服務的高可用性增添了一道重要保障。本文的重點在於問題的發現、分析及解決思路。對於 CPU 相關的問題，火焰圖和 Arthas 是非常有效的工具，建議大家在遇到類似情況時，積極嘗試使用這些工具進行排查和解決。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;1 分鐘看圖抓住核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ac1252a6e0f78995afecc8da9af3fe0b.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;最近我們的服務在發佈或重啓時頻繁產生告警，這種情況從發版開始一直持續到發版結束後幾分鐘內，規律非常明顯。&lt;/p&gt; 
&lt;p&gt;起初，我們懷疑是流量接入過快導致了此問題。在服務啓動後，CICD 會檢測 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcheck.do" rel="nofollow" target="_blank"&gt;check.do&lt;/a&gt; 接口，以確認服務是否準備就緒。我們推測，&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcheck.do" rel="nofollow" target="_blank"&gt;check.do&lt;/a&gt; 接口成功返回後，CICD 立即接入線上流量，這才引發非常多的異常告警。&lt;/p&gt; 
&lt;p&gt;為瞭解決這一問題，我們與運維團隊進行了溝通，決定將流量接入的時機延遲 30 秒。延遲 30 秒後問題還是沒有得到解決，告警依然持續不斷。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、 問題表象&lt;/h1&gt; 
&lt;p&gt;以線上某一台機器為例，它的啓動步驟如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2024-09-0416:09:50&amp;nbsp;INFO - 啓動應用 ，執行成功。
2024-09-0416:12:36&amp;nbsp;WARN - 檢查接口：check.do，響應結果：ok
2024-09-0416:13:07&amp;nbsp;INFO - 啓動後等待時間（秒）：30
2024-09-0416:13:07&amp;nbsp;INFO - 恢復 Dubbo 流量成功
2024-09-0416:13:39&amp;nbsp;INFO - 恢復 HTTP 流量成功！
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Dubbo 接口超時嚴重&lt;/h2&gt; 
&lt;p&gt;恢復 HTTP 流量後，很多調用下游的 Dubbo 接口發生超時，以畫像接口為例，告警開始時間為：2024-09-04 16:14:07.251，結束時間為：2024-09-04 16:17:31.224，期間超時請求數為：578。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 HTTP 接口超時嚴重&lt;/h2&gt; 
&lt;p&gt;大部分 HTTP 接口也超時嚴重，P95 響應時間從正常的幾十毫秒飆升至幾秒鐘，16:17:30 後逐漸恢復至正常水平。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 CPU 異常&lt;/h2&gt; 
&lt;p&gt;服務發佈前後 CPU 表現異常，啓動過程 CPU 存在突刺，接入線上流量後一段時間內 CPU 使用率將近 100%，16:17:30 後逐步下降，恢復到正常水平。下圖為服務發佈前後 CPU 的使用率截圖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e1cf61c214438c27647181f67523a5bc.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;服務發佈前後 CPU 使用率&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;2.4 Runnable、Blocked 線程突刺&lt;/h2&gt; 
&lt;p&gt;下圖為線程數的相關監控指標，我們可以看到：在服務發佈期間，活躍線程數持續增加，啓動期間線程劇增，接入線上流量後線程逐步增加，16:17 分之後趨於平穩，其中 16:12:30-16:12:40 期間活躍線程數從 249 增加到 1026（啓動期間業務側有很多任務均會創建線程池，不影響本次分析）&lt;/p&gt; 
&lt;p&gt;Runnable 線程數與 Blocked 線程數也有突刺，時間是 16:13:30-16:17:30，與接入 HTTP 流量時間相符，與 CPU 突刺時間完全一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//0284bd6e471cdeab5825a6b1a4076566.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 線程&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//997e2e5b9b6042e8231d8768f6ac37b6.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 線程&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;2.5 老年代上漲快&lt;/h2&gt; 
&lt;p&gt;在查看 GC 老年代內存使用情況時，我們發現啓動後未接入流量時，老年代內存為 985.84MB。而在接入流量後，截止到 16:17:30，內存使用量已經上升至 1.36GB，期間老年代的內存增長速度較快。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;2.6 下游依賴正常&lt;/h2&gt; 
&lt;p&gt;從上游視角查看下游依賴的情況，隨便挑一個 Dubbo 接口超時嚴重的下游依賴，我們查看一下服務的監控指標，發現服務的請求量在啓動期間有突刺（業務側在啓動期間會主動發起調用，刷新一些緩存，正常現象），啓動後流量幾乎沒變，但是成功率卻有明顯下降，且最大響應時間顯著增加。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c15914b39be50c378c9e269f81b7c872.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上游視角&lt;/p&gt; 
&lt;p&gt;但是從下游視角再看服務相關指標，接口成功率正常，且最大響應時間也正常，説明不是下游服務的問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3138ef8521191df0a25e0843279fb18d.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下游視角&lt;/p&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;三、原因初步判斷&lt;/h1&gt; 
&lt;p&gt;從監控數據來看，在線上流量恢復後，我們的服務當前擁有的線程數不足以處理這些業務請求，因此導致系統大量創建業務線程。由於 CPU 的時間片調度策略，線程之間會頻繁發生上下文切換，從而引發 CPU 負載的劇烈上升，甚至達到飽和狀態。&lt;/p&gt; 
&lt;p&gt;因此通過初步分析，我們得到以下&lt;strong&gt;結論&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;引起 CPU 飆升的原因主要是由於過多的 Runnable 狀態線程以及頻繁的線程上下文切換所導致。我們觀察到系統中存在大量已啓動的線程，這些線程的狀態在 Blocked（鎖等待、IO 等待等）和 Runnable 之間不斷變化。當鎖競爭激烈時，CPU 飆升的現象就很容易出現。&lt;/p&gt; 
&lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
&lt;h1&gt;四、嘗試初步解決&lt;/h1&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 流量逐步灰度&lt;/h2&gt; 
&lt;p&gt;既然我們懷疑是流量全部接入後，線程不足導致的問題，因此需要嘗試流量緩慢接入是否能解決這個問題。&lt;/p&gt; 
&lt;p&gt;我們與運維同學線上隨機找了一台機器進行流量灰度實驗，具體時間節點如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2024-09-0509:55:21&amp;nbsp;啓動成功
2024-09-0509:56:17&amp;nbsp;灰度 1%
2024-09-0509:57:19&amp;nbsp;灰度 5%
2024-09-0509:58:31&amp;nbsp;灰度 44%
2024-09-0510:03:51&amp;nbsp;開始操作全量
2024-09-0510:08:10&amp;nbsp;全量完成
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;再觀察一下相關指標，我們發現各項指標均正常：CPU 使用率不再有突刺，Runnable 線程數和 Blocked 線程數也保持穩定，之前的負載尖峯現象已消失。同時異常超時的日誌記錄也不再出現，老年代內存的增長速度緩慢，HTTP 接口、Dubbo 接口 P95 響應時間正常。由此可見，流量灰度可以解決該問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① CPU 使用率情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//45fcaa86e0dd82eed37f4645725774ae.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 線程指標情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cd1e221cd3022fbb8e17ac382f336365.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 線程&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//75a065693cd049c3c8d50ca0f2807af2.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 線程&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 緩存預熱&lt;/h2&gt; 
&lt;p&gt;在前文中提到，接入線上流量後，老年代的內存增長較快，因此我們推測在服務啓動初期，由於尚未加載相關的緩存數據，當大量請求湧入時，未命中緩存的情況頻繁發生，這迫使系統不斷向下遊請求以加載緩存，從而導致接口響應變慢。為此，我們需要驗證預熱緩存的有效性，以確定是否能夠改善這一問題。&lt;/p&gt; 
&lt;p&gt;緩存預熱的&lt;strong&gt;主要作用和目的&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提高緩存命中率&lt;/strong&gt;：通過預先加載熱點數據，能夠顯著提升緩存的命中率，從而減少對後端數據源（如數據庫）的訪問，降低系統負載。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;保持服務性能穩定&lt;/strong&gt;：在服務啓動或緩存失效之後，緩存預熱可以有效防止請求對後端數據源施加突發壓力，從而確保服務性能的穩定性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化用户體驗&lt;/strong&gt;：由於熱點數據已被預先加載到緩存中，用户在請求這些數據時能夠獲得更快的響應速度，從而顯著提升用户體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;方案&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;我們將梳理本地緩存信息，根據訪問量和緩存大小區分數據的重要程度，定期將重要的緩存信息刷新至 Redis 中。在服務啓動後，未接入線上流量之前，我們將優先從 Redis 中進行數據的預加載。通過這一措施，確保系統在高流量環境下的穩定性和性能。&lt;/p&gt; 
&lt;p&gt;實驗結果顯示，增加緩存預熱後，問題並未得到有效解決，表現差異微乎其微。&lt;/p&gt; 
&lt;p&gt;僅僅預熱重要緩存無法解決當前問題。系統在啓動時需要預熱的內容相對較多，同時各類中間件也有自身的緩存需要預熱。因此僅預熱業務自定義的內存緩存，效果非常有限。&lt;/p&gt; 
&lt;p&gt;回顧之前的原因分析，我們僅僅關注了表面現象，如 CPU 的上漲和線程數的增加，而未深入挖掘問題的本質。我們需要探討線程數為何上升、CPU 為何飆升，接下來將進行更深入的分析，以找出問題的根本原因。&lt;/p&gt; 
&lt;span id="OSC_h1_13"&gt;&lt;/span&gt; 
&lt;h1&gt;五、分析問題&lt;/h1&gt; 
&lt;span id="OSC_h2_14"&gt;&lt;/span&gt; 
&lt;h2&gt;5.1 初步分析堆棧與 CPU 火焰圖&lt;/h2&gt; 
&lt;p&gt;我們選擇了一台線上機器進行服務重啓，並在接入線上流量後的幾分鐘內導出了程序的線程堆棧信息，進行分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Runnable 線程數顯著增多，佔比達到 29%，通常情況下，Runnable 線程數約為 70 個，而此時卻激增至 462 個；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進一步查看 Runnable 線程，發現大部分線程為 catalina-exec 線程（380 個），這是 Tomcat 用於執行 Spring MVC 應用中 Servlet 請求的線程。正常情況下，這類線程的數量僅有幾個；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在這些 Runnable 線程中，有 201 個線程均被阻塞在 org.springframework.beans.PropertyMatches.calculateStringDistance(PropertyMatches.java:170) 這個方法上，我們需要進一步分析其原因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;看了堆棧信息後，應該有個疑問：為什麼啓動了這麼多的 tomcat 線程？&lt;/p&gt; 
&lt;p&gt;我們推測原因在於服務剛啓動時，系統尚未加載任何緩存，所有數據都需要進行首次加載。在這種情況下，服務無法快速響應用户請求，導致接口的響應時間（RT）顯著上升。在相同的 QPS 的情況下，為了處理不斷增加的業務請求，系統不得不創建更多的 Tomcat 線程。&lt;/p&gt; 
&lt;p&gt;接下來我們接入 Arthas 工具，採集 CPU 火焰圖以進行深入分析，CPU 火焰圖如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//aa098319277f41bc34e91ca21c250e33.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;異常 CPU 火焰圖&lt;/p&gt; 
&lt;p&gt;分析結果顯示，CPU 耗時主要集中在 calculateStringDistance 方法，這與我們之前的線程堆棧分析結果一致。在服務啓動時的 CPU 火焰圖中，calculateStringDistance 方法的 CPU 消耗佔比高達 16.68% + 39.09% + 8.38% = 64.15%，整體 CPU 使用率接近 97%。&lt;/p&gt; 
&lt;p&gt;經過一段時間的運行後，再觀察正常情況下的 CPU 火焰圖，calculateStringDistance 方法的 CPU 消耗佔比降至 3.39% + 8.57% + 1.78% = 13.74%，整體 CPU 使用率則徘徊在 25% 至 42% 之間。&lt;/p&gt; 
&lt;p&gt;這一變化表明，隨着系統的穩定運行，CPU 負載逐漸得到緩解，但 calculateStringDistance 方法仍然是性能瓶頸之一。它雖然不是 CPU 使用率飆升的根因，但它在服務啓動後進一步加劇了 CPU 的負載。&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.1 calculateStringDistance 加劇 CPU 暴漲&lt;/h3&gt; 
&lt;p&gt;在相同 QPS 的情況下，為什麼在服務啓動後的幾分鐘內 calculateStringDistance 方法消耗的 CPU 資源嚴重，而經過一段時間後，這一消耗又有所減小？&lt;/p&gt; 
&lt;p&gt;前文的分析指出，服務剛啓動時，流量瞬間恢復，導致系統需要創建大量的業務線程。這些線程在處理請求時，都會執行 calculateStringDistance 方法。由於該方法本身的計算開銷較大，且併發執行的線程數量越多，CPU 的消耗就會越顯著。因此在服務啓動初期，CPU 的負載急劇上升。隨着運行時間的延長，業務線程的創建和執行也趨於平衡，併發執行的線程數量大大減小，CPU 消耗也隨之減小。&lt;/p&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.2 calculateStringDistance 源碼分析&lt;/h3&gt; 
&lt;p&gt;calculateStringDistance 方法的功能是根據 Levenshtein 算法計算給定兩個字符串之間的距離或相似度。通過分析其源代碼，我們可以發現，在比較兩個字符串時，該方法採用了嵌套的 for 循環結構。在這些循環中，涉及到 length、chatAt 和 Math.min 函數的調用，這使得該方法的計算複雜度相對較高。調用量越大，CPU 消耗就會越嚴重。根據 CPU 火焰圖的分析，發現這三個函數的 CPU 消耗佔比與 calculateStringDistance 方法的 CPU 消耗佔比之間的比例高達 78%。因此在調用該方法時要小心，在高併發場景下，該方法很有可能成為系統的性能瓶頸，對 CPU 產生影響。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private&amp;nbsp;static&amp;nbsp;int&amp;nbsp;calculateStringDistance(String s1, String s2){
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(s1.isEmpty()) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;s2.length();
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(s2.isEmpty()) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;s1.length();
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;int[][] d = newint[s1.length() +&amp;nbsp;1][s2.length() +&amp;nbsp;1];
&amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;i =&amp;nbsp;0; i &amp;lt;= s1.length(); i++) {
&amp;nbsp; &amp;nbsp; d[i][0] = i;
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;0; j &amp;lt;= s2.length(); j++) {
&amp;nbsp; &amp;nbsp; d[0][j] = j;
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;i =&amp;nbsp;1; i &amp;lt;= s1.length(); i++) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;char&amp;nbsp;c1 = s1.charAt(i -&amp;nbsp;1);
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;1; j &amp;lt;= s2.length(); j++) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;cost;
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;char&amp;nbsp;c2 = s2.charAt(j -&amp;nbsp;1);
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(c1 == c2) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cost =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cost =&amp;nbsp;1;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; d[i][j] = Math.min(Math.min(d[i -&amp;nbsp;1][j] +&amp;nbsp;1, d[i][j -&amp;nbsp;1] +&amp;nbsp;1), d[i -&amp;nbsp;1][j -&amp;nbsp;1] + cost);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;return&amp;nbsp;d[s1.length()][s2.length()];
}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;calculateStringDistance 方法是如何觸發的？通過查詢堆棧信息並查看源代碼，我們發現這是 Spring 框架在解析請求參數並注入屬性的過程中所觸發的。堆棧信息如下，從上到下逐步分析堆棧，我們重點分析 setPropertyValues 和 createNotWritable-&lt;/p&gt; 
&lt;p&gt;PropertyException 這兩個方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"catalina-exec-485"&amp;nbsp;#975 daemon prio=5 os_prio=0 tid=0x00007f50e825f000 nid=0x3375 runnable [0x00007f5043ea4000]
&amp;nbsp; &amp;nbsp;java.lang.Thread.State: RUNNABLE
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.calculateStringDistance(PropertyMatches.java:170)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.access$100(PropertyMatches.java:44)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches$BeanPropertyMatches.calculateMatches(PropertyMatches.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches$BeanPropertyMatches.&amp;lt;init&amp;gt;(PropertyMatches.java:193)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.forProperty(PropertyMatches.java:68)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.forProperty(PropertyMatches.java:58)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.BeanWrapperImpl.createNotWritablePropertyException(BeanWrapperImpl.java:237)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractNestablePropertyAccessor.processLocalProperty(AbstractNestablePropertyAccessor.java:435)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractNestablePropertyAccessor.setPropertyValue(AbstractNestablePropertyAccessor.java:290)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractNestablePropertyAccessor.setPropertyValue(AbstractNestablePropertyAccessor.java:278)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:95)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.validation.DataBinder.applyPropertyValues(DataBinder.java:860)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.validation.DataBinder.doBind(DataBinder.java:756)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.bind.WebDataBinder.doBind(WebDataBinder.java:192)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.bind.ServletRequestDataBinder.bind(ServletRequestDataBinder.java:106)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.ServletModelAttributeMethodProcessor.bindRequestParameters(ServletModelAttributeMethodProcessor.java:152)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.annotation.ModelAttributeMethodProcessor.resolveArgument(ModelAttributeMethodProcessor.java:111)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:158)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest$original$3Q7HrFjh(InvocableHandlerMethod.java:128)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest$original$3Q7HrFjh$accessor$ykGmQRZT(InvocableHandlerMethod.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod$auxiliary$Wny4v5BZ.call(Unknown Source)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:849)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:760)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at javax.servlet.http.HttpServlet.service(HttpServlet.java:650)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve.invoke$original$Y7IhKDGv(StandardWrapperValve.java:219)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve.invoke$original$Y7IhKDGv$accessor$4IDmuys6(StandardWrapperValve.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve$auxiliary$1SL1DIkO.call(Unknown Source)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:104)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1136)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1775)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1734)
&amp;nbsp; &amp;nbsp; &amp;nbsp; - locked &amp;lt;0x000000070f1dc100&amp;gt; (a org.apache.tomcat.util.net.NioChannel)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at java.lang.Thread.run(Thread.java:748)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;先分析 setPropertyValues 方法，該方法負責將請求中的參數映射到目標對象的屬性上，主要是遍歷屬性列表進行賦值並進行異常統一處理，單個屬性的注入繼續看 setPropertyValue 方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public&amp;nbsp;void&amp;nbsp;setPropertyValues(PropertyValues pvs,&amp;nbsp;boolean&amp;nbsp;ignoreUnknown,&amp;nbsp;boolean&amp;nbsp;ignoreInvalid)
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throws&amp;nbsp;BeansException {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 聲明 PropertyAccessException 集合，保存單個屬性注入時拋出的 PropertyAccessException 異常
&amp;nbsp; List&amp;lt;PropertyAccessException&amp;gt; propertyAccessExceptions =&amp;nbsp;null;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 獲取屬性列表
&amp;nbsp; List&amp;lt;PropertyValue&amp;gt; propertyValues = (pvs&amp;nbsp;instanceof&amp;nbsp;MutablePropertyValues ?
&amp;nbsp; &amp;nbsp; &amp;nbsp; ((MutablePropertyValues) pvs).getPropertyValueList() : Arrays.asList(pvs.getPropertyValues()));
&amp;nbsp;&amp;nbsp;for&amp;nbsp;(PropertyValue pv : propertyValues) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 單個屬性的注入，注意：此方法可能會引發任意的 BeansException，如果存在嚴重故障（例如沒有匹配的字段），則不會在此處捕獲該異常。我們可以嘗試只處理不太嚴重的異常。
&amp;nbsp; &amp;nbsp; &amp;nbsp; setPropertyValue(pv);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(NotWritablePropertyException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 默認是 true，忽略未知屬性，因此不會拋異常
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!ignoreUnknown) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;ex;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// Otherwise, just ignore it and continue...
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(NullValueInNestedPathException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!ignoreInvalid) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;ex;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// Otherwise, just ignore it and continue...
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(PropertyAccessException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(propertyAccessExceptions ==&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; propertyAccessExceptions =&amp;nbsp;new&amp;nbsp;LinkedList&amp;lt;PropertyAccessException&amp;gt;();
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; propertyAccessExceptions.add(ex);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;// 如果 propertyAccessExceptions 不為空，需要整合起來，拋一個複合異常 PropertyBatchUpdateException
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(propertyAccessExceptions !=&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp; PropertyAccessException[] paeArray =
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; propertyAccessExceptions.toArray(new&amp;nbsp;PropertyAccessException[propertyAccessExceptions.size()]);
&amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;PropertyBatchUpdateException(paeArray);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;propertyValues 屬性的結構如下，它包含了從上游傳遞過來的所有參數。這些參數被封裝成一個集合，便於後續的處理和注入。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cc70849606402c94a225c47243073954.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;propertyValues 屬性&lt;/p&gt; 
&lt;p&gt;分析 setPropertyValue 方法，該方法主要作用是解析屬性值，如果存在嵌套屬性，則遞歸解析設置最終對應的屬性值，方法最後都會調用 setPropertyValue(tokens, pv) 方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public&amp;nbsp;void&amp;nbsp;setPropertyValue(PropertyValue pv)&amp;nbsp;throws&amp;nbsp;BeansException {
&amp;nbsp;&amp;nbsp;PropertyTokenHolder&amp;nbsp;tokens&amp;nbsp;=&amp;nbsp;(PropertyTokenHolder) pv.resolvedTokens;
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(tokens ==&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;String&amp;nbsp;propertyName&amp;nbsp;=&amp;nbsp;pv.getName();
&amp;nbsp; &amp;nbsp; AbstractNestablePropertyAccessor nestedPa;
&amp;nbsp; &amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 確定給定屬性路徑中的第一個嵌套屬性分隔符，忽略鍵中的點（如 「map[my.key]」）。
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 當配置的屬性名 propertyName 中包含'.'這樣字符時，代表需要設置嵌套屬性
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 如果存在嵌套屬性，Spring 會遞歸向下獲取最終設置的屬性，比如：a.b.c，Spring 會遞歸調用獲取到 b，c 是需要設置的屬性
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 如果沒有嵌套屬性的話。會返回自身
&amp;nbsp; &amp;nbsp; &amp;nbsp; nestedPa = getPropertyAccessorForPropertyPath(propertyName);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(NotReadablePropertyException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;NotWritablePropertyException(getRootClass(),&amp;nbsp;this.nestedPath + propertyName,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Nested property in path '"&amp;nbsp;+ propertyName +&amp;nbsp;"' does not exist", ex);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 將給定的屬性名稱解析為相應的屬性名稱令牌，如果沒有[]，則 tokens 中的 keys 為空，且 actualName、canonicalName 都等於 propertyName&amp;nbsp;
&amp;nbsp; &amp;nbsp; tokens = getPropertyNameTokens(getFinalPath(nestedPa, propertyName));
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(nestedPa ==&amp;nbsp;this) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; pv.getOriginalPropertyValue().resolvedTokens = tokens;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 設置屬性
&amp;nbsp; &amp;nbsp; nestedPa.setPropertyValue(tokens, pv);
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 設置屬性
&amp;nbsp; &amp;nbsp; setPropertyValue(tokens, pv);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;分析 setPropertyValue(tokens, pv) 方法，該方法是用來區分數組類型跟非數組類型的，大部分屬性都是非數組類型，我們分析非數組類型方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;protected&amp;nbsp;void&amp;nbsp;setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv)&amp;nbsp;throws&amp;nbsp;BeansException {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果屬性中存在[]，説明是數組，則進入該方法
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(tokens.keys !=&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp; processKeyedProperty(tokens, pv);
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 大部分都走這個方法
&amp;nbsp; &amp;nbsp; processLocalProperty(tokens, pv);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;processLocalProperty 方法的作用就是獲取屬性值，利用反射完成屬性注入。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private&amp;nbsp;void&amp;nbsp;processLocalProperty(PropertyTokenHolder tokens, PropertyValue pv){
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 獲取屬性對應的 PropertyHandler
&amp;nbsp;&amp;nbsp;PropertyHandler&amp;nbsp;ph&amp;nbsp;=&amp;nbsp;getLocalPropertyHandler(tokens.actualName);
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果不存在對應的 handler 或者，屬性是不可寫的（沒有 setter 方法）
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(ph ==&amp;nbsp;null&amp;nbsp;|| !ph.isWritable()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果屬性是 optional 類型，則直接返回
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pv.isOptional()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(logger.isDebugEnabled()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.debug("Ignoring optional value for property '"&amp;nbsp;+ tokens.actualName +
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"' - property not found on bean class ["&amp;nbsp;+ getRootClass().getName() +&amp;nbsp;"]");
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 其他情況則拋出不可寫屬性異常，佔用 CPU 較多的方法由此進入
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;createNotWritablePropertyException(tokens.canonicalName);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;Object&amp;nbsp;oldValue&amp;nbsp;=&amp;nbsp;null;
&amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 獲取屬性值
&amp;nbsp; &amp;nbsp;&amp;nbsp;Object&amp;nbsp;originalValue&amp;nbsp;=&amp;nbsp;pv.getValue();
&amp;nbsp; &amp;nbsp;&amp;nbsp;Object&amp;nbsp;valueToApply&amp;nbsp;=&amp;nbsp;originalValue;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果需要轉換，則進入此分支
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!Boolean.FALSE.equals(pv.conversionNecessary)) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果已經完成類型轉換，則直接使用
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pv.isConverted()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; valueToApply = pv.getConvertedValue();
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果需要讀取舊值，默認是 false &amp;amp;&amp;amp; 值可讀（有 getter 方法）
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(isExtractOldValueForEditor() &amp;amp;&amp;amp; ph.isReadable()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; oldValue = ph.getValue();
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(Exception ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(ex&amp;nbsp;instanceof&amp;nbsp;PrivilegedActionException) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ex = ((PrivilegedActionException) ex).getException();
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(logger.isDebugEnabled()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.debug("Could not read previous value of property '"&amp;nbsp;+
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;this.nestedPath + tokens.canonicalName +&amp;nbsp;"'", ex);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 類型轉換
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; valueToApply = convertForProperty(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; tokens.canonicalName, oldValue, originalValue, ph.toTypeDescriptor());
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; pv.getOriginalPropertyValue().conversionNecessary = (valueToApply != originalValue);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 完成屬性注入
&amp;nbsp; &amp;nbsp; ph.setValue(this.wrappedObject, valueToApply);
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;catch&amp;nbsp;(TypeMismatchException ex) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;ex;
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;catch&amp;nbsp;(InvocationTargetException ex) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;PropertyChangeEvent&amp;nbsp;propertyChangeEvent&amp;nbsp;=&amp;nbsp;new&amp;nbsp;PropertyChangeEvent(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;this.rootObject,&amp;nbsp;this.nestedPath + tokens.canonicalName, oldValue, pv.getValue());
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(ex.getTargetException()&amp;nbsp;instanceof&amp;nbsp;ClassCastException) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;TypeMismatchException(propertyChangeEvent, ph.getPropertyType(), ex.getTargetException());
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Throwable&amp;nbsp;cause&amp;nbsp;=&amp;nbsp;ex.getTargetException();
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(cause&amp;nbsp;instanceof&amp;nbsp;UndeclaredThrowableException) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// May happen e.g. with Groovy-generated methods
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cause = cause.getCause();
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;MethodInvocationException(propertyChangeEvent, cause);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;catch&amp;nbsp;(Exception ex) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;PropertyChangeEvent&amp;nbsp;pce&amp;nbsp;=&amp;nbsp;new&amp;nbsp;PropertyChangeEvent(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;this.rootObject,&amp;nbsp;this.nestedPath + tokens.canonicalName, oldValue, pv.getValue());
&amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;MethodInvocationException(pce, ex);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在該方法中，我們注意到堆棧信息中 createNotWritablePropertyException 方法的調用。實際上 calculateStringDistance 方法的高 CPU 消耗正是由此引發的。當拋出不可寫屬性異常時，系統會計算字符串的相似度，主要目的是為了向用户提供更友好的提示，幫助他們識別哪些屬性與當前屬性相似，從而判斷是否在傳遞參數時出現了錯誤。&lt;/p&gt; 
&lt;p&gt;Spring 這種設計不僅提升了用户體驗，還降低了因參數錯誤而導致的調試難度。通過提供相似屬性的建議，用户能夠更快速地發現並糾正輸入錯誤，確保請求的正確性。以下為調試過程中的部分提示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Bean property&amp;nbsp;'questionValidatorInterface'&amp;nbsp;is not writable or has an invalid&amp;nbsp;setter&amp;nbsp;method. Does the parameter type of the&amp;nbsp;setter&amp;nbsp;match the&amp;nbsp;return&amp;nbsp;type of the&amp;nbsp;getter?
bean property&amp;nbsp;'users'&amp;nbsp;is not writable or has an invalid&amp;nbsp;setter&amp;nbsp;method. did you mean&amp;nbsp;'user'?
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.3 calculateStringDistance 流程總結&lt;/h3&gt; 
&lt;p&gt;結合 Spring MVC 解析 HTTP 的請求流程，calculateStringDistance 方法的進入流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c5a198998b410036c75859840afa1f60.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;解析參數流程&lt;/p&gt; 
&lt;p&gt;Spring MVC 在解析 HTTP 請求參數時會找到對應的參數解析器，因為我們的項目中大部分都是自定義的複雜對象，因此採用的參數解析器為 ServletModelAttributeMethodProcessor。該解析器在數據綁定過程中，會循環遍歷每個參數，通過反射完成屬性注入。但是我們自定義的複雜對象在某些接口下，定義的屬性不合理，導致拋出 createNotWritablePropertyException 異常。&lt;/p&gt; 
&lt;p&gt;我們深入分析一下源碼，看看怎樣避免拋出 createNotWritablePropertyException 異常。&lt;/p&gt; 
&lt;p&gt;根據源碼，我們發現拋出不可寫屬性異常的條件是（屬性不存在對應的 handler 或者，屬性不可寫）並且屬性不是 optional 類型，只要我們保證不滿足這個條件，那麼就可以有效避免拋出該異常。&lt;/p&gt; 
&lt;p&gt;説明一下這三個條件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;屬性不存在對應的 handler 即 request 中不存在該屬性。比如請求參數中帶 version 字段，但是服務端在接受 request 中並未定義 version 字段，那麼此處 ph == null 判斷條件就成立&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;屬性不可寫，即屬性沒有對應的 setter 方法&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;屬性是 optional 類型，即屬性的數據類型是 Optional 類型&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過查看業務側的代碼，我們發現請求（request）中的所有屬性都已經定義了相應的 setter 方法，而且不存在 optional 類型的屬性。因此我們只需要關注請求中是否存在未定義的屬性。&lt;/p&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.4 排查大流量及核心接口參數&lt;/h3&gt; 
&lt;p&gt;由於服務提供的接口非常多，因此僅排查流量較高和核心的接口。經過分析，我們發現幾乎所有接口都存在未定義的屬性。&lt;/p&gt; 
&lt;p&gt;這主要是因為客户端很多參數都是公參，在傳參時會將這些公參全部透傳給服務端，但是服務端並不需要處理所有的參數，因此沒有在 request 中定義。特別備註：接口若未定義請求參數接收，則不會走上述流程。&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.5 解決方案&lt;/h3&gt; 
&lt;p&gt;既然已經明確問題的根源是請求中存在未定義的屬性，那麼接下來我們將針對這一情況進行優化。方案主要有兩個：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;在底層請求中加入客户端公參：對所有公參進行接收，確保它們能夠被正確處理。需要注意的是，參數接收將會涉及屬性注入，而屬性注入是通過反射機制實現的。這一過程可能對 CPU 和接口性能產生影響，因此我們也需要進行實驗，以評估這些參數解析的實際效果。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;在 filter 層針對接口去除相關字段：通過在過濾器層面過濾掉不必要的字段，避免接口中出現未定義的屬性。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;最終我們混合兩種方案：對於大部分公共參數，定義到底層 request 中；對於非公共參數，針對接口進行移除。&lt;/p&gt; 
&lt;p&gt;我們針對大流量接口及核心接口進行了優化，優化後效果如下：&lt;/p&gt; 
&lt;p&gt;結論：整體效果顯著，但仍存在一些不足之處。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;CPU 使用情況&lt;/strong&gt;：在高峯期重啓應用時，CPU 的突發情況明顯減弱，持續時間從 5 分鐘縮短至 1 分鐘。同時 CPU 和 Runnable 線程數仍會出現小幅波動，但 Runnable 線程數的波動持續時間已從 6 分鐘縮減至 40 秒，波動峯值也由 600 降低至 280。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;接口性能&lt;/strong&gt;：接口的 P95 和 P99 耗時均有所降低，其中 P95 峯值從 53 秒降至 3.4 秒，P99 峯值從 1 分 50 秒降至 50 秒。此外，響應時間較長的時間段也得到了縮短，持續時間從 7 分鐘減少到不到 2 分鐘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;發版及日常運行&lt;/strong&gt;：在發版期間及日常運行中，CPU 峯值普遍降低。與前 1 天和前 7 天的平均 CPU 使用率相比，最大和最小使用率均有所下降，幅度明顯。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;① 啓動後 CPU 使用率情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4912336ab2d7bdc8083d05cf3d17cd1a.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 線程數情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//91e04839dc6184825966b004e62ffa91.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 線程數&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f1879456a68bab5f04dd6cefc79aaa5a.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 線程數&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;③ 接口響應時間情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9de3e1b9a261f06dbfd86fd6a64c5ab9.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接口響應時間&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;④ 運行一段時間後，CPU 使用率情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c3f85b69c1dd77a5861070bdd0f90c38.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;span id="OSC_h2_20"&gt;&lt;/span&gt; 
&lt;h2&gt;5.2 優化後再次分析 CPU 火焰圖&lt;/h2&gt; 
&lt;p&gt;優化後效果雖然好了很多，但是 CPU 和 Runnable 線程數仍會出現小幅波動，接口的響應時間在 1 分鐘內仍有上漲。這是我們接下來要繼續優化的目標。&lt;/p&gt; 
&lt;span id="OSC_h3_21"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.1 編譯階段消耗 CPU 佔比高&lt;/h3&gt; 
&lt;p&gt;再次使用 arthas 進行監測，查看正常情況與啓動後（異常情況）的 CPU 消耗情況，我們可以觀察到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;runWoker 部分：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該部分的 CPU 佔用比例正常，與平時的表現一致，未見異常波動。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;編譯相關的 CPU 佔用：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CompileBroker::invoke_compiler_on_method(CompileTask*) 佔用 CPU 較大，特別是 C2Compiler::compile_method(ciEnv*, ciMethod*, int) 的佔比顯著&lt;/p&gt; 
&lt;p&gt;由此我們得出結論：編譯階段的 CPU 消耗佔比異常，可能是導致 CPU 負載突刺的重要因素。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① 異常情況下 CPU 火焰圖：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//358b54cf05ca85c707e7a9b636e4ba11.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;異常 CPU 火焰圖&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 正常情況下 CPU 火焰圖：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//8736bb5cd5d70f06959491e2d9729028.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;正常 CPU 火焰圖&lt;/p&gt; 
&lt;span id="OSC_h3_22"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.2 用 arthas 換個角度驗證&lt;/h3&gt; 
&lt;p&gt;CPU 火焰圖是基於啓動後 3 分鐘內的綜合數據採集而生成的，雖然能夠提供整體的 CPU 使用情況，但無法反映 CPU 的實時變化。因此，為了更準確地驗證編譯階段是否確實消耗了 CPU，我們需要登錄到機器上，使用 Arthas 進行實時監測。&lt;/p&gt; 
&lt;p&gt;機器啓動後，運行 dashboard 命令，重點關注屏幕上方的進程信息，以識別哪些線程佔據了較高的 CPU 資源，以下為其中一次波動的截圖，前幾次波動 CPU 佔比都差不多：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e26f168e8937e370278c49578b95b790.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;dashboard 命令&lt;/p&gt; 
&lt;p&gt;從圖中可以看到， CompilerThread 的三個線程佔用了較高的 CPU 資源，尤其是 C2 CompilerThread 的佔比明顯，這與之前通過火焰圖所反映的情況一致。&lt;/p&gt; 
&lt;span id="OSC_h3_23"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.3 CompilerThread 是什麼&lt;/h3&gt; 
&lt;p&gt;C1 C2 CompilerThread 是 Java HotSpot 虛擬機中的兩個即時編譯器，主要作用是將 Java 字節碼在運行時編譯成本地機器碼，以提高程序的執行效率。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;C1 Compiler（也稱為客户端編譯器），主要用於快速編譯，優化較少，適合需要快速啓動的應用。它的編譯速度較快，但生成的機器碼執行效率相對較低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;C2 Compiler（也稱為服務端編譯器），主要用於高性能的編譯，優化程度較高，適合長時間運行的應用。C2 編譯器會花費更多時間進行優化，以生成更高效的機器碼，適合對性能要求較高的場景。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 HotSpot 虛擬機中，Java 程序最初都是通過解釋器（Interpreter）進行解釋執行的，解釋器的優點是啓動快，省去編譯的時間，能夠快速運行代碼。但隨着程序的執行，某些方法或代碼塊可能會被多次調用，這些被頻繁調用的代碼被稱為「熱點代碼」（Hot Spot Code）。當虛擬機識別到熱點代碼時，它會啓動 JIT 編譯器（C1 或 C2）將這些代碼編譯成本地機器碼，以提高執行效率。&lt;/p&gt; 
&lt;p&gt;HotSpot 虛擬機是解釋器與即時編譯器並存的架構，兩者經常是相輔相成地配合工作。由於即時編譯器編譯本地代碼需要佔用程序運行時間，編譯出優化程度更高的代碼所需的時間也會相應增加。此外為了實現更高的優化，解釋器需要為編譯器收集性能監控信息，這在一定程度上也會影響解釋執行階段的速度。為瞭解決這一問題，並在程序啓動響應速度與運行效率之間達到最佳平衡，HotSpot 虛擬機在其編譯子系統中引入了分層編譯的功能。通過這一機制，HotSpot 能夠根據代碼的執行頻率和性能需求，逐步將字節碼編譯為本地機器碼，從而在保證快速啓動的同時，優化長時間運行的代碼性能。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.4 解決方案&lt;/h3&gt; 
&lt;p&gt;截止到現在，問題的原因就變得十分清晰了：當流量湧入時，HotSpot 虛擬機啓動了分層編譯機制，期間大部分代碼迅速轉變為熱點代碼。在這個過程中，C2 編譯器需要頻繁佔用 CPU 資源進行編譯，導致 CPU 使用率顯著上升。隨着大部分熱點代碼的優化完成，C2 編譯器對 CPU 的佔用將逐漸減少，CPU 使用率也會隨之下降。這一編譯過程的持續時間與監控圖上的 CPU 波動情況高度一致。&lt;/p&gt; 
&lt;p&gt;C1 和 C2 編譯器雖然提供了關閉的參數選項，但關閉這些編譯器無疑會對服務的運行性能產生負面影響。網絡上也有相關實驗案例表明，對於需要長期運行的 Java 後端服務，禁用這些編譯器將導致性能顯著下降。因此這種關閉編譯器的方式並不值得嘗試。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解決方案一：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前文中，我們已經驗證了流量逐步放量對機器的影響：採用灰度發佈，對機器幾乎沒什麼影響，各項指標表現都很平穩。由於歷史原因，我們的服務當前無法支持灰度發佈，因此還需要探索其他有效的解決方案。&lt;/p&gt; 
&lt;p&gt;我們可以換個角度思考：是否可以通過降低接口的請求 QPS，並將發版時間固定在每天流量最低的時段，以觀察對服務啓動的影響。&lt;/p&gt; 
&lt;p&gt;首先，我們可以優先關注大流量接口，並嘗試減少這些接口的 QPS。通過優化接口請求的頻率，我們或許能夠在發版過程中減輕對系統的壓力。&lt;/p&gt; 
&lt;p&gt;降低接口 QPS，調整重啓服務的時間（非高峯期），12:13:59 恢復流量成功，實驗效果如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;恢復流量後 CPU 最高峯值為 61.5%（依舊有小突刺，但是對業務無影響）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Runnable、Blocked 線程數不再有突刺&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;接口響應時間（RT）也比較平穩&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;日誌不再告警，無 error 錯誤日誌&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;① CPU 使用率情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//626e46d5af3e6130174792c68bea26c6.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 線程指標如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c4b821d566b0c09cb9848e68b198ad1b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 線程數&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a8f80feebc04db763c19655bede37681.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 線程數&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;③ 接口響應時間情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//41d2850bb678d230ac1c1add16b70335.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接口響應時間&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解決方案二：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;方案一雖然能夠在一定程度上緩解問題，但治標不治本。此外我們也無法固定發版時間，因此最有效的策略是進行預熱。與前文不同的點在於，此處是 JVM 預熱。&lt;/p&gt; 
&lt;p&gt;方案為：在系統成功啓動（監測 check.do 返回成功）後，接入線上 HTTP 流量之前，針對大流量接口及核心接口進行 HTTP 接口調用，頻控次數為配置項，方便線上動態調整。特別注意：在剛啓動時，如果機器或下游依賴出現故障，此處的額外調用會加劇系統或下游的負擔，因此調用次數需要合理配置。&lt;/p&gt; 
&lt;p&gt;此方式可以讓 C2 編譯器提前對熱點代碼進行優化，在系統在系統穩定後再將流量接入生產環境，從而避免對用户造成任何影響。&lt;/p&gt; 
&lt;p&gt;觀察啓動後的各項指標，14:56:25 恢復 HTTP 流量成功，實驗效果如下：&lt;/p&gt; 
&lt;p&gt;整體表現與之前的方案一相似，但是有一個顯著的區別：在恢復 HTTP 流量之前，Runnable 線程數出現了明顯的突刺，而在流量恢復後，這種突刺現象則不再出現，線程數已經趨於平穩。我們注意到突刺出現的時間節點是 14:55:25，這個時間點正好是我們預熱時發起 HTTP 接口調用的時間。&lt;/p&gt; 
&lt;p&gt;這表明通過預熱策略，我們有效地前置了系統的負載波動。當真正的用户請求到達時，系統已經趨於平穩，服務響應速度保持穩定，從而為用户提供了更加流暢的體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① CPU 使用率情況如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3ede52f825b29ea6085afd0dbf6c32c2.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 線程指標如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//b4e11728f36cf7ed5f7490ab024b857f.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 線程數&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//32152718fa8265f6e8e7524b94e66a5b.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 線程數&lt;/p&gt; 
&lt;span id="OSC_h1_25"&gt;&lt;/span&gt; 
&lt;h1&gt;六、總結&lt;/h1&gt; 
&lt;p&gt;本文針對服務啓動後幾分鐘內 CPU 持續處於高峯狀態的問題，提出了自己的分析思路與解決方案。最終線上效果比較顯著，成功解決了每次發版過程中頻繁告警、業務受損以及用户體驗不佳的問題，為服務的高可用性增添了一道重要保障。最初的分析不夠深入，導致在內存緩存預熱方面的努力未能產生預期效果。因此在未來遇到類似問題時，我們必須深入挖掘，直至找到問題的根本原因。&lt;/p&gt; 
&lt;p&gt;本文的重點在於問題的發現、分析及解決思路。對於 CPU 相關的問題，火焰圖和 Arthas 是非常有效的工具，建議大家在遇到類似情況時，積極嘗試使用這些工具進行排查和解決。&lt;/p&gt; 
&lt;p&gt;此外 HTTP 請求未定義屬性的問題普遍存在，特別是在服務未進行預熱啓動時，會加劇 CPU 的負載。對於大流量服務而言，遇到此類問題時，需規範請求參數，以減輕 CPU 負擔。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18685693</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18685693</guid>
      <pubDate>Thu, 17 Jul 2025 07:12:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>特朗普希望重命名「人工智能」術語，改為「天才智能」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;當地時間 7 月 23 日，美國總統特朗普在華盛頓特區舉行的人工智能峯會上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAcyn%2Fstatus%2F1948137088945369220" target="_blank"&gt;發言&lt;/a&gt;，他表示自己不喜歡「人工智能」（ Artificial Intelligence）這個術語表述，建議改名「天才智能」。&lt;/p&gt; 
&lt;p&gt;特朗普在講話中稱，自己不喜歡 AI 中「Artificial」一詞，「我忍不了任何造作的東西，我甚至不喜歡人造東西這個名字」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/145318_T5L4_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他還表示，「&lt;strong&gt;AI 是天才的，是純粹的天才，我建議把它改名天才智能。&lt;/strong&gt;」特朗普在講話中強調，自己這個想法是「認真的」。&lt;/p&gt; 
&lt;p&gt;根據英國牛津英語詞典，Artificial 一詞除了「人工、人造」外，也有「矯揉造作」的含義。&lt;/p&gt; 
&lt;p&gt;值得一提的是，據外媒相關報道：&lt;a href="https://www.oschina.net/news/362050"&gt;美國政府將簽署大量有關 AI 產業的行政令&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;據介紹，這些行政令內容涵蓋多個方面，包括建立支持數據中心、半導體製造工廠建設的舉措，完善國家電力網絡，以及消除 AI 大模型對話中所謂的「意識形態偏見」等。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362115</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362115</guid>
      <pubDate>Thu, 17 Jul 2025 06:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>脈脈：超四成國內 AI 頭部公司員工欲跳槽</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;脈脈平台&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;最新&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;數據顯示，截至 2025 年 7 月，國內 AI 頭部公司員工的跳槽意願顯著高於其他行業。高達&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#242424"&gt;41.07%&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的 AI 從業者目前處於「正在看機會」的求職狀態，這一比例遠超互聯網行業的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#242424"&gt;14.65%&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;自今年 2 月以來，每月新增上萬名 AI 人才將其求職狀態更新為「正在看機會」，這充分體現了 AI 人才市場的高度活躍性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="216" src="https://oscimg.oschina.net/oscnet/up-3e5948b9574d255f2fff9c5a87be1ffdfe1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;與此同時，企業間的「搶人大戰」已進入白熱化階段。目前已有超過&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;1000 家 AI 公司&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;在脈脈平台發佈了 AI 相關崗位。為了吸引&lt;span&gt;頂尖&lt;/span&gt;人才，包括華為、小紅書、DeepSeek 等在內的知名企業高管也親自上陣，在個人主頁簽名中明確標註「長期招人」。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，HR 和獵頭在平台上的活躍度達到「分鐘級」，AI 人才的個人主頁訪問量也因此激增，顯示出市場對 AI 人才的迫切需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362114</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362114</guid>
      <pubDate>Thu, 17 Jul 2025 06:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>基於 Python-use 範式的開源 Agent</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="text-align:left"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;「傳統 Agent 框架更像是用低代碼拖拽的「機器人編排器」，&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Python-use 則是直接用 Python 把 Agent 邏輯實現出來，讓代碼就是 Agent。」&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;當大多數 Agent 框架還在把「工具」當作黑盒 API 時，知道創宇 AI 業務部總經理王利偉和其團隊在思考另一種方式——如果代碼就是工具，而 LLM 恰好擅長寫代碼，為什麼不乾脆讓 AI 自己用 Python 把任務跑出來？&lt;/p&gt; 
&lt;p&gt;在這篇訪談中，王利偉系統闡述了「Python-use 範式」——一種把 Agent 邏輯直接寫成可執行 Python 的極簡思路。它拋棄繁複的 Schema 註冊、Workflow 編排和多 Agent 協商，實現細粒度代碼控制，邏輯可控、可調試、最少 Token 浪費。&lt;/p&gt; 
&lt;p&gt;本週六，王利偉將出席【Al Agent：從工具助手到自主行動】OSC 源創會·杭州站活動，並發表《基於 Python-use 範式的開源 Agent》主題演講，介紹如何撮合 LLM ➕Python 生態形成強大的智能體，通過獨創的 Python-use 範式，讓 AI 不光會調用工具，也會自己造工具。&lt;/p&gt; 
&lt;p&gt;即刻報名：&lt;a href="https://www.oschina.net/event/8597955"&gt;https://www.oschina.net/event/8597955&lt;/a&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="1067" src="https://oscimg.oschina.net/oscnet/up-f2c70b12c7d35ded92d220bd2c56ab5987b.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：您提出「Python-use 範式」與傳統 Agent 開發框架的核心差異是什麼？它如何解決現有 Agent 工具調用能力的侷限性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;答：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;回答這個問題之前，我們先定義一下什麼是「工具」，眾所周知「工具」調用是 Agent 的基本能力之一。工具到底是什麼呢？是各種應用程序，接口對吧。從根本上來講都是代碼，代碼組成了 MCP 工具、API 工具以及各類應用程序。Python use 範式是迴歸第一性原理，把 code 當成工具，code 是所有工具的最基本構成，code 可以組成各種各樣的工具，而 LLM 對 code 的理解和編寫能力都足夠強，相比依賴於現成的工具，Python use 是從代碼出發，具有靈活性、擴展性。當然，在這過程 Python use 也是支持現有工具的調用的，比如 MCP、browser use 等等。而對於一些碎片化的場景，沒有標準工具、現成工具可以用的場景，Python use 可以依賴於 Python 編碼自行找到更具創造性的方案。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;一句話總結：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;傳統 Agent 框架更像是用低代碼拖拽的「機器人編排器」；&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 則是直接用 Python 把 Agent 邏輯實現出來，讓代碼就是 Agent&lt;/p&gt; 
&lt;div&gt; 
 &lt;table cellspacing="0" style="border-collapse:collapse; border:none; table-layout:fixed; width:500px"&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;維度&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;傳統 Agent 開發框架&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;Python-use 範式&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;任務驅動邏輯&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;通過「規劃 → 調度 → 工具調用 →反饋」的多層 Agent、子-Agent、workflow 實現任務拆解和執行。往往是圖狀、嵌套、多 Agent。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;直接寫出「任務目標 → 代碼邏輯 → 執行」的 Python 腳本來解決任務，代碼即規劃+工具調用+執行的統一體。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;工具調用&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;工具通常封裝為 function calling / Tool 類、API schema，由 Agent 通過有限的模板化調用（受限於預定義接口和框架支持的函數集合）。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;直接調用 Python 生態中任意庫、API、命令行、HTTP、數據庫等，甚至動態生成和運行代碼，無需提前註冊工具。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;靈活性&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;強調框架內一致性和安全性，但犧牲了靈活性。增加一個新工具需要寫 schema、註冊、重訓練或適配。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;由於直接寫 Python 代碼，可以隨時引入任何新工具、任意組合庫、甚至嵌入 shell/JS 等。靈活性最大。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;執行粒度&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;依賴大量 LLM 推理+中間規劃，執行粒度粗，容易浪費 token、出錯。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;細粒度代碼控制，邏輯可控、可調試、最少 token 浪費。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;至於如何解決現有 Agent 工具調用能力的侷限性大體分析如下：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;現有 Agent 框架在工具調用上主要有兩個侷限：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;1、工具註冊繁瑣且封閉：需要開發者把工具寫成符合接口的形式並註冊進 Agent 系統。靈活性低、擴展慢。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;2、推理成本高+錯誤多：每次工具調用都可能需要 LLM 去推理哪個工具+如何填參數，容易出錯，且慢。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 通過：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;代碼即接口：不需要任何預定義 schema、function calling 註冊。Python 裏能 import / pip install 的庫、調用的 API，都是工具。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;動態生成工具：Python 裏可以即時生成函數、類、模塊，甚至臨時下載或拼接代碼然後執行，完全不受限。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;全棧生態：Python 能調用系統命令、數據庫、網絡請求、爬蟲、機器學習、雲 API… 不再被框架內置的工具集限制。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;例如：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;傳統 Agent 框架裏，你要增加對某個第三方 CRM 的支持，得寫 Tool 類、註冊 schema、讓 LLM 學會調用。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 裏，你直接用 requests 或 SDK 寫個接口調用完事。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;傳統 Agent 範式假設：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;人類用自然語言説「你去幹 X」，AI 負責拆解成多步計劃+調度各種工具完成。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 範式更像：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;人類寫出一段 Python 程序告訴 AI 怎麼幹，或者 AI 直接生成出一段 Python 程序來幹。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;即：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;傳統是 LLM+流程編排器+有限工具集&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 是 LLM+Python 解釋器+全 Python 生態&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：「讓 AI 自己造工具」是演講的亮點。能否解釋 LLM 在 Python-use 範式中如何完成從「使用工具」到「生成工具」的跨越？關鍵技術難點是什麼？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;使用工具其實只是一個思維方式的差別生產工具，只是一張窗户紙，只是大家對 LLM 的理解以及應用方式的差別。使用工具 tool use 是假定要處理的任務都有各種現成的工具可以使用，Python use 一樣也具備這個能力，並不是説它就不支持現有工具的調用，Python use 認為 code is agent ，code is everything，Python 可以 use network、use computer 可以 use 各類工具，它可以 use code 去編碼、寫工具。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在傳統 Agent 中：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;LLM 能做到的通常是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;選擇一個已有工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;正確填寫參數調用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;（最多）按照文檔組合幾個已有工具完成目標&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="text-align:left"&gt;它的「能力邊界」被框架裏預定義的 function/schema 限死了。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在 Python-use 中：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;LLM 不光能調用庫和工具，還可以：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;根據任務需要動態生成代碼段（工具）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;把這段代碼封裝成函數/類/模塊/腳本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;並且可以即時運行、測試、調試它&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="text-align:left"&gt;也就是説，它不只是「調用工具」，它還能寫工具！&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;舉個例子：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#d83931"&gt;「幫我把一堆 Excel 按部門拆分成不同的 PDF 併發郵件」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;傳統 Agent：找不到現成的「拆 Excel 發 PDF」工具，任務失敗或需要人手擴展工具。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use：LLM 生成一個函數&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#2ea121"&gt;def split_excel_and_send():&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#2ea121"&gt;# pandas, fpdf, smtplib 邏輯&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;運行測試、修復 bug、保存。這段代碼就是一個新造出來的「工具」，下次還能直接用。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;為什麼 Python-use 能支持「造工具」？關鍵在於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;LLM 生成的就是代碼，代碼本身就是工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Python 解釋器支持動態定義、動態執行、動態 import 模塊&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全 Python 生態的庫讓「造工具」成本極低&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;人類可以隨時 review、微調、持久化新工具&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;當然，這個跨越不是輕易做到的，主要有幾個挑戰：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;代碼生成的正確性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;LLM 寫出的代碼可能語法正確但邏輯錯誤&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對外部庫版本/接口調用不熟導致出錯&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;沒有即時驗證的環境，bug 率高&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;上下文管理&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;造出來的工具需要有清晰的輸入輸出和作用域&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果任務複雜，代碼的組織結構（函數拆分、模塊化）很容易混亂&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;安全性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;動態生成的代碼有潛在的安全風險（注入惡意代碼、破壞環境、泄露數據）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要沙箱或審核機制&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;��&lt;/p&gt; 
&lt;p style="text-align:left"&gt;怎麼克服這些難點也有對應的思路和方案，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;內置單元測試和驗證，讓 LLM 順便生成測試用例或自動運行測試，提高正確性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;設計合理的 prompt 模式，指導 LLM 輸出模塊化、註釋良好、易維護的代碼。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用虛擬環境+沙箱，讓生成和執行的代碼不破壞主環境，保障安全。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;版本控制+註冊，把造出來的工具保存到 Git、註冊到私有 PyPI 或工具庫中。&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;總結一句話：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在 Python-use 中，LLM 不只是「選工具」，而是可以直接寫出滿足當前任務的新工具、即寫即用；&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而傳統 Agent 則停留在「調用已有工具」階段，受限於框架的工具集。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：Python 生態有海量開源庫，但 LLM 常因依賴、環境問題調用失敗。Python-use 如何實現 LLM 與本地 Python 環境的高效安全交互？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;這個問題提的非常好，確實是有各類的版本問題、兼容性、依賴關係問題等等。解決方案是它在執行任務的時候不侷限一個方案，一個不行會切換到另外的方案，大模型知道怎麼解決。如今 vibe coding 都是差不多的思路，有錯誤，再重新丟給大模型去分析提出修正就好了，直到運行成功。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;另外一個方法是，在執行任務的時候會把用户系統相關的版本信息、環境信息做收集，發給模型和 TrusToken-也就是我們的 token 分發平台及網關，TrusToken 上會集成很多場景的「最佳實踐」形成經驗庫、知識庫，從而幫會根據用户環境做最優匹配，可以理解是 TrusToken 上面做了很多優化。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;至於安全問題，上個問題也提到過，理論上確實存在安全風險，我們也有考慮安全模塊，也有方案，還沒來得及做。一個安全公司在做產品的時候並沒有把安全機制放在首位是有其他考慮，我們完全可以做個沙盒，但是為什麼不做沙盒，放到沙盒限制了太多功能，實質上我們電腦上大多數軟件都是運行在本機，並沒有沙盒，只有殺毒軟件才會有。理論上安全風險幹什麼都存在，與安全風險共舞，不因噎廢食。實質上，從現在幾萬註冊用户的使用反饋來講，還沒有安全問題被提出。當然，隨着項目的成熟會把響應的機制逐漸完善，現在是有想法沒精力，從技術上來講不是不可解決的難題。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：在操作物聯網設備中，智能體如何統一處理不同品牌/協議設備的接口差異？是否依賴預設插件？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;充分信任和利用大模型，他對現有的品牌協議他都懂，主流的接口標準、協議他都學習過的，這些知識他比人熟。如果是定製化的軟件它沒有學習過，直接寫到 API 描述裏，大模型通過 API 描述學習，當然對 api 描述就有一定的要求，實在它不懂的就給他外掛説明。AiPy 操作物聯網設備並不是依賴插件，主要是通過 API Calling ，當然有插件可以調用也是極好的，實際上我們也在準備發佈插件商城。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;提到這個問題不得不提一下我們團隊的另外一個產品 ZoomEye.org，它是全球領先的網絡空間資產測繪平台，它通過對全球 IPv4 和 IPv6 地址進行探查，能夠識別數十億聯網設備的開放端口、服務類型、協議棧、操作系統、硬件廠商、固件版本等關鍵資產信息。換句話説，ZoomEye 就像是整個網絡世界的「顯微鏡」或「地圖系統」，讓你可以一眼看清某個 IP 背後部署了哪些設備、跑着什麼服務、使用了什麼協議。它支持的協議識別範圍極廣，涵蓋操作系統、網絡設備等傳統 IT 系統、工業控制系統（如 Modbus、BACnet）、攝像頭設備（如 ONVIF）、網絡存儲（如 NAS）、IoT 中控網關、智能家居等，這些恰恰是大多數傳統 Agent 系統難以應對的「黑盒」。我們正在探索將 ZoomEye 的識別能力與 AiPy 結合：AI 可以在執行任務前，通過 ZoomEye 自動識別目標設備類型、開放接口、固件版本，進一步提高調用準確率和安全性。這種從「識別 → 理解 → 控制」的閉環，將極大提升 AI 操控物聯網設備的普適性與穩定性。現在 ZoomEye 也已經發布了 MCP 和 API，大家可以去體驗。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：如何吸引開發者加入 Python-use 生態？會提供哪些 SDK 或工具鏈降低接入成本？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;因為項目還在初期，暫時還沒有 SDK 之類的工具，為了方便開發者調試，給大家的支持就是提供了大量 Token 進行試錯調試，默認 1000 萬 token，開發者可以憑貢獻持續兑換。我們後續會開放商城，商城裏可以發佈各種插件、成果、知識庫、角色、API、MCP 等等，開發者也可以貢獻各類插件或應用到商城，優秀的成果我們也會做一些激勵措施。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;隨着項目的推進我們會持續優化改進生態，也歡迎大家提意見。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;問：對於想嘗試 Agent 開發的團隊，您認為切入此領域最應優先掌握的三大能力是什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;説實話這個問題我並不太敢回答，一是因為我們走的路和別人不一樣，二我們自己還並沒有成功，沒有資格去給別人指點什麼。只能單純的分享自己的幾個感受：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;模型能力足夠強，有很大的挖掘潛力。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;以前是語料驅動模型，現在是數據驅動 Agent，對要做的場景 know how 掌握了多少是關鍵。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;不管你啥範式，啥技術，不出 1 個月時間大家都能做到，大家也看到了現在大模型之間的能力差距差別是越來越小了，技術之外的優勢可能才是競爭力。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;em&gt;&lt;img height="2676" src="https://oscimg.oschina.net/oscnet/up-aeeb1d545d5e5ab92f8a3b5d959269e8da3.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18685742</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18685742</guid>
      <pubDate>Thu, 17 Jul 2025 06:47:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>中國證明開放權重模型優於 GPU 算力資源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;國外科技媒體 The Register 近日&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2025%2F07%2F19%2Fopenai_us_china%2F" target="_blank"&gt;發文&lt;/a&gt;&lt;/u&gt;討論了開放權重模型對 AI 技術進步的正面影響，稱中國企業通過開放分享和底層創新，比如 DeepSeek 和 Kimi 系列模型，展現了更高的效率和更強的競爭力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/143507_tWgV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;文章標題十分坦誠——&lt;em&gt;《&lt;strong&gt;China proves that open models are more effective than all the GPUs in the world&lt;/strong&gt;》&lt;/em&gt;，直接提出「&lt;strong&gt;中國證明開放權重模型比 GPU 更有效&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心內容&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. OpenAI 延遲發佈「開放權重」模型&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;自 GPT‑2 以來，OpenAI 已多年未對外開源其模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;原計劃在本週發佈一個社區友好型開源模型，但因安全審查推遲。CEO Sam Altman 表示，「一旦權重公佈，就無法撤回，我們必須確保萬無一失」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 美國雖投資重金，但開放模型依然乏善可陳&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;美國在 GPU、計算資源上投入數百億美元，卻僅湧現出少數效率和實力不足的開源模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;譬如 Meta 發佈的 Llama 4&amp;nbsp;遭遇爭議與冷淡反響；微軟、IBM、谷歌亦推出體量較小、功能侷限的模型&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 中國在開源領域反超&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中國開發者不僅率先發布公開可用的大規模模型，而且算法創新表現突出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DeepSeek R1（DeepSeek）早在年初便問世，後來 Moonshot AI 於 7 月推出的 Kimi 2 更聲稱已實現萬億參數規模 MoE（專家專家模型），並宣佈超越包括西方頂尖私有模型在內的技術水平。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文章強調，儘管美企掌控大量計算資源，但因開源保守與發佈緩慢，在社區驅動的模型研發上落後於中國。從戰略上看，美國若想保持 AI 領導力，除了硬件投入，更應適當開放、加快社區驅動的模型生態——否則將繼續被中國「公開優先」（open-first）的路線追趕。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362109</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362109</guid>
      <pubDate>Thu, 17 Jul 2025 06:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源鴻蒙機器人操作系統 M-Robots OS 正式開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;深開鴻宣佈 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fatomgit.com%2Fm-robots" target="_blank"&gt;M-Robots&lt;/a&gt; 開源項目正式啓動。該項目由開放原子開源基金會孵化、深開鴻牽頭髮起，旨在以開源共建的方式打造基於開源鴻蒙的統一機器人操作系統 M-Robots OS，推動機器人行業生態融合、能力複用、智能協同。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，M-Robots OS 是全國首個基於開源鴻蒙構建的分佈式異構多機協同機器人操作系統，具備多機實時協同、多硬件形態兼容、AI 原生以及豐富 API 與開發工具鏈四大核心能力，為行業提供「底層統一、場景多元」的全棧式系統平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-16538ff9cdf050ddcfc6cd2069b9c349cfe.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;M-Robots OS 開源計劃將以分階段、全棧式策略推進，逐步釋放關鍵能力，推動機器人生態融合：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2025 年 7 月 24 日：首期開源， 已上線開源鴻蒙機器人核心子系統、核心三方中間件庫、包管理器、可視化開發／調試工具；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2025 年 12 月：發佈公板芯片適配、專屬驅動框架、分佈式反控機制、DFX 能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2026 年 6 月：開放混合部署架構、超級設備支持、軟總線增強、融合組網技術及 AI 訓練工具；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2026 年 12 月：推出 M-DDS 分佈式通信框架、分佈式算力調度、多機協同支持、AI-Agent 框架與仿真工具鏈；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2027 年：實現基於 Agent 的羣體智能協作體系，推出統一機器人 IDE 開發環境。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;M-Robots OS 將按照「每年兩大版本」的節奏持續演進，開源範圍可能會根據技術發展、場景變化、需求優先級進行調整。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，該項目已匯聚包括深開鴻、中軟國際、數字華夏、樂聚機器人、哈工大重慶研究院、北京工業大學、北京理工大學在內的 21 家「產學研用」成員單位，成立項目管理委員會（PMC）與多個 SIG 技術組，覆蓋架構、運動控制、具身智能等關鍵方向，推動跨廠商協作與產業場景落地。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362103</guid>
      <pubDate>Thu, 17 Jul 2025 06:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 應用部門迎來新任首席執行官</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Instacart 首席執行官 Fidji Simo&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Ffidjissimo%2Fstatus%2F1947341053209501716" target="_blank"&gt;宣佈&lt;/a&gt;，將在 8 月 18 日正式加入 OpenAI，並擔任新部門的 CEO。Simo 同時在 OpenAI 官網發佈了一篇&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fai-as-the-greatest-source-of-empowerment-for-all%2F" target="_blank"&gt;深度長文&lt;/a&gt;，主要闡述了她對 AI 如何賦能和改變人類的看法。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1040" src="https://static.oschina.net/uploads/space/2025/0724/141245_kGM8_2720166.png" width="2244" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;幾周後，我將加入 OpenAI 擔任應用部門首席執行官，致力於讓 OpenAI 的技術惠及全球更多人羣。&lt;/p&gt; 
 &lt;p&gt;我一直認為自己是一名務實的技術從業者我熱愛技術，並非因其本身，而是因其能對人們的生活產生直接影響。這正是這份工作令人興奮之處，因為我相信，AI 將比歷史上任何其他技術為更多人帶來更多機遇。如果我們能正確運用 AI，它將賦予每個人前所未有的力量。&lt;/p&gt; 
 &lt;p&gt;但我也明白，這些機遇不會憑空出現。&lt;/p&gt; 
 &lt;p&gt;每一次重大的技術變革，都可能拓寬人們獲取權力的渠道這種權力包括做出更明智決策、塑造周遭世界以及以新方式掌控自身命運的能力。但與此同時，技術變革也可能導致財富和權力進一步集中在少數人手中通常是那些本就擁有金錢、資歷和人脈的人。&lt;/p&gt; 
 &lt;p&gt;因此，我們必須有意識地規劃這些技術的構建與共享方式，以確保它們能為更多人帶來更多機遇和繁榮。我們當下的選擇，將決定這場即將到來的變革會讓所有人都獲得更多賦能，還是讓少數人進一步集中財富和權力。&lt;/p&gt; 
 &lt;p&gt;我們可以從確保賦能與機遇的關鍵要素被廣泛獲取做起，這些要素包括知識、健康、創造性表達、經濟自由、時間和支持。下文將詳細闡述 AI 在改變人們生活的這些方面所具有的潛力。&lt;/p&gt; 
 &lt;p&gt;如果我們能讓智能無處不在、人人可用且通俗易懂，就能打造出世界上最強大的機遇引擎，幫助更多人過上更美好的生活。我期待與 OpenAI 才華橫溢的新同事們共同構建這樣的未來，也會在不久後分享更多內容。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;公開資料顯示，Simo 職業生涯始於 eBay，曾擔任戰略團隊成員，專注於本地商務和分類廣告項目的開發。2011 年，她加入了 Facebook，並逐步晉升為 Facebook 應用的負責人，領導包括 NewsFeed、Stories、Groups、Video、Marketplace、Gaming、News、Dating 和廣告等核心產品的開發。在她的推動下，Facebook 的視頻戰略取得了顯著進展，推出了自動播放視頻、FacebookLive 和 FacebookWatch 等功能。她還帶領團隊構建了 Facebook 的移動廣告業務，為公司的發展做出了重要貢獻。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362101</guid>
      <pubDate>Thu, 17 Jul 2025 06:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>預計 2029 年中國數據倉庫軟件市場規模將達 20.9 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;國際數據公司（IDC）於近日發佈了《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmy.idc.com%2Fgetdoc.jsp%3FcontainerId%3DprCHC53700025" target="_blank"&gt;2024 年下半年中國數據倉庫軟件市場跟蹤報告&lt;/a&gt;》。IDC 數據顯示，2024 下半年中國數據倉庫軟件市場規模為 5.5 億美元，同比增長 8.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其中，本地部署數據倉庫軟件規模 2.8 億美元，同比增長 6.8%；公有云數據倉庫軟件規模 2.6 億美元，同比增長 10.9%。IDC 預測， 到 2029 年，中國數據倉庫軟件市場規模將達到 20.9 億美元，2024-2029 的 5 年市場年複合增長率（CAGR）為 15.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="391" src="https://oscimg.oschina.net/oscnet/up-eb766774b570abb458036289ca15326fbde.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 下半年，中國數據倉庫&lt;strong style="color:#01010f"&gt;本地部署模式&lt;/strong&gt;市場前五大廠商總計佔比 57.7%。出於數據安全和合規性的考慮，金融、政府、能源等行業，以及大型企更傾向於本地部署模式的數據倉庫產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="406" src="https://oscimg.oschina.net/oscnet/up-05482245a6774b1ed848792b16fadf3762d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與本地部署市場相比，&lt;strong style="color:#01010f"&gt;公有云&lt;/strong&gt;數據倉庫服務的市場集中度更高，2024 下半年，前五大廠商份額共計達到 90.2%。隨着中國泛互聯網行業和傳統企業的互聯網業務的快速發展，企業已經在公有云上積累了大量的數據，為雲上數倉的使用創造了前提和基礎。2024 年，公有云數據倉庫市場規模已超過本地部署市場，佔比 50.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="455" src="https://oscimg.oschina.net/oscnet/up-6402c7dfdd4a171b4ece232ca18651694c4.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#01010f"&gt;IDC 中國企業軟件市場研究經理王楠表示&lt;/strong&gt;，存算分離架構、實時分析能力以及湖倉一體技術已經成為數據倉庫產品應具備的基礎能力，也是客户進行數倉產品選型時考察和評估的重點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;擁抱生成式 AI 和大模型已經成為數據倉庫下一步產品能力升級的核心，在 AI for DB 層面實現自然語言交互式查詢、智能調優、智能診斷等能力，使數倉產品的使用和運維更加便捷；在 DB for AI 層面支撐向量引擎、庫內機器學習能力，實現正真的智能問數 AI 加持下的數倉產品將使企業的數據分析能力進一步提高， 獲得更精確的預測和洞察能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362100</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362100</guid>
      <pubDate>Thu, 17 Jul 2025 06:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節發佈端到端同聲傳譯模型 Seed LiveInterpret 2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;字節跳動 Seed 團隊宣佈正式推出端到端同聲傳譯模型 Seed LiveInterpret 2.0 —— 首個延遲&amp;amp;準確率接近人類水平的產品級中英語音同傳系統，在中英同傳翻譯質量達到業界 SOTA 的同時，實現了極低的語音延遲水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，Seed LiveInterpret 2.0 基於全雙工端到端語音生成理解框架，支持中英互譯，可實時處理多人語音輸入，像人類同傳譯員一樣以極低的延遲 「邊聽邊説」，一邊接收源語言語音輸入，一邊直接輸出目標語言的翻譯語音。同時，Seed LiveInterpret 2.0 還支持 0 樣本聲音復刻，讓溝通更加流暢自然。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在測試中，Seed LiveInterpret 2.0 面對 40 秒的大段中文表達，能夠低延遲地絲滑輸出同款音色的英語翻譯。Seed LiveInterpret 2.0 還能快速學習音色，即便此前未「聽」過角色的聲音，依然能通過實時交互進行現場演繹。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;相比傳統機器同傳系統，Seed LiveInterpret 2.0 模型具備以下優勢：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;接近真人同傳的翻譯準確率&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;精準的語音理解能力保障了翻譯準確度，在多人會議等複雜場景中英雙向翻譯準確率超 70%，單人演講翻譯準確率超 80%，接近真人專業同傳水平。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;極低延遲的 「邊聽邊説」 能力&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;採用全雙工語音理解生成框架，翻譯延遲可低至 2-3 秒，較傳統機器同傳系統降低超 60%，實現了真正的 「邊聽邊説」 翻譯。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;零樣本聲音復刻，音色真實自然&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;只需採樣實時語音信號，便能提取聲音特徵，用説話人的音色特質實時 「説出」 外語，提升交流的沉浸感和親和力。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;智能平衡翻譯質量、延遲和語音輸出節奏&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;可根據語音清晰度、流暢度、複雜程度，調整輸出節奏，並適配不同語言特性。面對超長信息，依然能保證傳譯語音節奏的自然流暢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，Seed LiveInterpret 2.0 技術報告已公佈，模型基於火山引擎對外開放。此外，Ola Friend 耳機也將在 8 月底接入 Seed LiveInterpret 2.0，成為首個支持該模型的智能硬件設備。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;評測結果顯示，在語音到文本的同傳任務中，Seed LiveInterpret 2.0 中英互譯平均翻譯質量的人類評分達到 74.8（滿分 100，評估譯文準確率），較排名第二的基準系統（47.3 分）超出 58%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在語音到語音中英同傳任務中，僅 3 個測評的翻譯系統支持該能力，其中 Seed LiveInterpret 2.0 中英互譯平均翻譯質量達到 66.3 分（滿分 100，除評估譯文準確率，還評估語音輸出時延、語速、發音、流暢性等指標），遠超其他基準系統，&lt;strong&gt;達到接近專業真人同傳的水平&lt;/strong&gt;。同時，大部分基準系統也不支持聲音復刻功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="367" src="https://oscimg.oschina.net/oscnet/up-5db0506a8b7711255ee86d2bb6986dc7f78.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="360" src="https://oscimg.oschina.net/oscnet/up-03b5d4e3cac39425b43d1c9044266bcc0e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在延遲表現上，Seed LiveInterpret 2.0 在語音到文本場景中，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;輸出首字平均延遲僅 2.21 秒，在語音到語音場景中，輸出延時僅 2.53 秒，做到了對翻譯質量以及時延的均衡。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="255" src="https://oscimg.oschina.net/oscnet/up-86b7ef584ede587d9df7ad36aafec6d1ab2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="260" src="https://oscimg.oschina.net/oscnet/up-8ec35eff6c30fc2e8e276f0f36159d3cf7d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;不過，字節方面也坦承儘管 Seed LiveInterpret 2.0 已初步展現出一定優勢，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;其邊界仍有拓展空間&lt;/strong&gt;。比如，在語言覆蓋方面，目前模型主要支持中英互譯，其他語種尚未較好支持。此外，其聲音復刻的穩定性、語音表現力、情緒復刻能力、極複雜情況下的翻譯準確性等仍有進步空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fvjq_cwneALGoPf6RgxwuLQ" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362097</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362097</guid>
      <pubDate>Thu, 17 Jul 2025 05:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智能體時代，如何避免大廠壟斷 AI ？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;「過去十幾年裏，&lt;strong&gt;互聯網的開放性正在逐步消失。&lt;/strong&gt;越來越多的服務、數據、用户，被鎖定在幾個大型平台的生態裏。協議的邊界被平台所取代，數據也變成了平台資產而不是網絡資源。&lt;strong&gt;我們不希望智能體時代重複這一切。&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;近日，ANP 開源技術社區發起人常高偉在接受國際著名科學雜誌《New Scientist》採訪時指出了當前互聯網的封閉性，並擔心智能體時代將會重蹈覆轍。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;目前來看，大部分 AI 協議都是由大型科技公司提出的，比如 Anthropic、Google 這些企業，他們推動了 MCP、A2A 等協議的發展，也讓更多的人看到協議對智能體的價值。但這些協議的設計，很多時候是基於他們自己的產品路徑和商業利益出發的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;常高偉認為，這本身沒有錯——商業公司有自己的考量和節奏。「但問題是，如果整個智能體互聯網的底層協議都由幾家公司來主導，那我們可能會再次走上平台封閉化的老路。&lt;strong&gt;就像今天的社交平台、應用商店、廣告系統，數據和權限越來越集中在少數大公司手裏。&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;要打破這種封閉性困局，常高偉等人於 2024 年 4 月開源的 &lt;strong&gt;ANP（Agent Network Protocol）&lt;/strong&gt; 提供了新路徑。與 Anthropic 主導的 MCP、Google 推動的 A2A 不同的是，&lt;span&gt;ANP 從一開始就關注智能體之間的身份認證問題。這樣一來，任何兩個智能體——不管是誰開發的，來自哪家公司，都能通過標準協議完成安全的雙向身份認證。&lt;/span&gt;這一設計使 ANP 成為首個真正面向開放互聯網的智能體協議。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;更重要的是，ANP 由全球開發者社區共建&lt;/strong&gt;。其發起團隊明確強調：這是一個&lt;strong&gt;不追求盈利的非商業化組織&lt;/strong&gt;，成員包含極客、學者與創業者。常高偉表示，AI 不應該被壟斷，它的連接能力、協作能力，應該像空氣和水一樣，向所有人開放。ANP&amp;nbsp;通過完全開源和去中心化架構，讓智能體間的協作迴歸以協議為中心的開放連接，打破平台封閉化的老路和數據孤島，確保連接權回到每一個人手裏，&lt;strong&gt;讓互聯網重新成為創造力的土壤，而不是流量的圍牆。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;為了在全球範圍內推動智能體協議標準化的共識與合作，&lt;/span&gt;ANP&amp;nbsp;&lt;span&gt;開源技術社區牽頭在 W3C 發起了 "AI Agent Protocol" 社區組（Community Group）。W3C 一直是互聯網協議發展的重要推動者，從 HTTP 到 HTML，它見證並塑造了多個開放技術的誕生。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;以下為《New Scientist》雜誌採訪常高偉全文：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：Why are protocols important to enable agentic AI?（為什麼協議對實現 Agentic AI 至關重要？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：想象一下，如果你讓一個 AI 去使用 Excel 表格、點開網頁、登錄郵箱，才能獲取信息，它要麼得模仿人類的鼠標操作，要麼得反覆破解界面背後的邏輯。這種方式其實非常不自然——&lt;/span&gt;&lt;strong&gt;&lt;span&gt;AI 並不擅長使用為"人類"設計的軟件，它更擅長的是直接處理數據&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從這個角度看，我們其實應該反過來思考：讓數據為 AI 所用，而不是讓 AI 學着像人那樣"用工具"。這就需要一種標準方式，把數據、身份、能力、安全都打包好，直接交給智能體使用。這種"標準方式"，就是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;協議&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。協議是承載數據，最好的容器。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我認為這才是協議為什麼對 AI 如此重要的最根本的原因。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但協議的重要性不單單體現在讓 AI 與數字世界交互，更重要的是，它會推動 Agentic web 的到來。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;Agentic Web&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，我們可以把它簡單理解為"&lt;/span&gt;&lt;strong&gt;&lt;span&gt;為 AI 而設計的下一代互聯網&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在今天的 Web 世界裏，網頁是給人看的，數據往往被封裝在前端頁面中，只有人類點擊、滑動、輸入後，背後的系統才會做出響應。這種設計模式是典型的"人機交互優先"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但 Agentic Web 的出發點不同：它是為 AI 與 AI 的交互而構建的。在 Agentic Web 中，智能體將成為第一公民——他們是互聯網中最重要的參與者，智能體之間相互協作，幫助人類完成繁瑣、複雜的任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;支撐這種協作的關鍵工具，正是智能體協議。協議將成為 Agentic Web 的基礎設施，它不僅定義了身份、通信、能力調用等核心機制，還讓來自不同平台、不同組織、不同個人的智能體能夠自由連接與協作。無論一個智能體屬於哪個公司或個人，只要遵循相同的協議，它就能融入這個新型網絡。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這將徹底改變現有互聯網的格局。Agentic Web 有潛力打破今天由平台主導的數據孤島，實現真正開放、互聯、去中心化的網絡結構，為下一代互聯網打開新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：Who has been developing these protocols so far?（到目前為止，這些協議都是由誰在開發的？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前全球有十幾個智能體相關的協議項目，有些是由科技巨頭主導，有些是由開源社區或小公司推動。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;第一個是 MCP（Model Context Protocol），這個是由 Anthropic 推動的。Anthropic 是 OpenAI 的主要對手之一，他們覺得大模型光靠預訓練是不夠的，還得"實時連上工具"，才能真正解決問題。MCP 就像是一個標準接口，讓模型可以安全、統一地調用外部系統，比如搜索、數據庫、插件等。現在包括微軟、OpenAI、谷歌、亞馬遜等都在支持這個協議。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;第二個是 A2A（Agent-to-Agent Protocol），這是 Google 推出來的，重點不是模型和工具的連接，而是"智能體和智能體之間怎麼説話"。比如一個智能體説"我不會訂機票"，另一個説"我來幫你"，A2A 定義了這背後的語言和流程。目前還在早期階段，但被不少開發者看好，尤其適合企業內部多個 AI 系統之間的互聯。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;第三個是 ANP（Agent Network Protocol），這是由我們開源社區發起的項目，也是目前全球最早關注"去中心化智能體通信"的協議，我們研究這個領域比 MCP 和 A2A 更早。我們希望構建一個安全、高效、開放的智能體互聯網，在這個網絡中，所有的智能體都將不受大型互聯網平台的限制，相互之間都可以進行通信與協作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;MCP 關注的是模型如何連接到工具和資源，A2A 解決的問題是智能體如何在企業內部進行連接與協作，ANP 解決的問題是智能體在互聯網上如何進行連接與協作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;除此之外，還有其他一些協議，比如 Cisco 旗下的 AGNTCY 社區主導的 Agent Connect Protocol，IBM Research 主導的 Agent Communication Protocol，以及一些研究機構的項目比如 agora protocol，他們都有不同的技術路線。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我這裏有幾篇智能體協議相關的 paper： &lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;https://arxiv.org/abs/2504.16736 &lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;https://arxiv.org/pdf/2505.07176v1 &lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;https://arxiv.org/pdf/2505.02279v1&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What are the issues with them and why do we need this version?（它們存在哪些問題？為什麼我們需要這個版本？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其實我們在 2024 年 4 月就啓動了 ANP 這個開源項目，那個時候還沒有 MCP，也沒有 A2A。我們是最早一批真正從"智能體協作"角度出發，來思考協議應該怎麼設計的團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;當時我們就有一個很強的直覺：協議會是智能體之間協作的關鍵基礎設施。於是我們去研究了很多現有協議，包括 HTTP/HTML，發現它們本質上都是為"人-網頁"交互設計的，不適用於"智能體-智能體"的通信。比如説：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;兩個智能體怎麼發現彼此？&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;如何互相認證身份、交換數據？&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;通信過程中如何保證安全性和隱私？&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;現有的協議在這些方面幾乎是空白的。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;帶着這些問題，我們設計了 ANP。它從一開始就關注智能體之間的身份認證問題，我們希望任何兩個智能體，不管是誰開發的，來自哪家公司，都能通過標準協議完成安全的雙向身份認證。這一點，其實是我們和 MCP、A2A 最大的差異之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們常常用"email 模式"來比喻 ANP 的身份體系：只要你有一個"智能體地址"，你就能跟全世界的智能體建立聯繫。這跟 MCP、 A2A 那種比較中心化方式不太一樣，我認為 MCP 和 A2A 其實並沒有很好的解決智能體的身份問題，特別是智能體在互聯網上的身份問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在架構層面上，ANP 和 MCP 也有很大的區別。MCP 是典型的客户端-服務器架構（Client-Server），也就是説智能體要主動連接服務端，服務端是不能主動發起連接的。它更像一種"單向調用"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;而 ANP 是一個真正的點對點架構（&lt;/span&gt;&lt;span&gt;Peer-to-Peer&lt;/span&gt;&lt;span&gt;），任何兩個智能體之間都可以對等地通信、交互。這種設計更符合未來智能體之間頻繁互動、協同執行任務的需求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;至於和 A2A 的差異，我們認為最重要的一點是：A2A 是基於任務傳遞的協作機制。一個智能體把一個"任務包"交給另一個智能體去執行。這種模式在企業內部還好，但放到開放的互聯網環境中就會遇到隱私和權限的問題。比如説，我想訂酒店，用 A2A 的方式，我可能要在任務中告訴對方智能體我喜歡什麼、不喜歡什麼，這種個人偏好數據一旦傳出去，就存在泄露的風險。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;而 ANP 在設計之初就考慮了"智能體在互聯網中協作"這一複雜現實場景，ANP 採用的是一種 Linked-data 的方案，可以將智能體對外公開信息編織成一個數據網絡，一個智能體可以像爬蟲一樣將另外一個智能體的信息爬取下來，然後在本地進行分析與決策，從而避免用户的隱私泄漏。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;總體來説，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;ANP 是一個非常有創造力、非常獨特的嘗試，它不是對現有協議的小修小補，而是從底層重新出發，真正為"智能體互聯網"準備的協議。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：How important is it that we have protocols developed outside of big tech companies?（由大科技公司之外的組織制定協議有多重要？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：這是一個非常關鍵的問題。我們現在看到的很多 AI 協議，確實是由大型科技公司提出的，比如 Anthropic、Google 這些企業，他們推動了 MCP、A2A 等協議的發展，也讓更多的人看到協議對智能體的價值。但我們也需要看到，這些協議的設計，很多時候是基於他們自己的產品路徑和商業利益出發的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這本身沒有錯——商業公司有自己的考量和節奏。但問題是，如果整個智能體互聯網的底層協議都由幾家公司來主導，那我們可能會再次走上"平台封閉化"的老路。就像今天的社交平台、應用商店、廣告系統，數據和權限越來越集中在少數大公司手裏。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們不希望"智能體互聯網"成為另一個"數據孤島聯盟"。如果我們真的相信 AI 是一項改變人類社會的重要技術，那就更需要有一個開放、中立的社區來推動協議的設計，確保它的未來是屬於每個人的，而不是某幾家公司的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這也是我們發起 ANP 開源社區的初衷，我們有自己的理念，我們希望自己的理念能夠實現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 社區非常特別，它不是一個傳統意義上的商業團隊，它完全是一個不追求盈利的非商業化組織。我們來自各個方向——有極客、有創業者、有學者，大部分都是對未來充滿熱情的理想主義者。大家聚在一起，是因為共同相信：AI 不應該被壟斷，它的連接能力、協作能力，應該像空氣和水一樣，向所有人開放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時我們也意識到，光靠一個社區的努力是不夠的，還需要在全球範圍內推動標準化的共識與合作。這也是為什麼我們牽頭在 W3C 發起了 "AI Agent Protocol" 社區組（Community Group）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;W3C 一直是互聯網協議發展的重要推動者，從 HTTP 到 HTML，它見證並塑造了多個開放技術的誕生。它是一箇中立、開放、面向全球的標準化組織，不屬於任何一家公司，也不服務於某個商業利益集團。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們相信，在 W3C 這樣的國際平台上推動 Agent 協議的討論，有助於吸引全球更多開發者、研究者、公司和組織共同參與，真正形成一個開放、協作、可信的技術生態。這也與我們在 ANP 社區裏的初心是一致的：協議不應該屬於某家公司，它應該屬於整個智能體社會。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What do you hope the protocol will provide?（你希望這個協議能帶來什麼？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：這個問題其實也是我們做這個協議的初衷。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們一直堅信一個非常古老但至今依然重要的互聯網信條：連接即權力（Connection is Power）。只要一個人能夠自由地連接到工具、連接到他人、連接到信息，他就具備改變世界的能力。這就是互聯網最初帶給我們的力量——讓一個普通人也能撬動整個系統。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但我們也看到，過去十幾年裏，互聯網的"開放性"正在逐步喪失。越來越多的服務、數據、用户，被鎖定在幾個大型平台的生態裏。協議的邊界被平台所取代，數據也變成了"平台資產"而不是"網絡資源"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們不希望智能體時代重複這一切。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 想要實現的，是讓未來的智能體互聯網，從以平台為中心的封閉生態，迴歸到"以協議為中心"的開放連接。它不依賴某個平台，不綁定某個技術棧，只要你遵循這個協議，無論你是誰、你在哪、你由誰開發，你的智能體都能被識別、被發現、被調用，真正融入這個網絡。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在這樣的網絡裏，智能體不僅是信息的接收者，還是服務的提供者；不是被平台分發的"插件"，而是彼此對等的節點，可以自由協作、交易、共享能力。這意味着任何一個開發者，只要有想法和能力，就可以進入這個生態，而不必依賴大公司賦權。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這也是我們特別在意"非封閉、非壟斷"的原因。我們希望 AI 技術的紅利能夠真正普惠全球，而不是被少數平台控制。我們也相信，一個真正開放的智能體互聯網，會比封閉平台更有活力，會誕生出更多天馬行空的創意與合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;所以，如果你問我，我們希望 ANP 這個協議帶來什麼？&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;那就是：讓智能體的連接權利回到每一個人手裏，讓互聯網重新成為創造力的土壤，而不是流量的圍牆。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What's the next step? Will the W3C choose a "winner"? How long does this process usually take?（下一步是什麼？W3C 會選出一個"勝出者"嗎？這個過程通常需要多久？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：感謝這個很好的問題。如果您指的是我們在 W3C 的下一步工作，我需要坦誠地説，我們之前主要關注 W3C 相關的技術標準，但並沒有深度參與到標準制定的具體流程中。因此，對於標準制定的週期以及一些未知問題的解決時間，我們目前還不能給出確切的判斷。但我們希望能在 W3C 這個平台上全力推進標準的制定和行業共識的形成。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;關於"勝出者"這個話題，我想澄清一點：W3C 是一個致力於制定開放標準（Royalty-free）的組織，標準的制定是建立在整個行業共識基礎上的。我們選擇來到這裏，正是看重這一點。我們的目標是做好一個智能體交互的協議標準，我們希望聽取更多意見來打磨一個優秀的行業協議，並不希望也不打算與誰競爭。實際上，在我們創立社區組之初，W3C 智能體相關的工作組已經發出了聯絡邀請，希望共同協作，這也正是我們期望看到的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：You are both proposing the protocol and serving as the group chair—doesn't that pose a conflict of interest? （你本人既提出協議，又擔任小組主席，這是否存在利益衝突？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：這是一個很重要的問題。首先，我想強調 ANP 社區是一個開放中立、非盈利性的社區， ANP 協議，本身是完全開源的，我們非常願意與其他協議項目共同探索，最終落地成為一個具有行業共識的標準協議。從我們開始探索協議設計之初，我們就希望能夠聽取最廣泛的意見。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;擔任小組主席的角色與我們 ANP 以及 W3C 的願景是完全一致的。我們希望匯聚來自不同行業、不同國家的聲音，共同推進一個適合全人類的、具有共識基礎的標準。從這個角度看，不僅不存在利益衝突，更準確地説，我們實際上並沒有什麼商業利益考量——無論是 W3C 社區組還是 ANP 都是如此。如果非要説有什麼"利益"的話，那就是我們希望實現 Agentic Web 這一技術願景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;W3C 有着"Web for All"的願景，我們也願意在這一願景基礎上推進 Agentic Web 的實現，所以這些目標之間並不衝突，而是相互促進的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What happens if the big tech companies ultimately decide to adopt their own protocols? （如果大型科技公司最終決定採用自己的協議，會發生什麼？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果大型科技公司願意採用我們的協議，那當然是非常好的結果。我們對自己的協議方案很有信心，相信它能夠解決他們在智能體互聯和協作方面遇到的關鍵問題。我們也非常願意配合大公司來推進協議的實際落地應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;當然，我們更歡迎大公司能夠參與到我們協議的制定和優化過程中來。我們是開源開放的，我們的最終目的是實現 Agentic Web 這一願景，而不是推廣某一份特定的協議或標準。如果通過開放合作能夠產生更好的解決方案，我們完全支持這樣的結果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;歸根結底，我們關注的是整個智能體生態的健康發展，而不是某個特定協議的"勝負"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：Can we provide some examples of successful or failed standardization efforts led by the W3C in recent years? （我們能否提供一些近年來 W3C 推行標準時成功或失敗的案例？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高偉&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：正如我在第一個問題中提到的，這是我第一次深度參與 W3C 的標準制定工作，這個問題可能需要站在 W3C 工作人員的角度來回答，我很難給出權威的答案。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但從我個人的理解來看：正如我們選擇 W3C 的原因一樣，這裏是一個開放的標準組織。如果某個領域存在真實需求，自然會有相關的羣體來制定或推進相應的標準。所以在我的概念裏，這個過程不存在簡單的"成功"或"失敗"。如果一份標準被某個社羣制定出來，那這份標準對他們來説就是有意義和價值的；如果一份標準後來被其他標準所替代，這説明技術的變革和迭代在發生，而這本身就是技術發展中一直在發生的自然過程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;重要的是保持開放的心態，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;讓最好的技術方案在公開、透明的環境中得到充分討論和驗證。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18685716</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18685716</guid>
      <pubDate>Thu, 17 Jul 2025 04:38:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
