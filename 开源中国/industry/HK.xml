<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 12 Feb 2025 21:39:34 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>RWKV 2025 生態內容徵集大賽 | 1 月投稿作品及評審結果</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家好，我們在 2024 年底推出了 「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生態內容徵集大賽&lt;/a&gt;」，公開徵集 RWKV 相關的作品，包括但不限於 RWKV 相關的論文、講解 RWKV 的教程，以及基於 RWKV 的應用等。&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，活動共收到 RWKV 生態作品投稿 &lt;strong&gt;11 份&lt;/strong&gt;，包括 &lt;strong&gt;3 篇論文、7 款應用和 1 篇教程/動畫&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文將公佈 2025 年 1 月的活動投稿作品及評審結果。&lt;/p&gt; 
&lt;h2&gt;評審結果和意見&lt;/h2&gt; 
&lt;h3&gt;論文類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UI&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03971&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.03971&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：RWKV-UI: UI Understanding with Enhanced Perception and Reasoning&lt;/li&gt; 
   &lt;li&gt;投稿人：Kmui&lt;/li&gt; 
   &lt;li&gt;獲獎類型：金獎（4888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：基於 RWKV 的全新研究方向，因此獲得金獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OmniRWKVSR&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.00404&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.00404&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：Exploring Linear Attention Alternative for Single Image Super-Resolution&lt;/li&gt; 
   &lt;li&gt;投稿人：nomodeset&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UNet&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：RWKV-UNet：Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
   &lt;li&gt;投稿人：Gavin&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;應用類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;fla-rwkv7&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Ffla-hub%2Frwkv7-6790fd37b4b6137b088a0d8a&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/collections/fla-hub/rwkv7-6790fd37b4b6137b088a0d8a&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：flash-linear-attention 的 RWKV-7 支持&lt;/li&gt; 
   &lt;li&gt;投稿人：張宇&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：如果可以解決這個庫運行 Bo 的 MMLU 腳本時的速度和顯存佔用問題，&lt;strong&gt;可升級金獎&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;conRWKV&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F00ffcc%2FconRWKV&quot; target=&quot;_blank&quot;&gt;https://github.com/00ffcc/conRWKV&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：提供了一個高併發的 RWKV 雲端推理引擎，以方便後續基於 RWKV 的應用&lt;/li&gt; 
   &lt;li&gt;投稿人：#9AC8E2&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;R-translator&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fl15y%2FR-translator&quot; target=&quot;_blank&quot;&gt;https://github.com/l15y/R-translator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：基於 RWKV 的 AI 翻譯工具&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;獲獎類型：鐵獎（888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-ZeroCoT&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2FRWKV-ZeroCoT&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/RWKV-ZeroCoT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：ZoreCoT 的原始實現&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;獲獎類型：鐵獎（888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;substitute&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAXFOX%2Fsubstitute&quot; target=&quot;_blank&quot;&gt;https://github.com/AXFOX/substitute&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：基於 Ai00 Server（RWKV） 驅動的 Kdenlive 字幕校驗和替換工具&lt;/li&gt; 
   &lt;li&gt;投稿人：我想上岸&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;rwkv v6 7b cot&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fly444983%2FRWKV_ST_for_AI00%2Ffile%2Fview%2Fmaster%3FfileName%3D7B_LY_COT.state%26status%3D2&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/ly444983/RWKV_ST_for_AI00/file/view/master?fileName=7B_LY_COT.state&amp;amp;status=2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：基於 RWKV-V6-7B 的 rwkv cot state&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;new_rwkv_pip&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2Fnew_rwkv_pip&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/new_rwkv_pip&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：重構後的 rwkv_pip 庫，把 v4-v7 各代模型都整理成統一的結構&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;教程/動畫類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;有思維的語言模型：RWKV-7 狀態演化過程&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1DY6fYdECa%2F&quot; target=&quot;_blank&quot;&gt;https://www.bilibili.com/video/BV1DY6fYdECa/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：RWKV-7 狀態演化視頻&lt;/li&gt; 
   &lt;li&gt;投稿人：136279841&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：作品高贊評論在質疑效果，請用 v7 的實際效果去向用户證明。如果用户認可，可升級獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;評審結果快速對照表格&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名稱&lt;/th&gt; 
   &lt;th&gt;作品分類&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初評獎項&lt;/th&gt; 
   &lt;th&gt;得獎理由&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UI&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;Kmui&lt;/td&gt; 
   &lt;td&gt;金獎（4888 元）&lt;/td&gt; 
   &lt;td&gt;基於 RWKV 的全新研究方向&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OmniRWKVSR&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;nomodeset&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UNet&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;Gavin&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;有思維的語言模型：RWKV-7 狀態演化過程&lt;/td&gt; 
   &lt;td&gt;教程/動畫&lt;/td&gt; 
   &lt;td&gt;136279841&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;作品高贊評論在質疑效果，請用 v7 的實際效果去向用户證明。如果用户認可，可升級獎。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;substitute&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;我想上岸&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fla-rwkv7&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;張宇&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;如果可以解決這個庫運行 Bo 的 MMLU 腳本時的速度和顯存佔用問題，可&lt;strong&gt;升級金獎。&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R-translator&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;鐵獎（888 元）&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rwkv v6 7b cot&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-ZeroCoT&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;鐵獎（888 元）&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;new_rwkv_pip&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conRWKV&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;#9AC8E2&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用户，可面向社區內外宣傳並招募用户，有真實用户後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;獎品/獎金髮放規則&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;實物獎品（RWKV 周邊等）&lt;strong&gt;以&lt;/strong&gt;順豐快遞&lt;/strong&gt;方式發出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;獎金&lt;/strong&gt;以&lt;strong&gt;轉賬或第三方線上平台&lt;/strong&gt;等方式發放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情況下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;領取獎金，團隊內部&lt;strong&gt;自行協商分配獎金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿與獎項升級&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均會獲得&lt;strong&gt;評審意見&lt;/strong&gt;。請根據評審意見優化你的作品，然後可&lt;strong&gt;再次投稿以升級獎項&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;獎項成功升級時，我們將補發&lt;strong&gt;前後兩個獎金的差價&lt;/strong&gt;。例如投稿作品從鐵獎（888 元）升級到銀獎（2888 元），則補發 2888-888=2000 元獎金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活動海報&lt;/strong&gt;，歡迎各位轉發！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-de56881e7277f3f31798464afb87dbc3c15.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活動最終解釋權歸元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333398</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333398</guid>
            <pubDate>Fri, 07 Feb 2025 09:57:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>別再買 9.9 的 deepseek 本地部署啦！一文教你輕鬆部署，告別 「服務器繁忙」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;開源的意義，在於人人機會均等。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;本人 IT 小白，不會寫代碼、不會看文檔，甚至一句「 Hello ，World 」 用 Python 寫完，都要靠高亮來判斷語法是否正確。哈哈哈，像我這樣的人，離本地部署，暢玩 Deepseek 遠嗎？&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;實測！世上無難事，只要肯動手！&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是我用公司配發的 HP 筆記本，本地部署 deepseek 的傻瓜式流程，內容如下：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;設備： HP Laptop 14&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;系統：Win&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;應用程序：LM Studio&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;模型版本：DeepSeek R1 Distill Qwen 1.5B &lt;span style=&quot;color:#8f959e&quot;&gt;（我都這配置了，還要啥自行車）&lt;/span&gt;；DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;輔助工具：VS code &lt;span style=&quot;color:#8f959e&quot;&gt;（輕量？不不不，它是神）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;為什麼我會選用 LM Studio &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;在嘗試部署之前，同事跟我推薦過一個叫「 Ollama 」 的開源工具，但我實測之後發現，在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2F&quot; target=&quot;_blank&quot;&gt;https://ollama.com/&lt;/a&gt; （ Ollama 官網）下載 Windows 版本時，可能會跳轉到 github ，響應超時而無法下載。&lt;/p&gt; 
 &lt;p&gt;並且，Ollama 主要圍繞命令行展開，不像 LM Studio 具備直觀的圖形化操作界面，通過「點點點」就可以使用，所以，對於很多名詞都不明所以的我來説——&lt;strong&gt;能用，比好不好用，更重要。&lt;/strong&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_1&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;1、於是，我進入 LM Studio 的官網（ &lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flmstudio.ai%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://lmstudio.ai/&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; ），並下載了首頁的 0.3.9 版本。&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fe0fc4d91864142b575cad0941864dbb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_2&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;2、下載 LM Studio 3.9.0-6-x68 安裝包，所需空間 1.3 &lt;/strong&gt;&lt;strong&gt;GB&lt;/strong&gt;&lt;strong&gt; （全中文的，沒有門檻）&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a9c2a4552e660adf721db6398545166a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;打開【 LM-Studio 】，就可以使用該軟件，也可以創建桌面快捷。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1c26e3812675b161bb2711f22a87de0d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;界面長這樣👇&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//14810d4ac4953cce2010fb5f0fc7e593.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_3&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;3、英文界面？沒事兒！內置簡體中文~&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//381dd1bf2bc27a93d7cd0133f14a362e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4521be9d0ece8c5f6522e29c72f58cb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_4&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;4、接下來，我們就可以下載模型了，也超簡單&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5b68c13f9a0a6c4737a2d41f8cc92b69.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;但是，問題來了！！！&lt;/strong&gt;第一次下載 LM Studio ，搜索模型並下載，往往下載不了，這是因為 LM Studio 關聯 Hugging Face 或 llama.cpp 的模型庫，默認下載地址無法正常訪問。&lt;strong&gt;此時，我們可以通過 VScode ，修改 LM Studio 的安裝文件解決。&lt;/strong&gt;（ 怎麼下載 VScode ？別搞了兄弟！）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;退出 LM Studio 後，打開 LM Studio 的安裝目錄，如👇圖&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c7e5de0c94f6bc1ac0a848d340120b9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;找到兩個文件，路徑如下&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\main\index.js&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\renderer\main_window.js&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bad366546f55463174a123dcd533fb38.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;打開 VScode ，在 VCcode 同時打開這兩個文件&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e72d38f52a807e0bd51fa1a323451edf.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷鍵 ctrl+shift+h 調出批量替換，將 &lt;code&gt;huggingface.co&lt;/code&gt; 替換成 &lt;code&gt;hf-mirror.com&lt;/code&gt; ，然後快捷鍵 ctrl+alt+enter 應用替換（兩個文件同時打開時，可同時替換）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bd348a106dd3879fb521b5ffad959a78.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷鍵 ctrl+s ，保存文件即可退出 VScode ，再打開 LM Studio 就可以搜索下載模型了~&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;span id=&quot;OSC_h4_5&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;5、搜索適合設備配置的模型，下載並使用&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1323fb9dc1b4b3b3f89f726b17290d9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;一開始，小編也只敢用 HP 本下載最小的 1.5B ，但後面搜索了一些資料，整理下表：&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeb8f9a7b500a326f92c20de7d91ce400c8.jpg&quot; width=&quot;784&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;span id=&quot;OSC_h4_6&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;6、實測階段&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 1.5B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;問題設置 1：人有幾隻腳？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//334794f64dac8ccb583dd0137b9e933c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 2：請簡述一下，什麼是「模型蒸餾」？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//962255f6c3582b01c7913ace1faf11fd.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//069652c7705521531ac17af8bab48c79.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c72aa05116825a0c8727b76d77d13e1c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 3：8.11 和 8.4 誰大？直接得出結論。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bb33fdd55da3112b2dcf57f18e1fbe8c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;問題設置 1：你認為「模型開源」的意義是什麼？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3c5c2039712441d2048404de675270ba.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 2：你如何評價梁文鋒？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b3f62d7ac407be1f2b9fa9b7f19304aa.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 3：你認為，人工智能的下一個技術突破點是？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e76d56190bda354d2f8bf81e6f187557.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;得到這個回答時，我發現，並不是我想要的，所以，我又繼續追問了一個問題：&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;如果不侷限於中國呢？如果是全球人工智能技術，你覺得下一個技術突破點是什麼？ &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是 7B 的答案（因為不好截圖，所以用文字表達）：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;在人工智能領域，每一次技術突破都伴隨着對現有侷限性的突破和技術創新。如果將目光放長遠，並不限於中國的地區或行業背景，全球範圍內，下一個可能的技術突破方向可以從以下幾個角度進行分析：&lt;/p&gt; 
  &lt;p&gt;1. &lt;strong&gt;通用人工智能（AGI）的突破&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;目前，AI 主要集中在特定任務上（如 NLP、計算機視覺等），仍然缺乏真正具有「通用性」的自主學習能力。如何讓機器具備類似人類般的學習能力和通用認知模式仍然是一個未解之謎。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;符號推理與&lt;/strong&gt;&lt;strong&gt;知識圖譜&lt;/strong&gt;：結合符號邏輯和知識圖譜，使得 AI 能夠進行更抽象的推理和概念理解。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;強化學習&lt;/strong&gt;&lt;strong&gt;的進化&lt;/strong&gt;：探索更具效率和創造力的強化學習方法，推動 AGI 的發展。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨模態理解和整合&lt;/strong&gt;：使 AI 能夠更好地理解和處理多模態信息（如文本、圖像、音頻等），從而具備更全面的理解能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;2. &lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;與協作&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;當前的大模型（如 GPT 系列、LLama 系列）已經在特定領域展現了強大的性能，但規模和複雜性仍然有限。未來，通過模型的聯合訓練和知識共享（如「元學習」或「模型平均」），可能實現更大規模、更高效的 AI 系統。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;具體方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型協作與知識共享&lt;/strong&gt;：多個研究機構或企業聯合訓練大型語言模型，促進知識的開放性和共享性。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多領域&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;的融合&lt;/strong&gt;：創建涵蓋科學、藝術、醫療等多領域的大型模型，提升跨領域應用的能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;3. &lt;strong&gt;人機協作與&lt;/strong&gt;&lt;strong&gt;自適應系統&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;隨着 AI 技術的成熟，人機協作將成為未來的重要趨勢。如何讓 AI 能夠更自然地與人類交互、理解和協同工作，仍然是一個關鍵方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;情感理解與倫理決策&lt;/strong&gt;：開發能夠理解人類情感和價值觀的 AI 系統，使其在複雜的社會環境中做出更具倫理性的決策。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;動態任務適應&lt;/strong&gt;：設計更加靈活的 AI 系統，能夠在不同情境中自適應任務要求，提升通用性。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;4. &lt;strong&gt;多模態與跨媒體理解&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;當前 AI 大多侷限於單一模態（如文本或圖像），如何整合多種模態信息（如文本、音頻、視頻、甚至傳感器數據）進行更全面的理解和推理，仍然是一個未解之謎。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模態融合框架&lt;/strong&gt;：開發能夠處理並整合多種模態數據的模型架構。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨領域&lt;/strong&gt;&lt;strong&gt;知識圖譜&lt;/strong&gt;：構建跨領域的知識圖譜，幫助 AI 更好地理解不同模態之間的關係。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;5. &lt;strong&gt;硬件與效率優化&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;雖然大模型在軟件層面取得了進展，但計算資源（如 GPU、TPU 等）仍然是制約其廣泛應用的關鍵因素。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;未來可能會有更高效的硬件設計和算法優化，使得 AI 系統的計算效率顯著提升。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;6. &lt;strong&gt;倫理與安全&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;AI 的自主性和複雜性可能帶來新的倫理問題和安全風險。如何在技術發展的同時確保 AI 系統的安全性和透明性，也是一個重要方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;系統的透明性&lt;/strong&gt;：研究如何讓 AI 系統更加透明，以便於人類理解和監督。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;法律與框架的完善&lt;/strong&gt;：推動相關法律法規的制定，確保 AI 技術的發展符合社會價值觀。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;總結&lt;/p&gt; 
  &lt;p&gt;從全球視角來看，下一個技術突破可能集中在以下方面：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;推動 AGI（通用人工智能）的發展；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;擴展大模型的協作和共享能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;提升多模態理解和人機協作能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;優化硬件效率並確保倫理安全。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p&gt;這些方向既需要基礎理論研究，也需要跨學科合作和技術落地。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;span id=&quot;OSC_h4_7&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;7、後記&lt;/h4&gt; 
 &lt;p&gt;體驗了幾個回合下來，首先能肯定的是，上文測試的兩個模型確實沒有網頁版 or APP 版所輸出的內容有趣（怪小編&lt;s&gt;財&lt;/s&gt;實力不行），但至少不會出現「服務器繁忙」，且不聯網也可以使用。&lt;/p&gt; 
 &lt;p&gt;其次，通過 LM Studio ，我們還可以輕鬆部署甚多有意思的開源模型在本地，而寫這一篇超超超超超基礎的博客，無非是在回答本文一開始的那句話：&lt;strong&gt;開源的意義，在於人人機會均等&lt;/strong&gt;。不僅是程序員、開發者、AI 從業人員，如根本不會寫代碼的我，也可以共享這一份人類智慧。&lt;/p&gt; 
 &lt;p&gt;可能有人會説，1.5B 能幹什麼？像個傻子！7B 能幹什麼？上不得枱面！對此，小編想用 Deepseek R1 自己輸出的一句話回答大夥兒——&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;火焰不需要羨慕灰燼的重量（滿血模型，也是從第一行代碼而來的）&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;最後，分享一個昨晚在地鐵上親歷的場景：&lt;/p&gt; 
 &lt;p&gt;寒假快結束了，兩個小學生在地鐵上互抄作業，小學生 A 説：「牛 B 呀！寒假生活你居然做完了？！」 小學生 B 説：「你傻呀！用 AI 呀~手機摸出來給我玩兩把！我跟你上分！」&lt;/p&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
 &lt;/div&gt; 
 &lt;p&gt;PS：希望在哪些網絡覆蓋不佳、基礎設備不好，逼仄、失語的角落，也能萌芽智慧之光......&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/7819858/blog/17563840</link>
            <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/17563840</guid>
            <pubDate>Fri, 07 Feb 2025 09:32:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>百度今年或將發佈下一代 AI 模型 Ernie 5.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F12%2Fchina-tech-giant-baidu-to-release-next-generation-ai-model-this-year-as-deepseek-shakes-up-market.html&quot; target=&quot;_blank&quot;&gt;據 CNBC 報道&lt;/a&gt;&lt;/u&gt;，百度今年將發佈下一代 AI 模型 Ernie 5.0。&lt;/p&gt; 
&lt;p&gt;消息人士稱，被稱為「基礎模型」的 Ernie5.0，將在多模態能力方面有重大增強，但沒有具體説明其功能。「多模態」AI 指可以處理文本、視頻、圖像和音頻等不同形式的數據，並進行轉換和結合 —— 比如將文本轉化為視頻，或反向操作。而基礎模型能夠理解語言，執行包括生成文本、圖像在內的多種任務，同時支持與人類自然語言的互動。&lt;/p&gt; 
&lt;p&gt;這一消息正值蘋果公司將其潛在客户&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333288&quot;&gt;轉向&lt;/a&gt;&lt;/u&gt;阿里巴巴之後，市場普遍猜測此舉是百度為了應對局勢的變化，試圖穩住股價和市場地位。&lt;/p&gt; 
&lt;p&gt;百度首席執行官李彥宏本週在迪拜的世界政府峯會上表示：「我們正處於一個令人激動的時代……12 個月內，基礎模型的推理成本預計將下降 90% 以上。如果成本能夠大幅降低，意味着生產力將呈同等比例提升。這也正是創新的核心所在。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;報道稱，百度的文心大模型已經在其多個面向消費者和企業的產品中應用，包括雲存儲和內容創作。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;百度上個月宣佈，截至 2024 年底，其文庫平台已吸引 4000 萬付費用户，比 2023 年底增長了 60%。包括利用 AI 根據公司財報生成 PPT 在內的一系列新功能，已在 1 月開始向用户發佈。&lt;/p&gt; 
&lt;p&gt;當前的 ERNIE 模型版本為 4.0，於 2023 年 10 月發佈。2024 年 8 月，百度發佈了升級版的 ERNIE 4.0 &quot;turbo&quot;，目前並未正式宣佈下一次更新的計劃。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-741c4810e55393b362a8f9a60b8c98a65dd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333389</guid>
            <pubDate>Fri, 07 Feb 2025 09:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英特爾開源全新 NLP 模型：Polite Guard</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英特爾&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;推出 Polite Guard，一種用於文本分類任務的開源自然語言處理 (NLP) 語言模型，採用 MIT 許可。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 旨在使開發人員更容易生成自己的合成數據並微調他們的模型、通過提供針對敵對攻擊的防禦機制來增強系統的彈性、允許開發人員評估和比較他們的模型在禮貌分類方面的性能，以及通過確保在各個平台上進行尊重和禮貌的互動來提高客户滿意度和忠誠度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該模型由 BERT 微調而來，可將文本分為四個不同的類別：polite, somewhat polite、neutral 以及 impolite。目前，英特爾已在&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 和&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FIntel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;Hugging Face&lt;/a&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;上開源了相關的數據集和 Polite Guard 源代碼。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 數據集包含三個部分：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Few-Shot 提示生成 50,000 個帶標籤樣本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Chain-of-Thought（CoT）提示生成的 50,000 個帶標籤樣本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;來自企業培訓的 200 個經過匿名化處理（屏蔽個人標識符）的標註樣本。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告指出，合成數據被劃分為訓練集（80%）、驗證集（10%）和測試集（10%），每組均根據標籤進行平衡。Polite Guard 模型完全在合成數據上進行訓練，但在合成數據和真實標註數據的測試集上進行評估，準確率和 F1 分數均達到了 92.4%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-46439a7eec58b0b02d7e2377a193c43abe8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e66b191ecaab81e31ad281895c85f48be6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可查看&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;英特爾社區博客&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333358/intel-polite-guard</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333358/intel-polite-guard</guid>
            <pubDate>Fri, 07 Feb 2025 07:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英國和美國拒絕簽署國際人工智能宣言</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在巴黎舉行的全球峯會上，英國和美國沒有簽署人工智能（AI）國際宣言。這份由法國、中國和印度等國簽署的聲明承諾以&quot;開放&quot;、&quot;包容&quot;和&quot;道德&quot;的方式來發展人工智能技術。&lt;/p&gt; 
&lt;p&gt;在巴黎舉行的人工智能行動峯會的討論重點是人工智能對社會和環境的影響——以及需要採取哪些行動來獲取其利益和防範其風險。&lt;/p&gt; 
&lt;p&gt;美國和英國沒有解釋不簽署的原因。&lt;/p&gt; 
&lt;p&gt;但早些時候，美國副總統萬斯（JD Vance）在巴黎對與會代表説，對人工智能（AI）的過多監管可能會&quot;扼殺一個剛剛起飛的變革性行業&quot;。萬斯週二在巴黎舉行的峯會上告訴世界各國領導人，人工智能是&quot;特朗普政府不會浪費的機會&quot;，並表示&quot;有利於增長的人工智能政策&quot;應優先於安全。他説，這將需要促進人工智能發展的監管，&quot;而不是扼殺它&quot;。萬斯還説，歐洲領導人尤其應該&quot;以樂觀而非恐懼的態度看待這一新領域&quot;。&lt;/p&gt; 
&lt;p&gt;他的這番話似乎讓他與法國總統埃馬紐埃爾-馬克龍（Emmanuel Macron）產生了分歧，後者為進一步監管的必要性進行了辯護。&lt;/p&gt; 
&lt;p&gt;馬克龍在峯會上説：&quot;我們需要這些規則來推動人工智能的發展。&quot;這是在討論人工智能發展對社會、環境和治理的影響之際發表的。&lt;/p&gt; 
&lt;p&gt;參加巴黎峯會的政策制定者、高管和外交官們一直在思考如何獲取人工智能創新的經濟效益，同時應對該技術的風險。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1decb699dddc94378060a3327ba296ab72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;法國總統埃馬紐埃爾-馬克龍（Emmanuel Macron）在社交媒體上發佈了自己出演熱門電影和電視劇的 deepfake 搞笑片段彙編，拉開了本次峯會的序幕。&lt;/p&gt; 
&lt;p&gt;歐盟委員會主席烏蘇拉-馮德萊恩（Ursula von der Leyen）週二表示：&quot;本次峯會的重點是行動，而這正是我們現在所需要的。&quot;她説，在整個峯會期間，歐洲一直倡導的人工智能方法也將強調創新、合作和&quot;擁抱開源&quot;技術的力量。&lt;/p&gt; 
&lt;p&gt;此次會議的召開正值美歐貿易關係日益緊張之際。美國總統特朗普已決定對進口到美國的鋼鐵和鋁徵收關税，此舉將影響英國和歐盟。&lt;/p&gt; 
&lt;p&gt;據悉， 英國不會立即採取報復行動，因為英國既要與特朗普政府保持良好關係，又要與歐盟建立更緊密的關係，因此英國希望走一條微妙的道路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333337</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333337</guid>
            <pubDate>Fri, 07 Feb 2025 05:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI CEO 奧爾特曼：願意在人工智能領域與中國合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日，美國企業家埃隆·馬斯克等投資人當地時間 2 月 10 日提議「以 974 億美元競購」由其參與創建的美國開放人工智能研究中心（OpenAI）的非營利性母公司。&lt;/p&gt; 
&lt;p&gt;對此，2 月 11 日在法國巴黎出席人工智能行動峯會的 OpenAI 首席執行官薩姆·奧爾特曼&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot;&gt;再次強調「公司不賣」&lt;/a&gt;&lt;/u&gt;，並表示，「如果馬斯克願意談」，那麼他將「很樂意收購推特（即社交媒體平台 X）」。&lt;/p&gt; 
&lt;p&gt;奧爾特曼還表示，「&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;願意在人工智能領域與中國合作，並將為此盡最大努力，因為這很重要。&lt;/strong&gt;&lt;/span&gt;」&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c01d53e2a43f4d2a467d4d590cc812b528.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據外媒週一報道，特斯拉 CEO 埃隆·馬斯克正率領一羣投資者，提出以 974 億美元收購 OpenAI 的控制權。馬斯克律師馬克·託貝羅夫補充説，他已於週一提交收購要約。&lt;/p&gt; 
&lt;p&gt;報道援引託貝羅夫提供的馬斯克聲明稱，「現在是時候讓 OpenAI 迴歸其曾經開源、注重安全的初衷了。」&lt;/p&gt; 
&lt;p&gt;OpenAI 首席執行官山姆·奧爾特曼在 X 平台上發帖稱，他寫道：「不了，謝謝。不過如果你願意的話，我們可以花 97.4 億美元收購推特。」隨後，馬斯克在 X 平台上回復這位 OpenAI 負責人，稱他為「騙子」。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/105032_Gj7Z_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333323</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333323</guid>
            <pubDate>Fri, 07 Feb 2025 03:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>稚暉君創業公司智元近日在深圳新設立「靈犀」產品線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.leiphone.com%2Fcategory%2Frobot%2FIYV9qXAR1wFN5Omd.html&quot; target=&quot;_blank&quot;&gt;根據「AI 科技評論」獨家報道&lt;/a&gt;，智元機器人三大事業部之一靈犀近日在深圳設立，目前正在招兵買馬。&lt;/p&gt; 
&lt;p&gt;據瞭解，智元此前調整組織架構，新設立三大產品線，分別是遠徵、靈犀和 Genie。此外還有幾個一級部門，例如靈巧手。&lt;/p&gt; 
&lt;p&gt;智元新成立的三大產品線分設三地，除了「靈犀」產品線在深圳外，遠徵產品線在上海，Genie 產品線大部隊在北京。&lt;/p&gt; 
&lt;p&gt;遠徵、靈犀、Genie 三大產品線總裁分別由王闖（前大疆 Livo 激光雷達負責人）、稚暉君、姚卯青（前蔚來工程總監）擔任。據瞭解，Genie 產品線前身是由上海交大閆維新教授和姚卯青指揮的研究院。&lt;/p&gt; 
&lt;p&gt;目前靈犀產品線由稚暉君暫代，還在招一號位人選。靈犀系列是智元產品矩陣之一，原先只有產品，並沒有配備專門產品線。此次新設立的靈犀產品線，將承接此前的靈犀系列產品。2024 年 10 月，智元曾宣佈&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhiyuan-robot.com%2FDOCS%2FOS%2FX1-PDG&quot; target=&quot;_blank&quot;&gt;開源靈犀 X1&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67d9642e1e623e3859f9c4aa1823336b99b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;稚暉君所在部門為 CTO Office，領銜 X-Lab 和 EI-Lab。X-Lab 由稚暉君指揮，EI-Lab 則歸北大計算機學院前沿計算研究中心助理教授董豪管理。&lt;/p&gt; 
&lt;p&gt;據介紹，靈犀主要做 To C，面向養老方向。而遠徵和 Genie 在產品腿部形態上做區分，遠徵做足式機器人，Genie 則是輪式機器人。&lt;/p&gt; 
&lt;p&gt;智元自成立起便開啓全棧自研，涵蓋軟件、硬件、大腦、小腦和雲系統等。技術上，智元提出具身智能 G1 到 G5 的演進路徑和技術框架，目前處於 G2 和 G3 階段。&lt;/p&gt; 
&lt;p&gt;智元持續推進量產工作。2024 年 12 月，智元機器人正式宣佈開啓機器人量產。2025 年 1 月 6 日，智元量產第 1000 台通用具身機器人正式下線。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/254290&quot; target=&quot;news&quot;&gt;稚暉君首款創業產品——智元機器人「遠徵 A1」發佈&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/327297&quot; target=&quot;news&quot;&gt;智元機器人重磅開源百萬真機數據集 AgiBot World&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328925&quot; target=&quot;news&quot;&gt;智元機器人具身算法團隊推出 EnerVerse 架構&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333319</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333319</guid>
            <pubDate>Fri, 07 Feb 2025 03:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>梁文鋒實習往事：月薪 1.6 萬、沒畢業就被任命為部門經理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前「今日閔行」公眾號&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9e1Eva97SJCgDJp3ukjlwA&quot; target=&quot;_blank&quot;&gt;發文稱&lt;/a&gt;，DeepSeek 創始人梁文鋒 2009 年曾在上海閔行的上海艾麒信息科技股份有限公司實習，負責內容也跟人工智能有關。&lt;/p&gt; 
&lt;p&gt;據艾麒信息創始人周朝恩透露，梁文鋒是其浙大校友，&lt;strong&gt;2009 年梁文鋒以實習生身份加入艾麒，後經推薦直接擔任新技術部經理，月薪 16000 元&lt;/strong&gt;，算是高薪特別聘請的。&lt;/p&gt; 
&lt;p&gt;「入職後，他便全身心投入到人工智能視頻與圖像技術的研究中，常常一整天都待在辦公室裏，專注地鑽研技術難題，甚至半天都不出來一次。」&lt;/p&gt; 
&lt;p&gt;他還透露了對梁文鋒的第一印象：「初見梁文鋒時，他戴着一副眼鏡，斯文有禮，身材清瘦，給人一種文靜內斂的印象。」&lt;/p&gt; 
&lt;p&gt;不過在深入接觸後，周朝恩發梁文鋒雖不善言辭，但在技術交流中卻能清晰地表達自己的觀點，「他為人沉着冷靜，性格簡單直接，對產品和技術有着極高的追求，堪稱典型的技術男風格」。&lt;/p&gt; 
&lt;p&gt;周朝恩介紹稱，梁文鋒在艾麒信息期間，當時公司新技術部也在研究做 100M CPU 的手機上視頻編解碼技術，並充分運用手機上 GPU 來高效處理視頻編解碼等技術。在這過程中，梁文鋒積累了豐富的技術經驗，為他後續創業打下了堅實的技術基礎。&lt;/p&gt; 
&lt;p&gt;他也曾管理過多位算法工程師，採用扁平化管理方式，給予團隊成員充分的自由和信任，發揮每個人的特長，並帶領團隊攻克了多項技術難題，優化了圖像視頻處理算法，提升了服務性能。&lt;/p&gt; 
&lt;p&gt;豐富的管理經驗在他創業後得到了延續。周朝恩告訴記者，梁文鋒招聘的團隊成員大多是數學競賽一等獎、拿過國際金牌的算法人才，這種對高端人才的管理和激勵方式，使得他在管理量化投資和深度求索時能夠迅速組建一支高效專業的技術團隊。&lt;/p&gt; 
&lt;p&gt;2023 年 5 月，梁文鋒在籌備深度求索之前，還特意回到艾麒公司進行調研。&lt;/p&gt; 
&lt;p&gt;此次調研，他比約定的時間提早 3 分鐘來到了周朝恩的辦公室，他不僅僅是看望老同事，而且還瞭解到艾麒信息也正在做大模型相關產品，「他與我們探討了人工智能相關技術，交流了將近 2 個小時」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333308</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333308</guid>
            <pubDate>Fri, 07 Feb 2025 03:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 創始人未出席巴黎 AI 峯會</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期有消息稱，中國人工智能企業深度求索（DeepSeek）創始人梁文鋒受邀參加在巴黎舉辦的&quot;AI 行動峯會&quot;（AI for Action Summit）。此次峯會聚焦全球人工智能技術發展、倫理治理及跨領域協作，被視為推動全球 AI 治理框架落地的重要國際會議。為期兩天的人工智能行動峯會已於當地時間 10 日在法國首都巴黎的大皇宮拉開帷幕。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FphNF2U-ytrx6v97fqes_tA&quot; target=&quot;_blank&quot;&gt;根據鳳凰網科技的報道&lt;/a&gt;&lt;/u&gt;，接近 DeepSeek 的人士稱梁文鋒沒有參加這次在巴黎舉辦的人工智能行動峯會，公司層面也無人蔘加。&lt;/p&gt; 
&lt;p&gt;目前，除傳聞受邀的梁文鋒外，已披露的參會名單包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenAI 首席技術官米拉·穆拉蒂&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china&quot;&gt;DeepMind 首席執行官戴密斯·哈薩比斯&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;法國總統馬克龍&lt;/li&gt; 
 &lt;li&gt;歐盟委員會數字事務副主席維斯塔格&lt;/li&gt; 
 &lt;li&gt;圖靈獎得主楊立昆&lt;/li&gt; 
 &lt;li&gt;斯坦福大學 HAI 研究院院長李飛飛等人&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;法國總統馬克龍在這次峯會開幕前夕曾表示，不會因為某個技術來自特定國家和地區就去禁用它，因為這很荒謬，他認為，DeepSeek 的出現是一個好消息，並希望下一代這樣的模型會出現在歐洲。&lt;/p&gt; 
&lt;p&gt;此外，值得注意的是，2 月 11 日，彭博社對 7 位初創公司創始人及 AI 專家的調研顯示，預計 DeepSeek 的估值在 10 億美元到逾 1500 億美元之間，估值區間的中間值為 20 億至 300 億美元。這樣的預測無疑讓持有 84% 股份的梁文峯身家暴漲，有望躋身亞洲科技鉅富之列。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333302</guid>
            <pubDate>Fri, 07 Feb 2025 02:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV-7 2.9B 模型正式發佈，SOTA 架構，帶來 SOTA 使用體驗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 2 月 11 日，RWKV 基金會正式發佈 RWKV-7-World-2.9B-V3 模型（以下簡稱 RWKV-7-2.9B）。&lt;/p&gt; 
&lt;p&gt;RWKV-7-2.9B 模型基於 RWKV World V3 數據集訓練。無論是&lt;strong&gt;模型評測&lt;/strong&gt;還是&lt;strong&gt;實際體驗&lt;/strong&gt;，RWKV-7-2.9B 都超越了上一代 RWKV-6-&lt;strong&gt;7B&lt;/strong&gt; 模型。&lt;/p&gt; 
&lt;h3&gt;英文和多語言測評&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 模型的英文和多語言能力，均&lt;strong&gt;顯著超越所有同尺寸模型&lt;/strong&gt;，包括 &lt;strong&gt;Llama 3.2 3B、Qwen2.5 3B&lt;/strong&gt; 等知名優秀開源模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d75cea1cbd01a3f14f4250fc3b49ce974da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;MMLU 測試&lt;/h3&gt; 
&lt;p&gt;在&lt;strong&gt;選擇題&lt;/strong&gt;形式的 MMLU 測試上，RWKV-7-2.9B 模型得分為 &lt;strong&gt;54.56&lt;/strong&gt;%。作為對比，上一版本的 RWKV-6-World-3B-V2.1 模型 MMLU 評分是 &lt;strong&gt;32.38&lt;/strong&gt;%。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV-7-2.9B 基底模型的性能提升完全通過&lt;strong&gt;常規訓練&lt;/strong&gt;實現，未針對任何測試進行「優化」，也沒有采取退火或 post-training 等優化策略。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;生成案例&lt;/h2&gt; 
&lt;p&gt;以下是 RWKV-7-2.9B 的生成案例（使用 RWKV Runner 運行）：&lt;/p&gt; 
&lt;h3&gt;代碼任務&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2c8e4dddba547a3a1e2f3473517ac578748.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e77fd7b64c80a0fc62785042feb96839832.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;多語言任務&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 多語言寫請假信：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4b6f6adf1987001921bcb9ba30dc8c803dd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以下是圖中的原文和翻譯：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;Lieber Herr [先生的名字],
Ich möchte Ihnen mitteilen, dass ich mich auf dem Weg zur Marsrakete befinde und morgen eine Woche lang fehlen werde. Ich habe diese Entscheidung getroffen, weil ich mein Leben erkunden möchte.
Es war ein großer Genuss, von Ihnen unterrichtet worden zu sein und vieles zu lernen. Ich werde dieses Wissen nie vergessen.
Ich hoffe, dass wir uns bald wiedersehen werden und danke Ihnen für alles!
Mit freundlichen Grüßen
[Ihr Name]
尊敬的[先生姓名]先生：
我在此通知您我正在前往火星火箭的途中，我將從明天起缺席一週。做出這個決定是因為我想探索我的生活。
能夠接受您的教導並學習很多東西是一種極大的享受。我將永遠不會忘記這些知識。
希望我們能很快再次見面併為一切向您致謝！
此致
敬禮
[您的姓名]
--------------------------------------------------------------------------------------
عزيزي السيد [اسم المعلم$$],
أود أن أخبرك أنني أتجه حالياً إلى سفينة الغوص تحت الماء وأنا غائب ليوم واحد في الأسبوع. قررت هذا القرار لأنني أريد أن أكتشف العالم.
لقد كان من الجيد التعلم منك واستلام معلومات عديدة. سأحافظ على هذه المعرفة دائمًا في ذاكرتي.
آمل أن نلقى بعضًا مرة أخرى وأشكرك على كل شيء!
باحترام،
[اسم المطالب]
尊敬的[老師姓名]先生：
我謹此告知您：我將開始參與深海潛水艇的作業項目（每週將固定缺席一日）。作出這個決定是因為我想借此機會探索未知的世界。
能跟隨您學習並收穫豐富的知識是我的榮幸，這些寶貴的教導我將永遠銘記於心。
期待未來能有重逢之日！衷心感謝您給予的一切！
此致，敬禮
[申請人姓名]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;角色扮演&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 進行「八戒」角色扮演，&lt;strong&gt;未添加任何角色扮演提示詞或者角色預設&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-16c7b7c3d510d80e6e6a07dc7499606cb54.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;小説續寫&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 續寫小説（高亮板塊為 deepseek-R1 生成的前文）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b28c60063a5dfba402cba27473bb63ad559.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型下載&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 現已上傳到各大模型平台，可以從以下倉庫下載：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HF 主站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HF 鏡像站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FBlinkDL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://hf-mirror.com/BlinkDL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ModelScope：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FBlink_DL%2Frwkv-7-world%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/Blink_DL/rwkv-7-world/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2Frwkv-7-world%2F&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/rwkv-7-world/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;在線 Demo&lt;/h3&gt; 
&lt;p&gt;可在 Hugging Face Demo 在線體驗 RWKV-7-2.9B 模型：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在線 Demo 為續寫模式，不支持直接對話。請使用以下兩種格式輸入 prompts :&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;User: (你的問題，比如「請為我推薦三本適合五歲小孩閲讀的世界名著」 )
 
Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Instruction: （你希望模型進行什麼操作，比如「請將下列瑞典語翻譯成中文」）
 
Input:（輸入給模型的內容，比如「hur l?ng tid tog det att bygga twin towers」）
 
Response:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;未來計劃&lt;/h2&gt; 
&lt;p&gt;RWKV-7-2.9B 模型的強大能力，得益於 RWKV-7 架構的精妙改進。在應用了「動態 State 演化機制」後，RWKV-7 擁有強大的 in-context-learning（上下文學習）能力，在推理過程中更好地學習上下文的關係，生成的內容生更精簡、更合理。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV-7 的架構思路和細節：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj7IgeaqgnLfVl_sVn6OmzQ&quot; target=&quot;_blank&quot;&gt;RWKV-7：極先進的大模型架構，長文本能力極強&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV-7-7B 預計將使用新的 RWKV World V3.1 數據集訓練。World V3.1 數據集將在 World V3 的基礎上新增大量數學、代碼和 reasoning 數據，進一步增強模型的&lt;strong&gt;代碼、數學和推理能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;請關注我們的公眾號「RWKV 元始智能」，第一時間獲取 RWKV 動態！&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;RWKV 是一種創新的深度學習網絡架構，它結合了 Transformer 與 RNN 的優點，同時實現高度並行化訓練與高效推理。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV 中文官網（包括大量 RWKV 多模態論文）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV 英文官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.com%2F&quot; target=&quot;_blank&quot;&gt;https://rwkv.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV-5/6（Eagle &amp;amp; Finch）論文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.05892&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.05892&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV-4 論文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.13048&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2305.13048&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區！您可從 RWKV 官網瞭解 RWKV 模型，也可加入我們的官方論壇、QQ 頻道和羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV 論壇：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QQ 頻道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333299</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333299</guid>
            <pubDate>Fri, 07 Feb 2025 02:40:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>馬雲現身阿里杭州總部，閃現閒魚、夸克兩大業務辦公區</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日下午，阿里巴巴創始人馬雲現身阿里杭州園區，身穿阿里巴巴黑色文化夾克，全程微笑並向員工揮手致意。&lt;/p&gt; 
&lt;p&gt;據社交媒體上的阿里員工透露，今日上午，馬雲先出現的地方是阿里西溪園區 A 區 2 號樓的閒魚。此後，下午又有人在 C 區的夸克偶遇馬雲，身旁還有阿里巴巴集團 CEO 吳泳銘陪同。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60c6d8f397d9898ecffe3d57cacc36134b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;作為阿里 AI To C 的代表產品，夸克近期也升級了品牌 Slogan—「2 億人的 AI 全能助手」。&lt;/p&gt; 
&lt;p&gt;同時，阿里 AI To C 正在「招賢納士」，以提升用户的信息服務體驗。2 月 6 日，全球頂尖人工智能科學家、Salesforce 集團（CRM）前副總裁許主洪（Steven Hoi）&lt;a href=&quot;https://www.oschina.net/news/332267&quot; target=&quot;_blank&quot;&gt;正式加入阿里&lt;/a&gt;，出任集團副總裁，向吳嘉彙報，負責 AI To C 業務的多模態基礎模型及 Agents 相關基礎研究與應用解決方案。&lt;/p&gt; 
&lt;p&gt;有偶遇馬雲的阿里員工表示，「馬老師精神真的好好，特別開心的跟我們合影打招呼，就在智能信息這層，巡樓祝大家新年快樂。」&lt;/p&gt; 
&lt;p&gt;據悉，去年 11 月 29 日，馬雲第一次出現在阿里西溪園區 C 區，即杭州全球總部新園區。12 月 8 日，馬雲參加了螞蟻集團成立 20 週年活動。在活動上，馬雲着重提到了 AI 發展，他表示，從今天來看，未來 20 年的 AI 時代能帶來的改變會超出所有人的想象，因為 AI 會是一個更加偉大的時代。&lt;/p&gt; 
&lt;p&gt;2 月 8 日，馬雲也曾被網友在新加坡的一個高爾夫球場偶遇。當時，他正在享受一場悠閒的球賽，看起來狀態極佳。馬雲在新加坡的現身也引發了不少猜測，有人認為他可能正在為阿里巴巴的全球化戰略做準備，也有人認為他只是單純地享受個人時光。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333296</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333296</guid>
            <pubDate>Fri, 07 Feb 2025 02:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百川智能 CEO 王小川：AGI 的盡頭是生命科學</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo7wg-YavNVPm-KJxFpJ9uA&quot; target=&quot;_blank&quot;&gt;百川智能創始人兼 CEO 王小川接受晚點對話的採訪&lt;/a&gt;&lt;/u&gt;，表示「不是文本創作、不是物理模型，&lt;strong&gt;AGI 的盡頭是生命科學&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;採訪中，王小川提到，之所以堅定了公司方向聚焦醫療，是因為大模型是造人的，而醫生是人類職業中最複雜的之一，所以它可以成為一個標尺。並且他認為，大模型能造出醫生時，就是達到了 AGI。&lt;/p&gt; 
&lt;p&gt;同時，王小川對 DeepSeek 的「火爆全球」表示振奮，一方面他認為 DeepSeek 改變了行業格局，中國離實現 AGI 和應用爆發更近，另一方面，他覺得 DeepSeek 的出圈讓更多人體驗到了 AI，教育了整個行業。&lt;/p&gt; 
&lt;p&gt;在談及訓練醫療大模型費用時，&lt;strong&gt;王小川認為醫療模型有更高的價值，它關係生命健康，因此不能按 token 來算錢&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;王小川還預測了未來的技術發展趨勢。AI 通過學會使用工具，一步步學習製造工具，最後形成循環，AI 寫完代碼自己運行，AI 自己造工具自己用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333290</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333290</guid>
            <pubDate>Fri, 07 Feb 2025 02:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>國行蘋果 AI 敲定與阿里巴巴合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;根據科技媒體 The Information 的獨家報道，&lt;strong&gt;蘋果公司已經與阿里巴巴達成合作，為國行版的 iPhone 用户提供 AI 功能&lt;/strong&gt;，消息來源為一位知情人士。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0212/101826_AE4P_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，蘋果與阿里巴巴共同開發的國行 AI 功能已提交給國內相關部門審核。&lt;/p&gt; 
&lt;p&gt;兩位對該項目有直接瞭解的人士稱，蘋果在 2023 年開始測試來自中國開發者的不同 AI 模型，並一度選擇百度作為主要合作對象，但由於百度在為蘋果智能開發模型方面的進展未達到美國公司的標準，因此該合作後來被取消。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;蘋果最近幾個月開始考慮其他選項，評估騰訊、字節跳動、阿里巴巴以及 Deepseek 開發的模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;報道還提到，&lt;strong&gt;蘋果最終放棄了最近呼聲很高的 DeepSeek ，因為 DeepSeek 團隊缺乏支持像蘋果這樣的大客户所需的人力和經驗&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;648&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0212/101851_M45f_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;日前，蘋果向開發者發送了關於「利用蘋果智能的力量」開發者活動的相關郵件。&lt;/p&gt; 
&lt;p&gt;值得關注的是，本次活動將於 3 月 25 日 10:00 至 12:00 在上海&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/332912&quot;&gt;舉行&lt;/a&gt;&lt;/u&gt;，活動主題將圍繞蘋果智能和機器學習兩個方面。而這一舉動，也暗示在中國大陸的蘋果智能 AI 功能或將上線。&lt;/p&gt; 
&lt;p&gt;截至發稿前，蘋果和阿里巴巴官方尚未對此作出回應，但這兩家公司美股漲幅均已超過 1%，百度股價下跌超 4%。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相關來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fapple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&quot; target=&quot;_blank&quot;&gt;https://www.theinformation.com/articles/apple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333288</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333288</guid>
            <pubDate>Fri, 07 Feb 2025 02:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>李彥宏談 DeepSeek 爆火：創新是不能被計劃的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在阿聯酋迪拜舉辦的 World Governments Summit 2025 峯會上，百度創始人李彥宏與阿聯酋 AI 部長奧馬爾·蘇丹·奧拉馬對談時提及 DeepSeek 表示：創新是不能被計劃的。「你不知道創新何時何地到來，你所能做的是，營造一個有利於創新的環境。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;284&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-20f4da7c355029d6c8b5f97139534ed0d93.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 突然爆火背後，李彥宏稱，如果回顧過去幾百年，大多數創新都與降低成本有關，不僅是在人工智能領域，甚至不僅僅是在 IT 行業。如果能將成本降低一定數量、一定百分比，這意味着生產率提高了相同的百分比。這幾乎就是創新的本質。而今天，創新的速度比以前快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以科技行業為例，在過去，當業界談論摩爾定律時常説，每 18 個月性能會翻倍、成本會減半；但今天，當大家談論大語言模型時，可以説每 12 個月，推理成本就可以降低 90% 以上。這比人們過去幾十年經歷的計算機革命要快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「大語言模型是一個非常龐大的領域。在中國，我們必須在推理和訓練方面創新以降低成本。幸運的是，過去一年，我們看到了顯著進步。」李彥宏表示，在對話中，奧拉馬還提到，幾周前，當 DeepSeek 成為人人都談論的話題時，不少全球大型芯片廠商股價大幅下跌。因為巨頭們此前需要花費數十億美元用於推理數據中心、訓練這些人工智能系統和模型。在 DeepSeek 的衝擊下，數據中心和 AI 基礎設施的未來是否會發生變化？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;李彥宏表示，自己在過去一個月左右的時間裏，一直在思考這個問題。從基本面來看，最重要的仍然是技術進步非常快，成本每年降低約 90%，性能越來越好。「當技術發展如此之快，你無法停止投資。你必須投資，以確保處於這場技術創新或革命的最前沿。我們仍需對芯片、數據中心和雲基礎設施進行持續投入，用於打造更優秀、更智能的下一代模型。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為此，企業需要使用更多的算力來嘗試不同的路徑。「也許，在某個時刻你會找到一條捷徑，比如説只需 600 萬美元就能訓練出一個模型，但在此之前，你可能已經花費了數十億美元，用來探索哪條路才是花費這 600 萬美元的正確途徑。」李彥宏説。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他認為，目前的 AI 應用離那種級別的應用還有很遠的距離。「整個世界目前都在焦急地尋找這樣的超級 App。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333284</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333284</guid>
            <pubDate>Fri, 07 Feb 2025 02:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度文小言（原文心一言）App 接入 DeepSeek-R1 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;iOS 版百度文小言（原文心一言）App 日前迎來了 4.9.0 版本更新，更新描述稱該版本已接入 DeepSeek-R1 模型，優化拍照解題功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5a4769f89c4a201f4028836651b2741d29f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲ 百度文小言（原文心一言）App 接入 DeepSeek-R1 模型&lt;/p&gt; 
&lt;p&gt;接入 DeepSeek-R1 模型後，文心一言 App 的拍照解題功能得到了顯著提升。用户在使用該功能時，可以清晰地看到解題過程中的思考步驟，這與 DeepSeek 特有的思維鏈功能非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4cc68ae51d81f06ed72ba3d94755a877e04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1944e58c65fe9c878bae4407b0cf63cf2ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用户表示，「這極大地提升了用户的解題體驗。用户通過拍攝問題，系統將自動識別並給出詳細的解題思路，這對於需要進行學習和複習的用户來説是個好消息。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333181</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333181</guid>
            <pubDate>Thu, 06 Feb 2025 10:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>男子用 DeepSeek 買彩票中獎：買 10 元中 5 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日，詞條#用 DeepSeek 買彩票真中獎了#登上微博熱搜榜第一，引起許多網友熱議。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/172819_3xs4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據媒體報道，日前，安徽蕪湖一男子發帖稱，自己按照 DeepSeek 推薦的號碼買雙色球，真的中獎了。&lt;/p&gt; 
&lt;p&gt;該男子用 5 組 DeepSeek 推薦的數字下注，&lt;strong&gt;合計 10 元，其中一組數字中了「2+1」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/173130_nyzI_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，這是第一次買雙色球，也是才接觸 DeepSeek，突發奇想想看看到底準不準，這樣的行為不能「上頭」，自己之後不會再用 DeepSeek 推薦的數字繼續買彩票。&lt;/p&gt; 
&lt;p&gt;據中國福利彩票服務熱線工作人員介紹，&lt;strong&gt;上述情況是中了六等獎，獎金為 5 元。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於該男子的做法，有網友表示：「合計 10 元，中了 5 元？有沒有可能沒有 DeepSeek，你買五組也有這個概率呢？我覺得也沒必要神話 DeepSeek。」「隨機概率這麼大，跟它真沒太大關係。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333169</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333169</guid>
            <pubDate>Thu, 06 Feb 2025 09:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度李彥宏：自動駕駛比人開車安全十倍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日消息，「世界政府峯會」（World Goverments Summit 2025）今日在阿聯酋迪拜開幕，百度創始人李彥宏今日上午在主論壇上與阿聯酋 AI 部長奧馬爾・蘇丹・奧拉馬（Omar Sultan AI Olama）對談時表示，Robotaxi 可以大大降低交通事故死亡率。從蘿蔔快跑的實際記錄來看，出險率僅為人類駕駛員的 1/14。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8b66f69d2ba73a703403b32ebdae56e2f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李彥宏表示：「技術進步非常快，自動駕駛比人類司機安全十倍。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74a55024af52c507dd898d356bf590ace0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，2024 年第二季度，百度的自動駕駛服務蘿蔔快跑供應的自動駕駛訂單約 89.9 萬單，同比增長 26%。截至 2024 年 7 月 28 日，蘿蔔快跑累計為公眾提供的自動駕駛出行服務訂單超過 700 萬單。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/301302&quot; target=&quot;news&quot;&gt;百度旗下的「蘿蔔快跑」無人駕駛出租車武漢街頭撞倒行人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333160</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333160</guid>
            <pubDate>Thu, 06 Feb 2025 08:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>嘉立創集團加入 openKylin，助推社區計算多元化生態繁榮</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;text-align:justify&quot;&gt;&lt;span&gt;近日，深圳嘉立創科技集團股份有限公司（簡稱「嘉立創集團」），簽署 OpenAtom openKylin（簡稱「openKylin」）社區 CLA（Contributor License Agreement 貢獻者許可協議），正式加入 openKylin 開源社區。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1527&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8345ba8245337a544b99cf88d729976dd5.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;嘉立創集團&lt;/span&gt;&lt;/span&gt;&lt;span&gt;是電子及機械產業一站式基礎設施服務提供商，旗下擁有電子及機械產業一站式服務提供商嘉立創科技、大批量 PCB/PCBA 智造企業中信華和國內領先的樣品/小批量電子元器件線上服務商立創商城等三大運營板塊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;依託產業鏈一站式服務、全流程閉環數字化底座、柔性化智能製造等領先優勢以及百萬級用户基礎，公司打造了「一站式產業互聯智造模式」，為客户提供覆蓋從打樣到小批量再到大批量的 PCB 智造、電子元器件商城、SMT、激光鋼網等電子產業鏈和 CNC 機械智造、3D 打印、FA 機械電氣零部件商城等機械產業鏈一體化服務，以及以 EDA、CAM、DFM、CAD 軟件為核心的工業軟件集羣。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;410&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-620266042dadaea8fb8477b013d338fc9ca.jpg&quot; width=&quot;940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;在加入 openKylin 社區後，嘉立創集團除了在產品適配、市場推廣、技術協同等關鍵業務領域積極作為與開拓進取之外，也將進一步秉持開放合作、互利共贏的發展理念，充分發揮自身資源優勢與產品的優越性，對 openKylin 社區進行全方位的業務支持，助力實現開源生態的繁榮發展，&lt;span&gt;為經濟持續發展、科技再創新高提供源動力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333148</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333148</guid>
            <pubDate>Thu, 06 Feb 2025 07:55:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>DeepSeek 梁文鋒身家暴漲，有專家預計或超黃仁勳</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社報道顯示，7 位創業公司創始人和人工智能專家對 DeepSeek 的估值存在巨大分歧，估值區間在 10 億美元到 1550 億美元之間。按照彭博億萬富翁指數中間值估算，DeepSeek 估值約在 20 億至 300 億美元，而持有公司 84% 股份的梁文鋒，身家可能在 16.8 億到 252 億美元之間，有望躋身亞洲最富有的科技大亨之列，甚至問鼎中國首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不同業內人士給出的估值差異極大。波士頓風險投資公司 Glasswing Ventures 創始人魯迪納・塞塞裏認為，按同行公司估值，DeepSeek 最少值 10 億美元；研究工程師 Sebastian Raschka 則覺得，憑藉強大的品牌認知度，其估值應在 20 億到 100 億美元之間，高於 Mistral AI。而 Sweat Free Telecom 創始人查納基亞・拉姆德夫的預測更為樂觀，認為 DeepSeek 估值可達 1550 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2fbcd3fec3d8b307089121298b01c62f34.webp&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前 1 月有報道稱，軟銀集團洽談牽頭對 OpenAI 進行最高 400 億美元融資，融資後估值達 3000 億美元。若 DeepSeek 按此估值一半計算，梁文鋒個人財富或達 1260 億美元，有望超過英偉達 CEO 黃仁勳，身家遠超鍾睒睒等富豪，在同領域也將遠超字節跳動創始人張一鳴（2024 年福布斯中國內地富豪榜顯示張一鳴身價 456 億美元，梁文鋒身家或為其 3 倍） 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;梁文鋒出生於 1985 年，本碩就讀於浙江大學信息與通用工程專業，師從項志宇，研究機器視覺，2010 年畢業。畢業後，他投身量化投資，成立幻方量化，僅 6 年管理規模達千億，成為 「量化四大天王」 之一。2023 年 5 月，梁文鋒決心進軍通用人工智能領域，7 月成立 DeepSeek，被視為量化投身 AI 創業第一人。2024 年 12 月底，DeepSeek 發佈的 DeepSeek-V3 火遍全網。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不過，由於 DeepSeek 收入、利潤等財務數據保密，外界只能通過對比 OpenAI、Anthropic 等公司估值來推測其價值，這些估值僅供參考。梁文鋒的真實身家究竟幾何，還需時間揭曉。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333142</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333142</guid>
            <pubDate>Thu, 06 Feb 2025 07:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「互聯網之子」 Aaron Swartz 雕像在互聯網檔案館揭幕</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Aaron Swartz 的大理石雕像上週五在互聯網檔案館的禮堂揭幕，有大約 300 人出席，半身像下方刻有文字&lt;em&gt;「The Internet&#39;s Own Boy（互聯網之子）」&lt;/em&gt;。本週重 312 磅的雕像將先轉移至大廳，直至獲得許可放置在當地公園內。&lt;/p&gt; 
&lt;p&gt;揭幕儀式上，Creative Commons 聯合創始人 Lisa Rein 強調：「崇拜 Aaron 的前提是正確理解他的故事——他並非殉道者，而是為公眾已付費的科學研究成果應自由獲取而戰。」電子前沿基金會（EFF）執行董事 Cindy Cohn 則稱，這座雕像「提醒人們為真理與正義持續鬥爭」。科幻作家 Cory Doctorow 在視頻致辭中暗諷特朗普政府時期的政治環境：「這是一個希望稀缺的時代，但這座雕像應激勵我們讓世界變得更好」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f82cf0e74040f33cd165bbe250c47ae3e5c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Aaron Swartz 出生於 1986 年，參與了 RSS 和 Markdown、web.py 等項目的開發，被視為是 Reddit 的聯合創始人。&lt;/p&gt; 
&lt;p&gt;2011 年 1 月他因為在 MIT 下載學術論文而遭到逮捕，面臨最高 35 年的刑期，他拒絕了認罪協議，於 2013 年 1 月 11 日自殺身亡。他在當年被追授進入互聯網名人堂。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/92332/in-memory-of-aron-swartz&quot; target=&quot;news&quot;&gt;紀念 Aaron Swartz：他用生命捍衞了互聯網的開放和自由&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/36671/aaron-swartz-kill-himself&quot; target=&quot;news&quot;&gt;web.py 作者 Aaron Swartz 自殺身亡&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</guid>
            <pubDate>Thu, 06 Feb 2025 06:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>