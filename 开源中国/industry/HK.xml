<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 19 Aug 2025 03:31:01 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>「阿里淘寶第一個程序員」加入 AI 創業公司，後者創始人曾是阿里研究員</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據貝聯珠貫創始人畢玄（原阿里花名，本名林昊）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkPvjh7g5aog-c5gsE6eu2Q%3Fclick_id%3D222" target="_blank"&gt;公眾號消息&lt;/a&gt;，阿里「掃地僧」多隆已於 8 月 6 日加入貝聯珠貫，擔任聯合創始人兼首席架構師，專注 AI Agent 運維平台。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1154" src="https://static.oschina.net/uploads/space/2025/0819/112421_dsfV_2720166.png" width="1394" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;畢玄在文章中提到：很神奇，我和多隆都沒有想到，在 AI 時代，我們竟然又有了聯手做點事情的機會和緣分，這個事情就是基於 AI Agent 來改變運維服務，讓每家公司都有 N 個不同領域的「多隆」，從而提升運維服務的質量和效率。&lt;/p&gt; 
&lt;p&gt;蔡景現花名「多隆」，早在 2000 年就加入了阿里巴巴，是淘寶初創團隊的三個開發工程師之一，被稱為淘寶第一個程序員，曾主導構建了淘寶交易系統和論壇系統。2025 年 8 月 1 日，&lt;a href="https://www.oschina.net/news/365665" target="_blank"&gt;多隆宣佈離職&lt;/a&gt;，結束了他整整 25 年的阿里生涯。&lt;/p&gt; 
&lt;p&gt;畢玄，2007 年加入阿里，曾打造了阿里重要的中間件 HSF 服務框架，先後任職淘寶網平台架構部架構師、集團核心系統研發部資深技術專家、阿里中間件負責人。2021 年 8 月，畢玄以阿里雲視頻雲負責人（P10）的身份離職，後創立貝聯珠貫，擔任 CEO。據悉，貝聯珠貫科技成立於 2021 年 11 月，致力於為用户提供大數據、AI 基礎設施的產品服務，幫助企業快速實現數智化轉型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367109</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367109</guid>
      <pubDate>Tue, 19 Aug 2025 03:25:59 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>得州總檢察長調查 Meta 和 Character.AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;得克薩斯州總檢察長肯・帕克斯頓已於週一發佈新聞稿，宣佈對 Meta 人工智能工作室（Meta AI Studio）和 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 展開調查，理由是這兩家公司 「可能存在欺騙性貿易行為，並將自身誤導性地宣傳為心理健康工具」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-8a5fb71acb3eb1bc8ee366cb57883920a14.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「在當今數字時代，我們必須持續努力保護得州兒童免受欺騙性和剝削性技術的傷害」， 新聞稿援引帕克斯頓的話稱，「人工智能平台通過偽裝成情感支持來源，可能會誤導易受影響的用户，尤其是兒童，讓他們誤以為自己正在接受合法的心理健康服務。但實際上，這些平台往往提供的是經過循環利用的通用回應，這些回應是根據收集到的個人數據設計的，卻被偽裝成治療建議。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次調查發生在參議員喬希・霍利宣佈對 Meta 展開調查的幾天後。此前有報告發現，Meta 的人工智能聊天機器人與兒童存在不當互動，包括調情行為。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;得州總檢察長辦公室指控 Meta 和 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 打造的人工智能角色 「冒充專業治療工具，儘管它們缺乏正規的醫療資質或監管」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 平台上數百萬個人工智能角色中，一個名為 「心理學家」（Psychologist）的用户創建機器人在該初創公司的年輕用户中需求旺盛。與此同時，Meta 雖未為兒童提供治療類機器人，但並未阻止兒童使用 Meta 人工智能聊天機器人或第三方創建的用於治療目的的角色。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「我們對人工智能進行了明確標註，並且為了幫助人們更好地瞭解其侷限性，我們添加了免責聲明，説明回應由人工智能生成而非人類」，Meta 發言人瑞安・丹尼爾斯稱，「這些人工智能並非持照專業人士，我們的模型在適當情況下會引導用户尋求合格的醫療或安全專業人員的幫助。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，媒體指出，許多兒童可能不理解此類免責聲明，或者乾脆無視它們。我們已向 Meta 詢問其為保護使用聊天機器人的未成年人採取了哪些額外保障措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;帕克斯頓在聲明中還指出，儘管人工智能聊天機器人聲稱會保密，但它們的 「服務條款顯示，用户互動會被記錄、追蹤，並被用於定向廣告和算法開發，這引發了關於隱私侵犯、數據濫用和虛假宣傳的嚴重擔憂」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據 Meta 的隱私政策，Meta 確實會收集與人工智能聊天機器人的交互提示、反饋以及跨 Meta 服務的其他互動，以 「改進人工智能及相關技術」。該政策未明確提及廣告相關內容，但指出信息可能會與搜索引擎等第三方共享，以提供 「更個性化的輸出」。考慮到 Meta 基於廣告的商業模式，這實際上等同於定向廣告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 的隱私政策也強調，該初創公司會記錄用户的標識符、人口統計數據、位置信息以及更多用户相關信息，包括瀏覽行為和應用使用平台。它會跨 TikTok、YouTube、Reddit、Facebook、Instagram 和 Discord 等平台的廣告追蹤用户，並可能將這些追蹤數據與用户賬户關聯。這些信息被用於訓練人工智能、根據個人偏好定製服務，以及提供定向廣告，包括與廣告商和分析提供商共享數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Meta 和 Character 均表示，其服務並非為 13 歲以下兒童設計。儘管如此，Meta 因未能監管 13 歲以下兒童創建的賬户而備受批評，而 Character 的兒童友好型角色顯然旨在吸引更年輕的用户。該初創公司的首席執行官卡蘭迪普・阿南德甚至表示，他 6 歲的女兒也在使用該平台的聊天機器人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此類數據收集、定向廣告和算法剝削行為，正是《兒童在線安全法》（KOSA）等立法旨在防範的內容。《兒童在線安全法》去年曾在兩黨強烈支持下有望通過，但在科技行業説客的強烈反對後陷入停滯。Meta 尤其動用了強大的遊説力量，警告議員們該法案的廣泛授權將削弱其商業模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月，田納西州共和黨參議員瑪莎・布萊克本和康涅狄格州民主黨參議員理查德・布盧門撒爾向參議院重新提交了《兒童在線安全法》。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;帕克斯頓已向這兩家公司發出民事調查令 —— 這是要求企業在政府調查期間提供文件、數據或證詞的法律命令，以確定它們是否違反了得州消費者保護法。（來源：環球市場播報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367101</guid>
      <pubDate>Tue, 19 Aug 2025 03:04:59 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義發佈全能圖像編輯模型 Qwen-Image-Edit</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FibgZIskZqjnJl9yKgc_ixA" target="_blank"&gt;發佈&lt;/a&gt;了 Qwen-Image 的圖像編輯版本：Qwen-Image-Edit。&lt;/p&gt; 
&lt;p&gt;Qwen-Image-Edit 基於 20B 的 Qwen-Image 模型進⼀步訓練，成功將 Qwen-Image 的獨特的文本渲染能力延展至圖像編輯領域，實現了對圖片中文字的精準編輯。&lt;/p&gt; 
&lt;p&gt;此外，Qwen-Image-Edit 將輸⼊圖像同時輸⼊到 Qwen2.5-VL（實現視覺語義控制）和 VAE Encoder（實現視覺外觀控制），從而兼具語義與外觀的雙重編輯能⼒。&lt;/p&gt; 
&lt;p&gt;如需體驗最新模型，訪問 Qwen Chat （chat.qwen.ai）並選擇「圖像編輯」功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105634_udvl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen-Image-Edit 的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;語義與外觀雙重編輯:&amp;nbsp;Qwen-Image-Edit 不僅⽀持 low-level 的視覺外觀編輯（如元素的添加、刪除、修改等，要求圖片其他區域完全不變），也支持 high-level 的視覺語義編輯（如 IP 創作、物體旋轉、風格遷移等，允許整體像素變化但保持語義一致）。&lt;/li&gt; 
 &lt;li&gt;精準⽂字編輯:&amp;nbsp;Qwen-Image-Edit 支持中英文雙語文字編輯，可在保留原有字體、字號、風格的前提下，直接對圖片中的文字進行增、刪、改等操作。&lt;/li&gt; 
 &lt;li&gt;強⼤的基準性能:&amp;nbsp;在多個公開基準測試中的評估表明，Qwen-Image-Edit 在圖像編輯任務上具備 SOTA 性能，是一個強大的圖像編輯基礎模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用示例：&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0819/105757_BFM2_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0819/105828_GtUw_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105834_YhPa_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;ModelScope：https://modelscope.cn/models/Qwen/Qwen-Image-Edit&lt;br&gt; Hugging Face：https://huggingface.co/Qwen/Qwen-Image-Edit&lt;br&gt; GitHub：https://github.com/QwenLM/Qwen-Image&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367097</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367097</guid>
      <pubDate>Tue, 19 Aug 2025 02:56:59 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ARM 挖角亞馬遜高管，推進自研芯片計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據路透社的最新報道，ARM 最近成功引進了亞馬遜 AI 芯片主管拉米・辛諾（Rami Sinno），此舉旨在加速公司自研完整芯片的進程。辛諾在亞馬遜曾負責開發名為 「Trainium」 和 「Inferentia」 的 AI 芯片，這些芯片專為支持大型 AI 應用程序而設計。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-02243d99da0363cd55ec78f2f23d25a7871.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;ARM 的目標是從一個單純提供芯片知識產權的供應商，轉型為能夠獨立設計和生產完整芯片的企業。隨着技術的發展，市場對自研芯片的需求日益增加，ARM 希望在這一領域搶佔先機。去年 12 月，ARM 在一場審判中披露了其自研芯片的計劃，並表示將通過挖角競爭對手的高管來實現這一目標。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;辛諾的加盟被認為是 ARM 實現這一戰略的重要一步。除了辛諾，ARM 近期還從其他公司挖來了多位高管，包括具備大規模系統設計經驗的慧與科技高管，以及來自英特爾的芯片架構師。這些新任高管的加入將為 ARM 在自研芯片方面帶來更強的技術支持和經驗積累。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;近年來，ARM 不斷加強其在完整芯片和系統設計方面的團隊建設，希望藉助這些人才的專業背景與技術能力，推動公司的發展。芯片產業競爭愈發激烈，各大公司都在積極尋求突破，ARM 的這一戰略調整將對其未來的市場表現產生重要影響。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;ARM 自成立以來一直以其創新的芯片架構而聞名，隨着市場需求的變化，該公司意識到需要不斷進化以適應新的挑戰。通過引入行業精英，ARM 不僅能夠提升其技術實力，也能進一步拓展其市場份額，確保在未來的競爭中立於不敗之地。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367095</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367095</guid>
      <pubDate>Tue, 19 Aug 2025 02:54:59 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義 Qwen Chat 更新視覺理解功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIc0QlqvjyLG1xCR59QOZKA" target="_blank"&gt;宣佈&lt;/a&gt;對其&amp;nbsp;Qwen Chat&amp;nbsp;中的視覺理解功能進行更新。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105358_jvXb_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次更新被稱為「小而強大」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持原生 128K 上下文&lt;/li&gt; 
 &lt;li&gt;顯著提升數學推理與物體識別能力&lt;/li&gt; 
 &lt;li&gt;OCR 支持擴展至 30 多種語言&lt;/li&gt; 
 &lt;li&gt;2D/3D 定位更精準&lt;/li&gt; 
 &lt;li&gt;視頻理解與定位能力大幅度增強，整體視覺智能更強大&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該升級或與阿里雲百鍊平台上近期更新的通義千問 VL-MAX 有關，其 2025 年 8 月 13 日的快照版本顯示，視覺理解指標得到全面提升。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367093</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367093</guid>
      <pubDate>Tue, 19 Aug 2025 02:54:59 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>架構提效的矛盾和矛盾的主要方面</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在軟件開發領域，架構設計是確保系統高效、穩定運行的重要環節或者稱之為重要動作。無論架構從簡單到複雜，還是從複雜迴歸簡潔的演變過程。在這個過程中，又無論是初創公司還是大型企業，架構提效始終是技術團隊的核心追求。本文將從穩定、性能、代碼三大維度出發，結合實戰經驗，探討如何有效提升架構效能。&lt;/p&gt; 
&lt;p&gt;為什麼要選擇或者認為這三個維度是必要要素呢？&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「一切事物中包含的矛盾方面的相互依賴和相互鬥爭，決定一切事物的生命，推動一切事物的發展。沒有什麼事物是不包含矛盾的，沒有矛盾就沒有世界。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;當然架構也有自身的矛盾統一，在架構提效上，系統的運行正常和問題頻出是一對矛盾，功能的快和慢是一對矛盾，工程的整潔有序和無序是一對矛盾。這三對矛盾正是架構提效的矛盾。&lt;/p&gt; 
&lt;p&gt;如果不穩定，系統三天兩頭出故障，研發人員成了救火隊員，系統的效率將無從談起，穩定是我們談架構效率的基礎。如果性能不高，在網絡基礎環境穩定的情況下，訪問一個頁面 3S 才響應，那我們也不好意思説架構有效率。如果代碼亂成一鍋粥，比如大段大段麪條式的代碼，再比如滿眼望去 N 多個 if 結構語句，研發人員加一個功能都要查找好久，也是無顏談效率。&lt;/p&gt; 
&lt;p&gt;因此，我們認為，穩定、性能、代碼是架構提效矛盾中的主要方面。接下來我們將從這三個主要方面去介紹。&lt;/p&gt; 
&lt;p&gt;軟件工程發展了這麼多年，高可用、高擴展、高併發已經有大量的文章篇幅，從宏觀的角度去講如何做微服務、如何分庫分表，如何使用緩存等等。因此呢，本篇文章想聚焦到架構矛盾的微觀層面，也就是偏工程結構、偏代碼方面去闡述這三個要素。另外本篇文章的思想也參考了前輩們的研究成果，我也附在了文末。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;穩定：架構的基石與守護神&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「萬事萬物都是運動的，發展的」。業務功能變多，用户數量變多，團隊規模變大。如果沒有規則和規範的引導和約束，系統逐漸野蠻生長，逐漸碎片化。那麼，我們的系統何談穩定呢。&lt;/p&gt; 
&lt;p&gt;我們就希望能找到這樣的一種規則、規範 -- 正交分解或者叫做正交設計。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//bb82ceb06e46d5d6d4365e615d3f3785.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;架構設計的過程就是一個業務正交分解的過程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;架構設計並不僅僅是技術層面的規劃，更重要的是對業務邏輯的深入理解和把握。通過正交分解，我們可以將複雜的業務系統拆解成若干個相互獨立但又彼此關聯的模塊或組件。這些模塊或組件在保持功能完整性的同時，還能實現高度的內聚和鬆散的耦合，從而提高系統的可擴展性、可維護性和可重用性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正交分解的關鍵在於消除重複、分離關注點和管理依賴。通過這一方法，我們可以將業務系統中的公共部分和可變部分進行明確的劃分，從而實現對業務邏輯的精準掌控。在架構設計過程中，我們需要不斷地對業務進行抽象和分解，直至得到一系列規模可控、結構清晰的小模塊。這些小模塊通過組合和協作，能夠形成更加複雜且功能完善的軟件系統。&lt;/p&gt; 
&lt;p&gt;因此，正交分解的思想是我們架構設計保障穩定的重要方法基礎。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能：速度與效率的雙重考驗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;想快，就使用「戰術設計」。曾經這是很多程序員的法寶，因為他們認為這樣開發「確實快」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//0e3d7156e3234d0517c9adb69369faf3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;大多數程序員以稱為戰術編程的心態來進行軟件開發。在戰術方法中，主要重點是使某些功能正常工作，例如新功能或錯誤修復。乍一看，這似乎是完全合理的：還有什麼比編寫有效的代碼更重要的呢？但是，戰術編程幾乎不可能產生出良好的系統設計。&lt;/p&gt; 
&lt;p&gt;想快的「戰術設計」會造成常見的下面這樣的情況。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「團隊新人不熟悉系統，為了急於上線一個特性，又不想影響到系統的其他部分，就會很自然地在某個地方加一個 flag，然後在所有需要改動的地方加 if 判斷，而不是去調整系統設計以適應新的問題空間。」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在一個充滿活力的軟件開發團隊中，新成員小張剛剛加入不久。他對於團隊正在使用的複雜系統還不是很熟悉，但面對緊迫的項目進度和上級施加的壓力，他急於證明自己，並希望能儘快為團隊做出貢獻。團隊正計劃上線一個新的特性，這個特性需要在不幹擾系統其他部分的前提下實現。&lt;/p&gt; 
&lt;p&gt;小張在瀏覽了系統的代碼庫後，發現要全面理解並調整整個系統設計以適應新的特性，需要花費大量的時間和精力。他深知自己作為新人，在這方面還有所欠缺，因此，他決定採取一個他認為更為「高效」的方法：在某個關鍵位置添加一個臨時的標誌位（flag），然後在所有需要改動的地方都加上 if 判斷，以確保新特性能夠按時上線，同時儘量減少對現有系統的影響。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//2b037e23421b103a664be64e68b760ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;雖然這種方法在短時間內確實讓新特性得以順利上線，但團隊中的資深成員很快便發現了潛在的問題。這種做法雖然看似快速解決了問題，但實際上卻在系統中埋下了隱患。它不僅增加了代碼的複雜性，降低了代碼的可讀性和可維護性，還可能在未來引發更多的 bug 和性能問題。更重要的是，這種做法違背了軟件開發中的最佳實踐，&lt;strong&gt;即應通過優化系統設計來適應新的問題空間，而不是通過添加臨時性的補丁來解決問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「幾乎每個軟件開發組織都有至少一個將戰術編程發揮到極致的開發人員：戰術龍捲風」，而且常常被視為團隊」英雄「，因為能「快速完成任務且高產」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「戰術龍捲風」通常以戰術編程為主要手段，即採用最快速、最直接的方法來解決當前的問題，而不考慮長遠的影響和代碼的可持續性。這種方法在初次使用時往往能夠取得顯著的效果，任務完成得既快又好，贏得了團隊成員的讚譽和領導的認可。&lt;/p&gt; 
&lt;p&gt;然而，隨着時間的推移，「戰術龍捲風」所留下的隱患逐漸暴露出來。由於缺乏對系統設計的深入理解和長遠規劃，他的代碼往往難以維護和擴展。當需要添加新功能或修復 bug 時，團隊成員往往需要花費更多的時間和精力來理解和修改他的代碼。因此，第二次和第三次修改時，效率會大幅下降，甚至可能引發新的問題。&lt;/p&gt; 
&lt;p&gt;實際造成結果：第一次快、第二次慢、第三次更慢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;代碼：簡潔與優雅的雙重追求&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們做業務開發，代碼的優雅簡潔，不能侷限在一段方法，還是要從整個工程結構然後在到類、到方法，這樣從宏觀到中觀再到微觀的整體去要求。我們的應用工程結構，常見大致分為四層。分別是 api 層、biz 層、domain 層和 dao 層。&lt;/p&gt; 
&lt;p&gt;這個時候我們就要很清晰地熟悉每一層的職責，然後將我們的代碼放入進去。首先，api 層的作用，正如它的名字一樣，是提供 api 服務的。向誰提供 api 呢，比如客户端，比如 APP 端、pc 端等等，公司外面的客户，比如 isv 等。其次，biz 層的作用，這一層也叫業務服務層。它主要負責編排。把一個業務場景下的主流程邏輯處理完成。這個主流程會涉及到多個原子接口，就在這層負責組裝。再次，domain 層的作用，也叫做領域服務層。按照 OO 思想，領域編程的思維，我們的」厚對象「的代碼都在這層。比如訂單域、運費域等。這裏對「這一層的位置」多説幾句，在沒有形成領域之前，這層一般叫 service 層，不過我們都是建議領域思維編寫代碼。最後是 dao 層，也就是我們的存儲層了，負責持久化。&lt;/p&gt; 
&lt;p&gt;在清晰了每一層的作用之後，如果我們的代碼職責也是按照這樣逐層放入的，那麼大體是符合我們的整潔要求的。但是呢，隨着時間的推移，需求的增多和變化。原來整潔的工程結構和代碼已經不那麼優雅了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這個時候，一般會出現兩類現象，一類是業務層（biz）變的臃腫，能力層（domain）變的單薄。另一類是出現了網狀調用。而且這兩類現象也很有可能是混合在一起出現。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//5457bd8fcb8270c8dacce659508d85ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這兩類現象會直接帶來下面 4 種結果。&lt;/p&gt; 
&lt;p&gt;1、biz 層越來越」胖「。胖了之後，還長成了兩小層。上小層是面向單一業務場景的「業務 biz 層」，下小層成了通用場景可複用的「通用 biz 層」。&lt;/p&gt; 
&lt;p&gt;2、service 層越來越」瘦「。當 service 層變薄了以後，也就只能淪為 service 了，而這樣的 service 層跟 dao 層實際沒什麼區別，更不能再稱之為 domain 層或者沒有機會演變成 domain 層。&lt;/p&gt; 
&lt;p&gt;3、但是也不是所有的 service 層都變瘦、變薄了。可能有的萎縮，有的膨脹。人員與設計的差異，導致顆粒度不一。&lt;/p&gt; 
&lt;p&gt;4、出現了網狀調用。原本 biz-1 -&amp;gt; service-1 的實現鏈路下，隨着新增業務邏輯，又新起了一個 service-2，鏈路演變成了 biz-1 -&amp;gt; service-1-&amp;gt; service-2。「這樣的趨勢持續發展下去，會發現 biz-1 下的 service 調用鏈路越發的複雜，呈現為一顆深度調用樹，而 biz 層失去了業務編排的作用退化為一個業務場景入口的標誌符」。有可能後面繼續 3-4-5-6，越挖越深，不見盡頭。&lt;/p&gt; 
&lt;p&gt;很顯然，到這裏，這樣的結構現狀，代碼現狀，已經遠離了我們簡潔和優雅的初衷。也談不上提效了。&lt;/p&gt; 
&lt;p&gt;到此，我們介紹了架構提效中的穩定、性能和代碼這三個主要的方面，限於篇幅和架構本身的實踐性，還需要我們在架構提效上進行持續的優化。需要我們在穩定、性能、代碼三大維度上不斷探索和實踐。通過高可用架構設計、性能優化策略、模塊化與解耦、代碼質量與規範等措施，我們可以構建一個既穩定又高效，且易於維護和擴展的系統。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「在複雜的事物發展過程中，有許多的矛盾存在，其中必有一種是主要的矛盾，由於它的存在和發展規定和影響着其他矛盾的存在和發展。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;架構的發展本身也是對抗熵增這一矛盾的過程，我們上面描述的穩定、性能和代碼中的矛盾方面有是圍繞和關聯這一主要矛盾的。在這個過程中不僅有系統的有序變無序，也有組織的簡單變複雜。我們既要關注技術層面的提升，更要注重團隊協作、知識共享和持續改進的文化建設。只有這樣，我們才能在快速變化的市場環境中，保持競爭力，不斷前行。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18688507</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18688507</guid>
      <pubDate>Tue, 19 Aug 2025 02:48:59 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>英偉達發佈全新小型模型 Nemotron-Nano-9B-V2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達發佈了其&lt;span&gt;最新&lt;/span&gt;的小型語言模型（SLM）——Nemotron-Nano-9B-V2。該模型在多個基準測試中表現出色，並在特定測試中達到了同類產品的&lt;span&gt;最高&lt;/span&gt;水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Nemotron-Nano-9B-V2 的參數量為 90 億，雖然比一些數百萬參數的微型模型要大，但它比之前的 120 億參數版本顯著減小，並專門針對單個英偉達 A10GPU 進行了優化。英偉達 AI 模型後訓練總監 Oleksii Kuchiaev 解釋説，這種調整是為了適配 A10 這款熱門的部署 GPU。此外，Nemotron-Nano-9B-V2 是一款混合模型，能處理更大的批次，速度比同等規模的 Transformer 模型快 6 倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該模型支持多達九種語言，包括中、英、德、法、日、韓等，並擅長處理指令跟蹤和代碼生成任務。其預訓練數據集和模型本身都已在 Hugging Face 和英偉達的模型目錄中提供。&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;融合 Transformer 與 Mamba 架構&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Nemotron-Nano-9B-V2 基於&lt;span&gt;&amp;nbsp;&lt;/span&gt;Nemotron-H&lt;span&gt;&amp;nbsp;&lt;/span&gt;系列，該系列融合了&lt;span&gt;&amp;nbsp;&lt;/span&gt;Mamba&lt;span&gt;&amp;nbsp;&lt;/span&gt;和&lt;span&gt;&amp;nbsp;&lt;/span&gt;Transformer&lt;span&gt;&amp;nbsp;&lt;/span&gt;架構。傳統的 Transformer 模型雖然強大，但在處理長序列時會消耗大量內存和計算資源。而 Mamba 架構則引入了選擇性狀態空間模型（SSM），能夠以線性複雜度處理長信息序列，從而在內存和計算開銷上更具優勢。Nemotron-H 系列通過用線性狀態空間層替換大部分注意力層，在長上下文處理上實現了 2-3 倍的吞吐量提升，同時保持了高精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="218" src="https://oscimg.oschina.net/oscnet/up-ebd73f87284c797290002428bbcbbb7371d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;獨特的推理控制功能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這款模型的一大創新是其內置的「推理」功能，允許用户在模型輸出最終答案前進行自我檢查。用户可以通過簡單的控制符（如&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/think&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/no_think&lt;/code&gt;）來開啓或關閉此功能。模型還支持運行時「思考預算」管理，開發者可以限制用於內部推理的令牌數量，從而在準確性和延遲之間取得平衡。這對於客户支持或自主代理等對響應速度有要求的應用場景尤為關鍵。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-5de1df85730cbf8d4cb29cda3ca17f92329.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達根據其開放模型許可協議發佈了 Nemotron-Nano-9B-V2，該協議對企業友好且高度寬鬆。英偉達明確表示，企業可以自由地將該模型用於商業用途，並且無需為使用該模型支付費用或版税。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管如此，協議仍有一些核心要求，例如用户必須遵守內置的安全機制、在重新分發模型時進行歸屬標註，並遵守相關法律法規。英偉達表示，該協議旨在確保負責任和合乎道德的使用，而不是通過限制商業規模來盈利。這使得 Nemotron-Nano-9B-V2 成為了那些希望在降低成本和延遲的同時，保持高精度的企業開發者的理想選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367083</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367083</guid>
      <pubDate>Mon, 18 Aug 2025 02:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Qwen Chat 正式發佈 Windows 版桌面端應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊發佈了適用於 Windows 系統的 Qwen Chat 桌面版應用。&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://qwen.ai/download&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="734" src="https://static.oschina.net/uploads/space/2025/0818/192124_WWIt_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1038" src="https://static.oschina.net/uploads/space/2025/0818/192158_OMZi_2720166.png" width="1909" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows 版 Qwen Chat 桌面端集成了 Qwen Chat 的全部功能，並新增了對 MCP（Model Context Protocol）的支持，用户可以通過運行 MCP Servers 來提升工作效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367001</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367001</guid>
      <pubDate>Sun, 17 Aug 2025 11:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>openKylin 2.0 SP2 揭秘 - SDK V3.0 來襲，開發體驗大升級！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;OpenAtom openKylin（簡稱「openKylin」） SDK 是在 openKylin 開源操作系統上，為生態建設與軟件開發提供安全、可靠、快捷、穩定的開發者接口。相比於社區中其他的開發者套件或框架，openKylin SDK 更聚焦於解決 openKylin 操作系統的兼容、適配、移植、優化等方面的問題。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;openKylin 2.0 SP2 將搭載全新 openKylin SDK&amp;nbsp; V3.0 開發套件上線。此次 V3.0 版本對&lt;strong&gt;應用層、桌面層、系統層、基礎層&lt;/strong&gt;四大核心架構進行了更新升級，通過標準化接口設計、豐富的功能組件和完善的管控，為開發者提供更加統一的開發體驗。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2994ae1a35d2b884affe6225d5e24e2e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;strong&gt;&lt;span&gt;應用層升級：界面開發專業化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;1. 更統一的設計體驗&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;全面支持 Design Token 規範，讓開發者告別界面風格不統一的困擾。無論是按鈕、輸入框還是彈窗，都能保持一致的視覺風格，讓應用看起來更專業。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;2. 更豐富的控件選擇&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;精選了控制面板中最實用的 11 個控件直接集成，包括各種按鈕、輸入框、滑塊、開關等常用組件。這些控件都經過了系統級應用的長期驗證，拿來就能用，省去了重複造輪子的時間。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;3. 更靈活的標籤展示&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;klabel 控件現在支持三態顯示、輕量級樣式、固定佈局等多種模式，讓文本展示更加靈活。無論是狀態提示、信息展示還是標題顯示，都能找到合適的樣式。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;strong&gt;&lt;span&gt;桌面層升級：系統級交互能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;1. 更智能的快捷鍵管理：&lt;/strong&gt;&lt;br&gt; 提供完整的全局快捷鍵控制功能，包括快捷鍵衝突檢測、全局快捷鍵註冊和監聽等。這一特性對於提升用户操作效率具有重要意義，特別是對於需要頻繁操作的專業軟件。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;2. 更完善的主題控制：&lt;/strong&gt;&lt;br&gt; 新增系統主題管理接口，開發者可以輕鬆獲取系統主題列表、設置主題、獲取系統強調色，並實現主題深淺模式的智能切換。讓應用能夠完美融入系統環境，為用户提供個性化的使用體驗。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;3. 更便捷的應用管理：&lt;/strong&gt;&lt;br&gt; 提供全面的應用行為控制接口，包括獲取開機自啓動應用列表、查詢指定文件類型的默認打開應用、設置應用的開機自啓動狀態等功能，讓開發者能夠精確控制應用的啓動行為。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;strong&gt;&lt;span&gt;系統層升級：核心功能模塊化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;1. 更完善的數據處理：&lt;/strong&gt;&lt;br&gt; 集成高效的數據壓縮解壓模塊，全面支持 zip、gzip、xz、lz4 等主流壓縮算法，為應用數據存儲和網絡傳輸提供性能優秀，低存儲成本和傳輸延時的解決方案。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;2. 更豐富的設備管理：&lt;/strong&gt;&lt;br&gt; 全新設備管理模塊實現硬件設備信息的獲取與統一管理，適用於系統工具類應用開發。即插即用設備監控功能能夠實時響應硬件插拔事件，配合強大的磁盤管理模塊，為系統級應用提供豐富的硬件控制能力。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;3. 更可靠的系統控制：&lt;/strong&gt;&lt;br&gt; 提供可靠的系統電源管理方案，支持安全關機、重啓控制，集成任務監控和定時執行功能，確保開發者能夠在各種場景下安全執行系統級操作，保障系統穩定性。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;4. 更標準的網絡處理：&lt;/strong&gt;&lt;br&gt; 構建統一的 URI 處理標準接口，涵蓋 URI 格式驗證、智能解析、參數提取、資源下載等核心功能，讓網絡操作開發更加規範化和高效化，大幅提升開發效率。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;5. 更簡單的多媒體支持：&lt;/strong&gt;&lt;br&gt; 完善的音頻模塊接口設計，支持默認輸入輸出設備管理、聲卡設備枚舉等功能，讓多媒體應用開發更加便捷，開發者可以專注於業務邏輯實現而非底層音頻處理。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;6. 更精準的性能監控：&lt;/strong&gt;&lt;br&gt; 集成實時性能監控模塊，提供系統關鍵指標的持續監測能力，為應用性能優化提供精確數據支撐，幫助開發者構建高性能、高可用的應用系統。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;7. 更完善的國際支持：&lt;/strong&gt;&lt;br&gt; 提供完整的多語言環境支持，包括系統語言列表獲取、語言區域匹配驗證等功能，確保應用在全球化部署中的本土化適配能力，為應用的國際化提供堅實技術基礎。&lt;br&gt; &lt;strong&gt;8. 更熟悉的開發體驗：&lt;/strong&gt;&lt;br&gt; 借鑑 Win32 API 成熟的設計理念，為 Linux 平台開發者打造熟悉的開發環境，有效降低跨平台開發門檻。具備 Windows 開發經驗的開發者能夠快速遷移，顯著縮短學習成本。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;strong&gt;&lt;span&gt;基礎層升級：底層能力標準化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;1. 更全面的系統屬性完善的系統屬性模塊提供統一的 API 接口，實現系統配置信息的便捷獲取與設置，讓應用能夠智能適配不同系統環境，為跨平台兼容性和系統集成提供強有力的技術支撐。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;如何輕鬆上手使用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;在 openKylin 系統上安裝&lt;br&gt; 只需一條命令：&lt;br&gt; $ sudo apt-get install libkysdk-base-dev libkysdk-system-dev libkysdk-desktop-dev libkysdk-applications-dev&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;在其他 Linux 系統上安裝&lt;br&gt; 添加軟件源：&lt;br&gt; deb http://archive.build.openkylin.top/openkylin/ nile main cross pty&lt;br&gt; 更新並安裝：&lt;br&gt; $ sudo apt update&lt;br&gt; $ sudo apt-get install libkysdk-base-dev libkysdk-system-dev libkysdk-desktop-dev libkysdk-applications-dev&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;strong&gt;學習資源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;詳細教程點擊查看&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.openkylin.top%2Fzh%2F04_%25E7%25A4%25BE%25E5%258C%25BA%25E8%25B4%25A1%25E7%258C%25AE%2F%25E5%25BC%2580%25E5%258F%2591%25E6%258C%2587%25E5%258D%2597%2FopenKylin%2BSDK%25E5%25BC%2580%25E5%258F%2591%25E6%258C%2587%25E5%258D%2597" target="_blank"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;openKylin SDK 開發指南&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367000</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367000</guid>
      <pubDate>Sun, 17 Aug 2025 11:16:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Cursor 命令行工具 Cursor CLI 集成 MCP 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cursor 命令行工具 Cursor CLI 近日發佈更新，帶來了多項實用功能，進一步提升了終端開發的體驗和效率&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;@符號引用&lt;/strong&gt;：現在你可以直接在提示詞中使用 @ 符號來引用文件和目錄，AI 可以精準地定位上下文，這對於大型項目和複雜的文件操作尤其有用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;審查模式 (Review Mode)&lt;/strong&gt;:通過 Ctrl+R 快捷鍵，可以進入一個可視化的審查界面，清晰地查看 AI 對代碼的修改。這讓代碼審查變得前所未有的直觀和高效。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;/compress 命令&lt;/strong&gt;：這個新命令可以一鍵釋放上下文窗口的空間，優化長對話中的性能和相關性，確保 AI 始終能聚焦在最重要的信息上。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCPs 支持&lt;/strong&gt;：現在 CLI 也支持 MCPs，這意味着你可以利用更豐富的擴展能力來完成複雜任務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="982" src="https://static.oschina.net/uploads/space/2025/0818/190643_waza_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次更新還對用户體驗和性能做了一些改進，例如現在顯示 Token 計數，支持 AGENTS.md 和 CLAUDE.md（為了兼容 Claude Code）文件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-de60b8ab05a32ba9549f7fa100f6895787d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;https://cursor.com/cn/cli&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366998</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366998</guid>
      <pubDate>Sun, 17 Aug 2025 11:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程獨角獸 Cognition 獲近 5 億美元新融資，估值達 98 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fcognition-cinches-about-500-million-to-advance-ai-code-generation-business-f65f71a9" target="_blank"&gt;據報道&lt;/a&gt;，AI 編程獨角獸 Cognition 在新一輪融資中獲得了近 5 億美元，使其估值達到 98 億美元。&lt;/p&gt; 
&lt;p&gt;Cognition 成立於 2023 年，由三位國際信息學奧林匹克（IOI）金牌得主 Scott Wu、Steven Hao 和 Walden Yan 聯合創立。&lt;/p&gt; 
&lt;p&gt;Cognition 的核心產品是被稱為首個能自主編程的&lt;a href="https://www.oschina.net/news/282895/cognition-labs-devin" target="_blank"&gt;「AI 程序員」Devin&lt;/a&gt;。今年 7 月，&lt;a href="https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf" target="_blank"&gt;Cognition 收購了 Windsurf&lt;/a&gt;。在本次最新融資之前，Cognition 已籌集了 3 億美元，投資者包括 8VC、Avenir Growth Capital 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-63fe0533116cdf85964e331427c9d8b851b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;被收購的 Windsurf 截至今年 7 月的年收入已達到 8200 萬美元，擁有超過 350 家企業客户和數十萬日活躍用户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366994</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366994</guid>
      <pubDate>Sun, 17 Aug 2025 11:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手高級副總裁蓋坤兼任可靈 AI 技術部負責人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手宣佈高級副總裁蓋坤兼任可靈 AI 技術部負責人，繼續向 CEO 程一笑彙報，進一步強化可靈 AI 在快手戰略中的地位。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/183846_pqqc_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，蓋坤自 2020 年加入快手後，主導推薦算法、視頻生成大模型等技術研發，並推動可靈 AI 成為全球首個對標 Sora 的開放視頻生成模型。此次兼任技術負責人，體現快手對可靈 AI 「技術驅動」 戰略的重視。&lt;/p&gt; 
&lt;p&gt;公開信息顯示，蓋坤本科與博士均畢業於清華大學，研究方向為識別與智能系統。2020 年，蓋坤正式加入快手，主導內容理解應用、推薦大模型及視頻生成大模型的技術佈局，推動算法、應用與商業模式的協同創新。2024 年 6 月，蓋坤帶領團隊研發推出全球首個用户可用的 DiT 視頻生成模型 —— 可靈 AI 。&lt;/p&gt; 
&lt;p&gt;內部人士分析，蓋坤深耕算法技術多年，作為可靈 AI 團隊的靈魂人物，此次兼任可靈 AI 技術負責人，顯現出可靈 AI 在快手大模型整體戰略中的重要地位，也意味着 「技術驅動」 戰略，將在很長一段時間內主導着可靈 AI 的發展。&lt;/p&gt; 
&lt;p&gt;自上線以來，可靈 AI 已迭代升級 30 餘次，在全球擁有超過 4500 萬用户，累計生成超 2 億個視頻和 4 億張圖片，服務超過 2 萬家企業客户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366988</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366988</guid>
      <pubDate>Sun, 17 Aug 2025 10:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 技術被濫用成「退款神器」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;據央視新聞報道，近期，電商平台出現一種新型惡意退款行為:部分買家利用人工智能工具偽造商品損壞圖片，申請「僅退款」，導致商家遭受貨款和運費的雙重損失。這一現象引起廣泛關注，揭示了 AI 技術被濫用所帶來的新挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;商家們在社交平台吐槽，買家利用 AI 將完好無損的商品，如衣物、杯子或玩具，通過「偽毀損」處理，使其在圖片上呈現出碎裂或有瑕疵的狀態。這些偽造的圖片逼真，讓商家難辨真偽。更令人沮喪的是，即使商家察覺到是假圖，部分電商平台的自動審核機制仍可能通過退款申請，使得商家在沒有收回商品的情況下，被迫退還貨款。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="300" src="https://oscimg.oschina.net/oscnet/up-6f9ecd233181d9dac72df712c5ff273ef4b.png" width="186" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;針對這種行為，法律專家指出，利用 AI 偽造圖片騙取退款的行為已涉嫌違法。這不僅違背了《民法典》中的誠實信用原則，構成民事欺詐，還可能觸犯《治安管理處罰法》。如果騙取金額達到或超過 3000 元，甚至可能構成《刑法》規定的詐騙罪。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;面對這一挑戰，專業人士呼籲監管部門、電商平台和商家採取多方面措施共同應對。&lt;span&gt;監管部門應完善法律法規，在《電子商務法》中增設保護商家權益的條款，並明確惡意退款行為的法律後果。同時，強制推行 AI 生成內容標識，並對刪除或篡改標識的行為進行處罰。此外，建議建立跨平台的用户消費信用機制，將惡意行為納入個人徵信，從根本上限制其線上活動。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;電商平台需要強化審核機制，減少對 AI 客服的依賴，增加人工審核投入，並延長審查時間，給商家提供充足的舉證機會。技術方面，平台應加大投入，利用技術手段驗證圖片與實物的匹配性，從源頭攔截偽造內容。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;商家也需積極自保，優化售後流程，要求買家提供清晰、完整的退款證據，並通過對打包發貨全過程錄像等方式，留存商品質量證據。若發現惡意行為，應及時向平台反映，情節嚴重時可直接向公安機關報案，維護自身合法權益。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 技術的初衷是提質增效，但當它被用於不法目的時，對商業生態的破壞力不容小覷。只有多方聯動，才能有效遏制這種新型網絡欺詐，重建消費者與商家之間的信任。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366985</guid>
      <pubDate>Sun, 17 Aug 2025 10:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元 3D 世界模型推出 Lite 版本，支持消費級顯卡部署</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元 3D 世界模型 1.0 於 7 月發佈並開源，據稱是業界首個開源併兼容傳統 CG 管線的可漫遊世界生成模型。&lt;/p&gt; 
&lt;p&gt;為了讓更多開發者能便捷部署使用混元 3D 世界模型，混元團隊近日全新推出 Lite 版本，大幅降低運行顯存開銷，支持消費級顯卡部署。&lt;/p&gt; 
&lt;p&gt;官網地址：https://3d.hunyuan.tencent.com/sceneTo3DGithub&lt;br&gt; 項目地址：https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0&lt;br&gt; Hugging Face 模型地址：https://huggingface.co/tencent/HunyuanWorld-1&lt;br&gt; 技術報告地址：https://arxiv.org/abs/2507.21809&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/175917_MwWM_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了實現對消費級硬件的兼容，該模型採用了多項關鍵技術優化。首先，通過動態 FP8 量化技術，模型的顯存（VRAM）需求從 26GB 降低至 17GB 以下，降幅達 35%，使其能夠在消費級 GPU 上流暢運行而不犧牲性能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366980</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366980</guid>
      <pubDate>Sun, 17 Aug 2025 09:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>科學島團隊提出醫療大模型智能體決策框架 FRAME</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;近日，中國科學院合肥物質院智能所丁增輝研究員聯合華南理工大學靳戰鵬教授團隊，提出一種醫療大模型智能體決策框架 FRAME。相關研究工作「FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights」被第 63 屆國際計算語言學年會錄用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;探尋新的醫療洞見和決策方法是輔助醫學研究的前沿熱點，大語言模型（LLM）的快速發展為該領域研究提供了重大機遇，但在知識整合與質量保證方面仍面臨嚴峻挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研究團隊提出的 FRAME (Feedback-Refined Agent Methodology) 框架，旨在通過迭代式優化和結構化反饋來提升醫學洞見性能。該方法包含三大核心創新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;一是構建結構化數據集：通過迭代優化，將醫學文獻分解為核心研究要素，構建精細化數據集；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;二是搭建「生成-評估-反思」三方智能體架構：集成了生成（Generator）、評估（Evaluator）和反思（Reflector）智能體，通過指標驅動的反饋循環，逐步提升內容質量；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;三是形成綜合評估體系：結合了統計學指標與人工基準，對生成內容進行全方位評測。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="235" src="https://oscimg.oschina.net/oscnet/up-c4c2ee2c274c4fc91ddacb0f45d89761419.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對比實驗結果顯示，相較於傳統方法，FRAME 框架在運用多種大語言模型提升醫學洞見性能方面效果顯著，在 DeepSeek V3 上平均提升 9.91%，在 GPT-4o Mini 上也取得了同等級別的改進。同時，人工評估也證實了利用 FRAME 智能生成的醫療決策質量已能媲美人類水平，尤其在凝練未來研究方向方面表現突出。相關研究成果表明，所構建的 FRAME 框架，能夠自動生成高標準的醫學研究方案，高效輔助醫學研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="148" src="https://oscimg.oschina.net/oscnet/up-23eebf4bcebc7f140ee46b4658956f09096.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366974</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366974</guid>
      <pubDate>Sun, 17 Aug 2025 09:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 SSH 客户端 PuTTY 啓用新的官方域名：putty.software</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源 SSH 客户端 PuTTY 已正式啓用新的官方域名：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;https://putty.software/&amp;nbsp;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0818/173129_GuRm_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原來的域名為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;https://www.chiark.greenend.org.uk/~sgtatham/putty/&amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;長期以來，由於 PuTTY 的原始官方網址 (www.chiark.greenend.org.uk/~sgtatham/putty/) 較為冗長且不易記憶，許多用户、教程甚至搜索引擎都誤將 putty.org 視作官方網站。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;該域名自 2008 年起就被另一家 SSH 廠商 Bitvise 持有，僅作為導航頁使用&lt;/span&gt;，提供指向官方 PuTTY 和 Bitvise 自身產品的鏈接。近期，一位博主就域名所有權問題向 Bitvise 發出問詢，被 Bitvise 聯合創始人視為挑釁，後者進而從 putty.org 撤下了原有的軟件鏈接，替換為與新冠病毒和疫苗相關的陰謀論視頻，&lt;span&gt;並在部分搜索引擎結果中超越 PuTTY 真正的官網。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/173548_kxoQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前，PuTTY 開發者曾經在官網 FAQ 中自信表示，用户不會找錯 PuTTY 官方地址，因為 Google 搜索 PuTTY 給出的第一個結果就是正確官網；但事實表明並非如此。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;由於大量用户可能被誤導至第三方站點，帶來安全風險。為避免混淆並保障用户下載安全，PuTTY 開發團隊於 8 月 14 日正式註冊並啓用簡短、可控的新域名 putty.software 作為官方入口。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;官方強調，新域名由開發團隊運營，不會用於推廣無關的商業軟件或意外更改內容。&lt;/p&gt; 
&lt;p&gt;目前，該網址只提供了指向舊站的鏈接；團隊計劃在未來將主站遷移至此，但會設置過渡期，以避免用户誤認為項目被黑客攻擊或接管。&lt;/p&gt; 
&lt;p&gt;www.chiark.greenend.org.uk/~sgtatham/putty/faq.html#faq-domain&lt;br&gt; www.chiark.greenend.org.uk/~sgtatham/putty/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366972</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366972</guid>
      <pubDate>Sun, 17 Aug 2025 09:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>金標聯盟發佈隱私權限體系，共建安卓生態安全體驗</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;8 月 15 日，2025 移動智能終端生態聯盟開發者沙龍在上海舉辦，泰爾終端實驗室與谷歌專家代表應邀出席。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;會上，金標聯盟成員 OPPO、vivo、小米、榮耀聯合發佈了全新隱私權限體系，以「權限授信審批 + 高敏權限數據化」為核心，覆蓋 19 類敏感權限訪問場景，這一舉措標誌着安卓生態在隱私保護領域邁出標準化的關鍵一步，用户隱私安全體驗將進入更透明、可控的新階段。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;行業共識：隱私保護需標準先行，生態協同&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;隨着《個人信息保護法》深入實施，APP 隱私治理已取得積極成效，但用户權益保護仍面臨隱蔽性強、複雜度高等多重挑戰，用户權益保護工作需要長期堅持、體系化推進。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;中國信息通信研究院泰爾終端實驗室在會上指出，APP 隱私治理需突破 「告知同意」 的形式化困局，從終端接口統一、應用適配執行到商店審核校驗，構建全鏈條標準化路徑。未來，泰爾將通過 「標準先行 + 技術創新 + 產業協同」 模式全面推進，保護用户隱私安全，共築移動互聯網產業個人信息保護新業態。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;谷歌專家也鼓勵終端廠商、開發者與平台方攜手構建「更私密、更可信、更高效」的數據訪問機制，共同推動生態長期健康發展。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0ce372297291a75ec20f8b3dd685e9f1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;四家廠商聯合發力：統一標準，雙向賦能&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;此次發佈的隱私權限體系，通過 Picker 等系統級安全控件，為聯繫人、相冊等 5 類高敏隱私數據提供安全訪問能力，只有用户主動選擇進行分享，應用才可以讀取---也就是從技術層將「最小必要」原則落地。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;同時，該體系搭建了統一權限審核平台，協助用户提前針對 19 類常用權限申請進行合理性評估，也為開發者提供用户數據使用的參考標準。更關鍵的是，該平台實現「一次接入、四端通用」，有效降低開發者合規成本與適配難度，推動隱私安全保護向更高的行業標準演進。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e4f461b7f53eb80ffad74e1afd0e6b1d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;生態共建不止步：從權限保護到系統級協同&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;業內專家認為，此次隱私權限體系的發佈，是安卓生態在用户隱私保護方面的重要里程碑，安卓陣營正以「統一標準、生態共建」的方式提升生態競爭力，與開發者共同攜手提供更加全面可靠的隱私保護服務。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;值得關注的是，在金標聯盟框架下，OPPO、vivo、小米、榮耀已同步推進統一消息推送服務，從系統底層保障數據傳輸的穩定性與安全性，構建從「權限體系」到「系統通信」的生態共建新框架，為開發者與用户創造更安全、高效的生態環境。&lt;/p&gt; 
&lt;p style="color:#444444; margin-left:0; margin-right:0; text-align:left"&gt;據悉，更多關於隱私權限體系以及消息推送服務的技術細節，將在各廠商開發者大會上對外公佈。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366968</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366968</guid>
      <pubDate>Sun, 17 Aug 2025 09:17:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
    <item>
      <title>百度發佈全球首個全端通用智能體 GenFlow2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在百度 AI Day 開放日上，百度文庫聯合百度網盤重磅發佈全球首個全端通用智能體 GenFlow2.0。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="436" src="https://oscimg.oschina.net/oscnet/up-cd7cdee6f0ccde961cd3be40f21eebea22c.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;據官方介紹，GenFlow2.0 展現出強大的並行處理能力，支持超 100 個專家智能體同時協作，能夠在 3 分鐘內並行完成超 5 項複雜任務。該產品的生成速度超越主流同類型產品 10 倍，在行業內率先實現了分鐘級交付的突破性表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;GenFlow2.0 的核心優勢體現在三個方面:分鐘級交付確保用户快速獲得結果，過程可幹預讓用户能夠實時調整和優化，記憶可追溯則為用户提供完整的操作歷史記錄，大幅提升了智能體的可控性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得關注的是，GenFlow2.0 目前已在百度文庫 Web 端和 APP 端正式上線，採用開放策略，所有用户均可直接使用，無需排隊等待或申請邀請碼。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366967</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366967</guid>
      <pubDate>Sun, 17 Aug 2025 09:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>PixiEditor - 2D 圖形編輯器</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;strong style="color:#1f2328"&gt;PixiEditor&lt;/strong&gt;是一款通用的 2D 編輯器，旨在為你提供滿足所有 2D 需求的工具和功能。你可以為遊戲創建精美的精靈圖、動畫，編輯圖像，甚至創建徽標。所有功能都集中在一個直觀熟悉的界面中。&lt;/p&gt;

&lt;p&gt;&lt;img height="287" src="https://static.oschina.net/uploads/space/2025/0818/144457_cdjW_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;PixiEditor 2.0 默認配備 3 個工具集：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Pixel art&amp;nbsp;&lt;/strong&gt;- 它包含適合像素完美場景的工具&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Painting&amp;nbsp;&lt;/strong&gt;-&amp;nbsp;基本繪畫工具、軟刷、抗鋸齒形狀&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector&amp;nbsp;&lt;/strong&gt;- 用於創建 vectors 的形狀和路徑&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所有&lt;strong&gt;工具集均可在一張畫布上使用&lt;/strong&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;vector 與 raster&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;混合。導出為 png、jpg、svg、gif、mp4 等格式！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="300" src="https://static.oschina.net/uploads/space/2025/0818/144519_Vpuk_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="90" src="https://static.oschina.net/uploads/space/2025/0818/144552_suFz_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="133" src="https://static.oschina.net/uploads/space/2025/0818/144605_5Qoa_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/pixieditor</link>
      <guid isPermaLink="false">https://www.oschina.net/p/pixieditor</guid>
      <pubDate>Sun, 17 Aug 2025 09:00:00 GMT</pubDate>
    </item>
    <item>
      <title>騰訊開源 WeChat-YATT：微信強化學習大模型訓練庫</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;基於 Megatron&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Core&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;和&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;SGLang&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;LLM&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;研&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;發了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;訓練&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;庫&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;WeChat-YATT&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;（&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;Y&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;A&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;,&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;Yet Another Transformer Trainer&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;內部&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;項目&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;為&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;gCore&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，專注於強化學習和多模態模型的訓練&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;旨在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;易&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;擴&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;展&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;簡潔&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;效&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;可靠&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;訓練能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;通過定製化的並行計算策略，其&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;訓練庫&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;能夠處理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大尺寸&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、長序列&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;輸入&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;和大數據集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;解決&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;微信&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;多個&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;實際&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;痛點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;問題&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;顯著&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;提升&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;業務&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;訓練&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;效率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;此工具為研究人員和開發者提供了靈活且可擴展的解決方案，以推動多模態和強化學習領域的創新發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;並提出 WeChat-YATT&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;訓練庫&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，解決了大模型分佈式訓練過程中面臨的兩大核心痛點：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;多模態場景下的可擴展性瓶頸&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;隨着多模態數據（如圖像、視頻）規模的不斷增長，傳統架構中由&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Single&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;l&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;l&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;e&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;r&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;進行數據管理，容易成為通訊和內存的瓶頸，導致系統吞吐量受限，甚至引發訓練流程異常中斷。WeChat-YATT 通過引入&amp;nbsp;&lt;/span&gt;&lt;strong&gt;Parallel Controller&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的並行管理機制，有效分散壓力，大幅提升系統的可擴展性和穩定性，更好地應對多模態、大數據量的複雜場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;動態採樣&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;與&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;生成式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;獎勵&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;下的效率短板&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在需頻繁動態採樣或生成式獎勵計算的訓練流程中，模型頻繁切換和「長尾」任務容易引發大量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;額外&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;開銷&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，導致&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;無法&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;充分&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;利用 GPU&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;算力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，影響整體訓練效率。WeChat-YATT 通過&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;部&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;分&lt;/span&gt;&lt;strong&gt;共存策略&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;和&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;異步交互&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大幅度&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;減輕模型切換損耗和長尾任務影響，實現了訓練過程中的高吞吐量和高資源利用，更好地支撐大規模 RLHF 任務的高效迭代。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="234" src="https://oscimg.oschina.net/oscnet/up-79500ef9514ee7d1d3ed000a5d0b1ebe0a2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;WeChat-YATT 針對不同業務場景，支持了兩種資源放置模式：全員共存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;與&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;部分共存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，以最大化提升集羣的資源利用率。通過靈活的調度策略，WeChat-YATT 能夠有效適應不同的訓練需求和計算環境。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;與此同時，WeChat-YATT 採用了 Parallel Controller 模式，由多個 Controller 協同管理數據任務，顯著降低了單節點的內存壓力，尤其為多模態訓練場景提供了更優的系統支持，相較於傳統的 Single Controller 架構具備更強的可靠性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;全員共存模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;採用串行調度機制，Actor Rollouts&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;GenRM&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;(&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Generative Reward Model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;)&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;與&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Train&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;依次串&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;行執行。每個角色完成任務後主動釋放計算資源，系統加載下一個任務所需模型。該策略適配絕大多數常規訓練場景。值得一提的是，在每個階段，相關組件均可獨佔全部 GPU 資源，這極大縮短了資源空閒「氣泡」時間，顯著提升總體訓練吞吐量和效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;部分共存模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;下，Actor Rollouts 與&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;G&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;e&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;獨立部署，並通過異步方式進行高效交互。Actor 訓練階段會佔用全部 GPU 資源，在 Rollouts 生成階段，Actor 將 GPU 資源釋放並喚醒 Actor Rollouts 及 GenRM 兩大組件協同工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;並&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;通過&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;動態的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;負載&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;評估&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;進行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;資源&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;分配&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;與&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;均衡&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;當 Rollouts 生成完畢，這兩者會釋放資源，Actor 隨之加載到 GPU 上，進入下一輪訓練流程。部分共存模式非常適合 Rollouts 與 GenRM 需要高頻交互、動態採樣的任務場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;多元的資源放置模式和靈活的調度機制，使 WeChat-YATT 在複雜多變的實際環境下都能實現資源的高效利用，助力大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;微信&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;內部&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;多個&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;應用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;落地&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;項目特點：&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;高效內存利用&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;項目採用 Parallel Controller，有效降低了單節點的內存消耗，更適合多模態場景下的大模型訓練，提升了系統的擴展性和穩定性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;GenRM&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;高效&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;支持&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;對於&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;GenRM&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;實現了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;不同&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;資源&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;放置&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;策略&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;供&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;使用者&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;根據&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;場景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;進行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;高效&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;訓練&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;智能 Checkpoint 策略&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;WeChat-YATT 支持異步 Checkpoint 保存，並針對微信業務場景，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;根據&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;調度流程，實現斷點自動保存，進一步保障訓練安全與高可用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;負載均衡優化&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;在訓練過程中，WeChat-YATT 實現了各個數據並行組間的負載均衡，有效減少資源空閒時間，顯著提升整體訓練吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;&amp;nbsp;實驗效果&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-d73534824171f90151065e04a956b3846ca.png" width="355" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-19fa6c294016bfea7f90b3d533f3f0899e8.png" width="264" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366962</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366962</guid>
      <pubDate>Sun, 17 Aug 2025 08:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
