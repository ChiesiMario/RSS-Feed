<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 22 Jul 2025 02:43:18 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Qwen3 旗艦版更新：Qwen3-235B-A22B-Instruct-2507-FP8</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;阿里通義千問宣佈更新旗艦版 Qwen3 模型，推出 Qwen3-235B-A22B-FP8 非思考模式（Non-thinking）的更新版本，命名為 Qwen3-235B-A22B-Instruct-2507-FP8。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;具體來説，&lt;strong&gt;Qwen3-235B-A22B-Instruct-2507-FP8&amp;nbsp;&lt;/strong&gt;具有以下主要增強功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;一般能力&lt;strong&gt;有顯著提高，包括&lt;/strong&gt;&lt;strong&gt;遵循指令、邏輯推理、文本理解、數學、科學、編碼和工具使用&lt;/strong&gt;。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;跨多種語言的&lt;/strong&gt;長尾知識覆蓋率&lt;strong&gt;大幅提升&lt;/strong&gt;。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;在主觀和開放式任務中&lt;/strong&gt;&lt;strong&gt;明顯更好地&lt;/strong&gt;與用户偏好保持一致，從而能夠獲得更多有用的回應和更高質量的文本生成。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;大幅提升了長文本處理的能力，擴展到 256K 的文本長度。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-7c06d16beba0ad60c33410d15d6158ad917.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;性能&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="1021" src="https://static.oschina.net/uploads/space/2025/0722/104117_dP2t_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;為了達到最佳性能，阿里官方建議採用以下設置：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;採樣參數：&lt;/span&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style="color:#000000"&gt;建議使用&lt;code&gt;Temperature=0.7&lt;/code&gt;,&amp;nbsp;&lt;code&gt;TopP=0.8&lt;/code&gt;,&amp;nbsp;&lt;code&gt;TopK=20&lt;/code&gt;和&lt;code&gt;MinP=0&lt;/code&gt;&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style="color:#000000"&gt;對於支持的框架，可以在 0 到 2 之間調整&lt;code&gt;presence_penalty&lt;/code&gt; 參數，以減少無休止的重複。不過，使用較高的值偶爾可能會導致語言混合和模型性能的輕微下降。&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;足夠的輸出長度：建議對於大多數查詢使用 16,384 個 token 的輸出長度，這對於指導模型來説已經足夠了。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;標準化輸出格式：建議在基準測試時使用提示來標準化模型輸出。&lt;/span&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style="color:#000000"&gt;數學問題：在提示詞中包含「Please reason step by step, and put your final answer within \boxed{}.」。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style="color:#000000"&gt;多項選擇題：在提示詞中添加以下 JSON 結構以標準化響應：「Please show your choice in the&amp;nbsp;&lt;code&gt;answer&lt;/code&gt;&amp;nbsp;field with only the choice letter, e.g.,&amp;nbsp;&lt;code&gt;"answer": "C"&lt;/code&gt;.」&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361625</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361625</guid>
      <pubDate>Tue, 22 Jul 2025 02:36:15 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>鴻蒙 NEXT 開發案例：世界時間表</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361623</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361623</guid>
      <pubDate>Tue, 22 Jul 2025 02:33:15 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>鴻蒙 NEXT 實戰：構建安全高效的在線支付應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361621</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361621</guid>
      <pubDate>Tue, 22 Jul 2025 02:29:15 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>經濟學家警告：AI 泡沫或將比互聯網泡沫更嚴重</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;經濟學家託爾斯滕・斯洛克（Torsten Slok）發近日出警告，稱當前的人工智能（AI）泡沫可能比上世紀 90 年代末的互聯網泡沫更為嚴重。斯洛克是阿波羅全球管理公司的首席經濟學家，他在一份廣泛傳播的報告中指出，當前標準普爾 500 指數（S&amp;amp;P500）&lt;span&gt;前十&lt;/span&gt;名公司的估值顯著高於 1990 年代的水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="376" src="https://oscimg.oschina.net/oscnet/up-1e2c52de0779e855d42924bc124be66222f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;斯洛克提到，當前標準普爾 500 指數&lt;span&gt;前十&lt;/span&gt;名公司的市盈率（P/E）不斷攀升，已經超越了 1990 年代的記錄。市盈率通常被視為一種衡量股票價格相對於公司盈利水平的指標，較高的市盈率意味着股票價格&lt;span&gt;極高&lt;/span&gt;。&lt;span&gt;最新&lt;/span&gt;數據顯示，這些公司的市盈率持續上升，而它們的盈利水平卻並未同步增長，市場的熱情似乎正在脱離理性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;科技巨頭們對 AI 的熱情不斷推動市場，尤其是 AI 芯片製造商英偉達在標準普爾 500 指數中的表現尤為突出，緊隨其後的是微軟、蘋果、亞馬遜、Meta 和谷歌等公司。雖然這些公司在 AI 基礎設施上的投入高達數十億美元，但它們的收益依舊無法與這些支出相匹配，市場的高估值令人擔憂。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;與此相似，AI 批評人士艾德・齊特龍（Ed Zitron）也將當前的 AI 熱潮比作 2007 年的次貸危機，這一危機導致了美國房地產市場的崩潰。硅谷對 AI 的持續追逐在今年初遭遇考驗，當時一家名為 DeepSeek 的中國 AI 公司展示了其 AI 聊天機器人在訓練過程中所需的計算能力遠低於其他大型語言模型的競爭者，這引發了超過 1 萬億美元的市場拋售。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;雖然 AI 工具如 ChatGPT 和谷歌的 Gemini 在 2023 年獲得了極大的關注，但其收入與數十億美元的基礎設施投資相比依然微不足道。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據標準普爾全球研究的一份報告，預計到 2029 年，生成性 AI 市場的總收入將以驚人的速度增長，達到 850 億美元。然而，這一數字與 Meta 在 2023 年計劃投入的超過 600 億美元的資本支出相比，仍顯得微不足道。因此，科技公司需要向投資者證明，鉅額的 AI 投資終將帶來回報，而不會重蹈歷史上最嚴重的股市崩盤的覆轍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361618</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361618</guid>
      <pubDate>Tue, 22 Jul 2025 02:27:15 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手開源 AutoThink 大模型 KAT-V，40B 性能逼近 R1-0528</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;快手近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVQo5uRAJGGqhwlf7it1GlA" target="_blank"&gt;發佈&lt;/a&gt;並開源了 KAT-V1 自動思考（AutoThink）大模型，這是一款融合思考與非思考能力、並且可以根據問題難度自動切換思考形態的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，KAT-V1 模型共有 40B 和 200B 兩個版本。在自動思考模式下，40B 版本的性能可追平今年 5 月發佈的新版 DeepSeek-R1（參數量為 6850 億）。而 200B 版本的模型，則在多項基準測試中超過了 Qwen、DeepSeek 和 Llama 這三大開源模型家族中的旗艦模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="190" src="https://oscimg.oschina.net/oscnet/up-6d4181b792c7809e665692736de58f77f0f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 LiveCodeBench Pro 基準測試中，KAT-V1 也以 40B 的參數成功躋身於閉源模型之列，超越一眾思考/非思考的開源模型。目前，KAT-V1 模型家族的 40B 版本已開源上線。技術報告透露，200B 版本的 MoE 模型仍在訓練過程中。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="349" src="https://oscimg.oschina.net/oscnet/up-d43fbd44b3b2178e7de9ea8513a33d41d02.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;KAT-V1 模型由 Qwen2.5-32B 擴展而來，通過分層定向擴展的策略，將模型參數量有選擇地擴展到 40B，減少了無效的參數增長，實現規模與計算效率的平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 KAT-V1 模型的預訓練階段，Kwaipilot 團隊構造了大量的思考/非思考數據。對於非思考數據，為了保證問題的廣泛性，他們從預先收集的 5TB tokens 預訓練數據中，抽取出部分帶有推理特徵、具有一定難度的多領域數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="336" src="https://oscimg.oschina.net/oscnet/up-8292fd097c0e95bbd9e0232987356a422bd.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;思考數據則使用一個 Agentic 框架來合成。該框架由解答者（solver）、思考者（thinker）和評論者（critic）組成。解答者先提供初步答案，思考者對解決方案進行反思和迭代改進，評論者對整個流程進行監督，以保證邏輯一致性和輸出質量。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;這一框架可在一定程度上提升合成數據的質量——只有經過核驗的高質量合成數據才能被保留，並轉化為長思維鏈（long-CoT）數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;預訓練階段，Kwaipilot 團隊使用了大約 1000 萬個示例的語料，其中約 34.8% 的數據為思考數據，約 65.2% 的數據為非思考數據。這些數據涵蓋了科學、代碼、數學、工具調用和通用知識等廣泛領域，給模型的能力泛化提供基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Kwaipilot 團隊選擇通過模型蒸餾的方式完成模型的初始化冷啓動——先讓一個大型教師模型在輸入數據上輸出詳細的概率分佈，再讓較小的學生模型在相同輸入下產生預測，通過最小化兩者之間的差異，使學生模型學習教師模型的預測模式和知識。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;不過，KAT-V1 採用了獨特的異構蒸餾框架，能夠更高效地將教師模型的知識傳遞給學生模型。該框架由通用 Logits 蒸餾損失（ULD Loss）和多 Token 預測（MTP）兩大模塊組成。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="128" src="https://oscimg.oschina.net/oscnet/up-7fa488f4839e384c6958dc80eb6ce5cc4ab.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;整體上，這個設計大大提高了知識遷移的效率，讓小模型在冷啓動時用較少算力就能快速獲得較好的性能。Kwaipilot 團隊透露，他們以傳統方法 1/30 的成本，完成了模型的冷啓初始化。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Kwaipilot 團隊還提出了一種分佈式獎勵的強化學習算法：Step-SRPO。在 Step-SRPO 框架中，模型先進行「推理必要性評估」，判斷每個問題是否需要深入思考，以避免對簡單問題浪費計算資源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;隨後，通過雙重獎勵機制引導學習：判斷獎勵（Judge Reward）根據模型是否正確選擇推理模式打分，鼓勵準確判斷推理需求；答案獎勵（Answer Reward）依據最終回答的正確性和質量進行評分，並結合判斷獎勵進行調整，確保回答質量和推理選擇相一致。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="267" src="https://oscimg.oschina.net/oscnet/up-524071521d5090e62d5e49d6a0fccff2387.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;數據顯示，由於強化學習的獎勵策略，模型選擇思考模式的比例不斷降低。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="255" src="https://oscimg.oschina.net/oscnet/up-b218aecc2b7006d8c87e806732cc88b853a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;這種趨勢在測試集上的表現更為明顯，模型在多個測試集的平均 token 數下降了 20%-30%，其中複雜推理榜單 (例如 AIME 2025/2024、LCB、GPQA) 變化趨勢最小，但是相對簡易榜單的比例下降趨勢更為明顯。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="246" src="https://oscimg.oschina.net/oscnet/up-b899d2a35cff3183bd96fdbc70e220586cf.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Step-SRPO 讓模型在訓練中逐步學會既能保持高準確性，也能根據問題難度靈活調整推理深度，最終實現在模型性能上漲的前提下，還能進一步降低 token 的使用，提升了模型輸出 token 的思考密度以及對是否應該開啓思考模式判斷的智能程度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;強化學習訓練後，KAT-V1 40B 成功學會了自動在某些簡單問題上切換到非思考模式，模型性能在保持和 DeepSeek-R1-0528 接近的水位下，平均 token 消耗降低。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="222" src="https://oscimg.oschina.net/oscnet/up-83dfac1a38035b2f80be00105ef4ea09f8a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVQo5uRAJGGqhwlf7it1GlA" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361613</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361613</guid>
      <pubDate>Tue, 22 Jul 2025 02:17:15 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開發者的福音：Zadig 支持飛書單點登錄，告別 10+ 密碼記憶</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img height="798" src="https://oscimg.oschina.net/oscnet/up-f48276dfe9e43046c202f3ed7e26ac7d2d1.png" width="1876" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在當今數字化辦公浪潮中，飛書已成為眾多企業團隊協作的首選平台，其高效、便捷的溝通方式深受用户喜愛。然而，在開發領域，多系統多賬號的管理一直是讓開發者們頭疼不已的難題。為瞭解決這一問題，Zadig 正式宣佈支持飛書單點登錄（SSO），開發者可以通過飛書賬號直接登錄 Zadig，告別多賬號管理的煩惱，享受更高效、更安全的開發體驗。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;Zadig 與飛書集成的優勢&lt;/h1&gt; 
&lt;p&gt;通過將 Zadig 與飛書賬號系統集成，開發者可以享受以下優勢：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;單點登錄&lt;/strong&gt;：使用飛書賬號直接登錄 Zadig，無需額外創建和管理賬號，簡化登錄流程。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增強安全性&lt;/strong&gt;：飛書提供了多層次的安全認證機制，確保賬號和數據的安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;提高效率&lt;/strong&gt;：減少賬號管理的複雜性，讓開發者更專注於核心開發工作。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;統一身份管理&lt;/strong&gt;：企業可以通過飛書統一管理員工賬號，提升管理效率。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;集成步驟詳解&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;步驟 1：創建飛書應用&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;訪問飛書開放平台&lt;/strong&gt;：登錄飛書開放平台（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen.feishu.cn%2F" rel="nofollow" target="_blank"&gt;https://open.feishu.cn&lt;/a&gt;），創建一個新的「企業自建應用」。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="1520" src="https://oscimg.oschina.net/oscnet/up-34d308c170afcfb2c80044eae14f5ccab14.png" width="2950" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;開通權限：&lt;/strong&gt; 在權限管理中，配置以下權限項：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;contact:user.email:readonly&lt;/code&gt;：獲取用户郵箱信息。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;contact:user.phone:readonly&lt;/code&gt;：獲取用户手機號。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1520" src="https://oscimg.oschina.net/oscnet/up-5ac0e62a42aee4f74a6ffb079bfcebb032c.png" width="2950" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;獲取 App ID 和 App Secret&lt;/strong&gt;：在應用創建完成後，獲取應用的 App ID 和 App Secret，這些信息將用於後續的 Zadig 配置。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="1520" src="https://oscimg.oschina.net/oscnet/up-e7cb7cf5c7014a6eb3bd36750d439ffba19.png" width="2950" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;發佈飛書應用&lt;/strong&gt;：創建版本併發布飛書應用，確保應用處於可用狀態。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;步驟 2：配置 Zadig 賬號集成&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;訪問 Zadig 系統設置&lt;/strong&gt;：登錄 Zadig 系統，進入系統設置 -&amp;gt; 系統集成 -&amp;gt; 賬號系統，選擇「飛書」作為集成方式，將步驟 1 中獲取的 App ID 和 App Secret 填入相應的字段中。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="1520" src="https://oscimg.oschina.net/oscnet/up-092faa4c15cd36fee98bda679c6ea7dcd2f.png" width="2950" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;獲取 Callback 地址&lt;/strong&gt;：在 Zadig 配置頁面中，獲取 Callback 地址。這個地址將用於飛書開放平台中的回調配置。配置完成後，將飛書賬號系統設置為默認賬號系統。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="1514" src="https://oscimg.oschina.net/oscnet/up-2ead595169bddc697b1f2cf20debeb01280.png" width="2944" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1516" src="https://oscimg.oschina.net/oscnet/up-250680db4307ed77f8c12be4bc2e9892bb0.png" width="2956" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;配置飛書回調地址&lt;/strong&gt;：回到飛書開放平台，將 Zadig 提供的 Callback 地址配置到飛書應用的回調地址中。確保回調地址正確無誤，以便飛書能夠將認證信息正確傳遞迴 Zadig。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="1520" src="https://oscimg.oschina.net/oscnet/up-16c3f54b2860c2b28004f71ad1bdc459c5d.png" width="2950" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;使用飛書賬號登錄 Zadig&lt;/h1&gt; 
&lt;p&gt;配置完成後，訪問 Zadig，完成飛書賬號認證即可快速登錄 Zadig。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1516" src="https://oscimg.oschina.net/oscnet/up-f40ce579a4ecdb8caab3468708e65d5498c.png" width="2956" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;結語&lt;/h1&gt; 
&lt;p&gt;Zadig 與飛書的集成，為開發者提供了無縫的單點登錄體驗，簡化了多賬號管理的複雜性。未來，Zadig 將繼續擴展與主流企業工具的集成能力，幫助團隊更專注於核心業務，釋放更大的生產力。&lt;/p&gt; 
&lt;p style="color:#ff4c88; margin-left:0; margin-right:0; text-align:center"&gt;&lt;strong&gt;即日起，Zadig 新版發佈&lt;br&gt; 掃碼諮詢搶先體驗&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="943" src="https://oscimg.oschina.net/oscnet/up-0c7876673ed701ed97107bb53b607d661dd.png" width="1797" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank" rel="nofollow"&gt;Zadig 在 Github&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href="https://gitee.com/koderover/zadig" rel="nofollow"&gt;Zadig 在 Gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;&lt;span&gt;推薦閲讀：&lt;/span&gt;&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style="color:#002a64; margin-left:0; margin-right:0"&gt;&lt;a href="https://my.oschina.net/koderover/blog/17622087" target="_blank" rel="nofollow"&gt;Zadig：首個深度集成 DeepSeek 的 DevOps 平台&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href="https://my.oschina.net/koderover/blog/11210095" target="_blank" rel="nofollow"&gt;Zadig 官網博客正式發佈，技術乾貨實踐管飽&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href="https://my.oschina.net/koderover/blog/16492101" target="_blank" rel="nofollow"&gt;流水線早已 out 了？你需要更高效能的工作流&lt;/a&gt;&amp;nbsp;/&lt;span style="background-color:#ffffff; color:#002a64"&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://my.oschina.net/koderover/blog/10316143" target="_blank" rel="nofollow"&gt;Jenkins 遷移 Zadig，新項目實施上線效率提升 6 倍&lt;/a&gt;&amp;nbsp;/&lt;a href="https://my.oschina.net/koderover/blog/17644385" target="_blank" rel="nofollow"&gt;Zadig 辭舊迎新發布 V3.3，更好看更好用超穩定&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/koderover/blog/18043823</link>
      <guid isPermaLink="false">https://my.oschina.net/koderover/blog/18043823</guid>
      <pubDate>Tue, 22 Jul 2025 02:04:15 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Ubuntu 25.10 Raspberry Pi 鏡像將更加精簡</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;由於本週合併的變更，專為 Raspberry Pi 設計的&amp;nbsp;Ubuntu 25.10&amp;nbsp;鏡像將比目前 Raspberry Pi 的 Ubuntu Linux 版本精簡得多。針對 Raspberry Pi 單板計算機的 Ubuntu 桌面鏡像將基於「桌面最小化」種子，而非「完整」桌面鏡像。&lt;/p&gt; 
&lt;p&gt;將 Raspberry Pi 鏡像切換到 Ubuntu 桌面最小化基礎版本意味着一些應用程序（例如 GNOME 日曆、Deja Dup、File Roller、GNOME Snapshot、LibreOffice、Rhythmbox、Shotwell、Simple Scan、Thunderbird、Totem、Transmission 等）不再是開箱即用，目前可節省約 777MB 的空間。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-de495f01584405664da462dc9ec6c95da08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;當然，對於需要特定應用程序的用户，以後仍然可以從 Ubuntu 軟件包存檔中輕鬆安裝這些應用程序。一些桌面用户可能會懷念 LibreOffice 和 Thunderbird 之類的應用，而默認放棄 Simple Scan、Transmission BitTorrent 客户端和其他應用可以説是早就應該採取的舉措。&lt;/p&gt; 
&lt;p&gt;當前的 Ubuntu 25.04 樹莓派鏡像大小為 2.9GB，而 Ubuntu 24.04.2 LTS 樹莓派桌面鏡像大小為 2.6GB。Canonical 工程師 Dave Jones 在&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Ffoundations-team-updates-2025-07-17%2F64102%2F5" target="_blank"&gt;Ubuntu 基金會團隊筆記&lt;/a&gt;中詳細介紹了 Ubuntu 25.10 樹莓派鏡像的精簡行動。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361546</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361546</guid>
      <pubDate>Wed, 16 Jul 2025 11:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>KDE Plasma 的程序窗口終於有了圓潤的底部角</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;KDE 團隊為 Breeze 裝飾的窗口添加了圓角底角。這項視覺更新計劃在即將推出的 Plasma 6.5 中實現，是許多用户長期以來一直要求的功能，甚至早在 2021 年就已提交了正式提案。&lt;/p&gt; 
&lt;p&gt;它的正式發佈意味着社區開發的變通方案的需求將減少，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmatinlotfali%2FKDE-Rounded-Corners" target="_blank"&gt;KDE-Rounded-Corners&lt;/a&gt; 是一個流行的第三方腳本，多年來一直用於此目的。該功能將默認啓用，但對於喜歡經典尖角外觀的用户，它提供了一個選項。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-809176a99cd127ce5bb0db2bb95ecb32c1a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Plasma 6.5 的 UI 改進仍在進行中，KRunner 搜索結果排序的優化工作已開始進行。初步改進包括移除 KDE 應用和收藏夾的優先級提升，以減少搜索結果的隨機性。磁盤和設備小部件也變得更加靈活，現在允許在不運行錯誤檢查的情況下掛載磁盤，或者在不掛載磁盤的情況下運行錯誤檢查。&lt;/p&gt; 
&lt;p&gt;除此之外，Discover 和 System Monitor 等應用程序中的側邊欄現在可以調整大小，並且會記住您設置的寬度。天氣報告小部件現在會在計算機從長時間睡眠中喚醒後立即獲取新數據。&lt;/p&gt; 
&lt;p&gt;在修復 bug 方面，我們計劃修復鎖屏光標的 bug，使其在開啓 HDR 模式時能夠正確變暗。為了提升性能，Plasma 6.5 將降低 KWin 對顯示器 EDID 數據中色度信息的信任度，因為這些信息經常出現錯誤。&lt;/p&gt; 
&lt;p&gt;文件對話框窗口大小的數據現在存儲在狀態配置文件中而不是設置配置文件中，並且開發人員添加了更多自動測試來驗證 Plasma 的加載過程。&lt;/p&gt; 
&lt;p&gt;Plasma 6.4 的第四個錯誤修復版本 6.4.4 將於 8 月 5 日發佈。此更新預計將解決一系列問題，例如音量控制頁面在某些語言下無法正確調整大小、使用軟件渲染時應用程序崩潰以及系統設置中表單閃爍等問題。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361545</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361545</guid>
      <pubDate>Wed, 16 Jul 2025 11:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>讓代碼更可靠的小技巧：邊寫代碼邊證明它能正確運行</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;讓你的代碼更可靠？秘訣是在腦中「寫證明」！&lt;/p&gt; 
&lt;p&gt;有網友分享了一個寫代碼時的小技巧，引發了大量程序員的共鳴。這個技巧就是：&lt;strong&gt;邊寫代碼邊在腦中「證明」它會正確運行&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;這是一個技巧，但其實更像一種思維習慣：在寫每一行代碼的同時，不斷驗證它的邏輯是否自洽、是否會出錯。當這種思維方式練熟之後，很多人會驚喜地發現：自己的代碼常常一次就能跑通，甚至無需調試。&lt;/p&gt; 
&lt;p&gt;具體如何「證明」呢？Matthew 提供了五個實戰中常用的思路：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;單調性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;程序中的某些狀態一旦更新，就不該回退，比如「已完成的任務」「增長的日誌」等。想象某個狀態只能往一個方向變化，就能排除很多可能出錯的路徑。&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;前置條件 / 後置條件&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;明確函數「執行前必須成立」和「執行後必須成立」的條件，從而幫助你設計測試用例 &amp;amp; 寫斷言。如果某個函數的前/後置條件説不清楚，説明它本身就寫得不清楚，值得重構！&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;不變量&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;不變量是貫穿整個程序生命週期必須保持不變的條件。把程序拆成小步驟，每一步都必須守住這個不變量，整體自然可靠。&lt;/p&gt; 
&lt;p&gt;當你發現系統變得詭異或時好時壞時，往往是某個關鍵不變量被偷偷破壞了。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;隔離變化&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;代碼的每一次改動，都有一個「爆炸半徑」。理想情況下，變化應儘量侷限在本模塊內部，而不是牽一髮而動全身。&lt;/p&gt; 
&lt;p&gt;可以利用模塊邊界或接口作為防火牆，貫徹「開閉原則」：加功能是加代碼，而不是改舊代碼。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;歸納法&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;當你面對遞歸結構（比如樹、列表）或寫遞歸函數時，用數學歸納思維最自然。先證明最簡單情況是正確的。再假設子結構已經正確，然後證明更大結構也正確。&lt;/p&gt; 
&lt;p&gt;作者在文章最後一段拋出了一個核心概念：Proof-affinity，直譯是「可證明性」。&lt;/p&gt; 
&lt;p&gt;簡單來説就是，你寫的代碼，能不能輕鬆地用邏輯説服自己它不會出錯。&lt;/p&gt; 
&lt;p&gt;不依賴測試、不需要日誌，只靠邏輯推導，你就能大致確信這段邏輯的正確性，這種代碼往往設計得很優秀。&lt;/p&gt; 
&lt;p&gt;上述的這些技巧，不僅能幫助你推理，也能反過來指導你如何寫出好代碼。換句話説：能被「證明」得越輕鬆的代碼，往往本身就設計得更好。&lt;/p&gt; 
&lt;p&gt;這種證明的能力和練習打字一樣，需要反覆練手、變成本能。作者推薦從這三件事做起：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多寫數學證明&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多刷 Leetcode，但重質不重量&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;嘗試用證明的方式解釋自己的代碼邏輯&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;感興趣的朋友可以查看原文：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthe-nerve-blog.ghost.io%2Fto-be-a-better-programmer-write-little-proofs-in-your-head%2F" target="_blank"&gt;https://the-nerve-blog.ghost.io/to-be-a-better-programmer-write-little-proofs-in-your-head/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361541</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361541</guid>
      <pubDate>Wed, 16 Jul 2025 11:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 超級智能團隊的一半成員來自中國</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;馬克·扎克伯格在科技行業的某個特定賭註上習慣於投入鉅額資金，比如斥資 460 億美元打造元宇宙，但大多數人都知道，這個計劃最終以失敗告終。如今，Meta 首席執行官正在四處招聘人才，並將這些人安置在超級智能實驗室。該實驗室的團隊致力於各種基礎模型的研發，力爭在人工智能競賽中佔據領先地位。&lt;/p&gt; 
&lt;p&gt;至於該部門的員工名單，一份詳細名單顯示，該部門共有 44 名員工。有趣的是，&lt;strong&gt;其中 50% 來自中國，40% 的人從 OpenAI 離職&lt;/strong&gt;，此外還有其他一些「令人大開眼界」的發現。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4c9dc62a4cdaa55014056f865231cea5672.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Meta 目前正在大舉招聘，試圖從 OpenAI、蘋果等知名公司挖走人才，並向他們提供難以拒絕的待遇。在招募這家 iPhone 製造商的基礎模型主管 （附帶 2 億美元的簽約獎金）之前，Meta 已經挖走了三名前 OpenAI 員工，其中一人聲稱自己並沒有獲得 1 億美元的簽約獎金。&lt;/p&gt; 
&lt;p&gt;雖然 Meta 只知道其承諾的人才招募金額，但@deedydas 從一位匿名公司員工那裏獲得了這家社交媒體巨頭超級智能實驗室的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fdeedydas%2Fstatus%2F1946597162068091177" target="_blank"&gt;詳細員工名單&lt;/a&gt;。如上所述，50% 的招聘人員來自中國，其中 75% 為博士，70% 為研究人員。OpenAI 的招聘人數最多，佔 40%，其次是 Google 的 DeepMind，佔 20%，Scale 的招聘人數為 15%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/190818_KDrF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;簡而言之，Meta 的超級智能實驗室員工構成相當多元化，其中大多數人甚至在公司工作不到一個月。X 上的帖子還提到，這些新員工的年薪可能在 1000 萬至 1 億美元之間，但這一數字尚未得到證實。這份名單中最引人注目的細節或許是，44 名員工中有 50% 來自中國，一旦特朗普政府開始調查該公司是否存在任何安全違規行為，這可能會讓 Meta 陷入困境。&lt;/p&gt; 
&lt;p&gt;因此，如果馬克·扎克伯格將來被各路監管機構問及這些中國研究人員的情況，我們不會感到驚訝。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361539</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361539</guid>
      <pubDate>Wed, 16 Jul 2025 11:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>波蘭程序員在 10 小時編程馬拉松中擊敗 OpenAI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在東京舉行的 2025 年 AtCoder 世界巡迴賽總決賽（AWTF）中，來自波蘭格丁尼亞的 42 歲程序員 Psyho 創造了歷史，擊敗了 OpenAI 的定製 AI 模型，贏得了這場比賽。&lt;/p&gt; 
&lt;p&gt;這場賽事被認為是世界上最負盛名的編程比賽之一，邀請了 12 位頂尖人類程序員和一個 AI 競爭對手來應對極具挑戰性的任務。&lt;/p&gt; 
&lt;p&gt;經過 10 小時的編程馬拉松，Psyho 以約 9.5% 的優勢戰勝了 AI，贏得了第一名，而 OpenAI 的模型獲得了第二名。&lt;/p&gt; 
&lt;p&gt;Psyho 在社交媒體上表示：「人類勝利了（至少現在是這樣）！」他承認在比賽前的三天裏，他只睡了大約 10 個小時，將自己推向了極限。&lt;/p&gt; 
&lt;p&gt;OpenAI 首席執行官 Sam Altman 回應道：「幹得好，Psyho。」&lt;/p&gt; 
&lt;p&gt;&lt;img height="1105" src="https://static.oschina.net/uploads/space/2025/0721/190121_fO7b_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;今年的挑戰要求參賽者在 30×30 的網格上規劃機器人的路徑，使用盡可能少的移動次數，這是一個 NP-hard 優化問題，有無數可能的結果。&lt;/p&gt; 
&lt;p&gt;賽前 OpenAI 的 AI 模型 OpenAIAHC 被認為在比賽中佔據主導地位，但 D?biak 的創新性、啓發式驅動的方法——使用解決問題的捷徑和有根據的猜測，而不是暴力計算——確保了他贏得了比賽。&lt;/p&gt; 
&lt;p&gt;比賽管理員 Yoichi Iwata 讚揚了他的獨特方法，指出 AI 在原始優化方面表現出色，但在「人類創造力」方面仍有不足。&lt;/p&gt; 
&lt;p&gt;Psyho 是一位前 OpenAI 工程師，曾幫助開發 OpenAI Five，他使用 Visual Studio Code 進行比賽，僅依賴基本的自動完成功能，並承認 AI 將他推向了極限：「我的得分接近模型的得分，這促使我全力以赴。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f77e296a89edb2d66ba4cad4489aa35510a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 10 小時馬拉松的最後階段，他超越了 OpenAIAHC，贏得了比賽和 50 萬日元的獎金。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361538</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361538</guid>
      <pubDate>Wed, 16 Jul 2025 11:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：24h 智能計分網球學練館</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2102</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2102</guid>
      <pubDate>Wed, 16 Jul 2025 10:54:00 GMT</pubDate>
    </item>
    <item>
      <title>Windows 包管理器 UniGetUI 發佈 3.3，支持批量下載</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windows 11/10 上相當歡迎的包管理器 UniGetUI（原 WinGetUI）迎來了重大更新。這一版本原本計劃作為 3.2.1 發佈，但由於更新內容遠超預期，開發者決定直接提升版本號至&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarticliment%2FUniGetUI%2Freleases%2Ftag%2F3.3.0" target="_blank"&gt;3.3.0。&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;此次更新亮點頗多，其中最引人注目的便是新增了批量下載安裝程序的功能，用户現在可以一次性下載多個軟件的安裝包。&lt;/p&gt; 
&lt;p&gt;此外，UniGetUI 還允許用户選擇特定的包管理器可執行文件，併為每個包管理器設置默認安裝選項。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f5522da28b5d043ecc23b82e07eab9826ed.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;除了這些新功能外，UniGetUI 還引入了雲備份和恢復功能，用户可以將軟件配置備份到雲端，在更換設備或系統重裝後能夠快速恢復之前的設置。同時軟件還支持更多命令，並且用户可以在安裝、卸載或更新軟件包之前終止相關進程，避免衝突和錯誤。&lt;/p&gt; 
&lt;p&gt;PowerShell7 在更新時會自動清理舊版本，搜索框的位置被調整以更好地利用空間，工具欄得到了增強，內部錯誤檢測機制也進行了升級，部分對話框也進行了更新。&lt;/p&gt; 
&lt;p&gt;值得注意的是，由於 XAML 和 YAML 文件的使用率極低（僅 0.7% - 1.3% 的用户使用），開發者決定不再支持這兩種文件格式的創建，以減少開發維護成本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361533</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361533</guid>
      <pubDate>Wed, 16 Jul 2025 10:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>官宣！Dora-rs 官方中文教程正式發佈！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;&lt;code&gt;Dora-rs&lt;/code&gt;：是一個為現代 AI 機器人應用設計的、以數據流為核心的機器人開發框架 。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在機器人開發的世界裏，我們常常面臨這樣的困境：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;過於複雜&lt;/strong&gt;： 傳統軟件棧學習曲線陡峭，配置繁瑣，讓快速原型驗證成為奢望。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;性能瓶頸&lt;/strong&gt;： 數據在不同模塊間傳遞時延遲巨大，嚴重影響系統的實時響應與可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;集成困難&lt;/strong&gt;： 融合不同來源的硬件與算法庫，就像一場永無止境的「膠水代碼」戰爭。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分佈式難題&lt;/strong&gt;： 多機器人協作時，通信衝突、帶寬搶佔等問題層出不窮。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;我們相信，是時候用現代化的軟件開發實踐，為機器人領域帶來一些改變了。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Dora-rs，因此而生。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;為什麼選擇 Dora-rs？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;我們摒棄了複雜的概念堆砌，將核心優勢聚焦於三點：&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;1. 化繁為簡：像搭樂高一樣構建應用&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Dora-rs 的核心是數據流。你不再需要維護複雜的狀態和糾結於瑣碎的通信實現，而是將應用拆解成一個個獨立的、可複用的節點和操作符，然後像畫流程圖一樣將它們連接起來，定義清晰的數據流向。這種聲明式的方法極大地降低了系統的心智負擔，讓集成和調試變得前所未有的簡單。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;2. 極致高效：為高性能而生的零拷貝通信&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;性能是機器人系統的生命線。Dora-rs 底層採用 Apache Arrow 數據格式，並實現了節點間的零拷貝通信。這意味着數據在傳遞時無需在內存中進行不必要的複製，從而將端到端延遲降至微秒級，為實時感知、決策和控制提供了堅實的性能基礎。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;3. 根源可靠：Rust 帶來的內存安全保證&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Dora-rs 由 Rust 語言構建。這不僅帶來了卓越的性能，更重要的是，Rust 強大的所有權和借用檢查機制，可以在編譯階段就消除一整類的內存安全漏洞（如空指針、數據競爭等）。對於追求穩定性和可靠性的機器人應用而言，這是一種來自語言層面的、與生俱來的安全感。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;我們為你準備了什麼？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;我們準備了一份官方系統化教程。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;紙上得來終覺淺，為了幫助你真正掌握 Dora-rs，我們推出了這份官方系統化教程。它不是零散的博客文章，而是一份結構完整、路徑清晰的專業文檔。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;為了讓你能系統化地掌握 Dora-rs，我們為你規劃了以下這條清晰的學習路徑：&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;開始&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;介紹：Dora-rs 是什麼？&lt;/li&gt; 
 &lt;li&gt;快速上手&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;基礎&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;數據流&lt;/li&gt; 
 &lt;li&gt;節點&lt;/li&gt; 
 &lt;li&gt;操作符&lt;/li&gt; 
 &lt;li&gt;事件流處理&lt;/li&gt; 
 &lt;li&gt;數據信息 / Arrow Data&lt;/li&gt; 
 &lt;li&gt;多語言支持：API 綁定&lt;/li&gt; 
 &lt;li&gt;命令行接口&lt;/li&gt; 
 &lt;li&gt;守護進程&lt;/li&gt; 
 &lt;li&gt;協調器&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;學完本教程，你將不僅掌握 Dora-rs 的核心設計哲學，更能獨立構建、運行、調試一個基於數據流的模塊化機器人應用，為你未來駕馭複雜機器人項目打下最堅實的基礎。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;我們已將這份結構完整的中文教程部署在社區網站上，你可以掃描下方二維碼或者通過本文末尾的鏈接直接開始學習。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-1ccb97a05a676e0418d83681015ee4eda42.png" width="400" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;Dora 中文社區&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;官方中文教程入口&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="color: rgb(25, 27, 31); margin-left: 0px; margin-right: 0px; text-align: start;"&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoracc.com%2F" target="_blank"&gt;https://doracc.com&lt;/a&gt;&lt;/u&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;⭐ Dora-rs GitHub 倉庫地址&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="color: rgb(25, 27, 31); margin-left: 0px; margin-right: 0px; text-align: start;"&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdora-rs%2Fdora" target="_blank"&gt;https://github.com/dora-rs/dora&lt;/a&gt;&lt;/u&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;我們相信，一個優秀的工具最終是為開發者服務的。我們編寫這份教程，是希望它能真正幫你掃清學習路上的障礙，讓你感受到現代化機器人開發的簡潔與高效。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;下一步行動&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;⭐ 支持項目 ：點亮我們的 GitHub Star&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;分享文章：點個「贊」和「分享」，讓更多人發現&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;開始學習 ：點擊上方鏈接直達教程&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361526</guid>
      <pubDate>Wed, 16 Jul 2025 10:43:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>​斯坦福開源 OctoTools，多工具協作 AI Agent</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;斯坦福大學開源了一款名為 OctoTools 的 AI Agent，該工具能夠結合超過 11 種不同的工具，以應對複雜的推理任務。傳統的 AI 助手往往依賴於單一模型，難以有效處理需要多步推理和跨領域知識的挑戰。而 OctoTools 的問世，則為這些問題提供了新的解決方案。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="591" src="https://static.oschina.net/uploads/space/2025/0721/173755_M5fY_4252687.png" width="1057" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OctoTools 在多個領域表現出色，測試數據顯示其在 16 項基準測試中的平均準確率非常高。這使得它能夠在數學、科學和醫學等複雜場景中輕鬆完成任務。用户可以通過 OctoTools 更好地解決視覺謎題或進行基於文本的推理，提升工作效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該框架的基礎構件是 「工具卡片」，這些卡片以標準化的形式封裝各種工具的功能和元數據。工具包括圖像識別、數學計算、網絡搜索及特定領域的專家系統等。每個工具卡片都詳細描述了工具的基本信息，例如輸入輸出格式、使用限制和&lt;span&gt;最佳&lt;/span&gt;實踐。這些信息為規劃器和執行器提供了必要的指導，幫助其有效使用這些工具。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在 OctoTools 的工作流程中，規劃器作為系統的大腦，負責分析用户查詢並制定解決方案。它會根據任務目標和所需技能選擇合適的工具，生成詳細的行動計劃。這個過程類似於人類在解決問題時的思考方式，通過逐步細化來確保每一步都朝着最終目標前進。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;執行器則負責將規劃器制定的行動計劃轉化為可執行命令，並運行相應的工具。通過這種方式，OctoTools 不僅能夠執行簡單命令，還能處理複雜的多步操作，提升系統的可靠性和可維護性。此外，上下文驗證器則負責檢查任務進展中的一致性，確保最終結果的準確性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361510</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361510</guid>
      <pubDate>Wed, 16 Jul 2025 09:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟服務器軟件被曝嚴重安全漏洞，黑客藉此在全球發起攻擊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;微軟服務器軟件近日被曝存在嚴重安全漏洞，不明身份的黑客在過去幾天利用這一漏洞對全球範圍的目標發起了攻擊。目前已有多家機構證實服務器被攻破，相關部門正緊急採取補救措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據路透社美東時間 20 日報道，微軟公司近日發佈安全警告，稱其 SharePoint 服務器軟件正在遭到持續攻擊，該軟件廣泛用於政府機構和企業內部文件共享。此次全球攻擊已入侵了美國聯邦和州政府機構、大學、能源公司以及一家亞洲電信公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="335" src="https://static.oschina.net/uploads/space/2025/0721/171427_6M5M_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟在 7 月 20 日發佈的安全通告中表示，攻擊者正在利用 SharePoint 軟件中的一個「允許授權攻擊者在網絡中執行偽裝行為」的漏洞。據《華盛頓郵報》率先披露的消息，不明身份的攻擊者在過去幾天內利用漏洞對全球各地的目標發動了攻擊。這次攻擊被稱為「零日攻擊」，因為它利用了一個此前未知的漏洞。專家表示，全球有數以萬計的此類服務器處於風險之中。美國政府及其在加拿大和澳大利亞的合作伙伴正在調查 SharePoint 服務器的入侵事件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;美國聯邦調查局（FBI）在 20 日的一份聲明中表示，已知悉此次攻擊事件，正在與聯邦政府和私營部門的合作伙伴密切協作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;荷蘭研究機構 Eye Security 指出，攻擊者可能通過訪問 SharePoint 服務器，進而接入核心服務系統，實施敏感數據竊取、密碼獲取等行為。更令人擔憂的是，研究人員發現攻擊者可能已經獲取系統密鑰，即使系統打上補丁後，仍有可能再次被遠程入侵。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據《華盛頓郵報》報道，至少兩個美國聯邦政府機構的服務器已被攻破。報道還稱，美國東部某州一名官員表示，攻擊者「劫持」了該州一份對公眾開放的政府文檔庫，目前該機構無法訪問相關內容，尚不清楚資料是否已被刪除。該官員表示：「我們可能需要在另一個文檔庫中重新發布這些文件。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次事件引發了美國國內廣泛關注。美國國土安全部下屬網絡安全與基礎設施安全局（CISA）在接到安全公司通報後已迅速介入，並通知了大約 100 個潛在受影響的組織，包括公立學校和大學。CISA 發言人馬西·麥卡錫（Marci McCarthy）表示，儘管該機構目前由代理局長領導，但相關人員仍「晝夜不停」地應對此次安全事件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟 20 日表示，已為 SharePoint 訂閲版（SharePoint Subscription Edition）發佈安全更新，並建議客户立即安裝。同時，微軟正在為 2016 版和 2019 版 SharePoint 開發補丁。如果客户無法啓用建議的惡意軟件防護，微軟建議立即斷開服務器與互聯網的連接，直到補丁可用為止。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361504</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361504</guid>
      <pubDate>Wed, 16 Jul 2025 09:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>我國網民規模已達 11.23 億人，互聯網普及率達 79.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;7 月 21 日，中國互聯網絡信息中心（CNNIC）在京發佈第 56 次《中國互聯網絡發展狀況統計報告》（以下簡稱《報告》）。《報告》顯示，「十四五」期間，我國互聯網建設取得顯著成就。新型信息基礎設施加速佈局，互聯網基礎資源持續豐富，為互聯網普及和數字經濟發展提供了堅實支撐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;截至 6 月，我國網民規模達 11.23 億人，互聯網普及率達 79.7%，越來越多的羣體共享數字發展成果。新興市場蓬勃發展，人工智能技術加速應用落地，全球影響力不斷提升，科技創新引領經濟社會高質量發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;基礎資源穩固根基&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;基礎設施量質齊升&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《報告》顯示，2025 年上半年，基礎資源保有量保持穩定，信息基礎設施持續夯實，移動互聯網接入流量不斷增長，賦能信息通信業高質量發展再上新台階。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一是互聯網基礎資源保有量築牢根基。截至 6 月，我國域名總數為 3262 萬個，其中，國家頂級域名「.CN」數量為 2085 萬個；IPv6 地址數量為 68567 塊/32。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;二是信息基礎設施持續夯實。1 月，工業和信息化部發布《關於開展萬兆光網試點工作的通知》，提出開展萬兆光網試點，有序引導萬兆光網從技術試點逐步走向部署應用；電信普遍服務實施十週年，截至 6 月底，我國 5G 基站總數達 455 萬個，十年間推動實現了「村村通寬帶、鄉鄉通 5G」，行政村通 5G 比例超過 90%；移動用户上網流量連續 6 個月實現兩位數增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;互聯網普惠深入推進&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;銀髮農村羣體共享發展成果&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《報告》顯示，截至 6 月，我國網民規模達 11.23 億人，互聯網普及率達 79.7%；60 歲及以上銀髮網民規模達 1.61 億人、農村網民規模達 3.22 億人，保持穩定增長態勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一是銀髮經濟快速發展，賦能互聯網進一步普及應用。政府高度重視老年羣體惠享數字紅利，我國老年羣體互聯網普及率達 52.0%。2025 年《政府工作報告》提出大力發展銀髮經濟，6 月工業和信息化部公佈《智慧健康養老產品及服務推廣目錄（2024 年版）》，推動銀髮羣體深度共享信息化發展成果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;二是縣域富民產業發展，互聯網點亮農村居民數字化新生活。互聯網賦能鄉村振興成效顯著，我國農村地區互聯網普及率為 69.2%，較 2024 年 12 月提升 1.9 個百分點。數字文旅新模式不斷湧現，拓寬農村居民數字化就業增收新渠道，3 月鄉村遊產品預訂量同比增長 52%；農村流通高質量發展，一季度全國快遞業務量中發往農村地區的佔比達到三成，全國縣域生活服務消費訂單量同比增長 42.1%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;數字文娛出海勢頭不減&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;融合線下提升發展活力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《報告》顯示，2025 年上半年，我國數字文娛領域發展「內外兼修」，持續向全球輸出優秀文化價值，並不斷拓展與線下的融合，為國內文旅市場增加新動力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一是網絡文學出海熱度不斷攀升，成為中華文化「走出去」的創新載體。2024 年網絡文學出海市場規模超 50 億元，培育海外網絡作家 46 萬名，海外用户規模超 3.5 億，覆蓋全球 200 多個國家和地區，其中日本市場用户規模激增 180%，成為全球用户增速最快的新興市場。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;二是網絡遊戲出海迎來新的發展機遇。4 月，國務院發佈《加快推進服務業擴大開放綜合試點工作方案》，明確將「發展遊戲出海業務，佈局從 IP 打造到遊戲製作、發行、海外運營的整個產業鏈」納入國家級戰略工程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;三是網絡視頻對線下文化賦能效應逐漸顯現。網絡劇與旅遊深入融合，如運河題材網絡劇與旅遊形成協同矩陣，推動運河沿岸城市遊客總量增加 40%，民宿預訂量同比提升 215%。短視頻平台通過整合本地政務資源、平台流量與商家資源，構建線上線下消費閉環，為更多實體商家帶去新客流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成式人工智能產品數量攀升&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;應用場景不斷深化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《報告》顯示，2025 年上半年，生成式人工智能產品實現了從技術到應用的全方位進步，產品數量迅猛增長，應用場景持續擴大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一是我國在人工智能領域影響力顯著提升。截至 3 月，共有 346 款生成式人工智能服務在國家互聯網信息辦公室完成備案。我國人工智能產品湧現引發全球關注，DeepSeek 上線不足 20 天全球日活躍用户就突破 3000 萬，登頂全球 140 個國家及地區的應用市場，成為全球用户增速最快的生成式人工智能應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;二是生成式人工智能技術不斷向具體應用場景縱深滲透。用户方面，截至 6 月，用户利用生成式人工智能產品回答問題的比例最高，達 80.9%。產業方面，2024 年我國人工智能產業規模突破 7000 億元，連續多年保持 20% 以上的增長率。國產人工智能產品不僅在千億級參數規模、多模態能力等方面實現突破，並與辦公協同、教育普惠、工業設計、內容創作等場景深度融合，構建了覆蓋多個領域的智能應用生態。（記者，張崗）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361501</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361501</guid>
      <pubDate>Wed, 16 Jul 2025 09:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Resume Matcher —— 製作一份能獲得面試機會的簡歷</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="color:#1f2328"&gt;&lt;strong&gt;告別 ATS 機器人自動拒絕的困擾。&lt;/strong&gt;Resume&amp;nbsp;Matcher 是一個 AI 驅動的平台，它對招聘算法進行逆向工程，精準地向你展示如何定製你的簡歷。獲取關鍵詞、格式和洞察，助你順利通過首屏篩選，最終交到真人手中。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="color:#1f2328"&gt;Resume&amp;nbsp;Matcher &lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;旨在幫助用户優化簡歷，以突出技能和經驗，從而引起潛在僱主的共鳴。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;項目正在積極改進中，致力於構建一個&lt;strong&gt;用於製作簡歷的 VS Code 版本&lt;/strong&gt;，並添加新功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;主要特點：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;本地運行&lt;/strong&gt;：無需將簡歷上傳到服務器。所有功能均在你的機器上運行，並採用 Ollama 的開源 AI 模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ATS 兼容性&lt;/strong&gt;：獲取有關你的簡歷與 ATS 系統兼容性的詳細分析。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;即時匹配分數&lt;/strong&gt;：上傳簡歷和職位描述以獲得快速匹配分數和關鍵改進領域。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;關鍵字優化器&lt;/strong&gt;：將你的簡歷與工作關鍵字對齊，並識別關鍵內容差距。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;指導改進&lt;/strong&gt;：獲得明確的建議，讓你的簡歷脱穎而出。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="183" src="https://static.oschina.net/uploads/space/2025/0721/154029_WBq2_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/resume-matcher</link>
      <guid isPermaLink="false">https://www.oschina.net/p/resume-matcher</guid>
      <pubDate>Wed, 16 Jul 2025 09:03:00 GMT</pubDate>
    </item>
    <item>
      <title>LibreOffice 指責微軟故意製造複雜格式鎖住用户</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源辦公軟件 LibreOffice 近期近期一直在不遺餘力地&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.documentfoundation.org%2Fblog%2F2025%2F07%2F18%2Fartificially-complex-xml-schema-as-lock-in-tool%2F" target="_blank"&gt;批評微軟及其做法&lt;/a&gt;&lt;strong&gt;，這一次更是指責微軟故意使用「不必要的複雜」文件格式，通過其 Microsoft 365（Office）鎖住用户&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0721/164419_fUou_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;XML 是一種標記語言，用於結構化和定義文檔，被微軟 365 和 LibreOffice 等程序廣泛使用。&lt;/p&gt; 
&lt;p&gt;LibreOffice 表示，XML 模式包括 XML 文檔的結構、數據類型和規則，並在 XML Schema Definition（XSD）文件中描述，用於告訴電腦該如何處理數據，並確保數據遵循規則。&lt;/p&gt; 
&lt;p&gt;但 LibreOffice 和微軟在文件格式的選擇上截然不同，LibreOffice 採用 OpenDocument Format（ODF），這是一種開放標準，旨在不受單一公司控制，這種格式提供瞭如.odt（文本）和.ods（電子表格）等文件類型。&lt;/p&gt; 
&lt;p&gt;而微軟則創建了自己的 Office Open XML（OOXML），以支持其軟件中的所有功能，從而產生了我們熟悉的.docx 和.xlsx 文件。&lt;/p&gt; 
&lt;p&gt;有意思的是，這兩種格式實際上都是 ZIP 存檔，最簡單的驗證方法是將一個.docx 文件重命名為.zip，然後解壓縮，這將展示出 Microsoft 365 文檔的內部結構。&lt;/p&gt; 
&lt;p&gt;LibreOffice 指出，XML 本應作為「橋樑」，但微軟通過使其架構「複雜到成為障礙而非橋樑」來武器化自己的架構。&lt;/p&gt; 
&lt;p&gt;LibreOffice 將其比作鐵路系統，軌道是公共的，但一家公司的控制系統如此複雜，以至於其他公司無法早出兼容的列車，從而幾乎不可能與其他公司競爭，而且用户沒有意識到他們被這些技術障礙所束縛。&lt;/p&gt; 
&lt;p&gt;LibreOffice 還認為這種鎖定邏輯在其他地方發揮作用，它將複雜的文件格式直接與 Windows 11 的推廣聯繫起來，認為微軟沒有充分的技術理由強迫用户切換到 Windows 11。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361488</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361488</guid>
      <pubDate>Wed, 16 Jul 2025 08:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>京東開源輕量化通用多智能體 JoyAgent-JDGenie，GAIA 準確率 75.15%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fzh%2Fnews%2F19831" target="_blank"&gt;AIbase&lt;/a&gt; 從網絡信息獲悉，京東正式開源了一款產品級端到端通用多智能體系統 JoyAgent-JDGenie，在 GAIA 基準測試中以 75.15% 的準確率超越 OWL、OpenManus 等競品，位居行業前列。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GAIA 基準領跑，性能卓越&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;JoyAgent-JDGenie 在 GAIA 基準測試中表現亮眼，以 75.15% 的總體準確率刷新了多智能體系統的性能紀錄。&lt;/p&gt; 
&lt;p&gt;根據 GAIA 基準的評估標準，該系統在難度分級的任務中展現了優異的能力：Level1 任務準確率達 85% 以上，Level2 任務接近 78%，而在最複雜的 Level3 任務中也取得了 55% 的出色成績，顯著超越其他開源框架如 OWL（約 65%）和 OpenManus(約 65%)。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;端到端多智能體框架，開箱即用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;JoyAgent-JDGenie 是一款完整的端到端多智能體系統，支持用户通過簡單查詢或任務輸入直接獲得答案或解決方案。該框架集成了前端、後端、核心引擎以及多個子智能體模塊，包括報告生成智能體、代碼智能體、PPT 智能體和文件智能體，覆蓋了從文檔處理到代碼生成、演示文稿製作等多樣化場景。AIbase 瞭解到，開發者可通過掛載自定義子智能體或外部工具（如 Web 搜索 API 或 Python 解釋器）進一步擴展功能，滿足特定業務需求。&lt;/p&gt; 
&lt;p&gt;&lt;img height="246" src="https://oscimg.oschina.net/oscnet/up-ec6403d7c741e6e5f377cd0fe3bedcc4bf3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與傳統單一智能體系統不同，JoyAgent-JDGenie 採用多層級協作設計，通過任務分解和智能體協同，高效處理複雜任務。例如，用户輸入「生成一份關於 2025 年 AI 趨勢的 PPT」，系統會自動分配任務給 PPT 智能體和數據分析智能體，生成包含圖表和內容的演示文稿。這種開箱即用的特性極大降低了開發門檻，適合企業快速部署 AI 應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多模態與記憶優化，智能更進一步&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;JoyAgent-JDGenie 的多模態與記憶設計是其核心亮點。系統支持文本、圖像、代碼等多種輸入和輸出形式，能夠處理 GAIA 基準中的多模態任務，如解析 PDF 文件、分析圖像內容或處理音頻數據。此外，框架引入了跨任務級別的相似任務記憶機制，允許系統根據歷史任務記錄優化當前任務的處理效率。例如，在重複生成類似報告時，系統可調用歷史數據，減少重複計算，提升響應速度。&lt;/p&gt; 
&lt;p&gt;AIbase 從社區反饋中獲悉，JoyAgent-JDGenie 的多模態能力在處理複雜任務時表現出色。例如，在 GAIA Level3 任務中，系統能夠通過鏈式推理（Chain-of-Thought）結合外部工具，準確回答涉及多源數據整合的問題，如「根據某幅畫作和歷史記錄提取特定信息」。這種能力使其在數據分析、內容創作和自動化工作流中具有廣泛應用前景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;開源生態，助力開發者創新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目前，JoyAgent-JDGenie 已公開了前端、後端、框架、引擎以及核心子智能體的完整代碼，開發者可基於此進行二次開發或直接部署。項目還提供了詳細的文檔和快速入門指南，支持在 Windows、Linux 等多個平台上運行，兼容主流硬件環境。&lt;/p&gt; 
&lt;p&gt;社區反饋顯示，JoyAgent-JDGenie 的模塊化設計便於擴展。例如，開發者可通過添加新的子智能體（如專用於金融分析或醫療數據處理的智能體）快速定製系統。此外，京東團隊表示將持續優化框架，計劃引入本地化 LLM 支持和更高效的推理加速技術，以降低對雲端 API 的依賴，進一步提升性能和成本效益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361479</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361479</guid>
      <pubDate>Wed, 16 Jul 2025 08:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
