<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 02 Jul 2025 02:47:16 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>1-5 月我國互聯網業務收入 7735 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工業和信息化部運行監測協調局最新&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fgxsj%2Ftjfx%2Fhlw%2Fart%2F2025%2Fart_8805da85aec14555b88e36da36ea4e27.html" target="_blank"&gt;發佈&lt;/a&gt;&lt;span style="color:#000000"&gt;了 2025 年 1-5 月份互聯網和相關服務業運行情況。具體如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;一、總體運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;互聯網業務收入穩定增長。1－5 月份，規模以上互聯網和相關服務企業（以下簡稱互聯網企業）完成互聯網業務收入 7735 億元，同比增長 0.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;利潤總額降幅持續收窄。1－5 月份，規模以上互聯網企業實現利潤總額 692 億元，同比下降 2.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研發經費增勢放緩。1－5 月份，規模以上互聯網企業共投入研發經費 390.6 億元，同比增長 4.1%，增速較 1－4 月份回落 0.7 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;二、分地區運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;東部地區互聯網業務收入增速放緩，西部地區收入增速領先。1－5 月份，東部地區完成互聯網業務收入 6943 億元，同比增長 2.8%，高於全國增速 1.9 個百分點，佔全國互聯網業務收入的 89.8%。中部地區完成互聯網業務收入 308.4 億元，同比下降 30.1%，低於全國增速 31 個百分點。西部地區完成互聯網業務收入 467.8 億元，同比增長 4.3%。東北地區完成互聯網業務收入 15.7 億元，同比下降 24.1%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;京津冀地區互聯網業務收入保持較快增勢。1－5 月份，京津冀地區完成互聯網業務收入 2666 億元，同比增長 8.3%，佔全國互聯網業務收入的 34.5%。長三角地區完成互聯網業務收入 2470 億元，同比下降 2.1%，佔全國互聯網業務收入的 31.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;超三成地區互聯網業務增速實現正增長。1－5 月份，互聯網業務累計收入居前 5 名的北京、廣東、上海、浙江和天津共完成業務收入 6496 億元，同比增長 4.1%，佔全國（扣除跨地區企業）互聯網業務收入的 84%。全國互聯網業務收入實現正增長的省（區、市）有 11 個，其中山西、內蒙古、四川、陝西增速超 10%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;附註：規模以上互聯網和相關服務企業口徑為上年互聯網和相關服務收入 2000 萬元及以上，文中所有同比增速均按可比口徑計算。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358301</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358301</guid>
      <pubDate>Wed, 02 Jul 2025 02:42:14 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華為開源大規模 MoE 模型推理部署技術「Omni-Infer」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;華為公佈了基於昇騰的超大規模 MoE 模型推理加速技術「Omni-Infer」。&lt;/p&gt; 
&lt;p&gt;官方介紹，Omni-Infer 是一套專為昇騰硬件平台定製的強大推理加速工具集，完全兼容業界目前主流的開源大模型推理框架（比如 vLLM 等），旨在提供高性能、企業級推理能力，具備原生支持且功能集持續擴展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ad6ff90d8d31fab0e52f1d92fd7d9bb90e3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;部分核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高級注意力機制優化：專為 LLM、MLLM 和 MoE 模型定製，增強性能與可擴展性。&lt;/li&gt; 
 &lt;li&gt;請求級負載均衡：針對所有序列長度優化預填充（prefill）和解碼（decode）階段，實現最大吞吐量與低延遲。&lt;/li&gt; 
 &lt;li&gt;優化的 MoE 專家部署：支持 EP144/EP288 配置的大規模混合專家（Mixture of Experts, MoE）模型。&lt;/li&gt; 
 &lt;li&gt;MoE 專家負載均衡：具備分層非均勻冗餘和近實時動態專家放置功能，提升資源利用效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;目前，Omni-Infer 已公佈技術報告及可分析代碼包等內容：&lt;a href="https://gitee.com/omniai/omniinfer"&gt;https://gitee.com/omniai/omniinfer&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358292</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358292</guid>
      <pubDate>Wed, 02 Jul 2025 02:27:14 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Iceberg 在圖靈落地應用</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;導讀&lt;/h1&gt; 
&lt;p&gt;百度 MEG 上一代大數據產品存在平台分散、易用性差等問題，導致開發效率低下、學習成本高，業務需求響應遲緩。為瞭解決這些問題，百度 MEG 內部開發了圖靈 3.0 生態系統，包括 Turing Data Engine(TDE) 計算&amp;amp;存儲引擎、Turing Data Studio(TDS) 數據開發治理平台和 Turing Data Analysis(TDA) 可視化 BI 產品。依託圖靈 3.0 生態，我們引入了數據湖表格式：Apache Iceberg，利用其特性並在多種業務場景下進行優化實踐，解決圖靈數倉業務實時數據入湖，數據表歷史記錄更新效率低等多個痛點問題。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 圖靈 3.0 生態概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由於百度 MEG 上一代大數據產品存在平台多、易用性差及數據流轉繁瑣等問題。這些問題導致開發人員研發效率低及多平台間高昂的學習成本；業務部門的感知則是需求交付遲緩、數據產出延遲及數據質量低等問題。為瞭解決上述問題，我們構建了新一代大數據解決方案——"圖靈 3.0"，旨在覆蓋數據全生命週期，支持全鏈路數據操作，提供高效敏捷且統一的強大數據生態系統，其中包括數據計算引擎、數據開發和數據分析三個核心部分：&lt;/p&gt; 
&lt;p&gt;1. TDE（Turing Data Engine）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247581388%26idx%3D1%26sn%3De71a4f3c4ca283ac6e8fe51d0a45a02b%26scene%3D21%23wechat_redirect" target="_blank"&gt;圖靈生態的計算引擎&lt;/a&gt;，包含基於 Hive、Iceberg 進行數據處理的 Spark 和&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247601378%26idx%3D1%26sn%3D9234aeef05c3813cfb34d9a064261984%26scene%3D21%23wechat_redirect" target="_blank"&gt;ClickHouse 高性能計算引擎&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;2. TDS（Turing Data Studio）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247599508%26idx%3D1%26sn%3D19094522609ca58528295a8ccbb061bd%26scene%3D21%23wechat_redirect" target="_blank"&gt;一站式數據開發治理平台&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;3. TDA（Turing Data Analysis）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247584876%26idx%3D1%26sn%3D7bf459415ef8d51685d4e1c335b0603e%26scene%3D21%23wechat_redirect" target="_blank"&gt;新一代可視化 BI 產品&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;本文主要介紹數據湖表格式 Iceberg 在圖靈 3.0 生態下的應用與實踐。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1764b56858226d39002905e95ec9f32e1d2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△圖靈 3.0 生態產品&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 問題&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MEG 數據中台基於 Hive 構建了離線數據倉庫，已支持手百，搜索，商業，貼吧，小説，用增架構，銷售等多個業務需求，但隨着業務的發展，業務對數據的實時性以及查詢性能等有更高要求，當前主要存在以下幾個問題：&lt;/p&gt; 
&lt;p&gt;1. 商業、電商、銷售等業務，週期性地更新行業等信息，單次更新數據量佔比小、字段少，但是基於 Hive 的數據更新（以下簡稱：數據回溯）只能通過全量覆蓋寫的方式實現，數據回溯週期長、效率低、成本高。&lt;/p&gt; 
&lt;p&gt;2. 由於 Hive 在實時數據更新以及事務支持上存在一定侷限性，無法有效滿足業務構建實時數倉的需求。&lt;/p&gt; 
&lt;p&gt;3. 在處理大規模數據集上，Hive 的查詢性能受到如元數據的加載解析以及每次訪問數據都需通過分佈式文件系統 listFile 遍歷文件列表等問題的影響，導致性能降低。&lt;/p&gt; 
&lt;p&gt;基於上述問題，我們通過技術調研，最終引入了開源的數據湖表格式 Iceberg，構建數據湖存儲服務，並藉助大數據生態的 Spark、Flink 等計算引擎來實現數據湖的分析，將其無縫集成到圖靈生態中，幫助業務提效降本，構建更快速、更高效、更低成本的數據中台產品。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 Hive 和 Iceberg 對比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Hive 作為一個基於 Hadoop 生態系統的開源數據倉庫工具，主要用於對大規模結構化數據進行存儲、查詢和分析。而 Iceberg 作為新一代數據湖表格式，提供了類似傳統數據庫的事務性，保證和數據一致性，並支持複雜的數據操作，如行級更新和刪除等，更加適合實時更新，流批一體數據場景，下表列出 Hive 和 Iceberg 一些主要特性對比：&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Hive&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Iceberg&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;行級更新&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;不支持&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持 merge into、&lt;/span&gt; 
         &lt;span&gt;upsert&lt;/span&gt; 
         &lt;span&gt;等語法進行行級別更新能力&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;時效性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;小時級別/天級&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;分鐘級&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;事務&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;非完整的 ACID 事務&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持完整的 ACID 事務，同時使用多快照提供了讀寫分離的特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;元數據管理方式&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;基於 Mysql 進行元數據存儲&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;通過文件組織管理，直接存儲數據文件元數據&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;數據版本控制&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;無&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持時間旅⾏(Time travel) 特性，可基於快照進行歷史數據版本管理和訪問&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 Iceberg 的組織結構&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Iceberg 文件組織分為元數據層和數據層，主要包含 version-hint，metadata file、snapshot file、manifest file 和 data file 文件類型，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;metadata 元數據層&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a. version-hint：該文件作為元數據索引初始文件，記錄了 Iceberg 表的版本號，通過版本號找到對應的 metadata file。&lt;/p&gt; 
&lt;p&gt;b. metadata file：記錄了 Iceberg 表的 schemas、properties 以及快照等信息。&lt;/p&gt; 
&lt;p&gt;c. snapshot file（manifest-list）：每次數據 commit 會生成一個新的快照，保存了該快照下每個 manifest file 路徑及對應的分區範圍。&lt;/p&gt; 
&lt;p&gt;d. manifest file：記錄數據文件元信息，包含每個數據文件的路徑、文件的大小等一系列統計信息（如文件每列的最大最小值、空值數等），實現元數據和數據文件的關聯。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;data 數據層&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;data file：實際的數據文件，以 parquet 等列存格式存儲數據。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f4a0f78b290db1caccb1aa213d0eb2ebc13.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表結構&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f506fa444f1e285b84c15e9adb1fd379988.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 文件組織結構&lt;/p&gt; 
&lt;p&gt;通過上述 Iceberg 元數據文件組織結構，Iceberg 實現了文件級的元信息統計及版本化管理。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;02 Iceberg 能力建設與應用&lt;/h1&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 圖靈生態能力適配&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 統一元數據服務&lt;/h3&gt; 
&lt;p&gt;由於原生 iceberg 缺少元數據的可視化管理能力，我們通過構建統一的元數據微服務，將 Iceberg 表和 Hive 表元數據進行管理，對應用層提供相關表和分區的增刪改查等接口，統一數據存儲的元數據操作入口。&lt;/p&gt; 
&lt;p&gt;該微服務主要包含常駐 SparkSession 模塊，EngineMetaService 模塊和元數據模塊，通過將 SparkSession 常駐，為用户提供 Iceberg 表和 Hive 表元數據和分區數據的增刪改查功能，以及可視化的元數據管理界面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-76e46b4f67c2c75cd8176866ca4893e5c2e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△統一元數據服務架構&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 打通 Iceberg 和 Hive 聯邦查詢&lt;/h3&gt; 
&lt;p&gt;為了兼容歷史業務存量 Hive 表，同時降低用户使用 Iceberg 的成本。我們在計算引擎層面打通 Iceberg 和 Hive 聯邦查詢能力，並保證了 Iceberg 表與原有方式語法一致。&lt;/p&gt; 
&lt;p&gt;通常在一條 SQL 執行過程中，主要可簡化以下 Parse、Analyzer、Optimizer、CBO 四個流程。通過在 Analyzer 和 Plan 階段進行改進優化，來打通 Iceberg 和 Hive 表聯邦查詢。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Analyzer 階段：該階段主要是將 spark 未解析的邏輯計劃進行解析，我們通過對 SparkSessionCatalog 加載方式改造，優先加載 iceberg 表使用的 catalog 類型，如果用户 SQL 使用的是 Iceberg 表，則對應會使用 IcebergCatalog 和 iceberg 數據源訪問，否則使用 SessionCatalog 與 Hive 數據源訪問。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optimizer 階段：為加強數據安全管理，我們進一步打通 Iceberg 表鑑權能力，在基於邏輯計劃生成物理計劃階段，解析注入表、字段信息以及表操作類型規則，並與公司內數管平台交互，實現對 Iceberg 表和字段的鑑權&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a5292d689d944eafa1fc34ca2637e610b9f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 和 Hive 聯邦查詢適配流程&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 存量 Hive 低成本遷移 Iceberg&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;現有數倉業務數據主要存儲於 Hive 表，為支持業務快速切換 Iceberg 應用新技術，我們建設了存量 Hive 表低成本遷移至 Iceberg 表的能力。&lt;/p&gt; 
&lt;p&gt;以下是在實踐過程中的兩種遷移方案對比：&lt;/p&gt; 
&lt;p&gt;方式 1：使用 Iceberg 功能 migrate 進行原地遷移，通過社區提供的 CALL migrate 語法，直接執行如下示例的 SQL 語句，即可將 Hive 表升級為 Iceberg 表。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CALL&amp;nbsp;catalog_name.system.migrate('db.sample', map('foo',&amp;nbsp;'bar'));﻿


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該方案操作簡單且可回滾，但這種方式在圖靈生態落地過程中也存在一些問題：&lt;/p&gt; 
&lt;p&gt;該方式會基於原 Hive 表的數據信息構建 Iceberg 元數據信息，並將原 Hive 表名重命名為 sample_backup_，同時數據路徑也進行重命名。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下游無法讀：在執行遷移過程中，原 Hive 表對應的路徑已經被重命名，進而導致下游業務無法正常讀取正在遷移中的表。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多表掛載衝突：在業務的使用場景中，存在同一份物理數據被多個 Hive 表掛載可能，直接修改路徑會導致其他表失效。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;方式 2：基於上述問題，我們進一步對現有方案進行優化，不改變 Hive 表原有的數據路徑，來實現 Hive 低成本遷移 Iceberg，具體流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;構建 Iceberg 元數據：直接複用 Hive 的分區數據，新建同名的 Iceberg 表，並重建 Iceberg 元數據，最終新 Iceberg 表的元數據信息實際指向是 Hive 分區數據存儲位置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據校驗：當 Iceberg 元數據構建完成後，查詢 Iceberg 表中字段數據，和遷移之前 Hive 表字段數據，進行一致性校驗，驗證遷移是否符合預期。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;讀寫切換：數據校驗完成後，我們只需要將對應表的屬性更新為 Iceberg。因為我們已經打通了 Iceberg 和 Hive 的查詢，且遷移後表名未變，業務可正常使用原有表名及語法進行查詢和寫入，降低遷移成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eea52f5d044ee6bc0ba16749ae9f4589492.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Hive 遷移 Iceberg 整體實現流程&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 Iceberg 在圖靈的應用和性能優化&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.1 圖靈實時數倉應用&lt;/h3&gt; 
&lt;p&gt;在圖靈數倉大部分場景中，用户主要依託天級或小時級運行的離線 Spark 任務來完成數據入倉。在這種模式下，難以滿足部分對數據實時性要求較高的需求。&lt;/p&gt; 
&lt;p&gt;為解決該問題，我們基於 Iceberg+Flink 構建的圖靈實時湖倉架構，整體重構流程如下圖所示。該架構模式實現了數據分鐘級別實時入倉，顯著提升了數據入倉的時效性。進一步擴展了整個圖靈的應用場景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;針對數據分析和 case 排查等場景，業務可基於圖靈常駐計算引擎進行實時查詢，快速獲取所需要的數據支持業務分析決策；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對策略迭代、特徵生產以及機器學習等複雜計算場景，可基於 spark 例行任務進行加工生產；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對策略數據調研分析、科學計算等複雜場景通過數據交互計算引擎 Jupyter 進行數據計算。通過構建圖靈實時湖倉架構，既保證了數據分析的時效性又兼顧了複雜計算任務的處理能力，有效提升了業務的數據處理效率和分析決策能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fabfc35e204c90fdf9ccd937438c044d8c6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△圖靈實時湖倉架構演變&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.2 行級更新策略&lt;/h3&gt; 
&lt;p&gt;在圖靈數倉業務場景下，商業、搜索、電商、銷售等業務，週期性地更新行業等信息。而 Hive 在該場景下支持相對較弱，需通過全量覆蓋寫方式刷新數據，這種方式在大數據量場景下，回溯數據週期長，消耗資源大，所需要的人力時間成本也高。我們通過利用 Iceberg 行級更新的特性，基於 update、merge into 等方式回溯進行字段變更，能夠很大程度的提高回溯效率，降低資源和人力成本。&lt;/p&gt; 
&lt;p&gt;針對數據行級更新，Iceberg 提供了兩種策略，分別為 COW(Copy on Write： 寫時複製) 或 MOR (Merge on Read：讀時合併)，其中 MOR 根據其標記刪除文件的區別又細分了兩種方式（Equality Delete File 和 Position Delete File）。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新策略&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新後的讀取效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新時寫入效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;適用場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;備註&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;COW&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最慢&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;讀多寫少場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;﻿&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 標記條件刪除（&lt;/span&gt; 
         &lt;span&gt;&lt;span style="color:#191b1f"&gt;&lt;span&gt;Equality Delete File&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
         &lt;span&gt;）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;較快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;寫入多、讀取少場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;讀開銷：每次讀取數據需要額外讀取標記刪除列數據進行比較。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;寫開銷：只需要存儲標記過濾數據的條件，寫入成本極低。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 標記位置刪除（Position Delete File）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;快（依賴更新數據量）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;較快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;少量數據更新、讀取少場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;讀開銷：加載每個文件需過濾的數據行號。（刪除行過多，影響性能）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;寫開銷：需要掃描一遍原數據，找出待刪除數據的行號。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;關於 COW 和 MOR 更新策略的文件表現形式如下圖所示，我們針對不同場景採用不同更新策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;對於日常數據查詢分析場景，小時級&amp;amp;天級離線例行生成加工場景，由於查詢次數會遠多於數據更新次數，可默認採用 COW 策略；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對一些業務更新少量字段進行長週期回溯場景，以及實時場景，寫入頻繁，通過使用 MOR 策略，來支持用户進行數據回溯變更字段信息，以提升數據更新效率並節省資源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082e448b69e5bbdb64cc8dbc417fdcbe04d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△COW 和 MOR 兩種更新策略對比&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45b92197037fdcbd76356145ee09137730c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△MOR 兩種刪除文件類型&amp;amp;更新字段示例&lt;/p&gt; 
&lt;p&gt;在業務進行數據回溯應用過程中，我們採用 MOR(Position Delete File) 進行行級數據更新，通過原 Hive 回溯和新 Iceberg 回溯兩種方式對比，在一天 24 小時不同分區上，驗證了 Hive 和 Iceberg 新舊的回溯效率，如下圖所示，業務回溯效率整體可平均提升 50%+；進一步地對比單次回溯一年數據消耗的計算資源量對比，平均整體降低 70%+的計算資源消耗，整體上極大提升回溯效率，並降低資源成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ec2f7bfd27359aea682e96ed16bd8438b28.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△ Hive 和 Iceberg 回溯效率對比&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.3 Iceberg 表生命週期管理和性能優化&lt;/h3&gt; 
&lt;p&gt;在 Iceberg 應用實踐的過程中，針對不同業務場景遇到的問題，我們彙總如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件過多：在實時湖倉業務場景，為了要保證數據的時效性，通常是分鐘級別的 commit 操作，在這種場景下，單個作業執行一天，則需要 1440 個 commit，如果執行時間更長，則會產生更多的 commit，隨着時間的累積，元數據以及數據文件等都會產生大量的小文件，對於整體查詢的性能會產生一定的影響。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;存儲資源增加：如果 iceberg 表的快照不及時進行清理，可能會造成數據存儲增加，導致存儲賬號資源緊張。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺乏分區數據統一管理：在一些業務場景，只需要保存一定天數的分區數據，針對無用數據需要進行刪除處理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據文件組織不均衡且無序：由於表數據寫入是隨機無序，且針對表數據文件大小會存在不均衡的情況。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;針對上述問題，我們通過對 Iceberg 表進行全生命週期管理，並結合 Iceberg 特性優化表查詢性能，保障整個數據鏈路的穩定性，整體框架如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6f3d4d018567c082ed09d5addc93eb145e6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表生命週期管理和性能優化流程&lt;/p&gt; 
&lt;p&gt;以上流程主要包含表數據生命週期管理和表性能優化兩部分。&lt;/p&gt; 
&lt;p&gt;一方面，對於表數據生命週期管理，我們通過在線服務執行定時任務，來實現對錶數據和元數據進行全生命週期監控，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;數據分區過期：基於用户配置的表生命週期，進行分區數據刪除，保證數據文件按期清理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元數據快照清理：為用户提供按照時間維度天級別和按照個數維度小時級別兩種快照過期策略，精細化元數據快照過期處理，實現存儲資源的高效利用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元數據孤兒文件清理：通過天級例行任務來觸發清理由於計算引擎執行任務失敗等情況產生的一些沒有被引用的孤兒文件，避免元數據累積影響性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一方面，在表性能優化方面，我們結合圖靈數倉表使用情況，並基於 Iceberg 原生特性，為用户在平台側提供 Iceberg 表優化算子（如下圖示例），主要包含以下兩種能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件合併：通過制定合併文件大小，對錶數據文件進行重寫合併，避免產生大量小文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;z-order 排序優化：實現對錶相關字段進行重排序，提升查詢性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ba76a39d6a2f835b0d8fb1866416f21a652.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表優化算子任務創建示例&lt;/p&gt; 
&lt;p&gt;我們通過對 Iceberg 表整體的生命週期管理，實現了數據和元數據的統一治理，表元數據小文件數萬個降低到數百級別，合理控制了元數據產生的數量，並解決了數據頻繁回溯場景下存儲快速增加的問題。而在表查詢優化方面，通過在一些表的數據重分佈和字段重排序應用，在部分業務表查詢性能提速 50%。&lt;/p&gt; 
&lt;span id="OSC_h1_16"&gt;&lt;/span&gt; 
&lt;h1&gt;03 未來規劃&lt;/h1&gt; 
&lt;p&gt;Iceberg 作為圖靈 3.0 生態中的重要組成部分，基於其高時效性、行級更新能力、小文件合併以及 Z-order 等成體系的數據優化的技術解決方案，為 MEG 數據中台業務提供構建湖倉一體，解決數據回溯等痛點問題的能力。目前 Iceberg 的應用已覆蓋搜索，商業，銷售，用增架構等多個業務線，通過低成本助力業務將存量 Hive 遷移 Iceberg 表，為業務提供高性能數據查詢，同時實現對業務的降本增效。此外，我們也在不斷完善 Iceberg 數據存儲引擎的各項能力，包含表數據智能治理、查詢優化、智能索引以及特定場景的性能問題等，並不斷擴大 Iceberg 的業務覆蓋範圍。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18679436</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18679436</guid>
      <pubDate>Sat, 10 May 2025 10:17:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>RWKV 社區六月動態：多次亮相高規格活動，適合混合架構的新特性發布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;歡迎大家收看《RWKV 社區最新動態》，本期內容收錄了 RWKV 社區 2025 年 6 月的最新動態。&lt;/p&gt; 
&lt;p&gt;只需 3 分鐘，快速瞭解 RWKV 社區 6 月都有哪些新鮮事！&lt;/p&gt; 
&lt;h2&gt;6 月動態省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新聞動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV-8 系列之 DeepEmbedAttention 發佈&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 學術研究動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新論文：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation（基於 RWKV 的醫學視頻生成，已被 &lt;strong&gt;MICCAI 2025 提前接收&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：Pan-Sharpening via Causal-Aware Feature Distribution Calibration（基於 RWKV 的全色鋭化，一區頂刊 &lt;strong&gt;TGRS&lt;/strong&gt; 接收）&lt;/li&gt; 
   &lt;li&gt;新論文：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration（基於 RWKV 的低光照圖像恢復，已入選 &lt;strong&gt;CVPR 2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing（RWKV 的視覺語言模型，發表於 JCR Q1 期刊 Information Fusion）&lt;/li&gt; 
   &lt;li&gt;新論文：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection（遙感變化檢測，IEEE TAES 接收）&lt;/li&gt; 
   &lt;li&gt;新論文：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR（基於 RWKV 的語音識別，Interspeech 2025 接收）&lt;/li&gt; 
   &lt;li&gt;新論文：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV（基於 RWKV 的音樂生成）&lt;/li&gt; 
   &lt;li&gt;新論文：Out-of-Distribution Semantic Occupancy Prediction（引入 RWKV 增強特徵的 3D 語義佔用預測）&lt;/li&gt; 
   &lt;li&gt;新論文：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification（基於 RWKV 的量子增強圖像分類）&lt;/li&gt; 
   &lt;li&gt;新論文：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation（基於 RWKV 的醫學圖像分割）&lt;/li&gt; 
   &lt;li&gt;新論文：Exploring Diffusion with Test-Time Training on Efficient Image Restoration（基於 RWKV 的圖像修復）&lt;/li&gt; 
   &lt;li&gt;新論文：Relational Context Modeling for Improved Knowledge Graph Completion（混合 RWKV 架構的知識圖譜補全）&lt;/li&gt; 
   &lt;li&gt;新論文：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation（基於 RWKV 的醫學圖像分割）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKV-IF: Efficient and Controllable RNA Inverse Folding via Attention-Free Language Modeling（基於 RWKV 的 RNA 逆折疊）&lt;/li&gt; 
   &lt;li&gt;新論文：A Parallel Processing Architecture for Long-Term Power Load Forecasting（基於 RWKV 的長期電力負荷預測）&lt;/li&gt; 
   &lt;li&gt;新論文：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance（集體運動臨界性盲識別）&lt;/li&gt; 
   &lt;li&gt;新論文：融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法（基於 RWKV 的醫學影像分割）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區項目動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;rwkv_Ascend（RWKV 和昇騰共建的算子庫）&lt;/li&gt; 
   &lt;li&gt;rwkv7-g1-1.5b-instruct-preview（RWKV 的後訓練模型）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區市場活動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 參加亞馬遜雲科技中國峯會&lt;/li&gt; 
   &lt;li&gt;RWKV 參加 RTE Open Day&lt;/li&gt; 
   &lt;li&gt;RWKV 參加魔搭開發者大會&lt;/li&gt; 
   &lt;li&gt;RWKV 參加 GAIC 全球互聯網架構大會&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相上海開源創新箐英薈&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相國際技術進出口交易會&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相香港 NovaX 國際創投嘉年華&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 模型新聞動態&lt;/h2&gt; 
&lt;h3&gt;RWKV-8 系列之 DeepEmbedAttention&lt;/h3&gt; 
&lt;p&gt;5 月 27 日，我們公開了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首個新特性 DeepEmbed：對端側友好的稀疏設計，解決 MoE 顯存佔用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;6 月 30 日，與其相關的另一個新特性 DeepEmbedAttention（DEA）也正式公佈。這是一種基於 RWKV-8 DeepEmbed 思路的注意力變體，擁有極小的 KV 緩存，尤其適合混合模型（例如後續的 RWKV-7s 混合模型），可將它們的長上下文性能提升到 Transformer 水準。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="DeepEmbedAttention-loss" src="https://oscimg.oschina.net/oscnet/up-1df5adeb74b9c9eb0c3f35fe35e39185bf0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;詳細報道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;RWKV-8 系列之 DeepEmbedAttention：精簡 KV 緩存，尤其適合混合模型（RWKV-7s）&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RWKV 學術研究動態&lt;/h2&gt; 
&lt;p&gt;RWKV 學術研究包括 &lt;strong&gt;基於 RWKV 架構的新論文&lt;/strong&gt; 或 &lt;strong&gt;RWKV 社區參加的學術研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;FEAT&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.04956" target="_blank"&gt;https://arxiv.org/abs/2506.04956&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型架構中的 WKV 注意力機制，提出了 FEAT 模型，通過統一的空間-時間-通道注意力機制解決醫療視頻生成中通道交互不足、計算複雜度高和去噪指導粗糙的問題。在多個數據集上實現了高效高質量的醫療視頻生成。&lt;/p&gt; 
&lt;p&gt;該項工作十分新穎和出色，已經以 top9% 的評分提前入選 &lt;strong&gt;MICCAI 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250605-FEAT" src="https://oscimg.oschina.net/oscnet/up-467d7594221b6e113f5533aa24c0fe733fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11023855" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11023855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-04&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種新的全色鋭化方法，通過因果推斷解決網絡優化中的頻率不平衡問題。該方法在訓練階段利用 RWKV 架構的全局感受野，有效學習高頻分量的長尾分佈，並量化特徵偏差的累積方向。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，該方法在多個基準數據集上均優於現有先進方法，展示了其在全色鋭化任務中的有效性和魯棒性。&lt;/p&gt; 
&lt;p&gt;文中方法在全色鋭化任務中有出色的表現，已入選一區頂刊 &lt;strong&gt;IEEE Transactions on Geoscience and Remote Sensing&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250604-Pan-Sharpening_via_Causal-Aware_Feature_Distribution_Calibration" src="https://oscimg.oschina.net/oscnet/up-eec12432c41aab67b1095296c7aa214168b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.23068" target="_blank"&gt;https://arxiv.org/abs/2505.23068&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型，提出了一種統一的多狀態視角模型 URWKV，用於低光照圖像恢復。該模型通過定製化的 URWKV 塊感知和分析複雜退化，利用多階段狀態實現自適應場景感知的亮度調製。顯著提升了性能。&lt;/p&gt; 
&lt;p&gt;論文受到廣泛認可，已入選 &lt;strong&gt;CVPR 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-URWKV" src="https://oscimg.oschina.net/oscnet/up-b0e6fa626bfa9e998ebf650bc70d4c9f7ee.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;VisualRWKV-HM&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1566253525004099" target="_blank"&gt;https://www.sciencedirect.com/science/article/pii/S1566253525004099&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="20250606-VisualRWKV-HM" src="https://oscimg.oschina.net/oscnet/up-2d4c04b5430391084f2b0de8de9a7905587.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了 VisualRWKV-HM，這是一種具有線性複雜度的視覺語言模型，在單圖像、多圖像和多視圖基準測試中均達到了 SOTA 性能。&lt;/p&gt; 
&lt;p&gt;與基於 Transformer-Mamba 架構的混合模型 LongLLaVA 相比，它在上下文長度為 16K 時消耗的內存更少，吞吐量提高了 24%。此外，VisualRWKV-HM 具有良好的可擴展性，通過擴展狀態編碼器和解碼器，可以進一步提高性能。&lt;/p&gt; 
&lt;h3&gt;SMNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11039697" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11039697&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型和 Mamba 架構提出了一種新的遙感變化檢測模型 SMNet，該模型通過整合多層次特徵表示，有效解決了當前方法在變化檢測任務中性能有限和特徵表達能力不足的問題。SMNet 利用 RWKV 的多方向 WKV 注意力機制和 Mamba 的空間架構，增強了模型處理語義信息的能力。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，SMNet 在多個遙感變化檢測基準數據集上表現出色，顯著優於現有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250618-SMNet_A_Semantic_Guided" src="https://oscimg.oschina.net/oscnet/up-56b21424d56741e3598d42c23708a33f28e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.19761" target="_blank"&gt;https://arxiv.org/abs/2506.19761&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文研究了將多頭注意力（MHA）替換為雙向循環注意力（RA）在長語音識別（ASR）中的應用，發現雙向 RWKV-Conformer 模型在保持相似準確率的同時，效率更高。通過引入 Direction Dropout 方法，進一步提升了模型的靈活性和性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250624-Accurate,fast,cheap" src="https://oscimg.oschina.net/oscnet/up-9e59775226d89bf420c19693e382a38938d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MIDI-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.13001" target="_blank"&gt;https://arxiv.org/abs/2506.13001&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了 MIDI-RWKV ，一個用於個性化、多軌道、長上下文和可控符號音樂填充的新型模型。該模型採用 RWKV-7 線性架構，能夠在邊緣設備上實現高效且連貫的音樂協同創作。MIDI-RWKV 通過微調初始狀態實現了在極小樣本條件下的個性化。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，MIDI-RWKV 在多項定量和定性指標上均優於現有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-MIDI-RWKV" src="https://oscimg.oschina.net/oscnet/up-059e2194193005d16941dfb46b2a50126d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Out-of-Distribution Semantic Occupancy Prediction&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Out-of-Distribution Semantic Occupancy Prediction&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.21185" target="_blank"&gt;https://arxiv.org/abs/2506.21185&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這篇論文為解決自動駕駛中的"意外"物體識別難題，創新性地引入 RWKV 架構來強化模型的特徵感知力，並提出了 OccOoD 框架。它巧妙融合了精細的 3D 體素和全局的鳥瞰圖視角，能更準確地判斷異常。為了訓練和驗證模型，作者還獨創性地構建了合成異常數據集.&lt;/p&gt; 
&lt;p&gt;實驗結果表明，在不影響常規物體識別性能的前提下，實現了對未知風險的精準捕獲。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250626-Out-of-Distribution Semantic Occupancy Prediction" src="https://oscimg.oschina.net/oscnet/up-541580df9785f32fdb7111c003976df721d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Vision-QRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.06633" target="_blank"&gt;https://arxiv.org/abs/2506.06633&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-07&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種量子增強的混合架構 Vision-QRWKV，用於圖像分類任務。通過將變分量子電路（VQC）集成到 RWKV 的通道混合組件中，模型提升了非線性特徵轉換能力。&lt;/p&gt; 
&lt;p&gt;實驗表明，該模型在多個醫療和標準圖像數據集上表現優於經典模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250607-Vision-QRWKV" src="https://oscimg.oschina.net/oscnet/up-669a60a01e8d0426df73da6bbf8f6477034.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Diet-Seg&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.05.31.657149v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.05.31.657149v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-03&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種新型腦腫瘤分割框架 Diet-Seg，通過將基於熵的像素級難度估計與動態學習率調節策略結合，有效提升了腦腫瘤分割的準確性。Diet-Seg 框架採用 RWKV-UNet 作為主幹網絡，以捕捉全局空間依賴性。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，Diet-Seg 在 BraTS2018--2021 數據集上表現優於現有方法，特別是在腫瘤子區域的分割上取得了顯著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250603-Diet-Seg Dynamic" src="https://oscimg.oschina.net/oscnet/up-4e65bcaea7495f4a3f7ef38e13fafaed70c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DiffRWKVIR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Exploring Diffusion with Test-Time Training on Efficient Image Restoration&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.14541" target="_blank"&gt;https://arxiv.org/abs/2506.14541&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-17&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了 DiffRWKVIR 框架，該框架將測試時訓練（TTT）與高效擴散相結合，通過 Omni-Scale 2D 狀態演化擴展 RWKV 的位置依賴參數化，實現全局上下文感知，並通過塊優化閃存處理加速計算，最終在圖像修復任務中超越現有方法，顯著提升了效率和效果。&lt;/p&gt; 
&lt;p&gt;該論文還提出了先驗引導的高效擴散方法，通過提取緊湊的圖像先驗表示，加速了訓練和推理過程，同時解決了傳統擴散模型中的計算低效問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250617-Exploring Diffusion with Test-Time Training on Efficient Image Restoration" src="https://oscimg.oschina.net/oscnet/up-185f166afa6a20a24ff6dfbff5ca302ec83.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RCME&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Relational Context Modeling for Improved Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.engineeringletters.com%2Fissues_v33%2Fissue_6%2FEL_33_6_28.pdf" target="_blank"&gt;https://www.engineeringletters.com/issues_v33/issue_6/EL_33_6_28.pdf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型和 TuckER 模型，提出了一種名為 RCME 的混合架構，用於改進知識圖譜補全。RCME 結合了 RWKV 的序列建模能力和動態嵌入生成，以及 TuckER 的關係解碼魯棒性，在鏈接預測和三元組分類任務中表現優於多種先進模型。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，該架構在多個基準數據集上均取得了顯著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250601-Relational Context Modeling for Improved" src="https://oscimg.oschina.net/oscnet/up-3df836cf1461d197114ffa8bce7c49241b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Med-URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.10858" target="_blank"&gt;https://arxiv.org/abs/2506.10858&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-12&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了一種名為 Med-URWKV 的純 RWKV 架構，該架構基於 U-Net 框架構建，並融入了基於 ImageNet 的預訓練，以進一步探索 RWKV 在醫學圖像分割任務中的潛力。&lt;/p&gt; 
&lt;p&gt;研究通過在七個數據集上的實驗，驗證了 Med-URWKV 在醫學圖像分割任務中的有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250612-Med-URWKV" src="https://oscimg.oschina.net/oscnet/up-5b67fb50ae77f12d7a02f9c6fa831e31496.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-IF&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.06.13.659654v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.06.13.659654v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種名為 RWKV-IF 的高效可控 RNA 逆折疊框架，通過將結構到序列的生成建模為條件語言建模任務，以線性複雜度捕獲長程依賴關係。研究引入了一種解碼策略，結合 Top-k 採樣、温度控制和 G-C 含量偏向，生成結構準確且具有生物物理意義的序列。顯著優於傳統搜索基線方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250614-RWKV-IF" src="https://oscimg.oschina.net/oscnet/up-a3f69a2c1c24040e3bee2df1570eebd2a19.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MP-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：A Parallel Processing Architecture for Long-Term Power Load Forecasting&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F2673-4591%2F97%2F1%2F26" target="_blank"&gt;https://www.mdpi.com/2673-4591/97/1/26&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV-TS 模型提出了 MP-RWKV，通過並行處理路徑解決長期電力負荷預測中不同預測範圍的挑戰。MP-RWKV 通過上下文狀態機制和位置感知注意力機制，在短期和長期預測場景中均表現出色。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，MP-RWKV 在 24 小時至 432 小時的預測範圍內均優於現有基準模型，尤其在傳統模型性能下降的長期預測中表現突出。顯著提升了長期電力負荷預測的準確性和穩定性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-A Parallel Processing Architecture for Long-Term Power Load Forecasting" src="https://oscimg.oschina.net/oscnet/up-1cd2d5a4b1ab3666aacf1439e4e1a8c45c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Blind Identification&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5297784" target="_blank"&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5297784&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV-7 序列模型提出了一種無參數的集體運動臨界性識別方法，通過分析單智能體軌跡數據來檢測 Vicsek 模型中的臨界區域。&lt;/p&gt; 
&lt;p&gt;該方法利用預測香農熵的方差作為指標，無需系統控制參數或全局信息，成功在 L=32 和 L=64 系統中識別出臨界噪聲水平，且結果符合有限尺寸縮放原理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance" src="https://oscimg.oschina.net/oscnet/up-80916e606288454a3f41baab295cf426a08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biomedeng.cn%2Farticle%2F10.7507%2F1001-5515.202412009" target="_blank"&gt;https://www.biomedeng.cn/article/10.7507/1001-5515.202412009&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種融合接收加權鍵值架構（RWKV）和球面幾何特徵（SGF）採樣技術的甲狀腺結節分割方法。該方法通過二維偏移預測和像素級採樣位置調整，有效捕捉鄰近區域細節，實現精確分割。同時，本研究引入了區塊注意力模塊（PAM），利用區域交叉注意力機制優化解碼器特徵圖，使其更精確關注編碼器的高分辨率特徵。&lt;/p&gt; 
&lt;p&gt;在甲狀腺結節區域分割數據集（TN3K）和甲狀腺影像數字數據庫（DDTI）上的實驗表明，本文所提方法的戴斯相似係數（DSC）分別達到 87.24% 和 80.79%，優於現有模型，且計算複雜度較低，或可為甲狀腺結節精確分割提供一種高效解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法" src="https://oscimg.oschina.net/oscnet/up-ab6be27562fe5cd66667ddfadbe4265a5c9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社區活動&lt;/h2&gt; 
&lt;h3&gt;RWKV 參加亞馬遜雲科技中國峯會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 19 日，RWKV 團隊受邀出席於上海舉辦的亞馬遜雲科技中國峯會，並榮膺「智創未來」領航獎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="AMZ-1" src="https://oscimg.oschina.net/oscnet/up-f86080aa51519b5f93f947f0abf82dddc3c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 參加 RTE Open Day&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 21 日至 22 日，北京，一場屬於技術人的盛會------RTE Open Day 拉開帷幕。RWKV 團隊與來自全國的技術愛好者和開發者們齊聚一堂，展示前沿應用，共話 AGI 的無限可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RTE Openday AGI Playground-3" src="https://oscimg.oschina.net/oscnet/up-b3b31a96ba8288b0c7b1da1bb4fc8d1d81b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 參加魔搭開發者大會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日，在國家信息中心指導、魔搭社區主辦的 2025 魔搭開發者大會上，RWKV 團隊受邀出席。團隊與廣大開發者深入分享了 RWKV 的最新進展與架構的核心亮點，共探 AI 技術的新可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="ModelScope-2" src="https://oscimg.oschina.net/oscnet/up-c4cf19d1c15dd0f606d0a8e16b9b6a283f2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 參加 GAIC 全球互聯網架構大會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 14 日，在全球互聯網架構大會上，RWKV 團隊深度解析了 RWKV 最新架構在精度、顯存佔用及運算速度等方面的核心優勢，並面向公眾分享了簡單易用的基於 RWKV 進行微調、推理與多模態開發的最佳實踐。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="GIAC-1" src="https://oscimg.oschina.net/oscnet/up-62a00f9d678a10835a9faac67b61310ad08.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相上海開源創新箐英薈&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 28 日，RWKV 團隊出席由上海開源信息技術協會主辦的 2025 上海開源創新箐英薈，並憑藉其卓越的技術貢獻和活躍的社區生態，榮獲主辦方頒發的"優秀開源項目獎"。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-1" src="https://oscimg.oschina.net/oscnet/up-059448850eedb205228e74d972e9cc20be4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-2" src="https://oscimg.oschina.net/oscnet/up-1dccb3bfe4475ff6bdb9e7b19d5de026d95.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相國際技術進出口交易會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 11 日至 13 日，RWKV 團隊攜其創新成果亮相上海世博展覽館，出席（上海）國際技術進出口交易會。會上，團隊向與會者展示了 RWKV 在端側部署、低資源消耗及可持續學習等方面的卓越優勢，引發廣泛關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="CSITF-1" src="https://oscimg.oschina.net/oscnet/up-aca0e633ac77f03ce72e551535a52187854.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相香港 NovaX 國際創投嘉年華&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日至 7 月 1 日，RWKV 團隊登陸香港，在 NovaX Global Investmatch Carnival 國際創投嘉年華 2025 的舞台上，與全球頂尖的創投機構和行業領袖齊聚一堂，共同探討 AI 技術的商業前景與未來機遇。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="NovaX-1" src="https://oscimg.oschina.net/oscnet/up-e8e859c258f108b8ebb09921dd3b78b4edb.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社區項目動態&lt;/h2&gt; 
&lt;h3&gt;rwkv_Ascend&lt;/h3&gt; 
&lt;p&gt;cann-ops-rwkv 是 RWKV 與昇騰共建的算子倉庫，歡迎 rwkv 愛好者學習、使用和魔改的 RNN attention（rwkv、fla）系列算子代碼。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;項目地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fappleinsky%2Frwkv_Ascend" target="_blank"&gt;https://github.com/appleinsky/rwkv_Ascend&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;rwkv7-g1-1.5b-instruct-preview&lt;/h3&gt; 
&lt;p&gt;此項目是 RWKV7-G1 1.5B 的後訓練模型，強化了指令遵循能力和中文能力，同時擁有更高的情商。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FSeikaijyu%2Frwkv7-g1-1.5b-instruct-preview" target="_blank"&gt;https://hf-mirror.com/Seikaijyu/rwkv7-g1-1.5b-instruct-preview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="RWKV7-G1-1.5B-instruct" src="https://oscimg.oschina.net/oscnet/up-beed0d3d6a0e327fb38fe4d0b43057e9996.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358194</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358194</guid>
      <pubDate>Sat, 10 May 2025 08:39:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Ubuntu Debcrafters 團隊成立，旨在維護 Ubuntu 檔案庫健康</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Canonical 工程副總裁 Jon Seager 發文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fintroducing-debcrafters%2F63674" target="_blank"&gt;宣佈&lt;/a&gt;&amp;nbsp;Ubuntu Debcrafters 團隊的成立。主要目標在於維護 Ubuntu 檔案庫的健康，但也旨在吸引廣泛的 Linux 發行版專業人才。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 表示，其鼓勵 Debian、Arch Linux、NixOS 等發行版的貢獻者加入 Debcrafters&amp;nbsp;團隊，貢獻的同時還可以獲得報酬，並促進學習和想法共享。該團隊由 Debian 開發人員、穩定版本更新 (SRU) 團隊成員和檔案管理員組成，並於 2025 年 5 月初首次開始合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-0e0b14cf8de1e9a97b9c9dba65bf6513bb0.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 在 Debcrafters 公告中解釋道：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;Debcrafters 的主要使命是維護 Ubuntu 檔案的健康。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;該團隊將負責同步和合並來自 Debian 的軟件包、審查提議的遷移問題、上游 Ubuntu 增量，並負責重大轉變，例如升級到 glibc 和過去的示例，例如 t64 和 python3 轉變。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他們將管理存檔測試重建的調度、觸發和報告，這些重建工作在我們對關鍵軟件包進行重大更改時進行。我們在默認啓用框架指針時以及切換 coreutils 到 uutilsUbuntu 25.10 中的實現時都執行了這些操作。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他們將負責 autopkgtestUbuntu 基礎架構的演變和維護，並在引入更多發行版規模的集成測試方面發揮重要作用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他們將致力於改進 Ubuntu 檔案庫、其貢獻者和狀態的報告和儀錶板，並對塑造我們用於構建和塑造 Ubuntu 的工具產生更廣泛的興趣。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;這支團隊與桌面、服務器和基礎團隊的不同之處在於，他們處理的軟件包範圍非常廣泛。Debcrafters 團隊的成員每個週期都會遷移數千個軟件包——其中許多軟件包他們並不十分熟悉，但他們將運用不斷提升的發行版維護和打包技能，在沒有其他明確或現有所有者的情況下進行維護。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358188/ubuntu-debcrafters</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358188/ubuntu-debcrafters</guid>
      <pubDate>Sat, 10 May 2025 08:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟被曝將「AI 使用量」納入員工考核，直接掛鈎績效</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-internal-memo-using-ai-no-longer-optional-github-copilot-2025-6" target="_blank"&gt;根據《商業內幕》的報道&lt;/a&gt;，微軟開發者工具部門總裁 Julia Liuson 最近發出內部郵件，要求各級主管在評估員工績效時，將其使用 GitHub Copilot 等內部 AI 工具的情況納入考量。&lt;/p&gt; 
&lt;p&gt;Liuson 表示，AI 已成為微軟日常工作的核心，就像團隊協作、數據導向思維和溝通能力一樣，使用 AI 不再是選擇題，而是每個崗位的基本要求。她指出，員工是否有效使用 AI，應該被納入對其整體表現和影響力的全面評估之中。&lt;/p&gt; 
&lt;p&gt;具體執行框架如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;基礎合規層&lt;/strong&gt; ：要求員工在郵件撰寫、會議記錄、代碼開發等高頻場景 100% 啓用 Copilot 基礎功能，系統自動記錄使用時長和任務覆蓋率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;效能增值層&lt;/strong&gt; ：按崗位類型設定差異化 KPI，如開發人員需實現 30% 代碼由 Copilot 生成，銷售部門需達成 AI 優化提案的成交率提升指標。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;創新應用層&lt;/strong&gt; ：將員工使用 Copilot 開發新工作流程或業務解決方案的實踐成果，納入晉升評估加分項。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;知情人士透露，微軟各團隊的績效考核標準不盡相同，目前已有部分團隊考慮在下一個財年正式將 AI 工具使用情況作為績效指標之一。另據兩位瞭解內情的人士稱，這一改變旨在應對微軟內部 Copilot 服務推廣緩慢的問題。微軟希望提升整體使用率，也希望產品開發人員更深入理解自家 AI 工具的運作方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</guid>
      <pubDate>Sat, 10 May 2025 08:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 將其 AI 部門重組為 「超級智能實驗室」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 公司首席執行官馬克-扎克伯格（Mark Zuckerberg）正在重組公司的人工智能工作，以打造人工智能 「superintelligence」為中心。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fzuckerberg-announces-meta-superintelligence-effort-more-hires%3Fsrnd%3Dundefined" target="_blank"&gt;彭博社&lt;/a&gt;報道，其從該公司於週一發出的一份內部備忘錄得知，Meta 公司所有從事人工智能工作的團隊今後都將隸屬於一個名為 Meta 超級智能實驗室（Meta Superintelligence Labs）的新團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="366" src="https://oscimg.oschina.net/oscnet/up-44145dfdb97dd1159efb1314b8297ede5e1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「超級智能實驗室」 將由前 Scale AI 首席執行官亞歷山大・王（Alexandr Wang）擔任首席人工智能官，負責整體方向與管理。他將與 GitHub 前首席執行官納特-弗裏德曼（Nat Friedman）合作，後者將負責 Meta 的人工智能產品和應用研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格一直在努力在人工通用智能（AGI）競賽中取得領先，主要是通過收購人工智能公司和頂級人工智能公司的員工。本月早些時候，Meta 向 Scale AI 投資了 143 億美元，並在此過程中引入了 Wang。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers" target="news"&gt;Meta 成功挖角三名 OpenAI 研究人員&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357940" target="news"&gt;OpenAI 被曝將重新調整薪酬以應對 Meta 挖人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358181/meta-superintelligence-labs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358181/meta-superintelligence-labs</guid>
      <pubDate>Sat, 10 May 2025 07:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟開源 GitHub Copilot Chat 的 VS Code 擴展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟在 5 月舉辦的開發者大會上&lt;a href="https://www.oschina.net/news/350732/ms-vs-code-open-source-ai-editor"&gt;宣佈&lt;/a&gt;要將 VS Code 打造成開源 AI 編輯器，近日該計劃達成了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fblogs%2F2025%2F06%2F30%2FopenSourceAIEditorFirstMilestone" target="_blank"&gt;首個里程碑&lt;/a&gt;——GitHub Copilot Chat 的 VS Code 擴展采用 MIT 開源許可證正式開源。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1098" src="https://static.oschina.net/uploads/space/2025/0701/153012_qXMd_2720166.png" width="2460" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-chat" target="_blank"&gt;https://github.com/microsoft/vscode-copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該擴展提供了類似 Cursor 的 Chat 面板，通過聊天的方式來編輯代碼，它還可以根據代碼提交者、變量和斜線命令等信息，給出與代碼庫相關的回答。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a176b7fa906f848e0f9b0982762510cc49.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-190bfc8a0cc77c524892684d44d95a0f15c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;擴展地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat" target="_blank"&gt;https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;由於 Copilot Chat 與 VS Code 深度集成，其發佈與 VS Code 同步進行，因此每個新版本的 Copilot Chat 僅兼容最新版本的 VS Code。這意味着如果你使用的是舊版本的 VS Code，將無法使用最新的 Copilot Chat。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358178</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358178</guid>
      <pubDate>Sat, 10 May 2025 07:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節、騰訊、阿里等 13 家頭部企業去年利潤總額同比增 19.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;5 月底結束的 2024 年度企業所得税彙算清繳數據顯示，字節跳動、騰訊、阿里巴巴等 13 家頭部企業營業收入和利潤總額同比分別增長 11.9%、19.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上述企業是數字經濟領域的代表企業，彙算清繳數據顯示，2024 年度，數字經濟及其核心產業營業收入和利潤總額同比分別增長 5.9%、2.7%。其中，信息傳輸、軟件和信息技術服務業營業收入和利潤總額同比分別增長 11.5%、13.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除數字經濟外，2024 年度，醫藥製造、航空航天等高技術產業營業收入和利潤總額同比分別增長 8.9%、7.5%。細分行業看，科學研究和技術服務業營業收入和利潤總額同比分別增長 11.7%、7.5%，航空航天產業營業收入和利潤總額同比分別增長 10.5%、26.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，機器人產業也步入發展快車道，近兩年機器人產業營業收入平均同比增長 10.2%。其中，特殊作業機器人、服務消費機器人、工業機器人 2024 年度同比分別增長 28.4%、12.4%、7%，多場景應用加速落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;總體上看，數字經濟、高技術產業、機器人產業三個領域 2024 年度共減免企業所得税 1.97 萬億元，總營業收入同比增長 7.1%，利潤總額同比增長 5.2%，我國新質生產力持續發展壯大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家税務總局相關負責人表示，税務部門將不折不扣落實落細結構性減税降費政策，同時，依法嚴厲打擊違規享受、惡意騙取税費優惠等違法行為，堅決防止政策「紅包」落入不法分子「腰包」。（新京報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358163</guid>
      <pubDate>Sat, 10 May 2025 06:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻數科面向香港市場開放四大自研技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻數科面向香港市場開放四大自研技術——Layer2 網絡、大模型開發工具、「區塊鏈+IoT」可信架構、機構級 Web3 錢包技術，為香港建設全球數字資產創新中心提供全棧技術服務。&lt;/p&gt; 
&lt;p&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-e94b03fe5b81530ba178b109352a29a4037.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;資料顯示，螞蟻數科自 2016 年起投入區塊鏈技術研發，全球區塊鏈授權專利排名第一，核心技術如智能合約、網絡傳輸、存儲引擎、跨鏈技術等已取得重大突破，處於全球領先水平。此前，螞蟻數科作為核心成員加入香港金管局 Ensemble 沙盒，並宣佈將海外總部落户香港。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358160</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358160</guid>
      <pubDate>Sat, 10 May 2025 05:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>加鎖失效，非鎖之過，加之錯也</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：京東零售，邢成&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;多個進程或線程同時 (或着説在同一段時間內) 訪問同一資源會產生併發問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;銀行兩操作員同時操作同一賬户就是典型的例子。比如 A、B 操作員同時讀取一餘額為 1000 元的賬户，A 操作員為該賬户增加 100 元，B 操作員同時為該賬户減去 50 元，A 先提交，B 後提交。 最後實際賬户餘額為 1000-50=950 元，但本該為 1000+100-50=1050。&lt;strong&gt;這就是典型的併發問題&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;從事零售供應鏈庫存業務，對庫存數量操作增減十分頻繁，同樣存在類似上述銀行取款遇到的問題，庫存數量操作有誤勢必給前台銷售產生損失影響，因此需要關注對庫存數量併發操作下的一致性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;下面通過一個真實的案例分享在併發情況下如何保證庫存數量的準確性。&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;問題是什麼-加鎖失效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;看看下面這段流程和代碼，思考會有併發問題嗎？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c52b6c3f660ed58046c9e16a5be9c444.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;加鎖前&lt;/strong&gt; &lt;strong&gt;，獲取箱子明細數據，此處在鎖之外，存在併發髒讀問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//1036ef25fae37b26c448522f6777c80c.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;加鎖後&lt;/strong&gt; &lt;strong&gt;，並進行箱子上架分批次回傳業務處理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//020a84a9615ca8e8cec22118aefca76f.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;加鎖後，&lt;/strong&gt; &lt;strong&gt;更新箱子明細上架數量邏輯：已上架數量 = 加鎖前的明細數據（髒讀） + 報文回傳的明細數據，直接進行行更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//21d80ae4a594960a582dde2c19321099.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;原因是什麼-加鎖的位置不正確&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//20d9ce564f5386039bb12242e16ef05b.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心的問題原因&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;業務分佈式鎖失效：&lt;/strong&gt; 使用分佈式鎖加鎖了，但是仍然使用加鎖前查詢的數據，導致出現髒讀&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;Mysql 鎖失效：&lt;/strong&gt; 數據庫更新時，未上任何鎖，導致髒讀的數據直接覆蓋更新當前行&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有同學這時問了，為啥防重碼也沒有生效呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;防重碼主要是用作冪等邏輯的，同一個請求多次處理，結果仍然是相同的。&lt;/p&gt; 
&lt;p&gt;但是這是兩次不同的請求，防重碼是不同的，因此不能只依賴防重碼保證一致性。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;解決方案有哪些&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1、代碼層面：&lt;/strong&gt; 使用鎖（如互斥鎖、讀寫鎖、分佈式鎖等）來控制資源的訪問，數據獲取的全部操作都需要再獲取鎖後才進行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;將獲取箱子明細的代碼移動到加鎖之後，只有獲取到分佈式鎖，才能執行分批次上架查詢和更新（串行化）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5ffc0121557805521cbb33921c4be06a.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;對應改造後的代碼：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//751c2001d8d70843f24dcf8b6fa5eaa6.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、數據庫層面：&lt;/strong&gt; 實現事務管理，確保數據的一致性；合理設置事務隔離級別，以防止髒讀、或者採用樂觀鎖或悲觀鎖來處理併發更新，合理設計查詢效率，減少鎖競爭。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;數據庫的併發上鎖處理和業務代碼的上鎖是互補的關係&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;因為無法保證後續業務的調整或其他業務代碼的調用能始終保持獲取數據的一致性，數據庫的併發上鎖處理更多是一種兜底保證機制。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;樂觀鎖更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e4262e1d681aa19763c8066296032481.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;悲觀鎖更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4078a93beef3c9b077595bb8968b3a5d.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;擴展方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;應用程序設計：&lt;/strong&gt; 在應用程序設計階段，儘量避免長時間持有數據庫連接或事務，減少併發操作的可能性，利用 AI 代碼評審或者人工提前找出可能出現併發問題的地方；合理設置鎖的粒度，避免鎖失效。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;網絡負載層面：&lt;/strong&gt; 採用限流控制訪問頻率；採用分佈式數據庫，進行數據分片，降低單節點併發壓力；使用負載均衡，將網絡請求分發到不同的服務器，提高系統處理併發的能力，防止系統過載。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;請求層面：&lt;/strong&gt; 前端點擊防重、系統冪等防重、儘可能降低同一請求的多次重試訪問引起的一致性問題。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;通過以上措施，可以在不同層面有效地防止併發問題，保證系統的數據的一致性。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18638221</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18638221</guid>
      <pubDate>Sat, 10 May 2025 03:26:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>通義千問 Qwen-TTS 新增支持北京話、上海話和四川話中文方言</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通義千問團隊更新並&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-VDOJrDgVzC6JI4CVTHe4w" target="_blank"&gt;上線&lt;/a&gt;了 Qwen-TTS 文本轉語音服務，&amp;nbsp;新增支持生成三種中文方言，包括北京話、上海話和四川話。&lt;/p&gt; 
&lt;p&gt;據介紹，Qwen-TTS 使用了超過 300 萬小時的大規模語料庫進行訓練，合成效果達到了人類級別的自然度和表現力，旨在提供超自然、富有表現力的音頻，並能智能處理韻律、語速和情感。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Qwen-TTS 能夠根據輸入文本自動調整韻律、節奏和情緒變化，進一步提升語音的真實感和表達力。&lt;/p&gt; 
&lt;p&gt;目前，Qwen-TTS 支持七種中英雙語音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京話）、Jada（上海話） 和 Sunny（四川話）。未來，我們還將推出更多語言和語音風格，進一步豐富用户的選擇體驗。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fblog%2Fqwen-tts%2F" target="_blank"&gt;https://qwenlm.github.io/blog/qwen-tts/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358128/qwen-tts</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358128/qwen-tts</guid>
      <pubDate>Sat, 10 May 2025 03:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>消息稱蘋果考慮讓 Anthropic 和 OpenAI 為 Siri 提供支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#212623"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fapple-weighs-replacing-siri-s-ai-llms-with-anthropic-claude-or-openai-chatgpt" target="_blank"&gt;彭博社&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;報道稱，蘋果正在考慮使用 OpenAI 和 Anthropic 的 AI 模型來支持其更新版 Siri，而不是使用該公司內部開發的技術。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="329" src="https://oscimg.oschina.net/oscnet/up-b75a8d1cc618ffd03df5516bae4e561bc31.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息指出，蘋果公司正在繼續構建一個名為「LLM Siri」的內部項目，該項目使用內部 AI 模型。但該公司已要求 OpenAI 和 Anthropic 訓練其可在蘋果雲基礎設施上運行的 AI 模型版本，以供測試。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由於一系列技術挑戰，蘋果被迫將原定於 2025 年發佈的人工智能 Siri 推遲到 2026 年或更晚。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這一失敗或許由來已久；過去幾年，蘋果在 AI 競賽中一直落後於谷歌、OpenAI 和 Anthropic。雖然 Siri 已經可以調用 ChatGPT 來回答難題，但蘋果現在似乎正在探索與第三方 AI 提供商的技術進行更深入的整合。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358124</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358124</guid>
      <pubDate>Sat, 10 May 2025 02:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程助手 Cursor 提供 Web 和移動端版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程助手 Cursor &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fcn%2Fblog%2Fagent-web" target="_blank"&gt;推出&lt;/a&gt;&lt;/u&gt;了可在網頁和移動設備上使用的 AI Agent 功能。用户現在可以通過瀏覽器或手機隨時啓動複雜的編碼任務，例如修復錯誤或進行代碼庫問答，並讓 Agent 在後台運行。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1522" src="https://static.oschina.net/uploads/space/2025/0701/102654_ieGo_2720166.png" width="1684" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1078" src="https://static.oschina.net/uploads/space/2025/0701/102948_z9W9_2720166.png" width="1398" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任務完成後，用户可以在桌面端的 Cursor IDE 中無縫銜接，審查、合併代碼修改，或與團隊成員分享鏈接進行協作。&lt;/p&gt; 
&lt;p&gt;該功能支持並行執行，用户可以同時啓動多個使用不同模型的 Agent，並比較結果以選擇最佳方案。為了獲得更好的移動端體驗，Cursor 支持安裝為漸進式網絡應用（PWA），從而實現推送通知、全屏界面和離線查看等原生應用體驗。此外還集成了 Slack，用户可以直接在 Slack 中通過提及@Cursor 來觸發 Agent。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2c82f625dd429efeb71a6d75f6189dbb4bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;定價方面，網頁和移動端 Agent 與 Background Agents 採用相同的模式，目前運行計算本身免費，僅根據用户選擇的 AI 模型收取使用費。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.cursor.com%2Fget-started%2Fweb-and-mobile-agent%23slack-integration-not-working" target="_blank"&gt;詳情查看文檔&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358117/cursor-web-and-mobile-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358117/cursor-web-and-mobile-agent</guid>
      <pubDate>Sat, 10 May 2025 02:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 澄清與谷歌芯片傳聞：並無大規模合作計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;日前，有報道稱&amp;nbsp;OpenAI 正轉向其競爭對手的 AI 芯片以滿足日益增長的需求。對此，OpenAI 對外發布聲明，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.com%2Fen-us%2Fnews%2Ftechnology%2Fopenai-says-it-has-no-plan-to-use-googles-in-house-chip%2Far-AA1HItOZ%3Focid%3DBingNewsSerp" target="_blank"&gt;否認&lt;/a&gt;了媒體有關其計劃採用谷歌自研芯片的報道。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 的一位發言人表示，儘管該公司正在對谷歌的張量處理單元（TPU）進行早期測試，但目前並沒有大規模使用這些芯片的打算。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="378" src="https://oscimg.oschina.net/oscnet/up-d1a613253026c0819f2d66ccaa58bfeeeac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在人工智能領域，實驗室測試各種芯片的情況十分普遍，但要實現新硬件的大規模應用通常需要較長時間。此外，這也涉及到不同的架構和軟件支持，難度不小。OpenAI 表示，目前正積極使用英偉達的圖形處理器（GPU）和 AMD 的人工智能芯片，以滿足日益增長的計算需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，OpenAI 也在研發自己的芯片，預計將在今年達到 「定型」 里程碑，屆時這些芯片的設計將最終確定並投入生產。此前有報道稱，OpenAI 已與谷歌雲服務達成合作協議，以滿足其不斷增長的計算能力需求。這一合作被認為是人工智能領域兩個主要競爭對手之間的一次意外聯手。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管 OpenAI 在計算能力方面的主要來源將是由新興雲公司 CoreWeave 提供支持的 GPU 服務器，谷歌也在積極擴大其自研人工智能芯片（TPU）的外部可用性。TPU 芯片之前主要用於谷歌的內部項目，但現在也開始吸引包括蘋果在內的其他科技巨頭以及一些初創公司的關注，如 Anthropic 和 Safe Superintelligence，這些公司都是 OpenAI 的競爭對手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358116</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358116</guid>
      <pubDate>Sat, 10 May 2025 02:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包上線「深入研究」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;豆包「深入研究」功能已經在豆包 App、網頁版及電腦版正式開啓測試，用户可免費體驗。&lt;/p&gt; 
&lt;p&gt;基於模型的搜索、推理及 Agent 能力，「深入研究」可以幫助用户更快速、全面和結構化地處理高難度的複雜任務。針對長途旅行攻略、複雜購買決策、最新政策解讀、商業科技趨勢發展等需要獲取大量資料、長時間研究的問題，藉助「深入研究」能力，幾分鐘即可完成初步方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9f6c1c14ffd9352f40ee1c98040fd7cff53.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，豆包還支持以可視化網頁和報告文檔兩種方式呈現研究結果。&lt;/p&gt; 
&lt;p&gt;據介紹，將豆包更新至最新版後，打開 App 或電腦版，選擇「深入研究」，輸入詳細指令或一句話 prompt，等待幾分鐘，即可生成一份報告。使用豆包 App 生成報告後，還可以打開報告內容，選擇右上角「聽」按鈕，一鍵轉成播客，隨時聽。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358039</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358039</guid>
      <pubDate>Fri, 09 May 2025 11:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>德國要求蘋果和谷歌從應用商店下架 DeepSeek</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fsustainability%2Fboards-policy-regulation%2Fdeepseek-faces-expulsion-app-stores-germany-2025-06-27%2F" target="_blank"&gt;據路透社報道&lt;/a&gt;，德國數據保護專員梅克·坎普發佈聲明，宣稱已要求蘋果和谷歌公司從其在德國的應用商店中下架中國初創公司自主研發的人工智能（AI）大語言模型「深度求索」（DeepSeek）的應用。他給出的理由是所謂的數據安全擔憂。&lt;/p&gt; 
&lt;p&gt;坎普在聲明中指控 DeepSeek「非法將用户個人數據傳輸至中國」，並要求蘋果與谷歌儘快審查這一要求，以決定是否在德國封禁該應用，不過並未設定具體的處理時限。&lt;/p&gt; 
&lt;p&gt;媒體報道顯示，谷歌公司證實已收到相關通知，目前正在進行評估；而蘋果公司則暫未對此作出回應。&lt;/p&gt; 
&lt;p&gt;此前，DeepSeek 也因所謂數據安全問題，在歐美多地遭遇審查。另據媒體報道，意大利已於今年稍早以「個人數據使用不透明」為由，將 DeepSeek 應用從應用商店下架；荷蘭則禁止政府設備使用該應用；比利時也建議政府官員避免使用 DeepSeek，並表示相關評估仍在進行中。與此同時，美國國會議員正計劃提出法案，禁止聯邦政府機構使用任何中國開發的 AI 模型。&lt;/p&gt; 
&lt;p&gt;針對部分國家傳出禁止或限制使用 DeepSeek 的消息，中國外交部發言人此前已作出回應。在今年 2 月 6 日的例行記者會上，外交部發言人表示，中國政府始終高度重視數據隱私和安全保護，並依法開展相關工作，從未要求且將來也不會要求企業或個人以違法形式採集或存儲數據。&lt;/p&gt; 
&lt;p&gt;此外，在今年 3 月 18 日的例行記者會上，另一位外交部發言人再次強調，中方一貫反對泛化國家安全概念、將經貿科技問題政治化的做法，並將堅定維護中國企業的合法權益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358029</guid>
      <pubDate>Fri, 09 May 2025 10:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV-8 系列之 DeepEmbedAttention：精簡 KV 緩存，尤其適合混合模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月 27 日，我們公開了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首個新特性 DeepEmbed：對端側友好的稀疏設計，解決 MoE 顯存佔用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;今天，我們公開與其相關的另一個新特性：&lt;strong&gt;DeepEmbedAttention（DEA）&lt;/strong&gt; ，這是一種基於 RWKV-8 的 DeepEmbed 思路構建的注意力變體，擁有&lt;strong&gt;極小的 KV 緩存&lt;/strong&gt; ，尤其適合&lt;strong&gt;混合模型&lt;/strong&gt;（例如後續的 RWKV-7s 混合模型），可將它們的長上下文性能提升到 Transformer 水準。&lt;/p&gt; 
&lt;p&gt;DEA 的結構定義例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# q: D =&amp;gt; 256
# k: D =&amp;gt; 32, k_up: 32 =&amp;gt; 256, k_emb: V =&amp;gt; 256
# v: D =&amp;gt; 32, vup: 32 =&amp;gt; D, v_emb: V =&amp;gt; D
q = ln_q(q(x))
k = ln_k(k_up(k(x)) * k_emb(idx))
v = ln_v(tanh(v_up(v(x))) * v_emb(idx))   
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然後將 QKV 的輸出加到 RWKV-7 的輸出上。這適合並行計算，例如可在不同設備（或異構計算）計算 QKV 和 RWKV-7 部分。&lt;/p&gt; 
&lt;p&gt;這個注意力頭的維度是 256，但由於 DEA 的 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; 只需緩存 32 維，KV 總共只需緩存 64 個值（32+32）。&lt;/p&gt; 
&lt;p&gt;對於 RWKV-7，只需在每層加上一個 DEA head，就能顯著增強長上下文能力。因此，對比現有的高效注意力機制（例如 MLA 使用 576 個值），&lt;strong&gt;DEA 的 KV 緩存進一步縮小到 64/576 = 1/9&lt;/strong&gt;，實現了極致效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c7be8702b07a9534c09539a5fa78e2cdc44.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖中 loss delta 圖的橫軸是隨着前文長度增加時 token 的位置（token_pos），縱軸表示兩種架構在不同 token 位置的 loss 差值（token_loss delta）。&lt;/p&gt; 
&lt;p&gt;實驗結果顯示：隨着前文長度增加，RWKV-7s（加入 DeepEmbed 和 DEA）在越來越長前文的 loss &lt;strong&gt;相較原版 RWKV-7 持續下降&lt;/strong&gt;，從 -0.13 降至 -0.17。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;這意味着 RWKV-7s 這類添加了 DEA 的混合模型，在處理長上下文時表現更好。因為 token 越靠後，所依賴的前文也越長，而 loss 差值持續擴大，代表 RWKV-7s 對比 RWKV-7 更有能力利用越來越長的前文所包含的越來越多的信息，語言建模能力越來越強。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;最後，儘管 DEA 的 KV 緩存非常小，但它仍會隨上下文長度而緩慢增長。&lt;strong&gt;RWKV-8 的目標，是在完全無 KV 緩存的情況下也能實現強上下文能力&lt;/strong&gt;，且我們也有方法，後續逐步公佈，歡迎大家關注。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358026</guid>
      <pubDate>Fri, 09 May 2025 10:11:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>歐洲首台百萬兆次級超級計算機 JUPITER 啓用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;位於德國的於利希超級計算中心（Jülich Supercomputing Center）近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspectrum.ieee.org%2Fjupiter-exascale-supercomputer-europe" target="_blank"&gt;推出&lt;/a&gt;了歐洲首台百萬兆次級超級計算機 JUPITER (木星)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-37c973b7767f9f8d83e4f3ade8a1fabef7f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;JUPITER 於 2025 年 6 月首次亮相於全球最強大計算機系統的 TOP500 排行榜上，位列第四。它擁有 5900 個加速計算節點，配備了約 24000 顆 Nvidia Grace-Hopper&amp;nbsp;超級芯片和 1300 個使用 Rhea1 處理器的節點。此外，JUPITER 還採用了 InfiniBand NDR 網絡來確保高速數據傳輸。該計算機的設計旨在支持複雜的科學計算任務，推動氣候模型和天氣預報的研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這個項目旨在創建一個地球系統的數字複製品，以更好地監測和預測自然現象與人類活動的相互作用。研究者們表示，需要這樣一台大型機器來處理氣候和大氣數據，JUPITER 能以 700 米的分辨率展示這些物理現象，從而為氣象學和氣候科學提供更深入的洞察。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，德國伊爾梅瑙工業大學的物理學家們也在利用 JUPITER 進行研究。他們專注於可視化熱羽流，探討流體和氣體的對流與湍流現象。科學家們通過這台超級計算機的強大運算能力，能夠呈現出以前無法獲得的細節，進一步理解自然界中複雜的流動模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;JUPITER 的建設始於 2018 年，經過多次升級和完善，在 2024 年計劃推出的 JEDI 原型機和 JETI 過渡系統模塊的支持下，最終在 2025 年全面投入使用。該計算機的能效設計也備受關注，其製冷系統利用附近的魯爾河水，為校園建築提供取暖，展現出對能源消耗的關注和可持續發展理念。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358021/jupiter-exascale-supercomputer-europe</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358021/jupiter-exascale-supercomputer-europe</guid>
      <pubDate>Fri, 09 May 2025 09:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>JSON Crack —— 將 JSON 可視化為交互式圖表</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;JSON Crack 是一款以結構化交互式圖表形式可視化 JSON 數據的工具，方便用户探索、格式化和驗證 JSON。它提供多種功能，例如將 JSON 轉換為其他格式（CSV、YAML）、生成 JSON Schema、執行查詢以及將可視化結果導出為圖像。其設計兼顧了可讀性和易用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可視化工具&lt;/strong&gt;：立即將 JSON、YAML、CSV、XML 和 TOML 轉換為暗模式或亮模式下的交互式圖形或樹。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轉換&lt;/strong&gt;：無縫轉換數據格式，如將 JSON 轉換為 CSV 或將 XML 轉換為 JSON，以便於共享。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;格式化和驗證&lt;/strong&gt;：美化和驗證 JSON、YAML 和 CSV 以獲得清晰準確的數據。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代碼生成&lt;/strong&gt;：生成 TypeScript 接口、Golang 結構和 JSON 模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JSON Schema&lt;/strong&gt;：創建 JSON Schema、模擬數據並驗證各種數據格式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高級工具&lt;/strong&gt;：解碼 JWT、隨機化數據以及運行 jq 或 JSON 路徑查詢。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;導出圖像&lt;/strong&gt;：將你的可視化效果下載為 PNG、JPEG 或 SVG。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隱私&lt;/strong&gt;：所有數據處理都是本地的；服務器上不會存儲任何內容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="438" src="https://static.oschina.net/uploads/space/2025/0630/164831_2A2G_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/jsoncrack</link>
      <guid isPermaLink="false">https://www.oschina.net/p/jsoncrack</guid>
      <pubDate>Fri, 09 May 2025 09:20:00 GMT</pubDate>
    </item>
  </channel>
</rss>
