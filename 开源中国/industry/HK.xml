<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 17 Feb 2025 16:36:09 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>OpenAI 對 GPT-4o 模型進行更新</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI CEO 薩姆・奧特曼在社交平台 X 上表示，該公司對 GPT-4o 進行了更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1f3df4ef62755ac81ca803cc24807853ec5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，GPT – 4o 的表現非常出色，在評論區他還説道，&lt;strong&gt;GPT–4o 是「網上最好的搜索產品之一」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;根據相關測試數據，GPT-4o 更新後性能相當強悍，從 Lmarena 競技榜的第 5 名上升至第 1 名，而且是全方位的領先。從總體情況、創意寫作、編碼、指令遵循、長提示到多輪對話。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7e1a2d8ec03fcda8d64e38cf2bd2b4c962d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 於去年 5 月發佈了 GPT-4o，其中的「o」代表「omni」（即全面、全能的意思），這個模型同時具備文本、圖片、視頻和語音方面的能力，甚至就是 GPT-5 的一個未完成版。&lt;/p&gt; 
&lt;p&gt;而在同年 7 月，OpenAI 官宣推出 GPT-3.5 Turbo 的替代品——GPT-4o mini，這是 GPT-4o 更小參數量的簡化版本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334403</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334403</guid>
            <pubDate>Fri, 07 Feb 2025 11:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「AI 公務員」來了！廣東深圳首批 70 名正式上崗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;廣東深圳福田區日前推出基於 DeepSeek 開發的 AI 數智員工，上線福田區政務大模型 2.0 版，除了有 DeepSeek 通用能力外，還結合各部門各單位實際業務流程，量身定製個性化智能體，首批滿足 240 個業務場景使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;253&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-046e1231afd4b4ffadd892d508d61fea619.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據悉，福田區政務大模型 2.0 版以全尺寸 DeepSeek R1 為核心底座，憑藉混合專家架構（MoE）與強化學習技術，有效破解傳統政務大模型算力消耗高、響應不穩定和專業性不足的痛點，依託國產算力平台實現本地化細分領域訓練，確保符合不同行業不同單位的具體需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，福田區已上線 11 大類 70 名「數智員工」，覆蓋政務服務全鏈條。通過 240 個政務場景終端的精準解析，覆蓋公文處理、民生服務、應急管理、招商引資等多元場景。個性化定製生成時間從 5 天壓縮至分鐘級。公文格式修正準確率超 95%，審核時間縮短 90%，錯誤率控制在 5% 以內。「AI 任務督辦助手」跨部門任務分派效率提升 80%，按時完成率提升 25%。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334385</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334385</guid>
            <pubDate>Fri, 07 Feb 2025 09:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國科技「7 巨頭」已悄然形成：阿里/騰訊/美團/中芯/小米/聯想/比亞迪</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;美國有科技 7 姐妹（蘋果、谷歌、亞馬遜、微軟、Meta、特斯拉、英偉達），那麼中國對飆的 7 巨頭也隨之而來。&lt;/p&gt; 
&lt;p&gt;多家機構給出的報告顯示，中國科技股七巨頭已經悄然形成，其分別是：&lt;strong&gt;小米、聯想、比亞迪、中芯國際、阿里巴巴、騰訊、美團&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;這七家公司涵蓋&lt;strong&gt;硬件製造、雲計算、半導體、智能終端、本地生活&lt;/strong&gt;等核心領域，其中以騰訊市值 4.3 萬億港元居首。&lt;/p&gt; 
&lt;p&gt;報告指出，以蘋果、谷歌、亞馬遜、微軟、Meta、特斯拉、英偉達為代表的科技七巨頭憑藉穩健的業績增長和在 AI 等前沿領域持續創新，已成為美股科技核心資產。&lt;/p&gt; 
&lt;p&gt;受到 AI 人工智能的風口催化，上述中國 7 巨頭的股價都不同程度的迎來了暴漲，而不少外資也是旗幟鮮明地看多和做多這 7 巨頭。報告指出各科技企業的優勢。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;小米：端側 AI 落地主要受益者之一。&lt;/li&gt; 
 &lt;li&gt;聯想：大模型落地推動 AI PC 和服務器加速發展。&lt;/li&gt; 
 &lt;li&gt;比亞迪：電動車龍頭智能化轉型機遇。&lt;/li&gt; 
 &lt;li&gt;中芯國際：全球產業鏈重構主要受益者之一。&lt;/li&gt; 
 &lt;li&gt;阿里巴巴：中國大陸領先雲服務廠商，受益 AI 需求迸發。&lt;/li&gt; 
 &lt;li&gt;騰訊：AI 賦能社交廣告，混元大模型未來可期。&lt;/li&gt; 
 &lt;li&gt;美團：本地生活消費龍頭，零售+科技戰略落地為公司帶來長期成長。&lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334382</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334382</guid>
            <pubDate>Fri, 07 Feb 2025 09:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊元寶再更新：DeepSeek R1+騰訊混元 T1「雙核」驅動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;繼上週接入「滿血版」DeepSeek-R1 後，騰訊元寶宣佈又上線騰訊混元最新「深度思考模型」Thinker（T1），目前已開啓小範圍灰測，用户可以自行選用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e1d07289adca12841e6e46c8ea7703d63e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，無論是使用混元 T1，還是使用 DeepSeek，均支持聯網搜索，覆蓋公眾號等騰訊生態內容及互聯網權威信源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;用户在元寶裏提問時，可以選擇從微信裏上傳文件；也可以通過元寶小程序在微信裏上傳文件，元寶一鍵解析，無需多餘步驟，大幅減少操作成本。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334365</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334365</guid>
            <pubDate>Fri, 07 Feb 2025 08:57:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Fedora 整合至 WSL 即將完成，官方發起「捉蟲」測試活動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Fedora 與微軟 Windows Subsystem for Linux (WSL) 的整合即將完成，Fedora 團隊正在召集社區提供幫助。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/165215_oE96_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffedoraproject.org%2Fwiki%2FTest_Day%3A2025-02-17_WSL&quot; target=&quot;_blank&quot;&gt;https://fedoraproject.org/wiki/Test_Day:2025-02-17_WSL&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;測試活動定於 2025 年 2 月 17 日（星期一）舉行，在 Fedora 正式發佈之前，愛好者們將有機會在 WSL 下試用 Fedora。如果您裝有 Windows 10 或 11，並且有空閒時間，那麼現在就是您貢獻力量的時候了。&lt;/p&gt; 
&lt;p&gt;這次 Fedora 測試活動本質上是一次社區組織的尋找 bug 的活動。無論您是 Fedora 的忠實支持者，還是僅僅對 Windows 中的 Linux 理念感興趣，都歡迎您的參與。參加測試的要求包括：&lt;strong&gt;具有虛擬化功能的 x86 或 AArch64 設置、願意遵守測試準則，以及有能力下載大型測試鏡像&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;所有必要的資源，從安裝程序到故障排除建議，都在 Fedora WSL 測試日維基上有詳細説明。Fedora 團隊鼓勵參與者在測試後通過 Fedora 測試周在線平台提交他們的發現。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334363/test-fedora-microsoft-windows-subsystem-linux-wsl</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334363/test-fedora-microsoft-windows-subsystem-linux-wsl</guid>
            <pubDate>Fri, 07 Feb 2025 08:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>如何公正評價百度開源的貢獻？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;本文轉載自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcIXVXI-QNK0GqVqlQBMQxw&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/cIXVXI-QNK0GqVqlQBMQxw&lt;/a&gt;&lt;br&gt; 作者：譚中意&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;引子&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;近日，因百度宣佈開源文心大模型而引發熱議，不少媒體與業內人士對李彥宏及百度此前的言論提出質疑，發表例如「李彥宏「推翻」李彥宏」，「李彥宏此前言論遭「打臉」類似的文章，甚至有人認為百度的「開源」只是表面文章。&lt;/p&gt; 
&lt;p&gt;面對這些質疑，涉及對企業開源貢獻評價標準的不同理解。其實人的看法會因為世事變化發生很大的變化，出現打臉是在所難免的。但是，公正的評價一個企業的開源貢獻，不能只看他們説了什麼、謀求了多大商業利益，而應從開源世界的標準出發，看他們到底做了什麼、貢獻了什麼。&lt;/p&gt; 
&lt;p&gt;本文將從如何客觀評價企業開源貢獻的方法入手，並結合百度多年來的優秀開源項目，給出一個公正的評價。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;一、如何公正評價企業的開源貢獻&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;評價一個企業的開源貢獻，關鍵在於&lt;strong&gt;看做了什麼&lt;/strong&gt;而非&lt;strong&gt;説了什麼&lt;/strong&gt;。以下幾點是常用的評價方法：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;項目質量與長期價值&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;（1）項目本身質量&lt;/strong&gt;：優秀的開源項目應該能夠在工業界得到廣泛的應用。它應該是在它的技術生命週期內，在解決一些開發者實際的問題上有獨到之處，這是這個項目的最根本的技術價值。即開源項目本身得有用，而且確實被工業界廣泛使用了。例如，可以考察這個開源項目被企業和開發者實際使用的案例數量等指標。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;（2）項目長期價值&lt;/strong&gt;：一個項目被開源出來，如果不能長期迭代，不斷解決各種新的問題，而只是開源了一個版本然後就沒有更新了，那麼這個項目雖然也有一點點價值，但是價值很有限。持續的代碼提交、定期的版本發佈（尤其是對高危漏洞的及時修復版本）、積極的社區維護，都是項目長期價值的體現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;人才培養&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;企業開源不僅是代碼的貢獻，更是培養開發人才、推動整個行業技術進步的重要途徑。企業通過開放項目，不僅提升了自身技術水平，也為整個生態輸送了大量高質量的人才。所以看企業開源的價值，圍繞開源項目帶來的人才培養也是重要的一個方面。例如，可以考察該企業是否圍繞這個開源項目開展了相關的培訓、認證、開發者活動，以及開源社區中湧現出的優秀開發者和貢獻者是否得到了行業的認可和發展，而不僅僅只侷限在這一個項目上。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;對行業的長期技術推動與生態效應&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;評價企業開源貢獻，還需關注其在行業內對標準制定、技術創新和生態構建方面的影響。一個企業的開源行為如果能推動整個產業技術進步，形成廣泛的影響力，則其貢獻不可小覷。例如，可以考察企業開源項目是否參與了行業標準的制定，是否引領了新的技術方向，是否構建了開放協作的生態系統，吸引了產業鏈上下游的參與者。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;總之，公正評價應着眼於實際成果——開源項目的本身質量和長期價值，以及企業對人才培養與生態建設的長遠貢獻，而非僅憑商業成功或單純的口號來論斷。&lt;/p&gt; 
&lt;p&gt;另外，國內某些媒體往往只以開源商業化的成功以否來評價一個企業開源的價值，其實企業開源只是該企業其整體商業戰略的一個環節，企業商業的成功取決於多個因素，市場、營銷、渠道、交付、團隊等等，開源只是其中一個因素而已。&lt;/p&gt; 
&lt;p&gt;所以業內也有不少企業，開源項目做的相當不錯，但是對應的商業化做的不怎麼成功。例如雲原生領域內的基石項目 Kubernetes 的創始方是 Google 公司，但是容器雲即基於 kubernetes 搭建的雲服務，在全球公有云市場份額最大的是 AWS。（根據&amp;nbsp;&lt;strong&gt;perplexity.ai 搜索 2023 年容器雲全球市場份額得到 2023 年全球容器雲市場份額的前三名是亞馬遜 AWS、微軟 Azure 和谷歌雲，分別佔據 32%、20% 和 9% 的市場份額。&lt;/strong&gt;）&lt;/p&gt; 
&lt;p&gt;這充分説明，開源項目的成功與其商業化成果之間不能簡單劃等號。雖然谷歌雲在容器雲市場份額不如 AWS 和 Azure，但是任何行內人都不會否定 Google 在雲原生領域內的突出貢獻，是它開源的 kubernetes 並加上 docker 共同創造嶄新的雲原生產業。因此不能拿商業的不成功，來否定開源項目本身的成功，進而否定該公司開源的不成功。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;&lt;strong&gt;二、百度的優秀開源項目舉例&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;百度多年來在開源領域的探索和投入不容小覷，其多個開源項目在國內外都產生了深遠影響。筆者簡單列舉幾個筆者熟悉的項目，而這些項目僅僅是百度眾多開源項目中的幾個。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Apollo&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;作為開放的自動駕駛平台，百度 Apollo 自 2017 年開源 1.0 以來持續迭代，引領了自動駕駛技術的開源潮流，不僅樹立了技術標杆，也促使更多企業和研究機構加入開放合作，共同推動產業進步。據瞭解，國內眾多自動駕駛車廠和技術提供商，要麼基於 Apollo 的開源代碼魔改，要麼借鑑其開源的架構設計和源碼實現之後再構建自己的系統，這充分體現了 Apollo 的技術價值。&lt;/p&gt; &lt;p&gt;同時，Apollo 在&lt;strong&gt;人才培養&lt;/strong&gt;和&lt;strong&gt;生態建設&lt;/strong&gt;上的貢獻同樣突出。其開源平台為高校、科研機構和初創公司提供了寶貴的學習和實踐機會，培養了眾多自動駕駛領域的技術人才。此外，Apollo 開放的架構和工具鏈降低了行業技術門檻，推動了自動駕駛技術的普及，並吸引了車企、芯片廠商等產業鏈夥伴，共同加速技術落地。可以説，Apollo 不僅貢獻了技術，還通過開源促進了人才成長和產業生態的發展。有行業專家指出，Apollo 的開源模式加速了中國自動駕駛技術的發展進程，降低了整個行業創新的成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PaddlePaddle（飛槳）&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;作為中國首個產業級深度學習平台，飛槳為廣大開發者提供了全面的 AI 解決方案，推動了人工智能技術的普及和商業落地，其生態已輻射眾多產業領域。筆者個人覺得尤其重要的是，PaddlePaddle 在教育界和產業界長期進行了大量的培訓和推廣工作，成功培養了大批人工智能的開發者和科學家，為後來大模型研發的遍地開花奠定了堅實的基礎。飛槳平台在推動中國人工智能人才培養方面發揮了重要作用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ECharts&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;ECharts 是源於百度的一款基於 JavaScript 的數據可視化庫，現在是隸屬於 Apache 開源軟件基金會的頂級項目。自開源以來在數據可視化領域取得了顯著的成就和廣泛的應用.截至目前，ECharts 在 GitHub 上已獲得超過 6.19 萬 Star，在同類數據可視化庫中名列前茅 (數據來源： GitHub)。它廣泛地被各種數據 BI 產品所集成，例如 Apache Superset 等等。還在國內外多個行業內被廣泛使用，例如數據分析、交互教育等。比較難得的是，雖然是源於百度的開源項目，但是項目的貢獻者是來自多個公司的志願者，並沒有來自百度的全職維護者。社區的長期發展一直得到足夠保證，目前正在籌備下個大版本 ECharts 6.0 的發佈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;brpc&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;作為起源於百度的一款高性能、分佈式的遠程調用（RPC）框架，在特別吃性能的大規模分佈式場景下使用很多，例如各大互聯網公司的搜索、廣告、推薦、存儲等系統上。它同樣是 Apache 開源軟件基金會的頂級項目，開源至今培養了大批高性能應用的開發者。目前的維護者是來自多家公司的志願者，也同樣沒有百度全職員工的投入，但一直在不斷的往前發展，包括增加新特性，發佈安全修復版本等。2016 年開源至今一直不斷發展新的 Committer，還發布了數十個新的版本。今年 1 月份他們還發了兩個版本，增加一些新的特性和修復了一些 Bugs。brpc 項目的持續迭代和社區活躍度，體現了其強大的生命力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;當然，這幾個項目只是本人比較熟知的幾個項目，只是冰山下的一角。除此之外，還有 Doris、BFE、SAN 等數百個項目。通過這些項目，我們可以看到百度不僅在核心技術上做出了實際貢獻，而且通過開源模式推動了整個技術生態的發展和人才的培養。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;&lt;strong&gt;三、結論&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;評價一個企業的開源貢獻，應從源於這個企業的開源項目的技術質量、社區影響、人才培養以及對產業生態的推動等多方面進行綜合考量。百度在這些方面都有着突出表現——&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其開源項目如 Apollo、paddlepaddle、ECharts、brpc 等，不僅在技術上具備先進性，還被廣泛應用於工業界；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同時，百度還通過開源平台培養了大量技術人才，推動了自動駕駛、人工智能等多個行業的進步。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，&amp;nbsp;&lt;strong&gt;綜合來看，&lt;/strong&gt;&amp;nbsp;百度的開源努力為中國乃至全世界的技術進步和產業生態建設做出了&lt;strong&gt;積極&lt;/strong&gt;貢獻，而針對&lt;strong&gt;部分&lt;/strong&gt;過激言論，則顯然是片面的、不夠全面的評價。&lt;strong&gt;當然，我們也應該看到，企業開源是一個複雜而動態的過程，百度的開源之路也面臨着很大的挑戰和改進空間。&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;&lt;strong&gt;四、最後&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;百度不惜「打臉」自己，成為業內首個從閉源路線轉向開源路線的大模型廠商，這一決定本身就展現了相當的魄力。&lt;/p&gt; 
&lt;p&gt;從商業角度來看，開源意味着放棄部分技術封鎖帶來的競爭壁壘，承擔更多的不確定性，但百度依然選擇開放文心大模型，表明其對技術共創和生態繁榮的認可。&lt;/p&gt; 
&lt;p&gt;從行業角度來看，百度的這一舉措不僅為國內大模型開源生態注入了新的活力，也為其他廠商提供了新的參考路徑，推動國內人工智能技術的開放合作與良性競爭。&lt;/p&gt; 
&lt;p&gt;有評論認為，無論如何，百度這次的選擇，都是中國 AI 開源發展史上具有里程碑意義的一步，但是從長期來看，仍然有待時間和市場的檢驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334357</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334357</guid>
            <pubDate>Fri, 07 Feb 2025 08:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國移動申請 AI 數智人相關商標</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;天眼查知識產權信息顯示，中國移動通信集團有限公司近日申請註冊「中移智安麒」「中移安麒」商標，國際分類為通訊服務、科學儀器，當前商標狀態均為等待實質審查。&lt;/p&gt; 
&lt;p&gt;根據介紹，作為中國移動自主研發的專家型數字員工，中國移動 AI 數智人安麒以大數據為基礎、人工智能算法為驅動、安全專家知識為核心，具備自動化安全測試、個性化安全培訓等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;176&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d48730a8b9bfcb58999469412369d80ce2.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334342</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334342</guid>
            <pubDate>Fri, 07 Feb 2025 07:47:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 提出「CodeI/O」：通過代碼輸入-輸出預測提煉推理模式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 團隊最近提出了一種名為「CodeIO」的新方法，用來提升大型語言模型（如 ChatGPT 等）的推理能力。傳統方法通常專注於訓練模型解決數學題或生成代碼，但其他類型的推理任務（如邏輯推理、科學推理）由於缺乏高質量的訓練數據，效果往往不佳。&lt;/p&gt; 
&lt;p&gt;這項研究的核心思路是：&lt;strong&gt;用代碼教模型「解題思維」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;代碼中其實隱藏着豐富的「解題套路」。例如，一段計算階乘的代碼，本質上包含了「從 1 連乘到 n」的數學推理步驟。&lt;/p&gt; 
&lt;p&gt;CodeIO 的巧妙之處在於：&lt;/p&gt; 
&lt;p&gt;1. 把代碼變成「輸入-輸出」練習題：給定一個代碼函數和輸入，讓模型預測輸出；或者給定代碼和輸出，讓模型反推輸入。&lt;br&gt; 2. 用自然語言描述推理過程：模型需要像學生寫解題步驟一樣，用文字説明「為什麼輸入 A 會得到輸出 B」，而不是直接生成代碼。這種「思維鏈」訓練讓模型學會通用的推理方法，比如如何拆解問題、如何驗證條件等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-329627648b1420a4bd96c277796e656e498.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-53304e171496cc07dddbbf90f1d4d56f5c6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如何實現？&lt;/p&gt; 
&lt;p&gt;⭐收集代碼：從算法題庫、數學問題等來源篩選 45 萬多個代碼函數。&lt;br&gt; ⭐生成練習題：為每個代碼函數自動生成多組輸入輸出對，例如測試階乘函數時，輸入 5 對應輸出 120。&lt;br&gt; ⭐讓模型「寫解題步驟」：使用一個強大的開源模型（DeepSeek-V2.5）為每個練習題生成自然語言的推理過程。&lt;br&gt; ⭐糾錯升級（CoDEI/O++）：如果模型預測錯誤，系統會通過執行代碼得到正確答案，並讓模型根據反饋重新生成推理步驟。類似老師批改作業後讓學生訂正。&lt;/p&gt; 
&lt;p&gt;效果如何？&lt;/p&gt; 
&lt;p&gt;⭐在 14 個不同類型的推理測試中（涵蓋數學、邏輯、常識等），經過 CoDEI/O 訓練的模型表現更全面：&lt;br&gt; ⭐不偏科：傳統方法可能在數學題上得分高，但邏輯題得分低，而 CoDEI/O 在所有任務中均有提升。&lt;br&gt; ⭐驗證可靠：模型的推理步驟可以通過代碼執行直接驗證，確保正確性。&lt;br&gt; ⭐開源共享：所有訓練數據和模型已公開（GitHub），方便後續研究。&lt;/p&gt; 
&lt;p&gt;總結一下，CodeI/O 就像是一種新的「思考訓練營」，它利用代碼這種結構化的信息，讓 AI 學習更通用、更可靠的推理能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;詳細介紹：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodei-o.github.io%2F&quot; target=&quot;_blank&quot;&gt;https://codei-o.github.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.07316&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.07316&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334339</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334339</guid>
            <pubDate>Fri, 07 Feb 2025 07:34:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>最新屍檢報告認定 OpenAI「吹哨人」死因為自殺</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 11 月 26 日，前 OpenAI 員工 Suchir Balaji 在舊金山的公寓中被發現死亡，年僅 26 歲。時至今日，舊金山法醫部門在最新公佈的屍檢報告裁定 Balaji 的死因為開槍自殺，駁斥了 Balaji 家人有關他殺的懷疑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;344&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1a05ba4a3131262dbb151b1411f9a3d8cd9.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;資料顯示，Balaji 是一名印度裔美國人，曾在加州大學伯克利分校學習並獲得了計算機科學學士學位。大學期間，他於 2019 年在 Scale AI 實習，並於 2021 年畢業後加入 OpenAI，參與過 WebGPT 的研發，後來又加入 GPT-4 的預訓練團隊，o1 的推理團隊以及 ChatGPT 的後訓練團隊。2024 年 8 月，他因對公司的商業行為感到失望後離職，並公開表達了自己的擔憂：「如果你相信我所相信的，你就必須離開公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;10 月份，Balaji 因指控 OpenAI 非法使用受版權保護的材料來訓練其 AI 模型而廣受關注。《紐約時報》後來將他列為該報對 OpenAI 的訴訟中「擁有獨特和相關文件」的關鍵人物。彼時，OpenAI 正在被眾多著名作家和新聞出版商起訴侵犯版權。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;離開 OpenAI 後，Balaji 表示自己一直在從事「個人項目」。據他母親説，他計劃創建一個以機器學習和神經科學為中心的非營利組織。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334332/death-of-openai-suchir-balaji</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334332/death-of-openai-suchir-balaji</guid>
            <pubDate>Fri, 07 Feb 2025 07:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Asahi Linux 創始人宣佈辭去項目負責人職務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;上週，Hector Martin 辭去了 Linux 內核 Apple Silicon 代碼的上游維護工作。當時他仍然計劃為 Asahi Linux 項目的下游內核做出貢獻，但就在前兩天，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarcan.st%2F2025%2F02%2Fresigning-as-asahi-linux-project-lead%2F&quot; target=&quot;_blank&quot;&gt;他出人意料地決定辭去 Asahi Linux 項目負責人的職位&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/143821_rzmV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Asahi Linux 項目創始人 Hector Martin 在博客宣佈，他將辭去項目負責人的職務。Martin 説道，隨着時間的推移，參與項目變得越來越沒有樂趣，並注意到了關於 Asahi Linux 在 Apple Silicon 上缺乏 Apple M3/M4 支持以及其他缺失功能（如 Thunderbolt 和 USB-C 顯示器）的用户投訴。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由於圍繞 Apple 芯片硬件上 Asahi Linux 的用户期望感到沮喪，並且最近還與 Linux 內核中 Rust 代碼的上游挫折/爭論/挑戰以及其他因素相關，Hector Martin 決定辭職&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「我立即辭去 Asahi Linux 項目負責人的職務。Asahi Linux&amp;nbsp;項目將繼續進行，我正在與團隊的其他成員一起處理職責和行政憑證的移交。我的個人 Patreon 將暫停，那些曾向我個人捐贈的用户建議轉移到 Asahi Linux OpenCollective（GitHub Sponsors 不允許我單方面暫停付款，但我的贊助者將被告知這一變化，以便他們可以手動取消贊助）。&lt;/p&gt; 
 &lt;p&gt;我想感謝整個 Asahi Linux 團隊，沒有你們，我獨自一人根本無法取得任何進展。我還對我的所有 Patreon 和 GitHub 贊助者表示最深切的感激，是你們讓這個項目從一開始就成為一個可行的現實。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Martin 在博客中也表達了對 Linus 的失望：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Rust for Linux 作為一個上游 Linux 項目所遇到的問題已經有詳細的記錄，我就不在此贅述了。我只想説，我認為 Linus 在處理將 Rust 整合到 Linux 中的問題上是其作為領導者的一大敗筆。&lt;strong&gt;這樣一個大型項目需要得到主要利益相關者的大力支持才能生存下去，而他的做法似乎只是靜觀其變&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;與此同時，在他下游的多個子系統維護者卻竭力阻撓或妨礙項目的進行，發出令人無法接受的辱罵，並普遍打擊士氣。幾個月前，一位主要的 Rust for Linux 維護者已經辭職。&lt;/p&gt; 
 &lt;p&gt;當蘋果發佈 M1 時，Linus Torvalds 希望它能運行 Linux，但並不抱太大希望。我們實現了這一願望，Linux 5.19 從運行 Asahi Linux 的 M2 MacBook Air 上發佈。我曾希望他的熱情能轉化為對我們社區的支持，並幫助我們解決上游問題。&lt;/p&gt; 
 &lt;p&gt;遺憾的是，這一切都沒有實現。2023 年 11 月，我向他發出邀請，與他討論內核貢獻和維護方面的挑戰，看看我們能提供什麼幫助。他從未回覆。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Asahi Linux 博客也&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fasahilinux.org%2F2025%2F02%2Fpassing-the-torch%2F&quot; target=&quot;_blank&quot;&gt;已確認了 Hector 的辭職&lt;/a&gt;，而剩餘的開發者計劃繼續推動 Linux 在 Apple Silicon 硬件上的發展。&lt;/p&gt; 
&lt;p&gt;當前 Asahi Linux 成員包括 Alyssa Rosenzweig、chaos_princess、Davide Cavalca、Neal Gompa、James Calligeros、Janne Grunau 和 Sven Peter。剩餘的開發者表示他們仍將專注於將代碼提交到 Linux 內核。預計 Apple M3 和 M4 硬件支持將在他們更多的代碼被提交到上游以及持續集成取得進展之後才會實現。&lt;/p&gt; 
&lt;p&gt;對於今年的 Apple M1/M2 硬件，他們希望實現 DP Alt Mode、Vulkan 驅動程序中的稀疏圖像以及內置麥克風支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead</guid>
            <pubDate>Fri, 07 Feb 2025 06:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>GNOME 官網全新改版</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;GNOME 全新官網已&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnome.org%2F&quot; target=&quot;_blank&quot;&gt;上線&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;screenshot&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142818_JmM4.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新的設計看起來既時尚又現代，它簡化了頭部設計、空間更寬敞，色彩更鮮豔，還有簡單而有效的動畫，等等，比之前（相對單調）的舊版本更能傳達 GNOME 充滿活力、以用户為中心的理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142819_RWzj.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;文檔方面，GNOME 開發文檔和設計指南現在各自擁有專門的章節，並附上了相關鏈接，還有一個部分展示了支持 GNOME 的組織列表（包括 Canonical），以強調 GNOME 在更廣泛的 Linux 生態中扮演的關鍵角色。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/img/202502/17142820_bW25.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;詳情訪問 GNOME 官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnome.org%2F&quot; target=&quot;_blank&quot;&gt;https://www.gnome.org/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334308/gnome-website-revamp-goes-live</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334308/gnome-website-revamp-goes-live</guid>
            <pubDate>Fri, 07 Feb 2025 06:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「天工」成為全球首例登百級台階的人形機器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國地共建具身智能機器人創新中心宣佈，在户外真實地形測試中，「天工」機器人連續攀爬多級階梯，成功登上北京通州區海子牆公園最高點，成為全球首例可在室外連續攀爬多級階梯的人形機器人。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國創中心持續提升具身小腦能力，實現了基於視覺的感知行走，可實現無磕碰、不踩稜、不踏空地跨越連續多級樓梯和 35 釐米大高差台階，奔跑時速提高至 12km/h，並且能在雪地進行高速奔跑，同時具備更強的抗幹擾能力，大外力衝擊下仍可保持平衡。應對複雜地形的移動能力提升，將成為人形機器人走出實驗室，在真實環境執行任務，甚至在山地、雪地救援、廢墟等極端環境下作業的基礎，為具身智能機器人規模化應用夯實技術底座。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fb4868df102f12e166908215d6ce18410f2.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，升級後的「天工」能夠輕鬆應對超 10KG 重物落下所造成的高達 45Ns 衝量，相當於一名職業拳擊手以 450 N 的力，重擊對手的一瞬間打出的力道，即使在光滑的雪地上從各個方向突然出現的各類幹擾等，「天工」均能保持穩定平衡不發生摔倒，達到業內領先水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過具身小腦所帶來的全身控制能力升級，「天工」面對複雜環境的移動能力再次大幅提升，首次真正發揮出雙足結構為人形機器人帶來的多地形通用性優勢，在實現全地形場景技術閉環的同時，更為行業確立了複雜環境移動能力的全新標杆。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;未來，該技術也將納入國創中心所打造的開源開放生態彙總，通過技術共享降低行業創新門檻將加速具身智能機器人在千行百業的規模化落地，為具身智能產業化開闢更具想象力的落地路徑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/289801&quot; target=&quot;_blank&quot;&gt;北京人形機器人創新中心發佈全球首個純電驅擬人奔跑的全尺寸人形機器人 「天工」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334302</guid>
            <pubDate>Fri, 07 Feb 2025 06:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>ReasonFlux：通過分層模板縮放提升 LLM 推理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大型語言模型（LLMs）已經展現出了卓越的問題解決能力，然而，複雜的推理任務——例如競技級別的數學問題或複雜的代碼生成——仍然具有挑戰性。這些任務需要精確地穿越龐大的解空間，並進行細緻的逐步思考。現有的方法雖然在提高準確性方面有所改進，但往往面臨着高計算成本、僵化的搜索策略以及難以跨不同問題進行泛化的難題。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.marktechpost.com%2F2025%2F02%2F15%2Freasonflux-elevating-llm-reasoning-with-hierarchical-template-scaling%2F&quot; target=&quot;_blank&quot;&gt;https://www.marktechpost.com/2025/02/15/reasonflux-elevating-llm-reasoning-with-hierarchical-template-scaling/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在這篇論文中，研究人員介紹了一個新的框架，&lt;strong&gt;ReasonFlux&lt;/strong&gt;，它通過重新構想 LLMs 如何使用分層、模板引導的策略來規劃和執行推理步驟，從而解決了這些侷限性。 最近用於增強大型語言模型推理的方法分為兩大類：&lt;em&gt;深思熟慮的搜索_和_獎勵引導的方法&lt;/em&gt;。像思維樹（ToT）這樣的技術使 LLM 能夠探索多個推理路徑，而蒙特卡洛樹搜索（MCTS）則將問題分解為步驟，這些步驟由過程獎勵模型（PRM）引導。&lt;/p&gt; 
&lt;p&gt;儘管這些方法有效，但由於採樣過多和手動搜索設計，它們的可擴展性較差。例如，MCTS 需要遍歷成千上萬的潛在步驟，這使得它在實際應用中計算成本過高。與此同時，像思維緩衝（BoT）這樣的檢索增強生成 RAG 方法利用存儲的問題解決模板，但在適應性地整合多個模板方面存在困難，這限制了它們在複雜場景中的效用。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1066&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/135909_MMin_3820517.png&quot; width=&quot;1750&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;ReasonFlux 引入了一個結構化的框架，該框架結合了精選的高層次思維模板庫與分層強化學習（HRL），以動態規劃和優化推理路徑。它不是優化單個步驟，而是專注於配置最優的 &lt;em&gt;模板軌跡&lt;/em&gt;——從結構化知識庫中檢索出的抽象問題解決策略序列。這種方法簡化了搜索空間，並使高效適應子問題成為可能。該框架由三個主要組件組成：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;結構化模板庫&lt;/strong&gt;：研究團隊構建了一個包含 500 個思維模板的庫，每個模板封裝了一種問題解決策略（例如，「三角代換優化積分」）。模板包含元數據——名稱、標籤、描述和應用步驟——以實現高效的檢索。例如，一個標記為「有理函數優化」的模板可能會指導大型語言模型（LLM）應用特定的代數替換。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分層強化學習&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;基於結構的微調&lt;/strong&gt;：將基本 LLM（例如，Qwen2.5-32B）微調以將模板元數據與其功能描述關聯起來，確保它理解何時以及如何應用每個模板。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;模板軌跡優化&lt;/strong&gt;：利用偏好學習，該模型學會根據效果對模板序列進行排序。對於給定的問題，會採樣多個軌跡，並根據它們在類似問題上的成功率來確定獎勵。這訓練模型優先考慮高獎勵序列，從而提高其規劃能力。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自適應推理縮放&lt;/strong&gt;：在推理過程中，ReasonFlux 充當「導航員」，分析問題以檢索相關模板，並根據中間結果動態調整軌跡。例如，如果一個涉及「多項式因式分解」的步驟產生了意外的約束，系統可能會轉向「約束傳播」模板。這種規劃和執行之間的迭代互動反映了人類的解決問題方式，其中部分解決方案會指導後續步驟。&lt;/p&gt; &lt;img height=&quot;376&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/135928_eZy6_3820517.png&quot; width=&quot;1686&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ReasonFlux 在 MATH、AIME 和 OlympiadBench 等競爭級基準測試中進行了評估，超越了前沿模型（GPT-4o、Claude）以及專業開源模型（DeepSeek-V3、Mathstral）。關鍵結果包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MATH 準確率達到 91.2%，超過 OpenAI 的 o1-preview 6.7%。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 準確率為 56.7%，超出 DeepSeek-V3 45%，與 o1-mini 相當。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OlympiadBench 準確率為 63.3%，比先前方法提高了 14%。&lt;/strong&gt;此外，結構化模板庫展示了強大的泛化能力：當應用於不同的問題時，它將小型模型（例如，7B 參數）的能力提升至能夠通過直接推理超越大型模型。此外，ReasonFlux 實現了更好的探索-利用平衡，在複雜任務上比 MCTS 和 Best-of-N 需要少 40% 的計算步驟（見圖 5）。 總結來説，ReasonFlux 重新定義了 LLMs 處理複雜推理的方式，通過將高級策略與逐步執行解耦。其分層模板系統減少了計算開銷，同時提高了準確性和適應性，解決了現有方法中的關鍵差距。通過利用結構化知識和動態規劃，該框架為高效、可擴展的推理設定了新的標準——證明即使是小型、有良好指導的模型也能與最大的前沿系統相媲美。這一創新為在資源受限的環境中部署高級推理開闢了道路，從教育到自動化代碼生成。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334301/reasonflux-llm</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334301/reasonflux-llm</guid>
            <pubDate>Fri, 07 Feb 2025 06:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>FocusAny 支持 DeepSeek 模型，每天可領取 100W Token</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:0&quot;&gt;近日，領先的 AI 工具平台 FocusAny 接入 DeepSeek 模型，正式集成其先進的大語言模型。此次合作旨在為用户提供更強大的 AI 支持，進一步提升工作效率和創造力。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//9c01f3c5c8b3e42afb8182d15f5b275e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;每日免費領取 100W Token&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;為慶祝此次合作，FocusAny 推出限時福利：即日起，所有用户每天可免費領取 100W Token，用於體驗 DeepSeek 模型的強大功能。無論是文本生成、代碼編寫，還是數據分析，DeepSeek 模型都能為用户提供高效、精準的解決方案。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//5038c86744ea401feae4ac2c6e409313.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;DeepSeek 模型：智能助手的新標杆&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;DeepSeek 模型以其卓越的自然語言處理能力和廣泛的應用場景著稱。通過與 FocusAny 的集成，用户可以在日常工作中輕鬆調用 DeepSeek 模型，享受智能化的寫作、編程和決策支持。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//036551e3cdfcc5944030070159b6789f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;strong&gt;&lt;span&gt;關於 FocusAny&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;FocusAny 作為一家致力於提供高效、便捷 AI 服務的平台，此次接入 DeepSeek 無疑將為用户帶來更加豐富的功能和體驗。通過&amp;nbsp;FocusAny，用户可以輕鬆接入 DeepSeek 模型，利用其強大的推理能力解決各種問題。同時，每天可領取的 100 萬 Token 也為用户提供了充足的資源，讓他們能夠盡情體驗 DeepSeek 模型的各項功能。&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//d77626550ffe45ef7e3be5e04b0d8c4e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:.5em; margin-right:.5em&quot;&gt;&lt;span&gt;&lt;strong&gt;關於 DeepSeek&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;DeepSeek 是由幻方量化創立的人工智能公司推出的一系列 AI 模型，包括 DeepSeekCoder、DeepSeekLLM、DeepSeek-V2、DeepSeek-V3 和 DeepSeek-R1 等多個版本。這些模型在技術架構上展現出了前所未有的突破，採用了混合專家架構（MoE）、多頭潛在注意力（MLA）機制等創新技術，極大地提升了模型的處理效率和準確性。DeepSeek 模型在自然語言處理、代碼生成與編程輔助、多模態數據處理等多個領域內展示了卓越的能力，成為了眾多企業和開發者首選的解決方案。&lt;/p&gt; 
 &lt;p style=&quot;color:#06071f; margin-left:0; margin-right:0&quot;&gt;隨着 AI 技術的不斷發展，DeepSeek 系列模型的應用場景也將越來越廣泛。FocusAny 接入 DeepSeek，無疑將為 AI 技術的應用和發展注入新的活力。我們期待未來 FocusAny 能夠為用户帶來更多驚喜和突破，共同推動 AI 技術的進步和發展。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334299</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334299</guid>
            <pubDate>Fri, 07 Feb 2025 05:57:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>微軟開源「專業領域知識-推理能力 RAG」 —— PIKE-RAG</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近年來，大語言模型（LLM）憑藉強大的文本生成能力在各個領域引起了廣泛關注。它們不僅能寫文章、翻譯語言，還能完成創作任務。但當遇到需要專業領域知識支持的工業級問題時，比如半導體設計、製藥研發或法律條文解讀，這些模型往往力不從心。這不僅因為訓練數據中缺少足夠的專業信息，還因為單靠「生成」能力，難以構建嚴謹的邏輯推理和多層次的信息整合。&lt;/p&gt; 
&lt;h2&gt;為什麼傳統方法會遇到瓶頸？&lt;/h2&gt; 
&lt;p&gt;目前，為瞭解決這一問題，業界提出了「檢索增強生成」（Retrieval-Augmented Generation，簡稱 RAG）的思路。其核心理念是在生成答案之前，先從一個龐大的外部知識庫中檢索出相關信息，再將這些信息融入生成的上下文中，從而使回答更準確、更有事實依據。&lt;/p&gt; 
&lt;p&gt;然而，傳統 RAG 方法存在以下幾個問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知識來源複雜&lt;/strong&gt;：現實中的數據不僅僅是純文本，還包括表格、圖表、圖片等多種格式。單一的文本檢索難以捕捉這些多樣信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;專業領域知識不足&lt;/strong&gt;：工業應用中的專業知識具有特定術語和邏輯，普通模型難以準確提取和理解，從而導致回答不夠嚴謹。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「一刀切」的策略&lt;/strong&gt;：不同類型的問題（如簡單事實問答與需要多步推理的複雜問題）要求不同的處理策略，而傳統方法往往採用統一流程，無法兼顧所有需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PIKE-RAG 的創新之處&lt;/h2&gt; 
&lt;p&gt;為瞭解決上述不足，微軟亞洲研究院提出了 PIKE-RAG —— 一種專注於「知識」和「推理」增強的生成框架。PIKE-RAG 不僅幫助模型檢索相關知識，更注重如何理解、拆解和合理組織這些信息，從而構建出嚴謹的推理鏈。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;788&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121127_pF8y_3820517.png&quot; width=&quot;2072&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;792&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121200_n64m_3820517.png&quot; width=&quot;2058&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;810&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/121040_68c7_3820517.png&quot; width=&quot;2088&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面我們來看看它的核心設計：&lt;/p&gt; 
&lt;h3&gt;1. 分級任務設計&lt;/h3&gt; 
&lt;p&gt;論文將問題大致分為四類：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事實型問題&lt;/strong&gt;：例如「這款 LED 產品的額定電流是多少？」&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;鏈式推理問題&lt;/strong&gt;：需要跨多個信息點進行關聯，比如比較多個產品的性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;預測型問題&lt;/strong&gt;：例如「未來 5 年半導體技術可能有哪些突破？」&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;創造型問題&lt;/strong&gt;：要求模型發揮創造力，提出新見解。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種分類使得系統能根據問題的難度和性質，採用針對性的處理策略，從而「量體裁衣」地提升答案的準確性和邏輯性。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1246&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/120535_p84F_3820517.png&quot; width=&quot;1124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;2. 知識「原子化」與任務分解&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;知識原子化&lt;/strong&gt;：面對複雜問題，系統會將長文檔或複雜數據拆分成最基本的信息單元（知識原子）。這種拆分類似於把大問題拆成小問題，每個小單元便於獨立檢索和理解。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知識感知的任務分解&lt;/strong&gt;：系統根據問題需求，動態分解任務，並利用已提取的知識原子構建邏輯推理鏈。這樣一來，即使是多步推理的問題，系統也能循序漸進地「拼湊」出最終答案。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;任務分解器訓練&lt;/strong&gt;：為實現高效分解，系統還引入了可訓練的任務分解模塊，通過大量領域數據學習如何將問題正確拆解併合理組合各個知識點。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 分階段系統構建&lt;/h3&gt; 
&lt;p&gt;PIKE-RAG 採用了分階段的開發策略，逐步提升系統的處理能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;初級階段&lt;/strong&gt;：專注於構建一個多模態知識庫。系統會從文本、表格、圖像等多種格式中抽取信息，並利用解析算法將它們統一組織成一個結構化、關聯緊密的知識網絡。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中級階段&lt;/strong&gt;：在事實型問題上引入多粒度檢索技術，結合增強型文本切分和自動標記機制，確保能精確提取出關鍵信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高級階段&lt;/strong&gt;：逐步引入鏈式推理模塊、知識原子化處理和任務分解器，使系統不僅能夠檢索信息，更能在多跳推理、預測和創造性回答等複雜任務中表現優異。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;實現原理：如何讓系統「知曉」與「推理」&lt;/h2&gt; 
&lt;p&gt;在 PIKE-RAG 系統中，設計者採用了層次化、分階段的實現策略，確保系統能逐步提升對複雜問題的處理能力。下面詳細介紹各個主要環節的實現原理：&lt;/p&gt; 
&lt;h3&gt;1. 知識庫構建（Level-0）&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;文件解析&lt;/strong&gt;：系統首先從各種格式的數據中抽取信息，將非結構化數據（如掃描文檔、表格、圖片中的文字）經過專門算法轉換為統一的文本數據。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知識組織&lt;/strong&gt;：解析後的信息被組織成一個多層次的異構圖，各類數據節點（例如產品技術規格、圖表、説明文字等）通過超鏈接、引用關係等方式互相連接，形成結構化的知識庫，便於後續的高效檢索和利用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 專門模塊針對不同問題&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;事實型問題模塊（Level-1）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;增強型切分與自動標記&lt;/strong&gt;：長文檔被切分成更小的信息塊，並自動為每個信息塊打上標籤，以便在檢索時更精確地匹配查詢內容。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;多粒度檢索&lt;/strong&gt;：系統在檢索時不僅搜索全文，還能在不同層級和粒度上查找相關信息，提高檢索的準確性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;鏈式推理問題模塊（Level-2）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;知識原子化&lt;/strong&gt;：將大塊複雜知識拆解成最小的基本單元，使得每個單元都能獨立檢索並參與推理。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;任務分解&lt;/strong&gt;：針對複雜問題，系統動態分解成多個子任務，每個子任務依次解決後再組合成最終答案。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;訓練可調的任務分解器&lt;/strong&gt;：通過大量領域數據訓練，系統學會如何針對不同專業問題設計合適的分解策略和推理流程。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;預測型與創造型問題模塊（Level-3 &amp;amp; Level-4）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在高級階段，系統不僅能處理已知信息，還能在已有數據基礎上推演預測未來趨勢或提出創造性觀點，從而滿足更高層次的應用需求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;684&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0217/120551_g5tH_3820517.png&quot; width=&quot;828&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3. 分階段開發策略&lt;/h3&gt; 
&lt;p&gt;整個系統從構建基礎知識庫開始，逐步引入不同層次的檢索與推理模塊。每個階段的開發都以解決特定問題為目標：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;初級階段&lt;/strong&gt;確保系統在簡單事實問答上表現出色；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中級階段&lt;/strong&gt;引入多跳推理和任務分解，處理更復雜的問題；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高級階段&lt;/strong&gt;則針對預測和創造性任務進行優化，使系統具備更強的靈活性和適應性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;實驗效果與應用前景&lt;/h2&gt; 
&lt;p&gt;通過大量實驗驗證，PIKE-RAG 在開放領域和法律領域的問答任務中均展現了卓越的性能。得益於知識原子化、任務分解以及多粒度檢索技術，該系統在處理多步推理和複雜查詢時表現尤為出色。這不僅為工業級問答系統的發展提供了新思路，也為未來在更多複雜場景中的應用奠定了基礎。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FPIKE-RAG&quot; target=&quot;_blank&quot;&gt;https://github.com/microsoft/PIKE-RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpike-rag.azurewebsites.net%2F&quot; target=&quot;_blank&quot;&gt;https://pike-rag.azurewebsites.net&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334286/microsoft-pike-rag</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334286/microsoft-pike-rag</guid>
            <pubDate>Fri, 07 Feb 2025 04:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OBS Studio 批評 Fedora 的 Flatpak 打包，稱其是惡意分支</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;開源屏幕錄製和直播應用 OBS Studio 近日向 Fedora 提出了批評，指出它對該應用程序的 Flatpak 打包存在問題，並威脅説如果不加以解決，將採取法律行動。&lt;/p&gt; 
&lt;p&gt;三週前 OBS Studio 團隊就提交了&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.com%2Ffedora%2Fsigs%2Fflatpak%2Ffedora-flatpaks%2F-%2Fissues%2F39%23note_2344970813&quot; target=&quot;_blank&quot;&gt;Fedora Flatpak SIG 工單&lt;/a&gt;&amp;nbsp;—— 關於 Fedora 提供「損壞」的 OBS Studio Flatpak 被視為官方軟件包：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「Fedora Flatpaks 應用商店提供的非官方 OBS Studio Flatpak 似乎打包不佳且已損壞，導致用户向上遊投訴，因為他們認為這是 OBS Studio 的官方軟件包。這種情況在 OBS Studio 之外也存在多個例子，許多用户對 Fedora Flatpaks 被強制推廣，缺少或沒有明確的選項退出感到不滿。&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.gnome.org%2FGNOME%2Fgnome-software%2F-%2Fissues%2F2754&quot; target=&quot;_blank&quot;&gt;https://gitlab.gnome.org/GNOME/gnome-software/-/issues/2754&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpagure.io%2Ffedora-workstation%2Fissue%2F463&quot; target=&quot;_blank&quot;&gt;https://pagure.io/fedora-workstation/issue/463&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;我們希望請求將該軟件包移除，或者明確指出它是一個第三方軟件包。&lt;strong&gt;確保下游軟件包正常工作不應是上游的責任，尤其是當它們覆蓋官方軟件包時&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;我還想了解為什麼有人認為將一個運行得非常完美的 Flatpak 版本破壞後，以更高的優先級發佈到我們的官方構建中是一個好主意。我們在官方 Flatpak 上投入了大量的努力，以確保它們在 Flathub 上發佈時能儘可能地正常運行。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;但然後在過去的一天裏，Fedora 不但沒有刪除，似乎還和 OBS Studio 團隊對罵起來，這讓後者非常不爽，因此認定 Fedora Flatpak 上的 OBS Studio 是個惡意分支，並威脅採取法律行動：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由於目前很明顯 Fedora 對此沒有興趣進行理性討論，並決定訴諸於人身攻擊，我們現在將 Fedora Flatpaks 分發的 OBS Studio 視為惡意分支。&lt;/p&gt; 
 &lt;p&gt;這是一個正式請求，要求從您的分發中移除我們所有的品牌標識，包括但不限於我們的名稱、我們的標誌、屬於 OBS 項目的任何附加知識產權。&lt;/p&gt; 
 &lt;p&gt;如果不遵守，可能會導致採取進一步的法律行動。我們期望在接下來的 7 個工作日內收到回覆（截至 2025 年 2 月 21 日星期五）。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334282/obs-studio-poor-fedora-flatpak</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334282/obs-studio-poor-fedora-flatpak</guid>
            <pubDate>Fri, 07 Feb 2025 03:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 快速集成和使用 solon-flow 規則與流引擎（用 yaml 編寫業務規則）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本文參考自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnblogs.com%2Fstudyjobs%2Fp%2F18125096&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/studyjobs/p/18125096&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;規則引擎技術的主要思想是將應用程序中的業務規則分離出來，業務規則不再以程序代碼的形式駐留在系統中，而是存儲在獨立的文件或者數據庫中，完全獨立於程序。業務人員可以像管理數據一樣對業務規則進行管理。業務規則在程序運行時被加載到規則引擎中供應用系統調用。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 是新的規則引擎技術，由 OpenSolon 開源組織提供的基於 Java 語言開發的開源規則引擎，可以將複雜且多變的業務規則從硬編碼中解放出來，以 yaml 規則腳本的形式存放在文件或特定的存儲介質中（例如數據庫），使得業務規則的變更不需要修改項目代碼、不需要重啓服務器就可以立即生效。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本篇博客的 demo 以個税計算器為例，介紹如何使用 solon-flow 規則引擎，有關具體技術細節，限於篇幅有限，這裏不會介紹，具體細節可以參考官網。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 官網地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2Flearn-solon-flow&quot; target=&quot;_blank&quot;&gt;https://solon.noear.org/article/learn-solon-flow&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 源碼下載地址：&lt;a href=&quot;https://gitee.com/opensolon/solon/tree/main/solon-projects/solon-flow/solon-flow&quot;&gt;https://gitee.com/opensolon/solon/tree/main/solon-projects/solon-flow/solon-flow&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1、搭建工程&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;搭建一個 solon 工程，結構如下：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a2c3e430e7024d75925e6ced1b180c30.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-flow 規則引擎將規則編寫在以 .yml （很流行的配置文）為後綴的文件中，yml 文件默認也是使用 yaml + java 語言編寫，所以學習起來很容易。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;一般情況下，我們使用 IDEA 編寫業務規則，默認情況下 .yml 文件會被打包到項目 jar 包中，為了方便後續調整規則，我們可以將 yml 文件的內容，存儲到數據庫中或者 oss 雲盤中，程序在運行時從 jar 包外部讀取規則內容。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;完束上的 pom 文件的內容：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;&amp;lt;?xml version=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;1.0&quot;&lt;/span&gt; encoding=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;project&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;xmlns&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://maven.apache.org/POM/4.0.0&quot;&lt;/span&gt;
         &lt;span style=&quot;color:#986801&quot;&gt;
                xmlns:xsi&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt;
         &lt;span style=&quot;color:#986801&quot;&gt;xsi:schemaLocation&lt;/span&gt;=&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;modelVersion&lt;/span&gt;&amp;gt;&lt;/span&gt;4.0.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;modelVersion&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-parent&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;3.0.8&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;relativePath&lt;/span&gt; /&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.example&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;demo-rule&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;java.version&lt;/span&gt;&amp;gt;&lt;/span&gt;11&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;java.version&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-web&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;em&gt;&amp;lt;!-- 規則與流引擎 --&amp;gt;&lt;/em&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-flow&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-logging-simple&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.projectlombok&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;lombok&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;provided&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-test&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;test&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;scope&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;build&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;finalName&lt;/span&gt;&amp;gt;&lt;/span&gt;${project.artifactId}&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;finalName&lt;/span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;plugins&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;plugin&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-maven-plugin&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;plugin&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;plugins&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;build&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;project&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2、代碼細節展示&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;此文的 demo 是個税計算器，我們創建一個用於向規則引擎傳遞數據的實體類&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#a626a4&quot;&gt;package&lt;/span&gt; com.example.demo.model;

&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; lombok.Data;

&lt;span style=&quot;color:#4078f2&quot;&gt;@Data&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;Calculation&lt;/span&gt; {
    &lt;em&gt;//税前工資&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wage;
    &lt;em&gt;//應納税所得額&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wagemore;
    &lt;em&gt;//税率&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; cess;
    &lt;em&gt;//速算扣除數&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; preminus;
    &lt;em&gt;//扣税額&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wageminus;
    &lt;em&gt;//税後工資&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;private&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; actualwage;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;這裏不考慮繳納社保和專項扣除等因素，個税計算的規則如下：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img height=&quot;250&quot; src=&quot;https://oscimg.oschina.net/oscnet//ebd65a9942d8b3bc121987723eeaa014.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;之後我們在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;flow/rule.yml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中編寫的規則如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;rule&lt;/span&gt;
&lt;span style=&quot;color:#986801&quot;&gt;nodes:&lt;/span&gt;
  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_setWagemore&quot;&lt;/span&gt; &lt;em&gt;#計算應納税所得額&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      import java.time.LocalDate;
      //2022-10-1 後生效
      return cal.getWage() &amp;gt; 0 &amp;amp;&amp;amp; LocalDate.now().compareTo(LocalDate.of(2022,10,1)) &amp;gt; 0;
&lt;/span&gt;    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      double wagemore = cal.getWage() - 5000;
      cal.setWagemore(wagemore);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_3000&quot;&lt;/span&gt;  &lt;em&gt;#設置税率、速算扣除數&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;lt;= 3000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.03);//税率
      cal.setPreminus(0);//速算扣除數
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 3000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.1);//税率
      cal.setPreminus(210);//速算扣除數
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_25000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 12000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 25000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.2);
      cal.setPreminus(1410);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_35000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 25000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 35000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.25);
      cal.setPreminus(2660);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_55000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 35000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 55000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.25);
      cal.setPreminus(2660);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 55000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.35);
      cal.setPreminus(7160);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_max&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 80000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.45);
      cal.setPreminus(15160);
&lt;/span&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_result&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWage() &amp;gt; 0 &amp;amp;&amp;amp; cal.getWagemore() &amp;gt; 0 &amp;amp;&amp;amp; cal.getCess() &amp;gt; 0&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      //扣税額
      double wageminus = cal.getWagemore() * cal.getCess() - cal.getPreminus();
      double actualwage = cal.getWage() - wageminus;
      cal.setWageminus(wageminus);
      cal.setActualwage(actualwage);
      System.out.println(&quot;--税前工資：&quot;+cal.getWage());
      System.out.println(&quot;--應納税所得額：&quot;+cal.getWagemore());
      System.out.println(&quot;--税率：&quot; + cal.getCess());
      System.out.println(&quot;--速算扣除數：&quot; + cal.getPreminus());
      System.out.println(&quot;--扣税額：&quot; + cal.getWageminus());
      System.out.println(&quot;--税後工資：&quot; + cal.getActualwage());
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本 demo 設定每次被調用時，都去讀取 rule.yml 的內容（可時實生效），具體代碼在 RuleService 中實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#a626a4&quot;&gt;package&lt;/span&gt; com.example.demo.dso;

&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; com.example.demo.model.Calculation;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.annotation.Component;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.flow.ChainContext;
&lt;span style=&quot;color:#a626a4&quot;&gt;import&lt;/span&gt; org.noear.solon.flow.FlowEngine;

&lt;span style=&quot;color:#4078f2&quot;&gt;@Component&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;RuleService&lt;/span&gt; {
    &lt;em&gt;//調用 Drools 規則引擎實現個人所得税計算&lt;/em&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Calculation &lt;span style=&quot;color:#4078f2&quot;&gt;calculate&lt;/span&gt;&lt;span&gt;(Calculation calculation)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; Throwable {
        &lt;span style=&quot;color:#986801&quot;&gt;FlowEngine&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;flowEngine&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; FlowEngine.newInstance();
        flowEngine.load(Chain.parseByUri(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;file:src/main/resources/flow/rule.yml&quot;&lt;/span&gt;)); &lt;em&gt;//動態加載源碼下的文件，修改後實時生效&lt;/em&gt;

        &lt;em&gt;//構建上下文&lt;/em&gt;
        &lt;span style=&quot;color:#986801&quot;&gt;ChainContext&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;ctx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;ChainContext&lt;/span&gt;();
        ctx.put(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal&quot;&lt;/span&gt;, calculation);

        &lt;em&gt;//執行規則&lt;/em&gt;
        flowEngine.eval(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;rule&quot;&lt;/span&gt;, ctx);

        &lt;em&gt;//返回運行算後的&lt;/em&gt;
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; calculation;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;然後在 RuleController 中對外提供計算個税的接口，只需要傳遞一個税前工資額即可計算得出結果&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;rule&quot;)&lt;/span&gt;
&lt;span style=&quot;color:#4078f2&quot;&gt;@Controller&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;RuleController&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    RuleService ruleService;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;calculate&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Calculation &lt;span style=&quot;color:#4078f2&quot;&gt;calculate&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#986801&quot;&gt;double&lt;/span&gt; wage)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; Throwable {
        &lt;span style=&quot;color:#986801&quot;&gt;Calculation&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;calculation&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;Calculation&lt;/span&gt;();
        calculation.setWage(wage);
        calculation = ruleService.calculate(calculation);
        System.out.println(calculation);
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; calculation;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3、驗證成果&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;啓動後，可以訪問接口&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;http://localhost:8080/rule/calculate?wage=10000&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;即可查看到靜態頁面，輸入 10000 元計算個税，如下圖：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df17e27488d65c9710b199cfd67a33fb.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;結果可以發現，税率是 0.1，執行的是 rule.yml 文件中的名稱為 tax_12000 的規則，此時你可以使用 IDEA 修改一下，比如將税率修改為 0.2&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;  &lt;span style=&quot;color:#4078f2&quot;&gt;-&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;id:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;tax_12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;when:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;cal.getWagemore() &amp;gt; 3000 &amp;amp;&amp;amp; cal.getWagemore() &amp;lt;= 12000&quot;&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;task:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;|
      cal.setCess(0.2);//這裏故意將税率修改為 0.2
      cal.setPreminus(210);//速算扣除數
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;注意不需要重啓 IDEA 的項目（可時實生效），此時重新點擊頁面中的計算，發現剛剛修改的規則生效了，如下圖所示：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3887df8f59e854e1ad073beefcebd3da.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;好了，以上就是有關 solon-flow 規則引擎的介紹（在 spring 裏差不多），有興趣的話可以下載源代碼進行驗證。&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;本示例，源碼下載地址：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;a href=&quot;https://gitee.com/opensolon/solon-flow_rule-demo&quot;&gt;https://gitee.com/opensolon/solon-flow_rule-demo&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            
            
            </description>
            <link>https://www.oschina.net/news/334278</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334278</guid>
            <pubDate>Fri, 07 Feb 2025 03:33:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>2024 年 Rust 社區調查報告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Rust 調查團隊很高興與大家分享我們關於 Rust 編程語言的 2024 年調查結果，該調查於 2024 年 12 月 5 日至 2024 年 12 月 23 日進行。與往年一樣，2024 年的 Rust 狀態調查旨在收集 Rust 用户以及更廣泛地關注 Rust 未來的所有人的見解和反饋。&lt;/p&gt; 
&lt;p&gt;這份調查的第九版揭示了來自全球 Rust 語言社區的全新見解和學習機會，以下我們將進行總結。除了這篇博客文章外，&lt;strong&gt;我們還&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fraw.githubusercontent.com%2Frust-lang%2Fsurveys%2Fmain%2Fsurveys%2F2024-annual-survey%2Freport%2Fannual-survey-2024-report.pdf&quot; target=&quot;_blank&quot;&gt;準備了一份報告&lt;/a&gt;&lt;/u&gt;&lt;/strong&gt;，其中包含了調查中所有問題的彙總結果圖表。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我們對每一位在過去一年中抽出時間表達對 Rust 看法和體驗的社區成員表示最誠摯的感謝。您的參與將幫助我們使 Rust 對每個人來説都變得更好。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下文包含了大量數據，所以請坐穩，享受閲讀！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參與&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111550_gaCL_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，2024 年，我們收到的調查查看次數比上一年少。這可能是由於調查僅進行了兩週，而上一年調查進行了近一個月。然而，完成率也有所下降，這似乎表明調查可能有點太長了。我們將考慮這一點，為下一次調查的版本進行調整。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;社區&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Rust 狀態調查不僅為我們提供了關於世界各地有多少 Rust 用户在使用和體驗該語言的寶貴見解，而且還讓我們瞭解了我們全球社區的結構。這些信息讓我們瞭解到語言的使用情況以及隨着時間的推移，我們可能需要解決的接入差距。我們希望這些數據和我們的相關分析能進一步促進關於我們如何繼續優先考慮 Rust 社區的全球接入和包容性的重要討論。&lt;/p&gt; 
&lt;p&gt;與往年一樣，我們詢問了受訪者他們居住在哪個國家。排名前十的國家依次是：美國（22%）、德國（14%）、英國（6%）、法國（6%）、中國（5%）、加拿大（3%）、荷蘭（3%）、俄羅斯（3%）、澳大利亞（2%）和瑞典（2%）。我們很高興看到 Rust 受到世界各地用户的喜愛！您可以在下面的圖表中嘗試找到您的國家：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111604_Xkme_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們也詢問了受訪者是否認為自己屬於一個邊緣化社區的一員。在回答者中，74.5% 選擇了「否」，15.5% 選擇了「是」，10% 選擇不願意透露。&lt;/p&gt; 
&lt;p&gt;我們詢問了選擇「是」的羣體，他們將自己識別為哪些特定羣體的成員。將自己視為技術領域中被代表性不足或邊緣化羣體成員的大多數人將自己識別為女同性戀、男同性戀、雙性戀或其他非異性戀。其次是神經多樣性羣體，佔比 46%，其次是跨性別羣體，佔比 35%。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111617_hrzo_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;每年，我們必須承認 Rust 社區和開源整體在多樣性、公平性和包容性（DEI）方面的差距。我們相信，Rust 基金會在推進 Rust 社區聚會全球訪問和在每個週期向多元化的維護者羣體分配補助金方面正在開展出色的工作，您可以在這裏瞭解更多信息。即便如此，全球包容性和訪問性只是 DEI 的一個要素，調查工作組將繼續在這個領域推動進步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust 使用情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自認是 Rust 用户的人數與去年相當，大約為 92%。這個高比例並不令人驚訝，因為我們主要針對現有的 Rust 開發者進行這項調查。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111627_7qhc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;同樣地，像去年一樣，大約 31% 的未將自己標識為 Rust 用户的人士將難度感知作為不使用 Rust 的主要原因。不使用 Rust 的最常見原因是受訪者們還沒有機會嘗試它。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111639_1Cns_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在參與 2024 年調查的前 Rust 用户中，36% 的人士將不可控因素列為他們不再使用 Rust 的原因，這比去年下降了 10 個百分點。&lt;/p&gt; 
&lt;p&gt;今年，我們還詢問受訪者如果有機會，他們是否會考慮再次使用 Rust，結果發現很大一部分受訪者（63%）會這麼做。這真是令人欣慰！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111652_RnJ5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;標記為 N/A 的封閉答案在調查的前一個版本中並未出現。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;不再使用 Rust 的人告訴我們，這主要是因為他們實際上並不需要它（或他們公司的目標發生了變化），或者因為它不是這項工作的合適工具。少數人報告稱，他們被這種語言或其生態系統整體所壓倒，或者認為轉向或引入 Rust 在人力成本上過於昂貴。&lt;/p&gt; 
&lt;p&gt;在 2024 年使用 Rust 的人中，有 53% 的人是每天（或幾乎每天）使用它——比上一年增加了 4 個百分點。我們可以觀察到，在過去的幾年中，Rust 的使用頻率呈上升趨勢，這表明 Rust 在工作場所的使用越來越多。這一點也由下文「Rust at Work」部分中提到的其他答案所證實。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111737_L7g6_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rust 的專業技能在我們的受訪者中也持續增長！20% 的受訪者能夠編寫（僅）簡單的 Rust 程序（相比 2023 年下降了 3 個百分點），而 53% 的人認為自己使用 Rust 是高效的——這一比例在 2023 年為 47%。雖然這項調查只是衡量 Rust 整體技能變化的一個工具，但這些數字令人鼓舞，因為它們代表了每年迴歸調查的許多 Rustaceans 的知識增長。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111747_VI2v_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不出所料，最受歡迎的 Rust 版本是最新穩定版，無論是最新版本還是與用户的 Linux 發行版一起提供的版本。幾乎三分之一的用户也使用最新的夜間版本，由於各種原因（見下文）。然而，似乎 beta 工具鏈的使用並不多，這有點遺憾。我們希望鼓勵 Rust 用户更多地使用 beta 工具鏈（例如在 CI 環境中），以幫助測試即將穩定化的 Rust 版本。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111759_RPoz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;人們使用夜間工具鏈主要是為了獲取特定的不穩定語言功能。也有幾位用户提到，他們對夜間版本的 rustfmt 更滿意，或者他們使用夜間編譯器是因為編譯速度更快。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111809_jJfZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;學習 Rust&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;要使用 Rust，程序員首先必須學習它，所以我們總是對他們是怎樣學習的很感興趣。根據調查結果，似乎大多數用户通過 Rust 文檔以及《Rust 編程語言》這本書來學習，這本書長期以來一直是新 Rustaceans 最喜歡的學習資源。許多人似乎也通過閲讀 Rust crate 的源代碼來學習。事實上，成千上萬 Rust crate 的文檔和源代碼都可在 docs.rs 和 GitHub 上找到，這使得學習變得更加容易。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111822_KHvR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於屬於「其他」類別的回答，它們可以歸納為三個類別：使用 LLM（大型語言模型）助手（如 Copilot、ChatGPT、Claude 等）、閲讀官方 Rust 論壇（Discord、URLO）或在貢獻 Rust 項目時接受指導的人。我們想向那些使我們的空間對新來者友好和歡迎的人表示衷心的感謝，因為這是一項重要的工作，而且它是有回報的。有趣的是，相當數量的人通過「做中學」來學習，並使用 rustc 錯誤信息和 clippy 作為指南，這是 Rust 診斷質量的良好指標。&lt;/p&gt; 
&lt;p&gt;至於正規教育，似乎 Rust 尚未滲透到大學課程中，因為這是一個通常發展緩慢的領域。只有極少數受訪者（大約 3%）曾上過大學的 Rust 課程或使用過大學學習材料。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111833_l4Zn_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編程環境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;關於 Rustaceans 使用的操作系統，Linux 是最受歡迎的選擇，而且它似乎每年都在變得越來越受歡迎。其次是 macOS 和 Windows，它們的使用份額非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111844_giEi_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9695c9f7f5975eb79647c3db5c61467af25.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;順便提一下，如您在詞雲中看到的，還有一些用户更喜歡 Arch。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Rust 程序員使用他們的 Rust 程序針對一系列的平台。我們發現針對嵌入式和移動平台的目標用户有所增加，但除此之外，平台分佈與去年大致相同。由於 WebAssembly 目標相當多樣化，我們這次將其分為兩個單獨的類別。根據結果，很明顯，在使用 WebAssembly 時，它主要是在瀏覽器（23%）的上下文中，而不是其他用例（7%）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111901_JLWt_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當然，我們不能忘記許多程序員最喜愛的主題：他們使用哪個 IDE（開發環境）。儘管 Visual Studio Code 仍然是最受歡迎的選擇，但今年的市場份額下降了 5 個百分點。另一方面，Zed 編輯器似乎最近獲得了相當大的關注度。選擇「其他」的少數人正在使用各種各樣的不同工具：從 CursorAI 到經典如 Kate 或 Notepad++。特別提一下使用「ed」的 3 個人，這真是一項了不起的成就。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111912_hDw1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e87b497c85dbd1dced8a457b81fc3d05e46.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;您還可以查看詞雲，它總結了對此問題的開放性回答（「其他」類別），以瞭解其他哪些編輯器也受歡迎。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Rust 在工作中的使用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們很高興看到越來越多的人在工作時使用 Rust 進行大部分編碼，從去年的 34% 上升到 38%。在過去幾年中，這一指標呈現出明顯的上升趨勢。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111924_MVQm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rust 在公司中的使用似乎也在增加，因為 45% 的受訪者表示他們的組織在 Rust 上的使用並非微不足道，這比 2023 年增加了 7 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111934_YhGk_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再次強調，我們調查受訪者僱主投資 Rust 的首要原因是可以構建相對正確且無 bug 的軟件。其次受歡迎的原因是 Rust 的性能特性。21% 在工作中使用 Rust 的受訪者這麼做是因為他們已經熟悉它，因此它是他們的默認選擇，比 2023 年增加了 5 個百分點。這似乎表明，Rust 正成為越來越多公司選擇的基礎語言之一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111945_PfzP_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;與上一年相似，很大比例的受訪者（82%）報告説 Rust 幫助他們的公司實現了目標。總的來説，似乎程序員和公司對他們在 Rust 上的使用感到非常滿意，這真是太好了！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/111956_tivA_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在技術領域，情況與前一年相當相似。Rust 似乎特別受歡迎，用於創建服務器後端、Web 和網絡服務以及雲計算技術。它似乎也在嵌入式用例方面獲得了更多的關注。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112012_w7WV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;您可以向右滾動圖表以查看更多領域。請注意，在 2023 年的調查中，汽車領域並未作為封閉答案提供（它只是通過開放式答案輸入的），這或許可以解釋為什麼會有如此大的跳躍。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;看到專業 Rust 使用的持續增長以及許多用户對其性能、控制、安全性、安全性、愉悦性等方面的信心，這令人興奮！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;挑戰&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正如往常一樣，State of Rust 調查的主要目標之一是揭示過去一年 Rustaceans 心中的挑戰、擔憂和優先事項。&lt;/p&gt; 
&lt;p&gt;我們詢問了用户關於限制他們生產力的 Rust 方面。不出所料，緩慢的編譯速度位列榜首，這似乎一直是 Rust 用户的永久性擔憂。一如既往，有努力正在進行中以提高編譯器的速度，例如啓用並行前端或默認切換到更快的鏈接器。我們邀請您測試這些改進，並告訴我們如果您遇到任何問題。&lt;/p&gt; 
&lt;p&gt;其他挑戰包括對 Rust 調試的支持不佳以及 Rust 編譯器工件的高磁盤使用量。另一方面，大多數 Rust 用户似乎對它的運行時性能、編譯器的正確性和穩定性以及 Rust 的文檔都非常滿意。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112026_HY9X_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於 Rust 用户希望穩定（或實現）的具體不穩定（或缺失）功能，最希望的是異步閉包和 if/let while 鏈。嗯，好消息是！異步閉包將在 Rust 的下一個版本（1.85）中穩定，而 if/let while 鏈有望在 Edition 2024 發佈後不久跟進很快之後，這次發佈也將發生在 Rust 1.85 中。&lt;/p&gt; 
&lt;p&gt;其他備受渴望的功能包括生成器（同步和異步）以及更強大的泛型常量表達式。您可以關注 Rust 項目目標以跟蹤這些（以及其他）功能的進展。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112038_zfN3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在對此問題的公開回答中，人們真的很有幫助，並盡力描述限制他們生產力的最顯著問題。我們看到了關於異步編程（永恆的寵兒）的挑戰，錯誤的可調試性（人們普遍喜歡，但並不適合每個人）或 Rust 工具緩慢或資源密集（rust-analyzer 和 rustfmt）的提及。一些用户還希望有更好的 IDE 故事和與其他語言的改進互操作性。&lt;/p&gt; 
&lt;p&gt;今年，我們還增加了一個關於 Rust 進化速度的新問題。雖然大多數人似乎對現狀感到滿意，但回答此問題的人中有超過四分之一的人希望 Rust 能夠更快地穩定和/或添加新功能，只有 7% 的受訪者希望 Rust 放慢或完全停止添加新功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112052_mhgg_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有趣的是，當我們詢問受訪者關於他們對 Rust 未來發展的主要擔憂時，其中一個最常提到的答案是擔心 Rust 會變得過於複雜。這似乎與上一個問題的答案形成了對比。也許 Rust 用户仍然認為 Rust 的複雜性是可控的，但他們擔心有一天它可能會變得過於複雜。&lt;/p&gt; 
&lt;p&gt;我們很高興地看到，對 Rust 項目治理和 Rust 基金會支持不足的擔憂在 2023 年下降了約 6 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/112103_2fAx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;展望未來&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每年，Rust 狀態調查的結果都有助於揭示 Rust 項目和生態系統中許多需要改進的領域，以及對我們社區運作良好的方面。&lt;/p&gt; 
&lt;p&gt;如果您對 Rust 年度調查有任何建議，請告訴我們！&lt;/p&gt; 
&lt;p&gt;我們非常感謝參與 2024 年 Rust 狀態調查並幫助其創建的人們。雖然開發和維護一種編程語言總是伴隨着挑戰，但今年我們很高興看到高水平的調查參與和坦率的反饋，這將真正幫助我們讓 Rust 更好地服務於每個人。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334273/2024-state-of-rust-survey-results</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334273/2024-state-of-rust-survey-results</guid>
            <pubDate>Fri, 07 Feb 2025 03:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 首屆全球開發者大會定檔 2 月 21 日，研討 RWKV-7 架構與未來趨勢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;新一代大模型架構 RWKV 將於 &lt;strong&gt;2025 年 2 月 22 日&lt;/strong&gt;在&lt;strong&gt;上海&lt;/strong&gt;舉辦首屆主題為 &lt;strong&gt;《RWKV-7 架構與未來趨勢》&lt;/strong&gt; 的開發者大會，大會將深入探討 RWKV-7 的獨家技術亮點、應用場景以及未來趨勢，展示 RWKV 在推動全球 AI 發展中的前瞻性與領導力。&lt;/p&gt; 
&lt;p&gt;RWKV-7 架構採用動態狀態演化（dynamic state evolution）機制，超越了傳統的 attention/linear attention 範式，擁有強大的上下文學習（in-context learning）能力和持續學習能力。RWKV-7 模型在推理過程中就能不斷自動根據新的數據進行自我優化和改進（test-time training），從而顯著提升了模型的理解力和處理能力。例如 RWKV-7 2.9B 模型的英文和多語言能力（英文評測 71.1%，多語言評測 62.3%），均顯著超越所有同尺寸模型，包括 Llama 3.2 3B（英文評測 68.7%，多語言評測 57.3%）、Qwen2.5 3B（英文評測 68.6%，多語言評測 57.0%）等知名優秀開源模型。且 RWKV-7 2.9B 只訓練了 3T tokens，另兩者訓練了接近 20T tokens。更大規模的 RWKV-7 也在訓練中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0dde119f43dfd830ac5ecc616e6a70e1783.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此次大會將匯聚來自全球的技術專家、頂尖大學教授、行業領袖與創業者，預計超過 3000 名開發者和 AI 技術愛好者將參與其中。大會將設有多個&lt;strong&gt;分享和互動環節&lt;/strong&gt;，為參與者提供一個寶貴的交流與合作平台，幫助全球開發者共同探索 AI 的未來發展方向。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV 開發者論壇演講嘉賓及議程：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a9aff24ab7e5cc3158b5d66b43b45612a83.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV 開發者大會 | 大會信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;時間：2025 年 2 月 22 日 14:00&lt;/li&gt; 
 &lt;li&gt;地點：上海漕河涇現代服務園大廈 A6 號樓&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;RWKV 開發者大會 | 報名二維碼：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1646ff713189f4ad7d2790a64066d4124a6.jpg&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;未來，RWKV 將繼續通過持續創新和生態建設，致力於為全球開發者提供強大的技術支持與資源，推動 AI 技術的普及與應用，敬請期待！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334263</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334263</guid>
            <pubDate>Fri, 07 Feb 2025 02:51:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>Zadig：首個深度集成 DeepSeek 的 DevOps 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img height=&quot;383&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2230cda1042253217386ec9e74ab4b9bf7b.png&quot; width=&quot;898&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言：當工程效能遭遇數據迷霧&lt;/h1&gt; 
&lt;p&gt;在微服務與雲原生架構普及的今天，DevOps 團隊正面臨雙重挑戰：日均千次的流水線執行產生 TB 級數據，卻難以轉化為有效洞見；K8s 生產環境複雜度指數級增長，人工巡檢如同大海撈針。Zadig 與 DeepSeek 的深度協同，首次將 AGI 技術注入 DevOps 全生命週期，推出「&lt;strong&gt;AI 效能分析&lt;/strong&gt;」與「&lt;strong&gt;AI 環境巡檢&lt;/strong&gt;」兩大核心能力，實現從經驗驅動到智能決策的範式轉移。現已面向社區用户全面開放，開源力量再進化！&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;AI 效能診斷：讓數據説話，精準定位效能瓶頸&lt;/h1&gt; 
&lt;p&gt;傳統工程效能分析往往依賴人工統計與經驗判斷，效率低且易受主觀因素影響，而 Zadig 沉澱了研發過程的構建、部署、測試等大量效能數據，基於 DeepSeek 的 AI 能力，通過智能分析數據，為團隊提供客觀、可操作的改進建議。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能數據分析&lt;/strong&gt;：通過自然語言交互（Prompt 方式），AI 可快速分析流水線、構建、測試等環節的效能數據，識別瓶頸問題。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1530&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74e2b55272658d6609a7f07b0434738960b.png&quot; width=&quot;2942&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;問題精準定位&lt;/strong&gt;：無論是構建耗時過長、測試通過率低，還是資源利用率不足，AI 都能清晰指出問題所在。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1486&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-888422976ca2585f16a7cfc4a352681b7ad.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;科學改進建議&lt;/strong&gt;：基於分析結果，AI 提供具體的優化建議，例如並行測試策略、資源分配調整等，幫助團隊快速提升效能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1486&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d89c13f6e249b6d1517a5d28bd169d63f7d.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;場景價值：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;無需手動分析海量數據，AI 自動生成效能報告，節省大量時間。&lt;/li&gt; 
 &lt;li&gt;通過數據驅動的優化建議，團隊可快速落地改進措施，提升交付效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;AI 環境巡檢：全天候守護，讓環境問題無所遁形&lt;/h1&gt; 
&lt;p&gt;面對複雜的 Kubernetes 生產環境，傳統人工巡檢耗時費力，且難以覆蓋潛在風險。Zadig 的 AI 環境巡檢功能，通過定時巡檢與智能告警，確保環境穩定性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心能力：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;定時自動巡檢&lt;/strong&gt;：AI 定期對 Kubernetes 環境進行全方位檢查，覆蓋資源狀態、服務健康度等關鍵指標。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;2170&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6351737e713118924456d4aa5a02c16d82b.png&quot; width=&quot;3410&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;智能問題識別&lt;/strong&gt;：自動識別常見環境問題，如 Pod 異常、資源不足、配置錯誤等，並給出相應的解決方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1530&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f291d5d35f8a63fbb52c7f1a73cd20d7696.png&quot; width=&quot;2942&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;即時告警推送&lt;/strong&gt;：巡檢結果通過 IM 工具（如飛書、釘釘、企業微信等）實時通知相關責任人，確保問題第一時間被處理。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1666&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c8ddc2f1472da2e9cebbc2efb6f9a52cdef.png&quot; width=&quot;2234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;場景價值：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;無需手動巡檢，AI 自動完成環境健康檢查，大幅降低人力成本。&lt;/li&gt; 
 &lt;li&gt;通過即時告警，團隊可快速響應環境問題，避免小問題演變為大故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;結語&lt;/h1&gt; 
&lt;p&gt;Zadig 通過集成 DeepSeek 的 AI 能力，將智能技術深度融入 DevOps 流程，為研發運維團隊帶來了前所未有的效能提升和環境穩定性保障。未來，隨着 AI 技術的不斷發展，Zadig 將繼續探索更多創新應用場景，助力企業實現數字化轉型，提升核心競爭力。&lt;/p&gt; 
&lt;p&gt;Zadig 免費基礎版已全面支持 AI 能力，0 成本解鎖智能 DevOps！&lt;/p&gt; 
&lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;即日起，Zadig 新版發佈&lt;br&gt; 掃碼諮詢搶先體驗&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#191b1f; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;943&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0c7876673ed701ed97107bb53b607d661dd.png&quot; width=&quot;1797&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Zadig 在 Github&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://gitee.com/koderover/zadig&quot; rel=&quot;nofollow&quot;&gt;Zadig 在 Gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;&lt;span&gt;推薦閲讀：&lt;/span&gt;&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#002a64; margin-left:0; margin-right:0&quot;&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/11210095&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Zadig 官網博客正式發佈，技術乾貨實踐管飽&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/16492101&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;流水線早已 out 了？你需要更高效能的工作流&lt;/a&gt;&amp;nbsp;/&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10316143&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Jenkins 遷移 Zadig，新項目實施上線效率提升 6 倍&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/16507771&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;🚀 重大更新！Zadig V3.2.0 重塑工作流體驗，強勢推出迭代管理&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/koderover/blog/17622087</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/17622087</guid>
            <pubDate>Fri, 07 Feb 2025 02:44:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>