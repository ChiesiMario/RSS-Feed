<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 17 Apr 2025 21:37:26 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>有了它，AI 都能直接管理 Gitee 代碼倉啦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;不久前，Gitee 開源了官方的 MCP Server——&lt;a href=&quot;https://gitee.com/oschina/mcp-gitee&quot; rel=&quot;nofollow&quot;&gt;Gitee MCP Server&lt;/a&gt;。有了它，我們就能用 AI 助手直接管理 Gitee 代碼倉了！&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;讀取文件內容、查看 PR 變更、理解 Issue 描述，甚至直接操作代碼管理任務，比如創建 PR、合併分支、發佈版本等等，全都不是問題。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;簡單來説，Gitee MCP Server 讓 AI 不再是「代碼的旁觀者」，真正成為了參與軟件開發過程的智能助手。&lt;/p&gt; 
 &lt;p&gt;如果你是&lt;strong&gt;個人開發者&lt;/strong&gt;， Gitee MCP Server 可以讓 AI 助手直接參與 PR 審查，減少低級錯誤，提高代碼質量；如果你是&lt;strong&gt;開源項目維護者&lt;/strong&gt;，可以接入 Gitee MCP Server，讓 AI 助手幫助處理大量 Issue，並提供自動化代碼審查，提升社區協作效率。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;既然它是一個 MCP Server，那麼所有支持 MCP Client 的應用都能用，&lt;/strong&gt;比如 Cursor、claude desktop、windsurf、cherry studio 或是自行實現的帶有 mcp client 的 Agent，等等。（之前「馬建倉」就&lt;a href=&quot;https://www.oschina.net/news/340077&quot; rel=&quot;nofollow&quot;&gt;秀了把操作&lt;/a&gt;：沒寫一行代碼，只用 Cursor 和 Gitee MCP 做了個貪吃蛇遊戲。 ）&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a4168709eaed70c553754b7015120c1931.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;那麼，這麼好用的東西怎麼用呢？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;4 月 21 日晚，&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;Gitee 研發工程師黃家建&lt;/span&gt;&lt;/strong&gt;將做客【開源中國】直播欄目《技術領航》，手把手教學如何上手 Gitee MCP Server：從安裝與配置開始，實戰演練如何用 AI 開發工具結合 Gitee MCP Server 實現 AI + 研發流程的融合。&lt;/p&gt; 
 &lt;p&gt;當然啦，作為 Gitee MCP Server 核心開發者，黃家建還會結合自己的實踐經驗，講一講 MCP 協議是什麼，與 function call 到底有什麼區別。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;趕緊打開微信，掃碼預約直播吧~&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;1840&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-858977b0e133cc1bd2a46be9d6dc787b8dc.png&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（碼雲）是開源中國於 2013 年推出的基於 Git 的代碼託管平台、企業級研發效能平台，提供中國本土化的代碼託管服務。&lt;br&gt; 目前，Gitee 已經有超過 1350 萬名開發者，累計託管超過 3600 萬個代碼倉庫，是中國境內規模最大的代碼託管平台。同時，旗下企業級 DevOps 研發效能管理平台 Gitee 企業版已服務超過 36 萬家企業。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;網址：&lt;a href=&quot;https://gitee.com/&quot; rel=&quot;nofollow&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技術領航》是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用户作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用户和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18184933</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18184933</guid>
            <pubDate>Sun, 13 Apr 2025 13:44:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>北京市人工智能產業投資基金追加投資智譜（Z.ai）2 億元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1829640482444053837%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;《北京日報》報道稱&lt;/a&gt;，&lt;strong&gt;北京市人工智能產業投資基金追加投資北京智譜華章科技股份有限公司（以下簡稱智譜）2 億人民幣。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京市人工智能產業投資基金表示，智譜是基金成立以來投資的第一家 AI 大模型企業，也是目前成長最快的企業。智譜在包括文本、推理、語音、圖像、視頻、代碼等在內的全面模型能力上有深厚積累。此外，商業化佈局完善，擁有超過百萬規模的開發者社區和企業用户。&lt;/p&gt; 
&lt;p&gt;北京市人工智能產業投資基金表示：希望通過這次投資，進一步推動智譜在開源模型和算法創新方面的能力建設。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4 月 15 日，智譜開源 32B/9B 系列 GLM 模型，包括了基座、推理和沉思模型，所有模型採用寬鬆的 MIT 許可協議，免費商用、分發，引發業內關注。與此同時，智譜啓用全新域名 Z.ai，目前該平台整合了 32B 基座、推理、沉思三類 GLM 模型，後續將作為智譜最新模型的交互體驗入口。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;472&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/192641_FbK5_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智譜此前在開源方面已經做了很多貢獻，2023 年率先開源國內第一個 Chat 大模型 ChatGLM-6B，短時間內就吸引超過千萬次下載。智譜持續為開源社區和大模型生態發展注入源源不斷的活力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京市人工智能產業投資基金自 2023 年 12 月成立以來，圍繞北京市在人工智能領域的總體佈局，開展直接股權投資。重點方向包括人工智能芯片、訓練數據及相關軟件等底層技術領域，大模型算法創新、具身智能、可信 AI 等關鍵領域，以及大模型等人工智能技術產品開發和垂直行業創新應用等相關領域。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344631&quot; target=&quot;news&quot;&gt;智譜啓動上市輔導&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344598&quot; target=&quot;news&quot;&gt;智譜開源 32B/9B 系列 GLM 模型，極速版最高達到 200 tokens/秒&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345155</guid>
            <pubDate>Sun, 13 Apr 2025 11:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Figma 要求 AI 初創公司停止使用「Dev Mode」一詞</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;近日，設計協作平台 Figma 向瑞典人工智能編程初創公司 Loveable 發出了一份停止使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FBillHeyman%2Fstatus%2F1912182928471412932&quot; target=&quot;_blank&quot;&gt;警告&lt;/a&gt;，原因是 &lt;strong&gt;Loveable 將其新產品的某項功能命名為「Dev Mode」，而 Figma 聲稱該術語已被其註冊為商標&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a60eef82084c2c7bde0249e75284af4f5bc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftsdr.uspto.gov%2F%23caseNumber%3D98045640%26caseSearchType%3DUS_APPLICATION%26caseType%3DDEFAULT%26searchType%3DstatusSearch&quot; target=&quot;_blank&quot;&gt;據美國專利商標局的記錄顯示&lt;/a&gt;，Figma 在 2024 年 11 月成功註冊了「Dev Mode」商標。該公司於 2023 年推出了自己的「Dev Mode」功能，旨在幫助設計師和開發者更好地協作。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1838&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/183511_QrFp_2720166.png&quot; width=&quot;2684&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.figma.com%2Fdev-mode%2F&quot; target=&quot;_blank&quot;&gt;https://www.figma.com/dev-mode/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Figma 在致 Loveable 的信中表示：「我們很榮幸您認同‘Dev Mode’是連接設計與開發的軟件工具的理想名稱。」&lt;/p&gt; 
&lt;p&gt;然而，Figma 強調，該術語已與其軟件廣泛關聯，並且公司需要「保護我們的知識產權」，因此要求 Loveable 停止在其產品中使用「Dev Mode」一詞。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345147/figma-the-term-dev-mode</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345147/figma-the-term-dev-mode</guid>
            <pubDate>Sun, 13 Apr 2025 10:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Qt AI Assistant v0.9 發佈，AI 驅動的開發助手</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;過去兩年中，Qt 一直在努力擁抱生成式 AI，以增強 Qt Creator 中 Qt/QML/C++應用程序的編碼能力。去年推出的 Qt AI Assistant 是一款 AI 驅動的開發助手，可在 Qt Creator 中運行，支持多種大型語言模型（LLM）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-45670371548f2d5dce858a5fa6c1497cc5e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1240&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/182356_Duh4_2720166.png&quot; width=&quot;2308&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Qt AI Assistant v0.9 已於近日發佈，旨在為構建 Qt/C++軟件提供最新的 AI 驅動編碼幫助。現在，通過 CodeLlama-7B-QML 和 DeepSeekCoder v2 Lite 語言模型支持，Qt AI Assistant 提供了本地 LLM 支持。&lt;/p&gt; 
&lt;p&gt;Qt 還發布了 CodeLlama-7B-QML 和 CodeLlama-13B-QML 作為他們在 HuggingFace 和 Ollama 上微調的模型，這些模型基於額外的 QML 代碼片段進行訓練。&lt;/p&gt; 
&lt;p&gt;Qt AI Assistant v0.9 還增加了流式文本支持，以便更好地逐段處理大型語言模型的響應。同時，還引入了利用 AI 構建 Google Test 測試的初步支持。此外，Qt AI Assistant 現在還能夠為 QML 和 C++ 代碼生成內聯代碼註釋。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qt.io%2Fblog%2Fqt-ai-assistant-v0.9-released-deploy-llms-locally-and-enjoy-the-upgraded-user-experience&quot; target=&quot;_blank&quot;&gt;Qt 博客&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345140/qt-ai-assistant-v0-9-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345140/qt-ai-assistant-v0-9-released</guid>
            <pubDate>Sun, 13 Apr 2025 10:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Scala 語言未來如何進化？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;blockquote&gt; 
 &lt;p&gt;Scala 語言創建者 Martin Odersky 以及關鍵庫作者與維護者李浩毅描述了他們對 Scala 語言未來的規劃，並希望 Scala 能在現代編程領域保有一席之地。&lt;/p&gt; 
 &lt;p&gt;原文：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2025%2F03%2F24%2Fevolving-scala.html&quot; target=&quot;_blank&quot;&gt;Evolving Scala&lt;/a&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Scala 應該前進得多快？需要改進什麼？語言本身是否應該改變？本文討論了&lt;strong&gt;Scala 必須不斷進化&lt;/strong&gt;的原因，為什麼這種進化是必要的，以及我們預計這種進化將採取哪些方向。&lt;/p&gt; 
&lt;p&gt;我們希望這能涵蓋許多關於 Scala 語言方向的常見問題，並幫助社區瞭解語言在未來幾個月和幾年中將走向何方。&lt;/p&gt; 
&lt;h2&gt;摘要&lt;/h2&gt; 
&lt;p&gt;儘管 Scala 不再像 2010 年代中期那樣處於炒作的風口浪尖，根據大多數調查，該語言保持在主流語言列表之外。從技術角度來看，核心語言和生態系統在過去十年中得到了極大的改善。在許多方面，Scala 今天的基石比十年前要好得多。&lt;/p&gt; 
&lt;p&gt;Scala 一直引領着編程領域的潮流。為了換取比主流語言略遜一籌的打磨和穩定性，人們選擇 Scala，以便今天就能享受到下個十年的語言特性。Scala 的價值始終在於這些語言特性所賦予的獨特組合——&lt;strong&gt;&lt;em&gt;安全性和便利性&lt;/em&gt;&lt;/strong&gt;，以及它將&lt;strong&gt;&lt;em&gt;面向對象和函數式編程&lt;/em&gt;&lt;/strong&gt;思想融合在一起，從而優雅地適應這些特性。&lt;/p&gt; 
&lt;p&gt;但其他語言也在不斷進步，因此 Scala 必須繼續創新，在它的優勢和劣勢上不斷改進，特別關注新用户的入門體驗。當然，有一些持續存在的問題，尤其是在 IDE 支持以及生態系統的易學性方面，隨着語言的發展，工具、兼容性和遷移成本等問題也始終會存在。但如果 Scala 想要在未來幾年保持其吸引力和相關性，它別無選擇，只能繼續前進。&lt;/p&gt; 
&lt;h2&gt;Scala 當前所處的位置&lt;/h2&gt; 
&lt;p&gt;儘管炒作已經消退，但從普及度來看，Scala 仍然處於其一貫的位置：並不完全屬於主流，但比那些更小眾的語言有着更廣泛的採用率。例如，RedMonk 語言排名在 2014 年將 Scala 排在第 14 位（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2014%2F06%2F13%2Flanguage-rankings-6-14%2F&quot; target=&quot;_blank&quot;&gt;2014 年的排名&lt;/a&gt;），10 年後的 2024 年仍然在第 14 位（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2024%2F09%2F12%2Flanguage-rankings-6-24%2F&quot; target=&quot;_blank&quot;&gt;2024 年的排名&lt;/a&gt;）。&lt;/p&gt; 
&lt;p&gt;在這段時間裏，編程領域發生了顯著變化：Swift 取代了 Objective C，Go、Kotlin、Dart 和 Rust 的出現，CoffeeScript 和 Perl 的衰落。然而，Scala 的位置始終保持不變。儘管社區中的個人來來去去，但整體而言，Scala 似乎保持着強大的穩定性，擁有一個堅實的愛好者基礎。&lt;/p&gt; 
&lt;p&gt;技術上，Scala 現在比 10 年前擁有更堅實的基礎。生態系統已經成熟，各種反應式或純函數式編程風格已經找到了他們的受眾。像&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Ftoolkit%2Fintroduction.html&quot; target=&quot;_blank&quot;&gt;Scala Toolkit&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcom-lihaoyi&quot; target=&quot;_blank&quot;&gt;com.lihaoyi&lt;/a&gt;平台這樣的替代風格現在也可供選擇。新的構建工具如&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscala-cli.virtuslab.org%2F&quot; target=&quot;_blank&quot;&gt;Scala-CLI&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmill-build.org%2F&quot; target=&quot;_blank&quot;&gt;Mill&lt;/a&gt;已經出現，而開發者工具如&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fscalafmt&quot; target=&quot;_blank&quot;&gt;Scalafmt&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalacenter%2Fscalafix&quot; target=&quot;_blank&quot;&gt;Scalafix&lt;/a&gt;已經得到廣泛應用。IDE 仍然是一個痛點，但我們預計到 2025 年它們會有所改進。重用符號運算符的潮流已經逐漸式微。&lt;/p&gt; 
&lt;p&gt;Scala 一直處於語言前沿，證明瞭像 lambda 表達式、記錄和模式匹配等語言特性在 10-15 年後被 Java、Python 和其他主流語言採納的可行性。目前尚不清楚主流語言在 10-15 年後將會採納 Scala 的哪些當前特性。&lt;/p&gt; 
&lt;h2&gt;Scala 將走向何方？&lt;/h2&gt; 
&lt;p&gt;在本節中，我們將討論核心 Scala 開發者將集中精力的一些領域。&lt;/p&gt; 
&lt;h3&gt;安全性與便利性：兩者取其一&lt;/h3&gt; 
&lt;p&gt;Scala 一直是一種混合型語言。面向對象和函數式風格的融合經常被提及。但它的另一種融合是 &lt;em&gt;安全性&lt;/em&gt; 和 &lt;em&gt;便利性&lt;/em&gt;。傳統上，「腳本」語言如 Python 不安全但方便，而「應用」語言如 Java 安全但不便。Scala 是第一個證明你可以在同一語言中做到這兩點的語言。更現代的語言如 Swift 或 Kotlin 也在這條道路上取得了進步，當 Scala 最初開始時，這種想法是聞所未聞的。&lt;/p&gt; 
&lt;p&gt;然而，過去二十年裏，編程領域並沒有停滯不前。曾經屬於 Scala 的許多獨特之處現在已成為普遍現象。所有現代語言都提供了泛型、類型推斷、lambda 表達式、記錄、模式匹配等特性。為了繼續吸引用户，Scala 必須在這兩個方向上繼續創新：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提升安全性而不犧牲便利性&lt;/strong&gt;：例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fexperimental%2Fcc.html&quot; target=&quot;_blank&quot;&gt;捕獲檢查&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fexperimental%2Fexplicit-nulls.html&quot; target=&quot;_blank&quot;&gt;顯式空值&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fother-new-features%2Fsafe-initialization.html&quot; target=&quot;_blank&quot;&gt;安全初始化&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Fbook%2Fca-multiversal-equality.html&quot; target=&quot;_blank&quot;&gt;多態等價&lt;/a&gt; 等特性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;在不妥協安全性的前提下提高便利性&lt;/strong&gt;：如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fenums%2Fenums.html&quot; target=&quot;_blank&quot;&gt;枚舉&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fother-new-features%2Findentation.html&quot; target=&quot;_blank&quot;&gt;可選括號&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdotty.epfl.ch%2Fdocs%2Freference%2Fother-new-features%2Fnamed-tuples.html&quot; target=&quot;_blank&quot;&gt;命名元組&lt;/a&gt; 等特性。關於 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcontributors.scala-lang.org%2Ft%2Fpre-sip-a-syntax-for-aggregate-literals%2F6697&quot; target=&quot;_blank&quot;&gt;聚合數據字面量&lt;/a&gt; 的討論激起了廣泛的興趣，儘管目前還太早看到它將帶來什麼結果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Scala 生態系統廣泛且多樣化，但我們認為這些雙重目標是共同的主線。無論您是在 JVM 上使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fakka.io%2F&quot; target=&quot;_blank&quot;&gt;Akka&lt;/a&gt; 實現後端服務，通過 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fscala.js%2F&quot; target=&quot;_blank&quot;&gt;Scala.js&lt;/a&gt; 在瀏覽器中構建 Web UI，還是通過 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chisel-lang.org%2F&quot; target=&quot;_blank&quot;&gt;Chisel&lt;/a&gt; 定製硅芯片，Scala 的安全性和便利性是人們選擇這種語言的原因。&lt;/p&gt; 
&lt;p&gt;其他語言也在追求這些目標，但我們相信 Scala 做得比大多數語言都要好：它的類型系統、模式匹配、集合庫、多重繼承系統等都是業界領先的，即使其他語言也有自己的特色。因此，Scala 能夠比其他語言更好地執行和組合特性，並以一種統一、簡潔和原則性的方式將這些特性結合起來，而不是臨時性地拼接它們。&lt;/p&gt; 
&lt;p&gt;展望未來，Scala 必須繼續追求安全性和便利性的雙重目標。明天的流行框架可能與今天的不同，而今天的又與幾年前的不同。但幾十年來，開發者們一直希望獲得安全性和便利性，我們預計在未來幾年這種需求將繼續存在。&lt;/p&gt; 
&lt;h3&gt;打磨「粗糙邊緣」&lt;/h3&gt; 
&lt;p&gt;Scala 已不再是新興語言。二十年前，許多事物看似是好的想法，但並非所有決定都取得了預期的效果。儘管長期使用 Scala 的開發者可能已經習慣了這些特性，但 Scala 語言本身需要不斷打磨這些粗糙的邊緣：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;一些特性，如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Foverviews%2Fcore%2Factors.html&quot; target=&quot;_blank&quot;&gt;scala-actors&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala-parser-combinators&quot; target=&quot;_blank&quot;&gt;scala-parser-combinators&lt;/a&gt; 或 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala-xml&quot; target=&quot;_blank&quot;&gt;scala-xml&lt;/a&gt; 已經被移除。它們現在作為獨立的庫存在，你可以根據需要選擇使用或不使用，但已不再是語言的核心部分或標準庫的一部分。其他類似的清理工作包括 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2018%2F06%2F13%2Fscala-213-collections.html&quot; target=&quot;_blank&quot;&gt;Scala 2.13 集合重寫&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;正在處理的更多問題包括：&lt;code&gt;@unroll&lt;/code&gt; 以避免與默認參數和 &lt;code&gt;case class&lt;/code&gt; 的二進制兼容性問題，這是實驗性的（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F78&quot; target=&quot;_blank&quot;&gt;SIP-61&lt;/a&gt;），以及 &lt;code&gt;for&lt;/code&gt;-comprehension 的改進處於預覽階段（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F79&quot; target=&quot;_blank&quot;&gt;SIP-62&lt;/a&gt;），這些改進應該有助於解決使用這些 Scala 語言特性時長期存在的問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一些其他長期存在的問題尚未得到解決，但正在討論中：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F105&quot; target=&quot;_blank&quot;&gt;靈活的變長參數&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcontributors.scala-lang.org%2Ft%2Funpacking-classes-into-method-argument-lists%2F6329&quot; target=&quot;_blank&quot;&gt;解包&lt;/a&gt;、涉及 &lt;code&gt;for&lt;/code&gt;-comprehension 語法的一些其他問題，等等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;過去 20 年間，編程領域發生了巨大變化，Swift、Kotlin、Java、C# 和 Python 等語言都迅速發展。有時是發現新的方法，有時是針對常見用例收斂到相似解決方案。僅僅因為 Scala 在 2005 年做出了一個設計決策，並且我們接受了這個決策 20 年，並不意味着這個決策在 2025 年仍然是最佳的。有時，我們可以也應該做得更好。&lt;/p&gt; 
&lt;p&gt;Scala 的核心一直是其面向對象（OO）和函數式編程（FP）特徵的融合，以及安全性和便利性的融合，但其他一切都是可以討論的。例如，Scala 經歷了三次集合庫的迭代，才到達了今天的地位，儘管經歷了變革，但語言也因此變得更加出色。我們今天能夠解決哪些長期存在的問題，而我們在 5-10 年後會為此感到慶幸？我們可以從其他語言中採納哪些特性和約定，而不是以我們獨特的方式重新發明輪子？&lt;/p&gt; 
&lt;h3&gt;讓新手更容易上手&lt;/h3&gt; 
&lt;p&gt;我們相信 Scala 可以變得更加容易讓新入門者掌握。所有高級 Scala 用户在某個時刻也都是新手。你今天所聽到的所有大型 Scala 項目最初都是由一羣新手開始的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;大學生嘗試使用這門語言來完成他們的研究項目&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Python/Ruby 開發者嘗試使用這門語言來提高他們生產系統的穩定性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;想要更多靈活性、力量和快速開發的 Java 老手&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們支持高級用户和高級框架，但根據定義，高級用户能夠自我照顧：解決他們自己的問題，編寫他們自己的文檔，並提出他們自己的語言變更。Scala 的高級用户一直都在提交他們自己的補丁和改進——來自 Akka 世界的&lt;code&gt;scala.concurrent.Future&lt;/code&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Fcats%2Fissues%2F2948&quot; target=&quot;_blank&quot;&gt;部分統一&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2F2021%2F02%2F26%2Ftuples-bring-generic-programming-to-scala-3.html&quot; target=&quot;_blank&quot;&gt;泛型元組&lt;/a&gt;，以及來自純函數式編程世界的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Fkind-projector&quot; target=&quot;_blank&quot;&gt;kind-projector&lt;/a&gt;——我們希望他們將繼續這樣做。相比之下，新來者必須依賴 Scala 的核心維護者來確保他們有一個良好的體驗。&lt;/p&gt; 
&lt;p&gt;實際上，這意味着：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;優先支持簡單易用的庫，如&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Ftoolkit%2Fintroduction.html&quot; target=&quot;_blank&quot;&gt;Scala Toolkit&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcom-lihaoyi&quot; target=&quot;_blank&quot;&gt;com.lihaoyi&lt;/a&gt;平台，提供代碼和文檔支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;將 Scala 語法與其他語言中不必要的差異進行對齊。已經實現了通過&lt;code&gt;import foo.*&lt;/code&gt;進行的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fchanged-features%2Fimports.html&quot; target=&quot;_blank&quot;&gt;通配符導入&lt;/a&gt;和通過&lt;code&gt;foo*&lt;/code&gt;進行的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fchanged-features%2Fvararg-splices.html&quot; target=&quot;_blank&quot;&gt;可變參數拼接&lt;/a&gt;，後者取代了舊的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F46418559%2Fextractor-not-compiling-in-scala%2F46420376&quot; target=&quot;_blank&quot;&gt;蝸牛操作符&lt;/a&gt; &lt;code&gt;foo@_*&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下一個重要的 Scala 項目很可能會由那些為瞭解決之前沒有人想過要解決的問題而開始學習這門語言的新手發起。他們會很聰明，但不會是那些推動 Scala 語言極限的專家，他們也不會使用最複雜的高級語言特性或設計模式。他們會知道 Java、Python 或 JavaScript，因為那是他們在學校裏學的。這就是我們需要確保那些人能夠輕鬆地進入 Scala 語言的原因。&lt;/p&gt; 
&lt;h2&gt;考慮的替代方案&lt;/h2&gt; 
&lt;p&gt;關於 Scala 應該走向何方，總是有不同的意見。我們將討論兩個在語言發展方向上反覆出現的主張。&lt;/p&gt; 
&lt;h3&gt;為什麼不全面擁抱框架？&lt;/h3&gt; 
&lt;p&gt;社區中常見的請求之一是讓 Scala 社區全面擁抱某些框架或工具鏈。例如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;將 Scala 全面作為純函數式編程語言&lt;/li&gt; 
 &lt;li&gt;將 IO monads 作為構建應用程序的方式&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;這些想法值得討論；畢竟，使用 Scala 進行純函數式編程和 IO 單子的子社區一直健康且充滿活力。然而，當更深入地分析這種做法時，存在一些問題：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Scala 的設計初衷就是靈活且富有表現力。正如歷史所證明的那樣，這促進了創新：十年前，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fakka%2Fakka&quot; target=&quot;_blank&quot;&gt;Akka&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalaz%2Fscalaz&quot; target=&quot;_blank&quot;&gt;Scalaz&lt;/a&gt; 是流行的框架。Scalaz 讓位於更新的函數式庫，如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzio%2Fzio&quot; target=&quot;_blank&quot;&gt;ZIO&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Fcats-effect&quot; target=&quot;_blank&quot;&gt;Cats-Effect&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmonix%2Fmonix&quot; target=&quot;_blank&quot;&gt;Monix&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftypelevel%2Ffs2&quot; target=&quot;_blank&quot;&gt;FS2&lt;/a&gt;。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgetkyo%2Fkyo&quot; target=&quot;_blank&quot;&gt;Kyo&lt;/a&gt; 看起來有潛力，但仍然處於早期階段。Scala 語言必須足夠通用，以支持這種自然演變，而不能將自己綁定到那些隨時間興衰的具體框架上。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;核心 Scala 開發者並非框架專家。當 Akka 流行時，他們並非 actor 模型方面的專家，如今也不是 IO monads 方面的專家。因此，我們需要那些子社區中的高級用户為自己發聲，並推動語言在社區所需方面的改進。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;因此，Scala 必須保持通用性，通過構建任何框架或庫都能從中受益的特性。我們鼓勵框架愛好者提出對 Scala 語言的改進建議：雖然並非每個具體想法都會被接受，但反饋會推動語言變化，從而惠及所有框架。&lt;/p&gt; 
&lt;h3&gt;為什麼不能凍結所有特性開發？&lt;/h3&gt; 
&lt;p&gt;另一個常見的請求是「停止實現特性」。這經常在語言討論中出現，來自對工具支持、就業市場或其他事物不滿意的人。這些情緒是可以理解的。但現實中，凍結特性開發將註定導致 Scala 語言的衰落。&lt;/p&gt; 
&lt;p&gt;Scala 一直以來都比 Java 等語言功能更豐富，但打磨和穩定性卻相對不足。Scala 的核心價值主張是，作為交換，你將獲得來自未來的語言特性，而其他語言可能要過 10-15 年才能獲得：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Apache Spark 於 2014 年選擇 Scala 作為在 JVM 上具有 lambda 表達式和模式匹配功能的語言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Akka 選擇 Scala，因為它是一種簡潔、高效的編程語言，支持使用 Futures 或 Actors 進行輕量級併發。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scalaz 和 Cats 選擇 Scala，因為它是一種簡潔的語言，擁有豐富的類型系統。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其他語言開始採用這些特性，給 Scala 帶來了創新的壓力。到 2025 年，基本上在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2024%2F09%2F12%2Flanguage-rankings-6-24%2F&quot; target=&quot;_blank&quot;&gt;RedMonk top 20&lt;/a&gt; 的所有語言中，都包含了 lambda 表達式、模式匹配、輕量級併發和類型系統！那麼，為什麼任何項目會選擇 Scala 呢？&lt;/p&gt; 
&lt;p&gt;Scala 僅憑穩定性和完善性是無法與主流語言競爭的，因此如果我們今天停止功能開發，Scala 最終會變成一個功能更差、完善性和穩定性更差的編程語言，並且沒有存在的理由。因此，Scala 需要持續不斷的改進來維持其發展，為人們和項目提供選擇這門語言的理由。我們可能會犯錯——沒有一條保證成功的道路——但功能凍結是一條保證停滯和失敗的道路。&lt;/p&gt; 
&lt;h2&gt;Scala 生態系統中的開放性問題&lt;/h2&gt; 
&lt;p&gt;Scala 生態系統並非沒有問題。以下我們將簡要介紹我們認為 Scala 當前面臨的最大挑戰，以及我們將如何應對這些問題。&lt;/p&gt; 
&lt;h3&gt;工具：集成開發環境 (IDEs)&lt;/h3&gt; 
&lt;p&gt;「工具」是上次 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscalasurvey2023.virtuslab.com%2F&quot; target=&quot;_blank&quot;&gt;VirtusLab Scala 調查&lt;/a&gt; 中指出的最大改進領域。這主要指的是集成開發環境（IntelliJ 和 VSCode）以及構建工具（如 sbt），這些是每位編寫 Scala 的人都必須與之交互的工具。&lt;/p&gt; 
&lt;p&gt;在 Scala 社區中，使用的兩個主要 IDE 是 IntelliJ 和 VSCode。上述調查表明，大約 80% 的受訪者使用 IntelliJ，大約 50% 使用 VSCode，還有一些人同時使用兩者。&lt;/p&gt; 
&lt;h4&gt;IntelliJ&lt;/h4&gt; 
&lt;p&gt;IntelliJ 對 Scala 3 的支持仍然需要趕上它對 Scala 2 一直以來的支持質量。儘管如此，進展是穩步的，最近的改進顯示出加速的步伐。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Scala 3 最近引入了「預覽」功能的概念：這些功能已經從實驗性穩定下來，但尚未在 IDE 和其他生態系統中獲得支持。這是為了幫助 IntelliJ 和其他 IDE 有足夠的時間跟進，以免在語言演變時落後。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fscala%2F2024%2F05%2F13%2Fjetbrains-joins-the-scala-center-advisory-board%2F&quot; target=&quot;_blank&quot;&gt;JetBrains 現已成為 Scala 中心諮詢委員會的成員&lt;/a&gt;。這已經改善了 JetBrains 和 Scala 編譯器團隊之間的溝通和協調，並有助於避免過去出現的問題，即 IntelliJ 需要時間才能跟上 Scala 的變化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最近的語言變更已經相對迅速地融入到 IntelliJ 中：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2Fsips%2Ftypeclasses-syntax.html&quot; target=&quot;_blank&quot;&gt;SIP-64 改進的給定語法&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2Fnamed-tuples.html&quot; target=&quot;_blank&quot;&gt;SIP-58 命名元組&lt;/a&gt; 已經在 IntelliJ 2024.3 中可用，而 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2Fbetter-fors.html&quot; target=&quot;_blank&quot;&gt;SIP-62 For 推導改進&lt;/a&gt; 將在 2025.1 中提供。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;我們承認還有很多工作要做。IntelliJ 團隊正在努力提供對 Scala 3 的最佳支持，您可以期待在未來幾個月看到更多改進。&lt;/p&gt; 
&lt;h4&gt;Metals - Scala 語言服務器&lt;/h4&gt; 
&lt;p&gt;金屬（Metals）通常與 VSCode 一起使用，但也支持其他編輯器。金屬（Metals）與 IntelliJ 相比面臨不同的挑戰：它始終使用實際的 Scala 編譯器來進行代碼智能，因此始終與實際語言保持同步。但它曾遇到過穩定性問題（例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals%2Fissues%2F6478&quot; target=&quot;_blank&quot;&gt;#6478&lt;/a&gt;），其中一些問題源於其多進程架構的複雜性，另一些則源於其與 Scala 3 的新集成（例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals%2Fissues%2F6628&quot; target=&quot;_blank&quot;&gt;#6628&lt;/a&gt;）。金屬（Metals）的維護者目前正在專注於修復最突出的問題，但如果您在自己的代碼庫中發現了任何問題，請打開 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals%2Fissues&quot; target=&quot;_blank&quot;&gt;https://github.com/scalameta/metals/issues&lt;/a&gt; 上的問題，VirtusLab 團隊將樂意查看（必要時甚至簽署保密協議）。&lt;/p&gt; 
&lt;p&gt;Scala 3 編譯器的開發者已經廣泛使用 IntelliJ 和 Metals，我們也清楚開發者在使用這兩個 IDE 時所面臨的問題。我們將繼續在發現問題時進行報告，並與 IntelliJ 和 Metals 的維護者合作，以改善編譯器與 IDE 之間的集成。但我們也需要社區人士積極參與問題報告，以便 IDE 維護者能夠進行調查和修復。&lt;/p&gt; 
&lt;h3&gt;構建工具&lt;/h3&gt; 
&lt;p&gt;構建工具 sbt 的複雜性在過去十年或更長時間一直是 Scala 社區的一個長期問題。然而，我們認為隧道盡頭已經出現了曙光：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscala-cli.virtuslab.org%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Scala-CLI&lt;/strong&gt;&lt;/a&gt; 已變得流行。現在它是默認的 Scala 啓動器（自 Scala &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala3%2Freleases%2Ftag%2F3.5.0&quot; target=&quot;_blank&quot;&gt;3.5.0&lt;/a&gt; 以來）。最新的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscalasurvey2023.virtuslab.com%2F&quot; target=&quot;_blank&quot;&gt;VirtusLab Scala 調查&lt;/a&gt; 顯示，35% 的人喜歡使用它，另外 35% 的人想要學習它。雖然不適合大型多模塊項目，但 Scala-CLI 幾乎為幾乎所有單模塊項目提供了所需的一切。它也是探索性編碼小型項目和實驗的出色工具。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;替代方案如&lt;/strong&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmill-build.org%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Mill&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;存在&lt;/strong&gt;。調查發現，10% 的 Scala 開發者喜歡使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmill-build.org%2F&quot; target=&quot;_blank&quot;&gt;Mill&lt;/a&gt;，但近 50% 的人希望學習它，而像&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feed3si9n.com%2Fsbt-remote-cache%2F&quot; target=&quot;_blank&quot;&gt;Scala-CLI&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcoursier%2Fcoursier&quot; target=&quot;_blank&quot;&gt;Coursier&lt;/a&gt;這樣的基礎項目也是使用 Mill 構建的。我們認為，Mill 為大型項目提供了 sbt 的一個很好的替代方案。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foyvindberg%2Fbleep&quot; target=&quot;_blank&quot;&gt;Bleep&lt;/a&gt;雖然仍處於早期階段，但在構建工具領域提供了一個不同的視角，同時也展現出了巨大的潛力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;sbt 本身也隨着時間的推移有了很大的改進&lt;/strong&gt;。在過去的幾年裏，我們看到了諸如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsbt%2Fsbt%2Fpull%2F3434&quot; target=&quot;_blank&quot;&gt;Unified Slash Syntax&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsbt%2Fsbt-projectmatrix&quot; target=&quot;_blank&quot;&gt;sbt Project-Matrix&lt;/a&gt; 等改進，而即將到來的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-sbt.org%2F2.x%2Fdocs%2Fen%2Fchanges%2Fsbt-2.0-change-summary.html&quot; target=&quot;_blank&quot;&gt;sbt 2.0&lt;/a&gt; 發佈將帶來 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feed3si9n.com%2Fsudori-part6%2F&quot; target=&quot;_blank&quot;&gt;構建查詢&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feed3si9n.com%2Fsbt-remote-cache%2F&quot; target=&quot;_blank&quot;&gt;遠程緩存&lt;/a&gt; 等其他改進。雖然仍然不是完美無缺，但到 2025 年使用 sbt 的體驗已經遠遠優於十年前。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FdavidB%2Fscala-maven-plugin&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Maven&lt;/strong&gt;&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2Fcurrent%2Fuserguide%2Fscala_plugin.html&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Gradle&lt;/strong&gt;&lt;/a&gt; 也可以使用。這些構建工具在 Java 圈子裏已經流行了很長時間，並且廣為人知。雖然它們在開源社區中並不像 sbt 那樣受歡迎，但我們看到它們被廣泛應用於許多商業 Scala 代碼庫中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;總體而言，我們預計這個問題在將來會自行解決：一方面是通過 sbt 本身隨時間不斷改進，另一方面是通過項目選擇提供優秀替代方案的其他工具。&lt;/p&gt; 
&lt;h3&gt;生態系統易學性&lt;/h3&gt; 
&lt;p&gt;我們在 Scala 語言中看到的第三大問題是生態系統的易學性。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Scala 生態系統始終為高級用户提供了框架：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fakka.io%2F&quot; target=&quot;_blank&quot;&gt;Akka&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftypelevel.org%2Fcats-effect%2F&quot; target=&quot;_blank&quot;&gt;Cats-Effect&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzio.dev%2F&quot; target=&quot;_blank&quot;&gt;ZIO&lt;/a&gt; 以及其他。但它缺乏一個適合初級用户（例如：你的學生學期項目、你的新畢業生創業項目的代碼庫、由非工程師維護的 devops 或數據分析腳本）的平台。這些領域是 Scala 框架不適合的地方，但 Scala 語言卻可以適用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Scala 生態系統中的文檔傳統上也一直是個問題。這加劇了上述問題：學習一個強大的框架或庫已經足夠困難，但糟糕的文檔使得學習變得更加困難。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;傳統上，儘管有人可能喜歡 Scala 語言，但當他們嘗試做一些簡單的事情，比如「發起一個 HTTP 請求」或「啓動一個服務器」時，他們會遇到一個障礙，突然需要學習關於 Actor、IO 單子或其他高級主題的知識，而相關文檔或學習資料卻不夠充分。&lt;/p&gt; 
&lt;p&gt;但在這裏，我們也看到了樂觀的理由：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Ftoolkit%2Fintroduction.html&quot; target=&quot;_blank&quot;&gt;Scala Toolkit&lt;/a&gt; 和高度重疊的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcom-lihaoyi&quot; target=&quot;_blank&quot;&gt;com-lihaoyi&lt;/a&gt; 平台，它們包括許多相同的庫。這些提供了幾乎完整且易於使用的「新手友好」平台。它可能沒有更復雜框架的所有功能和裝飾，但絕對足夠用於許多生產部署，並且如果需要，可以輕鬆過渡到更復雜的框架。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最近 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2025%2F02%2F25%2Frock-the-jvm-partnership.html&quot; target=&quot;_blank&quot;&gt;Scala Center 與 Rock the JVM 的合作&lt;/a&gt; 有望幫助改善 Scala 的教學方面。來自 Rock the JVM 的 Daniel Ciocîrlan 一直是一位傑出的教育者和高質量教育材料的創作者。我們希望這次合作能夠擴大 Rock the JVM 的影響力，並幫助 Scala 新手發現並受益於他優秀的視頻和課程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;這是一個我們一直在緩慢取得進步的領域，我們希望這種「新手友好」的 Scala 風格隨着時間的推移而發展：不是以犧牲更高級框架為代價，而是在它們並行發展的同時，隨着新手的數量增加，更多的人在需要時選擇更復雜的框架。&lt;/p&gt; 
&lt;h2&gt;如何幫助&lt;/h2&gt; 
&lt;p&gt;Scala 是一個社區努力的結果；沒有像其他語言那樣的龐大企業贊助 Scala 的開發。因此，我們需要社區的幫忙來推動語言的發展。這種幫助可以以各種方式實現。&lt;/p&gt; 
&lt;h3&gt;財政&lt;/h3&gt; 
&lt;p&gt;如果您想從財政上支持 Scala，有兩個主要羣體您可以支持：&lt;/p&gt; 
&lt;h4&gt;Scala 中心&lt;/h4&gt; 
&lt;p&gt;Scala 中心支持以下兩個方面：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;核心 Scala 語言和編譯器的開發：探索、原型設計、實施、維護和調試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 Scala 社區。這包括 Scala Days 會議、Scala 大使計劃以及工具峯會。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;您可以通過以下兩種方式向 Scala 中心捐款：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;個人捐款或讓您的公司向 Scala 中心捐款 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fscala.epfl.ch%2Fdonate.html&quot; target=&quot;_blank&quot;&gt;https://scala.epfl.ch/donate.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;您可以鼓勵您的公司加入 Scala 中心諮詢委員會，以持續資助它。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您想支持核心 Scala 語言和社區工作，請向 Scala 中心捐款。他們的大部分工作可能並不光彩奪目，但它們在確保 Scala 生態系統持續健康發展中發揮着關鍵作用。&lt;/p&gt; 
&lt;h4&gt;VirtusLab&lt;/h4&gt; 
&lt;p&gt;VirtusLab 負責許多 Scala 工具的核心開發：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Metals 和 VSCode Metals 插件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scala-CLI&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scala 3 LTS，Scala 的發佈流程和一般項目管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Scalameta 組織內的工具&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您在使用 Metals 或 Scala-CLI 時遇到問題，並且想資助修復或改進，您應該聯繫 VirtusLab，郵箱地址為&amp;nbsp;scala@virtuslab.com.&lt;/p&gt; 
&lt;h3&gt;代碼&lt;/h3&gt; 
&lt;p&gt;Scala 生態系統的大部分內容都是開源的。這意味着您可以直接深入代碼，修復或改進您自己需要的部分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;您可以自己修復 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fscala3&quot; target=&quot;_blank&quot;&gt;Scala3&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJetBrains%2Fintellij-scala&quot; target=&quot;_blank&quot;&gt;IntelliJ&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscalameta%2Fmetals&quot; target=&quot;_blank&quot;&gt;Metals&lt;/a&gt; 中的錯誤。儘管代碼庫很大，但有人能夠深入其中並修復他們自己用例所需的錯誤並不罕見。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每 three 周都會進行一次 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fcontribute%2F%23so-you-want-to-improve-the-scala-3-compiler&quot; target=&quot;_blank&quot;&gt;Compiler Spree&lt;/a&gt; 和 Tooling Spree。這些是遠程編碼會議，您可以與 Scala 語言和工具的核心貢獻者合作解決小規模的問題，並獲取技能和知識，以應對更具挑戰性的問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;向工具和基礎設施貢獻修復和改進並不容易，但這也不是不可能的。Scala 工具鏈的大部分都是開源的，並且在過去多次由個人和公司進行了一次的快速貢獻，他們只是需要修復某些問題。向這些項目提交拉取請求與任何專業軟件工程師每天已經做的工作沒有區別，並且可以幫助你定期改善使用 Scala 的體驗。&lt;/p&gt; 
&lt;h3&gt;語言設計&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fsips%2F&quot; target=&quot;_blank&quot;&gt;Scala 改進流程&lt;/a&gt; 並不僅限於核心 Scala 貢獻者。任何人都可以提出一個，例如 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F40&quot; target=&quot;_blank&quot;&gt;SIP-42 二進制整數字面量&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F78&quot; target=&quot;_blank&quot;&gt;SIP-61 為二進制兼容性@unroll 默認參數&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fscala%2Fimprovement-proposals%2Fpull%2F97&quot; target=&quot;_blank&quot;&gt;SIP-67 改進嚴格相等性&lt;/a&gt;。如果核心 Scala 團隊沒有優先考慮你想要的，你總是可以介入並提出自己對語言改進的建議。畢竟，沒有人比你更瞭解自己的需求！&lt;/p&gt; 
&lt;p&gt;SIPs 進入語言並不容易。無法保證一個 SIP 會被接受。即使 SIP 成功通過，通常也需要數月甚至一年時間來完成整個審查、實施和實驗過程，最終才能進入 Scala 的發佈。相反，最初被拒絕的想法可能在經過數月或數年的額外實驗和改進後找到進入的方式。但我們需要更多的貢獻者提出更改，而不僅僅是限於 Martin Odersky 和 EPFL 的團隊。&lt;/p&gt; 
&lt;p&gt;如果您有想法要提出，但需要幫助實施，並且有資金支付，請聯繫 [email&amp;nbsp;protected]，我們可以幫助找到合適的專家進行合作。&lt;/p&gt; 
&lt;h2&gt;結論&lt;/h2&gt; 
&lt;p&gt;語言發展是一個間接的過程。核心 Scala 團隊無法獨自構建下一個重大的 Scala 成功故事，這也不會一蹴而就。我們能做的就是從各個方面提升 Scala 的體驗：語言、工具和社區，並希望某處某個人會為一個新的項目選擇 Scala，使其成為「下一個大熱門」。&lt;/p&gt; 
&lt;p&gt;我們認為 Scala 語言的核心吸引力在於其安全性與便利性的結合。強大的類型系統和編譯器可以防止錯誤，提供出色的運行時性能，而簡潔的語法和類型推斷則使其感覺像任何腳本語言一樣靈活和富有表現力。毫無疑問，其他語言也在追求相同的目標，我們認為 Scala 憑藉其獨特的混合函數式-面向對象的設計，可以在多個方面做得更好，從而吸引並留住用户。&lt;/p&gt; 
&lt;p&gt;但 Scala 語言及其生態系統的細節將隨着時間的推移而演變，我們不應過度依賴我們已經習慣的偶然複雜性。正如 Scala 在 2.13 版本中極大地簡化了&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2Fblog%2F2018%2F06%2F13%2Fscala-213-collections.html&quot; target=&quot;_blank&quot;&gt;集合&lt;/a&gt;，並且用更簡單的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scala-lang.org%2F2021%2F02%2F26%2Ftuples-bring-generic-programming-to-scala-3.html&quot; target=&quot;_blank&quot;&gt;泛型元組&lt;/a&gt;和其他&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.scala-lang.org%2Fscala3%2Freference%2Fnew-types%2Findex.html&quot; target=&quot;_blank&quot;&gt;類型系統特性&lt;/a&gt;取代了類型級別的體操一樣，我們期望繼續發現可以改進 Scala 的領域。始終會有關於向後兼容性、遷移和易學性的擔憂，但無論如何，Scala 需要不斷地、批判性地審視自己，並借鑑過去二十年其他語言所學到的東西來提升開發者體驗。&lt;/p&gt; 
&lt;p&gt;Scala 一直是一個社區項目，我們需要社區的幫助來推動它向前發展：無論是通過資金支持、提交拉取請求，還是在語言設計方面。我們希望社區中的每個人都能以自己的方式做出貢獻，並推動語言的發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345137/evolving-scala</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345137/evolving-scala</guid>
            <pubDate>Sun, 13 Apr 2025 10:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>首個雲超算國標正式發佈：阿里雲、華為雲等聯合起草</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;近日，國家市場監督管理總局、國家標準化管理委員會正式發佈首個雲超算國家標準 GB/T 45400-2025，將於今年 10 月實施。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e500d685c371b785670bd445adca14e3947.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該標準由阿里雲、華為雲、騰訊雲、中國電子技術標準化研究院等機構牽頭起草，為雲超算在更多高性能計算領域的大規模應用奠定基礎，推動我國算力基礎設施建設邁向標準化、智能化新階段。&lt;/p&gt; 
&lt;p&gt;雲超算是一種新型的高性能計算（HPC），它基於雲基礎設施對外提供彈性可擴展的高性能計算服務。&lt;/p&gt; 
&lt;p&gt;目前，傳統高性能計算在大模型訓練、自動駕駛、生命科學、工業製造、半導體芯片等領域展開應用，並逐漸向更多行業滲透。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;但傳統 HPC 往往架構複雜、擴展性不佳，並存在性能瓶頸、價格高昂等門檻，很多企業雖然想用，卻可能「不懂用」，或「用不好」、「用不起」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;開箱即用的雲超算成為高性能計算的新選擇，多家單位在此背景下聯合起草首個雲超算國家標準，對雲超算基礎架構、資源協同調度、全棧安全可信體系等關鍵技術指標作出權威性界定，內容囊括雲超算服務的設計研發、部署運維和效能評估全流程。&lt;/p&gt; 
&lt;p&gt;新標準的出爐，相當於給各行各業提供了一份包含雲超算服務產品的設計、實現、應用和選型的科學指南。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345132</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345132</guid>
            <pubDate>Sun, 13 Apr 2025 09:44:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 Solon AI MCP Server 入門：Helloworld （國產解決方案）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;目前網上能看到的 MCP Server 基本上都是基於 Python 或者 nodejs ，雖然也有 Java 版本的 MCP SDK，但是鮮有基於 Java 開發的。 作為 Java 開發中的國產頂級框架 Solon 已經基於 MCP SDK 在進行 Solon AI MCP 框架開發了，本文將使用 Solon AI MCP 做一個簡單的 MCP Server 入門。&lt;/p&gt; 
&lt;h3&gt;引入依賴&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;Solon AI MCP 是 Solon AI 最新增加的特性。支持 Mcp Server 和 Mcp Client，且支持 Java 8 到 Java 24。最新的版本號為 3.2.0（隨 Solon 的版號）。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-ai-mcp&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;3.2.0&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style=&quot;color:#e45649&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;開始寫工具&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;solon-ai-mcp 支持多端點的架構，可以手動構建端點，或者註解構建端點（&lt;code&gt;@McpServerEndpoint&lt;/code&gt;）。再使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@ToolMapping&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;註解編寫工具，就像開發 MVC 一樣簡單和熟悉。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;@ToolMapping 註解標記這個方法是一個工具映射，通過 description 屬性告訴大模型這個工具是做什麼的，其實就是提示詞，大模型會根據自己的理解調用這個工具，所以這個描述很重要。&lt;/li&gt; 
 &lt;li&gt;@ToolParam：從名字可以看出來，就是工具調用時需要傳什麼參數&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@McpServerEndpoint(sseEndpoint = &quot;/sse&quot;)&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;HelloService&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@ToolMapping(description = &quot;你好世界&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; String &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#4078f2&quot;&gt;@ToolParam(description = &quot;名字&quot;)&lt;/span&gt; String name)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; SQLException {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;hello &quot;&lt;/span&gt; + name;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;這樣就可以了。啓動時就會自動註冊。並且打印基本的信息：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e47839b4670ac8858c97f2c82a4af150.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;用客户端做個單測（調用這個工具）&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Slf4j&lt;/span&gt;
&lt;span style=&quot;color:#4078f2&quot;&gt;@SolonTest(App.class)&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;HelloTest&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;extends&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;HttpTester&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Test&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;void&lt;/span&gt; &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span style=&quot;color:#986801&quot;&gt;McpClientToolProvider&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;clientToolProvider&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; McpClientToolProvider.builder()
                .apiUrl(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;http://localhost:8080/sse&quot;&lt;/span&gt;)
                .build();

        &lt;span style=&quot;color:#986801&quot;&gt;String&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; clientToolProvider.callToolAsText(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;hello&quot;&lt;/span&gt;, Maps.of(&lt;span style=&quot;color:#50a14f&quot;&gt;&quot;name&quot;&lt;/span&gt;, &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;solon&quot;&lt;/span&gt;));
        log.warn(rst);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;運行單測後：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//80088a925343da37cad3f8f7a721f471.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345131</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345131</guid>
            <pubDate>Sun, 13 Apr 2025 09:43:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>黃仁勳：英偉達堅定不移服務中國市場，AI 將在每個行業引發顛覆性變革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4 月 17 日，中國貿促會會長任鴻斌在北京與英偉達公司首席執行官黃仁勳舉行會談。這是黃仁勳時隔 3 個月再次到訪北京。黃仁勳在會談中表示，&lt;strong&gt;中國是英偉達非常重要的市場，希望繼續與中國合作。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;372&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1bf052320ee3587eb2eedcd683357c58a5d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據央視財經，針對美國政府決定對英偉達對華出口的 H20 芯片，黃仁勳表示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;美國政府加強芯片出口管制已對英偉達業務產生重大影響，當前全球正掀起一場激烈的人工智能競賽，作為當代最具變革性的核心技術，AI 對各行業發展的推動前景廣闊，世界各國都在加速推進技術應用，研發創新與能力提升，這必將對包括中國在內的全球市場格局產生深遠影響。作為深耕中國市場三十載的企業，我們與中國市場共同成長、相互成就。中國不僅是全球最具規模的消費市場之一，其蓬勃發展的產業生態與領先的軟件實力，更成為我們持續創新的重要動力，在中國市場的成功經驗推動我們不斷加大研發投入，而與中國企業的深度合作，也使我們成長為更具競爭力的國際化企業。因此，&lt;strong&gt;我們將繼續不遺餘力優化符合監管要求的產品體系，堅定不移地服務中國市場。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;黃仁勳還表示，AI 已經在諸多領域產生了重大影響，例如在軟件編程方面，如今幾乎所有的英偉達員工都會藉助 AI 進行輔助開發。人工智能正在深刻改變眾多行業的發展格局，但這僅僅是個開端，無論是醫療健康、金融服務、氣候科技還是製造業，每個行業都將迎來人工智能引發的顛覆性變革。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345130</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345130</guid>
            <pubDate>Sun, 13 Apr 2025 09:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Vanna —— 基於 RAG 的自然語言生成 SQL 工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;Vanna 是一個 MIT 許可的開源 Python RAG（檢索增強生成）框架，用於 SQL 生成和相關功能。&lt;/span&gt;&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;工作原理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img height=&quot;357&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/151133_1FdG_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Vanna 的工作分為兩個簡單的步驟 - 在你的數據上訓練 RAG「模型」，然後提出問題，這些問題將返回可設置為在你的數據庫上自動運行的 SQL 查詢。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;在你的數據上訓練 RAG「模型」&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提出問題&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;500&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/151158_TZIY_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;p&gt;&lt;strong&gt;Supported LLMs&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/openai&quot;&gt;OpenAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/anthropic&quot;&gt;Anthropic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/blob/main/src/vanna/google/gemini_chat.py&quot;&gt;Gemini&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/blob/main/src/vanna/hf/hf.py&quot;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/bedrock&quot;&gt;AWS Bedrock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/ollama&quot;&gt;Ollama&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianwen&quot;&gt;Qianwen&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianfan&quot;&gt;Qianfan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/ZhipuAI&quot;&gt;Zhipu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;p&gt;&lt;strong&gt;Supported VectorStores&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/azuresearch&quot;&gt;AzureSearch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/opensearch&quot;&gt;Opensearch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/pgvector&quot;&gt;PgVector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/pinecone&quot;&gt;PineCone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/chromadb&quot;&gt;ChromaDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/faiss&quot;&gt;FAISS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/marqo&quot;&gt;Marqo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/milvus&quot;&gt;Milvus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/qdrant&quot;&gt;Qdrant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/weaviate&quot;&gt;Weaviate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vanna-ai/vanna/tree/main/src/vanna/oracle&quot;&gt;Oracle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;p&gt;&lt;strong&gt;Supported Databases&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.postgresql.org/&quot;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.mysql.com/&quot;&gt;MySQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://prestodb.io/&quot;&gt;PrestoDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://hive.apache.org/&quot;&gt;Apache Hive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://clickhouse.com/&quot;&gt;ClickHouse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.snowflake.com/en/&quot;&gt;Snowflake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.oracle.com/&quot;&gt;Oracle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.microsoft.com/en-us/sql-server/sql-server-downloads&quot;&gt;Microsoft SQL Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://cloud.google.com/bigquery&quot;&gt;BigQuery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.sqlite.org/&quot;&gt;SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://duckdb.org/&quot;&gt;DuckDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/vanna</link>
            <guid isPermaLink="false">https://www.oschina.net/p/vanna</guid>
            <pubDate>Sun, 13 Apr 2025 09:32:00 GMT</pubDate>
        </item>
        <item>
            <title>CVE 基金會成立</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;有 25 年曆史的 CVE 項目在漏洞管理中起到了舉足輕重的作用，它負責分配和管理漏洞的唯一 CVE ID 編號，確保在提及特定漏洞和補丁時針對的是同一個漏洞。&lt;/p&gt; 
&lt;p&gt;非營利組織 MITRE 與美國國土安全部簽訂了運營 CVE 項目的合同，MITRE 週二確認，合同沒有續簽。這意味着從 4 月 16 日（星期三）起&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/345038&quot;&gt;美國政府將停止資助 CVE&lt;/a&gt;&lt;/u&gt;。安全行業人士擔心在其他人接手前漏洞管理上將會出現巨大混亂。&lt;/p&gt; 
&lt;p&gt;CVE Naming Authority 機構 VulnCheck 表示預留了 1000 個 1000 個 CVE 用於 2025 年的漏洞。MITRE 每月發佈 300-600 個 CVE，預留的編號只夠用 2-3 個月。&lt;/p&gt; 
&lt;p&gt;為了應對危機，長期擔任 CVE 董事會成員的聯盟宣佈成立&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thecvefoundation.org%2F&quot; target=&quot;_blank&quot;&gt;CVE 基金會&lt;/a&gt;，這是一個致力於確保漏洞識別系統持續運行的非營利組織。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;700&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/165002_yPMw_2720166.png&quot; width=&quot;1670&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新成立的基金會官員肯特·蘭德菲爾德表示：「CVE 作為全球網絡安全生態系統的基石，其重要性不容忽視。全球網絡安全專業人員的日常工作——從安全工具和公告到威脅情報和響應——都依賴於 CVE 標識符和數據。如果沒有 CVE，防禦者在應對全球網絡威脅時將處於極其不利的地位。」&lt;/p&gt; 
&lt;p&gt;CVE 計劃提供了一個標準化的系統，用於識別和分類所有軟件和硬件（包括 Apple 的 macOS、iOS、iPadOS 和其他產品）中的安全漏洞。當安全研究人員發現漏洞時，他們會被分配唯一的 CVE 標識符，以便 Apple 等公司協調補丁和更新。&lt;/p&gt; 
&lt;p&gt;MITRE 公司與美國國土安全部簽訂了合同，負責管理該項目。該公司確認，政府資金已於 4 月 16 日到期。&lt;/p&gt; 
&lt;p&gt;據路透社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fus-funding-running-out-critical-cyber-vulnerability-database-manager-says-2025-04-15%2F&quot; target=&quot;_blank&quot;&gt;報道&lt;/a&gt;，該項目的到期可能與聯邦政府正在進行的大規模裁員有關，此次裁員的部分原因是政府效率部（DOGE）。&lt;/p&gt; 
&lt;p&gt;受此次裁員影響的美國網絡安全和基礎設施安全局（CISA）表示，由於突然出現的資金缺口可能會擾亂全球漏洞管理，該局正在「緊急努力減輕影響」。&lt;/p&gt; 
&lt;p&gt;安全專家警告稱，如果沒有 CVE，網絡安全工作將面臨「徹底混亂」，因為用於溝通漏洞的通用語言實際上將消失。一位研究人員將其比作「突然刪除所有詞典」。&lt;/p&gt; 
&lt;p&gt;新成立的 CVE 基金會旨在將該項目轉型為不依賴單一政府資助的專門的非營利模式。基金會的組織者透露，他們過去一年一直在為這一可能性做準備。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thecvefoundation.org%2F&quot; target=&quot;_blank&quot;&gt;該基金會在公告&lt;/a&gt;中表示：「對於國際網絡安全界來説，此舉代表着一個建立反映當今威脅形勢全球性的治理機制的機會。」&lt;/p&gt; 
&lt;p&gt;資金削減還影響了相關的通用弱點枚舉 (CWE) 計劃，該計劃幫助蘋果等公司在潛在安全問題成為漏洞之前發現它們。&lt;/p&gt; 
&lt;p&gt;CVE 基金會預計將在未來幾天公佈更多有關其架構和資金計劃的細節。蘋果和其他大型科技公司可能會在支持其成為網絡安全基礎設施關鍵組成部分方面發揮重要作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345117/the-cve-foundation</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345117/the-cve-foundation</guid>
            <pubDate>Sun, 13 Apr 2025 08:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>特朗普政府考慮在美國禁用 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nytimes.com%2F2025%2F04%2F16%2Ftechnology%2Fnvidia-deepseek-china-ai-trump.html&quot; target=&quot;_blank&quot;&gt;《紐約時報》&lt;/a&gt;週三報道稱，特朗普政府正在考慮對中國人工智能實驗室 DeepSeek 實施新的限制，限制其購買英偉達的人工智能芯片，並可能禁止美國人訪問其人工智能服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-203442edacfcf58c37d7ea5f763fad361b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這些限制是特朗普政府在人工智能領域與中國競爭的舉措之一。在 DeepSeek 震驚硅谷和華爾街數月後，美國官員似乎正在權衡多種方案，以限制中國獲取美國技術和消費者。&lt;/p&gt; 
&lt;p&gt;週二，白宮採取行動限制更多英偉達人工智能芯片以及 AMD 的計算卡產品向中國銷售，加強拜登政府制定的規定。&lt;/p&gt; 
&lt;p&gt;近幾個月來，DeepSeek 在美國人工智能開發者中的人氣飆升，這家初創公司具有競爭力的定價迫使硅谷以更低的成本提供前沿人工智能模型。&lt;/p&gt; 
&lt;p&gt;此前，OpenAI 指控這家中國實驗室對其模型進行了篡改，違反了 OpenAI 的使用條款。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關閲讀：&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338735/openai-calls-deepseek-state-controlled&quot; target=&quot;news&quot;&gt;OpenAI 呼籲美國政府禁止 DeepSeek&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344925&quot; target=&quot;news&quot;&gt;英偉達對華特供版 AI 芯片（H20 GPU）遭遇出口管制&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345109/deepseek-china-ai-trump</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345109/deepseek-china-ai-trump</guid>
            <pubDate>Sun, 13 Apr 2025 08:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節跳動發佈視頻生成基礎大模型 Seaweed-7B</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;字節跳動近日公佈了一個僅 70 億參數的視頻生成基礎大模型「Seaweed-7B」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4514fa3f8394e07ea2ee816465b6d9d857e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseaweed.video%2F&quot; target=&quot;_blank&quot;&gt;https://seaweed.video/&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;令人驚喜的是，該模型以 66.5 萬個 H100 GPU 小時訓練成本，在文本/圖像到視頻生成任務中全面超越 140 億參數的 Wan 2.1，具體來看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seaweed-7B Elo 評分為 1047，勝率 58%，而 Wan 2.1 僅有 53%，OpenAI 的 Sora 更是僅有 36%&lt;/li&gt; 
 &lt;li&gt;可實時生成分辨率為 1280×720、幀率為 24fps 的視頻，比同類模型快 62 倍&lt;/li&gt; 
 &lt;li&gt;40GB 顯存即可支持 1280×720 分辨率生成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據官方介紹，Seaweed-7B 結合了變分自編碼器（VAE）和潛在擴散變換器（DiT）。其中，VAE 負責高效的訓練和推理，而 DiT 則通過擴散模型生成圖像和視頻，顯著提高了生成的質量與效率。&lt;/p&gt; 
&lt;p&gt;另外，團隊為了提升 Seaweed-7B 的訓練效率，採用了多階段訓練策略和 GPU 資源的優化調配。預訓練階段通過低分辨率圖像開始，逐步引入高分辨率視頻訓練，提升了模型的泛化能力。此外，在後訓練階段，通過監督微調和基於人類反饋的強化學習（RLHF）進一步提高了生成視頻的美學質量和運動一致性。&lt;/p&gt; 
&lt;p&gt;目前，Seaweed-7B 相關報告已公開：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseaweed.video%2Fseaweed.pdf&quot; target=&quot;_blank&quot;&gt;https://seaweed.video/seaweed.pdf&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345103/bytedance-seaweed-video</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345103/bytedance-seaweed-video</guid>
            <pubDate>Sun, 13 Apr 2025 08:20:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>馬斯克：特斯拉將實現純 AI 自動駕駛，僅需攝像頭和 AI 芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;馬斯克近日在社交媒體發文稱，特斯拉即將實現一種通用的、純 AI 的全自動駕駛（FSD）解決方案。&lt;/p&gt; 
&lt;p&gt;據其介紹，這一技術將完全依賴於攝像頭和特斯拉自主研發的 AI 芯片，並由特斯拉開發的 AI 軟件驅動。實際上，這一聲明與特斯拉長期以來堅持的僅靠視覺實現自動駕駛的願景相一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/160721_YZPO_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，特斯拉官方 X 賬號近日發佈視頻，稱特斯拉德克薩斯工廠現在使用 FSD 無監督技術將汽車從生產線末端運送到發貨物流區，同時宣佈無監督 FSD 系統已積累超 50000 英里（約 80467.22 公里）駕駛里程，全程無需人工幹預。&lt;/p&gt; 
&lt;p&gt;在特斯拉工廠內部，新款 Model Y 和 Cybertruck 實現了從生產線到交付停車場的自動行駛。自動駕駛車輛運用最新 AI4 硬件（4.0 版），可應對交通標誌、工廠建設、行人和機械化交通等複雜道路環境，且車輛間能相互通信以避免碰撞。&lt;/p&gt; 
&lt;p&gt;據悉，特斯拉無監督 FSD 公路測試計劃即將開啓，預計 6 月於奧斯汀率先開展。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/340233&quot; target=&quot;news&quot;&gt;馬斯克：2024 年特斯拉 AI 投資約 100 億美元、FSD 安全水平將超過人類&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345100</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345100</guid>
            <pubDate>Sun, 13 Apr 2025 08:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Linux 6.16 主線內核將合併 Asahi UAPI，進一步優化支持蘋果 M1 / M2 圖形驅動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Fdri-devel%2Fe147ff95-697b-4067-9e2e-7cbd424e162a%40linux.intel.com%2F&quot; target=&quot;_blank&quot;&gt;根據 Linux 內核郵件列表的消息&lt;/a&gt;&lt;/u&gt;，Asahi 驅動用户空間 API（UAPI）的頭文件已通過 DRM-Misc-Next，被提交至 DRM-Next 隊列，並計劃在 Linux 6.16 的合併窗口（預計為 6 月）正式納入主線內核。&lt;/p&gt; 
&lt;p&gt;這一 UAPI 主要用於支持蘋果 M1 和 M2 系列芯片的 GPU，目標是實現 Linux 系統對這些硬件圖形功能的驅動。&lt;/p&gt; 
&lt;p&gt;UAPI 的設計參考了其他現代 Vulkan 驅動程序（例如 Xe 和 Panthor），採用了顯式虛擬內存管理與同步機制，從而確保運行效率。開發者 Alyssa Rosenzweig 表示，此舉的目的是讓 Mesa 驅動能夠直接基於主線內核構建，減少對外部頭文件的依賴，從而提升系統的兼容性。&lt;/p&gt; 
&lt;p&gt;儘管 UAPI 的頭文件已經提交，但完整的 Asahi 內核圖形驅動目前尚未完成開發。主要原因在於該驅動使用 Rust 語言編寫，而 Rust 在內核中的抽象支持仍需大量的上游工作。&lt;/p&gt; 
&lt;p&gt;此外，作為一款生產級圖形驅動，Asahi 依賴許多尚未合併的 Rust 抽象層，因此短期內難以實現全面的上游整合。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1dade207fb4a37d21fe204449acb7a922be.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，Mesa 開源堆棧已驗證了 UAPI，並支持包括 OpenGL 4.6、OpenGL ES 3.2、OpenCL 3.0 以及 Vulkan 1.4 在內的多種標準。然而，由於用户空間與主線內核之間的對接尚未完全實現，實際應用仍然受到一定限制。&lt;/p&gt; 
&lt;p&gt;Rosenzweig 進一步強調，提交 UAPI 頭文件的主要目的是為了接受社區的審查，以確保其穩定性，並在未來以向後兼容的方式進行演進，從而為後續驅動程序的全面落地奠定基礎。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345097/linux-6-16-ashai-uapi-header</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345097/linux-6-16-ashai-uapi-header</guid>
            <pubDate>Sun, 13 Apr 2025 08:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>豆包公佈 Seedream 3.0 文生圖模型技術報告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;字節跳動旗下「豆包大模型團隊」&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmLRMHXq51HDBN_Vaylm_mw&quot; target=&quot;_blank&quot;&gt;發文表示&lt;/a&gt;&lt;/u&gt;，全新圖像生成基礎模型「Seedream 3.0」技術報告正式發佈。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Seedream 3.0 是一個原生高分辨率、支持中英雙語的圖像生成基礎模型，亮點如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原生 2K 直出，適配多比例場景：無需後處理可直接輸出 2K 分辨率圖像，從手機端到巨幅海報場景的視覺需求均可滿足；&lt;/li&gt; 
 &lt;li&gt;3 秒出圖，大幅提升創作效率：面向海報設計、視覺創意等需求，可實現 3 秒左右快速生成高品質圖像，實現「所想即所得」的實時創意交互；&lt;/li&gt; 
 &lt;li&gt;小字更準，文本排版效果增強：優化小字體高保真生成、多行文本語義排版等業界難題，讓 AI 具備商業級圖文設計能力；&lt;/li&gt; 
 &lt;li&gt;美感 &amp;amp; 結構提升，生成富有感染力：指令遵循進一步增強，人體和物體結構崩壞改善，且進一步弱化了出圖的 AI 感，實現從「看得清」到「有感染力」的審美提升。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/155350_bNhq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，在權威競技場 Artificial Analysis 上，Seedream 3.0 與 GPT-4o、Imagen 3、Midjourney v6.1、FLUX 1.1 Pro、Ideogram 3.0 等文生圖模型同台競技，在近期打榜中，一度排名第一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/154909_oM7T_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Seedream 3.0 已在本月正式上線，目前已在豆包、即夢等平台全量開放。&lt;/p&gt; 
&lt;p&gt;另外，Seedream 3.0 的相關技術報告以及詳細內容也已經上架：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Arxiv：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2504.11346&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2504.11346&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;技術呈現頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fteam.doubao.com%2Ftech%2Fseedream3_0&quot; target=&quot;_blank&quot;&gt;https://team.doubao.com/tech/seedream3_0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345096/seedream-3-0-technical-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345096/seedream-3-0-technical-report</guid>
            <pubDate>Sun, 13 Apr 2025 07:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊開啓史上最大就業計劃，今年六成面向技術人才</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;騰訊&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC1XKIdH8q2DGiYNW-_7wnw&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;啓動史上最大就業計劃，三年內將新增 28000 個實習崗位並加大轉化錄用，其中僅 2025 年，就將迎來 10000 名校招實習生，有六成面向技術人才開放。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;317&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2aeffe1036b528f19b384ec56ffd839c94a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;騰訊方面表示，今年開放的校招實習崗位涵蓋技術、產品、設計、市場、職能等五大類 70 餘種崗位，包括大模型、研發、算法、市場、策劃、運營、銷售、美術等多個崗位職能。同時，在大模型加速落地的背景下，騰訊加大了人工智能、大數據、雲計算、遊戲引擎、數字內容等技術類崗位的招聘力度，技術類崗位「擴招」力度空前，佔比超 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;截至今年 3 月初，騰訊集團目前正式員工人數超 55000 人，其中科技類人才超過 40000 人，佔比高達 73%，這其中，直接從事技術研發工作的員工超 27000 人，佔整體員工人數的近半比例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;騰訊公司高級副總裁、首席人才官奚丹表示：「校招是騰訊最重要的人才來源之一。一直以來，騰訊都高度重視對於校招生的關注和投入，招聘數量在互聯網企業中處於領先。在科技創新驅動發展的時代命題下，騰訊也強化對科技人才的前瞻性儲備，與青年人才共同成長，推進互聯網、大數據、人工智能技術創新。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345095</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345095</guid>
            <pubDate>Sun, 13 Apr 2025 07:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Claude 更新：高級 Research 功能、深度集成 Google Workspace、語音模式即將上線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Claude 母公司 Anthropic 宣佈對其 AI 助手 Claude 進行重要升級，旨在進一步增強其作為高效協作工具的實用性。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;810&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/153302_4zCu_2720166.png&quot; width=&quot;896&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本次更新引入了兩項新功能，&lt;strong&gt;Research 和 Google Workspace 深度集成&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Claude 本次新增的 Research 功能，與此前 OpenAI 在 ChatGPT 中所推出的 Deep Research 類似，能夠主動進行多輪搜索，逐步深入問題並進行多角度探索，最後系統性地為用户提供更高質量的回答內容。值得一提的是，本次 Claude 的 Research 擁有代理式（Agentic）搜索框架，支持自主規劃並執行多步驟搜索任務。&lt;/p&gt; 
&lt;p&gt;其核心特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代理式（Agentic）搜索框架：Claude 不再侷限於單一查詢，而是能夠以代理方式運作，自主規劃並執行多步驟、相互關聯的搜索任務。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;跨源信息整合： 該功能支持同時檢索並分析來自用户授權的內部數據源（如企業知識庫）以及廣泛的互聯網公開信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;系統性問題探索：對於複雜或開放性的用户查詢，Claude 能夠從多個維度進行系統性探索，深度挖掘信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可驗證的綜合答案：最終輸出為結構化、內容全面的回答，並附帶清晰的引用來源，確保信息的可追溯性和可靠性，為用户的決策提供堅實依據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另外，為了增強 Claude 各方面能力，Anthropic 為其深度集成了 Google Workspace 應用套件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;無縫連接核心應用：&lt;/strong&gt;&amp;nbsp;除原有的文檔處理外，Claude 現可直接、安全地連接用户的 Gmail、Google 日曆和 Google 文檔。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自動化上下文獲取：&lt;/strong&gt; 無需用户手動上傳文件或反覆提供背景信息，Claude 可直接訪問並理解郵件內容、日曆安排及文檔細節，自動獲取相關工作上下文。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;情境感知驅動的協助：&lt;/strong&gt;&amp;nbsp;基於對用户工作環境的深入理解，Claude 能夠提供關聯性更強、更精準的輔助，例如根據郵件和日曆信息自動生成會議摘要、識別待辦事項或查找項目相關資料。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;信息透明與可信：&lt;/strong&gt;&amp;nbsp;所有通過集成訪問的信息，Claude 在利用時都會提供內嵌引用，確保操作的透明度和信息來源的可驗證性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/153646_3cnX_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Research&lt;/strong&gt;&amp;nbsp;功能目前處於早期 Beta 測試階段，面向美國、日本、巴西地區的 Max、Team 和 Enterprise 付費計劃用户開放，用户可在設置中啓用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Google Workspace 集成&lt;/strong&gt;同樣處於 Beta 階段，所有付費計劃用户均可在個人設置中啓用。需要注意的是，Team 和 Enterprise 計劃的管理員需先在組織層面授權該集成。&lt;/p&gt; 
&lt;p&gt;另外，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-15%2Fanthropic-is-readying-a-voice-assistant-feature-to-rival-openai&quot; target=&quot;_blank&quot;&gt;根據彭博社的報道&lt;/a&gt;&lt;/u&gt;，Claude 的語音模式即將在本月上線。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345094/anthropic-claude-research</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345094/anthropic-claude-research</guid>
            <pubDate>Sun, 13 Apr 2025 07:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Spark on K8s 在 vivo 大數據平台的混部實戰</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網大數據團隊- Qin Yehai&lt;/p&gt; 
 &lt;p&gt;在離線混部可以提高整體的資源利用率，不過離線 Spark 任務部署到混部容器集羣需要做一定的改造，本文將從在離線混部中的離線任務的角度，講述離線任務是如何進行容器化、平台上的離線任務如何平滑地提交到混部集羣、離線任務在混部集羣中如何調度的完整實現以及過程中的問題解決。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、在離線業務差異&lt;/h1&gt; 
&lt;p&gt;互聯網數據業務服務一般可以分為在線服務和離線任務兩大類，在線服務是指那些長時間運行、隨時響應對實時性要求高、負載壓力隨着接收流量起伏的服務，如電商、遊戲等服務，離線任務是指運行週期短、可執行時間提交對實時性要求低、有一定容錯性、負載壓力基本可控的服務，如離線計算任務、模型訓練等。一般在線服務在白天時段繁忙，離線任務在凌晨繁忙，兩者的業務高峯期存在錯峯現象，如果按傳統方式在線和離線都是分別獨立機器部署，業務高峯時期需要更多機器來支持，業務低峯期又存在部分機器空閒，整體資源利用率都不高。因此行業提出來在離線混部的解決方案，在線和離線業務通過混部系統部署在同一批機器，實現共享資源並錯峯互補，提高整體的資源利用率。目前業內利用混部技術可以將數據中心的 CPU 利用率提升至 40% 左右，vivo 在 2023 年混部平台投入生產也已經將部分混部集羣的 CPU 利用率提升至 30% 左右，整體收益也是可觀的。&lt;/p&gt; 
&lt;p&gt;混部系統需要有強大的隔離能力，絕大部分都是基於容器，所以混部的前提是在線和離線業務都容器化，對於容器管理工具如 K8s 來説是更適應於運行時間長、啓停次數少、容器數量少的在線服務，在線服務也能比較容易地上容器，而對於運行時間短、啓停頻繁、容器數量大的離線任務，對 K8s 來説不是天然地適應，但容器化已是大勢所趨，K8s 也推出了性能更好的調度器、用於離線任務的控制器，Spark 在 2.3 版本後也支持容器化，諸多技術的發展也推動離線任務實現容器化以及在離線混部的落地。&lt;/p&gt; 
&lt;p&gt;本文將從在離線混部中的離線任務的角度，講述離線任務是如何進行容器化、平台上的離線任務如何平滑地提交到混部集羣、離線任務在混部集羣中如何調度的完整實現以及過程中的問題解決。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、離線任務容器化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Spark Operator 方案&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 方案對比&lt;/h3&gt; 
&lt;p&gt;vivo 離線任務大部分任務是以 Spark 作為執行引擎，Spark 任務運行在 K8s 上，目前業界有兩種架構的方案：Spark on K8s 及 Yarn on K8s。兩者部分優缺點對比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//944f211eda9a472ce3e9c7cc7342579a.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark on K8s 是 Spark 容器化，由 K8s 直接創建 Driver 和 Executor 的 Pod 來運行 Spark 作業，Yarn on K8s 是 Yarn 的容器化，由 K8s 創建 RM 和 NM 的 Pod，Spark 的 Driver 和 Executor 運行在 NM Pod 的 container 中，正是由於兩種架構方案的區別，它們各自也會存在優缺點。&lt;/p&gt; 
&lt;p&gt;Yarn on K8s 方案可以支持原生的 Hive、Spark、Flink 等引擎，它僅需要創建一定數量的 NodeManager Pod 來滿足作業需求，Pod 運行相對穩定因此對 K8s 的壓力比較小，本身 Yarn 支持調度性能和調度策略也是專門為離線任務設計的，調度性能比 K8s 的強很多。由於 NodeManager ESS 服務是對磁盤有容量和讀寫性能要求的，混部機器的磁盤一般難以滿足，所以也需要能支持不同引擎的 Remote Shuffle Service。在資源利用上，NodeManager 需要滿足多個作業的資源，最小單位是 Container，Pod 的資源粒度比較大，自身也會佔用一些資源，如果資源粒度得不到有效地彈性伸縮，也會造成資源的浪費，因此需要引入額外的組件來協調,根據 Kubernetes 集羣節點的剩餘資源，動態調整 NodeManager 的 CPU 和內存，然而這也需要一定的改造成本。在資源緊張的情況下，NodeManager Pod 如果被驅逐也就意味着整個 NodeManager 被銷燬，將會影響多個任務。&lt;/p&gt; 
&lt;p&gt;Spark on K8s 方案目前在 Spark 3.1 以上版本才正式可用，它需要頻繁的創建、查詢、銷燬大量的 Executor Pod，對 K8s 的 ApiServer 和 ETCD 等組件都會造成比較大的壓力，K8s 的調度器也不是專門為離線的大批量任務設計的，調度性能也比較弱。另一方面，Spark on K8s 雖然只能支持 Spark3.X 的 RSS，不過目前有較多的開源產品可選擇。在資源利用上，最小單位是 Driver 和 Executor 的 Pod，資源粒度小，可以填充到更多的碎片資源，調度時直接與 K8s 對接，資源的彈性調度更多由 K8s 來承擔，不需要額外的組件，改造成本比較低。在資源緊張的情況下，Executor、Driver 的 Pod 將依次逐個被驅逐，任務的穩定性會更高。&lt;/p&gt; 
&lt;p&gt;而對於 Spark on K8s 方案，還細分 2 種實現方案：Spark Submit on K8s 和 Spark Operator on K8s。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//65d397e91ee4e5dc2fd2dc1392df5e8c.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SparkOnK8s 架構圖&lt;/p&gt; 
&lt;p&gt;(圖片來源：Spark 官網)&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9690ad754f277e44ce4a6a09f6f7058a.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark Operator 架構圖&lt;/p&gt; 
&lt;p&gt;(圖片來源：Spark Operator 開源項目)&lt;/p&gt; 
&lt;p&gt;以 spark-submit 方式提交到 K8s 集羣是 Spark 在 2.3 版本後提供的原生功能，客户端通過 spark-submit 設置 K8s 的相關參數，內部再調用 K8sApi 在 K8s 集羣中創建 Driver Pod，Driver 再調用 K8sApi 創建需要的 Executor Pod，共同組成 Spark Application，作業結束後 Executor Pod 會被 Driver Pod 銷燬，而 Driver Pod 則繼續存在直到被清理。使用 spark-submit 方式的最大好處是由 spark-submit 來與 K8s 的進行交換，提交作業的方式幾乎保持一致。但是因為使用的便利性所需要的封裝也會帶來一些缺點，spark-submit 是通過 K8sApi 創建 Pod，使用非聲明式的提交接口，如果需要修改 K8s 配置就需要重新開發新接口，二次開發複雜繁瑣，雖然 Spark 提供了大量的 K8s 配置參數，但也遠比不了 K8s YAML 的聲明式的提交方式更加靈活，而且 Spark Application 和 K8s Workload 的生命週期還不能較好地對應起來，生命週期不能靈活控制，任務監控也比較難接入 Prometheus 集羣監控。雖然 Spark 社區也不斷地在推出新特性來和 K8s 集成地更加靈活，不過對於些複雜場景需要定製開發，spark-submit 的封裝性也會成為阻礙。&lt;/p&gt; 
&lt;p&gt;spark-submit 還是離線任務提交的思維，而 Spark Operator 方式就更傾向於 K8s 作業的思維，作為 K8s 的自定義控制器，在集成了原生的 Spark on K8s 的基礎上利用 K8s 原生能力提供了更全面管控功能。Spark Operator 使用聲明式的 YAML 提交 Spark 作業，並提供額外組件來管理 Spark 作業的生命週期，SparkApplication 控制器，負責 SparkApplicationObject 的創建、更新和刪除，同時處理各種事件和作業狀態，Submission Runner, 負責調用 spark-submit 提交 Spark 作業，Driver 和 Executor 的運行流程是一致的，Spark Pod Monitor，負責監控和同步 Spark 作業相關 Pod 的狀態。Spark Operator 最大的好處是為在 K8s 中的 Spark 作業提供了更好的控制、管理和監控的功能，可以更加緊密地與 K8s 結合並能靈活使用 K8s 各種特性來滿足複雜場景，例如混部場景，而相對地它也不再像 spark-submit 那樣方便地提交任務，所以如何使用 Spark Operator 優雅提交任務將是在離線混部中一項重要的工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 最終選項&lt;/h3&gt; 
&lt;p&gt;在大的架構選型上，我們選擇了 Spark on K8s，一方面因為 Spark3.X 是 vivo 當前及未來 2~3 年的主流離線引擎，另一方面 vivo 有比較完善的 K8s 生態體系，內部對 K8s 研發也比較深入，環境和能力都能很好地支持，在應用的小方向上，我們選擇了 Spark Operator，因為它在混部這種複雜場景下使用更加靈活、擴展性更強、改造成本更低，我們最終決定使用 Spark Operator 方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 Spark 優化&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 Spark 鏡像&lt;/h3&gt; 
&lt;p&gt;Spark 任務容器化的第一步就是構建具有 Spark 相關環境的鏡像，Spark 任務類型主要分為 sql 任務和 jar 任務，在實踐的過程中我們發現 Spark 的鏡像構建需要&lt;strong&gt;注意幾個問題&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark 環境的完整性&lt;/strong&gt;：鏡像中除了打入自研的 Spark 包以外，還需要打入相應的依賴如 Hadoop、ZSTD、RSS 等包，對於 SparkJar 任務還有直接調用 Hadoop 客户端的，因此 Hadoop 客户端也需要打入鏡像中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JDK 版本問題&lt;/strong&gt;：K8s 使用的 Spark 是基於 3.2.0 版本，鏡像打包工具默認使用 JDK11，而自研的 Spark 用的 JDK1.8，由於在 Yarn 和 K8s 上使用的 JDK 版本不同，導致在雙跑驗證數據一致性時發現了 hash 函數、時間戳不一致的問題，因此 Spark 鏡像中的 JDK 版本需要和 Yarn 保持一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;環境變量問題&lt;/strong&gt;：鏡像生成容器後需要預置如 Spark、Hadoop 的環境變量，如果鏡像中相關目錄的位置不能完全和 Yarn 的提交節點保持一致，則需要檢查各啓動腳本，如 spark-env.sh 中的環境變量的路徑是否存在，發生衝突時可以修改為絕對路徑。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Spark 鏡像構建完成後，區分 SparkSql 任務和 SparkJar 任務實質就是啓動命令的不同，事實上 SparkSql 任務也就是 SparkJar 任務的一種，只是啓動的主類是固定的，兩者的啓動參數如下：&lt;/p&gt; 
&lt;p&gt;SparkSql 任務：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver -f {sql 文件}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SparkJar 任務：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class {jar 任務主類} {jar 任務 jar 包} {參數}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;早期不僅構建了 Spark 鏡像，還構建了 Spark 日誌鏡像，容器組成結構會複雜一些。如圖例如 Driver 容器，我們將 Spark、Hadoop 等配置文件構建了 configMap，啓動 initContainer 來拉取從 configMap 拉取配置文件，然後啓動 Driver 容器執行 Spark 任務，同時也使用 sidecar 創建日誌上報的容器，在 Spark 任務運行完成後上報 Driver 和 Executor 日誌到 Spark HistoryServer。這樣的方案看似充分應用了 K8s 技術，但是在實踐的過程中這些技術卻被一一棄用，轉而逐步地把各種功能集中到了一個 Driver 容器上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c1f0bf5a2f03578b42831a80908e1aad.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體演進如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 initContainer&lt;/strong&gt;，拉取 Spark 等配置文件步驟寫在啓動命令中，Spark 作業執行前執行下載配置，原因在多個 namespace 下不方便統一管理，而且 configmap 內容較大，會導致 Pod 啓動時配置加載的延遲增加，影響了 Pod 創建速度，同時 K8s 的內存和 CPU 資源佔用增加，對 kube-apiserver、ETCD 負載有一些影響。去掉 initContainer 還有個重要的好處就是減小 ETCD 的存儲壓力，事實上我們在移除 initContainer 拉取配置的功能後的一段時間內還保留着 initContainer，在任務逐漸上量後發現 ETCD 的存儲比較滿，分析後發現 Spark 作業中的一個 Pod 生命週期大約 8 次更新，其中 initContainer 更新會佔用 2 次，移除了之後理論上是可以減少 1/4 的 ETCD 存儲，實際應用中完全去除了 initContainer 也確實能減小了 ETCD 的存儲壓力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 sidecar 創建日誌上報的容器&lt;/strong&gt;，Driver 和 Executor 日誌上報步驟寫在啓動命令中，Spark 作業執行完後再執行腳本上報，原因是 sidecar 在同一個 Pod 中與主容器共享相同的生命週期，不使用 sidecar 方式就能更快創建 Pod，Spark 任務執行完成後能更快釋放資源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於 Spark 作業會頻繁創建、更新和銷燬大量的 Pod，所以去除非必要的容器，提高 Pod 生命週期流轉速度，就能降低 kube-apiserver、ETCD 工作負載，也能提高 Spark 的作業效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 Spark 改造&lt;/h3&gt; 
&lt;p&gt;Spark 任務運行在 K8s 上，對於一些使用的兼容問題也進行了&lt;strong&gt;相關改造&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HistoryServer 改造&lt;/strong&gt;，因為 Spark Operator 沒有存儲已結束作業的日誌，因此參考了 on Yarn 的方式，在 Spark 作業結束後，通過日誌上傳腳本把 Driver 和 Executor 的日誌上傳 HDFS，與 Yarn 日誌聚合類似，同時也在 Spark HistoryServer 做了二次開發工作，增加了 on K8s 方式的日誌查看接口，用户查看已完成的 Executor 日誌時，不再請求 JobHistory Server，而是請求 Spark HistoryServer 接口。但日誌上傳方式需要 Executor 執行完才能查看到日誌，為了能實時查看到執行中的日誌，可以在 Executor 內部實現一個 HTTP 服務，根據 Pod 以及端口信息拼接出日誌請求 URL，Executor 啓動一個 Servlet 自動獲取本地日誌並返回。日誌查看體驗上做到了基本與 Yarn 一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主機 ip 通信&lt;/strong&gt;，Spark Driver 和 Executor 之間的通信通常是通過主機名進行的，不過隨着 Spark 任務增多，CoreDNS 因為頻繁的域名解釋請求導致壓力增大，甚至會影響到在線服務，因此我們將 Hadoop 的配置文件改為 ip 格式、設置 Driver 和 Executor 使用 ip 地址，同時去除了對應的 K8s Service，通過訪問 ip 而不是域名的方式來規避這個問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件參數兼容&lt;/strong&gt;，Spark Driver 在 K8s 上是運行在某一個 Pod 中的，所以文件需要是全局可視的，如 HDFS 文件，否則就會報文件未找到的錯誤，但 Spark 作業運行在大數據作業平台時有的任務使用的上傳的本地文件，因此對於提交到 K8s 的任務，第一步是要把上傳到大數據作業平台的文件再次上傳到 HDFS，第二步是改造 add jar 和--file 等命令邏輯，Spark 任務在未能讀取本地文件後將再嘗試讀取二次上傳到 HDFS 的文件，實現任務無需修改成全局可視的文件路徑也能讀取到文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;non-daemon 線程終止&lt;/strong&gt;，在 K8s 上運行的 Spark 任務是指定 Client 模式，Client 模式下 Driver 遇到異常時停掉 SparkContxet，等所有 non-daemon 線程結束後，Driver 才會退出，但如果存在一直運行的 non-daemon 線程，那麼 Driver 一直不退出，任務就一直處於執行中。因此需要改造成 Cluster 模式的異常退出機制，即異常時以非 0 退出碼退出，不再等待其他的 non-daemon 線程結束，Driver 直接終止，以確保 Driver Pod 的正常結束。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Spark Operator 優化&lt;/h2&gt; 
&lt;p&gt;隨着在 K8s 上運行的 Spark 任務不斷增加，K8s 集羣的負載也逐漸顯現。因此，需要對 Spark Operator 進行一系列優化，以減輕 K8s 集羣的壓力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;離線使用獨立的 kube-apiserver&lt;/strong&gt;，混部集羣中離線容器佔了很大一部分，而且離線任務由於生命週期短，容器創建銷燬更加頻繁，這對 kube-apiserver 造成了很大的壓力，然而在線業務需要更高的穩定性，為了減少離線對在線業務的影響，我們拆分了 kube-apiserver，離線任務通過指定 master 參數來使用獨立的 kube-apiserver。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 K8s 的 HostNetwork 網絡模式&lt;/strong&gt;，在 K8s 上啓動 Driver 與 Executor 雖然使用的是獨立 ip+固定端口，但頻繁的 ip 申請和釋放也對 kube-apiserver 造成了一定的壓力，因此我們改為使用 HostNetwork 網絡模式，同時不指定端口避免端口衝突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化 Spark Operator 控制器的隊列&lt;/strong&gt;，在任務量比較大的情況下，Spark Operator 對 Pod 創建消耗效率會遇到瓶頸，排查後發現是 Spark Operator 的事件處理隊列的併發數和限速桶的默認配置地太小，因此我們調低 Spark maxPendingPods 參數，調高 schedulerBacklogTimeout、 sustainedSchedulerBacklogTimeout 參數，減少 Pending Pod 個數，使 Pod 的處理效率符合集羣的承載水平。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化 Spark Driver List Pod 接口&lt;/strong&gt;，使用 kube-apiserver 緩存，避免對 ETCD 產生影響，同時修改 Spark Driver 清理 Executor 邏輯，直接 Delete，減少 List Pod 對 kube-apiserver 壓力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存儲 emptydir + log lv 存儲優化&lt;/strong&gt;，開發 CSI 插件，Spark 任務的離線日誌單獨存儲，避免對在線業務 pod 的影響和磁盤負載高等問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark Secret 標記 immutable&lt;/strong&gt;，減少 kubelet watch secret 請求，降低 kube-apiserver 的負載。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、離線任務提交&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 平台任務提交平滑切換&lt;/h2&gt; 
&lt;p&gt;離線任務容器化方案確定後就要落地到生產，目前有 SparkSql 和 SparkJar 兩種離線任務實現了容器化，這裏以 SparkSql 任務為例描述 Spark 提交到混部 K8s 集羣的流程並達到與傳統客户端提交任務幾乎無差異的平滑切換。目前 vivo 的離線任務都是通過大數據平台進行提交和調度的，平台會把主要的提交流程進行封裝形成簡單操作的功能，例如在平台上提交 SparkSql 任務流程一般是編寫 sql、提交任務、查看 Driver 日誌或在跳轉到 SparkUI、執行完成後獲取結果以及更新任務狀態。&lt;/p&gt; 
&lt;p&gt;在平台內部，SparkSql 任務使用傳統的 spark-submit&lt;strong&gt;提交流程&lt;/strong&gt;是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户編寫好的 sql 上傳到提交節點生成一個 sql 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交節點使用 Spark 客户端執行該 sql 文件啓動 SparkSql 任務；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務啓動後，通過不斷地 tail 操作查詢日誌轉存到 HBase 方便在平台頁面上查詢到 Driver 日誌；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務結束後，再查詢輸出結果轉存到 HBase 方便在平台頁面上查詢到執行結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根據提交 sql 任務命令的返回碼來更新任務狀態。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;傳統 Spark 客户端提交任務大部分只會涉及到提交節點的客户端與平台服務器之間的交互，而 SparkSql 任務提交到混部 K8s 集羣，從上節的 Spark 容器化方案的原理可知最終目的是要將 Spark 任務的任務參數按一定的格式封裝好傳入 Spark Operator 控制器來創建相關的容器，平台需要通過會調用容器團隊提供的封裝好 K8sApi 的統一接入層來創建 Spark 容器。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//15dcd589c32637e1dde5ed6757b4eed7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在平台內部，SparkSql 任務提交到混部 K8s 集羣的&lt;strong&gt;完整流程&lt;/strong&gt;為：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户編寫好的 sql 上傳到 HDFS 生成一個遠程可訪問的 HDFS 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SparkSql 任務參數封裝好傳入容器接入層的 createSpark 接口來調用 Spark Operator 控制器容器，再由 Spark Operator 控制器創建 Driver Pod，最後由 Driver Pod 根據 Spark 任務需要創建多個 Executor Pod，這些 Driver、Executor 的 Pod 相當於 Driver 和 Executor 的角色，共同配合執行 Spark 作業；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務啓動後，通過容器接入層的 getDriverLog 接口週期性地查詢 Driver 日誌，實質上是查詢 Driver 容器的日誌，查詢到的 Driver 日誌會轉存到 HBase 方便在平台頁面上查詢；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務結束後，一方面通過 Spark 啓動腳本中的日誌上傳命令，把 Driver 和 Executor 的日誌上傳 HDFS，可以在改造後的 Spark HistoryServer 直接查看，另一方面執行結果也會先輸出到 HDFS，再從 HDFS 轉存到 HBase 方便在平台頁面上查詢到執行結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過輪詢接入層的 getSpark 接口根據返回的狀態碼來更新任務狀態，在任務結束後，此時 Driver Pod 不會主動退出，首先將任務狀態更新為成功，在日誌和結果都存儲完成後，再調用 deleteSpark 接口主動地殺死 Driver Pod 釋放資源，完成整個 Spark 任務流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;可以看出 SparkSql 任務提交到混部 K8s 的執行主體是容器，因此需要增加容器接入層來管理 Spark 相關的容器，同時容器的使用更傾向於存算分離的效果，因此需要使用 HDFS 作為遠程文件中轉。&lt;/p&gt; 
&lt;p&gt;大數據平台上傳統使用 spark-submit 和 onK8s 使用 spark-operator 的 SparkSql 任務執行流程對比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//024fa2e15ecb64123b58156eb1fd2188.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 混部任務的資源參數調整&lt;/h2&gt; 
&lt;p&gt;Spark 任務的 Driver 和 Executor，在 Yarn 上執行實質是運行在 NodeManager 節點上的，而在 K8s 上執行實質是運行在對應的 Pod 中的，由於 Spark on K8s 的提交方式和運行環境都不同於 on Yarn，任務的資源參數不能直接套用，需要做一些參數調整才能提交到 K8s 上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、資源參數提取和轉換&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SparkSql 任務在 Yarn 上可以靈活地調整 sql 中的配置來滿足不同特性的任務，sql 中的資源配置會覆蓋客户端啓動時的全局配置，因為 Executor 是運行在 NodeManager 節點上的，資源會相對充裕能滿足 Executor 的資源需求，與此不同的是 Spark on K8s 的 Executor 是運行在 Executor Pod 中的，使用的資源會受到 Pod 資源規格大小的限制，而 spark-operator 的提交方式是要先獲取 Executor 全局資源規格並生成相應資源規格大小的 Executor Pod，所以在提交 Spark 任務到 K8s 前就要準確地獲取任務真正生效的資源參數。在大數據平台中資源參數會存在多中類型的參數中，參數的優先級為：任務配置參數 &amp;lt; 任務模板參數 &amp;lt; sql 中設置參數 &amp;lt; HBO 優化參數 &amp;lt; 平台統一參數，按此優先級順序依次提取最終的資源參數並傳入容器接入層創建 Spark 作業。另外容器接入層對於 Spark 的 arguments 和 sparkConf 參數都是要求以字符數組的方式傳入，需要做好對原任務參數中的單引號、雙引號、反斜槓和回車等符號以及分段落的處理和轉換。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、overheadMemory 的計算&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Yarn 上 Executor 是運行在 NodeManager 節點上的，節點的資源一般都大於並能滿足 container 申請的資源，所以在 Yarn 上只需要關心 container 本身申請的資源即可，而在 K8s 上 Executor 運行在對應的 Pod 中，可以把 Pod 理解為只一台獨立的節點，除了要滿足 container 申請的資源量，還需要一些 Pod 容運行時網絡、存儲等基礎設施的自身開銷資源，如果把 Spark 任務中 Driver 和 Executor 申請的資源直接設置為 K8s 中 Driver Pod 和 Executor Pod 的資源規格，有可能出現 OOM 情況，另外還要考慮非 JVM 內存，Spark 默認會把申請的 Executor 內存乘以一個係數或者至少預留 384 MiB 內存作為額外的非 JVM 內存緩衝區，用於堆外內存分配、非 JVM 任務以及各類系統進程的使用，可以通過設置 overheadMemory 進行覆蓋。因此 K8s 的 Pod 除了要滿足申請的 Memory 和運行時需要的 overheadMemory 的資源，還會再添加 100M 資源用於 Pod 運行的自身開銷。&lt;/p&gt; 
&lt;p&gt;pod 的資源規格 = memory + pod overheadMemory&lt;/p&gt; 
&lt;p&gt;對於 overheadMemory 也需要先獲取到並加到 Pod 的資源規格，如果任務有配置就直接使用配置的 overheadMemory，如果沒有配置值則按一定計算公式來計算得到。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = overheadMemory + 100M&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;無配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = (max(384M，0.1*memory)) 向上取整到 512MB 的整數倍 + 100M&lt;/p&gt; 
&lt;p&gt;不過在實際應用中發現對於個別任務，即使 K8s 上配置的 overheadMemory 比在 Yarn 的配置多 100M，完全一樣的任務在 K8s 上則有較多的 Executor OOM 情況，而在 Yarn 上卻完全沒有，目前排查到的現象是有 JVM 堆外的內存無法回收，如果任務需要較多的對外內存，堆外內存一直增長最終導致 OOM，但哪些內存無法回收的還未排查到。目前對於這些 OOM 過多且實際影響到運行效率的任務，在原 overheadMemory 基礎上再增加 512M 後就沒有 OOM 情況了，同時也有采用了大數據平台的 HBO 能力自動調整內存參數來事後規避這個問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、CPU 超分配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spark 任務申請的 CPU 使用一般不會使用完，事實上 Executor Pod 的 CPU 利用率也並不是很高，比如 Executor 申請 1 個核，通常只能利用 0.6 個核，存在 CPU 浪費的現象。Executor Pod 的資源規格是創建的時候分配的，利用容器的能力，可以採取 CPU 超分的方式提高 CPU 的利用率，例如 Executor 申請 1 核，實際用 0.6 核，如果 Pod 分配 1 核，那利用率就只有 60%，但如果 Pod 只分配 0.8 核，那利用率就有 75% 了，所以超分的策略就是申請了 1 核只給 0.8 核，但還是要按 1 核的申請量來運行任務。目前平台使用的是靜態的固定比例超分設置為 0.8，實施超分配置策略後 Pod 的實際 CPU 利用率打到 80% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//29fe0829e28d1e2084e2dbba0910de3a.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 混部任務的篩選提交&lt;/h2&gt; 
&lt;p&gt;經過上面的任務提交方式的改造和任務資源參數的調整，原 SparkSql 和 SparkJar 任務就可以平滑切換提交到混部 K8s 上執行了，但在大規模切換之前平台還做了比較長期的雙跑驗證工作，在執行成功率、數據一致性和執行時效等方案都進行了雙跑比較，雙跑通過的任務才能切換到 K8s 上執行。除了雙跑通過，前期還設置了其他的篩選條件如下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//698830de13538cf7b2a6cf67d0b6fa45.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前期按這些條件篩選出可以提交到 K8s 的任務，然後分批的進行 K8s 任務的參數標記，並把標記的這批任務添加監控進行跟蹤。經過雙跑驗證、任務篩選、批量標記、監控跟蹤和問題解決這一整套 SparkSql 任務上量 K8s 的流程，K8s 上的任務運行逐步穩定，K8s 的兼容問題也基本解決，因此目前取消了雙跑通過的這一條件，主要保留了任務重要性、運行時長和重試次數這幾個篩選指標。隨着 SparkSql 任務上量和穩定，提交到 K8s 的任務類型也增加了 SparkJar 任務，SparkJar 任務無法進行雙跑驗證，所以在各種 K8s 兼容問題解決後再推進會更加穩妥。&lt;/p&gt; 
&lt;p&gt;目前大數據平台會定期篩選和標記一批 SparkSql 和 SparkJar 任務允許提交到混部 K8s，用户也可以自行開啓，在任務配置頁面只顯示已開啓混部，則該任務就有機會被提交到混部 K8s 上執行。當然，用户也可以手動關閉這一開關，並且手動操作的優先級最高，手動關閉後平台的自動開啓功能將不再生效。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、彈性調度系統&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 彈性調度功能矩陣&lt;/h2&gt; 
&lt;p&gt;Spark 任務開啓了混部也不是必定能提交到混部，最終能不能在混部集羣上執行，還要根據當時混部集羣的資源和運行情況等來確定，為了更好地協調離線任務和混部集羣的供需關係，大數據平台構建了離線任務混部彈性調度系統。彈性調度系統的設計目是混部集羣有資源了就調度離線任務，但在生產環境中不管是混部集羣還是離線任務都會各自的問題需要解決和優化的需求，彈性調度系統也逐步演變成了全面管理離線任務提交到混部以實現混部資源最大化利用的功能矩陣。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.1 資源水位線調度&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//878bdd653f0ec47e7c32fe0b09e8f975.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;彈性調度的流程，任務按調度時間以任務流的形式過來，如果任務標記了允許提交到混部，那就會先去查詢 K8s 的各個集羣，如果某一個集羣資源充足就直接提交到 K8s，如果當時沒有足夠資源就等待資源再判斷，這裏分為有三類任務，第一類是一直等 K8s 資源，永不超時，只會提交到 K8s；第二類是長時間等待，超時時間在 1 到 5 分鐘，可以等久一點；第三類是短時等待，超時時間為 30-60 秒，稍微等一下，如果 K8s 沒有資源就回到 Yarn 上執行，目前平台標記的任務大部分任務都是第三類短時等待。&lt;/p&gt; 
&lt;p&gt;混部集羣提供給離線任務的資源是呈潮汐波動的，使用百分比的水位線方式才能更好地貼合資源的波動情況。混部集羣提供的資源是指 CPU 和內存，但離線任務一般不能百分之百地獲取到這部分資源，需要設置一個折算比例也就是水位線來計算出離線任務能使用的真正資源是多少，水位線的設置需要考慮&lt;strong&gt;幾個因素&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、混部集羣的碎片化率&lt;/strong&gt;，混部集羣中的機器規格和正在運行的業務佔用量都是不確定的，但一般大規格的機器多的集羣碎片化率較低，所以小規格的機器多的集羣的水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、資源動態分配容納率&lt;/strong&gt;，對於開啓了動態分配的 Spark 任務，無法提前知道任務所需的資源，需要留有一部分資源用於動態分配的消耗，如果同樣的水位線資源規模大的混部集羣容納率會高，所以資源規模小的集羣的水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、資源配比的均衡性&lt;/strong&gt;，不同的集羣或者同一集羣的不同時間段的 CPU 和內存配比可能會存在很大的差異，例如 Spark 任務的 CPU 和內存的平均比例是 1 核 6G，即 1:6，如果有 CPU 和內存比為 1:2 的，內存會被用完而 CPU 有剩餘，此時為了內存留有部分餘量，水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部資源可用量 = 混部資源提供量 * 資源水位線&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;資源水位線有 CPU 水位線和內存水位線，設計時以 CPU 或內存中的最低水位線為準，哪個資源先分配完就停止提交任務，不過在實際生產中大部分混部集羣都是受內存限制較多，個別時段 CPU 比內存多但通過其他的限制手段即使 CPU 滿載對任務影響不大，因此目前只開啓了內存資源水位線。以上提到的 3 點可以當成集羣的固有消耗需要保留有一定的餘量，為了直觀地控制混部資源使用率和引入優先策略，計算方式調整為：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部資源可用量 = 混部資源提供量 * (1-餘量水位線) * 優先水位線&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;餘量水位線根據各個集羣來調整，一般為 0.05，優先水位線的範圍可以在 0-1 之間。優先水位線的作用是對於一些符合優先條件的任務可以優先提交，但是任務調度是一有任務就要調度的流式調度，不能夠先集中再挑選優先任務而是先到先得，所以要為優先任務預留一部分資源，例如優先水位線為 0.8，混部資源使用到 0.8 以下的時候任何任務都可以調度上來，但使用量超過了 0.8，那只有優先任務能調上來，也就是為優先任務預留了 0.2 的資源，當然即使資源使用量達到了 1，由於餘量水位線的存在，實際的使用量為 0.95，混部集羣仍有資源維持週轉。優先水位線是最常用的調整參數，它實質就是控制混部任務提交量，不僅能調整混部資源的使用量，還在灰度測試、壓力測試和問題排查等事項起到了靈活調節的作用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.2 其他調度能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1.多集羣管理&lt;/strong&gt;：混部集羣通常會有多個，vivo 目前就有多個生產環境的混部集羣，各混部集羣由於建設週期、機器規格和業務接入的不同，混部資源的規模和變化趨勢都會呈現比較大的差異，因此每個集羣的調度策略配置都需要做到能獨立調整來適應各自的資源特點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.分時段控制&lt;/strong&gt;：每個混部集羣上的在線業務一般是潮汐波動的，給到離線任務的資源也是潮汐波動的，因此每個集羣需要做到在每天不同時段可以調整不同的調度策略，尤其在波峯波谷差異較大的時間段各自調整配置的差異會更大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.分散 namespace&lt;/strong&gt;：Spark 任務的 Driver Pod 和 Executor Pod 都會放在一個 namespace 中管理，如果所有任務都由一個 namespace 管理，那需要管理的 pod 數量會達到數十萬的級別，會對 K8s 集羣的性能和穩定性產生影響。因此需要將 Spark 任務平均分配到多個 namespace，採用的方案是輪詢填充，任務優先分配到多個 namespace 中任務最少 namespace。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.失敗回退 Yarn&lt;/strong&gt;：離線任務混部推進的過程中還有會有 Spark 兼容問題、混部集羣異常和平台變更等問題導致的離線任務在混部 K8s 上運行失敗，為了減少失敗對任務的影響，任務在 K8s 上首次執行失敗後就會自動回到 Yarn 重新執行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.資源准入粒度&lt;/strong&gt;：各混部集羣的機器規格和碎片率是不一樣的，如 executorMemory=2G 這樣較小粒度的 Spark 任務即使碎片率較高的混部集羣可以填充，而對於 executorMemory=16G 這樣較大粒度的 Spark 任務，機器規格大的集羣才更容易獲取到資源，因此不同混部集羣可以設置不同的准入粒度，小規格和碎片率高的集羣准入粒度可以設置小一些。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6.任務偏好配置&lt;/strong&gt;：對於一些灰度任務和特殊要求的任務，例如只有在 0 到 8 點才允許提交到混部、只提交到某幾個指定的混部集羣等調度要求，需要支持任務偏好配置，在任務參數中調整混部控制參數實現相應的調度需求。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 彈性調度策略優化&lt;/h2&gt; 
&lt;p&gt;彈性調度的核心是通過資源水位線的調節，有混部資源就調度離線任務，但實際生產中還要考慮混部集羣的運行情況，是否能穩定地接收和消化離線任務，同時在存在多個差異較大的集羣時提交到哪個集羣最優。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1 任務調度穩定優化&lt;/h3&gt; 
&lt;p&gt;大數據平台的離線任務提交高峯在凌晨時段而且調度時間集中在整點半點，還有 5 分和 10 分這樣的整分，例如 03:00 調度的任務達 1000 個，但在 03:01 調度的任務只有 10 個，過於集中地提交任務會導致混部集羣 Pending Pod 數量急劇上升，這是因為無論是查詢集羣資源還是 Pending 數的接口，更新數據都需要一定的週期時間，而且離線任務提交上去到獲取資源也受 K8s 的調度時間的影響，所以獲取集羣運行情況總會滯後於任務提交。例如 03:00 查詢集羣是有資源的並且是健康的，由於任務開啓了動態分配所以不能確定需要多少資源，此時集中提交了 1000 個任務，這 1000 個任務首先會創建 1000 個 Driver Pod，集羣資源還是能滿足的並且優先創建，假如每個 Driver 需要創建 100 個 Executor，如果集羣沒有這麼多資源，那就會產生大量的 Penging Pod，嚴重影響集羣的性能和穩定以及任務的執行效率，因此需要對彈性調度的穩定性進行優化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短時提交限制&lt;/strong&gt;：避免集中提交任務的直接方案就是根據各混部集羣的資源規模設置短時提交的任務數量限制，例如 1 分鐘內只能提交 100 個任務，集羣短時間內 Pending Pod 數量會增加但仍在可以承受範圍內，集羣和任務都會穩定運行。短時提交限制相當於攔截並捨棄了部分某個時間點集中提交的任務，這裏相當於捨棄了 900 個任務，那麼提交的總任務量就減少了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;延遲打散提交&lt;/strong&gt;：為解決短時提交限制導致捨棄部分任務的問題，增加了短時延遲打散提交，例如 03:00 提交的 1000 個任務，隨機打散到 03:00 到 03:03 的 3 分鐘內，即使有短時提交限制，這 3 分鐘內也可以提交 300 個任務。理論上將集中提交的任務延遲更久，能提交到混部的任務會更多，但是增加延遲時長就等於增加任務的執行時長，會影響到業務數據產出的及時性，因此延遲打散提交策略只能是短時的，進一步的優化是執行時長更久的任務延遲更久一點，但根本解決方案還是用户能將調度時間儘量打散。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集羣反饋限制&lt;/strong&gt;：短時提交限制和延遲打散提交都屬於靜態限制，需要人為地根據各個混部集羣的情況去判斷和設置限制值，因此需要做到動態限制，就需要獲取集羣的運行情況並根據運行情況進行限制。事實上 K8s 的調度性能相比於 Yarn 還是有差距的，從提交的 Spark 任務到獲取到資源運行 Pod 有一定的滯後時間差，這段時間查詢內還是有剩餘資源，但如果還繼續提交新任務就會產生更多 Pending Pod，因此需要做集羣運行情況的反饋控制，例如查詢 Pending Pod 數、等待的 SparkApp 數，當數量達到一定數量就不再提交新任務。&lt;/p&gt; 
&lt;p&gt;集羣反饋限制雖然是動態的能根據混部集羣情況進行反饋調節，但是查詢集羣狀態是滯後的，這種滯後的控制就容易被集中提交給打垮，所以要加上短時提交限制來上一道保險，為緩解短時提交限制造成的任務損失，就引入了延遲打散提交，而在延時打散的過程中集羣能逐步消化任務，查詢集羣狀態逐步接近真實情況，這時又可以交給集羣反饋限制來動態調節，逐步從突增恢復到穩定，三個調度穩定優化策略相輔相成。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 集羣分配均勻優化&lt;/h3&gt; 
&lt;p&gt;離線任務會調度到多個混部集羣，每個集羣的資源總量和可用資源量，以及集羣運行狀況都不相同，為保證離線任務的運行穩定和執行效率，需要在多個混部集羣中選擇一個最合適的集羣。各個集羣會按一定的規則進行排序，離線任務會按這個排序依次輪詢各個集羣，只要集羣剩餘資源滿足且沒有被短時提交限制、集羣反饋限制等拒絕，離線任務就提交到該集羣。集羣排序的&lt;strong&gt;演化順序&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;①初始方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排隊隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;剩餘資源量多的優先&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b0cade1eb777379e3744a4104790af8.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源最多的集羣，保證離線任務運行穩定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於小集羣剩餘資源量很小一直分配不到任務容易「餓死」（事實上有的小集羣全部資源量都達不到一個大集羣的 20%）&lt;/p&gt; 
&lt;p&gt;② 優化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;將資源使用量超過一定比例的集羣放到排序隊列，剩餘的集羣放到隨機隊列&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c8b8441d6a201f0d2e84113fcc307c2f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源較多的集羣，即保證任務的運行穩定，隨機的方式也能均勻「餵飽」每個集羣&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨機分配在大任務量時相當於是平均分配，每個集羣都會調度差不多的任務量，當前情況會存在整點集中提交大量任務，小集羣接收和大集羣同樣任務量會抗不住，影響任務執行穩定和效率，小集羣容易「撐死」&lt;/p&gt; 
&lt;p&gt;③再優化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加權隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;按剩餘資源進行加權隨機，剩餘資源多的集羣有更多概率分配到任務&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39918d1411bca61982582118837a610.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源較多的集羣，「大集羣多吃，小集羣少吃」，每個集羣都能填充同時保證任務的運行穩定&lt;/p&gt; 
&lt;p&gt;④ 最終方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優先隊列（排序）+加權隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考慮優先隊列，無視其他排序規則，優先隊列裏的集羣將最優先，在優先隊列中的集羣再按資源排序&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//db44e6961fb051bfbb59cb66ff17797f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;繼承上一方案的優點，同時對於特定項目或機房的離線任務，能優先調度到某些特定的集羣&lt;/p&gt; 
&lt;p&gt;目前只以內存作為資源水位線的衡量標準，這裏的資源量指的是內存量。最開始方案是按集羣的剩餘資源排序，內存資源剩餘多的集羣優先，缺點是小集羣一直分配不到任務容易「餓死」，然後使用隨機的方式也能均勻「餵飽」每個集羣，但小集羣接收同樣任務量時容易「撐死」，於是隨機隊列按剩餘資源進行加權隨機，剩餘資源多的集羣有更多概率分配到任務，這樣離線任務優先提交到資源較多的集羣，「大集羣多吃，小集羣少吃」，每個集羣都能填充同時保證任務的運行穩定，在此基礎上增加優先隊列，無視其他排序規則，優先隊列裏的集羣將最優先，在優先隊列中的集羣再按資源排序，能優先調度到某些特定的集羣，形成最終集羣選擇排序方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_21&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、混部的效果與未來規劃&lt;/h1&gt; 
&lt;p&gt;經過以上的對 Spark 組件、K8s 混部系統、大數據平台以及彈性調度系統的改造和優化，目前混部集羣及提交混部的離線任務運行持續穩定，每天任務調度到混部的次數達 10+萬次，在凌晨的高峯期通過混部能為離線任務額外增加數百 TB 內存的計算資源，部分混部集羣的 CPU 利用率提升至 30% 左右，整體收益也是可觀的。&lt;/p&gt; 
&lt;p&gt;雖然目前 vivo 的在離線混部達到了一定的規模，但未來要繼續提高混部的規模和收益，還有規劃一些改進工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;1、提高離線任務混部規模。&lt;/h2&gt; 
&lt;p&gt;離線任務混部的節點是在線業務提供的，節點規模取決於在線業務峯值，峯值越高那麼在業務低峯期能提供給離線混部資源就越多，因此提高混部規模的重要因素是提交更多的離線任務。然而目前採用的 Spark Operator 方案能提交的離線任務只有標準的 SparkSql 和 SparkJar 任務，而對於非標準的任務如腳本任務，腳本中除了調用 spark-submit 提交 Spark 作業還有額外的處理邏輯，這類任務還不能直接以 Spark Operator 的方式提交。事實上 Spark 作業更多是來自腳本任務的非標準任務，如果要繼續增加離線任務的量，就必須把非標準任務也提交到混部，因此後續是選擇改造 spark-submit 客户端支持 Spark Operator，或是選擇使用 Yarn on K8s，還需要綜合評估。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2、提高離線任務混部收益。&lt;/h2&gt; 
&lt;p&gt;目前混部節點 CPU 的平均利用率達到 30%，但仍有提升空間。從離線任務的角度來看，一方面是要增加錯峯互補的時間段，例如離線任務的高峯期是 02:00 到 08:00，在線業務的高峯期是 06:00 到 23:00，在 06:00 後在線業務逐步上量開始回收資源，所以離線任務能顯著提高混部集羣 CPU 利用率的黃金時間是有 02:00 到 06:00 這 4 個小時，因此如果能把離線任務高峯期提前到 00:00 到 06:00，混部提效的黃金時間就能達到 6 小時。所以需要推動離線任務高峯期的前移，對於有依賴鏈路的任務，儘量減少調度時間的間隔，上游任務完成後能儘快調起下游任務，而對於沒有依賴的任務，可以儘量提前調度時間，不過這兩種調整都需要推動業務方來調整，平台也可以給予一定的計算成本優惠作為激勵。另一方面是要提高混部資源的填充率，Spark 任務需要創建大量的 Executor Pod，目前混部集羣的調度器為了保證調度效率就沒有開啓預選、優先策略，事實上 Spark 的資源粒度比較小更適合填充資源碎片，所以在不影響 K8s 調度效率的情況下優化資源調配策略，把合適的資源粒度的 Pod 分配到合適的混部節點，也是提高混部收益的方向。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18181972</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18181972</guid>
            <pubDate>Sun, 13 Apr 2025 06:41:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>開源多模態大模型「書生·萬象 3.0」發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海人工智能實驗室（上海 AI 實驗室）升級並開源了通用多模態大模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frb_gVjQTuwdx0hse6KuAkA&quot; target=&quot;_blank&quot;&gt;書生·萬象 3.0&lt;/a&gt;（InternVL3）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，通過採用創新的多模態預訓練和後訓練方法，InternVL3 多模態基礎能力全面提升，在專家級基準測試、多模態性能全面測試中，10 億~780 億參數的全量級版本在開源模型中性能均位列第一，同時大幅提升了圖形用户界面（GUI）智能體、建築場景圖紙理解、空間感知推理以及通識學科推理等方面的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;292&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1e01575a2bc4dfc8530b94281d9005d52e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在專家級多學科領域知識推理基準測試 MMMU 中再次突破開源模型極限，取得 72.2 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;基於司南 OpenCompass 開源評測框架，研究團隊對 InternVL3 進行了全面系統的評估，包括多學科推理、文檔理解、多圖像 / 視頻理解、現實世界理解、多模態幻覺檢測、視覺定位、多語言能力以及以語言為中心的基準測試。評測結果顯示，InternVL3 在開源多模態大模型中性能表現最優，創造了開源多模態大模型的性能新標杆，性能接近閉源模型 Gemini-2.5-Pro；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;創新提出原生多模態預訓練方法，將語言和多模態學習整合於同一個預訓練階段，提升及拓展多模態能力的同時，進一步提升純語言能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;提出混合偏好優化算法以及多模態測試階段增強，通過負監督修正模型響應分佈，大幅提升模型推理能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;公測版本：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.intern-ai.org.cn%2F%C2%A0&quot; target=&quot;_blank&quot;&gt;https://chat.intern-ai.org.cn/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345071</guid>
            <pubDate>Sun, 13 Apr 2025 06:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>豆包 1.5·深度思考模型發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今日火山引擎 AI 創新巡展杭州站現場，火山引擎總裁譚待發布了最新的豆包 1.5·深度思考模型，升級豆包·文生圖模型 3.0、豆包·視覺理解模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時，面向 Agent 服務，發佈 OS Agent 解決方案、GUI Agent 大模型——豆包 1.5·UI-TARS 模型；面向大規模推理，發佈 AI 雲原生·ServingKit 推理套件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據透露，截至 2025 年 3 月底，豆包大模型日均 tokens 調用量已超過 12.7 萬億，是 2024 年 12 月的 3 倍，是一年前剛剛發佈時的 106 倍。IDC 報告顯示，2024 年中國公有云大模型調用量激增，火山引擎以 46.4% 的市場份額位居中國市場第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;豆包 1.5·深度思考模型在數學、編程、科學推理等專業領域及創意寫作等通用任務中表現突出。同時，模型採用 MoE 架構，總參數 200B，激活參數為 20B，低於業界同類模型參數規模的 50%，具備顯著的推理成本優勢。基於高效算法，豆包 1.5·深度思考模型在提供行業極高併發承載能力的同時，實現 20 毫秒極低延遲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;363&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be145536aac0c4457023c8127490097c66a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，豆包 1.5·深度思考模型還具備視覺理解能力，可以像人類一樣，不光基於文字思考，更能基於所見畫面思考，思考更立體，讓模型同時擁有「大腦」和「眼睛」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;升級的豆包·文生圖模型 3.0 則能夠實現更好的文字排版表現、實拍級的圖像生成效果，以及 2K 的高清圖片生成方式。可以廣泛應用於影視、海報、繪畫、玩偶設計等營銷、電商、設計場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本的豆包·視覺理解模型具備更強的視覺定位能力，支持多目標、小目標、通用目標的框定位和點定位，並支持定位計數、描述定位內容、3D 定位。可應用於線下門店的巡檢場景、GUI agent、機器人訓練、自動駕駛訓練等。新版本在視頻理解能力上也有大幅提升，比如記憶、總結理解、速度感知、長視頻理解等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRYJ2OiZM_M-Jh27x3OFEdg&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345068</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345068</guid>
            <pubDate>Sun, 13 Apr 2025 05:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>