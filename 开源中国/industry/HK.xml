<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-綜合資訊</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-綜合資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 26 Mar 2025 21:42:24 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>中國 AIGC APP 月活 TOP10 出爐：DeepSeek 第一、豆包第二</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fl4_g0dgHMu0g9E2AEbRLfw&quot; target=&quot;_blank&quot;&gt;QuestMobile 數據顯示&lt;/a&gt;&lt;/u&gt;，截止 2025 年 1 月，全網用户月人均使用時長提升至 171.4 小時，增速放緩，人均使用次數及 APP 個數分別達到 2487.9 次和 28.7 個，趨於穩定。其中，數量、時長同比均微增，但是次數同比出現了罕見的下降。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;582&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/192553_3GKs_2720166.png&quot; width=&quot;960&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，月活躍用户增長榜單中，AIGC、智能家居、用車服務等領域同比分別增長了 244.7%、16.7%、20.8%；相比之下，兩年前的 2023 年 1 月，月活躍用户增長較快的領域分別為綜合電商、手機銀行、效率辦公、益智休閒遊戲等領域，增速分別為 12.1%、18.4%、22.9%、57.5%。&lt;/p&gt; 
&lt;p&gt;QuestMobile 數據顯示，2025 年 1 月，AIGC APP 行業月活躍用户規模同比增長率高達 244.7%，淨增量超 9200 萬，領跑移動互聯網行業。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/192740_XN38_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;隨着 AI 大模型的不斷升級，深度思考和推理能力顯著提升，AIGC 已成為全網增速最快賽道，&lt;strong&gt;DeepSeek APP 上線次月活躍用户規模突破 1.8 億，豆包 APP 破億，騰訊元寶、納米 AI 搜索在 DeepSeek 大模型加持下，躋身 TOP5&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/192702_SJHe_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/192719_cAAX_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;QuestMobile 數據顯示，納米 AI 搜索、騰訊元寶 APP 在接入 DeepSeek 大模型後日活躍用户規模提升顯著，其中，騰訊元寶 APP 在接入大模型 11 天后日活躍用户規模突破 500 萬，納米 AI 搜索 2 月日活峯值達 384.8 萬。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341168</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341168</guid>
            <pubDate>Sat, 22 Mar 2025 11:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>worth-calculator —— 計算「這班上得值不值」的開源項目</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;worth-calculator 是一個工作性價比計算器，通過一系列計算公式，計算出我們當前工作的性價比分數，看到底 「值不值得」 上這個（B）班。&lt;/p&gt;

&lt;p&gt;具體能算以下幾項信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;nbsp;到手工資: 基於年薪和實際工作天數算出真實日薪。&lt;/li&gt;
&lt;li&gt;時間成本: 上班時長、通勤時間、各種假期都考慮進去了。&lt;/li&gt;
&lt;li&gt;&amp;nbsp;工作環境: 從工位到同事，全方位評估。&lt;/li&gt;
&lt;li&gt;最終結果: 給你一個直觀的參考指標。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;結果評判標準：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;😱 低於 1.0：很慘&lt;/li&gt;
&lt;li&gt;😐 1.0-1.8：一般&lt;/li&gt;
&lt;li&gt;😎 1.8-2.5：很爽&lt;/li&gt;
&lt;li&gt;🤩 高於 2.5：爽到爆炸&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;運行效果&lt;/p&gt;

&lt;p&gt;&lt;img height=&quot;3494&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/185439_kGZz_2720166.png&quot; width=&quot;1862&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/185507_bxX6_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/worth-calculator</link>
            <guid isPermaLink="false">https://www.oschina.net/p/worth-calculator</guid>
            <pubDate>Sat, 22 Mar 2025 11:07:00 GMT</pubDate>
        </item>
        <item>
            <title>讓 AI 評審代碼！Gitee Code MCP 幫你高效完成 PR Review</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;還在為開發寫的「屎山」代碼發愁？&lt;/p&gt; 
&lt;p&gt;還在為每天 Review 不完的代碼苦惱？&lt;/p&gt; 
&lt;p&gt;每次看完代碼卻不知道怎麼評論合適？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;今天馬建倉繼續帶着 Gitee Code MCP 走來了！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;馬建倉今天將帶你體驗 Gitee Code MCP + Cursor 的完整實踐流程，並展示 AI 在&lt;code&gt;代碼審核&lt;/code&gt;、&lt;code&gt;優化建議&lt;/code&gt;、&lt;code&gt;自動合併&lt;/code&gt;環節的強大能力。&lt;/p&gt; 
&lt;p&gt;把代碼託管簡單化，把 PR Review 敏捷化，用 Gitee Code MCP 把 PR Review 的煩惱統統搞定！&lt;/p&gt; 
&lt;h1&gt;01 快速上手：配置 Gitee Code MCP&lt;/h1&gt; 
&lt;p&gt;在開始之前，要先擁有屬於自己的 Gitee DevOps 旗艦版賬號，並創建私人令牌（僅需&lt;code&gt;接口操作&lt;/code&gt;和&lt;code&gt;代碼庫&lt;/code&gt;、&lt;code&gt;代碼組&lt;/code&gt;權限）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182107_e4mQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下載並編譯 Gitee Code MCP Server，可選擇&lt;code&gt;Docker&lt;/code&gt;或&amp;nbsp;&lt;code&gt;Node&lt;/code&gt;方式運行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker build 編譯：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t gitee-mcp:latest -f Dockerfile .&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Npm 安裝依賴，使用 node 運行：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;npm install&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 Cursor 中安裝使用 MCP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182139_sUUi_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;配置 MCP Server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以 Docker 方式運行 MCP Server：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;mcp_server_gitee&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;docker&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;run&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;--rm&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-i&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-e&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_PERSONAL_ACCESS_TOKEN&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-e&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_API_URL&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;gitee-mcp:latest&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;env&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_PERSONAL_ACCESS_TOKEN&quot;:&amp;nbsp;&quot;個人令牌&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_API_URL&quot;:&amp;nbsp;&quot;http://xxx.gitee.work/api/v8&quot;&amp;nbsp;// V8 接口
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;disabled&quot;:&amp;nbsp;false,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;autoApprove&quot;: []
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以 Node 方式運行 MCP Server：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;gitee_mcp&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;node&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;mcp 代碼目錄/build/index.js&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;env&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_PERSONAL_ACCESS_TOKEN&quot;:&amp;nbsp;&quot;個人令牌&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;GITEE_API_URL&quot;:&amp;nbsp;&quot;http://xxx.gitee.work/api/v8&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;出現彈窗後，無需關閉，查看 MCP Server 顯示為綠色即為成功運行。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182208_c2r1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;打開新的聊天窗口，設置為 Agent 聊天。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182219_BpD2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;至此環境配置完成，接下來讓我們看看 Gitee Code MCP 如何，智能化提升 PR Review 體驗。&lt;/p&gt; 
&lt;h1&gt;02 AI 賦能 PR Review：高效應對三大評審場景&lt;/h1&gt; 
&lt;h2&gt;「屎山」代碼？快速駁回！&lt;/h2&gt; 
&lt;p&gt;面對團隊中堆積如山的 PR，逐個手動檢查不僅低效，還可能遺漏關鍵問題。Gitee Code MCP 可以直接獲取代碼倉庫中的所有待審 PR，快速呈現變更內容，並智能分析代碼質量，幫助開發者精準識別可能存在的問題。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;獲取代碼倉庫&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182245_vg10_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這時 Gitee Code MCP 會把想要查的倉庫展示出來。如果想知道這個倉庫裏當前有哪些 PR 沒處理的，同樣可以讓 Gitee Code MCP 列出來：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182259_ahK3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;分析 PR 很累？不用擔心，Gitee Code MCP 可以幫你一鍵 Review：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182317_cprc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;讓我們再回到 Gitee Code 上看一看：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182334_8utO_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;神級代碼？照樣鋭評！&lt;/h2&gt; 
&lt;p&gt;即便是經驗豐富的開發者，寫出了看起來十分完美的代碼，也難免在代碼優化上有所疏漏。&lt;/p&gt; 
&lt;p&gt;Gitee Code MCP 不僅能識別問題代碼，還能提供優化建議，幫助團隊提升整體代碼質量：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182349_ch25_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們可以在 Gitee Code 的 PR 詳情中看到 AI 具體説了什麼。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182402_676Y_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;無可挑剔，輕鬆合併！&lt;/h2&gt; 
&lt;p&gt;當代碼通過審核後，Gitee Code MCP 還能，自動執行 PR 合併操作，避免繁瑣的人工點擊流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182422_7myc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再返回 Gitee Code 查看合併結果：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/182435_wt9o_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;至此，我們在 PR Review 時不再需要任何人工的操作，對代碼的評審也完全可以交給 Cursor 和 Gitee MCP Server 去做，從此不再需要為代碼評審苦惱。&lt;/p&gt; 
&lt;p&gt;除了 PR Review，Gitee Code MCP 還支持 Issue 處理、Commit 追蹤、代碼倉庫管理等完整代碼倉庫相關 DevOps 流程。現在就去試試，探索 AI 賦能開發的新方式吧！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;推薦閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/340077&quot; target=&quot;news&quot;&gt;寫一行代碼，用 Cursor + Gitee MCP 實現貪吃蛇遊戲&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/339785&quot; target=&quot;news&quot;&gt;Gitee MCP Server：讓 AI 助手接管繁瑣事務，助力 Gitee 專業版研發提效&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338794/gitee-mcp-server&quot; target=&quot;news&quot;&gt;Gitee MCP Server 正式開源：讓 AI 助手直連你的代碼倉庫&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341154</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341154</guid>
            <pubDate>Sat, 22 Mar 2025 10:25:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 官方詳解 V3 模型「小版本」升級，各項能力全面進階</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;DeepSeek-V3 模型&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/340789/deepseek-v3-0324&quot;&gt;近日進行了更新&lt;/a&gt;&lt;/u&gt;，雖然大家都説更新後的 DeepSeek-V3-0324 強到沒邊——哪怕叫 DeepSeek V3.5 也不為過，但官方仍低調地稱其是「小版本升級」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;486&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/172423_W9Lc_2720166.png&quot; width=&quot;1402&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下面是官方針對 DeepSeek-V3-0324 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FXK6ymJL7y0vo_GQXxmpuBA&quot; target=&quot;_blank&quot;&gt;發佈的更新説明&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;DeepSeek V3 模型已完成小版本升級，目前版本號 DeepSeek-V3-0324，用户登錄官方網頁、APP、小程序進入對話界面後，&lt;strong&gt;關閉深度思考&lt;/strong&gt;即可體驗。API 接口和使用方式保持不變。&lt;/p&gt; 
&lt;p&gt;如非複雜推理任務，建議使用新版本 V3 模型，即刻享受速度更加流暢、效果全面提升的對話體驗。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;模型能力提升一覽&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;推理任務表現提高&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;新版 V3 模型借鑑 DeepSeek-R1 模型訓練過程中所使用的強化學習技術，大幅提高了在推理類任務上的表現水平，在數學、代碼類相關評測集上取得了超過 GPT-4.5 的得分成績。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;799&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/173130_fEuG_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;新版 V3 模型的百科知識（MMLU-Pro, GPQA）、數學（MATH-500, AIME 2024）和代碼任務（LiveCodeBench）表現均有提升&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;前端開發能力增強&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 HTML 等代碼前端任務上，新版 V3 模型生成的代碼可用性更高，視覺效果也更加美觀、富有設計感。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8c268dc1982a47b1d5c1d3960317fb4b7c2.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;動圖展示了一個由模型生成的演示多個小球在指定空間範圍內運動的 p5.js 程序，包含若干可以調整重力、摩擦力等參數的滑動按鈕，並以賽博朋克風格的 HTML 呈現&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;中文寫作升級&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在中文寫作任務方面，新版 V3 模型基於 R1 的寫作水平進行了進一步優化，同時特別提升了中長篇文本創作的內容質量。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1761&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/173210_hnNh_2720166.png&quot; width=&quot;1252&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;中文搜索能力優化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;新版 V3 模型可以在聯網搜索場景下，對於報告生成類指令輸出內容更為詳實準確、排版更加清晰美觀的結果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ceb41b23b1984968d9c56909a7beb38153.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，新版 V3 模型在&lt;strong&gt;工具調用、角色扮演、&lt;strong&gt;&lt;strong&gt;問答&lt;/strong&gt;&lt;/strong&gt;閒聊&lt;/strong&gt;等方面也得到了一定幅度的能力提升。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;模型開源&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeek-V3-0324 與之前的 DeepSeek-V3 使用同樣的 base 模型，僅改進了後訓練方法。私有化部署時只需要更新 checkpoint 和 tokenizer_config.json（tool calls 相關變動）。模型參數約 660B，開源版本上下文長度為 128K（網頁端、App 和 API 提供 64K 上下文）。&lt;/p&gt; 
&lt;p&gt;V3-0324 模型權重下載請參考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Model Scope:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fdeepseek-ai%2FDeepSeek-V3-0324&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/deepseek-ai/DeepSeek-V3-0324&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Huggingface:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3-0324&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3-0324&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;與 DeepSeek-R1 保持一致，此次我們的開源倉庫（包括模型權重）&lt;strong&gt;統一採用 MIT License&lt;/strong&gt;，並允許用户利用模型輸出、通過模型蒸餾等方式訓練其他模型。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#d35400&quot;&gt;&lt;strong&gt;最後，奉上 DeepSeek V3 最新版的免費體驗地址，由模力方舟提供：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;u&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api/packages/1917?model=DeepSeek-V3&amp;amp;package=1917&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api/packages/1917?model=DeepSeek-V3&amp;amp;package=1917&lt;/a&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/103438_ukgv_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;模力方舟的 Serverless API 提供了視頻生成、文本生成、視覺模型、圖像生成與處理、文檔處理 / OCR、自動語音識別、語音合成、特徵抽取、代碼生成、風控識別十大類共 58 款各領域的頂尖開源模型的在線體驗和 API 使用。通過購買模型資源包，即可通過極低的價格即可盡享眾多主流模型。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;683&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/103139_wjCp_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341137/deepseek-v3-0324-detail</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341137/deepseek-v3-0324-detail</guid>
            <pubDate>Sat, 22 Mar 2025 09:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>高通在全球三大洲指控 ARM 壟斷，芯片架構授權模式面臨重構</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;英國芯片設計公司 Arm&amp;nbsp;自被軟銀收購後，業務模式已經逐漸從基礎架構提供商轉向完整芯片設計商。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-25%2Fqualcomm-takes-legal-fight-with-arm-to-global-antitrust-agencies&quot; target=&quot;_blank&quot;&gt;彭博社今天援引知情人士的話透露&lt;/a&gt;&lt;/u&gt;，高通已向歐盟委員會、美國聯邦貿易委員會（FTC）及韓國公平交易委員會提交機密文件，指控 Arm&amp;nbsp;涉嫌濫用市場支配地位實施反競爭行為。&lt;/p&gt; 
&lt;p&gt;高通是全球最大手機芯片製造商。該公司認為，Arm 通過開放授權模式使業界對其技術形成高度依賴，同時也促成了芯片產業的蓬勃發展。但是，這一充滿活力的市場如今正受到威脅，因為 Arm 正通過限制技術訪問來推動自身的芯片製造野心，以提高利潤。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-378959a9f2407fecd1acaf54103c1824963.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在與監管機構的私下會議和保密文件中，高通指控 Arm 在運營開放授權模式 20 餘年後，突然限制技術訪問權限，試圖通過自研芯片業務提升利潤。具體表現為：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;拒絕提供協議範圍內的關鍵技術&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;修改授權條款阻礙客户產品開發&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;利用指令集架構壟斷地位擠壓下游廠商&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;高通表示，Arm 正「不擇手段」提升財務表現，包括終止與部分客户的授權協議、要求芯片廠商簽訂捆綁協議、強制收取更高專利費。&lt;/p&gt; 
&lt;p&gt;高通認為，Arm 通過開放的許可模式建立了對其技術的嚴重依賴，這也促進了一個蓬勃發展的芯片產業。高通向全球競爭管理機構表示，由於 Arm 種種限制行為，目前市場正在受到威脅。&lt;/p&gt; 
&lt;p&gt;高通發言人拒絕置評。歐盟委員會、美國 FTC 和韓國公平貿易委員會的發言人也拒絕置評。&lt;/p&gt; 
&lt;p&gt;Arm 方面則表示對勝訴充滿信心：「Arm 仍然專注於加強創新，促進競爭，並尊重合同權利和義務。任何關於反競爭行為的指控都不過是高通為了自身競爭利益，不擇手段地轉移人們對其與我方持續商業糾紛實質的注意力並擴大爭端範圍的絕望嘗試。」&lt;/p&gt; 
&lt;p&gt;閲讀更多：&lt;a href=&quot;https://www.oschina.net/news/318231&quot; target=&quot;news&quot;&gt;英偉達、高通等芯片四巨頭聯手，以新 CPU 架構對抗英特爾、AMD&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341129</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341129</guid>
            <pubDate>Sat, 22 Mar 2025 09:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>螞蟻數科發佈能源電力時序大模型 EnergyTS，預測精度超谷歌、亞馬遜</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;螞蟻數科在蘇州舉辦的新能源數字資產社區春季峯會上，宣佈正式推出能源電力時序大模型 EnergyTS。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EnergyTS 專為新能源行業定製，在光伏場景測評中，其發電量預測準確率顯著超越谷歌（TimesFM-V2.0）和亞馬遜 (Chronos-Large) 等國際主流通用時序模型。在 T+1 天預測中，模型的平均絕對誤差僅為 0.0233，較谷歌模型提升約 22.4%;在 T+3 天預測中，性能提升更是達到 46.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;206&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e865e9a90be3dc50aca39f98046b6a90b3a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EnergyTS 通過 AI 技術，可精準預測發電量、電力供需情況，有效緩解電價波動、儲能調度收益低等關聯風險，為行業提供更智能的經營決策支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該模型具備多尺度訓練、多模態融合、多任務學習和零樣本冷啓等優勢，可廣泛應用於光伏發電、風力發電、儲能、微電網、電力交易等多個場景，實現&quot;開箱即用&quot;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;螞蟻數科 CEO 趙聞飆表示，公司致力於解決各行業在 AI 時代的智能化轉型問題，未來將在更多領域探索大模型技術與行業實際問題的結合。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341125</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341125</guid>
            <pubDate>Sat, 22 Mar 2025 09:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>TensorRT-LLM —— 優化大型語言模型推理的 TensorRT 工具箱</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;TensorRT-LLM 為用户提供了易於使用的 Python API，用於定義大型語言模型（LLM）和構建 TensorRT 引擎，這些引擎包含最先進的優化技術，可在英偉達（NVIDIA）圖形處理器上高效執行推理。&lt;/p&gt;

&lt;p&gt;TensorRT-LLM 還包含用於創建執行這些 TensorRT 引擎的 Python 和 C++ 運行時的組件。它還包括一個用於與英偉達 Triton 推理服務器（NVIDIA Triton Inference Server）集成的後端；這是一個為 LLM 提供服務的生產質量系統。使用 TensorRT-LLM 構建的模型可以在多種配置上執行，從單個 GPU 到具有多個 GPU 的多個節點（使用張量並行和/或管道並行）。&lt;/p&gt;

&lt;p&gt;TensorRT-LLM 的 Python API 架構與 PyTorch API 相似。它為用户提供了包含 einsum、softmax、matmul 或 view 等函數的功能模塊。層模塊捆綁了用於組裝 LLM 的有用構件，如 Attention 塊、MLP 或整個 Transformer 層。GPTAttention 或 BertAttention 等特定模型組件可在模型模塊中找到。&lt;/p&gt;

&lt;p&gt;TensorRT-LLM 預先定義了幾種常用模型。它們可以很容易地修改和擴展，以滿足客户的需求。可&lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM#Models&quot;&gt;參閲支持型號&lt;/a&gt;列表&amp;nbsp;。&lt;/p&gt;

&lt;p&gt;為了最大限度地提高性能並減少內存佔用，TensorRT-LLM 允許使用不同的量化模式來執行模型（具體示例見 &lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM/blob/release/0.5.0/examples/gpt&quot;&gt;&lt;code&gt;examples/gpt&lt;/code&gt;&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;）。TensorRT-LLM 支持 INT4 或 INT8 權重（和 FP16 activations，又稱 INT4/INT8 weight-only）以及 SmoothQuant 技術的完整&lt;a href=&quot;https://arxiv.org/abs/2211.10438&quot;&gt;實現&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img height=&quot;284&quot; src=&quot;https://static.oschina.net/uploads/space/2023/1116/164435_jwZL_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/tensorrt-llm</link>
            <guid isPermaLink="false">https://www.oschina.net/p/tensorrt-llm</guid>
            <pubDate>Sat, 22 Mar 2025 08:44:00 GMT</pubDate>
        </item>
        <item>
            <title>蘿蔔快跑在自貢成立科技公司，含 AI 相關業務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，近日，蘿蔔運力（自貢）科技有限公司成立，法定代表人為畢然，註冊資本 100 萬人民幣。公司由蘿蔔快跑關聯公司蘿蔔運力（北京）科技有限公司全資持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;313&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a544cf9d0bfa2827963e1b32d87d99f4929.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;經營範圍包括軟件開發、計算機系統服務、互聯網數據服務、數據處理和存儲支持服務、人工智能應用軟件開發、人工智能基礎軟件開發等，由蘿蔔快跑關聯公司蘿蔔運力（北京）科技有限公司全資持股。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341116</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341116</guid>
            <pubDate>Sat, 22 Mar 2025 08:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>華為增資至 409.4 億，近一年已 3 次增資</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 App 顯示，華為技術有限公司近日發生工商變更，註冊資本由約 408.4 億人民幣增至約 409.4 億人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5af3d0d03a8d4183622343df88b625dd7f.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基本信息顯示，華為技術有限公司 (曾用名：深圳市華為技術有限公司) ，成立於 1987 年，位於廣東省深圳市，由華為投資控股有限公司全資持股。是一家以從事計算機、通信和其他電子設備製造業為主的企業。企業註冊資本 4094113.182 萬人民幣，超過了 100% 的廣東省同行，實繳資本 4054113.18 萬人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;變更記錄表明，該公司近一年已三次增資，前兩次分別發生於 2024 年 4 月、2024 年 6 月。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341115</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341115</guid>
            <pubDate>Sat, 22 Mar 2025 08:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Cloudflare 開源 OpenPubkey SSH（OPKSSH），將單點登錄集成到 SSH</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Cloudflare 近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fopen-sourcing-openpubkey-ssh-opkssh-integrating-single-sign-on-with-ssh%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;將 OPKSSH（OpenPubkey SSH）代碼庫捐贈給 Linux 基金會旗下的 OpenPubkey 項目，這意味着開發者現在可通過開源方式實現基於單點登錄（SSO）的 SSH 密鑰管理。&lt;/p&gt; 
&lt;p&gt;OPKSSH 通過將 OpenID Connect（OIDC）協議與 SSH 協議無縫結合，使企業能夠利用現有身份提供商（如 Google、Azure AD）直接管理 SSH 訪問權限，徹底告別手動配置 SSH 密鑰的時代。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-609a9940408bc6b0fe8a976760b572a27f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OPKSSH 基於 OpenPubkey 協議，該協議通過在 OIDC 的 ID Token 中嵌入用户公鑰，生成名為「PK Token」的短期證書。當用户執行&lt;code&gt;opkssh login&lt;/code&gt;時，流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;生成臨時 SSH 密鑰對（默認有效期 24 小時）；&lt;/li&gt; 
 &lt;li&gt;通過瀏覽器跳轉完成 OIDC 認證，獲取包含公鑰的 PK Token；&lt;/li&gt; 
 &lt;li&gt;將 PK Token 寫入本地 SSH 公鑰文件，私鑰僅存於內存。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;服務器端只需在 SSH 配置中添加兩行驗證邏輯（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenpubkey%2Fopenpubkey&quot; target=&quot;_blank&quot;&gt;示例代碼&lt;/a&gt;），即可將傳統 SSH 公鑰驗證替換為 PK Token 驗證。該方案兼容任何 OIDC 提供商，且無需修改 SSH 協議棧。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OPKSSH&amp;nbsp;三大核心優勢&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全性躍升&lt;/strong&gt;：臨時密鑰自動過期，消除長期密鑰泄露風險。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;運維簡化&lt;/strong&gt;：管理員通過郵件地址管理權限（如&lt;code&gt;authorized_emails&lt;/code&gt;文件），無需跟蹤密鑰指紋。用户可在任意設備通過&lt;code&gt;opkssh login&lt;/code&gt;生成密鑰，徹底解決密鑰分發難題。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;審計透明化&lt;/strong&gt;：所有 SSH 登錄事件均關聯 OIDC 身份信息，天然支持 SIEM 系統集成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;適用場景與遷移成本&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OPKSSH 適用於已部署 OIDC 的企業環境，尤其是需嚴格管控雲服務器或 CI/CD 系統訪問權限的場景。遷移僅需：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在目標服務器運行安裝腳本（&lt;code&gt;curl -sSfL https://install.opkssh.dev | sh&lt;/code&gt;）；&lt;/li&gt; 
 &lt;li&gt;在身份提供商註冊 OPKSSH 客户端 ID。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;OpenPubkey SSH（OPKSSH）採用 Apache 2.0 許可證，開源地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenpubkey%2Fopkssh&quot; target=&quot;_blank&quot;&gt;https://github.com/openpubkey/opkssh&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341113/cloudflare-open-sourcing-openpubkey</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341113/cloudflare-open-sourcing-openpubkey</guid>
            <pubDate>Sat, 22 Mar 2025 08:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>崑崙萬維發佈全球首款音樂推理大模型 Mureka O1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;崑崙萬維宣佈&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1JPYXUwX-1JAVpz3IgygtQ&quot; target=&quot;_blank&quot;&gt;推出&lt;/a&gt; Mureka O1 模型與 Mureka V6 模型。「Mureka O1 作為全球首款音樂推理大模型，性能超越 Suno、模型登頂 SOTA，中國科技創新再次在 AI 音樂領域領跑全球。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 4 月，崑崙萬維發佈了第一代音樂生成模型：Mureka V1（SkyMusic）。Mureka V6 是當前 Mureka 的基座模型，支持純音樂生成，還支持 10 種語言的 AI 音樂創作，包括英語、中文、日語、韓語、法語、西班牙語、葡萄牙語、德語、意大利語和俄語。在 Mureka V6 中，團隊引入自研 ICL（in-context learning）技術，使得聲場更加開闊，人聲質感和混音設計進一步強化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;270&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eb6a0135a337596b6a6a105f75b95b34fb8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mureka O1 模型是基於 Mureka V6 思維鏈的推理優化版本，也是全球範圍內首個引入 CoT 的音樂模型，在推理過程中加入思考與自我批判，大幅提升音樂品質、音樂創作效率和靈活性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mureka V6 和 O1 模式支持多元化的音樂創作風格及情感表達。曲風涵蓋爵士 (Jazz)、電子 (Electronic)、流行 (Pop)、鄉村 (Country)、節奏布魯斯 (R&amp;amp;B)、靈魂樂 (Soul)、藍調 (Blues)、搖滾 (Rock)、舞曲 (Dance) 等；情感維度包括快樂、放縱、神秘、充滿活力、悲傷等多種情緒表達。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，Mureka 還提供兩個特色音樂生成功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;歌曲參考（Reference Fuction）：將音樂本身作為提示，用户可直接上傳音頻或 Youtube 鏈接作為創作提示，比文本提示更直接更高級的提示方式；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;音色克隆（Vocal Fuction）：Mureka 是全球首個可以指定演唱歌手音色的 AI 音樂生成平台，用户不僅可以選擇官方提供的多種歌手音色，還可以上傳自己的聲音，讓 AI 學習並復刻，精準模擬歌手音色，一鍵生成個性化專屬作品。自定義歌手音色的功能宣告人人都能成為 AI 歌手的時代正式到來了。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mureka O1 中包含了 Mureka 團隊最新發布的音樂生成領域的創新研究成果——MusiCoT。根據介紹，MusiCoT 利用了思維鏈 Chain-of-Thought （CoT）方法，不同於傳統自迴歸模型逐步生成音頻，MusiCoT 首次在細粒度音頻 token 預測前預生成整體音樂結構，大幅提升生成音樂的結構連貫性與樂器編排精準度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MusiCoT 基於 CLAP 模型，無需人工標註即具備高擴展性，並顯著提高了生成音樂的可解釋性和質量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基於首次在音樂生成領域引入 Chain-of-Thought（CoT）技術、算法框架的升級，Mureka O1 不僅保持了低延遲音樂生成，還顯著提升了歌詞旋律契合度、演唱準確性和藝術表現力等，多項指標領先於 Suno V4。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;294&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-503e30956b12803e771c5937b2b29cdd12d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cbf0a6f76c773afe0506002d7f11fe7135c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-82ca85f7fa60597b44ceaddec62bfe1e73c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;330&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-051e429a4d3e0dc2eb7a98978f95ef96f3c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341110</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341110</guid>
            <pubDate>Sat, 22 Mar 2025 08:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Keep 發佈行業首個通用健身教練 Agent</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Keep &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJLWX87Yf6_gItCfnBBr_BA&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;推出了運動健康垂直領域的專屬模型 &lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FKinetic.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kinetic.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;，並基於此模型同步上線了首個通用 AI 教練體驗版——卡卡（Kaka）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;518&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-739b9d7574b6c7b7ef80dc204107e953669.png&quot; width=&quot;350&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FKinetic.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kinetic.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 為 Keep 研發的運動健康垂類專屬模型，為行業首發。這一模型為 Keep 基於大量的運動數據和運動專業知識的沉澱，以及基座模型基礎上訓練和優化後發佈，在運動健康垂類領域有更專業的表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Keep 方面表示，未來將會持續更新 &lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FKinetic.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kinetic.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 的模型能力，除了文字交互形態，未來會增加多模態的能力，包括音頻和圖像等。同時，還會增加圖片的識別、語音互動等新的交互來豐富 AI 教練的服務技能，這些技能也會無縫銜接在用户使用 Keep 過程中，讓用户感受到 AI 教練的價值。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Keep AI 教練卡卡（Kaka）當前主要應用在運動方案定製的場景，Keep 用户可在「今日」頁面找到應用入口。卡卡（Kaka）可基於用户的運動訴求定製訓練計劃和方案，同時也支持基礎問答。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;預計在 5 月份上線卡卡（Kaka）正式版，增加多模態能力，包括語音指導以及圖片識別等能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年 2 月初，Keep CEO 王寧在公司成立 10 週年之際表示，公司未來要全力 All in AI，基於十年的運動數據積累與沉澱，讓在線健身從推薦走向生成，持續引領運動科技行業。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341108</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341108</guid>
            <pubDate>Sat, 22 Mar 2025 08:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>龍芯 x86 架構轉譯器 LATX 開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;LATX（Loongson Architecture Translator for x86）即龍芯 x86 架構轉譯器，是，一個&lt;strong&gt;面向 LoongArch 架構的高性能用户級二進制翻譯器&lt;/strong&gt;，用於在龍芯（龍架構）系，統上高效地運行 32/64 位 x86 應用程序。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flat-opensource%2Flat%2Freleases%2Ftag%2F1.6.0&quot; target=&quot;_blank&quot;&gt;LATX Version 1.6.0 &lt;/a&gt;已在 GitHub 開源，&lt;strong&gt;遵循 GPLv2 協議&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flat-opensource%2Flat&quot; target=&quot;_blank&quot;&gt;https://github.com/lat-opensource/lat&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;項目介紹稱，&lt;strong&gt;LATX 基於 QEMU 6 版本開發並進行了深度優化，性能相比原生 QEMU 有顯著提升&lt;/strong&gt;。 項目利用龍架構的各指令集擴展（如向量擴展和二進制轉譯指令集）對 X86 指令集，進行了高效翻譯，並採用了 AOT（Ahead-of-Time ）預編譯、運行時庫直通等關鍵優，化技術，其中庫直通優化思想借鑑及引用了 box64 項目的部分源碼。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;項目背景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 LoongArch 架構生態建設過程中，運行已有的 x86 程序存在兼容性和性能瓶頸， 原生 QEMU 等模擬器在性能和兼容性上並不能完全滿足需求。因此，龍芯工程師在 QEMU 6 的基礎上進行了二次開發，通過引入預編譯、庫直通以及其他針對性優化，大幅減少，了指令翻譯和執行的開銷，努力實現「更快、更穩定、更兼容」的目標。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;歷史演進&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;LATX 歷經多個開發階段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2021 年&lt;/strong&gt;：項目啓動，完成 LATX 到 QEMU 6 的移植，Q3 項目進入 Alpha 階段。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2022 年&lt;/strong&gt;：支持庫直通等優化，Q3 項目進入到 Beta 階段。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2023 年&lt;/strong&gt;：持續完善系統調用等接口的支持，以及更細緻的指令優化。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2024 年&lt;/strong&gt;：項目進入到 RC 階段。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;LATX 未來的優化與完善方向包括但不限於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持更復雜的 x86 指令集擴展（如 AVX）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進一步提升庫直通優化的覆蓋範圍。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提供詳細的性能分析工具鏈，幫助開發者快速定位性能瓶頸。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;維護更詳細的文檔與使用指南。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;閲讀更多：&lt;a href=&quot;https://www.oschina.net/news/340714&quot; target=&quot;news&quot;&gt;《龍架構生態白皮書（2024 年）》發佈&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341107/loongson-lat-opensource</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341107/loongson-lat-opensource</guid>
            <pubDate>Sat, 22 Mar 2025 07:59:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Eywe 項目管理軟件：市場驅動的新產品開發利器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Eywe 項目管理軟件：市場驅動的新產品開發利器&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在當今競爭激烈的市場環境中，企業需要高效、敏捷的研發流程來確保產品從概念到上市的成功。然而，跨部門協作困難、節點質量管控流於形式、資源衝突等問題常常成為研發團隊的絆腳石。Eywe 項目管理軟件應運而生，致力於幫助企業構建市場驅動的研發流程，實現從需求到交付的全生命週期管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;743&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-30c982ca7a59b0ad3ca86602da741577811.png&quot; width=&quot;1408&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;為什麼選擇 Eywe？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;端到端流程打通&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Eywe 通過結構化的產品開發流程，將市場、研發、生產、銷售等環節無縫銜接，確保每個階段的目標清晰、責任明確，徹底解決「有流程無執行」的痛點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能協同與資源優化&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;跨部門協作不再困難！Eywe 提供實時協作平台，支持多項目資源動態分配，避免資源衝突，讓團隊聚焦於高優先級任務。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;嚴控節點質量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;內置技術評審模板和問題回溯機制，確保每個里程碑的質量達標，杜絕「批鬥會」式評審，真正實現「一次把事情做對」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據驅動的決策支持&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通過可視化報表和風險預警功能，管理層可以快速掌握項目進展，基於數據做出科學決策，減少「拍腦袋」式判斷。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;知識沉澱與複用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Eywe 的情景化知識管理功能，將項目經驗、模板、案例系統化沉澱，避免重複錯誤，加速團隊能力提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Eywe 的核心功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;結構化流程管理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：支持產品開發的 6 大階段（概念、方案、開發、驗證、發佈、生命週期），靈活適配企業實際需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多級計劃體系&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：從里程碑計劃到專業領域計劃，確保任務層層分解、責任到人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;風險管理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：自動識別、評估和跟蹤風險，提供應對策略，降低項目不確定性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;跨平台協作&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：隨時隨地跟進項目進展，打破地域限制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;客户見證&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Eywe 幫助我們實現了研發流程的標準化和透明化，項目交付週期縮短了 30%，跨部門協作效率顯著提升。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;——某通信科技企業研發總監&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「從需求到上市的全流程管理，Eywe 讓我們的產品開發更加聚焦市場，財務回報率提高了 20%。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt; &lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;——某家電行業產品經理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;789&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b7da1599e07da0f1ee7a742944539a97dc0.png&quot; width=&quot;1359&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;立即體驗 Eywe，開啓高效研發之旅！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;無論您是初創企業還是行業巨頭，Eywe 都能為您提供量身定製的解決方案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Eywe&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;官網&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.cseywe.com&quot; target=&quot;_blank&quot;&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#0000ff&quot;&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;http://www.cseywe.com&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;軟件體驗網址&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.cseywe.com%3A8080&quot; target=&quot;_blank&quot;&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#0000ff&quot;&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;http://www.cseywe.com:8080&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;賬號：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#0000ff&quot;&gt;&lt;span&gt;ZhangSan &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;密碼：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#0000ff&quot;&gt;&lt;span&gt;123456&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;讓 Eywe 成為您市場驅動研發的得力助手，助力企業實現產品成功與財務成功！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341095</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341095</guid>
            <pubDate>Sat, 22 Mar 2025 07:22:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>清華大學開源 Video-T1：無需重新訓練 AI 視頻秒變高清大片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;清華大學的研究團隊近日開源了其最新的研究成果——Video-T1。這項技術的核心在於測試時縮放 （Test-Time Scaling， TTS），旨在通過在視頻生成過程的推理階段投入更多的計算資源，顯著提升生成視頻的質量和與文本提示的一致性，而無需重新進行昂貴的模型訓練。這一創新性的方法為視頻生成領域帶來了新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;何為「測試時縮放」?&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在大型語言模型 （LLMs） 領域，研究人員已經發現，通過在測試階段增加計算量可以有效提升模型性能。Video-T1 借鑑了這一思路，並將其應用於視頻生成領域。簡單來説，傳統的視頻生成模型在接收到文本提示後，會直接生成一段視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;而採用了 TTS 的 Video-T1，則像是在生成視頻的過程中進行多次「搜索」和「篩選」，&lt;strong&gt;通過生成多個候選視頻，並利用「測試驗證器」進行評估，最終選擇質量最高的視頻&lt;/strong&gt;。這就像一位精雕細琢的藝術家，在完成最終作品前會嘗試多種不同的方法和細節。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 的核心技術&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 並沒有直接增加訓練成本，而是專注於如何更有效地利用現有模型的能力。其核心方法可以理解為在模型的「噪聲空間」中尋找更優的視頻生成軌跡。為了實現這一目標，研究團隊提出了兩種主要的搜索策略:&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;隨機線性搜索 （Random Linear Search）&lt;/strong&gt;:這種方法通過&lt;strong&gt;隨機採樣多個高斯噪聲&lt;/strong&gt;，讓視頻生成模型對這些噪聲進行逐步去噪，生成多個候選視頻片段，然後利用測試驗證器對這些候選視頻進行評分，最終選擇得分最高的視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;幀樹搜索 （Tree-of-Frames， ToF）&lt;/strong&gt;:考慮到同時對所有幀進行全步去噪會帶來巨大的計算成本，ToF 採用了一種更高效的策略。它將視頻生成過程分為三個階段:首先進行&lt;strong&gt;圖像級別的對齊&lt;/strong&gt;，這會影響後續幀的生成;其次，在測試驗證器中使用&lt;strong&gt;動態提示&lt;/strong&gt;，重點關注&lt;strong&gt;運動的穩定性&lt;/strong&gt;和&lt;strong&gt;物理上的合理性&lt;/strong&gt;，並根據反饋指導搜索過程;最後，評估視頻的整體質量，並選擇與文本提示對齊度最高的視頻。ToF 這種自迴歸的方式能夠更智能地探索視頻生成的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;291&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a31db7613d8e9d4e81825607ee221dc4a49.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TTS 的顯著效果&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;實驗結果表明，隨着測試時計算量的增加（即生成更多候選視頻），模型性能會持續提升。這意味着，通過投入更多的推理時間，即使是同一個視頻生成模型，也能夠產生&lt;strong&gt;更高質量、與文本提示更加一致的視頻&lt;/strong&gt;。研究人員在多個視頻生成模型上進行了實驗，結果都顯示出 TTS 能夠穩定地帶來性能提升。同時，不同的測試驗證器關注的評估方面有所不同，因此在性能提升的速率和程度上也存在差異。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 的 TTS 方法在常見的提示類別（如場景、物體）和容易評估的維度 (如圖像質量) 上取得了顯著的改進。通過觀察官方提供的視頻演示可以看出，經過 TTS 處理後的視頻在&lt;strong&gt;清晰度、細節和與文本描述的貼合度&lt;/strong&gt;上都有明顯的提升。例如，描述「戴着太陽鏡在泳池邊當救生員的貓」的視頻，在經過 TTS 處理後，貓的形象更加清晰，救生員的動作也更加自然。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;293&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-97931a836bd63018b344817d13e7d029863.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;挑戰與展望&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管 TTS 在許多方面都帶來了顯著的進步，但研究人員也指出，對於一些難以評估的潛在屬性，例如&lt;strong&gt;運動的流暢性&lt;/strong&gt;和&lt;strong&gt;時序上的一致性&lt;/strong&gt;（避免畫面閃爍），TTS 的改進效果相對有限。這主要是因為這些屬性需要對跨幀的運動軌跡進行精確控制，而目前的視頻生成模型在這方面仍然面臨挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;清華大學開源的 Video-T1 通過創新的測試時縮放策略，為提升視頻生成質量提供了一種新的有效途徑。它無需昂貴的重新訓練，而是通過更智能地利用推理時的計算資源，讓現有模型煥發出更強的能力。隨着未來研究的深入，我們有理由期待 TTS 技術在視頻生成領域發揮越來越重要的作用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341094</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341094</guid>
            <pubDate>Sat, 22 Mar 2025 07:18:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>哥倫比亞大學研發 3D 光子電子芯片，突破 AI 數據傳輸瓶頸</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;美國哥倫比亞大學工程團隊與康奈爾大學工程團隊合作成功開發出全球首款&lt;strong&gt;三維集成光子-電子芯片&lt;/strong&gt;，實現了前所未有的效率和帶寬。&lt;/p&gt; 
&lt;p&gt;相關研究論文已於&amp;nbsp;3 月 21 日發表於《自然・光子學》上：&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41566-025-01633-0&quot; target=&quot;_blank&quot;&gt;DOI:&amp;nbsp;10.1038/s41566-025-01633-0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-131d9e739b45c53af3cedf7d25d9ece622b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲&amp;nbsp;電氣工程教授 Keren Bergman，及電氣研究生、論文合著者 Michael Cullen&lt;/p&gt; 
&lt;p&gt;他們通過深度融合光子技術與先進的互補金屬氧化物半導體電子技術，讓這種新型三維光電子芯片實現了 800Gb/s 超高帶寬與 120 飛焦 / 比特的極致能效，帶寬密度達 5.3 Tb/s/mm² 遠超現有基準。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fd9154017bb1eae29074e948da27f8417bc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這項突破性的技術有望重塑 AI 硬件，使未來的智能系統能夠以更快的速度傳輸數據，同時顯著降低能耗，這對於智能汽車、大規模 AI 模型等未來技術至關重要。&lt;/p&gt; 
&lt;p&gt;Bergman 教授表示：「我們展示了一種能夠以空前之低的能耗傳輸大量數據的技術。這項創新突破了長期以來限制傳統計算機和 AI 系統數據傳輸的能源壁壘。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341093</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341093</guid>
            <pubDate>Sat, 22 Mar 2025 07:15:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenBao 獲採納為 EdgeX 的秘密存儲</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為增強安全性和開放性，EdgeX Foundry 正式將 OpenBao 作為 EdgeX 4.0 版本的默認秘密存儲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EdgeX Foundry 是一個開源的 IoT/邊緣計算框架，由 Linux 基金會託管。它旨在通過靈活的微服務架構，實現設備、應用和服務之間的無縫通信。無論你在自動化、能源還是建築管理領域，EdgeX 都能以標準化的方式將一切連接起來。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;152&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1956e610d420b596ef4a166f66529a5a0b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前，EdgeX 主要依賴 HashiCorp Vault 安全存儲敏感信息。然而，隨着 Vault 轉向商業源許可證（BSL），EdgeX 社區選中了 OpenBao 作為未來的替代方案。OpenBao 是一個由社區驅動的開源項目，屬於 Linux 基金會。它提供基於身份的秘密和加密管理系統，確保敏感數據得到保護。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMZsyEUjRY2JkmfAaY9o-BA&quot; target=&quot;_blank&quot;&gt;指出&lt;/a&gt;，選擇 OpenBao 的原因包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;無縫遷移 – OpenBao 設計上與其上游 API 兼容，切換過程順利且無憂。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;開放和供應商中立的許可證 – 開源自由和長期社區合作。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;安全優先的方法 – 強加密和基於身份的訪問控制確保秘密安全。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;活躍的社區支持 – 專注團隊確保持續改進、安全更新和功能增強。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於已經在使用 EdgeX 的用户，這一變更幾乎不會造成影響。核心服務已更新以支持 OpenBao，同時保持與之前相同的 API，意味着幹擾最小。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341087</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341087</guid>
            <pubDate>Sat, 22 Mar 2025 07:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>頂尖 AI 專家齊國君自美歸國：加盟西湖大學、拿過華為總裁獎</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scmp.com%2Fnews%2Fchina%2Fscience%2Farticle%2F3303527%2Fai-expert-guo-jun-qi-leaves-us-china&quot; target=&quot;_blank&quot;&gt;根據《南華早報》的報道&lt;/a&gt;&lt;/u&gt;，屢獲殊榮的人工智能（AI）專家和計算機科學家齊國君在美國工作十幾年後，已回國加盟位於杭州的西湖大學領導 「MAPLE 實驗室」 團隊。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.westlake.edu.cn%2Ffaculty%2Fguojun-qi.html&quot; target=&quot;_blank&quot;&gt;據西湖大學官網介紹&lt;/a&gt;&lt;/u&gt;，齊國君，安徽合肥人，國際電氣和電子工程師協會會士（IEEE Fellow）、國際模式識別聯合會會士（IAPR Fellow）、國際計算機協會（ACM）傑出科學家，中國科學技術大學郭沫若獎得主。&lt;/p&gt; 
&lt;p&gt;齊國君課題組主要開展機器感知和學習方向的研究，致力於研發對虛實場景進行多模態感知、生成與交互的人工智能系統，並應用於多媒體計算、基於 AIGC 的智慧創作等領域。他在人工智能多模態算法與模型、智慧創作與虛擬現實等多個領域取得了多項開創性成果。已在相關國際會議與雜誌上發表論文共計 200 餘篇，引用近 20000 次。&lt;/p&gt; 
&lt;p&gt;西湖大學形容，通俗地講，齊國君可以被看做機器的 「養育者」，他開發模型，教機器能夠同時理解文字、圖片、音頻、視頻等多種媒介傳遞的信息，讓機器變得 「更智能」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/145658_Rof3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從 2014 年到 2024 年，齊國君在美國做了十年研究，他先加入了 IBM T.J. Watson 研究中心擔任研究員，之後進入美國中佛羅裏達大學執教一年。然後離開美國中佛羅裏達大學，加入華為美國研究中心，擔任技術副總裁（Technical VP）和首席 AI 科學家（Chief AI Scientist）。&lt;/p&gt; 
&lt;p&gt;在華為美國研究中心，他主要負責華為雲 EI 智能體項目，主持設計 TrafficGo 智慧城市系統，優化整合了每天數億級的多模態數據，對 200 多個路口的複雜路況進行實時調控，極大提升了交通出行效率和應急事件處理速度，因此獲得華為總裁獎。&lt;/p&gt; 
&lt;p&gt;再然後，他去了 OPPO，一手創立了 OPPO 西雅圖研究中心，還是立足於多模態數據的處理，把研究的邊界往虛擬現實領域拓寬了一步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341086</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341086</guid>
            <pubDate>Sat, 22 Mar 2025 07:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國大模型密集開源，影響幾何？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年以來，中國大模型開源的消息一個接一個。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里雲通義千問從除夕夜開源全新的視覺模型 Qwen2.5-VL，再到本月初發布並開源了全新推理模型 QwQ-32B，在開源當日就登頂全球主流 AI 開源社區 Hugging Face 的趨勢榜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek(深度求索) 達成過「開源周」，其在 2 月末連續五天發佈五個代碼庫，並於近日繼續開源上線了升級後的 DeepSeek-V3 模型。 階躍星辰則在一個月左右時間開源三款多模態大模型，其最新開源的是圖生視頻模型 Step-Video-TI2V，支持生成的視頻具備運動幅度可控和鏡頭運動可控兩大核心特點，同時自帶一定的特效生成能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為何開源大模型成為中國當前的發展潮流？FutureLabs 未來實驗室首席專家胡延平對中新社記者表示，大模型廠商普遍選擇開源，且有強勁的市場爆發力，是因為人工智能發展處在四個重要時刻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一是端側智能的需求崛起，包括個人單機部署 AI 方面的需求，推動端側智能快速發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;二是企業行業 AI 部署的需求驅動，千行百業 AI 需求激增，但通用雲端大模型難以滿足差異化的業務場景與數據隱私保護的需要。開源憑藉靈活性和定製化能力，成為企業實現差異化部署的首選，開源模型體現出隨需應變的明顯優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中新社記者獲取的數據顯示，截至 3 月 25 日，通義千問開源模型 Qwen 系列的全球下載量已超 2 億。通過千千萬萬的開發者和中小企業，通義大模型深入千行百業，包括醫療、教育、金融、電力、交通、計算機等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;三是 AI 產業生態化進入加速時刻，出現分工協作體系，上下游協作關係更為清晰。頭部企業聚焦模型能力強化，中小企業則基於開源模型開發細分場景應用，形成企業數量更大的產業腰部、大模型後市場，這是一個分工日趨明確的產業生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;四是 AI 大模型能力提升顯著，從「可用」進入「高可用」時刻，用户、應用由此進入爆發性增長時刻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據中國工信部官方消息，目前，中國已成為全球開源參與者數量排名第二、增長速度最快的國家。另有數據顯示，阿里通義開源模型的衍生模型數量已突破 10 萬個，成為全球最大的開源模型族羣。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國大模型密集開源，影響幾何？&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國科學院院士梅宏曾表示，大語言模型在未來需要像互聯網一樣，走向開源，由全世界共同維護一個開放共享的基礎模型，盡力保證其與人類知識的同步。否則，任何一個機構所掌控的基礎模型都難以讓其他機構用户放心地上傳應用數據，也就很難產生足以滿足各行各業業務需求的大量應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;胡延平説，以通義千問為代表的中國大模型正藉助這一波開源大勢，縮小與全球領先 AI 技術的差距，最重要的是中國開源的生態化獲得極大成功，為今後發展積蓄了較強勢能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里雲高級總監朱迅垚認為，現在大家逐步認識到，開源模型將成為推動中國人工智能發展最強勁的引擎。下一步，建議從國家到地方再到企業，以更加積極的態度擁抱開源，同時在佈局智能算力、構建高質量數據集、上雲用雲等方面加快創新步伐，緊跟世界先進水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;有外媒近日報道稱，中國科技公司選擇開源路線，不僅是為了與同類型公司展開競爭，更是為了加速 AI 的採用和創新。開源模型降低了成本，為產品創新打開了大門。這一趨勢不僅將推動中國 AI 領域的快速發展，甚至可能縮短技術差距。&amp;nbsp;(中新社，記者，夏賓)&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341084</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341084</guid>
            <pubDate>Sat, 22 Mar 2025 06:57:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘋果花費約 10 億美元採購英偉達 AI 服務器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;蘋果公司曾公開宣稱其正在使用 Apple Silicon 服務器來支持&amp;nbsp;Apple Intelligence&amp;nbsp;的運行，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.investors.com%2Fnews%2Ftechnology%2Fapple-stock-apple-joins-ai-data-center-race%2F&quot; target=&quot;_blank&quot;&gt;但根據 Loop Capital 分析師 Ananda Baruah 的説法&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;該公司現在也在花費 10 億美元購買 NVIDIA 的 AI 服務器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;他在給投資者的一份報告中寫道： 「&amp;nbsp;AAPL 正式加入大型服務器集羣 Gen AI 遊戲，超微[Super Micro Computer] 和戴爾是關鍵的服務器合作伙伴。雖然我們仍在收集更全面的信息，但這似乎有可能成為 Gen AI LLM（大型語言模型）集羣。」&lt;/p&gt; 
&lt;p&gt;Baruah 聲稱，蘋果正在購買 250 台 NVIDIA NVL72 服務器，每台服務器的成本在 370 萬至 400 萬美元之間。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;梳理事件時間線如下：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 4 月：消息稱蘋果將使用自研芯片搭建 AI 服務器&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 6 月：消息稱蘋果數據中心將全面採用 Apple Silicon&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 9 月：蘋果軟件工程高級副總裁 Craig Federighi 公開確認，Apple Intelligence 服務完全運行在自研服務器上，稱這是「行業雲端處理新標準」。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2025 年 3 月：分析師披露蘋果訂購 250 台英偉達 NVL72 服務器，單台成本 370 萬至 400 萬美元（現匯率約合 2685.9 萬至 2903.7 萬元人民幣），總價近 10 億美元（現匯率約合 72.59 億元人民幣）。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據 NVIDIA 稱，其 NVL72 服務器包含 36 個 Grace CPU 和 72 個 Blackwell GPU。該公司還表示，截至 2025 年 3 月 18 日，該服務器尚未上市。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f4be572287f934556dc646afc95fcd6fca2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;毫無疑問，蘋果現在可以預訂服務器，而且該公司認為有必要擴大其服務器，這並不奇怪。從數量來看，這可能是為了開發目的，而不是面向公眾，但現在還無法判斷——這是假設報道是正確的。&lt;/p&gt; 
&lt;p&gt;如果它的目的不僅僅是開發，那麼這與 Federighi 的説法並不完全相符，他認為使用 Apple Silicon 服務器「為行業雲端處理樹立了新標準」。&lt;/p&gt; 
&lt;p&gt;他説：「在我們之前沒有 Apple Silicon 服務器的情況下，在數據中心構建服務器，並構建一個在數據中心運行的自定義操作系統，這是一項艱鉅的任務。」「[創建]信任模型，除非服務器正在運行的所有軟件的簽名已發佈到透明日誌中，否則您的設備將拒絕向服務器發出請求，這無疑是解決方案中最獨特的元素之一，並且對信任模型至關重要。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341081/apple-spend-1-billion-on-nvidia-servers-for-ai-analyst</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341081/apple-spend-1-billion-on-nvidia-servers-for-ai-analyst</guid>
            <pubDate>Sat, 22 Mar 2025 06:49:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>