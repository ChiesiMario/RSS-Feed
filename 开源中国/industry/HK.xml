<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 16 Sep 2025 07:40:31 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>​Meta AI 發佈 MobileLLM-R1：輕量級邊緣推理模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Meta AI 近日推出了 MobileLLM-R1，這是一系列輕量級邊緣推理模型，目前已在 Hugging Face 上發佈。該系列模型參數範圍從 140M 到 950M，專注於高效的數學、編碼和科學推理，且在不足 10 億的參數規模下實現了優秀的性能表現。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="365" src="https://oscimg.oschina.net/oscnet/up-30b7f801e9b13bb0046a53750505a0aa2ec.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;MobileLLM-R1 的&lt;span&gt;最大&lt;/span&gt;模型為 MobileLLM-R1-950M，採用了一系列架構優化設計:包括 22 層 Transformer 結構、24 個注意力頭和 6 個分組 KV 頭。模型的嵌入維度為 1536，隱藏層維度為 6144。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，模型還採用了分組查詢注意力（GQA）來減少計算和內存需求，塊級權重共享技術降低了參數數量而不顯著增加延遲，SwiGLU 激活函數提升了小模型的表示能力。模型支持 4K 的上下文長度和 32K 的後訓練模型。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在訓練效率方面，MobileLLM-R1 的表現同樣引人注目。該模型總共在約 4.2 萬億個 token 上進行訓練，相較於 Qwen3 的 0.6B 模型訓練的 36 萬億 token，MobileLLM-R1 僅使用了約 11.7% 的數據便達到了或超越了 Qwen3 的準確率。同時，模型在數學、編碼和推理數據集上進行了監督微調，從而降低了訓練成本和資源需求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在各項基準測試中，MobileLLM-R1-950M 的表現優異:在 MATH500 數據集上，其準確率比 OLMo-1.24B 高出約 5 倍，且比 SmolLM2-1.7B 高出約 2 倍。在 GSM8K、AIME 和 LiveCodeBench 等推理和編碼任務上，MobileLLM-R1 甚至與 Qwen3-0.6B 相匹配或超越，儘管所使用的 token 數量遠少於後者。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，MobileLLM-R1 的聚焦也帶來了侷限性。雖然在數學、編碼和結構化推理方面表現強勁，但在一般對話、常識推理和創造性任務上，MobileLLM-R1 的表現較大型模型有所不足。此外，模型在生產環境中的使用受到 FAIR NC（非商業）許可證的限制，較長的上下文 (32K) 也提高了推理時的 KV 緩存和內存需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372545</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372545</guid>
      <pubDate>Tue, 16 Sep 2025 07:30:27 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開發者必看：隱語框架的分層拆解和使用</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;打開鏈接點亮社區 Star，照亮技術的前進之路。 &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-edf8393baa8c76890c2e321dca39a57a078.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;每一個點贊，都是社區技術大佬前進的動力&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Github 地址： &lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsecretflow%2Fsecretflow" target="_blank"&gt;https://github.com/secretflow/secretflow&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f1f5ac60c4e44a644832b0e9d03aac9f579.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;一、"隱語"架構設計全貌&lt;/h2&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;1.隱語框架設計思想&lt;/h3&gt; 
&lt;p&gt;隱私計算是一個新興的跨學科領域，涉及&lt;strong&gt;密碼學、機器學習、數據庫、硬件&lt;/strong&gt;等多個領域。根據過去幾年的實踐經驗，我們發現&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隱私計算技術方向多樣，&lt;/strong&gt;不同場景下有其各自更為合適的技術解決方案&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隱私計算學習曲線很高&lt;/strong&gt;，非隱私計算背景的用户使用困難&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隱私計算涉及領域眾多，&lt;/strong&gt;需要領域專家共同協作&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-66d2fb38d008b759553f3f5a5253b809349.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;隱語的設計目標&lt;/strong&gt;是使得數據科學家和機器學習開發者可以非常容易地使用隱私計算技術進行數據分析和機器學習建模，而無需瞭解底層技術細節。&lt;/p&gt; 
&lt;p&gt;為達到這個目標，**隱語提供了一層設備抽象，**將多方安全計算 (MPC)、同態加密 (HE) 和可信執行環境 (TEE) 等隱私計算技術抽象為密文設備， 將單方計算抽象為明文設備。&lt;/p&gt; 
&lt;p&gt;基於這層抽象，數據分析和機器學習工作流可以表示為一張計算圖，&lt;strong&gt;其中節點表示某個設備上的計算，邊表示設備之間的數據流動，不同類型設備之間的數據流動會自動進行協議轉換&lt;/strong&gt;。在這一點上，隱語借鑑了主流的深度學習框架，後者將神經網絡表示為一張由設備上的算子和設備間的張量流動構成的計算圖。&lt;/p&gt; 
&lt;p&gt;隱語框架圍繞開放這一核心思想，提供了不同層次的設計抽象，希望為不同類型的開發者都提供良好的開發體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在設備層，隱語提供了良好的設備接口和協議接口，支持更多的設備和協議插拔式的接入&lt;/strong&gt;，我們希望與密碼學、可信硬件、硬件加速等領域專家通力合作，不斷擴展密態計算的類型和功能，不斷提升協議的安全性和計算性能。&lt;/p&gt; 
&lt;p&gt;同時，隱語提供了良好的設備接口，第三方隱私計算協議可作為設備插拔式接入。&lt;strong&gt;在算法層，為機器學習提供了靈活的編程接口，算法開發者可以很容易定義自己的算法。&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;2.架構分層總覽&lt;/h3&gt; 
&lt;p&gt;隱語總體架構自底向上一共分為五層：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-41a68e7f0ca01ba4db1273f9f2d109f05cd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;資源管理層：&lt;/strong&gt; 主要承擔了兩方面的職責。第一是面向業務交付團隊，可以屏蔽不同機構底層基礎設施的差異，降低業務交付團隊的部署運維成本。另一方面，通過對不同機構的資源進行集中式管理，構建出一個高效協作的數據協同網絡。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;明密文計算設備與原語層：&lt;/strong&gt; 提供了統一的可編程設備抽象，將多方安全計算 (MPC)、同態加密 (HE)、可信硬件 (TEE) 等隱私計算技術抽象為密態設備，將單方本地計算抽象為明文設備。同時，提供了一些不適合作為設備抽象的基礎算法，如差分隱私 (DP)、安全聚合 (Secure Aggregation) 等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;明密文混合調度層：&lt;/strong&gt; 提供了統一的設備調度抽象，將上層算法描述為一張有向無環圖，其中節點表示某個設備上的計算，邊表示設備之間的數據流動，即邏輯計算圖。邏輯計算圖由分佈式框架進一步拆分並調度至物理節點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI &amp;amp; BI 隱私算法層：&lt;/strong&gt; 這一層的目的是屏蔽掉隱私計算技術細節，但保留隱私計算的概念，其目的是降低隱私計算算法的開發門檻，提升開發效率。&lt;/p&gt; 
&lt;p&gt;有隱私計算算法開發訴求的同學，可以根據自身場景和業務的特點，設計出一些特化的隱私計算算法，來滿足自身業務和場景對安全性、計算性能和計算精度的平衡。&lt;/p&gt; 
&lt;p&gt;在這一層上，隱語本身也會提供一些通用的算法能力，比如 MPC 的 LR/XGB/NN，聯邦學習算法，SQL 能力等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;用户界面層：&lt;/strong&gt; 隱語的目標並不是做一個端到端的產品，而是為了讓不同的業務都能夠通過快速集成隱語而具備全面的隱私計算能力。因此我們會在最上層去提供一層比較薄的產品 API，以及一些 SDK，去降低業務方集成隱語的成本。&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;3.架構細節拆解&lt;/strong&gt;&lt;/h3&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;設備與原語層&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;隱語的設備分為物理設備和邏輯設備，其中，物理設備是隱私計算各個參與方的物理機器，邏輯設備則由一個或多個物理設備構成。&lt;/p&gt; 
&lt;p&gt;邏輯設備支持一組，特定的計算算子 (Device Ops)，有自己特定的數據表示 (Device Object)。&lt;strong&gt;邏輯設備分為明文和密文兩種類型，前者執行單方本地計算，後者執行多方參與的隱私計算。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;邏輯設備的運行時負責內存管理、數據傳輸、算子調度等職責，運行在一個或多個物理設備上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;邏輯設備和物理設備不是一對一的關係，一個物理設備可能同時屬於多個邏輯設備&lt;/strong&gt;。在同一組物理設備上，可以根據不同的隱私協議和參與組合虛擬出不同的邏輯設備。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-814224da9f6ff77d2740d3b16167d0fbe4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下表是隱語目前暫定支持的設備列表：&lt;/p&gt; 
&lt;table border="1" cellpadding="1" cellspacing="1" style="width:500px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;設備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;類型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;運行時&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;算子&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;協議&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;前端&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;狀態&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;PYU&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;明文&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Python Interpreter&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;—&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;—&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Python&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Release&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;SPU&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;密文&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;SPU VM&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;PSI, XLA HLO&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;SPDZ-2k, ABY3&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;JAX, TensorFlow, PyTorch&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Alpha&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;HEU&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;密文&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;HEU Runtime&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Add, XLA HLO&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Paillier, OU, TFHE&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Numpy, JAX&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span style="color:#333333"&gt;Alpha&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;TEE&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;密文&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;TEE Runtime&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;XLA HLO&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Intel SGX&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;JAX, TensorFlow, PyTorch&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;WIP&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id="OSC_h4_6"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;可編程性&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;邏輯設備具備可編程性，即用户可以在設備上自定義計算邏輯，每個設備對用户提供了協議無關的編程接口。**在一個設備上，用户可以定義從簡單的矩陣運算， 到完整的深度模型訓練。**當然，這一切取決於設備提供的計算能力。&lt;/p&gt; 
&lt;p&gt;對於明文設備 PYU，它的前端為 python，用户可以通過&lt;code&gt;@device&lt;/code&gt;將一段預定義 python 函數調度至其上執行。&lt;/p&gt; 
&lt;p&gt;對於密文設備 SPU、HEU、TEE，它們的前端可以是任何支持 XLA 的框架， 如 JAX, TensorFlow,PyTorch 等。同樣的，用户也可以通過&lt;code&gt;@device&lt;/code&gt;將基於這些前端自定義的函數調度至指定的設備執行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import jax.numpy as jnp

dev = Device()  # maybe PYU, SPU, HEU, TEE


@device(dev)
def selu(x, alpha=1.67, lmbda=1.05):
    return lmbda * jnp.where(x &amp;gt; 0, x, alpha * jnp.exp(x) - alpha)


res = selu(x)  # res is a DeviceObject
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;用户自定義函數首先轉換成&lt;strong&gt;XLA HLO Computation&lt;/strong&gt;，由 XLA 進行設備無關的代碼優化和分析，併發往後端設備。後端設備進一步執行代碼優化和分析，並生成最終，的可執行代碼。&lt;/p&gt; 
&lt;p&gt;可執行代碼或由設備的虛擬機解釋執行 (SPU, HEU)，或由硬件直接執行 (TEE)。使用 XLA HLO 作為 IR，使得我們可以複用 XLA 前端和設備無關，代碼優化，同時使得後端實現更加簡潔乾淨。&lt;/p&gt; 
&lt;p&gt;對於密文設備（半同態）HEU，它僅支持一組有限的計算，因此提供了一組預定義算子如&lt;code&gt;__add__&lt;/code&gt;,&lt;code&gt;__mul__&lt;/code&gt;等，用户不能通過&lt;code&gt;@device&lt;/code&gt;進行自定義編程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;x, y = HEUObject(), PYUObject()
z = x + y  # add
z = x * y  # mul
z = x @ y  # matmul
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_7"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;協議轉換&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;用户在邏輯設備上進行編程，構建邏輯計算圖，**其節點表示設備上的一段函數或算子，邊表示設備對象的流動。**邏輯計算圖被設備進一步分割為子圖，兩個子圖間的，邊表示跨設備的對象流動，此時需要進行協議轉換。設備對象的&lt;code&gt;DeviceObject.to&lt;/code&gt;接口用於轉換至目標設備對象，任何新增的設備都應該提供相應的轉換函數並，插入對象轉換表中。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;下表是各個邏輯設備對象的轉換表：&lt;/strong&gt;&lt;/p&gt; 
&lt;table border="1" cellpadding="1" cellspacing="1" style="width:500px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PYU&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;SPU&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HEU&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;TEE&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PYU&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
   &lt;td&gt;share&lt;/td&gt; 
   &lt;td&gt;encrypt&lt;/td&gt; 
   &lt;td&gt;encrypt&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SPU&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;reconstruct&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
   &lt;td&gt;encrypt+add&lt;/td&gt; 
   &lt;td&gt;reconstruct+encrypt&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;HEU&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;decrypt&lt;/td&gt; 
   &lt;td&gt;minus+decrypt&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
   &lt;td&gt;decrypt+encrypt&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TEE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;decrypt&lt;/td&gt; 
   &lt;td&gt;decrypt+share&lt;/td&gt; 
   &lt;td&gt;decrypt+encrypt&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id="OSC_h4_8"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;分佈式引擎&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;用户基於設備構建了一張邏輯計算圖，那麼我們如何執行這張計算圖？由於邏輯設備映射到一個或多個物理設備，&lt;strong&gt;因此我們需要將邏輯設備上的算子正確調度到其對應的物理設備，同時處理好這些物理設備間的數據傳輸關係&lt;/strong&gt;。毫無疑問，我們需要一個分佈式圖執行引擎來解決這些問題。&lt;/p&gt; 
&lt;p&gt;那麼我們需要一個怎樣的分佈式圖執行引擎？以下是隱語對它的要求&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;細粒度的異構計算：在一張邏輯計算圖中，具有不同粒度的計算任務，既有簡單的數據處理（秒級），也有複雜的多方訓練（幾個小時至幾十小時）。同時，物理節點具有不同的硬件環境，CPU, GPU, TEE, FPGA 等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;靈活的計算模型：在水平、垂直場景下，針對數據處理和模型訓練等不同工作流，支持多種並行模型，如數據並行、模型並行、混合並行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;動態執行：在聯邦學習場景下，不同機構的數據規模、帶寬延遲、機器性能可能有較大差異，這導致同步模式的效率受限於最慢的工作節點。因此，我們希望支持，異步訓練模式，這要求圖執行引擎具有動態執行能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2c0fb0a2006a01dc6e88397c7510e42537d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;隱語針對隱私計算場景，已經對框架進行了一些安全加固工作：&lt;strong&gt;通過身份認證、代碼預裝、代碼存證等手段對框架做了整體加固&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;未來，還將探索沙箱隔離、訪問控制、靜態圖等機制以進一步提升安全水位。在環境適配方面，為了適配跨機構網絡通信的特點，推進了 GCS gRPC 通信、域名支持、弱網斷線處理等相關功能的開發。&lt;/p&gt; 
&lt;span id="OSC_h4_9"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;AI &amp;amp; BI 隱私算法&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;這一層的目的是其目的是降低隱私計算算法的開發門檻，提升開發效率。有隱私計算算法開發訴求的同學，可以根據自身場景和業務的特點，設計出一些特化的隱私計算算法，來&lt;strong&gt;滿足自身業務和場景對安全性、計算性能和計算精度的平衡&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在這一層上，隱語本身也會提供一些通用的算法能力，比如 MPC 的 LR/XGB/NN，聯邦學習算法，SQL 能力等。&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;二、"隱語"框架的使用&lt;/h2&gt; 
&lt;p&gt;使用隱語構建隱私計算算法 &lt;strong&gt;邏輯設備抽象為算法開發者提供了極大的靈活性，&lt;/strong&gt; 他們可以像積木一樣自由組合這些設備，在設備上自定義計算，從而構建自己的隱私計算算法。&lt;/p&gt; 
&lt;p&gt;接下來，我們通過一個具體的算法來展示隱語框架的通用編程能力。聯邦學習算法聯邦機器學習又名聯邦學習、聯合學習、聯盟學習，是一種機器學習框架，能有效幫助多個機構在滿足用户隱私保護、數據安全和政府法規的要求下，進行數據使用和機器學習建模。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ac805372dc1d72a4712d5e495a399b0eba4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;聯邦學習的算法流程如上圖所示，大致分為以下四個步驟：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;機構節點在本地進行多輪訓練，得到模型參數&lt;/li&gt; 
 &lt;li&gt;機構節點使用加密協議，將模型參數上傳至聚合節點&lt;/li&gt; 
 &lt;li&gt;聚合節點使用加密協議，對模型參數進行聚合，得到全局模型&lt;/li&gt; 
 &lt;li&gt;機構節點從聚合節點獲取最新的全局模型，進入下一輪訓練&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;節點本地訓練&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;機構節點運行在機構本地，隱語提供了一個邏輯設備&lt;code&gt;PYU&lt;/code&gt;，執行本地的明文計算。&lt;/p&gt; 
&lt;p&gt;下面的&lt;code&gt;BaseTFModel&lt;/code&gt;定義了本地模型訓練邏輯，用户可以選擇自己喜好的機器學習框架，如&lt;code&gt;TensorFlow, PyTorch&lt;/code&gt;等。&lt;/p&gt; 
&lt;p&gt;隱語提供了&lt;code&gt;@proxy&lt;/code&gt;裝飾器，對一個普通的類進行了初始設置，以便後續在邏輯設備上對其實例化。&lt;code&gt;@proxy(PYUObject)&lt;/code&gt;表明該類需要在 PYU 設備上實例化。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@proxy(PYUObject)
class BaseTFModel:
    def train_step(self, weights, cur_steps, train_steps) -&amp;gt; Tuple[np.ndarray, int]:
    self.model.set_weights(weights)
        num_sample = 0
        for _ in range(train_steps):
            x, y = next(self.train_set)
            num_sample += x.shape[0]
            self.model.fit(x, y)

        return self.model.get_weights(), num_sample
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;模型安全聚合&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;模型聚合對各個機構節點的模型參數進行加權平均，如下面&lt;code&gt;_average&lt;/code&gt;所示。隱語邏輯設備的最大特點在於可編程性，用户可以將一段函數調度到多種設備執行，以達到使用不同隱私計算技術的目的。&lt;/p&gt; 
&lt;p&gt;目前，&lt;code&gt;DeviceAggregator&lt;/code&gt;可以支持 PYU 明文聚合，也可以支持 SPU MPC 協議聚合，後續我們還將支持 TEE, HEU 等多種密文設備。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@dataclass
class DeviceAggregator(Aggregator):
    device: Union[PYU, SPU]

    def average(self, data: List[DeviceObject], axis=0, weights=None):
        # 2. 機構節點使用加密協議，將模型參數上傳至聚合節點
        data = [d.to(self.device) for d in data]
        if isinstance(weights, (list, tuple)):
            weights = [w.to(self.device) if isinstance(w, DeviceObject) else w for w in weights]

        def _average(data, axis, weights):
            return [jnp.average(element, axis=axis, weights=weights) for element in zip(*data)]

        # 3. 聚合節點使用加密協議，對模型參數進行聚合，得到全局模型
        return self.device(_average, static_argnames='axis')(data, axis=axis, weights=weights)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;訓練流程整合&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有了節點本地訓練、模型安全聚合，我們就可以將其整合起來形成完整的訓練流程。首先，我們在每個 PYU 設備（代表機構節點）創建 BaseTFModel 實例。&lt;/p&gt; 
&lt;p&gt;同時，初始化聚合器，可以是 PYU, SPU, TEE, Secure Aggregation。然後，按照上述描述的聯邦學習算法流程進行迭代訓練。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;class FedTFModel:
    def __init__(self, device_list: List[PYU] = [], model: Callable[[], tf.keras.Model] = None, aggregator=None):
        # 在每個機構節點 (PYU) 創建一個 BaseTFModel 實例
        self._workers = {device: BaseTFModel(
            model, device=device) for device in device_list}
        # 聚合器，可以是 PYU, SPUPPU, TEE, Secure Aggregation
    self._aggregator = aggregator

    def fit(self, x: Union[HDataFrame, FedNdarray], y: Union[HDataFrame, FedNdarray], batch_size=32, epochs=1, verbose='auto',
            callbacks=None, validation_data=None, shuffle=True,
            class_weight=None, sample_weight=None, validation_freq=1, aggregate_freq=1):
    self.handle_data(train_x, train_y, batch_size=batch_size,
                     shuffle=shuffle, epochs=epochs)

    # 初始化模型參數
    current_weights = {
        device: worker.get_weights() for device, worker in self._workers.items()}

    for epoch in range(epochs):
        for step in range(0, self.steps_per_epoch, aggregate_freq):
            weights, sample_nums = [], []
            for device, worker in self._workers.items():
                # 1. 機構節點在本地進行多輪訓練，得到模型參數
                weight, sample_num = worker.train_step(current_weights[device], epoch*self.steps_per_epoch+step, aggregate_freq)
                weights.append(weight)
                sample_nums.append(sample_num)
            # 模型參數聚合，可以是：PYU, SPU, TEE, Secure Aggregation
            current_weight = self._aggregator.average(
                weights, weights=sample_nums)
            # 4. 機構節點從聚合節點獲取最新的全局模型，進入下一輪訓練
            current_weights = {device: current_weight.to(device) for device, worker in self._workers.items()}
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h4_11"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;更多算法：&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;通過以上聯邦學習算法的例子，我們展示了隱語作為隱私計算框架的可編程性、可擴展性。&lt;/p&gt; 
&lt;p&gt;期待您基於隱語探索更多&lt;strong&gt;有趣的用法&lt;/strong&gt;！更多詳情請參考我們的教程和實現。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecretflow.readthedocs.io%2Fzh%2Flatest%2Ftutorial%2Findex.html%23" target="_blank"&gt;https://secretflow.readthedocs.io/zh/latest/tutorial/index.html#&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在 SPU 進行 PSI 對齊，邏輯迴歸、神經網絡訓練&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用 SPU HEU 的組合構建 HESS-LR, HESS-XGB 算法&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;橫向聯邦學習，在 PYU 進行本地訓練，使用 SPU、TEE、Secure Aggregation 進行梯度、權重聚合&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;縱向拆分學習，將一個模型拆分至多個 PYU，使用 PYU 聚合隱層，使用差分隱私保護前向隱層和反向梯度&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-edf8393baa8c76890c2e321dca39a57a078.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;打開鏈接即可點亮社區 Star，照亮技術的前進之路。&lt;/p&gt; 
&lt;p&gt;Github 地址：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsecretflow%2Fsecretflow" target="_blank"&gt;https://github.com/secretflow/secretflow&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本文由隱語社區統一發布，歡迎大家點 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsecretflow%2Fsecretflow" target="_blank"&gt;Star&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5915128/blog/18691893</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5915128/blog/18691893</guid>
      <pubDate>Tue, 16 Sep 2025 07:10:27 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>OpenAI 發佈最大規模 ChatGPT 普通用户使用報告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 經濟研究團隊與哈佛大學經濟學家 David Deming 合作完成了名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fhow-people-are-using-chatgpt%2F" target="_blank"&gt;&lt;em&gt;《How people are using ChatGPT》&lt;/em&gt;&lt;/a&gt;的研究報告，據稱這是有史以來最大規模的一次關於普通用户（consumer users）如何使用 ChatGPT 的調查。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/151027_d0un_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;樣本包括 150 萬條對話，結合了 ChatGPT 在 2025 年中期的用户活動數據（當時每週有約 7 億活躍用户）。&lt;/p&gt; 
&lt;p&gt;下面是該研究的一些發現：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;誰在使用 ChatGPT？&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性別差距正在縮小。早期用户中，名字可分辨為「女性傾向」的佔比曾比現在少；到了 2025 年 7 月，這一比例上升到超過一半。&lt;/li&gt; 
 &lt;li&gt;在低收入和中等收入國家的採用率增長尤其快。到 2025 年 5 月，最低收入國家的增長率是最高收入國家的 4 倍以上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;人們用 ChatGPT 做什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;大部分對話是關於處理日常任務（practical guidance）、獲取信息（seeking information）和寫作（writing）。寫作是工作中最常見的任務類型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;互動類型可以分為三類：「Asking」（提問）、「Doing」（執行任務／創造輸出）、「Expressing」（表達）。在這些中：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;「Asking」（約 49%）— 用户尋求建議、信息等；&lt;/li&gt; 
   &lt;li&gt;「Doing」（約 40%）— 包括起草文本、策劃、編程等實作型任務，其中約三分之一是用於工作用途。&lt;/li&gt; 
   &lt;li&gt;「Expressing」（約 11%）— 包括情感表達、反思、娛樂或個人探索等。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;使用形式與演變？&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;大約 30% 的使用與工作有關，約 70% 與非工作（個人生活）有關。兩者都在增長，説明 ChatGPT 不僅是生產力工具，也在個人日常生活中創造價值。&lt;/li&gt; 
 &lt;li&gt;一個關鍵的價值是決策支持（decision support）：ChatGPT 在知識密集型職業中能夠幫助改善判斷和效率。&lt;/li&gt; 
 &lt;li&gt;使用隨着時間加深：隨着模型能力的提升和用户探索出新的用途，人們使用頻次與深入程度都在上升。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;研究發現，ChatGPT 的用户基礎越來越廣泛，使用者的社會／經濟背景差距在縮小。 它不僅在工作場景中提高效率，也在日常生活中提供幫助；因此其經濟價值不僅體現在對 GDP 的直接貢獻，也體現在人們日常生活中未被傳統經濟統計完全捕捉的價值。 OpenAI 從中得出的理念是，人工智能的訪問應當被視為基本權利，讓更多人能利用它釋放潛力，塑造自己的未來。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372540/how-people-are-using-chatgpt</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372540/how-people-are-using-chatgpt</guid>
      <pubDate>Tue, 16 Sep 2025 07:09:27 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊跨端開源框架 Kuikly 適配「液態玻璃」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Kuikly 是基於 Kotlin Multiplatform 的 UI 與邏輯全面跨端綜合解決方案，由騰訊大前端領域 Oteam（公司級）推出，旨在提供一套一碼多端、極致易用、動態靈活的全平台高性能開發框架。&lt;/p&gt; 
&lt;p&gt;目前支持如下平台：Android、iOS、鴻蒙、Web（beta）和小程序（beta）。&lt;/p&gt; 
&lt;p&gt;Kuikly 團隊介紹稱，項目已完成對「液態玻璃」的首階段適配，並對外開源發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/143023_KFsf_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="640" src="https://static.oschina.net/uploads/space/2025/0916/143104_iaPI_2720166.jpg" width="295" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了適配「液態玻璃」，Kuikly 沒有引入新的獨立組件，而是為現有組件提供了簡潔的視圖屬性擴展。例如，開發者只需通過一行&amp;nbsp;&lt;code&gt;glassEffectIOS()&lt;/code&gt;代碼，即可為任意容器視圖啓用液態玻璃效果。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;View {
    attr {
        glassEffectIOS() // iOS 平台將自動添加液態玻璃效果
    }
    // ... 其他子視圖
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;團隊表示，Kuikly 的適配工作並非簡單的 UI 改造，而是充分利用原生提供的基礎能力，在框架渲染層和 DSL 驅動層兩方面進行擴展，旨在為開發者提供一套便捷、低成本的適配方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372524</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372524</guid>
      <pubDate>Sun, 14 Sep 2025 06:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>邏輯智能開源語音大模型框架 LLaSO</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;北京深度邏輯智能科技有限公司宣佈於近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC_6mpkuhZKux-2_R4ry-WA" target="_blank"&gt;推出&lt;/a&gt;了 LLaSO—— 首個完全開放、端到端的語音語言模型研究框架。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;「&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;旨在為整個社區提供一個統一、透明且可復現的基礎設施，其貢獻是 「全家桶」 式的，包含了一整套開源的數據、基準和模型，希望以此加速 LSLM 領域的社區驅動式創新。&lt;/span&gt;」&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="293" src="https://oscimg.oschina.net/oscnet/up-ed6dc13e714b133ebab01f09bf906071073.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;LLaSO 框架包括三個核心開源組件：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span&gt;&lt;strong&gt;LLaSO-Align：大規模語音 - 文本對齊數據集&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;數據規模&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：1200 萬語音 - 文本對齊樣本&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;數據來源&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：聚合對話、有聲書、多口音語音等多樣化來源&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;技術目標&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：通過自動語音識別（ASR）任務建立語音表示與文本語義空間的精確對齊&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;質量控制&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：採用多重過濾機制確保數據質量和説話人多樣性&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span&gt;&lt;strong&gt;LLaSO-Instruct：多任務指令微調數據集&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;數據規模&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：1350 萬多任務指令樣本&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;任務覆蓋&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：涵蓋語言學、語義學、副語言學三大類共 20 項任務&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;語言學任務：ASR、翻譯、總結等基礎語言理解&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
   &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;語義學任務：問答、推理、內容分析等高級認知&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
   &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;副語言學任務：情感識別、口音檢測、説話人分析等&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;模&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;態支&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;持&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：系統性支持三種交互配置&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;文本指令 + 音頻輸入（Text-Audio）&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
   &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;音頻指令 + 文本輸入（Audio-Text）&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
   &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;純音頻指令與輸入（Audio-Audio）&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span&gt;&lt;strong&gt;LLaSO-Eval：標準化評估基準&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;樣本規模&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：15,044 個測試樣本&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;數據隔離&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：與訓練集嚴格分離，確保評估公平性&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;評&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;估維&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;度&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：覆蓋所有 20 項任務的 comprehensive evaluation&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;strong style="color:#3daad6"&gt;可復現性&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;：提供統一評估協議和自動化評估工具&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;為驗證框架有效性，邏輯智能團隊基於 LLaSO 數據訓練了 38 億參數的參考模型 LLaSO-Base。&lt;/span&gt;實驗&lt;span&gt;&lt;span&gt;結果表明，LLaSO-Base 以 0.72 的得分在所有參評模型中排名首位，相較於排名第二的 Kimi-Audio (0.65) 和第三位的 Qwen2-Audio (0.57) 展現出明顯的性能優勢。該結果充分驗證了 LLaSO-Base 模型的整體效能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;進一步分析發現，採用多任務訓練範式的模型（如 LLaSO-Base）在綜合評測中的表現明顯優於專門針對特定任務（如 AQA）進行定向優化的模型（例如 Llama-Omni 和 Mini-Omni）。這一現象印證了多樣化任務訓練策略在提升模型泛化能力方面的重要價值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-7f6af77eab1e1f711528bdf0107dbc9009b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372521</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372521</guid>
      <pubDate>Sun, 14 Sep 2025 06:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包超越 DeepSeek，奪 8 月中國原生 AI App 月活第一</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;QuestMobile 最新發布的 2025 年 8 月數據顯示，豆包月活躍用户規模超越 DeepSeek，登頂中國原生 AI App 月活榜首。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 8 月，豆包月活躍用户規模達 15742 萬，環比增長 6.6%，從第二名升至第一名。曾居首位的 DeepSeek，8 月用户規模雖仍處億級，但因-4.0% 的環比增速，排名下滑 1 位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其他選手錶現各異，騰訊元寶以 22.4% 的高環比增速，穩坐第三，月活規模處於 1000 萬-1 億量級。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-8238d5a3fc82af06988bd71a14aa8c12677.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372512</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372512</guid>
      <pubDate>Sun, 14 Sep 2025 06:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Kimi K2 官方高速版 API 開啓限時 5 折特惠</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Kimi K2 官方高速版 API &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwAZcYpDNbn4S8P8HbPNHIw" target="_blank"&gt;宣佈&lt;/a&gt;開啓為期一個月的 5 折特惠。活動有效期為：2025 年 09 月 16 日（含）到 10 月 15 日（含），10 月 16 日 0 時起恢復原價。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="402" src="https://oscimg.oschina.net/oscnet/up-e4a7c820caf6ccd83e90de55faa3eae6d2f.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;kimi-k2-turbo-preview 是 Kimi K2 模型的高速版，模型參數與 kimi-k2-0905 一致，已提升至 256K 上下文。Kimi K2 高速版的輸出速度達 60~100 Token/s，是普通版的 6 倍左右。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，「我們已開啓為期一個月的 5 折特惠，希望每個開發者都有機會體驗到更暢快、快、快、快、快、快的 Coding 體驗。此外，Kimi K2 官方 API 支持自動上下文緩存，可為你節省更多輸入 Tokens。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372503</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372503</guid>
      <pubDate>Sun, 14 Sep 2025 05:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華擎發佈 AI QuickSet WSL，在 Windows 下執行 Linux AI Apps</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;華擎（ASRock）宣佈推出 AI QuickSet 安裝小幫手的第二代版本——&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.asrock.com%2Fmicrosite%2Faiquicksetwsl%2F" target="_blank"&gt;AI QuickSet WSL&lt;/a&gt;，旨在助力用户在 Windows 系統中便捷搭建功能完備的 WSL（適用於 Linux 的 Windows 子系統）環境，並部署一系列基於 Linux 系統的 AI 應用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/120635_w1cS_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;華擎表示，在 Windows 上構建合適的 AI 開發環境，步驟繁瑣且耗時久，而眾多前沿 AI 應用多在 Linux 環境開發運行，這給想在 Windows 使用 Linux AI 應用的初學者帶來挑戰。&lt;/p&gt; 
&lt;p&gt;AI QuickSet WSL 基於 AMD ROCm 平台打造，可自動化整個工作流程，確保 WSL 環境針對華擎 AMD Radeon RX 9000 系列顯卡完成加速預先配置。&lt;/p&gt; 
&lt;p&gt;&lt;img height="563" src="https://static.oschina.net/uploads/space/2025/0916/120650_BBax_2720166.png" width="433" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該工具內置為 ROCm 優化的 PyTorch 等基礎框架，還提供多款「開箱即用」的 AI 應用工具，包含：可根據文字描述生成全新音樂的 Audiocraft、用於圖片與漫畫翻譯的 Image/Manga Translator、可將人像轉換為卡通風格的 PixtoonLab，以及能輕鬆去除或替換影片背景的 Video Background Remover &amp;amp; Changer。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372488</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372488</guid>
      <pubDate>Sun, 14 Sep 2025 04:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>如何秒級實現接口間 「冪等」 補償：一款輕量級仿冪等數據校正處理輔助工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;導語&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;本文分析了在網絡超時場景下，RPC 服務調用數據一致性的問題，對於接口無冪等、接口冪等失效情況下，對異常數據快速處理做了分析思考和嘗試，開發了一款輕量級仿冪等數據校正處理輔助工具。該工具可以 MOCK 或 SPY 服務調用，不限於 RPC 接口，進程內的方法調用也支持，與 JSF、WebService、HTTP 方式無關，只要方法能被代理，就可以使用，寫服務、讀服務均可以支持。目前已在生產環境中使用，在關鍵時刻可以發揮相應的作用。本文工具並不重要，重要的是與大家一起探討一些解決方案，給大家提供一種思路。如果小夥伴有類似訴求，也歡迎大家合適的場景下接入使用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;由來&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最近在參與系統的故障與處理恢復專題，我腦海中衍生了一個關於數據校正處理（或稱之為修數，或數據處理）相關的一個 idea，可以在一些場景下發揮重要作用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本文的重點不是探討故障與處理恢復措施，比如三板斧、三把刀，而是將我腦海中的這個 idea 場景剖開，打算設計和開發一款對應的數據處理提效工具，落地到相應場景中去使用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;場景分析&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在分佈式架構中，應用之間的網絡通信，簡單説存在三種狀態：成功、失敗、超時，簡稱為網絡三態。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;成功：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;請求成功發送並且得到正確的響應。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;失敗：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;請求發送失敗或收到的響應表示操作失敗。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;超時：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;請求在指定時間內沒有收到響應。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//8303165aa49fcad6d9551b93c03d8c49.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//82115900f151a4b78557e00a2dc1c5a5.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對於成功而言，可以正常響應處理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對於失敗而言，可以進行數據回退、重試補償等手段。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對於成功、失敗這兩種狀態而言，結果都是明確的，在分佈式數據一致性處理上也相對比較簡單。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對於超時而言，調用方感知的是超時，服務提供方處理的時間超出預期時間，但服務提供方最終是否執行成功，不得而知。有可能執行失敗，也有可能最終處理成功並落庫，只是未能響應給調用方。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在超時情況下，即使調用方再感知超時後，回退自身數據後，同時嘗試回退服務提供方的數據時，大概率也是回退失敗，因為此時服務提供方尚未執行完成，數據尚未落庫完成。如果説 delay 一段時間後，再去回退服務提供方的數據，倒是可行，但 delay 多長時間，回退多少次才能成功，都不確定，對調用方來説，也增加了複雜性和運維難度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假如服務調用是同一個線程中的本地調用，訪問同一個數據庫實例，則可以直接使用數據庫事務來保障一致性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果是分佈式調用，可以採取分佈式事務措施，例如 2PC、3PC、TCC、Saga 事務等方式來保障一致性，市面上也有成熟的分佈式事務中間件可以使用，例如 Seata 解決方案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;上面説到分佈式事務只是順着話題延伸了一下，本文重點不是探討分佈式事務的解決方案，況且很多京東系統，並沒有接入分佈式事務解決方案，本文重點思考在超時場景下，有沒有一些手段或工具可以幫助快速數據一致性處理、故障恢復。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;思考&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;超時也許是由於網絡抖動，或者服務器負載過高造成的服務超時，也有可能是程序性能不佳造成的持續超時。最終的數據處理和恢復方向，都是要讓數據在應用之間得以流動落地，才能使整個鏈路的流程走下去，即要保障應用間數據的最終一致性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果服務可以降級，則降級是比較快速的一個恢復手段。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果服務不可降級，則通過重試補償等手段來恢復數據的一致性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RPC 服務重試，調用方、服務提供方需要保障接口的冪等性才能保證重試無副作用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;何為冪等性？冪等是一次和多次請求某一個資源對於資源本身應該具有同樣的結果，換言之，其任意多次執行對資源本身所產生的影響均與一次執行的影響相同。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接口的冪等性，需要調用方和服務提供方相互配合才行，倘若服務提供方提供的接口支持冪等性，雙方按照約定接口入參中的 uuid 作為唯一序列號進行防重，但服務提供方每次的重試調用（無論上次調用成功與否）uuid 都會改變，這就會使得冪等失效。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果接口沒有實現冪等性，或者由於調用方每次必變 uuid 導致冪等失效，在這種情況下，該如何快速恢復數據呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//96fab606c22c807f8804977e164de844.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如上圖所示，由於服務超時後，應用 B 內部仍在持續執行，此時恢復手段是：人工介入，梳理數據後，人工將應用 B 的數據進行回退，或者人工將應用 A 的數據進行補齊推動流程向後走，人工保證 A 和 B 之間的數據一致性。倘若應用 A、B 背後的流程比較長，涉及的表關係比較複雜，數據量比較大，這時候人工就難以處理了，也容易出錯，造成二次傷害。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;之前還遇到過一種情況，服務提供方和調用方都支持冪等，但由於一些原因，調用方很久之前的一個異步任務失敗了，而調用方用於冪等防重的數據歸檔了。當時為了支持冪等重試，從歸檔庫里拉回了相應的流水數據到生產庫，才重試調用成功，費力費力，效率低。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;思路&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這裏持續探索無冪等或冪等失效場景下的重試能力建設。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//eea2e1c2d739018b2a4692c00ffca6c7.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在應急處理情況下，向來都是爭分奪秒，這裏可以通過 MOCK 結果返回給調用方 A，相當於「預支成功」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;並非所有的「預支成功」都是合理的，為了讓「預支成功」儘可能合理，需要在服務提供方內部實現裏，做好充分的判斷和校驗，這種判斷和校驗儘量是輕量級的。如果高併發情況下的「預支成功」判斷不合理，事後可以人工介入核對和補償數據。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;建設工具&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對工具的期望&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;由於接口無冪等或冪等失效，需要對能夠預支成功的請求圈定一個範圍，這個範圍要支持配置，最好支持動態配置秒級生效。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對這個範圍內的請求，進行偽冪等，MOCK 特定結果，返回給調用方，使得調用方可以拿到成功結果快速推動流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;•&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;圈定的範圍儘可能具體，儘量避免不該 MOCK 的進行了 MOCK，造成服務調用方的數據沒得到刷新，導致數據的不一致。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在實現中，我稱這個工具為「魔法工具」，是一種「障眼法」，是一種「預先支付成功」，是一種 MOCK 或 SPY，對於調用方 A 來説，是一種體感上的成功，認為調用方真的處理成功了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;配置&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//f2e03fc503b2f2d838b80057d6c11b8c.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在配置中，支持多個配置內容的存在，比如有多個單據需要同時進行偽冪等 MOCK。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//69f902731c7a9a83287f1a210edb6570.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//3fc672168a015ec1f50bef206ee0ba00.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更直觀地，用一個 JSON 數據示例來看一下數據結構：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;{
    "detailList": [
        {
            "enabled": true,
            "className": "com.jdwl.wms.stock.app.service.main.StockTransferAppServiceImpl",
            "methodName": "increaseStock",
            "basicNo1": null,
            "basicNo2": null,
            "basicNo3": "6_6_601",
            "uuidList": null,
            "businessNoList": [
                "GZQ202503160250001"
            ],
            "startTime": "2025-03-16 01:50:00",
            "endTime": "2025-03-18 03:50:00",
            "strategy": "DO_AND_RETURN_SUCCESS_REGARDLESS_OF_FAILURE",
            "defaultResult": {
                "resultValue": true,
                "resultCode": 100000,
                "prompType": 0,
                "success": true
            }
        }
    ]
}

&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;startTime、endTime 時間區間是用來卡控配置生效的時間段，正常情況下配置是短暫生效，起到數據處理的作用後，應去掉該配置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前策略有兩種：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//dc3db9330133021b9fb639b2b1edf3ae.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這兩個策略的區別是要不要真正執行一次接口實現，類似於單測中的 MOCK 和 SPY 效果。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;defaultResult 是該接口方法的期望返回值，配置對應的返回值 JSON，會按照配置的內容直接返回給調用方。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;核心實現&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;圈定範圍的匹配&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//d949d28bdf0bd3de007806517ee3902e.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;按不同策略 MOCK 或 SPY&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//89cf796c6fecdf955888991513be6f24.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_11"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用案例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;案例一 MOCK 服務調用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通過 DUCC 配置圈定要 MOCK 的範圍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//b8ede20be0545441b5fadb54f12268c9.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;{
    "detailList": [
        {
            "enabled": true,
            "className": "com.jdwl.wms.stock.app.service.main.StockTransferAppServiceImpl",
            "methodName": "increaseStock",
            "basicNo1": null,
            "basicNo2": null,
            "basicNo3": "6_6_601",
            "uuidList": null,
            "businessNoList": [
                "GZQ202503160250001"
            ],
            "startTime": "2025-03-16 01:50:00",
            "endTime": "2025-03-18 03:50:00",
            "strategy": "DO_NOTHING_AND_RETURN_SPECIFIED_VALUE",
            "defaultResult": {
                "resultValue": true,
                "resultCode": 100000,
                "prompType": 0,
                "success": true
            }
        }
    ]
}

&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 JSF 平台模擬客户端調用方發起調用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//15d6244f00c5a863ebecaa587a9b3112.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這裏採用的策略是&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DO_NOTHING_AND_RETURN_SPECIFIED_VALUE，即：不執行，直接返回指定的返回值&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;JSF 的返回值就是在上面所配置的返回值內容。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;驗證執行情況&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這裏檢查數據庫落庫情況，看方法是否真地得到執行。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//e5cc32a3b3b2c048d4be47cbef70608b.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;與預期一致，方法被成功 MOCK，未真正執行該方法，返回了預先配置的返回值。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_16"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;案例二，阻隔異常數據生成&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近期生產環境遇到一個場景，逆向盤點時，有個終止盤點的操作，這個操作表示結束盤點，並且未盤點的明細則以少貨缺量的方式提報差異，並預佔庫存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;雖然按鈕有提示，但少概率下會有操作人員不看提示而誤點擊，形成大量的差異庫存預佔。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這些預佔是由於誤點擊形成的差異預佔，並非真實的差異，屬於異常數據，這種數據需要釋放關閉處理，如果數據量較大，現場會找研發團隊協助處理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;異常監控&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;收到監控告警，查看流量情況，發現有突發差異提報流量，短時間內調用量比日常高出很多。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//5b2684833dc51fb34778098887a3e724.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;阻隔配置&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;找到異常倉號和單號，與現場電話對齊後，決定對該異常單進行阻隔攔截，避免產生更多的異常數據。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//dad593a365c62156e7492ab854eccb33.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;{
    "detailList": [
        {
            "enabled": true,
            "className": "com.jdwl.wms.stock.app.service.main.StockExceptionHandleAppServiceImpl",
            "methodName": "recordDifferenceDetail",
            "basicNo1": null,
            "basicNo2": null,
            "basicNo3": "11309_200",
            "uuidList": null,
            "businessNoList": [
                "DPPT1904111957150015488"
            ],
            "startTime": "2025-03-24 19:37:00",
            "endTime": "2025-03-25 00:00:00",
            "strategy": "DO_NOTHING_AND_RETURN_SPECIFIED_VALUE",
            "defaultResult": {
                "resultValue": true,
                "resultCode": 100000,
                "prompType": 0,
                "success": true
            }
        }
    ]
}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;結果核實&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt="" src="https://oscimg.oschina.net/oscnet//8f78246f5db28cba16d7d3e78d7084d2.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:transparent"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通過核實日誌和數據，該工具有效阻隔了部分異常數據的生成，節省了異常數據核對和處理的時間。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_20"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;總結&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本文所提出的一款輕量級仿冪等數據校正處理輔助工具，可以達到 MOCK 或 SPY 的效果。不僅可以用在無冪等或冪等失效場景下，數據庫快速處理恢復的場合，還可以用於一些查詢類、校驗類的讀服務的 MOCK 場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;現階段工具還比較簡單，功能還很有限，使用場景也有針對性和侷限性，希望在一些場景上可以幫助大家。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本文工具並不重要，重要的是與大家一起探討一些解決方案，給大家提供一種思路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本文的解決方案是我短時間內的一個思考和落地嘗試，未必是最優的，希望與大家一起交流更好的方案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_21"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如何接入使用？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果小夥伴也有類似使用訴求，大家可以先在測試、UAT 環境接入試用，然後再逐步推廣線上生產環境。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接入方法也非常簡單，如下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_22"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1、引入 Maven 依賴&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;!-- http://sd.jd.com/article/44544?shareId=105168&amp;amp;isHideShareButton=1 --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;com.jd.sword&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;sword-aspect&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1.0.2-SNAPSHOT&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusions&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;org.projectlombok&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;lombok&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;org.apache.commons&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;commons-lang3&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;org.slf4j&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;slf4j-api&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;org.springframework&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;spring-context&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;org.aspectj&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;aspectjweaver&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;com.alibaba&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;fastjson&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;com.jd.laf.config&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;laf-config-client-jd-spring&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/exclusions&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;com.jd.sword&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;sword-constant&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1.0.0-SNAPSHOT&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;com.jd.sword&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;sword-annotation&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1.0.1-SNAPSHOT&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;

&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#393c5a"&gt;對於其中的間接依賴，例如 lombok 等，大家可以使用自己工程中的已有依賴，在這裏可以通過 exclusion 排掉，如果自己工程中沒有這些依賴，可以不 exclusion。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2、在被攔截方法上打上註解&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;@Magic&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;enabled &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;,&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; basicNo3 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;"#args[0].requestHeader.warehouseNo"&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;,&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; uuid &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;"#args[0].requestHeader.uuid"&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;,&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; businessNo &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;"#args[0].requestHeader.businessNo"&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;

&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;支持&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;SpEL 表達式&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;建議在服務提供方的內部方法實現內，或者調用方在調用目標 API 的防腐層上進行註解。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;服務提供方的內部方法實現內，不一定是放在 API 的 impl 層，也可以是其內部的 Service 層，比如放在冪等防重和輕量級校驗判斷之後，重量級核心邏輯實現之前。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_24"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3、使用時進行按需配置&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DUCC 配置或 Spring yml 配置都可以，更推薦使用 DUCC 動態配置生效。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用完應儘快去掉配置，可以保留空殼，將 detailList 置為空 list。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;示例配置：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;{
    "detailList": [
        {
            "enabled": true,
            "className": "com.jdwl.wms.stock.app.service.main.StockTransferAppServiceImpl",
            "methodName": "increaseStock",
            "basicNo1": null,
            "basicNo2": null,
            "basicNo3": "6_6_601",
            "uuidList": null,
            "businessNoList": [
                "GZQ202503160250001"
            ],
            "startTime": "2025-03-16 01:50:00",
            "endTime": "2025-03-18 03:50:00",
            "strategy": "DO_NOTHING_AND_RETURN_SPECIFIED_VALUE",
            "defaultResult": {
                "resultValue": true,
                "resultCode": 100000,
                "prompType": 0,
                "success": true
            }
        }
    ]
}

&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;或&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;magic:
  content: '{"detailList":[{"enabled":true,"className":"com.jdwl.wms.stock.app.service.main.StockTransferAppServiceImpl","methodName":"increaseStock","basicNo1":null,"basicNo2":null,"basicNo3":"6_6_601","uuidList":null,"businessNoList":["GZQ202503160250"],"startTime":"2025-03-16 01:50:00","endTime":"2025-03-18 03:50:00","strategy":"DO_AND_RETURN_SUCCESS_REGARDLESS_OF_FAILURE","defaultResult":{"resultValue":true,"resultCode":100000,"prompType":0,"success":true}}]}'

&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18691875</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18691875</guid>
      <pubDate>Sun, 14 Sep 2025 03:31:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>谷歌 DeepMind 發佈差分隱私語言模型 VaultGemma</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 DeepMind 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fresearch.google%2Fblog%2Fvaultgemma-the-worlds-most-capable-differentially-private-llm%2F" target="_blank"&gt;推出&lt;/a&gt;了一款名為 VaultGemma 的新型語言模型，專注於保護用户隱私。這是目前規模最大的具備差分隱私能力的開源模型，擁有 10 億參數。&lt;/p&gt; 
&lt;p&gt;大語言模型通常存在一個隱患：它們可能在訓練過程中記住了部分數據，包括姓名、地址甚至完整文檔等敏感信息。而差分隱私技術通過在訓練過程中引入可控的隨機噪聲，有效防止模型將輸出與特定訓練樣本關聯起來。&lt;/p&gt; 
&lt;p&gt;這意味着，即使 VaultGemma 曾接觸過機密文件，從統計上也無法將其內容還原。谷歌表示，初步測試已驗證該模型不會泄露或復現訓練數據。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52b97f4136efa9449fe9e6580c465ed3228.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在架構上，VaultGemma 是基於 Google Gemma 2 架構的僅解碼器 Transformer 模型，具有 26 層並使用多查詢注意力機制。研究人員表示，關鍵設計選擇之一是將序列長度限制為 1024 個 Token，這有助於管理私有訓練的密集計算需求。開發過程由一套新穎的"差分隱私縮放定律"指導，為平衡計算能力、隱私預算和模型效用之間的權衡提供框架。&lt;/p&gt; 
&lt;p&gt;VaultGemma 的性能大致相當於五年前的普通語言模型，在生成能力上略顯保守，但為隱私安全提供了更強保障。&lt;/p&gt; 
&lt;p&gt;谷歌研究人員表示，他們正在 Hugging Face 和 Kaggle 上以開源許可證提供 VaultGemma 及其權重和代碼庫，以普及私有 AI 的訪問。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372471</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372471</guid>
      <pubDate>Sun, 14 Sep 2025 03:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 AI 承包商裁員風波：200 多名員工因工作條件爭議被解僱</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌近期對外包公司 GlobalLogic 的承包商進行了裁員，超過 200 名員工因工薪和工作條件問題被解僱。這一行動引發了員工的不滿和抗議，他們指出長期以來的低薪與惡劣的工作環境，導致這一衝突不斷升級。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這些被裁的承包商主要負責谷歌的 AI 產品的評估和改進工作，包括新推出的 Gemini 聊天機器人及其 AI 概述功能。這些員工通常通過對 AI 生成的內容進行評估和編輯，來提升產品的表現。然而，裁員的發生讓他們感到措手不及，許多人在被告知裁員時並未得到充分的解釋和預警。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="277" src="https://oscimg.oschina.net/oscnet/up-51606cb1d0c07af735b3f9d472e5156aa64.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;其中一位名叫安德魯・勞宗（Andrew Lauzon）的前員工表示，他於 2024 年 3 月加入 GlobalLogic，工作內容包括對 AI 輸出進行評估及模型輸入提示的制定。他對突如其來的裁員感到震驚，並對未來的工作感到不安。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在繼續工作的員工中，許多人也表達了對未來的不確定性。他們擔心公司正在計劃用 AI 自動化評估，從而取代人類的工作崗位。同時，儘管公司在招聘新員工，但卻在減少現有員工的數量。這種情況尤其在德克薩斯州的奧斯汀辦事處尤為明顯，許多員工被要求重返辦公室工作，給那些無法承擔通勤費用或身體狀況不佳的員工帶來了額外壓力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;許多承包商表示，自己的薪水偏低，工作條件也不理想，導致士氣下降。儘管許多員工擁有碩士或博士學位，但他們的薪酬與工作強度和複雜性不成正比。在努力組織工會以爭取更好待遇的過程中，部分員工甚至遭遇了報復，部分員工向國家勞動關係委員會（NLRB）提出了投訴。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌的發言人回應稱，GlobalLogic 及其子承包商負責員工的僱傭和工作條件，谷歌將對供應商進行審核。儘管如此，員工們仍感受到工作環境的壓迫，社交空間受到限制，使得工作壓力加大。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372467</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372467</guid>
      <pubDate>Sun, 14 Sep 2025 03:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥解壓神器——打臉機</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2218</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2218</guid>
      <pubDate>Sun, 14 Sep 2025 02:54:00 GMT</pubDate>
    </item>
    <item>
      <title>瑞士三強聯合發佈開源大模型 Apertus</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;瑞士聯邦理工學院洛桑分校（EPFL）、蘇黎世聯邦理工學院（ETH Zurich）以及瑞士國家&lt;span&gt;超級&lt;/span&gt;計算中心（CSCS）近日聯合發佈了一個名為 「Apertus」 的大規模開源語言模型，該模型的名字在拉丁語中意為 「開放」。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-1bf6c0c62764859dbeda7ab7e4f4c0cb194.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;與當前市場上如 OpenAI 的 GPT 系列、Meta 的 Llama 和 Anthropic 的 Claude 等美國大型模型相比，Apertus 不僅注重技術本身，更以其透明度贏得了廣泛的關注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這款模型的所有內容，包括模型權重、架構設計、訓練代碼以及數據來源等，全部實現了公開，甚至連訓練過程的完整文檔也毫無保留。這種 「開放」 策略讓 Apertus 成為了一個值得期待的新選擇。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在這個 AI 快速發展的時代，「數據黑箱」 的現象依然普遍存在。許多大型科技公司在發佈他們的模型時，往往對外界隱瞞了大量關鍵細節，導致了行業的不信任感。而 Apertus 則打破了這一常規，力求通過開源的方式來促進技術的共享與合作。研究人員和開發者們可以在此基礎上進行創新與改進，推動整個行業的進步。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這項研究的團隊表示，Apertus 的推出不僅旨在為研究提供便利，更希望激勵全球的 AI 研究者和開發者共同參與到開源生態中來。通過這種方式，Apertus 希望能夠降低 AI 技術的門檻，讓更多的人能夠參與到 AI 的開發和應用中，從而加速科技進步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372461</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372461</guid>
      <pubDate>Sun, 14 Sep 2025 02:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里 AI 編程工具 Qoder 正式推出付費訂閲計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里巴巴旗下 AI 編程工具 Qoder 宣佈正式面向全球用户推出付費訂閲計劃，Pro 版每月 20 美元（現匯率約合 142.4 元人民幣），Pro + 版本 60 美元（現匯率約合 427.3 元人民幣）。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1080" src="https://static.oschina.net/uploads/space/2025/0916/104047_7oG4_2720166.jpg" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="587" src="https://static.oschina.net/uploads/space/2025/0916/104059_8jyB_2720166.png" width="1809" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pro 版權益&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;無限代碼補全和 Next Edits&lt;/strong&gt;：智能補全代碼，預測下一步操作，讓編程更加輕鬆高效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;2,000 Credits&lt;/strong&gt;：靈活調用全球最先進的高級模型，滿足日常開發需求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Quest Mode&lt;/strong&gt;：Spec 驅動的委派編程模式，多任務異步執行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Repo Wiki&lt;/strong&gt;：代碼倉庫的知識顯性化，支持共享和導出。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Pro+ 版權益&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;無限代碼補全和 Next Edits&lt;/strong&gt;：智能補全代碼，預測下一步操作，讓編程更加輕鬆高效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;6,000 Credits&lt;/strong&gt;：靈活調用全球最先進的高級模型，滿足日常開發需求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Quest Mode&lt;/strong&gt;：Spec 驅動的委派編程模式，多任務異步執行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Repo Wiki&lt;/strong&gt;：代碼倉庫的知識顯性化，支持共享和導出。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，Qoder 新用户限時 2 周免費試用，暢享超值權益：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;1,000 Credits 用於高級模型&lt;/li&gt; 
 &lt;li&gt;無限代碼補全和 Next Edits&lt;/li&gt; 
 &lt;li&gt;Quest Mode&lt;/li&gt; 
 &lt;li&gt;Repo Wiki&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;訂閲頁面：https://qoder.com/pricing&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372459</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372459</guid>
      <pubDate>Sun, 14 Sep 2025 02:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2025 年 Python 現狀：83% 仍在運行舊版，Python Web 開發復興</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;第八屆年度 Python 開發者調查現已發佈，基於全球 30,000 多名 Python 開發者的調查回覆。 本次調查由 Python Software Foundation 和 JetBrains 的 PyCharm 團隊合作開展。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;2025 年 Python 現狀（速通版）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;50% 的 Python 開發者擁有不到 2 年的專業經驗&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;51% 使用 Python 進行數據探索和處理&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;46% 使用 Python 進行 Web 開發&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;FastAPI 的使用率在一年內從 29% 增長到 38%&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;83% 仍在運行舊版 Python&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;三分之一為開源軟件做出貢獻：&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;78% 編寫代碼&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;40% 編寫文檔&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;Web 服務器正在轉向異步和基於 Rust 的工具&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;Python 的發展方向&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;69% 計劃嘗試 AI 編碼智能體。 智能體化 AI 的採用將快速增長&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;並行線程處理即將在 Python 3.14 中推出。 異步、等待和線程處理至關重要&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;GUI 和移動開發正在蓬勃發展&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;2025 年的可行想法&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;嘗試智能體化 AI 提高工作效率&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;學習 uv 實現更快的軟件包管理&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style="color:#000000"&gt;使內容和工具適合初學者&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查顯示，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;86% 的受訪者使用 Python 作為編寫計算機程序、構建應用程序、創建 API 等任務的主要語言&lt;/strong&gt;。有 50% 的受訪者擁有不到兩年的專業編碼經驗， 39% 使用 Python 的經驗不足兩年（即使算上業餘愛好或教育環境）。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「這一結果再次證明，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;Python 是職業生涯初期人士的理想語言。&lt;/strong&gt;&amp;nbsp;簡潔（但不過分簡單）的語法和易於上手的特性既能吸引新人程序員，同時也受到資深程序員的青睞。&amp;nbsp;」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;51% 的受訪 Python 開發者參與數據探索和處理，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;主要使用 pandas 和 NumPy。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;就 Python 運行時最新版和舊版的分佈情況而言。 僅 15% 使用了最新發布的 Python 版本，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;83% 使用的是一年前或更早的版本&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-43a5221be3c2e39a0076f78b41c3f631617.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;至於為什麼還有人沒更新到最新版本的 Python？ 調查結果給出了兩個主要原因。&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;我正在使用的版本能滿足我的所有需求 (53%)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;我沒有時間更新 (25%)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Python Web 開發的復興&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在受訪者中，2024 年有 46% 使用 Python 進行 Web 開發。 Web「次要」語言也相應增加，HTML/CSS 的使用率提升了 15%，JavaScript 的使用率提升了 14%，SQL 的使用率提升了 16%。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="414" src="https://oscimg.oschina.net/oscnet/up-08a0a5b4d4855ae14af103eccb281c3da40.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Python Web 框架中最大的贏家是 FastAPI，其使用率從 29% 躍升至 38%（增加了 30%）。 雖然所有主要框架都實現了同比增長，但 FastAPI 近 30% 的增長率格外引人注目。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Python 在 Web 領域的飛躍可能部分歸因於大量新人湧入 Python 領域。 其中許多人從事 ML/AI/數據科學方面的工作，這些人通常沒有多年使用 Flask 或 Django 的經驗。 他們很可能會選擇最熱門的 Python Web 框架，而目前看來，這個框架就是 FastAPI。 人們在 FastAPI API 後面託管 ML 模型的例子有很多。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="429" src="https://oscimg.oschina.net/oscnet/up-360dbbd45783ffdaabab6bfa03671abefa6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Rust 是現在加快 Python 的方式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;過去幾年，Rust 已經成為 Python 的性能伴侶。 2025 年 Python Language Summit&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpyfound.blogspot.com%2F2025%2F06%2Fpython-language-summit-2025-what-do-core-developers-want-from-rust.html" target="_blank"&gt;&lt;span style="color:#000000"&gt;顯示&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;，「在新項目上傳到 PyPI 的所有原生代碼中，大約有四分之一到三分之一使用了 Rust」，這表明「人們正在選擇使用 Rust 啓動新項目」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從調查結果來看，發現在 Python 軟件包的二進制擴展程序中，Rust 的使用率從 27% 增長到 33%。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="404" src="https://oscimg.oschina.net/oscnet/up-a25cd836d105d604d538f847ab5c6429bac.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Postgres 是 Python 開發者的數據庫之王&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在被問及選擇哪種（哪些）數據庫（如果有）時，絕大多數受訪者都回答了 PostgreSQL。&amp;nbsp;&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;PostgreSQL 是 Python 數據庫之王，而且佔比還在增長，&lt;/strong&gt;從 43% 提升至 49%。 與去年同期相比增長了 14%，對於一個已有 28 年曆史的開源項目來説，這是個了不起的成績。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="368" src="https://oscimg.oschina.net/oscnet/up-64c78c70a781da0baa3aedb16cb8225c5eb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得注意的是，除了 Postgres 被大量使用之外，排名前六的數據庫的使用率都實現了同比增長。 如前文所述，這很可能是 Web 開發本身再次增長的另一個跡象。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能體化 AI 將帶來顛覆性變革&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;PSF 調查之外的調查顯示，2023 年約 70% 的開發者使用或計劃使用 AI 編碼工具，到 2024 年，約 44% 的專業開發者每天都會使用這些工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;JetBrains 的《2023 開發者生態系統現狀》報告指出，在幾年內，「基於 AI 的代碼生成工具從有趣的研究發展成為許多開發者工具箱的重要組成部分」。到 2025 年，根據《2025 開發者生態系統現狀》調查，&lt;strong&gt;近一半的受訪者 (49%) 計劃在未來一年內嘗試 AI 編碼智能體&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;各大科技公司的程序經理表示，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;他們幾乎無法僱用不接受智能體化 AI 的開發者。&lt;/strong&gt;&amp;nbsp;使用 AI 和不使用 AI 之間的效率差距實在太大了（估計使用 AI 後效率會提高約 30%）。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fpycharm%2F2025%2F09%2Fthe-state-of-python-2025%2F" target="_blank"&gt;查看完整報告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372458/the-state-of-python-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372458/the-state-of-python-2025</guid>
      <pubDate>Sun, 14 Sep 2025 02:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥簡單手搓一個智能門禁攝像頭</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2212</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2212</guid>
      <pubDate>Sun, 14 Sep 2025 02:34:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 發佈新編程模型 GPT‑5‑Codex，優化 Agentic Coding 能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 今日凌晨推出全新升級的新模型&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-upgrades-to-codex%2F" target="_blank"&gt; GPT‑5‑Codex&lt;/a&gt;，這是其在 GPT-5 基礎上專門為軟件工程優化的模型版本，進一步提升了 Codex 中的智能體編程（Agentic Coding）能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/103044_nL9C_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方表示，該版本在代碼審查、功能開發、大規模重構等場景中表現顯著提升，並且「在測試中可連續獨立工作超過 7 小時」。以下是本次升級的主要亮點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;工具全面升級：Codex CLI 全面重新設計，IDE 插件支持 VS Code 等主流環境，與 GitHub 深度集成雲端與本地環境可無縫切換；&lt;/li&gt; 
 &lt;li&gt;代碼審查能力強化：自動在 PR 中發現關鍵漏洞，減少無效評論，並可直接提出並實現修改建議。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/103155_65FN_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，GPT‑5‑Codex 已成為 Codex 雲端任務與代碼審查的默認模型，開發者也可通過 Codex CLI 或 IDE 插件在本地使用。與通用版 GPT‑5 相比，新版本在代碼重構任務的準確率從 33.9% 提升至 51.3%，高影響力審查評論比例也從 39.4% 提升至 52.4%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/103208_f98s_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/103232_QvKk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，Codex CLI 與 IDE 插件同步升級，支持在終端直接附加截圖、線框圖等設計資料，並可在雲端自動搭建運行環境、執行依賴安裝。官方稱，通過緩存容器等優化，雲端任務完成時間中位數縮短了 90%。&lt;/p&gt; 
&lt;p&gt;目前，Codex 已整合至 ChatGPT Plus、Pro、Business、Edu 與 Enterprise 計劃中，企業用户可按需購買額外額度，API 接入版本也將很快上線。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372453</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372453</guid>
      <pubDate>Sun, 14 Sep 2025 02:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技發佈開源世界模型-動作架構：UnifoLM-WMA-0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;宇樹科技正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkrQOGN9hqM0Nye9KfHpThw" target="_blank"&gt;推出&lt;/a&gt;跨多類機器人本體的開源世界模型-動作（WMA）架構 —— UnifoLM-WMA-0。該架構旨在為通用機器人學習提供統一的技術基礎，核心在於一個能夠理解機器人與環境交互物理規律的世界模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0916/102333_wzUL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該世界模型具備兩大核心功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;仿真引擎：作為交互式仿真器運行，為機器人學習生成合成數據。&lt;/li&gt; 
 &lt;li&gt;策略增強：可與動作頭對接，通過預測未來與物理世界的交互過程，優化決策性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模型接收圖像及文本指令，生成與文本指令對應的未來動作視頻。&lt;/p&gt; 
&lt;p&gt;官方介紹，UnifoLM-WMA-0 支持兩種運行模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;決策模式：提供機器人與環境物理交互的預測信息，輔助策略生成動作。&lt;/li&gt; 
 &lt;li&gt;仿真模式：基於機器人動作生成高保真環境反饋。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在訓練方面，團隊基於 5 個宇樹科技開源數據集完成模型訓練，測試結果顯示，該模型可根據「當前圖像」及一定數量的「機器人未來動作」實現交互可控生成，並具備長程任務的持續交互生成能力。&lt;/p&gt; 
&lt;p&gt;項目主頁：https://unigen-x.github.io/unifolm-world-model-action.github.io/&lt;br&gt; 開源代碼網址：https://github.com/unitreerobotics/unifolm-world-model-action&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372450/unitreerobotics-unifolm-world-model-action</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372450/unitreerobotics-unifolm-world-model-action</guid>
      <pubDate>Sun, 14 Sep 2025 02:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 重組機器人團隊劍指「通用機器人」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 正在重返機器人研究領域，這標誌着該公司在中斷五年之後，重新將物理人工智能（AI）作為其核心關注點。《連線》雜誌報道稱，OpenAI 正在招聘專門從事人形機器人研究的人員，旨在通過遠程操作和模擬訓練，打造能夠執行通用任務的機器人。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-f9e16bedff73205d06dc93e1f2c899f753c.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據招聘信息，新成立的團隊將專注於傳感和原型設計，其&lt;span&gt;終極&lt;/span&gt;使命是創造「通用機器人，以加速通用人工智能（AGI）的實現。雖然該公司尚未正式確認該項目是否針對人形機器人，但種種跡象表明，其研究方向確實與類人系統緊密相關。新加入的團隊成員包括斯坦福大學研究員李成書 (Chen-Shu Lee)，他曾專注於類人家用機器人的基準測試，進一步印證了這一推測。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;早在 2020 年，OpenAI 曾因訓練數據不足而暫停其機器人研究工作。然而，該公司於今年 1 月再次發佈了多個機器人相關的職位，這表明隨着技術和數據的積累，OpenAI 已準備好重啓這一重要項目，繼續探索物理世界中的 AI 應用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372449</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372449</guid>
      <pubDate>Sun, 14 Sep 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>網安周開幕｜綠盟大模型能力再獲權威肯定，持續推動 AI 與網絡安全深度融合</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" height="177" src="https://oscimg.oschina.net/oscnet//00adc33f8c5022b4075b940514844e44.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;9 月 15 日，2025 年國家網絡安全宣傳週的開幕式及一系列重要活動在雲南昆明舉辦。其中，開幕式現場，12387 網絡安全事件報告平台正式啓動。綠盟科技集團黨委書記、董事長兼總裁胡忠華，集團董事、首席技術官、高級副總裁葉曉虎，副總裁陳珂，總裁助理張銘等受邀出席相關活動。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;在網絡安全技術高峯論壇上，國家計算機網絡應急技術處理協調中心發佈了 2025 年人工智能技術賦能網絡安全應用測試結果。&lt;strong&gt;綠盟科技在基於智能體的網絡安全自動化分析響應場景中表現突出，榮獲賽道第二名，並在大模型生成內容安全風險檢測中位列第五&lt;/strong&gt;。這也是繼 2024 年在相關賽道測試中取得優異表現後，公司大模型能力再次在權威測試中得到認可。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet//b6e681bb078c9e2344e4618963a38515.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;該場景要求參測團隊利用 AI 智能體檢測釣魚郵件、終端異常行為、DNS 隱蔽隧道異常行為，並通過跨域日誌（郵件、終端、DNS）進行關聯分析，識別出完整攻擊鏈，並提出處置方案。綜合指標包括檢測與關聯分析的準確率、漏報率及處置正確性。綠盟科技憑藉智能體驅動的自動化分析與響應能力，實現了從「檢測—分析—研判—處置」的智能化閉環，能夠精準識別複雜攻擊鏈並生成可執行的處置建議，充分展示了公司在智能化安全運營方向的積累。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;深耕「AI+安全」，持續打造大模型能力&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;綠盟科技始終把人工智能作為推動安全能力躍升的重要引擎。2023 年，公司發佈了風雲衞 AI 安全能力平台，率先構建安全垂直領域的大模型體系。該平台融合大模型、小模型與安全知識圖譜，將 AI 能力「原子化」嵌入安全運營體系，覆蓋安全數據分析、威脅情報研判、攻擊鏈追蹤與處置響應等關鍵環節，並已在政府、金融、能源、運營商、科教文衞等重點行業落地應用。平台已通過國家網信辦算法模型雙備案，同時入選世界人工智能大會《2024 大模型典型示範應用案例集》，並通過工信部信通院 AI 安全能力評估。此次在國家網絡安全宣傳週測試中獲獎，既是對風雲衞在智能體應用上的又一次檢驗，也進一步印證了公司在「AI+安全」方向的技術路線和產品實踐的成熟度。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;聚焦技術攻堅，持續拓展應用場景&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;大模型和智能體的快速發展正在改變攻防模式。綠盟科技面向衞星通信、無人機、車聯網、AI 攻防等新興場景持續研發，2025 年發佈十餘款新品，並推出大模型安全治理方案、場景化安全方案、備案評估與紅隊服務等，全面守護用户智能化轉型的可信與安全。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;同時，公司不斷推動傳統產品融入 AI 能力，逐步向智能體方向演進，在安全運營、數據安全、供應鏈安全等場景全面提升能力，讓智能化成為網絡安全建設的堅實底座。面對複雜多變的應用環境，綠盟科技積極推動行業協同與能力互通，適配多種國產化硬件與操作系統，強化與產業鏈上下游合作，確保 AI 安全能力具備彈性、兼容性和可擴展性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;近日，國務院印發的《關於深入實施「人工智能+」行動的意見》，對人工智能應用安全治理和潛在風險防控提出了更高要求，不僅回應了人工智能快速演進帶來的安全挑戰，也為行業高質量發展明確了方向。綠盟科技將繼續以自主創新為根本，以產業需求為導向，深化人工智能與安全場景結合，服務國家重大任務，支撐產業數字化轉型，推動構建更加智能化、主動化的網絡安全體系，為數字經濟的繁榮發展貢獻力量。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372445</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372445</guid>
      <pubDate>Sun, 14 Sep 2025 02:05:00 GMT</pubDate>
      <author>作者: 開源科技</author>
    </item>
  </channel>
</rss>
