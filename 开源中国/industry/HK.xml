<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 10 Jun 2025 12:41:24 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>微軟開始測試 Windows 11 的新版「開始」菜單</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟現在&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F06%2F09%2Fannouncing-windows-11-insider-preview-build-26200-5641-dev-channel%2F" target="_blank"&gt;允許&lt;/a&gt;&lt;/u&gt; Windows 11 測試人員試用全新、更大的「開始」菜單，該菜單包含可滾動的界面、新的視圖和更多可自定義功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-133f02d0def812a3023b1918667ec4cbb4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows Insider 團隊解釋説：「我們更新了可滾動的「開始」菜單，讓您可以更輕鬆地啓動應用。」 這個可滾動的「開始」菜單意味着所有應用現在都位於頂層，因此您無需導航到第二個頁面即可找到應用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95c628f3783c80a5c0be69c6167b9d9f144.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更新後的「開始」菜單有兩個新視圖可供選擇&lt;/p&gt; 
&lt;p&gt;您還可以禁用推薦部分，以便查看更多應用，並選擇兩種新視圖：類別視圖和網格視圖。默認類別視圖按類別對應用進行分組，而網格視圖則按字母順序排列，更像傳統的列表視圖。&lt;/p&gt; 
&lt;p&gt;微軟還根據設備或顯示器的屏幕尺寸放大了「開始」菜單。Windows Insider 團隊表示：「在較大的設備上，用户可以在「開始」菜單中看到 8 列固定應用、6 條推薦和 4 列類別。在較小的設備上，你將看到 6 列固定應用、4 條推薦和 3 列類別。」&lt;/p&gt; 
&lt;p&gt;開始菜單上還新增了一個移動設備按鈕，可用於展開或摺疊與開始菜單一起顯示的「Phone Link」界面。微軟還允許 Windows 11 用户選擇顯示哪些鎖屏小部件，允許添加或刪除小部件，並重新排列它們以適應鎖屏。&lt;/p&gt; 
&lt;p&gt;最後，最新的 Dev Channel 版本還包含一個新的 Gamepad 鍵盤更新，可讓您使用控制器通過 PIN 碼登錄 PC。這是微軟改進 Windows 11 在手持遊戲設備（例如最近發佈的 ROG Xbox Ally 設備）上的運行效果的一部分。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</guid>
      <pubDate>Sun, 11 May 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美團發佈 AI Coding Agent 工具「NoCode」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;美團&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FdByPiajMM7fX109GSotLVQ" target="_blank"&gt;上線&lt;/a&gt;了名為「NoCode」的&amp;nbsp;&lt;/span&gt;AI Coding Agent 工具&lt;span&gt;，用户通過自然語言對話即可生成網頁、小程序等應用，並支持實時修改、一鍵部署。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;NoCode 是一款無需編程背景和經驗，通過自然語言和對話形式，即可快速生成應用的平台。可幫助不同角色以"零代碼"的方式創建個人提效工具、產品原型、可交互頁面等，降低開發門檻，實現創意釋放。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;NoCode&lt;/span&gt;功能亮點&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自然語言編程&lt;/strong&gt;：使用自然語言描述想法，NoCode 自動解讀並轉化為完整功能，無需編程經驗即可生成可用能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;實時預覽效果&lt;/strong&gt;：根據對話內容即時渲染、呈現頁面，可實時查看每次對話後的實際效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;局部定位修改&lt;/strong&gt;：使用 Visual Edit 功能，可針對定位內容進行局部修改及完善；同時支持版本間對比、回退，保障每一步都「有跡可循」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;一鍵部署分享&lt;/strong&gt;：應用完成後，代碼將自動上傳到倉庫，可直接分享鏈接給他人使用，簡化發佈流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0610/184826_5IfE_2720166.png" width="750" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;體驗地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnocode.cn%2F" target="_blank"&gt;https://nocode.cn/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354675/meituan-nocode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354675/meituan-nocode</guid>
      <pubDate>Sun, 11 May 2025 10:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>法國 AI 初創公司 Mistral 將發佈推理模型 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F06%2F10%2Fmicrosoft-backed-ai-lab-mistral-debuts-reasoning-model-to-rival-openai.html" target="_blank"&gt;根據 CNBC 的報道&lt;/a&gt;，法國 AI 初創公司 Mistral 將推出其首個推理模型 Magistral，加入與 OpenAI、DeepSeek 等全球領先企業的競爭。&lt;/p&gt; 
&lt;p&gt;&lt;img height="898" src="https://static.oschina.net/uploads/space/2025/0610/183614_pyVq_2720166.png" width="2104" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mistral 首席執行官亞瑟・門施介紹道，Magistral 不僅擅長數學和編碼，還能夠實現歐洲語言的邏輯推理，突破了美國和中國模型的語言侷限性。&lt;/p&gt; 
&lt;p&gt;今年 3 月，Mistral 已發佈 240 億參數的 Mistral Small 3.1 模型，該模型以低成本實現本地運行，部分性能甚至超越 OpenAI 的 GPT-4o mini。5 月，Mistral 進一步推出了 Medium 3 模型，這款中量級模型在保持前沿性能的同時，顯著降低了企業使用成本，每百萬 Token 輸入僅需 0.4 美元。&lt;/p&gt; 
&lt;p&gt;Mistral 通過技術創新，正逐步提升其在全球 AI 市場的競爭力，併為多語言應用場景提供更優解決方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</guid>
      <pubDate>Sun, 11 May 2025 10:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度網盤、文庫聯合發佈「AI 相機」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;6 月 10 日，在百度 AI Day 開放日上，百度網盤、文庫聯合發佈行業首個「拍存管一體」的「AI 相機」，具備全模態輸入、處理、輸出的系統化完整交付 AI 能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-acb055f53ca9b3a5f087e132e834b1d7f25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 相機已在百度網盤 App 上線，並已接入百度文庫 App。百度文庫還宣佈多智能體協作能力「GenFlow 超能搭子」全新升級為 2.0 版本，使其成為率先實現全場景滿足、全鏈路覆蓋的多智能體協作應用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/183107_JyHR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GenFlow 超能搭子 2.0 依託於文庫、網盤海量的公私域數據和用户記憶庫，可完整交付更懂用户的個性化內容；它可以自主調用各種模型和工具，一次性並行生成多模態、多格式內容；它還支持後鏈路的編輯環節，在內容創作上靈活度更高。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354672</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354672</guid>
      <pubDate>Sun, 11 May 2025 10:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 時代的「數據之困」，什麼是 AI-Ready Data</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;人工智能（AI）無疑是當今科技領域最激動人心的變革力量，它橫跨各個行業，展現出重塑未來的巨大潛力。從智能客服到精準醫療，從自動駕駛到個性化推薦，AI 的觸角幾乎無所不至。然而，在這股 AI 浪潮之下，一個普遍的困境也日益凸顯：許多雄心勃勃的 AI 項目在起步後便步履維艱，難以實現預期的投資回報，甚至大量試點項目最終未能成功轉化為生產力。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;這種「雷聲大，雨點小」的現象，不禁讓人深思：&lt;strong&gt;AI 的理想與現實之間，究竟橫亙着怎樣的鴻溝？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;追根溯源，這一困境的核心往往直指 AI 的「食糧」——數據。數據是驅動 AI 系統洞察、預測和決策的燃料。然而，企業在將數據應用於 AI 時，普遍面臨着一系列嚴峻挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;數據質量參差不齊&lt;/strong&gt;：不準確、不完整、標籤錯誤或充滿噪聲的數據是 AI 項目失敗的常見元兇。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E5%25AD%25A4%25E5%25B2%259B%26zhida_source%3Dentity" target="_blank"&gt;數據孤島&lt;/a&gt;&lt;/span&gt;與集成難題&lt;/strong&gt;：數據往往散落在企業內部各個孤立的系統中，格式各異，難以有效整合和統一訪問。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;缺乏標準化與有效治理&lt;/strong&gt;：數據格式不統一、元數據缺失、數據血緣關係不清晰以及&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E6%25B2%25BB%25E7%2590%2586%26zhida_source%3Dentity" target="_blank"&gt;數據治理&lt;/a&gt;&lt;/span&gt;機制的薄弱，都為 AI 應用埋下了隱患。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;這些普遍存在的數據問題，實際上反映了許多企業在 AI 戰略上的一個深層錯位：即，&lt;strong&gt;對 AI 技術本身抱有極高期望，卻忽視了構建堅實數據基礎的重要性&lt;/strong&gt;。企業紛紛投入巨資採購先進的 AI 工具和算法，但如果供給這些「智能引擎」的是劣質「燃料」，那麼再強大的算法也難以發揮其應有的效能。AI 的雄心壯志與薄弱的數據能力之間形成的巨大反差，正是導致眾多 AI 項目折戟的關鍵。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;面對 AI 時代的「數據之困」，企業迫切需要一種能夠有效解決上述問題、真正釋放 AI 潛能的數據形態。於是，「AI-ready Data」 的概念應運而生。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;什麼是 AI-ready Data？為何如此重要？&lt;/strong&gt;&lt;/h2&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//be5fce4d40a25157514e64dbd6664171.jpg" width="1024" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data：超越數據的「數據」&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data，顧名思義，是指那些經過精心準備、結構化處理和嚴格驗證，能夠以最佳效能服務於人工智能應用的數據。這類數據使得 AI 算法能夠高效地學習模式、做出準確預測並生成有價值的洞察。它強調的不僅僅是擁有海量數據，更在於數據的質量、結構和相關性，確保數據能夠被 AI 算法高效處理和分析。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;打個比方，如果説 AI 是一個高性能引擎，那麼 AI-ready Data 就是為其量身定製的、經過提純的高辛烷值燃料，確保引擎能夠以巔峯狀態持續運轉。它不是原始、未經雕琢的「數據礦石」，而是經過精煉、可以直接投入 AI「熔爐」的「高品位原料」。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data 不可或缺的價值&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 之所以關鍵，在於它能為 AI 的成功應用帶來一系列實實在在的好處。高質量、準備充分的數據是訓練出高精度、高可靠性 AI 模型的基礎，直接決定了模型的準確性和有效性，正所謂「Garbage in, Garbage out」。通過大幅減少數據科學家在數據清洗和整理上耗費的巨量時間，AI-ready Data 能夠顯著加速 AI 項目的落地進程，使團隊更專注於模型創新與優化。它是構建穩健、可擴展 AI 系統，使其能處理複雜任務並大規模有效運作的基石，最終通過驅動更明智決策、提升運營效率、降低成本和增強市場競爭力，為企業創造切實的商業價值。同時，清晰、可溯源且管理良好的數據還有助於企業遵守日益嚴格的數據法規與 AI 倫理規範，為 AI 系統的透明度和問責制提供保障。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;理解 AI-ready Data 的價值，更要認識到它並非一勞永逸的靜態目標，而是一個持續演進的動態過程，需要隨 AI 發展、業務變化及法規更新不斷調整優化，其及時性、可擴展性和定期刷新的需求都印證了這是一項長期投入。追求 AI-ready Data 的本質，是將數據管理從單純的「收集」提升到戰略性的「策展」與「價值創造」層面，要求企業帶着明確的 AI 應用目標有意識地準備數據，使數據管理從後端支持轉變為驅動創新的核心環節。更深遠地看，實現數據 AI 就緒的努力將催化組織在數據治理、數據素養和跨部門協作等方面的全面成熟，打破數據孤島，提升整體數據能力，從而孕育出惠及企業全局的數據驅動文化，這其中，人的因素和流程優化與技術平台同等重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;不同領域的 AI-ready Data 特徵上有什麼區別？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;儘管 AI-ready Data 的核心原則具有普適性，但在不同的 AI 細分領域，其具體的形態、準備的側重點以及在模型訓練和推理階段的要求，都會呈現出顯著的差異。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;機器學習中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;傳統的機器學習是許多企業 AI 應用的起點，其對數據的要求相對成熟和明確。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：ML 模型的數據通常是結構化的表格數據，例如 CSV 文件或數據庫中的表，其中每一行代表一個樣本，每一列代表一個特徵。對於監督學習任務，數據中還會包含一個目標列或標籤列，用以指示模型需要預測的結果 。雖然 ML 也可以處理文本、圖像等非結構化數據，但這往往需要通過複雜的特徵工程將其轉換為結構化的數值特徵，才能被傳統 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：ML 模型的數據通常是結構化的表格數據，例如 CSV 文件或數據庫中的表，其中每一行代表一個樣本，每一列代表一個特徵。對於監督學習任務，數據中還會包含一個目標列或標籤列，用以指示模型需要預測的結果 。雖然 ML 也可以處理文本、圖像等非結構化數據，但這往往需要通過複雜的特徵工程將其轉換為結構化的數值特徵，才能被傳統 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：用於預測客户流失的數據集，可能包含客户的人口統計信息、消費行為、服務使用頻率等特徵；用於垃圾郵件檢測的已標註郵件數據集。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//3911ebe7c46166407d1fad003e28b19d.jpg" width="600" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;深度學習中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;深度學習以其處理複雜模式和大規模數據的能力，在圖像識別、自然語言處理等領域取得了革命性進展，其對數據的需求也更為「貪婪」。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：深度學習模型的訓練通常依賴於大規模的非結構化以及多模態數據，如圖像、音頻、文本和視頻。這些數據往往需要進行大量且精準的標註，例如物體檢測任務中的邊界框、圖像分割的掩碼、語音識別的文本轉錄等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：數據的「量」和「多樣性」是深度學習成功的關鍵。同時，標註的一致性和準確性對模型性能至關重要，高質量的數據集是實現準確語音識別等任務的基礎。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：著名的 ImageNet 數據集包含數百萬張標註圖像；LibriSpeech 數據集包含數千小時的轉錄音頻；維基百科的文本轉儲等大型文本語料庫。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//22383fbb9f6e44994f6c4a867cb18fce.jpg" width="700" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E7%2594%259F%25E6%2588%2590%25E5%25BC%258FAI%26zhida_source%3Dentity" target="_blank"&gt;生成式 AI&lt;/a&gt;&lt;/span&gt;與 RAG 系統中的 AI-Ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;具體到生成式 AI 領域，其對 AI-ready data 的需求首先體現在模型預訓練和微調階段。基礎模型的構建依賴於規模宏大、內容多樣甚至多模態的數據集，涵蓋了從公開網頁文本、專業書籍到代碼、圖像和音視頻等廣泛來源。而模型的微調則更側重於特定領域內高質量、高相關性的專業數據集。貫穿始終的是對數據合規性、版權以及潛在偏見的嚴格審視與倫理考量，負責任的數據策略是實現 AI 價值的前提。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在眾多生成式 AI 應用中，檢索增強生成（RAG）架構尤為依賴 AI-ready data 的精細化準備。RAG 通過引入外部知識源來提升模型輸出的準確性、時效性和深度，其核心挑戰在於如何將這些外部知識高效、準確地「喂」給 LLM。這一過程的關鍵瓶頸與優化焦點在於數據切片（Chunking）。當前主流的數據切片方法往往顯得「粗糙」。許多系統簡單地採用固定字符數、按句子或段落等規則進行切分，這種方式極易破壞文本原有的語義完整性，可能導致一個完整的邏輯思路或上下文聯繫在切分中斷裂，進而影響大模型對信息的準確理解和答案生成的質量。同時，這些簡單方法常常忽略文檔的內在結構，如章節、標題、列表和表格等，而這些結構本身就承載着重要的語義信息。面對不同類型（如法律合同、技術手冊、研究論文或代碼）和複雜格式的文檔，通用的「一刀切」切片策略往往難以達到理想效果。切片的大小也需精妙平衡：過小則可能上下文不足，難以支撐複雜問答；過大則可能引入過多噪聲，稀釋關鍵信息。此外，多數在數據預處理階段完成的靜態切片，也缺乏對用户動態查詢意圖的靈活適應性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;因此，理想的 RAG 數據切片策略應向更智能化、語義驅動的方向演進。其核心目標是&lt;strong&gt;最大程度地保持語義單元的完整性&lt;/strong&gt;，切分點應儘可能選在自然的語義邊界。同時，要充分感知並利用文檔的固有結構信息，如將標題及其對應內容作為一個單元，或整體處理表格及其註釋。為了保持切分後各知識塊之間的上下文連貫，可以採用重疊切片技術，或構建具有內在聯繫的層級式塊結構，並通過元數據明確記錄它們之間的邏輯關係。針對不同內容特性，應採用內容自適應的切片邏輯。至關重要的是，每個切分後的數據塊都應附帶豐富的元數據，如原始文檔出處、章節信息、主題標籤等，這些元數據不僅能提升檢索的精確度，還能為大模型提供更全面的背景知識，從而增強其輸出內容的可信度和可溯源性。&lt;/p&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f2fb964dde666532d21ce8a16e7310fe.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DPhysical%2BAI%26zhida_source%3Dentity" target="_blank"&gt;Physical AI&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Physicla AI，如機器人和自動駕駛系統，需要在複雜的物理世界中進行感知、決策和行動，其數據需求具有獨特性和挑戰性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;訓練數據&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：來自多種傳感器的融合數據，包括激光雷達的點雲數據、攝像頭的圖像/視頻流、雷達信號、慣性測量單元數據、GPS 定位信息、觸覺傳感器數據等。此外，還包括機器人的關節狀態、運動軌跡、與環境的交互數據，以及大量來自模擬環境的合成數據。這類數據通常是時間序列數據，需要精確的時間同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：要求數據能夠高保真地復現真實世界的物理特性和動態變化，覆蓋多樣化的環境條件（如不同天氣、光照）、複雜的交互場景和罕見的邊緣案例。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：自動駕駛領域的&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DWaymo%2BOpen%2BDataset%26zhida_source%3Dentity" target="_blank"&gt;Waymo Open Dataset&lt;/a&gt;&lt;/span&gt;、&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DnuScenes%25E6%2595%25B0%25E6%258D%25AE%25E9%259B%2586%26zhida_source%3Dentity" target="_blank"&gt;nuScenes 數據集&lt;/a&gt;&lt;/span&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;推理數據&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：來自機器人或車輛上搭載的各種傳感器的實時、連續的數據流。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：數據處理的低延遲性對於物理 AI 系統做出及時、安全的決策和行動至關重要。系統還需要對傳感器噪聲、數據丟失或遮擋等情況具有魯棒性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f6effd68cabc43be465afc81f71a66c4.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;審視這四大 AI 領域對數據的需求演變，可以發現一個清晰的趨勢：AI 模型對數據的「胃口」越來越大，要求的數據集規模日益龐大，多樣性和複雜性也與日俱增。從機器學習對結構化數據的依賴，到深度學習對海量非結構化數據的渴求，再到生成式 AI 對網絡規模多模態數據的吞噬，以及 Physical AI 對高維、多傳感器融合數據的整合，無不體現了這一趨勢。這種趨勢意味着，數據的「AI 就緒」不僅關乎數據本身的質量和形態，也對底層的數據存儲、處理和管理技術平台提出了更高的要求。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;打造 AI 的堅實基礎：通往 AI-ready Data 之路&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;將原始數據轉化為 AI-ready Data，是一項涉及多個步驟的持續性系統工程，而非一蹴而就的任務。這需要隨着 AI 技術、業務需求和數據源的變化而不斷演進和優化，是一個動態的、持續改進的過程。一個典型的數據準備流程始於數據收集與獲取，即從多樣化的內外部來源彙集原始數據，&lt;strong&gt;尤其值得強調的是，在 AI 時代，企業自身積累的、獨特的內部數據是構建差異化競爭優勢和深化護城河的核心戰略資產，對其的有效盤活與利用是首要任務。&lt;/strong&gt;隨後是數據清洗與預處理，旨在識別並修正原始數據中的錯誤、不一致、缺失值和重複項，以提升數據質量。接着進行數據轉換與豐富，將數據轉化為適合 AI 模型的格式，可能包括特徵工程、數據聚合，並通過添加元數據等方式增強數據上下文。對於監督學習任務，準確的數據標註是不可或缺的一環。在數據投入訓練之前，需進行嚴格的數據驗證與質量保證。最後，貫穿整個數據生命週期的是數據治理與安全，要求企業建立清晰的管理政策，確保數據合規、安全。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 並非遙不可及的理想概念，而是成功且可靠的人工智能應用的堅實基石。正如高質量原材料是優質產品的先決條件，高質量的 AI-ready Data 是構建高性能 AI 模型的根本保障，&lt;strong&gt;特別是當這些數據源自企業內部，承載着特定業務洞察和運營經驗時，其轉化為 AI 洞察的能力，將直接賦能企業構建難以複製的競爭壁壘。&lt;/strong&gt;它能夠顯著提升模型的準確性和可靠性，加速 AI 應用的研發部署，並最終驅動商業價值和創新突破。因此，企業應將提升數據就緒水平，尤其是內部數據的「AI 就緒」水平，視為一項戰略要務，而非項目啓動後的被動補救。通往 AI 驅動的創新之路，很大程度上是由對自身獨特數據資產的深度挖掘和高質量準備鋪就的。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;擁抱 AI-ready Data，意味着正視數據的挑戰，投入必要資源，建立完善的流程和文化，核心目標在於充分釋放企業內部沉澱數據的潛在價值。這無疑是一項艱鉅的任務，但其回報——通過人工智能洞察自身運營、優化決策、創新產品與服務，從而在市場競爭中佔據領先地位——將是無可估量的。生成式 AI 並非短暫趨勢，而是一場深刻的變革，而適配這種變革的數據基礎設施和數據就緒能力，&lt;strong&gt;特別是將企業獨有的內部數據轉化為驅動 AI 的優質燃料的能力，將是企業在這場變革中深化護城河、立於不敗之地的關鍵。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354670</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354670</guid>
      <pubDate>Sun, 11 May 2025 10:26:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>RWKV 2025 生態內容徵集大賽 | 5 月投稿作品及評審結果</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;大家好，我們在 2024 年底推出了 「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生態內容徵集大賽&lt;/a&gt;」，公開徵集 RWKV 相關的作品，包括但不限於 RWKV 相關的論文、講解 RWKV 的教程，以及基於 RWKV 的應用等。&lt;/p&gt; 
&lt;p&gt;2025 年 5 月，活動共收到 RWKV 生態作品投稿 &lt;strong&gt;2 份&lt;/strong&gt;，包括 &lt;strong&gt;1 篇論文、1 個教程&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文將公佈 2025 年 5 月的活動投稿作品及評審結果。&lt;/p&gt; 
&lt;h2&gt;評審結果&lt;/h2&gt; 
&lt;h3&gt;評審結果省流版&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名稱&lt;/th&gt; 
   &lt;th&gt;作品分類&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初評獎項&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;biomems&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-V7 模型解析與實戰：架構原理、機制剖析及自定義微調模型效果展示&lt;/td&gt; 
   &lt;td&gt;教程&lt;/td&gt; 
   &lt;td&gt;坤&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下面是「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生態內容徵集大賽&lt;/a&gt;」 5 月投稿獲獎的作品介紹。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;論文類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.11165" target="_blank"&gt;https://arxiv.org/abs/2505.11165&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：biomems&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;項目介紹：論文提出了一種新的異步到同步框架 EVA，用於實時事件相機數據處理&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;該框架基於 RWKV-6 構建了高效的異步編碼器，實現了逐事件的表示更新，並採用自監督學習方法獲得具有高度泛化能力的事件表示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="Maximizing Asynchronicity" src="https://oscimg.oschina.net/oscnet/up-3ca302b9d83762576c1d83a5c2add0e09c0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;教程類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-V7 模型解析與實戰：架構原理、機制剖析及自定義微調模型效果展示&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F1904346608985944244%3Fshare_code%3D1nLMwML5XPvsB%26utm_psn%3D1904552110802055283" target="_blank"&gt;https://zhuanlan.zhihu.com/p/1904346608985944244?share_code=1nLMwML5XPvsB&amp;amp;utm_psn=1904552110802055283&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：坤&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;項目介紹：從原理解析到微調實踐的全流程教程&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;首先帶領初學者一起初步理解 RWKV 架構，然後使用 RWKV-PEFT 微調倉庫進行了全流程的微調並展示了微調效果，在學習原理的同時，微調屬於自己的 RWKV。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="RWKV-V7 模型解析與實戰" src="https://oscimg.oschina.net/oscnet/up-0c74d7e4f003a4e0322e3aee4c8f3e90ec4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;獎品/獎金髮放規則&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;實物獎品（RWKV 周邊等）&lt;strong&gt;以&lt;/strong&gt;順豐快遞&lt;/strong&gt;方式發出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;獎金&lt;/strong&gt;以&lt;strong&gt;轉賬或第三方線上平台&lt;/strong&gt;等方式發放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情況下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;領取獎金，團隊內部&lt;strong&gt;自行協商分配獎金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿與獎項升級&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均會獲得&lt;strong&gt;評審意見&lt;/strong&gt;。請根據評審意見優化你的作品，然後可&lt;strong&gt;再次投稿以升級獎項&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;獎項成功升級時，我們將補發&lt;strong&gt;前後兩個獎金的差價&lt;/strong&gt;。例如投稿作品從鐵獎（888 元）升級到銀獎（2888 元），則補發 2888-888=2000 元獎金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活動海報&lt;/strong&gt;，歡迎各位轉發！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4e11c3df39730d4d504ca57e04f84ed60f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活動最終解釋權歸元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354657</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354657</guid>
      <pubDate>Sun, 11 May 2025 09:42:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>NJet Portal 應用門户管理介紹</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#252933"&gt;NGINX 向雲原生演進，All in&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2F" target="_blank"&gt;OpenNJet&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#252933"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;1. 應用門户簡介&lt;/p&gt; 
&lt;p&gt;NJet 應用引擎是基於 Nginx 的面向互聯網和雲原生應用提供的運行時組態服務程序，作為底層引擎，NJet 實現了 NGINX 雲原生功能增強、安全加固和代碼重構，利用動態加載機制可以實現不同的產品形態，如 Web 服務器、流媒體服務器、負載均衡、代理 (Proxy)、應用中間件、API 網關、消息隊列等產品形態等等。NJet 使用現有的 API Gateway 及各動態配置模塊提供的能力，實現了一個 Portal 管理模塊。通過該模塊，對外提供應用門户的功能，以此來簡化應用的開發及部署過程。應用可以只專注於業務邏輯的實現，將通用的安裝配置及權限認證功能統一交給 NJet 應用門户管理模塊。邏輯架構如下圖所示：&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;br&gt; &lt;img alt="" height="364" src="https://oscimg.oschina.net/oscnet/up-1f786429eefc649f1a786a4cf6d613b839d.png" width="589" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;2. 應用部署流程&lt;/h2&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;用户使用管理員賬號登錄 Portal 門户，上傳應用，添加用户/組/角色，最後進行應用的授權。完成上述操作後，使用普通用户賬號登錄門户，即可使用應用。&lt;/p&gt; 
&lt;h3&gt;a. 管理員登錄&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;在部署包含 Portal 管理模塊的環境上，使用 api gateway 的管理員賬號登錄後，將顯示 Portal 的管理界面，在該界面中可以進行應用的部署，及相關的授權。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;br&gt; &lt;img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-eb99b29a0f3b3cd23de5b461cd4a307898a.png" width="535" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="265" src="https://oscimg.oschina.net/oscnet/up-ab63854c3979c9c02e058a9e5b9632536ac.png" width="829" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;b. 上傳應用&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;應用管理中點擊「新增」，選擇 Portal 應用的相應 npk 文件 (應用的結構在後續章節進行説明)。點擊確認後，Portal 管理模塊將自動創建應用需要的 Location/Upstream, 由於使用了 NJet 的動態配置功能，所有的改動將實時生效，不需要重啓或重加載 NJet。&lt;img align="left" alt="" height="212" src="https://oscimg.oschina.net/oscnet/up-757c44ef7b8cf6030198b1761680d007b2a.png" width="829" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;應用如果需要連接第三方組件，門户管理模塊也提供了通用組件的配置能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;&lt;img alt="" height="222" src="https://oscimg.oschina.net/oscnet/up-8a2148c2b01426d9fa293529473c654602d.png" width="830" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;c. 創建訪問應用需要的用户/組/角色&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;應用門户使用 Api Gateway 提供的授權能力，其模型是「用户-&amp;gt;組-&amp;gt;角色」的授權模型，一個用户可以歸屬於不同的用户組，一個用户組可以分配多個角色，API 授權將授權到角色上。&lt;/p&gt; 
&lt;p&gt;&lt;br&gt; &lt;img alt="" height="494" src="https://oscimg.oschina.net/oscnet/up-f4fd4b50f510813d71234bbbc62275705b0.png" width="448" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;應用門户的 UI 上可以對用户/組/角色及相互間的關係進行維護。&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="286" src="https://oscimg.oschina.net/oscnet/up-5f0951a26bee7f0cedc0e42d92883207860.png" width="829" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;d. 對應用進行授權&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;在應用管理中，選擇應用授權，對應用不同的訪問路徑可以授予不同的角色。&lt;br&gt; &lt;img alt="" height="342" src="https://oscimg.oschina.net/oscnet/up-de990e0cca6a922521203b0b7babccfc768.png" width="831" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;e. 普通用户登錄&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;使用普通用户賬號登錄後，將顯示應用一覽頁面，在改列表頁面中點擊對應的圖標，將跳轉至具體的應用中。&lt;br&gt; &lt;img alt="" height="216" src="https://oscimg.oschina.net/oscnet/up-ad17ad389f138b2dff790b1ec2894dd5d56.png" width="828" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3. Portal 應用結構&lt;/h2&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;使用 Portal 管理模塊部署的應用，需要使用 Portal 模塊可以識別的格式進行目錄規劃及應用打包，文件類型是 npk (NJet Package)。 典型的目錄結構如下圖所示：&lt;br&gt; &lt;img alt="" height="477" src="https://oscimg.oschina.net/oscnet/up-f5452ae3568b4853df0c59f8e64151432d3.png" width="397" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;META-INF 目錄&lt;br&gt; manifest.json: 應用的基本信息，包括入口地址，配置地址，及 location / upstream 信息。&lt;br&gt; 圖標文件: jpg 或 jpg 格式的文件&lt;br&gt; app_openapi.json: openapi 3.0 格式的文件，其中 path 支持，通配符*， 例如 /setting/*&lt;br&gt; app_schema.json: 應用需要的組件配置項 （可選，非必須）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;scripts 目錄&lt;br&gt; 應用使用的腳本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;static 目錄&lt;br&gt; 靜態頁面，資源文件，javascript 腳本， css&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;manifest.json 示例&lt;br&gt; 該文件中定了入口地址（entry_point), 應用配置地址（cfg_url), 及應用需要的 location, upstream servers, \proxy_pass。Location 中可以直接配置屬性（"__access_control": 「true」 ） 來標識該訪問地址需要使用門户提供的用户授權功能。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; "manifest_version": "1.0.0",
&amp;nbsp; "app": {
&amp;nbsp; &amp;nbsp; "name": "ollamaApp",
&amp;nbsp; &amp;nbsp; "version": "1.0.0",
&amp;nbsp; &amp;nbsp; "arch": "x86_64",
&amp;nbsp; &amp;nbsp; "description": "Ollma Chat application",
&amp;nbsp; &amp;nbsp; "icon_file": "ollama.jpg",
&amp;nbsp; &amp;nbsp; "api_file": "app_openapi.json" 
&amp;nbsp; },
&amp;nbsp; "deployment": {
&amp;nbsp; &amp;nbsp; "type": "location",
&amp;nbsp; &amp;nbsp; "server_name": "",
&amp;nbsp; &amp;nbsp; "entry_point": "/ollama-app/open/chat",
&amp;nbsp; &amp;nbsp; "cfg_url": "/ollama-app/open/config",
&amp;nbsp; &amp;nbsp; "locations": [
&amp;nbsp; &amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "path": "/ollama-app/conversation",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "properties": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; " content_by_lua_file": "${APP_PREFIX}/scripts/chat_api.lua"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "path": "/ollama-app/setting",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "properties": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "__access_control": "true", 
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; " content_by_lua_file": "${APP_PREFIX}/scripts/chat_api.lua"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "path": "/ollama-app/chat",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "properties": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "access_by_lua_file": "${APP_PREFIX}/scripts/access.lua", &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"proxy_set_header": [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "Host 192.168.0.206",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "Origin http://192.168.0.206"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "proxy_pass": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "schema": "http",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "servers": [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; {"server":"192.168.40.206:11434"}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "url": "/api/chat"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "path": "/ollama-app",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "properties": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "__access_control": "true", 
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "alias": "${APP_PREFIX}/static/",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "try_files": "$uri $uri/ /ollama-app/index.html"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; ]
&amp;nbsp; }
}


&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;app_schema.json 示例&lt;br&gt; 應用需要連接第三方組件時，組件的配置通過 json 文件描述配置項，門户管理模塊將根據 json 內容動態生成配置頁面。該配置使用 formily (阿里巴巴表單框架&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fformilyjs.org%2F" target="_blank"&gt;https://formilyjs.org/&lt;/a&gt;) 定義的格式。 以下示例文件為連接 redis 組件時需提供的 json 文件。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
    "redis_host": {
        "type": "string",
        "x-component": "Input",
        "x-component-props": {
            "placeholder": "請輸入 ip 地址"
        },
        "x-decorator": "Form.Item",
        "x-decorator-props": {
            "label": "Redis IP",
            "tooltip": "請輸入 ip 地址"
        }
    },
    "redis_port": {
        "type": "number",
        "x-component": "InputNumber",
        "x-component-props": {
            "placeholder": "請輸入端口號",
            "min": 0,
            "max": 65535
        },
        "x-decorator": "Form.Item",
        "x-decorator-props": {
            "label": "Redis Port",
            "tooltip": "請輸入端口號"
        }
    },
    "redis_password": {
        "type": "string",
        "x-component": "Input.Password",
        "x-component-props": {
            "placeholder": "請輸入，密碼"
        },
        "x-decorator": "Form.Item",
        "x-decorator-props": {
            "label": "Redis 密碼",
            "tooltip": "請輸入密碼"
        }
    }
}



&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Demo 應用完整實例&lt;/h2&gt; 
&lt;h3&gt;a. 通過 ftp 獲取到 demo 應用包&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;地址：&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2Fcases%2Fnjet_portal%2Fftp.tmlake.com" target="_blank"&gt;ftp.tmlake.com&lt;/a&gt;&lt;br&gt; 目錄： /OpenNjet/Software/v3.2.2-portal&lt;br&gt; 文件： demo_app_1.0.2.npk&lt;/p&gt; 
&lt;h3&gt;b. 使用默認管理員賬號 agw_admin /****** 登錄 /portal&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="" height="473" src="https://oscimg.oschina.net/oscnet/up-90b64286f130065e401aafc262e64d8a63c.png" width="828" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;c. 添加 demo 應用&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;在應用管理中，選擇新增，添加獲取的 demo_app_1.0.2.npk, 並點擊確認&lt;br&gt; &lt;img alt="" height="403" src="https://oscimg.oschina.net/oscnet/up-74132c3765bd3e076b713b3594e31cc2036.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;成功後，應用管理頁面將出現 demo 應用的條目&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="291" src="https://oscimg.oschina.net/oscnet/up-d046f5dd8476abbe99d7e72b7c6b91aa41d.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;d. 為用户添加用户/組/角色&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;添加一個 demo 用户角色&lt;br&gt; &lt;img alt="" height="389" src="https://oscimg.oschina.net/oscnet/up-dc1584bc1a527fb8264f1b910c92e18b8e7.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;添加一個 demo 用户組&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;&lt;img alt="" height="386" src="https://oscimg.oschina.net/oscnet/up-6cb8a602364807628ba2f61b7535fdcce93.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;為這個組分配角色&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="340" src="https://oscimg.oschina.net/oscnet/up-629e14cdbe83d75b2f4f52dc5994f7f793e.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img alt="" height="470" src="https://oscimg.oschina.net/oscnet/up-6712ce985aaf4f38446286a9f1f30c5405c.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;添加一個 user1 用户，並指定 domain 為 「demo」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br&gt; &lt;img alt="" height="540" src="https://oscimg.oschina.net/oscnet/up-85d0418338f2a1046e2fa6abe9cd6656ec0.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;為這個用户分配組&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="361" src="https://oscimg.oschina.net/oscnet/up-8e05d33ef94fc4717e072ca9b038a305ca8.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="500" src="https://oscimg.oschina.net/oscnet/up-4fd2fe5a506a97333930938cff6c9597e67.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;e. 編輯應用的授權&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;在應用管理列表中點擊 demo 的授權&lt;br&gt; &lt;img alt="" height="324" src="https://oscimg.oschina.net/oscnet/up-604171afe88c704ba56f4142dd09981c520.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;該應用只有一個訪問地址，選擇後點擊授權，在彈出的窗口下拉框中選擇"demoUserRole"&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="460" src="https://oscimg.oschina.net/oscnet/up-278c912f13145bb652cd5cd8d39cda54952.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;f. 使用剛創建的普通用户賬號登錄 /portal&lt;/h3&gt; 
&lt;p&gt;&lt;br&gt; &lt;img alt="" height="423" src="https://oscimg.oschina.net/oscnet/up-b9fb454d110707137e2acbfa401c8769432.png" width="974" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;應用列表中顯示出我們剛剛部署的 demo 應用&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="356" src="https://oscimg.oschina.net/oscnet/up-859d8d18885c7d84eb0a33ff2f6975c5502.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#555555"&gt;點擊應用圖標後，跳轉到應用的頁面&lt;/span&gt;&lt;br&gt; &lt;img alt="" height="299" src="https://oscimg.oschina.net/oscnet/up-c339336df13139c0f650b22103ac13934c1.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;該 demo 應用只是簡單的一些頁面 Tab, 展示的也只是一些測試數據&lt;/p&gt; 
&lt;h2&gt;5. 後續改進&lt;/h2&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;目前部署的應用有新版本需要升級時，需要在應用管理中刪除應用後，重新上傳。後續將繼續優化門户管理模塊，提供應用的版本管理及回滾功能。&lt;/p&gt; 
&lt;h2&gt;6. 參考&lt;/h2&gt; 
&lt;h3&gt;a. 使用到的 API&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;API Gateway: 用户/組/權限的增刪改查，api group 創建，oas3.0 格式文檔導入，應用部署接口&lt;br&gt; &lt;a href="https://gitee.com/njet-rd/njet/blob/master/doc/swagger/helper_api_gateway.yaml"&gt;https://gitee.com/njet-rd/njet/blob/master/doc/swagger/helper_api_gateway.yaml&lt;/a&gt;&lt;br&gt; 動態 Location API: 動態添加及刪除 Location&lt;br&gt; &lt;a href="https://gitee.com/njet-rd/njet/blob/master/doc/swagger/helper_dy_loc.yaml"&gt;https://gitee.com/njet-rd/njet/blob/master/doc/swagger/helper_dy_loc.yaml&lt;/a&gt;&lt;br&gt; 動態 Upstream API: 動態添加及刪除 Upsteam&lt;br&gt; &lt;a href="https://gitee.com/njet-rd/njet/blob/master/doc/swagger/helper_dyn_http_ups.yaml"&gt;https://gitee.com/njet-rd/njet/blob/master/doc/swagger/helper_dyn_http_ups.yaml&lt;/a&gt;\&lt;/p&gt; 
&lt;h3&gt;b. Demo 應用包的下載&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;地址：&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2Fcases%2Fnjet_portal%2Fftp.tmlake.com" target="_blank"&gt;ftp.tmlake.com&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;\&lt;br&gt; 目錄： /OpenNjet/Software/v3.2.2-portal&lt;br&gt; 文件： demo_app_1.0.2.npk&lt;/p&gt; 
&lt;h3&gt;c. NJet 版本及 Portal 獲取及安裝&lt;/h3&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;NJet 版本需要 &amp;gt; 3.2.2&lt;br&gt; Portal 門户管理模塊獲取：&lt;br&gt; 地址：&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2Fcases%2Fnjet_portal%2Fftp.tmlake.com" target="_blank"&gt;ftp.tmlake.com&lt;/a&gt;&lt;/p&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;目錄： /OpenNjet/Software/v3.2.2-portal/&lt;br&gt; 文件： portal_1.0.2.npk , ssh_remote_mod.so&lt;br&gt; Portal 門户管理模塊安裝：&lt;br&gt; 修改配置 /usr/local/njet/conf/njet.conf&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;worker_processes auto;

cluster_name njet;
node_name node1;

error_log logs/error.log error;

helper ctrl modules/njt_helper_ctrl_module.so conf/njet_ctrl.conf;
helper broker modules/njt_helper_broker_module.so;

load_module modules/njt_agent_dynlog_module.so;  
load_module modules/njt_dyn_ssl_module.so;
load_module modules/njt_http_vtsc_module.so;
load_module modules/njt_http_location_module.so;
load_module modules/njt_http_lua_module.so;
load_module modules/njt_http_dyn_upstream_module.so;
load_module modules/njt_http_dyn_server_module.so;  
load_module modules/njt_http_token_sync_module.so;
load_module modules/njt_http_upstream_member_module.so;
load_module modules/njt_http_dyn_lua_module.so;

events {
    worker_connections  1024;
}

shared_slab_pool_size  100m;   
http {
    token_sync zone=token:4M sync_time=5s clean_time=10s;
    dyn_kv_conf conf/iot-work.conf;
    include mime.types;
    access_log off;
    vhost_traffic_status_zone;

    lua_package_path "$prefix/lualib/lib/?.lua;$prefix/modules/?.lua;$prefix/apps/?.lua;;";
    lua_package_cpath "$prefix/lualib/clib/?.so;;";
    init_by_lua_block {
        local _=require("lor.index")
        local _=require("lsqlite3complete")
    }
    server {
        listen       8080;
        error_page 401 =302 /portal;
        client_max_body_size 1000m; 
        location / {
           root html;
        }
        location /icons/ {
            alias /usr/local/njet/apps/__icons/;
            try_files $uri =404;
       }
    }
}


&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;load_module modules/njt_http_sendmsg_module.so;
load_module modules/njt_ctrl_config_api_module.so; 
load_module modules/njt_helper_health_check_module.so;
load_module modules/njt_http_upstream_api_module.so; 
load_module modules/njt_http_location_api_module.so;
load_module modules/njt_doc_module.so;
load_module modules/njt_http_vtsd_module.so;
load_module modules/njt_http_lua_module.so;
load_module modules/njt_http_dyn_upstream_module.so;
load_module modules/njt_http_dyn_upstream_api_module.so;
load_module modules/njt_http_dyn_server_api_module.so; 
load_module modules/njt_http_upload_module.so;

error_log logs/error_ctrl.log error;

events {
    worker_connections  1024;
}

http {
    dyn_kv_conf conf/ctrl_kv.conf;
    lua_package_path "$prefix/lualib/lib/?.lua;$prefix/modules/?.lua;;";
    lua_package_cpath "$prefix/lualib/clib/?.so;;";
    init_by_lua_block {
        local _=require("lor.index")
        local _=require("lsqlite3complete")
    }
    include mime.types;
    access_log off;
    server {
        client_max_body_size 1000m;  
        listen       8081;

        location / {
            return 200 "njet control panel\n";
        }

        location /api {
            dyn_module_api;  
        }
        
        location /doc {
            doc_api;
        }
        
        location /metrics {
            vhost_traffic_status_display;
            vhost_traffic_status_display_format html;
        }

        location /api_gateway {
           access_by_lua_block {
              local ac=require("api_gateway.access.control")
              local access=ac.new("/api_gateway")
              access:check()
           }
           content_by_lua_block {
              local api_gateway=require("api_gateway")
              api_gateway.main()
           }
        }
    }
}


&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;拷貝 ssh_remote_mod.so&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo cp ssh_remote_mod.so /usr/local/njet/lualib/clib/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;重啓 njet&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo systemctl stop njet
sudo systemctl start njet     


&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#555555; margin-left:0; margin-right:0; text-align:start"&gt;將下載後的 portal_1.0.2.npk 文件上傳到 njet 主機上，並且主機上安裝 curl 及 jq 命令行工具&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;NJET_SITE="http://localhost:8081"

PORTAL_FILE=$(curl -k -s -F "file=@portal_1.0.2.npk"  "$NJET_SITE/api/v1/upload" |jq -r '.file')

TOKEN=$(curl -k -X POST -d '{"login_data":{"username": "agw_admin", "password": "********"}}' -s "$NJET_SITE/api_gateway/auth/login" | jq -r '.token')

curl -X 'POST' \
  "$NJET_SITE/api_gateway/deploy/app" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d "{\"uploaded_file\": \"$PORTAL_FILE\"}"&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="background-color:#f6f6f6; color:#333333"&gt;&lt;span&gt;NJet&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用引擎通過內核重構實現了獨特的運行時&lt;strong&gt;動態配置加載&lt;/strong&gt;能力，是&lt;strong&gt;新一代高性能 Web 應用引擎&lt;/strong&gt;。NJet 擁有高性能數據面處理能力，將集羣、高可用、主動健康檢查、聲明式 API 等多種輔助功能，通過 NJet 獨特的副駕駛 CoPilot 服務框架調度，從而方便功能擴展，隔離管理 / 控制功能對數據面的影響，NJet 應用引擎性能超過 CNCF 推薦 Envoy 應用引擎的三倍。&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#f8f8f8; color:#666666"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fnjet.org.cn%252Fmailman%252Flistinfo" target="_blank"&gt;郵件組&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2Fmailman%2Flistinfo" target="_blank"&gt;&lt;span style="background-color:#f8f8f8; color:#666666"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span style="background-color:#f6f6f6; color:#333333"&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2F" target="_blank"&gt;官網&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354653</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354653</guid>
      <pubDate>Sun, 11 May 2025 09:21:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>如何以 MLOps 保障時效表達穩定性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;消費者選擇電商平台進行購物，除了獨特的商品，購物體驗也越來越成為消費者衡量平台的重要標準。如何幫助客户快速的檢索到自己想要購買的商品，如何讓客户買到性價比最高的商品，如何幫助客户在更短的時間內收到購買的商品，這些都是平台為消費者提供的重要服務。筆者在訂單履約時效項目的參與過程中，主要負責通過算法，幫助平台提升訂單履約率和準確率。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6d9c0787cf0c148664e456ed72af1e16.jpg" alt="背景 1.jpg" referrerpolicy="no-referrer"&gt; &lt;img src="https://oscimg.oschina.net/oscnet//bdf5fe41611ebedf368e369a4e62903b.jpg" alt="背景 2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們先來直觀感受一下時效對體驗的影響。從上面 2 張圖，我們能夠看到，右圖訂單的交付時效比較長，客户對訂單支付意願就會大大降低，有行業專業人士分析，時效表達多一天，影響的 GMV 就達千萬級，可見時效表達越短對應的收益越大，但也會給供應鏈履約帶來更大的成本。從運營的角度，如果想要給消費者更短時效的體驗，但卻超越了供應鏈當前的履約能力（比如告知消費者 1 天送達，實際是 3 天），則會帶來大量客訴，在得物平台因為有"晚到必賠"規則，會額外增加超時賠付優惠券的負擔，引發資損。所以在得物做時效表達，需要同時兼顧時效的準確率（告知消費者 1 天送達，實際也是 1 天）和履約率（告知消費者 1 天送達，實際不超過 1 天）。&lt;/p&gt; 
&lt;p&gt;在我們長期探索過程中，模型逐漸經歷了統計模型、ML 模型、DL 模型的演化。商業環境上也經歷了惡劣天氣、春節、大促等各種極端場景的考驗，算法模型也在一次次的挑戰中，變得越來越堅實，並從手工操作逐步實現自動化流程。為了讓流程更加高效、穩定，我們引入了 MLOps 的理念，本文拋磚引玉，與大家一起聊聊，我們在結合 MLOps 應用的心路歷程，期待能與大家碰撞出思維的火花。&lt;/p&gt; 
&lt;h1&gt;二、什麼是 MLOps&lt;/h1&gt; 
&lt;p&gt;附：MLOps 方法論： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fml-ops.org%2Fcontent%2Fmlops-principles" target="_blank"&gt;https://ml-ops.org/content/mlops-principles&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;MLOps 的核心理念&lt;/h2&gt; 
&lt;p&gt;隨着算法模型在工業界的應用越來越深，越來越廣，業界逐漸實踐出一些標準，讓我們能更高效、更穩定、低成本且長久地管理模型的整個生命週期， 涉及模型訓練、模型發佈、灰度或 AB，及模型的長期監控等等。&lt;/p&gt; 
&lt;p&gt;其核心理念，主要有以下 7 個方面的模型管理規範：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Versioning， 數據、模型、代碼等是否有版本記錄，是否能便捷地回溯；&lt;/li&gt; 
 &lt;li&gt;Testing， 數據、特徵、模型的生成是否有邏輯校驗；代碼是否有單元測試等；&lt;/li&gt; 
 &lt;li&gt;Automation，數據、特徵的生成是否有自動調度，模型訓練、搜參是否自動，代碼提交合並是否 CI/CD；&lt;/li&gt; 
 &lt;li&gt;Reproducibility，基於 Versioning 的保障，是否能在任意時間復現歷史某次模型預測結果；&lt;/li&gt; 
 &lt;li&gt;Deployment，發佈在生產、AB、陪跑等環境，是否能保證入參一致性，代碼一致性；&lt;/li&gt; 
 &lt;li&gt;Monitoring，模型精度下降是否能感知，數據漂移、數據泄露等是否會被發現；&lt;/li&gt; 
 &lt;li&gt;Documentation &amp;amp; Project Structure， 文檔、項目結構是否具備可讀性，結構性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MLOps 核心理念落地關鍵問題&lt;/h2&gt; 
&lt;p&gt;MLOps 的核心理念，應用到業務的過程，並不是一個完全由機器完成，全自動化的過程，而是需要業務團隊根據實際業務的情況，不斷調整入參，調整模型的過程，會涉及大量的人與機器的交互。因此，如何將這些核心理念應用到具體的業務中，我們需要思考 2 個方面的問題：&lt;/p&gt; 
&lt;h3&gt;算法模型在設計過程中，要保障業務執行的效果&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;模型復現問題：預測模型是如何生成的，如果模型丟失了，能否重新訓練找回丟失的模型？&lt;/li&gt; 
 &lt;li&gt;線上一致性問題，線上時效表達時，訂單是由哪個模型預測的？同樣的入參給到同一個模型預測，是否保持冪等？ 發佈新模型時，如何保障模型上線後的效果符合預期？&lt;/li&gt; 
 &lt;li&gt;模型快速升級問題：線上指標下降了，模型更新流程需要多少人工介入？更新頻次的增加，是否帶來人工成本線性增長？&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;如何降低業務使用算法模型的門檻&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;運營模型的門檻是否可以降低？&lt;/li&gt; 
 &lt;li&gt;業務、產品是否能配置化地訓練、選擇自己需要的模型？&lt;/li&gt; 
 &lt;li&gt;是否能讓更多樣化的業務決策能落地，獲得更好的業務收益呢？&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;三、MLOps 關鍵理念的實踐--時效仿真產品&lt;/h1&gt; 
&lt;p&gt;基於上述的思考，我們設計並開發了時效仿真產品，並將 MLOps 的理念融入其中。&lt;/p&gt; 
&lt;h2&gt;模型的可復現性&lt;/h2&gt; 
&lt;p&gt;對於模型訓練環節來説，訓練集、代碼版本和模型參數是三個非常重要的因素。其中代碼版本、模型超參可以通過 git 和數據庫控制， 比較容易忽略的是訓練集的狀態，我們通過數據分層和業務日期隔離兩種方法確保了訓練集的可追溯性。&lt;/p&gt; 
&lt;h3&gt;數據分層，保障數據版本一致性&lt;/h3&gt; 
&lt;p&gt;如下圖所示，在訓練環節，時效仿真產品的用户可以圈選任意天的訂單用作訓練。同樣圈選了下列日期的樣本，站在不同日期訓練是不一樣的。比如站在 20240903 和 20240902，那麼對於 20240901 支付的訓練樣本，20240903 會比 20240902 多一批已簽收訂單進入模型訓練。越近期的數據越能反映履約網絡的變化，一般 20240903 訓練得到的模型預測會更準一點。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d572e90e86b01efbb06d59b115709418.jpg" alt="模型 1.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;時效仿真產品-訓練樣本的圈選&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a04dfdd7ea4cc9a0f7289d304abcc0ea.jpg" alt="模型 2.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;數據分層&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;這就説明瞭圈選同樣支付日期的訂單做訓練樣本，因為訓練日期不同導致已簽收訂單不同，進而影響實際進入模型訓練的樣本不同。&lt;/p&gt; 
&lt;p&gt;針對這個問題，我們做了數據分層，如上右圖所示，數倉會將每日訂單的最新狀態更新完畢， 用户發起仿真任務後，服務端按需取對應訂單，通過仿真任務 ID 作為分區，落到訓練集和預測集表。隨後通過 AI 計算平台調起訓練、預測任務，同樣傳入仿真任務 ID，訓練預測任務取相應分區。這樣日後需要重新訓練，我們能保證同一個仿真任務得到的數據是一樣的。&lt;/p&gt; 
&lt;h3&gt;業務日期隔離，防止數據泄露問題&lt;/h3&gt; 
&lt;p&gt;數據分層雖然保障了數據版本的一致性，但時效場景因其特殊性，我們仍可能遇到數據泄露的問題。如下圖所示，按經驗訂單平均在 4 天內能被簽收，但是數據上從 20240830 開始訂單的簽收時間延長了，因為 20240902 是颱風摩羯登陸的日子，受到颱風天氣的影響，簽收時間也發生了變化。&lt;/p&gt; 
&lt;p&gt;針對 20240830~20240901 期間的支付訂單，做訂單簽收時長的時效預測，有一部分訂單會在台風前簽收，有一部分會在台風後簽收，在台風到來前後訓練得到的模型是完全不同的，預測的結果也是不同的。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在台風前訓練，模型平均預測時間就是 4 天，&lt;/li&gt; 
 &lt;li&gt;在台風後訓練，模型就會預測時間偏長。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果颱風結束後模型沒及時調整，那整個時效表達的準確性就會大打折扣，不僅會破壞模型的可復現性，對模型準確性也造成了影響。我們做過測算，在不加幹預情況下，颱風後預測樣本履約率會大幅上升 (+2.3pt)，T 日準確率大幅折損 (-30.82pt)，模型表達過於保守。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//107df891e8de02dcd6a07c867333918f.jpg" alt="數據泄露 1.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;同支付訂單，簽收區間示意圖&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;如何解決呢？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對於可復現性，我們在後台記錄了每個仿真任務的執行業務日期， 根據業務執行日期來判斷，模型可以看到哪些天已簽收訂單做訓練數據， 這個場景裏只要把業務日期固定在台風前，那不管是哪天訓練的模型，其效果都是一樣的。&lt;/li&gt; 
 &lt;li&gt;對於準確性而言，我們希望讓模型訓練正常日期，預測正常時長，颱風、暴雪等異常情況通過 bcp（Business Continuity Planning）加時來保障，颱風過後指標能迅速回歸正常。基於此，我們在時效仿真產品裏設計了訂單圈選時間類型，可以按支付或應履約日期來圈選，颱風情況就按應履約圈選颱風前的樣本即可，如下左圖。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//b70c836a299b0d2427bdd55e5ba4d367.jpg" alt="颱風.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過上述的產品設計，我們能保證模型在任意時間訓練，任意歷史狀態下看到的數據都是一致的，為模型可復現性打下了基礎。每個模型訓練完成後，除了保存模型文件，我們也會記錄代碼版本、特徵、後處理策略等模型必要參數。&lt;/p&gt; 
&lt;h2&gt;線上的一致性保障&lt;/h2&gt; 
&lt;p&gt;當我們得到理想的模型及仿真結果後，接下去要確保安全地上線，如何能確保也是知易行難。仿真可以失敗無數次，只要有一次成功就可以，上線卻不容許那麼多次失敗，最好是一次成功。&lt;/p&gt; 
&lt;p&gt;在時效場景裏更特殊的是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;隨着時間的推移我們的履約網絡能力是一個動態變化的過程，相應地模型也需要長期頻繁的更新。&lt;/li&gt; 
 &lt;li&gt;每次模型上線後，其效果一般要等訂單走完支付到簽收的生命週期後才能回收效果，一般今天上線的模型，下週才知道線上效果如何。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;那麼如何保障模型每次更新都是可靠的，通過一段時間的探索，我們找到了模型可靠性三步曲，依靠&lt;strong&gt;流量回放、流程保障和自動發佈&lt;/strong&gt;來保障線上模型的效果。&lt;/p&gt; 
&lt;h3&gt;流量回放，確保仿真入參和線上入參一致性，提升模型準確率&lt;/h3&gt; 
&lt;p&gt;我們經常會遇到模型仿真效果很好，但線上陪跑就掉很多精度，排查後發現仿真和線上陪跑的入參存在不一致的情況。比如賣家發貨地址、承運商等信息，在支付的時候存在不確定性，線上有入參補齊邏輯，比如用子模型預測，或拿歷史眾數填充；但仿真時這些信息已成歷史，落在表裏的是真實數據了。這就導致了線上、線下的入參不一致。&lt;/p&gt; 
&lt;p&gt;服務端同學為此建設了堅實的流量回放能力。平台不同的業務流程，各環節的預測是不同的。以相對複雜的現貨流程為例，需要預測商家發貨、頭程運輸、庫內作業和尾程運輸，理論上每一段都可以用不同的模型來預測，每一段預測入參都可能不一樣。服務端同學設計的統一流量回放能力保障了在每一段的入參、出參、調用模型版本都記錄在案，做到了任意訂單的可追溯。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4cff6ab40712418eeb61ada8d2aac7bd.jpg" alt="業務流程.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;複雜的業務流程&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//043b093c887e5b5d7b0c11d9c8d85a3e.jpg" alt="流量回放.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;統一的流量回放&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;對應到模型訓練、仿真環節， 我們用真實數據做訓練， 用線上實際入參來仿真，這樣最大化地保障模型精度，減少了仿真與上線之間的精度損失。&lt;/p&gt; 
&lt;h3&gt;流程保障，取得模型穩定性和準確性之間的平衡，最大化業務效果&lt;/h3&gt; 
&lt;p&gt;網絡履約能力會受到多種事件變化因素的影響，根據事件因素的特點，大致可分為臨時性變化和長久性變化。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;臨時性變化：比如颱風惡劣天氣、兩會管控、春節打烊等事件觸發，事件開始時履約能力急劇變差，事件結束後馬上又恢復；&lt;/li&gt; 
 &lt;li&gt;長久性變化：比如承運商班次調整、倉網變化等，其影響時間較長。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;臨時性變化不應該放入模型訓練， 長久性變化應該讓模型去學習，並且越早學習到表達就越準。&lt;/p&gt; 
&lt;p&gt;如何判斷是臨時性還是長久性變化呢？如果不加約束，儘量用最新數據訓練，難以排除臨時性變化影響的樣本，這樣在事件結束後模型表達會偏保守，如上文的颱風後陪跑，會損失指標的穩定性。如果加以約束，用履約已完成的訂單做訓練，這樣可以通過履約時長等統計數據來判斷是否屬臨時性異常，可以減少異常樣本的幹擾，但也會損失一定準確性。&lt;/p&gt; 
&lt;p&gt;與產品同學反覆溝通了方案後，最終站在業務效果最大化的角度，我們選擇在穩定性和準確性之間取其平衡，每週會定時啓動較新樣本仿真，選其中較優模型進入陪跑，待部分簽收後決策是否選擇模型上線，詳細流程如下圖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//b5317de402611fcc7f86753e4b587df8.jpg" alt="流程保障.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;模型自動發佈，確保模型落地效果&lt;/h3&gt; 
&lt;p&gt;模型的發佈涉及到一系列流程，流程中所做的配置和操作，對模型效果會有較大的影響。因此，模型的發佈也是非常重要的環節。但模型發佈，一般需要等一週後，有部分訂單簽收，才能看到實際的結果，存在滯後性。在早期曾發生過多起，因為模型發佈流程問題，導致模型效果打了折扣，比如新特徵模型取錯了線上 Redis 特徵名、Ark 開關配置錯誤、模型更新後部分服務器 sdk 未升級等等。基於此，我們建立了模型自動發佈流程，將線上邏輯不符合預期的情況提前反映出來。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;梳理了模型發佈流程圖，將發佈流程標準化，如下左圖所示；&lt;/li&gt; 
 &lt;li&gt;取消發佈流程中的手動操作，改為系統自動操作，同時沉澱了 SLA；&lt;/li&gt; 
 &lt;li&gt;接入了模型上線審批流：陪跑回收到符合預期的效果後，需要由業務方決策選用哪個模型上線，模型的上線，將直接決定業務運營的效果和管理成本，為此我們也接入了審批流，如下右圖所示；&lt;/li&gt; 
 &lt;li&gt;建立離線陪跑相同模型的方法來驗證線上、仿真預測的一致性，離線陪跑的訂單及入參通過流量回放獲得，兩邊對比預測結果是否一致；&lt;/li&gt; 
 &lt;li&gt;建立舊模型反向陪跑：尤其模型有新特徵或新邏輯的情況下，未來的網絡履約能力可能存在較大的波動，如果舊模型直接下線，網絡履約能力波動帶來的影響將很難，需要有舊模型的陪跑，才能確定是線上邏輯問題，還是網絡履約能力變化問題。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d3285d9b3a5185e6e9b8372c8efd40dd.jpg" alt="發佈流程.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;發佈流程&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6aebbcb90903a605333cd4c7f8c731ed.jpg" alt="上線審批流.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;上線審批流&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;良好的自動化離不開合理的自動化流程設計，Automation 作為 MLOps 的重要模塊，幫助我們較好的解決了手動操作帶來的風險和人工成本，在流量回放的一致性驗證、模型仿真陪跑流程、發佈自動化三方面做的自動化為我們日常低成本運營帶來了很大幫助。&lt;/p&gt; 
&lt;h2&gt;模型落地標準化、產品化、自動化，降低業務落地門檻&lt;/h2&gt; 
&lt;p&gt;在模型線上表達比較穩定之後，公司希望在不同的業務場景嘗試模型的應用，比如經濟型快遞獨立模型、週末獨立模型、支付和應履約模型等，不同的場景應用目的雖然不同，但其底層基礎流程大致相同，為了能夠讓業務根據不同的管理訴求，能夠靈活的調整模型訓練集，我們跟時效工程、算法工程團隊合作，藉助 AI 計算平台的調度能力，結合自研的 faas，將模型訓練、仿真做成了完全可自助的產品。其大致流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9d4b606717b23674d7c073e939bf4f10.jpg" alt="模型落地.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在產品前端，用户可以按需選擇不同的樣本，選擇靈活性非常大，可以按不同週期、承運商、類目、訂單類型、線路等等各種維度來圈選需要訓練或仿真的訂單。服務端在接受訓練、仿真請求後，按需生成訓練集和預測集，再調度 AI 計算平台執行相應任務。這裏我們通過 faas 解耦與仿真邏輯解析層隔離的方式支撐了產品靈活性和底層架構穩定性。&lt;/p&gt; 
&lt;h3&gt;faas 解耦，提升算法維護模型的靈活性&lt;/h3&gt; 
&lt;p&gt;如下左圖，沒有 faas，調用 KubeAI 的邏輯非常深地耦合在服務端的代碼裏，算法同學想要調整這部分配置，就需要服務端同學改代碼去發版；&lt;/p&gt; 
&lt;p&gt;如下右圖，有了 faas，服務端只需要關心調用了哪個 function，關鍵的入參是什麼就可以了，其調用如右圖。 鏡像版本、啓動命令、模板 ID 的更新就解耦給到算法同學去維護了，增加了算法迭代靈活性的同時，保障了服務端接口的穩定性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e300fa0487f34b9539272ba0640f2b5f.jpg" alt="服務器耦合.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;服務端耦合過多調用 AI 計算平台代碼&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a6a3468c4394b440ae1b532d83bf342e.jpg" alt="服務端只關心.jpg" referrerpolicy="no-referrer"&gt; &lt;em&gt;服務端只關心調用 function 和入參&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;仿真邏輯解析層隔離，計算任務原子化，適配多種業務場景&lt;/h3&gt; 
&lt;p&gt;業務的需求往往是複雜的，靈活的，多變的，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增加多種業務類型如品牌直髮、現貨；&lt;/li&gt; 
 &lt;li&gt;批量訓練、預測多個模型擇優，不同模型對應不同特徵、超參等，最後將較優模型註冊到仿真產品；&lt;/li&gt; 
 &lt;li&gt;支持多種預測目標，如支付-簽收、支付-到倉、發貨-簽收等不同模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;面對業務多變的需求，我們需要讓計算任務具有原子性，穩定的特點。我們選擇在 AI 計算平台實際執行的任務中增加解析層和後處理層的方法，與用户的需求交互，按需生成不同的配置、啓動命令來調用 pipline，中間執行的 pipline 是一直穩定的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9d851028f283ca2e4be3642dbe462c42.jpg" alt="pipline.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如此，我們將工程與算法的交互做了良好的解耦，讓工程與算法各司其職；讓底層穩定下來，解析層靈動起來。時效仿真產品就變得更敏捷，整個模型的訓練、預測可以更高效、自動地運轉。&lt;/p&gt; 
&lt;p&gt;目前，模型的仿真已經基本不需要算法同學介入，極大的解放了研發團隊在模型探索業務應用和模型更新上的精力，減少了研發在持續維護模型上的成本。&lt;/p&gt; 
&lt;h2&gt;業務應用效果&lt;/h2&gt; 
&lt;p&gt;綜上所述，在保證模型效果的同時，將模型的應用門檻降低，使得產品業務等非研發同學也能參與進模型的應用上來，藉助其業務的敏感性和專業性，可以在更多的業務場景中創造進一步價值。&lt;/p&gt; 
&lt;p&gt;本期我們將為大家介紹，業務在模型使用中，兩個比較典型的創新方法，一個是時效 AB 方法，帶來了較好的貨幣化收益，一個是新特徵挖掘，顯著提升了模型準確率兩個典型案例。&lt;/p&gt; 
&lt;h3&gt;時效 AB，貨幣化收益明顯&lt;/h3&gt; 
&lt;p&gt;得物非常重視消費者的購物體驗，在時效上，也制定了賠付策略，為用户提供訂單時效保障，超時則提供賠付補償。這套策略提升了客户訂單的轉化，留存，但也對時效的保障提出了更高的要求，不僅要考慮時效的準確性，還需要兼顧賠付成本和 GMV 收益。如果時效表達過於激進，可能會促轉化提高 GMV，但同時增大了訂單超時的風險，造成晚到必賠及客訴成本， 表達保守則反之。&lt;/p&gt; 
&lt;p&gt;那收益和成本之間的平衡點在哪兒呢？&lt;/p&gt; 
&lt;p&gt;產品同學由此牽頭做了 AB 實驗，通過仿真產品，我們得到多組履約率和準確率不同的組合，在不同用户 AB 過程中找到了收益和成本之間的平衡點。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ead5ebfe83b4e7a13d7c87fb8fbd1756.jpg" alt="收益成本平衡.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;新特徵挖掘，顯著提升模型準確性&lt;/h3&gt; 
&lt;p&gt;業務產品在運營管理中發現，相對日常，週末、節假日期間，部分商家、承運商的網絡履約能力會有一定波動，模型預測準確度也會受到影響。&lt;/p&gt; 
&lt;p&gt;分析後發現，網絡履約能力的波動可以由一系列統計指標來刻畫，比如昨日支付單量、昨日未攬收單量比例等。那這些指標能否讓模型感知到呢？&lt;/p&gt; 
&lt;p&gt;通過仿真產品測算得到這些指標作為新特徵，模型可以顯著提升準確率，上線後也能保持相應優勢，使得平台在週末、節假日期間也能提供高質量履約服務。&lt;/p&gt; 
&lt;p&gt;通過產品化降低的使用門檻，我們也期望未來會有更多有意思的場景與產品業務同學共同挖掘，創造更大的價值！&lt;/p&gt; 
&lt;h1&gt;五、延展 scale 的思考&lt;/h1&gt; 
&lt;p&gt;經過近 1 年的建設，供應鏈算法團隊和時效團隊配合緊密做了完善的工程建設。但從長遠來看，供應鏈未來會有越來越多的場景要複用同樣的能力，從短期來看，當前合作模式也存在一定侷限。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;算法模型發佈靈活性要求更高，預處理、後處理變動靈活，而業務代碼又期望穩定。&lt;/li&gt; 
 &lt;li&gt;模型運營上對算法可見度較低，模型版本記錄、當前上線陪跑了哪些模型對算法無法有效感知。&lt;/li&gt; 
 &lt;li&gt;模型推理耦合在業務應用裏，對機器成本提高了要求。業務邏輯對機器配置要求低，但因為算法模型對機器要求配置高，所以拉高了業務域的機器成本，不便運維降本。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;因此在最近供應鏈算法工程小分隊成立了，並且與 AI 計算平台團隊強強聯合，希望把業務域邏輯和算法邏輯解耦開來，讓算法同學能更好地幹預、運維模型，讓更多場景可以低成本地接入 MLOps 標準。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4e2e78ee529420fc927815058d506107.jpg" alt="MLops 標準.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，讓 AI 負責底層調度，供應鏈工程負責抽象公共能力，供應鏈算法和業務開發團隊靈活地在各種場景落地。希望在不久的將來，我們有更多更好的故事可以與諸位分享，也歡迎各位業界大佬能加入我們團隊！&lt;/p&gt; 
&lt;p&gt;文 / 凡飛&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/16686495</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/16686495</guid>
      <pubDate>Sun, 11 May 2025 09:11:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>英國擬投資 10 億英鎊推動人工智能發展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;英國首相斯塔默在 9 日舉辦的倫敦科技周開幕式上説，將投資 10 億英鎊（1 英鎊約合 1.35 美元），將英國的算力提升 20 倍，大幅提升人工智能基礎設施，推動英國從人工智能技術接受者轉變為製造者，確保人工智能大幅改善公共服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;斯塔默説，英國將建造更多實驗室、數據中心，以更快速度推進人工智能技術發展。2023 年，英國人工智能行業增速是其他經濟領域的 30 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除大力投資建設相關基礎設施外，斯塔默還宣佈，英國將與 11 家大型企業合作，以期在未來五年培訓 750 萬名人工智能從業人員。英國還將推出新的「科技優先培訓計劃」，這意味着多達 100 萬年輕人將接受科技技能培訓，人工智能技術培訓將貫穿英國教育體系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;美國英偉達公司總裁兼首席執行官黃仁勳當天在開幕式上表示，英偉達計劃在英國布里斯托爾打造人工智能實驗室。斯塔默説，此舉將有助於推動英國西南地區的就業和發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一年一度的倫敦科技周是英國政府支持的大規模科技盛會。主辦方表示，本屆科技周將迎來 125 個國家和地區的約 3 萬名與會者。（新華社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354644</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354644</guid>
      <pubDate>Sun, 11 May 2025 08:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克稱用 Grok AI 技術優化 𝕏 平台的內容推薦系統</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;6 月 10 日，埃隆・馬斯克在&amp;nbsp;&lt;span&gt;𝕏&amp;nbsp;&lt;/span&gt;&lt;span&gt;平台上發佈了一系列推文，宣佈引入 Grok AI 技術，以優化&amp;nbsp;&lt;/span&gt;&lt;span style="color:#0f1419"&gt;𝕏&amp;nbsp;&lt;/span&gt;&lt;span&gt;平台的內容推薦系統。這一舉措旨在提升平台的整體內容質量，讓更多優質內容得到展示。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;馬斯克在推文中表示：「如果你對將先進 AI 應用於&amp;nbsp;&lt;span&gt;𝕏&amp;nbsp;&lt;/span&gt;&lt;span&gt;平台的內容推薦系統感興趣，請加入我們！正確地實現這一目標對於提升人類的集體智慧至關重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/164022_d5Yj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;他進一步&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1932144751371038919" target="_blank"&gt;解釋道&lt;/a&gt;，&lt;strong&gt;隨着推薦算法更多地使用 Grok AI，用户將開始在自己的信息流中看到更多來自小型賬號的優質內容&lt;/strong&gt;。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;這一消息引發了廣泛關注，許多用户和內容創作者對這一變化表示期待，認為這將為平台帶來更多的多樣性和創新。同時，也有部分用户擔心算法調整可能帶來的不確定性，希望平台能夠確保推薦內容的質量和多樣性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354637</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354637</guid>
      <pubDate>Sun, 11 May 2025 08:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OmniTools —— 自託管的強大網頁工具集合</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OmniTools，這是一款自託管的 Web 應用，提供各種在線工具來簡化日常任務。無論是編寫代碼、處理圖片/視頻、PDF 還是處理數字，OmniTools 都能滿足你的需求。這裏是&lt;a href="https://omnitools.app/"&gt;演示&lt;/a&gt;網站。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;無廣告，無追蹤，只需通過瀏覽器即可快速訪問實用工具。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所有文件均在客户端完全處理：所有內容都不會離開你的設備。此外，Docker 鏡像非常輕量，僅 28MB，可快速部署並輕鬆實現自託管。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="580" src="https://static.oschina.net/uploads/space/2025/0609/154328_gGI0_4252687.png" width="1203" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/omni-tools</link>
      <guid isPermaLink="false">https://www.oschina.net/p/omni-tools</guid>
      <pubDate>Sun, 11 May 2025 08:34:00 GMT</pubDate>
    </item>
    <item>
      <title>蘋果 WWDC 25 視覺智能 AI 升級開放，微美全息以多模態模型驅動場景革新提升競爭力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;6 月 10 日消息，蘋果召開 WWDC 2025 全球開發者大會，更新了全產品線的軟件系統，包括 iOS、VisionOS、tvOS、WatchOS、iPadOS、MacOS 等，首次進行了命名以及視覺化的兩大統一。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//05cf88114ab3892d47bdab673ad84b1e.png" width="719" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;AI 方面宣佈的最大消息是蘋果確認計劃向開發者開放 Apple Intelligence 基礎模型，將允許應用程序開發者使用底層的 Apple Intelligence 技術編寫自己的軟件和功能。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//677d6dd42f53c728bbceaeb21923dedd.png" width="683" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;另外，在發佈會上，蘋果為旗下操作系統引入了全新的視覺化設計，名為 Liquid Glass，這是蘋果首次推出各系統通用的設計，也讓視覺效果更加和諧統一。蘋果的 Liquid Glass 的全新操作系統界面，稱這是該公司迄今為止最全面的設計更新。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//e00afd42b0cb7daa7dbfff7b4f8c8c01.png" width="662" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;行業方面，以大模型為核心的人工智能技術飛速發展，成為推動經濟發展的新引擎。從技術方向來看，AI（人工智能）大模型正朝着多模態、專業化、通用化以及大小模型協同的方向發展。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;多模態大模型能夠處理多種模態的數據，實現更加複雜的智能任務；專業化大模型針對特定行業或領域的需求進行定製和優化；通用化大模型旨在實現跨領域的智能應用；而大小模型協同是未來 AI 大模型發展的重要方向之一。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;此外，科技巨頭同業陸續已展開軍備競賽，如 Meta 主要依賴自主研發與開源策略推進 AI 技術發展，微軟向 OpenAI 注資逾 130 億美元，谷歌母公司 Alphabet 則向競爭對手 Anthropic 投入數十億美元。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//fd4afefc670aed4059aeba94b8a0130b.png" width="719" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;與此同時，資料顯示，微美全息（WIMI.US）作為 AI 多模態技術領域的領先企業，通過技術創新與生態佈局，正在加速 AI 大模型在多個行業的深度應用。當前，微美全息通過多模態技術重構影視、廣告等內容生產流程，並與金融、汽車、教育等行業合作定製解決方案，具有獨特的技術路線和應用場景，能夠在 AI 領域實現持續突破和創新。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;在 AI 競賽愈發激烈的當下，WWDC 25，是蘋果用一場全平台的視覺大換血和 AI 能力的逐步開放，展現了其在 AI 時代的獨特選擇。不過，與 Google、OpenAI、Anthropic 等對手相比，蘋果尚未拿出真正讓人驚豔的 AI 殺手鐧，所以，接下去其終究能在 AI 趨勢下取得一席之地，就請拭目以待。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354619</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354619</guid>
      <pubDate>Sun, 11 May 2025 07:21:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>蘋果發佈 Containerization：在 macOS 上運行 Linux 容器的 Swift 框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Containerization 是 Swift 編寫的容器運行時，用於在 macOS 上運行 Linux 容器。使用了 Apple 芯片的 Virtualization.framework。&lt;/p&gt;

&lt;p&gt;Containerization 提供的 API 用於：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;管理 OCI 鏡像&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;與遠程註冊中心交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;創建並填充 ext4 文件系統&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;與 Netlink 套接字家族交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;創建針對快速啓動時間優化的 Linux 內核&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成輕量級虛擬機&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;管理虛擬機的運行時環境&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成並與容器化進程交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 Rosetta 2 在 Apple 芯片上執行 x86_64 進程&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Containerization 框架賦予開發者直接在 Mac 上創建、下載或運行容器鏡像的能力，其基於針對 Apple 芯片優化的開源框架構建，能夠對容器映像進行安全隔離。&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f12698847fd251962a8dabcb596a127209c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/containerization</link>
      <guid isPermaLink="false">https://www.oschina.net/p/containerization</guid>
      <pubDate>Sun, 11 May 2025 07:17:00 GMT</pubDate>
    </item>
    <item>
      <title>擁抱 AI 協同：盈米如何打造開放生態平台的底層邏輯與實踐路徑</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;近日，由阿里雲主辦、盈米基金協辦的「AI 勢能 Tech Day·財富管理專場」閉門研討會在廣州舉行。30 家國內頂尖金融機構的大模型專家、技術負責人蔘加了會議，共同探討大模型技術在證券、基金、銀行等財富管理領域的金融+AI 創新應用與實踐，融合「技術突破+業務升級」雙重視角，為未來構建開放共享的財富管理新生態探尋對策思路。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;盈米基金聯合創始人、副總裁兼技術負責人劉永，副總裁、且慢業務負責人林傑才，高級技術總監梁仲智、吳珂皓以及且慢產品負責人辜騰玉等出席本次會議。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;會上，盈米基金高級技術總監梁仲智發表主題演講《盈米 AI 開放生態平台——盈米的 AI 協同轉型探索》，深度剖析了企業在 AI 革命浪潮下的協同轉型路徑。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;他系統性地闡述了從 AI 輔助業務到 AI 協同業務，再到 AI 主導業務的演進路徑，並分享了盈米基金開放生態平台及盈米 MCP Server 的構建思路與實踐成果。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;「AI 協同轉型並非只是簡單的技術引入，而是一場涉及企業能力認知、組織架構乃至生產關係的深刻變革。其核心在於面向 AI 進行企業能力‘再資產化’，構建開放的協同生態。」梁仲智表示。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;br&gt; &lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//ba60a4ed2e8b35d19610198d41c99b18.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜盈米基金高級技術總監梁仲智發表主題演講《盈米 AI 開放生態平台——盈米的 AI 協同轉型探索》）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;01 AI 協同轉型，一場智力領域的"工業革命"&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;在 AI 技術深度賦能金融業的當下，財富管理行業正經歷前所未有的智能化變革。梁仲智將這輪 AI 變革浪潮比喻為&lt;strong&gt;繼工業革命之後的"智力革命"。&lt;/strong&gt;如果説工業革命用機器替代了體力勞動，實現了大規模自動化生產，那麼 AI 革命則將在智力層面實現類似的跨越。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//b68cb56f77c2e35d6f1d1a2b5c7c293a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;他進一步闡述，在 2024 年之前，AI 更多被我們視為高級搜索工具，與業務的融合度並不高。而從今年（2025 年）開始，企業應該要開始推動 AI 的協同轉型，即將所有業務的設計、運作全流程都與 AI 協同生產，實現從搜索工具到智力引擎的跨越。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;基於 Scaling Law 這一人工智能領域的核心理論，梁仲智預測，未來 AI 或將主導大部分的業務，而人類則更多扮演一個監督者的角色，這也就意味着之後團隊的「智力」生產力將不再受限於人力資源。企業可以將業務的最佳 SOP 進行 Agent 化，僅需投入相應算力資本，就能獲得穩定高質量的智力生產力，且這種增長是非線性的。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;以合規審核為例，傳統模式下人力投入隨審核量線性增加，而通過 AI 固化 SOP 後，審核能力不再受限於人力，只需投入算力即可實現規模化處理。&lt;strong&gt;「我們的目標是從‘車間工人’轉變為‘車間主管’，學會駕馭這個新質生產力。」&lt;/strong&gt;梁仲智表示。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;02 AI 協同轉型的核心：面向 AI 的企業能力「再資產化」&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;要想實現 AI 協同業務，最關鍵的是在於讓 AI 能夠獲取企業的數據和調用核心業務接口。為此，梁仲智提出了一個概念——&lt;strong&gt;面向 AI 的企業能力「再資產化」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//a13c426264b9f02aeea5fe3243ec8b08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜盈米 AI 開放平台系統）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;對於什麼是能力的「再資產化」？他進一步解釋道，當前在企業內部其實存在大量分散、未協同的數據和接口，且形式各異、錯綜複雜。AI 協同轉型的首要任務便是將這些孤立的數據和能力進行集中管理，並通過 AI 技術來實現快速、低成本的資產治理。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;梁仲智介紹，許多企業現有的數據和接口最初是為機器而非 AI 設計的，若不經處理 AI 是難以理解其具體含義。因此，所有接口都需要進行集中處理使其對 AI 友好。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;以盈米基金為例，將適合 AI 調用的接口規範通過 prompt 交給 AI，讓 AI 自動完成接口的改造，全程無需人工操作。這種 AI 協作的方式極大地提升了效率，使得公司一半的接口在兩天內便完成了接入。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;在完成公司的資產治理和接口改造後，盈米將數據、算法、工具、內容、投研、投顧服務等核心能力，通過 MCP 協議和 OpenAPI 協議向 AI 開放。如此一來，在盈米內部各業務團隊可便捷地使用這些能力，去賦能特定的業務場景，最終實現與 AI 的深度協同發展。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;作為一家基金投顧公司，同時也是一家金融科技公司，盈米基金不僅是金融 AI 的先行者，更是佈道者。在完成企業能力「再資產化」後，盈米在 2025 年 3 月推出了 AI 開放平台，將自身沉澱多年的金融能力、數據和工具對外開放共享，&lt;strong&gt;旨在讓更多人能夠輕鬆構建和使用專業級金融 AI 應用，享受 AI 協同與自動化的智能財富管理服務。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;03 AI 協同，為什麼會走向對外開放？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;談及為何要構建 AI 開放平台，梁仲智舉了一個形象的例子來説明這個問題：「設想在未來，我下班開車回家的時候，跟我的智能眼鏡説：‘剛發工資，最近有什麼投資產品推薦的？’AI 回覆：‘我調用了盈米 MCP 的工具查詢，結合你目前的情況，我認為 A 產品挺適合。同時我發現你安裝了 X 投資 App，但由於它沒有提供任何工具，我無法給予你相關推薦，你可以自行打開 APP 查看’。」&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;相較於傳統的 APP 操作系統，只能提供應用入口，不能提供直接、具體的服務，這也是我們詬病「人工智能不智能」的原因所在。而未來的 AI 則應該更有自主權和決策權，自身就能靈活決定和操作業務的邏輯和服務的形態。這麼一來&lt;strong&gt;，對 AI 開放就變得尤為重要。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;梁仲智認為，「開放」應該具有三重含義：&lt;strong&gt;對內開放、對外開放，以及對 AI 開放。&lt;/strong&gt;對內開放，就是內部賦能，打破部門牆；對外開放，是構建外部的生態系統；而最核心的是對 AI 開放，需要把企業內部所有的東西都向 AI 開放，才能實現真正的 AI 協同轉型。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//ddfea33af22308f7f4f241d133de3aeb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜盈米對外開放的三重含義）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;對於如何構建 AI 開放平台？梁仲智分享道，「盈米 AI 開放平台的底層涵蓋了企業數據、交易能力、投研投顧能力等。通過治理和再資產化，這些能力進入 API 層，轉化為 AI 可調用和使用的形態。然後，在網關層將這些能力以合適協議（如 MCP 協議）向外暴露。」&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;盈米且慢 MCP Server 作為盈米 AI 開放平台的一部分，已於今年 4 月在阿里雲百鍊平台首發上線，並陸續入駐了&lt;strong&gt;火山引擎、百度 AI 助手、魔搭社區等主流平台&lt;/strong&gt;。用户也可以在 Cursor、Trae、CherryStudio、Dify 等平台便捷地接入使用。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;盈米且慢 MCP Server&amp;nbsp;首批提供了 30 多個金融工具，涵蓋投研、投顧、金融數據等維度，核心能力包括資產診斷與配置、金融資訊與觀點、基金數據以及回測和蒙特卡洛測算等投研能力，與 AI 大模型的優勢形成互補。&lt;strong&gt;目前已有上千名用户申請使用盈米且慢 MCP 工具。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//5783079b5144c469fb066b550d542520.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜盈米且慢 MCP4 月上線阿里雲百鍊平台）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;隨後，梁仲智分享了幾個投顧業務與 AI 協同落地的實踐案例。在財富管理領域，因為投顧服務的非標性，不同客户的目標、需求都不一樣，要做到千人千面，就需要真人顧問來把關和服務。如果按照過去簡單的自動化解決方案，不僅漏損率高，而且轉人工服務的幾率也大。在實現了投顧業務與 AI 協同之後，效率和服務質量將得到大幅提升。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//f3c52ddd45dcf25746276a9c6fe75b49.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜通過盈米且慢 MCP 生成的資產診斷報告，部分展示｜僅作釋義，不作為任何投資建議）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;財務規劃報告提效&lt;/strong&gt;：過去，投顧為客户出具一份完整的財務報告平均需要 3 小時。現在，通過將所需數據和 SOP 封裝成 MCP 之後供 AI 調用。通過盈米且慢 MCP，只需幾句大白話與 AI 協同，3 分鐘內即可生成報告初稿，投顧在此基礎上再進行個性化調整，確認無誤後就能發給特定的客户。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="如圖片無法顯示，請刷新頁面" src="https://oscimg.oschina.net/oscnet//81136abcafea5fcb2a540eec783e01f0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜通過盈米且慢 MCP 生成的基金季度分析報告，部分展示，作者：大白君的奇思妙想｜僅作釋義，不作為任何投資建議。）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;基金研究報告自動化&lt;/strong&gt;：研究員過去需要花費數小時才能完成一份全面的基金季度研究報告，如今通過盈米且慢 MCP，在幾分鐘內即可生成專業的基金研究報告。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//6c03be711ecf324cb938ae9df65f9043.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜且慢 AI 智能助手「AI 小顧」）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;AI 小顧能力再升級&lt;/strong&gt;：基於 Qwen 大模型打造的且慢「AI 小顧」，在接入盈米且慢 MCP 後，AI 小顧的回答準確率大幅提升至 90% 以上，有效降低了客户服務「轉人工」的比例。截至目前，且慢「AI 小顧」累計服務超 10 萬名用户，解決客户問題超 100 萬次。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;04 AI 協同轉型帶來的深層變革：重塑生產關係&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;當 AI 協同使得生產力極大提升之後，又會如何影響我們的生產關係？&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;梁仲智最後分享了他對 AI 協同轉型帶來的深層影響的思考。他認為未來在企業的組織結構、工程管理、激勵機制和合作生態等方面將進行全面的重構。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//182794e937af9c192eb99c58ef885ca0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;（圖｜盈米基金高級技術總監梁仲智發表主題演講）&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;組織結構調整&lt;/strong&gt;：未來的職場角色可能向兩端收縮。一部分人專注於服務 AI，為 AI 提供數據、封裝 API；另一部分人則深入業務，直接負責交付結果，中間負責翻譯和傳話的角色將減少。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;軟件工程變革&lt;/strong&gt;：在軟件管理方面，文檔將成為核心資產，因為代碼的生成成本在降低；管理工具和職責分工也將隨之重構。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;人才篩選與激勵機制調整&lt;/strong&gt;：未來對員工編碼技巧的價值可能會下降，而對業務理解和表達能力的要求將會相應提升。同時，員工中可能會出現「超級個體」，這就需要企業及時調整考核激勵機制。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;外部合作生態重塑&lt;/strong&gt;：傳統 SaaS 服務的價值可能因成本大幅降低而減弱，未來企業考慮合作的重點，應該轉向構建面向知識的生態系統以及業務 SOP 的梳理與沉澱。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;05 擁抱 AI 變革，共創智能財富管理新未來&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;綜述所述，盈米基金的 AI 協同轉型實踐，一定程度上為財富管理行業提供了有效的樣本。無論是從企業能力「再資產化」，到 AI 開放平台建設；還是從 MCP Server 的率先推出，到投顧服務的效率革命，盈米基金用自身的實際行動詮釋了什麼是真正的 AI 協同轉型。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;而這場"智力革命"的意義是遠超技術層面的，它也正在重新定義企業的組織形態和價值創造方式。正如梁仲智所言，我們需要從「車間工人」轉變為「車間主管」，學會駕馭 AI 這一「新質生產力」。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;面對這場深刻的 AI 變革，企業需要主動擁抱和積極探索自身與 AI 的協同路徑。未來的財富管理行業，必將是人機協同、AI 智能驅動的新生態。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;而這個未來，正在加速到來。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//1efa6c1028ec73d48de35a46fb2d356f.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354617</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354617</guid>
      <pubDate>Sun, 11 May 2025 07:16:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>阿里通義實驗室開源檢索增強預訓練框架 MaskSearch</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義實驗室&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjabNf48U-HoN9W648dmX2Q" target="_blank"&gt;發佈&lt;/a&gt;並開源了 MaskSearch 預訓練框架，聲稱能讓 AI 學會「主動搜索 + 多步推理」，從而更準確、更智能地回答複雜問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="385" src="https://oscimg.oschina.net/oscnet/up-66d5bfa06d72ffa4b1078a43c0bdfd45eba.webp" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據介紹，MaskSearch 的核心在於它提出的一種全新預訓練任務——&lt;strong&gt;檢索增強掩碼預測（RAMP）&lt;/strong&gt;&amp;nbsp;，在這個任務中，模型需要填補句子中的掩碼部分，並且必須通過主動搜索和多步推理來完成任務。&lt;/p&gt; 
&lt;p&gt;&lt;img height="403" src="https://oscimg.oschina.net/oscnet/up-fc9d9a6a5fdacfd87e065f2589f2309ab08.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="color:#4a4a4a"&gt;&lt;span&gt;例如，給定一個句子：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;Andrew Barto received his&amp;nbsp;&lt;span&gt;[mask]&lt;/span&gt;&amp;nbsp;with distinction in&amp;nbsp;&lt;span&gt;[mask]&lt;/span&gt;&amp;nbsp;&lt;span style="color:#ca7d37"&gt;from&lt;/span&gt;&amp;nbsp;the University of Michigan in&amp;nbsp;&lt;span style="color:#0e9ce5"&gt;1970&lt;/span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="color:#4a4a4a"&gt;&lt;span&gt;AI 需要通過搜索引擎查找相關信息，逐步推理出被遮蓋的部分。模型首先分析上下文，判斷需要查找的信息是「學位類型」和「專業方向」。隨後，它調用搜索引擎進行查詢，得到關於 Andrew Barto 的相關信息，並從中提取出關鍵片段：「Andrew Barto, B.S., math, University of Michigan, 1970」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="color:#4a4a4a"&gt;&lt;span&gt;接着，AI 進行推理整合，最終填補掩碼輸出完整句子：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span style="color:#dd1144"&gt;Andrew&lt;/span&gt;&amp;nbsp;&lt;span style="color:#dd1144"&gt;Barto&lt;/span&gt;&amp;nbsp;received his B.&lt;span&gt;S&lt;/span&gt;.&amp;nbsp;&lt;span style="color:#ca7d37"&gt;with&lt;/span&gt;&amp;nbsp;distinction&amp;nbsp;&lt;span style="color:#ca7d37"&gt;in&lt;/span&gt;&amp;nbsp;math&amp;nbsp;&lt;span style="color:#ca7d37"&gt;from&lt;/span&gt;&amp;nbsp;the&amp;nbsp;&lt;span style="color:#dd1144"&gt;University&lt;/span&gt;&amp;nbsp;&lt;span style="color:#ca7d37"&gt;of&lt;/span&gt;&amp;nbsp;&lt;span style="color:#dd1144"&gt;Michigan&lt;/span&gt;&amp;nbsp;&lt;span style="color:#ca7d37"&gt;in&lt;/span&gt;&amp;nbsp;&lt;span style="color:#0e9ce5"&gt;1970&lt;/span&gt;。&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;實驗表明，即使是小模型（如 Qwen2.5-1.5B），在經過 MaskSearch 預訓練後，也能在多個開放域問答任務中取得顯著提升。例如，在 Bamboogle 數據集中性能提升超過 11.78% ，真正做到了「小模型也能挑戰大模型」。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;img height="354" src="https://oscimg.oschina.net/oscnet/up-b3ddb53ca899c492045ff28febdbd54f73f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354614</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354614</guid>
      <pubDate>Sun, 11 May 2025 07:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>蘋果設備端和服務器端基礎語言模型的更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文翻譯自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmachinelearning.apple.com%2Fresearch%2Fapple-foundation-models-2025-updates" target="_blank"&gt;https://machinelearning.apple.com/research/apple-foundation-models-2025-updates&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ab638eada802c4871bb91a726b10d31eabc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;藉助 Apple Intelligence，我們將在人們每天使用的應用和體驗中集成強大的生成式人工智能，同時保護用户的隱私。在 2025 年全球開發者大會（WWDC）上，我們推出了一代全新的語言基礎模型，這些模型專門設計用於增強我們最新軟件版本中的 Apple Intelligence 特性。我們還推出了新的 Foundation Models 框架，該框架讓應用開發者可以直接訪問 Apple Intelligence 核心的設備端基礎語言模型。&lt;/p&gt; 
&lt;p&gt;我們構建了這些生成模型，以支持我們在各平台中集成的廣泛智能功能。這些模型提升了工具使用和推理能力，能夠理解圖像和文本輸入，運行更快且更高效，並且支持 15 種語言。我們的最新基礎模型經過優化，可在 Apple 芯片上高效運行，包括一個緊湊型的、約 30 億參數的模型，以及一個基於服務器的混合專家模型，其架構專為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecurity.apple.com%2Fblog%2Fprivate-cloud-compute%2F" target="_blank"&gt;私有云計算&lt;/a&gt;設計。這兩個基礎模型是蘋果為支持我們的用户而創建的更大生成模型家族的一部分。&lt;/p&gt; 
&lt;p&gt;在此概述中，我們詳細介紹了我們設計的模型架構、用於訓練的數據、所採用的訓練配方、用於優化推理的技術，以及與同類模型相比的評估結果。在整個過程中，我們強調瞭如何在設備和私有云計算上實現速度和效率的提升，同時擴展了能力並提高了質量。最後，在我們持續致力於維護核心價值觀的承諾下，我們展示了負責任的人工智能原則如何貫穿整個模型開發過程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d77e148d22b633cb086c702429e723f9622.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;圖 1：蘋果基礎模型的建模概述&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型架構&lt;/h2&gt; 
&lt;p&gt;我們開發了設備端和服務器模型，以滿足廣泛的表現和部署需求。設備端模型針對效率進行了優化，並針對 Apple 芯片進行了定製，使推理具備低延遲且資源使用極少的特性，而服務器模型則設計用於提供高準確性和可擴展性，以處理更復雜的任務。共同而言，它們構成了一個互補的解決方案集，能夠適應多種應用場景。&lt;/p&gt; 
&lt;p&gt;我們通過開發新的模型架構，提高了兩種模型的效率。對於端側模型，我們將完整模型分成兩個塊，深度比例為 5:3。塊 2 的所有鍵值（KV）緩存都直接與塊 1 最終層生成的 KV 緩存共享，從而將 KV 緩存的內存使用量減少了 37.5%，顯著提高了首次令牌生成時間。我們還為服務器模型開發了新的架構，引入了並行軌道混合專家（PT-MoE）設計（見&lt;a href="https://www.oschina.net/news/354610/apple-foundation-models-2025-updates#figure2"&gt;圖 2&lt;/a&gt;）。該模型由多個較小的 Transformer 組成，稱為軌道，這些軌道獨立處理令牌，僅在每個軌道塊的輸入和輸出邊界進行同步。每個軌道塊還具有自己的 MoE 層。結合軌道獨立性帶來的軌道級並行性，這種設計顯著減少了同步開銷，使模型能夠高效擴展，同時在不犧牲質量的情況下保持低延遲。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0c199164ae8858ba38229a44aa3a9b9c5e2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;圖 2：PT-MoE 架構示意圖。每個軌道由多個軌道塊組成，每個軌道塊包含固定數量的 transformer/MoE 層。假設總共有 L 層和軌道塊深度 D，那麼我們從 2L（張量並行）的同步開銷減少到 L/D（軌道並行）。例如，如果 D = 4，PT 可將同步開銷減少 87.5%。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;為支持更長的上下文輸入，我們設計了一種交錯注意力架構，結合滑動窗口局部注意力層、旋轉位置嵌入（RoPE）和無位置嵌入（NoPE）的全局注意力層。這種設置提高了長度泛化能力，減少了 KV 緩存大小，並在長上下文推理中保持模型質量。&lt;/p&gt; 
&lt;p&gt;為了啓用視覺能力，我們開發了一個在大規模圖像數據上訓練的視覺編碼器。它由一個用於提取豐富特徵的視覺主幹網絡和一個將特徵與 LLM 的標記表示對齊的視覺-語言適配器組成。我們使用標準的 Vision Transformer（ViT-g）作為服務器模型，參數量為 10 億；而用於設備端部署的更高效 ViTDet-L 主幹網絡參數量為 3 億。為了進一步有效捕捉並整合局部細節和更廣泛的全局上下文，我們在標準的 ViTDet 中添加了一個新穎的註冊窗口（RW）機制，使得全局上下文和局部細節都能被有效捕捉。&lt;/p&gt; 
&lt;h2&gt;訓練數據&lt;/h2&gt; 
&lt;p&gt;我們相信通過使用多樣且高質量的數據來訓練我們的模型。這包括我們從出版商處獲得許可的數據、從公開可用或開源數據集精心整理的數據，以及由我們的網絡爬蟲 Applebot 爬取的公開信息。我們在訓練基礎模型時不會使用用户的私人個人數據或用户交互數據。此外，我們採取措施應用過濾器，以刪除某些類別的人口識別信息，並排除粗俗和不安全的內容。&lt;/p&gt; 
&lt;p&gt;此外，我們繼續遵循倫理網絡爬蟲的最佳實踐，包括遵循廣泛採用的 robots.txt 協議，允許網頁發佈者選擇性地退出其內容被用於訓練 Apple 的生成基礎模型。網頁發佈者可以對 Applebot 可以查看的頁面以及這些頁面如何被使用進行精細控制，同時這些頁面仍會出現在 Siri 和 Spotlight 的搜索結果中。&lt;/p&gt; 
&lt;h3&gt;文本數據&lt;/h3&gt; 
&lt;p&gt;儘管如上所述保留了某些排除項，我們繼續從由 Applebot 抓取的網絡內容中獲取我們模型預訓練數據的重要部分，這些內容涵蓋了數百億頁的網頁，涉及廣泛的語言、地區和主題。鑑於網絡內容的雜亂性，Applebot 採用了先進的抓取策略，以優先獲取高質量和多樣化的網頁內容。特別是，我們專注於捕獲高保真度的 HTML 頁面，這些頁面豐富了數據集，不僅包含文本，還包含結構化的元數據，以對媒體內容與周圍文本內容進行對齊。為了提高相關性和質量，系統利用了多種信號，包括基於領域級別的語言識別、主題分佈分析以及 URL 路徑模式的啓發式方法。&lt;/p&gt; 
&lt;p&gt;我們特別注重準確地從文檔和現代網站中提取內容。我們通過無頭渲染增強了文檔集合，實現了全頁加載、動態內容交互和 JavaScript 執行，這對於從網頁架構中提取數據至關重要。對於依賴動態內容和用户交互的網站，我們啓用了完整的頁面加載和交互模擬，以可靠地從複雜頁面中提取有意義的信息。我們還將在提取流程中整合大型語言模型（LLMs），尤其是在領域特定文檔中，因為它們通常比傳統基於規則的方法表現更佳。&lt;/p&gt; 
&lt;p&gt;除了先進的爬蟲策略，我們還顯著擴大了訓練數據的規模和多樣性，並納入了大量高質量的通用領域、數學和編程內容。我們還擴展了多語言支持，以支持即將在今年下半年推出的新的語言。&lt;/p&gt; 
&lt;p&gt;我們認為高質量的過濾在整體模型性能中起着關鍵作用。我們通過減少對過於激進的啓發式規則的依賴，並引入更多基於模型的過濾技術，優化了我們的數據過濾流程。通過引入基於模型的信號，我們能夠保留更多具有信息量的內容，從而獲得更大規模且質量更高的預訓練數據集。&lt;/p&gt; 
&lt;h3&gt;圖像數據&lt;/h3&gt; 
&lt;p&gt;為了增強我們的模型，併為 Apple Intelligence 功能提供視覺理解能力，我們將在預訓練流程中引入圖像數據，利用高質量的授權數據以及公開可用的圖像數據。&lt;/p&gt; 
&lt;p&gt;使用我們的網頁爬蟲策略，我們獲取了帶有對應 alt 文本的圖像對。除了過濾以確保符合法律要求外，我們還過濾了數據質量，包括圖像與文本的一致性。去重後，這一過程產生了超過 100 億對高質量的圖像-文本對。此外，我們通過保留從爬取文檔中原始觀察到的文本上下文來創建圖像-文本交錯數據。在過濾質量和法律合規性後，這產生了 1.75 億個交錯的圖像-文本文檔，包含超過 5.5 億張圖像。由於網絡爬取的圖像-文本對通常較短，且往往無法全面描述圖像的視覺細節，我們使用合成圖像描述數據來提供更豐富的描述。我們開發了一個內部的圖像描述模型，能夠提供不同細節層次的高質量描述，從關鍵詞到段落級的全面描述，生成了超過 50 億個圖像-描述對，這些數據被用於預訓練的各個階段。&lt;/p&gt; 
&lt;p&gt;為提高模型在文本豐富的視覺理解方面的能力，我們整理了多種文本豐富的數據集，包括通過授權數據、網絡爬蟲和內部合成方式獲取的 PDF、文檔、手稿、信息圖、表格和圖表。我們隨後從圖像數據中提取文本，並從圖像數據中生成轉錄文本和問答對。&lt;/p&gt; 
&lt;p&gt;我們整理了多種圖像-文本數據類型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高質量標題數據和基於語義的標題&lt;/strong&gt;：我們使用對比語言-圖像預訓練（CLIP）模型和光學字符識別（OCR）工具作為過濾器，從上述合成圖像標題數據中獲取高質量圖像。然後，我們使用內部的定位模型對標題中的名詞進行定位，並在名詞後附加座標，形成基於語義的標題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;表格、圖表和圖表&lt;/strong&gt;：對於圖表和圖表，我們首先讓內部的 LLM 生成合成數據字段和相應的值，然後讓 LLM 編寫代碼，根據之前合成的數據樣本生成各種類型的圖表和圖表。最後，我們將圖表、圖表和數據樣本輸入教師模型，以生成用於模型訓練的問答對。對於表格，我們從公開網站中解析表格並將其轉換為 markdown，然後使用教師模型生成的圖像-markdown 配對以及圖像-合成問答對用於模型訓練。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;預訓練&lt;/h2&gt; 
&lt;p&gt;我們的預訓練配方已演進，以擴展 Apple Intelligence 能力，支持更多語言以及更廣泛的功能，包括需要圖像理解的功能。&lt;/p&gt; 
&lt;p&gt;預訓練在多個階段進行，其中第一個且計算需求最高的階段僅針對文本模態。我們使用蒸餾損失訓練設備端模型，但沒有采用大型密集模型作為教師模型並從頭開始預訓練，而是利用少量最高質量的文本數據，對一個預訓練的約 3B 模型中的 64 個專家、每兩層混合專家（MoE）進行稀疏升維處理。這將教師模型的訓練成本降低了 90%。然而，我們從頭開始在 14T 文本標記上訓練了稀疏服務器模型。&lt;/p&gt; 
&lt;p&gt;為了更好地支持新語言，我們在這一階段將文本分詞器的詞彙量從 10 萬擴展到 15 萬，僅用 25% 更多的標記，就實現了對許多額外語言的表示質量。為了實現視覺感知，我們使用 CLIP 風格的對比損失訓練了設備端和服務器端的視覺編碼器，對 60 億張圖像-文本對進行對齊，從而得到了具有良好視覺基礎的編碼器。&lt;/p&gt; 
&lt;p&gt;在預訓練的第二階段，我們使用一個小的解碼器，將視覺編碼器與一個視覺-語言適應模塊聯合訓練，利用高質量文本數據、交錯的圖像-文本數據和領域特定的圖像-文本數據，對圖像特徵與模型表示空間進行對齊。然後，我們利用這些視覺編碼器和預訓練模型，提升代碼、數學、多語言、長上下文理解能力，並通過多個連續的預訓練階段融入圖像理解。&lt;/p&gt; 
&lt;p&gt;在持續預訓練階段，我們調整了數據集的混合比例，同時結合經過驗證正確的合成數據，以提升代碼、數學和多語言能力。隨後，我們通過多模態適應引入了視覺理解，而不會損害模型的文本能力。在此階段，我們從頭開始訓練了一個視覺-語言適應模塊，以連接視覺編碼器到兩個模型。在最終的持續預訓練階段，我們訓練模型以處理顯著更長的上下文長度，使用最多 65K 個標記的序列，這些序列來自自然發生的長格式數據、專門針對特定能力設計的合成長格式數據，以及之前預訓練輪次中的混合數據。&lt;/p&gt; 
&lt;h2&gt;後訓練&lt;/h2&gt; 
&lt;p&gt;與我們在預訓練中的方法類似，我們演進我們的後訓練流程，以支持語言擴展和視覺理解。&lt;/p&gt; 
&lt;p&gt;我們通過結合人工編寫的數據示例和合成數據對監督微調（SFT）進行了擴展，重點提升核心視覺能力。這包括常識知識、推理、文本豐富的圖像理解、文本與視覺定位，以及多圖像推理。我們進一步通過檢索額外圖像併合成其對應的提示和響應，來增強視覺 SFT 數據的多樣性。&lt;/p&gt; 
&lt;p&gt;我們利用這一 SFT 階段進一步啓用工具使用和多語言支持。我們設計了一種過程監督標註方法，其中標註人員向工具使用代理平台發起查詢，返回平台的完整軌跡，包括工具調用細節、相應的執行響應以及最終響應。這使標註人員能夠檢查模型的預測並糾正錯誤，從而生成一個樹狀結構的數據集用於教學。為了擴展到更多語言，我們默認將輸出語言與輸入語言匹配，但我們也通過創建一個包含多種語言的多樣化數據集，啓用了提示和響應使用不同語言的選項。&lt;/p&gt; 
&lt;p&gt;我們在 SFT 階段之後，對設備端模型和服務器端模型均應用了基於人類反饋的強化學習（RLHF）。同時，我們提出了一種基於模型多輪生成獎勵方差的新型提示選擇算法，用於為 RLHF 訓練定製提示數據集。我們的評估結果顯示，RLHF 在人類和自動基準測試中均帶來了顯著提升。此外，儘管我們在 SFT 和 RLHF 階段均引入了多語言數據，但我們發現 RLHF 在 SFT 基礎上提供了顯著提升，導致人類評估中的勝敗比達到 16:9。&lt;/p&gt; 
&lt;p&gt;為繼續提升模型在多語言性能上的質量，我們使用了指令遵循評估（IFEval）和 Alpaca Evals，並以 GPT-4o 作為評判者。我們收集了每種支持語言中由母語者撰寫的 1000 個提示。通過仔細的提示微調，我們實現了自動評估與人類評估之間的良好對齊，從而加快了迭代速度。&lt;/p&gt; 
&lt;h2&gt;優化&lt;/h2&gt; 
&lt;p&gt;在過去一年中，我們擴展了 Apple Intelligence 的功能，並在提高推理效率、減少設備端和服務器端模型的功耗的同時，提升了模型的質量。&lt;/p&gt; 
&lt;p&gt;我們使用量化感知訓練（QAT）將設備端模型壓縮到每權重 2 位（bpw），採用了一種新穎的可學習權重裁剪和權重初始化組合。服務器端模型則使用了一種基於塊的紋理壓縮方法，稱為自適應可擴展紋理壓縮（ASTC）。雖然 ASTC 最初是為圖形管線開發的，但我們發現它在模型壓縮方面也非常有效。ASTC 解壓過程在 Apple GPU 中實現了專用硬件組件，使權重解碼無需引入額外的計算開銷。&lt;/p&gt; 
&lt;p&gt;對於兩種模型，我們對嵌入表進行了 4 位量化——對於設備端模型，使用 QAT 與基礎權重聯合訓練；而對於服務器端模型，則使用後訓練量化。鍵值緩存（KV cache）每個權重量化為 8 位。然後，我們使用額外的數據訓練低秩適配器，以恢復由於這些壓縮步驟而損失的質量。通過這些技術，我們觀察到一些輕微的質量退化，甚至有微小的提升，例如，對於設備端模型，在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.03057" target="_blank"&gt;MGSM&lt;/a&gt;上出現了約 4.6% 的退化，在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2009.03300" target="_blank"&gt;MMLU&lt;/a&gt;上提升了 1.5%；而對於服務器端模型，在 MGSM 上退化了 2.7%，在 MMLU 上退化了 2.3%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/144031_zIWy_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;表 1. On-Device 和 Server 基礎模型的壓縮和比特率。&lt;/p&gt; 
&lt;h2&gt;基礎模型框架&lt;/h2&gt; 
&lt;p&gt;新的基礎模型框架為開發者提供了訪問權限，使他們能夠使用搭載在設備上的約 30 億參數語言模型，開始創建自己可靠、適用於生產的生成式 AI 功能。Apple Intelligence 核心的約 30 億參數語言基礎模型在多種文本任務上表現出色，例如摘要、實體提取、文本理解、細化、簡短對話、生成創意內容等。它並非設計成一個用於一般世界知識的聊天機器人。我們鼓勵應用開發者使用此框架來構建有助於他們應用的特色功能。&lt;/p&gt; 
&lt;p&gt;我們框架的亮點是一種直觀的 Swift 方法，用於受限解碼，稱為引導生成。通過引導生成，開發者可以直接使用豐富的 Swift 數據結構，只需在 Swift 結構體或枚舉上添加一個&lt;code&gt;@Generable&lt;/code&gt;宏註解。這之所以可行，是因為與模型、操作系統和 Swift 編程語言的垂直集成。它始於 Swift 編譯器宏，這些宏將開發者定義的類型轉換為標準化的輸出格式規範。在提示模型時，框架會將響應格式注入提示中，而模型能夠理解並遵守該格式，因為其在專門設計的引導生成規範數據集上進行了後訓練。接下來，一個操作系統守護進程採用高度優化且互補的受限解碼和推測解碼實現，以提高推理速度，同時確保模型的輸出符合預期格式。基於這些保證，框架能夠可靠地從模型輸出創建 Swift 類型的實例。這通過讓應用開發者編寫更簡單的代碼，而這些代碼又由 Swift 類型系統支持，從而簡化了開發者的體驗。&lt;/p&gt; 
&lt;p&gt;工具調用為開發者提供了定製 ~3B 模型能力的權力，通過創建提供模型特定信息源或服務的工具來實現。&lt;/p&gt; 
&lt;p&gt;框架對工具調用的處理方式基於引導生成。開發者提供簡單的 Tool Swift 協議實現，框架會自動且最優地處理並行和串行工具調用可能帶來的複雜調用圖。模型在工具使用數據上的微調提高了該框架功能的可靠性。&lt;/p&gt; 
&lt;p&gt;我們精心設計了該框架，以幫助應用開發者充分利用設備上的模型。對於需要教會約 3B 模型完全新技能的專用應用場景，我們還提供了一個 Python 工具包，用於訓練排名 32 的適配器。由該工具包生成的適配器與基礎模型框架完全兼容。然而，適配器必須隨着基礎模型的新版本重新訓練，因此在徹底探索基礎模型能力之後，才應在高級應用場景中考慮部署一個適配器。&lt;/p&gt; 
&lt;h2&gt;評估&lt;/h2&gt; 
&lt;p&gt;我們使用人類評估者對我們的設備端和服務器端模型進行了離線質量評估。我們評估了標準的基本語言和推理能力，包括分析推理、頭腦風暴、聊天、分類、封閉式問題和回答、編碼、創意寫作、提取、數學推理、開放式問題和回答、改寫、摘要以及工具使用。&lt;/p&gt; 
&lt;p&gt;隨着我們模型支持的語言和區域的擴展，我們也擴展了評估任務集，使其具有區域特定性。人類評分者評估模型生成的響應是否聽起來符合該區域用户的母語。例如，當一個模型回應來自英國用户的一個英語體育問題時，預期該模型知道「足球」比「足球」更符合當地習慣用語。評分者可以針對模型響應中的多種問題進行標記，包括不當地域化的術語或不自然的短語。區域特定的評估使用了與英語美國區域類似的分類，只是排除了像數學和編程這樣的技術領域，這些領域大多本質上是地域無關的。&lt;/p&gt; 
&lt;p&gt;我們發現，我們的設備端模型在所有語言中均表現良好，優於稍大的 Qwen-2.5-3B 模型，並在英語中與較大的 Qwen-3-4B 和 Gemma-3-4B 模型具有競爭力。我們的服務器端模型在與 Llama-4-Scout 模型的對比中表現良好，Llama-4-Scout 的總大小和活躍參數數量與我們的服務器模型相當，但落後於較大的模型，如 Qwen-3-235B 和專有版本的 GPT-4o。&lt;/p&gt; 
&lt;h3&gt;文本響應的人類評估&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/144120_VNv0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 3：在將 Apple 的基準模型與公開可訪問模型進行並列評估時，文本響應中被首選的響應比例。結果按 3 個地區組呈現，這是我們觀察 Apple Intelligence 國際化方式的一種視角。例如，英語（非美國）包括英國英語、加拿大英語等其他語言。PFIGSCJK 指的是葡萄牙語、法語、意大利語、德語、西班牙語、簡體中文、日語和韓語。&lt;/p&gt; 
&lt;p&gt;隨着我們的模型支持擴展到圖像模態，使用了圖像-問題對的評估集來評估圖像理解能力。該評估集包含與文本評估集相似的類別，以及圖像特定的類別，如信息圖，這些類別挑戰模型對文本豐富的圖像進行推理。我們比較了設備端模型與類似規模的視覺模型，即 InternVL-2.5-4B、Qwen-2.5-VL-3B-Instruct 和 Gemma-3-4B，並將我們的服務器模型與 Llama-4-Scout、Qwen-2.5-VL-32B 和 GPT–4o 進行比較。我們發現，蘋果的設備端模型在與較大的 InternVL 和 Qwen 相比時表現良好，在與 Gemma 競爭時也表現出競爭力，而我們的服務器模型在推理 FLOPS 僅為一半的情況下，優於 Qwen-2.5-VL，但落後於 Llama-4-Scout 和 GPT–4o。&lt;/p&gt; 
&lt;h3&gt;圖像響應的人類評估&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/144211_J6Df_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 4：在將蘋果基礎模型與可比模型進行圖像響應並列評估時，首選響應的比例。&lt;/p&gt; 
&lt;p&gt;除了評估基礎模型的通用能力外，還對適配器進行了特徵特定的評估。例如，考慮基於適配器的視覺智能功能，該功能可以從傳單的圖片中創建日曆事件。收集了一組覆蓋廣泛環境設置、相機角度和其他挑戰性場景的傳單作為評估集。該集用於評估模型準確從傳單中提取信息（包括日期和地點）以正確創建日曆事件的能力。&lt;/p&gt; 
&lt;h2&gt;負責任的人工智能&lt;/h2&gt; 
&lt;p&gt;Apple Intelligence 是在每一步都基於我們的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finvestor.apple.com%2Four_values%2F" target="_blank"&gt;核心價值觀&lt;/a&gt; 設計，並建立在行業領先的隱私保護基礎之上。此外，我們還制定了我們的負責任的人工智能原則，以指導我們如何開發人工智能工具，以及支撐這些工具的模型。這些原則體現在使 Apple Intelligence 成為可能的架構的每一個階段，並連接了功能和工具與專用模型：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;通過智能工具賦能用户：&lt;/strong&gt; 我們識別 AI 可以負責任地用於滿足特定用户需求的領域，並創建相應的工具。我們尊重用户如何選擇使用這些工具來實現他們的目標。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;代表我們的用户：&lt;/strong&gt; 我們打造深度個性化的產品，目標是真實地代表全球的用户。我們持續努力避免在我們的 AI 工具和模型中延續刻板印象和系統性偏見。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;精心設計：&lt;/strong&gt; 在我們的整個流程中，包括設計、模型訓練、特徵開發和質量評估等階段，我們都會採取預防措施，以識別我們的 AI 工具可能被誤用或導致潛在危害的方式。我們將通過用户反饋持續監控並主動改進我們的 AI 工具。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;保護隱私：&lt;/strong&gt; 我們通過強大的設備端處理和突破性的基礎設施，如私有云計算，來保護用户的隱私。我們在訓練基礎模型時，不會使用用户的私人個人數據或用户交互數據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;這些原則指導我們在產品開發週期中的各項工作，影響我們的產品設計、政策、評估和緩解措施。作為蘋果對負責任 AI 的承諾的一部分，我們繼續識別並緩解使用基礎模型固有的風險，例如幻覺和對提示注入的易受性。我們的安全分類法幫助我們識別需要謹慎處理的敏感內容。&lt;/p&gt; 
&lt;p&gt;為評估 Apple Intelligence 的安全性，我們在部署之前評估了基礎模型以及每個使用這些模型的功能。對於基礎模型，我們結合了內部和外部的人類評估與自動評分，並將我們的模型與外部模型進行比較以進行基準測試。我們構建了針對性的安全性評估數據集，以評估基礎模型在摘要、問答和頭腦風暴等任務上的表現，特別是在處理高風險和敏感內容時的表現。對於各個功能，我們設計了專注於用户面對風險的數據集，以專門識別不想要或未預期的結果，以及測試質量問題在應用於敏感的特定應用程序內容時可能產生的影響。例如，我們在設計新的基礎模型框架和支持資源時特別謹慎，以幫助提高應用程序中生成式 AI 的安全性。該框架通過內置的安全防護措施來確保基本的安全性，以減輕有害的模型輸入和輸出。為了幫助應用程序設計師和開發者將適合他們應用程序的 AI 安全性納入考慮，我們創建了教育資料，例如新的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fdesign%2Fhuman-interface-guidelines%2Fgenerative-ai" target="_blank"&gt;生成式 AI 人機界面指南&lt;/a&gt; 以指導負責任的 AI 原則。&lt;/p&gt; 
&lt;p&gt;隨着我們向新語言擴展功能，我們也在不同地區和文化中擴展了安全表示，並持續改進以適應我們用户廣泛的文化和語言多樣性。除了遵守當地的法律和法規外，我們還結合了高質量的外部代表性數據源，與內部和外部的法律、語言和文化專家合作，並審查了以往產品決策的先例，以確保我們的方法在語境中是尊重且相關的。為了設計多語言使用的緩解措施，我們從基礎模型層面的多語言預訓練對齊開始，然後擴展到針對特定功能的適配器，這些適配器整合了安全對齊數據。此外，我們擴展了我們的防護模型，這些模型旨在攔截有害提示，並在保持多語言適配器的同時，使用語言特定的訓練數據。我們還開發了定製數據集，以緩解模型輸出中的文化特定風險和偏見及刻板印象。同樣，我們通過機器翻譯和定向合成數據生成等工具，將我們的評估數據集擴展到多種語言和地域，並由母語者進行完善。最後，我們在各個功能上進行了人工紅隊測試，以識別每個地區特有的風險。&lt;/p&gt; 
&lt;p&gt;我們持續監控並主動改進我們的功能，藉助用户反饋。例如，在圖像遊樂場中，用户可以通過點擊「點贊」或「踩踏」來對生成的圖像提供反饋，還可以添加評論。應用程序開發者也可以通過&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fbug-reporting%2F" target="_blank"&gt;反饋助手&lt;/a&gt; 提供反饋。來自用户和開發者的反饋，以及評估數據和其他指標，幫助我們持續改進 Apple Intelligence 功能和模型。&lt;/p&gt; 
&lt;h2&gt;結論&lt;/h2&gt; 
&lt;p&gt;我們非常興奮地使 Apple Intelligence 核心語言基礎模型更加高效和強大，從而解鎖一系列集成在我們軟件平台中的有用功能，併為全球眾多語言的用户帶來這些功能。我們還為應用開發者提供了直接訪問我們設備上的語言基礎模型的新 Foundation Models 框架。應用開發者可以利用無需成本的 AI 推理功能，僅通過幾行代碼即可實現，從而通過幾行代碼將文本提取和摘要等能力帶入他們的應用中。我們的最新基礎模型在每一步都體現了我們的核心價值觀，例如我們對隱私的承諾，以及我們的負責任 AI 方法。我們期待在未來的技術報告中分享有關我們語言基礎模型更新的更多細節。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354610/apple-foundation-models-2025-updates</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354610/apple-foundation-models-2025-updates</guid>
      <pubDate>Sun, 11 May 2025 06:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美團王興詳解 AI 佈局：No Code 平台免費開放，1680 個應用已上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在近日於北京美團總部恆電大廈舉行的股東大會上，美團創始人王興&lt;span&gt;首次&lt;/span&gt;系統闡述了公司在人工智能領域的戰略佈局和發展規劃，揭示了美團在 AI 浪潮中的深度思考與大膽實踐。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;王興將美團的 AI 發展劃分為不同階段。早期，公司已在外賣配送的路由和派單系統中應用深度神經網絡算法。當前階段則聚焦於大語言模型及其衍生應用的開發與部署。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;面對 AI 領域的激烈競爭，美團在過去近三年時間裏進行了大規模投入。王興坦言，硬件投入尤其巨大，"卡是很貴的，而且還不好買，機房也得提早準備"。在人才爭奪方面，由於&lt;span&gt;頂級&lt;/span&gt;AI 人才極度稀缺，薪酬水平被推至新高，人才獲取和保留成為重大挑戰。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;No Code 革命：讓非程序員也能編程&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;美團 AI 應用的一大亮點是內部研發的 No Code 平台。該平台讓公司兩萬多名研發人員，包括產品經理、UI 設計師、商業分析師甚至 HR 和財務人員，都能通過 AI 輔助完成編程工作。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;王興強調，No Code 的核心價值在於實現"0 到 1"的突破，讓原本不擅長編程的員工也能獨立開發應用。"只要他有想法，AI 能自動幫他生成代碼"，這大幅提升了團隊整體的創新能力和工作效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，美團已將 No Code 平台免費向公眾開放，平台上已有 1680 個應用正式發佈並可免費使用。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;理性看待 AI 發展週期：短期高估，長期低估&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對於 AI 技術的發展前景，王興指出，人們往往"容易高估一、兩年能夠發生的變化，但是低估十年發生變化"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;王興認為，儘管 ChatGPT 發佈至今已兩年半，AI 雖取得顯著進展，但相比早年智能手機的革命性影響，還未從根本上改變人們的生活方式。然而，從十年維度看，AI 將帶來翻天覆地的變化。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;財務考量：短期承壓，長期受益&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;談及 AI 投入對公司財務表現的影響，王興明確表示，AI 鉅額投入在短期內"不見得那麼正向"，需要股東保持耐心。但從長期視角，他堅信科技力量最終能提升生產力，更好地服務於美團"幫大家吃得更好，生活得更好"的使命。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354604</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354604</guid>
      <pubDate>Sun, 11 May 2025 06:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全球首個 AI 芯片設計系統發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;全球首個基於人工智能技術的處理器芯片軟硬件全自動設計系統「啓蒙」近日正式發佈。該系統能實現從芯片硬件到基礎軟件的全流程自動化設計，意味着實現 AI 設計芯片，而且其設計在多項關鍵指標上達到人類專家手工設計水平。相關研究成果近日發佈於預印本網站 arXiv。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="288" src="https://oscimg.oschina.net/oscnet/up-db5d4d90ec1bfadbda426806d4a67345e79.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;span style="color:#000000"&gt;「啓蒙 1 號」實物。圖片來自相關公開論文&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 CPU 自動設計方面，利用「啓蒙」系統實現國際首個全自動化設計的 CPU 芯片「啓蒙 1 號」，5 小時內完成 32 位 RISC-V CPU 的全部前端設計，性能達到 Intel 486 水平，規模超過 400 萬個邏輯門，目前已完成流片。其升級版「啓蒙 2 號」為國際首個全自動設計的超標量處理器核，性能達到 ARM Cortex A53 水平，規模擴大至 1700 萬個邏輯門。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這項研究有望改變處理器芯片軟硬件的設計範式。它不僅能顯著減少人工參與、提升設計效率、縮短設計週期，更能針對特定應用場景需求實現快速定製化設計，靈活滿足日益多樣化的芯片設計需求。&lt;/span&gt;（&lt;span style="color:#000000"&gt;科技日報&lt;/span&gt;）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354601</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354601</guid>
      <pubDate>Sun, 11 May 2025 06:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 基金會推出 FAIR 包管理器項目，打造去中心化 WordPress 生態</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 基金會上週&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-the-fair-package-manager-project-for-open-source-content-management-system-stability" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出 FAIR 包管理器項目，旨在打造一個去中心化的 WordPress 插件與主題生態系統，該項目意圖將控制權歸還給網站託管服務商和開發者，被業界廣泛認為是回應 WP Engine 爭議事件的一項延伸舉措。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9818ada8ca862301eb4dd9cf16b05bbd370.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;WordPress 聯合創始人 Matthew Mullenweg 去年對競爭對手 WP Engine 發動了攻擊，引發了一場至今尚未解決的訴訟。期間他還通過其控制的 WordPress.org 開源項目劫持了 WP Engine 的插件。&lt;/p&gt; 
&lt;p&gt;用於分發 WordPress 插件的 FAIR 包管理器項目試圖解決這一問題，它將確保 WordPress 插件不受任何一方的控制。它是中心化 WordPress.org 插件和主題生態系統的去中心化替代，旨在將控制權交還給 WordPress 託管者和開發商。它採用了聯邦式開源架構。&lt;/p&gt; 
&lt;h3&gt;FAIR 項目目標&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;去中心化&lt;/strong&gt; ：消除對任何單一來源核心更新、插件、主題和翻譯的依賴，實現跨生態系統的聯邦化，整合來自任何來源的插件，構建更強大的開源軟件供應鏈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;增強安全性&lt;/strong&gt; ：減少發送給商業實體的自動瀏覽器數據傳輸和遙測數據，促進 WordPress 與歐洲通用數據保護條例的一致性，同時支持現代安全實踐，建立供應鏈安全，包括改進加密安全措施、增強瀏覽器兼容性檢查等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;促進創新與協作&lt;/strong&gt; ：通過提供更多的選項來控制所依賴的工具，促進商業插件開發者、託管商和應用開發者之間的創新，鼓勵各方參與貢獻，推動 WordPress 生態系統的整體發展。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;FAIR 功能和特點&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;即插即用&lt;/strong&gt; ：FAIR 套件管理器可以作為一個即插即用型 WordPress 插件使用，能夠平滑替換現有依賴 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FWordPress.org" target="_blank"&gt;WordPress.org&lt;/a&gt; API 的集中式服務架構。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多種部署方式&lt;/strong&gt; ：託管服務商可通過提供可直接安裝在現有 WordPress 站點上的獨立插件，或通過 FAIR 官方發行版實現網站的自動部署這兩種方式來部署 FAIR 系統。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;增強隱私保護&lt;/strong&gt; ：通過減少不必要的數據傳輸，提升用户隱私保護水平。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;關於 FAIR 項目的詳情，訪問 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffairpm" target="_blank"&gt;https://github.com/fairpm&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354583/lf-announces-the-fair-package-manager-project</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354583/lf-announces-the-fair-package-manager-project</guid>
      <pubDate>Sun, 11 May 2025 04:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 業績狂飆，年收入首次突破百億大關</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在短短三年的時間裏，美國人工智能研究公司 OpenAI 憑藉其熱門聊天機器人 ChatGPT，實現了令人矚目的業績，年化經常性收入（ARR）已突破 100 億美元大關。根據&lt;span&gt;最新&lt;/span&gt;數據顯示，OpenAI 的 ARR 去年為約 55 億美元，這意味着今年增長近 80%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;ARR 是企業從訂閲服務或產品中獲得的預期年度收入，尤其適用於評估那些基於訂閲模式（如 SaaS 服務）的企業，因為它能反映出企業從現有客户那裏獲得的穩定和週期性收入。OpenAI 的發言人透露，這一數據不僅包含了消費者產品和 ChatGPT 商業版本的收入，還涵蓋了 API 的銷售，但並不包括與微軟的授權收入和其他大額交易。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="316" src="https://oscimg.oschina.net/oscnet/up-6a5ee1c98aeae2080e11f341b57ef05b7f1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，OpenAI 目前已擁有 300 萬付費商業用户，比 2 月份的 200 萬大幅增加。分析人士認為，這一用户增長也為 OpenAI 的高估值提供了支持。目前，OpenAI 的估值大約是其收入的 30 倍，這顯示出其投資者對公司未來增長的樂觀預期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;今年 3 月，OpenAI 完成了一輪高達 400 億美元的融資，這也成為了有史以來&lt;span&gt;最大&lt;/span&gt;的私營科技融資案。值得一提的是，日本軟銀集團已經取代微軟，成為 OpenAI 的&lt;span&gt;第一&lt;/span&gt;大投資者。儘管如此，OpenAI 的首席執行官 Sam Altman 仍強調，微軟將繼續為其提供強大的計算資源，兩者的合作關係依舊穩固。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技術合作方面，蘋果公司在最近的 WWDC 大會上宣佈，將把 OpenAI 的圖像生成功能整合到自家的 Image Playground 功能中，ChatGPT 將幫助用户進行圖像調整。這一舉措將進一步推動 OpenAI 的技術在日常生活中的應用。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管 OpenAI 在盈利能力上仍面臨挑戰，去年其虧損達到約 50 億美元，但公司設定的目標是在 2029 年實現年收入 1250 億美元。這需要更多的資金支持與市場擴展，才能實現這一驚人的增長速度。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354580</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354580</guid>
      <pubDate>Sun, 11 May 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
