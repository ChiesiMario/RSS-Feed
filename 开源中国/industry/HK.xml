<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 31 Jul 2025 02:43:52 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>梁文鋒署名論文獲 ACL 2025 最佳論文獎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;第 63 屆國際計算語言學年會（ACL 2025）正式頒獎，共有 4 篇論文入選「最佳論文」，其中 DeepSeek 和北大合作、梁文鋒（DeepSeek 創始人）署名的文章，以及北大楊耀東團隊獲得了其中兩篇。&lt;/p&gt; 
&lt;p&gt;由 DeepSeek、北大、華盛頓大學合作，梁文鋒署名的為&lt;strong&gt;&lt;em&gt;《Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention》&lt;/em&gt;&lt;/strong&gt;，其提出的稀疏注意力 NSA 模型的算法，能夠從一般任務到嚴苛的長下文任務，都能擁有出色卓越的表現：將長文本處理速度提高了最多 11 倍，而性能超過了全注意力模型。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d43b8ad2a0cb2e2f280f11b7d2d96a63fba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;詳情查看：&lt;a href="https://www.oschina.net/news/334671/deepseek-nsa" target="_blank"&gt;DeepSeek 提出新的注意力機制：原生稀疏注意力 (NSA)，創始人親自提交論文&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;而北京大學人工智能研究院的《Language Models Resist Alignment: Evidence From Data Compression》則主要探討了為什麼 LLM（大語言模型）的「安全對齊」效果很脆弱且容易被逆轉。&lt;/p&gt; 
&lt;p&gt;值得一提的是，本次 ACL 2025 總投稿數量創下歷史新高，達到了 8360 篇論文，而論文裏的中國作者比例超過了 51%。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363302</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363302</guid>
      <pubDate>Thu, 31 Jul 2025 02:41:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Ollama 面向 macOS 和 Windows 發佈全新桌面端應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源本地大模型運行工具 Ollama &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Fblog%2Fnew-app" target="_blank"&gt;宣佈&lt;/a&gt;面向 macOS 和 Windows 推出全新的桌面應用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a12430aed754921a4326f7ef21eb9d24636.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-07aa1e5500ceada403fe1e9b28ba8e1cf6a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-805c9f5a18229aa113850d12d0d6c4ba740.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d0a1de49aefe9fa1a17182ded084e940619.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;功能介紹&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;便捷聊天：提供了一個直觀的界面，讓用户可以輕鬆下載並與各種本地模型進行聊天&lt;/li&gt; 
 &lt;li&gt;文件處理：支持通過拖放方式處理文件，可以對文本或 PDF 文件內容進行推理。用户可以在設置中增加上下文長度以處理大型文檔，但這會需要更多內存&lt;/li&gt; 
 &lt;li&gt;多模態支持：基於 Ollama 新的多模態引擎，應用支持向 Gemma 3 等模型發送圖像進行分析&lt;/li&gt; 
 &lt;li&gt;代碼理解：可以處理代碼文件，幫助模型理解和編寫文檔&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於偏好純命令行界面的用户，Ollama 仍在 GitHub 的發佈頁面提供獨立的 CLI 版本下載。&lt;/p&gt; 
&lt;p&gt;下載地址：https://github.com/ollama/ollama/releases/tag/v0.10.0&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363298/ollama-new-app</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363298/ollama-new-app</guid>
      <pubDate>Thu, 31 Jul 2025 02:23:49 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟封禁 LibreOffice 開發者的 Hotmail 賬號</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，LibreOffice 開發者 Mike Kaganski 的微軟 Hotmail 郵箱賬號&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.neowin.net%2Fnews%2Fmicrosoft-bans-libreoffice-developers-account-without-warning-rejects-appeal%2F" target="_blank"&gt;被封禁&lt;/a&gt;，理由是「違反了微軟的服務協議」。&lt;/p&gt; 
&lt;p&gt;事件起因是 Kaganski 在使用 Thunderbird 郵件客户端向 LibreOffice 開發者郵件列表發送技術郵件時，郵件無法發送，隨後他的微軟賬號被封鎖，且無法登錄。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c7ca38626be574a8f6b00ac850427dd3382.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kaganski 表示，他確信郵件內容並未違反微軟的服務協議，推測可能是某個自動化系統錯誤地標記了他的賬户。他介紹了在申訴過程中遇到的諸多障礙：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;自動申訴系統&lt;/strong&gt;：系統要求他提供手機號碼進行驗證，但他輸入手機號碼後收到「嘗試其他方法」的錯誤提示，而系統並未提供其他驗證方法。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;聯繫支持團隊&lt;/strong&gt;：微軟的聯繫頁面要求先登錄才能聯繫支持團隊，但 Kaganski 的賬號已被封鎖，無法登錄。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;通過妻子賬號申訴&lt;/strong&gt;：他最終通過妻子的賬號提交了申訴，但微軟支持團隊的回覆只是讓他再次嘗試登錄並提供手機號碼，這與他之前嘗試過的方法並無二致。微軟在沒有采取任何實質性措施的情況下，直接將他的申訴標記為「已解決」並關閉了申訴。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d88cd85757e8270fc2ab5786489a31ea266.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;截至 7 月 30 日，Kaganski 的微軟賬號仍未恢復。他最終通過 Gmail 成功發送了郵件。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363224</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363224</guid>
      <pubDate>Wed, 16 Jul 2025 12:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 內核社區正在討論關於「AI 生成代碼」的新提案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;資深 Linux 開發者、NVIDIA 員工 Sasha Levin（此前曾就職於 Google 和微軟）兼 Linux LTS 內核聯合維護者提出了 Linux 內核 AI 編程助手的配置方案和文檔/規則，供開發者使用由 AI 編碼實用程序（共同）編寫的補丁為 Linux 內核做出貢獻。&lt;/p&gt; 
&lt;p&gt;Sasha Levin 不久前發出了一份 RFC，&lt;strong&gt;提議在 Linux 內核文檔區引入一個 AI 編碼助手配置文件，供 Claude 等 AI 編碼助手進行解讀&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-690d9dc6b25d0b1cae4cb9a383ac69c9d55.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外他還提出了一套初步的 Linux 內核貢獻規則，其中包含 AI 歸屬要求和其他詳細信息，供希望藉助 Claude 和 Grok 等 AI 助手為上游 Linux 內核做出貢獻的開發者參考。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1638" src="https://static.oschina.net/uploads/space/2025/0730/200208_NXuG_2720166.png" width="2302" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Sasha Levin 在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Fall%2F20250725175358.1989323-1-sashal%40kernel.org%2F" target="_blank"&gt;RFC 補丁系列&lt;/a&gt;中解釋道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;該補丁系列為使用 Linux 內核代碼庫的 AI 編碼助手添加了統一的配置和文檔。隨着 AI 工具在軟件開發中變得越來越普遍，為它們在內核開發中的使用制定清晰的指南非常重要。&lt;/p&gt; 
 &lt;p&gt;該系列包含兩個補丁：&lt;/p&gt; 
 &lt;p&gt;1. 第一個補丁為各種 AI 編碼助手（Claude、GitHub Copilot、Cursor、Codeium、Continue、Windsurf 和 Aider）添加了統一的配置文件。這些都符號鏈接到一箇中央文檔文件，以確保跨工具的一致性。&lt;/p&gt; 
 &lt;p&gt;2.. 第二個補丁添加了指導 AI 助手進行 Linux 內核開發實踐的實際規則和文檔，包括：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;遵循內核編碼標準&lt;/li&gt; 
  &lt;li&gt;尊重開發過程&lt;/li&gt; 
  &lt;li&gt;正確歸屬 AI 生成的貢獻&lt;/li&gt; 
  &lt;li&gt;理解許可要求&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;以下示例演示了這些指南在實踐中是如何運作的，展示了提交中正確的 AI 歸屬以及助手對內核文檔要求的理解。&lt;/p&gt; 
 &lt;p&gt;所有 AI 助手都必須使用 Co-developed-by 標籤在提交中標識自己，以確保 AI 參與代碼開發的完全透明。」&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363222</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363222</guid>
      <pubDate>Wed, 16 Jul 2025 12:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英特爾資深 Linux 內核工程師加入 Meta</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 已經擁有一支全明星 Linux 內核工程師團隊，而且他們似乎仍在招募頂級 Linux 內核人才。&lt;/p&gt; 
&lt;p&gt;長期擔任英特爾 Linux 內核工程師的 Kirill Shutemov 作為信任域擴展 (TDX) 的維護者為英特爾對 Linux 內核的貢獻不可低估，這對他們在 Xeon 上的機密計算至關重要，他還參與了線性地址空間分離 (LASS) 和許多其他 Linux 內核內存管理相關功能。&lt;/p&gt; 
&lt;p&gt;兩週前離開英特爾後，Shutemov 公開宣佈他現在受僱於 Meta，擔任倫敦的 Linux 內核軟件工程師。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4f705edc8f6648e7a903fda69788e7e2a05.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他的個人郵箱地址顯示他仍然是 Linux 內核中英特爾信任域擴展代碼的上游維護者。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1448" src="https://static.oschina.net/uploads/space/2025/0730/195000_IDBG_2720166.png" width="1534" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他現在在 Meta 擔任 Linux 內核軟件工程師，與日益壯大的 Linux 內核開發者和維護人員團隊並肩工作。這對於整個開源社區來説無疑是一大勝利，希望 Shutemov 對 Linux 內存管理和內核其他領域的貢獻能夠持續下去，且 Meta 不會與任何特定的芯片供應商綁定。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363220</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363220</guid>
      <pubDate>Wed, 16 Jul 2025 11:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源視頻編輯器 OpenCut 收到超過 12 萬行代碼的 PR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源視頻編輯器&amp;nbsp;OpenCut 作者在社交媒體分享了該項目收到的一個「巨大」 PR：一名開發者向&amp;nbsp;OpenCut 貢獻了超過 12 萬行代碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77035b3dbda9f40e56a4dae456026a14987.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從提交信息來看，這個 PR 應該是開發者 Vibe Coding 的「成果」——因為大部分 commits 都有 Claude Code 的頭像。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-951280606a50bf6cf90b63adca47f588285.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外這個 PR 的內容出奇地少，雖然它包含超過 12 萬行代碼，但其中大部分是 AI 生成的文檔（86K 行，68%），以及 9K 行 AI 生成的測試（7%），所以實際代碼只有 32K 行（25%）。&lt;/p&gt; 
&lt;p&gt;更不用説那糟糕的文檔了，大部分感覺像是從 LLM 會話中的複製粘貼。&lt;/p&gt; 
&lt;p&gt;圍觀地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenCut-app%2FOpenCut%2Fpull%2F479" target="_blank"&gt;https://github.com/OpenCut-app/OpenCut/pull/479&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363213</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363213</guid>
      <pubDate>Wed, 16 Jul 2025 11:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 芯片新貴 Groq 融資臨近，估值飆升至 60 億美金</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AI 芯片創業公司 Groq 正處於一輪新的融資談判中，預計將籌集 6 億美元資金，估值接近 60 億美元。根據彭博社的消息，這項交易尚未最終敲定，具體條款可能會有所變動。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-792d436049d6eee6319309b8c7cd56c22be.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Groq 在 2024 年 8 月時成功籌集了 6.4 億美元，當時的估值為 28 億美元，短短一年間，公司的估值幾乎翻了一番。此前，Groq 共計籌集了約 10 億美元的資金。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次融資由位於德克薩斯州的投資公司 Disruptive 領投。值得一提的是，去年 11 月的融資由黑石集團（BlackRock）主導，同時也得到了 Neuberger Berman、Type One Ventures、思科 (Cisco)、KDDI 以及三星催化基金等多家機構的參與。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Groq 成立於 2016 年，由曾在谷歌開發 Tensor 處理單元芯片的 Jonathan Ross 創辦。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;本輪融資的背景是，Groq 在 5 月份與加拿大貝爾公司（Bell Canada）達成獨家合作，旨在推動其大型 AI 基礎設施項目。此外，在 4 月份，Groq 還與 Meta 公司達成了合作，為後者提供 AI 基礎設施，以加速 Llama4 的推理能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363210</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363210</guid>
      <pubDate>Wed, 16 Jul 2025 10:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 回應 10 億美元挖人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;《連線》雜誌報道，Meta CEO 馬克・扎克伯格正在全力為其新成立的&lt;span&gt;超級&lt;/span&gt;智能實驗室招募&lt;span&gt;頂尖&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 人才。儘管扎克伯格已經成功挖走了多名 OpenAI 的&lt;span&gt;頂尖&lt;/span&gt;研究員，但他的新目標則是穆拉蒂創辦的 AI 公司 Thinking Machines Lab（TML）的員工。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據悉，穆拉蒂的新公司現有 50 名員工，但 Meta 已經與超過 12 名員工接觸，甚至提供了豐厚的薪酬報價。某些報價總額超過 10 億美元，為期數年，而其他報價則在 2 億至 5 億美元之間，分四年支付。Meta 甚至承諾，加入&lt;span&gt;第一&lt;/span&gt;年的薪酬就能高達 5000 萬至 1 億美元。然而，至今尚無人願意接受這些誘人的邀約。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="299" src="https://oscimg.oschina.net/oscnet/up-8e03f375e3692f7957f2783333ac415f68f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對此，Meta 通訊總監 Andy Stone 在聲明中表示，雖然有部分員工收到高額薪酬報價，但報道的細節存在失實之處。他質疑此類報道的背後動機，並強調 Meta 只向少數 TML 員工發出邀約。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;扎克伯格的招募策略頗具個人特色。他最初通過 WhatsApp 與潛在招募對象聯繫，隨後迅速安排面試，包括與自己及其他高管的長時間對話。扎克伯格向受邀者表示，Meta 希望打造&lt;span&gt;世界級&lt;/span&gt;的 AI 助手，為每位用户提供有價值的 AI 服務。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管 Meta 在構建前沿 AI 模型方面落後於一些小型競爭對手，但其計劃通過開源策略來削弱 OpenAI 的市場地位。Meta 希望通過發佈競爭性的開源模型，將 AI 技術商品化，儘管這一路徑充滿挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，Meta 的高薪招募策略為何屢屢失利呢？一些知情人士透露，儘管扎克伯格已成功招募近 24 人，但領導風格和團隊氛圍卻成為了不少&lt;span&gt;頂尖&lt;/span&gt;人才的顧慮。此外，Meta 的產品路線圖似乎未能打動許多人，尤其是與 OpenAI 等公司的使命相比。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TML 剛完成了歷史上&lt;span&gt;最大&lt;/span&gt;的一輪融資，估值高達 120 億美元，研究人員並不需要在理想和金錢之間做選擇。對他們而言，選擇留在這樣一家有潛力的公司無疑是更具吸引力的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363209</guid>
      <pubDate>Wed, 16 Jul 2025 10:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>《中國人工智能安全承諾框架》發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 世界人工智能大會暨人工智能全球治理高級別會議「人工智能發展與安全」全體會議 7 月 26 日下午在上海召開。會議由中國人工智能發展與安全研究網絡（以下簡稱「研究網絡」，CnAISDA）主辦。上海市委常委、常務副市長吳偉，國家發展和改革委員會創新驅動發展中心主任霍福鵬出席並致辭。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;傑弗裏・辛頓、姚期智、約書亞・本吉奧和大衞・帕特森 4 位圖靈獎得主&lt;/strong&gt;，以及 20 多位國內外頂尖專家出席會議，共同探討人工智能安全發展、縮小智能鴻溝等前沿議題，積極尋求人工智能安全治理國際合作路徑。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7cef0e7074e44eea0bd5ccd53b80704e958.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;中國信息通信研究院（簡稱「中國信通院」）院長、中國人工智能產業發展聯盟（AIIA）秘書長餘曉暉受邀參與對話，牽頭與清華大學、上海人工智能實驗室、中國電子信息產業發展研究院等單位的代表一起發佈《&lt;strong&gt;中國人工智能安全承諾框架&lt;/strong&gt;》。&lt;/p&gt; 
&lt;p&gt;該《框架》在 AIIA《人工智能安全承諾》（2024 年 12 月發佈）的基礎上，&lt;strong&gt;新增了加強人工智能安全治理國際合作、防範前沿人工智能安全風險等內容&lt;/strong&gt;，體現了中國產業界願與全球各方緊密攜手，共促人工智能向善發展的堅定決心和開放態度。&lt;/p&gt; 
&lt;p&gt;下一步，中國信通院作為「研究網絡」成員和 AIIA 秘書處單位，將與簽署企業攜手，&lt;strong&gt;通過披露行動、測試驗證等方式，推動《框架》的落地實踐&lt;/strong&gt;，促進我國人工智能朝着有益、安全、公平方向健康有序發展，並積極開展國際治理合作，為全球人工智能安全治理貢獻中國智慧和中國力量。&lt;/p&gt; 
&lt;p&gt;附《框架》中英文全文：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;中國人工智能安全承諾框架&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;CHINA ARTIFICIAL INTELLIGENCE SECURITY AND SAFETY COMMITMENTS FRAMEWORK&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;人工智能浪潮席捲全球，積極釋放技術價值紅利，對全球經濟社會發展和人類文明進步產生深遠影響。我們也清晰認知到，人工智能帶來難以預知的各種風險挑戰。為把握新一輪發展機遇，中國人工智能發展與安全研究網絡成員鄭重發起《中國人工智能安全承諾框架》，通過產業自律，以高水平安全保障高質量發展，協力共促人工智能穩健發展。此事由中國信息通信研究院牽頭推進。我們深知，自律承諾是獲得社會信任的關鍵要素，我們將以本承諾作為行動守則，接受社會各界監督，不斷提升優化，促進人工智能技術應用以人為本，智能向善。&lt;/p&gt; 
 &lt;p&gt;The wave of artificial intelligence (AI) is sweeping across the globe, actively generating technological dividends and exerting profound influence on global economic and social development as well as the progress of human civilization. At the same time, we are keenly aware that AI brings about unpredictable risks and complex challenges. To seize this new round of development opportunities, members of China AI Safety and Development Association (CnAISDA) solemnly launch the AI Security and Safety Commitments. Through industry self-regulation, we will leverage high-level security and safety measures to support high-quality development, and collaborate to promote the robust development of AI. This initiative is led and promoted by the China Academy of Information and Communications Technology (CAICT). We fully recognize that commitments to self-discipline constitute a critical foundation for gaining the trust of the international community. Guided by the Commitments as our code of conduct, and subject to the oversight of all stakeholders, we will continuously improve and refine our approach. By doing so, we will ensure that the application of AI technologies always remains people-centered and aligned with the principle of AI for good.&lt;/p&gt; 
 &lt;p&gt;承諾一：設置安全團隊或組織架構，構建安全風險管理機制。內部設有專業團隊負責開展人工智能風險評估、安全治理等工作，明確安全負責人。主動設定符合實際需求的安全風險基線，開源時採取相應的安全措施，開展貫穿人工智能開發部署全生命週期的風險管理，明確風險識別和應對流程及措施。&lt;/p&gt; 
 &lt;p&gt;Commitment I: Establish security and safety teams or organizational structures and build security and safety risk management mechanisms. Designate a leader responsible for AI security and safety, establish specialized teams to conduct AI risk assessments and safety, security and governance within the enterprise. Proactively define realistic security and safety risk baselines, adopt appropriate security and safety measures for open-source initiatives, and implement risk management practices throughout the entire AI development and deployment life cycle. Clearly outline processes and measures for risk identification and mitigation.&lt;/p&gt; 
 &lt;p&gt;承諾二：開展模型安全測試，提升模型效果與安全可靠性。通過專業性的仿真測試團隊，在發佈、更新人工智能模型之前對其進行紅隊測試。對於大模型，重點圍繞其通用理解、推理和決策能力，以及其在工業、教育、醫療、金融、法律等場景下表現出的能力開展安全性和可靠性測試。&lt;/p&gt; 
 &lt;p&gt;Commitment II: Conduct security and safety testing for AI models to enhance the performance, safety and reliability. Through dedicated simulation and red-teaming experts, rigorously test AI models prior to their release or update. For large models in particular, prioritize safety and reliability evaluations focusing on their general understanding, reasoning, and decision-making capabilities, as well as their performance in critical domains such as industry, education, healthcare, finance, and law.&lt;/p&gt; 
 &lt;p&gt;承諾三：採取措施保障訓練數據和業務數據安全。制定數據安全防護制度，配套建立防護技術措施，發現並及時處置數據投毒的情況，把控訓練數據的準確性與可靠性。對業務數據進行加密存儲與訪問控制，確保商業秘密、用户隱私及用户上傳的知識庫僅在授權下訪問，不被人工智能模型非法輸出，保障數據安全與隱私權益。&lt;/p&gt; 
 &lt;p&gt;Commitment III: Implement measures to safeguard the security of training data and operational data. Establish data security protection policies and deploy corresponding technical measures to detect and promptly address data poisoning incidents, ensuring the accuracy and reliability of training data. Encrypt operational data and enforce access controls to protect business secrets, user privacy, and user-uploaded knowledge base, ensuring access is restricted to authorized use only. Prevent unauthorized outputs by AI models, thereby safeguarding data security and privacy rights.&lt;/p&gt; 
 &lt;p&gt;承諾四：提升基礎設施安全。建立人工智能系統部署的軟硬件安全監測和防護能力，實施定期和動態的安全滲透測試，模擬各種潛在的風險場景，識別並報告環境中的安全隱患，研判可能導致的各種風險。建立基礎設施安全應急響應機制，包括應急處理流程、責任分配以及事後改進方案。&lt;/p&gt; 
 &lt;p&gt;Commitment IV: Enhance infrastructure security. Develop robust capabilities for monitoring and protecting the software and hardware used in AI system deployments. Conduct regular and dynamic security penetration tests to simulate potential risk scenarios, identify and report security vulnerabilities in the infrastructure, and assess associated risks. Establish an infrastructure security incident response mechanism, including emergency response procedures, clear accountability assignments, and post-incident improvement solutions.&lt;/p&gt; 
 &lt;p&gt;承諾五：增強模型透明度。主動披露安全治理實踐舉措，提升對各利益攸關方的透明度。公開披露模型的功能、適用領域以及侷限性。通過模型説明、服務協議等方式，向公眾披露可能涵蓋的風險。&lt;/p&gt; 
 &lt;p&gt;Commitment V: Enhance model transparency. Proactively disclose safety and security governance measures and improve transparency for all stakeholders. Provide clear information about the model's capabilities, applicable fields, and limitations. Inform potential risks to the public through model documentation, service agreements, or others.&lt;/p&gt; 
 &lt;p&gt;承諾六：積極開展前沿安全研究，防範前沿領域安全風險。研究開發和部署智能向善的人工智能系統，積極向公眾披露研究成果，以幫助應對社會面臨的挑戰。加強對人工智能系統在前沿領域中的濫用風險研判，防範其在高危場景的潛在濫用風險。&lt;/p&gt; 
 &lt;p&gt;Commitment VI: Vigorously advance frontier safety and security research, and prevent safety and security risks in frontier fields. Innovate in the development and deployment of AI systems that embody the principle of AI for good, and disclose research findings with the public transparently, contributing to addressing pressing challenges faced by society. Strengthen the assessment of risks related to the abuse of AI systems in frontier fields, and prevent potential risks of their abuse in high-risk scenarios.&lt;/p&gt; 
 &lt;p&gt;承諾七：加強安全治理國際合作，推動技術向善普惠應用。積極參與全球人工智能安全治理交流對話，共享風險識別、評估與防控經驗及最佳實踐。積極承擔社會責任，加強科普宣傳、開展技能培訓，提升人工智能素養和技能水平，助力彌合智能鴻溝。&lt;/p&gt; 
 &lt;p&gt;Commitment VII: Strengthen international cooperation on AI safety, security and governance, and promote inclusive, beneficial applications of AI. Actively participate in global dialogues on AI safety, security and governance, and contribute to the exchange of experiences and best practices in risk identification, assessment, and mitigation. Fulfill social responsibilities by advancing public science communication, enhancing AI education, and providing skills training to improve AI literacy and capabilities, with a focus on bridging the global intelligence divide.&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363206</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363206</guid>
      <pubDate>Wed, 16 Jul 2025 09:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>FFmpeg 8.0 將於 8 月底發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源多媒體框架 FFmpeg 計劃於 8 月底發佈 8.0 版本。&lt;/p&gt; 
&lt;p&gt;按照計劃，FFmpeg 8.0 代碼應該在未來一兩週內分支出來，然後在此兩週後發佈 FFmpeg 8.0 版本。所以大約在 8 月底，FFmpeg 8.0 就會上線。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0730/172734_8M9I_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fffmpeg.org%2Fpipermail%2Fffmpeg-devel%2F2025-July%2F347010.html" target="_blank"&gt;https://ffmpeg.org/pipermail/ffmpeg-devel/2025-July/347010.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此次更新涵蓋多種新編碼器與解碼器，包括 RealVideo 6.0、APV、動畫 JPEG-XL 等。同時，新增對 OpenHarmony 的編解碼支持及 VVC/H.266 的 VA-API 加速功能。更新還涵蓋 AVX-512 優化、HDR 視頻支持增強、WHIP 複用器實現低延遲傳輸等，部分功能性能提升達 100 倍。&lt;/p&gt; 
&lt;p&gt;此外，MP4 複用器現已支持 CENC AV1，FLV v2 也增強了現代編碼兼容性。&lt;/p&gt; 
&lt;p&gt;FFmpeg 8.0 尚未合併但可能及時完成的一項功能是&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpatchwork.ffmpeg.org%2Fproject%2Fffmpeg%2Fpatch%2F20250719125526.389239-1-vpalmisano%40gmail.com%2F" target="_blank"&gt;最近&lt;/a&gt;為 FFmpeg 添加 OpenAI Whisper 音頻過濾器支持的工作。這可以為 FFmpeg 提供 AI 驅動的實時字幕/轉錄支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363199/ffmpeg-8-0-coming-soon</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363199/ffmpeg-8-0-coming-soon</guid>
      <pubDate>Wed, 16 Jul 2025 09:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 洽談 50 億美元融資，估值達 1700 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彭博社援引知情人士&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-29%2Fanthropic-nears-deal-to-raise-funding-at-170-billion-valuation" target="_blank"&gt;消息稱&lt;/a&gt;，Anthropic 即將達成協議，在新一輪融資中籌集高達 50 億美元，從而使其估值達到 1700 億美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;知情人士表示，投資公司&amp;nbsp;Iconiq Capital&amp;nbsp;將領投此輪融資，預計融資總額將在 30 億至 50 億美元之間。部分知情人士表示，Iconiq 正在洽談投資約 10 億美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，Anthropic 還一直在與卡塔爾投資局 (QIA) 和新加坡主權基金新加坡政府投資公司 (GIC) 洽談參與此輪融資。&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;其他潛在投資者包括亞馬遜，該公司此前已向 Anthropic 投資數十億美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Lightspeed 也參與了新一輪融資。其他正在洽談參與的風險投資公司包括&amp;nbsp;Menlo Ventures&amp;nbsp;和&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Alkeon Capital Management。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Anthropic 將接受不低於 2 億美元的融資。一位知情人士表示，這筆融資最終可能會有第二位領投方。談判仍在最後敲定中，細節可能會有所變動。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-98dfff5c6e147489718fd1050088352376d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着最近幾輪融資談判的推進，Anthropic 的銷售額大幅增長。據彭博社此前&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-15%2Fopenai-rival-anthropic-courts-finance-industry-with-new-ai-tools" target="_blank"&gt;報道&lt;/a&gt;，該公司本月初的年度經常性收入約為 40 億美元。截至 7 月底，這一數字已攀升至約 50 億美元。該公司預計，到今年年底，其經常性收入可能達到 90 億美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;新的融資將標誌着該公司估值的大幅躍升，並鞏固其作為全球領先人工智能開發商之一的地位。今年早些時候，Anthropic 在由光速創投領投的 35 億美元融資中估值達到 615 億美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Anthropic、Iconiq、GIC、Lightspeed、亞馬遜和 Menlo Ventures 均拒絕置評。卡塔爾投資局和 Alkeon 的代表尚未回應置評請求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《連線》雜誌此前曾報道了 Anthropic 首席執行官 Dario Amodei 在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wired.com%2Fstory%2Fanthropic-dario-amodei-gulf-state-leaked-memo%2F" target="_blank"&gt;最近&lt;/a&gt;發給員工的一份備忘錄中承認，有必要從中東籌集資金。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363198</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363198</guid>
      <pubDate>Wed, 16 Jul 2025 09:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>s3mini —— 小巧快速的 S3 客户端</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;code&gt;s3mini&lt;/code&gt;是一款超輕量級 Typescript 客户端（壓縮後約 14 KB，每秒操作數提升約 15%），用於兼容 S3 的對象存儲。它可在 Node、Bun、Cloudflare Workers 和其他邊緣平台上運行。已在 Cloudflare R2、Backblaze B2、DigitalOcean Spaces 和 MinIO 上測試過。（不支持瀏覽器！）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;輕巧快速：平均每秒操作數增加約 15%，大小僅為 ~14 KB（最小化，未壓縮）。&lt;/li&gt;
&lt;li&gt;零依賴；支持 AWS SigV4（無預簽名請求）。&lt;/li&gt;
&lt;li&gt;適用於 Cloudflare Workers；非常適合邊緣計算、Node 和 Bun（不支持瀏覽器）。&lt;/li&gt;
&lt;li&gt;僅包含必要的 S3 API — 改進的列表、放置、獲取、刪除等。&lt;/li&gt;
&lt;li&gt;BYOS3&amp;nbsp;&lt;strong&gt;-&lt;/strong&gt;自帶與 S3 兼容的存儲桶（已在 Cloudflare R2、Backblaze B2、DigitalOcean Spaces、MinIO 和 Garage 上測試！Ceph 和 AWS 已加入測試隊列）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt="" height="403" src="https://static.oschina.net/uploads/space/2025/0612/145619_y755_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/s3mini</link>
      <guid isPermaLink="false">https://www.oschina.net/p/s3mini</guid>
      <pubDate>Wed, 16 Jul 2025 09:03:00 GMT</pubDate>
    </item>
    <item>
      <title>微軟羅列受 AI 衝擊最大的 40 個職業崗位</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟近日發佈了一份 AI 相關研究&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fartificial-intelligence%2Fmicrosoft-reveals-40-jobs-about-to-be-destroyed-by-and-safe-from-ai" target="_blank"&gt;報告&lt;/a&gt;，分析了美國用户和 Copilot 超過 20 萬次對話，探討了 AI 在各領域的應用情況，並列出了受 AI 衝擊影響最大的 40 個職業崗位。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/164742_GQ27_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該報告分析了美國用户和 Copilot 超過 20 萬次對話，探討了人們最常使用 AI 的領域。根據用户滿意度和 Copilot 被要求處理特定任務的頻率，研究人員計算出 AI 接管不同工作角色的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9a52e207c0707356014987acb75a9d4c228.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-257c1393cd78d715b7708a3a215bb07fb93.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;基於報告數據，翻譯和口譯人員受 AI 衝擊最為嚴重，現代 AI 工具已能提供快速的多語言語音旁白和實時翻譯，這些崗位與 Copilot 當前能做的事情有最大的重合。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;受衝擊最大的職業&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;翻譯和口譯人員受影響最為嚴重，因為現代 AI 工具已能提供快速的多語言語音旁白和實時翻譯，與 Copilot 的功能高度重合。&lt;/li&gt; 
 &lt;li&gt;歷史學家也面臨較大沖擊，他們常藉助 AI 分析社會話題或驗證歷史事實，而信息收集是語言模型的優勢，存在明顯的替代潛力。&lt;/li&gt; 
 &lt;li&gt;作家、銷售代表和客服人員同樣處於受衝擊的前列，這些工作涉及大量溝通任務，用户常將相關任務交給 Copilot，且效果良好。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;受衝擊較小的職業&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;護理助理、按摩師和重型設備操作員的職業受 AI 影響較小。這些工作涉及實體存在、親手護理或機器操作，目前 AI 無法複製。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363192</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363192</guid>
      <pubDate>Wed, 16 Jul 2025 08:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Dropbox Passwords 即將停止服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Dropbox &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.dropbox.com%2Fen-us%2Finstalls%2Fdropbox-passwords-discontinuation" target="_blank"&gt;發佈官方公告&lt;/a&gt;，宣佈 Dropbox Passwords 將於 2025 年 10 月 28 日停用。Dropbox 建議用户將密碼轉移至其他密碼管理應用程序，例如 1Password。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/164104_T9vF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;停用計劃概覽&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 10 月 28 日&lt;/strong&gt;將全面停用 Dropbox Passwords。屆時你無法再訪問、添加或使用任何保存的用户名、密碼和支付信息，這些數據將被永久安全刪除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;階段性變化流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 8 月 28 日&lt;/strong&gt;：移動端 App 和瀏覽器擴展設為 &lt;strong&gt;只讀模式&lt;/strong&gt;，停止新增內容和自動填充功能，但仍可查看已有密碼數據。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 9 月 11 日&lt;/strong&gt;：&lt;strong&gt;移動 App 停用&lt;/strong&gt;，你仍可通過瀏覽器擴展查看數據。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 10 月 28 日&lt;/strong&gt;：功能全面關閉並刪除所有密碼數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;為什麼要停用？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Dropbox 表示將專注於提升其核心產品功能，故決定停止開發密碼管理工具，並推薦用户改用其他密碼管理器，如 1Password。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363190</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363190</guid>
      <pubDate>Wed, 16 Jul 2025 08:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里巴巴 1688 發佈「AI 版」App 與「88 查」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;阿里巴巴旗下的 B2B 批發平台 1688 近日正式發佈多項 AI 新品和升級舉措，旨在通過人工智能技術全面賦能中小企業，提升採購效率。此次發佈的核心亮點包括推出全新的「1688AI 版」App、上線免費企業查詢工具「88 查」，並對現有「阿里巴巴 1688」App 進行全面 AI 化升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-86d878ed359505322a95851647189883259.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據介紹，全新發布的「1688AI 版」App 正陸續登陸各大手機應用商店，面向採購買家全面開放。這款新應用聚焦創業與拿貨場景，集成了五大核心 AI 功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 搜索：提供更智能、精準的搜索體驗。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 選品：基於大數據和 AI 算法，為買家智能推薦優質貨源。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 創款：助力商家進行產品設計和創新。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 圖搜：支持通過圖片進行商品搜索。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 查企：與「88 查」功能打通，方便買家快速查詢企業信息。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這些功能覆蓋了從商機發現、智能推薦與組貨，到產品設計和創新等生意全鏈路需求，旨在提升採購效率和成功率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「88 查」也已上線 PC 端，並深度集成於 1688App，同時接入支付寶和微信小程序，支持用户跨平台免費使用。「88 查」的一大特色是支持自然語言交互，用户只需輸入簡單描述，即可快速查詢工廠的資質認證、生產實力與核心能力。更進一步，該工具還集成了深度研究能力，能夠快速生成行業和企業研究報告，為買家提供決策支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次 AI 能力將同步覆蓋 1688 的移動端與 PC 端，未來還將結合不同終端和用户羣體的交互特性持續迭代。通過 AI 技術，1688 旨在助力買家實現高效選品、精準找廠、簡單做生意的目標。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363188</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363188</guid>
      <pubDate>Wed, 16 Jul 2025 08:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>未來五年，AI 創造的百萬富翁數量將超過互聯網二十年來的總和</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;黃仁勳在"All-In"播客節目中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.entrepreneur.com%2Fbusiness-news%2Fnvidia-ceo-jensen-huang-says-ai-will-create-millionaires%2F495134" target="_blank"&gt;詳細闡述&lt;/a&gt;了人工智能的財富創造邏輯。他認為 AI 技術使人們能夠創造全新的事物，有效填補技能空白，為個人和企業提供了前所未有的創收機會。&lt;/p&gt; 
&lt;p&gt;黃仁勳預測在未來 5 年內，&lt;strong&gt;AI 領域創造的百萬富翁要多於互聯網 20 年創造的&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height="760" src="https://static.oschina.net/uploads/space/2025/0730/161900_2YNk_2720166.png" width="1552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這種技術被他稱為"有史以來最偉大的技術均衡器"，因為它能讓任何人都成為程序員。傳統編程需要掌握 Python 或 C++等複雜編程語言，這些技術門檻往往將普通人排除在外。&lt;/p&gt; 
&lt;p&gt;AI 技術的革命性在於其降低了技術應用的門檻。任何人都可以用自然語言與人工智能進行交流，無需經過漫長的技術學習過程。這種變化使得每個創意人員都擁有了技術技能，同時每個技術人員都可以利用 AI 來發揮創造力。&lt;/p&gt; 
&lt;p&gt;黃仁勳指出，因為人工智能的存在，每個人都可以成為"藝術家"或"程序員"，這種身份的轉換為財富創造提供了無限可能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363179</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363179</guid>
      <pubDate>Wed, 16 Jul 2025 08:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英特爾停止開發開源深度學習軟件 PlaidML，倉庫已歸檔</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;根據 PlaidML 開源 GitHub 倉庫的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fplaidml%2Fplaidml" target="_blank"&gt;「已歸檔」提醒&lt;/a&gt;，英特爾已停止對 PlaidML 開源深度學習框架進行維護和支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b8bebfd44f2469fdbe8aa634565d35abbdb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-edaef0683a12744ca6200c5f0153cdc1ffa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PlaidML 是一個開源的張量編譯器，旨在為各種 CPU、GPU 和其他加速器提供性能可移植性。它曾與英特爾的 nGraph 編譯器結合，支持 PyTorch、Keras（TensorFlow）和 OpenVino 等流行的深度學習框架。&lt;/p&gt; 
&lt;p&gt;PlaidML 由英特爾在 2018 年收購的 Vertex.AI 開發，收購之後一直繼續開發，但在經歷一次大規模代碼重組之後開發進度顯著降低，直到今年初徹底死亡，與此同時 AI 領域的競爭在顯著加速。&lt;/p&gt; 
&lt;p&gt;英特爾終止該項目的原因尚未明確，但這一決定對英特爾的開源軟件生態系統來説是一個打擊。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363172/intel-plaidml-archived</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363172/intel-plaidml-archived</guid>
      <pubDate>Wed, 16 Jul 2025 08:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>商湯發佈「日日新 SenseNova V6.5」大模型體系</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;商湯科技在 WAIC 2025 上發佈了「日日新 SenseNova V6.5」大模型體系，其推理和多模態能力超越多個主流模型，且性價比提升 3 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/153957_Ek9w_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/154010_eiFA_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/154040_VjKR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;日日新 V6.5 重點升級了強推理、高效率和智能體三大能力。該模型在國內率先突破圖文交錯思維鏈技術，引入形象思維，並改進了多模態模型的融合架構，使得文本和多模態推理能力超越 Gemini 2.5 Pro 和 Claude-4 Sonnet，多模態交互能力超越 Gemini 2.5 Flash 和 GPT-4o，同時性價比相較 V6.0 提升了 3 倍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363167</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363167</guid>
      <pubDate>Wed, 16 Jul 2025 07:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程軟件 Cline 回應 Anthropic 限制 Max 用量的新政策</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;日前，Anthropic 開始針對 Claude Code 訂閲用户&lt;u&gt;&lt;a href="https://www.oschina.net/news/362871"&gt;加入新的每週用量限制&lt;/a&gt;&lt;/u&gt;，並且根據目前使用情況來計算，這一調整將影響不到 5% 的用户。&lt;/p&gt; 
&lt;p&gt;具體來看，從 8 月 28 日起，Anthropic 將在現有的每 5 小時重置的用量限制基礎上，增加每週用量限制：每 7 天重置的總體每週用量上限；針對 Claude Opus 4 的每週用量上限，每 7 天重置。&lt;/p&gt; 
&lt;p&gt;Anthropic 表示，Claude Code 作為其訂閲服務的一部分，該產品用户增長速度前所未有。但同時 Claude Code 存在一些違反政策的行為，以及一些超常規的使用模式。而這些行為影響了所有用户的系統容量。對此，Anthropic 推出的新用量限制旨在解決這些問題，為所有用户提供一個更公平的使用體驗。&lt;/p&gt; 
&lt;p&gt;而 AI 編程軟件 Cline &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1949943033891307589" target="_blank"&gt;也回應了 Anthropic 的新政策。&lt;/a&gt;&lt;strong&gt;Cline 將 AI 訂閲比作加油站，而車（AI 工具）和油（AI 推理服務）都由同一家 AI 公司控制，用户買了油卻不知道實際加了多少，甚至還沒法瞭解實際消耗和服務內容&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b714d24bfd8ec4d5f5174c7a6b4d395f74e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 認為，任何宣稱自己是無限服務都是不可持續的，AI 推理本質上是像汽油、電力一樣的商品。Cline 還指出，重度用户的使用成本遠超訂閲費用，從而導致服務商虧損，不得不設置限額或限制使用，最終用户體驗也變得受損，得不償失。&lt;/p&gt; 
&lt;p&gt;Cline 還表示，&lt;strong&gt;將來訂閲模式終將被市場淘汰，未來應選擇利益與用户一致、架構透明的工具和平台&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363163</guid>
      <pubDate>Wed, 16 Jul 2025 07:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TPU Deep Dive：Google TPU 架構深度分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 在人工智能算力軍備競賽愈演愈烈的今天，為什麼 Google 會選擇與主流 GPU 截然不同的技術路線，開發出架構獨特的 TPU？這種專用芯片究竟憑藉什麼優勢，能夠支撐起 Gemini、Veo&amp;nbsp;等&amp;nbsp;AI 模型的訓練與推理？&lt;/p&gt; 
 &lt;p&gt;文章從單芯片架構出發，深入剖析了 TPU 的核心設計理念：首先解釋了 TPU 如何通過脈動陣列和流水線技術優化矩陣運算，然後闡述了 XLA 編譯器如何通過預先編譯減少緩存依賴，大幅降低能耗。在多芯片層面，作者詳細介紹了 TPU 從託盤、機架、Pod 到 Multi-Pod 的層級擴展架構，特別是 OCS 光交換技術如何實現靈活的拓撲重構和故障容錯。文章還通過具體案例展示了不同拓撲結構對並行訓練策略的影響，以及 Multi-Pod 架構如何支撐超大規模模型訓練。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Henry Ko&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;最近我大量使用 TPU，發現它們與 GPU 的設計理念非常不同，感覺很有趣。&lt;/p&gt; 
&lt;p&gt;TPU 的主要優勢在於其可擴展性。這是通過硬件層面（例如能效方面和模塊化）與軟件層面（例如 XLA compiler）的協同設計實現的。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 背景信息&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;簡單介紹一下 TPU，它是谷歌的專用集成電路（ASIC），其設計聚焦於兩大要素：極高的矩陣運算（matmul）吞吐量和能源效率。&lt;/p&gt; 
&lt;p&gt;它們的起源可追溯到 2006 年的谷歌。當時，他們正在評估是採用 GPU、FPGA 還是定製的 ASIC。當時，只有少數應用需要使用專用硬件，他們判斷通過從大型數據中心調配多餘的 CPU 算力即可滿足這些需求。但這一情況在 2013 年發生了變化，當時谷歌的語音搜索功能運行在神經網絡上，而內部預測認為，如果該功能發展起來，將需要遠超以往的算力。&lt;/p&gt; 
&lt;p&gt;時至今日，TPU 已為谷歌的大多數人工智能服務提供算力支撐。當然，也包括 Gemini 或 Veo 的訓練和推理，也包括他們的推薦模型。&lt;/p&gt; 
&lt;p&gt;讓我們從底層開始，深入瞭解一下 TPU 的內部構造。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 單個 TPU 芯片內部的架構層級&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;下文圖示均以 TPUv4 為例，但其整體佈局基本也適用於最新一代 TPU（如 TPUv6p 「Trillium」。TPUv7 「Ironwood」 的細節截至 2025 年 6 月尚未公佈）。&lt;/p&gt; 
&lt;p&gt;單顆 TPUv4 芯片的結構如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b7a986ab2586ba485d59aac151bc5dbf109.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPU Single Chip + TensorCore&lt;/p&gt; 
&lt;p&gt;每顆芯片內含兩個 TPU TensorCore，負責所有計算。（注：面向推理的專用 TPU 僅有一個 TensorCore）。兩個 TensorCore 共享同一份內存：CMEM（128 MiB）和 HBM（32 GiB）。&lt;/p&gt; 
&lt;p&gt;而在每個 TensorCore 內部，都有計算單元和較小的內存緩衝區：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）矩陣乘法單元 (MXU)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;這是 TensorCore 的核心部件，是一個 128x128 的脈動陣列（systolic array）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;脈動陣列的原理稍後説明。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2）向量單元（VPU）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;負責執行通用的逐元素操作（例如 ReLU、點加/點乘、歸約操作）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3）向量內存（VMEM；32 MiB）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;內存緩衝區。HBM 中的數據需先複製到 VMEM，TensorCore 才能開始計算。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4）標量單元 + 標量內存（SMEM；10 MiB）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用於調度 VPU 和 MXU 的執行指令。&lt;/li&gt; 
 &lt;li&gt;負責管理控制流、標量運算和內存地址生成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用的是英偉達（NVIDIA）GPU，那麼一些初步觀察結果可能會讓你大吃一驚：&lt;/p&gt; 
&lt;p&gt;1）TPU 的片上內存單元（CMEM、VMEM、SMEM）遠大於 GPU 的 L1/L2 緩存。&lt;/p&gt; 
&lt;p&gt;2）TPU 的 HBM 容量卻遠小於 GPU 的 HBM。&lt;/p&gt; 
&lt;p&gt;3）負責計算的"核心"（cores）數量明顯更少。&lt;/p&gt; 
&lt;p&gt;這與 GPU 架構完全相反 —— GPU 擁有較小的 L1/L2 緩存（以 H100 為例，分別為 256KB 和 50MB）、更大的 HBM（H100 為 80GB）以及數以萬計的計算核心（cores）。&lt;/p&gt; 
&lt;p&gt;在我們進一步討論之前，需明確的是，TPU 與 GPU 同樣具備極高的吞吐量。單顆 TPU v5p 芯片可達 500 TFLOPs/sec，由 8960 顆芯片組成的完整 pod 集羣可實現約 4.45 ExaFLOPs/sec。而最新的 "Ironwood" TPUv7 每個 pod（9216 顆芯片）據稱可達 42.5 ExaFLOPS/sec。&lt;/p&gt; 
&lt;p&gt;要理解 TPU 如何實現這種性能，我們需要深入探究其設計理念。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 TPU 的設計理念&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;TPU 通過兩大技術支柱和一個核心前提實現了驚人的吞吐量與能源效率：systolic array（脈動陣列） + pipelining（流水線）、Ahead-of-Time (AoT) compilation（預先編譯），以及假設絕大多數運算都可通過適配 systolic array（脈動陣列）的方式表達。幸運的是，在現代深度學習（DL）領域，計算的大部分都是矩陣運算，而這些運算都適合使用 systolic array（脈動陣列）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 TPU 設計選擇之一：Systolic Array + Pipelining&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;問：什麼是 Systolic Array？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;答：Systolic Array 是一種硬件設計架構，由相互連接的處理單元（PE）網格組成。每個 PE 執行少量運算（例如乘法和累加運算），並將結果傳遞給相鄰 PE。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-35d3a118a74284c503027134a4294314974.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這種設計的好處是，數據一旦輸入 systolic array（脈動陣列），便無需額外的控制邏輯來處理數據。此外，當脈動陣列的規模足夠大時，除輸入輸出外再無內存讀寫操作。&lt;/p&gt; 
&lt;p&gt;由於脈動陣列的剛性結構設計（rigid organization），其僅能處理具有固定數據流模式的操作，但幸運的是，矩陣乘法和卷積運算（convolutions）恰好完美適配這種架構範式。&lt;/p&gt; 
&lt;p&gt;不僅如此，pipelining（流水線技術）顯然有機會將計算與數據移動重疊執行。下圖展示了 TPU 架構上 pipelined pointwise operation （通過流水線技術，加速 pointwise operation（逐點操作） 的執行過程。）的示意圖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-038f3eb06befc2339ee00a80b38e0b91727.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pipelined Pointwise Operation (from "How to Scale Your Model"&amp;nbsp;[4])&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;旁註：Systolic Arrays（脈動陣列）的侷限性 —— 稀疏性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們可以看到，脈動陣列（systolic arrays）非常喜歡稠密矩陣（dense matrices）（即每個 PE 幾乎每個時鐘週期都處於活躍狀態）。然而，其劣勢是，相同規模的稀疏矩陣（sparse matrices）無法獲得性能提升 —— 即使對於零值元素（zero-valued elements），PE 仍需執行相同數量的計算週期（cycles），導致資源浪費。&lt;/p&gt; 
&lt;p&gt;如若深度學習（DL）領域更傾向於採用更不規則的稀疏性（例如 MoE 架構），應對脈動陣列的這一系統性侷限將變得愈發重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 TPU 設計選擇之二：預先（AoT）編譯 + 減少對緩存的依賴&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本節將回答 TPU 如何通過軟硬件協同設計（TPU + XLA 編譯器）來避免使用緩存，從而實現高能效。&lt;/p&gt; 
&lt;p&gt;首先，請記住傳統緩存是為了處理不可預測的內存訪問模式而設計的。一個應用程序的內存訪問模式（memory access patterns），可能與另一個應用程序大相徑庭。從本質上講，緩存允許硬件靈活地適應各種應用場景。這也是 GPU（相較於 TPU）靈活性極高的一個重要原因。&lt;/p&gt; 
&lt;p&gt;然而，緩存訪問（以及一般意義上的內存訪問）會消耗大量能源。下面是對芯片（45 納米，0.9V；[18]）上各類操作的能耗粗略估計。這裏的主要啓示是，&lt;strong&gt;內存的訪問和控制佔用了大部分的能耗，而算術操作本身的能耗佔比則小得多。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-828c725d5f974a2973ca0fdeaa15296501f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但是，如果你的應用非常特殊，而且其計算和內存訪問模式具有很高的可預測性呢？&lt;/p&gt; 
&lt;p&gt;舉個極端的例子，如果我們的編譯器能提前確定所有需要的內存訪問，那麼硬件僅需一個暫存器作為緩衝區就足以滿足需求，根本不需要緩存。&lt;/p&gt; 
&lt;p&gt;這正是 TPU 的設計理念所追求的，也是 TPU 使用 XLA 編譯器設計以實現這一目標的根本原因。XLA 編譯器通過提前分析計算圖來生成優化過的程序。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;問：但 JAX 在 TPU 上也運行良好，它們使用 &lt;a href="https://my.oschina.net/u/3233893"&gt;@jit&lt;/a&gt; 嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;TPU 上的 JAX+XLA 實際處於 JIT 與 AOT 的混合模式，因此容易產生混淆。當首次調用 JAX 中被 &lt;a href="https://my.oschina.net/u/3233893"&gt;@jit&lt;/a&gt; 修飾的函數時，JAX 會進行代碼追蹤並生成靜態計算圖。然後將其傳遞給 XLA 編譯器，在那裏被轉化為適用於 TPU 的完全靜態二進制文件。在最後的轉化階段，編譯器會實施針對 TPU 的優化（例如，最大限度地減少內存訪問），使整個過程適合 TPU。&lt;/p&gt; 
&lt;p&gt;但有一點需要注意：當輸入張量的形狀（shape）發生變化時，已編譯的 JIT 函數需重新編譯並緩存。這就是為什麼 JAX 在處理動態填充（dynamic padding）或長度隨輸入變化的 for 循環層時表現不佳。&lt;/p&gt; 
&lt;p&gt;當然，這種方案雖有優勢，卻也存在明顯的侷限。它缺乏靈活性，而對編譯器的重度依賴猶如一把雙刃劍。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;那麼，Google 為何仍要堅持這種設計理念？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TPU 及其能源效率（TPUv4）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;前文的能耗示意圖並不能精確反映 TPU 的實際情況，此處是 TPUv4 的能耗細目。注意，TPUv4 採用 7nm 工藝，表中 45nm 的數據僅用於對比（[3], [16]）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-929fea9deb2dd94de8a7dbbbf5af8b32f14.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bae4859f266ed820ecd3b512e9ceb4f62b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;單次操作能耗對比（TPUv4, 7 nm）&lt;/p&gt; 
&lt;p&gt;上方的柱狀圖展示了具體數值，但需注意，現代芯片採用的是 HBM3 內存，其能耗遠低於本圖表中顯示的 DDR3/4 DRAM。儘管如此，該圖仍表明內存操作的能耗仍高出計算操作數個數量級。&lt;/p&gt; 
&lt;p&gt;這恰與 scaling laws 形成呼應：我們非常樂意通過增加浮點運算量（FLOPS）來換取更少的內存操作。因此減少內存操作能帶來雙重優化收益——不僅提升程序運行速度，還可顯著降低能耗。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 TPU 的多芯片互聯層級結構&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現在升級到更高層級，觀察 TPU 在多芯片環境中的運作方式。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 託盤層級（即"板卡"；含 4 個芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8e3fe72f71ddb1cea8fad910065ba1c07b1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;單塊 TPU 託盤包含 4 個 TPU 芯片或 8 個 TensorCore（簡稱"核心"）。每塊託盤配備獨立 CPU 主機（注：推理型 TPU 的每個主機可訪問 2 塊託盤，因其每芯片僅含 1 個核心）。&lt;/p&gt; 
&lt;p&gt;主機（Host） ⇔ 芯片（Chip）的連接採用 PCIe 接口，但芯片（Chip）⇔芯片（Chip）之間通過 Inter-Core Interconnect（ICI）連接，該接口具備更高帶寬。&lt;/p&gt; 
&lt;p&gt;不過 ICI 連接還可進一步擴展至多塊託盤。為此，我們需要繼續提升到機架層級（Rack level）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.2 機架層級（4x4x4 芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;TPU 最令人興奮的特性在於其可擴展性，這一點從機架層級開始顯現。&lt;/p&gt; 
&lt;p&gt;一個 TPU 機架包含 64 個 TPU 芯片，通過 4x4x4 三維環面網絡互聯。如果您看過谷歌的 TPU 宣傳資料（如下圖），這張圖展示的是 8 個 TPU 機架的集羣。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4bd138cd1af2330bfc7d037d4a01afa568f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;8 個 TPU 機架（TPUv4）&lt;/p&gt; 
&lt;p&gt;但在深入討論機架之前，我們需要澄清幾個容易混淆的術語：機架（Rack）、Pod 和切片（Slice）的區別。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;問：TPU 機架、TPU Pod 和 TPU 切片有何不同？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;不同谷歌資料對這些術語的使用存在差異，有時甚至混用"TPU Pod"和"TPU Slice"。本文采用谷歌 TPU 論文和 GCP 官方文檔的定義（[3][7][9]）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）TPU 機架（Rack）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;包含 64 塊芯片的物理單元，也稱為「立方體（cube）」。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2）TPU Pod&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過 ICI 和光纖連接的 TPU 最大單元。&lt;/li&gt; 
 &lt;li&gt;又稱"Superpod"或"Full Pod"。例如 TPUv4 的 TPU Pod 包含 4096 塊芯片（或 64 個機架）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3）TPU 切片（Slice）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;介於 4 塊芯片到 Superpod 規模之間的任何 TPU 配置組合。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;主要區別在於，TPU 機架和 TPU Pod 是物理計量單位，而 TPU 切片是抽象計量單位。當然，TPU 切片的設置涉及重要的物理拓撲約束，但現階段我們暫不展開討論。&lt;/p&gt; 
&lt;p&gt;現在，我們將聚焦物理計量單位：TPU 機架和 TPU Pod。這是因為，理解 TPU 系統的物理連接方式，能更深入地掌握其設計哲學。&lt;/p&gt; 
&lt;p&gt;現在回到 TPUv4 機架的具體結構：&lt;/p&gt; 
&lt;p&gt;單個 TPU 機架通過 ICI 和 OCS（Optical Circuit Switching）技術連接 64 個芯片。實質上，我們通過組合多個託盤（trays）來構建一個 64 芯片的完整系統。這種"將小型單元組裝成超級計算機"的設計理念將持續貫穿後續層級。&lt;/p&gt; 
&lt;p&gt;下圖展示了 TPUv4 單個機架的拓撲結構。它採用 4x4x4 三維環面網絡，其中每個節點都代表一塊芯片，藍色箭頭表示 ICI 鏈路，而各個面上的連接線則代表 OCS（根據文獻 [7] 重繪）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d720ac051e5ed63612d648da6093008d2c0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;使用 OCS 的 TPU 單機架架構&lt;/p&gt; 
&lt;p&gt;然而，這張圖表引出了兩個關鍵問題：為何 OCS 僅應用於環面結構的表面？換句話説 —— 使用 OCS 的核心優勢是什麼？共有三大核心優勢，我們將在後文再詳述另外兩點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的優勢 #1：環繞連接 (Wraparound)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過環形拓撲優化節點間的通信效率。&lt;/p&gt; 
&lt;p&gt;OCS 還承擔特定 TPU 配置的環繞連接功能。該設計將兩節點間的跳數從最壞情況下 N-1 跳降至每軸 (N-1)/2 跳，因為每條軸均形成一個環形（一維環面拓撲）。&lt;/p&gt; 
&lt;p&gt;隨着規模的進一步擴大，這種影響變得更加重要，因為降低芯片間的通信延遲對於高度並行化的實現至關重要。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附註：並非所有 TPU 都採用 3D 環面拓撲&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;注意，早期 TPU（如 TPUv2/v3）及推理專用 TPU（如 TPUv5e/v6e）使用 2D 環面拓撲而非下文所述的 3D 環面。不過 TPUv7"Ironwood" 雖定位為推理芯片，但其拓撲疑似 3D 環面（注：僅根據官方宣傳材料推測）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73f622dc9ad94d85b7665298423d5669470.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2D 環面拓撲示意圖&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.3 Full Pod 層級（又稱 "Superpod"；TPUv4 為 4096 塊芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;正如我們通過互聯多個芯片構建 TPU 機架，我們也可連接多個機架組成大型 Superpod。&lt;/p&gt; 
&lt;p&gt;Superpod 特指僅通過 ICI 和 OCS 互聯的最大 TPU 集羣規模。雖然存在 multi-pod 層級，但這種層級需依賴更慢速的連接方式，後續將展開説明。&lt;/p&gt; 
&lt;p&gt;芯片數量會因版本不同而變化，但 TPUv4 的芯片數量為 4096（即 64 個 4x4x4 芯片的機架）。最新的 TPUv7 "Ironwood" 則高達 9216 塊芯片。&lt;/p&gt; 
&lt;p&gt;下圖展示了 TPUv4 的一個 Superpod：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f3fbc86962bf3edf862e7aa966347174fb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPUv4 Superpod 架構（64 個機架）&lt;/p&gt; 
&lt;p&gt;請注意，每個立方體（即 TPU 機架）是如何通過 OCS 相互連接的，這種設計也支持在 Pod 內靈活劃分 TPU 切片。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;採用 OCS 的 TPU 切片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們可在 Pod 內申請 TPU 子集，即 TPU 切片。但即使所需芯片數 (N) 相同，也存在多種拓撲結構可供選擇。&lt;/p&gt; 
&lt;p&gt;例如，若總共需要 512 塊芯片，可選擇立方體 (8x8x8)、條狀拓撲 (4x4x32) 或矩形拓撲 (4x8x16)。選擇切片的拓撲結構本身就是一個超參數。&lt;/p&gt; 
&lt;p&gt;所選拓撲結構直接影響節點間通信帶寬，進而影響各類並行策略的性能表現。&lt;/p&gt; 
&lt;p&gt;以立方體結構（如 8x8x8）為例，它特別適合需要全連接通信的並行計算模式，比如數據並行或張量並行，因為這種拓撲結構能提供最高的二分帶寬（bisection bandwidth）。而條狀結構（如 4x4x32）則更適用於流水線計算，這種佈局可以讓順序排列的計算層之間實現更快速的數據傳輸（前提是單個計算層能夠適配 4x4 芯片的子切片配置）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-143cbdf8803aec31540f9640581582d1b4f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;典型 TPU 拓撲示例&lt;/p&gt; 
&lt;p&gt;當然，最優拓撲取決於具體模型結構，其尋優過程本身即是一門學問。TPUv4 論文[9]實測表明，拓撲優化可大大提升吞吐量（注：我不確定第一行指的是哪種 LLM 架構，因為沒有具體説明）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3f8cb4956e8dbbdc78ec97d12a6ad2c70f0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不同拓撲結構的吞吐量優化對比&lt;/p&gt; 
&lt;p&gt;前文闡述了 TPU 切片，但另有一項重要的特性有助於提高 TPU 的運行穩定性。&lt;/p&gt; 
&lt;p&gt;藉助 OCS 技術，這些切片無需佔據物理連續的機架空間。這正是 OCS 的第二大優勢 —— 可能也是其最大優勢，但我們此前尚未展開討論。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的優勢 #2：可重新配置的非連續多節點切片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;需注意，這不同於將多個節點硬連在一起來模擬非連續切片。由於 OCS 採用光交換技術而非硬連線架構，跨節點間的物理線纜數量大幅減少，從而支持更大規模的集羣擴展（即可構建超大規模 TPU Pod）。&lt;/p&gt; 
&lt;p&gt;這樣就可以進行靈活的節點規模配置。例如，假設我們想在單個 Pod 上運行三個任務。雖然傳統的調度方式不允許這樣做，但 OCS 連接允許我們抽象出節點的物理位置，使整個 Pod 可視為一個"節點資源池"（根據參考文獻[6]重繪）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4ea87894ad75b8b37c6e3913584dffafa2c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;單任務可將 Pod 內機架視為"節點資源池"&lt;/p&gt; 
&lt;p&gt;此舉不僅提高了 Pod 的利用率，而且能在節點出現故障的情況下簡化維護流程。谷歌將其描述為"故障節點的影響範圍很小"。但尚不確定其液冷系統在部分節點停機時如何運作。&lt;/p&gt; 
&lt;p&gt;最後，這種靈活的 OCS 還有項延伸應用：我們還可以改變 TPU 切片的拓撲結構（例如將規則環面調整為扭曲環面）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的優勢 #3：扭曲環面拓撲&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此前我們通過改變固定芯片數量下的 (x,y,z) 維度來實現不同的 TPU 切片拓撲結構。本節則聚焦固定維度配置，通過改變佈線方式構造新型拓撲。&lt;/p&gt; 
&lt;p&gt;典型案例如下：將常規條狀環面改造為扭曲條狀環面。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-85b47be563d32b35b9ca154cf668cbd2637.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;常規環面 vs 扭曲環面（來源：TPUv4 論文[9]）&lt;/p&gt; 
&lt;p&gt;扭曲環面拓撲結構能加速扭曲二維平面上的芯片之間的通信，該特性對提升全局通信效率尤其有用。&lt;/p&gt; 
&lt;p&gt;下文將深入分析其具體應用場景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;使用扭曲環面加速訓練&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;理論上，扭曲環面對張量並行（TP）的加速效益最大，因為每層涉及多次 all-gather 和 reduce-scatter 操作。對數據並行（DP）也有適度提升，因為每個訓練步需執行 all-reduce 操作，但發生頻率較低。&lt;/p&gt; 
&lt;p&gt;想象一下，假設我們訓練一個標準的僅解碼器架構的 Transformer 模型，並採用多種並行策略來加速訓練。下面我們將看到兩種場景：&lt;/p&gt; 
&lt;p&gt;場景 #1：4x4x16 拓撲結構（TP+PP；共 256 塊芯片）&lt;/p&gt; 
&lt;p&gt;設定 z 軸為流水線 (PP) 維度，二維 TP 維度為 4x4。本質上，假設第 k 層位於 z=k 平面，且每層分片至 16 塊芯片。若未明確繪製，默認採用 OCS 最近鄰連接。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c158c58b081b3127519935fe864668599b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TP+PP 的 4x4x16 拓撲架構&lt;/p&gt; 
&lt;p&gt;通過在每個 z=k 平面實施 2D 環面扭曲，可加速 TP 層內芯片通信。由於 PP 層主要依靠點對點通信，因此沒有必要沿 PP 層扭曲。&lt;/p&gt; 
&lt;p&gt;注：實際應用中，扭曲環面在芯片數＞4x4 時效益顯著。本示例使用 4x4 僅出於可視化的目的。&lt;/p&gt; 
&lt;p&gt;場景 #2：16x4x16 拓撲（DP+TP+PP；共 1024 塊芯片）&lt;/p&gt; 
&lt;p&gt;作為延伸方案，我們在前一場景基礎上增加 DP 維度（x 軸 4 個實例），即沿 x 軸部署 4 組場景 #1 的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4e493d83184c5815acc5549e6e4ca1cac25.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DP+TP+PP 的 16x4x16 拓撲架構&lt;/p&gt; 
&lt;p&gt;請注意，扭曲環面僅應用於每個 DP 模型內的每個 TP 維度（即對每個 z=k 平面實施 4x4 二維扭曲，k 取值 1…16）。DP 維度僅維持基礎的環繞連接，使每行構成長度為 16 的水平環。&lt;/p&gt; 
&lt;p&gt;你可能已經發現還有一種拓撲結構方案（如 8x8x16，即 2x2 DP 維度），但這會混合 DP 與 TP 維度 —— 這就變得更加複雜了。具體來説，我們還不清楚如何在 y 軸構建 OCS 環繞連接的同時兼容各 TP 維度的扭曲環面？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.4 Multi-Pod 層級（即"Multislice"；TPUv4 支持 4096+ 塊芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e021ce9f1d8e82723b22c8fbdf6be01f8e7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPU 層次結構的最終層級是 Multi-pod 架構。此時可將多個 Pod 視為一台大型機器，但 Pod 之間的通信需通過數據中心網絡（DCN） 進行 —— 其帶寬低於 ICI。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c5bb1c222fa2d34a24b8b089ee833b622c1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過 DCN 互聯的雙 Pod 架構&amp;nbsp;[1]&lt;/p&gt; 
&lt;p&gt;PaLM 模型即採用此方案進行訓練。在 6144 個 TPUv4 芯片（2 個 Pod）上耗時 56 天完成。下圖是 6 個 Pod 中的 TPU 任務分配情況：綠色為 PaLM 任務，紅色為空閒狀態，其餘為其他任務。注意每個方格代表一個 4x4x4 的 TPU 芯片立方體。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-791b4b38218cbfe875837f430b10f698ff7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PaLM 訓練過程中的 TPU Pod 利用率&amp;nbsp;[6]&lt;/p&gt; 
&lt;p&gt;實現這一架構已屬不易，但更關鍵的是開發者體驗設計，具體來説，就是要關注：&lt;strong&gt;如何實現模型擴展過程中系統/硬件層面的最大程度抽象化？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;谷歌的解決方案是：由 XLA 編譯器在大規模計算場景下協調芯片間的通信。研究人員只需配置相關參數（如 DP、FSDP、TP 等並行維度及切片數量），XLA 編譯器即會根據當前 TPU 拓撲結構自動插入分層集合通信操作（Xu et al, 2021: GSPMD&amp;nbsp;[2]）。我們的目標是在儘可能少修改代碼的情況下實現大規模訓練。&lt;/p&gt; 
&lt;p&gt;例如，谷歌博客[1]展示了跨多 TPU 切片的 all-reduce 操作分解流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-864563517512833776c5a4b7dd55fc20f47.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;XLA 實現的跨 Pod All-Reduce 規約操作&lt;/p&gt; 
&lt;p&gt;這表明 XLA 編譯器可以同時處理切片內與切片間的集合通信操作。&lt;/p&gt; 
&lt;p&gt;舉個具體例子，在訓練模型時，TPU 的拓撲結構可能如下所示。激活值的通信在切片內通過 ICI 進行，而梯度的通信則需跨切片通過 DCN 完成（即在 DCN 的 DP 維度上）[1]。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f87c248ffd203825db16d7c22f26d12bcb7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 實物圖示對照解析&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;結合硬件實拍圖理解架構圖會更直觀，以下為綜合解析。&lt;/p&gt; 
&lt;p&gt;若看過谷歌 TPU 宣傳資料，可能見過下圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ae14450a22f237528185172376402b3a6d3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;8 個 TPU 機架（TPUv4）&lt;/p&gt; 
&lt;p&gt;此圖為 8 個 TPU Pods 的集羣，每個單元即前述的 4x4x4 三維環面架構。一個 Pod 中的每一行有 2 個託盤，這意味着每一行有 8 個 TPU 芯片。&lt;/p&gt; 
&lt;p&gt;單塊 TPUv4 託盤實拍圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b5b9d5a5afd11a5c6d6ace8039c121749ab.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;請注意，圖中簡化為只有一個 PCIe 端口，但實際託盤上有 4 個 PCIe 端口（在左側） —— 每個 TPU 一個。&lt;/p&gt; 
&lt;p&gt;單芯片結構圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5d7b5b890cac752887d5cf0368066797a60.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPUv4 芯片：中央是 ASIC + 4 組 HBM 內存堆棧&lt;/p&gt; 
&lt;p&gt;中央區域為 ASIC 芯片，周圍 4 個區塊為 HBM 內存堆棧。因 TPUv4 內含 2 個 TensorCore，故配置 4 組 HBM 內存堆棧。&lt;/p&gt; 
&lt;p&gt;未找到 TPUv4 芯片平面圖，此處展示結構近似的 TPUv4i（推理芯片），其僅含 1 個 TensorCore[3]：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-77ee6c51de3ea94847bc8083d166140baba.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可見 CMEM（芯片內存）在 TPUv4i 的佈局中佔據了相當大的空間。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 致謝&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;感謝 Google TPU Research Cloud（TRC）提供的 TPU 資源支持！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] Google Blog: TPU Multi-Slice Training（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fcompute%2Fusing-cloud-tpu-multislice-to-scale-ai-workloads%EF%BC%89" target="_blank"&gt;https://cloud.google.com/blog/products/compute/using-cloud-tpu-multislice-to-scale-ai-workloads）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] Xu, et al. "GSPMD: General and Scalable Parallelizaton for ML Computation Graphs"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2105.04663%EF%BC%89" target="_blank"&gt;https://arxiv.org/pdf/2105.04663）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] Jouppi et al. "Ten Lessons From Three Generations Shaped Google's TPUv4i"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgwern.net%2Fdoc%2Fai%2Fscaling%2Fhardware%2F2021-jouppi.pdf%EF%BC%89" target="_blank"&gt;https://gwern.net/doc/ai/scaling/hardware/2021-jouppi.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] How to Scale Your Model - TPUs（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Ftpus%2F%EF%BC%89" target="_blank"&gt;https://jax-ml.github.io/scaling-book/tpus/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] Domain Specific Architectures for AI Inference - TPUs（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffleetwood.dev%2Fposts%2Fdomain-specific-architectures%23google-tpu%EF%BC%89" target="_blank"&gt;https://fleetwood.dev/posts/domain-specific-architectures#google-tpu）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] HotChips 2023: TPUv4（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc2023.hotchips.org%2Fassets%2Fprogram%2Fconference%2Fday2%2FML%2Btraining%2FHC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf%EF%BC%89" target="_blank"&gt;https://hc2023.hotchips.org/assets/program/conference/day2/ML+training/HC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Google Cloud Docs: TPUv4（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Ftpu%2Fdocs%2Fv4%EF%BC%89" target="_blank"&gt;https://cloud.google.com/tpu/docs/v4）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8] Jouppi et al. "In-Datacenter Performance Analysis of a Tensor Processing Unit" -- TPU origins paper（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1704.04760%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/1704.04760）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9] Jouppi et al. "TPU v4"-- TPUv4 paper（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2304.01433%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2304.01433）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10] PaLM training video（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D0yPFBxkOKRY%EF%BC%89" target="_blank"&gt;https://www.youtube.com/watch?v=0yPFBxkOKRY）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11] HotChips 2021: "Challenges in large scale training of Giant Transformers on Google TPU machines"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc33.hotchips.org%2Fassets%2Fprogram%2Ftutorials%2FHC2021.Google.Sameer%2BKumar.pdf%EF%BC%89" target="_blank"&gt;https://hc33.hotchips.org/assets/program/tutorials/HC2021.Google.Sameer+Kumar.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12] HotChips 2020: "Exploring Limits of ML Training on Google TPUs"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc32.hotchips.org%2Fassets%2Fprogram%2Ftutorials%2FHC2020.Google.SameerKumarDehaoChen.v02.pdf%EF%BC%89" target="_blank"&gt;https://hc32.hotchips.org/assets/program/tutorials/HC2020.Google.SameerKumarDehaoChen.v02.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13] Google Blog: Ironwood（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgoogle-cloud%2Fironwood-tpu-age-of-inference%2F%EF%BC%89" target="_blank"&gt;https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14] HotChips 2019: "Cloud TPU: Codesigning Architecture and Infrastructure"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fold.hotchips.org%2Fhc31%2FHC31_T3_Cloud_TPU_Codesign.pdf%EF%BC%89" target="_blank"&gt;https://old.hotchips.org/hc31/HC31_T3_Cloud_TPU_Codesign.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15] ETH Zurich's Comp Arch Lecture 28: Systolic Array Architectures（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DXkgtANeDrm8%EF%BC%89" target="_blank"&gt;https://www.youtube.com/watch?v=XkgtANeDrm8）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16] Patterson presentation: "A Decade of Machine Learning Accelerators: Lessons Learned and Carbon Footprint"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cs.ucla.edu%2Fwp-content%2Fuploads%2Fcs%2FPATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf%EF%BC%89" target="_blank"&gt;https://www.cs.ucla.edu/wp-content/uploads/cs/PATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17] Camara et al. "Twisted Torus Topologies for Enhanced Interconnection Networks."（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpersonales.unican.es%2Fvallejoe%2FPublications%2FC%25C3%25A1mara%2B-%2BTPDS%2710%2B-%2BTwisted%2BTorus%2BTopologies%2Bfor%2BEnhanced%2BInterconnection%2BNetworks.pdf%EF%BC%89" target="_blank"&gt;https://personales.unican.es/vallejoe/Publications/C%C3%A1mara+-+TPDS'10+-+Twisted+Torus+Topologies+for+Enhanced+Interconnection+Networks.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18] Horowitz article: "Computing's Energy Problem(and what we can do about it)"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgwern.net%2Fdoc%2Fcs%2Fhardware%2F2014-horowitz-2.pdf%EF%BC%89" target="_blank"&gt;https://gwern.net/doc/cs/hardware/2014-horowitz-2.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;您更傾向 TPU 的專用化路線（犧牲靈活性換取能效），還是 GPU 的通用化路線（保留靈活性但能耗較高）？請結合您的應用場景説明理由。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhenryhmko.github.io%2Fposts%2Ftpu%2Ftpu.html" target="_blank"&gt;https://henryhmko.github.io/posts/tpu/tpu.html&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18686348</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18686348</guid>
      <pubDate>Wed, 16 Jul 2025 07:14:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
