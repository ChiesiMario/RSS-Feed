<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Fri, 08 Aug 2025 21:40:12 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Perplexity 為特朗普 Truth Social 提供技術支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 初創公司 Perplexity 正在為美國總統特朗普的社交媒體平台 Truth Social 提供技術支持，推出全新的 AI 搜索引擎。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這款名為"Truth Search AI"的搜索引擎已在 Truth Social 網頁版上線，iOS 和 Android 應用的公測版本預計將在"不久的將來"推出。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特朗普媒體在新聞稿中表示，Perplexity 的技術能夠提供"直接、上下文準確的答案和透明引用"，這將幫助 Truth Social"指數級增加"用户可獲取的信息量。不過，該社交媒體平台仍保留對 AI 搜索引擎信息來源的控制權。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Truth Social 使用的是 Perplexity Sonar API，該接口承諾能夠查詢網絡以獲取&lt;span&gt;最新&lt;/span&gt;和經過驗證的信息，即使這些信息來自屏蔽 Perplexity 爬蟲的網站，同時支持結構化輸出，允許用户自定義搜索引擎響應的格式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Perplexity 發言人傑西·德懷爾向 TechCrunch 透露，Sonar API 的準確性取決於 Truth Social 限制的信息源範圍。德懷爾表示:"我們對此沒有可見性或控制權，就像你在自己公司內部使用 API，或者作為學術研究人員想要用它搜索自己的數據一樣。"&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TechCrunch 已聯繫特朗普媒體瞭解更多信息，包括 Truth Search AI 是否能訪問整個網絡、是否會優先考慮某些信息源，以及 AI 是否會被指示對總統和現任政府給出有利回應，對民主黨人給出不利評價。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;為了評估該搜索機器人會引用哪些信息源，Axios 向其提出了一系列問題，如"2021 年 1 月 6 日發生了什麼?"和"唐納德·特朗普為什麼被彈劾?"在所有回應中，FoxNews.com 要麼是最常見的信息源，要麼是&lt;span&gt;唯一&lt;/span&gt;列出的信息源。其他信息源包括 FoxBusiness.com、《華盛頓時報》或《大紀元時報》。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;相比之下，Perplexity 的公共搜索引擎返回更廣泛的信息源，包括維基百科、Reddit、YouTube、NPR 和 Politico 等。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特朗普媒體 CEO、前加利福尼亞州國會議員德文·努內斯在聲明中表示，Truth Social 計劃"根據用户反饋完善和擴展搜索功能，同時為平台實施廣泛的額外增強功能"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Perplexity 首席商務官德米特里·舍韋連科在聲明中也指出，Perplexity 的 AI 提供帶有"透明引用的答案，讓任何人都能深入挖掘"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;7 月下旬，特朗普在發佈 AI 行動計劃的同時，頒佈了一項針對"有偏見 AI"或非"意識形態中立"模型的行政命令。該命令特別將有關種族或性別、無意識偏見、系統性種族主義以及其他歸入多元化、公平和包容性範疇的觀念稱為"普遍且具有破壞性"的意識形態，可能"扭曲輸出的質量和準確性"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Truth Search AI 的推出正值 OpenAI、Anthropic 和谷歌等&lt;span&gt;頂級&lt;/span&gt;AI 公司被列入獲準向聯邦民用機構銷售服務的供應商名單。OpenAI 週三與美國政府中央採購部門達成協議，以每年僅 1 美元的價格向各機構銷售 ChatGPT 企業版。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365083</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365083</guid>
      <pubDate>Thu, 07 Aug 2025 10:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>天翼雲與飛輪科技達成戰略合作，共築雲數融合新生態</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;點擊關注，瞭解更多&lt;strong&gt;實時數倉領域&lt;/strong&gt;前沿資訊與技術實踐！&lt;/p&gt; 
&lt;p&gt;---&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;2025 年 7 月 23 日，天翼雲科技有限公司與北京飛輪數據科技有限公司戰略合作簽約儀式順利舉行。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;後續雙方將秉承誠信互用原則，基於各自產品技術優勢，在技術共創、商業拓展、生態構建等領域展開深度合作，為千行百業數字化轉型注入新動能。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;天翼雲智能邊緣事業部副總經理、大數據產品線總經理任春德和飛輪科技創始人王猛代表雙方簽約。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//5e550aa74269d1150d02bef40b574574.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;&lt;span&gt;數字經濟加速滲透的今天，數據作為核心生產要素的價值日益凸顯。《數字中國建設整體佈局規劃》、《「數據要素 ×」 三年行動計劃》、《國家數據基礎設施建設指引》等國家政策的發佈持續推動數據基礎設施建設，企業對實時數據處理、高效數據分析的需求愈發迫切。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;天翼雲自主研發的大數據平台翼 MR，基於 Apache Doris 和&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;Apache Iceberg&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;構建湖倉一體方案，兼具靈活性、高性能和低成本優勢，同時滿足了各行業客户報表和 BI 分析、湖倉融合分析、日誌存儲分析、高併發實時分析、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;MPP&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;數據庫國產化替代等多種場景需求，已在多行業多場景下驗證了其強大能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;&lt;span&gt;飛輪科技自 2022 年成立以來，積極投身 Apache Doris 開源社區建設的同時，自主研發的實時數據倉庫 SelectDB，滿足大規模實時數據場景下的極速查詢分析需求，已服務全球 5000 餘家金融、電信、製造、能源、汽車、物流、政務等中大型企業，沉澱了實時報表、用户畫像、數據湖查詢、日誌分析等成熟的行業解決方案。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//2d53bf3fc9768ff9b0897eb4e2e6e2a5.jpg" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;此次合作，天翼雲的大數據基礎設施與飛輪科技的實時數據分析技術形成深度協同，天翼雲翼 MR 為數據處理提供穩定、安全的 「數據底座」，飛輪科技則以 SelectDB 激活數據的實時價值，共同構建 「存、算、管、用」 一體化的雲數融合解決方案。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;後續雙方將圍繞四大方向展開合作：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span style="color:#0065fd"&gt;技術共創是合作核心。&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;雙方將聚焦 Apache Doris 技術生態，聯合開展研發創新，推動實時數據倉庫技術迭代，提升在開源社區的影響力，助力國產分析型數據庫技術自主可控。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span style="color:#0065fd"&gt;商業協同覆蓋全場景&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;。共同推廣基於 Apache Doris 的湖倉一體解決方案，重點服務實時報表、湖倉融合分析、日誌存儲分析等高價值場景，加速政企客户數字化轉型。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span style="color:#0065fd"&gt;生態共建強化品牌合力。&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;通過聯合品牌曝光、技術峯會、行業活動等形式，雙方將共同強化在實時數據分析領域的領導地位，吸引產業鏈上下游夥伴加入，構建開放共贏的產業生態。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span style="color:#0065fd"&gt;人才共育夯實長期基礎。&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;在 Apache Doris 開源社區聯合培養技術人才，通過培訓、研討會等形式，提升社區活躍度與技術儲備，為行業持續輸出專業力量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;&lt;span&gt;此次戰略合作的達成，標誌着天翼雲進一步完善了大數據的生態拼圖，飛輪科技將基於合作資源加速技術商業化進程。雙方將以 「優勢互補、共同開拓、強強聯合、合作共贏」 為原則，攜手構建雲數融合新生態，為促進經濟的高質量發展注入澎湃動力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;- END -&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//eb111e9017f84234e63685f961c56ebc.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#888888"&gt;&lt;span&gt;作為基於 Apache Doris 的商業化公司，飛輪科技秉承着 「開源技術創新」和「實時數倉服務」雙輪驅動的戰略，在投入資源大力參與 Apache Doris 社區研發和推廣的同時，基於 Apache Doris 內核打造了聚焦於企業大數據實時分析需求的企業級產品 SelectDB ，面向新一代需求打造世界領先的實時分析能力。自 2022 年成立以來，獲得 IDG 資本、紅杉中國、襄禾資本等頂級 VC 的近 10 億元融資，創下了近年來開源基礎軟件領域的新紀錄。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365081</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365081</guid>
      <pubDate>Thu, 07 Aug 2025 10:37:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Valkey 單點性能比肩 Redis 集羣了？Valkey8.0 新特性分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、&amp;nbsp; 背景&lt;/h1&gt; 
&lt;p&gt;Valkey 社區於 2024 年 09 月發佈了 Valkey8.0 正式版，在之前的文章《Redis 是單線程模型？》中，我們提到，Redis 社區在 Redis6.0 中引入了多線程 IO 特性，將 Redis 單節點訪問請求從 10W/s 提升到 20W/s，而在 Valkey8.0 版本中，通過引入異步 IO 線程、內存預取（Prefetch）、內存訪問分攤（MAA）等新特性，並且除了將讀寫網絡數據卸載到 IO 線程執行外，還會將 event 事件循環、對象內存釋放等耗時動作也卸載到 IO 線程執行，使得 Valkey 單節點訪問請求可以提升到 100W/s，大幅提升 Valkey 單節點性能。&lt;/p&gt; 
&lt;p&gt;Valkey 8.0 中引入的異步 IO 與 Redis 6.0 中的多線程 IO 有什麼區別？Valkey8.0 中如何應用內存預取和內存訪問分攤技術進一步來提升性能的？本篇文章讓我們來一起看看。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2024 年，Redis 商業支持公司 Redis Labs 宣佈 Redis 核心代碼的許可證從 BSD 變更為 RSALv2 ，明確禁止雲廠商提供 Redis 託管服務，這一決定直接導致社區分裂。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為維護開源自由，Linux 基金會聯合多家科技公司（包括 AWS、Google Cloud、Oracle 等）宣佈支持 Valkey ，Valkey 基於 Redis 7.2.4 開發，作為 Redis 的替代分支。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Valkey8.0 為 Valkey 社區發佈的首個主要大版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最新消息，在 Redis 項目創始人 antirez 今年加入 Redis 商業公司 5 個月後，Redis 宣傳從 Redis8 開始，Redis 項目重新開源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、&amp;nbsp; 異步 IO 線程背景&lt;/h1&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;Redis6.0 多線程 IO&lt;/h4&gt; 
&lt;p&gt;在 Redis 6.0 中引入了多線程 IO 特性，用來處理網絡數據的讀寫和協議解析，讀寫數據執行流程如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5375925ba50c7c815558c17f2726d0f5.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 Redis6.0 中，讀數據流程是主線程先將所有可讀客户端加入一個隊列，全部處理完後，再通過 RR 算法將這些可讀客户端分配給 IO 線程，由 IO 線程執行讀數據；寫數據流程類似處理。&lt;/p&gt; 
&lt;p&gt;儘管引入多線程 IO 大幅提升了 Redis 性能，但是&amp;nbsp;&lt;strong&gt;Redis6.0 的多線程 IO 仍然存在一些不足：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;主線程在處理客户端命令時，IO 線程會均處於空閒狀態；由於主線程會阻塞等待所有 IO 線程完成讀寫數據，主線程在執行 IO 相關任務期間的性能受到最慢 IO 線程速度的限制&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;由於主線程同步等待 IO 線程，IO 線程僅執行讀取解析和寫入操作，主線程仍然承擔大部分 IO 任務&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;Valkey 8.0 異步 IO 線程&lt;/h4&gt; 
&lt;p&gt;Valkey8.0 通過使用任務隊列使主線程向 IO 線程發送任務，IO 線程異步並行執行任務提升整體性能。Valkey 8.0 異步 IO 線程工作流程整體設計圖如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//7bcc95e1d36fbabb48b1e8829daacc4a.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;IO 線程初始化&lt;/h4&gt; 
&lt;p&gt;在 Valkey 啓動時進行初始化的時候，根據配置的線程數量 server.io_threads_num&amp;nbsp;決定是否創建異步 IO 線程，如果 server.io_threads_num == 1 表示不開啓，另外，IO 線程數量最大不超過 15 個；如果配置開啓異步 IO 線程，則初始化的時候按需創建異步 IO 線程。&lt;/p&gt; 
&lt;span id="OSC_h4_6"&gt;&lt;/span&gt; 
&lt;h4&gt;線程間通信&lt;/h4&gt; 
&lt;p&gt;Valkey 初始化創建 IO 線程的時候，會給每個 IO 線程創建一個&lt;strong&gt;靜態、無鎖、固定大小（大小為 2048）的&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;環形緩衝區&lt;/strong&gt;作為任務隊列，用於主線程發送任務，以及 IO 線程接收任務。&lt;/p&gt; 
&lt;p&gt;環形緩衝區是從主線程到 IO 線程的單向通道。當發生讀/寫事件時，主線程會發送一個讀/寫任務，然後在進入 event 事件監測休眠之前，它會遍歷所有待處理的讀/寫客户端，檢查每個客户端的 IO 線程是否已經處理完畢。IO 線程通過切換客户端結構體上的原子標誌 read_state / write_state 來表示它已經處理完一個客户端的讀/寫操作。&lt;/p&gt; 
&lt;span id="OSC_h4_7"&gt;&lt;/span&gt; 
&lt;h4&gt;讀數據流程&lt;/h4&gt; 
&lt;p&gt;讀數據流程如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//48484b4ab3428948bf602d27b4c2e200.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;主線程監測到有讀事件時，檢查是否開啓 IO 線程，如果開啓了 IO 線程，會根據算法選擇一個 IO 線程，檢查選中的 IO 線程任務隊列是否已滿，如果任務隊列未滿，則將該待讀事件客户端加入 IO 線程的任務隊列。&lt;/p&gt; 
&lt;p&gt;如果未開啓 IO 線程，或者選中的 IO 線程任務隊列已滿，則由主線程完成讀數據操作並執行命令。&lt;/p&gt; 
&lt;p&gt;IO 線程循環從任務隊列獲取任務，如果是讀數據任務，則執行讀數據流程。先讀取數據，然後解析命令，並從命令列表中查找命令並保存在指定字段（這裏也是把本來由主線程在執行命令時執行的動作卸載到 IO 線程完成）。&lt;/p&gt; 
&lt;p&gt;主線程在進入 event 事件監聽睡眠前，循環遍歷所有在等待 IO 線程讀數據的客户端，檢查數據是否讀取完成，如果是則加入批量預取數據數組，當全部客户端都檢查完成或者批量預取數據數組存滿，則批量執行命令。&lt;/p&gt; 
&lt;p&gt;在 Redis6.0 中，需要先將所有可讀客户端存入一個隊列，再遍歷可讀客户端列表通過 RR 算法將可讀事件分配到不同的 IO 線程中，然後主線程設置 IO 線程開啓讀數據，在主線程執行這些操作期間，IO 線程均處於空閒狀態。&lt;/p&gt; 
&lt;p&gt;在 Valkey 8.0 中，每監測到一個可讀事件，立即通過任務隊列發送到一個 IO 線程，IO 線程立即可以開始讀數據操作，主線程遍歷後續可讀事件期間，IO 線程異步在執行讀取操作。&lt;/p&gt; 
&lt;span id="OSC_h4_8"&gt;&lt;/span&gt; 
&lt;h4&gt;寫數據流程&lt;/h4&gt; 
&lt;p&gt;主線程執行完每個命令時，將客户端加入等待等寫隊列 clients_pending_write，將響應客户端的數據寫入到響應緩存 buf 或者 reply 鏈表。&lt;/p&gt; 
&lt;p&gt;主線程處理完所有命令後，循環遍歷等待寫隊列 clients_pending_write，將通過算法選擇一個 IO 線程，如果選中的 IO 線程任務隊列未滿，將該客户端寫數據任務加入 IO 線程的任務隊列。&lt;/p&gt; 
&lt;p&gt;IO 線程循環從任務隊列獲取任務，如果是寫數據任務，則執行寫數據流，將數據寫回給用户。&lt;/p&gt; 
&lt;span id="OSC_h4_9"&gt;&lt;/span&gt; 
&lt;h4&gt;動態調整 IO 線程數量&lt;/h4&gt; 
&lt;p&gt;每次在有可讀事件或者可寫事件需要執行前，Valkey 會根據可讀/寫事件數量，動態調整活躍 IO 線程數量，最大活躍 IO 線程數量不超過設置的允許 IO 線程數量（固定為 15）。&lt;/p&gt; 
&lt;p&gt;根據可讀/寫事件數量、每個 IO 線程可執行事件數量（可配置）、以及最大允許活躍 IO 線程數量，計算需要的目標活躍 IO 線程數量，當前活躍 IO 線程數量小於目標數量時，可增加活躍 IO 線程，當前活躍 IO 線程數量大於目標數量時，可減少活躍 IO 線程。&lt;/p&gt; 
&lt;p&gt;動態增加或者減少活躍 IO 線程數量，減少活躍 IO 線程並不會直接關閉創建出來的 IO 線程，而是通過加鎖使當前沒有任務可執行的 IO 線程暫停輪詢查找任務，避免 IO 線程不必要的空輪詢；同樣增加活躍 IO 線程只需要主線程釋放鎖即可，IO 線程獲取到鎖後，開始輪詢獲取是否有可執行任務需要執行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;儘管 I/O 線程數量可動態調整，具有動態特性，但主線程仍保持線程親和性，確保在可能的情況下由同一個 I/O 線程處理同一客户端的 I/O 請求，從而提高內存訪問的局部性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_10"&gt;&lt;/span&gt; 
&lt;h4&gt;卸載更多任務到 IO 線程&lt;/h4&gt; 
&lt;p&gt;在 Valkey 8.0 中，除了讀取解析數據/寫入操作之外，還將很多額外的工作卸載到 I/O 線程，以便更好地利用 I/O 線程並減少主線程的負載。&lt;/p&gt; 
&lt;span id="OSC_h4_11"&gt;&lt;/span&gt; 
&lt;h4&gt;事件輪詢卸載到 IO 線程&lt;/h4&gt; 
&lt;p&gt;在 Valkey 中使用了 IO 多路複用模型實現在主線程中來高效處理所有來自客户端的連接讀寫訪問，而套接字輪詢系統調用（例如 epoll_wait）是開銷很大的過程，僅由主線程來執行會消耗大量主線程時間。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 中，當主線程有待處理的 I/O 操作或要執行的命令時，主線程都會將套接字輪詢系統調用調度到 IO 線程執行，否則由主線程自身來執行。&lt;/p&gt; 
&lt;p&gt;為避免競爭條件，&lt;strong&gt;在任何給定時間，最多隻有一個線程（io_thread 或主線程）執行 epoll_wait&lt;/strong&gt;，當主線程將事件輪詢系統調用分配給一個 IO 線程執行後，主線程執行完命令處理後，不再執行事件輪詢系統調用，而是直接檢查 IO 線程的輪詢等待結果，查看是否有可讀寫事件。&lt;/p&gt; 
&lt;span id="OSC_h4_12"&gt;&lt;/span&gt; 
&lt;h4&gt;對象釋放卸載到 IO 線程&lt;/h4&gt; 
&lt;p&gt;在 Valkey 讀取客户端數據後，命令解析過程中會分配大量命令參數對象，在命令處理完成後，需要釋放為這些命令參數分配的內存空間，在 Valkey8.0 中，將這些命令參數內存空間釋放分配給 IO 線程執行，並且會分配給執行該參數解析（內存分配）的同一個 IO 線程來執行（通過客户端 ID 進行標識）。&lt;/p&gt; 
&lt;span id="OSC_h4_13"&gt;&lt;/span&gt; 
&lt;h4&gt;命令查找卸載&lt;/h4&gt; 
&lt;p&gt;如前面在讀數據流程中提到的，當 IO 線程解析來自客户端的 Querybuf 的命令時，它可以在命令字典中執行命令查找，並且 IO 線程會將查找到的命令存儲在客户端的指定字段中，後續主線程執行命令時直接使用即可，可以節省主線程執行命令的時間。&lt;/p&gt; 
&lt;span id="OSC_h1_14"&gt;&lt;/span&gt; 
&lt;h1&gt;三、&amp;nbsp;數據預取 (Prefetch) 與內存訪問分攤（MAA）&lt;/h1&gt; 
&lt;p&gt;在 Valkey8.0 中引入異步 IO 線程提高並行度，並且將更多的工作轉移到 IO 線程，將主線程執行的 I/O 操作量降至最低，此時，經過測試，單個 Valkey 節點每秒處理請求可達 80W。&lt;/p&gt; 
&lt;p&gt;通過分析開啓 IO 線程後 Valkey 性能，主線程大部分時間都花銷在訪問內存查找 key，這是因為 Valkey 字典是一個簡單但低效的鏈式哈希實現，在遍歷哈希鏈表時，每次訪問 dictEntry 結構體、指向鍵的指針或值對象，都很可能需要進行昂貴的外部內存訪問。&lt;/p&gt; 
&lt;p&gt;於是在 Valkey8.0 中引入了**數據預取（Prefetch）和內存訪問分攤（MAA）**技術，進一步提升 Valkey 單節點訪問性能。&lt;/p&gt; 
&lt;span id="OSC_h4_15"&gt;&lt;/span&gt; 
&lt;h4&gt;數據預取（Prefetch）&lt;/h4&gt; 
&lt;p&gt;隨着摩爾定律在過去 30 年間的持續生效，CPU 的運算速度大幅提升，而存儲器（主要是內存）的速度提升相對較慢，這導致了存儲器與 CPU 之間的速度差異。當 CPU 執行指令時，如果需要從內存中讀取數據或指令，由於存儲器速度的限制，CPU 可能需要等待訪問存儲器操作完成，從而導致性能瓶頸。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//68471ba00c97e2f740ede5c9479170c8.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為瞭解決訪問存儲器瓶頸這一問題，現代計算機系統採用了多級緩存及內存層次結構，包括 L1、L2、L3 緩存以及主存等。儘管高速緩存（Cache）能夠提供更快的訪問速度，但其容量有限，當 CPU 訪問的數據無法在高速緩存中找到時，就需要從更慢的內存層級中獲取數據，這會導致較高的訪問延遲，並降低整體性能。&lt;/p&gt; 
&lt;p&gt;數據預取（Prefetching）技術可以在一定程度上解決訪問存儲器成為 CPU 性能瓶頸的問題。數據預取是一種提前將數據或指令從內存中預先加載到高速緩存中的技術。通過預取，CPU 可以在實際使用之前將數據預先加載到緩存中，從而減少對內存的訪問延遲。這樣可以提高訪問存儲器的效率，減少 CPU 等待訪問存儲器的時間，從而提升整體性能。&lt;/p&gt; 
&lt;p&gt;__builtin_prefetch() 是 gcc 編輯器提供的一個內置函數，它通過對數據手工預取到 CPU 的緩存中，減少了讀取延遲，從而提高程序的執行效率。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 中，主線程在執行命令之前，通過使用 __builtin_prefetch() 命令，對所有即將操作的命令參數、key 及對應的 value 進行批量預取，提高主線程執行命令的效率。&lt;/p&gt; 
&lt;span id="OSC_h4_16"&gt;&lt;/span&gt; 
&lt;h4&gt;內存訪問分攤（MAA）&lt;/h4&gt; 
&lt;p&gt;內存訪問攤銷 (MAA) 是一種旨在通過降低內存訪問延遲的影響來優化動態數據結構性能的技術。它適用於需要併發執行多個操作的情況。其背後的原理是，對於某些動態數據結構，批量執行操作比單獨執行每個操作更高效。&lt;/p&gt; 
&lt;p&gt;這種方法並非按順序執行操作，而是將所有操作交錯執行。具體做法是，每當某個操作需要訪問內存時，程序都會預取必要的內存並切換到另一個操作。這確保了當一個操作因等待內存訪問而被阻塞時，其他內存訪問可以並行執行，從而降低平均訪問延遲。&lt;/p&gt; 
&lt;span id="OSC_h4_17"&gt;&lt;/span&gt; 
&lt;h4&gt;Valkey8.0 預取數據應用&lt;/h4&gt; 
&lt;p&gt;Valkey 是一個鍵值對數據庫，在 Valkey 中的鍵值對是由字典（也稱為 hash 表）保存的，如下圖所示的鏈式哈希表。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cd1cd5adf93474cd0357a33b0979b79e.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 之前，在哈希表中查找一個 key 及對應的 value 步驟如下描述：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;計算 key 的 hash 值，找到對應的 bucket&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遍歷存儲在 bucket 中通過鏈表連接的 entry，直到找到需要的 key&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果找到 key，再訪問 key 映射的 RedisObj（也就是存儲的 value），如果存儲的 value 是 OBJ_ENCODING_RAW 類型，還需要進一步訪問內存地址獲取真正的數據&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;每一步操作都需要等待前面的步驟完成內存數據讀取，整個訪問過程是一個串行步驟，這種動態數據結構會阻礙處理器推測未來可以並行執行的內存加載指令的能力，因此訪問內存成為 Valkey 處理數據的性能瓶頸。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 中，對於具有可執行命令的客户端（即 IO 線程已解析命令的客户端），主線程將創建一個最多包含 16 條命令的批次，批量處理這些命令。並且執行命令前，先將命令參數預取到主線程的一級緩存中，再將所有命令所需的字典條目 entry 和值 value 都從字典中預取。&lt;/p&gt; 
&lt;p&gt;同時，預取命令所需的字典條目 entry 和值 value 時遍歷字典的方式與上述查找 key 過程類似，不同的是，每個 key 每次只執行一步，然後不等待從內存中完成讀取數據，而只是預取數據，然後繼續執行下一個 key 的下一次預取動作。這樣當所有 key 都遍歷完成第一步後，開始執行第二步的時候，執行第二步所需的第一步數據已經預取到了 L1 高速緩存。這樣通過交錯執行所有 key，並且結合預取，達到分攤訪問內存的效果。&lt;/p&gt; 
&lt;p&gt;單個 key 預取流程如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9e9c931a61fcbcd4bbc4b3e96130cef9.jpeg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;每批次多個 key 預取流程則是&lt;strong&gt;循環遍歷每個 key 交錯執行&lt;/strong&gt;上述步驟，先預取其中一個 key 的 bucket，然後不會執行預取該 key 的 entry，因為此時如果接着流程預取該 key 的 entry，需要等待將該 key 的 bucket 內存讀取出來；而是執行下一個 key 的預取動作。也就是達成所有 key 的預取動作一直在並行執行效果，分攤內存訪問時間。&lt;/p&gt; 
&lt;p&gt;多個 key 批量預取流程如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f3f922b4aa11d09e6fdbfbdd56467008.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;循環遍歷每個 key 交錯執行上述步驟，先執行一個 key 的預取動作，然後交錯執行另一個 key 的預取動作，所有 key 的預取動作並行執行，降低所有 key 訪問內存總時間。&lt;/p&gt; 
&lt;p&gt;同一批次所有 key 和 value 都完成預取後，主線程開始批量執行命令。相比在 Valkey8.0 之前的版本中，主線程逐個處理每個客户端命令，批量預取數據加上批量處理，大幅提升單節點 Valkey 服務器性能，社區測試單節點 Valkey 訪問請求可以達到每秒 120W。&lt;/p&gt; 
&lt;span id="OSC_h1_18"&gt;&lt;/span&gt; 
&lt;h1&gt;四、&amp;nbsp; 總結&lt;/h1&gt; 
&lt;p&gt;本文分析了在 Valkey8.0 中通過引入**異步 IO 線程、內存預取（Prefetch）、內存訪問分攤（MAA）**等新特性，極大的提升了 Valkey 單節點性能，這些技術手段和算法思想也值得我們在實際業務開發中借鑑和使用。&lt;/p&gt; 
&lt;p&gt;Valkey8.0 中以上性能提升特性由亞馬遜貢獻，亞馬遜也做了一系列壓測對比，在增強 IO 多路複用的加持下，&lt;strong&gt;Valkey 單節點 QPS 最大可以超過 100W&lt;/strong&gt;，壓測數據可以參考《推陳出新 – Valkey 性能測試：探索版本變遷與雲託管的效能提升》&lt;em&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fblogs%2Fchina%2Fvalkey-performance-testing-exploring-version-changes-and-cloud-hosting-performance-improvements%2F%25EF%25BC%2589" rel="nofollow" target="_blank"&gt;https://aws.amazon.com/cn/blogs/china/valkey-performance-testing-exploring-version-changes-and-cloud-hosting-performance-improvements/）&lt;/a&gt;&lt;/em&gt;，單節點性能完全可以比肩 Redis 低版本中等規模集羣了。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 版本中，除了以上重大性能提升優化以外，還在提升內存利用率、加快主從複製效率、增強 resharding 過程中高可用性、實驗性支持 RDMA，以及提升集羣的觀測性等方面都進行了多項優化。我們後續再詳細介紹。&lt;/p&gt; 
&lt;p&gt;Valkey8.0 正式版發佈至今時間還不算太長，經過一段時間的驗證後，我們也會考慮將自建 Redis server 版本逐步升級到新版本，為業務提供性能更優的緩存服務。&lt;/p&gt; 
&lt;span id="OSC_h4_19"&gt;&lt;/span&gt; 
&lt;h4&gt;往期回顧&lt;/h4&gt; 
&lt;p&gt;1.Java SPI 機制初探｜得物技術&lt;/p&gt; 
&lt;p&gt;2.得物向量數據庫落地實踐&lt;/p&gt; 
&lt;p&gt;3.Java volatile 關鍵字到底是什麼｜得物技術&lt;/p&gt; 
&lt;p&gt;4.社區搜索離線回溯系統設計：架構、挑戰與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;5.從 「卡頓」 到 「秒開」：外投首屏性能優化的 6 個實戰錦囊｜得物技術&lt;/p&gt; 
&lt;p&gt;文 / 竹徑&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18687322</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18687322</guid>
      <pubDate>Thu, 07 Aug 2025 10:02:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Meta 組建新實驗室牽頭開發新版 Llama 大語言模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.wsj.com%2Farticles%2F%25E6%258F%25AD%25E7%25A7%2598meta%25E8%25B6%2585%25E7%25BA%25A7%25E6%2599%25BA%25E8%2583%25BD%25E7%2589%25B9%25E9%2581%25A3%25E9%2598%259F-tbd-lab-2ce269af" target="_blank"&gt;據華爾街日報&lt;/a&gt;&lt;/u&gt;，Meta Platforms 公司在推動構建比人類更聰明的計算機思維的過程中，一個名為 TBD 實驗室的團隊走在了最前沿，該團隊擁有許多該公司從競爭對手實驗室挖來的研究人員，其中一些人的薪酬高達數千萬或數億美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-69fd19271a38218d5f585cf2d85b30b1420.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據知情人士透露，TBD 實驗室 (to be determined，意為「待定」) 正在牽頭開發最新版本的大語言模型 Llama。上週，負責監督 Meta 超級智能實驗室的首席人工智能官亞歷山大·王在給員工的一份備忘錄中寫道，TBD 實驗室將與 Meta 的其他人工智能團隊合作開展各種項目，包括即將發佈的模型、模型推理能力的擴展和人工智能代理的開發。&lt;/p&gt; 
&lt;p&gt;新的 Llama 項目由 Jack Rae 領導，他是從谷歌聘請到 TBD 實驗室的。Meta 現有的 Llama 團隊成員和 TBD 實驗室正在合作開發這款產品。該模型還沒有正式名稱，但在內部被一些人稱為 Llama4.5 和 Llama 4。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365065</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365065</guid>
      <pubDate>Thu, 07 Aug 2025 10:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gitee 移動軟件工廠：突破網絡限制的開發新模式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近年來，在&lt;strong&gt;軟件工廠&lt;/strong&gt;的大趨勢下，各大單位都在致力於打造專業化的軟件工廠，提升研發體系化能力。然而在實際研發過程中，特別是在&lt;strong&gt;嵌入式開發、FPGA 開發及涉密系統場景下&lt;/strong&gt;，常常會遇到如下問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;研發人員需前往外部實驗室、測試基地或現場環境進行嵌入式系統或專用硬件調試；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;現場網絡與軟件工廠部署環境物理隔離，無法訪問原有的研發平台、代碼倉庫、流水線等基礎能力；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;調試週期較長、頻繁進出，導致效率低、環境切換複雜、數據易丟失；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;外部現場開發缺乏標準化工具支撐，過程依賴人工操作，難以實現研發自動化與資產規範管理。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不僅如此，在武器裝備開發、外場測試、保密單位等典型任務中，還面臨着更為複雜的挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;任務高度定製，需頻繁適配不同平台、接口與運行環境，導致調試與驗證工作量陡增；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;涉密限制下，無法使用遠程桌面、USB 存儲、無線傳輸等常規手段，資料交換與程序部署極為低效；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;關鍵測試資源僅存在於特定硬件設備或外場環境中，無法常態化復現，嚴重影響開發節奏；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;涉及嵌入式、通信、導控等多專業團隊，因缺乏統一平台，協同開發進展緩慢；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;典型部署場景（如艦船、機載、野外）環境惡劣，板卡接入困難、電源波動大、温濕度極端，調試失敗率高，返工成本大；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多型號並行開發，需求頻繁變更，缺少統一配置管理，容易誤刷程序或測試用例錯配，帶來不可估量損失；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;開發設備與測試設備一一綁定，調試過程全靠人工值守與現場操作，容錯率低、加班成常態。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些問題不僅僅是「效率低」，更直接影響交付週期、質量可控性與工程資產的積累能力。&lt;/p&gt; 
&lt;p&gt;為破解這一通用難題，&lt;strong&gt;Gitee 推出全新形態的「移動軟件工廠」解決方案&lt;/strong&gt;。通過具備便攜性、標準化與可控性的移動研發平台，幫助團隊打破物理邊界，實現「隨時隨地、無懼隔離」的高效協同，真正打通現場作業與總部工廠之間的能力壁壘。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175018_uILk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;什麼是移動軟件工廠&lt;/h2&gt; 
&lt;p&gt;移動軟件工廠是一套可&lt;strong&gt;移動、自包含、靈活裝配的軟件開發環境&lt;/strong&gt;，可以根據外場環境的研發需求，將研發過程中所需的各類工具打包至便攜設備中（如代碼倉庫、構建環境、測試框架等等），支持真正的&lt;strong&gt;離線研發閉環&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;不同於傳統的「鏡像克隆」或「雲端同步」模式，&lt;strong&gt;Gitee 移動軟件工廠強調靈活裝配、現場自運行、過程可控可審計&lt;/strong&gt;，具備以下關鍵能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;研發能力可遷移：將項目管理、需求管理、代碼管理、構建發佈等核心研發能力封裝為容器與鏡像，隨設備下發，實現「工具隨人走，能力隨處有」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自動化保障一致性：即使在與總部隔離的環境下，依然可本地運行標準化流水線與質量流程，保障研發一致性與規範不打折。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模塊化靈活裝配：支持按需加載代碼倉、製品庫、流水線、需求管理等模塊，滿足不同項目、現場與網絡環境下的定製化需求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據安全同步機制：支持智能增量同步，傳輸過程通過國密 SM4 進行加解密，一鍵回傳增量代碼變更內容、構建制品與項目審計數據，實現離島研發資產與過程數據回傳總部。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;憑藉這套可組裝式部署架構，移動軟件工廠可根據實際任務靈活配置，適配多種交付形態，真正實現「因需而建、隨地可用」，在分佈式、離線場景下展現出領先優勢。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175034_SvGM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;總部與移動協同開發：保障資產迴流與數據閉環&lt;/h2&gt; 
&lt;p&gt;在面對多場景、多環境的複雜交付需求時，Gitee 提出了「移動軟件工廠」解決方案。其核心是構建一套&lt;strong&gt;可統一規範、可離線運行、可有序迴流、資產安全可靠&lt;/strong&gt;的研發閉環體系。&lt;/p&gt; 
&lt;p&gt;總部統一提供依賴庫、構建鏡像、安全規則等資源標準；現場研發人員通過移動軟件工廠設備，即可在無網絡環境下完成編碼、構建、測試及質量檢測任務；研發數據與資產通過智能增量機制與受控路徑，&lt;strong&gt;實現從本地到總部的高效迴流與沉澱複用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;下圖展示了此閉環體系的六大關鍵模塊，從資源規範、現場執行到數據迴歸，形成端到端的閉環保障：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175110_b5OO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這一機制確保&lt;strong&gt;無論網絡通或不通、人員是否分散，研發流程始終連貫&lt;/strong&gt;，最大化保障組織的知識積累、安全合規與多地協作效率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;核心能力：一台設備實現完整研發閉環&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;離線項目管理：本地支持需求、任務、缺陷、變更等全流程管理，內置甘特圖、燃盡圖等常用視圖。權限、流程與字段配置與總部保持一致，迴歸後自動同步，避免標準割裂。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分佈式代碼管理：基於 Gitee 分佈式架構，支持離線提交、簽名提交、受保護分支等策略。總部可預設分支策略與合併規則，降低多地協作衝突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;本地安全掃描：內置基礎的代碼規範與依賴合規掃描，支持在離線階段提前發現問題。漏洞庫支持定期打包更新，迴歸後執行完整掃描並聯動缺陷管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自動化流水線執行：支持本地 Runner，完成構建、單元測試、打包等關鍵流程，保持與總部流水線環境一致。也可按需定製適配複雜測試場景，如硬件在環測試等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;本地依賴管理：預置常用依賴庫，支持離線解析、構建不阻塞。迴歸後統一執行版本衝突檢測、許可證合規校驗，並生成 SBOM。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 編程助手（離線可用）：內置輕量級 AI 能力，支持代碼補全與缺陷提示等功能。支持離線運行，迴歸總部後可自動更新知識模型。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="715" src="https://static.oschina.net/uploads/space/2025/0808/175128_EMpZ_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175137_y8iT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;落地實施與部署等級&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;方案評估與定製：梳理現有流程，制定鏡像與同步策略；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;總部環境建設：搭建構建鏡像庫與合規規則集；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;移動環境交付：按項目交付設備並預置管控策略，開展培訓；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同步與持續優化：啓用智能同步與迴歸驗證，持續更新體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175153_RHxM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;三種部署等級：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;一級部署：數據高可用，適配輕量研發；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;二級部署：數據高可用 + 服務可用，適配小團隊協同；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;三級部署：數據高可用 + 服務高可用，適配關鍵任務場景，支持主備與高可用擴展。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;核心價值與場景收益&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;效率提升：擺脱網絡依賴，現場即可構建；模塊化部署適配現場差異；遠程批量控制減少值守；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安全可控：兼容涉密現場，杜絕 USB/遠程桌面，符合安全合規要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;質量保障：支持需求變更頻繁場景下的配置一致性；減少誤刷與錯配問題；支持外場硬件對接；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成本優化：減少專線/外網依賴，降低環境搭建與駐場支持的人力成本；避免因流程中斷造成的延期與差旅開銷。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175204_q4od_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;技術底座：架構創新保障可控可溯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;容器化打包：鏡像封裝，簽名驗證，SBOM 輸出，環境可信；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能增量同步：差異計算，斷點續傳，適配弱網隔離場景；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安全加固機制：全盤加密，權限控制，離線審計日誌回傳。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;面向未來：軟件開發的新範式&lt;/h2&gt; 
&lt;p&gt;移動軟件工廠不僅是技術創新，更是研發模式的革新：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;開發環境去中心化，實現真正的分佈式開發&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安全與效率兼得，打破二者只能二選一的困局&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 與工程化深度融合，全面賦能研發流程&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在複雜多變的開發環境中，誰能更快適應變化，誰就能領先一步。移動軟件工廠，讓開發不再受網絡束縛，讓創新在任何地方都能自由綻放。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;硬件+能力組合一體化交付&lt;/h2&gt; 
&lt;p&gt;為了保障「移動軟件工廠」真正落地可用，我們配套交付的並不僅是鏡像和工具鏈，還包括&lt;strong&gt;硬件層面的移動一體機設備&lt;/strong&gt;。如下圖所示，它採用&lt;strong&gt;加固型嵌入式工控機形態&lt;/strong&gt;，結合工業級機櫃封裝與運維支撐能力，可靈活部署於辦公室、研發基地、野外現場等場景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175232_2juu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;標準配置説明：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;支持桌面或落地放置，底部帶滑輪便於移動；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;機櫃內部含計算節點、陣列磁盤、交換機、電源管理模塊等；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;支持靜音運行、遠程管理、電壓監控與斷電保護；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;交付即用，已預配置 Gitee 移動軟件工廠環境，整體為一套脱網可用的 Gitee DevSecOps 私有云。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;當前我們沉澱了三種高頻部署模型，適用於不同場景落地，但也支持模塊級靈活裁剪與擴展，滿足不同客户的研發重點與使用場景（不僅限於以下形式，所有模塊均支持按需組合部署）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;移動全流程開發工廠： 面向具備複雜項目管理與協同需求的單位，預置 Team、Insight、Code、CI/CD、Repo 等全棧能力，實現從需求、任務、編碼到度量的全流程閉環。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;移動代碼開發工廠： 聚焦於代碼開發與製品構建場景，預裝 Code、CI/CD、Repo 等核心能力，適合純研發場景的「輕協同」團隊部署。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;移動智能開發工廠： 在移動代碼工廠的基礎上，內嵌 AI 編程助手能力（支持離線運行），面向效率導向型團隊，賦能本地編碼與代碼質量保障。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過這些組合，客户可根據任務輕重、團隊分工、安全等級，自主靈活選配，實現真正貼合自身場景的「移動式 DevSecOps 工廠」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365060</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365060</guid>
      <pubDate>Thu, 07 Aug 2025 09:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥 xbatis 一個真的好用 ORM 框架：簡單，方便，快捷，強大！！！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1&gt;xbatis 是什麼&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn%2Fzh-CN%2Fintro%2FwhatIs.html%23xbatis-%25E6%2598%25AF%25E4%25BB%2580%25E4%25B9%2588" target="_blank"&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p style="color:#3c3c43; margin-left:0; margin-right:0; text-align:start"&gt;xbatis 是一款基於 mybatis 的 ORM 框架，ORM 程度非常高，幾乎不需要再寫 SQL;&lt;br&gt; &lt;br&gt; 同時內置多種&lt;strong&gt;數據庫函數&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;, 具有良好的不同數據庫遷移能力，注意它可以&lt;strong&gt;同時支持多種數據庫！！！&lt;/strong&gt;，一款真正意義上的 ORM 框架&lt;br&gt; &lt;br&gt; xbatis 具有良好程序設計，非常穩定（經過 testcase 驗證）；優雅的 API、簡而易懂的方法操作，讓你寫代碼和寫 SQL 幾乎一樣，學習成本幾乎為零。&lt;br&gt; &lt;br&gt; 功能強大，支持&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;多表 / 子查詢，自動分頁，優雅的 XML 自動分頁&lt;/strong&gt;等眾多功能！！&lt;/p&gt; 
&lt;h1&gt;支持分頁，原生自帶或 XML 中自動分頁&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;public&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;Demo&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;{
    &lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Autowired&lt;/span&gt;&lt;/span&gt;
    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; SysUserMapper sysUserMapper;

    &lt;span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;public&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;void&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;page&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;{
        Pager&amp;lt;SysUser&amp;gt; pager= QueryChain.of(sysUserMapper)
                .join(SysUser::getRoleId, SysRole::getId)
                .like(SysUser::getUserName,&lt;span style="color:#032f62"&gt;&lt;span style="color:#032f62"&gt;"abc"&lt;/span&gt;&lt;/span&gt;)
                .paging(Pager.of(&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;));
    }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;不喜歡 JOIN，又不想寫代碼，懶？可以&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Data&lt;/span&gt;&lt;/span&gt;
&lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@ResultEntity(SysUser.class)&lt;/span&gt;&lt;/span&gt;
&lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;public&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;SysUserVo&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;{

    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; Integer id;

    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; String userName;

    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; LocalDateTime createTime;

    &lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Fetch(source = SysUser.class , property=SysUser.Fields.roleId, target = SysRole.class, targetProperty = SysRole.Fields.id, targetSelectProperty = SysRole.Fields.roleName, orderBy = SysRole.Fields.id+&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6a737d"&gt;&lt;span&gt;" asc"&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#6a737d"&gt;)&lt;/span&gt;&lt;/span&gt;
    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; List&amp;lt;String&amp;gt; sysRoleNames;

    &lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Fetch(source = SysUser.class , property=SysUser.Fields.roleId, target = SysRole.class, targetProperty = SysRole.Fields.id, orderBy = SysRole.Fields.id+&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6a737d"&gt;&lt;span&gt;" asc"&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#6a737d"&gt;)&lt;/span&gt;&lt;/span&gt;
    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; List&amp;lt;SysRole&amp;gt; sysRoles;
}

&lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Service&lt;/span&gt;&lt;/span&gt;
&lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;public&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;Test&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;{

    &lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Autowired&lt;/span&gt;&lt;/span&gt;
    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; SysUserMapper sysUserMapper;

    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;public&lt;/span&gt;&lt;/span&gt; void demo() {
        Pager&amp;lt;SysUserVo&amp;gt; pager = QueryChain.of(sysUserMapper)
                .select(SysUserVo&lt;span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;
                .eq(SysUser::getId,&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;)
                .like(SysUser::getUserName,&lt;span style="color:#032f62"&gt;&lt;span style="color:#032f62"&gt;"xxx"&lt;/span&gt;&lt;/span&gt;)
                .returnType(SysUserVo&lt;span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;
                .paging(Pager.of(&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;,&lt;span&gt;&lt;span&gt;10&lt;/span&gt;&lt;/span&gt;));
    }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;單表查詢，自動加載另外一張表數據，省事&lt;/p&gt; 
&lt;h1&gt;枚舉名稱，還需要自己注入？來&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@Data&lt;/span&gt;&lt;/span&gt;
&lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@ResultEntity&lt;/span&gt;&lt;/span&gt;(SysUser&lt;span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;public&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;SysUserVo&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;{

    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; Integer id;
    
    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; String userName;

    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; String password;
    
    &lt;span style="color:#d73a49"&gt;&lt;span style="color:#d73a49"&gt;private&lt;/span&gt;&lt;/span&gt; Integer status;

    &lt;span style="color:#6a737d"&gt;&lt;span style="color:#6a737d"&gt;@PutEnumValue&lt;/span&gt;&lt;/span&gt;(source = SysUser&lt;span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;property&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;= SysUser.Fields.status, target = StatusEnum&lt;span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span style="color:#d73a49"&gt;&lt;span&gt;&lt;span style="color:#d73a49"&gt;class&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;private&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;String&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span style="color:#6f42c1"&gt;&lt;span&gt;&lt;span style="color:#6f42c1"&gt;statusName&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;一個註解搞定，牛不牛，再也不用自己寫代碼搞了&lt;/p&gt; 
&lt;h1&gt;不同數據庫，我想執行不同的函數或 sql，怎麼弄？來這裏&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;SysUser sysUser = QueryChain.of(sysUserMapper)
        .select(SysUser::getId)
        // dbAdapt((query, selector) 可以多次
        .dbAdapt((query, selector) -&amp;gt; {
            selector.when(DbType.H2, (dbType) -&amp;gt; {
                    &lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;/span&gt;H2 拼接 id = &lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;
                    query.e&lt;span style="color:#032f62"&gt;&lt;span style="color:#032f62"&gt;q(SysUser::getId, 3)&lt;/span&gt;&lt;/span&gt;;
                }).when(DbType.MYSQL, (dbType) -&amp;gt; {
                    &lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;/span&gt;MYSQL 拼接 id = &lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;
                    query.e&lt;span style="color:#032f62"&gt;&lt;span style="color:#032f62"&gt;q(SysUser::getId, 2)&lt;/span&gt;&lt;/span&gt;;
                }).otherwise((dbType) -&amp;gt; {
                    &lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;/span&gt;其他，拼接 id = &lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;
                    query.e&lt;span style="color:#032f62"&gt;&lt;span style="color:#032f62"&gt;q(SysUser::getId, 1)&lt;/span&gt;&lt;/span&gt;;
                });
        })
        .get();&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多無敵功能，來&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxbatis.cn" target="_blank"&gt;https://xbatis.cn&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365059</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365059</guid>
      <pubDate>Thu, 07 Aug 2025 09:52:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>深度對話尤雨溪：前端的未來、Rust、AI 與開源商業化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vue 框架與 Vite 構建工具的創造者，VoidZero Inc. 創始人&amp;nbsp;&lt;strong&gt;尤雨溪&lt;/strong&gt;近期到訪 Kong 上海辦公室展開了一場深度技術交流。討論的內容不僅涵蓋了 Vue 與 Vite 的最新進展，還深入探討了前端基礎設施的 Rust 化趨勢、AI 時代開發者的角色轉變，以及開源項目的可持續商業路徑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174721_mmqs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是精華回顧：&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;Vue 與 Vite 的發展動態與未來展望&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;Vue 3 的穩定演進&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Vue 3 自 2020 年發佈以來，現已佔據總下載量約 70%，大多數新項目也選擇以 Vue 3 為基礎。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;API 設計趨於穩定，未來不會有類似 Vue 2 向 Vue 3 的斷代式變更，而是致力於長期維護與優化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;核心關注點將包括開發體驗提升、IDE 的 TypeScript 支持強化、以及響應式系統與編譯器性能優化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Vapor Mode&lt;/strong&gt;：Vue 3.6 中引入的實驗性編譯模式，通過重構編譯策略實現顯著性能提升，但保持現有 API 不變。開發者可以 opt-in 的方式下試用。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;Vite 的演化與 VoidZero 的誕生&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;雖最初為 Vue 設計，&lt;strong&gt;Vite&lt;/strong&gt;&amp;nbsp;已成長為跨生態的構建基礎設施，支持包括 React、Svelte、Solid、Astro 等框架。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;當前約有&amp;nbsp;&lt;strong&gt;接近一半的 Vite 用户來自 React 社區&lt;/strong&gt;，每週下載量超&amp;nbsp;&lt;strong&gt;1500 萬次&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尤雨溪認為 Vite 有潛力成為前端「&lt;strong&gt;共享基礎設施層（Shared Infra Layer）&lt;/strong&gt;」，解決生態碎片化問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VoidZero Inc.：尤雨溪於 2024 年創立的公司，獲 Accel 領投約 460 萬美元種子輪融資，目標是構建基於 Rust 的下一代前端工具鏈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;Rust 化的前端基礎設施&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;為什麼選擇 Rust？&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;當前 JavaScript 編寫的工具鏈在大型項目中面臨性能瓶頸（如 Babel、Webpack）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Rust 更適合處理「&lt;strong&gt;定義明確且計算密集&lt;/strong&gt;」的問題，如解析器、轉譯器、依賴解析等基礎設施組件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VoidZero 正在將這類「熱點路徑」遷移到 Rust 編寫的工具中，以提升整體構建性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;Rolldown、Oxc 與工具鏈整合&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;VoidZero 推出的&amp;nbsp;&lt;strong&gt;Rolldown&lt;/strong&gt;&amp;nbsp;是一款 Rust 打造的現代打包器，融合了 ESBuild 的速度優勢和 Rollup 的插件機制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;配合&amp;nbsp;&lt;strong&gt;Oxc&lt;/strong&gt;（解析器、Linter、Formatter）和&amp;nbsp;&lt;strong&gt;Vitest&lt;/strong&gt;（測試框架），構建統一、模塊化的開發體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🛠️ 工具鏈將逐步融入 Vite，構成一個基於 Rust 的構建核心、並保留部分 TypeScript 模塊以保障靈活性和快速迭代的混合架構。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;未來工具鏈構想與企業支持&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;VoidZero 規劃中的開發體驗流程&lt;/strong&gt;： vite new → dev → lint → test → build，實現開箱即用的項目起步與構建體驗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企業級版本將包括：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Monorepo 緩存系統&lt;/strong&gt;：類似 Turborepo/Nx，實現精準緩存失效；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI Agent 集成探索&lt;/strong&gt;：讓 AI 輔助成為前端開發的一部分。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;尤雨溪強調：「工程導向的項目，應該由最強的工程師去構建底層系統，才能最大化開發者體驗。」&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;社區、文化與 AI 時代的思考&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;如何看待開源社區的「噪音」與爭議&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;開源社區必然多元，早期常陷入「討好所有人」的困境。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成熟項目需明確目標用户與社區邊界，避免「用户特權感」（Entitlement）影響維護節奏。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;開源是一種合作關係，不是服務關係，良好的行為準則和反饋機制至關重要。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;「前端娛樂圈化」現象&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;某些爭論被社交平台放大，導致注意力偏離實際工程問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尤雨溪建議開發者：「多跳出自身領域，少陷入無意義的框架之爭。」&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;AI 與程序員的角色重構&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;未來開發必然是「&lt;strong&gt;人類 + AI 協同&lt;/strong&gt;」模式，AI 會自動化重複性高的流程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;真正不可取代的是人類的判斷力與創造力，尤其是在產品定義與複雜架構決策中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 無法準確理解歷史代碼上下文，也難以勝任抽象設計。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尤雨溪本人在法律合同等文檔處理上已廣泛使用 AI 工具，大幅節省律師成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;開源商業化的探索路徑&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;成功的開源商業化並非只有上市一種形式，維持長期生存同樣重要。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Vue 項目通過社區贊助維持核心團隊運行，屬於輕量可持續的成功模式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端框架商業化更難因缺少服務型後端組件；VoidZero 的目標是打造&lt;strong&gt;可自我造血的高階工具鏈&lt;/strong&gt;，而非僅作流量入口。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;其他話題與個人興趣&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;對 React Server Components 的評價&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vue 不會採用類似方案，而是採用&lt;strong&gt;構建時靜態預渲染 + 最小 JS 運行時&lt;/strong&gt;的路徑，追求性能與開發體驗的平衡。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;日常生活&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;參觀《黑神話：悟空》展覽，對其藝術與技術水準印象深刻。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;休閒時會使用&amp;nbsp;&lt;strong&gt;解壓類指尖玩具&lt;/strong&gt;&amp;nbsp;來緩解注意力障礙。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每週會打羽毛球，強調工作之餘保持運動對身體的重要性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174754_Sev7_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;strong&gt;結語&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;尤雨溪老師此次分享，為我們描繪了前端技術的新篇章：以 Rust 為內核、AI 為助力、開源為根本。&lt;/p&gt; 
&lt;p&gt;本次的直播回放可以在「&lt;strong&gt;OSC 開源社區&lt;/strong&gt;」視頻號中進行查看：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174803_1cW9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365057</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365057</guid>
      <pubDate>Thu, 07 Aug 2025 09:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>會翻譯、懂產品、還能畫頭像：Gitee 智能三連上線！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在開發者參與項目協作的過程中，從讀懂文檔、掌握功能，到展示個性，很多細節往往比想象中更難：&lt;/p&gt; 
&lt;p&gt;📄&amp;nbsp;&lt;strong&gt;README 是外文，看得一頭霧水&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🤔&amp;nbsp;&lt;strong&gt;企業版功能很多，一時間找不到使用路徑&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🧑‍💻&amp;nbsp;&lt;strong&gt;社區頭像都差不多，沒法展示個人特色&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為瞭解決這些常見但容易被忽視的問題，Gitee 新上線了三項智能化功能，從理解項目、快速上手到個性表達，全鏈路優化開發體驗：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一鍵翻譯 README，項目文檔看得懂&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能助手隨問隨答，功能使用不迷路&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 頭像生成，自定義專屬程序員形象&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;接下來就帶你逐一瞭解這次更新的重點亮點——&lt;/p&gt; 
&lt;h3&gt;README 一鍵翻譯：跨語言項目協作更輕鬆&lt;/h3&gt; 
&lt;p&gt;你是否遇到過這樣的場景，克隆下來的項目，README 是全英文，核心用法不明不白，還得靠翻譯工具搞半天。&lt;/p&gt; 
&lt;p&gt;現在，只需在英文 README 文件上方點擊「翻譯為中文」，README 頁面將瞬間完成 AI 翻譯，原地閲讀，不跳轉、不依賴第三方平台，真正做到「沉浸式翻譯」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174240_We6y_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;馬建倉實測下來翻譯速度超快：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174302_Dxs4_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該功能由 Gitee 與開源項目&lt;code&gt;translate.js&lt;/code&gt;聯合提供支持，開發者通過引用&lt;code&gt;translate.js&lt;/code&gt;，兩行 JavaScript 代碼即可實現 HTML 多語言全自動翻譯。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174316_J9sI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這不僅讓開源項目更具國際可讀性，也讓日常開發者查閲他人項目更加高效順暢。&lt;/p&gt; 
&lt;h3&gt;Gitee 智能助手：常見問題秒回答&lt;/h3&gt; 
&lt;p&gt;你也許注意到了，在 Gitee 頁面側邊按鈕和 Gitee 幫助中心出現了一個新入口：「Gitee 智能助手」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174329_eD7Z_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;你也可以直接訪問 https://help.gitee.com/chat，進入 Gitee 智能助手頁面：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174341_v6CH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這是 Gitee 官方推出的 AI 智能助手，可隨時向它提問，當前重點覆蓋 Gitee 社區版和企業版功能使用場景，例如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;如何添加企業成員？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;項目權限怎麼管理？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如何從免費賬號升級為企業版？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企業版 AI 能力包括什麼？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Gitee 項目管理有哪些優勢？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174356_F4zo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相比傳統 FAQ，它響應更快、理解更強，也更適配你的提問方式。特別適合剛接觸企業版的用户，邊用邊問，邊學邊上手。&lt;/p&gt; 
&lt;h3&gt;AI 頭像生成：打造你的專屬開發者形象&lt;/h3&gt; 
&lt;p&gt;除了提升協作效率，Gitee 也為用户帶來了更有趣、更個性化的新功能：AI 頭像生成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174427_5oR9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;該功能由模力方舟提供技術支持&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在個人設置頁點擊自己的頭像，即可使用 AI 生成模式，選擇身份（如程序員、年輕男性）、風格（漫畫風、電影風等）、髮型、背景等參數，幾秒鐘就能生成獨一無二的專屬頭像。&lt;/p&gt; 
&lt;p&gt;不論你是低調極客派，還是喜歡有趣表達，現在都可以輕鬆「畫」出屬於自己的開發者頭像。&lt;/p&gt; 
&lt;h3&gt;Gitee 智能化升級，讓協作更高效&lt;/h3&gt; 
&lt;p&gt;本次上線的三項新功能，圍繞開發者在協作過程中的三個關鍵場景展開：讀懂文檔、掌握用法、表達自我，從工具性到體驗感，全面優化。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;README 翻譯功能，讓開源項目更易於跨語言傳播，也幫助開發者快速理解項目內容；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能助手功能，則為使用路徑中的關鍵節點，提供了更便捷、更友好的智能化引導體驗；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 頭像生成，輕鬆打造開發者自己的個性形象，讓社區互動不再千篇一律。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;從可讀性、可用性，到個性表達，&lt;strong&gt;Gitee 正在通過智能化升級，打通「理解—使用—參與」的完整路徑&lt;/strong&gt;，讓開發者既能用得順手，也能留下自己的風格印記。&lt;/p&gt; 
&lt;p&gt;未來，我們還將持續拓展智能工具鏈的深度與温度，為你帶來更多真正用得上的開發體驗。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;歡迎體驗：&lt;u&gt;&lt;strong&gt;&lt;em&gt;&lt;a href="https://gitee.com/" target="_blank"&gt;https://gitee.com/&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365056</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365056</guid>
      <pubDate>Thu, 07 Aug 2025 09:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MetaStone-S1：反思型生成式大模型（Reflective Generative Model）</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;MetaStone-S1 是反思型生成式大模型（Reflective Generative Model），在數學、代碼和中文推理任務上以 32B 的參數量達到了與 OpenAI-o3 系列相近的水平。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5b7f913ec1d1edd4e8d563efc5d926ec005.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;MetaStone-S1 基於反思型生成範式訓練得到，反思型生成範式是將 「Long-CoT 強化學習」與「過程評分學習」融合的訓練範式，該範式使單個模型同時具備「深度推理」與「高質量推理鏈路篩選」的能力。通過共享過程評分和策略模型的主幹網絡，該範式顯著降低了 99% 的過程評分推理耗時，實現了又快又好的文本回答效果。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6b00edd28a2bbf6ab32d77928e5fd7b8b59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;MetaStone-S1 在小尺寸模型上的性能對比：&lt;/p&gt;

&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0806/192929_y0R0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;MetaStone-S1 在大尺寸模型上的性能對比：&lt;/p&gt;

&lt;p&gt;&lt;img height="1054" src="https://static.oschina.net/uploads/space/2025/0806/192925_gOSt_2720166.png" width="1320" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/metastone-s1</link>
      <guid isPermaLink="false">https://www.oschina.net/p/metastone-s1</guid>
      <pubDate>Thu, 07 Aug 2025 09:38:00 GMT</pubDate>
    </item>
    <item>
      <title>韓國扶持五大聯合體開發「主權 AI」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;綜合韓聯社、《朝鮮日報》和《京鄉新聞》等韓媒報道，韓國政府 4 日正式選定 NAVER Cloud、Upstage、SK 電訊、NC AI、LG AI 研究院五個聯合體作為「人工智能（AI）基礎模型研發項目」的首批扶持對象，全面啓動「主權 AI」國家戰略。這是李在明政府提出「邁向 AI 三大強國」目標後，首次對本土基礎大模型研發力量進行篩選和集中投入，標誌着韓國在全球 AI 技術競爭中邁出實質性步伐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據韓國科學技術信息通信部（科技部）介紹，此次入選的 5 個聯合體從全國 15 個團隊中脱穎而出，涵蓋大型企業、AI 初創公司、產學研機構等多方力量，均具備自主設計和開發 AI 基礎模型的核心能力。根據韓國政府公佈的計劃，首輪項目評估將於今年 12 月起啓動，到 2027 年每六個月淘汰一組，逐步縮減扶持對象，最終僅遴選 1 至 2 個聯合體作為長期合作方。韓國業內普遍認為這是一場「真刀真槍的較量」，事關國家未來人工智能能力的保障。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韓國政府計劃在 2027 年前向五支「國家代表隊」投入約 5300 億韓元（1000 韓元約合 5.2 元人民幣）支持：其中 4500 億用於 GPU（圖形處理器）支持，628 億用於 AI 訓練數據建設，最高 250 億用於人才引進。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該項目旨在開發具有國際競爭力、自主研發的人工智能基礎模型，減少對外國技術的依賴，並拓展國內人工智能生態系統。韓政府認為，該模型將推動國內各行各業的人工智能轉型。政府明確目標是將技術水平提升至包括美國 OpenAI 推出的大模型 ChatGPT 在內的頂尖 AI 模型的 95%。據英國 Tortoise Media 年度《全球 AI 指數》，韓國 AI 技術實力居全球第六（2024 年基準），與排名前兩位的美中兩國存在顯著差距。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韓國業內認為，數據資源短缺是制約本土 AI 模型質量的重要瓶頸。與領先國家相比，韓國在可用於訓練的大規模高質量數據方面明顯不足。為此，韓國政府明確提出，將通過國家記錄院、國史編纂委員會、統計廳等統一採購公共數據，向入選聯合體提供使用權限，並根據各團隊需求支持個別數據庫構建，助力基礎模型開發。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在期待階段性成果的同時，韓國業界也呼籲政府將扶持重心進一步延伸至更具產業價值的長期路徑。參與項目的 AI 研發人員指出，僅靠模型本身尚不足以支撐 AI 強國地位，關鍵在於推動 AI 向製造、醫療、金融等高附加值產業加速融合。對此，韓國科技部長官裴慶勳表示，該項目是「韓國 AI」的起點，將全力支持「主權 AI」生態的擴張，並逐步擴大政策工具箱，構建以「主權 AI」為核心的全鏈條支援體系。（環球時報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365053</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365053</guid>
      <pubDate>Thu, 07 Aug 2025 09:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>今年上半年我國機器人產業營業收入同比增長 27.8%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 世界機器人大會開幕式上，工業和信息化部副部長辛國斌介紹，今年上半年，我國機器人產業營業收入同比增長 27.8%，工業機器人和服務機器人產量同比分別增長 35.6% 和 25.5%，連續 12 年位居全球最大工業機器人應用市場。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;辛國斌指出，世界機器人大會自 2015 年起，迄今已迎來具有里程碑意義的十年。10 年間全球機器人產業實現飛躍式發展，呈現三個「加速」的態勢：一是智能水平加速提升；應用邊界加速擴展；創新要素加速匯聚。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="337" src="https://oscimg.oschina.net/oscnet/up-82381b9c95f185220dda658c7552e588f83.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他提到，圍繞老齡社會應對、智能製造升級、農業現代化轉型、深空深海探索等全球性關鍵領域，中國願探索國際合作新模式，讓智能機器人的創新成果跨越環境，惠及世界每一個角落。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365046</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365046</guid>
      <pubDate>Thu, 07 Aug 2025 09:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>KittenTTS - 25MB 以下最先進的 TTS 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Kitten TTS 是一個開源的真實文本轉語音模型，僅具有 1500 萬個參數，專為輕量級部署和高質量語音合成而設計。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;目前處於開發者預覽階段。&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;超輕量級&lt;/strong&gt;：模型大小小於 25MB&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU 優化&lt;/strong&gt;：在任何設備上無需 GPU 即可運行&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高品質語音&lt;/strong&gt;：提供多種優質語音選項&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;快速推理&lt;/strong&gt;：針對實時語音合成進行了優化&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;安裝&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;pip install https://github.com/KittenML/KittenTTS/releases/download/0.1/kittentts-0.1.0-py3-none-any.whl&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基本用法&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;from kittentts import KittenTTS
m = KittenTTS("KittenML/kitten-tts-nano-0.1")

audio = m.generate("This high quality TTS model works without a GPU", voice='expr-voice-2-f' )

# available_voices : [  'expr-voice-2-m', 'expr-voice-2-f', 'expr-voice-3-m', 'expr-voice-3-f',  'expr-voice-4-m', 'expr-voice-4-f', 'expr-voice-5-m', 'expr-voice-5-f' ]

# Save the audio
import soundfile as sf
sf.write('output.wav', audio, 24000)&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/kittentts</link>
      <guid isPermaLink="false">https://www.oschina.net/p/kittentts</guid>
      <pubDate>Thu, 07 Aug 2025 09:14:00 GMT</pubDate>
    </item>
    <item>
      <title>馬斯克：AI 是解決日本人口危機的唯一希望</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;埃隆·馬斯克近日在社交平台發文，對日本嚴峻的人口問題發表了自己的看法。他指出，日本今年人口將減少近 100 萬，這一趨勢的根源早在半個世紀前就已種下，與人工智能的發展無關。他強調，「&lt;strong&gt;人工智能是扭轉這一局面的&lt;span&gt;唯一&lt;/span&gt;希望&lt;/strong&gt;。」&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="365" src="https://oscimg.oschina.net/oscnet/up-18e76d8f77bfe23364728d9305749681dbb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;馬斯克的言論與日本官方公佈的數據相吻合。據日本總務省 7 月 6 日發佈的統計數據，截至 2025 年 1 月 1 日，不計居住在日本的外國人，日本人口已連續第 16 年減少。總人口數約為 1.2065 億，相比去年減少了約 90.8 萬人，創下自 1968 年有統計數據以來的&lt;span&gt;最大&lt;/span&gt;降幅。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;數據顯示，從 2024 年初到 2025 年初，日本的出生人數創下歷史新低，而死亡人數則達到新高，進一步加劇了人口萎縮的趨勢。馬斯克的此番言論，為日本乃至全球面臨的人口挑戰提供了一個極具爭議性的解決思路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365041</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365041</guid>
      <pubDate>Thu, 07 Aug 2025 08:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>LangChain 發佈開源異步編程 Agent：Open SWE</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;LangChain 發佈了名為「Open SWE」的開源異步編程 Agent（Asynchronous Coding Agent）。它能自動理解代碼庫、制定解決方案、執行代碼變更，並完成從規劃到創建 Pull Request 的全流程。&lt;/p&gt; 
&lt;p&gt;核心功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;智能規劃（允許用户審核修改方案）&lt;/li&gt; 
 &lt;li&gt;人機協作（實時幹預任務）&lt;/li&gt; 
 &lt;li&gt;雲端並行處理（不佔用本地資源）&lt;/li&gt; 
 &lt;li&gt;端到端任務管理（自動創建 GitHub Issue 和 PR）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-84a6f93afdaf7a3c319de12e81307f6100f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其技術架構採用多智能體協作（規劃師、編程師、審查員等），基於 LangGraph 框架實現。用户可通過 Web 界面或 GitHub 標籤觸發任務，適用於複雜代碼庫的自動化協作開發。&lt;/p&gt; 
&lt;p&gt;相關鏈接&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent/&lt;/span&gt;&lt;br&gt; &lt;span&gt;https://github.com/langchain-ai/open-swe&lt;/span&gt;&lt;br&gt; &lt;span&gt;https://swe.langchain.com/&lt;/span&gt;&lt;br&gt; &lt;span&gt;https://docs.langchain.com/labs/swe&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365036/langchain-open-source-asynchronous-coding-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365036/langchain-open-source-asynchronous-coding-agent</guid>
      <pubDate>Thu, 07 Aug 2025 08:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 限時免費提供 GPT-5 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據 Cursor 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fen%2Fblog%2Fgpt-5" target="_blank"&gt;聲明&lt;/a&gt;及網絡信息，Cursor 針對其付費計劃用户提供了一定額度的 GPT-5 免費使用權限。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;X 平台上，@rohanpaul_ai 在 7 月 28 日的帖子中提到，Cursor 正考慮與 OpenAI 深化合作，部分得益於 GPT-5 在編碼任務中的卓越表現。帖子指出，GPT-5 在軟件工程、代理式規劃和多步驟工作流等領域的性能尤為突出，甚至超越了 Anthropic 的 Claude Sonnet4 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次限時免費活動旨在讓更多開發者體驗 GPT-5 的強大功能。Cursor 的付費計劃用户將獲得 GPT-5 的免費使用額度，具體時間窗口尚未明確，但活動已在開發者社區引發廣泛討論。這一舉措被視為 Cursor 在 AI 編碼工具市場中鞏固競爭優勢的戰略步驟，尤其是考慮到其年收入已接近 5 億美元，且部分收入與 Anthropic 的合作相關。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="363" src="https://oscimg.oschina.net/oscnet/up-2db6ccc955b243e8a18835eeee79e46540b.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;X 平台上的開發者對 Cursor 的更新反應熱烈。有報道稱 GPT-5 在軟件工程任務中的表現「極其積極」，尤其在代碼生成和調試方面表現優異。 許多開發者表示，Cursor 的免費 GPT-5 使用權限和 CLI 工具的推出將進一步推動 AI 在編程領域的普及。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;&lt;a href="https://www.oschina.net/news/364999/cursor-cli" target="news"&gt;Cursor 發佈命令行工具 Cursor CLI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365035</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365035</guid>
      <pubDate>Thu, 07 Aug 2025 08:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>多鄰國股價暴漲 30%，AI 戰略引爭議卻創造十億美元營收奇蹟</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多鄰國公司週三公佈的季度財報顯示，儘管此前因選擇擁抱生成式 AI 而非人工員工遭遇廣泛抨擊，公司營收仍超出預期。這一消息推動多鄰國股價飆升近 30%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;今年 4 月，公司&lt;/span&gt;&lt;span style="color:#212623"&gt;首席執行官 Luis von Ahn&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn%F0%9F%87%B1%F0%9F%87%AEactivity%3A7322560534824865792%2F" target="_blank"&gt;宣佈&lt;/a&gt;&lt;span style="color:#000000"&gt;多鄰國將轉型為"AI 優先"公司，逐步淘汰合同工。他還建議各團隊除非無法進一步自動化工作流程，否則不要增加員工招聘。藉助生成式 AI 技術，多鄰國新增 148 門語言課程，課程總量較此前翻了一倍多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;他當時表示："如果沒有 AI，我們需要幾十年時間才能將內容規模擴展到更多學習者。我們有責任儘快為學習者提供這些內容。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-30637c0e2142cdbe95fad780b3ab7ed124b.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;雖然部分多鄰國用户認為 AI 功能讓應用體驗變差，但公司財務數據卻講述着截然不同的故事。多鄰國預計今年營收將突破 10 億美元大關，日活躍用户同比增長 40%。這一增長表現雖然顯著，但處於公司此前預估 40%-45% 增長區間的下限，有投資者在週三的季度財報電話會議上向馮·安提及這一點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#212623"&gt;Luis von Ahn&amp;nbsp;&lt;/span&gt;&lt;span style="color:#000000"&gt;解釋道："我們增長率偏向下限的原因是我談到了 AI 相關內容，但沒有提供充分的背景信息。因此我們在社交媒體上遭受了一些抨擊。最重要的是，我們希望讓社交媒體上的情緒變得積極。我們停止發佈尖鋭的帖子，開始發佈能讓情緒更加積極的內容，這個策略奏效了。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在 TikTok 平台上，多鄰國視頻下的熱門評論仍多為對公司 AI 策略的批評。尖刻的評論者會詢問出現多人的視頻是否使用 AI 製作，多鄰國通常回復："不是的，這是我們優秀團隊製作的！"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;即使公眾對多鄰國的態度發生轉變，但公司的財務表現並未受到影響。從公司角度來看，這才是最重要的。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365032</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365032</guid>
      <pubDate>Thu, 07 Aug 2025 08:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源企業級智能體平台 MaxKB v2.0.2 發佈，高級編排應用新增會話變量，支持對話用户掃碼登錄，支持工作空間資源統一管理</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="color:#000000; text-align:start"&gt;2025 年 8 月 7 日，MaxKB 開源企業級智能體平台正式發佈 v2.0.2 版本。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;在 MaxKB v2.0.2 版本中，&lt;strong&gt;社區版方面&lt;/strong&gt;，高級編排應用新增會話變量功能，適用於用户在多次對話中進行數據暫存、邏輯判斷的場景，能夠有效增強系統的邏輯處理能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;X-Pack 增強包方面&lt;/strong&gt;，在對話用户登錄時，MaxKB 新增企業微信、釘釘、飛書等第三方平台掃碼登錄支持；在系統資源管理中，新增支持系統管理員對系統內所有工作空間的應用、知識庫、工具、模型等資源進行統一管理。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;此外，MaxKB 開源項目組還進行了超過 20 項功能更新和問題修復。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;新增功能&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#5a55fa"&gt;■ 高級編排應用新增會話變量功能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;MaxKB v2.0.2 版本的高級編排應用新增會話變量功能。用户在高級編排的 「基本信息」 節點中自定義會話變量後，該變量將在當前對話的全流程持續生效，並且支持對話過程中的數據傳遞與邏輯調用。當用户新建對話時，系統將自動初始化會話變量，確保跨對話場景的變量獨立性與數據隔離性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-75122c498811b66ac03bb7a601a9cba41fa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 1 MaxKB 新增會話變量功能&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#5a55fa"&gt;■ 支持對話用户掃碼登錄（X-Pack）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;為提升對話用户體驗，MaxKB v2.0.2 版本對話用户登錄新增支持第三方平台掃碼登錄功能，支持通過企業微信、釘釘、飛書等主流企業辦公平台進行安全便捷的單點登錄。具體配置步驟如下：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;1. 系統管理配置：&lt;/strong&gt;依次選擇「系統管理」→「對話用户」→「登錄認證」，在「登錄認證」頁面中完成包括企業微信、釘釘、飛書在內的第三方平台掃碼登錄的相關設置。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a7fbd9656b276363f4832da66ec3e4f0040.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 2 對話用户掃碼登錄對接配置頁面&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;2. 應用訪問限制設置：&lt;/strong&gt;在目標應用的「概覽」頁面中，打開「訪問限制」配置對話框，啓用「身份驗證」 功能，選擇「登錄認證」選項，並將登錄方式設置為釘釘、飛書或者企業微信掃碼登錄。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4512fec9646fcd30f1f60af7ff73056db33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 3 在應用的「訪問限制」配置對話框開啓登錄認證設置&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;3. 用户登錄流程：&lt;/strong&gt;完成上述配置後，當對話用户打開小助手提問時，系統將自動彈出對應第三方平台的掃碼登錄界面。用户掃碼確認後即可快速登錄，開啓與小助手的對話交互。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="1406" src="https://oscimg.oschina.net/oscnet/up-ee52f7c25ac9839c37ce7129234e5e8da9a.png" width="976" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 4 對話用户打開小助手時需要先進行掃碼登錄&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#5a55fa"&gt;■ 支持工作空間相關資源的統一管理（X-Pack）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;MaxKB v2.0.2 版本在「資源管理」模塊中賦予了系統管理員對資源的編輯、刪除及配置等能力。通過該功能，系統管理員可以對工作空間內的應用、知識庫、工具和模型等資源進行統一的管理與維護，從而實現資源的集中化管控，顯著增強了系統資源的精細化管理能力，並且提升了資源管理與維護的便捷性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="1610" src="https://oscimg.oschina.net/oscnet/up-0610a5e08dc073f908ade888de3ad36dfd9.png" width="3076" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲圖 5 MaxKB「資源管理-應用」管理頁面&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;功能優化&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;對話用户（X-Pack）：支持同步 LDAP 和企業微信用户；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;對話用户（X-Pack）：支持按用户來源和狀態查詢；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知識庫：針對數據量較大的複雜場景，提升了知識庫檢索性能；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知識庫：對話用户支持按用户來源查詢；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：調整高級編排應用的文件上傳限制，單次對話最多可上傳 100 個文件，單文件最大支持 1000MB；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：支持按應用發佈狀態查詢；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：對話用户支持按用户來源查詢；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：上傳文件後自動填充問題字段；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：優化浮窗模式和移動模式的登錄交互體驗；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;用户管理：支持按用户來源和狀態查詢；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;系統：優化系統 UI 樣式。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;問題修復&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知識庫：修復在全文檢索模式下命中測試報錯的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知識庫：修復上傳離線文檔頁面部分內容國際化顯示不正確的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知識庫：修復上傳離線文檔的分段規則頁面滾動條滾動範圍不正確的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用（X-Pack）：修復在應用接入的釘釘平台對話時，AI 回覆未按 Markdown 樣式顯示的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復部分情況下 MCP 調用節點執行報錯的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復相同的兩節點之間多次連線導致重複執行的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復修改模型參數時參數顯示不正確的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復添加應用子節點時未過濾未發佈狀態應用的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復上傳的文件名稱中含有「&lt;em&gt;&amp;amp;nbsp&lt;/em&gt;」 字符時，URL 不顯示的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復用户對話時 AI 回覆的圖片無法點擊放大的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復 AI 回覆為表格數據時顯示錯位的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面（X-Pack）：修復 License 未授權時，打開問答頁面報錯的問題；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;共享模型（X-Pack）：修復刪除共享模型時報錯的問題。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4736111/blog/18687412</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/18687412</guid>
      <pubDate>Thu, 07 Aug 2025 08:16:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>AI 智能體記憶機制詳解</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 為什麼我們總是感覺在與 AI 助手重複着同樣的對話？為什麼明明告訴過它的重要信息，五分鐘後它就完全遺忘了？&lt;/p&gt; 
 &lt;p&gt;我們今天為大家帶來的文章，作者的觀點是：記憶能力是 AI 從工具進階為真正智能夥伴的關鍵橋樑，只有具備完善的記憶系統，AI 才能提供個性化體驗、擁有持續學習和處理複雜任務的能力。&lt;/p&gt; 
 &lt;p&gt;本文深度解析了記憶增強型 AI 系統的核心技術架構，介紹了"觀察→記憶→行動→反思→更新"這一認知閉環解決方案。作者還系統闡述了從實時內存狀態到向量數據庫的多層次存儲機制，並詳細解析了工作記憶、情景記憶和語義記憶這三種記憶類型。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Bhavishya Pandit&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;是否總感覺你在和 AI 助手重複着同樣的對話？你告訴它一些重要的事情，五分鐘後，它就忘了。很長一段時間以來，這就是和大多數 AI 進行對話的現實情況。它們非常聰明，卻只有金魚般的記憶。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-923e90490a35f728b302cc47fb2b658e48c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但這種情況正在改變。如今，AI 小夥伴能記住我們上週的對話，回想起我們的喜好，並從與我們長期的交流互動中學習。這是目前人工智能的前沿領域之一，也是我想在今天這篇文章中深入探討的主題：AI 記憶能力的精妙之處。讓我們來分析一下，AI 是如何獲得記憶能力的。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 為何 AI 需要記憶能力&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;從本質來看，記憶就是為我們提供上下文。它是連接過往經歷與當下行為的紐帶。對 AI 而言，這是從工具進階為真正智能夥伴的關鍵橋樑。&lt;/strong&gt; 缺乏記憶能力的 AI 將無法實現：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2421fcf65f410c9fdc683a7a794d8c5d8fd.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Source[1]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;個性化體驗：無法記住你喜歡簡明扼要的要點而非冗長的段落，或在推薦食譜時忽略你是素食者&lt;/li&gt; 
 &lt;li&gt;從交流互動中學習：每次互動都需從頭開始，無法更好地幫助你&lt;/li&gt; 
 &lt;li&gt;處理複雜任務：想象一下與這樣的助手一起撰寫報告 ------ 它每次接收新數據都會遺忘項目目標&lt;/li&gt; 
 &lt;li&gt;讓 AI 擁有記憶能力，就是要讓它更有用、更個性化、更像人類，能夠為我們提供幫助。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;02 記憶增強型 AI 系統的核心運作架構&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;這個系統可以被視為一個持續運轉的認知閉環，使 AI 能夠感知環境、採取行動並從經驗中持續學習。整個過程可分解為一個強大的自我迭代循環。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-da7af7c3bec8e5f377b951e0f3dfce92505.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;觀察&lt;/strong&gt;：首先，智能體感知任務或用户輸入。這是其"眼睛與耳朵"所在，負責接收當前的上下文信息。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;記憶&lt;/strong&gt;：隨後智能體存儲即時上下文與相關對話歷史。這不僅僅是記錄文字，更要理解當前時刻"發生的事情"以及"這些事為什麼會發生"。&lt;/p&gt; 
&lt;p&gt;3）&lt;strong&gt;行動&lt;/strong&gt;：基於上下文，智能體執行動作或作出決策。可能表現為編寫代碼、回答問題或調用特定工具。&lt;/p&gt; 
&lt;p&gt;4）&lt;strong&gt;反思&lt;/strong&gt;：行動完成後進行評估。行動結果是成功還是失敗？是否更接近目標？&lt;/p&gt; 
&lt;p&gt;5）&lt;strong&gt;更新記憶&lt;/strong&gt;：最終（也是最關鍵的環節），將新學習到的認知模式與推理洞察回傳至記憶庫。&lt;/p&gt; 
&lt;p&gt;正是這種觀察 → 記憶 → 行動 → 反思 → 更新的迭代循環，賦予智能體實時改進的能力，使其每一次交互都轉化為實踐課程。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 這些記憶內容存儲在何處？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;那麼，這些記憶信息究竟存放在何處呢？在智能體系統中，記憶被精心組織在不同的存儲層級中，各司其職。其運作機制可類比為一個高度有序的工作車間。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f9e1986386fa4263d903f3940a86bdcc010.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;實時內存態（In-Memory state）&lt;/strong&gt; ：這是智能體短期使用的臨時工作區。存儲當前任務所需的即時信息，例如您設定的實時目標或剛調用的工具的輸出結果。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;持久化日誌（Persistent logs）&lt;/strong&gt; ：智能體在此建立跨多個會話的長期事件檔案，記錄行為軌跡、反思結論及任務結果。就像一本詳細的項目筆記本，它記錄了智能體所做的事情、智能體如何完成任務以及最終結果。這可以確保在下一個任務開始之前，從之前的任務中學到的知識不會丟失。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;向量數據庫（Vector databases）&lt;/strong&gt; ：向量數據庫存儲歷史交互數據時，並非簡單記錄文本，而是將其轉化為藴含豐富語義的嵌入向量 ------ 即數據的高維數值表徵。嵌入向量能捕捉信息的語義精髓與內在關聯，使智能體可基於上下文的相似度（而非關鍵詞匹配）檢索記憶。其機制更像觸發人腦的"尋找與此相似的情境記憶"，而非在文檔中進行關鍵詞搜索。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 尋找正確的記憶內容&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;當你向智能體提問時，它並不會逐字逐句地通讀自己的整個過往經歷。相反，它會執行一次優雅的高速檢索，以找到最相關的上下文。以下是這種語義搜索背後的運作原理：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fc371cc4405686f69d3a55bfd1c8825a0b6.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;創建嵌入向量&lt;/strong&gt;：智能體獲取你當前的任務或問題，並指令一個嵌入模型將其轉化為數字化的嵌入向量。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;搜索記憶內容&lt;/strong&gt;：這個新的嵌入向量隨後被髮送到向量數據庫，附帶一條簡單指令："find the memories most similar to this（找到與此最相似的記憶內容）"。&lt;/p&gt; 
&lt;p&gt;3）&lt;strong&gt;尋找最匹配的記憶內容&lt;/strong&gt;：數據庫將查詢嵌入向量（query embedding）與存儲的記憶嵌入向量（memory embeddings）進行比對，並檢索出最相關的前 k 個匹配項。這些匹配項可能包括過往出現的同類錯誤、其他類似任務中的成功執行結果，或是用户之前提過的相關需求。&lt;/p&gt; 
&lt;p&gt;4）&lt;strong&gt;使用記憶內容&lt;/strong&gt;：然後，相關數據會被送回主智能體，用以指導其下一步行動。&lt;/p&gt; 
&lt;p&gt;整個過程快速、模糊匹配、並且具備上下文感知能力。其核心運作理念在於： &lt;strong&gt;"智能檢索有用信息"（"find what's useful"）&lt;/strong&gt; 而非"機械記憶全部數據"（"remember everything"）。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 反思與真正的學習&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;此環節是區分基礎的一次性 LLM 與真正的智能體型系統的關鍵。任務完成後，智能體並非直接轉向新任務，而是暫停進行自我反思，並通過提出下列核心問題實現進階學習：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;哪些步驟是有效的？原因何在？&lt;/li&gt; 
 &lt;li&gt;執行過程中在哪些方面遇到了困難？&lt;/li&gt; 
 &lt;li&gt;基於當前執行結果（成功/失敗），下次是否需調整策略？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9cac879e627cbaba61e922a25748b4c3528.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過反思產生的洞見（無論是從成功中獲得的經驗，還是從失敗中獲得的教訓）將被記錄並存儲至記憶庫。這種反思循環機制使智能體能持續從行動中學習，確保未來所作的決策始終受歷史經驗指引。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 記憶類型&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;為做出智能決策，智能體會綜合使用多種類型的記憶 ------ 這與人類大腦的運作方式高度相似。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）工作記憶（Working memory）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可視為智能體的思維便利貼（mental sticky notes），用於短期存儲當前任務的指令、目標及執行步驟。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;短期記憶（Short-Term memory）：指 AI 為完成即時任務臨時暫存信息的能力。在現代 AI（如 ChatGPT）中，這種記憶通常被稱為"上下文窗口"（context window）。 
  &lt;ul&gt; 
   &lt;li&gt;本質功能：預定義的對話緩存空間，存儲當前會話的所有輸入/輸出內容&lt;/li&gt; 
   &lt;li&gt;運作原理：類比 AI 的運行內存（RAM），通過快速存取保持對話的連貫性（可實時調用上下文窗口內全部信息，從而理解最新問題的上下文）&lt;/li&gt; 
   &lt;li&gt;侷限：對話長度超限時，最早期的內容將被主動遺忘（為新內容騰出空間） ------ 這就是長對話中 AI 遺忘開頭內容的原因&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2）情景記憶（Episodic memory）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;相當於智能體的任務日記，記錄歷史執行過程中的關鍵信息，如：具體成功案例、失敗教訓、用户互動歷史。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3）語義記憶（Semantic memory）&lt;/strong&gt; ：這是智能體的長期知識庫，相當於一本內置的百科全書，它儲存着這個智能體通過長期經驗積累的通用知識、行為模式和應對策略。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;長期記憶（Long-Term memory）：這是最重要的部分。通過構建持久化的"數據庫"，使人工智能能在不同會話、不同日期乃至間隔數月後依然記住你。 
  &lt;ul&gt; 
   &lt;li&gt;本質功能：為人工智能提供存儲機制，更重要的是能夠檢索過往交互中的關鍵信息。&lt;/li&gt; 
   &lt;li&gt;運作原理：當前最主流的技術是檢索增強生成（RAG）。其運作流程如下： 
    &lt;ol&gt; 
     &lt;li&gt;存儲記憶：當用户提供重要信息（如"我的公司叫'Innovate Next'"）時，系統將其轉化為稱為"向量"的數學表徵，儲存在專用向量數據庫中&lt;/li&gt; 
     &lt;li&gt;調用記憶：當用户提出相關問題（如"為我的公司提供營銷建議"）時，系統首先查詢該數據庫獲取相關記憶片段&lt;/li&gt; 
     &lt;li&gt;應用記憶：在生成回覆前，將檢索到的記憶（"用户公司名為 Innovate Next"）用來增強提示詞&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;智能體的實時操作（工作記憶）、過往經歷（情景記憶）與通用知識（語義記憶）三者融合，才能做出真正的智能決策。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 The Future&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本文所訴內容並非理論空談，而是當前正在加速推進的現實。諸如 LangChain、LangGraph、LlamaIndex 及 CrewAI 等現代框架均已內置支持這類記憶系統 ------ 從簡易的緩存（buffers）到複雜的長期檢索器（long-term retrievers），相關技術正以閃電般的速度迭代演進。不妨關注一下專為智能體設計的 Mem0 等新興架構，它們的目標是實現智能化的記憶管理 ------ 能像人類一樣自主判斷信息價值，動態篩選需要保留的內容並優化存儲方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我們最終要構建的不只是處理信息的 AI，而是能與信息建立深度聯結的夥伴。具備記憶、學習和進化能力的 AI，正是精巧工具與真正協作夥伴的本質區別。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-871f7011f1975d249dd54e3524c76913039.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Source[2]，這個漫畫的笑點在於機器人被要求識別貓的種類，但它卻表示自己更擅長識別狗，因此無法完成這個關於貓的分類任務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓AI 記住太多個人信息會不會成為一把雙刃劍？你覺得應該在哪些方面設置記憶邊界？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Di%26url%3Dhttps%253A%252F%252Fblog.dailydoseofds.com%252Fp%252Fai-agents-crash-coursepart-8-and%26psig%3DAOvVaw0gDe2xHs6PQhdBIgL0MuSE%26ust%3D1750944586681000%26source%3Dimages%26cd%3Dvfe%26opi%3D89978449%26ved%3D0CBQQjRxqFwoTCJjD_ILXjI4DFQAAAAAdAAAAABAE" target="_blank"&gt;https://www.google.com/url?sa=i&amp;amp;url=https%3A%2F%2Fblog.dailydoseofds.com%2Fp%2Fai-agents-crash-coursepart-8-and&amp;amp;psig=AOvVaw0gDe2xHs6PQhdBIgL0MuSE&amp;amp;ust=1750944586681000&amp;amp;source=images&amp;amp;cd=vfe&amp;amp;opi=89978449&amp;amp;ved=0CBQQjRxqFwoTCJjD_ILXjI4DFQAAAAAdAAAAABAE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fimages.squarespace-cdn.com%2Fcontent%2Fv1%2F60f577b77c1ea50a11c79e10%2F1628338487176-BOJB5H9DCQ51E87V6NCI%2F20210129_dog_or_Cat_3.jpg" target="_blank"&gt;https://images.squarespace-cdn.com/content/v1/60f577b77c1ea50a11c79e10/1628338487176-BOJB5H9DCQ51E87V6NCI/20210129_dog_or_Cat_3.jpg&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbhavishyapandit9.substack.com%2Fp%2Fhow-memory-works-in-agentic-ai-a" target="_blank"&gt;https://bhavishyapandit9.substack.com/p/how-memory-works-in-agentic-ai-a&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18687444</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18687444</guid>
      <pubDate>Thu, 07 Aug 2025 08:15:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>AlmaLinux 發行版原生支持英偉達 GPU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AlmaLinux 項目&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falmalinux.org%2Fblog%2F2025-08-06-announcing-native-nvidia-suport" target="_blank"&gt;宣佈&lt;/a&gt;，AlmaLinux 10 和 AlmaLinux 9 &lt;strong&gt;現已支持 NVIDIA 的原生圖形驅動程序&lt;/strong&gt;，該驅動程序基於 NVIDIA 的開源內核模塊，這些模塊現已方便地打包在 AlmaLinux 倉庫中，便於使用，幷包含 NVIDIA 的閉源用户空間包，如 CUDA。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2593b3cf2eed6aff2963f9b608cecc024ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="804" src="https://static.oschina.net/uploads/space/2025/0808/160908_kTh5_2720166.png" width="1780" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AlmaLinux 與社區合作，為 AlmaLinux 9/10 提供了原生 NVIDIA 驅動程序支持，這些驅動程序基於其現代開源但不在內核樹中的 Turing 及更新版本內核驅動程序構建。通過使用開源內核驅動程序代碼，實現了 UEFI 安全啓動支持，並在 AlmaLinux 上安裝這些內核模塊包時提供了更好的體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365028/almalinux-native-nvidia-support</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365028/almalinux-native-nvidia-support</guid>
      <pubDate>Thu, 07 Aug 2025 08:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克：OpenAI 會「生吞」微軟</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式發佈旗艦模型 GPT-5，該模型在廣泛領域表現卓越，位居榜首：不僅在文本生成、網頁開發和視覺內容創作上排名第一，更在高難度提示詞響應、編程、數學推理、創意寫作以及長文處理等多個關鍵領域拔得頭籌。&lt;/p&gt; 
&lt;p&gt;OpenAI 首席執行官 Sam Altman 特別發文感謝合作伙伴，稱：「感謝微軟、英偉達、甲骨文、谷歌和 Coreweave 的鼎力支持，讓 GPT-5 的誕生成為可能！這背後是海量 GPU 資源的持續投入。」&lt;/p&gt; 
&lt;p&gt;微軟 CEO 薩提亞·納德拉 (Satya Nadella) 隨即宣佈 GPT-5 的集成上線：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;今天，GPT-5 已登陸我們的多個核心平台，包括 Microsoft 365 Copilot、Copilot、GitHub Copilot 以及 Azure AI Foundry。這是我們的合作伙伴 OpenAI 迄今為止最強大的模型，在推理、編碼和對話能力上實現了重大突破。所有訓練均在 Azure 雲平台上完成。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;與此同時，特斯拉 CEO 埃隆·馬斯克 (Elon Musk) 在納德拉的推文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1953509998233104649" target="_blank"&gt;回覆稱&lt;/a&gt;：「OpenAI 會「生吞」微軟。」&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/155746_esxJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;馬斯克與 OpenAI 的淵源由來已久。2015 年，馬斯克作為聯合創始人蔘與創立 OpenAI，其初衷是建立非營利機構，致力於「確保人工智能造福全人類」。然而，2018 年因控制權分歧，馬斯克選擇離開。此後雙方矛盾逐漸公開化。2024 年，馬斯克更是多次起訴 OpenAI，指控其違背非營利承諾，轉向商業化路線。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365026</guid>
      <pubDate>Thu, 07 Aug 2025 08:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
