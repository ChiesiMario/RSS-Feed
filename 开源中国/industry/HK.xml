<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Mon, 08 Sep 2025 02:57:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>OpenAI 最新論文：語言模型為什麼會出現幻覺？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 近日發表的新論文&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fwhy-language-models-hallucinate%2F" target="_blank"&gt;《Why language models hallucinate》&lt;/a&gt;&lt;/em&gt;研究了語言模型產生幻覺的核心原因，認為是現有訓練與評估機制鼓勵模型猜測而非承認不確定性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/104428_pwe5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該論文認為，語言模型之所以會產生幻覺（即在不確定時進行猜測，生成看似可信但錯誤的陳述，而不是承認不確定性），是因為現有的訓練和評估程序更傾向於獎勵猜測行為，而非承認不確定性的做法 。&lt;/p&gt; 
&lt;p&gt;就像面對難題的學生一樣，大型語言模型在不確定時有時會進行猜測，從而產生看似合理但錯誤的陳述，而不是承認不確定性。&lt;/p&gt; 
&lt;p&gt;這種「幻覺」現象即使在最先進的系統中也持續存在，並會破壞信任。&lt;/p&gt; 
&lt;p&gt;我們認為，語言模型產生幻覺是因為訓練和評估程序獎勵猜測而非承認不確定性，我們還分析了現代訓練流程中產生幻覺的統計原因。&lt;/p&gt; 
&lt;p&gt;幻覺無需被神秘化——它們源於簡單的二元分類錯誤。如果無法將不正確的陳述與事實區分開來，那麼預訓練語言模型中的幻覺就會在自然的統計壓力下產生。&lt;/p&gt; 
&lt;p&gt;接着我們認為，幻覺之所以持續存在，是因為大多數評估的評分方式——語言模型被優化成優秀的「考生」，而在不確定時進行猜測可以提高測試表現。&lt;/p&gt; 
&lt;p&gt;這種懲罰不確定性回答的「流行病」只能通過一種社會技術性的緩解措施來解決：修改那些雖不一致但主導着排行榜的現有基準測試的評分方式，而不是引入額外的幻覺評估。&lt;/p&gt; 
&lt;p&gt;這一改變或許能引導該領域走向更值得信賴的人工智能系統。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370863/why-language-models-hallucinate</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370863/why-language-models-hallucinate</guid>
      <pubDate>Mon, 08 Sep 2025 02:45:28 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>蘋果計劃 2025 年底在中國推出 Apple Intelligence</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;彭博社記者 Mark Gurman &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2025-09-07%2Fapple-s-iphone-17-air-event-which-new-iphone-should-i-buy-iphone-17-pro-mf9n5f9g" target="_blank"&gt;最新透露稱&lt;/a&gt;，蘋果目前還在繼續推進 Apple Intelligence 在中國的發佈計劃，預計年底前才能上線，iPhone 17 首發無緣。&lt;/p&gt; 
&lt;p&gt;據悉，國行 iPhone 的 Apple Intelligence 是通過第三方提供服務，整合了阿里巴巴、百度的大模型。&lt;/p&gt; 
&lt;p&gt;其中，文心一言是核心雲端引擎，阿里負責蘋果內容合規審查。其實 iOS 18.5 開始，Apple Intelligence 就已經支持中文版了，蘋果方面的準備已經就位，目前更多的是審核問題。&lt;/p&gt; 
&lt;p&gt;據報道，蘋果正組織中國區員工對相關功能進行測試，並持續與阿里巴巴及其他合作方推進技術落地工作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370856</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370856</guid>
      <pubDate>Mon, 08 Sep 2025 02:28:28 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>法院在 Meta 訴 Bright Data 案中判決 Bright Data 勝訴，重申收集公共網絡數據的權利</title>
      <description/>
      <link>https://www.oschina.net/news/370852</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370852</guid>
      <pubDate>Mon, 08 Sep 2025 02:11:28 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 支付 15 億美元和解版權訴訟</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 初創公司 Anthropic 近日同意支付至少 15 億美元，以和解一起涉及 50 萬本書籍的版權侵權訴訟。這一和解協議創下美國版權案件史上的&lt;span&gt;最高&lt;/span&gt;金額記錄，標誌着 AI 行業與內容創作者之間版權爭議的重要里程碑。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據訴訟指控，Anthropic 被指通過 Library Genesis 和 Pirate Library Mirror 等盜版網站下載了超過 700 萬本電子書，並將這些內容用於訓練其聊天機器人 Claude。和解協議顯示，每位受影響的作家預計將獲得約 3000 美元賠償，遠高於美國作家協會最初預估的 750 美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，Anthropic 還承諾銷燬其下載的所有原始文件及副本。該案件於去年 8 月由作家安德里亞·巴茨、查爾斯·格雷伯和柯克·華萊士·約翰遜等人代表提起訴訟。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-faa55c0e99754ad42c61e9d8fc6f9dda387.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在法庭審理過程中，Anthropic 曾試圖以"合理使用"原則為其行為辯護，但法院並未採納這一辯解。法院認為，Anthropic 明知使用的是盜版材料，因此其合理使用主張不能成立。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;美國作家協會首席執行官瑪麗·拉森伯格對和解結果表示積極態度，認為這向 AI 行業傳達了明確信號:未經授權使用作家作品進行 AI 訓練將面臨嚴重法律後果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，業內分析人士指出，雖然 15 億美元的賠償金額看似巨大，但對於剛剛完成 130 億美元融資、估值達 1830 億美元的 Anthropic 而言，這筆費用相對有限。這引發了人們對科技公司可能將此類賠償視為"發展成本"的擔憂。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得注意的是，類似的版權爭議並非孤立事件。蘋果公司和華納兄弟近期也因相似問題面臨訴訟，顯示出 AI 行業在版權問題上的普遍挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這起案件的和解反映了 AI 技術發展與知識產權保護之間的緊張關係。隨着 AI 模型對大量訓練數據的需求不斷增長，如何在技術創新與版權保護之間找到平衡點，將成為行業發展面臨的重要課題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對於內容創作者而言，此次和解雖然帶來了經濟補償，但也暴露了數字時代版權保護的複雜性。未來，相關法律法規和行業標準的完善將對 AI 技術的健康發展起到關鍵作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370850</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370850</guid>
      <pubDate>Mon, 08 Sep 2025 02:06:28 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義發佈 Qwen3-Max-Preview，參數量超 1 萬億</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJQocVWFMgBemmRnip7mzqQ"&gt;正式發佈&lt;/a&gt;萬億參數大模型 Qwen3-Max-Preview，參數量突破 1 萬億級別，成為其迄今規模最大的閉源旗艦模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0908/100034_nrr2_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Qwen3-Max-Preview 在多項主流權威基準測試中展現出全球領先的性能。&lt;/p&gt; 
&lt;p&gt;在通用知識（SuperGPQA）、數學推理（AIME25）、編程（LiveCodeBench v6）、人類偏好對齊（Arena-Hard v2）以及綜合性能力評估（LiveBench）評測中，Qwen3-Max-Preview 超越了 Claude-Opus 4（Non-Thinking），以及 Kimi-K2、DeepSeek-V3.1 和通義此前的開源最佳 Qwen3-235B-A22B-Instruct-2507。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0908/100102_inEl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，Qwen3-Max-Preview 已正式上線阿里雲百鍊平台，可通過 API 直接調用。同時，Qwen Chat 也同步上線新模型，支持免費使用。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1486" src="https://static.oschina.net/uploads/space/2025/0908/100057_i9Sv_2720166.png" width="2988" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;🔗體驗地址：https://chat.qwen.ai/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370848</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370848</guid>
      <pubDate>Mon, 08 Sep 2025 02:03:28 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>國內首個 AI 計算開放架構發佈</title>
      <description/>
      <link>https://www.oschina.net/news/370846</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370846</guid>
      <pubDate>Mon, 08 Sep 2025 01:54:28 GMT</pubDate>
    </item>
    <item>
      <title>智譜推出「Claude API 用户特別搬家計劃」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，美國頭部大模型公司&amp;nbsp;Anthropic&amp;nbsp;&lt;a href="https://www.oschina.net/news/370416" target="_blank"&gt;宣佈&lt;/a&gt;，將停止向多數股權由中國資本持有的集團出售 Claude 服務，範圍涵蓋中國大陸及通過海外註冊或雲服務間接使用的企業。&lt;/p&gt; 
&lt;p&gt;為幫助開發者平穩過渡，智譜正式推出「Claude API 用户特別搬家計劃」。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;一鍵遷移，暢享 GLM-4.5&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;智譜已全面兼容 Claude 協議，用户&lt;strong&gt;只需&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;替換 API URL&lt;/strong&gt;&lt;/strong&gt;，即可從 Claude 無縫切換至&amp;nbsp;&lt;strong&gt;&lt;strong&gt;GLM 模型 API&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智譜將為用户提供：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;新用户&lt;/strong&gt;&lt;/strong&gt;：贈送 2000 萬 Tokens 免費體驗；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;開發者&lt;/strong&gt;：GLM-4.5 編碼專屬包月套餐，價格僅為 Claude&amp;nbsp;&lt;strong&gt;1/7&lt;/strong&gt;，用量提升&amp;nbsp;&lt;strong&gt;3 倍&lt;/strong&gt;、速度更快（平均 55 Tokens/s）；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;遷移無憂&lt;/strong&gt;：從 Claude 到 GLM 的系統遷移教程，可便捷、快速地完成模型切換。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;為企業客户額外提供：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;滿足業務需求的併發規模；&lt;/li&gt; 
 &lt;li&gt;更低成本的折扣優惠權益；&lt;/li&gt; 
 &lt;li&gt;1 對 1 的搬家顧問與解決方案服務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速遷移教程&lt;/h2&gt; 
&lt;p&gt;如果你在使用 Claude API，訪問 bigmodel.cn，遷移到 GLM 非常簡單。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;替換你訪問的&amp;nbsp;base_url&amp;nbsp;為&amp;nbsp;https://open.bigmodel.cn/api/anthropic；&lt;/li&gt; 
 &lt;li&gt;在智譜開放平台申請&amp;nbsp;api_key；&lt;/li&gt; 
 &lt;li&gt;調用時使用智譜模型編碼即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# 原來的 Claude 代碼
import anthropic
client = anthropic.Anthropic(
    base_url="your-base-url",
    api_key="your-api-key",
)
# 遷移到智譜 AI，只需要修改三個地方
client = anthropic.Anthropic(
    api_key="your-zhipuai-api-key",  # 替換為智譜 AI API Key
    base_url="https://open.bigmodel.cn/api/anthropic"  # 配置智譜 AI base_url
)
# 模型編碼使用，智譜 AI 模型，其他代碼保持不變
message = client.messages.create(
    model="glm-4.5",  # 使用智譜 AI 模型
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
)&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370531</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370531</guid>
      <pubDate>Fri, 05 Sep 2025 10:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元遊戲視覺生成平台正式發佈 2.0 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;騰訊混元遊戲視覺生成平台正式發佈 2.0 版本，新增遊戲圖生視頻、自定義模型訓練、角色一鍵精修等能力，並大幅提升遊戲 2D 生圖模型能力，圖生視頻和文生圖模型在遊戲場景達到行業 SOTA 水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次升級進一步解決了遊戲美術設計與宣發中的動態內容生成、風格定製化、細節優化等痛點，幫助遊戲美術設計師提高效率。本次能力升級的同時，混元遊戲平台宣佈面向所有用户開放，用户可以通過騰訊混元官網體驗，登錄即可使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="274" src="https://oscimg.oschina.net/oscnet/up-881d8901997b0231d342668e831e17877df.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;新推出的遊戲 AI 動畫/CG 能力基於騰訊混元圖生視頻能力，可以讓靜態畫面秒變動畫，包括角色 360 度旋轉等遊戲。用户上傳任意遊戲圖片並輸入動態描述，即刻生成高質量動態視頻，支持遊戲角色動作、場景特效及「萬物旋轉」展示，適用於遊戲 CG 預演、角色原畫三視圖創作、技能特效預覽，替代傳統逐幀繪製流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自定義模型訓練大幅降低了生圖模型精調門檻，讓個人用户也可以通過少量圖片微調自己專屬的 LoRA 模型，解決遊戲項目風格統一難題，尤其適合獨立工作室打造 IP 化美術資產。混元遊戲官網提供了預設風格，包括歐卡、二次元、寫實 CG 等，同時支持用户使用個人數據集訓練專屬 LoRA 風格模型或者角色模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自定義模型訓練能力基於混元生圖底模，簡化了 LoRA 模型的訓練流程，用户只需上傳數十張圖片並設置觸發詞，系統自動打標，數小時即可完成模型訓練。整個訓練過程均為可視化操作，無需代碼基礎或複雜工具。該能力目前處於內測階段，用户可以申請使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;角色一鍵精修能力主要用於對遊戲角色原畫的細節豐富或風格轉換，提供高一致性模式和高創意性模式。高一致性模式可保留原圖結構，精細化服飾紋理、光影層次，適用於角色定稿優化；高創意性模式支持將角色原畫轉換為國風、3D 化、二次元等風格並細化效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;混元遊戲 2.0 針對平台背後的 2D 生圖模型進行了升級，文生圖能力達到遊戲行業 SOTA 級別。混元遊戲大幅提升生圖模型的美學與構圖，使其更能滿足遊戲美術創作需求，同時針對遊戲獨有的場景進行優化，提供遊戲技能特效、環境特效與遊戲交互界面等生成能力，專項優化遊戲場景、遊戲道具物品、遊戲角色等生成效果。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370526</guid>
      <pubDate>Fri, 05 Sep 2025 10:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>聯想發佈全球首款垂直旋轉屏 AI PC</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在德國柏林 IFA 期間舉行的 2025 聯想創新世界大會上，聯想帶來了諸多新品。其中最引人注意的就是一款 ThinkBook VertiFlex 概念機，同時這也是業界首款 14 英寸屏幕可垂直旋轉筆記本電腦。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="278" src="https://oscimg.oschina.net/oscnet/up-37aa8c07d9e00681e1351bdc757279581ab.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這款概念機最大特點就是配備的旋轉顯示系統，可以在水平和垂直方向之間雙模式切換，採用 17.9 毫米和 1.39 公斤輕薄設計。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;垂直顯示模式適合分屏多任務、顯示代碼和查看文檔等場景，並且在垂直顯示模式下，智能手機可以通過聯想超級互聯連接到 PC 上，用於傳輸文件和手機鏡像。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="311" src="https://oscimg.oschina.net/oscnet/up-59757bf204952fc6b4dbc03f4a4839c6721.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;事實上，這並不是聯想首次在筆記本電腦屏幕上的創新，此前就曾發佈了透明屏、三摺疊屏，以及今年即將開賣的卷軸屏 PC。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370522</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370522</guid>
      <pubDate>Fri, 05 Sep 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全球首個「一站式」數智化生命科學研究平台 AI4S LAB 上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;北京大學深圳研究生院與百度智能雲近日聯合宣佈，雙方攜手打造的「一站式」數智化生命科學研究平台——AI4S LAB 正式上線。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該平台深度整合算力、數據、模型、實驗四大要素，開發多智能體協同系統，為科研工作者帶來「AI 驅動、乾濕閉環、全鏈數智」的雲端科研體驗，極大提升科研效能與創新能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-4a6c75631c23cca67acff14e602a9274676.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI4S LAB 數智化支撐生態建設包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;算力：配備可伸縮的高性能計算集羣，搭載面向科學智能需求的超智融合算力調度系統。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;模型：基於百度智能雲千帆大模型平台開發私有化模型與數據管理能力，為 AI4S LAB 提供了 Agent 開發所需模型、Agent 編排、數據和定製化服務。匹配一站式模型效果調優工具鏈，為平台提供模型納管、精調與推理支持，尤其是生物領域大語言的場景化適配與調用。具有卓越的模型推理託管能力，在配備超 10 個可直接使用的通用與生命科學垂直領域代表性模型的同時，還支持各類主流推理框架和模型的自定義導入與部署，為科研工作者提供了高度靈活的開發環境。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;數據：配備超 15 個專業數據集，提供開放共享且持續產生新數據的知識平台，提供高效數據管理功能、智能可視化數據分析工具。實驗：集成超過 22 台套的先進高通量、自動化、自迭代智能實驗設備，面對生命合成領域，提供工程菌株構建與優化，蛋白表達與酶工程，代謝工程與調控，非天然氨基酸整合，合成噬菌體開發等多場景提供高效科研服務。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;北京大學深圳研究生院自主研發的 AI4S 原生多智能體系統——BIOMA，是平台全鏈路智能化實現的核心，提供高效協同的雲化研究能力，涵蓋了從理論預測、實驗設計、自動化執行到數據分析與迭代的各個環節，助力科研人員突破傳統研究的時空限制。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;BIOMA 多智能體系統的強大能力包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;逆向智能設計： 從期望的功能或性能指標出發，智能設計全新的實驗方案與材料。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能創制與表徵： 自動化地執行復雜的實驗流程，並對結果進行精確表徵。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;科研數據智能分析與迭代： 對海量實驗數據進行深度分析，並基於分析結果自主優化後續實驗方案。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-42c4dd9e2e3b6665fae4d5b9511c060a767.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;BIOMA 多智能體系統由一系列功能協同的智能體構成，每個智能體在科研流程中扮演着關鍵角色：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#222222"&gt;理論科學家智能體（PredAgent）&lt;/strong&gt;&lt;strong style="color:#222222"&gt;，&lt;/strong&gt;在理論預測階段，解析科研人員以自然語言輸入的研究構想，並即時調用全球前沿的預測模型和工具進行模擬與計算。極大地提升了理論設計的效率，更通過算法優化增強了預測的準確性，為後續的實驗研究奠定堅實理論基礎。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;實驗規劃師智能體（ProAgent）&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;具備自主生成完整、可執行的標準化實驗方案的能力。在乾濕閉環&lt;strong&gt;驗證&lt;/strong&gt;&lt;strong&gt;階段&lt;/strong&gt;，通過與研究人員的多輪交互，精確提煉並完善濕實驗方案的每一個細節，包括試劑選擇、參數設定以及儀器調配等，從而構建出邏輯嚴謹、操作性強的實驗流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能實驗室自動化被《自然》期刊列為「2025 年值得關注的七大技術」之首。&lt;strong&gt;實驗室指揮官智能體（OperAgent）&lt;/strong&gt;&lt;strong&gt;，&lt;/strong&gt;負責在實驗執行階段，將 ProAgent 生成的複雜實驗方案轉化為機器可精確執行的指令。通過對實驗室超 22 台自動化設備的多線程精準調度與協同控制，成功打造 7x24 小時不間斷運行的「黑燈實驗室」，實現了真正意義上的無人化、自動化實驗流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;數據分析師智能體（ComAgent），&lt;/strong&gt;致力於構建一個一體化的科研數據生態系統，提供豐富的數據分析工具與可視化圖表，同時基於設定的關鍵性能指標，對實驗數據進行深度挖掘與洞察。通過自主分析，ComAgent 生成富有洞見的優化建議，並自動規劃下一輪的實驗方案，從而形成可持續進化的科研閉環，加速科學發現進程。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370509</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370509</guid>
      <pubDate>Fri, 05 Sep 2025 09:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Hopp - 開源結對編程應用程序</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hopp 是一款開源結對編程應用，可讓你與隊友結對編程。該應用使用 Tauri 構建，WebRTC 基礎架構由&lt;a href="https://livekit.io/"&gt;LiveKit&lt;/a&gt;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;img height="132" src="https://static.oschina.net/uploads/space/2025/0903/144658_hgds_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特性&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;超高品質屏幕共享&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gethopp.app/blog/latency-exploration"&gt;優化了 WebRTC&lt;/a&gt;，以獲得最佳質量的屏幕共享&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.livekit.io/home/cloud/architecture/#distributed-mesh-architecture"&gt;依靠 LiveKit 網絡&lt;/a&gt;實現大規模低延遲&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Mob&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;編程&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;加入房間並立即與最多 10 名隊友配對&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一鍵配對&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;不再在聊天中與隊友分享鏈接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;開放式建造&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;希望與 OSS 社區共同打造 Hopp&lt;/li&gt;
&lt;li&gt;這帶來了自託管和社區創新的好處&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/hopp</link>
      <guid isPermaLink="false">https://www.oschina.net/p/hopp</guid>
      <pubDate>Fri, 05 Sep 2025 09:24:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenDataLab 與釘釘聯手推出面向企業用户的文檔解析工具 DLU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;OpenDataLab 和釘釘基於 MinerU &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLg-4_0PNluM8l_pYQTjc7Q" target="_blank"&gt;推出&lt;/a&gt;了一款面向企業用户的文檔解析工具——DLU&lt;/span&gt;&lt;span&gt;(Document Language Understanding)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/172338_aEbD_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MinerU 是上海人工智能實驗室（上海 AI 實驗室）OpenDataLab 推出的智能文檔解析引擎，因精準解析能力及廣泛兼容性深受用户青睞，在 GitHub 上已累計獲得超 4 萬星標。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/172239_vfIi_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;基於 MinerU 打造的 DLU 將於近期開源，其具備良好的文件格式兼容性，深層次的內容理解與精準的結構化輸出能力，不僅支持主流的 Office 文檔、PDF、Markdown 及代碼文件，還涵蓋釘釘自有的文檔、表格與 AI 表格格式；並支持提取純文本內容，精準解析圖表、公式、插圖乃至專業領域的化學分子式等複雜視覺元素，並將其有效轉換為適合大模型訓練的高質量語料。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370505</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370505</guid>
      <pubDate>Fri, 05 Sep 2025 09:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>拍我 AI 接入谷歌 Nano Banana，限時免費使用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;拍我 AI 已正式接入谷歌 Nano Banana（Gemini 2.5 Flash Image），並同步開啓「拍我 AI 免費開放日」限時活動，從 9 月 5 日持續至 9 月 10 日，為期六天。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-31f43668eb292a7a399ef21c78092a4f3ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;在此期間，國內用户可免費體驗 PixVerse Agent 創作助手，零成本生成各類創意短片。用户只需選擇喜歡的模板並上傳一張圖片，Agent 即可自動識別圖像特徵，生成 5–30 秒的完整視頻。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;作為國內首批接入 Nano Banana 的 AI 視頻生成平台，拍我 AI 國內版同步推出更多趣味模板，包括 3D 手辦製造局、和名人合照、捕獲心動角色、騎龍高手等，讓普通用户也能輕鬆上手，製作精緻、有趣的短視頻作品，以及更進一步製作出自己喜愛的遊戲畫面！目前拍我 AI 網頁端和移動端 APP 均可同步體驗。&lt;/p&gt; 
&lt;p&gt;今年 6 月 6 日，PixVerse 上線了中國版本拍我 AI，目前平台的全球用户規模已突破 1 億。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370503</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370503</guid>
      <pubDate>Fri, 05 Sep 2025 09:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>VC 投資人嘗試 20 天「氛圍編程」，稱成本高昂、易累積技術債</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Kevin Kuipers 是一名 VC 投資人，最近他&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkevinkuipers.substack.com%2Fp%2Fvc-for-vibe-coding-a-fresh-new-start" target="_blank"&gt;分享&lt;/a&gt;了「Vibe Coding」的實踐經驗，通過 AI 編程構建面向 VC 的全新工作平台。&lt;/p&gt; 
&lt;p&gt;Kuipers 在暑假期間嘗試了沉浸式的「氛圍編程（Vibe Coding）」，目標是為自己的基金打造「AI-native」（AI 原生）管理系統。他先從 Telegram 智能體起步，逐步擴展到 Web 和桌面端應用，用 AI 自動整合文章、郵件、Pitch Deck、對話等信息，構建出一個「知識雲」，從非結構化數據中提煉趨勢與洞見。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165630_7gXE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在技術棧上，他大量依賴 Supabase、Orq.ai、Mem0、Koyeb、Linkup、ScrapingBee 等工具，並利用 Claude 直接生成 UI/UX，大幅減少了傳統 Figma 等設計流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165641_hALP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0905/165713_UDsC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他指出，AI 編程的優勢是能在幾周內完成原型，顯著提升迭代效率，但同時也伴隨挑戰：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;技術債容易累積，代碼質量難控；&lt;/li&gt; 
 &lt;li&gt;成本高昂，僅 20 天就消耗約 2600 美元 Token；&lt;/li&gt; 
 &lt;li&gt;LLM 的創造力和破壞力並存，需要工程師負責架構與質量。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Kuipers 強調，「vibe coding」核心不是寫代碼，而是「快速建造」，讓 VC 的知識管理和決策更高效。他認為，這種模式可能重塑風險投資的工作方式，也讓投資人與工程師保持更深度的互動。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370500/vc-for-vibe-coding-a-fresh-new-start</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370500/vc-for-vibe-coding-a-fresh-new-start</guid>
      <pubDate>Fri, 05 Sep 2025 08:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「Nano Banana」上線不到 10 天，為谷歌 Gemini 吸引超過 1000 萬名新用户</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌最新的 AI 實驗項目「Nano Banana」在上週爆火，谷歌實驗室副總裁 Josh Woodward 在 X 上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fjoshwoodward%2Fstatus%2F1963627742618165270" target="_blank"&gt;透露&lt;/a&gt;，自該功能上線以來，累計已完成超 2 億次圖像編輯，&lt;strong&gt;帶動超 1000 萬新用户嘗試 Gemini 應用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;對於這款產品的受歡迎程度，他形容稱導致「TPU 嚴重過載，SRE 警報不停。」&lt;/p&gt; 
&lt;p&gt;&lt;img height="854" src="https://static.oschina.net/uploads/space/2025/0905/164501_ZL7i_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;Gemini 2.5 Flash Image&lt;/span&gt;（內部代號 Nano Banana）是谷歌&lt;span style="background-color:#ffffff; color:#333333"&gt;最先進的圖像生成與編輯模型，&lt;/span&gt;主要特點如下：&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;充分保持角色的一致性：它可以輕鬆地將同一個角色置於不同的環境中，或者從多個角度展示同一款產品，同時完美地保持其核心主體不變。&lt;/li&gt; 
 &lt;li&gt;基於提示的圖片編輯：允許用户通過簡單的自然語言指令，對圖片進行精準的局部修改 。&lt;/li&gt; 
 &lt;li&gt;利用 Gemini 的現實世界知識：模型可藉助 Gemini 強大的世界知識庫，讓圖像生成變得更加「智能」。&lt;/li&gt; 
 &lt;li&gt;多幅圖像融合：可以將一張圖片中的物體「放」進另一張圖片的場景裏，整個過程只需一條提示指令就能完成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;性能表現上，Gemini 2.5 Flash Image 在多項基準測試上均為第一名，超越 OpenAI ChatGPT 4o（GPT Image 1 high）、Qwen Image Edit 等模型。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfee07407ab38e2b001fd0dbe895d36f242.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370497</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370497</guid>
      <pubDate>Fri, 05 Sep 2025 08:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>尤雨溪 VoidZero 公司 8 月成果速覽</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;尤雨溪 VoidZero 公司&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fwhats-new-aug-2025" target="_blank"&gt;發佈&lt;/a&gt;了 2025 年 8 月回顧，闡述了&amp;nbsp;Vite、Vitest、Oxc、Rolldown 的項目更新以及社區動態。&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-bf866c877e66b526b8d1364ddab2a5ebfa3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具體包括：&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Oxlint：類型感知 linting 和自定義 JS 插件&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Oxlint &lt;span style="color:#3d3d3d"&gt;旨在成為一款功能齊全、運行速度與原生速度一致的 Linting 替代品。本月發佈了兩項重大更新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;類型感知 linting&lt;/strong&gt;：基於 TypeScript 的 Go 端口和 tsgolint，支持 40 個類型感知規則，如 no-floating-promises。性能保持高效，無需犧牲速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自定義 JS 插件支持&lt;/strong&gt;：提供 ESLint 兼容 API，支持運行現有 ESLint 插件，而不犧牲性能。未來，幾乎所有 ESLint 插件都能無縫兼容 Oxlint。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Vite&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vite 現已通過&lt;code&gt;@vitejs/plugin-rsc&lt;/code&gt;引入 React Server Component 支持。目標是為每個基於 Vite 的 React 框架提供統一的解決方案。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;@vitejs/plugin-react&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitejs%2Fvite-plugin-react%2Fblob%2Fmain%2Fpackages%2Fplugin-react%2FCHANGELOG.md%23500-beta0-2025-07-28" target="_blank"&gt;5.0 版本已發佈&lt;/a&gt;。當檢測到&lt;code&gt;rolldown-vite&lt;/code&gt;時，它會直接集成&lt;code&gt;@vitejs/plugin-react-oxc&lt;/code&gt;，因此不再需要額外安裝其他插件。&lt;/li&gt; 
 &lt;li&gt;Dev server 漏洞修復，修復源代碼泄露風險。詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreen.sapphi.red%2Fblog%2Faddressing-source-code-leaks-across-the-ecosystem-a-retrospective" target="_blank"&gt;閲讀 Sapphi 的回顧博客文章&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvite-pwa%2Fvite-plugin-pwa%2Fpull%2F877" target="_blank"&gt;&lt;code&gt;vite-plugin-pwa&lt;/code&gt;（和其他 Vite 插件）&lt;/a&gt;的 Plugin Hooks 現已到位，使用&lt;code&gt;rolldown-vite&lt;/code&gt;時可顯著提升其運行速度&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;Vitest&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vitest 在最新的 v4 測試版中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbsky.app%2Fprofile%2Ferus.dev%2Fpost%2F3luzbsen2722x" target="_blank"&gt;支持可視化迴歸測試&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;v4 測試版通過平均縮短 Vitest 啓動時間 25%，進一步提升了測試速度。&lt;/li&gt; 
 &lt;li&gt;Vitest 的實驗性&amp;nbsp;programmatic API&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitest-dev%2Fvitest%2Fpull%2F8408" target="_blank"&gt;現在可以解析測試文件，&lt;/a&gt;而不是運行它們來收集測試數據。這對於第三方服務提供商尤其有用，並且有助於未來實現更快的過濾速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Rolldown&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolldown-Vite&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvitejs%2Frolldown-vite%2Fpull%2F168" target="_blank"&gt;開箱即用地支持原生插件&lt;/a&gt;。在原生標誌下進行改進，並解決所有生態系統 CI 問題後，第一組插件被認為足夠穩定，可以默認啓用，從而提升所有構建的速度，而無需任何配置。&lt;/li&gt; 
 &lt;li&gt;消除&amp;nbsp;Dead code elimination 和 treeshaking 優化是精簡 bundle 的關鍵。在最近的 Rolldown 版本中進行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fpull%2F5826" target="_blank"&gt;多項&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fpull%2F5829" target="_blank"&gt;改進&lt;/a&gt;，以進一步降低 bundle 大小。 
  &lt;ul&gt; 
   &lt;li&gt;新增&lt;code&gt;inlineConst&lt;/code&gt;&amp;nbsp;功能：在打包過程中內聯導入的常量值（而非引用它們）。由於減少了變量查找次數，此特性可縮小打包文件體積並提升運行時性能。自 1.0.0-beta.35 版本起，此優化將默認啓用。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Rolldown 現在有一個&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frolldown.rs%2Freference%2Fconfig-options%23tsconfig" target="_blank"&gt;頂級&lt;code&gt;tsconfig&lt;/code&gt;選項&lt;/a&gt;。可以將其指向項目的 tsconfig 路徑，從而允許解析器遵循&lt;code&gt;compilerOptions.paths&lt;/code&gt;的別名設置，併為轉換配置建立默認值。此功能將取代先前引入的&lt;code&gt;resolve.tsconfigFilename&lt;/code&gt;選項。&lt;/li&gt; 
 &lt;li&gt;第一個案例研究已經發布：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fcase-study-plaid-rolldown" target="_blank"&gt;瞭解 PLAID Inc. 如何遷移到 Rolldown 並將其構建時間縮短 97%&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Oxc&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rolldown 團隊不僅致力於確保打包體積更小，Oxc 的壓縮工具現在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foxc-project%2Foxc%2Fpull%2F13026" target="_blank"&gt;也會多次運行 dead code 消除&lt;/a&gt;，類似於 Rollup。這可以進一步減小打包體積，同時只增加極小的開銷。&lt;/li&gt; 
 &lt;li&gt;如果你正在使用 React 和&lt;code&gt;styled-components&lt;/code&gt;，構建速度將顯著提升，因為 Oxc 現在將其大部分功能作為原生轉換支持。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frolldown%2Frolldown%2Fblob%2Fmain%2Fexamples%2Fstyled-components-native%2FREADME.md" target="_blank"&gt;如本例所示，&lt;/a&gt;它也可以在 Rolldown 中輕鬆啓用。&lt;/li&gt; 
 &lt;li&gt;提升性能&lt;code&gt;tsgolint&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvoidzero.dev%2Fposts%2Fwhats-new-aug-2025" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370495/voidzero-whats-new-aug-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370495/voidzero-whats-new-aug-2025</guid>
      <pubDate>Fri, 05 Sep 2025 08:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>這款插件讓你在開源圖像編輯器 GIMP 中體驗谷歌 Nano Banana</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開發者 Josh Ellithorpe 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthoughts.greyh.at%2Fposts%2Fdream-prompter%2F" target="_blank"&gt;發佈&lt;/a&gt;&amp;nbsp;Dream Prompter 開源插件，將谷歌最新的 Gemini 2.5 Flash Image Preview 模型（代號 「Nano Banana」）引入 GIMP。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-57d084ce880042f5d91d09d2e5a1dc48003.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該插件支持用户在 GIMP 內直接通過文字提示生成新圖像，或對現有圖像進行自然語言編輯，無需切換到外部工具。使用 Dream Prompter 需綁定啓用計費的 Google Gemini API key，插件本身已開源並託管在 GitHub。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7dee797f30e7632220f65ce17e0f9abb13d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ellithorpe 表示，他在 Claude 模型的幫助下快速完成了插件開發。這一集成讓 GIMP 用户能夠在開源環境中享受與 Adobe 等商業軟件類似的 AI 創作體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370492</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370492</guid>
      <pubDate>Fri, 05 Sep 2025 08:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 生成優化 Metal 內核，PyTorch 推理速度提升 87%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據 Gimlet Labs 的&lt;span&gt;最新&lt;/span&gt;研究，AI 能夠自動生成優化的 Metal 內核，使得 PyTorch 推理速度提升了 87%。這一突破性成果不僅提高了性能，還在測試的 215 個 PyTorch 模塊上實現了平均 1.87 倍的加速，某些工作負載的速度甚至提高了數百倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="236" src="https://oscimg.oschina.net/oscnet/up-bffbe7fb79340a185f9f81437c72a069abe.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人員選取了來自多個&lt;span&gt;頂尖&lt;/span&gt;機構的八個 AI 模型，包括 Anthropic、DeepSeek 和 OpenAI，利用這些模型為蘋果設備生成優化的 GPU 內核。這一過程無需修改用户代碼或使用新的框架，直接在蘋果硬件上提升模型性能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在實驗中，研究團隊選擇了 Mac Studio （搭載 Apple M4Max 芯片） 進行測試，基準設置為 PyTorch 的 eager 模式。實驗採用了 KernelBench 數據集中的 215 個 PyTorch 模塊，這些模塊被分為三類，涵蓋從簡單的矩陣乘法到完整的模型架構。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;測試過程包括接收輸入和 PyTorch 代碼，生成 Metal 內核，並評估其正確性。數據顯示，隨着嘗試次數的增加，AI 生成內核的正確性逐步提升。例如，在第五次嘗試時，正確實現的比例達到了 94%。此外，模型們在生成內核時表現出了跨層級的能力，儘管非推理模型有時也能生成有效內核。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;實驗結果表明，GPT-5 模型在某些任務上實現了 4.65 倍的速度提升。更令人驚訝的是，o3 模型在某些情況下甚至將延遲降低了 9000 倍。研究還發現，單一模型在某些任務上並不總是表現&lt;span&gt;最好&lt;/span&gt;，多個模型的結合能夠生成更優的內核。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;為了進一步提升性能，研究者嘗試引入額外上下文信息，如 CUDA 實現和 gputrace 的性能分析數據，結果顯示這種方法在性能加速方面達到了平均 1.87 倍，相比於普通智能體的 1.31 倍提升了三倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;需要注意的是，研究人員強調，這一工作並不是為了展示最終的性能極限，而是為了驗證 AI 在內核生成中的可行性，希望通過自動化減少開發人員的負擔。整體而言，這項研究標誌着 AI 技術在硬件優化領域的一個重要進展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370488</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370488</guid>
      <pubDate>Fri, 05 Sep 2025 08:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>WinStore 小白友好的，社區驅動的軟件下載利器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1&gt;WinStore 是什麼&lt;/h1&gt; 
&lt;p&gt;WinStore 是藉助社區共享的力量，打造一個小白友好的，官方的軟件和環境下載地址，避免在找軟件時，被無良網站誘拐下載，導致電腦被惡意軟件和流氓插件佔領。 能夠在 Windows 下一鍵安裝使用，無需多餘配置，無廣告，無後門，代碼純開源，半離線模式，僅需在更新軟件庫時，臨時給與聯網權限即可。 在計劃中的後續版本中，還將集成 Windows 工具箱功能，為小白提供一鍵的軟件卸載，清理，磁盤清理，文件保險箱，免費壁紙等功能。&lt;/p&gt; 
&lt;h1&gt;為什麼要使用 Winstore&lt;/h1&gt; 
&lt;p&gt;作為一個 windows 系統的習慣用户，真的對於現在 windows 的軟件生態環境感到無比的難受，各種的流氓插件，各種捆綁包，全家桶，數不盡的廣告牛皮癬……我們簡單下載一個 steam 可能就會遇到無數的套殼，盜版，偽裝的軟件，更離譜的是，我親眼看着我朋友下載了一個需要支付 49.9 元才能使用的 steam😂。還經常看到一些文員同事，和其他對於電腦維護不太瞭解的朋友，電腦桌面上各種的 《是兄弟就來砍我》《正版傳奇》《性感發牌在線荷官😂》。導致電腦成了流氓軟件的自助餐廳，瘋狂恰飯。這些流氓軟件不但危害了用户的電腦，還導致正版軟件的口碑遭到嚴重影響。 WinStore 採用全官方下載，不會導致電腦被無良下載站的所謂《高速下載》《下載器下載》誘導。同時社區還會分享眾多個人開發者製作的良心軟件，一鍵下載，直達正版，讓電腦的軟件環境，重回安全，安逸。&lt;/p&gt; 
&lt;h1&gt;Winstore 特點&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;無廣告&lt;/li&gt; 
 &lt;li&gt;無後門&lt;/li&gt; 
 &lt;li&gt;官方直達&lt;/li&gt; 
 &lt;li&gt;軟件精簡（安裝包不到 10MB，運行佔用不超過 80MB）&lt;/li&gt; 
 &lt;li&gt;社區驅動，資源不斷豐富&lt;/li&gt; 
 &lt;li&gt;全免費，無收費項目和套路&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;軟件界面&lt;/h1&gt; 
&lt;p&gt;如果大家覺得對你產生了幫助，請移步倉庫給項目點一個 star，你的支持就是開發者最大的動力。&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href="https://gitee.com/MR-wind/win-store/releases/download/1.0.0/WinStoreSetup.exe"&gt;https://gitee.com/MR-wind/win-store/releases/download/1.0.0/WinStoreSetup.exe&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;倉庫地址：&lt;a href="https://gitee.com/MR-wind/win-store"&gt;https://gitee.com/MR-wind/win-store&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370607</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370607</guid>
      <pubDate>Fri, 05 Sep 2025 05:30:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Firefox 將在 2026 年終止對 32 位 Linux 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Mozilla &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Ffuturereleases%2F2025%2F09%2F05%2Ffirefox-32-bit-linux-support-to-end-in-2026%2F" target="_blank"&gt;宣佈&lt;/a&gt; Firefox 144 版本（預計發佈於 2025 年）是最後一個仍支持 32 位 Linux 的版本。自 Firefox 145 開始，將不再提供對 32 位 Linux 的支持。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/105312_Tahd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mozilla 在公告提到，近年來大多數 Linux 發行版已普遍放棄對 32 位 Linux 的支持，導致維護這一平台變得「越來越困難且不可靠」。為了專注於為用户提供更現代、更穩定的 Firefox，Mozilla 決定撤回對 32 位 Linux 的支持。&lt;/p&gt; 
&lt;p&gt;如果你正在使用 32 位 Linux 系統上的 Firefox，Mozilla 強烈建議切換到 64 位操作系統，並安裝支持持續更新的 Firefox 64 位版本。&lt;/p&gt; 
&lt;p&gt;對於暫時無法升級的用户，Mozilla 提供了過渡方案——Firefox ESR 140 的 32 位構建仍將繼續提供安全更新，直到 2026 年 9 月。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370864/firefox-32-bit-linux-support-to-end-in-2026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370864/firefox-32-bit-linux-support-to-end-in-2026</guid>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
