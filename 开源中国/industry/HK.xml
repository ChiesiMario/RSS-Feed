<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Fri, 04 Jul 2025 07:43:10 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>法國 AI 研究機構開源 Kyutai TTS，低延遲流式文本轉語音技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;法國 AI 研究機構 Kyutai Labs 宣佈開源其最新文本轉語音（TTS）技術——Kyutai TTS，這是一個實時的語音生成解決方案。Kyutai TTS 以低延遲與高保真聲音為亮點，支持文本流式傳輸，無需完整文本即可開始生成音頻，特別適合實時交互場景。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0704/145146_pipR_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkyutai.org%2Fnext%2Ftts" target="_blank"&gt;https://kyutai.org/next/tts&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Kyutai TTS 在性能上表現卓越。使用單塊 NVIDIA L40S GPU，該模型可同時處理 32 個請求，延遲僅為 350 毫秒。此外，系統不僅生成高質量音頻，還能輸出單詞的精確時間戳，方便實時字幕生成或交互式應用，如 Unmute 平台的中斷處理功能。&lt;/p&gt; 
&lt;p&gt;在語言支持與質量評估方面，Kyutai TTS 目前支持英語和法語，單詞錯誤率（WER）分別為 2.82 和 3.29，展現出高準確度。説話者相似度達到 77.1%(英語) 和 78.7%(法語)，確保語音自然且接近原始樣本。模型還能處理長篇文章，突破傳統 TTS 的 30 秒限制，適合新聞、書籍等長篇內容生成。&lt;/p&gt; 
&lt;p&gt;Kyutai TTS 採用延遲流建模（DSM）架構，結合 Rust 服務器實現高效批處理，已在 GitHub 和 Hugging Face 開放源碼與模型權重，助力全球開發者推動語音技術創新。&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkyutai-labs%2Fdelayed-streams-modeling" target="_blank"&gt;https://github.com/kyutai-labs/delayed-streams-modeling&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358755</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358755</guid>
      <pubDate>Fri, 04 Jul 2025 06:53:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技或於科創板 IPO</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;據《每日經濟新聞》從宇樹科技相關投資方獲悉，宇樹科技後續有計劃於科創板 IPO（首次公開募股）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-b580657b265e86eea613b405eac902d810a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月 29 日，宇樹科技發佈通知稱，因公司發展需要，杭州宇樹科技有限公司即日起名稱變更為「杭州宇樹科技股份有限公司」。彼時，有媒體報道稱，宇樹科技這一舉動可視同完成股改。至於為何變更名稱，外界認為或許是為了 IPO 鋪路。而宇樹科技曾回應，「這是公司運營方面的常規變更」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;6 月份消息，宇樹科技已完成了始於去年 9 月的 C 輪融資交割，由中國移動旗下基金、騰訊、錦秋、阿里、螞蟻、吉利資本共同領投，絕大部分老股東跟投。融資金額接近 7 億元人民幣，投後估值超 120 億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技創始人兼 CEO 王興興還在夏季達沃斯論壇上透露，公司年度營收已超 10 億元人民幣。此前也有宇樹科技投資人透露，自 2020 年起，宇樹科技已連續 5 年實現盈利。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/352690" target="_blank"&gt;宇樹科技回應更名 「股份有限公司」&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/356437" target="_blank"&gt;宇樹科技確認：近期已完成 C 輪融資交割&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/357324" target="_blank"&gt;宇樹科技王興興：公司目前年度營收超過十億元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358747</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358747</guid>
      <pubDate>Sun, 11 May 2025 06:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>印度程序員用一份假簡歷騙了 5 家硅谷 AI 公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 時代「最強」打工王者出現了。近期，一名叫 Soham Parekh 的印度程序員被曝通過一份假簡歷，在多家硅谷 AI 初創公司進行遠程兼職，最多時同時打了五份工，領取多份工資，引發廣泛關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45b140ce1925eb09a92af71a5196c086da0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Playground AI 的創始人 Sohail Doshi 最早發文爆料，稱這名印度工程師靠着一份幾乎 90% 造假的簡歷，同時在 3-5 家初創公司上班。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a368826a86d01bca7fba881f66b1122a59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Sohail Doshi 表示，入職第一週就發現對方不對勁，於是立馬開除，臨走前還苦口婆心地勸對方別再騙人了，沒想到這位印度工程師非但沒收手，還越戰越勇，繼續多線作戰。&lt;/p&gt; 
&lt;p&gt;後續，風投機構 YC 總裁 Garry Tan 也親自下場發文表示，如果沒有 YC 社區，這個人可能還在繼續操作，甚至永遠不會被發現。&lt;/p&gt; 
&lt;p&gt;據 Garry Tan 的説法，&lt;strong&gt;這位印度工程師專挑 YC 支持的創業公司下手，同時在至少三家由 YC 支持的創業公司打卡上班，最多甚至五家，並且每家公司都以為他是全職&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-627ac6534e25a6f42898e1b76863c6317df.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，Soham Parekh 雖然在簡歷和麪試這兩方面堪稱完美，但在正式工作（或者工作試用期）真正開始的時候， 他會找一個又一個的藉口，解釋為什麼缺席會議，或者為什麼工作被推遲，亦或者他每天都會找個藉口請假半天，比如説要見律師。後面，這些藉口越來越荒謬，直到所有人開始意識到他明顯在撒謊。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358729</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358729</guid>
      <pubDate>Sun, 11 May 2025 04:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>號碼生成系統的創新實踐：遊戲週週樂幸運碼設計</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者： vivo 互聯網服務器團隊- Zhang Jing&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本文以遊戲週週樂的幸運碼為切入點，針對其生成過程中涉及的隨機性、唯一性及高併發等特點，設計了一種基於號段+子碼的創新架構。該方案不僅在生成速度上表現突出，還顯著提升了存儲效率，同時降低了擴容成本，為類似的號碼生成系統提供了設計上的新思路和啓發。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;文章太長？1 分鐘看圖抓住核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d0f19634e0555861f34c6d1a965332e5035.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、業務背景&lt;/h1&gt; 
&lt;p&gt;用户可通過完成相關任務獲取週週樂幸運碼，幸運碼的投放規則如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;基礎投放量&lt;/strong&gt;：每期 100 萬注唯一無重複的 6 位數字幸運碼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;動態擴容機制&lt;/strong&gt;：參與人數超額時，可實時追加 100 萬注&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、幸運碼特性&lt;/h1&gt; 
&lt;p&gt;根據背景介紹，我們可以知道幸運碼需要支持如下特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隨機性&lt;/strong&gt;，發給每個用户的幸運碼都是隨機的，同時每個用户領取的多個幸運碼也是隨機的。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;唯一性&lt;/strong&gt;，每一組的幸運碼中，各幸運碼都是唯一的。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;範圍性&lt;/strong&gt;，幸運碼嚴格限定在 000000 到 999999 區間內。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高併發&lt;/strong&gt;，幸運碼的生成和發放需要支持高併發，能夠至少達到 300QPS。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可追加&lt;/strong&gt;，在當期活動非常火爆時，需要可臨時追加一組幸運碼庫存。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;三、方案選型&lt;/h1&gt; 
&lt;p&gt;鑑於幸運碼需嚴格限定在 6 位數字範圍內（000000-999999），傳統雪花算法因生成超長 ID（64 位二進制）且依賴時間戳遞增特性，難以直接適配。以下將對比三種方案：實時隨機生成模式、預生成庫存模式及號段+子碼模式，並會根據生成速度、存儲效率、擴容成本三個核心指標進行系統性評估，最終選擇出最優解決方案。&lt;/p&gt; 
&lt;h2&gt;3.1 方案一：實時隨機生成模式&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;實現邏輯：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;生成隨機數&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;再查詢數據庫是否有該隨機數&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若沒有則入庫，完成幸運碼發放&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若有再重新執行第一步&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;缺陷分析：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;碰撞概率隨庫存消耗不斷上升&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據庫 IO 壓力隨併發量線性增長&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不滿足高併發場景性能要求&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3.2 方案二：預生成庫存模式&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;實現邏輯：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;採用預生成幸運碼方式：離線生成 100 萬個幸運碼，隨機打散，寫入數據庫，每個幸運碼對應一個從 1 自增的序列號，並使用 Redis 記錄幸運碼序列號索引，初始值為 1。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;發放步驟&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;從 Redis 查詢幸運碼序列號索引&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用該索引查詢幸運碼，並完成幸運碼發放&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遞增 Redis 的序列號索引，確保序列號索引關聯的幸運碼是下一個可發放的幸運碼&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;缺陷分析：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存儲空間浪費&lt;/strong&gt;：未發放號碼佔用存儲&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;擴容效率低下&lt;/strong&gt;：追加庫存需重新預生成&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3.3 方案三：號段+子碼模式&lt;/h2&gt; 
&lt;p&gt;採用號段+子碼機制：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;號段管理&lt;/strong&gt;：將 10^6 號碼劃分為 1000 個號段（號段值：0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;子碼管理&lt;/strong&gt;：每個號段維護 1000 個可用子碼（子碼值：0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成規則&lt;/strong&gt;：幸運碼=隨機號段*1000+隨機子碼（示例：129358=129*1000+358）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-45d325576bad2645b81b131cf8277e2e471.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.4 方案對比&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-079c02eb66e15c161b0b30001341fb6548d.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;綜上，我們綜合幸運碼生成速度、存儲效率、擴容成本等指標，最終採用了號段+子碼模式來生成幸運碼。&lt;/p&gt; 
&lt;h1&gt;四、關鍵技術實現&lt;/h1&gt; 
&lt;h2&gt;4.1 號段分層機制&lt;/h2&gt; 
&lt;p&gt;將 100 萬注幸運碼劃分為 1000 個號段（每段 1000 注），每個號段由兩部分組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;號段 ID&lt;/strong&gt;：號段 ID 為唯一且不重複的整數，範圍介於 0 到 999 之間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;子碼串&lt;/strong&gt;：1000 位字符串，採用"01"標記使用狀態，0 表示未使用，1 表示已使用，初始全 0。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;幸運碼生成公式：&lt;/p&gt; 
&lt;p&gt;幸運碼 = 號段 ID * 1000 + 子碼位置&lt;/p&gt; 
&lt;p&gt;該設計既保留了生成幸運碼的隨機性（號段 ID 隨機+子碼隨機），又通過子碼的類比特位存儲方式提升了存儲效率。&lt;/p&gt; 
&lt;h2&gt;4.2 分佈式併發控制&lt;/h2&gt; 
&lt;h3&gt;4.2.1 多級緩存策略&lt;/h3&gt; 
&lt;p&gt;Redis 存儲可用號段集合，若號段的子碼使用完，該號段會從 Redis 集合中剔除，同時本地緩存也會預加載可用號段，確保發碼時能更高效地獲取候選號段。&lt;/p&gt; 
&lt;h3&gt;4.2.2 高效鎖搶佔策略&lt;/h3&gt; 
&lt;p&gt;系統為每個號段分配了分佈式鎖，當執行發放幸運碼時，會從本地緩存隨機獲取 15 個候選號段。然後在遍歷獲取號段時，將等待鎖的超時時間設置成 30ms，確保號段被佔用的情況下能夠快速遍歷到下一個號段（根據實際場景統計，等待鎖的情況很少發生，一般最多遍歷到第二個號段即可成功搶佔）。一旦成功獲得號段的分佈式鎖後，便可進一步隨機獲取該號段下的可用子碼。&lt;/p&gt; 
&lt;h3&gt;4.2.3 動態庫存策略&lt;/h3&gt; 
&lt;p&gt;要追加庫存，只需再創建一組幸運碼號段，並寫入 Redis，後續發放時獲取該組的可用號段生成幸運碼即可。從性能和存儲空間上遠優於預生成方式。&lt;/p&gt; 
&lt;h2&gt;4.3 幸運碼發放&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;發放步驟&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;隨機獲取至多 15 個可用號段&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遍歷號段&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;搶佔號段的分佈式鎖&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若號段的分佈式鎖搶佔成功，則隨機獲取號段中可用的子碼，再根據號段和子碼生成幸運碼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若號段的分佈式鎖搶佔失敗，則遍歷下一個號段，並重覆上述步驟&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-18b4f57ed57a5e892f4084f7f66b15e177f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;五、總結&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;（1）雙重隨機保障&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一級隨機：號段選擇隨機（0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;二級隨機：子碼選擇隨機（0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過號段隨機和子碼隨機方式確保生成的幸運碼完全隨機&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（2）數據唯一性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過號段唯一和號段內的子碼唯一確保生成的幸運碼全局唯一&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（3）彈性擴展能力&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;擴容耗時僅需秒級別&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;存儲空間相比預生成方案節省 80%&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（4）高性能發放&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;通過多重緩存及高效號段搶佔策略大幅提升幸運碼生成效率&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實測 QPS&amp;gt;300，平均響應時間&amp;lt;15ms&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本設計方案通過創新的號段+子碼管理機制，在保證號碼隨機性和唯一性的同時，實現了高併發場景下的穩定服務能力，為類似號碼生成系統的設計提供了可複用的架構範式。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18683260</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18683260</guid>
      <pubDate>Sun, 11 May 2025 03:44:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>​前 OpenAI 研究員揭露：簽約 Meta 並未獲 1 億美元獎金</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期，一位前 OpenAI 研究員的言論引發了廣泛關注。他表示，儘管 Meta 公司在挖角 OpenAI 的科研人才時聲稱提供高達 1 億美元的簽約獎金，但他和他的同事並未收到這筆獎金。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="386" src="https://oscimg.oschina.net/oscnet/up-48f34a74f8c7850e98ec9150ffd25671085.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這位研究員名叫盧卡斯・貝耶爾（Lucas Beyer），他和同事亞歷山大・科列斯尼科夫 (Alexander Kolesnikov)、翟曉華 (Xiaohua Zhai) 在去年 11 月加入 OpenAI，並共同設立了該公司在蘇黎世的辦公室。根據《商業內幕》的報道，這三位前 Google DeepMind 的研究科學家近期選擇離開 OpenAI，加入了 Meta。貝耶爾在社交媒體上公開表示，他和同事並沒有獲得 Meta 所宣傳的 1 億美元簽約獎金，這一消息引發了網友們的熱議。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在貝耶爾的社交媒體帖子下，許多人對此表示同情，認為他在職業生涯中作出了重要的選擇，但同時也有網友認為他選擇了離開 OpenAI 並獲得了相應的經濟補償，是他應得的結果。與此同時，Meta 也在加速發展，並向數據標註公司 Scale AI 投資了 150 億美元。預計該公司的創始人兼首席執行官 Alexandr Wang 將辭職加入 Meta，與貝耶爾等人一起合作研發&lt;span&gt;超級&lt;/span&gt;智能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對此，OpenAI 的現任研究人員可能會感到一絲寬慰，因為儘管 Meta 多次試圖挖走他們，但目前尚未有員工接受這份工作。OpenAI 首席執行官 Sam Altman 在一次節目中提到，Meta 正在積極招聘，希望從其他 AI 公司中挖走優秀人才，但他認為這種方式並不會創造出良好的企業文化。他同時也表達了對 Meta 在創新能力上的一些保留態度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;至今，Meta 尚未對此事作出任何正式回應，而貝耶爾的聲明則給人們帶來了更多的思考。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358715</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358715</guid>
      <pubDate>Sun, 11 May 2025 03:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>LiblibAI 正式推出 Lovart 國內版本「星流 Agent」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 3 日，LiblibAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMRJOdgJZaYL2Ocn8fnc5HQ"&gt;推出&lt;/a&gt;Lovart 國內版本「星流 Agent」，定位為一款面向中文創作者的智能設計拍檔。產品延續 Lovart 海外版本的核心能力，支持自然語言生成整套設計物料，包含主圖、海報、社媒封面、視頻動畫及 3D 模型等。系統已接入十餘個主流大模型，支持圖像、視頻、聲音、3D 的一站式生成與導出。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b48e5a2b164ddb85b9eab30d0fb019dfa69.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，星流 Agent 的核心能力包括全流程自動化設計，用户輸入簡單需求後，Agent 能自動拆解任務、確定風格並生成包括主圖、延展圖、社交媒體封面在內的全套視覺物料。它還引入了「無邊畫布」和智能協作編輯功能，支持在畫布內進行多輪對話式改圖、修圖、換圖和調整構圖。&lt;/p&gt; 
&lt;p&gt;此外，星流 Agent 背後接入了 F.1、Kling、Qwen 等十多個頂尖模型，能自動調用最合適的模型組合，一站式生成圖像、視頻、聲音、3D 等多種模態內容，並支持多種格式導出。&lt;/p&gt; 
&lt;p&gt;目前星流 Agent 已在 PC 端及移動端同步上線。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.xingliu.art%2F%C2%A0"&gt;https://www.xingliu.art/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358708</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358708</guid>
      <pubDate>Sun, 11 May 2025 02:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 代碼編輯器 Cursor 發佈 1.2：新增 Agent Planning、Memories 正式 GA</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 代碼編輯器 Cursor 發佈了 1.2 版本，帶來了多項功能增強。&lt;/p&gt; 
&lt;p&gt;新版本引入了 Agent Planning 功能，通過結構化的待辦事項列表（To-do lists）幫助 Agent 更好地規劃和執行長時程任務。用户現在可以為 Agent 排隊發送後續指令，無需等待當前任務完成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/103205_n4EJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，"Memories"功能正式 GA，改進了記憶生成質量和 UI。代碼庫搜索功能通過新的嵌入模型和優化的提示詞變得更加準確，同時新增了對 PR、issue、commit 和分支的語義搜索和上下文提取能力。Tab 代碼補全速度提升了約 100 毫秒，Agent 也具備瞭解決合併衝突的能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/103244_iVp5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，Cursor 的 CEO 在官方論壇發文，澄清了 6 月 16 日對 Pro 套餐的調整。新方案從請求次數限制改為算力限制，Pro 用户每月可獲得至少等值 20 美元 API 價格的模型推理額度，並取消了 Agent 的工具調用次數限制。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/103432_ObdB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/355977" target="news"&gt;Cursor 推出月費 200 美元的 Ultra 計劃，Pro 計劃將更新為「不限量但有速率限制」的模式&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;官方文檔中還提到了新的 Pro+（60 美元/月，3 倍額度）和 Ultra（200 美元/月，20 倍額度）套餐。儘管官方做出了澄清，但部分用户仍在論壇表示新定價模型透明度不足。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關來源&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fcn%2Fchangelog%2F1-2" target="_blank"&gt;https://cursor.com/cn/changelog/1-2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.cursor.com%2Ft%2Fclarifying-june-16-pro-changes%2F111740" target="_blank"&gt;https://forum.cursor.com/t/clarifying-june-16-pro-changes/111740&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358702/cursor-1-2</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358702/cursor-1-2</guid>
      <pubDate>Sun, 11 May 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>崑崙萬維開源第二代獎勵模型 Skywork-Reward-V2 系列</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;崑崙萬維&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fcjv5V_PSZSYObiD9b8VwHA" target="_blank"&gt;宣佈&lt;/a&gt;繼續開源第二代獎勵模型（Reward Model）Skywork-Reward-V2 系列，共包含 8 個基於不同基座模型和不同大小的獎勵模型，參數規模從 6 億到 80 億不等，其在七大主流獎勵模型評測榜單中全面奪魁。在 2024 年 9 月，崑崙萬維曾首次開源了 Skywork-Reward 系列模型及相關數據集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，在打造這一新一代獎勵模型的過程中，崑崙萬維方面構建了一個包含總共 4000 萬對偏好對比的混合數據集 Skywork-SynPref-40M。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為實現大規模、高效的數據篩選與過濾，特別設計了人機協同的兩階段流程，將人工標註的高質量與模型的規模化處理能力相結合。在這一流程中，人類提供經過嚴格驗證的高質量標註，大型語言模型（LLMs）則根據人工指導進行自動整理和擴充。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基於上述優質的混合偏好數據開發了 Skywork-Reward-V2 系列，其展現了廣泛的適用性，在多個能力維度上表現出色，包括對人類偏好的通用對齊、客觀正確性、安全性、風格偏差的抵抗能力，以及 best-of-N 擴展能力。經實驗驗證，該系列模型在七個主流獎勵模型評測基準上均獲得最佳表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="166" src="https://oscimg.oschina.net/oscnet/up-aba612d774aa51bd830ebc7d8a86ace93bd.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;相比上一代 Skywork-Reward，崑崙萬維全新發布的 Skywork-Reward-V2 系列提供了基於 Qwen3 和 LLaMA3 系列模型訓練的 8 個獎勵模型，參數規模覆蓋從 6 億至 80 億。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-f62f4cf74e27a339b3b803de36d10cac23e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;即便基於最小模型 Skywork-Reward-V2-Qwen3-0.6B，其整體性能已幾乎達到上一代最強模型 Skywork-Reward-Gemma-2-27B-v0.2 的平均水平。更進一步，Skywork-Reward-V2-Qwen3-1.7B 在平均性能上已超越當前開源獎勵模型的 SOTA——INF-ORM-Llama3.1-70B。而最大規模的 Skywork-Reward-V2-Llama-3.1-8B。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="261" src="https://oscimg.oschina.net/oscnet/up-3f53bbb3373c196b2c3a4cab3dd05e6faf8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，Skywork-Reward-V2 在多項高級能力評估中均取得領先成績：包括 Best-of-N(BoN) 任務、偏見抵抗能力測試（RM-Bench）、複雜指令理解及真實性判斷（RewardBench v2），展現了出色的泛化能力與實用性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="116" src="https://oscimg.oschina.net/oscnet/up-2a48408860f058ccd51f588fdb4c87c35ae.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="323" src="https://oscimg.oschina.net/oscnet/up-85c3640ee15c11793833144e683ec2270db.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Skywork-Reward-V2 系列模型專注於對偏好數據規模擴展的研究，崑崙萬維方面表示，其團隊也將研究輻射面陸續轉向其他尚未被充分探索的領域，例如替代訓練技術與建模目標。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fcjv5V_PSZSYObiD9b8VwHA" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358700</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358700</guid>
      <pubDate>Sun, 11 May 2025 02:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2025 全球數字經濟大會全球開源創新發展論壇邀您共話</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img height="6538" src="https://static.oschina.net/uploads/space/2025/0704/093748_oSix_2720166.png" width="1200" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358693</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358693</guid>
      <pubDate>Sun, 11 May 2025 01:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全球 AI 人才榜單首次曝光，華人撐起半邊天</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 3 日，2025 全球數字經濟大會上，一份重磅榜單面向全球首次揭曉。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;該榜單基於近十年近 10 萬篇文獻深度分析，列出了全球人工智能領域的 Top100 人才&lt;/strong&gt;。其中，華人依舊拿下了主力席位。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsDvBk1WCxUrJqMOu2Q9p6g" target="_blank"&gt;鳳凰網科技從中提煉了出了一份較為矚目的人員名單&lt;/a&gt;，這些人現多數就職於國內外企業，仍在人工智能前沿探索領域活躍，包括：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何愷明&lt;/strong&gt;，曾任職於 AI 殿堂美國麻省理工學院（MIT），作為 ResNet 之父，是深度學習革命的關鍵推手，其提出的殘差學習（Residual Learning）概念，一舉攻破了困擾神經網絡多年的「梯度消失」難題，讓深達千層的網絡訓練成為可能。其論文引用數以駭人的數十萬次傲視羣雄（公開數據約 40 萬 +），被譽為「CV 界的諾獎級工作」。6 月 26 日，何愷明剛剛官宣入職 GoogleDeepMind，擔任傑出科學家，同時還保留了 MIT 終身副教授身份。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194046_NzCP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;張祥雨&lt;/strong&gt;，曾是曠視研究院的頂樑柱，現已入職階躍星辰任首席科學家； 2016 年，以 ResNet（作為核心貢獻者之一）問鼎 CVPR 最佳論文，震動世界！隨後在 ImageNet、COCO 等視覺「奧林匹克」賽場多次屠榜。其與團隊開創的 ResNet、ShuffleNet 系列影響頗深，Google Scholar 引用逾 40,000 次，是無數手機、攝像頭、自動駕駛系統的「核心引擎」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194104_my7v_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;任少卿&lt;/strong&gt;，蔚來汽車自動駕駛的靈魂人物，計算機視覺與自動駕駛融合領域的頂尖專家，曾發表多篇極具影響力的 CV 頂會論文。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194115_XBIO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/9ccdcd47-cf38-495f-a15c-11c7758e41da.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;田奇&lt;/strong&gt;，華為在人工智能領域的重要人物，也是華為計算產品線（昇騰 AI 處理器等）和 MindSpore 框架背後的核心操盤手。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194127_1K5b_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/06d18e54-babe-4198-a0f2-f0ed8e8fc7d2.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;王雲鶴&lt;/strong&gt;，華為諾亞方舟實驗室的研究員。專注於 AI 基礎模型、神經網絡架構搜索（NAS）、模型輕量化等前沿方向，是華為 AI「頂天」（前沿）又「立地」（落地）戰略的重要實踐者。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194139_3XP0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/3e5805f0-1b78-44bb-ba08-0ba2b5e6c899.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;謝凌曦&lt;/strong&gt;，華為天才少年，在計算機視覺，特別是視覺大模型、自監督學習、對抗魯棒性等領域有系列開創性工作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194149_Jxf5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/85b5a95b-03b3-4936-96f3-fecdbf8a954a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;strong&gt;王曉剛&lt;/strong&gt;，商湯科技聯合創始人、核心技術奠基人之一。在商湯，他主導了核心視覺算法框架的構建。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194158_juQG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/b2340c80-9b01-4125-9c86-035e2353db25.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;石建萍&lt;/strong&gt;，商湯科技自動駕駛研發團隊的領軍女將。帶領團隊在智能駕駛視覺感知、多傳感器融合、高精定位等方面取得突破性進展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194208_Tj3r_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/b0c91622-96b2-4f33-be72-40b2b4802389.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閆俊傑&lt;/strong&gt;，MiniMax 創始人，國內最早一批成立的大模型公司核心人物。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194219_yNU3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/6b21b373-3805-435f-8f02-df120995bb9a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;曹越&lt;/strong&gt;，前微軟傑出工程師，現 Sand.AI 創始人兼 CEO。專注打造下一代 AI 智能體（AI Agent）平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194228_wqU6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/f1b580d1-bd41-490b-9080-e4bdc8effc1e.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;陶大程&lt;/strong&gt;，新加坡南洋理工大學（NTU）協理副校長、澳大利亞桂冠教授，視覺大牛，IEEE / AAAS / ACM 三料 Fellow，曾任京東探索研究院院長（2023 年卸任）。研究橫跨計算機視覺、機器學習、統計學習、可信 AI（魯棒性、可解釋性、公平性）等核心領域。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194240_wWsg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/cb439f78-abc0-4ebb-a823-9121a7ada5a5.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;劉子緯&lt;/strong&gt;，新加坡南洋理工大學（NTU）新鋭實力派教授，學術明星。在視覺-語言理解（VLP）、多模態大模型、信息檢索方向成果斐然。其工作多次發表於 CVPR, ICCV, NeurIPS 等頂會，並常居排行榜前列，是推動多模態預訓練模型發展與應用的重要力量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194307_cOI1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/e10b6eaa-b533-4846-ac3d-1688c5e7ca50.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;賈佳亞&lt;/strong&gt;，香港中文大學計算機科學與工程系教授，思謀科技創始人。著名計算機視覺學者，專注於底層視覺重建、圖像增強、圖像分割、醫學圖像分析等方向。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194322_DDlL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/f17121d8-c2e7-4ff0-9203-e1743fc8674f.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;楊明玄&lt;/strong&gt;，美國加州大學默塞德分校（UC Merced）計算機科學教授,Google DeepMind 研究員。深耕機器學習和數據挖掘領域，特別是在圖神經網絡（GNN）、推薦系統、社交網絡分析等方面有突出建樹。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194332_aIW0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/5c0ee9b8-ae73-4c39-b4ad-9ba80f95187f.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;劉威&lt;/strong&gt;，前騰訊混元大模型技術負責人之一，騰訊傑出科學家，2025 年初離職創業。2024 年領導開源混元文生圖模型、3D 生成模型「Hunyuan3D-1.0」，推動騰訊內部 700 + 業務接入 AI 能力（如微信輸入法、騰訊會議）。發表頂會論文 100 + 篇，總引用 3600 + 次，獲 CVPR 青年研究者獎、SIGIR 最佳論文榮譽獎。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194344_6WyQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/44dd9265-ca1d-4db3-8e44-70ee47565a3a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;顏水成&lt;/strong&gt;，新加坡國立大學終身教授，培養 50 + 名博士，建立亞太最大計算機視覺實驗室，歷任 360 首席科學家、依圖 CTO、Sea 集團 AI Lab 主任；2023 年加入崑崙萬維任 2050 全球研究院院長，2024 年底卸任。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194359_j5g6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/496764e9-1b16-47dd-a8e1-3349844dd95d.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據東壁科技數據創始人、深圳大學特聘教授吳登生介紹，該報告基於東壁全球科技文獻數據平台（dbdata.com），對全球 AI 研究生態進行系統分析，數據集涵蓋近 20 萬名來自 175 個國家和地區、3847 個機構的學者，時間跨度為 2015 至 2024 年。&lt;/p&gt; 
&lt;p&gt;值得一提的是，何愷明、劉子緯、王曉剛、陶大程均師承中國人工智能先驅、商湯科技創始人湯曉鷗，張祥雨曾師從何愷明。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358641</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358641</guid>
      <pubDate>Sat, 10 May 2025 11:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Bytebase 3.8.0 - 顯著優化 schema 同步 / 回滾兼容性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;🔔 重大變更&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;顯著優化多數據庫（MySQL/PostgreSQL/TiDB/SQL Server/Oracle）的 schema 同步/回滾兼容性，支持絕大多數常見數據庫對象。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fchange-database%2Fsynchronize-schema%23supported-objects" target="_blank"&gt;文檔地址&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-21a7f23efb479d2c33408917a613e8bb91b.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下線工單訂閲功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;將 SQL 審核中心更名為變更計劃。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;🎄 改進&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增查詢結果行數限制功能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cad54dad1deaf4e15ad8f12933c09c1609c.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增多域名配置支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4380358be992a487045a8f39061a6ba967e.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;簡化默認值輸入：不再區分表達式和值，統一通過文本輸入框填寫。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在審批流程處展示全部審批人，且可懸停顯示細節。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5c8191a2cf70d8536b5ec930d9fca7b36e2.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;🐞 Bug 修復&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;修復了 ClickHouse 查詢中的 JSON 數據類型顯示問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Terraform SSL 配置中新增 &lt;code&gt;use_ssl&lt;/code&gt; 字段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;📕 安裝及升級&lt;/h1&gt; 
&lt;p&gt;新安裝 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fget-started%2Fself-host" target="_blank"&gt;https://docs.bytebase.com/get-started/self-host&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;升級 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fget-started%2Fupgrade" target="_blank"&gt;https://docs.bytebase.com/get-started/upgrade&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;升級前請備份元數據庫，升級後無法回退版本。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;💡 更多資訊，請關注 Bytebase 公號：Bytebase&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6148470/blog/18683355</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/18683355</guid>
      <pubDate>Sat, 10 May 2025 10:24:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Perplexity 上線月費 200 美元的「Max」訂閲服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Perplexity 公司推出了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perplexity.ai%2Fhub%2Fblog%2Fintroducing-perplexity-max" target="_blank"&gt; Perplexity Max &lt;/a&gt;訂閲服務，月費為 200 美元（約合 1433 元人民幣），可以享受諸多權益。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1abe17d787b691e146a089eccf4834806a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;購買 Perplexity Max 訂閲計劃的用户，可以無限制訪問電子表格和報告生成工具 Labs，並支持提前體驗 Comet 瀏覽器在內的諸多新功能。&lt;/p&gt; 
&lt;p&gt;該公司表示，Perplexity Max 是為以下用户設計的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要無限訪問全面分析工具的專業人士&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要大量研究能力的內容創作者和作家&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進行競爭情報和市場研究的商業策略師&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;從事複雜、多方面項目的學術研究人員&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Max 用户還支持在 Perplexity 服務中，調用 OpenAI 的 o3-pro 和 Claude Opus 4 等先進 AI 模型。隨着 Max 的推出，Perplexity 成為最新一家推出超高端訂閲服務層的 AI 提供商。&lt;/p&gt; 
&lt;p&gt;OpenAI 是首家推出每月 200 美元的 ChatGPT Pro 訂閲服務的公司，但近幾個月來，Google、Anthropic 和 Cursor 也紛紛效仿。&lt;/p&gt; 
&lt;p&gt;Perplexity 目前提供多種訂閲計劃。除了每月 200 美元的 Max 計劃外，還提供每月 20 美元的消費者 Pro 計劃，以及每人每月 40 美元的企業 Pro 計劃。該公司表示，最終也將為企業客户推出超高端的 Max 計劃。&lt;/p&gt; 
&lt;p&gt;Perplexity 在 2024 年主要依靠每月 20 美元的 Pro 計劃訂閲，實現了大約 3400 萬美元的收入，但據 The Information 看到的財務數據，公司仍燒掉了約 6500 萬美元現金。&lt;/p&gt; 
&lt;p&gt;據報道，Perplexity 的現金消耗主要來自對雲服務器的重金投入以及購買 OpenAI 和 Anthropic 的 AI 模型訪問權。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perplexity.ai%2Fhelp-center%2Fen%2Farticles%2F11680686-perplexity-max" target="_blank"&gt;https://www.perplexity.ai/help-center/en/articles/11680686-perplexity-max&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358621/perplexity-max</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358621/perplexity-max</guid>
      <pubDate>Sat, 10 May 2025 09:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>X 平台（原 Twitter）上線 AI 筆記功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;X 平台（原 Twitter）&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FCommunityNotes%2Fstatus%2F1940132205486915917" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;正式啓動 AI Note Writer 的 API 試點計劃，允許全球開發者創建 AI 機器人來撰寫社區內容。未來，這些由 AI 撰寫的筆記如果被一定數量的用户認為有幫助，就可以在平台上公開展示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b9141239b889f5cfe9e01d79314f39bdc80.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;X 表示，該計劃旨在加速社區內容的產出效率，同時通過社區反饋機制，不斷優化 AI 的準確性、公正性與實用性。AI 筆記將遵循與人工內容相同的審核準則，並會在介面中明確標註。&lt;/p&gt; 
&lt;p&gt;首批 AI Note Writer 將在本月內開放上線，且將逐步開放。&lt;/p&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunitynotes.x.com%2Fguide%2Fen%2Fapi%2Foverview" target="_blank"&gt;https://communitynotes.x.com/guide/en/api/overview&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358606/ai-note-writer-api</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358606/ai-note-writer-api</guid>
      <pubDate>Sat, 10 May 2025 08:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>畢馬威：醫療大模型中國發布數量佔全球七成</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;畢馬威中國發布《首屆健康科技 50》報告指出，醫療大模型目前主要分為五類，包括大型語言模型 (LLM)、語言條件多智能體大型、多模態大模型、圖學習大模型、視覺語言大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在全球範圍內，據不完全統計，在已發佈的醫療大模型中，按模型類別來看，大語言模型數量最多，佔比近 65%；按分佈海內外發表數量來看，中國發布數量佔比超 70%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="265" src="https://oscimg.oschina.net/oscnet/up-0f5af0008879ca0ee50480307bd0d62db20.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外報告指出，2024 年，中國醫療科技市場規模突破百億，達到 102.5 億元，同比增長 75.3%。2025-2027 年，中國醫療科技的增幅預計會有所放緩，但行業總市場規模仍呈現穩健增長趨勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2023 年中國醫療機器人市場規模達到約 108 億元，近五年年均複合增長率高達 25.74%。中國智能醫療器械市場增長迅猛，預計 2025 年將達 242.3 億元，2026 年-2027 年總體有望保持較高速增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fassets.kpmg.com%2Fcontent%2Fdam%2Fkpmg%2Fcn%2Fpdf%2Fzh%2F2025%2F07%2Fkpmg-china-healthcare-health-tech-50.pdf" target="_blank"&gt;查看完整報告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358603</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358603</guid>
      <pubDate>Sat, 10 May 2025 08:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>IT 技術人員被解僱，怒改公司所有密碼，獲刑 7 個月</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據報道，在英國西約克郡，一位被解僱 IT 技術人員因心懷怨恨，對僱主公司發動了一場數字攻擊，最終被判處 7 個月零 14 天的監禁。&lt;/p&gt; 
&lt;p&gt;根據警方的公告，2022 年 7 月，Mohammed Umar Taj 在被公司暫停工作後的數小時內，便開始實施惡意的 「數字暴行」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d7c99b29132ed474e2163c68143d842ddfa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他非法侵入公司系統，擅自更改登錄憑證，還破壞了公司的多因素身份驗證系統，致使公司日常運營受到嚴重幹擾，造成至少 20 萬美元的損失。&lt;/p&gt; 
&lt;p&gt;公司稱 Taj 的報復行為不僅給公司帶來了經濟損失，還損害了公司的聲譽，給公司帶來了聲譽損害和業務損失。&lt;/p&gt; 
&lt;p&gt;由於網絡攻擊的連鎖反應，不僅約克郡的員工工作受阻，英國、德國以及巴林的客户也受到了不同程度的影響。&lt;/p&gt; 
&lt;p&gt;上週，31 歲的 Taj 在約克郡的利茲刑事法庭出庭受審，他在之前的聽證會上承認了 「未經授權對計算機進行操作並妨礙計算機訪問」 的罪名，最終被判處 7 個月零 14 天的監禁。&lt;/p&gt; 
&lt;p&gt;警方還在報告中提醒所有企業：「保護好你們的網絡，這不僅能防止數據丟失和代價高昂的網絡攻擊，還能維護與客户和利益相關者的信任關係。」&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以下是該事件的具體介紹：&lt;/p&gt; 
&lt;h3&gt;案件經過&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Taj 在被公司停職後，公司未及時撤銷其賬號權限，他便利用這一漏洞，非法侵入系統，篡改了公司的系統權限，把公司員工以及海外客户都踢出系統之外，導致公司運營陷入癱瘓。&lt;/li&gt; 
 &lt;li&gt;他在實施攻擊後，還曾 「自豪地談論」 自己的攻擊過程，警方在後續調查中找到了他作案的操作記錄和通話內容。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;法院判決&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Taj 最終在利茲皇家法院承認自己未經授權幹擾公司計算機系統的正常運行，於 2025 年 6 月 26 日在利茲刑事法庭被判處七個月零 14 天的監禁。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;事件影響&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;直接經濟損失&lt;/strong&gt; ：該公司遭受了至少 20 萬英鎊的損失，約合人民幣近 200 萬元。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;業務中斷&lt;/strong&gt; ：系統的癱瘓直接導致公司業務無法正常開展，無論是內部的日常運作還是與海外客户的合作都受到了嚴重影響，公司的聲譽也受到了損害。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358595</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358595</guid>
      <pubDate>Sat, 10 May 2025 08:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cloudflare 推出「按次抓取付費」計劃，發起「內容獨立日」倡議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cloudflare 宣佈推出一項名為 「Pay per crawl」 的新功能，並聯合多家內容平台發起 「內容獨立日」 倡議，旨在改變 AI 公司無償抓取網絡內容進行模型訓練的現狀。該計劃允許網站所有者向 AI 爬蟲收取內容訪問費用，為內容創作者提供除完全開放或完全封鎖之外的第三種選擇。Cloudflare 將擔任該計劃的記錄商家（Merchant of Record）。&lt;/p&gt; 
&lt;p&gt;該功能基於 HTTP 狀態碼 402 (Payment Required) 實現。當 AI 爬蟲請求受保護內容時，若未攜帶支付意圖，將收到 402 響應及定價信息。網站所有者可以為自己的域名設定一個統一的、按次請求的單價，並對不同的 AI 爬蟲設置三種策略：允許免費訪問、按價收費或完全阻止。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5f8ad61f543b26ca4f0d391b8c340b1f6a3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;技術上，該系統通過 「Web Bot Auth」 機制，使用 Ed25519 密鑰對和 HTTP 消息簽名來驗證爬蟲身份，防止欺騙。爬蟲可通過在請求頭中加入 crawler-max-price（願意支付的最高價格）或在收到 402 響應後加入 crawler-exact-price（同意支付的確切價格）來表明支付意圖。交易成功後，響應頭中會包含 crawler-charged 字段。&lt;/p&gt; 
&lt;p&gt;過去 30 年，谷歌和內容創作者之間形成了一種默契：谷歌用創作者的內容吸引用户搜索，再把用户送回原網站，讓創作者賺取廣告費或訂閲收入。但隨着 AI 工具興起，用户越來越多地直接從 AI 獲得答案，原創內容的網站流量暴跌，創作者的收益嚴重受損。&lt;/p&gt; 
&lt;p&gt;為此，Cloudflare 聯合眾多內容平台，在 2025 年 7 月 1 日宣佈了 「內容獨立日」，明確要求 AI 公司不能再免費抓取內容，必須為內容創作者支付合理的報酬。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b62a9cf03f1853620715f17a648ca213898.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cloudflare 表示，此舉旨在為內容創作者提供對其數字資產的程序化控制，確保他們能從自己的工作中獲得補償，從而維持一個健康、多樣化的互聯網內容生態。未來，該系統有望演變為一個更復雜的代理（Agent）經濟市場，AI 代理可以根據預算，以編程方式協商併購買所需的數據訪問權限。&lt;/p&gt; 
&lt;p&gt;他們希望通過這樣的行動，讓創作者重新獲得應有的價值和尊重，同時推動 AI 和原創內容之間形成一種新的、公平的生態模式。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;更多詳情：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fcontrol-content-use-for-ai-training%2F"&gt;https://blog.cloudflare.com/control-content-use-for-ai-training/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fzh-cn%2Fcontent-independence-day-no-ai-crawl-without-compensation%2F"&gt;https://blog.cloudflare.com/zh-cn/content-independence-day-no-ai-crawl-without-compensation/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358592/content-independence-day-no-ai-crawl</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358592/content-independence-day-no-ai-crawl</guid>
      <pubDate>Sat, 10 May 2025 07:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊提醒開發者可將微信小程序遷移至 QQ 客户端</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊 QQ 小程序開發者平台發文，提醒 QQ 客户端將全面接入微信小程序，&lt;strong&gt;開發者可以將微信小程序遷移至 QQ 以取代原有的舊版 QQ 小程序&lt;/strong&gt;，開發者當前已上線的舊版 QQ 小程序仍可正常使用和更新，不過官方稱「強烈建議儘早遷移，以便獲得更完整的接口支持，同時享受 QQ + 微信的雙端流量紅利」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e508f98702091d79c43aa333caf718d83a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;遷移前，QQ 小程序引擎實際上對微信小程序的大多數接口進行了兼容，原本只需要在微信小程序原有代碼基礎上做一些簡單判斷（主要是登錄方面）就可以分別提交兩個平台。&lt;/p&gt; 
&lt;p&gt;而在遷移後，QQ 端運行的就是微信小程序，體驗比 QQ 小程序會好一些。開發者需要通過 QQ 提供的插件（qq-wxmini-plugin）區分運行環境、處理登錄邏輯。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;來源：https://m.ithome.com/html/864991.htm&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/346915" target="news"&gt;手機版 QQ 支持微信小程序&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358586</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358586</guid>
      <pubDate>Sat, 10 May 2025 07:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>多模態才是智能應用爆發的關鍵？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;此前，快手發佈 2025 年一季度財報時，一個數字引發關注：成立僅兩年的 AI 業務線「可靈 AI」單季度貢獻營收 1.5 億元，同比增長 320%。而可靈 AI 正是一個多模態應用的典型產品，涉及到語言、視頻、音頻等交互。&lt;/p&gt; 
&lt;p&gt;前不久，在 OSCHINA 和小度教育技術負責人丁小晶的&lt;a href="https://my.oschina.net/u/4489239/blog/18426743" rel="nofollow"&gt;對話&lt;/a&gt;中。丁小晶表示，多模態技術非常重要，甚至可以説，沒有多模態技術效果的快速提升，教育行業不可能如此迅猛發展。比如 AI 作業批改和 AI 講題答疑方向的應用，完全靠純文本大模型是無法滿足需求的，非常依賴對大模型的圖片理解能力。還比如超擬人 AI 老師，語音情感大模型就起來非常關鍵的作用。&lt;/p&gt; 
&lt;p&gt;百度最新發布的發佈文心快碼 Comate AI IDE 產品，其中也提到了多模態能力的增強，比如支持 Figma 設計稿一鍵轉換為高可用代碼，能實現圖層的精準還原。百度工程效能部前端研發經理楊經緯告訴開源中國，無論是從自然語言、圖片還是設計稿生成代碼，最終都是為了能更加接近人類工程的意圖，因為人類去描述自己想要實現的想法的方式與形態是多種多樣的，也就對應了研發過程中的多模態形式。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="210" src="https://oscimg.oschina.net/oscnet/up-db06f16dbd4e854566d762bff8c3dfe1e5f.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;人類從不會只用一種感官認知世界。人工智能也勢必不能僅有一種交互途徑。&lt;/p&gt; 
&lt;p&gt;我們聞到咖啡香氣的瞬間，腦海裏會立刻浮現深褐色液體與白瓷杯的畫面；聽到「貓」這個詞時，腦海中自動補全毛茸茸的觸感和呼嚕聲。這種多模態信息融合，正是人類智能的底層邏輯。而單一模態交換的 AI 模型的信息處理能力有限，例如文本生成模型難以理解圖像語義，無法根據文字生成圖像，視頻生成工具則無法同步解析聲音與畫面邏輯。這種時候，就需要多模態模型或是能力的配合。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;多模態，比文本慢一步&lt;/h2&gt; 
&lt;p&gt;智源研究院院長王仲遠不久前公開&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.cn%2Fzh-cn%2F%25E6%258A%2580%25E6%259C%25AF%2F%25E6%258A%2580%25E6%259C%25AF%25E5%2585%25AC%25E5%258F%25B8%2F%25E8%2581%259A%25E7%2584%25A6%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581-chatgpt%25E6%2597%25B6%25E5%2588%25BB%25E6%259C%25AA%25E5%2588%25B0-2025%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B-%25E5%258F%2598%25E6%2585%25A2-%25E4%25BA%2586%25E5%2590%2597%2Far-AA1GjaHk%3Focid%3DBingNewsSerp" rel="nofollow" target="_blank"&gt;指出&lt;/a&gt;，當前多模態大模型的學習路徑，尤其是多模態理解模型，通常是先將語言模型訓練到很強的程度，再學習其他模態信息。在這個過程中，模型的能力可能會出現下降。&lt;/p&gt; 
&lt;p&gt;比單一模態更難的是，多模態模型還需解決一個核心問題：如何將圖像、文本、音頻等異構數據在語義層面對齊並融合。&lt;/p&gt; 
&lt;p&gt;文本、圖像、聲音等模態的數據結構天然異構——文本是離散符號序列，圖像是連續像素矩陣，音頻是時間序列信號。比如要讓模型理解「貓」的文本描述與貓的圖片、叫聲之間的關聯，需構建跨模態的共享語義空間。&lt;/p&gt; 
&lt;p&gt;早期，有研究嘗試通過數據級拼接，將圖像像素和文本特徵直接拼接，實現跨模態融合，但由於圖像和文本的時空特性差異較大，導致特徵對齊困難，最終效果不佳。直到對比學習和注意力機制的出現，才實現跨模態語義映射。比如 OpenAI 2021 年推出的一種基於對比學習只的多模態預訓練模型 CLIP，它通過大規模的圖像和文本數據進行訓練，使得模型能夠理解圖像內容和相關文本之間的語義關係。CLIP 的核心貢獻在於它打破了傳統的固定類別標籤範式，通過對比學習的方式，將圖像和文本映射到同一個向量空間中，從而實現跨模態的檢索和分類。但是 CLIP 模型的訓練數據規模龐大，據 OpenAI 披露，其使用了約 4 億圖像-文本對進行訓練，訓練成本高達數千 GPU 日，遠超 GPT-3 等純文本模型。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-4ad6b286433edebde043654fd53af191e30.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;&lt;em&gt;CLIP 模型方法概述 &lt;/em&gt;&lt;/span&gt;&lt;span style="color:#8f959e"&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2103.00020" rel="nofollow" target="_blank"&gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多模態融合需處理高維數據，如 4K 視頻的像素量是文本的百萬倍，傳統 Transformer 的二次方計算複雜度成為致命短板。對此，業界也有一些解決方式，比如此前 Mamba 架構通過狀態空間模型 SSM 將計算複雜度降至線性，2025 年擴展動態融合模塊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F2985554863" rel="nofollow" target="_blank"&gt; FusionMamba&lt;/a&gt;，在其中實現多模態特徵高效交互，推理速度提升 3 倍。&lt;/p&gt; 
&lt;p&gt;不僅如此，相較於文本的資料庫和數據集，高質量多模態數據集也更加稀缺，收集難度更大。比如醫療影像、工業質檢的報告中的缺陷描述等，就需專家級別的標註人員。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;落地需求更多&lt;/h2&gt; 
&lt;p&gt;雖然技術上還有諸多難點，但是多模態能力正在逐步提升，並且帶來非常可觀的價值和效果。&lt;/p&gt; 
&lt;p&gt;比如，從圖片或者是 Figma 設計稿直接生成代碼可以幫助許多開發者或是產品經理完成一些開發工作。這項能力此前在一些低代碼或是輔助編程工具中也存在，但往往是通過 Figma DSL 進行設計稿解析，通過節點虛擬化技術實現像素級還原，其不足在於不一定適配當前項目，比如轉了一套 Vue 框架的代碼，就無法在 React 框架項目中使用。&lt;/p&gt; 
&lt;p&gt;楊經緯介紹，此次文心快碼 Comate AI IDE 的發佈以及相關功能更新後，通過大模型能力增強了 Figma to Code 和當前項目的融合度。首先在 IDE 裏進行操作，天然就可以理解用户當前環境和本地優勢，而 IDE 內智能體 Zulu 的接入，會更深入到本地項目中瞭解當前的框架、能力、代碼風格等，再結合 Image to Code 的能力，可以實現較高的還原度，並且適配當前的項目。&lt;/p&gt; 
&lt;p&gt;而根據一些公開信息顯示，可靈 AI 的多模態技術，支持通過圖片、文字、聲音甚至手繪軌跡等輸入生成視頻。在上半年的 2.0 模型的迭代中，可靈 AI 也發佈了 AI 視頻生成的全新交互理念 Multi-modal Visual Language（MVL），讓用户能夠結合圖像參考、視頻片段等多模態信息，將腦海中包含身份、外觀、風格、場景、動作、表情、運鏡在內的多維度複雜創意，直接高效地傳達給 AI。MVL 由 TXT（Pure Text，語義骨架）和 MMW（Multi-modal-document as a Word，多模態描述子）組成，能從視頻生成設定的基礎方向以及精細控制這兩個層面。此外，其技術也結合了類 Sora 的 DiT 結構和 Flow 擴散模型，提升在物理模擬和細節上的表現。&lt;/p&gt; 
&lt;p&gt;基於這些技術特徵。商業化層面，截至今年 6 月，可靈 AI 已為超過 1 萬家企業客户提供 API 服務，覆蓋廣告營銷、影視動畫等領域，企業客户續費率較高。&lt;/p&gt; 
&lt;p&gt;此外，一些傳統行業或場景也在結合多模態能力，實現與 AI 的加速融合。比如迪瑞醫療近期採用的多模態 AI 大模型算法技術為臨牀診斷帶來了重要的技術革新，結合多種檢測結果和患者的多維信息，如尿常規、血常規、生化和化學發光免疫，以及患者的個人背景、臨牀表現、現病史與既往病史等，進行全面分析。&lt;/p&gt; 
&lt;p&gt;這種跨學科的信息整合使得診斷提示更加精準，對於減少漏診、誤診的概率具有顯著的作用，並進一步提升了醫療診療的整體效率。大洋彼岸，斯坦福醫學院的科研團隊研發出了一種名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxMTM0OTQzNQ%3D%3D%26mid%3D2247486194%26idx%3D1%26sn%3D5ac605d67ca7019b3b2e524d65b0f88e%26chksm%3Dc0eed67e545679711993370e69032cc62e9d4fc0c6ff3e283c43854fd93355eae8a07b4fcb02%23rd" rel="nofollow" target="_blank"&gt; MUSK 的 AI 模型&lt;/a&gt;，將視覺數據，如病理圖像和文本數據的病歷和臨牀記錄相結合，為癌症治療帶來了新的可能。MUSK 模型不僅提高了預測癌症患者預後和治療反應的準確性，而且通過分析數千個數據點，更準確地確定了哪些療法對個體患者最有效。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-196e0ee8b1058ba8ee70698e626a846fe72.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="background-color:#f2f3f5"&gt;&lt;em&gt;視覺問答測試，圖片來源於網絡&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在金融領域。江蘇銀行通過本地化部署微調 DeepSeek-VL2 多模態模型、輕量 DeepSeek-R1 推理模型，分別運用於智能合同質檢和自動化估值對賬場景中，通過對海量金融數據的挖掘與分析，重塑金融服務模式，實現金融語義理解準確率與業務效率雙突破。具體而言，DeepSeek-VL2 多模態模型採用了最新的 Transformer 架構，結合多層次的特徵融合機制，有效提升了金融合同、賬單等複雜文本與圖像信息的理解能力。模型在智能合同質檢場景中表現出色，準確率較傳統方法提升了 15% 以上，顯著降低了人工審核成本。同時，輕量化的 DeepSeek-R1 推理模型則在自動化估值與對賬場景中展現出極佳的實時響應能力，推理速度提升了 30%，為金融業務流程的自動化提供了堅實支撐。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;新的基礎設施&lt;/h2&gt; 
&lt;p&gt;應用邊界在不斷拓寬的同時，多模態模型的能力也在成長。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而隨着應用場景的深化，模型架構也在同步進化，從基礎感知邁向複雜推理成為必然趨勢。OpenAI 在 2025 年 4 月發佈了多模態模型 O3 和 O4-mini，實現了「用圖像思考」的突破性能力。這些模型不僅能夠識別圖像內容，還能將圖像信息整合進推理思維鏈，支持多步推理和因果分析，比如夠處理模糊、倒置或複雜的圖像輸入，並給出合理的推理結果。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;其背後的關鍵技術包括分層注意力機制，將圖像分解為局部細節、全局關係和時序邏輯三層結構，從而提升對圖像內容的理解能力；動態工具鏈調用，在推理過程中，模型可以自主選擇 Python 分析、知識圖譜檢索、圖像生成等工具輔助決策，以及安全約束模塊，通過對抗訓練減少模型的幻覺輸出。&lt;/p&gt; 
&lt;p&gt;就在本月，中國科學院自動化研究所等單位的科研人員&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkw.beijing.gov.cn%2Fxwdt%2Fkcyx%2Fxwdtkjqy%2F202506%2Ft20250611_4111006.html" rel="nofollow" target="_blank"&gt;首次證實&lt;/a&gt;，多模態大語言模型在訓練過程中自己學會了「理解」事物，而且這種理解方式和人類非常像。&lt;/p&gt; 
&lt;p&gt;科研人員借鑑人腦認知的原理，設計了一個巧妙的實驗：讓大模型和人類玩「找不同」遊戲。實驗人員會給出三個物品概念（選自 1854 種常見物品），要求選出最不搭的那個。通過分析高達 470 萬次的判斷數據，科研人員繪製出了大模型的「思維導圖」——「概念地圖」。通過實驗證實多模態大模型具備類人「概念理解」能力。研究團隊設計「找不同」遊戲，基於 470 萬次判斷數據繪製大模型「概念地圖」，提煉 66 個理解維度（如物體功能、文化意義），發現其與人腦神經活動高度一致，證明多模態模型比純文本模型更接近人類思維模式。&lt;/p&gt; 
&lt;p&gt;據谷歌雲在 2024 年年底發佈的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.qq.com%2Frain%2Fa%2F20241219A07AW200" rel="nofollow" target="_blank"&gt;《2025 年人工智能商業趨勢報告》&lt;/a&gt;，預測到 2025 年，多模態 AI 將成為企業採用 AI 的主要驅動力。這種技術通過整合圖像、視頻、音頻和文本等多種數據源，使 AI 能夠以前所未有的準確性從更廣泛的上下文源中學習，提供更精確、定製化的輸出，創造自然直觀的體驗。報告預計，全球多模態 AI 市場規模將在 2025 年達到 24 億美元，到 2037 年底達到 989 億美元。&lt;/p&gt; 
&lt;p&gt;2025 進度已經過半，我們也能看到市面上許多多模態技術和產品的進展，而這場變革的終極圖景，或許正是讓 AI 真正成為理解世界、服務人類的「多模態智能夥伴」。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18679654</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18679654</guid>
      <pubDate>Sat, 10 May 2025 07:31:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Windows 11 記事本正式支持 Markdown</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月底，預覽體驗計劃中的 Windows 11 記事本迎來史詩級更新：&lt;a href="https://www.oschina.net/news/353253/windows-notepad-markdown"&gt;支持 Markdown 格式&lt;/a&gt;。現在普通用户也可以使用這個版本了，只需要在應用商店中更新記事本即可使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-af88d0da29ab2cf4246999e5b5025bf874c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前支持：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;粗體&lt;/li&gt; 
 &lt;li&gt;斜體&lt;/li&gt; 
 &lt;li&gt;鏈接&lt;/li&gt; 
 &lt;li&gt;序號&lt;/li&gt; 
 &lt;li&gt;標題（H1～H5）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如下面的屏幕截圖所示，您可以點擊新的「H1」圖標，然後選擇您喜歡的標題：標題、副標題、章節，甚至是小節。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-387e4d297dcd5ac663e49554b55e2f51091.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接下來，我們可以看到項目符號和數字列表按鈕，以及用於加粗或應用斜體的選項，但最吸引我注意的是超鏈接支持。現在，您可以使用 Ctrl + K 鍵盤快捷鍵（該快捷鍵在 Word 中也使用）插入帶有錨文本的鏈接，並在默認瀏覽器中打開。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79d07dc4e8307d47c79e780de309830f227.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，您可以點擊屏幕底部的「格式化視圖」按鈕切換到 Markdown 語法（原始）視圖。&lt;/p&gt; 
&lt;p&gt;與「格式」視圖不同，語法視圖允許您將井號轉換為標題、使用星號強調、用反引號包裹代碼等等。語法視圖類似於在後端使用 Markdown 編輯器，但它不會更改輸出。這取決於您在記事本中使用 Markdown 的方式。&lt;/p&gt; 
&lt;p&gt;在我們的測試中，Windows 最新版本觀察到記事本默認啓用 Markdown，但您有兩個選擇。您可以單擊清理格式按鈕，返回原始記事本體驗，而無需禁用 Markdown 支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-78b526954a85441998f9ce8f508e77c65f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;或者，您可以打開「設置」，向下滾動一點，找到一個名為「格式化」的新選項。關閉「格式化」後，記事本的經典體驗將恢復。您將不再看到格式化欄，Windows 也不會提示您使用它。&lt;/p&gt; 
&lt;p&gt;測試中，我們還注意到微軟在記事本中實現了非常輕量級的 Markdown 功能，它不會讓您的電腦運行速度變慢。&lt;/p&gt; 
&lt;p&gt;有些人可能會認為，給記事本添加太多功能違背了它作為純文本編輯器的初衷。這種觀點很有道理，但只要 Markdown 之類的功能是可選的，我並不介意。如果我需要它們，可以在「設置」中打開；如果不需要，也可以再次關閉。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/353253/windows-notepad-markdown" target="news"&gt;Windows 記事本支持 Markdown&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358574/windows-11-notepad-markdown</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358574/windows-11-notepad-markdown</guid>
      <pubDate>Sat, 10 May 2025 07:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克 xAI 獲 100 億美元融資引關注，亞馬遜/微美全息佈局 AI 大模型應用加速落地</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;7 月 3 日消息，摩根士丹利在海外社交媒體 X 上發文，稱埃隆·馬斯克旗下 xAI 已完成 50 億美元（約合人民幣 358 億）債務融資及另外 50 億美元（約合人民幣 358 億）戰略股權融資。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img height="268" src="https://oscimg.oschina.net/oscnet//9981b9dae3d71c1206ff0c355aa797ad.png" width="300" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;獲新融資，xAI 估值破萬億&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;除債務融資外，xAI 還就約 200 億美元股權融資進行談判，這將使公司估值超過 1200 億美元。該交易獲得超額認購，參與方包括多家全球知名債務投資者，所募資金將用於開發 AI 解決方案，包括建設數據中心及 xAI 旗艦平台 Grok 更新升級。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;據悉，xAI 是馬斯克於 2023 年 7 月創辦，公司員工大多來自 OpenAI、谷歌 DeepMind、微軟、特斯拉等巨頭。硅谷競爭進入白熱化階段，為了讓它能和 ChatGPT 直接競爭，馬斯克將最近兩年的大部分精力用 xA，他們已經正在研發 Grok 4 人工智能模型。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//1be2c9519deef1028c410402dbd8bceb.png" width="719" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;亞馬遜發佈新 AI 大模型&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;與此同時，全球電商、雲計算巨頭亞馬遜（AMZN.US）在官網宣佈，在機器人技術與 AI 領域的兩個重要里程碑：推出新的 AI 基礎大模型 Deep Fleet，部署的機器人數量突破 100 萬大關。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//c99015b5cf3475a9ddb496174bee193d.png" width="657" referrerpolicy="no-referrer"&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;近日，百度（BIDU.US）正式開源文心大模型 4.5 系列模型，涵蓋 47B、3B 激活參數的混合專家（MoE）模型，與 0.3B 參數的稠密型模型等 10 款模型，並實現預訓練權重和推理代碼的完全開源。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;目前，文心大模型 4.5 開源系列已可在飛槳星河社區、HuggingFace 等平台下載部署使用，同時開源模型 API 服務也可在百度智能雲千帆大模型平台使用。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;另據外媒消息人士透露稱，蘋果（AAPL.US）公司正考慮放棄其自研內部模型，並使用 Anthropic 或 OpenAI 的人工智能（AI）技術來驅動新版 Siri。知情人士透露，蘋果已與這兩家公司進行了接觸，討論將它們的大語言模型（LLM）部署在蘋果自有云基礎設施上進行測試。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src="https://oscimg.oschina.net/oscnet//be1a66f75bfecfe9519cc3a7a5153d00.png" width="548" referrerpolicy="no-referrer"&gt;
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;微美全息 AI 產業邁入應用新階段&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;與此同時，面對洶湧的 AI 浪潮，資料顯示，AI 視覺創新廠商微美全息（WIMI.US）憑藉多年來的技術積累，旗下人工智能大模型形成了差異化競爭優勢，推動大模型向普惠性融合創新基礎設施轉化，自主創新生態也不斷完善，加速 AI 技術向生產端滲透。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;此外，微美全息通過開源模式推動基座大模型創新，持續推進多模態大模型研發，支持語音、圖像、視頻等多類型數據融合分析，並計劃推出更高精度的推理模型，促進「技術-數據-場景」循環迭代，降低中小企業使用門檻，為智能製造、智慧城市等場景提供廣泛支持。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;strong&gt;&lt;span&gt;結語&lt;/span&gt;&lt;/strong&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;不可否認，為了能讓 xAI 追趕上 OpenAI，馬斯克可謂是付出了所有。而乘風 AI 熱潮，全球大模型百花齊放，並且國產 DeepSeek 實現彎道超車，打破海外算力封鎖，奠定了國產 AI 公司後來居上的基石，推動大模型技術的研究與創新發展，加速推進人工智能在千行百業的應用與價值創造。隨着這些創新技術的應用推廣，AI 技術或將改變整個行業的格局。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358569</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358569</guid>
      <pubDate>Sat, 10 May 2025 06:56:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
  </channel>
</rss>
