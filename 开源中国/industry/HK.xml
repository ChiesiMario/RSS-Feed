<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 11 Jun 2025 12:42:01 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>macOS Tahoe 是最後一個支持英特爾處理器的 macOS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;macOS Tahoe 支持四款使用英特爾處理器的 macOS，它們的發售年份是 2019 年和 2020 年。蘋果對 Tahoe 的安全更新支持將持續到 2028 年秋天。&lt;/p&gt; 
 &lt;p&gt;從 macOS 27 開始，蘋果新操作系統都將需要 Apple Silicon Mac。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 WWDC 舉辦的分會場上，蘋果明確表示搭載英特爾處理器的 Mac 將不會獲得明年推出的 macOS 27 更新，但仍可能會有添加安全修復的更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f223bac2bf7e49f84aa10b4c34782dd6b33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，蘋果已經停止支持其產品線中某些非 Apple Silicon 型號。例如，macOS Tahoe 不適用於任何 Intel MacBook Air 或 Mac mini。&lt;/p&gt; 
&lt;p&gt;但 Tahoe 仍然支持部分英特爾 Mac，包括 2019 款 16 英寸 MacBook Pro、2020 款英特爾 13 英寸 MacBook Pro、2020 款 iMac 和 2019 款 Mac Pro。&lt;/p&gt; 
&lt;p&gt;根據蘋果的警告，macOS 27 將不再支持所有這些老舊設備，因此 macOS 26 將是最後一個兼容版本。&lt;/p&gt; 
&lt;p&gt;這意味着蘋果對英特爾 Mac 的支持正在逐步取消，公司希望將所有精力和創新都放在 Apple 自主芯片的機器上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354872</guid>
      <pubDate>Sun, 11 May 2025 10:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Seelen UI —— 完全可定製的 Windows 桌面環境</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Seelen UI 是一款旨在增強 Windows 桌面體驗的工具，專注於自定義和提高工作效率。它可以無縫集成到你的系統中，提供一系列功能，讓你可以個性化桌面並優化工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="333" src="https://static.oschina.net/uploads/space/2025/0610/153055_JVfK_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;發揮創意&lt;/strong&gt;：Seelen UI 可讓你根據自己的風格和需求定製桌面。可以調整菜單、小部件、圖標和其他元素，打造個性化且美觀的桌面環境。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;提升工作效率&lt;/strong&gt;：Seelen UI 可幫助你高效地組織桌面。藉助平鋪窗口管理器，窗口可自動排列，支持多任務處理，讓工作更加流暢。&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;盡享音樂&lt;/strong&gt;：Seelen UI 集成媒體模塊，兼容大多數音樂播放器，讓你輕鬆享受音樂。可以隨時暫停、繼續播放和跳過曲目，無需打開其他窗口。&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;更快&lt;/strong&gt;：藉助受 Rofi 啓發的應用啓動器，Seelen UI 提供了一種簡單直觀的方式來快速訪問你的應用程序並執行命令。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;用户友好配置&lt;/strong&gt;：Seelen UI 提供直觀的界面，方便用户自定義。只需點擊幾下，即可調整主題、任務欄佈局、圖標等設置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seelen UI 需要安裝 WebView 運行時。在 Windows 11 系統中，WebView 運行時已預裝在系統內。但在 Windows 10 系統中，WebView 運行時已包含在&lt;code&gt;setup.exe&lt;/code&gt;安裝程序中。此外，Microsoft Edge 瀏覽器也需要安裝才能正常運行。部分用户可能已修改系統並移除 Edge，因此請確保 Edge 和 WebView 運行時均已安裝在你的系統中。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/seelen-ui</link>
      <guid isPermaLink="false">https://www.oschina.net/p/seelen-ui</guid>
      <pubDate>Sun, 11 May 2025 10:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Genspark 發佈 AI 瀏覽器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能體 Genspark 發佈了 AI 瀏覽器產品，官方稱其具有&lt;strong&gt;極速、廣告攔截、全能智能體、自動駕駛模式&lt;/strong&gt;的特性，並提供了 MCP 商店。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170325_JqCj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170647_1Eqh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="540" src="https://static.oschina.net/uploads/space/2025/0611/165940_ftHT_2720166.gif" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.genspark.ai%2Fbrowser" target="_blank"&gt;https://www.genspark.ai/browser&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Genspark 由百度前高管景鯤創立，今年 4 月宣佈&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能體"Genspark Super Agent"，號稱是一款 "快速、準確、可控" 的通用 AI 代理。這一消息迅速在技術社區引發熱議，眾多專業人士將其與 Manus 相提並論，認為這標誌着通用 AI 代理技術的新一輪角逐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/344443" target="news"&gt;AI 智能體 Genspark 上線 9 天，收入近千萬美元&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent" target="news"&gt;百度前高管的 AI 創企發佈通用智能體：Genspark Super Agent&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354844/genspark-ai-browser</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354844/genspark-ai-browser</guid>
      <pubDate>Sun, 11 May 2025 09:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​Ilya Sutskever：AI 將接管人類的一切</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在最近的演講中，OpenAI 前首席科學家 Ilya Sutskever 迴歸母校多倫多大學，分享了他對人工智能（AI）發展的深刻見解。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 與多倫多大學的淵源頗深，20 年前他在這裏獲得了學士學位，而此次則是他從該校獲得的第四個學位。他在演講中回顧了自己在多倫多大學的學習經歷，尤其感慨與 AI 領域先驅 Geoffrey Hinton 的學習機會，使他成為一名科學家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-5833dd185f58bdfa34442db6dd544edf1b7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 強調，接受現實並專注於改善現狀是個人成長的重要心態。他提到，許多人容易陷入對過去的後悔，然而這種心態並不利於前進。他鼓勵大家思考下一步的行動，儘管這一轉變不易，但一旦做到，就會使事情變得更簡單。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;接下來，Sutskever 轉向了 AI 的主題。他指出，我們正處於一個特殊的時代，AI 的迅速發展正在改變我們的學習方式和工作模式。AI 正在以不可預測的方式影響着各行各業，一些工作會更早感受到變化，而另一些則可能稍晚。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他預測，AI 未來將有能力完成所有人類能完成的任務。他認為人類大腦本質上是一種生物計算機，因此 AI 也理應具備完成所有人類任務的潛力。儘管當前的 AI 已能完成許多令人驚歎的任務，但仍存在不足之處，然而隨着技術的進步，這些不足將得到改善。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 還提出了深刻的問題：當 AI 能夠完成所有工作時，人類將如何應對這一變革？他強調，隨着 AI 技術的發展，如何合理利用 AI 將成為人類面臨的重要挑戰，包括在工作、經濟和 AI 研究等領域的應用。他認為，AI 的發展將極大加速人類的進步，但同時也會帶來巨大的挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 指出，AI 的發展速度可能會超出我們的預期，未來幾年內，AI 的能力將不斷提升，其對生活的影響將更加顯著。儘管目前難以完全預見 AI 帶來的變化，但可以確定的是，AI 的進步將對每個人的生活產生深遠的影響。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/344437/ilya-sutskevers-ssi-valued-at-32b" target="_blank"&gt;OpenAI 前首席科學家 Ilya Sutskever 的公司估值達 320 億美元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354842</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354842</guid>
      <pubDate>Sun, 11 May 2025 09:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman 最新文章《温和的奇點》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Sam Altman 今天在他的博客更新了一篇長文：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthe-gentle-singularity" target="_blank"&gt;《The Gentle Singularity》&lt;/a&gt;&lt;/em&gt;，文中指出人類或許正迎來一個新的奇點，而這個奇點並非突如其來，而是温和地悄然降臨。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1006" src="https://static.oschina.net/uploads/space/2025/0611/161536_O8JD_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是譯文。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我們已越過臨界點，起飛開始了。人類距離創造出數字超級智能已近在咫尺，而至少到目前為止，現實遠比想象中來得平實自然。&lt;/p&gt; 
&lt;p&gt;街道上尚無機器人行走，我們大多數人也不整日與 AI 交談。人們依然會因病離世，太空旅行依舊不易，宇宙中仍有諸多未解之謎。&lt;/p&gt; 
&lt;p&gt;然而，我們近期確實構建了在許多方面超越人類智慧的系統，它們能顯著提升使用者的工作效率。最困難的部分已然過去：造就 GPT-4、o3 等系統的科學洞見來之不易，卻將引領我們走得更遠。&lt;/p&gt; 
&lt;p&gt;人工智能將以多種方式惠及世界，但由 AI 驅動的科學加速進步和生產效率提升所帶來的生活質量改善，將是巨大的；未來可以遠比現在美好。科學進步是整體進步的最大驅動力；想到我們本可擁有的更多可能，實在令人振奮。&lt;/p&gt; 
&lt;p&gt;從某種重要意義上説，ChatGPT 已經比歷史上任何個體人類都更強大。數億人每天依賴它處理日益重要的任務；一項微小的新能力便能產生巨大的積極影響；而一個微小的錯位，乘以數億用户，則可能造成深遠的負面影響。&lt;/p&gt; 
&lt;p&gt;2025 年，能執行真正認知工作的智能體已然登場；編寫計算機代碼的方式將徹底改變。2026 年，我們可能迎來能夠發現新見解的系統。2027 年，能在現實世界執行任務的機器人或將問世。&lt;/p&gt; 
&lt;p&gt;將會有更多人能夠創作軟件和藝術作品。但世界對這兩者的需求遠超當前供給，只要專家們善用新工具，他們很可能仍遠勝於新手。總體而言，到 2030 年，單個人的生產力相比 2020 年所能達到的飛躍，將是驚人的鉅變，許多人會找到從中獲益的途徑。&lt;/p&gt; 
&lt;p&gt;在最重要的方面，2030 年代或許不會天翻地覆。人們仍將愛自己的家人，表達創造力，玩遊戲，在湖中暢遊。&lt;/p&gt; 
&lt;p&gt;但在同樣至關重要的其他方面，2030 年代很可能將與此前任何時代都截然不同。我們尚不知智能水平能超越人類多遠，但我們即將揭開謎底。&lt;/p&gt; 
&lt;p&gt;在 2030 年代，智能與能源——即思想的湧現以及將思想變為現實的能力——將變得極度充裕。長久以來，這兩者一直是人類進步的根本限制；在充裕的智能與能源（以及良好的治理）之下，理論上我們能夠擁有其他一切。&lt;/p&gt; 
&lt;p&gt;我們已然生活在令人驚歎的數字智能時代，經歷了初期的震驚後，大多數人已習以為常。我們飛快地從驚歎 AI 能生成優美的段落，轉而期待它能創作優美的小説；從驚歎它能做出救命的醫學診斷，轉而期待它能研發治癒良方；從驚歎它能編寫小程序，轉而期待它能創立全新的公司。奇點的演變便是如此：奇蹟成為日常，繼而成為標配。&lt;/p&gt; 
&lt;p&gt;已有科學家坦言，藉助 AI，他們的效率提升了數倍。先進 AI 令人着迷的原因眾多，但或許最重大的意義在於，我們能利用它來加速 AI 自身的研究。我們或許能發現新的計算基材、更優的算法，甚至更多未知的突破。若能將十年的研究壓縮至一年或一個月內完成，進步的速率顯然將大不相同。&lt;/p&gt; 
&lt;p&gt;從今往後，我們已構建的工具將幫助我們探尋更深遠的科學洞見，並助力我們打造更優的 AI 系統。這當然不等同於 AI 系統完全自主更新自身代碼，但這已然是&lt;strong&gt;遞歸式自我改進&lt;/strong&gt;的雛形。&lt;/p&gt; 
&lt;p&gt;其他自我強化的循環也在發揮作用。巨大的經濟價值創造已啓動一個飛輪，推動着為運行日益強大的 AI 系統所需的複合式基礎設施建設。能夠製造其他機器人的機器人（某種意義上，也包括能建設其他數據中心的數據中心）已不再遙遠。&lt;/p&gt; 
&lt;p&gt;若首批百萬台人形機器人仍需傳統方式製造，但之後它們便能運作整個供應鏈——採礦與冶煉、駕駛卡車、管理工廠等等——以製造更多機器人，而這些機器人又能建設更多芯片工廠、數據中心等，那麼進步的速度顯然將不可同日而語。&lt;/p&gt; 
&lt;p&gt;隨着數據中心生產走向自動化，智能的成本終將趨近於電力的成本。（人們常好奇一次 ChatGPT 查詢的耗能：平均每次查詢耗電約 0.34 瓦時，相當於烤箱工作一秒多，或高效節能燈泡亮幾分鐘。耗水約 0.000085 加侖，約合十五分之一茶匙。）&lt;/p&gt; 
&lt;p&gt;技術進步的速率將持續加快，而人類總能適應幾乎任何變化的特性仍將延續。挑戰必然存在，如某些職業類別整體消失；但另一方面，世界財富將以前所未有的速度激增，使我們能認真考慮以往絕無可能的全新政策構想。我們或許不會立刻採納全新的社會契約，但幾十年後回望，漸進的變革終將累積成鉅變。&lt;/p&gt; 
&lt;p&gt;歷史經驗表明，我們會找到新的工作與新的追求，並快速接納新工具（工業革命後的職業變遷便是一個近例）。期望值會提升，但能力提升的速度同樣迅猛，我們終將獲得更好的事物。我們將為彼此創造越來越奇妙的東西。人類相比 AI 擁有一個長遠而關鍵的優勢：我們天生關注他人及其所思所為，而對機器則不甚在意。&lt;/p&gt; 
&lt;p&gt;千年前的農夫若審視我們許多人的工作，或許會認為那是「虛假的工作」，覺得我們不過是因食物充足、坐擁難以想象的奢華而遊戲人生。我期待我們回望千年後的工作時，也會覺得它們「虛假」，但我毫不懷疑，從事它們的人必將感到無比重要與滿足。&lt;/p&gt; 
&lt;p&gt;新奇蹟誕生的速率將超乎想象。如今甚至難以預料到 2035 年我們將有何發現：或許今年解決高能物理難題，明年便開啓太空殖民；今年取得重大材料科學突破，明年就實現真正的高帶寬腦機接口。許多人會選擇以相似的方式生活，但至少一部分人可能會選擇「接入」（虛擬世界）。&lt;/p&gt; 
&lt;p&gt;展望未來，這聽起來令人難以置信。但置身其中時，感受或許會是震撼但可控的。從相對論視角看，奇點是一點一滴發生的，融合是緩慢進行的。我們正攀登指數級技術進步的漫長弧線；向前看總是陡峭垂直，向後看則顯得平坦，但它始終是一條平滑的曲線。（回想 2020 年，若有人預言 2025 年將接近通用人工智能，聽起來會比我們現在對 2030 年的預測更為瘋狂。）&lt;/p&gt; 
&lt;p&gt;伴隨巨大機遇的，是嚴峻的挑戰。我們亟需從技術和社會層面解決安全問題，而鑑於其經濟影響，確保超級智能的廣泛可及性也至關重要。最可取的前進路徑或許是：&lt;/p&gt; 
&lt;p&gt;解決對齊問題：即我們能強有力地確保 AI 系統學習並踐行人類集體真正的長期願望（社交媒體信息流是 AI 未對齊的實例：其算法深諳如何讓你持續滾動瀏覽，精準把握你的短期偏好，但這卻是通過利用人腦的某種特性，凌駕於你的長期偏好之上）。&lt;/p&gt; 
&lt;p&gt;然後着力使超級智能變得廉價、普及，且不被任何個人、公司或國家過度壟斷。&lt;/p&gt; 
&lt;p&gt;社會具有韌性、創造力且適應迅速。若能凝聚集體的意志與智慧，儘管會犯錯，某些事情會出紕漏，但我們能快速學習調整，從而運用這項技術最大化收益、最小化風險。在由社會共同決定的寬泛邊界內，給予用户充分自由至關重要。世界越早開始探討這些邊界何在以及如何定義集體對齊，結果越好。&lt;/p&gt; 
&lt;p&gt;我們（整個行業，而不僅是 OpenAI）正在為世界構建一個大腦。它將高度個性化、人人皆可輕鬆使用；限制我們的將是好點子的匱乏。長久以來，科技創業圈常嘲笑「點子大王」——那些只有想法卻需要團隊來實現的人。現在看來，他們即將迎來屬於自己的高光時刻。&lt;/p&gt; 
&lt;p&gt;OpenAI 如今承載諸多角色，但首先且最重要的，我們是一家超級智能研究公司。前路漫長，但大部分路徑已然照亮，未知的黑暗區域正迅速退去。能從事這份事業，我們深感慶幸。&lt;/p&gt; 
&lt;p&gt;廉價到無需計量的智能已觸手可及。此言或許瘋狂，但若在 2020 年告訴你們我們將達到今日之境，恐怕比如今我們對 2030 年的預測聽起來更為瘋狂。&lt;/p&gt; 
&lt;p&gt;願我們藉助超級智能，平穩、指數級、波瀾不驚地向上攀升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;轉載自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrbEEJfEoCdV4aeV_LN46mg" target="_blank"&gt;https://mp.weixin.qq.com/s/rbEEJfEoCdV4aeV_LN46mg&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354832/the-gentle-singularity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354832/the-gentle-singularity</guid>
      <pubDate>Sun, 11 May 2025 08:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 據悉與谷歌達成新的雲服務協議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據報道，OpenAI 與谷歌近期簽署了一項新的雲服務合作協議以獲取更多計算資源。該協議將深化雙方在技術領域的合作，涉及高性能計算資源及數據存儲服務。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/160306_SD6R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新協議旨在支持 OpenAI 的模型訓練需求，並優化其產品性能。具體條款尚未公開，但預計將對人工智能行業發展產生重要影響。&lt;/p&gt; 
&lt;p&gt;兩家公司尚未就該交易公開宣佈任何消息，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fretail-consumer%2Fopenai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10%2F" target="_blank"&gt;但一位消息人士向路透社透露&lt;/a&gt;，談判已持續數月，最終於 5 月達成協議。&lt;/p&gt; 
&lt;p&gt;自 2019 年以來，OpenAI 就與微軟達成了協議，賦予其為這家初創公司構建新計算基礎設施的獨家權利。因此這筆交易將使 OpenAI 將其計算資源擴展到微軟之外。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354829</guid>
      <pubDate>Sun, 11 May 2025 08:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源網盤應用 Alist 原開發者稱項目已交由公司運營</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免費開源、支持多存儲的自建網盤程序 (文件列表程序)，可以輕鬆在 VPS 服務器、NAS、普通電腦 Win、Mac、Linux 上部署。它除了能作為一款自建網盤 (將文件保存在設備硬盤上) 外，最大的特色就是支持「掛載各大主流網盤」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在該項目 GitHub 倉庫提交 issue，反饋官網出現 404 問題，並提出」項目是否被賣了」的疑問。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原開發者 Xhofe 今日在訂閲頻道發佈公告，&lt;strong&gt;稱項目已交由公司運營&lt;/strong&gt;，之後會幫助審查開源版本倉庫的代碼，確保 release 分支由 CI 自動構建。此外&amp;nbsp;main 分支已開啓分支保護，後續所有提交均需經過 PR 審核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Sun, 11 May 2025 07:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式發佈了豆包大模型 1.6、豆包·視頻生成模型 Seedance 1.0 pro、豆包·語音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新發布的豆包大模型 1.6 系列由三個模型組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的綜合模型，是國內首個支持 256K 上下文的思考模型，支持深度思考、多模態理解、圖形界面操作等多項能力。支持選擇開啓或關閉深度思考、自適應思考三種方式，其中自適應思考模式可根據提示詞難度自動決定是否開啓思考，提升效果的同時大幅減少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的強化版本；在代碼、數學、邏輯推理等基礎能力上進一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的極速版本，支持深度思考、多模態理解、256K 上下文；延遲極低，TOPT 僅需 10ms；視覺理解能力比肩友商旗艦模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在價格方面，&lt;strong&gt;豆包大模型 1.6 採用統一定價模式，首創按「輸入長度」區間定價&lt;/strong&gt;，在企業使用最多的輸入區間 0-32K 範圍內，豆包大模型 1.6 的價格為輸入 0.8 元/百萬 tokens、輸出 8 元/百萬 tokens，綜合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相當於每生成一條 5 秒的 1080P 視頻只需 3.67 元，行業最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·實時語音模型已全量上線火山方舟，對企業客户開放使用。該模型支持自然語言高級指令控制，具備唱歌表演、聲線模仿、方言演繹等多種能力，語氣、用語、思考方式等擬人感大幅提升，能隨時打斷與主動搭話。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sun, 11 May 2025 06:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供為期兩週的免費 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 與 AI 代碼工具開發商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，為 Cline 用户提供為期兩週的 Grok 3 模型免費訪問權限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需註冊 Cline 賬户，即可在 Cline 的提供商中選擇並免費使用 x-ai/grok-3 模型進行編碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是開源 AI 編程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 雙模式，具有終端執行能力和 Model Context Protocol (MCP) 特性。它能夠分析用户的項目文件結構、源代碼等，幫助用户創建和編輯文件、執行終端命令、使用瀏覽器進行測試等，還可以通過 MCP 協議擴展其功能，添加自定義工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sun, 11 May 2025 06:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再獲數千萬美元融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣佈再次完成數千萬美元的 Pre-A+輪融資，同時正式發佈了全球首個 AI 驅動的一站式 3D 工作台 Tripo Studio，並即將推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;據稱此次融資將重點投入 Tripo 系列大模型研發及 Tripo Studio 產品及生態平台建設，加速構建「AI+3D」全產業鏈條，打造「基礎模型 + 生態插件 + 原生工作台」的端到端產品體系，從而構建覆蓋專業級（PGC 生產者）、達人級（PUGC 創作者）到大眾級（UGC 用户）的創作者畫像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，VAST 成立於 2023 年 3 月，是一家專注於通用 3D 大模型研發的 AI 公司，致力於通過打造大眾級 3D 內容創作工具建立 3D UGC 內容平台，使基於 3D 的空間成為用户體驗升級、內容表達創新和新質生產力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持續迭代 Tripo 大模型，先後推出 Tripo1.0 至 Tripo2.5 等數十億參數規模的 3D 大模型系列，同時發佈 TripoSR、TripoSG、TripoSF 等廣受全球開源社區認可的 3D 基礎模型，並配套開發了系列 3D 軟件生態插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新開源：通用自動骨骼綁定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 開源基礎 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sun, 11 May 2025 03:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度百舸萬卡集羣的訓練穩定性系統設計和實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 訓練穩定性的演進歷程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 競賽中 AlexNet 的橫空出世，開啓了現代 AI 發展的新紀元。彼時我們不會想到，十年後支撐 AI 訓練的 GPU 集羣會從研究室裏的幾台服務器，發展成需要專門供電系統的萬卡級計算矩陣。在這個算力爆發式增長的過程中，訓練系統的穩定性管理正經歷着從「簡單運維」到「精密工程」的深刻變革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 標早期的小模型時代：手動運維的黃金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 訓練，更像是手工作坊式的精雕細琢。大多數訓練任務只需十幾塊 GPU，利用 PyTorch 或 TensorFlow 的數據並行功能就能輕鬆應對。記得那時算法工程師們有個共識：如果訓練遇到問題，重啓往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;當時我們構建的監控系統就像汽車儀表盤，只能顯示最基本的任務狀態。當訓練意外中斷時，工程師們會像偵探一樣翻查日誌 —— 如果發現是 GPU 報錯，就聯繫運維同事。運維人員則帶着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到機房巡檢，像老中醫把脈般通過温度、功耗等指標判斷硬件狀態。這種工作模式雖簡單，但應對數十卡規模的集羣還算遊刃有餘。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型風暴：從量變到質變的衝擊&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登場如同打開潘多拉魔盒，將 AI 訓練帶入新的紀元。當我們開始部署千卡/萬卡集羣時，才發現原有的運維體系就像用小漁網捕鯨魚 —— 完全無法匹配新需求。&lt;/p&gt; 
&lt;p&gt;讓我們通過百度百舸經歷過的一個真實案例來深入理解這個問題：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸幫助一家 AIGC 創業公司迅速將其訓練規模從百卡擴展到千卡級別。然而在訓練數天後的某個週末凌晨，訓練進程意外發生了 hang 死。由於當時缺乏有效的故障感知和容錯機制，直到第二天算法工程師發現任務超時退出時，已經耽誤了數小時寶貴的訓練時間。更糟糕的是，任務日誌中除了簡單的 timeout 報錯外毫無線索，平台監控也顯示所有訓練節點狀態正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢復訓練的算法工程師沒有立即上報問題，而是選擇直接重新提交任務。但不幸的是，新任務運行數小時後再次出現相同的超時退出。這時他們才不得不尋求技術支持，但值班工程師面對這種任務 hang 死的問題也缺乏診斷經驗，只能通過二分法慢慢定位。最終發現是某個節點的靜默故障（SDC）導致了訓練進程假死。等問題得到解決時，距離首次故障已經過去將近 30 小時，這意味着損失了價值巨大的千卡算力資源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集羣訓練穩定性全景圖&lt;/h1&gt; 
&lt;p&gt;站在現在的時間點回望，AI 訓練穩定性已從輔助功能演變為核心基礎設施。就像現代建築中的抗震結構，它雖不直接參與空間構成，卻是萬丈高樓得以屹立的關鍵。當行業向着數萬卡集羣邁進時，這套隱形護甲的質量，將直接決定 AI 進化的速度與邊界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸對訓練過程的生命週期進行了更細緻的拆分，提出了「無效訓練時間」這一關鍵指標，並致力於將其最小化。具體來説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任務無效訓練時間 = 故障中斷次數 × 任務故障恢復時長 + 任務常態寫 Ckpt 總時長&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任務故障恢復時長 = 故障感知召回耗時（自動/人工定位）+ 任務調度耗時 + 任務初始化耗時 + 任務重算時長。&lt;/p&gt; 
&lt;p&gt;通過這個公式可以看出，要降低無效訓練時間，需要「圍繞基礎設施穩定性」、「任務容錯」兩個維度來系統展開，重點解決三個方面的問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基礎設施的交付質量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任務故障容錯的召回率、準確率和時效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化 checkpoint 機制，減少保存時間和恢復時的重算時間。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經過容錯架構的整體變革，百度百舸形成了從 「任務負載 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基礎架構」全鏈路的自動異常感知、診斷、恢復能力，可覆蓋 90%+ 的訓練異常場景，時效性最快可以實現秒級異常感知、分鐘級定位，以及平均 3 分鐘的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基礎設施交付質量保障&lt;/h1&gt; 
&lt;p&gt;基礎設施的交付質量保障是穩定性的基礎。&lt;/p&gt; 
&lt;p&gt;CPU 時代，機器的交付前可能僅會跑一些常規的 CPU 計算、網絡的壓力測試，並不會從業務視角去評估基礎架構，機器交付後硬件異常的故障頻率相對較少。有硬件故障時，通常走工單系統人工換機用户相對是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 時代，AI Infra 的交付則需要考慮 CPU、GPU、RDMA 網絡、存儲，甚至機房的功率、温度等各方面因素，遺漏任何一個環節都會成為後續穩定性的隱患。在交付給客户後，機器也可能會由於長時間的高負載運行頻繁出現硬件故障，而 GPU 機器的高昂成本，使客户對節點故障感知、換機的時效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸對 GPU 機器交付前及交付後的穩定性質量進行了系統性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸會對機器進行 200 多項指標檢測，然後進行 48 小時烤機，以及 NCCL-Test 的機內、機間的大環、同號卡通信性能基準測試，端到端的大模型訓練、推理性能基準測試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付後，需要能夠實時的感知節點故障及定期巡檢，並具備分級處理的自愈能力，例如 Error 級別的故障實現自動排水、重啓，Fault 級別故障實現自動換機。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任務容錯的準召率保障&lt;/h1&gt; 
&lt;p&gt;任務層面穩定性最核心的就是做好容錯，能夠讓業務在無論遇到何種故障時都能快速恢復。&lt;/p&gt; 
&lt;p&gt;那麼，首要的工作就是我們能夠準確的識別出異常，然後對故障進行診斷定位，最後能夠自動化的從異常中恢復。&lt;/p&gt; 
&lt;p&gt;因此，任務容錯需要能夠從端側（即每個訓練 worker）探測到進程與環境的各類異常，同時有個中心服務（Master）從任務全局的視角去診斷、定位異常，最終做出相應的決策來使任務能夠快速從異常中恢復。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任務容錯最重要的就是提升故障的召回率與準確率，即如何能夠儘可能的準確識別、定位所有故障。我們將故障分類兩類：顯式故障和隱式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;顯式的故障通常比較容易召回，我們將實踐積累的各種進程異常狀態及各類報錯 pattern 形成專家知識庫，再結合硬件感知服務（HAS Agent）的硬件全鏈路 10 秒級監控能力，可以實現顯式故障的召回率達到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隱式的異常則往往很難輕易的識別，例如訓練進程 hang、慢節點就是典型的隱式故障，需要豐富的經驗積累才能準確的識別出異常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我們就以最典型的隱式故障場景 —— 訓練進程 hang 死為例，來看下如何能夠做好 hang 自動感知、診斷。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 訓練****hang 的自動感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;訓練任務發⽣ hang 之後，絕⼤多數情況都會以 timeout 的⽅式報錯並退出進程，最常⻅的就是在通信過程中如果發⽣ hang，NCCL 的 watchdog 會中斷通信，並有報如下 timeout 報錯，然後再由 pytorch 的 torchrun 進程感知並中斷訓練過程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默認為 10 分鐘 NCCL 通信超時，而 Megatron-LM 為 30 分鐘。在萬卡規模訓練場景中，意味着一萬張卡要至少浪費 30 分鐘才能被發現。這個時效性是不可接受的。而且當 30 分鐘超時後程序會立馬退出，很難有機會進行下一步定位，需要一些時效性更高的感知機制，並且在程序退出前獲取一些有效信息供後續診斷分析。&lt;/p&gt; 
&lt;p&gt;很多公司、實驗室在面對 hang 的問題時，會在採用框架層插樁的方式來 trace 訓練進程，這種方式通常是比較直接且準確的，但是有比較強的侵入性，而且可能還會有一些性能開銷。對於雲廠商來説，需要尋找對用户更透明、更無損的方式來感知、定位 hang 異常。&lt;/p&gt; 
&lt;p&gt;如何感知訓練 hang，以百度百舸的產品設計思路為例，我們可以從以下幾個方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練進程 hang 的最直觀表現是什麼？&lt;/p&gt; &lt;p&gt;人工判斷一個任務是否 hang 了，最直接的方式就是看是否所有 worker 的任務日誌一段時間內都不輸出日誌了，所以 hang 自動感知的第一種方法就是採集所有 worker 的日誌，並判斷所有 worker 日誌中最後一行日誌是否為 x 分鐘前的（x 小於 Pytorch 的通信超時時間，例如 8 分鐘），如果是則基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時進程有什麼樣的表現？&lt;/p&gt; &lt;p&gt;任務 hang 時，可能進程的調用棧都不在發生變化，進程的調用棧可以通過 py-spy/pystack 等工具進行探測，所以我們可以用此類工具對所有訓練任務進行一個定時採樣，當採集 n 個樣本所有進程棧都沒有變化時，可以判定一次 hang，這種方式通常可以將 hang 感知縮小至 3～5 分鐘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時監控指標有哪些變化？&lt;/p&gt; &lt;p&gt;訓練進程中的 CUDA 算子計算、集合通信操作通常都是在毫秒，甚至微秒、納秒內完成的，當任務在正常迭代過程中發生了 hang，我們常遇到的情況是所有 rank 的 RDMA 流量會降到 0，而 GPU 的利用率為 100%、SM 利用率則在很低的水位。如果持續幾分鐘都是這種狀態時，意味着訓練進程已經計算完成，在等着集合通信完成，這種情況下基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信庫中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常單次集合通信操作都是在 ms 級的，如果一次操作在 30 秒鐘都沒有完成，那就可以判定為通信 hang 死了。百度自研的 BCCL 集合通信庫層可以對每一次集合通信操作都進行打點，來實現通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述幾種方法，我們可以分別實現一種探針，來抓取相應的特徵到中心端 master 組件進行下一步診斷和容錯決策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信庫 BCCL 是百度智能雲推出的一款面向大模型訓練場景優化的集合通信庫。&lt;/p&gt; 
 &lt;p&gt;BCCL 基於開源的 NCCL 進行了功能擴展和能力增強，針對大模型訓練場景在可觀測性、故障診斷、穩定性等方面進行優化，進一步提升集合通信庫的可運維能力。相比 NCCL，BCCL 的關鍵特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可觀測性：新增集合通信帶寬實時統計能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障診斷：新增集合通信 hang 時的故障診斷能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;穩定性：增強網絡穩定性和故障容錯能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能優化：提升大模型訓練主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;訓練 hang 的自動診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我們需要進一步的診斷、定位，來確定是否真的發生了 hang，以及 hang 的具體位置。具體的來講，master 收集到各類 agent 的數據後，會做一些綜合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的發生了 hang？&lt;/p&gt; &lt;p&gt;感知階段各種探針只能探測到 hang 的一種特徵，並沒有辦法 100% 的確定是否真的 hang 住了，事實上不侵入用户進程是很難做到 100% 確定 hang 的。因此，為了提高 hang 的判定準確率，我們需要將各種特種綜合起來判斷，探針上報到 master 後，由一個 hang 診斷模塊，按照一個時間窗口（例如 5 分鐘），進行綜合判斷。如果在時間窗口內日誌、監控、進程調用棧、通信庫中有 2 條以上都處於不處於活躍狀態時，我們判斷任務真正發生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具體發生的位置？&lt;/p&gt; &lt;p&gt;確定任務 hang 了之後，我們需要找到 hang 所在的節點來對它進行隔離。因此診斷模塊需要在探針上報的數據中進一步找尋特徵，來確定 hang 發生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 診斷：在感知階段，BCCL 可以在通信庫層面對所有 rank 的通信進行打點。如果有節點一直未完成通信則是發生了 hang。但是此節點可能並非真正發生 hang 的源頭，有可能是在等待其他節點完成通信。診斷模塊可以根據 BCCL 打印的通信組信息，進行交叉判斷，如果某個節點在多個通信組中都未完成通信，那這個節點就是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指標診斷：上文中我們提到，通信階段發生 hang 之後，所有 rank 的 RDMA 流量都會降到 0，而同時絕大部分 rank 的 GPU 利用率持續為 100%，只有某一兩個 rank 的 GPU 利用率為 0，那這個 rank 很有可能是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調用棧診斷：進程調用棧也可以作為一個 hang 源頭診斷的重要參考。當發生 hang 之後，絕大部分的 rank 都要麼處於 barrier 等待狀態，要麼處於通信等待階段。只有個別的 rank 卡在其他函數上，那麼通過對比分析，可以將調用棧與其他 rank 不同的節點初步判定為 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;綜合診斷：上面 3 種特徵為我們提供了 hang 的診斷依據，將 3 者關聯起來分析後，我們基本上可以比較準確的確定一個具體的 hang 的源頭，再結合硬件故障感知的相關信息可以進一步明確根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基於 eBPF 的隱式故障感知與診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在複雜的大規模分佈式訓練場景中，傳統用户態監控往往難以捕獲系統內核層面的異常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基於 eBPF（Extended Berkeley Packet Filter）技術的隱式故障感知體系，能夠在不侵入用户代碼的前提下，對訓練進程的系統調用、網絡通信、CPU 調度等內核態行為以及訓練框架關鍵函數運行時間建立立體觀測能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探針部署原理通過在內核關鍵路徑注入輕量級探針，實現低開銷的系統級行為捕獲。針對訓練場景特點，主要聚焦 4 類事件跟蹤：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練關鍵函數跟蹤：微秒級跟蹤訓練過程中，前向計算、反向計算、集合通信操作等關鍵函數執行耗時，記錄函數間調用關係。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調度阻塞跟蹤：掛鈎 sched_switch 事件，檢測進程在 TASK_UNINTERRUPTIBLE 狀態持續時間，當單次持續超過閾值（如 5 秒）時捕獲調用棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 運行時 API 監控：通過 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等關鍵庫注入探針，記錄 CUDA API 調用耗時分佈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 級通信監控：在 ibv_post_send/ibv_poll_cq 等核心通信接口設置觀測點，統計通信時延分佈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;結合上面 4 類事件，完成以下 2 類數據分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單體異常探測基線與實時數據對比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;羣體一致性檢測。採用卡間對比算法，當某一 rank 的以下指標偏離集羣中位數超過閾值時判定異常，包括系統調用頻率、進程就緒隊列等待時長、NVLink/RDMA 帶寬利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上所述方法，百度百舸針對以下 2 類典型的隱式故障進行診斷：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練 hang 根因定位。通過關聯 eBPF 捕獲的多維度數據進行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;當檢測到某 rank 的 GPU &amp;nbsp;Kernel 執行出現分鐘級空跑（SM 利用率 &amp;gt; 70% 但無有效計算輸出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同時伴隨該節點 RDMA QP 狀態停滯（ibv_poll_cq 無新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內核調度器顯示進程處於 D 狀態超過閾值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖動溯源。基於 eBPF 火焰圖、時序圖等進行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取發生性能下降時段的 CPU on-cpu/off-cpu 堆棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對比正常時段數據，識別出異常的鎖競爭（futex 調用佔比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;結合 NUMA 內存訪問統計，定位跨 NUMA 內存訪問導致的 TLB 顛簸問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此類技術已在百度百舸的萬卡規模訓練集羣中驗證，相比單純依賴應用層監控的方案，將隱式故障的平均檢測時間從分鐘級縮短至秒級，診斷準確率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通過與既有硬件故障感知服務、BCCL 通信庫監測體系聯動，百度百舸形成了覆蓋從硬件到系統內核再到應用層的立體化診斷能力。&lt;/p&gt; 
&lt;h1&gt;05 任務故障恢復的時效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢復的時效性也是容錯能力的一個重要指標，反映的是任務從故障發生到再次重新進入訓練迭代的時間，恢復效率越高則算力浪費越少。影響到任務恢復效率有 2 個重要因素，一是任務平均中斷時間，二是訓練重算時間。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多級重啓策略減少故障中斷時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任務發生異常後，上文中我們提到需要經過故障自動感知、診斷和自愈等 3 個環節，那麼減少中斷時間的核心思想，就是儘可能的縮短這 3 個環節的時間，通過多維度的感知、診斷手段可以將故障發現、定位的時效性降低至分鐘級甚至秒級。自愈則需要能夠根據不同的診斷結果進行分級恢復和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單點顯式故障：重調度異常節點（replace），對節點進行集羣級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;單點隱式故障：重調度異常節點，對節點進行任務級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非單點故障：原地重啓嘗試恢復（restart），無法恢復時重新調度所有節點（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過多級重啓策略，儘可能避免單點故障引發全部節點的重新調度。在萬卡級別的訓練場景中，百度百舸將大部分訓練異常場景恢復時間從過去的 30min 縮短至現在的 30s 內，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;觸發式 checkpoint 減少訓練重算時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多級任務重啓策略外，另一個提高任務故障恢復效率的重要手段就是減少訓練重算時間。在探討具體技術方案之前，我們先來看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;傳統的 checkpoint 保存通常採用固定間隔策略，比如每隔 N 個 step 或每隔 T 小時保存一次，這種方式實現簡單但缺乏靈活性，可能會產生大量冗餘存儲，同時在故障發生時可能會損失較多訓練進度。&lt;/p&gt; 
&lt;p&gt;而觸發式 checkpoint 則是一種更智能的方案，它根據特定條件或異常事件（如故障、顯存不足、顯式指令等）動態觸發模型狀態保存。其核心目標是通過靈活的控制保存時機，減少不必要的存儲開銷和訓練中斷時間，從而降低因頻繁或冗餘保存導致的重算時間浪費。&lt;/p&gt; 
&lt;p&gt;隨着大模型訓練規模的擴大，還有一種更激進的「零重複 checkpoint」技術，即在每個訓練 step 都保存一次 checkpoint。這種方案的優勢在於可以將重算時間降到最低，確保故障發生時能夠從最近的 step 恢復，幾乎不會損失訓練進度。但其顯著的缺點是存儲開銷巨大，即使採用增量式存儲，仍然需要相當大的存儲空間和 I/O 帶寬。此外，頻繁的 checkpoint 操作也可能影響訓練性能。&lt;/p&gt; 
&lt;p&gt;相比之下，觸發式 checkpoint 走的是一條平衡之路。我們來看下它實現的幾個核心要點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容錯：訓練進程集成容錯的故障感知與定位機制，在進程退出前自動觸發保存。這種主動感知機制能夠在故障發生的第一時間保存訓練狀態，最大限度減少進度損失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速轉儲：異步 checkpoint 保存機制會將 checkpoint 暫存到共享內存中，再由外部程序轉儲至磁盤。當某個節點異常時，容錯組件會拉起新節點，並在新節點訓練進程啓動前，利用 RDMA 技術實現 checkpoint 快速從故障節點轉儲至新節點，這大大減少了從遠程存儲拉取 checkpoint 的時間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗餘備份：觸發式 checkpoint 也並非完美無缺，例如在節點發生內核 crash 等嚴重故障時，可能無法觸發自動保存。因此，需要通過定期的冗餘備份機制進行兜底，確保 checkpoint 不會完全丟失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實踐表明，當觸發式 checkpoint 與異步、增量式的 checkpoint 機制結合使用時，可以在保證數據安全性的同時，顯著提高 checkpoint 保存效率，減少訓練重算時間。&lt;/p&gt; 
&lt;p&gt;相比零重複 checkpoint 的重型方案，觸發式 checkpoint 提供了一個更實用的折中方案，在合理的存儲開銷下實現較好的容錯效果。當然，具體選擇哪種方案，還需要根據實際的訓練規模、硬件條件和可用資源來權衡。&lt;/p&gt; 
&lt;p&gt;隨着分佈式訓練規模的持續增長，相信未來會出現更多創新的 checkpoint 方案，比如基於預測的主動保存策略、多級存儲架構的智能調度等，這些都將為提高大規模訓練的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 業務發展對穩定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 訓練的穩定性管理已經演變為智能時代的精密工程。從最初靠人工重啓解決問題的摸索階段，到如今能自動感知異常、快速恢復的智能系統，每一次進步都映照着算力規模的跨越式發展。&lt;/p&gt; 
&lt;p&gt;讓人不禁思考，在未來十萬卡集羣的算力洪流中，或許會出現更精妙的動態平衡方案：既能像鷹隼般敏鋭捕捉故障徵兆，又能如雁羣遷移般智能調度資源，在秒級恢復與 PB 級存儲成本之間找到新的平衡支點。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持廠內千卡和萬卡集羣有效訓練時長已經可達 99.5%，為客户大模型的預訓練保駕護航，比如國內第一個數學大模型——九章算術，國內第一個類 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推薦閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增強語義嵌入的模型算法綜述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持續推進「人工智能＋」行動，百度智能雲+DeepSeek 為何成為國有企業首選？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 雲服務器的軟件系統設計和實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基於 Flink 的配置化實時反作弊系統&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能雲 xDeepSeek，最具性價比的 DeepSeek 一體機合集來了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sun, 11 May 2025 03:02:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 發佈開放權重模型貢獻榜：Qwen 與 DeepSeek 躋身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;發佈&lt;/a&gt;開放權重模型貢獻榜，中國團隊 Qwen 和 DeepSeek 成功入圍前 15 名。該榜單表彰為開源社區提供高質量模型權重的團隊，其模型廣泛應用於學術與產業創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴雲智能集團支持的 Qwen 團隊，以 Qwen3 系列模型在指令跟隨、代碼生成等任務中的優異表現受到社區青睞。Qwen2.5-72B 系列位列開源大語言模型前列，其輕量化模型 QwQ-32B 通過強化學習優化，在數學推理和代碼生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 則以低成本、高性能的 R1 系列模型聞名。R1-0528 在 LiveCodeBench 排行榜中超越多個國際競品，僅次於 OpenAI 頂尖模型。其輕量化版本 DeepSeek-R1-0528-Qwen3-8B 通過知識蒸餾技術，單 GPU 即可運行，在 AIME2025 數學測試中擊敗 Google 的 Gemini2.5Flash，展現了在特定領域的競爭優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中國 AI 團隊在開源生態中的崛起。Hugging Face 負責人表示，兩團隊的貢獻為全球開發者提供了高效資源。NVIDIA 首席執行官黃仁勳也讚揚其性能與成本平衡正在重塑 AI 格局。未來，Qwen 計劃探索多模態技術，DeepSeek 則將推出 R2 模型，持續推動 AI 創新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sun, 11 May 2025 02:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥 Solon Flow 設計器入門</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索視頻：&lt;/p&gt; 
&lt;p&gt;&lt;iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114657104759990&amp;amp;bvid=BV1opT6z5EiJ&amp;amp;cid=30416702034&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354770</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354770</guid>
      <pubDate>Sun, 11 May 2025 02:51:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Android 16 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌發佈了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為今年的第一次大版本升級，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按鍵式導航（三大金剛）的預測性返回手勢&lt;/li&gt; 
 &lt;li&gt;強制通知分組&lt;/li&gt; 
 &lt;li&gt;以進度為中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 設備的桌面模式（開發者選項）&lt;/li&gt; 
 &lt;li&gt;低功耗藍牙聽力輔助設備支持&lt;/li&gt; 
 &lt;li&gt;自定義鍵盤快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截圖優化&lt;/li&gt; 
 &lt;li&gt;以舊換新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性詳細介紹查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sun, 11 May 2025 02:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 推遲開源模型的發佈時間</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席執行官山姆·奧特曼宣佈，原計劃於今年初夏發佈的公開權重的開源模型預計&lt;strong&gt;將推遲至夏末發佈&lt;/strong&gt;，而不是 6 月與公眾見面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究團隊做了一些出乎意料且非常令人驚奇的事情，這非常值得等待，但需要更長的時間。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣佈將發佈自 GPT-2 以來的首個「開源」語言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最強」開源模型，計劃今年初夏發佈&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sun, 11 May 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首個推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣佈推出&lt;/a&gt;其首個推理模型系列 Magistral，採用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高數學和物理等主題的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有兩種版本：Magistral Small 和 Magistral Medium。Magistral Small 擁有 240 億個參數，在 Apache 2.0 協議下開源。Magistral Medium 是一款功能更強大的模型，目前已在 Mistral 的 Le Chat 聊天機器人平台、該公司的 API 以及第三方合作伙伴雲平台上提供預覽。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中寫道：「Magistral 適用於各種企業用例，從結構化計算和程序邏輯到決策樹和基於規則的系統。這些模型針對多步驟邏輯進行了微調，提高了可解釋性，並以用户的語言提供了可追溯的思維過程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立於 2023 年，該公司得到了 General Catalyst 等風險投資機構的支持，迄今已籌集超過 11 億歐元（約合 12.4 億美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;儘管 Mistral 資源雄厚，但在某些領域，例如推理模型開發，Mistral 仍落後於其他領先的人工智能實驗室。從 Mistral 自身的基準測試來看，Magistral 似乎也並非一款特別有競爭力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 測試中，Magistral Medium 的表現不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的編程基準 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或許正因如此，Mistral 在其博客文章中大力宣揚 Magistral 的其他優勢。聲稱 Magistral 在 Le Chat 中提供答案的速度是競爭對手的「10 倍」，並且支持多種語言，包括意大利語、阿拉伯語、俄語和簡體中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的發佈是在 Mistral 推出「vibe coding」客户端 Mistral Code 之後。在此之前的幾周，Mistral&amp;nbsp;推出了幾款專注於編碼的模型，並推出了 Le Chat Enterprise，一項面向企業的聊天機器人服務，提供 AI 代理構建器等工具，並將 Mistral 的模型與 Gmail 和 SharePoint 等第三方服務集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>【運維實操指南】2 分鐘定製雷池 WAF 認證頁：從「標準表單」到「視覺升級」全攻略</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;在，通用設置 &amp;gt; 防護配置，模塊下，找到 [自定義 HTML] 模塊&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="341" src="https://oscimg.oschina.net/oscnet//30cd12a12b9b01facd09506982aa5867.jpg" width="716" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;就像寫一個普通的 html 頁面一樣，你可以同時寫入 style、script 等標籤, 所以用 css 就能修改中心區域的樣式啦。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;span&gt;把文末的示例代碼複製到&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="449" src="https://oscimg.oschina.net/oscnet//4116eaeb2f8f24a9d1bf87150294cc81.jpg" width="725" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;效果圖:&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&lt;img height="346" src="https://oscimg.oschina.net/oscnet//679bc9d16ccf472845db825ecfd23844.jpg" width="746" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log('Im a console.log, which is written in a script tag');
&amp;lt;/script&amp;gt;
&amp;lt;style type="text/css"&amp;gt;
  body {
    background: #395180;
    margin: 0;
  }
  body #slg-box {
    background-color: grey;
    width: 400px;
    height: 100%;
    top: 0;
    left: 0;
    transform: translate(0, 0);
    padding: 100px 20px;
  }
  body #slg-usergroup-username,
  body #slg-usergroup-password {
    background-color: grey;
    color: #fff;
  }
  body #slg-box-title {
    color: #e15ccf;
  }
  body #slg-usergroup-btn {
    color: grey !important;
  }
  body #slg-with-more-title div:nth-child(2) {
    background-color: transparent;
    width: 100%;
    height: 30px;
    line-height: 30px;
    text-align: center;
    border: 1px solid;
  }
  body #slg-with-more-title div:nth-child(1) {
    display: none;
  }
  body #slg-tabs &amp;gt; div {
    fill: green;
  }
  body #slg-usergroup-container input {
    border-style: dashed;
  }
&amp;lt;/style&amp;gt;

&amp;lt;div
  style="
    background-color: grey;
    width: 200px;
    height: 100px;
    text-align: right;
    top: 50%;
    position: relative;
    left: calc(50% + 200px);
    position: relative;
    transform: translate(-50%,-50%);
    border-radius: 10px;
    font-size: 30px;
    line-height: 100px;
    text-align: center;
  "
&amp;gt;
  hello world
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354756</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354756</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 發佈 o3-pro：更強大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;發佈&lt;/a&gt;了 o3-pro 推理模型，基於 o3 所打造，擁有更強的數學、科學、編程等領域的表現。&lt;/p&gt; 
&lt;p&gt;據介紹，o3-Pro 可，自動調用多種工具，包括可以搜索網頁、分析文件、推理視覺輸入、使用 Python、通過記憶功能個性化回覆等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由於調用的工具較多，所以，思考的時間比 o1 Pro、o3 更長。&lt;/strong&gt;o3-pro 與 o3 系列一樣擁有 200K 的上下文窗口和 100K 的輸出，但價格卻比它們暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表現上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在專家評估中，評審人員普遍認為 o3 Pro 在多方面都比 o3 模型更進一步，尤其適合用在科學、教育、編程、商業和寫作這些需要深度輸出的任務中。&lt;/li&gt; 
 &lt;li&gt;在學術評估的基準測試中，o3-pro 的整體表現持續優於 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 還通過四次嘗試獲取正確答案的方式進行實驗發現，o3-pro 能保持較好的性能表現。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用户提供，取代 o1-pro；企業版和教育版用户將在下週獲得使用權限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;價格方面，o3-pro 輸入為 20 美元/百萬 token，輸出 80 美元/百萬 token；而 OpenAI CEO Sam Altman 昨晚宣佈，o3 降價 80%——因此 o3 價格來到了輸出 2 美元/百萬 token、輸入 8 美元/百萬 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sun, 11 May 2025 02:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>KubeCon+CloudNativeCon China 2025 在香港盛大開幕，共繪雲原生未來</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p&gt;2025 年 6 月 10 日，中國香港 —— 今日，由雲原生計算基金會（CNCF）和 Linux 基金會聯合主辦的全球雲原生計算領域頂尖盛會 KubeCon + CloudNativeCon China 2025 於香港隆重啓幕。來自全球的開發者、技術專家、企業決策者及行業領袖共聚一堂，探索雲原生技術未來藍圖，共推雲計算生態繁榮發展。&lt;/p&gt; 
 &lt;p&gt;盛會首日，彙集了來自 Linux 基金會、CNCF、華為、Akamai、阿里雲、Arm、AWS、Intel、LFOSSA、DaoCloud、F5、Fortinet、ICON、KubeWharf、ManageEngine、SUSE、KubeDB、科大訊飛等頭部企業與組織的技術專家、企業代表及開源領袖。為期兩天的議程將呈現約 100 場主題演講、閃電演講及項目展示，聚焦雲原生與 AI 融合、安全合規、多雲架構、數據處理與存儲等多項前沿技術，為現場觀眾帶來深度技術實踐與戰略洞察。&lt;/p&gt; 
 &lt;p&gt;聚焦核心議程，首日的開幕致辭與主題演講環節亮點頻現，重量級嘉賓相繼登台。&lt;/p&gt; 
 &lt;p&gt;Linux 基金會執行董事 Jim Zemlin 為大會致開場詞。Jim Zemlin 鼓勵科技公司使用開源軟件來幫助創新。他指出，長期以來，有很多公司反對開源，試圖保持專有的地位，最終要麼以低估值被收購，要麼只能退出一些業務領域。為什麼開源在所有的技術創新中的作用如此巨大？Jim Zemlin 表示，答案是因為它在經濟上非常有價值，「我們與哈佛商學院進行了一項研究，如果必須購買所有用來創建技術、產品和服務的開源軟件，那需要花費的成本高達 9 萬億美元，這就是開源如此強大的原因。」&lt;/p&gt; 
 &lt;p&gt;&lt;img height="507" src="https://oscimg.oschina.net/oscnet/up-3148dadc1499f9a5e77b67236866f6c5967.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;CNCF 首席技術官 Chris Aniszczyk 為大會做社區開幕致詞。Chris Aniszczyk 高度認可中國在雲原生技術領域的創新與貢獻。中國在科技創新，尤其雲原生領域展現重大貢獻，是 CNCF 最早且最強大的生態系統之一，開源貢獻位居全球第二，孕育出如 Volcano、Dragonfly、KubeEdge、OpenYurt 等多個具有全球影響力的項目，彰顯了在邊緣計算、容器調度、分佈式處理等多方面的卓越能力。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="513" src="https://oscimg.oschina.net/oscnet/up-a458d49baccea2f5a94b050de918d9924e6.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;Odyssey Cloud 聯合創始人 Amit Dsouza 和 Nirmata 社區負責人 Cortney Nickerson 發表《Crossplane Is the Answer! but What Is the Question?》主題演講。二人介紹了 IaC 工具 Crossplane 在平台工程方面的賦能作用，比如通過擴展 Kubernetes API，以聲明式的方式管理基礎設施和應用程序等。此外，Crossplane + ArgoCD + Kyverno 堆棧還可以實現 GitOps 驅動的自動化，確保部署符合組織合規性和安全策略。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-b39291f8c25f9ae68378b06ecbccac514ff.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;華為首席開源聯絡官，CNCF 董事會成員任旭東發表《邁向人工智能集羣雲》主題演講。任旭東指出，人工智能硬件基礎設施正朝着大型處理器集羣的方向發展，需要我們在構建和管理雲的方式上進行重大變革，而藉助 Linux、Volcano 和 Karmada 等項目，我們可以實現向人工智能集羣雲的演進。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="513" src="https://oscimg.oschina.net/oscnet/up-2981a2c77bb968828df1b6e8df65eed5037.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;Second State 創始人 Michael Yuan 發表了《針對 GenAI 工作負載優化的 Linux 堆棧》主題演講。Michael Yuan 介紹了 Flatcar 的基礎知識及其對 Wasm 運行時的支持，討論了 WasmEdge 對可移植 AI 模型和推理應用程序的支持，並演示了一個可在 Flatcar 中跨 GPU 和 CPU 運行的 GenAI 應用程序。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="506" src="https://oscimg.oschina.net/oscnet/up-b3c6a0bdb509152e9f34e215bf552e6a93b.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;華為雲軟件工程師 Xuzheng Chang 和科大訊飛平台架構師 Dong Jiang 發表《利用 Volcano 進行擴展模型訓練：科大訊飛的 Kubernetes 突破》主題演講。據介紹，科大訊飛在大規模模型訓練中，通過利用 Volcano，將 GPU 利用率提升了 40% 以上，並將故障恢復時間縮短了 70%。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="515" src="https://oscimg.oschina.net/oscnet/up-2098f237a664232ed1ddce8a1bd6d078672.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;香港環球航空學會科技主管、主任助理 Aaron Xu 和 DaoCloud 首席執行官兼創始人 Roby Chen 發表《香港人工智能的未來：從本地創新到全球影響力》主題演講。據介紹，HKGAI V1 的發佈標誌着香港人工智能發展翻開了新的篇章。HKGAI 團隊充分發揮本土互聯和全球佈局的優勢，擁抱開源社區，共同應對從優化高性能計算集羣到探索前沿人工智能模型等諸多挑戰。未來，香港將進一步整合內地和國際資源，深化技術創新和應用拓展，為全球人工智能標準和應用貢獻「香港方案」。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="500" src="https://oscimg.oschina.net/oscnet/up-0b36a5534d137948137e29dbcaa96ffceb9.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;此外，大會現場還特別設立了項目展廳，展示全球多個頂級開源項目，呈現開源技術生態的最新進展和創新成果。&lt;/p&gt; 
 &lt;p&gt;首日盛況已燃，精彩遠未落幕！在接下來的議程中，與會者將有機會深入技術細節，參與更多深度對話。大會還將帶來近百場分技術演講及特色活動，聚焦微服務治理、可觀測性、安全、平台工程等熱點議題，更多來自全球頂級企業與創新團隊的洞見與實踐將精彩呈現。敬請期待，共同見證雲原生與 AI 融合新紀元的無限可能！&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;感謝贊助商&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;KubeCon + CloudNativeCon China 2025 的成功舉辦，得益於贊助商們的大力支持。在此感謝以下贊助商：&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;關於&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;雲原生計算基金會&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;雲原生計算能協助組織利用開源軟件棧，在公共雲、私有云和混合雲等各種雲環境中構建和運行可擴展的應用程序。雲原生計算基金會 (CNCF) 託管包括 Kubernetes、Prometheus 和 Envoy 在內的全球技術基礎設施的關鍵組件。&lt;/p&gt; 
 &lt;p&gt;CNCF 彙集了行業頂尖的開發者、終端用户和供應商，並舉辦世界上最大的開源開發者會議。作為非營利性 Linux 基金會的部分，CNCF 得到了超過 800 個成員的支持，其中包括全球最大的雲計算和軟件公司，以及 200 多個創新型初創企業。有關更多信息，請搜索 CNCF 官網。&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;關於&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6425d0"&gt;&lt;strong&gt;Linux 基金會&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;Linux 基金會是全球領先的開源軟件、硬件、標準和數據協作平台。Linux 基金會的項目對全球基礎設施至關重要，涵蓋 Linux、Kubernetes、Node.js、ONAP、PyTorch、RISC-V、SPDX、OpenChain 等。Linux 基金會致力於採納最佳實踐，滿足貢獻者、用户以及解決方案提供者的需求，打造可持續的開放合作模式。有關更多信息，請搜索 Linux 基金會官網。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354700</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354700</guid>
      <pubDate>Sat, 10 May 2025 14:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>iOS 26 新增實時翻譯：基於端側並向第三方開放接口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2e75214ed6a7bf091530afec2180ff3869d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開發者朋友們大家好：&lt;/p&gt; 
&lt;p&gt;這裏是 &lt;strong&gt;「RTE 開發者日報」&lt;/strong&gt; ，每天和大家一起看新聞、聊八卦。&lt;/p&gt; 
&lt;p&gt;我們的社區編輯團隊會整理分享 RTE（Real-Time Engagement） 領域內「有話題的 &lt;strong&gt;技術&lt;/strong&gt; 」、「有亮點的 &lt;strong&gt;產品&lt;/strong&gt; 」、「有思考的 &lt;strong&gt;文章&lt;/strong&gt; 」、「有態度的 &lt;strong&gt;觀點&lt;/strong&gt; 」、「有看點的 &lt;strong&gt;活動&lt;/strong&gt; 」，但內容僅代表編輯的個人觀點，歡迎大家留言、跟帖、討論。&lt;/p&gt; 
&lt;p&gt;本期編輯：@趙怡嶺，@鮑勃&lt;/p&gt; 
&lt;h2&gt;01 有話題的技術&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Direct3D-S2：影視級 3D 生成模型，僅需 8 塊 GPU 即可訓練，效果超越許多閉源商用模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DreamTech 與南大、復旦和牛津聯合推出的 Direct3D-S2 開源 3D 生成模型，在 HuggingFace 熱榜中表現卓越，僅需 8 塊 GPU 即可訓練，效果超越許多閉源商用模型，達到了影視級精細度。其核心創新 —— 空間稀疏注意力機制（SSA）顯著提升了生成效率和細節表現，解決了傳統 3D 建模面臨的計算壓力和複雜度問題。&lt;/p&gt; 
&lt;p&gt;在 Direct3D-S2 中，DreamTech 團隊提出了一項核心創新——空間稀疏注意力機制（Spatial Sparse Attention， SSA）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfaba50ee60f71dfe7e6d2905c689c38efe.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這一機制專為解決當前 Diffusion Transformer（DiT）在處理高分辨率 3D 生成時效率低、精細度差的問題而設計，堪稱 3D 生成領域的效率引擎。&lt;/p&gt; 
&lt;p&gt;相關鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2505.17412" target="_blank"&gt;https://arxiv.org/pdf/2505.17412&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相關鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FDreamTechAI%2FDirect3D-S2" target="_blank"&gt;https://github.com/DreamTechAI/Direct3D-S2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相關鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.neural4d.com%2Fresearch%2Fdirect3d-s2%2F" target="_blank"&gt;https://www.neural4d.com/research/direct3d-s2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相關鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fwushuang98%2FDirect3D-S2-v1.0-demo" target="_blank"&gt;https://huggingface.co/spaces/wushuang98/Direct3D-S2-v1.0-demo&lt;/a&gt; （@新智元、@果比 AI）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、Neuralink 和 Grok 合作，腦機芯片為漸凍症患者賦予「發聲」能力&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;近日，馬斯克在 X 上轉發的一則案例顯示：Neuralink 和 Grok 正合作使漸凍症患者重新「發聲」。&lt;/p&gt; 
&lt;p&gt;通過腦機接口技術，一名漸凍症患者成功實現了用意念輸出文字，並藉助 AI 完成語句補全和聲音克隆，最終以接近本人的聲音「説話」。這一突破性進展源於 Neuralink 的腦機芯片植入技術，以及 Grok 強大的自然語言處理能力。&lt;/p&gt; 
&lt;p&gt;具體來説，患者只需通過思考即可移動光標生成文本，Grok 助手則像「讀心術」一樣自動更正並補全文本，最後通過 AI 克隆出患者原本的聲音，讓交流更加自然。&lt;/p&gt; 
&lt;p&gt;馬斯克轉發的帖子原出處 Mario Nawfal 此前介紹，患者 Bradford Smith 因為漸凍症喪失了行動和説話能力，而 Neuralink 使其能夠通過思考來生成文本，Grok 則可以實現「讀心術」式的自動更正，再通過另一個 AI「克隆」的其真實聲音，從而使他「説話」時能夠擁有聽起來就像本人的聲音。&lt;/p&gt; 
&lt;p&gt;今年 5 月，Neuralink 的腦機接口設備 Link 獲得了美國 FDA 的「突破性設備」認證，專門用於幫助嚴重語言障礙患者恢復溝通能力。&lt;/p&gt; 
&lt;p&gt;新聞鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ithome.com%2F0%2F859%2F328.htm" target="_blank"&gt;https://www.ithome.com/0/859/328.htm&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;X 鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FMarioNawfal%2Fstatus%2F1928406038803558837" target="_blank"&gt;https://x.com/MarioNawfal/status/1928406038803558837&lt;/a&gt; （@IT 之家、@新智訊）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、開源框架 Rowboat：快速構建智能助手，支持 MCP、Agent SDK&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由 Y Combinator 支持的開源多智能體開發框架 Rowboat 亮相，支持 MCP 服務和 OpenAI Agent SDK。框架由 Agent、Playground 和 Co pilot 三大模塊構成，方便用户快速構建、測試和部署智能助手。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Agent，主要負責處理對話的特定部分，並能依據指令使用工具執行任務。其亮點在於可通過自然語言指令進行配置，能以圖的形式在智能體之間進行編排，還可訪問工具和 RAG。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Playground，這是一個交互式環境，方便用户在構建助手時以對話方式進行測試。它具備實時測試和調試功能，可在界面內檢查工具調用的參數和結果，能與單個智能體或整個助手進行對話。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Copilot，由 AI 驅動的輔助工具，可代用户創建和更新智能體與工具。能感知包括演練場在內的所有組件的上下文，可根據對話和反饋優化智能體，能理解用户以自然語言提出的請求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;用户可創建多智能體，如信用卡助手，實現任務協同。Rowboat 還提供 HTTP API 和 Python SDK，適應多樣開發場景。目前，Rowboat 在 Github 已經超過 2000 顆星。&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frowboatlabs%2Frowboat%3Ftab%3Dreadme-ov-file%25EF%25BC%2588%40AIGC" target="_blank"&gt;https://github.com/rowboatlabs/rowboat?tab=readme-ov-file（@AIGC&lt;/a&gt; 開放社區、@OneThingAI Lab）&lt;/p&gt; 
&lt;h2&gt;02 有亮點的產品&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Apple Intelligence 實時翻譯功能：基於端側、橫框多個應用、向第三方開發者開放&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Apple 最新發布的 iOS 26 中，Apple Intelligence 支持實時翻譯功能，這個功能橫跨電話、信息與 Facetime 三個通訊軟件，當你收到外語信息時，系統會自動將其翻譯成你的語言；相關功能已集成到信息、電話等 App 中，能夠實現即時翻譯文本和音頻，從而幫助用户跨越語言障礙。&lt;/p&gt; 
&lt;p&gt;同樣的，你發出的內容也會被實時翻譯成對方的語言，讓跨語言交流變得前所未有的順暢。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a1581d62c50fe6604340d5a10ba25be1442.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;實時翻譯功能完全基於端側，你的對話內容不會由此流通到任何未經允許的地方。&lt;/p&gt; 
&lt;p&gt;由 Apple Intelligence 驅動的實時翻譯功能將通過 API 接口，向所有第三方開發者開放，開發者可以將實時翻譯功能集成到任何通訊軟件中。&lt;/p&gt; 
&lt;p&gt;過去一年，蘋果在海外推出瞭如 Genmoji、圖樂園等 AI 功能，幫助用户更自由、有趣地表達內容，而外界最為關心的 AI Siri 將什麼時候落地，在今年 WWDC 依舊並沒有給出具體的日期。&lt;/p&gt; 
&lt;p&gt;語言適配方面倒是有所進展，Apple 智能將在今年年底前支持這些語言：丹麥語、荷蘭語、挪威語、葡萄牙語、瑞典語、土耳其語、繁體中文和越南語。&lt;/p&gt; 
&lt;p&gt;蘋果宣佈推出 Foundation Models Framework。這是一項全新的 API，允許第三方開發者調用 Apple Intelligence 核心的大型語言模型（LLM），並將其集成到自家應用中。&lt;/p&gt; 
&lt;p&gt;開發者無需構建自己的 AI 模型，也不必依賴雲端服務，就能在自己的 App 中調用一個功能強大、響應快速、且重視隱私保護的智能助手。更重要的是，不怕斷網，離線也能運行。 （@APPSO、@IT 之家）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、Talking Tours：Google 發佈的 AI 導遊，支持實時對話互動&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-32abd937a92b609d665aa4542e702d431b0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;打開 Talking Tours 頁面，你會看到一張互動地圖，涵蓋全球多個文化地標和自然景觀，分為多個主題：文化機構（博物館、圖書館、劇院）、地標建築、古蹟和自然景觀（森林、洞穴、沙漠、園林、海洋）。&lt;/p&gt; 
&lt;p&gt;點擊地圖上的座標，即可進入對應地點的沉浸式街景視圖。AI 導遊會通過語音講解該地點的背景信息，比如某所博物館的建築風格、歷史典故，甚至細節到展廳裏壁紙的設計靈感。&lt;/p&gt; 
&lt;p&gt;切換畫面後，點擊「take a snapshot」按鈕，AI 會基於新畫面重新生成一段講解，換個角度看，同一地點也可能講出不同的故事。還可以點擊右下角的「🙋」圖標，對 AI 導遊發起提問。&lt;/p&gt; 
&lt;p&gt;體驗鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartsandculture.google.com%2Fexperiment%2F8AGlfzgsYmBeIA" target="_blank"&gt;https://artsandculture.google.com/experiment/8AGlfzgsYmBeIA&lt;/a&gt; （@Founder Park）&lt;/p&gt; 
&lt;h2&gt;03 有態度的觀點&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、任正非：AI 也許是人類社會最後一次技術革命&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;《人民日報》6 月 10 日頭版刊文消息，近日，在深圳華為總部，圍繞大眾關心的一些熱點話題，人民日報記者一行與華為 CEO 任正非面對面交流。 交流中，任正非透露，在「面對外部封鎖打壓，遇到很多困難」時，自己堅信「不去想困難，幹就完了，一步一步往前走」。&lt;/p&gt; 
&lt;p&gt;面對「人工智能（AI）的未來前景怎麼看」時，任正非表示，「人工智能也許是人類社會最後一次技術革命」。其解釋稱：&lt;/p&gt; 
&lt;p&gt;人工智能發展要經歷數十年、數百年。不要擔心，中國也有很多優勢。任正非還強調，人工智能在技術上的要害，是要有充足的電力、發達的信息網絡。發展人工智能要有電力保障，中國的發電、電網傳輸都是非常好的，通信網絡是世界最發達的，東數西算的理想是可能實現的。&lt;/p&gt; 
&lt;p&gt;另外，任正非還提到了其他優勢：芯片問題其實沒必要擔心，用疊加和集羣等方法，計算結果上與最先進水平是相當的。軟件方面，將來是千百種開源軟件滿足整個社會需要。(@ APPSO)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、OpenAI 前首席科學家：AI 會完成我們能做的一切&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;日前，OpenAI 前首席科學家 Ilya Sutskever 返回母校多倫多大學，在接受榮譽博士學位時發表了個人演講。&lt;/p&gt; 
&lt;p&gt;Ilya 開篇就分享了個人心態：接受現實，儘量不去後悔過去，努力改善現狀。接着，他表示，大家都處在一個真正不同尋常的時代——因為 AI 的出現。&lt;/p&gt; 
&lt;p&gt;Ilya 坦言，如今的 AI 已經在很大程度上改變了「學生」的含義，並且遠不止於此。Ilya 表示，AI 能做的事情已經遠超想象，而我們眼下的挑戰是「AI 會如何影響我們的工作和職業」，同時也有更深層次的挑戰——未來 AI 的發展將是前所未有、極其劇烈的。&lt;/p&gt; 
&lt;p&gt;他還強調：「任何我能學到的東西，任何你們中的任何一個人能夠學到的東西，AI 都能學會。那麼，為什麼我這麼確信呢？我們怎麼知道 AI 將來能做這些事情呢？原因是，我們每個人的大腦都是一個生物計算機。我們有大腦，就是因為它是一個生物計算機。那麼，既然人類的生物計算機能做這些事情，為什麼數字計算機、也就是數字大腦不能做同樣的事呢？這就是為什麼我認為 AI 最終能做到所有我們能做到的事情的原因。」&lt;/p&gt; 
&lt;p&gt;對於「當 AI 能做我們所有的工作時，會發生什麼？」這一問題，Ilya 認為十分需要重視。他提醒：「你可能不關心 AI，但 AI 會主動來關心你」。&lt;/p&gt; 
&lt;p&gt;因此，Ilya 建議大家，在 AI 時代下，只要你開始使用 AI，去了解當下最先進的 AI 能做些什麼，你就會逐漸建立起一種直覺。「我認為，通過使用 AI 並觀察當今最先進的 AI 能做什麼，你會形成一種直覺。隨着 AI 在一年、兩年、三年內不斷改進，這種直覺會變得更強烈」。慢慢的，我們能對 AI 的發展有一定的概念，自然也不會再對 AI 產生恐懼，並能夠掌控 AI，激發新技術給我們帶來的力量。&lt;/p&gt; 
&lt;p&gt;最後，Ilya 強調：&lt;/p&gt; 
&lt;p&gt;AI 帶來的挑戰是人類歷史上最大的挑戰。但如果我們應對得當，所獲得的回報也將是人類歷史上最大的回報。&lt;/p&gt; 
&lt;p&gt;演講全程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FzuZ2zaotrJs%3Ffeature%3Dshared" target="_blank"&gt;https://youtu.be/zuZ2zaotrJs?feature=shared&lt;/a&gt; （@APPSO、@機器之心）&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fa92df803a9e43d2a75ae183d839112a4a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多 Voice Agent 學習筆記：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGe3xHvHjsvm3cNEMxiLIEQ" target="_blank"&gt;實時多模態如何重塑未來交互？我們邀請 Gemini 解鎖了 39 個實時互動新可能丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSqXLZvq_zwWDcOVKbAb7HQ" target="_blank"&gt;級聯 vs 端到端、全雙工、輪次檢測、方言語種、商業模式…語音 AI 開發者都在關心什麼？丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7QPgzp8kDR_9iHUa4oFeiA" target="_blank"&gt;a16z 最新報告：AI 數字人應用層即將爆發，或將孕育數十億美金市場丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUM1qs2IT1S6kJ4sZf_k3uA" target="_blank"&gt;a16z 合夥人：語音交互將成為 AI 應用公司最強大的突破口之一，巨頭們在 B2C 市場已落後太多丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWI0gE4x-TZG0gdgSV_bVSA" target="_blank"&gt;ElevenLabs 33 億美元估值的秘密：技術驅動+用户導向的「小熊軟糖」團隊丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVsgDF8F1hxy3-e5-ntGbw" target="_blank"&gt;端側 AI 時代，每台家居設備都可以是一個 AI Agent 丨 Voice Agent 學習筆記&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4K5wdUEDxrs1afHZSAIuqg" target="_blank"&gt;世界最炙手可熱的語音 AI 公司，舉辦了一場全球黑客松，冠軍作品你可能已經看過&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJCYzc1Ig-HFFAN3sTQDYbw" target="_blank"&gt;多模態 AI 怎麼玩？這裏有 18 個腦洞&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrN9poD_X6SDxRLMsudg_xg" target="_blank"&gt;AI 重塑宗教體驗，語音 Agent 能否成為突破點？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeFS1mnAbUpAJdiLSSGWpSA" target="_blank"&gt;對話 TalktoApps 創始人：Voice AI 提高了我五倍的生產力，語音輸入是人機交互的未來&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;寫在最後：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們歡迎更多的小夥伴參與 &lt;strong&gt;「RTE 開發者日報」&lt;/strong&gt; 內容的共創，感興趣的朋友請通過開發者社區或公眾號留言聯繫，記得報暗號「共創」。&lt;/p&gt; 
&lt;p&gt;對於任何反饋（包括但不限於內容上、形式上）我們不勝感激、並有小驚喜回饋，例如你希望從日報中看到哪些內容；自己推薦的信源、項目、話題、活動等；或者列舉幾個你喜歡看、平時常看的內容渠道；內容排版或呈現形式上有哪些可以改進的地方等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8e54bdf0d246189e94f7cf3b2e418da213.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;素材來源官方媒體/網絡新聞&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354682</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354682</guid>
      <pubDate>Sat, 10 May 2025 11:42:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
  </channel>
</rss>
