<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 02 Jul 2025 16:46:13 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>DeepEval —— 開源 LLM 評估框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;DeepEval&amp;nbsp;&lt;/strong&gt;是一個簡單易用的開源 LLM 評估框架，用於評估和測試大型語言模型系統。它與 Pytest 類似，但專門用於對 LLM 輸出進行單元測試。DeepEval 結合了最新研究成果，基於 G-Eval、幻覺、答案相關性、RAGAS 等指標來評估 LLM 輸出，它使用 LLM 和其他各種在&lt;strong&gt;本地&lt;/strong&gt;運行的 NLP 模型進行評估。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;無論你的 LLM 應用程序是 RAG &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;pipelines&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;、聊天機器人、AI 代理，還是通過 LangChain 或 LlamaIndex 實現，DeepEval 都能滿足你的需求。藉助它，你可以輕鬆確定最佳模型、提示和架構，以改進你的 RAG 管道和代理工作流，防止 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;prompt drifting&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，甚至可以自信地從 OpenAI 過渡到託管你自己的 Deepseek R1。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&amp;nbsp;&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;以類似於 Pytest 的方式輕鬆地「單元測試」 LLM 輸出。&lt;/li&gt;
&lt;li&gt;即插即用 30 多個 LLM 評估指標，其中大多數都有研究支持。&lt;/li&gt;
&lt;li&gt;支持端到端和組件級評估。&lt;/li&gt;
&lt;li&gt;對 RAG、代理、聊天機器人以及幾乎任何用例的評估。&lt;/li&gt;
&lt;li&gt;使用最先進的進化技術生成合成數據集。&lt;/li&gt;
&lt;li&gt;指標易於定製並涵蓋所有用例。&lt;/li&gt;
&lt;li&gt;紅隊，安全掃描 LLM 應用程序是否存在安全漏洞。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1c1e21"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，DeepEval 還有一個雲平台&lt;a href="https://app.confident-ai.com/" target="_blank"&gt;Confident AI&lt;/a&gt;，允許團隊使用 DeepEval 在雲端進行&lt;strong&gt;評估、迴歸測試、紅隊和監控 LLM 應用程序。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="282" src="https://static.oschina.net/uploads/space/2025/0617/152602_UCxK_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepeval</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepeval</guid>
      <pubDate>Sat, 10 May 2025 10:44:00 GMT</pubDate>
    </item>
    <item>
      <title>設計協作平台 Figma 遞交首次公開募股（IPO）申請</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Figma 昨日正式提交了首次公開募股（IPO）申請，計劃在美國紐約證券交易所（NYSE）上市，股票代碼為「FIG」。&lt;/p&gt; 
&lt;p&gt;Figma 成立於 2016 年，主要在網絡上提供界面設計協作服務，同時也推出了 macOS / Windows 平台桌面客户端。該公司的產品線除了最早推出的設計工具 Figma Design 外，還包括在線協作白板 FigJam、演示文稿協作工具 Figma Slides、繪圖工具 Figma Draw、設計自動化軟件 Dev Mode、網站設計工具 Figma Sites，以及用於構建社交平台的 Figma Buzz 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0417/183511_QrFp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Figma 公司曾計劃在 2022 年以 200 億美元&lt;a href="https://www.oschina.net/news/210475/adobe-to-acquire-figma"&gt;出售給 Adobe&lt;/a&gt;，但由於歐盟和英國監管機構擔心該交易會影響市場競爭，相應計劃最終被叫停，迫使 Adobe 在當年底向 Figma 支付了 10 億美元的解約費用。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bf6c1fe7a671d0abebcca4cc84a6f1c39da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;參考 Figma 提交的 S-1 申請文件，今年第一季度，公司擁有 1300 萬月活躍用户（其中三分之二用户並非專業設計師），公司已獲得了 95% 的《財富》500 強企業和 78% 的《福布斯》全球 2000 強企業的青睞。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;而在營收方面，Figma 在 2024 年實現了 7.49 億美元（現匯率約合 53.65 億元人民幣）營收，同比增長 48%，但全年仍有 7.3 億美元（現匯率約合 52.29 億元人民幣）虧損。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358402</guid>
      <pubDate>Sat, 10 May 2025 08:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊回應微信「Al 搜索」泄露個人隱私：僅整合公開信息，不會碰用户隱私</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，網友在社交平台吐槽被微信新推出的「AI 搜索」功能強行開盒。&lt;/p&gt; 
&lt;p&gt;該網友發現，當微信推文中出現本人姓名時，名字會變成藍色超鏈接，點擊人名即可一鍵瀏覽公眾號 A1 強制生成的「個人簡歷」及所有涉及該姓名的推文。不少網友在嘗試了該功能後表示「確實可以根據名字查到很多個人資料」，引發隱私安全方面的擔憂。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ef93511d7c54a97e53e3f1cfb985f5f4df0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對此，騰訊方面今日回應媒體稱，為了豐富用户搜索體驗，微信搜索此前通過接入 DeepSeek 和混元等大模型推出 AI 搜索。AI 搜索僅整合公眾號及互聯網其他公開信息，不會使用用户隱私信息。根據用户近期的相關反饋，微信搜索將進一步優化 AI 搜索的使用體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358391</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358391</guid>
      <pubDate>Sat, 10 May 2025 08:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TDMQ RabbitMQ Serverless 版限流機制深度解析與實踐指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h2&gt;導語&lt;/h2&gt; 
&lt;p&gt;分佈式集羣限流是保障雲服務高可用性的核心技術手段，其意義不僅在於防止系統過載，更是構建彈性架構、優化資源效率、實現業務可持續性的關鍵策略。未來，隨着邊緣計算和 Serverless 的普及，限流技術將進一步與底層基礎設施深度融合，成為構建下一代高可用架構的核心基石。&lt;/p&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版作為一款極致彈性、高性能且高可靠的消息中間件，通過提供穩定低延遲的消息服務，助力企業實現系統異步解耦並高效應對海量消息堆積。然而，在高併發、大流量的實際業務中，如何科學分配資源、規避系統過載風險，已成為保障服務穩定性的關鍵。為此，騰訊雲 TDMQ RabbitMQ Serverless 版引入了集羣級別的分佈式限流機制，通過動態調控集羣的發送與消費速率，確保集羣在高負載下仍能穩定運行。&lt;/p&gt; 
&lt;p&gt;本文將深度剖析騰訊雲 TDMQ RabbitMQ Serverless 版的限流機制，涵蓋限流策略設計、觸發機制及底層實現邏輯。通過真實場景案例解析與實踐指南，系統講解如何通過客户端優化來降低限流影響，同時幫助客户精準掌握集羣限流相關服務端配置技巧，有效規避因流控策略不當引發的業務中斷風險，全面提升高併發場景下的系統穩定性與可靠性。&lt;/p&gt; 
&lt;h2&gt;概要設計&lt;/h2&gt; 
&lt;h3&gt;分佈式限流的必要性&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;資源瓶頸的不可預測性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在分佈式系統中，單節點流量可能因負載均衡策略（如 Round-Robin）不均導致傾斜。例如，某台服務器因硬件故障觸發重試風暴，流量突增 300%，若無全局視角的限流，可能引發級聯雪崩。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;長尾延遲的放大效應&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當某服務節點響應延遲升高（如磁盤刷寫延遲增大），後續請求堆積導致線程池耗盡，觸發上游重試，形成惡性循環。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;突發流量衝擊&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;秒殺活動、熱點新聞等場景下，流量可能在毫秒級陡增數十倍。例如，某電商平台大促期間，訂單服務 QPS 從 5k 飆升至 80k，若未通過分佈式限流攔截異常流量，核心計算資源將被瞬間打滿，導致服務不可用。&lt;/p&gt; 
&lt;h3&gt;TDMQ RabbitMQ Serverless 版限流規則&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版為超大規模、低時延、高可用性要求的在線業務提供專業級消息服務。客户端通過 RabbitMQ SDK 與 TDMQ RabbitMQ Serverless 版集羣建立長連接，實現高效的消息收發操作，同時動態佔用集羣的計算、存儲及網絡帶寬等關鍵資源。在此背景下，為確保消息服務的高性能與穩定性，在應對高併發、大流量場景時，必須對集羣的負載水位進行精細化管理。 基於集羣的資源配置上限，服務端支持動態調控客户端的每秒消息發送與消費能力（TPS），確保系統在高負載下依然保持穩定運行。&lt;/p&gt; 
&lt;p&gt;為實現資源隔離與靈活適配的雙重目標，系統對發送消息與消費消息的 TPS 配額進行獨立分配，並支持用户按需配置配額比例，從而實現精細化資源管理與業務場景的精準匹配（默認配額比例為 1 : 1 也即 50%）。業務可以根據實際的收發比例進行調整，可調整的收發消息比例範圍在 20%-80%（服務端支持動態調整該區間）之間。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-7e99eeeb65ba2619e29a1109b273abf1cd8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TDMQ RabbitMQ Serverless 版限流行為&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版採用 Fail-Fast 限流機制，即當客户端請求速率觸及預設上限時，服務端會即時返回錯誤響應。在響應時間敏感的在線業務場景中，該機制可使客户端實時感知限流事件並主動介入處理，從而有效避免因資源競爭導致的端到端時延長尾，保障業務連續性與系統穩定性。&lt;/p&gt; 
&lt;p&gt;以 1000TPS 規格的基礎集羣為例（假設收發 TPS 比例為 1:1 也即 50%），客户端視角下的限流行為：&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;説明&lt;/strong&gt; | &lt;strong&gt;發送消息限流&lt;/strong&gt; | &lt;strong&gt;消費消息限流&lt;/strong&gt; | | ------------ | ------------ | ------------ | | 觸發限流情景 | 所有連接該集羣的發送客户端每秒最多可發送 TPS 總和為 500 條，發送速率達到限制後，超限的發送請求會失敗。 | 所有連接該集羣的消費客户端每秒最多可消費 TPS 總和為 500 條，消費速率達到限制後，消息的消費延遲會增加。 | | 觸發限流時 SDK 日誌關鍵詞 | com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:xxx reason:PublishMessage, class-id=60, method-id=40) | 消費超過閾值以後，客户端使用 BasicGet 拉取消息時，會出現：com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 31436823332424324] Action: BasicGet rate limited by cluster rate limiter vhost: xxx. queue: xxx.當客户端使用 BasicConsume 消費消息時，服務端會抑制向客户端 DeliverMessage 的速率，客户端不會感知到明顯的 Channel 斷開的錯誤，整體表現為類似 AMQP 協議消費者 QOS 的行為，會抑制推送到消費者消息的速率，此時消費延遲會增加，可以通過調整限流比例或者增大購買的 TPS 來解決。消費的總 TPS 主要由 BasicGet 和 DeliverMessage 的調用 TPS 次數共享。 | | 觸發限流時 SDK 重試機制 | 客户端 SDK 業務側需要處理連接斷開的行為，需要對發送錯誤被限流的消息重新建立 Channel 連接然後進行發送重試。 | 客户端 SDK 業務消費側會感知到延遲增加。若使用拉取 BasicGet 拉取消息，會感知到 Channel 連接斷開，需要業務上主動重試。 |&lt;/p&gt; 
&lt;h2&gt;詳細設計與實現&lt;/h2&gt; 
&lt;h3&gt;架構設計&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版採用雙模式限流架構，兼顧節點級保護與集羣級協同：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;單機限流（Node-Level Throttling）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用於節點級資源保護，通過限制 CPU、內存、線程等關鍵資源的使用，防止單節點因過載導致服務不可用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分佈式限流（Cluster-Level Throttling）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基於集羣全局視角，通過多節點流量協同管理，保護共享存儲資源（如 Broker）及後端系統穩定性。該模式通過使用分佈式限流系統實現。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cab8876ba86ab2c10b491074cac992a20d0.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;限流實現&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版通過在計算層 （TDMQ RabbitMQ Serverless 版集羣）接入分佈式限流系統實現集羣級讀寫流量控制，其核心機制是：TDMQ RabbitMQ Serverless 版集羣節點在處理 BasicPublish / BasicGet / DeliverMessage 請求前，需通過集成的限流 SDK 向限流 Server 異步上報與申請 Token。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生產端限流&lt;/strong&gt; ：若 BasicPublish 申請失敗，則立即拒絕生產消息請求並返回錯誤。 &lt;strong&gt;消費端限流&lt;/strong&gt;：若 BasicGet 申請失敗，則立即拒絕拉取消息請求並返回錯誤。若 DeliverMessage 申請失敗，則抑制推送到消費者的消息速率，實現消費端不斷連接的流控，此時類似於 RabbitMQ 開源的實現，此時該消費者處於 Flow 狀態。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版集羣內部集成限流 SDK，該 SDK 提供 Token 申請 API，並負責與限流 Server 通信，通過這種集中式 Token 管理實現對核心存儲層 (底座 Broker 集羣) 的保護。&lt;/p&gt; 
&lt;h3&gt;限流實現難點一：如何平衡性能與精度&lt;/h3&gt; 
&lt;p&gt;使用 TDMQ RabbitMQ Serverless 版的各類在線業務通常對時延比較敏感，如果計算層節點處理每次讀寫請求都執行一次 Limiter RPC 調用（SDK -&amp;gt; Server）的話，雖然 Limiter Server 內部處理耗時幾乎可以忽略，但兩次 RPC 的網絡 IO 耗時對消息端到端時延的影響是不能忽視的。&lt;/p&gt; 
&lt;p&gt;實際上從服務端的角度看， TDMQ RabbitMQ Serverless 版執行限流的主要目的是防止核心存儲層過載，而非追求 100% 精準的流量控制，即 SDK 與 Server 之間的強同步並不是必須的。因此，為了在限流性能和限流精度之間取得平衡，Limiter 採用了一種【先消費後結算】的 Token 管理機制，Token 申請過程在限流 SDK 內部閉環，SDK 會週期性（週期大概在 50ms 以內，上報週期越短，限流越敏感）地向限流 Server 異步上報 Token 使用量並同步配額。&lt;/p&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版的限流機制通過以下四大核心特性，在保障系統穩定性的同時實現高性能與低時延的平衡：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;內存級處理，主鏈路零幹擾&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;執行機制&lt;/strong&gt;：限流判斷為純內存操作，不涉及外部 RPC 調用，確保消息處理流程完全不受阻塞。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能優勢&lt;/strong&gt;：主鏈路延遲無感知，適用於對響應時間要求嚴苛的在線業務場景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;先消費後結算，消除誤限流風險&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;設計原理&lt;/strong&gt; ：採用異步 Token 核銷機制，客户端可先執行操作，限流 SDK 後續異步週期性同步配額消耗。 &lt;strong&gt;效果保障&lt;/strong&gt;：杜絕因限流判斷延遲導致的正常請求被誤拒，確保業務連續性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;短暫超限容忍，資源緩衝池兜底&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;場景説明&lt;/strong&gt; ：在流量毛刺等突發場景中，可能出現瞬時配額超限，由於先消費後結算的機制導致。 &lt;strong&gt;容錯機制&lt;/strong&gt;：通過服務端資源預留 Buffer 吸收流量波動，避免因短暫超限觸發系統風險。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;彈性容錯設計，弱耦合架構保障可用性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;故障降級策略&lt;/strong&gt; ：當限流 Server 服務異常時，系統自動切換至單機 Sentinel 組件實現基礎單機限流功能。 &lt;strong&gt;依賴特性&lt;/strong&gt;：對限流 Server 服務實現弱耦合架構，可以通過隨時動態降級來避免限流 Server 服務異常導致的服務異常，確保分佈式限流服務的高可用。&lt;/p&gt; 
&lt;h3&gt;限流實現難點二：如何平滑限流毛刺&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版採用 TPS 作為集羣規格單位，用於衡量集羣的吞吐能力。例如，1000TPS 表示集羣每秒可處理 1000 條 TPS（即綜合生產、消費等操作的加權計算）。在分佈式限流系統中，這一規格對應每秒分配 1000 個 Token，其中 "一秒"即為默認的限流計數週期，用於動態控制流量配額。&lt;/p&gt; 
&lt;p&gt;在使用限流服務的實際運維中發現：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短週期（如 1 秒）&lt;/strong&gt;： 優勢：對流量波動敏感，可快速響應潛在過載風險； 缺陷：易因短暫毛刺誤觸限流，影響正常業務波動場景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;長週期（如 10 秒）&lt;/strong&gt;： 優勢：容忍毛刺，降低誤控率； 缺陷：服務端資源需承受更高瞬時衝擊風險。&lt;/p&gt; 
&lt;p&gt;為平衡流量控制精度與用户體驗，騰訊雲 TDMQ RabbitMQ Serverless 版將默認限流計數週期從 1 秒調整為 10 秒。這樣既降低了用户因毛刺導致的限流困擾，又通過利用少量的服務器預留資源 Buffer 來承載瞬時流量衝擊，為高併發場景下的消息處理提供了可靠的支撐。&lt;/p&gt; 
&lt;h3&gt;限流實現難點三：如何實現消費端限流&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版集羣使用 AMQP 協議與客户端交互，然而 AMQP 協議中並沒有定義很好的處理 Fail-Fast 限流錯誤的幀，因此在發送消息被限流的情況下，只能通過關閉 Channel 連接來通知到客户端，此時客户端會收到相應的 AlreadyClosedException 異常，然後業務需要通過重試來解決當前時間窗口內消息發送被限流的問題。&lt;/p&gt; 
&lt;p&gt;而在消費端限流的情況下，分為兩種情況，AMQP 協議中支持兩種消費模式，BasicGet（拉模式) 和 BasicConsume（推模式）。 此時對消費端的限流就需要考慮消費的連續性和延遲。針對 BasicGet 模式，是客户端發起的主動同步拉取消息的命令，此時客户端每一次拉取消息是可以直接感知到是否被限流的，更好的方式是通過關閉連接來讓客户端感知到限流，從而讓業務上通過重試來解決拉取當前時間窗口內消息消費被限流的問題。&lt;/p&gt; 
&lt;p&gt;但是針對 BasicConsume（推模式）, 同時也是 AMQP 客户端最普遍的使用方式，考慮到客户端開啓一個長連接監聽相應隊列上的消息，此時如果因為限流粗暴地關閉 Channel 連接, 此時的客户端往往不能實時感知到連接 Channel 斷開，增加了客户端業務上處理的複雜度，同時消費側重建 Channel 連接也會讓消費流量充滿毛刺和消費延遲增加。因此騰訊雲 TDMQ RabbitMQ Serverless 版在推模式下使用消費抑制的方式來實現消費端限流，當消費 TPS 超過閾值時，會減少推送到客户端的頻率，保證了在連接 Channel 不斷開的情況下，消費流量的平穩，儘量減少因為限流導致的消費延遲。&lt;/p&gt; 
&lt;h2&gt;客户端實踐教程&lt;/h2&gt; 
&lt;h3&gt;規劃集羣限流負載&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版的限流機制旨在保障服務穩定性與可靠性。防止在集羣高負載時出現服務響應長尾毛刺，最終導致請求成功率下降，業務受損等問題。因此，在接入時建議：客户側需要提前規劃集羣負載，依據當前規模和未來趨勢預測來充分評估業務 TPS， 如果業務流量具有波動特性，應以峯值 TPS 為準，根據相應的評估後的 TPS 購買相應規格的實例集羣。&lt;/p&gt; 
&lt;h3&gt;限流相關告警配置&lt;/h3&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版默認接入了騰訊雲監控的能力，可以利用騰訊雲 TDMQ RabbitMQ Serverless 版控制枱的監控告警能力實現對集羣負載的實時觀測，提前發現 TPS 水位風險並及時操作升配來避免觸發限流導致業務受損。告警策略建議：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;發送和消費 TPS 水位超過容量的 70% 時觸發告警，提醒進行升配評估。&lt;/li&gt; 
 &lt;li&gt;出現發送限流時觸發告警，警告業務發送消息可能失敗風險。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;客户端限流異常處理&lt;/h3&gt; 
&lt;p&gt;業務代碼通過 RabbitMQ SDK 發送消息時，需要捕獲包括限流錯誤在內的異常，並保存必要的上下文信息，以便人工介入恢復業務。當騰訊雲 TDMQ RabbitMQ Serverless 版實例的 TPS 流量峯值超過騰訊雲控制枱所購買實例的 TPS 規格上限時，業務側生產消費流量會被限流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;限流後的行為如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版服務端會返回錯誤碼信息。&lt;/p&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版服務端關閉當前請求的 Channel 連接，代碼中可以捕獲異常並重新打開 Channel 連接，具體請參見錯誤碼處理示例代碼章節。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;錯誤碼信息&lt;/strong&gt;： 錯誤碼：reply-code=530&lt;/p&gt; 
&lt;p&gt;錯誤信息：reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:xxx reason:PublishMessage, class-id=60, method-id=40)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;錯誤堆棧&lt;/strong&gt;：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Suppressed: com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:amqp-autotest reason:PublishMessage, class-id=60, method-id=40)
at com.rabbitmq.client.impl.AMQChannel.processShutdownSignal(AMQChannel.java:437)
at com.rabbitmq.client.impl.ChannelN.startProcessShutdownSignal(ChannelN.java:295)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:624)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:557)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:550)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.lambda$close$0(AutorecoveringChannel.java:74)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.executeAndClean(AutorecoveringChannel.java:102)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.close(AutorecoveringChannel.java:74)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RabbitMQ AMQP Java SDK 業界使用的比較廣泛，因此使用該 SDK 作為示例，RabbitMQ AMQP Java SDK 不會對限流錯誤進行自動重試，因此業務代碼需要捕獲異常並進行處理，示例代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private static final int MAX_RETRIES = 5; // 最大重試次數
private static final long WAIT_TIME_MS = 2000; // 每次重試的等待時間（以毫秒為單位）
private void doAnythingWithReopenChannels(Connection connection, Channel channel) {
    try {
        // ......
        // 在當前通道 channel 下執行的任何操作
        // 例如消息發送、消費等
        // ......
    } catch (AlreadyClosedException e) {
        String message = e.getMessage();
        if (isChannelClosed(message)) {
            // 如果通道已經關閉，關閉並重新創建通道
            channel = createChannelWithRetry(connection); 
            // 在重連後可以繼續執行其它操作
            // ......
        } else {
            throw e;
        }
    }
}
private Channel createChannelWithRetry(Connection connection) {
    for (int attempt = 1; attempt &amp;lt;= MAX_RETRIES; attempt++) {
        try {
            return connection.createChannel();
        } catch (Exception e) {
            System.err.println("Failed to create channel. Attempt " + attempt + " of " + MAX_RETRIES);
            // 檢查錯誤, 若仍是被限流導致的關閉錯誤，則可以等待後繼續重試
            // 也可移除本部分重試邏輯
            if (attempt &amp;lt; MAX_RETRIES) {
                try {
                    Thread.sleep(WAIT_TIME_MS);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt(); // 還原中斷狀態
                }
            } else {
                throw new RuntimeException("Exceeded maximum retries to create channel", e);
            }
        }
    }
    throw new RuntimeException("This line should never be reached"); // 理論上不會到達這裏
}
private boolean isChannelClosed(String errorMsg) {
    // 判斷是否包含 channel.close 報錯，該報錯代表通道已關閉。
    // 可能涵蓋 530，541 等錯誤信息。
    if (errorMsg != null &amp;amp;&amp;amp; errorMsg.contains("channel.close")) {
        System.out.println("[ChannelClosed] Error details: " + errorMsg);
        return true;
    }
    return false;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p&gt;騰訊雲 TDMQ RabbitMQ Serverless 版通過分佈式限流架構為在線業務提供高可用的消息服務保障。在分佈式限流模式下，服務端通過集中式 Token 管理系統（限流 Limiter）動態分配資源配額，防止因突發流量衝擊導致核心存儲層（底座 Broker 集羣）過載來提高系統穩定性，同時採用 【先消費後結算】的異步處理模式，客户端在限流 SDK 內部閉環完成 Token 申請，避免阻塞主鏈路，確保限流調用接口低延時，限流 SDK 週期性同步 Token 消耗數據至限流 Server，最終平衡了限流精度與調用限流服務的性能開銷。同時針對消費端的限流可以實現不斷 Channel 連接，實現了消費端在限流毛刺與消費延遲之間的雙重保證，此外，面對限流 Server 服務不可用的情況，系統能夠自動動態降級為單機限流模式，確保客户端請求的連續性，保持對限流服務的弱依賴設計來實現系統解耦。&lt;/p&gt; 
&lt;p&gt;在實際應用與運維中，同時也需要客户業務方的配合，在接入騰訊雲 TDMQ RabbitMQ Serverless 版服務時，業務方客户需要根據業務規模和未來趨勢合理規劃集羣，預留足夠的 TPS 配額以應對突發流量，防患於未然。同時騰訊雲 TDMQ RabbitMQ Serverless 版提供了服務端完善的監控和告警，支持客户通過監控告警能力實時訂閲集羣負載，提前發現 TPS 水位風險並及時進行升配等操作。在客户端業務代碼層面，需要捕獲限流異常並處理，保證代碼的健壯性，同時保存必要的上下文信息，以便人工查看相關日誌最終介入來恢復業務。&lt;/p&gt; 
&lt;p&gt;通過本文對騰訊雲 TDMQ RabbitMQ Serverless 版的限流機制的介紹與實踐教程，相信讀者對騰訊雲 TDMQ RabbitMQ Serverless 版的限流機制有了更深入的理解，並能夠在實際項目中靈活應用，最終為業務的高併發、大流量場景提供穩定的支持。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4587289/blog/18638288</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4587289/blog/18638288</guid>
      <pubDate>Sat, 10 May 2025 07:34:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>百度搜索迎來十年來最大改版：AI 智能框、百看、AI 助手全面進化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在近日的百度 AI Day 開放日上，百度搜索宣佈進行了其十年來最大規模的改版，此次革新涵蓋了搜索框、搜索結果頁以及整個搜索生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-98d15d20c6065a79b817c094d1a37c4066c.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;升級後的百度搜索框被命名為「智能框」，顯著增強了其輸入能力，現在可支持超過千字的文本輸入。同時，拍照、語音、視頻等多種輸入方式也得到全面加強，並能直接調取 AI 寫作、AI 作圖等創作工具，極大地豐富了用户與搜索的交互方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「百看」功能也在此次改版中實現了全面升級，不僅支持圖文、音視頻的混合內容輸出，還創新性地接入了智能體和真人服務等功能，旨在提供更豐富、多元的信息呈現形式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「AI 助手」的升級是本次改版的另一大亮點，新增了視頻通話功能，並顯著提升了多模態輸入、富媒體輸出、一站式工作台及深度搜索能力，使其成為更全面的 AI 輔助工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，智能創作能力也得到大幅提升，用户現在只需一句話即可生成三分鐘的創意視頻，並支持分鏡編輯和自定義畫面內容。截至目前，百度搜索開放平台已成功接入 1.8 萬多個優質 MCP（多媒體內容提供商），使其成為國內最大的 AI 生態系統。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得一提的是，此次百度搜索還接入了商業研發團隊自研的視頻生成模型 MuseSteamer 及其創作平台「繪想」。據瞭解，MuseSteamer 是全球首個實現中文音視頻一體化生成的視頻模型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358379</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358379</guid>
      <pubDate>Sat, 10 May 2025 07:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>向量檢索算法：從哈希、樹到量化與圖</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;向量檢索這門技術，其發展由來已久，可以追溯到上世紀六七十年代。1975 年發表的 KD 樹算法，就是早期經典的高維數據檢索算法之一。&lt;strong&gt;然而，此後近四十年間，向量檢索長期處於冷門狀態，並沒有特別多的應用需要它。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;直到 2015 年，ImageNet 圖片分類數據集及何愷明教授的 ResNet 等突破性論文引爆了深度學習，使得模型在多個任務上超越人類。推薦系統和搜索引擎快速成為向量檢索技術主要落地場景，向量引擎也由此開始大規模應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;大模型爆發又掀起第二輪熱潮：&lt;/strong&gt;基於向量檢索的 RAG 架構，已成為解決模型幻覺、實現知識實時更新的關鍵技術，推動其在多模態、企業知識庫等場景爆發式應用。&lt;/p&gt; 
&lt;p&gt;不久前，&lt;strong&gt;開源中國直播欄目《數智漫談》邀請到了傅聰博士，分享了向量檢索技術的發展情況。&lt;/strong&gt;傅聰於浙江大學計算機博士畢業，曾赴美國南加州大學訪問研究，其主導發明的 NSG、SSG、PSP、MAG 等高性能檢索算法，已落地為千億級向量檢索系統，成為工業界大規模檢索的標杆方案。目前，傅聰博士在 shopee(新加坡) 擔任資深算法專家，專注於 AI 大規模應用落地方面的研究。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;微信掃碼，觀看直播回放：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="189" src="https://oscimg.oschina.net/oscnet/up-a3d943da38c62d33dda46a1b30db2454488.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本文根據直播整理，介紹四種向量檢索算法類型：哈希算法、樹算法、量化算法、圖算法。其中，哈希算法、樹算法慢慢淡出了歷史舞台，量化算法、圖算法是當前主流。&lt;/p&gt; 
&lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;哈希算法：向量檢索的古早形態，已逐漸被淘汰&lt;/h4&gt; 
&lt;p&gt;向量檢索的最初形態——哈希算法，是一種歷史悠久的向量索引方式。&lt;/p&gt; 
&lt;p&gt;從事計算機相關行業的朋友，對哈希表應該都不陌生。哈希的本質是什麼？就是把數據通過一個哈希映射函數，映射到哈希桶（buckets）裏。目標是讓每個桶裏的數據分佈儘可能均勻，這樣就能通過高效的二進制方式快速檢索數據。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-3ebf5adc615560ea36947f573932442be26.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;向量哈希函數與我們常規理解的哈希算法，核心區別在於，哈希函數本身是專門為向量設計的。大家無需深究其具體實現，只需知道這類函數能將向量相對均勻地分散到各個哈希桶中，從而實現高效檢索。&lt;/p&gt; 
&lt;p&gt;那麼，為什麼哈希算法沒有在當下各領域大規模應用呢？主要原因有兩個：一是哈希表索引結構本身非常龐大；二是其效率低且精度差。&lt;/p&gt; 
&lt;p&gt;我們可以以構建一個線上工業級併發系統為例來説明。通常來説，系統性能的核心目標通常包括 QPS（即單機處理用户請求的最大併發能力）和 recall（召回精度）。在特定的延遲要求下，評估向量檢索算法的關鍵指標是——在此延遲約束內能達到多高的召回精度。而哈希算法最大的問題恰恰是其精度不足，因此才逐漸被淘汰。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;樹算法：單棵樹精度不夠，曇花一現&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;歷史上與哈希算法一樣曇花一現的，還有樹算法。它的本質就是分治思想。設想一個龐大複雜的高維向量空間，目標是通過方法將其逐層切分，最終把整個空間分割成許多小格子（也就是葉子節點），並讓每個葉子節點包含的向量數量儘量接近。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="391" src="https://oscimg.oschina.net/oscnet/up-f1128fc60ac26c9adde0404801cc8352ec4.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這樣就能借助樹結構高效的索引邏輯進行快速查詢。入門數據庫時學到的那些索引，很多其實就是這種樹結構，只是切分方式不同。&lt;/p&gt; 
&lt;p&gt;這種樹索引有個明顯特點：體積很大。 別光看它是一棵樹就覺得體積小。問題在於，單棵樹的檢索精度通常不夠好。所以實際應用中，要構建多棵樹。&lt;/p&gt; 
&lt;p&gt;比如上個時代，有名的開源檢索庫 FLANN (Fast Library for Approximate Nearest Neighbors)，它在計算機視覺領域用得挺多，就不會只建一棵樹，而是構建多棵隨機樹進行並行查詢，以此來提升效果。代價就是索引會膨脹得厲害。&lt;/p&gt; 
&lt;p&gt;相比哈希算法，它的精度確實高一些，但通常還是達不到在線產品系統的要求。關鍵問題在於：即使勉強達到某個精度（可能還不達標），它的檢索速度也依然非常慢。&lt;/p&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;量化算法：低損耗，空間切分類算法的性能天花板&lt;/h4&gt; 
&lt;p&gt;量化算法，和前兩類算法（哈希和樹算法）其實比較相似，可以把它們理解為空間切分類算法。這類算法有一個共同的缺陷，就是索引效率較低。&lt;/p&gt; 
&lt;p&gt;但量化算法另闢蹊徑，它用一種低損耗的方式實現了較好的空間切分。這裏有個比較經典的例子，就是 Meta 的 FAISS 庫（前身由 Facebook 開發），它最早集成的核心算法 IVFPQ（Product Quantization）代表了十年前的主流方案。PQ 的核心邏輯是通過聚類來切分空間，這和前兩類算法的思路不太一樣。&lt;/p&gt; 
&lt;p&gt;它具體是怎麼做的呢？在切分好的空間裏，選取中心點（圖中紅點）作為區域代表點。用户的查詢向量只需要和這些中心點計算距離。這個距離近似等價於查詢向量與該區域內所有原始數據點（藍點）的距離比較。這樣就能快速篩選出一部分近鄰候選向量，最後再用真實距離進行精確比較。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="233" src="https://oscimg.oschina.net/oscnet/up-15d3f09345246ba6a850f9370c91c0d7c3f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;br&gt; （圖片來源於，知乎用户 @vegetabledog）&lt;/p&gt; 
&lt;p&gt;這種算法的優勢很明顯：索引結構非常小（內存佔比低），檢索速度足夠快，而且精度也比哈希和樹算法更高。量化算法發展到這裏，可以説空間切分類算法的性能天花板已經顯現了。&lt;/p&gt; 
&lt;p&gt;也正是在這個階段，創新的圖檢索算法開始興起。&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;圖算法：精度高、速度快，當前被普遍採用&lt;/h4&gt; 
&lt;p&gt;圖檢索算法可以説和前面三種算法（哈希、樹、量化）是完全不同的思路。&lt;/p&gt; 
&lt;p&gt;前面那些算法的核心是「分而治之」，像切割領土、築牆建院一樣去切割空間。而圖算法的核心思想恰恰相反，它是要打通區塊之間的壁壘——不是去切分空間，而是在空間的點與點之間構建四通八達的「高速公路」，這就是圖算法的設計理念。&lt;/p&gt; 
&lt;p&gt;圖算法的特點是，它的索引會比量化算法大很多。但從當前各種基準測試的表現來看，它能在保持極快速度的同時，以高精度碾壓量化類算法。&lt;/p&gt; 
&lt;p&gt;那麼圖算法是怎麼檢索的呢？&lt;/p&gt; 
&lt;p&gt;假設我們已經構建好一個圖結構，圖中每個點只連接空間中的少量鄰近點。比如起始點是黑色點 M，目標查詢點是左下角的黑色點 P。從任意起點 M 逼近目標 P 的過程，本質上是一個貪婪式的圖上「遊走」：每一步都在當前點的鄰近中尋找離 P 最近的那個點跳轉過去，然後迭代重複這個過程。這樣一步步跳轉，最終就能逼近目標區域（紅色點即為最近的候選結果）。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-bb7e20fa086e16efab68928e5adbe9301ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;想要讓圖算法發展得更好——精度更高、速度更快——關鍵在於兩點：第一，路徑越短越好（跳轉次數少則速度快）；第二，鄰近越少越好（每個點計算量小則算力需求低）。這意味着理想的圖結構應該是足夠稀疏，並且點與點之間的連通路徑儘可能短。&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;選型：量化算法還是圖算法？&lt;/h4&gt; 
&lt;p&gt;現在開源項目或 Demo 中，最常用的就是量化算法和圖算法。那要怎麼選型、找到適用場景？根據長期工作經驗總結如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果數據總量較小，在線精度要求不高，但對內存或 GPU 顯存有嚴格限制，就比較適合用量化算法。因為量化是用聚類中心代表其他點，這個過程必然有信息損失——數據量越小損失越小，數據量越大精度下降越明顯。&lt;/li&gt; 
 &lt;li&gt;如果數據總量非常大，同時要求高精度、低延遲，並且有充足的內存資源（目前內存也相對便宜了），那麼圖算法是更好的選擇。實際上，當前無論是開源項目還是閉源產品，主流的向量檢索方案普遍都在使用圖算法。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="167" src="https://oscimg.oschina.net/oscnet/up-dc8e9e8b16cadc5a2d42d658c4914e8ae48.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;量化算法有一個典型場景，就是推薦系統中的 GPU 端向量召回。&lt;/strong&gt;例如在電商平台，需要構建一個約 2000-3000 萬規模的精品商品庫，通過向量表徵模型（如生成 64 維或 128 維向量）實時召回個性化商品作為推薦候選集。&lt;/p&gt; 
&lt;p&gt;這些向量表徵模型部署在 GPU 上進行推理，因此生成的向量數據會直接駐留在 GPU 顯存中。我們希望向量檢索也能在顯存內完成，避免向 CPU 傳輸數據。然而，模型本身可能已佔用 10 GB 以上的顯存，剩餘可用顯存往往僅剩 2-3GB。&lt;/p&gt; 
&lt;p&gt;在這種顯存受限的場景下，量化類檢索算法就顯得尤為合適。類似地，如果大模型應用中的知識庫規模有限，且需要端到端 GPU 處理，量化算法也是理想選擇。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;至於圖算法的典型場景，可以千億級視頻版權檢測為例。&lt;/strong&gt;抖音、快手等短視頻平台，抖音、快手這類平台每日面臨海量視頻上傳，必須在極短時間內完成版權篩查以避免法律風險，&lt;/p&gt; 
&lt;p&gt;其核心流程可分為三步：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;特徵提取：針對版權庫視頻，提取關鍵幀的畫面特徵並壓縮為高維向量（如 CLIP 生成 1024 維向量），確保內容相似的視頻片段在向量空間中距離相近；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;索引構建：將向量存入支持 ANN（近似最近鄰）檢索的專用數據庫（如 Milvus/FAISS），構建千億級向量索引；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實時檢索：新視頻上傳時，實時提取其特徵向量，在毫秒級延遲內從向量庫中檢索相似內容，返回相似度超過閾值（如 &amp;gt;95%）的潛在侵權片段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;面對這種超大規模數據+高併發+高精度的需求，圖檢索算法，可以説是目前最有效的解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;小結：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;縱觀向量檢索的發展，從早期的哈希、樹算法，到當前主流的量化、圖算法，技術的迭代始終圍繞着效率、精度與資源消耗的平衡。哈希與樹算法受限於精度或效率瓶頸，逐漸淡出主流視野；量化算法憑藉其低內存消耗的特性，在資源受限場景（如 GPU 顯存下的中小規模召回）找到了穩固位置；而圖算法則以其高精度、低延遲的優勢，成為應對千億級海量數據、高併發在線檢索的首選。&lt;/p&gt; 
&lt;p&gt;技術迭代一直在進步。傅聰博士主導發明的基於圖的 NSG 算法，已成為當前主流方案之一，但仍然在實踐中不斷演進——目前，他在 Shopee（新加坡） 帶領團隊已將其迭代至第三代 PSP 與第四代 MAG 算法，不斷突破着大規模向量檢索的性能邊界。&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span style="color:#27ae60"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;【數智漫談】&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OSCHINA 視頻號直播暢聊欄目【數智漫談】，每期一個技術話題，三五位專家圍坐，各抒己見，暢聊開源。給大家帶來最新的行業前沿、最熱門的技術話題、最有趣的開源項目、最犀利的思想交鋒。如果你手上也有新點子、好項目，想要跟同行交流分享，歡迎聯繫我們，講壇隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18683168</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18683168</guid>
      <pubDate>Sat, 10 May 2025 07:17:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Anthropic 年化收入達 40 億美元，較年初增長近 4 倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Information 援引知情人士稱，「AI 獨角獸」Anthropic 年化收入已達到每年 40 億美元，即每月 3.33 億美元，較今年年初增長了近四倍。與此同時，Anthropic 的競爭對手 Cursor 也在積極擴展業務，雙方之間的競爭愈加激烈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="269" src="https://oscimg.oschina.net/oscnet/up-2307b0436f3618822c9987fadd1eedab2af.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Cursor 是一款由 Anthropic 提供人工智能技術支持的編程應用程序，旨在幫助開發者提高工作效率。然而，Cursor 的背後並不僅僅依賴於 Anthropic 的技術。近期，Cursor 公司還招募了 Anthropic 的兩位高管。這兩位高管曾負責 Anthropic 的編程產品 Claude Code，他們的加入可能會進一步增強 Cursor 在市場上的競爭力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Anthropic 自成立以來，憑藉其先進的人工智能技術和強大的研發團隊，迅速佔領了市場。然而，隨着 Cursor 的崛起，Anthropic 面臨着新的挑戰。Cursor 雖然依賴於 Anthropic 的技術，但通過引入高管和不斷創新，Cursor 希望能在市場上佔據一席之地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不僅如此，人工智能技術的快速發展，也使得編程工具的需求不斷增加。市場對智能編程工具的熱情高漲，各家公司都在努力爭取更大的市場份額。面對這樣的市場環境，Anthropic 和 Cursor 之間的競爭將會更加白熱化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358314</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358314</guid>
      <pubDate>Sat, 10 May 2025 03:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>前 5 個月我國軟件業務收入 55788 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;工業和信息化部運行監測協調局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_451a835829c54325a8316fa9dd2a9d32.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;，&lt;/span&gt;&lt;span style="color:#000000"&gt;2025 年前 5 個月，我國軟件和信息技術服務業（以下簡稱「軟件業」）運行態勢良好，軟件業務收入穩健增長，利潤總額保持兩位數增長，軟件業務出口保持正增長。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="237" src="https://oscimg.oschina.net/oscnet/up-1716524be9e23b5228867787d358aa2a175.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;一、總體運行情況&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;軟件業務收入穩健增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，軟件業務收入 55788 億元，同比增長 11.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;利潤總額增速保持兩位數增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，軟件業利潤總額 6721 億元，同比增長 12.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;軟件業務出口保持正增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，軟件業務出口 227&lt;/span&gt;&lt;span style="color:#000000"&gt;.1&lt;/span&gt;&lt;span style="color:#000000"&gt;億美元，同比增長 3.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;二、分領域運行情況&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;軟件產品收入穩定增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，軟件產品收入 12478 億元，同比增長 9.8%，佔全行業收入的 22.4%。其中，基礎軟件收入 704 億元，同比增長 10&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%；工業軟件產品收入 1138 億元，同比增長 7&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;信息技術服務收入保持兩位數增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，信息技術服務收入 38096 億元，同比增長 12&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%，佔全行業收入的 68.3%。其中，雲計算、大數據服務共實現收入 5855 億元，同比增長 11.2%，佔信息技術服務收入的 15.4%；集成電路設計收入 1516 億元，同比增長 15.2%；電子商務平台技術服務收入 4355 億元，同比增長 7.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;信息安全收入穩定增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，信息安全產品和服務收入 787 億元，同比增長 8.4%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;嵌入式系統軟件收入穩定增長。前&lt;/span&gt;&lt;span style="color:#000000"&gt;5 個月，嵌入式系統軟件收入 4428 億元，同比增長 8.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;三、分地區運行情況&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;前 5 個月，東部地區、中部地區、西部地區和東北地區分別同比增長 11.3%、11.8%、11.0% 和 9.2%。東部地區佔全國軟件業務總收入的 84.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;京津冀地區軟件業務收入同比增長 12.3%，長三角地區軟件業務收入同比增長 11.9%。北京、廣東、江蘇、山東、上海軟件業務收入居全國前 5，同比分別增長 12.7%、8.5%、12.3%、12.1% 和 15.1%。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358308</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358308</guid>
      <pubDate>Sat, 10 May 2025 03:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>1-5 月我國互聯網業務收入 7735 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工業和信息化部運行監測協調局最新&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fgxsj%2Ftjfx%2Fhlw%2Fart%2F2025%2Fart_8805da85aec14555b88e36da36ea4e27.html" target="_blank"&gt;發佈&lt;/a&gt;&lt;span style="color:#000000"&gt;了 2025 年 1-5 月份互聯網和相關服務業運行情況。具體如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;一、總體運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;互聯網業務收入穩定增長。1－5 月份，規模以上互聯網和相關服務企業（以下簡稱互聯網企業）完成互聯網業務收入 7735 億元，同比增長 0.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;利潤總額降幅持續收窄。1－5 月份，規模以上互聯網企業實現利潤總額 692 億元，同比下降 2.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研發經費增勢放緩。1－5 月份，規模以上互聯網企業共投入研發經費 390.6 億元，同比增長 4.1%，增速較 1－4 月份回落 0.7 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;二、分地區運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;東部地區互聯網業務收入增速放緩，西部地區收入增速領先。1－5 月份，東部地區完成互聯網業務收入 6943 億元，同比增長 2.8%，高於全國增速 1.9 個百分點，佔全國互聯網業務收入的 89.8%。中部地區完成互聯網業務收入 308.4 億元，同比下降 30.1%，低於全國增速 31 個百分點。西部地區完成互聯網業務收入 467.8 億元，同比增長 4.3%。東北地區完成互聯網業務收入 15.7 億元，同比下降 24.1%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;京津冀地區互聯網業務收入保持較快增勢。1－5 月份，京津冀地區完成互聯網業務收入 2666 億元，同比增長 8.3%，佔全國互聯網業務收入的 34.5%。長三角地區完成互聯網業務收入 2470 億元，同比下降 2.1%，佔全國互聯網業務收入的 31.9%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;超三成地區互聯網業務增速實現正增長。1－5 月份，互聯網業務累計收入居前 5 名的北京、廣東、上海、浙江和天津共完成業務收入 6496 億元，同比增長 4.1%，佔全國（扣除跨地區企業）互聯網業務收入的 84%。全國互聯網業務收入實現正增長的省（區、市）有 11 個，其中山西、內蒙古、四川、陝西增速超 10%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;附註：規模以上互聯網和相關服務企業口徑為上年互聯網和相關服務收入 2000 萬元及以上，文中所有同比增速均按可比口徑計算。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358301</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358301</guid>
      <pubDate>Sat, 10 May 2025 02:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華為開源大規模 MoE 模型推理部署技術「Omni-Infer」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;華為公佈了基於昇騰的超大規模 MoE 模型推理加速技術「Omni-Infer」。&lt;/p&gt; 
&lt;p&gt;官方介紹，Omni-Infer 是一套專為昇騰硬件平台定製的強大推理加速工具集，完全兼容業界目前主流的開源大模型推理框架（比如 vLLM 等），旨在提供高性能、企業級推理能力，具備原生支持且功能集持續擴展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ad6ff90d8d31fab0e52f1d92fd7d9bb90e3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;部分核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高級注意力機制優化：專為 LLM、MLLM 和 MoE 模型定製，增強性能與可擴展性。&lt;/li&gt; 
 &lt;li&gt;請求級負載均衡：針對所有序列長度優化預填充（prefill）和解碼（decode）階段，實現最大吞吐量與低延遲。&lt;/li&gt; 
 &lt;li&gt;優化的 MoE 專家部署：支持 EP144/EP288 配置的大規模混合專家（Mixture of Experts, MoE）模型。&lt;/li&gt; 
 &lt;li&gt;MoE 專家負載均衡：具備分層非均勻冗餘和近實時動態專家放置功能，提升資源利用效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;目前，Omni-Infer 已公佈技術報告及可分析代碼包等內容：&lt;a href="https://gitee.com/omniai/omniinfer"&gt;https://gitee.com/omniai/omniinfer&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358292</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358292</guid>
      <pubDate>Sat, 10 May 2025 02:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Iceberg 在圖靈落地應用</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;導讀&lt;/h1&gt; 
&lt;p&gt;百度 MEG 上一代大數據產品存在平台分散、易用性差等問題，導致開發效率低下、學習成本高，業務需求響應遲緩。為瞭解決這些問題，百度 MEG 內部開發了圖靈 3.0 生態系統，包括 Turing Data Engine(TDE) 計算&amp;amp;存儲引擎、Turing Data Studio(TDS) 數據開發治理平台和 Turing Data Analysis(TDA) 可視化 BI 產品。依託圖靈 3.0 生態，我們引入了數據湖表格式：Apache Iceberg，利用其特性並在多種業務場景下進行優化實踐，解決圖靈數倉業務實時數據入湖，數據表歷史記錄更新效率低等多個痛點問題。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 圖靈 3.0 生態概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由於百度 MEG 上一代大數據產品存在平台多、易用性差及數據流轉繁瑣等問題。這些問題導致開發人員研發效率低及多平台間高昂的學習成本；業務部門的感知則是需求交付遲緩、數據產出延遲及數據質量低等問題。為瞭解決上述問題，我們構建了新一代大數據解決方案——"圖靈 3.0"，旨在覆蓋數據全生命週期，支持全鏈路數據操作，提供高效敏捷且統一的強大數據生態系統，其中包括數據計算引擎、數據開發和數據分析三個核心部分：&lt;/p&gt; 
&lt;p&gt;1. TDE（Turing Data Engine）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247581388%26idx%3D1%26sn%3De71a4f3c4ca283ac6e8fe51d0a45a02b%26scene%3D21%23wechat_redirect" target="_blank"&gt;圖靈生態的計算引擎&lt;/a&gt;，包含基於 Hive、Iceberg 進行數據處理的 Spark 和&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247601378%26idx%3D1%26sn%3D9234aeef05c3813cfb34d9a064261984%26scene%3D21%23wechat_redirect" target="_blank"&gt;ClickHouse 高性能計算引擎&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;2. TDS（Turing Data Studio）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247599508%26idx%3D1%26sn%3D19094522609ca58528295a8ccbb061bd%26scene%3D21%23wechat_redirect" target="_blank"&gt;一站式數據開發治理平台&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;3. TDA（Turing Data Analysis）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247584876%26idx%3D1%26sn%3D7bf459415ef8d51685d4e1c335b0603e%26scene%3D21%23wechat_redirect" target="_blank"&gt;新一代可視化 BI 產品&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;本文主要介紹數據湖表格式 Iceberg 在圖靈 3.0 生態下的應用與實踐。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1764b56858226d39002905e95ec9f32e1d2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△圖靈 3.0 生態產品&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 問題&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MEG 數據中台基於 Hive 構建了離線數據倉庫，已支持手百，搜索，商業，貼吧，小説，用增架構，銷售等多個業務需求，但隨着業務的發展，業務對數據的實時性以及查詢性能等有更高要求，當前主要存在以下幾個問題：&lt;/p&gt; 
&lt;p&gt;1. 商業、電商、銷售等業務，週期性地更新行業等信息，單次更新數據量佔比小、字段少，但是基於 Hive 的數據更新（以下簡稱：數據回溯）只能通過全量覆蓋寫的方式實現，數據回溯週期長、效率低、成本高。&lt;/p&gt; 
&lt;p&gt;2. 由於 Hive 在實時數據更新以及事務支持上存在一定侷限性，無法有效滿足業務構建實時數倉的需求。&lt;/p&gt; 
&lt;p&gt;3. 在處理大規模數據集上，Hive 的查詢性能受到如元數據的加載解析以及每次訪問數據都需通過分佈式文件系統 listFile 遍歷文件列表等問題的影響，導致性能降低。&lt;/p&gt; 
&lt;p&gt;基於上述問題，我們通過技術調研，最終引入了開源的數據湖表格式 Iceberg，構建數據湖存儲服務，並藉助大數據生態的 Spark、Flink 等計算引擎來實現數據湖的分析，將其無縫集成到圖靈生態中，幫助業務提效降本，構建更快速、更高效、更低成本的數據中台產品。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 Hive 和 Iceberg 對比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Hive 作為一個基於 Hadoop 生態系統的開源數據倉庫工具，主要用於對大規模結構化數據進行存儲、查詢和分析。而 Iceberg 作為新一代數據湖表格式，提供了類似傳統數據庫的事務性，保證和數據一致性，並支持複雜的數據操作，如行級更新和刪除等，更加適合實時更新，流批一體數據場景，下表列出 Hive 和 Iceberg 一些主要特性對比：&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Hive&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Iceberg&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;行級更新&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;不支持&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持 merge into、&lt;/span&gt; 
         &lt;span&gt;upsert&lt;/span&gt; 
         &lt;span&gt;等語法進行行級別更新能力&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;時效性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;小時級別/天級&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;分鐘級&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;事務&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;非完整的 ACID 事務&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持完整的 ACID 事務，同時使用多快照提供了讀寫分離的特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;元數據管理方式&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;基於 Mysql 進行元數據存儲&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;通過文件組織管理，直接存儲數據文件元數據&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;數據版本控制&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;無&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持時間旅⾏(Time travel) 特性，可基於快照進行歷史數據版本管理和訪問&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 Iceberg 的組織結構&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Iceberg 文件組織分為元數據層和數據層，主要包含 version-hint，metadata file、snapshot file、manifest file 和 data file 文件類型，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;metadata 元數據層&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a. version-hint：該文件作為元數據索引初始文件，記錄了 Iceberg 表的版本號，通過版本號找到對應的 metadata file。&lt;/p&gt; 
&lt;p&gt;b. metadata file：記錄了 Iceberg 表的 schemas、properties 以及快照等信息。&lt;/p&gt; 
&lt;p&gt;c. snapshot file（manifest-list）：每次數據 commit 會生成一個新的快照，保存了該快照下每個 manifest file 路徑及對應的分區範圍。&lt;/p&gt; 
&lt;p&gt;d. manifest file：記錄數據文件元信息，包含每個數據文件的路徑、文件的大小等一系列統計信息（如文件每列的最大最小值、空值數等），實現元數據和數據文件的關聯。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;data 數據層&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;data file：實際的數據文件，以 parquet 等列存格式存儲數據。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f4a0f78b290db1caccb1aa213d0eb2ebc13.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表結構&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f506fa444f1e285b84c15e9adb1fd379988.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 文件組織結構&lt;/p&gt; 
&lt;p&gt;通過上述 Iceberg 元數據文件組織結構，Iceberg 實現了文件級的元信息統計及版本化管理。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;02 Iceberg 能力建設與應用&lt;/h1&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 圖靈生態能力適配&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 統一元數據服務&lt;/h3&gt; 
&lt;p&gt;由於原生 iceberg 缺少元數據的可視化管理能力，我們通過構建統一的元數據微服務，將 Iceberg 表和 Hive 表元數據進行管理，對應用層提供相關表和分區的增刪改查等接口，統一數據存儲的元數據操作入口。&lt;/p&gt; 
&lt;p&gt;該微服務主要包含常駐 SparkSession 模塊，EngineMetaService 模塊和元數據模塊，通過將 SparkSession 常駐，為用户提供 Iceberg 表和 Hive 表元數據和分區數據的增刪改查功能，以及可視化的元數據管理界面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-76e46b4f67c2c75cd8176866ca4893e5c2e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△統一元數據服務架構&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 打通 Iceberg 和 Hive 聯邦查詢&lt;/h3&gt; 
&lt;p&gt;為了兼容歷史業務存量 Hive 表，同時降低用户使用 Iceberg 的成本。我們在計算引擎層面打通 Iceberg 和 Hive 聯邦查詢能力，並保證了 Iceberg 表與原有方式語法一致。&lt;/p&gt; 
&lt;p&gt;通常在一條 SQL 執行過程中，主要可簡化以下 Parse、Analyzer、Optimizer、CBO 四個流程。通過在 Analyzer 和 Plan 階段進行改進優化，來打通 Iceberg 和 Hive 表聯邦查詢。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Analyzer 階段：該階段主要是將 spark 未解析的邏輯計劃進行解析，我們通過對 SparkSessionCatalog 加載方式改造，優先加載 iceberg 表使用的 catalog 類型，如果用户 SQL 使用的是 Iceberg 表，則對應會使用 IcebergCatalog 和 iceberg 數據源訪問，否則使用 SessionCatalog 與 Hive 數據源訪問。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optimizer 階段：為加強數據安全管理，我們進一步打通 Iceberg 表鑑權能力，在基於邏輯計劃生成物理計劃階段，解析注入表、字段信息以及表操作類型規則，並與公司內數管平台交互，實現對 Iceberg 表和字段的鑑權&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a5292d689d944eafa1fc34ca2637e610b9f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 和 Hive 聯邦查詢適配流程&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 存量 Hive 低成本遷移 Iceberg&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;現有數倉業務數據主要存儲於 Hive 表，為支持業務快速切換 Iceberg 應用新技術，我們建設了存量 Hive 表低成本遷移至 Iceberg 表的能力。&lt;/p&gt; 
&lt;p&gt;以下是在實踐過程中的兩種遷移方案對比：&lt;/p&gt; 
&lt;p&gt;方式 1：使用 Iceberg 功能 migrate 進行原地遷移，通過社區提供的 CALL migrate 語法，直接執行如下示例的 SQL 語句，即可將 Hive 表升級為 Iceberg 表。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CALL&amp;nbsp;catalog_name.system.migrate('db.sample', map('foo',&amp;nbsp;'bar'));﻿


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該方案操作簡單且可回滾，但這種方式在圖靈生態落地過程中也存在一些問題：&lt;/p&gt; 
&lt;p&gt;該方式會基於原 Hive 表的數據信息構建 Iceberg 元數據信息，並將原 Hive 表名重命名為 sample_backup_，同時數據路徑也進行重命名。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下游無法讀：在執行遷移過程中，原 Hive 表對應的路徑已經被重命名，進而導致下游業務無法正常讀取正在遷移中的表。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多表掛載衝突：在業務的使用場景中，存在同一份物理數據被多個 Hive 表掛載可能，直接修改路徑會導致其他表失效。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;方式 2：基於上述問題，我們進一步對現有方案進行優化，不改變 Hive 表原有的數據路徑，來實現 Hive 低成本遷移 Iceberg，具體流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;構建 Iceberg 元數據：直接複用 Hive 的分區數據，新建同名的 Iceberg 表，並重建 Iceberg 元數據，最終新 Iceberg 表的元數據信息實際指向是 Hive 分區數據存儲位置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據校驗：當 Iceberg 元數據構建完成後，查詢 Iceberg 表中字段數據，和遷移之前 Hive 表字段數據，進行一致性校驗，驗證遷移是否符合預期。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;讀寫切換：數據校驗完成後，我們只需要將對應表的屬性更新為 Iceberg。因為我們已經打通了 Iceberg 和 Hive 的查詢，且遷移後表名未變，業務可正常使用原有表名及語法進行查詢和寫入，降低遷移成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eea52f5d044ee6bc0ba16749ae9f4589492.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Hive 遷移 Iceberg 整體實現流程&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 Iceberg 在圖靈的應用和性能優化&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.1 圖靈實時數倉應用&lt;/h3&gt; 
&lt;p&gt;在圖靈數倉大部分場景中，用户主要依託天級或小時級運行的離線 Spark 任務來完成數據入倉。在這種模式下，難以滿足部分對數據實時性要求較高的需求。&lt;/p&gt; 
&lt;p&gt;為解決該問題，我們基於 Iceberg+Flink 構建的圖靈實時湖倉架構，整體重構流程如下圖所示。該架構模式實現了數據分鐘級別實時入倉，顯著提升了數據入倉的時效性。進一步擴展了整個圖靈的應用場景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;針對數據分析和 case 排查等場景，業務可基於圖靈常駐計算引擎進行實時查詢，快速獲取所需要的數據支持業務分析決策；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對策略迭代、特徵生產以及機器學習等複雜計算場景，可基於 spark 例行任務進行加工生產；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對策略數據調研分析、科學計算等複雜場景通過數據交互計算引擎 Jupyter 進行數據計算。通過構建圖靈實時湖倉架構，既保證了數據分析的時效性又兼顧了複雜計算任務的處理能力，有效提升了業務的數據處理效率和分析決策能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fabfc35e204c90fdf9ccd937438c044d8c6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△圖靈實時湖倉架構演變&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.2 行級更新策略&lt;/h3&gt; 
&lt;p&gt;在圖靈數倉業務場景下，商業、搜索、電商、銷售等業務，週期性地更新行業等信息。而 Hive 在該場景下支持相對較弱，需通過全量覆蓋寫方式刷新數據，這種方式在大數據量場景下，回溯數據週期長，消耗資源大，所需要的人力時間成本也高。我們通過利用 Iceberg 行級更新的特性，基於 update、merge into 等方式回溯進行字段變更，能夠很大程度的提高回溯效率，降低資源和人力成本。&lt;/p&gt; 
&lt;p&gt;針對數據行級更新，Iceberg 提供了兩種策略，分別為 COW(Copy on Write： 寫時複製) 或 MOR (Merge on Read：讀時合併)，其中 MOR 根據其標記刪除文件的區別又細分了兩種方式（Equality Delete File 和 Position Delete File）。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新策略&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新後的讀取效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新時寫入效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;適用場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;備註&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;COW&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最慢&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;讀多寫少場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;﻿&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 標記條件刪除（&lt;/span&gt; 
         &lt;span&gt;&lt;span style="color:#191b1f"&gt;&lt;span&gt;Equality Delete File&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
         &lt;span&gt;）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;較快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;寫入多、讀取少場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;讀開銷：每次讀取數據需要額外讀取標記刪除列數據進行比較。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;寫開銷：只需要存儲標記過濾數據的條件，寫入成本極低。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 標記位置刪除（Position Delete File）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;快（依賴更新數據量）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;較快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;少量數據更新、讀取少場景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;讀開銷：加載每個文件需過濾的數據行號。（刪除行過多，影響性能）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;寫開銷：需要掃描一遍原數據，找出待刪除數據的行號。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;關於 COW 和 MOR 更新策略的文件表現形式如下圖所示，我們針對不同場景採用不同更新策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;對於日常數據查詢分析場景，小時級&amp;amp;天級離線例行生成加工場景，由於查詢次數會遠多於數據更新次數，可默認採用 COW 策略；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對一些業務更新少量字段進行長週期回溯場景，以及實時場景，寫入頻繁，通過使用 MOR 策略，來支持用户進行數據回溯變更字段信息，以提升數據更新效率並節省資源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082e448b69e5bbdb64cc8dbc417fdcbe04d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△COW 和 MOR 兩種更新策略對比&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45b92197037fdcbd76356145ee09137730c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△MOR 兩種刪除文件類型&amp;amp;更新字段示例&lt;/p&gt; 
&lt;p&gt;在業務進行數據回溯應用過程中，我們採用 MOR(Position Delete File) 進行行級數據更新，通過原 Hive 回溯和新 Iceberg 回溯兩種方式對比，在一天 24 小時不同分區上，驗證了 Hive 和 Iceberg 新舊的回溯效率，如下圖所示，業務回溯效率整體可平均提升 50%+；進一步地對比單次回溯一年數據消耗的計算資源量對比，平均整體降低 70%+的計算資源消耗，整體上極大提升回溯效率，並降低資源成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ec2f7bfd27359aea682e96ed16bd8438b28.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△ Hive 和 Iceberg 回溯效率對比&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.3 Iceberg 表生命週期管理和性能優化&lt;/h3&gt; 
&lt;p&gt;在 Iceberg 應用實踐的過程中，針對不同業務場景遇到的問題，我們彙總如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件過多：在實時湖倉業務場景，為了要保證數據的時效性，通常是分鐘級別的 commit 操作，在這種場景下，單個作業執行一天，則需要 1440 個 commit，如果執行時間更長，則會產生更多的 commit，隨着時間的累積，元數據以及數據文件等都會產生大量的小文件，對於整體查詢的性能會產生一定的影響。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;存儲資源增加：如果 iceberg 表的快照不及時進行清理，可能會造成數據存儲增加，導致存儲賬號資源緊張。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺乏分區數據統一管理：在一些業務場景，只需要保存一定天數的分區數據，針對無用數據需要進行刪除處理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據文件組織不均衡且無序：由於表數據寫入是隨機無序，且針對表數據文件大小會存在不均衡的情況。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;針對上述問題，我們通過對 Iceberg 表進行全生命週期管理，並結合 Iceberg 特性優化表查詢性能，保障整個數據鏈路的穩定性，整體框架如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6f3d4d018567c082ed09d5addc93eb145e6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表生命週期管理和性能優化流程&lt;/p&gt; 
&lt;p&gt;以上流程主要包含表數據生命週期管理和表性能優化兩部分。&lt;/p&gt; 
&lt;p&gt;一方面，對於表數據生命週期管理，我們通過在線服務執行定時任務，來實現對錶數據和元數據進行全生命週期監控，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;數據分區過期：基於用户配置的表生命週期，進行分區數據刪除，保證數據文件按期清理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元數據快照清理：為用户提供按照時間維度天級別和按照個數維度小時級別兩種快照過期策略，精細化元數據快照過期處理，實現存儲資源的高效利用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元數據孤兒文件清理：通過天級例行任務來觸發清理由於計算引擎執行任務失敗等情況產生的一些沒有被引用的孤兒文件，避免元數據累積影響性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一方面，在表性能優化方面，我們結合圖靈數倉表使用情況，並基於 Iceberg 原生特性，為用户在平台側提供 Iceberg 表優化算子（如下圖示例），主要包含以下兩種能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件合併：通過制定合併文件大小，對錶數據文件進行重寫合併，避免產生大量小文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;z-order 排序優化：實現對錶相關字段進行重排序，提升查詢性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ba76a39d6a2f835b0d8fb1866416f21a652.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表優化算子任務創建示例&lt;/p&gt; 
&lt;p&gt;我們通過對 Iceberg 表整體的生命週期管理，實現了數據和元數據的統一治理，表元數據小文件數萬個降低到數百級別，合理控制了元數據產生的數量，並解決了數據頻繁回溯場景下存儲快速增加的問題。而在表查詢優化方面，通過在一些表的數據重分佈和字段重排序應用，在部分業務表查詢性能提速 50%。&lt;/p&gt; 
&lt;span id="OSC_h1_16"&gt;&lt;/span&gt; 
&lt;h1&gt;03 未來規劃&lt;/h1&gt; 
&lt;p&gt;Iceberg 作為圖靈 3.0 生態中的重要組成部分，基於其高時效性、行級更新能力、小文件合併以及 Z-order 等成體系的數據優化的技術解決方案，為 MEG 數據中台業務提供構建湖倉一體，解決數據回溯等痛點問題的能力。目前 Iceberg 的應用已覆蓋搜索，商業，銷售，用增架構等多個業務線，通過低成本助力業務將存量 Hive 遷移 Iceberg 表，為業務提供高性能數據查詢，同時實現對業務的降本增效。此外，我們也在不斷完善 Iceberg 數據存儲引擎的各項能力，包含表數據智能治理、查詢優化、智能索引以及特定場景的性能問題等，並不斷擴大 Iceberg 的業務覆蓋範圍。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18679436</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18679436</guid>
      <pubDate>Fri, 09 May 2025 10:17:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>RWKV 社區六月動態：多次亮相高規格活動，適合混合架構的新特性發布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;歡迎大家收看《RWKV 社區最新動態》，本期內容收錄了 RWKV 社區 2025 年 6 月的最新動態。&lt;/p&gt; 
&lt;p&gt;只需 3 分鐘，快速瞭解 RWKV 社區 6 月都有哪些新鮮事！&lt;/p&gt; 
&lt;h2&gt;6 月動態省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新聞動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV-8 系列之 DeepEmbedAttention 發佈&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 學術研究動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新論文：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation（基於 RWKV 的醫學視頻生成，已被 &lt;strong&gt;MICCAI 2025 提前接收&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：Pan-Sharpening via Causal-Aware Feature Distribution Calibration（基於 RWKV 的全色鋭化，一區頂刊 &lt;strong&gt;TGRS&lt;/strong&gt; 接收）&lt;/li&gt; 
   &lt;li&gt;新論文：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration（基於 RWKV 的低光照圖像恢復，已入選 &lt;strong&gt;CVPR 2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新論文：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing（RWKV 的視覺語言模型，發表於 JCR Q1 期刊 Information Fusion）&lt;/li&gt; 
   &lt;li&gt;新論文：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection（遙感變化檢測，IEEE TAES 接收）&lt;/li&gt; 
   &lt;li&gt;新論文：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR（基於 RWKV 的語音識別，Interspeech 2025 接收）&lt;/li&gt; 
   &lt;li&gt;新論文：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV（基於 RWKV 的音樂生成）&lt;/li&gt; 
   &lt;li&gt;新論文：Out-of-Distribution Semantic Occupancy Prediction（引入 RWKV 增強特徵的 3D 語義佔用預測）&lt;/li&gt; 
   &lt;li&gt;新論文：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification（基於 RWKV 的量子增強圖像分類）&lt;/li&gt; 
   &lt;li&gt;新論文：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation（基於 RWKV 的醫學圖像分割）&lt;/li&gt; 
   &lt;li&gt;新論文：Exploring Diffusion with Test-Time Training on Efficient Image Restoration（基於 RWKV 的圖像修復）&lt;/li&gt; 
   &lt;li&gt;新論文：Relational Context Modeling for Improved Knowledge Graph Completion（混合 RWKV 架構的知識圖譜補全）&lt;/li&gt; 
   &lt;li&gt;新論文：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation（基於 RWKV 的醫學圖像分割）&lt;/li&gt; 
   &lt;li&gt;新論文：RWKV-IF: Efficient and Controllable RNA Inverse Folding via Attention-Free Language Modeling（基於 RWKV 的 RNA 逆折疊）&lt;/li&gt; 
   &lt;li&gt;新論文：A Parallel Processing Architecture for Long-Term Power Load Forecasting（基於 RWKV 的長期電力負荷預測）&lt;/li&gt; 
   &lt;li&gt;新論文：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance（集體運動臨界性盲識別）&lt;/li&gt; 
   &lt;li&gt;新論文：融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法（基於 RWKV 的醫學影像分割）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區項目動態&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;rwkv_Ascend（RWKV 和昇騰共建的算子庫）&lt;/li&gt; 
   &lt;li&gt;rwkv7-g1-1.5b-instruct-preview（RWKV 的後訓練模型）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社區市場活動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 參加亞馬遜雲科技中國峯會&lt;/li&gt; 
   &lt;li&gt;RWKV 參加 RTE Open Day&lt;/li&gt; 
   &lt;li&gt;RWKV 參加魔搭開發者大會&lt;/li&gt; 
   &lt;li&gt;RWKV 參加 GAIC 全球互聯網架構大會&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相上海開源創新箐英薈&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相國際技術進出口交易會&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相香港 NovaX 國際創投嘉年華&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 模型新聞動態&lt;/h2&gt; 
&lt;h3&gt;RWKV-8 系列之 DeepEmbedAttention&lt;/h3&gt; 
&lt;p&gt;5 月 27 日，我們公開了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首個新特性 DeepEmbed：對端側友好的稀疏設計，解決 MoE 顯存佔用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;6 月 30 日，與其相關的另一個新特性 DeepEmbedAttention（DEA）也正式公佈。這是一種基於 RWKV-8 DeepEmbed 思路的注意力變體，擁有極小的 KV 緩存，尤其適合混合模型（例如後續的 RWKV-7s 混合模型），可將它們的長上下文性能提升到 Transformer 水準。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="DeepEmbedAttention-loss" src="https://oscimg.oschina.net/oscnet/up-1df5adeb74b9c9eb0c3f35fe35e39185bf0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;詳細報道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;RWKV-8 系列之 DeepEmbedAttention：精簡 KV 緩存，尤其適合混合模型（RWKV-7s）&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RWKV 學術研究動態&lt;/h2&gt; 
&lt;p&gt;RWKV 學術研究包括 &lt;strong&gt;基於 RWKV 架構的新論文&lt;/strong&gt; 或 &lt;strong&gt;RWKV 社區參加的學術研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;FEAT&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.04956" target="_blank"&gt;https://arxiv.org/abs/2506.04956&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型架構中的 WKV 注意力機制，提出了 FEAT 模型，通過統一的空間-時間-通道注意力機制解決醫療視頻生成中通道交互不足、計算複雜度高和去噪指導粗糙的問題。在多個數據集上實現了高效高質量的醫療視頻生成。&lt;/p&gt; 
&lt;p&gt;該項工作十分新穎和出色，已經以 top9% 的評分提前入選 &lt;strong&gt;MICCAI 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250605-FEAT" src="https://oscimg.oschina.net/oscnet/up-467d7594221b6e113f5533aa24c0fe733fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11023855" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11023855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-04&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種新的全色鋭化方法，通過因果推斷解決網絡優化中的頻率不平衡問題。該方法在訓練階段利用 RWKV 架構的全局感受野，有效學習高頻分量的長尾分佈，並量化特徵偏差的累積方向。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，該方法在多個基準數據集上均優於現有先進方法，展示了其在全色鋭化任務中的有效性和魯棒性。&lt;/p&gt; 
&lt;p&gt;文中方法在全色鋭化任務中有出色的表現，已入選一區頂刊 &lt;strong&gt;IEEE Transactions on Geoscience and Remote Sensing&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250604-Pan-Sharpening_via_Causal-Aware_Feature_Distribution_Calibration" src="https://oscimg.oschina.net/oscnet/up-eec12432c41aab67b1095296c7aa214168b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.23068" target="_blank"&gt;https://arxiv.org/abs/2505.23068&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型，提出了一種統一的多狀態視角模型 URWKV，用於低光照圖像恢復。該模型通過定製化的 URWKV 塊感知和分析複雜退化，利用多階段狀態實現自適應場景感知的亮度調製。顯著提升了性能。&lt;/p&gt; 
&lt;p&gt;論文受到廣泛認可，已入選 &lt;strong&gt;CVPR 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-URWKV" src="https://oscimg.oschina.net/oscnet/up-b0e6fa626bfa9e998ebf650bc70d4c9f7ee.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;VisualRWKV-HM&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1566253525004099" target="_blank"&gt;https://www.sciencedirect.com/science/article/pii/S1566253525004099&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="20250606-VisualRWKV-HM" src="https://oscimg.oschina.net/oscnet/up-2d4c04b5430391084f2b0de8de9a7905587.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了 VisualRWKV-HM，這是一種具有線性複雜度的視覺語言模型，在單圖像、多圖像和多視圖基準測試中均達到了 SOTA 性能。&lt;/p&gt; 
&lt;p&gt;與基於 Transformer-Mamba 架構的混合模型 LongLLaVA 相比，它在上下文長度為 16K 時消耗的內存更少，吞吐量提高了 24%。此外，VisualRWKV-HM 具有良好的可擴展性，通過擴展狀態編碼器和解碼器，可以進一步提高性能。&lt;/p&gt; 
&lt;h3&gt;SMNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11039697" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11039697&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型和 Mamba 架構提出了一種新的遙感變化檢測模型 SMNet，該模型通過整合多層次特徵表示，有效解決了當前方法在變化檢測任務中性能有限和特徵表達能力不足的問題。SMNet 利用 RWKV 的多方向 WKV 注意力機制和 Mamba 的空間架構，增強了模型處理語義信息的能力。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，SMNet 在多個遙感變化檢測基準數據集上表現出色，顯著優於現有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250618-SMNet_A_Semantic_Guided" src="https://oscimg.oschina.net/oscnet/up-56b21424d56741e3598d42c23708a33f28e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.19761" target="_blank"&gt;https://arxiv.org/abs/2506.19761&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文研究了將多頭注意力（MHA）替換為雙向循環注意力（RA）在長語音識別（ASR）中的應用，發現雙向 RWKV-Conformer 模型在保持相似準確率的同時，效率更高。通過引入 Direction Dropout 方法，進一步提升了模型的靈活性和性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250624-Accurate,fast,cheap" src="https://oscimg.oschina.net/oscnet/up-9e59775226d89bf420c19693e382a38938d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MIDI-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.13001" target="_blank"&gt;https://arxiv.org/abs/2506.13001&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了 MIDI-RWKV ，一個用於個性化、多軌道、長上下文和可控符號音樂填充的新型模型。該模型採用 RWKV-7 線性架構，能夠在邊緣設備上實現高效且連貫的音樂協同創作。MIDI-RWKV 通過微調初始狀態實現了在極小樣本條件下的個性化。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，MIDI-RWKV 在多項定量和定性指標上均優於現有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-MIDI-RWKV" src="https://oscimg.oschina.net/oscnet/up-059e2194193005d16941dfb46b2a50126d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Out-of-Distribution Semantic Occupancy Prediction&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Out-of-Distribution Semantic Occupancy Prediction&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.21185" target="_blank"&gt;https://arxiv.org/abs/2506.21185&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這篇論文為解決自動駕駛中的"意外"物體識別難題，創新性地引入 RWKV 架構來強化模型的特徵感知力，並提出了 OccOoD 框架。它巧妙融合了精細的 3D 體素和全局的鳥瞰圖視角，能更準確地判斷異常。為了訓練和驗證模型，作者還獨創性地構建了合成異常數據集.&lt;/p&gt; 
&lt;p&gt;實驗結果表明，在不影響常規物體識別性能的前提下，實現了對未知風險的精準捕獲。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250626-Out-of-Distribution Semantic Occupancy Prediction" src="https://oscimg.oschina.net/oscnet/up-541580df9785f32fdb7111c003976df721d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Vision-QRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.06633" target="_blank"&gt;https://arxiv.org/abs/2506.06633&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-07&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種量子增強的混合架構 Vision-QRWKV，用於圖像分類任務。通過將變分量子電路（VQC）集成到 RWKV 的通道混合組件中，模型提升了非線性特徵轉換能力。&lt;/p&gt; 
&lt;p&gt;實驗表明，該模型在多個醫療和標準圖像數據集上表現優於經典模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250607-Vision-QRWKV" src="https://oscimg.oschina.net/oscnet/up-669a60a01e8d0426df73da6bbf8f6477034.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Diet-Seg&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.05.31.657149v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.05.31.657149v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-03&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種新型腦腫瘤分割框架 Diet-Seg，通過將基於熵的像素級難度估計與動態學習率調節策略結合，有效提升了腦腫瘤分割的準確性。Diet-Seg 框架採用 RWKV-UNet 作為主幹網絡，以捕捉全局空間依賴性。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，Diet-Seg 在 BraTS2018--2021 數據集上表現優於現有方法，特別是在腫瘤子區域的分割上取得了顯著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250603-Diet-Seg Dynamic" src="https://oscimg.oschina.net/oscnet/up-4e65bcaea7495f4a3f7ef38e13fafaed70c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DiffRWKVIR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Exploring Diffusion with Test-Time Training on Efficient Image Restoration&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.14541" target="_blank"&gt;https://arxiv.org/abs/2506.14541&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-17&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了 DiffRWKVIR 框架，該框架將測試時訓練（TTT）與高效擴散相結合，通過 Omni-Scale 2D 狀態演化擴展 RWKV 的位置依賴參數化，實現全局上下文感知，並通過塊優化閃存處理加速計算，最終在圖像修復任務中超越現有方法，顯著提升了效率和效果。&lt;/p&gt; 
&lt;p&gt;該論文還提出了先驗引導的高效擴散方法，通過提取緊湊的圖像先驗表示，加速了訓練和推理過程，同時解決了傳統擴散模型中的計算低效問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250617-Exploring Diffusion with Test-Time Training on Efficient Image Restoration" src="https://oscimg.oschina.net/oscnet/up-185f166afa6a20a24ff6dfbff5ca302ec83.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RCME&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Relational Context Modeling for Improved Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.engineeringletters.com%2Fissues_v33%2Fissue_6%2FEL_33_6_28.pdf" target="_blank"&gt;https://www.engineeringletters.com/issues_v33/issue_6/EL_33_6_28.pdf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型和 TuckER 模型，提出了一種名為 RCME 的混合架構，用於改進知識圖譜補全。RCME 結合了 RWKV 的序列建模能力和動態嵌入生成，以及 TuckER 的關係解碼魯棒性，在鏈接預測和三元組分類任務中表現優於多種先進模型。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，該架構在多個基準數據集上均取得了顯著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250601-Relational Context Modeling for Improved" src="https://oscimg.oschina.net/oscnet/up-3df836cf1461d197114ffa8bce7c49241b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Med-URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.10858" target="_blank"&gt;https://arxiv.org/abs/2506.10858&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-12&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文基於 RWKV 模型提出了一種名為 Med-URWKV 的純 RWKV 架構，該架構基於 U-Net 框架構建，並融入了基於 ImageNet 的預訓練，以進一步探索 RWKV 在醫學圖像分割任務中的潛力。&lt;/p&gt; 
&lt;p&gt;研究通過在七個數據集上的實驗，驗證了 Med-URWKV 在醫學圖像分割任務中的有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250612-Med-URWKV" src="https://oscimg.oschina.net/oscnet/up-5b67fb50ae77f12d7a02f9c6fa831e31496.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-IF&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.06.13.659654v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.06.13.659654v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV 模型提出了一種名為 RWKV-IF 的高效可控 RNA 逆折疊框架，通過將結構到序列的生成建模為條件語言建模任務，以線性複雜度捕獲長程依賴關係。研究引入了一種解碼策略，結合 Top-k 採樣、温度控制和 G-C 含量偏向，生成結構準確且具有生物物理意義的序列。顯著優於傳統搜索基線方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250614-RWKV-IF" src="https://oscimg.oschina.net/oscnet/up-a3f69a2c1c24040e3bee2df1570eebd2a19.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MP-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：A Parallel Processing Architecture for Long-Term Power Load Forecasting&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F2673-4591%2F97%2F1%2F26" target="_blank"&gt;https://www.mdpi.com/2673-4591/97/1/26&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV-TS 模型提出了 MP-RWKV，通過並行處理路徑解決長期電力負荷預測中不同預測範圍的挑戰。MP-RWKV 通過上下文狀態機制和位置感知注意力機制，在短期和長期預測場景中均表現出色。&lt;/p&gt; 
&lt;p&gt;實驗結果表明，MP-RWKV 在 24 小時至 432 小時的預測範圍內均優於現有基準模型，尤其在傳統模型性能下降的長期預測中表現突出。顯著提升了長期電力負荷預測的準確性和穩定性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-A Parallel Processing Architecture for Long-Term Power Load Forecasting" src="https://oscimg.oschina.net/oscnet/up-1cd2d5a4b1ab3666aacf1439e4e1a8c45c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Blind Identification&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5297784" target="_blank"&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5297784&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基於 RWKV-7 序列模型提出了一種無參數的集體運動臨界性識別方法，通過分析單智能體軌跡數據來檢測 Vicsek 模型中的臨界區域。&lt;/p&gt; 
&lt;p&gt;該方法利用預測香農熵的方差作為指標，無需系統控制參數或全局信息，成功在 L=32 和 L=64 系統中識別出臨界噪聲水平，且結果符合有限尺寸縮放原理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance" src="https://oscimg.oschina.net/oscnet/up-80916e606288454a3f41baab295cf426a08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文名稱：融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biomedeng.cn%2Farticle%2F10.7507%2F1001-5515.202412009" target="_blank"&gt;https://www.biomedeng.cn/article/10.7507/1001-5515.202412009&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;發佈日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;論文提出了一種融合接收加權鍵值架構（RWKV）和球面幾何特徵（SGF）採樣技術的甲狀腺結節分割方法。該方法通過二維偏移預測和像素級採樣位置調整，有效捕捉鄰近區域細節，實現精確分割。同時，本研究引入了區塊注意力模塊（PAM），利用區域交叉注意力機制優化解碼器特徵圖，使其更精確關注編碼器的高分辨率特徵。&lt;/p&gt; 
&lt;p&gt;在甲狀腺結節區域分割數據集（TN3K）和甲狀腺影像數字數據庫（DDTI）上的實驗表明，本文所提方法的戴斯相似係數（DSC）分別達到 87.24% 和 80.79%，優於現有模型，且計算複雜度較低，或可為甲狀腺結節精確分割提供一種高效解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-融合接收加權鍵值架構和球面幾何特徵的甲狀腺結節分割方法" src="https://oscimg.oschina.net/oscnet/up-ab6be27562fe5cd66667ddfadbe4265a5c9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社區活動&lt;/h2&gt; 
&lt;h3&gt;RWKV 參加亞馬遜雲科技中國峯會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 19 日，RWKV 團隊受邀出席於上海舉辦的亞馬遜雲科技中國峯會，並榮膺「智創未來」領航獎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="AMZ-1" src="https://oscimg.oschina.net/oscnet/up-f86080aa51519b5f93f947f0abf82dddc3c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 參加 RTE Open Day&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 21 日至 22 日，北京，一場屬於技術人的盛會------RTE Open Day 拉開帷幕。RWKV 團隊與來自全國的技術愛好者和開發者們齊聚一堂，展示前沿應用，共話 AGI 的無限可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RTE Openday AGI Playground-3" src="https://oscimg.oschina.net/oscnet/up-b3b31a96ba8288b0c7b1da1bb4fc8d1d81b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 參加魔搭開發者大會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日，在國家信息中心指導、魔搭社區主辦的 2025 魔搭開發者大會上，RWKV 團隊受邀出席。團隊與廣大開發者深入分享了 RWKV 的最新進展與架構的核心亮點，共探 AI 技術的新可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="ModelScope-2" src="https://oscimg.oschina.net/oscnet/up-c4cf19d1c15dd0f606d0a8e16b9b6a283f2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 參加 GAIC 全球互聯網架構大會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 14 日，在全球互聯網架構大會上，RWKV 團隊深度解析了 RWKV 最新架構在精度、顯存佔用及運算速度等方面的核心優勢，並面向公眾分享了簡單易用的基於 RWKV 進行微調、推理與多模態開發的最佳實踐。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="GIAC-1" src="https://oscimg.oschina.net/oscnet/up-62a00f9d678a10835a9faac67b61310ad08.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相上海開源創新箐英薈&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 28 日，RWKV 團隊出席由上海開源信息技術協會主辦的 2025 上海開源創新箐英薈，並憑藉其卓越的技術貢獻和活躍的社區生態，榮獲主辦方頒發的"優秀開源項目獎"。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-1" src="https://oscimg.oschina.net/oscnet/up-059448850eedb205228e74d972e9cc20be4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-2" src="https://oscimg.oschina.net/oscnet/up-1dccb3bfe4475ff6bdb9e7b19d5de026d95.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相國際技術進出口交易會&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 11 日至 13 日，RWKV 團隊攜其創新成果亮相上海世博展覽館，出席（上海）國際技術進出口交易會。會上，團隊向與會者展示了 RWKV 在端側部署、低資源消耗及可持續學習等方面的卓越優勢，引發廣泛關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="CSITF-1" src="https://oscimg.oschina.net/oscnet/up-aca0e633ac77f03ce72e551535a52187854.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相香港 NovaX 國際創投嘉年華&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日至 7 月 1 日，RWKV 團隊登陸香港，在 NovaX Global Investmatch Carnival 國際創投嘉年華 2025 的舞台上，與全球頂尖的創投機構和行業領袖齊聚一堂，共同探討 AI 技術的商業前景與未來機遇。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="NovaX-1" src="https://oscimg.oschina.net/oscnet/up-e8e859c258f108b8ebb09921dd3b78b4edb.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社區項目動態&lt;/h2&gt; 
&lt;h3&gt;rwkv_Ascend&lt;/h3&gt; 
&lt;p&gt;cann-ops-rwkv 是 RWKV 與昇騰共建的算子倉庫，歡迎 rwkv 愛好者學習、使用和魔改的 RNN attention（rwkv、fla）系列算子代碼。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;項目地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fappleinsky%2Frwkv_Ascend" target="_blank"&gt;https://github.com/appleinsky/rwkv_Ascend&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;rwkv7-g1-1.5b-instruct-preview&lt;/h3&gt; 
&lt;p&gt;此項目是 RWKV7-G1 1.5B 的後訓練模型，強化了指令遵循能力和中文能力，同時擁有更高的情商。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FSeikaijyu%2Frwkv7-g1-1.5b-instruct-preview" target="_blank"&gt;https://hf-mirror.com/Seikaijyu/rwkv7-g1-1.5b-instruct-preview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="RWKV7-G1-1.5B-instruct" src="https://oscimg.oschina.net/oscnet/up-beed0d3d6a0e327fb38fe4d0b43057e9996.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358194</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358194</guid>
      <pubDate>Fri, 09 May 2025 08:39:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Ubuntu Debcrafters 團隊成立，旨在維護 Ubuntu 檔案庫健康</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Canonical 工程副總裁 Jon Seager 發文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fintroducing-debcrafters%2F63674" target="_blank"&gt;宣佈&lt;/a&gt;&amp;nbsp;Ubuntu Debcrafters 團隊的成立。主要目標在於維護 Ubuntu 檔案庫的健康，但也旨在吸引廣泛的 Linux 發行版專業人才。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 表示，其鼓勵 Debian、Arch Linux、NixOS 等發行版的貢獻者加入 Debcrafters&amp;nbsp;團隊，貢獻的同時還可以獲得報酬，並促進學習和想法共享。該團隊由 Debian 開發人員、穩定版本更新 (SRU) 團隊成員和檔案管理員組成，並於 2025 年 5 月初首次開始合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-0e0b14cf8de1e9a97b9c9dba65bf6513bb0.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 在 Debcrafters 公告中解釋道：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;Debcrafters 的主要使命是維護 Ubuntu 檔案的健康。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;該團隊將負責同步和合並來自 Debian 的軟件包、審查提議的遷移問題、上游 Ubuntu 增量，並負責重大轉變，例如升級到 glibc 和過去的示例，例如 t64 和 python3 轉變。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他們將管理存檔測試重建的調度、觸發和報告，這些重建工作在我們對關鍵軟件包進行重大更改時進行。我們在默認啓用框架指針時以及切換 coreutils 到 uutilsUbuntu 25.10 中的實現時都執行了這些操作。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他們將負責 autopkgtestUbuntu 基礎架構的演變和維護，並在引入更多發行版規模的集成測試方面發揮重要作用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他們將致力於改進 Ubuntu 檔案庫、其貢獻者和狀態的報告和儀錶板，並對塑造我們用於構建和塑造 Ubuntu 的工具產生更廣泛的興趣。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;這支團隊與桌面、服務器和基礎團隊的不同之處在於，他們處理的軟件包範圍非常廣泛。Debcrafters 團隊的成員每個週期都會遷移數千個軟件包——其中許多軟件包他們並不十分熟悉，但他們將運用不斷提升的發行版維護和打包技能，在沒有其他明確或現有所有者的情況下進行維護。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358188/ubuntu-debcrafters</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358188/ubuntu-debcrafters</guid>
      <pubDate>Fri, 09 May 2025 08:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟被曝將「AI 使用量」納入員工考核，直接掛鈎績效</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-internal-memo-using-ai-no-longer-optional-github-copilot-2025-6" target="_blank"&gt;根據《商業內幕》的報道&lt;/a&gt;，微軟開發者工具部門總裁 Julia Liuson 最近發出內部郵件，要求各級主管在評估員工績效時，將其使用 GitHub Copilot 等內部 AI 工具的情況納入考量。&lt;/p&gt; 
&lt;p&gt;Liuson 表示，AI 已成為微軟日常工作的核心，就像團隊協作、數據導向思維和溝通能力一樣，使用 AI 不再是選擇題，而是每個崗位的基本要求。她指出，員工是否有效使用 AI，應該被納入對其整體表現和影響力的全面評估之中。&lt;/p&gt; 
&lt;p&gt;具體執行框架如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;基礎合規層&lt;/strong&gt; ：要求員工在郵件撰寫、會議記錄、代碼開發等高頻場景 100% 啓用 Copilot 基礎功能，系統自動記錄使用時長和任務覆蓋率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;效能增值層&lt;/strong&gt; ：按崗位類型設定差異化 KPI，如開發人員需實現 30% 代碼由 Copilot 生成，銷售部門需達成 AI 優化提案的成交率提升指標。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;創新應用層&lt;/strong&gt; ：將員工使用 Copilot 開發新工作流程或業務解決方案的實踐成果，納入晉升評估加分項。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;知情人士透露，微軟各團隊的績效考核標準不盡相同，目前已有部分團隊考慮在下一個財年正式將 AI 工具使用情況作為績效指標之一。另據兩位瞭解內情的人士稱，這一改變旨在應對微軟內部 Copilot 服務推廣緩慢的問題。微軟希望提升整體使用率，也希望產品開發人員更深入理解自家 AI 工具的運作方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</guid>
      <pubDate>Fri, 09 May 2025 08:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 將其 AI 部門重組為 「超級智能實驗室」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 公司首席執行官馬克-扎克伯格（Mark Zuckerberg）正在重組公司的人工智能工作，以打造人工智能 「superintelligence」為中心。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fzuckerberg-announces-meta-superintelligence-effort-more-hires%3Fsrnd%3Dundefined" target="_blank"&gt;彭博社&lt;/a&gt;報道，其從該公司於週一發出的一份內部備忘錄得知，Meta 公司所有從事人工智能工作的團隊今後都將隸屬於一個名為 Meta 超級智能實驗室（Meta Superintelligence Labs）的新團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="366" src="https://oscimg.oschina.net/oscnet/up-44145dfdb97dd1159efb1314b8297ede5e1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「超級智能實驗室」 將由前 Scale AI 首席執行官亞歷山大・王（Alexandr Wang）擔任首席人工智能官，負責整體方向與管理。他將與 GitHub 前首席執行官納特-弗裏德曼（Nat Friedman）合作，後者將負責 Meta 的人工智能產品和應用研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格一直在努力在人工通用智能（AGI）競賽中取得領先，主要是通過收購人工智能公司和頂級人工智能公司的員工。本月早些時候，Meta 向 Scale AI 投資了 143 億美元，並在此過程中引入了 Wang。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers" target="news"&gt;Meta 成功挖角三名 OpenAI 研究人員&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357940" target="news"&gt;OpenAI 被曝將重新調整薪酬以應對 Meta 挖人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358181/meta-superintelligence-labs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358181/meta-superintelligence-labs</guid>
      <pubDate>Fri, 09 May 2025 07:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟開源 GitHub Copilot Chat 的 VS Code 擴展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟在 5 月舉辦的開發者大會上&lt;a href="https://www.oschina.net/news/350732/ms-vs-code-open-source-ai-editor"&gt;宣佈&lt;/a&gt;要將 VS Code 打造成開源 AI 編輯器，近日該計劃達成了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fblogs%2F2025%2F06%2F30%2FopenSourceAIEditorFirstMilestone" target="_blank"&gt;首個里程碑&lt;/a&gt;——GitHub Copilot Chat 的 VS Code 擴展采用 MIT 開源許可證正式開源。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1098" src="https://static.oschina.net/uploads/space/2025/0701/153012_qXMd_2720166.png" width="2460" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-chat" target="_blank"&gt;https://github.com/microsoft/vscode-copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該擴展提供了類似 Cursor 的 Chat 面板，通過聊天的方式來編輯代碼，它還可以根據代碼提交者、變量和斜線命令等信息，給出與代碼庫相關的回答。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a176b7fa906f848e0f9b0982762510cc49.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-190bfc8a0cc77c524892684d44d95a0f15c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;擴展地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat" target="_blank"&gt;https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;由於 Copilot Chat 與 VS Code 深度集成，其發佈與 VS Code 同步進行，因此每個新版本的 Copilot Chat 僅兼容最新版本的 VS Code。這意味着如果你使用的是舊版本的 VS Code，將無法使用最新的 Copilot Chat。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358178</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358178</guid>
      <pubDate>Fri, 09 May 2025 07:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節、騰訊、阿里等 13 家頭部企業去年利潤總額同比增 19.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;5 月底結束的 2024 年度企業所得税彙算清繳數據顯示，字節跳動、騰訊、阿里巴巴等 13 家頭部企業營業收入和利潤總額同比分別增長 11.9%、19.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上述企業是數字經濟領域的代表企業，彙算清繳數據顯示，2024 年度，數字經濟及其核心產業營業收入和利潤總額同比分別增長 5.9%、2.7%。其中，信息傳輸、軟件和信息技術服務業營業收入和利潤總額同比分別增長 11.5%、13.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除數字經濟外，2024 年度，醫藥製造、航空航天等高技術產業營業收入和利潤總額同比分別增長 8.9%、7.5%。細分行業看，科學研究和技術服務業營業收入和利潤總額同比分別增長 11.7%、7.5%，航空航天產業營業收入和利潤總額同比分別增長 10.5%、26.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，機器人產業也步入發展快車道，近兩年機器人產業營業收入平均同比增長 10.2%。其中，特殊作業機器人、服務消費機器人、工業機器人 2024 年度同比分別增長 28.4%、12.4%、7%，多場景應用加速落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;總體上看，數字經濟、高技術產業、機器人產業三個領域 2024 年度共減免企業所得税 1.97 萬億元，總營業收入同比增長 7.1%，利潤總額同比增長 5.2%，我國新質生產力持續發展壯大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家税務總局相關負責人表示，税務部門將不折不扣落實落細結構性減税降費政策，同時，依法嚴厲打擊違規享受、惡意騙取税費優惠等違法行為，堅決防止政策「紅包」落入不法分子「腰包」。（新京報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358163</guid>
      <pubDate>Fri, 09 May 2025 06:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻數科面向香港市場開放四大自研技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻數科面向香港市場開放四大自研技術——Layer2 網絡、大模型開發工具、「區塊鏈+IoT」可信架構、機構級 Web3 錢包技術，為香港建設全球數字資產創新中心提供全棧技術服務。&lt;/p&gt; 
&lt;p&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-e94b03fe5b81530ba178b109352a29a4037.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;資料顯示，螞蟻數科自 2016 年起投入區塊鏈技術研發，全球區塊鏈授權專利排名第一，核心技術如智能合約、網絡傳輸、存儲引擎、跨鏈技術等已取得重大突破，處於全球領先水平。此前，螞蟻數科作為核心成員加入香港金管局 Ensemble 沙盒，並宣佈將海外總部落户香港。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358160</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358160</guid>
      <pubDate>Fri, 09 May 2025 05:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>加鎖失效，非鎖之過，加之錯也</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：京東零售，邢成&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;多個進程或線程同時 (或着説在同一段時間內) 訪問同一資源會產生併發問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;銀行兩操作員同時操作同一賬户就是典型的例子。比如 A、B 操作員同時讀取一餘額為 1000 元的賬户，A 操作員為該賬户增加 100 元，B 操作員同時為該賬户減去 50 元，A 先提交，B 後提交。 最後實際賬户餘額為 1000-50=950 元，但本該為 1000+100-50=1050。&lt;strong&gt;這就是典型的併發問題&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;從事零售供應鏈庫存業務，對庫存數量操作增減十分頻繁，同樣存在類似上述銀行取款遇到的問題，庫存數量操作有誤勢必給前台銷售產生損失影響，因此需要關注對庫存數量併發操作下的一致性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;下面通過一個真實的案例分享在併發情況下如何保證庫存數量的準確性。&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;問題是什麼-加鎖失效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;看看下面這段流程和代碼，思考會有併發問題嗎？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c52b6c3f660ed58046c9e16a5be9c444.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;加鎖前&lt;/strong&gt; &lt;strong&gt;，獲取箱子明細數據，此處在鎖之外，存在併發髒讀問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//1036ef25fae37b26c448522f6777c80c.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;加鎖後&lt;/strong&gt; &lt;strong&gt;，並進行箱子上架分批次回傳業務處理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//020a84a9615ca8e8cec22118aefca76f.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;加鎖後，&lt;/strong&gt; &lt;strong&gt;更新箱子明細上架數量邏輯：已上架數量 = 加鎖前的明細數據（髒讀） + 報文回傳的明細數據，直接進行行更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//21d80ae4a594960a582dde2c19321099.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;原因是什麼-加鎖的位置不正確&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//20d9ce564f5386039bb12242e16ef05b.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心的問題原因&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;業務分佈式鎖失效：&lt;/strong&gt; 使用分佈式鎖加鎖了，但是仍然使用加鎖前查詢的數據，導致出現髒讀&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;Mysql 鎖失效：&lt;/strong&gt; 數據庫更新時，未上任何鎖，導致髒讀的數據直接覆蓋更新當前行&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有同學這時問了，為啥防重碼也沒有生效呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;防重碼主要是用作冪等邏輯的，同一個請求多次處理，結果仍然是相同的。&lt;/p&gt; 
&lt;p&gt;但是這是兩次不同的請求，防重碼是不同的，因此不能只依賴防重碼保證一致性。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;解決方案有哪些&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1、代碼層面：&lt;/strong&gt; 使用鎖（如互斥鎖、讀寫鎖、分佈式鎖等）來控制資源的訪問，數據獲取的全部操作都需要再獲取鎖後才進行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;將獲取箱子明細的代碼移動到加鎖之後，只有獲取到分佈式鎖，才能執行分批次上架查詢和更新（串行化）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5ffc0121557805521cbb33921c4be06a.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;對應改造後的代碼：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//751c2001d8d70843f24dcf8b6fa5eaa6.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、數據庫層面：&lt;/strong&gt; 實現事務管理，確保數據的一致性；合理設置事務隔離級別，以防止髒讀、或者採用樂觀鎖或悲觀鎖來處理併發更新，合理設計查詢效率，減少鎖競爭。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;數據庫的併發上鎖處理和業務代碼的上鎖是互補的關係&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;因為無法保證後續業務的調整或其他業務代碼的調用能始終保持獲取數據的一致性，數據庫的併發上鎖處理更多是一種兜底保證機制。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;樂觀鎖更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e4262e1d681aa19763c8066296032481.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;悲觀鎖更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4078a93beef3c9b077595bb8968b3a5d.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;擴展方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;應用程序設計：&lt;/strong&gt; 在應用程序設計階段，儘量避免長時間持有數據庫連接或事務，減少併發操作的可能性，利用 AI 代碼評審或者人工提前找出可能出現併發問題的地方；合理設置鎖的粒度，避免鎖失效。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;網絡負載層面：&lt;/strong&gt; 採用限流控制訪問頻率；採用分佈式數據庫，進行數據分片，降低單節點併發壓力；使用負載均衡，將網絡請求分發到不同的服務器，提高系統處理併發的能力，防止系統過載。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;請求層面：&lt;/strong&gt; 前端點擊防重、系統冪等防重、儘可能降低同一請求的多次重試訪問引起的一致性問題。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;通過以上措施，可以在不同層面有效地防止併發問題，保證系統的數據的一致性。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18638221</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18638221</guid>
      <pubDate>Fri, 09 May 2025 03:26:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>通義千問 Qwen-TTS 新增支持北京話、上海話和四川話中文方言</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通義千問團隊更新並&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-VDOJrDgVzC6JI4CVTHe4w" target="_blank"&gt;上線&lt;/a&gt;了 Qwen-TTS 文本轉語音服務，&amp;nbsp;新增支持生成三種中文方言，包括北京話、上海話和四川話。&lt;/p&gt; 
&lt;p&gt;據介紹，Qwen-TTS 使用了超過 300 萬小時的大規模語料庫進行訓練，合成效果達到了人類級別的自然度和表現力，旨在提供超自然、富有表現力的音頻，並能智能處理韻律、語速和情感。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Qwen-TTS 能夠根據輸入文本自動調整韻律、節奏和情緒變化，進一步提升語音的真實感和表達力。&lt;/p&gt; 
&lt;p&gt;目前，Qwen-TTS 支持七種中英雙語音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京話）、Jada（上海話） 和 Sunny（四川話）。未來，我們還將推出更多語言和語音風格，進一步豐富用户的選擇體驗。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fblog%2Fqwen-tts%2F" target="_blank"&gt;https://qwenlm.github.io/blog/qwen-tts/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358128/qwen-tts</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358128/qwen-tts</guid>
      <pubDate>Fri, 09 May 2025 03:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
